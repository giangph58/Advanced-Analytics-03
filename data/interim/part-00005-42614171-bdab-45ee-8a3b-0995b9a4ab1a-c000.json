{"aid":"http://arxiv.org/abs/2503.21681v1","title":"A Comprehensive Benchmark for RNA 3D Structure-Function Modeling","summary":"The RNA structure-function relationship has recently garnered significant\nattention within the deep learning community, promising to grow in importance\nas nucleic acid structure models advance. However, the absence of standardized\nand accessible benchmarks for deep learning on RNA 3D structures has impeded\nthe development of models for RNA functional characteristics.\n  In this work, we introduce a set of seven benchmarking datasets for RNA\nstructure-function prediction, designed to address this gap. Our library builds\non the established Python library rnaglib, and offers easy data distribution\nand encoding, splitters and evaluation methods, providing a convenient\nall-in-one framework for comparing models. Datasets are implemented in a fully\nmodular and reproducible manner, facilitating for community contributions and\ncustomization. Finally, we provide initial baseline results for all tasks using\na graph neural network.\n  Source code: https://github.com/cgoliver/rnaglib\n  Documentation: https://rnaglib.org","main_category":"q-bio.BM","categories":"q-bio.BM,cs.LG,stat.ML","published":"2025-03-27T16:49:31Z"}
{"aid":"http://arxiv.org/abs/2503.21691v1","title":"Place Capability Graphs: A General-Purpose Model of Rust's Ownership and\n  Borrowing Guarantees","summary":"Rust's novel type system has proved an attractive target for verification and\nprogram analysis tools, due to the rich guarantees it provides for controlling\naliasing and mutability. However, fully understanding, extracting and\nexploiting these guarantees is subtle and challenging: existing models for\nRust's type checking either support a smaller idealised language disconnected\nfrom real-world Rust code, or come with severe limitations in terms of precise\nmodelling of Rust borrows, composite types storing them, function signatures\nand loops.\n  In this paper, we present a novel model of Rust's type-checking called Place\nCapability Graphs, which lifts these limitations, and which can be directly\ncalculated from the Rust compiler's own programmatic representations and\nanalyses. We demonstrate that our model supports over 98% of Rust functions in\nthe most popular public crates, and show its suitability as a general-purpose\nbasis for verification and program analysis tools by developing promising new\nprototype versions of the existing Flowistry and Prusti tools.","main_category":"cs.PL","categories":"cs.PL","published":"2025-03-27T16:55:41Z"}
{"aid":"http://arxiv.org/abs/2503.21698v1","title":"Anisotropic light-tailored RKKY interaction in two-dimensional $d$-wave\n  altermagnets","summary":"Altermagnets are known in spintronics for their intrinsic spin-splitting and\nunconventional magnetic responses, particularly to magnetic impurities.\nHowever, effectively controlling the magnetic exchange interactions in\naltermagnets is challenging for practical applications. Here, we propose using\ncircularly polarized light to tune the Ruderman-Kittel-Kasuya-Yosida (RKKY)\ninteraction in two-dimensional $d$-wave altermagnets. Using the real-space\nretarded Green's functions approach, our results show that while the Heisenberg\nand Ising exchanges dominate, a notable Dzyaloshinskii-Moriya (DM) interaction\nalso plays a key role. Furthermore, the inherent strength of altermagnetism\nimprints chirp-like signatures into the magnetic responses, which can be\ndynamically tuned via light. We mainly demonstrate that gate-induced Rashba\nspin-orbit coupling is essential in response to light -- light selectively and\nanisotropically adjusts the DM interaction without affecting the other\nexchanges. Our findings further indicate that rotating the altermagnet by\n$45^\\circ$ relative to the light's polarization direction generates a\nDirac-like dispersion and different DM interactions. We finally extract\ncritical thresholds where light reverses DM interactions along one axis or\nbalances both in-plane components. The anisotropic light-driven control of RKKY\ninteractions in 2D altermagnets not only highlights their unique properties but\nalso opens new avenues for engineering tailored magnetic characteristics in\nspintronic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-27T17:03:27Z"}
{"aid":"http://arxiv.org/abs/2503.21711v1","title":"Efficient Computation of the Directional Extremal Boundary of a Union of\n  Equal-Radius Circles","summary":"This paper focuses on computing the directional extremal boundary of a union\nof equal-radius circles. We introduce an efficient algorithm that accurately\ndetermines this boundary by analyzing the intersections and dominant\nrelationships among the circles. The algorithm has time complexity of O(n log\nn).","main_category":"cs.CG","categories":"cs.CG","published":"2025-03-27T17:22:14Z"}
{"aid":"http://arxiv.org/abs/2503.21715v1","title":"A Powerful Bootstrap Test of Independence in High Dimensions","summary":"This paper proposes a nonparametric test of independence of one random\nvariable from a large pool of other random variables. The test statistic is the\nmaximum of several Chatterjee's rank correlations and critical values are\ncomputed via a block multiplier bootstrap. The test is shown to asymptotically\ncontrol size uniformly over a large class of data-generating processes, even\nwhen the number of variables is much larger than sample size. The test is\nconsistent against any fixed alternative. It can be combined with a stepwise\nprocedure for selecting those variables from the pool that violate\nindependence, while controlling the family-wise error rate. All formal results\nleave the dependence among variables in the pool completely unrestricted. In\nsimulations, we find that our test is very powerful, outperforming existing\ntests in most scenarios considered, particularly in high dimensions and/or when\nthe variables in the pool are dependent.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-03-27T17:28:15Z"}
{"aid":"http://arxiv.org/abs/2503.21740v1","title":"Transitioning to Memory Burden: Detectable Small Primordial Black Holes\n  as Dark Matter","summary":"Mounting theoretical evidence suggests that black holes are subjected to the\nmemory burden effect, implying that after certain time the information stored\nin them suppresses the decay rate. This effect opens up a new window for small\nprimordial black holes (PBHs) below $10^{15}\\,{\\rm g}$ as dark matter. We show\nthat the smooth transition from semi-classical evaporation to the\nmemory-burdened phase strongly impacts observational bounds on the abundance of\nsmall PBHs. The most stringent constraints come from present-day fluxes of\nastrophysical particles. Remarkably, currently-transitioning small PBHs are\ndetectable through high-energetic neutrino events.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE,gr-qc,hep-th","published":"2025-03-27T17:51:05Z"}
{"aid":"http://arxiv.org/abs/2503.21758v1","title":"Lumina-Image 2.0: A Unified and Efficient Image Generative Framework","summary":"We introduce Lumina-Image 2.0, an advanced text-to-image generation framework\nthat achieves significant progress compared to previous work, Lumina-Next.\nLumina-Image 2.0 is built upon two key principles: (1) Unification - it adopts\na unified architecture (Unified Next-DiT) that treats text and image tokens as\na joint sequence, enabling natural cross-modal interactions and allowing\nseamless task expansion. Besides, since high-quality captioners can provide\nsemantically well-aligned text-image training pairs, we introduce a unified\ncaptioning system, Unified Captioner (UniCap), specifically designed for T2I\ngeneration tasks. UniCap excels at generating comprehensive and accurate\ncaptions, accelerating convergence and enhancing prompt adherence. (2)\nEfficiency - to improve the efficiency of our proposed model, we develop\nmulti-stage progressive training strategies and introduce inference\nacceleration techniques without compromising image quality. Extensive\nevaluations on academic benchmarks and public text-to-image arenas show that\nLumina-Image 2.0 delivers strong performances even with only 2.6B parameters,\nhighlighting its scalability and design efficiency. We have released our\ntraining details, code, and models at\nhttps://github.com/Alpha-VLLM/Lumina-Image-2.0.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:57:07Z"}
{"aid":"http://arxiv.org/abs/2503.21762v1","title":"On the open TS/ST correspondence","summary":"The topological string/spectral theory correspondence establishes a precise,\nnon-perturbative duality between topological strings on local Calabi-Yau\nthreefolds and the spectral theory of quantized mirror curves. While this\nduality has been rigorously formulated for the closed topological string\nsector, the open string sector remains less understood. Building on the results\nof [1-3], we make further progress in this direction by constructing entire,\noff-shell eigenfunctions for the quantized mirror curve from open topological\nstring partition functions. We focus on local $\\mathbb{F}_0$, whose mirror\ncurve corresponds to the Baxter equation of the two-particle, relativistic Toda\nlattice. We then study the standard and dual four-dimensional limits, where the\nquantum mirror curve for local $\\mathbb{F}_0$ degenerates into the modified\nMathieu and McCoy-Tracy-Wu operators, respectively. In these limits, our\nframework provides a way to construct entire, off-shell eigenfunctions for the\ndifference equations associated with these operators. Furthermore, we find a\nsimple relation between the on-shell eigenfunctions of the modified Mathieu and\nMcCoy-Tracy-Wu operators, leading to a functional relation between the\noperators themselves.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,math.SP","published":"2025-03-27T17:57:37Z"}
{"aid":"http://arxiv.org/abs/2503.21765v1","title":"Exploring the Evolution of Physics Cognition in Video Generation: A\n  Survey","summary":"Recent advancements in video generation have witnessed significant progress,\nespecially with the rapid advancement of diffusion models. Despite this, their\ndeficiencies in physical cognition have gradually received widespread attention\n- generated content often violates the fundamental laws of physics, falling\ninto the dilemma of ''visual realism but physical absurdity\". Researchers began\nto increasingly recognize the importance of physical fidelity in video\ngeneration and attempted to integrate heuristic physical cognition such as\nmotion representations and physical knowledge into generative systems to\nsimulate real-world dynamic scenarios. Considering the lack of a systematic\noverview in this field, this survey aims to provide a comprehensive summary of\narchitecture designs and their applications to fill this gap. Specifically, we\ndiscuss and organize the evolutionary process of physical cognition in video\ngeneration from a cognitive science perspective, while proposing a three-tier\ntaxonomy: 1) basic schema perception for generation, 2) passive cognition of\nphysical knowledge for generation, and 3) active cognition for world\nsimulation, encompassing state-of-the-art methods, classical paradigms, and\nbenchmarks. Subsequently, we emphasize the inherent key challenges in this\ndomain and delineate potential pathways for future research, contributing to\nadvancing the frontiers of discussion in both academia and industry. Through\nstructured review and interdisciplinary analysis, this survey aims to provide\ndirectional guidance for developing interpretable, controllable, and physically\nconsistent video generation paradigms, thereby propelling generative models\nfrom the stage of ''visual mimicry'' towards a new phase of ''human-like\nphysical comprehension''.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:58:33Z"}
{"aid":"http://arxiv.org/abs/2503.21779v1","title":"X$^{2}$-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time\n  Tomographic Reconstruction","summary":"Four-dimensional computed tomography (4D CT) reconstruction is crucial for\ncapturing dynamic anatomical changes but faces inherent limitations from\nconventional phase-binning workflows. Current methods discretize temporal\nresolution into fixed phases with respiratory gating devices, introducing\nmotion misalignment and restricting clinical practicality. In this paper, We\npropose X$^2$-Gaussian, a novel framework that enables continuous-time 4D-CT\nreconstruction by integrating dynamic radiative Gaussian splatting with\nself-supervised respiratory motion learning. Our approach models anatomical\ndynamics through a spatiotemporal encoder-decoder architecture that predicts\ntime-varying Gaussian deformations, eliminating phase discretization. To remove\ndependency on external gating devices, we introduce a physiology-driven\nperiodic consistency loss that learns patient-specific breathing cycles\ndirectly from projections via differentiable optimization. Extensive\nexperiments demonstrate state-of-the-art performance, achieving a 9.93 dB PSNR\ngain over traditional methods and 2.25 dB improvement against prior Gaussian\nsplatting techniques. By unifying continuous motion modeling with hardware-free\nperiod learning, X$^2$-Gaussian advances high-fidelity 4D CT reconstruction for\ndynamic clinical imaging. Project website at: https://x2-gaussian.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2503.23682v1","title":"Stability conditions on blowups","summary":"We study the relation between perverse stability conditions and geometric\nstability conditions under blow up. We confirm a conjecture of Toda in some\nspecial cases and show that geometric stability conditions can be induced from\nperverse stability conditions from semiorthogonal decompositions associated to\nblowups.","main_category":"math.AG","categories":"math.AG","published":"2025-03-31T03:13:46Z"}
{"aid":"http://arxiv.org/abs/2503.23689v1","title":"Existence of complete conformal metrics on $\\mathbb{R}^n$ with\n  prescribed Q-curvature","summary":"Given a smooth function $f(x)$ on $\\mathbb{R}^n$ which is positive somewhere\nand satisfies $f(x)=O(|x|^{-l})$ for any $l>\\frac{n}{2}$, we show that there\nexists a complete and conformal metric $g=e^{2u}|dx|^2$ with finite total\nQ-curvature such that its Q-curvature equals to $f(x)$.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-03-31T03:38:56Z"}
{"aid":"http://arxiv.org/abs/2503.23701v1","title":"Topological Electronic Structure and Transport Properties of the\n  Distorted Rutile-type WO$_2$","summary":"We elucidate the transport properties and electronic structures of distorted\nrutile-type WO2. Electrical resistivity and Hall effect measurements of\nhigh-quality single crystals revealed the transport property characteristics of\ntopological materials; these characteristics included an extremely large\nmagnetoresistance of 13,200% (2 K and 9 T) and a very high carrier mobility of\n25,700 cm2 V-1 s-1 (5 K). First-principles calculations revealed Dirac nodal\nlines (DNL) near the Fermi energy in the electronic structure when spin-orbit\ninteractions (SOIs) were absent. Although these DNLs mostly disappeared in the\npresence of SOIs, band crossings at high-symmetry points in the reciprocal\nspace existed as Dirac points. Furthermore, DNLs protected by nonsymmorphic\nsymmetry persisted on the ky = {\\pi}/b plane. The unique transport properties\noriginating from the topological electronic structure of chemically and\nthermally stable WO2 could represent an opportunity to investigate the\npotential electronic applications of the material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T03:58:36Z"}
{"aid":"http://arxiv.org/abs/2503.23704v1","title":"Paramagnetic half-moon shaped diffuse scattering arising from 3D\n  magnetic frustration","summary":"We use spin dynamics simulations to determine the origin of the unusual\ncorrelated diffuse scattering, characterised by half-moon shapes bridging the\nmagnetic Bragg peaks, observed in the polarised elastic neutron scattering from\nmanganese tungstate, MnWO\\textsubscript{4}. We first fit a Heisenberg\nHamiltonian with twelve nearest-neighbour exchange interactions and single-ion\nanisotropy to the experimental ground-state magnon dispersion. We then show via\nspin dynamics simulations that our model Hamiltonian both reproduces the\nexperimentally observed half-moon features and captures their persistence into\nthe paramagnetic regime. Moreover, we identify the three-dimensional, competing\nantiferromagnetic interactions driving this behavior. Our work complements\nearlier studies of half-moon-shaped signatures in pyrochlore and triangular\nstructures, by providing insight into their origin in a zigzag chain geometry\nwith three-dimensional competing exchange interactions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-03-31T04:01:00Z"}
{"aid":"http://arxiv.org/abs/2503.23708v1","title":"Towards Benchmarking and Assessing the Safety and Robustness of\n  Autonomous Driving on Safety-critical Scenarios","summary":"Autonomous driving has made significant progress in both academia and\nindustry, including performance improvements in perception task and the\ndevelopment of end-to-end autonomous driving systems. However, the safety and\nrobustness assessment of autonomous driving has not received sufficient\nattention. Current evaluations of autonomous driving are typically conducted in\nnatural driving scenarios. However, many accidents often occur in edge cases,\nalso known as safety-critical scenarios. These safety-critical scenarios are\ndifficult to collect, and there is currently no clear definition of what\nconstitutes a safety-critical scenario. In this work, we explore the safety and\nrobustness of autonomous driving in safety-critical scenarios. First, we\nprovide a definition of safety-critical scenarios, including static traffic\nscenarios such as adversarial attack scenarios and natural distribution shifts,\nas well as dynamic traffic scenarios such as accident scenarios. Then, we\ndevelop an autonomous driving safety testing platform to comprehensively\nevaluate autonomous driving systems, encompassing not only the assessment of\nperception modules but also system-level evaluations. Our work systematically\nconstructs a safety verification process for autonomous driving, providing\ntechnical support for the industry to establish standardized test framework and\nreduce risks in real-world road deployment.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-03-31T04:13:32Z"}
{"aid":"http://arxiv.org/abs/2503.23712v1","title":"ElimPCL: Eliminating Noise Accumulation with Progressive Curriculum\n  Labeling for Source-Free Domain Adaptation","summary":"Source-Free Domain Adaptation (SFDA) aims to train a target model without\nsource data, and the key is to generate pseudo-labels using a pre-trained\nsource model. However, we observe that the source model often produces highly\nuncertain pseudo-labels for hard samples, particularly those heavily affected\nby domain shifts, leading to these noisy pseudo-labels being introduced even\nbefore adaptation and further reinforced through parameter updates.\nAdditionally, they continuously influence neighbor samples through propagation\nin the feature space.To eliminate the issue of noise accumulation, we propose a\nnovel Progressive Curriculum Labeling (ElimPCL) method, which iteratively\nfilters trustworthy pseudo-labeled samples based on prototype consistency to\nexclude high-noise samples from training. Furthermore, a Dual MixUP technique\nis designed in the feature space to enhance the separability of hard samples,\nthereby mitigating the interference of noisy samples on their\nneighbors.Extensive experiments validate the effectiveness of ElimPCL,\nachieving up to a 3.4% improvement on challenging tasks compared to\nstate-of-the-art methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:28:27Z"}
{"aid":"http://arxiv.org/abs/2503.23744v1","title":"European Contributions to Fermilab Accelerator Upgrades and Facilities\n  for the DUNE Experiment","summary":"The Proton Improvement Plan (PIP-II) to the FNAL accelerator chain and the\nLong-Baseline Neutrino Facility (LBNF) will provide the world's most intense\nneutrino beam to the Deep Underground Neutrino Experiment (DUNE) enabling a\nwide-ranging physics program. This document outlines the significant\ncontributions made by European national laboratories and institutes towards\nrealizing the first phase of the project with a 1.2 MW neutrino beam.\nConstruction of this first phase is well underway. For DUNE Phase II, this will\nbe closely followed by an upgrade of the beam power to > 2 MW, for which the\nEuropean groups again have a key role and which will require the continued\nsupport of the European community for machine aspects of neutrino physics.\nBeyond the neutrino beam aspects, LBNF is also responsible for providing unique\ninfrastructure to install and operate the DUNE neutrino detectors at FNAL and\nat the Sanford Underground Research Facility (SURF). The cryostats for the\nfirst two Liquid Argon Time Projection Chamber detector modules at SURF, a\ncontribution of CERN to LBNF, are central to the success of the ongoing\nexecution of DUNE Phase I. Likewise, successful and timely procurement of\ncryostats for two additional detector modules at SURF will be critical to the\nsuccess of DUNE Phase II and the overall physics program. The DUNE\nCollaboration is submitting four main contributions to the 2026 Update of the\nEuropean Strategy for Particle Physics process. This paper is being submitted\nto the 'Accelerator technologies' and 'Projects and Large Experiments' streams.\nAdditional inputs related to the DUNE science program, DUNE detector\ntechnologies and R&D, and DUNE software and computing, are also being submitted\nto other streams.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex,physics.ins-det","published":"2025-03-31T05:47:29Z"}
{"aid":"http://arxiv.org/abs/2503.23756v1","title":"On a natural L2 metric on the space of Hermitian metrics","summary":"We investigate the space of Hermitian metrics on a fixed complex vector\nbundle. This infinite-dimensional space has appeared in the study of\nHermitian-Einstein structures, where a special L2-type Riemannian metric is\nintroduced. We compute the metric spray, geodesics and curvature associated to\nthis metric, and show that the exponential map is a diffeomorphsim. Though\nbeing geodesically complete, the space of Hermitian metrics is metrically\nincomplete, and its metric completion is proved to be the space of L2\nintegrable singular Hermitian metrics. In addition, both the original space and\nits completion are CAT(0). In the holomorphic case, it turns out that Griffiths\nseminegative/semipositive singular Hermitian metric is always L2 integrable in\nour sense. Also, in the Appendix, the Nash-Moser inverse function theorem is\nused to prove that, for any L2 metric on the space of smooth sections of a\ngiven fiber bundle, the exponential map is always a local diffeomorphism,\nprovided that each fiber is nonpositively curved.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T06:12:40Z"}
{"aid":"http://arxiv.org/abs/2503.23762v1","title":"UniSep: Universal Target Audio Separation with Language Models at Scale","summary":"We propose Universal target audio Separation (UniSep), addressing the\nseparation task on arbitrary mixtures of different types of audio.\nDistinguished from previous studies, UniSep is performed on unlimited source\ndomains and unlimited source numbers. We formulate the separation task as a\nsequence-to-sequence problem, and a large language model (LLM) is used to model\nthe audio sequence in the discrete latent space, leveraging the power of LLM in\nhandling complex mixture audios with large-scale data. Moreover, a novel\npre-training strategy is proposed to utilize audio-only data, which reduces the\nefforts of large-scale data simulation and enhances the ability of LLMs to\nunderstand the consistency and correlation of information within audio\nsequences. We also demonstrate the effectiveness of scaling datasets in an\naudio separation task: we use large-scale data (36.5k hours), including speech,\nmusic, and sound, to train a universal target audio separation model that is\nnot limited to a specific domain. Experiments show that UniSep achieves\ncompetitive subjective and objective evaluation results compared with\nsingle-task models.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-03-31T06:27:37Z"}
{"aid":"http://arxiv.org/abs/2503.23763v1","title":"Career Incentives, Risk-Taking, and Sorting Dynamics: Evidence from Top\n  Financial Advisers","summary":"We examine how career concerns influence the behavior and mobility of\nfinancial advisers. Drawing on a uniquely comprehensive matched panel that\ncombines employer-employee data with a longstanding national ranking, our study\ntests predictions from classic career concerns models and tournament theory.\nOur analysis shows that, in the early stages of their careers, advisers\ndestined for top performance differ significantly from their peers.\nSpecifically, before being ranked, these advisers are twice as likely to obtain\na key investment license, experience customer disputes at rates up to seven\ntimes higher, and transition to firms with 80% larger total assets. Moreover,\nwe find that top advisers mitigate the potential costs of their higher\nrisk-taking by facing reduced labor market penalties following disciplinary\nactions. Leveraging exogenous variation from the staggered adoption of the\nBroker Protocol through an event-study framework, our results reveal dynamic\nsorting: firms attract high-performing advisers intensely within a short\npost-adoption period. These findings shed new light on the interplay between\ncareer incentives, risk-taking, and labor market outcomes in the financial\nservices industry, with important implications for both firm performance and\nregulatory policy.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T06:27:41Z"}
{"aid":"http://arxiv.org/abs/2503.23782v1","title":"Distributional regression with reject option","summary":"Selective prediction, where a model has the option to abstain from making a\ndecision, is crucial for machine learning applications in which mistakes are\ncostly. In this work, we focus on distributional regression and introduce a\nframework that enables the model to abstain from estimation in situations of\nhigh uncertainty. We refer to this approach as distributional regression with\nreject option, inspired by similar concepts in classification and regression\nwith reject option. We study the scenario where the rejection rate is fixed. We\nderive a closed-form expression for the optimal rule, which relies on\nthresholding the entropy function of the Continuous Ranked Probability Score\n(CRPS). We propose a semi-supervised estimation procedure for the optimal rule,\nusing two datasets: the first, labeled, is used to estimate both the\nconditional distribution function and the entropy function of the CRPS, while\nthe second, unlabeled, is employed to calibrate the desired rejection rate.\nNotably, the control of the rejection rate is distribution-free. Under mild\nconditions, we show that our procedure is asymptotically as effective as the\noptimal rule, both in terms of error rate and rejection rate. Additionally, we\nestablish rates of convergence for our approach based on distributional\nk-nearest neighbor. A numerical analysis on real-world datasets demonstrates\nthe strong performance of our procedure","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-03-31T06:56:18Z"}
{"aid":"http://arxiv.org/abs/2503.23790v1","title":"Constructing geometric realizations of birational maps between Mori\n  Dream Spaces","summary":"We construct geometric realizations -- projective algebraic versions of\ncobordisms -- for birational maps between Mori Dream Spaces. We show that these\ngeometric realizations are Mori Dream Spaces, as well, and that they can be\nconstructed so that they induce factorizations of the original birational maps\nas compositions of wall-crossings. In the case of toric birational maps between\nnormal $\\mathbb{Q}$-factorial, projective toric varieties, we provide several\nSageMath functions to work with $\\mathbb{C}^*$-actions and birational geometry;\nin particular we show how to explicitly construct a moment polytope of a toric\ngeometric realization. Moreover, by embedding Mori Dream Spaces in toric\nvarieties, we obtain geometric realizations of birational maps of Mori Dream\nSpaces as restrictions of toric geometric realizations. We also provide\nexamples and discuss when a geometric realization is Fano.","main_category":"math.AG","categories":"math.AG","published":"2025-03-31T07:07:54Z"}
{"aid":"http://arxiv.org/abs/2503.23794v1","title":"Force-Free Molecular Dynamics Through Autoregressive Equivariant\n  Networks","summary":"Molecular dynamics (MD) simulations play a crucial role in scientific\nresearch. Yet their computational cost often limits the timescales and system\nsizes that can be explored. Most data-driven efforts have been focused on\nreducing the computational cost of accurate interatomic forces required for\nsolving the equations of motion. Despite their success, however, these machine\nlearning interatomic potentials (MLIPs) are still bound to small time-steps. In\nthis work, we introduce TrajCast, a transferable and data-efficient framework\nbased on autoregressive equivariant message passing networks that directly\nupdates atomic positions and velocities lifting the constraints imposed by\ntraditional numerical integration. We benchmark our framework across various\nsystems, including a small molecule, crystalline material, and bulk liquid,\ndemonstrating excellent agreement with reference MD simulations for structural,\ndynamical, and energetic properties. Depending on the system, TrajCast allows\nfor forecast intervals up to $30\\times$ larger than traditional MD time-steps,\ngenerating over 15 ns of trajectory data per day for a solid with more than\n4,000 atoms. By enabling efficient large-scale simulations over extended\ntimescales, TrajCast can accelerate materials discovery and explore physical\nphenomena beyond the reach of traditional simulations and experiments. An\nopen-source implementation of TrajCast is accessible under\nhttps://github.com/IBM/trajcast.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,cs.LG,physics.chem-ph","published":"2025-03-31T07:14:32Z"}
{"aid":"http://arxiv.org/abs/2503.23801v1","title":"A PINN Methodology for Temperature Field Reconstruction in the PIV\n  Measurement Plane: Case of Rayleigh-BÃ©nard Convection","summary":"We present a method to infer temperature fields from stereo particle-image\nvelocimetry (PIV) data in turbulent Rayleigh-B\\'enard convection (RBC) using\nPhysics-informed neural networks (PINNs). The physical setup is a cubic RBC\ncell with Rayleigh number $\\text{Ra}=10^7$ and Prandtl number $\\text{Pr}=0.7$.\nWith data only available in a vertical plane $A:x=x_0$, the residuals of the\ngoverning partial differential equations are minimised in an enclosing 3D\ndomain around $A$ with thickness $\\delta_x$. Dynamic collocation point sampling\nstrategies are used to overcome the lack of 3D labelled information and to\noptimize the overall convergence of the PINN. In particular, in the\nout-of-plane direction $x$, the collocation points are distributed according to\na normal distribution, in order to emphasize the region where data is provided.\nAlong the vertical direction, we leverage meshing information and sample points\nfrom a distribution designed based on the grid of a direct numerical simulation\n(DNS). This approach points greater attention to critical regions, particularly\nthe areas with high temperature gradients within the thermal boundary layers.\nUsing planar three-component velocity data from a DNS, we successfully validate\nthe reconstruction of the temperature fields in the PIV plane. We evaluate the\nrobustness of our method with respect to characteristics of the labelled data\nused for training: the data time span, the sampling frequency, some noisy data\nand boundary data omission, aiming to better accommodate the challenges\nassociated with experimental data. Developing PINNs on controlled simulation\ndata is a crucial step toward their effective deployment on experimental data.\nThe key is to systematically introduce noise, gaps, and uncertainties in\nsimulated data to mimic real-world conditions and ensure robust generalization.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-03-31T07:24:06Z"}
{"aid":"http://arxiv.org/abs/2503.23812v1","title":"A new independent look at the galactic black hole low-mass X-ray binary\n  distribution","summary":"Investigations of the Galactic black hole low-mass X-ray binaries (BH-LMXBs)\noffer valuable insights into the elusive black hole population in the Milky\nWay. Motivated by recent tensions in the natal kick velocity distribution and\nBH mass distribution of BH-LMXBs, we revisit the spatial distribution of the\nGalactic BH-LMXBs using a new set of distance measurements obtained from an\nX-ray spectral modelling framework that we introduced in earlier work. We\nperform a multiparameter simulation study to mitigate part of the bias present\nin our prior estimates and gain insights into possible observational selection\neffects that affect the observed population. We derive a bias correction\nfactor, well described by a Pareto probability density function that closely\nfollows an inverse-square law dependence on distance. We then construct a\nbias-corrected, literature-independent, Galactic spatial distribution that\nclearly traces spiral arm structures and shows a deficit of sources very close\nto the Galactic centre, which might be explained due to high extinction or a\ntrue paucity of these sources at that region. Further analysis of the\nsimulation results provides hints for a hidden population of BH-LMXBs at low\nGalactic heights. Lastly, we estimate the root-mean-squared Galactic height and\nfind that it is most compatible with a hybrid scenario of BH formation, with\nsome BHs receiving high natal kicks and thus propelled further from the thin\ndisc plane while others receiving low natal kicks and remaining close to their\nbirth place.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-03-31T07:45:41Z"}
{"aid":"http://arxiv.org/abs/2503.23813v1","title":"Evaluation of a Virtual Laboratory Platform in General Education on\n  Quantum Information Science","summary":"Quantum information science and technology has been revolutionizing our daily\nlife, which attracts the curiosity of young generations from diverse\nbackgrounds. While it is quite challenging to teach and learn quantum\ninformation science for non-physics majors due to the abstract and counter\nintuitive nature of quantum mechanics. To address such challenges, virtual\nlaboratories have offered an effective solution. This paper presents the\nresults of pedagogical research on the efficacy of a virtual laboratory\nplatform in general education courses on quantum information science.\nSpecifically, a virtual lab activity on the Bell test was developed using the\ncommercially available platform QLab. This activity aims to help undergraduates\nfrom diverse disciplines grasp the counterintuitive yet fundamental concept of\nquantum entanglement, famously referred to by Albert Einstein as \"spooky action\nat a distance.\" Qualitative and quantitative evaluations were conducted over\nthree academic years, demonstrating that the virtual laboratory enabled over 80\n\\% of students to comprehend the complex concept and characteristics of quantum\nentanglement. This study provides an effective solution for addressing the\nchallenges of teaching quantum information science in undergraduate general\neducation courses, particularly for students from both science and non-science\nbackgrounds.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-03-31T07:47:24Z"}
{"aid":"http://arxiv.org/abs/2503.23814v1","title":"An extension of linear self-attention for in-context learning","summary":"In-context learning is a remarkable property of transformers and has been the\nfocus of recent research. An attention mechanism is a key component in\ntransformers, in which an attention matrix encodes relationships between words\nin a sentence and is used as weights for words in a sentence. This mechanism is\neffective for capturing language representations. However, it is questionable\nwhether naive self-attention is suitable for in-context learning in general\ntasks, since the computation implemented by self-attention is somewhat\nrestrictive in terms of matrix multiplication. In fact, we may need appropriate\ninput form designs when considering heuristic implementations of computational\nalgorithms. In this paper, in case of linear self-attention, we extend it by\nintroducing a bias matrix in addition to a weight matrix for an input. Despite\nthe simple extension, the extended linear self-attention can output any\nconstant matrix, input matrix and multiplications of two or three matrices in\nthe input. Note that the second property implies that it can be a skip\nconnection. Therefore, flexible matrix manipulations can be implemented by\nconnecting the extended linear self-attention components. As an example of\nimplementation using the extended linear self-attention, we show a heuristic\nconstruction of a batch-type gradient descent of ridge regression under a\nreasonable input form.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T07:49:05Z"}
{"aid":"http://arxiv.org/abs/2503.23821v1","title":"Science4Peace: A Plea for Continued Peaceful International Scientific\n  Cooperation (Input to the European Strategy for Particle Physics -- 2026\n  update)","summary":"The European Strategy for Particle Physics (ESPP) - 2026 update is taking\nplace in a turbulent international climate. Many of the norms that have\ngoverned relations between states for decades are being broken or challenged.\nThe future progress of science in general, and particle physics in particular,\nwill depend on our ability to maintain peaceful international scientific\ncollaboration in the face of political pressures. We plead that the ESPP 2026\nupdate acknowledge explicitly the importance of peaceful international\nscientific collaboration, not only for the progress of science, but also as a\nprecious bridge between geopolitical blocs.\n  \"Scientific thought is the common heritage of mankind\" - Abdus Salam","main_category":"physics.soc-ph","categories":"physics.soc-ph,hep-ex,hep-ph,hep-th","published":"2025-03-31T08:15:42Z"}
{"aid":"http://arxiv.org/abs/2503.23824v1","title":"On the Reproducibility of Learned Sparse Retrieval Adaptations for Long\n  Documents","summary":"Document retrieval is one of the most challenging tasks in Information\nRetrieval. It requires handling longer contexts, often resulting in higher\nquery latency and increased computational overhead. Recently, Learned Sparse\nRetrieval (LSR) has emerged as a promising approach to address these\nchallenges. Some have proposed adapting the LSR approach to longer documents by\naggregating segmented document using different post-hoc methods, including\nn-grams and proximity scores, adjusting representations, and learning to\nensemble all signals. In this study, we aim to reproduce and examine the\nmechanisms of adapting LSR for long documents. Our reproducibility experiments\nconfirmed the importance of specific segments, with the first segment\nconsistently dominating document retrieval performance. Furthermore, We\nre-evaluate recently proposed methods -- ExactSDM and SoftSDM -- across varying\ndocument lengths, from short (up to 2 segments) to longer (3+ segments). We\nalso designed multiple analyses to probe the reproduced methods and shed light\non the impact of global information on adapting LSR to longer contexts. The\ncomplete code and implementation for this project is available at:\nhttps://github.com/lionisakis/Reproducibilitiy-lsr-long.","main_category":"cs.IR","categories":"cs.IR","published":"2025-03-31T08:19:31Z"}
{"aid":"http://arxiv.org/abs/2503.23828v1","title":"High-Throughput Exploration of NV-like Color Centers Across Host\n  Materials","summary":"Point defects in semiconductors offer a promising platform for advancing\nquantum technologies due to their localized energy states and controllable spin\nproperties. Prior research has focused on a limited set of defects within\nmaterials such as diamond, silicon carbide, and hexagonal boron nitride. We\npresent a high-throughput study to systematically identify and evaluate point\ndefects across a diverse range of host materials, aiming to uncover previously\nunexplored defects in novel host materials suitable for use in quantum\napplications. A range of host materials are selected for their desirable\nproperties, such as appropriate bandgaps, crystal structure, and absence of d-\nor f-electrons. The Automatic Defect Analysis and Qualification (ADAQ) software\nframework is used to generate vacancies, substitutions with s- and p-elements,\nand interstitials in these materials and use density functional theory to\ncalculate key properties such as Zero-Phonon Lines (ZPLs), ionic displacements,\nTransition Dipole Moments (TDMs), and formation energies. Special attention is\ngiven to charge correction methods for materials with dielectric anisotropy. We\nuncover new defect-host combinations with advantageous properties for quantum\napplications: 28 defects across 11 isotropic and 2 anisotropic host materials\nshow properties similar to the nitrogen-vacancy (NV) center in diamond.\nBeryllium (Be) substitutional defects in SrS, MgS, and SrO emerge as particu-\nlarly promising. These findings contribute to diversifying and enhancing the\nmaterials available for quantum technologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T08:22:24Z"}
{"aid":"http://arxiv.org/abs/2503.23839v1","title":"Three-dimensional Optical Reconstruction of colloidal electrokinetics\n  via multiplane imaging","summary":"Selective manipulation of particles is crucial in many fields, ranging from\nchemistry to biology and physics. Dielectrophoresis stands out due to its high\nselectivity potential and the absence of need for labels. To fully understand\nand control the phenomenon, observation of the dynamic of nanoparticles under\nDEP needs to be performed in the three spatial dimensions. However, not many\nmicroscopy approaches offer such capability at fast frame rates (>100fps) and\nhigh resolution. Here, we used widefield microscopy, to follow the\nspatiotemporal dynamics of fluorescently labelled polystyrene nanoparticles of\n200 nm under positive and negative dielectrophoresis conditions. This real-time\n3D imaging technique allows for single particle tracking, enabling\nsuper-resolved reconstruction of the DEP force and electrokinetic flows with\nunprecedented detail. We compare the differences for positive and negative\ndielectrophoresis conditions and rationalize these by direct comparison with\ndynamic modeling results. The framework shown here shows great promise to\nelucidate the frequency-dependent DEP behavior of nanoparticle, crucial for\nparticle manipulation and sorting.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-03-31T08:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.23877v1","title":"ZeroMimic: Distilling Robotic Manipulation Skills from Web Videos","summary":"Many recent advances in robotic manipulation have come through imitation\nlearning, yet these rely largely on mimicking a particularly hard-to-acquire\nform of demonstrations: those collected on the same robot in the same room with\nthe same objects as the trained policy must handle at test time. In contrast,\nlarge pre-recorded human video datasets demonstrating manipulation skills\nin-the-wild already exist, which contain valuable information for robots. Is it\npossible to distill a repository of useful robotic skill policies out of such\ndata without any additional requirements on robot-specific demonstrations or\nexploration? We present the first such system ZeroMimic, that generates\nimmediately deployable image goal-conditioned skill policies for several common\ncategories of manipulation tasks (opening, closing, pouring, pick&place,\ncutting, and stirring) each capable of acting upon diverse objects and across\ndiverse unseen task setups. ZeroMimic is carefully designed to exploit recent\nadvances in semantic and geometric visual understanding of human videos,\ntogether with modern grasp affordance detectors and imitation policy classes.\nAfter training ZeroMimic on the popular EpicKitchens dataset of ego-centric\nhuman videos, we evaluate its out-of-the-box performance in varied real-world\nand simulated kitchen settings with two different robot embodiments,\ndemonstrating its impressive abilities to handle these varied tasks. To enable\nplug-and-play reuse of ZeroMimic policies on other task setups and robots, we\nrelease software and policy checkpoints of our skill policies.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.LG","published":"2025-03-31T09:27:00Z"}
{"aid":"http://arxiv.org/abs/2503.23885v1","title":"Robust Suboptimal Local Basis Function Algorithms for Identification of\n  Nonstationary FIR Systems in Impulsive Noise Environments","summary":"While local basis function (LBF) estimation algorithms, commonly used for\nidentifying/tracking systems with time-varying parameters, demonstrate good\nperformance under the assumption of normally distributed measurement noise, the\nestimation results may significantly deviate from satisfactory when the noise\ndistribution is impulsive in nature, for example, corrupted by outliers. This\npaper introduces a computationally efficient method to make the LBF estimator\nrobust, enhancing its resistance to impulsive noise. First, the choice of basis\nfunctions is optimized based on the knowledge of parameter variation\nstatistics. Then, the parameter tracking algorithm is made robust using the\nsequential data trimming technique. Finally, it is demonstrated that the\nproposed algorithm can undergo online tuning through parallel estimation and\nleave-one-out cross-validation.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-03-31T09:37:58Z"}
{"aid":"http://arxiv.org/abs/2503.23888v1","title":"MuseFace: Text-driven Face Editing via Diffusion-based Mask Generation\n  Approach","summary":"Face editing modifies the appearance of face, which plays a key role in\ncustomization and enhancement of personal images. Although much work have\nachieved remarkable success in text-driven face editing, they still face\nsignificant challenges as none of them simultaneously fulfill the\ncharacteristics of diversity, controllability and flexibility. To address this\nchallenge, we propose MuseFace, a text-driven face editing framework, which\nrelies solely on text prompt to enable face editing. Specifically, MuseFace\nintegrates a Text-to-Mask diffusion model and a semantic-aware face editing\nmodel, capable of directly generating fine-grained semantic masks from text and\nperforming face editing. The Text-to-Mask diffusion model provides\n\\textit{diversity} and \\textit{flexibility} to the framework, while the\nsemantic-aware face editing model ensures \\textit{controllability} of the\nframework. Our framework can create fine-grained semantic masks, making precise\nface editing possible, and significantly enhancing the controllability and\nflexibility of face editing models. Extensive experiments demonstrate that\nMuseFace achieves superior high-fidelity performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:41:09Z"}
{"aid":"http://arxiv.org/abs/2503.23895v1","title":"Better wit than wealth: Dynamic Parametric Retrieval Augmented\n  Generation for Test-time Knowledge Enhancement","summary":"Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nretrieving relevant documents from external sources and incorporating them into\nthe context. While it improves reliability by providing factual texts, it\nsignificantly increases inference costs as context length grows and introduces\nchallenging issue of RAG hallucination, primarily caused by the lack of\ncorresponding parametric knowledge in LLMs. An efficient solution is to enhance\nthe knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by\nembedding document into LLMs parameters to perform test-time knowledge\nenhancement, effectively reducing inference costs through offline training.\nHowever, its high training and storage costs, along with limited generalization\nability, significantly restrict its practical adoption. To address these\nchallenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that\nleverages a lightweight parameter translator model to efficiently convert\ndocuments into parametric knowledge. DyPRAG not only reduces inference,\ntraining, and storage costs but also dynamically generates parametric\nknowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge\nconflicts in a plug-and-play manner at test-time. Extensive experiments on\nmultiple datasets demonstrate the effectiveness and generalization capabilities\nof DyPRAG, offering a powerful and practical RAG paradigm which enables\nsuperior knowledge fusion and mitigates RAG hallucination in real-world\napplications. Our code is available at https://github.com/Trae1ounG/DyPRAG.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T09:46:35Z"}
{"aid":"http://arxiv.org/abs/2503.23905v1","title":"Boosting MLLM Reasoning with Text-Debiased Hint-GRPO","summary":"MLLM reasoning has drawn widespread research for its excellent\nproblem-solving capability. Current reasoning methods fall into two types: PRM,\nwhich supervises the intermediate reasoning steps, and ORM, which supervises\nthe final results. Recently, DeepSeek-R1 has challenged the traditional view\nthat PRM outperforms ORM, which demonstrates strong generalization performance\nusing an ORM method (i.e., GRPO). However, current MLLM's GRPO algorithms still\nstruggle to handle challenging and complex multimodal reasoning tasks (e.g.,\nmathematical reasoning). In this work, we reveal two problems that impede the\nperformance of GRPO on the MLLM: Low data utilization and Text-bias. Low data\nutilization refers to that GRPO cannot acquire positive rewards to update the\nMLLM on difficult samples, and text-bias is a phenomenon that the MLLM bypasses\nimage condition and solely relies on text condition for generation after GRPO\ntraining. To tackle these problems, this work proposes Hint-GRPO that improves\ndata utilization by adaptively providing hints for samples of varying\ndifficulty, and text-bias calibration that mitigates text-bias by calibrating\nthe token prediction logits with image condition in test-time. Experiment\nresults on three base MLLMs across eleven datasets demonstrate that our\nproposed methods advance the reasoning capability of original MLLM by a large\nmargin, exhibiting superior performance to existing MLLM reasoning methods. Our\ncode is available at https://github.com/hqhQAQ/Hint-GRPO.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:54:55Z"}
{"aid":"http://arxiv.org/abs/2503.23916v1","title":"Deterministic Bottom-Up Fabrication of Plasmonic Nanostructures on\n  Optical Nanofibers via Blurred Electron Beam Deposition","summary":"This study introduces a novel method for the deterministic fabrication of\nmetallic nanostructures with controlled geometry and composition on suspended,\nsingle mode tapered optical nanofibers (TNFs) using a tailored Blurred Electron\nBeam Induced Deposition (BEBID) technique. TNFs, owing to their subwavelength\ndiameters and intense evanescent fields, offer a unique platform for enhanced\nlight matter interactions at the nanoscale. However, their mechanical fragility\nhas thus far hindered the integration of plasmonic structures using\nconventional high energy deposition methods. BEBID addresses this limitation by\ndeliberately defocusing the electron beam to reduce local mechanical stress,\nminimize vibration, and prevent fiber damage during deposition, thereby\nenabling the one-step growth of platinum nanopillars with sub 20 nm spatial\nprecision and high structural fidelity directly on suspended TNFs. The\nfabricated structures were characterized using SEM, EDX, and their optical\nproperties were investigated through broadband scattering spectra and\npolarization resolved measurements, showing strong agreement with Finite\nDifference Time Domain (FDTD) simulations. Numerical modeling further reveals\nthat ordered arrays of nanopillars can shape and direct the scattered field\nalong the fiber axis, enabling directional emission. This work establishes\nBEBID as a versatile bottom up nanofabrication approach for functional photonic\narchitectures on fragile substrates, with direct applications in quantum\nphotonics, nano optics, and on fiber plasmonic sensing.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-03-31T10:06:58Z"}
{"aid":"http://arxiv.org/abs/2503.23919v1","title":"Production of $K^+K^-$ Pairs Through Decay of $Ï$ Meson","summary":"We develop a theoretical framework for the production of $K^+K^-$ pairs\nthrough the decay of $\\phi$ mesons produced from a thermal background, based on\nthe Nambu-Jona-Lasinio (NJL) model. The differential production rate of\n$K^+K^-$ is related to the self-energy of the $\\phi$ meson, incorporating the\ncontributions of the quark loop at leading order and the kaon loop at\nnext-to-leading order in the $1/N_c$ expansion. We numerically evaluate the\ninvariant mass spectrum of the $K^+K^-$ pair both in vacuum and at finite\ntemperature. The inclusion of the kaon loop results in a finite width of the\nspectrum, improving agreement with experimental data. We also investigate the\nspin alignment of the $\\phi$ meson induced by its motion relative to the\nthermal background. In the NJL model with only chiral condensates, we find that\ndeviations from the unpolarized limit of 1/3 are negligible.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-th","published":"2025-03-31T10:08:18Z"}
{"aid":"http://arxiv.org/abs/2503.23925v1","title":"CoMatch: Dynamic Covisibility-Aware Transformer for Bilateral\n  Subpixel-Level Semi-Dense Image Matching","summary":"This prospective study proposes CoMatch, a novel semi-dense image matcher\nwith dynamic covisibility awareness and bilateral subpixel accuracy. Firstly,\nobserving that modeling context interaction over the entire coarse feature map\nelicits highly redundant computation due to the neighboring representation\nsimilarity of tokens, a covisibility-guided token condenser is introduced to\nadaptively aggregate tokens in light of their covisibility scores that are\ndynamically estimated, thereby ensuring computational efficiency while\nimproving the representational capacity of aggregated tokens simultaneously.\nSecondly, considering that feature interaction with massive non-covisible areas\nis distracting, which may degrade feature distinctiveness, a\ncovisibility-assisted attention mechanism is deployed to selectively suppress\nirrelevant message broadcast from non-covisible reduced tokens, resulting in\nrobust and compact attention to relevant rather than all ones. Thirdly, we find\nthat at the fine-level stage, current methods adjust only the target view's\nkeypoints to subpixel level, while those in the source view remain restricted\nat the coarse level and thus not informative enough, detrimental to keypoint\nlocation-sensitive usages. A simple yet potent fine correlation module is\ndeveloped to refine the matching candidates in both source and target views to\nsubpixel level, attaining attractive performance improvement. Thorough\nexperimentation across an array of public benchmarks affirms CoMatch's\npromising accuracy, efficiency, and generalizability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:17:01Z"}
{"aid":"http://arxiv.org/abs/2503.23951v1","title":"JointTuner: Appearance-Motion Adaptive Joint Training for Customized\n  Video Generation","summary":"Recent text-to-video advancements have enabled coherent video synthesis from\nprompts and expanded to fine-grained control over appearance and motion.\nHowever, existing methods either suffer from concept interference due to\nfeature domain mismatch caused by naive decoupled optimizations or exhibit\nappearance contamination induced by spatial feature leakage resulting from the\nentanglement of motion and appearance in reference video reconstructions. In\nthis paper, we propose JointTuner, a novel adaptive joint training framework,\nto alleviate these issues. Specifically, we develop Adaptive LoRA, which\nincorporates a context-aware gating mechanism, and integrate the gated LoRA\ncomponents into the spatial and temporal Transformers within the diffusion\nmodel. These components enable simultaneous optimization of appearance and\nmotion, eliminating concept interference. In addition, we introduce the\nAppearance-independent Temporal Loss, which decouples motion patterns from\nintrinsic appearance in reference video reconstructions through an\nappearance-agnostic noise prediction task. The key innovation lies in adding\nframe-wise offset noise to the ground-truth Gaussian noise, perturbing its\ndistribution, thereby disrupting spatial attributes associated with frames\nwhile preserving temporal coherence. Furthermore, we construct a benchmark\ncomprising 90 appearance-motion customized combinations and 10 multi-type\nautomatic metrics across four dimensions, facilitating a more comprehensive\nevaluation for this customization task. Extensive experiments demonstrate the\nsuperior performance of our method compared to current advanced approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:04:07Z"}
{"aid":"http://arxiv.org/abs/2503.23964v1","title":"On Cameron's Greedy Conjecture","summary":"A base for a permutation group $G$ acting on a set $\\Omega$ is a subset\n$\\mathcal{B}$ of $\\Omega$ whose pointwise stabiliser $G_{(\\mathcal{B})}$ is\ntrivial. There is a natural greedy algorithm for constructing a base of\nrelatively small size. We write $\\mathcal{G}(G)$ the maximum size of a base it\nproduces, and $b(G)$ for the size of the smallest base for $G$. In 1999, Peter\nCameron conjectured that there exists an absolute constant $c$ such that every\nfinite primitive group $G$ satisfies $\\mathcal{G}(G)\\leq cb(G)$. We show that\nif $G$ is $\\mathrm{S}_n$ or $\\mathrm{A}_n$ acting primitively then either\nCameron's Greedy Conjecture holds for $G$, or $G$ falls into one class of\npossible exceptions.","main_category":"math.GR","categories":"math.GR,math.CO","published":"2025-03-31T11:27:03Z"}
{"aid":"http://arxiv.org/abs/2503.23978v1","title":"Non-Abelian Gauge Enhances Self-Healing for Non-Hermitian Topological\n  Su-Schrieffer-Heeger Chain","summary":"This work introduces and analyzes a non-Hermitian Su-Schrieffer-Heeger (SSH)\nmodel generalized through spin-dependent non-Abelian SU(2) gauge couplings. By\nincorporating SU(2) symmetry transformations that couple explicitly to spin\ndegrees of freedom, our model demonstrates distinct topological properties\noriginating from the interplay between non-Hermiticity and gauge-induced\nspin-orbit coupling. Exact diagonalization and generalized Brillouin zone (GBZ)\nanalyses reveal distinct spectral phases, characterized by complex-energy loops\nunder periodic boundary conditions (PBC) and substantial localization\nindicative of the non-Hermitian skin effect (NHSE) under open boundary\nconditions (OBC). We define a gauge-invariant winding number for non-Hermitian\nchiral symmetry, clarifying the topological transitions. Furthermore, we\nuncover a novel self-healing phenomenon in response to dynamically introduced\nscattering potentials, showing significant robustness enhancement induced by\nappropriate non-Abelian SU(2) couplings. These findings clarify how non-Abelian\ngauge interactions can control spin-dependent localization and dynamical\nstability in non-Hermitian topological systems, guiding the development of\ntunable quantum devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.other","published":"2025-03-31T11:41:35Z"}
{"aid":"http://arxiv.org/abs/2503.23991v1","title":"Deviation Between Team-Optimal Solution and Nash Equilibrium in Flow\n  Assignment Problems","summary":"We investigate the relationship between the team-optimal solution and the\nNash equilibrium (NE) to assess the impact of strategy deviation on team\nperformance. As a working use case, we focus on a class of flow assignment\nproblems in which each source node acts as a cooperating decision maker (DM)\nwithin a team that minimizes the team cost based on the team-optimal strategy.\nIn practice, some selfish DMs may prioritize their own marginal cost and\ndeviate from NE strategies, thus potentially degrading the overall performance.\nTo quantify this deviation, we explore the deviation bound between the\nteam-optimal solution and the NE in two specific scenarios: (i) when the\nteam-optimal solution is unique and (ii) when multiple solutions do exist. This\nhelps DMs analyze the factors influencing the deviation and adopting the NE\nstrategy within a tolerable range. Furthermore, in the special case of a\npotential game model, we establish the consistency between the team-optimal\nsolution and the NE. Once the consistency condition is satisfied, the strategy\ndeviation does not alter the total cost, and DMs do not face a strategic\ntrade-off. Finally, we validate our theoretical analysis through some\nsimulation studies.","main_category":"cs.GT","categories":"cs.GT,math.OC","published":"2025-03-31T12:06:09Z"}
{"aid":"http://arxiv.org/abs/2503.23992v1","title":"A cost of capital approach to determining the LGD discount rate","summary":"Loss Given Default (LGD) is a key risk parameter in determining a bank's\nregulatory capital. During LGD-estimation, realised recovery cash flows are to\nbe discounted at an appropriate rate. Regulatory guidance mandates that this\nrate should allow for the time value of money, as well as include a risk\npremium that reflects the \"undiversifiable risk\" within these recoveries.\nHaving extensively reviewed earlier methods of determining this rate, we\npropose a new approach that is inspired by the cost of capital approach from\nthe Solvency II regulatory regime. Our method involves estimating a\nmarket-consistent price for a portfolio of defaulted loans, from which an\nassociated discount rate may be inferred. We apply this method to mortgage and\npersonal loans data from a large South African bank. The results reveal the\nmain drivers of the discount rate to be the mean and variance of these\nrecoveries, as well as the bank's cost of capital in excess of the risk-free\nrate. Our method therefore produces a discount rate that reflects both the\nundiversifiable risk of recovery recoveries and the time value of money,\nthereby satisfying regulatory requirements. This work can subsequently enhance\nthe LGD-component within the modelling of both regulatory and economic capital.","main_category":"q-fin.RM","categories":"q-fin.RM,q-fin.ST","published":"2025-03-31T12:09:21Z"}
{"aid":"http://arxiv.org/abs/2503.24006v1","title":"Comparing representations of long clinical texts for the task of patient\n  note-identification","summary":"In this paper, we address the challenge of patient-note identification, which\ninvolves accurately matching an anonymized clinical note to its corresponding\npatient, represented by a set of related notes. This task has broad\napplications, including duplicate records detection and patient similarity\nanalysis, which require robust patient-level representations. We explore\nvarious embedding methods, including Hierarchical Attention Networks (HAN),\nthree-level Hierarchical Transformer Networks (HTN), LongFormer, and advanced\nBERT-based models, focusing on their ability to process mediumto-long clinical\ntexts effectively. Additionally, we evaluate different pooling strategies\n(mean, max, and mean_max) for aggregating wordlevel embeddings into\npatient-level representations and we examine the impact of sliding windows on\nmodel performance. Our results indicate that BERT-based embeddings outperform\ntraditional and hierarchical models, particularly in processing lengthy\nclinical notes and capturing nuanced patient representations. Among the pooling\nstrategies, mean_max pooling consistently yields the best results, highlighting\nits ability to capture critical features from clinical notes. Furthermore, the\nreproduction of our results on both MIMIC dataset and Necker hospital data\nwarehouse illustrates the generalizability of these approaches to real-world\napplications, emphasizing the importance of both embedding methods and\naggregation strategies in optimizing patient-note identification and enhancing\npatient-level modeling.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:31:44Z"}
{"aid":"http://arxiv.org/abs/2503.24009v1","title":"Learning 3D-Gaussian Simulators from RGB Videos","summary":"Learning physics simulations from video data requires maintaining spatial and\ntemporal consistency, a challenge often addressed with strong inductive biases\nor ground-truth 3D information -- limiting scalability and generalization. We\nintroduce 3DGSim, a 3D physics simulator that learns object dynamics end-to-end\nfrom multi-view RGB videos. It encodes images into a 3D Gaussian particle\nrepresentation, propagates dynamics via a transformer, and renders frames using\n3D Gaussian splatting. By jointly training inverse rendering with a dynamics\ntransformer using a temporal encoding and merging layer, 3DGSimembeds physical\nproperties into point-wise latent vectors without enforcing explicit\nconnectivity constraints. This enables the model to capture diverse physical\nbehaviors, from rigid to elastic and cloth-like interactions, along with\nrealistic lighting effects that also generalize to unseen multi-body\ninteractions and novel scene edits.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG,cs.RO","published":"2025-03-31T12:33:59Z"}
{"aid":"http://arxiv.org/abs/2503.24032v1","title":"BBoxCut: A Targeted Data Augmentation Technique for Enhancing Wheat Head\n  Detection Under Occlusions","summary":"Wheat plays a critical role in global food security, making it one of the\nmost extensively studied crops. Accurate identification and measurement of key\ncharacteristics of wheat heads are essential for breeders to select varieties\nfor cross-breeding, with the goal of developing nutrient-dense, resilient, and\nsustainable cultivars. Traditionally, these measurements are performed\nmanually, which is both time-consuming and inefficient. Advances in digital\ntechnologies have paved the way for automating this process. However, field\nconditions pose significant challenges, such as occlusions of leaves,\noverlapping wheat heads, varying lighting conditions, and motion blur. In this\npaper, we propose a novel data augmentation technique, BBoxCut, which uses\nrandom localized masking to simulate occlusions caused by leaves and\nneighboring wheat heads. We evaluated our approach using three state-of-the-art\nobject detectors and observed mean average precision (mAP) gains of 2.76, 3.26,\nand 1.9 for Faster R-CNN, FCOS, and DETR, respectively. Our augmentation\ntechnique led to significant improvements both qualitatively and\nquantitatively. In particular, the improvements were particularly evident in\nscenarios involving occluded wheat heads, demonstrating the robustness of our\nmethod in challenging field conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T12:59:02Z"}
{"aid":"http://arxiv.org/abs/2503.24048v1","title":"Surge sourcing via hybrid supply in a sharing economy: a\n  resource-efficient, progressive and sustainable way to satisfy surge demand","summary":"We propose a surge sourcing approach to address occasional synchronous high\ndemand (surge demand) in sharing economy systems, providing a\nsocio-economically progressive alternative to surge pricing. Instead of\nsuppressing demand among disadvantaged consumers, our scheme increases supply\nby involving privileged consumer-providers (prosumers) who under-utilize their\nresources. This hybrid supply approach maintains high quality-of-service (QoS)\nfor both consumers and prosumers in both normal and surge demand situations\nwithout surge pricing. To ensure prosumer QoS, we reserve a small portion of\nthe primary supply to meet their needs if their resources become unavailable\nduring surge periods. As the probability of such events is low compared to that\nof the surge demand itself, the reserved resources required are minimal. The\nresulting scheme is resource-efficient, socially progressive, and sustainable,\nexploiting under-used resources. We illustrate our scheme through two\napplications: high-range car sharing for owners of small EVs, and shared\ncharging points for EV drivers.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T13:12:03Z"}
{"aid":"http://arxiv.org/abs/2503.24065v1","title":"COSMO: Combination of Selective Memorization for Low-cost\n  Vision-and-Language Navigation","summary":"Vision-and-Language Navigation (VLN) tasks have gained prominence within\nartificial intelligence research due to their potential application in fields\nlike home assistants. Many contemporary VLN approaches, while based on\ntransformer architectures, have increasingly incorporated additional components\nsuch as external knowledge bases or map information to enhance performance.\nThese additions, while boosting performance, also lead to larger models and\nincreased computational costs. In this paper, to achieve both high performance\nand low computational costs, we propose a novel architecture with the\nCOmbination of Selective MemOrization (COSMO). Specifically, COSMO integrates\nstate-space modules and transformer modules, and incorporates two\nVLN-customized selective state space modules: the Round Selective Scan (RSS)\nand the Cross-modal Selective State Space Module (CS3). RSS facilitates\ncomprehensive inter-modal interactions within a single scan, while the CS3\nmodule adapts the selective state space module into a dual-stream architecture,\nthereby enhancing the acquisition of cross-modal interactions. Experimental\nvalidations on three mainstream VLN benchmarks, REVERIE, R2R, and R2R-CE, not\nonly demonstrate competitive navigation performance of our model but also show\na significant reduction in computational costs.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-03-31T13:24:10Z"}
{"aid":"http://arxiv.org/abs/2503.24070v1","title":"HACTS: a Human-As-Copilot Teleoperation System for Robot Learning","summary":"Teleoperation is essential for autonomous robot learning, especially in\nmanipulation tasks that require human demonstrations or corrections. However,\nmost existing systems only offer unilateral robot control and lack the ability\nto synchronize the robot's status with the teleoperation hardware, preventing\nreal-time, flexible intervention. In this work, we introduce HACTS\n(Human-As-Copilot Teleoperation System), a novel system that establishes\nbilateral, real-time joint synchronization between a robot arm and\nteleoperation hardware. This simple yet effective feedback mechanism, akin to a\nsteering wheel in autonomous vehicles, enables the human copilot to intervene\nseamlessly while collecting action-correction data for future learning.\nImplemented using 3D-printed components and low-cost, off-the-shelf motors,\nHACTS is both accessible and scalable. Our experiments show that HACTS\nsignificantly enhances performance in imitation learning (IL) and reinforcement\nlearning (RL) tasks, boosting IL recovery capabilities and data efficiency, and\nfacilitating human-in-the-loop RL. HACTS paves the way for more effective and\ninteractive human-robot collaboration and data-collection, advancing the\ncapabilities of robot manipulation.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-03-31T13:28:13Z"}
{"aid":"http://arxiv.org/abs/2503.24074v1","title":"Physics-informed neural networks for hidden boundary detection and flow\n  field reconstruction","summary":"Simultaneously detecting hidden solid boundaries and reconstructing flow\nfields from sparse observations poses a significant inverse challenge in fluid\nmechanics. This study presents a physics-informed neural network (PINN)\nframework designed to infer the presence, shape, and motion of static or moving\nsolid boundaries within a flow field. By integrating a body fraction parameter\ninto the governing equations, the model enforces no-slip/no-penetration\nboundary conditions in solid regions while preserving conservation laws of\nfluid dynamics. Using partial flow field data, the method simultaneously\nreconstructs the unknown flow field and infers the body fraction distribution,\nthereby revealing solid boundaries. The framework is validated across diverse\nscenarios, including incompressible Navier-Stokes and compressible Euler flows,\nsuch as steady flow past a fixed cylinder, an inline oscillating cylinder, and\nsubsonic flow over an airfoil. The results demonstrate accurate detection of\nhidden boundaries, reconstruction of missing flow data, and estimation of\ntrajectories and velocities of a moving body. Further analysis examines the\neffects of data sparsity, velocity-only measurements, and noise on inference\naccuracy. The proposed method exhibits robustness and versatility, highlighting\nits potential for applications when only limited experimental or numerical data\nare available.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG,physics.comp-ph","published":"2025-03-31T13:30:46Z"}
{"aid":"http://arxiv.org/abs/2503.24097v1","title":"Systematic Search for FFPs in KMTNet Full-Frame Images. I. Photometry\n  Pipeline","summary":"To exhume the buried signatures of free-floating planets (FFPs) with small\nangular Einstein radius $\\theta_\\mathrm{E}$, we build a new full-frame\ndifference image for the Korean Microlensing Telescope Network (KMTNet) survey\nbased on the newly optimized pySIS package. We introduce the detailed processes\nof the new pipeline, including frame registration, difference image analysis,\nand light curve extraction. To test this pipeline, we extract the light curves\nfor 483,068 stars with $I \\lesssim 17$ and conduct a model-independent search\nfor microlensing events. The search finds 36 microlensing events, including\nfive new events and six events discovered by other collaborations but missed by\nprevious KMTNet searches. We find that the light curves from the new pipeline\nare precise enough to be sensitive to FFPs with $\\theta_\\mathrm{E} \\sim\n1~\\mu$as. Using the new pipeline, a complete FFP search on the eight-year\nKMTNet images can be finished within six months and then yield the FFP mass\nfunction. The new pipeline can be used for a new KMTNet AlertFinder system,\nwith significantly reduced false positives.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,astro-ph.SR","published":"2025-03-31T13:50:38Z"}
{"aid":"http://arxiv.org/abs/2503.24111v1","title":"Inductive Graph Representation Learning with Quantum Graph Neural\n  Networks","summary":"Quantum Graph Neural Networks (QGNNs) present a promising approach for\ncombining quantum computing with graph-structured data processing. While\nclassical Graph Neural Networks (GNNs) are renowned for their scalability and\nrobustness, existing QGNNs often lack flexibility due to graph-specific quantum\ncircuit designs, limiting their applicability to a narrower range of\ngraph-structured problems, falling short of real-world scenarios. To address\nthese limitations, we propose a versatile QGNN framework inspired by the\nclassical GraphSAGE approach, utilizing quantum models as aggregators. In this\nwork, we integrate established techniques for inductive representation learning\non graphs with parametrized quantum convolutional and pooling layers,\neffectively bridging classical and quantum paradigms. The convolutional layer\nis flexible, enabling tailored designs for specific problems. Benchmarked on a\nnode regression task with the QM9 dataset, we demonstrate that our framework\nsuccessfully models a non-trivial molecular dataset, achieving performance\ncomparable to classical GNNs. In particular, we show that our quantum approach\nexhibits robust generalization across molecules with varying numbers of atoms\nwithout requiring circuit modifications, slightly outperforming classical GNNs.\nFurthermore, we numerically investigate the scalability of the QGNN framework.\nSpecifically, we demonstrate the absence of barren plateaus in our architecture\nas the number of qubits increases, suggesting that the proposed quantum model\ncan be extended to handle larger and more complex graph-based problems\neffectively.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-03-31T14:04:08Z"}
{"aid":"http://arxiv.org/abs/2503.24118v1","title":"Experimental and theoretical research of photoneutron reactions in the\n  181Ta nucleus","summary":"Bremsstrahlung fluxes for irradiating tantalum samples were formed by\nirradiating a tungsten converter with an electron beam with energy up to 130\nMeV. The relative yields and flux-averaged cross-sections of multinucleon\nphotonuclear reactions with the emission of up to 9 neutrons in 181Ta nuclei\nwere determined. Monte Carlo simulations to study the yields of photonuclear\nreactions were performed using Geant4 and TALYS-2.0 codes. The obtained\nexperimental results were compared with the available literature data and\ncalculated results. The comparison showed that the values of the relative\nreaction yield and the flux-averaged cross-section coincide with the literature\ndata, taking into account the different geometry of the experiments. The\ncalculated results coincide with the experimental ones only for reactions with\nthe emission of up to 5 neutrons from the nucleus.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T14:07:31Z"}
{"aid":"http://arxiv.org/abs/2503.24135v1","title":"PixelCAM: Pixel Class Activation Mapping for Histology Image\n  Classification and ROI Localization","summary":"Weakly supervised object localization (WSOL) methods allow training models to\nclassify images and localize ROIs. WSOL only requires low-cost image-class\nannotations yet provides a visually interpretable classifier, which is\nimportant in histology image analysis. Standard WSOL methods rely on class\nactivation mapping (CAM) methods to produce spatial localization maps according\nto a single- or two-step strategy. While both strategies have made significant\nprogress, they still face several limitations with histology images.\nSingle-step methods can easily result in under- or over-activation due to the\nlimited visual ROI saliency in histology images and the limited localization\ncues. They also face the well-known issue of asynchronous convergence between\nclassification and localization tasks. The two-step approach is sub-optimal\nbecause it is tied to a frozen classifier, limiting the capacity for\nlocalization. Moreover, these methods also struggle when applied to\nout-of-distribution (OOD) datasets. In this paper, a multi-task approach for\nWSOL is introduced for simultaneous training of both tasks to address the\nasynchronous convergence problem. In particular, localization is performed in\nthe pixel-feature space of an image encoder that is shared with classification.\nThis allows learning discriminant features and accurate delineation of\nforeground/background regions to support ROI localization and image\nclassification. We propose PixelCAM, a cost-effective foreground/background\npixel-wise classifier in the pixel-feature space that allows for spatial object\nlocalization. PixelCAM is trained using pixel pseudo-labels collected from a\npretrained WSOL model. Both image and pixel-wise classifiers are trained\nsimultaneously using standard gradient descent. In addition, our pixel\nclassifier can easily be integrated into CNN- and transformer-based\narchitectures without any modifications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T14:18:01Z"}
{"aid":"http://arxiv.org/abs/2503.24152v1","title":"Quantifying Grid-Forming Behavior: Bridging Device-level Dynamics and\n  System-Level Stability","summary":"Grid-Forming (GFM) technology is considered a promising solution to build\npower electronics-dominated power systems. However, the impact of GFM\nconverters on the system stability is still unquantified, creating a gap\nbetween the system- and device-level perspectives. To fill this gap, at the\ndevice-level, we propose a Forming Index to quantify a converter's response to\ngrid voltage variations, providing a characterization of its GFM behavior. At\nthe system-level, a quantitative notion of System Strength is introduced to\ncapture the fundamental requirements for power system formation. Finally, we\nestablish the alignment between device- and system-level metrics by\ndemonstrating that GFM converters provably enhance system strength.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T14:37:51Z"}
{"aid":"http://arxiv.org/abs/2503.24168v1","title":"The Compact Linear e$^+$e$^-$ Collider (CLIC)","summary":"The Compact Linear Collider (CLIC) is a TeV-scale high-luminosity linear\ne$^+$e$^-$ collider studied by the international CLIC and CLICdp\ncollaborations. CLIC uses a two-beam acceleration scheme, in which\nnormal-conducting high-gradient 12 GHz accelerating structures are powered via\na high-current drive beam. CLIC is foreseen to be built and operated in stages.\nThe initial 380 GeV stage, with a site length of 11 km, optimally combines the\nexploration of Higgs and top-quark physics, including a top threshold scan near\n350 GeV. A higher-energy stage, still using the initial single drive-beam\ncomplex, can be optimised for any energy up to 2 TeV. Parameters are presented\nin detail for a 1.5 TeV stage, with a site length of 29 km. Since the 2018\nESPPU reporting, significant effort was invested in CLIC accelerator\noptimisation, technology developments and system tests, including collaboration\nwith new-generation light sources and free-electron lasers. CLIC implementation\naspects at CERN have covered detailed studies of civil engineering, electrical\nnetworks, cooling and ventilation, scheduling, and costing. The CLIC baseline\nat 380 GeV is now 100 Hz operation, with a luminosity of 4.5$\\times\n10^{34}$\\,cm$^{-2}$s$^{-1}$ and a power consumption of 166 MW. Compared to the\n2018 design, this gives three times higher luminosity-per-power. The new\nbaseline has two beam-delivery systems, allowing for two detectors operating in\nparallel. The cost estimate of the 380 GeV baseline is approximately 7.17\nbillion CHF. The construction of the first CLIC energy stage could start as\nearly as 2033 with first beams available by 2041. This report summarises the\nCLIC project, its implementation and running scenarios, with emphasis on new\ndevelopments and recent progress. It concludes with an update on the CLIC\ndetector studies and on the physics potential in light of the improved\naccelerator performance.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-03-31T14:48:58Z"}
{"aid":"http://arxiv.org/abs/2503.24180v1","title":"Navi-plus: Managing Ambiguous GUI Navigation Tasks with Follow-up","summary":"Graphical user interfaces (GUI) automation agents are emerging as powerful\ntools, enabling humans to accomplish increasingly complex tasks on smart\ndevices. However, users often inadvertently omit key information when conveying\ntasks, which hinders agent performance in the current agent paradigm that does\nnot support immediate user intervention. To address this issue, we introduce a\n$\\textbf{Self-Correction GUI Navigation}$ task that incorporates interactive\ninformation completion capabilities within GUI agents. We developed the\n$\\textbf{Navi-plus}$ dataset with GUI follow-up question-answer pairs,\nalongside a $\\textbf{Dual-Stream Trajectory Evaluation}$ method to benchmark\nthis new capability. Our results show that agents equipped with the ability to\nask GUI follow-up questions can fully recover their performance when faced with\nambiguous user tasks.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-03-31T14:56:24Z"}
{"aid":"http://arxiv.org/abs/2503.24185v1","title":"Adding the constant evasion and constant prediction numbers to\n  CichoÅ's maximum","summary":"Let $\\mathfrak{e}^\\mathsf{const}_2$ be the constant evasion number, that is,\nthe size of the least family $F\\subseteq{}^{\\omega}2$ of reals such that for\neach predictor $\\pi\\colon {}^{<\\omega}2\\to 2$ there is $x\\in F$ which is not\nconstantly predicted by $\\pi$; and let $\\mathfrak{v}_2^\\mathsf{const}$ be the\nconstant prediction number, that is, the size of the least family $\\Pi_2$ of\nfunctions $\\pi\\colon {}^{<\\omega}2\\to 2$ such that for each $x\\in{}^{\\omega}2$\nthere is $\\pi\\in\\Pi_2$ that predicts constantly $x$. In this work, we show that\nthe constant evasion number $\\mathfrak{e}_2^{\\mathrm{cons}}$ and the constant\nprediction number $\\mathfrak{v}_2^\\mathsf{const}$ can be added to Cicho\\'n's\nmaximum with distinct values.","main_category":"math.LO","categories":"math.LO","published":"2025-03-31T15:02:26Z"}
{"aid":"http://arxiv.org/abs/2503.24198v1","title":"TwT: Thinking without Tokens by Habitual Reasoning Distillation with\n  Multi-Teachers' Guidance","summary":"Large Language Models (LLMs) have made significant strides in problem-solving\nby incorporating reasoning processes. However, this enhanced reasoning\ncapability results in an increased number of output tokens during inference,\nleading to higher computational costs. To address this challenge, we propose\nTwT (Thinking without Tokens), a method that reduces inference-time costs\nthrough habitual reasoning distillation with multi-teachers' guidance, while\nmaintaining high performance. Our approach introduces a Habitual Reasoning\nDistillation method, which internalizes explicit reasoning into the model's\nhabitual behavior through a Teacher-Guided compression strategy inspired by\nhuman cognition. Additionally, we propose Dual-Criteria Rejection Sampling\n(DCRS), a technique that generates a high-quality and diverse distillation\ndataset using multiple teacher models, making our method suitable for\nunsupervised scenarios. Experimental results demonstrate that TwT effectively\nreduces inference costs while preserving superior performance, achieving up to\na 13.6% improvement in accuracy with fewer output tokens compared to other\ndistillation methods, offering a highly practical solution for efficient LLM\ndeployment.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T15:16:31Z"}
{"aid":"http://arxiv.org/abs/2503.24205v1","title":"A Comparison of Parametric Dynamic Mode Decomposition Algorithms for\n  Thermal-Hydraulics Applications","summary":"In recent years, algorithms aiming at learning models from available data\nhave become quite popular due to two factors: 1) the significant developments\nin Artificial Intelligence techniques and 2) the availability of large amounts\nof data. Nevertheless, this topic has already been addressed by methodologies\nbelonging to the Reduced Order Modelling framework, of which perhaps the most\nfamous equation-free technique is Dynamic Mode Decomposition. This algorithm\naims to learn the best linear model that represents the physical phenomena\ndescribed by a time series dataset: its output is a best state operator of the\nunderlying dynamical system that can be used, in principle, to advance the\noriginal dataset in time even beyond its span. However, in its standard\nformulation, this technique cannot deal with parametric time series, meaning\nthat a different linear model has to be derived for each parameter realization.\nResearch on this is ongoing, and some versions of a parametric Dynamic Mode\nDecomposition already exist. This work contributes to this research field by\ncomparing the different algorithms presently deployed and assessing their\nadvantages and shortcomings compared to each other. To this aim, three\ndifferent thermal-hydraulics problems are considered: two benchmark 'flow over\ncylinder' test cases at diverse Reynolds numbers, whose datasets are,\nrespectively, obtained with the FEniCS finite element solver and retrieved from\nthe CFDbench dataset, and the DYNASTY experimental facility operating at\nPolitecnico di Milano, which studies the natural circulation established by\ninternally heated fluids for Generation IV nuclear applications, whose dataset\nwas generated using the RELAP5 nodal solver.","main_category":"math.DS","categories":"math.DS,cs.LG","published":"2025-03-31T15:23:22Z"}
{"aid":"http://arxiv.org/abs/2503.24218v1","title":"Visible optical vortices measured with bulk lateral shearing\n  interferometry","summary":"Ultrafast pulse optical vortices are spatiotemporal structures with a diverse\nrange of applications. There are different ways to generate them, often\nrestricted to a wavelength range. Likewise, characterization techniques\nfrequently possess similar limitations. In this work, we first generate\nultrashort optical vortices in the near infrared from Ti:sapphire laser pulses\nby means of structured waveplates and beam manipulation. Then, we produce the\nvisible vortices through up-conversion using a second-harmonic generation\ncrystal. The resulting beams require spatiotemporal characterization, which are\nperformed by bulk lateral shearing interferometry. The reference pulse is\ntemporally characterized with the amplitude swing technique. In this manner, we\npresent the generation of these pulses in the visible range, which are\nexperimentally validated, and demonstrate that bulk lateral shearing\ninterferometry can be used for pulsed beams across widely different spectral\nregions with the same setup. This finding is significant for future\napplications of the technique with various sources.","main_category":"physics.optics","categories":"physics.optics,physics.ins-det","published":"2025-03-31T15:36:13Z"}
{"aid":"http://arxiv.org/abs/2503.24223v1","title":"Jordanian deformation of the non-compact and $\\mathfrak{sl}_2\n  $-invariant $XXX_{-1/2}$ spin-chain","summary":"Using a Drinfeld twist of Jordanian type, we construct a deformation of the\nnon-compact and $\\mathfrak{sl}_2$-invariant $XXX_{-1/2}$ spin-chain. Before the\ndeformation, the seed model can be understood as a sector of the\n$\\mathfrak{psu}(2,2|4)$-invariant spin-chain encoding the spectral problem of\n$\\mathcal{N}=4$ super Yang-Mills at one loop in the planar limit. The\ndeformation gives rise to interesting features because, while being integrable,\nthe Hamiltonian is non-hermitian and non-diagonalisable, so that it only admits\na Jordan decomposition. Moreover, the eigenvalues of the deformed Hamiltonian\ncoincide with those of the original undeformed spin-chain. We use explicit\nexamples as well as the techniques of the coordinate and of the algebraic Bethe\nansatz to discuss the construction of the (generalised) eigenvectors of the\ndeformed model. We also show that the deformed spin-chain is equivalent to an\nundeformed one with twisted boundary conditions, and that it may be derived\nfrom a scaling limit of the non-compact $U_q(\\mathfrak{sl}_2)$-invariant\n$XXZ_{-1/2} $ spin-chain.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech,cond-mat.str-el,quant-ph","published":"2025-03-31T15:38:04Z"}
{"aid":"http://arxiv.org/abs/2503.24255v1","title":"The Mysterious Phenomenon of Forward-Progressing Student Tables","summary":"This study investigates the factors that contribute to the forward movement\nof student desks throughout the school day. We hypothesize that desk movement\nis influenced not only by classroom floor type but also by the physical\ncharacteristics of students, such as height and age. Furthermore, we explore\nhow the subject taught in the classroom (e.g., Science vs. Modern Foreign\nLanguages) contributes to desk dynamics. Utilizing a Monte Carlo simulation\nmodel, we quantitatively analyse the forces at play in these phenomena. This\nresearch reveals that desks on carpeted floors are particularly prone to\nmovement, especially in science classrooms with taller and younger students.\nWhile the results may seem trivial, they provide critical insights into the\nmechanics of classroom furniture behaviour and its implications for educational\npractices. The paper offers compelling evidence that classroom furniture has a\nmind of its own or, at the very least, a subtle gravitational pull towards the\nfront of the room.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-03-31T16:03:53Z"}
{"aid":"http://arxiv.org/abs/2503.24266v1","title":"EP240414a: Off-axis View of a Jet-Cocoon System from an Expanded\n  Progenitor Star","summary":"When a relativistic jet is launched following the core-collapse of a star,\nits interaction with the stellar envelope leads to the formation of a hot\ncocoon, which produces various viewing-angle-dependent observational phenomena\nfollowing the breakout from the surface. We study the observational signatures\nof fast X-ray transient (FXT) EP240414a, which may originate from a jet-cocoon\nsystem viewed slightly off-axis. In our model, (1) the prompt X-ray emission\nlasting $\\sim\\! 100\\,{\\rm{s}}$ is attributed to the cooling emission from the\ninner cocoon (shocked jet material); (2) the $\\sim\\! 0.1\\,{\\rm{d}}$ X-ray\nemission comes from the inner cocoon's afterglow; (3) the $\\sim\\!\n0.4\\,{\\rm{d}}$ thermal-dominated optical emission arises from the cooling of\nthe outer cocoon (shocked stellar material); (4) the $\\sim\\! 3\\,{\\rm{d}}$\nnon-thermal optical component and subsequent radio emission can be explained by\nthe afterglow from a jet with a viewing angle of $10^{\\circ}\\lesssim\n\\theta_{\\rm{v}}\\lesssim15^\\circ$; and (5) the associated broad-lined Type Ic\nsupernova only dominates the optical emission after $\\sim\\! 7\\rm\\, d$. Both the\njet inferred from the off-axis afterglow and the inner cocoon constrained by\nthe cooling emission are found to have similar kinetic energies, on the order\nof $10^{51}\\,{\\rm{erg}}$. We find that the progenitor's radius is\n$\\sim3\\,R_\\odot$ as constrained by the { inner cocoon's} cooling emissions,\nindicating that the pre-explosion star may be a massive helium star that is\nslightly inflated. More FXTs associated with off-axis jets and supernovae will\nbe further examined by the Einstein Probe, leading to a deeper understanding of\njet-cocoon systems.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T16:12:46Z"}
{"aid":"http://arxiv.org/abs/2503.24277v1","title":"Evaluating and Designing Sparse Autoencoders by Approximating\n  Quasi-Orthogonality","summary":"Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic\ninterpretability, but leading SAE approaches with top-$k$ style activation\nfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEs\nare based on the linear representation hypothesis (LRH), which assumes that the\nrepresentations of large language models (LLMs) are linearly encoded, and the\nsuperposition hypothesis (SH), which states that there can be more features in\nthe model than its dimensionality. We show that, based on the formal\ndefinitions of the LRH and SH, the magnitude of sparse feature vectors (the\nlatent representations learned by SAEs of the dense embeddings of LLMs) can be\napproximated using their corresponding dense vector with a closed-form error\nbound. To visualize this, we propose the ZF plot, which reveals a previously\nunknown relationship between LLM hidden embeddings and SAE feature vectors,\nallowing us to make the first empirical measurement of the extent to which\nfeature vectors of pre-trained SAEs are over- or under-activated for a given\ninput. Correspondingly, we introduce Approximate Feature Activation (AFA),\nwhich approximates the magnitude of the ground-truth sparse feature vector, and\npropose a new evaluation metric derived from AFA to assess the alignment\nbetween inputs and activations. We also leverage AFA to introduce a novel SAE\narchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with\ntheoretical justifications; and (b) obviate the need to tune SAE sparsity\nhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve\nreconstruction loss comparable to that of state-of-the-art top-k SAEs, without\nrequiring the hyperparameter $k$ to be tuned. Our code is available at:\nhttps://github.com/SewoongLee/top-afa-sae.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T16:22:11Z"}
{"aid":"http://arxiv.org/abs/2503.24292v1","title":"Implicit Electric Field Conjugation with the Photonic Lantern Nuller","summary":"The Photonic Lantern Nuller (PLN) is an instrument concept designed to\ncharacterize exoplanets within a single beam-width from its host star. The PLN\nleverages the spatial symmetry of a mode-selective photonic lantern (MSPL) to\ncreate nulled ports, which cancel out on-axis starlight but allow off-axis\nexoplanet light to couple. The null-depths are limited by wavefront aberrations\nin the system as well as by imperfections in the lantern. We show that the\nimplicit electric field conjugation algorithm can be used to reduce the stellar\ncoupling through the PLN by orders of magnitude while maintaining the majority\nof the off-axis light, leading to deeper null depths (~10^{-4}) and thus higher\nsensitivity to potential planet signals. We discuss a theory for the tradeoff\nwe observed between the different ports, where iEFC improves the nulls of some\nports at the expense of others, and show that targeting one port alone can lead\nto deeper starlight rejection through that port than when targeting all ports\nat once. We also observe different levels of stability depending on the port\nand discuss the implications for practically implementing this technique for\nscience observations.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP","published":"2025-03-31T16:38:18Z"}
{"aid":"http://arxiv.org/abs/2503.24309v1","title":"The edge-on disk Tau042021: icy grains at high altitudes and a wind\n  containing astronomical PAHs","summary":"Spectra of the nearly edge-on protoplanetary disks observed with the JWST\nhave shown ice absorption bands of varying optical depths and peculiar\nprofiles, challenging radiative transfer modelling and our understanding of\ndust and ice in disks. We build models including dust grain size, shape, and\ncomposition to reproduce JWST IFU spectroscopy of the large edge-on disk\nTau042021. We explore radiative transfer models using different dust grain size\ndistributions, including grains of effective radii a_eff = 0.005-3000 microns.\nScattering properties of distributions of triaxial ellipsoidal grains are\ncalculated. We consider compositions with silicates, amorphous carbon, and\nmixtures of H2O, CO2, and CO. We use RADMC-3D Monte Carlo radiative transfer\nmodels of Tau042021 to simulate the spectral cubes observed with JWST-NIRSpec\nand MIRI. We compare the results to observations, including H2O at 3.05\nmicrons, CO at 4.67 microns, and CO2 at 4.27 microns and to archival\nJWST-NIRCam and ALMA continuum images. The observed near- to mid-infrared imply\ndust distributions with grain sizes up to several tens of microns. The\nintensity distribution perpendicular to the disk exhibits emission profile\nwings extending into the upper disk atmosphere at altitudes exceeding the\nclassical scale height expected in the isothermal hydrostatic limit. We produce\nice map images demonstrating the presence of icy dust grains up to altitudes\nhigh above the disk midplane, more than three hydrostatic equilibrium scale\nheights. We demonstrate the presence of a wind containing the carriers of\nastronomical PAH bands. The wind appears as an X-shaped emission at 3.3, 6.2,\n7.7 and 11.3 microns, characteristic wavelengths of the infrared astronomical\nPAH bands. We associate the spatial distribution of this component with\ncarriers of astronomical PAH bands that form a layer of emission at the\ninterface with the H2 wind.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-03-31T16:56:16Z"}
{"aid":"http://arxiv.org/abs/2503.24325v1","title":"Pro-Routing: Proactive Routing of Autonomous Multi-Capacity Robots for\n  Pickup-and-Delivery Tasks","summary":"We consider a multi-robot setting, where we have a fleet of multi-capacity\nautonomous robots that must service spatially distributed pickup-and-delivery\nrequests with fixed maximum wait times. Requests can be either scheduled ahead\nof time or they can enter the system in real-time. In this setting, stability\nfor a routing policy is defined as the cost of the policy being uniformly\nbounded over time. Most previous work either solve the problem offline to\ntheoretically maintain stability or they consider dynamically arriving requests\nat the expense of the theoretical guarantees on stability. In this paper, we\naim to bridge this gap by proposing a novel proactive rollout-based routing\nframework that adapts to real-time demand while still provably maintaining the\nstability of the learned routing policy. We derive provable stability\nguarantees for our method by proposing a fleet sizing algorithm that obtains a\nsufficiently large fleet that ensures stability by construction. To validate\nour theoretical results, we consider a case study on real ride requests for\nHarvard's evening Van System. We also evaluate the performance of our framework\nusing the currently deployed smaller fleet size. In this smaller setup, we\ncompare against the currently deployed routing algorithm, greedy heuristics,\nand Monte-Carlo-Tree-Search-based algorithms. Our empirical results show that\nour framework maintains stability when we use the sufficiently large fleet size\nfound in our theoretical results. For the smaller currently deployed fleet\nsize, our method services 6% more requests than the closest baseline while\nreducing median passenger wait times by 33%.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.MA","published":"2025-03-31T17:14:07Z"}
{"aid":"http://arxiv.org/abs/2503.24327v1","title":"Thermal transport in superconductor heterostructures: some recent\n  progress","summary":"This article reviews recent advances in low-temperature electronic thermal\ntransport properties of thermally biased superconductor heterostructures\nfocusing on the two-terminal transport. Since the last decade, ferromagnetism\nhas been widely used to enhance the thermoelectricity in heterostructures based\non ordinary superconductors. The possibility of getting giant thermoelectric\neffects with optimum thermal conductance by breaking the electron-hole symmetry\nof the ordinary superconductor boosted the research in this direction.\nRecently, attention has been paid to the role of triplet Cooper pairs that\nemerged in ferromagnetic junctions and the possibility of advanced\napplications. Other forms of magnetism, specifically antiferromagnetism and\naltermagnetism, have been investigated to unravel the behavior of the thermal\nand charge current in thermally biased junctions. In parallel to ordinary\nsuperconductors, junctions with unconventional superconductors have been\nexplored for the same purpose. Thermal transport in superconducting bilayers\nhas been studied using advanced materials like Dirac and topological materials,\nincluding Weyl semimetals. Significant attention has been paid to thermally\nbiased topological Josephson junctions to explore the phase-tunable current in\nrecent times. Weyl Josephson junctions, multi-terminal Josephson junctions, and\nvarious other multilayer junctions have also been studied to engineer large\nthermoelectric effects and various functionalities with potential applications\nin superconductor-based thermal device components.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-03-31T17:17:25Z"}
{"aid":"http://arxiv.org/abs/2503.24348v1","title":"On the unitarity and modularity of ribbon tensor categories associated\n  with affine Lie algebras","summary":"We study the unitarity and modularity of ribbon tensor categories derived\nfrom simple affine Lie algebras, via their associated quantum groups. Based on\nnumerical calculations, and assuming two conjectures, we provide the complete\npicture for which values of $q$ these ribbon tensor categories are\n(pseudo-)unitary and for which values of $q$ they are modular. We compare our\nresults with the extensive rigorous results appearing in the literature,\nfinding complete agreement. For the cases that do not appear in the literature,\nwe complete the picture.","main_category":"math.QA","categories":"math.QA","published":"2025-03-31T17:32:29Z"}
{"aid":"http://arxiv.org/abs/2503.24353v1","title":"Universality of RÃ©nyi Entropy in Conformal Field Theory","summary":"We use the thermal effective theory to prove that, for the vacuum state in\nany conformal field theory in $d$ dimensions, the $n$-th R\\'enyi entropy\n$S_A^{(n)}$ behaves as $S_A^{(n)} = \\frac{f}{(2\\pi n)^{d-1}} \\frac{ {\\rm\nArea}(\\partial A)}{(d-2)\\epsilon^{d-2}}\\left(1+O(n)\\right)$ in the $n\n\\rightarrow 0$ limit when the boundary of the entanglement domain $A$ is\nspherical with the UV cutoff $\\epsilon$.The theory dependence is encapsulated\nin the cosmological constant $f$ in the thermal effective action. Using this\nresult, we estimate the density of states for large eigenvalues of the modular\nHamiltonian for the domain $A$. In two dimensions, we can use the hot spot idea\nto derive more powerful formulas valid for arbitrary positive $n$. We discuss\nthe difference between two and higher dimensions and clarify the applicability\nof the hot spot idea. We also use the thermal effective theory to derive an\nanalog of the Cardy formula for boundary operators in higher dimensions.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech,cond-mat.str-el,quant-ph","published":"2025-03-31T17:34:59Z"}
{"aid":"http://arxiv.org/abs/2503.24356v1","title":"Single-Shot Matrix-Matrix Multiplication Optical Tensor Processor for\n  Deep Learning","summary":"The ever-increasing data demand craves advancements in high-speed and\nenergy-efficient computing hardware. Analog optical neural network (ONN)\nprocessors have emerged as a promising solution, offering benefits in bandwidth\nand energy consumption. However, existing ONN processors exhibit limited\ncomputational parallelism, and while certain architectures achieve high\nparallelism, they encounter serious scaling roadblocks for large-scale\nimplementation. This restricts the throughput, latency, and energy efficiency\nadvantages of ONN processors. Here, we introduce a spatial-wavelength-temporal\nhyper-multiplexed ONN processor that supports high data dimensionality, high\ncomputing parallelism and is feasible for large-scale implementation, and in a\nsingle time step, a three-dimensional matrix-matrix multiplication (MMM)\noptical tensor processor is demonstrated. Our hardware accelerates\nconvolutional neural networks (CNNs) and deep neural networks (DNNs) through\nparallel matrix multiplication. We demonstrate benchmark image recognition\nusing a CNN and a subsequently fully connected DNN in the optical domain. The\nnetwork works with 292,616 weight parameters under ultra-low optical energy of\n20 attojoules (aJ) per multiply and accumulate (MAC) at 96.4% classification\naccuracy. The system supports broad spectral and spatial bandwidths and is\ncapable for large-scale demonstration, paving the way for highly efficient\nlarge-scale optical computing for next-generation deep learning.","main_category":"physics.optics","categories":"physics.optics","published":"2025-03-31T17:35:48Z"}
{"aid":"http://arxiv.org/abs/2503.24369v1","title":"Exploring light propagation in nonlinear electrodynamics: phase and\n  group velocities and related phenomena","summary":"Nonlinear electrodynamics has been an important area of research for a long\ntime. Investigations based on nonlinear Lagrangians, such as Euler-Heisenberg\nand Born-Infeld, are instrumental in exploring the limits of classical and\nquantum field theories, providing valuable insights into strong-field\nphenomena. In this context, this work considers how light propagates in\nstrong-field environments, where such nonlinearities play significant roles,\noffering a way to investigate events in high-energy astrophysics, quantum\noptics, and fundamental physics beyond classical Maxwell's framework. Here,\nseveral aspects of light propagation in nonlinear electrodynamics are\ndiscussed. Phase and group velocities are derived and several interesting\nbehaviors are unveiled, such as birefringence, non-reciprocal propagation, and\nasymmetries between phase and group velocities in special configurations.\nSpecific solutions based on commonly studied nonlinear theories are also\ninvestigated, and phenomena like slow-light and one-way propagation are\ndiscussed.","main_category":"physics.gen-ph","categories":"physics.gen-ph","published":"2025-03-31T17:49:51Z"}
{"aid":"http://arxiv.org/abs/2503.24377v1","title":"Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for\n  Large Language Models","summary":"Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to perform complex reasoning tasks, transitioning from\nfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).\nWhile System 2 reasoning improves task accuracy, it often incurs substantial\ncomputational costs due to its slow thinking nature and inefficient or\nunnecessary reasoning behaviors. In contrast, System 1 reasoning is\ncomputationally efficient but leads to suboptimal performance. Consequently, it\nis critical to balance the trade-off between performance (benefits) and\ncomputational costs (budgets), giving rise to the concept of reasoning economy.\nIn this survey, we provide a comprehensive analysis of reasoning economy in\nboth the post-training and test-time inference stages of LLMs, encompassing i)\nthe cause of reasoning inefficiency, ii) behavior analysis of different\nreasoning patterns, and iii) potential solutions to achieve reasoning economy.\nBy offering actionable insights and highlighting open challenges, we aim to\nshed light on strategies for improving the reasoning economy of LLMs, thereby\nserving as a valuable resource for advancing research in this evolving area. We\nalso provide a public repository to continually track developments in this\nfast-evolving field.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2503.24381v1","title":"UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in\n  Autonomous Driving","summary":"We introduce UniOcc, a comprehensive, unified benchmark for occupancy\nforecasting (i.e., predicting future occupancies based on historical\ninformation) and current-frame occupancy prediction from camera images. UniOcc\nunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and\nhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D\noccupancy labels with per-voxel flow annotations and support for cooperative\nautonomous driving. In terms of evaluation, unlike existing studies that rely\non suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics\nthat do not depend on ground-truth occupancy, enabling robust assessment of\nadditional aspects of occupancy quality. Through extensive experiments on\nstate-of-the-art models, we demonstrate that large-scale, diverse training data\nand explicit flow information significantly enhance occupancy prediction and\nforecasting performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.MA,cs.RO","published":"2025-03-31T17:59:24Z"}
{"aid":"http://arxiv.org/abs/2503.24388v1","title":"RIG: Synergizing Reasoning and Imagination in End-to-End Generalist\n  Policy","summary":"Reasoning before action and imagining potential outcomes (i.e., world models)\nare essential for embodied agents operating in complex open-world environments.\nYet, prior work either incorporates only one of these abilities in an\nend-to-end agent or integrates multiple specialized models into an agent\nsystem, limiting the learning efficiency and generalization of the policy.\nThus, this paper makes the first attempt to synergize Reasoning and Imagination\nin an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-end\nmanner, we construct a data pipeline that progressively integrates and enriches\nthe content of imagination and reasoning in the trajectories collected from\nexisting agents. The joint learning of reasoning and next image generation\nexplicitly models the inherent correlation between reasoning, action, and\ndynamics of environments, and thus exhibits more than $17\\times$ sample\nefficiency improvements and generalization in comparison with previous works.\nDuring inference, RIG first reasons about the next action, produces potential\naction, and then predicts the action outcomes, which offers the agent a chance\nto review and self-correct based on the imagination before taking real actions.\nExperimental results show that the synergy of reasoning and imagination not\nonly improves the robustness, generalization, and interoperability of\ngeneralist policy but also enables test-time scaling to enhance overall\nperformance.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG","published":"2025-03-31T17:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.01331v1","title":"An Explainable Reconfiguration-Based Optimization Algorithm for\n  Industrial and Reliability-Redundancy Allocation Problems","summary":"Industrial and reliability optimization problems often involve complex\nconstraints and require efficient, interpretable solutions. This paper presents\nAI-AEFA, an advanced parameter reconfiguration-based metaheuristic algorithm\ndesigned to address large-scale industrial and reliability-redundancy\nallocation problems. AI-AEFA enhances search space exploration and convergence\nefficiency through a novel log-sigmoid-based parameter adaptation and chaotic\nmapping mechanism. The algorithm is validated across twenty-eight IEEE CEC 2017\nconstrained benchmark problems, fifteen large-scale industrial optimization\nproblems, and seven reliability-redundancy allocation problems, consistently\noutperforming state-of-the-art optimization techniques in terms of feasibility,\ncomputational efficiency, and convergence speed. The additional key\ncontribution of this work is the integration of SHAP (Shapley Additive\nExplanations) to enhance the interpretability of AI-AEFA, providing insights\ninto the impact of key parameters such as Coulomb's constant, charge,\nacceleration, and electrostatic force. This explainability feature enables a\ndeeper understanding of decision-making within the AI-AEFA framework during the\noptimization processes. The findings confirm AI-AEFA as a robust, scalable, and\ninterpretable optimization tool with significant real-world applications.","main_category":"cs.AI","categories":"cs.AI,cs.NE","published":"2025-04-02T03:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.01341v1","title":"Uniform convergence to the equilibrium of the homogeneous\n  Boltzmann-Fermi-Dirac Equation with moderately soft potential","summary":"We concern the long-time behavior of mild solutions to the spatially\nhomogeneous Boltzmann--Fermi--Dirac equation with moderately soft potential.\nBased on the well-posedness results in [X-G. Lu, J. Stat. Phys., 105, (2001),\n353-388], we prove that the mild solution decays algebraically to the\nFermi--Dirac statistics with an explicit rate. Under the framework of the level\nset analysis by De Giorgi, we derive an $L^\\infty$ estimate which is uniform\nwith respect to the quantum parameter $\\varepsilon$. All quantitative estimates\nare independent of $\\varepsilon$, which implies that they also hold in the\nclassical limit, i.e., the Boltzmann equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T04:10:34Z"}
{"aid":"http://arxiv.org/abs/2504.01367v1","title":"Enhancing Computational Notebooks with Code+Data Space Versioning","summary":"There is a gap between how people explore data and how Jupyter-like\ncomputational notebooks are designed. People explore data nonlinearly, using\nexecution undos, branching, and/or complete reverts, whereas notebooks are\ndesigned for sequential exploration. Recent works like ForkIt are still\ninsufficient to support these multiple modes of nonlinear exploration in a\nunified way. In this work, we address the challenge by introducing\ntwo-dimensional code+data space versioning for computational notebooks and\nverifying its effectiveness using our prototype system, Kishuboard, which\nintegrates with Jupyter. By adjusting code and data knobs, users of Kishuboard\ncan intuitively manage the state of computational notebooks in a flexible way,\nthereby achieving both execution rollbacks and checkouts across complex\nmulti-branch exploration history. Moreover, this two-dimensional versioning\nmechanism can easily be presented along with a friendly one-dimensional\nhistory. Human subject studies indicate that Kishuboard significantly enhances\nuser productivity in various data science tasks.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-02T05:26:51Z"}
{"aid":"http://arxiv.org/abs/2504.01374v1","title":"The Multifractal IP Address Structure: Physical Explanation and\n  Implications","summary":"The structure of IP addresses observed in Internet traffic plays a critical\nrole for a wide range of networking problems of current interest. For example,\nmodern network telemetry systems that take advantage of existing data plane\ntechnologies for line rate traffic monitoring and processing cannot afford to\nwaste precious data plane resources on traffic that comes from \"uninteresting\"\nregions of the IP address space. However, there is currently no\nwell-established structural model or analysis toolbox that enables a\nfirst-principles approach to the specific problem of identifying\n\"uninteresting\" regions of the address space or the myriad of other networking\nproblems that prominently feature IP addresses.\n  To address this key missing piece, we present in this paper a\nfirst-of-its-kind empirically validated physical explanation for why the\nobserved IP address structure in measured Internet traffic is multifractal in\nnature. Our root cause analysis overcomes key limitations of mostly forgotten\nfindings from ~20 years ago and demonstrates that the Internet processes and\nmechanisms responsible for how IP addresses are allocated, assigned, and used\nin today's Internet are consistent with and well modeled by a class of\nevocative mathematical models called conservative cascades. We complement this\nroot cause analysis with the development of an improved toolbox that is\ntailor-made for analyzing finite and discrete sets of IP addresses and includes\nstatistical estimators that engender high confidence in the inferences they\nproduce. We illustrate the use of this toolbox in the context of a novel\naddress structure anomaly detection method we designed and conclude with a\ndiscussion of a range of challenging open networking problems that are\nmotivated or inspired by our findings.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T05:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.01382v1","title":"An Illusion of Progress? Assessing the Current State of Web Agents","summary":"As digitalization and cloud technologies evolve, the web is becoming\nincreasingly important in the modern society. Autonomous web agents based on\nlarge language models (LLMs) hold a great potential in work automation. It is\ntherefore important to accurately measure and monitor the progression of their\ncapabilities. In this work, we conduct a comprehensive and rigorous assessment\nof the current state of web agents. Our results depict a very different picture\nof the competency of current agents, suggesting over-optimism in previously\nreported results. This gap can be attributed to shortcomings in existing\nbenchmarks. We introduce Online-Mind2Web, an online evaluation benchmark\nconsisting of 300 diverse and realistic tasks spanning 136 websites. It enables\nus to evaluate web agents under a setting that approximates how real users use\nthese agents. To facilitate more scalable evaluation and development, we also\ndevelop a novel LLM-as-a-Judge automatic evaluation method and show that it can\nachieve around 85% agreement with human judgment, substantially higher than\nexisting methods. Finally, we present the first comprehensive comparative\nanalysis of current web agents, highlighting both their strengths and\nlimitations to inspire future research.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-02T05:51:29Z"}
{"aid":"http://arxiv.org/abs/2504.01384v1","title":"On the efficient computation of Fourier coefficients of eta-quotients","summary":"We give formulas for computing efficiently the generalized Kloosterman sums\nappearing in the Hardy-Ramanujan-Rademacher expansions of the Fourier\ncoefficients of general eta-quotients given by Sussman and Chern, as well as\nexplicit bounds for the tails of these series.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T05:52:33Z"}
{"aid":"http://arxiv.org/abs/2504.01388v1","title":"(Non-)well-founded derivations in the provability logic $\\mathsf{GLP}$","summary":"We examine cyclic, non-well-founded and well-founded derivations in the\nprovability logic $\\mathsf{GLP}$. While allowing cyclic derivations does not\nchange the system, the non-well-founded and well-founded derivations we\nconsider define the same proper infinitary extension of $\\mathsf{GLP}$. We\nestablish that this extension is strongly algebraic and neighbourhood complete\nwith respect to both local and global semantic consequence relations. In fact,\nthese completeness results are proved for generalizations of global and local\nconsequence relations, which we call global-local. In addition, we prove strong\nlocal neighbourhood completeness for the original system $\\mathsf{GLP}$ (with\nordinary derivations only).","main_category":"math.LO","categories":"math.LO","published":"2025-04-02T06:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.01394v1","title":"Double unstable avoided crossings and complex domain patterns formation\n  in spin-orbit coupled spin-1 condensates","summary":"We analyze the impact of spin-orbit and Rabi couplings on the dynamical\nstability of spin-orbit-coupled spin-1 Bose-Einstein condensates for\nferromagnetic (FM) and antiferromagnetic (AFM) interactions. Determining the\ncollective excitation spectrum through Bogoliubov-de-Gennes theory, we\ncharacterize the dynamical stability regime via modulational instability. For\nAFM interactions, the eigenspectrum reveals the presence of both stable and\nunstable avoided crossings (UAC), with the first-excited branch undergoing a\ndouble unstable avoided crossing. In contrast, with ferromagnetic interactions,\nonly a single UAC, which occurs between the low-lying and first-excited\nbranches, is observed. Furthermore, the eigenvectors demonstrate the transition\nfrom density-like to spin-like behaviour, as the collective excitation shows\nthe transition from stable to unstable mode for both the FM and AFM\ninteractions. In the multi-band instability state, eigenvectors display\nspin-density mixed mode, while they show spin-flip nature in the avoided\ncrossing regime. Our analysis suggests that spin-orbit coupling enhances the\ninstability gain, while Rabi coupling plays the opposite role. Finally, we\ncorroborate our analytical findings of stable and unstable regimes through\nnumerical simulations of the dynamical evolution of the condensates by\nintroducing the perturbations upon quenching the trap strength. The dynamical\nphases show the formation of complex domains with AFM interaction, which may be\nattributed to the double unstable avoided crossings in such a system.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-02T06:19:52Z"}
{"aid":"http://arxiv.org/abs/2504.01395v1","title":"From Easy to Hard: Building a Shortcut for Differentially Private Image\n  Synthesis","summary":"Differentially private (DP) image synthesis aims to generate synthetic images\nfrom a sensitive dataset, alleviating the privacy leakage concerns of\norganizations sharing and utilizing synthetic images. Although previous methods\nhave significantly progressed, especially in training diffusion models on\nsensitive images with DP Stochastic Gradient Descent (DP-SGD), they still\nsuffer from unsatisfactory performance. In this work, inspired by curriculum\nlearning, we propose a two-stage DP image synthesis framework, where diffusion\nmodels learn to generate DP synthetic images from easy to hard. Unlike existing\nmethods that directly use DP-SGD to train diffusion models, we propose an easy\nstage in the beginning, where diffusion models learn simple features of the\nsensitive images. To facilitate this easy stage, we propose to use `central\nimages', simply aggregations of random samples of the sensitive dataset.\nIntuitively, although those central images do not show details, they\ndemonstrate useful characteristics of all images and only incur minimal privacy\ncosts, thus helping early-phase model training. We conduct experiments to\npresent that on the average of four investigated image datasets, the fidelity\nand utility metrics of our synthetic images are 33.1% and 2.1% better than the\nstate-of-the-art method.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-02T06:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.01405v1","title":"Teaching Robots to Handle Nuclear Waste: A Teleoperation-Based Learning\n  Approach<","summary":"This paper presents a Learning from Teleoperation (LfT) framework that\nintegrates human expertise with robotic precision to enable robots to\nautonomously perform skills learned from human operators. The proposed\nframework addresses challenges in nuclear waste handling tasks, which often\ninvolve repetitive and meticulous manipulation operations. By capturing\noperator movements and manipulation forces during teleoperation, the framework\nutilizes this data to train machine learning models capable of replicating and\ngeneralizing human skills. We validate the effectiveness of the LfT framework\nthrough its application to a power plug insertion task, selected as a\nrepresentative scenario that is repetitive yet requires precise trajectory and\nforce control. Experimental results highlight significant improvements in task\nefficiency, while reducing reliance on continuous operator involvement.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T06:46:29Z"}
{"aid":"http://arxiv.org/abs/2504.01420v1","title":"FAIRE: Assessing Racial and Gender Bias in AI-Driven Resume Evaluations","summary":"In an era where AI-driven hiring is transforming recruitment practices,\nconcerns about fairness and bias have become increasingly important. To explore\nthese issues, we introduce a benchmark, FAIRE (Fairness Assessment In Resume\nEvaluation), to test for racial and gender bias in large language models (LLMs)\nused to evaluate resumes across different industries. We use two methods-direct\nscoring and ranking-to measure how model performance changes when resumes are\nslightly altered to reflect different racial or gender identities. Our findings\nreveal that while every model exhibits some degree of bias, the magnitude and\ndirection vary considerably. This benchmark provides a clear way to examine\nthese differences and offers valuable insights into the fairness of AI-based\nhiring tools. It highlights the urgent need for strategies to reduce bias in\nAI-driven recruitment. Our benchmark code and dataset are open-sourced at our\nrepository:\nhttps://github.com/athenawen/FAIRE-Fairness-Assessment-In-Resume-Evaluation.git.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T07:11:30Z"}
{"aid":"http://arxiv.org/abs/2504.01440v1","title":"Solving Time-Fractional Partial Integro-Differential Equations Using\n  Tensor Neural Networks","summary":"In this paper, we propose a novel machine learning method based on adaptive\ntensor neural network subspace to solve linear time-fractional diffusion-wave\nequations and nonlinear time-fractional partial integro-differential equations.\nIn this framework, the tensor neural network and Gauss-Jacobi quadrature are\neffectively combined to construct a universal numerical scheme for the temporal\nCaputo derivative with orders spanning $ (0,1)$ and $(1,2)$. Specifically, in\norder to effectively utilize Gauss-Jacobi quadrature to discretize Caputo\nderivatives, we design the tensor neural network function multiplied by the\nfunction $t^{\\mu}$ where the power $\\mu$ is selected according to the\nparameters of the equations at hand. Finally, some numerical examples are\nprovided to validate the efficiency and accuracy of the proposed tensor neural\nnetwork-based machine learning method.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T07:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.01445v1","title":"Enabling Systematic Generalization in Abstract Spatial Reasoning through\n  Meta-Learning for Compositionality","summary":"Systematic generalization refers to the capacity to understand and generate\nnovel combinations from known components. Despite recent progress by large\nlanguage models (LLMs) across various domains, these models often fail to\nextend their knowledge to novel compositional scenarios, revealing notable\nlimitations in systematic generalization. There has been an ongoing debate\nabout whether neural networks possess the capacity for systematic\ngeneralization, with recent studies suggesting that meta-learning approaches\ndesigned for compositionality can significantly enhance this ability. However,\nthese insights have largely been confined to linguistic problems, leaving their\napplicability to other tasks an open question. In this study, we extend the\napproach of meta-learning for compositionality to the domain of abstract\nspatial reasoning. To this end, we introduce $\\textit{SYGAR}$-a dataset\ndesigned to evaluate the capacity of models to systematically generalize from\nknown geometric transformations (e.g., translation, rotation) of\ntwo-dimensional objects to novel combinations of these transformations (e.g.,\ntranslation+rotation). Our results show that a transformer-based\nencoder-decoder model, trained via meta-learning for compositionality, can\nsystematically generalize to previously unseen transformation compositions,\nsignificantly outperforming state-of-the-art LLMs, including o3-mini, GPT-4o,\nand Gemini 2.0 Flash, which fail to exhibit similar systematic behavior. Our\nfindings highlight the effectiveness of meta-learning in promoting\nsystematicity beyond linguistic tasks, suggesting a promising direction toward\nmore robust and generalizable models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T07:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.01457v1","title":"Deep LG-Track: An Enhanced Localization-Confidence-Guided Multi-Object\n  Tracker","summary":"Multi-object tracking plays a crucial role in various applications, such as\nautonomous driving and security surveillance. This study introduces Deep\nLG-Track, a novel multi-object tracker that incorporates three key enhancements\nto improve the tracking accuracy and robustness. First, an adaptive Kalman\nfilter is developed to dynamically update the covariance of measurement noise\nbased on detection confidence and trajectory disappearance. Second, a novel\ncost matrix is formulated to adaptively fuse motion and appearance information,\nleveraging localization confidence and detection confidence as weighting\nfactors. Third, a dynamic appearance feature updating strategy is introduced,\nadjusting the relative weighting of historical and current appearance features\nbased on appearance clarity and localization accuracy. Comprehensive\nevaluations on the MOT17 and MOT20 datasets demonstrate that the proposed Deep\nLG-Track consistently outperforms state-of-the-art trackers across multiple\nperformance metrics, highlighting its effectiveness in multi-object tracking\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:10:18Z"}
{"aid":"http://arxiv.org/abs/2504.01461v1","title":"Fate of Berezinskii-Kosterlitz-Thouless Paired Phase in Coupled $XY$\n  Models","summary":"Intriguing phases may emerge when two-dimensional systems are coupled in a\nbilayer configuration. In particular, a Berezinskii-Kosterlitz-Thouless (BKT)\npaired superfluid phase was predicted and claimed to be numerically observed in\na coupled $XY$ model with ferromagnetic interlayer interactions, as reported in\n[\\href{https://doi.org/10.1103/PhysRevLett.123.100601}{Phys. Rev. Lett. 123,\n100601 (2019)}]. However, both our Monte Carlo simulations and analytical\nanalysis show that this model does not exhibit a BKT paired phase. We then\npropose a new model incorporating four-body interlayer interactions to realize\nthe BKT paired phase. Moreover, we observe that the anomalous magnetic\ndimension varies along the phase transition line between the disordered normal\nphase and the BKT paired phase. This finding requires an understanding beyond\nthe conventional phase transition theory.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-02T08:17:51Z"}
{"aid":"http://arxiv.org/abs/2504.01465v1","title":"Photometry and Spectroscopy of the Symbiotic Binary V1413 Aquilae during\n  the 2024 Eclipse","summary":"We report our photometric and spectroscopic observations and analysis of the\n2024 eclipse of the symbiotic binary V1413 Aquilae. We found the system in a\nvisually bright state and the eclipse time of minimum consistent with the\npublished ephemeris. The eclipse profile showed that the hot component was an\nextended object rather than an isolated white dwarf. By analyzing the eclipse\nprofile we estimated the orbital inclination to be 67.9{\\deg}, the radius of\nthe extended hot component surrounding the white dwarf to be 39.3 Rsun, and\nthat the red giant star was probably filling its Roche Lobe. From our flux\ncalibrated spectra, we determined the brightest component of the system to be\nthe hot component whose continuum and emission lines together are responsible\nfor 83% of the V-band light. The circumbinary nebula and its emission lines\ncontribute over 14%, while the red giant is responsible for less than 3%. Our\nspectra revealed a rich harvest of low ionization emission lines. By measuring\nhow flux in these emission lines varied through the eclipse, we have provided\ninformation which should prove useful for future modelling of this symbiotic\nsystem.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-02T08:22:23Z"}
{"aid":"http://arxiv.org/abs/2504.01469v1","title":"Mechanisms of Dual-Band Emission in Sb-Doped Rare-Earth Phosphates\n  Revealed","summary":"The Sb$^{3+}$ ion has garnered significant interest due to its effectiveness\nin boosting the optical properties of host materials. Among the interesting\nphenomena is the commonly observed dual-band emission, which has often been\ninterpreted by adopting the phenomenological model that explains the dual-band\nemission (``ultraviolet band'' and ``visible band'') in Sb-doped $L$PO$_{4}$\n($L$ = Sc, Y, Lu). However, the model for Sb-doped $L$PO$_{4}$ series itself\nhas not been well understood theoretically. In this work, we employ\nfirst-principles calculations combined with group-theory analysis to clarify\nthe underlying physical mechanism behind dual-band emission in Sb-doped\n$L$PO$_{4}$ series. We demonstrate that the dual-band arises from two\nexcited-state equilibrium structures, one exhibits a relatively small\ndistortion with respect to the ground-state equilibrium structure, while the\nother displays a significantly larger distortion, characteristic of an\n``off-center'' configuration. The deviations from the ground-state\nconfiguration are dominated by two distinct vibrational modes, $b_2$ and $e$\nmodes, involving the Jahn-Teller effect and the pseudo Jahn-Teller effect,\nrespectively. Furthermore, charge transition levels and energy barriers\ncalculated using the climbing image nudged elastic band (CI-NEB) method have\naided in understanding the relaxation between the two excited-state\nconfigurations and the property changes across the Sc, Y, and Lu series. These\ninsights provide a basis for understanding the exotic properties of Sb$^{3+}$\nin other hosts and may facilitate the design of optical materials in a broader\nrange of systems involving Sb$^{3+}$ ions.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T08:23:34Z"}
{"aid":"http://arxiv.org/abs/2504.01479v1","title":"Spectral theory of the Neumann-PoincarÃ© operator associated with\n  multi-layer structures and analysis of plasmon mode splitting","summary":"In this paper, we develop a general mathematical framework for analyzing\nelectostatics within multi-layer metamaterial structures. The multi-layer\nstructure can be designed by nesting complementary negative and regular\nmaterials together, and it can be easily achieved by truncating bulk metallic\nmaterial in a specific configuration. Using layer potentials and symmetrization\ntechniques, we establish the perturbation formula in terms of\nNeumann-Poincar\\'e (NP) operator for general multi-layered medium, and obtain\nthe spectral properties of the NP operator, which demonstrates that the number\nof plasmon modes increases with the number of layers. Based on Fourier series,\nwe present an exact matrix representation of the NP operator in an apparently\nunsymmetrical structure, exemplified by multi-layer confocal ellipses. By\nhighly intricate and delicate analysis, we establish a handy algebraic\nframework for studying the splitting of the plasmon modes within multi-layer\nstructures. Moreover, the asymptotic profiles of the plasmon modes are also\nobtained. This framework helps reveal the effects of material truncation and\nrotational symmetry breaking on the splitting of the plasmon modes, thereby\ninducing desired resonances and enabling the realization of customized\napplications.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T08:35:27Z"}
{"aid":"http://arxiv.org/abs/2504.01486v1","title":"Generalized Assignment and Knapsack Problems in the Random-Order Model","summary":"We study different online optimization problems in the random-order model.\nThere is a finite set of bins with known capacity and a finite set of items\narriving in a random order. Upon arrival of an item, its size and its value for\neach of the bins is revealed and it has to be decided immediately and\nirrevocably to which bin the item is assigned, or to not assign the item at\nall. In this setting, an algorithm is $\\alpha$-competitive if the total value\nof all items assigned to the bins is at least an $\\alpha$-fraction of the total\nvalue of an optimal assignment that knows all items beforehand. We give an\nalgorithm that is $\\alpha$-competitive with $\\alpha = (1-\\ln(2))/2 \\approx\n1/6.52$ improving upon the previous best algorithm with $\\alpha \\approx 1/6.99$\nfor the generalized assignment problem and the previous best algorithm with\n$\\alpha \\approx 1/6.65$ for the integral knapsack problem. We then study the\nfractional knapsack problem where we have a single bin and it is also allowed\nto pack items fractionally. For that case, we obtain an algorithm that is\n$\\alpha$-competitive with $\\alpha = 1/e \\approx 1/2.71$ improving on the\nprevious best algorithm with $\\alpha = 1/4.39$. We further show that this\ncompetitive ratio is the best-possible for deterministic algorithms in this\nmodel.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-04-02T08:38:41Z"}
{"aid":"http://arxiv.org/abs/2504.01487v1","title":"Discrete stability estimates for the pressureless\n  Euler-Poisson-Boltzmann equations in the Quasi-Neutral limit","summary":"We propose and study a fully implicit finite volume scheme for the\npressureless Euler-Poisson-Boltzmann equations on the one dimensional torus.\nEspecially, we design a consistent and dissipative discretization of the force\nterm which yields an unconditional energy decay. In addition, we establish a\ndiscrete analogue of the modulated energy estimate around constant states with\na small velocity. Numerical experiments are carried to illustrate our\ntheoretical results and to assess the accuracy of our scheme. A test case of\nthe literature is also illustrated.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T08:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.01503v1","title":"Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting\n  Conditions with View-Adaptive Curve Adjustment","summary":"Capturing high-quality photographs under diverse real-world lighting\nconditions is challenging, as both natural lighting (e.g., low-light) and\ncamera exposure settings (e.g., exposure time) significantly impact image\nquality. This challenge becomes more pronounced in multi-view scenarios, where\nvariations in lighting and image signal processor (ISP) settings across\nviewpoints introduce photometric inconsistencies. Such lighting degradations\nand view-dependent variations pose substantial challenges to novel view\nsynthesis (NVS) frameworks based on Neural Radiance Fields (NeRF) and 3D\nGaussian Splatting (3DGS). To address this, we introduce Luminance-GS, a novel\napproach to achieving high-quality novel view synthesis results under diverse\nchallenging lighting conditions using 3DGS. By adopting per-view color matrix\nmapping and view-adaptive curve adjustments, Luminance-GS achieves\nstate-of-the-art (SOTA) results across various lighting conditions -- including\nlow-light, overexposure, and varying exposure -- while not altering the\noriginal 3DGS explicit representation. Compared to previous NeRF- and\n3DGS-based baselines, Luminance-GS provides real-time rendering speed with\nimproved reconstruction quality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.01505v1","title":"In-situ compression and shape recovery of Ceramic single grain\n  micro-pillar","summary":"Most ceramic materials are known for high fracture toughness while reacting\nhighly brittle to physical deformation. Some advancements were made by\nutilizing the transformation toughening effect of Yttria-doped Zirconia.\nHowever, finding a ceramic material demonstrating an effect analogous to the\nShape Memory Effect (SME) in certain metals, that also allows for superelastic\nresponses, remains a challenge. The underlying mechanism for SME and\nsuperelasticity is based on crystallographic variations within the material's\ngrains, requiring sophisticated electron microscopy techniques for direct\nobservation. The combination of a scanning electron microscope (SEM) with\nfocused ion beam (FIB) milling, a Kleindiek Nanotechnik GmbH micro-manipulator\nwith a 1.5 $\\mu$m diamond tip, and the ability to achieve in-situ heating up to\n450 {\\deg}C on a Kleindiek heating stage provides a robust platform for the\npreparation, deformation, and heating of micro-pillars made from ceramic\nmaterials. This setup enabled us to conduct detailed studies on the\nZirconia-based ceramic, observing permanent deformation exceeding 4% strain,\nfollowed by shape recovery at 370 {\\deg}C. The paper provides outlines the key\nexperimental steps that facilitated these observations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T08:55:27Z"}
{"aid":"http://arxiv.org/abs/2504.01519v1","title":"Chain of Correction for Full-text Speech Recognition with Large Language\n  Models","summary":"Full-text error correction with Large Language Models (LLMs) for Automatic\nSpeech Recognition (ASR) has gained increased attention due to its potential to\ncorrect errors across long contexts and address a broader spectrum of error\ntypes, including punctuation restoration and inverse text normalization.\nNevertheless, many challenges persist, including issues related to stability,\ncontrollability, completeness, and fluency. To mitigate these challenges, this\npaper proposes the Chain of Correction (CoC) for full-text error correction\nwith LLMs, which corrects errors segment by segment using pre-recognized text\nas guidance within a regular multi-turn chat format. The CoC also uses\npre-recognized full text for context, allowing the model to better grasp global\nsemantics and maintain a comprehensive overview of the entire content.\nUtilizing the open-sourced full-text error correction dataset ChFT, we\nfine-tune a pre-trained LLM to evaluate the performance of the CoC framework.\nExperimental results demonstrate that the CoC effectively corrects errors in\nfull-text ASR outputs, significantly outperforming baseline and benchmark\nsystems. We further analyze how to set the correction threshold to balance\nunder-correction and over-rephrasing, extrapolate the CoC model on extremely\nlong ASR outputs, and investigate whether other types of information can be\nemployed to guide the error correction process.","main_category":"cs.CL","categories":"cs.CL,eess.AS","published":"2025-04-02T09:06:23Z"}
{"aid":"http://arxiv.org/abs/2504.01520v1","title":"Time-to-event prediction for grouped variables using Exclusive Lasso","summary":"The integration of high-dimensional genomic data and clinical data into\ntime-to-event prediction models has gained significant attention due to the\ngrowing availability of these datasets. Traditionally, a Cox regression model\nis employed, concatenating various covariate types linearly. Given that much of\nthe data may be redundant or irrelevant, feature selection through penalization\nis often desirable. A notable characteristic of these datasets is their\norganization into blocks of distinct data types, such as methylation and\nclinical predictors, which requires selecting a subset of covariates from each\ngroup due to high intra-group correlations. For this reason, we propose\nutilizing Exclusive Lasso regularization in place of standard Lasso\npenalization. We apply our methodology to a real-life cancer dataset,\ndemonstrating enhanced survival prediction performance compared to the\nconventional Cox regression model.","main_category":"stat.ME","categories":"stat.ME,stat.CO,stat.ML","published":"2025-04-02T09:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.01534v1","title":"Context-Aware Toxicity Detection in Multiplayer Games: Integrating\n  Domain-Adaptive Pretraining and Match Metadata","summary":"The detrimental effects of toxicity in competitive online video games are\nwidely acknowledged, prompting publishers to monitor player chat conversations.\nThis is challenging due to the context-dependent nature of toxicity, often\nspread across multiple messages or informed by non-textual interactions.\nTraditional toxicity detectors focus on isolated messages, missing the broader\ncontext needed for accurate moderation. This is especially problematic in video\ngames, where interactions involve specialized slang, abbreviations, and typos,\nmaking it difficult for standard models to detect toxicity, especially given\nits rarity. We adapted RoBERTa LLM to support moderation tailored to video\ngames, integrating both textual and non-textual context. By enhancing\npretrained embeddings with metadata and addressing the unique slang and\nlanguage quirks through domain adaptive pretraining, our method better captures\nthe nuances of player interactions. Using two gaming datasets - from Defense of\nthe Ancients 2 (DOTA 2) and Call of Duty$^\\circledR$: Modern\nWarfare$^\\circledR$III (MWIII) we demonstrate which sources of context\n(metadata, prior interactions...) are most useful, how to best leverage them to\nboost performance, and the conditions conducive to doing so. This work\nunderscores the importance of context-aware and domain-specific approaches for\nproactive moderation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T09:21:41Z"}
{"aid":"http://arxiv.org/abs/2504.01549v1","title":"Business Process Modeling Using a Metamodeling Approach","summary":"The thesis discusses topics related to the development of business process\nmanagement systems. Business process management systems have evolved on the\nbasis of workflow management systems through incremental inclusion of standard\ninformation system functions, for example, resource and client management. The\napplication of model driven development is required to deal with the complexity\nof business management systems and to increase development efficiency. In\ncontrast to conventional information systems, the behavior of business\nmanagement systems is strongly affected by the business models that they\nexecute. Thus, business process models also can be used for designing and\ndeveloping business management systems using sequentially applied model\ntransformations that adapt models to a specific execution platform.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T09:46:54Z"}
{"aid":"http://arxiv.org/abs/2504.01563v1","title":"Height arguments toward the dynamical Mordell-Lang problem in arbitrary\n  characteristic","summary":"We use height arguments to prove two results about the dynamical Mordell-Lang\nproblem. We are more interested in the positive characteristic case due to our\noriginal purpose.\n  (i) For an endomorphism of a projective variety, the return set of a dense\norbit into a curve is finite if any cohomological Lyapunov exponent of any\niteration is not an integer.\n  (ii) Let $f\\times g:X\\times C\\rightarrow X\\times C$ be an endomorphism in\nwhich $f$ and $g$ are endomorphisms of a projective variety $X$ and a curve\n$C$, respectively. If the degree of $g$ is greater than the first dynamical\ndegree of $f$, then the return sets of the system $(X\\times C,f\\times g)$ have\nthe same form as the return sets of the system $(X,f)$.\n  Using the second result, we deal with the case of split endomorphisms of\nproducts of curves, for which the degrees of the factors are pairwise distinct.\n  In the cases that the height argument cannot be applied, we find examples\nwhich show that the return set can be very complicated -- more complicated than\nexperts once imagine -- even for endomorphisms of tori of zero entropy.","main_category":"math.DS","categories":"math.DS,math.AG,math.NT","published":"2025-04-02T10:04:14Z"}
{"aid":"http://arxiv.org/abs/2504.01572v1","title":"A microscopic calculation of fission cross sections with the\n  non-equilibrium Green function method","summary":"We apply the non-equilibrium Green function (NEGF) method to microscopically\nevaluate fission cross sections for the neutron induced $^{235}$U$(n,f)$\nreaction. While the model space was restricted only to seniority zero\nconfigurations in the previous applications of the NEGF method, we remove this\nrestriction and include seniority non-zero configurations as well. In such\nmodel space, a proton-neutron interaction is active, for which we introduce a\nrandom interaction. We find that the seniority non-zero configurations\nsignificantly increase the fission cross sections, and thus the\nfission-to-capture branching ratios, even though they are still underestimated\nby about one order of magnitude as compared to the experimental data. In\naddition, we also find that the fission dynamics is governed by only a small\nnumber of eigenstates of the model Hamiltonian.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-02T10:18:05Z"}
{"aid":"http://arxiv.org/abs/2504.01573v1","title":"Asymmetric VI-NES with dry friction: An impact map approach","summary":"This paper examines the dynamics of a vibro-impact nonlinear energy sink\n(VI-NES) using a generalized impact map approach. The study incorporates\nasymmetry and dry friction, reflecting realistic conditions. The proposed\nmethod identifies all periodic solutions and determines their stability, and is\napplicable to various VI-NES configurations, including horizontal and vertical\norientations. Numerical results validate prior findings for symmetric\nfrictionless cases and extend them to include frictional and asymmetric\ndynamics, providing a powerful tool for optimizing the performance of VI-NES in\nvibration mitigation.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-02T10:19:43Z"}
{"aid":"http://arxiv.org/abs/2504.01581v1","title":"Shape transitions of sedimenting confined droplets and capsules: from\n  oblate to bullet-like geometries","summary":"The transport and deformation of confined droplets and flexible capsules are\ncentral to diverse phenomena and applications, from biological flows in\nmicrocapillaries to industrial processes in porous media. We combine\nexperiments and numerical simulations to investigate their shape dynamics under\nvarying levels of confinement and particle flexibility. A transition from an\noblate to a bullet-like shape is observed at a confinement threshold,\nindependent of flexibility. A fluid-structure interaction analysis reveals two\nregimes: a pressure-dominated and a viscous-dominated regime. For highly\nflexible particles, the pressure-dominated regime prevails and the deformation\nis enhanced. These findings offer new insights into the transport of flexible\nparticles in confined environments, with implications for biomedical\napplications, filtration technologies, and multiphase fluid mechanics.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T10:38:07Z"}
{"aid":"http://arxiv.org/abs/2504.01598v1","title":"Expanding the Horizons of Phase Transition-Based Luminescence\n  Thermometry","summary":"The limited operational range of phase transition-based luminescence\nthermometers necessitates the exploration of new host materials exhibiting\nfirst-order structural phase transitions to broaden the applicability of this\napproach. Addressing this need, the present study investigates the\nspectroscopic properties of as a function of temperature. A thermally induced\nstructural transition from the low-temperature orthorhombic phase to the\nhigh-temperature trigonal phase, occurring at approximately 430 K,\nsignificantly alters the spectroscopic properties of Eu3 ions. Specifically, a\nreduction in the number of Stark lines due to changes in the point symmetry of\nEu3 ions enables the development of a ratiometric luminescence thermometer with\nsensitivity as high as K. Furthermore, it was demonstrated that increasing the\nconcentration of Eu3 ions shifts the phase transition temperature, allowing for\nmodulation of the thermometric performance of this luminescence thermometer.\nThe findings presented here not only expand the repertoire of phase\ntransition-based luminescence thermometers but also illustrate how the\nluminescence properties of Eu3 ions can be employed to accurately monitor\nstructural changes in the host material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T11:05:57Z"}
{"aid":"http://arxiv.org/abs/2504.01605v1","title":"Multi-Relation Graph-Kernel Strengthen Network for Graph-Level\n  Clustering","summary":"Graph-level clustering is a fundamental task of data mining, aiming at\ndividing unlabeled graphs into distinct groups. However, existing deep methods\nthat are limited by pooling have difficulty extracting diverse and complex\ngraph structure features, while traditional graph kernel methods rely on\nexhaustive substructure search, unable to adaptive handle multi-relational\ndata. This limitation hampers producing robust and representative graph-level\nembeddings. To address this issue, we propose a novel Multi-Relation\nGraph-Kernel Strengthen Network for Graph-Level Clustering (MGSN), which\nintegrates multi-relation modeling with graph kernel techniques to fully\nleverage their respective advantages. Specifically, MGSN constructs\nmulti-relation graphs to capture diverse semantic relationships between nodes\nand graphs, which employ graph kernel methods to extract graph similarity\nfeatures, enriching the representation space. Moreover, a relation-aware\nrepresentation refinement strategy is designed, which adaptively aligns\nmulti-relation information across views while enhancing graph-level features\nthrough a progressive fusion process. Extensive experiments on multiple\nbenchmark datasets demonstrate the superiority of MGSN over state-of-the-art\nmethods. The results highlight its ability to leverage multi-relation\nstructures and graph kernel features, establishing a new paradigm for robust\ngraph-level clustering.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T11:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.01607v1","title":"High-Chern-number Quantum anomalous Hall insulators in mixing-stacked\n  MnBi$_2$Te$_4$ thin films","summary":"Quantum anomalous Hall (QAH) insulators are characterized by vanishing\nlongitudinal resistance and quantized Hall resistance in the absence of an\nexternal magnetic field. Among them, high-Chern-number QAH insulators offer\nmultiple nondissipative current channels, making them crucial for the\ndevelopment of low-power-consumption electronics. Using first-principles\ncalculations, we propose that high-Chern-number ($C>1$) QAH insulators can be\nrealized in MnBi$_2$Te$_4$ (MBT) multilayer films through the combination of\nmixed stacking orders, eliminating the need for additional buffer layers. The\nunderlying physical mechanism is validated by calculating real-space-resolved\nanomalous Hall conductivity (AHC). Local AHC is found to be predominantly\nlocated in regions with consecutive correct stacking orders, contributing to\nquasi-quantized AHC. Conversely, regions with consecutive incorrect stacking\ncontribute minimally to the total AHC, which can be attributed to the varied\ninterlayer coupling in different stacking configurations. Our work provides\nvaluable insights into the design principle for achieving large Chern numbers,\nand highlights the role of stacking configurations in manipulating electronic\nand topological properties in MBT films and its derivatives.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T11:20:40Z"}
{"aid":"http://arxiv.org/abs/2504.01617v1","title":"The Mini-SiTian Array: Evaluation Camera System","summary":"The Mini-SiTian project, which is the pathfinder for the SiTian project,\nutilizes three 30 cm telescopes equipped with commercial CMOS cameras (ZWO\nASI6200MM Pro) to simulate large-area time-domain survey. Due to the avoidance\nof the traditional mechanical shutter, the CMOS camera is favorable in\ntime-domain survey projects. In the future, the SiTian telescope array will\nemploy a two-by-two scientific-grade mosaic CMOS camera to survey a\n10,000-degree square area every 30 minutes. Therefore, the performance of CMOS\ndirectly determines the detection capability of SiTian telescopes for transient\nsources, and a comprehensive understanding of the performance of CMOS cameras\nis crucial. In this research, laboratory testing was conducted to thoroughly\nevaluate three cameras by assessing several critical parameters, including bias\nstability, dark current, pixel anomalies, linearity, gain, and read noise. We\nfind exceptional short-term bias stability with standard deviations below 0.02\nADU, negligible dark current of approximately 0.002 e$^{-}$ pixel$^{-1}$\ns$^{-1}$ at $0^\\circ\\text{C}$, and excellent linearity with nonlinearity\nconsistently below $\\pm$ 0.5\\%, and a small proportion (0.06\\% to 0.08\\%) of\npixels with anomalous responses. Furthermore, our analysis demonstrates uniform\ngain values across all cameras, ranging from 0.252 to 0.255 e$^{-}$ ADU$^{-1}$,\nwith low readout noise, measured to be below 1.6 e$^{-}$ using conventional\nmethods. We also propose a novel method for pixel-level gain and read noise\ncalculation for CMOS sensors, which revealed a narrow gain distribution and a\nlow median read noise of 1.028 e$^-$ for one of the cameras. The laboratory\ntesting of the ZWO ASI6200MM Pro cameras indicates their potential to meet the\nrequirements of time-domain surveys for the Mini-SiTian project.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:26:32Z"}
{"aid":"http://arxiv.org/abs/2504.01626v1","title":"NIR-to-NIR ratiometric and lifetime based luminescence thermometer on a\n  structural phase transition in Na3Sc2(PO4)3:Yb3+","summary":"The ratiometric approach is the most commonly employed readout technique in\nluminescence thermometry. To address the trade-off between the risk of\nmeasurement disturbance in thermometers with high spectral separation of\nemission bands (due to dispersion in the surrounding medium) and the low\nsensitivity observed in ratiometric thermometers based on Stark level\nthermalization, we propose a thermometer based on the structural phase\ntransition in . The use of Yb3+ ions as dopants and the changes in Stark level\nenergies associated with the thermally induced monoclinic-to-trigonal phase\ntransition enable the development of a thermometer with high relative\nsensitivity, achieving at 340K for N. Additionally, as demonstrated, the\nstructural transition alters the probability of radiative depopulation of the\n2F5/2 state of Yb3+, allowing the development of a lifetime-based luminescence\nthermometer. Furthermore, the phase transition temperature and consequently the\nthermometric performance of can be modulated by varying the Yb3+ ion\nconcentration, offering additional tunability for specific applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T11:32:02Z"}
{"aid":"http://arxiv.org/abs/2504.01628v1","title":"Copositive geometry of Feynman integrals","summary":"Copositive matrices and copositive polynomials are objects from optimization.\nWe connect these to the geometry of Feynman integrals in physics. The integral\nis guaranteed to converge if its kinematic parameters lie in the copositive\ncone. P\\'olya's method makes this manifest. We study the copositive cone for\nthe second Symanzik polynomial of any Feynman graph. Its algebraic boundary is\ndescribed by Landau discriminants.","main_category":"math.OC","categories":"math.OC,hep-th,math-ph,math.CO,math.MP","published":"2025-04-02T11:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.01658v1","title":"Scaling in Magnetic Neutron Scattering","summary":"We report the discovery of scaling in the mesoscale magnetic microstructure\nof bulk ferromagnets. Supported by analytical micromagnetic theory, we\nintroduce the field-dependent scaling length $l_{\\mathrm{C}}(H)$, which\ndescribes the characteristic long-wavelength magnetization fluctuations that\nare caused by microstructural defects by means of magnetoelastic and\nmagnetocrystalline anisotropy. The scaling length $l_{\\mathrm{C}}$ is\nidentified to consist of the micromagnetic exchange length of the field\n$l_{\\mathrm{H}}$, which depends on the magnetic interactions, and a\nfield-independent contribution that reflects the properties of the magnetic\nanisotropy field and the magnetostatic fluctuations. The latter finding is\nrooted in the convolution relationship between the grain microstructure and\nmicromagnetic response functions. We validated the scaling property by\nanalyzing experimental data for the magnetic neutron scattering cross section.\nWhen plotted as a function of the dimensionless scaled scattering vector\n$\\mathfrak{q}(H) = q \\, l_{\\mathrm{C}}(H)$, the field-dependent\namplitude-scaled neutron data of nanocrystalline Co and a Nd-Fe-B-based\nnanocomposite collapse onto a single master curve, demonstrating universal\nbehavior. The scaling length $l_{\\mathrm{C}}$ provides a framework for\nanalyzing the field-dependent neutron scattering cross section, highlighting\nthe existence of critical length scales that govern the mesoscale\nmicrostructure of magnetic materials.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T12:11:12Z"}
{"aid":"http://arxiv.org/abs/2504.01663v1","title":"Recovering Small Communities in the Planted Partition Model","summary":"We analyze community recovery in the planted partition model (PPM) in regimes\nwhere the number of communities is arbitrarily large. We examine the three\nstandard recovery regimes: exact recovery, almost exact recovery, and weak\nrecovery. When communities vary in size, traditional accuracy- or\nalignment-based metrics become unsuitable for assessing the correctness of a\npredicted partition. To address this, we redefine these recovery regimes using\nthe correlation coefficient, a more versatile metric for comparing partitions.\nWe then demonstrate that \\emph{Diamond Percolation}, an algorithm based on\ncommon-neighbors, successfully recovers communities under mild assumptions on\nedge probabilities, with minimal restrictions on the number and sizes of\ncommunities. As a key application, we consider the case where community sizes\nfollow a power-law distribution, a characteristic frequently found in\nreal-world networks. To the best of our knowledge, we provide the first\nrecovery results for such unbalanced partitions.","main_category":"math.PR","categories":"math.PR,cs.SI","published":"2025-04-02T12:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.01687v1","title":"Radiative Vlasov-Maxwell Equations","summary":"In the radiative Vlasov-Maxwell equations, the Lorentz force is modified by\nthe addition of radiation reaction forces. The radiation forces produce damping\nof particle energy but the forces are no longer divergence-free in momentum\nspace, which has an effect of concentration to zero momentum. We prove\nunconditional global regularity of solutions for a class of radiative\nVlasov-Maxwell equations with large initial data.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T12:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.01704v1","title":"Performance and applications of optical pin beams in turbulent\n  long-range free space optical communications","summary":"Optical pin beams (OPBs) are a promising candidate for realizing\nturbulence-resilient long-distance free-space optical communication links\nspanning hundreds of kilometers. In this work, we introduce a unified\ntheoretical model to describe the propagation of OPBs and present comprehensive\nsimulation results based on many realizations and link-budget analyses for\nconstant turbulence strengths. For reference, we compare the performance of the\nOPBs to weakly diverging and focusing Gaussian beams. For a 100km long\nair-to-air link, 10km above sea level, our simulation results show that OPBs\noffer an improved link budget of up to 8.6dB and enhanced beam wander\nstatistics of up to 3dB compared to the considered Gaussian beams.\nAdditionally, we identified a quadratic relationship between the transmitter\naperture diameter and the maximum achievable distances, which is crucial in\ndeciding the suitability of OPBs for a given application scenario.","main_category":"physics.optics","categories":"physics.optics,physics.ao-ph","published":"2025-04-02T13:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.01720v1","title":"Input-Erasing Two-Way Finite Automata","summary":"The present paper introduces and studies an alternative concept of two-way\nfinite automata called input-erasing two-way finite automata. Like the original\nmodel, these new automata can also move the reading head freely left or right\non the input tape. However, each time they read a symbol, they also erase it\nfrom the tape. The paper demonstrates that these automata define precisely the\nfamily of linear languages and are thus strictly stronger than the original\nones. Furthermore, it introduces a variety of restrictions placed upon these\nautomata and the way they work and investigates the effect of these\nrestrictions on their acceptance power. In particular, it explores the mutual\nrelations of language families resulting from some of these restrictions and\nshows that some of them reduce the power of these automata to that of even\nlinear grammars or even ordinary finite automata.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-02T13:28:01Z"}
{"aid":"http://arxiv.org/abs/2504.01735v1","title":"AdPO: Enhancing the Adversarial Robustness of Large Vision-Language\n  Models with Preference Optimization","summary":"Large Vision-Language Models (LVLMs), such as GPT-4o and LLaVA, have recently\nwitnessed remarkable advancements and are increasingly being deployed in\nreal-world applications. However, inheriting the sensitivity of visual neural\nnetworks, LVLMs remain vulnerable to adversarial attacks, which can result in\nerroneous or malicious outputs. While existing efforts utilize adversarial\nfine-tuning to enhance robustness, they often suffer from performance\ndegradation on clean inputs. In this paper, we proposes AdPO, a novel\nadversarial defense strategy for LVLMs based on preference optimization. For\nthe first time, we reframe adversarial training as a preference optimization\nproblem, aiming to enhance the model's preference for generating normal outputs\non clean inputs while rejecting the potential misleading outputs for\nadversarial examples. Notably, AdPO achieves this by solely modifying the image\nencoder, e.g., CLIP ViT, resulting in superior clean and adversarial\nperformance in a variety of downsream tasks. Considering that training involves\nlarge language models (LLMs), the computational cost increases significantly.\nWe validate that training on smaller LVLMs and subsequently transferring to\nlarger models can achieve competitive performance while maintaining efficiency\ncomparable to baseline methods. Our comprehensive experiments confirm the\neffectiveness of the proposed AdPO, which provides a novel perspective for\nfuture adversarial defense research.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T13:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.01743v1","title":"High Dimensional Bayesian Optimization using Lasso Variable Selection","summary":"Bayesian optimization (BO) is a leading method for optimizing expensive\nblack-box optimization and has been successfully applied across various\nscenarios. However, BO suffers from the curse of dimensionality, making it\nchallenging to scale to high-dimensional problems. Existing work has adopted a\nvariable selection strategy to select and optimize only a subset of variables\niteratively. Although this approach can mitigate the high-dimensional challenge\nin BO, it still leads to sample inefficiency. To address this issue, we\nintroduce a novel method that identifies important variables by estimating the\nlength scales of Gaussian process kernels. Next, we construct an effective\nsearch region consisting of multiple subspaces and optimize the acquisition\nfunction within this region, focusing on only the important variables. We\ndemonstrate that our proposed method achieves cumulative regret with a\nsublinear growth rate in the worst case while maintaining computational\nefficiency. Experiments on high-dimensional synthetic functions and real-world\nproblems show that our method achieves state-of-the-art performance.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T13:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.01745v1","title":"Characterising galaxy cluster scaling relations as cosmic isotropy\n  tracers using the FLAMINGO simulations","summary":"The standard cosmological model, $\\Lambda$CDM, assumes isotropy on large\ncosmic scales. However, recent studies using galaxy cluster scaling relations\nreported an apparent $H_0$ anisotropy at $5.4\\sigma$ that could be attributed\nto large bulk flows extending beyond $500\\,\\mathrm{Mpc}$, in disagreement with\n$\\Lambda$CDM. To quantify the statistical tension of the observational galaxy\ncluster data used in past studies with $\\Lambda$CDM, we utilise the isotropic\n($2.8\\,\\mathrm{Gpc})^3$ run of the FLAMINGO ($\\Lambda$CDM) simulations, the\nlargest hydrodynamical cosmological simulation available to date. We create\n1728 simulated lightcones and study the apparent level of anisotropy traced by\nX-ray and thermal Sunyaev-Zeldovich scaling relations in the same cluster\nsample selection and methodology as in Migkas et al. (2021, arXiv:2103.13904).\nWe find the probability of such apparent anisotropies randomly emerging in\ncluster scaling relations within a $\\Lambda$CDM universe to be $0.12\\%\\,\n(3.2\\sigma)$. The discrepancy goes up to $\\sim 3.6\\sigma$ when modelled as a\nbulk flow at $z < 0.1$. We find that statistical noise accounts for over $80\\%$\nof the anisotropy amplitude in each lightcone, with large peculiar velocities\ncontributing less than $20\\%$. We also show that anisotropy amplitudes are\nhighly sensitive to the intrinsic scatter in the scaling relations, with\ntighter relations providing stronger constraints. Nevertheless, the tension\nbetween Migkas et al. (2021, arXiv:2103.13904) and $\\Lambda$CDM persists,\nhowever, at a lower significance than previously reported.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T13:55:14Z"}
{"aid":"http://arxiv.org/abs/2504.01751v1","title":"Cyanine-Conjugated Gold Nanospheres for Near-infrared Fluorescence","summary":"Near-infrared fluorescence imaging offers improved spatial precision by\nreducing light scattering and absorption in tissue. Despite this key advantage,\nthe NIR region is limited by the availability of fluorophores, most of which\nexhibit relatively low quantum yield. In this study, gold nanospheres with\nabsorption peaks in the visible range were used to enhance the fluorescence\nintensity of the cyanine NIR fluorophore IRdye 800 in the first NIR window of\nthe electromagnetic spectrum. AuNSs with diameters ranging from 5 to 25 nm were\nchosen to investigate the impact of a nanoparticle size on fluorescence\nenhancement, functionalized with polyethylene glycol of varying molecular\nweights to optimize the distance between the fluorophore and the nanoparticle\nsurface. Theoretical analyses using finite-difference time-domain simulations\nand experimental comparisons with non-metallic nanoparticles were performed to\nidentify the factors contributing to the enhancement of fluorescence. PEGylated\nAuNSs conjugated with IRdye 800 (AuNDs) exhibited decreased photoisomerization,\nresulting in increased fluorescence intensity and altered fluorescence\nlifetimes. The observed enhancement in the fluorescence intensity of the AuNDs\nwas attributed to three primary mechanisms: metal-enhanced fluorescence,\naltered radiative decay rates, and steric stabilization. Among these three\nmechanisms, two are attributed to the tail-end absorption spectral overlap of\nthe AuNSs with IRdye 800. This study highlights the potential of AuNSs for\nimproving NIR-I fluorescence imaging and opens up new possibilities for\napplications in biomedical research.","main_category":"physics.optics","categories":"physics.optics,physics.chem-ph","published":"2025-04-02T14:03:37Z"}
{"aid":"http://arxiv.org/abs/2504.01758v1","title":"Isospin asymmetry and neutron stars in V-QCD","summary":"Isospin asymmetric nuclear matter is introduced to V-QCD, a bottom-up\nholographic Quantum Chromodynamics (QCD) model. Using a small isospin chemical\npotential we extract the symmetry energy in the model, finding excellent\nagreement with experimental results for some of the potentials. Extending the\ncalculation for finite and arbitrary sized isospin chemical potentials, we\nconstruct beta-equilibrated neutron stars via the usual\nTolman-Oppenheimer-Volkov (TOV) equations. We find, pleasingly, that the\nneutron stars passing the mass/radius and tidal deformability constraints are\nthose with the potentials that also lead to excellent symmetry energies.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-th","published":"2025-04-02T14:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.01760v1","title":"Compact Group Homeomorphisms Preserving The Haar Measure","summary":"This paper studies the measure-preserving homeomorphisms on compact groups\nand proposes new methods for constructing measure-preserving homeomorphisms on\ndirect products of compact groups and non-commutative compact groups.\n  On the direct product of compact groups, we construct measure-preserving\nhomeomorphisms using the method of integration. In particular, by applying this\nmethod to the \\(n\\)-dimensional torus \\({\\mathbb{T}}^{n}\\), we can construct\nmany new examples of measure-preserving homeomorphisms. We completely\ncharacterize the measure-preserving homeomorphisms on the two-dimensional torus\nwhere one coordinate is a translation depending on the other coordinate, and\ngeneralize this result to the \\(n\\)-dimensional torus.\n  For non-commutative compact groups, we generalize the concept of the\nnormalizer subgroup \\(N\\left( H\\right)\\) of the subgroup \\(H\\) to the\nnormalizer subset \\({E}_{K}( P)\\) from the subset \\(K\\) to the subset \\(P\\) of\nthe group of measure-preserving homeomorphisms. We prove that if \\(\\mu\\) is the\nunique \\(K\\)-invariant measure, then the elements in \\({E}_{K}\\left( P\\right)\\)\nalso preserve \\(\\mu\\). In some non-commutative compact groups the normalizer\nsubset \\({E}_{G}\\left( {\\mathrm{{AF}}\\left( G\\right) }\\right)\\) can give\nnon-affine homeomorphisms that preserve the Haar measure. Finally, we prove\nthat when \\(G\\) is a finite cyclic group and a \\(n\\)-dimensional torus, then\n\\(\\mathrm{{AF}}\\left( G\\right)= N\\left( G\\right) = {E}_{G}\\left(\n{\\mathrm{{AF}}\\left( G\\right) }\\right)\\).","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T14:16:29Z"}
{"aid":"http://arxiv.org/abs/2504.01769v1","title":"Operator aspects of wave propagation through periodic media","summary":"Recent results in quantitative homogenisation of the wave equation with\nrapidly oscillating coefficients are discussed from the operator-theoretic\nperspective, which views the solution as the result of applying the operator of\nhyperbolic dynamics, i.e. the unitary group of a self-adjoint operator on a\nsuitable Hilbert space. A prototype one-dimensional example of utilising the\nframework of Ryzhov boundary triples is analysed, where operator-norm resolvent\nestimates for the problem of classical moderate-contrast homogenisation are\nobtained. By an appropriate \"dilation\" procedure, these are shown to upgrade to\nsecond-order (and more generally, higher-order) estimates for the resolvent and\nthe unitary group describing the evolution for the related wave equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T14:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.01776v1","title":"Hydrodynamic simulations of the Disc of Gas Around Supermassive black\n  holes (HDGAS) -II; The transition from neutral atomic to molecular gas phases","summary":"We use HDGAS hydrodynamic simulations to study the impact of active galactic\nnucleus (AGN) feedback on the conversion of atomic-gas to molecular-gas within\nthe circumnuclear-disc (CND) of a typical AGN-dominated galaxy. The comparison\nof CI, CII, and CO line intensities and their ratios in the HDGAS\npost-processing radiative-transfer analysis reveals the complex interplay\nbetween AGN-activity, cold molecular gas properties, and the physical processes\ngoverning the evolution of star-formation in galaxies. Our results demonstrate\nthat the CI/CO intensity ratio serves as a reliable indicator of the\natomic-to-molecular gas transition. We present the probability distribution\nfunction (PDF) and abundance trends of various metal species related to\nmolecular H$2$ gas, highlighting differences in clumpiness and intensity maps\nbetween AGN feedback and NoAGN models. The profile of the integrated intensity\n(moment-0) maps shows that the AGN-feedback model exhibits a lower CI/CO\nintensity ratio in the vicinity of the supermassive black hole (< 50 pc),\nindicating a smaller atomic-gas abundance and the presence of positive\nAGN-feedback. Our simulations have successfully predicted the presence of\nfaint-CO emissions extending to larger radii from the galactic center. We also\nexplore the relationships between CII/CO and CI/CII intensity ratios, as well\nas the ratios versus CO intensity, which provides insights into the \"CO-dark\"\nissues. One notable feature in the later time-scale of the AGN model is the\npresence of a \"CO-dark\" region, where the intensity of CO emission ($\\rm\nI_{CO}$) is depleted relative to the H$_2$ column density ($N_{\\rm H_2}$)\ncompared to the NoAGN model.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T14:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.01781v1","title":"Proper scoring rules for estimation and forecast evaluation","summary":"Proper scoring rules have been a subject of growing interest in recent years,\nnot only as tools for evaluation of probabilistic forecasts but also as methods\nfor estimating probability distributions. In this article, we review the\nmathematical foundations of proper scoring rules including general\ncharacterization results and important families of scoring rules. We discuss\ntheir role in statistics and machine learning for estimation and forecast\nevaluation. Furthermore, we comment on interesting developments of their usage\nin applications.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-04-02T14:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.01784v1","title":"Optimized Schwarz method for the Stokes-Darcy problem with generalized\n  interface conditions","summary":"Due to their wide appearance in environmental settings as well as industrial\nand medical applications, the Stokes-Darcy problems with different sets of\ninterface conditions establish an active research area in the community of\nmathematical modelers and computational scientists. For numerical simulation of\nsuch coupled problems in applications, robust and efficient computational\nalgorithms are needed. In this work, we consider a generalization of the\nBeavers-Joseph interface condition recently developed using homogenization and\nboundary layer theory. This extension is applicable not only for the parallel\nflows to the fluid-porous interface as its predecessor, but also for arbitrary\nflow directions. To solve the Stokes-Darcy problem with these generalized\ninterface conditions efficiently, we develop and analyze a Robin-Robin domain\ndecomposition method using Fourier analysis to identify optimal weights in the\nRobin interface conditions. We study efficiency and robustness of the proposed\nmethod and provide numerical simulations which confirm the obtained theoretical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T14:48:28Z"}
{"aid":"http://arxiv.org/abs/2504.01815v1","title":"Multiplexed Control at Scale for Electrode Arrays in Trapped-Ion Quantum\n  Processors","summary":"The scaling up of trapped-ion quantum processors based on the quantum\ncharge-coupled device (QCCD) architecture is difficult owing to the extensive\nelectronics and high-density wiring required to control numerous trap\nelectrodes. In conventional QCCD architectures, each trap electrode is\ncontrolled via a dedicated digital-to-analog converter (DAC). The conventional\napproach places an overwhelming demand on electronic resources and wiring\ncomplexity. This is because the number of trap electrodes typically exceeds the\nnumber of trapped-ion qubits. This study proposes a method that leverages a\nhigh-speed DAC to generate time-division multiplexed signals to control a\nlarge-scale QCCD trapped-ion quantum processor. The proposed method replaces\nconventional DACs with a single high-speed DAC that generates the complete\nvoltage waveforms required to control the trap electrodes, thereby\nsignificantly reducing the wiring complexity and overall resource requirements.\nBased on realistic parameters and commercially available electronics, our\nanalysis demonstrates that a QCCD trapped-ion quantum computer with 10,000 trap\nelectrodes can be controlled using only 13 field-programmable gate arrays and\n104 high-speed DACs. This is in stark contrast to the 10,000 dedicated DACs\nrequired by conventional control methods. Consequently, employing this\napproach, we developed a proof-of-concept electronic system and evaluated its\nanalog output performance.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T15:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.01823v1","title":"Evidence of doubly OZI-suppressed decay $Î·_{c} \\to ÏÏ$ in the\n  radiative decay $J/Ï\\to Î³Î·_{c}$","summary":"Using a sample of $(10087\\pm44) \\times 10^{6}$ $J/\\psi$ events collected with\nthe BESIII detector at the BEPCII collider, the first evidence for the doubly\nOZI-suppressed decay $\\eta_{c} \\to \\omega\\phi$ is reported with a significance\nof 4.0$\\sigma$. The branching fraction of $\\eta_{c} \\to \\omega\\phi$ is measured\nto be $\\mathcal{B}(\\eta_{c} \\to \\omega\\phi) = (3.86 \\pm 0.92 \\pm 0.62) \\times\n10^{-5}$, where the first uncertainty is statistical and the second is\nsystematic. This result provides valuable insights into the underlying\nmechanisms of charmonium decays, particularly for processes such as $\\eta_{c}\n\\to VV$ (where $V$ represents a vector meson).","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-02T15:30:09Z"}
{"aid":"http://arxiv.org/abs/2504.01830v1","title":"Is Lorentz invariance violation found?","summary":"Lorentz invariance violation (LIV) has long been recognized as an observable\nlow-energy signature of quantum gravity. In spite of a great effort to detect\nLIV effects, so far only lower bounds have been derived. The high energy\nphotons from the gamma ray burst GRB 221009A have been detected by the LHAASO\ncollaboration and one at ${\\cal E} \\simeq 251 \\, \\rm TeV$ by the Carpet\ncollaboration using a partial data set. Very recently, the Carpet collaboration\nhas completed the full data analysis, reporting further support for their\npreviously detected photon now at ${\\cal E} = 300^{+ 43}_{- 38} \\, {\\rm TeV}$,\nwhich manifestly clashes with conventional physics. Taking this result at face\nvalue, we derive the first evidence for LIV and we show that such a detection\ncannot be explained by axion-like particles (ALPs), which allow for the\nobservation of the highest energy photons detected by LHAASO. We also outline a\nscenario in which ALPs and LIV naturally coexist. If confirmed by future\nobservations our finding would represent the first positive result in quantum\ngravity phenomenology.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,hep-ph,hep-th","published":"2025-04-02T15:39:37Z"}
{"aid":"http://arxiv.org/abs/2504.01874v1","title":"The Hitchin morphism for certain surfaces fibered over a curve","summary":"The Chen-Ng\\^o Conjecture predicts that the Hitchin morphism from the moduli\nstack of $G$-Higgs bundles on a smooth projective variety surjects onto the\nspace of spectral data. The conjecture is known to hold for the group $GL_n$\nand any surface, and for the group $GL_2$ and any smooth projective variety. We\nprove the Chen-Ng\\^o Conjecture for any reductive group when the variety is a\nruled surface or (a blowup of) a nonisotrivial elliptic fibration with reduced\nfibers. Furthermore, if the group is a classical group, i.e. $G \\in\n\\{SL_n,SO_n,Sp_{2n}\\}$, then we prove the Hitchin morphism restricted to the\nDolbeault moduli space of semiharmonic $G$-Higgs bundles surjects onto the\nspace of spectral data.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T16:30:25Z"}
{"aid":"http://arxiv.org/abs/2504.01875v1","title":"Architect Your Landscape Approach (AYLA) for Optimizations in Deep\n  Learning","summary":"Stochastic Gradient Descent (SGD) and its variants, such as ADAM, are\nfoundational to deep learning optimization, adjusting model parameters using\nfixed or adaptive learning rates based on loss function gradients. However,\nthese methods often face challenges in balancing adaptability and efficiency in\nnon-convex, high-dimensional settings. This paper introduces AYLA, a novel\noptimization technique that enhances training dynamics through loss function\ntransformations. By applying a tunable power-law transformation, AYLA preserves\ncritical points while scaling loss values to amplify gradient sensitivity,\naccelerating convergence. We further propose a dynamic (effective) learning\nrate that adapts to the transformed loss, improving optimization efficiency.\nEmpirical tests on finding minimum of a synthetic non-convex polynomial, a\nnon-convex curve-fitting dataset, and digit classification (MNIST) demonstrate\nthat AYLA surpasses SGD and ADAM in convergence speed and stability. This\napproach redefines the loss landscape for better optimization outcomes,\noffering a promising advancement for deep neural networks and can be applied to\nany optimization method and potentially improve the performance of it.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T16:31:39Z"}
{"aid":"http://arxiv.org/abs/2504.01936v1","title":"Fermionic Averaged Circuit Eigenvalue Sampling","summary":"Fermionic averaged circuit eigenvalue sampling (FACES) is a protocol to\nsimultaneously learn the averaged error rates of many fermionic linear optical\n(FLO) gates simultaneously and self-consistently from a suitable collection of\nFLO circuits. It is highly flexible, allowing for the in situ characterization\nof FLO-averaged gate-dependent noise under natural assumptions on a family of\ncontinuously parameterized one- and two-qubit gates. We rigorously show that\nour protocol has an efficient sampling complexity, owing in-part to useful\nproperties of the Kravchuk transformations that feature in our analysis. We\nsupport our conclusions with numerical results. As FLO circuits become\nuniversal with access to certain resource states, we expect our results to\ninform noise characterization and error mitigation techniques on universal\nquantum computing architectures which naturally admit a fermionic description.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T17:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.02217v1","title":"The Plot Thickens: Quantitative Part-by-Part Exploration of MLLM\n  Visualization Literacy","summary":"Multimodal Large Language Models (MLLMs) can interpret data visualizations,\nbut what makes a visualization understandable to these models? Do factors like\ncolor, shape, and text influence legibility, and how does this compare to human\nperception? In this paper, we build on prior work to systematically assess\nwhich visualization characteristics impact MLLM interpretability. We expanded\nthe Visualization Literacy Assessment Test (VLAT) test set from 12 to 380\nvisualizations by varying plot types, colors, and titles. This allowed us to\nstatistically analyze how these features affect model performance. Our findings\nsuggest that while color palettes have no significant impact on accuracy, plot\ntypes and the type of title significantly affect MLLM performance. We observe\nsimilar trends for model omissions. Based on these insights, we look into which\nplot types are beneficial for MLLMs in different tasks and propose\nvisualization design principles that enhance MLLM readability. Additionally, we\nmake the extended VLAT test set, VLAT ex, publicly available on\nhttps://osf.io/ermwx/ together with our supplemental material for future model\ntesting and evaluation.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T02:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.02241v1","title":"Quantum Deep Sets and Sequences","summary":"This paper introduces the quantum deep sets model, expanding the quantum\nmachine learning tool-box by enabling the possibility of learning variadic\nfunctions using quantum systems. A couple of variants are presented for this\nmodel. The first one focuses on mapping sets to quantum systems through state\nvector averaging: each element of the set is mapped to a quantum state, and the\nquantum state of the set is the average of the corresponding quantum states of\nits elements. This approach allows the definition of a permutation-invariant\nvariadic model. The second variant is useful for ordered sets, i.e., sequences,\nand relies on optimal coherification of tristochastic tensors that implement\nproducts of mixed states: each element of the set is mapped to a density\nmatrix, and the quantum state of the set is the product of the corresponding\ndensity matrices of its elements. Such variant can be relevant in tasks such as\nnatural language processing. The resulting quantum state in any of the variants\nis then processed to realise a function that solves a machine learning task\nsuch as classification, regression or density estimation. Through synthetic\nproblem examples, the efficacy and versatility of quantum deep sets and\nsequences (QDSs) is demonstrated.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-04-03T03:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.02254v1","title":"LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic\n  Ambiguity in Puzzle Tasks","summary":"Recent advancements in Large Language Models (LLMs) have not only showcased\nimpressive creative capabilities but also revealed emerging agentic behaviors\nthat exploit linguistic ambiguity in adversarial settings. In this study, we\ninvestigate how an LLM, acting as an autonomous agent, leverages semantic\nambiguity to generate deceptive puzzles that mislead and challenge human users.\nInspired by the popular puzzle game \"Connections\", we systematically compare\npuzzles produced through zero-shot prompting, role-injected adversarial\nprompts, and human-crafted examples, with an emphasis on understanding the\nunderlying agent decision-making processes. Employing computational analyses\nwith HateBERT to quantify semantic ambiguity, alongside subjective human\nevaluations, we demonstrate that explicit adversarial agent behaviors\nsignificantly heighten semantic ambiguity -- thereby increasing cognitive load\nand reducing fairness in puzzle solving. These findings provide critical\ninsights into the emergent agentic qualities of LLMs and underscore important\nethical considerations for evaluating and safely deploying autonomous language\nsystems in both educational technologies and entertainment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T03:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.02255v1","title":"Bipedal Robust Walking on Uneven Footholds: Piecewise Slope LIPM with\n  Discrete Model Predictive Control","summary":"This study presents an enhanced theoretical formulation for bipedal\nhierarchical control frameworks under uneven terrain conditions. Specifically,\nowing to the inherent limitations of the Linear Inverted Pendulum Model (LIPM)\nin handling terrain elevation variations, we develop a Piecewise Slope LIPM\n(PS-LIPM). This innovative model enables dynamic adjustment of the Center of\nMass (CoM) height to align with topographical undulations during single-step\ncycles. Another contribution is proposed a generalized Angular Momentum-based\nLIPM (G-ALIP) for CoM velocity compensation using Centroidal Angular Momentum\n(CAM) regulation. Building upon these advancements, we derive the DCM\nstep-to-step dynamics for Model Predictive Control MPC formulation, enabling\nsimultaneous optimization of step position and step duration. A hierarchical\ncontrol framework integrating MPC with a Whole-Body Controller (WBC) is\nimplemented for bipedal locomotion across uneven stepping stones. The results\nvalidate the efficacy of the proposed hierarchical control framework and the\ntheoretical formulation.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-03T03:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.02258v1","title":"Submanifold-genericity of $\\mathbb{R}^d$-actions and uniform\n  multiplicative Diophantine approximation","summary":"In this paper, we prove a new ergodic theorem for $\\mathbb{R}^d$-actions\ninvolving averages over dilated submanifolds, thereby generalizing the theory\nof spherical averages. Our main result is a quantitative estimate for the error\nterm of such averages valid for smooth functions under some effective mixing\nassumptions on the action. With the aid of this theorem, we investigate\nmultiplicative-type Dirichlet-improvability for $(m\\times n)$-matrices with\nreal coefficients. In particular, we establish that almost all matrices are\nuniformly approximable by the function $x\\mapsto x^{-1}(\\log\nx)^{-1+\\varepsilon}$ for any $\\varepsilon>0$. Results of this type motivate a\nquestion which can be thought as a strengthening of Littlewood's conjecture in\nmultiplicative Diophantine approximation.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-03T04:01:49Z"}
{"aid":"http://arxiv.org/abs/2504.02269v1","title":"Engineering Artificial Intelligence: Framework, Challenges, and Future\n  Direction","summary":"Over the past ten years, the application of artificial intelligence (AI) and\nmachine learning (ML) in engineering domains has gained significant popularity,\nshowcasing their potential in data-driven contexts. However, the complexity and\ndiversity of engineering problems often require the development of\ndomain-specific AI approaches, which are frequently hindered by a lack of\nsystematic methodologies, scalability, and robustness during the development\nprocess. To address this gap, this paper introduces the \"ABCDE\" as the key\nelements of Engineering AI and proposes a unified, systematic engineering AI\necosystem framework, including eight essential layers, along with attributes,\ngoals, and applications, to guide the development and deployment of AI\nsolutions for specific engineering needs. Additionally, key challenges are\nexamined, and nine future research directions are highlighted. By providing a\ncomprehensive perspective, this paper aims to advance the strategic\nimplementation of AI, fostering the development of next-generation engineering\nAI solutions.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-03T04:30:10Z"}
{"aid":"http://arxiv.org/abs/2504.02296v1","title":"Exceedance and force of centrality for functional data","summary":"Exceedance refers to instances where a dynamic process surpasses given\nthresholds, e.g., the occurrence of a heat wave. We propose a novel exceedance\nframework for functional data, where each observed random trajectory is\ntransformed into an exceedance function, which quantifies exceedance durations\nas a function of threshold levels. An inherent relationship between exceedance\nfunctions and probability distributions makes it possible to draw on\ndistributional data analysis techniques such as Fr\\'echet regression to study\nthe dependence of exceedances on Euclidean predictors, e.g., calendar year when\nthe exceedances are observed. We use local linear estimators to obtain\nexceedance functions from discretely observed functional data with noise and\nstudy the convergence of the proposed estimators. New concepts of interest\ninclude the force of centrality that quantifies the propensity of a system to\nrevert to lower levels when a given threshold has been exceeded, conditional\nexceedance functions when conditioning on Euclidean covariates, and threshold\nexceedance functions, which characterize the size of exceedance sets in\ndependence on covariates for any fixed threshold. We establish consistent\nestimation with rates of convergence for these targets. The practical merits of\nthe proposed methodology are illustrated through simulations and applications\nfor annual temperature curves and medfly activity profiles.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-03T05:58:24Z"}
{"aid":"http://arxiv.org/abs/2504.02297v1","title":"The temperature dependence of fractional topological charge objects","summary":"We present a novel method for defining the topological charge contained\nwithin distinct topological objects in the nontrivial ground-state fields of\nSU(N) lattice gauge theory. Such an analysis has been called for by the growing\nnumber of models for Yang-Mills topological structure which propose the\nexistence of fractionally charged objects. This investigation is performed for\nSU(3) at a range of temperatures across the deconfinement phase transition,\nproviding an assessment of how the topological structure evolves with\ntemperature. This reveals a connection between the topological charge and\nholonomy of the system which must be satisfied by finite-temperature models of\nYang-Mills vacuum structure. We find a promising consistency with the\ninstanton-dyon model for SU(N) vacuum structure.","main_category":"hep-lat","categories":"hep-lat,hep-ph,nucl-th","published":"2025-04-03T06:04:20Z"}
{"aid":"http://arxiv.org/abs/2504.02298v1","title":"SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in\n  Spiking Neural Networks","summary":"Spiking Neural Networks (SNNs), as a biologically plausible alternative to\nArtificial Neural Networks (ANNs), have demonstrated advantages in terms of\nenergy efficiency, temporal processing, and biological plausibility. However,\nSNNs are highly sensitive to distribution shifts, which can significantly\ndegrade their performance in real-world scenarios. Traditional test-time\nadaptation (TTA) methods designed for ANNs often fail to address the unique\ncomputational dynamics of SNNs, such as sparsity and temporal spiking behavior.\nTo address these challenges, we propose $\\textbf{SP}$ike-$\\textbf{A}$ware\n$\\textbf{C}$onsistency $\\textbf{E}$nhancement (SPACE), the first source-free\nand single-instance TTA method specifically designed for SNNs. SPACE leverages\nthe inherent spike dynamics of SNNs to maximize the consistency of\nspike-behavior-based local feature maps across augmented versions of a single\ntest sample, enabling robust adaptation without requiring source data. We\nevaluate SPACE on multiple datasets, including CIFAR-10-C, CIFAR-100-C,\nTiny-ImageNet-C and DVS Gesture-C. Furthermore, SPACE demonstrates strong\ngeneralization across different model architectures, achieving consistent\nperformance improvements on both VGG9 and ResNet11. Experimental results show\nthat SPACE outperforms state-of-the-art methods, highlighting its effectiveness\nand robustness in real-world settings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T06:05:05Z"}
{"aid":"http://arxiv.org/abs/2504.02305v1","title":"Nuclear Winds Drive Large-Scale Cold Gas Outflows in Quasars during the\n  Reionization Epoch","summary":"Accreting supermassive black holes (SMBHs) regulate the evolution of their\nhost galaxies through powerful outflows and multi-phase feedback. This process\nplays a crucial role in shaping SMBH-galaxy co-evolution across cosmic time,\nbut direct evidence linking nuclear winds to large-scale cold gas outflows,\nparticularly in high-redshift quasars, has remained elusive. Here we present\nstatistical evidence of a connection between nuclear winds and large-scale cold\ngas outflows in quasars at $z \\sim 5.5$. Using stacked [C II] 158 $\\mu$m\nemission profiles from ALMA observations, which trace galactic-scale neutral\ngas, we compare broad absorption line (BAL) quasars -- tracing parsec- to\nsub-kiloparsec-scale nuclear winds -- with non-BAL quasars. The BAL stack\nreveals a significant (S/N=4.45) broad component in the [C II] emission,\nindicating high-velocity neutral gas outflows with a velocity offset of $\\Delta\nv_{\\rm b} = -2.1 \\times 10^2 \\, \\rm km\\,s^{-1}$ and a full width at half\nmaximum of $1.18 \\times 10^3 \\, \\rm km\\,s^{-1}$, while the non-BAL stack shows\nno such feature. We estimate that a few percent up to one-quarter of the BAL\nwind energy is transferred to neutral gas on kiloparsec scales. These findings\nprovide direct observational evidence that nuclear winds couple with\ngalactic-scale neutral gas flows, supporting multi-phase AGN feedback models.\nThis mechanism may contribute to explaining the diversity of $M_{\\rm BH}/M_*$\nratios observed in some luminous AGN recently observed by JWST, compared to the\nMagorrian relation.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-03T06:22:57Z"}
{"aid":"http://arxiv.org/abs/2504.02329v1","title":"Towards Assessing Deep Learning Test Input Generators","summary":"Deep Learning (DL) systems are increasingly deployed in safety-critical\napplications, yet they remain vulnerable to robustness issues that can lead to\nsignificant failures. While numerous Test Input Generators (TIGs) have been\ndeveloped to evaluate DL robustness, a comprehensive assessment of their\neffectiveness across different dimensions is still lacking. This paper presents\na comprehensive assessment of four state-of-the-art TIGs--DeepHunter,\nDeepFault, AdvGAN, and SinVAD--across multiple critical aspects:\nfault-revealing capability, naturalness, diversity, and efficiency. Our\nempirical study leverages three pre-trained models (LeNet-5, VGG16, and\nEfficientNetB3) on datasets of varying complexity (MNIST, CIFAR-10, and\nImageNet-1K) to evaluate TIG performance. Our findings reveal important\ntrade-offs in robustness revealing capability, variation in test case\ngeneration, and computational efficiency across TIGs. The results also show\nthat TIG performance varies significantly with dataset complexity, as tools\nthat perform well on simpler datasets may struggle with more complex ones. In\ncontrast, others maintain steadier performance or better scalability. This\npaper offers practical guidance for selecting appropriate TIGs aligned with\nspecific objectives and dataset characteristics. Nonetheless, more work is\nneeded to address TIG limitations and advance TIGs for real-world,\nsafety-critical systems.","main_category":"cs.LG","categories":"cs.LG,cs.CV,cs.SE","published":"2025-04-03T07:06:55Z"}
{"aid":"http://arxiv.org/abs/2504.02330v1","title":"Commutators between coprime order elements in non-abelian simple groups","summary":"Recent investigations on the set of commutators between the elements of a\nfinite group having relatively prime orders have prompt us to propose a variant\nof the Ore conjecture: For every finite non-abelian simple group and for every\n$g\\in G$, there exist $x,y\\in G$ with $g=[y,x]$ and with the order of $x$\nrelatively prime to the order of $y$. In this note we present some evidence\ntowards the veracity of this conjecture by proving it for alternating groups\nand some sporadic simple groups.","main_category":"math.GR","categories":"math.GR","published":"2025-04-03T07:07:41Z"}
{"aid":"http://arxiv.org/abs/2504.02364v1","title":"SProBench: Stream Processing Benchmark for High Performance Computing\n  Infrastructure","summary":"Recent advancements in data stream processing frameworks have improved\nreal-time data handling, however, scalability remains a significant challenge\naffecting throughput and latency. While studies have explored this issue on\nlocal machines and cloud clusters, research on modern high performance\ncomputing (HPC) infrastructures is yet limited due to the lack of scalable\nmeasurement tools. This work presents SProBench, a novel benchmark suite\ndesigned to evaluate the performance of data stream processing frameworks in\nlarge-scale computing systems. Building on best practices, SProBench\nincorporates a modular architecture, offers native support for SLURM-based\nclusters, and seamlessly integrates with popular stream processing frameworks\nsuch as Apache Flink, Apache Spark Streaming, and Apache Kafka Streams.\nExperiments conducted on HPC clusters demonstrate its exceptional scalability,\ndelivering throughput that surpasses existing benchmarks by more than tenfold.\nThe distinctive features of SProBench, including complete customization\noptions, built-in automated experiment management tools, seamless\ninteroperability, and an open-source license, distinguish it as an innovative\nbenchmark suite tailored to meet the needs of modern data stream processing\nframeworks.","main_category":"cs.DC","categories":"cs.DC,cs.PF","published":"2025-04-03T07:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.02368v1","title":"Electrical conductivities and low frequency opacities in the warm dense\n  matter regime","summary":"In this article, we examine different approaches for calculating low\nfrequency opacities in the warm dense matter regime. The relevance of the\naverage-atom approximation and of different models for calculating opacities,\nsuch as the Ziman or Ziman-Evans models is discussed and the results compared\nto \\textit{ab initio} simulations. We begin by recalling the derivation of the\nZiman-Evans resistivity from Kubo's linear response theory, using the local\napproximation to the solutions of the Lippmann-Schwinger equation. With the\nhelp of this approximation, we explicitly introduce an ionic structure factor\ninto the Ziman formula, without resorting to the Born approximation. Both\napproaches involve the calculation of scattering phase shifts, which we\nintegrate from Calogero equation with an adaptive step numerical scheme based\non a Runge-Kutta-Merson solver. We show that if the atomic number $Z$ is not\ntoo large, integrating the phase shifts in this way is more time-efficient than\nusing a classical Numerov-type scheme to solve the radial Schr\\\"odinger\nequation. Various approximations are explored for phase shifts to further\nimprove computation time. For the Born approximation, we show that using Born\nphase shifts directly in the scattering cross-section gives more accurate\nresults than with the integral formula based on the Fourier transform of the\nelectron-ion potential. We also compare an analytical formula based on a Yukawa\nfit of the electron-ion potential to a numerical integration. The average-atom\nresults are compared with DFT-based molecular dynamics simulations for aluminum\nin the dilute regime and for copper, aluminum and gold at solid density and\ndifferent temperatures.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T08:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.02370v1","title":"A Spectral Approach for Quasinormal Frequencies of Noncommutative\n  Geometry-inspired Wormholes","summary":"We present a detailed investigation of quasinormal modes (QNMs) for\nnoncommutative geometry-inspired wormholes, focusing on scalar,\nelectromagnetic, and vector-type gravitational perturbations. By employing the\nspectral method, the perturbation equations are reformulated into an eigenvalue\nproblem over a compact domain, using Chebyshev polynomials to ensure high\nprecision and fast numerical convergence. Our results reveal the absence of\noverdamped modes, with all detected QNMs exhibiting oscillatory behaviour.\nAdditionally, for large values of the rescaled mass parameter, the QNMs of the\nnoncommutative wormhole transition smoothly to those of the classical\nSchwarzschild wormhole, validating the accuracy of the spectral method. This\nwork represents the first comprehensive exploration of QNMs in noncommutative\ngeometry-inspired wormholes, shedding light on their stability and dynamical\nproperties.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-03T08:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.02377v1","title":"Research Paper Recommender System by Considering Users' Information\n  Seeking Behaviors","summary":"With the rapid growth of scientific publications, researchers need to spend\nmore time and effort searching for papers that align with their research\ninterests. To address this challenge, paper recommendation systems have been\ndeveloped to help researchers in effectively identifying relevant paper. One of\nthe leading approaches to paper recommendation is content-based filtering\nmethod. Traditional content-based filtering methods recommend relevant papers\nto users based on the overall similarity of papers. However, these approaches\ndo not take into account the information seeking behaviors that users commonly\nemploy when searching for literature. Such behaviors include not only\nevaluating the overall similarity among papers, but also focusing on specific\nsections, such as the method section, to ensure that the approach aligns with\nthe user's interests. In this paper, we propose a content-based filtering\nrecommendation method that takes this information seeking behavior into\naccount. Specifically, in addition to considering the overall content of a\npaper, our approach also takes into account three specific sections\n(background, method, and results) and assigns weights to them to better reflect\nuser preferences. We conduct offline evaluations on the publicly available DBLP\ndataset, and the results demonstrate that the proposed method outperforms six\nbaseline methods in terms of precision, recall, F1-score, MRR, and MAP.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-03T08:11:58Z"}
{"aid":"http://arxiv.org/abs/2504.02403v1","title":"DaKultur: Evaluating the Cultural Awareness of Language Models for\n  Danish with Native Speakers","summary":"Large Language Models (LLMs) have seen widespread societal adoption. However,\nwhile they are able to interact with users in languages beyond English, they\nhave been shown to lack cultural awareness, providing anglocentric or\ninappropriate responses for underrepresented language communities. To\ninvestigate this gap and disentangle linguistic versus cultural proficiency, we\nconduct the first cultural evaluation study for the mid-resource language of\nDanish, in which native speakers prompt different models to solve tasks\nrequiring cultural awareness. Our analysis of the resulting 1,038 interactions\nfrom 63 demographically diverse participants highlights open challenges to\ncultural adaptation: Particularly, how currently employed automatically\ntranslated data are insufficient to train or measure cultural adaptation, and\nhow training on native-speaker data can more than double response acceptance\nrates. We release our study data as DaKultur - the first native Danish cultural\nawareness dataset.","main_category":"cs.CL","categories":"cs.CL,cs.CY,cs.HC","published":"2025-04-03T08:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.02404v1","title":"AnesBench: Multi-Dimensional Evaluation of LLM Reasoning in\n  Anesthesiology","summary":"The application of large language models (LLMs) in the medical field has\ngained significant attention, yet their reasoning capabilities in more\nspecialized domains like anesthesiology remain underexplored. In this paper, we\nsystematically evaluate the reasoning capabilities of LLMs in anesthesiology\nand analyze key factors influencing their performance. To this end, we\nintroduce AnesBench, a cross-lingual benchmark designed to assess\nanesthesiology-related reasoning across three levels: factual retrieval (System\n1), hybrid reasoning (System 1.x), and complex decision-making (System 2).\nThrough extensive experiments, we first explore how model characteristics,\nincluding model scale, Chain of Thought (CoT) length, and language\ntransferability, affect reasoning performance. Then, we further evaluate the\neffectiveness of different training strategies, leveraging our curated\nanesthesiology-related dataset, including continuous pre-training (CPT) and\nsupervised fine-tuning (SFT). Additionally, we also investigate how the\ntest-time reasoning techniques, such as Best-of-N sampling and beam search,\ninfluence reasoning performance, and assess the impact of reasoning-enhanced\nmodel distillation, specifically DeepSeek-R1. We will publicly release\nAnesBench, along with our CPT and SFT training datasets and evaluation code at\nhttps://github.com/MiliLab/AnesBench.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T08:54:23Z"}
{"aid":"http://arxiv.org/abs/2504.02416v1","title":"Hyperspectral Remote Sensing Images Salient Object Detection: The First\n  Benchmark Dataset and Baseline","summary":"The objective of hyperspectral remote sensing image salient object detection\n(HRSI-SOD) is to identify objects or regions that exhibit distinct spectrum\ncontrasts with the background. This area holds significant promise for\npractical applications; however, progress has been limited by a notable\nscarcity of dedicated datasets and methodologies. To bridge this gap and\nstimulate further research, we introduce the first HRSI-SOD dataset, termed\nHRSSD, which includes 704 hyperspectral images and 5327 pixel-level annotated\nsalient objects. The HRSSD dataset poses substantial challenges for salient\nobject detection algorithms due to large scale variation, diverse\nforeground-background relations, and multi-salient objects. Additionally, we\npropose an innovative and efficient baseline model for HRSI-SOD, termed the\nDeep Spectral Saliency Network (DSSN). The core of DSSN is the Cross-level\nSaliency Assessment Block, which performs pixel-wise attention and evaluates\nthe contributions of multi-scale similarity maps at each spatial location,\neffectively reducing erroneous responses in cluttered regions and emphasizes\nsalient regions across scales. Additionally, the High-resolution Fusion Module\ncombines bottom-up fusion strategy and learned spatial upsampling to leverage\nthe strengths of multi-scale saliency maps, ensuring accurate localization of\nsmall objects. Experiments on the HRSSD dataset robustly validate the\nsuperiority of DSSN, underscoring the critical need for specialized datasets\nand methodologies in this domain. Further evaluations on the HSOD-BIT and\nHS-SOD datasets demonstrate the generalizability of the proposed method. The\ndataset and source code are publicly available at\nhttps://github.com/laprf/HRSSD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.02431v1","title":"Koney: A Cyber Deception Orchestration Framework for Kubernetes","summary":"System operators responsible for protecting software applications remain\nhesitant to implement cyber deception technology, including methods that place\ntraps to catch attackers, despite its proven benefits. Overcoming their\nconcerns removes a barrier that currently hinders industry adoption of\ndeception technology. Our work introduces deception policy documents to\ndescribe deception technology \"as code\" and pairs them with Koney, a Kubernetes\noperator, which facilitates the setup, rotation, monitoring, and removal of\ntraps in Kubernetes. We leverage cloud-native technologies, such as service\nmeshes and eBPF, to automatically add traps to containerized software\napplications, without having access to the source code. We focus specifically\non operational properties, such as maintainability, scalability, and\nsimplicity, which we consider essential to accelerate the adoption of cyber\ndeception technology and to facilitate further research on cyber deception.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-03T09:37:14Z"}
{"aid":"http://arxiv.org/abs/2504.02437v1","title":"MonoGS++: Fast and Accurate Monocular RGB Gaussian SLAM","summary":"We present MonoGS++, a novel fast and accurate Simultaneous Localization and\nMapping (SLAM) method that leverages 3D Gaussian representations and operates\nsolely on RGB inputs. While previous 3D Gaussian Splatting (GS)-based methods\nlargely depended on depth sensors, our approach reduces the hardware dependency\nand only requires RGB input, leveraging online visual odometry (VO) to generate\nsparse point clouds in real-time. To reduce redundancy and enhance the quality\nof 3D scene reconstruction, we implemented a series of methodological\nenhancements in 3D Gaussian mapping. Firstly, we introduced dynamic 3D Gaussian\ninsertion to avoid adding redundant Gaussians in previously well-reconstructed\nareas. Secondly, we introduced clarity-enhancing Gaussian densification module\nand planar regularization to handle texture-less areas and flat surfaces\nbetter. We achieved precise camera tracking results both on the synthetic\nReplica and real-world TUM-RGBD datasets, comparable to those of the\nstate-of-the-art. Additionally, our method realized a significant 5.57x\nimprovement in frames per second (fps) over the previous state-of-the-art,\nMonoGS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:51:51Z"}
{"aid":"http://arxiv.org/abs/2504.02442v1","title":"Youthful perspectives on sustainability: Examining pro-environmental\n  behaviors in tourism through latent class cluster analysis","summary":"Tourism has emerged as a significant driver of the global economy. As its\neconomic impact grows, concerns regarding environmental sustainability have\nintensified. This paper explores the dual dimensions of sustainable tourism:\nthe relationship between tourism supply and sustainability, and tourist demand\ncharacteristics. It highlights the critical role of young tourists, who exhibit\na heightened awareness of environmental issues and advocate for sustainable\npractices. By conducting a survey among young Italian university students, the\nstudy identifies distinct segments based on family background, political\norientation, and travel habits. Utilizing latent class cluster analysis, the\nfindings aim to enhance understanding of pro-environmental behaviors among\nyouth, offering insights for policymakers to foster sustainable tourism\npractices.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-03T09:58:51Z"}
{"aid":"http://arxiv.org/abs/2504.02446v1","title":"Revolutionizing Medical Data Transmission with IoMT: A Comprehensive\n  Survey of Wireless Communication Solutions and Future Directions","summary":"Traditional hospital-based medical examination methods face unprecedented\nchallenges due to the aging global population. The Internet of Medical Things\n(IoMT), an advanced extension of the Internet of Things (IoT) tailored for the\nmedical field, offers a transformative solution for delivering medical care.\nIoMT consists of interconnected medical devices that collect and transmit\npatients' vital signs online. This data can be analyzed to identify potential\nhealth issues, support medical decision-making, enhance patient outcomes, and\nstreamline healthcare operations. Additionally, IoMT helps individuals make\ninformed decisions about their health and fitness. There is a natural synergy\nwith emerging communication technologies to ensure the secure and timely\ntransmission of medical data. This paper presents the first comprehensive\ntutorial on cutting-edge IoMT research focusing on wireless communication-based\nsolutions. It introduces a systematic three-tier framework to analyze IoMT\nnetworks and identify application scenarios. The paper examines the medical\ndata transmission process, including intra-wireless Body Area Networks (WBAN),\ninter-WBAN, and beyond-WBAN communications. It also discusses the challenges of\nimplementing IoMT applications, such as the longevity of biosensors, co-channel\ninterference management, information security, and data processing delays.\nProposed solutions to these challenges are explored from a wireless\ncommunication perspective, and future research directions are outlined. The\nsurvey concludes with a summary of key findings and insights.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-03T10:00:42Z"}
{"aid":"http://arxiv.org/abs/2504.02454v1","title":"Taylor Series-Inspired Local Structure Fitting Network for Few-shot\n  Point Cloud Semantic Segmentation","summary":"Few-shot point cloud semantic segmentation aims to accurately segment\n\"unseen\" new categories in point cloud scenes using limited labeled data.\nHowever, pretraining-based methods not only introduce excessive time overhead\nbut also overlook the local structure representation among irregular point\nclouds. To address these issues, we propose a pretraining-free local structure\nfitting network for few-shot point cloud semantic segmentation, named\nTaylorSeg. Specifically, inspired by Taylor series, we treat the local\nstructure representation of irregular point clouds as a polynomial fitting\nproblem and propose a novel local structure fitting convolution, called\nTaylorConv. This convolution learns the low-order basic information and\nhigh-order refined information of point clouds from explicit encoding of local\ngeometric structures. Then, using TaylorConv as the basic component, we\nconstruct two variants of TaylorSeg: a non-parametric TaylorSeg-NN and a\nparametric TaylorSeg-PN. The former can achieve performance comparable to\nexisting parametric models without pretraining. For the latter, we equip it\nwith an Adaptive Push-Pull (APP) module to mitigate the feature distribution\ndifferences between the query set and the support set. Extensive experiments\nvalidate the effectiveness of the proposed method. Notably, under the 2-way\n1-shot setting, TaylorSeg-PN achieves improvements of +2.28% and +4.37% mIoU on\nthe S3DIS and ScanNet datasets respectively, compared to the previous\nstate-of-the-art methods. Our code is available at\nhttps://github.com/changshuowang/TaylorSeg.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.02475v1","title":"Heat Conduction with Phase Change in Permafrost Modules of Vegetation\n  Models","summary":"We consider the problem of heat conduction with phase change, that is\nessential for permafrost modeling in Land Surface Models and Dynamic Global\nVegetation Models. These models require minimal computational effort and an\nextremely robust solver for large-scale, long-term simulations. The weak\nenthalpy formulation of the Stefan problem is used as the mathematical model\nand a finite element method is employed for the discretization. Leveraging the\npiecewise affine structure of the nonlinear time-stepping equation system, we\ndemonstrate that this system has a unique solution and provide a solver that is\nguaranteed to find this solution in a finite number of steps from any initial\nguess. Comparisons with the Neumann analytical solution and tests in the\nLund-Potsdam-Jena managed Land vegetation model reveal that the new method does\nnot introduce significantly higher computational costs than the widely used\nDECP method while providing greater accuracy. In particular, it avoids a known\nnonphysical artifact in the solution.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T10:52:35Z"}
{"aid":"http://arxiv.org/abs/2504.02485v1","title":"Tilted dipolar bosons in the quasi-2D regime: from liquid stripes to\n  droplets","summary":"We characterize a system of tilted dipoles in a quasi two-dimensional\n(flattened) geometry and in the thermodynamic limit. We consider a finite\ntrapping in the z-axis achievable in current experiments. We compute the phase\ndiagram of the system at its equilibrium density for high tilting angles, where\nit becomes self-bound, and a striped liquid state emerges. To characterize the\nsystem, we perform a variational calculation, which is benchmarked with the\nsolution of the extended Gross-Pitaevskii equation. We connect the\nphenomenology in the thermodynamic limit to the physics of the finite-size\nsystem, provide parameters for the realization of potentially supersolid\nstriped states and study the critical number for dipolar droplet formation. Our\nresults are helpful to guide potential experiments in the study of dipolar\natoms in quasi two-dimensional geometries in the dipole-dominated regime.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-03T11:07:48Z"}
{"aid":"http://arxiv.org/abs/2504.02490v1","title":"Iterative blow-ups for maps with bounded $\\mathcal{A}$-variation: a\n  refinement, with application to $\\mathrm{BD}$ and $\\mathrm{BV}$","summary":"We refine the iterated blow-up techniques. This technique, combined with a\nrigidity result and a specific choice of the kernel projection in the\nPoincar\\'e inequality, might be employed to completely linearize blow-ups along\nat least one sequence. We show how to implement such argument by applying it to\nderive affine blow-up limits for $\\mathrm{BD}$ and $\\mathrm{BV}$ functions\naround Cantor points. In doing so we identify a specific subset of points -\ncalled totally singular points having blow-ups with completely singular\ngradient measure $D p=D^s p$, $\\mathcal{E} p=\\mathcal{E}^s p$ - at which such\nlinearization fails.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-03T11:13:47Z"}
{"aid":"http://arxiv.org/abs/2504.02496v1","title":"Group-based Distinctive Image Captioning with Memory Difference Encoding\n  and Attention","summary":"Recent advances in image captioning have focused on enhancing accuracy by\nsubstantially increasing the dataset and model size. While conventional\ncaptioning models exhibit high performance on established metrics such as BLEU,\nCIDEr, and SPICE, the capability of captions to distinguish the target image\nfrom other similar images is under-explored. To generate distinctive captions,\na few pioneers employed contrastive learning or re-weighted the ground-truth\ncaptions. However, these approaches often overlook the relationships among\nobjects in a similar image group (e.g., items or properties within the same\nalbum or fine-grained events). In this paper, we introduce a novel approach to\nenhance the distinctiveness of image captions, namely Group-based Differential\nDistinctive Captioning Method, which visually compares each image with other\nimages in one similar group and highlights the uniqueness of each image. In\nparticular, we introduce a Group-based Differential Memory Attention (GDMA)\nmodule, designed to identify and emphasize object features in an image that are\nuniquely distinguishable within its image group, i.e., those exhibiting low\nsimilarity with objects in other images. This mechanism ensures that such\nunique object features are prioritized during caption generation for the image,\nthereby enhancing the distinctiveness of the resulting captions. To further\nrefine this process, we select distinctive words from the ground-truth captions\nto guide both the language decoder and the GDMA module. Additionally, we\npropose a new evaluation metric, the Distinctive Word Rate (DisWordRate), to\nquantitatively assess caption distinctiveness. Quantitative results indicate\nthat the proposed method significantly improves the distinctiveness of several\nbaseline models, and achieves state-of-the-art performance on distinctiveness\nwhile not excessively sacrificing accuracy...","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-03T11:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.02497v1","title":"An all-electrical scheme for valley polarization in graphene","summary":"We propose an all-electrical setup for achieving valley polarization in\ngraphene. The setup consists of a finite graphene sheet connected to normal\nmetal electrodes on both sides, with the junctions aligned along the zigzag\nedges while the armchair edges remain free. Each normal metal has two\nterminals, and when a bias is applied at one terminal while keeping the other\nthree grounded, valley polarization arises due to transverse momentum matching\nbetween graphene and the normal metal. The valley polarization is maximized\nwhen the Fermi wave vector of the normal metal is approximately half the\nseparation between the $K$ and $K'$ valleys in graphene. We analyze the\ndependence of conductance and valley polarization on system parameters such as\nthe width and length of the graphene sheet, as well as the chemical potentials\nof graphene and the normal metal. The conductance through graphene increases\nwith its width, while an increase in length initially reduces the conductance\nbefore leading to oscillatory behavior due to Fabry-P\\'erot interference. The\nvalley polarization efficiency decreases with increasing graphene length due to\ninter-valley mixing from back-and-forth reflections within the graphene region.\nFurthermore, we investigate the impact of disorder in graphene and find that\nwhile conductance near the Dirac point increases with disorder strength due to\nenhanced density of states, valley polarization efficiency decreases due to\nintervalley scattering. Our results provide insights into controlling valley\npolarization in graphene-based devices for valleytronic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-03T11:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.02520v1","title":"Beyond Traditional Coherence Time: An Electromagnetic Perspective for\n  Mobile Channels","summary":"Channel coherence time has been widely regarded as a critical parameter in\nthe design of mobile systems. However, a prominent challenge lies in\nintegrating electromagnetic (EM) polarization effects into the derivation of\nthe channel coherence time. In this paper, we develop a framework to analyze\nthe impact of polarization mismatch on the channel coherence time.\nSpecifically, we first establish an EM channel model to capture the essence of\nEM wave propagation. Based on this model, we then derive the EM temporal\ncorrelation function, incorporating the effects of polarization mismatch and\nbeam misalignment. Further, considering the random orientation of the mobile\nuser equipment (UE), we derive a closed-form solution for the EM coherence time\nin the turning scenario. When the trajectory degenerates into a straight line,\nwe also provide a closed-form lower bound on the EM coherence time. The\nsimulation results validate our theoretical analysis and reveal that neglecting\nthe EM polarization effects leads to overly optimistic estimates of the EM\ncoherence time.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-03T12:17:30Z"}
{"aid":"http://arxiv.org/abs/2504.02545v1","title":"MAD: Makeup All-in-One with Cross-Domain Diffusion Model","summary":"Existing makeup techniques often require designing multiple models to handle\ndifferent inputs and align features across domains for different makeup tasks,\ne.g., beauty filter, makeup transfer, and makeup removal, leading to increased\ncomplexity. Another limitation is the absence of text-guided makeup try-on,\nwhich is more user-friendly without needing reference images. In this study, we\nmake the first attempt to use a single model for various makeup tasks.\nSpecifically, we formulate different makeup tasks as cross-domain translations\nand leverage a cross-domain diffusion model to accomplish all tasks. Unlike\nexisting methods that rely on separate encoder-decoder configurations or\ncycle-based mechanisms, we propose using different domain embeddings to\nfacilitate domain control. This allows for seamless domain switching by merely\nchanging embeddings with a single model, thereby reducing the reliance on\nadditional modules for different tasks. Moreover, to support precise\ntext-to-makeup applications, we introduce the MT-Text dataset by extending the\nMT dataset with textual annotations, advancing the practicality of makeup\ntechnologies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:52:31Z"}
{"aid":"http://arxiv.org/abs/2504.02546v1","title":"GPG: A Simple and Strong Reinforcement Learning Baseline for Model\n  Reasoning","summary":"Reinforcement Learning (RL) can directly enhance the reasoning capabilities\nof large language models without extensive reliance on Supervised Fine-Tuning\n(SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism\nand propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike\nconventional methods, GPG directly optimize the original RL objective, thus\nobviating the need for surrogate loss functions. As illustrated in our paper,\nby eliminating both the critic and reference models, and avoiding KL divergence\nconstraints, our approach significantly simplifies the training process when\ncompared to Group Relative Policy Optimization (GRPO). Our approach achieves\nsuperior performance without relying on auxiliary techniques or adjustments.\nExtensive experiments demonstrate that our method not only reduces\ncomputational costs but also consistently outperforms GRPO across various\nunimodal and multimodal tasks. Our code is available at\nhttps://github.com/AMAP-ML/GPG.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T12:53:41Z"}
{"aid":"http://arxiv.org/abs/2504.02554v1","title":"Measure-independent description of wave-particle duality via coherence","summary":"Wave-particle duality as one of the expression of Bohr complementarity is a\nsignificant concept in the field of quantum mechanics. Quantitative analysis of\nwave-particle duality aims to establish a complementary relation between the\nparticle and wave properties. Beyond the conventional quantitative analysis\ndepending on special choice of quantum information measures, we are aimed to\nprovide a measure-independent complementary relation via coherence. By\nemploying maximally coherent states in the set of all states with fixed\ndiagonal elements, a measure-independent complementary relation is proposed.\nBased on this, we give a measure-independent description of\nwave-particle-mixedness triality in d-path interferometers. Our complementary\nrelations reveal the relationship between wave-particle duality and quantum\ncoherence, and also give a justification to coherence as it truly brings out\nthe wave nature of quantum systems at its heart.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T13:09:31Z"}
{"aid":"http://arxiv.org/abs/2504.02558v1","title":"Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results","summary":"Rip currents are the leading cause of fatal accidents and injuries on many\nbeaches worldwide, emphasizing the importance of automatically detecting these\nhazardous surface water currents. In this paper, we address a novel task: rip\ncurrent instance segmentation. We introduce a comprehensive dataset containing\n$2,466$ images with newly created polygonal annotations for instance\nsegmentation, used for training and validation. Additionally, we present a\nnovel dataset comprising $17$ drone videos (comprising about $24K$ frames)\ncaptured at $30 FPS$, annotated with both polygons for instance segmentation\nand bounding boxes for object detection, employed for testing purposes. We\ntrain various versions of YOLOv8 for instance segmentation on static images and\nassess their performance on the test dataset (videos). The best results were\nachieved by the YOLOv8-nano model (runnable on a portable device), with an\nmAP50 of $88.94%$ on the validation dataset and $81.21%$ macro average on the\ntest dataset. The results provide a baseline for future research in rip current\nsegmentation. Our work contributes to the existing literature by introducing a\ndetailed, annotated dataset, and training a deep learning model for instance\nsegmentation of rip currents. The code, training details and the annotated\ndataset are made publicly available at https://github.com/Irikos/rip_currents.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T13:14:16Z"}
{"aid":"http://arxiv.org/abs/2504.02560v1","title":"L-LBVC: Long-Term Motion Estimation and Prediction for Learned\n  Bi-Directional Video Compression","summary":"Recently, learned video compression (LVC) has shown superior performance\nunder low-delay configuration. However, the performance of learned\nbi-directional video compression (LBVC) still lags behind traditional\nbi-directional coding. The performance gap mainly arises from inaccurate\nlong-term motion estimation and prediction of distant frames, especially in\nlarge motion scenes. To solve these two critical problems, this paper proposes\na novel LBVC framework, namely L-LBVC. Firstly, we propose an adaptive motion\nestimation module that can handle both short-term and long-term motions.\nSpecifically, we directly estimate the optical flows for adjacent frames and\nnon-adjacent frames with small motions. For non-adjacent frames with large\nmotions, we recursively accumulate local flows between adjacent frames to\nestimate long-term flows. Secondly, we propose an adaptive motion prediction\nmodule that can largely reduce the bit cost for motion coding. To improve the\naccuracy of long-term motion prediction, we adaptively downsample reference\nframes during testing to match the motion ranges observed during training.\nExperiments show that our L-LBVC significantly outperforms previous\nstate-of-the-art LVC methods and even surpasses VVC (VTM) on some test datasets\nunder random access configuration.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-03T13:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.02565v1","title":"MAD: A Magnitude And Direction Policy Parametrization for Stability\n  Constrained Reinforcement Learning","summary":"We introduce magnitude and direction (MAD) policies, a policy\nparameterization for reinforcement learning (RL) that preserves Lp closed-loop\nstability for nonlinear dynamical systems. Although complete in their ability\nto describe all stabilizing controllers, methods based on nonlinear Youla and\nsystem-level synthesis are significantly affected by the difficulty of\nparameterizing Lp-stable operators. In contrast, MAD policies introduce\nexplicit feedback on state-dependent features - a key element behind the\nsuccess of RL pipelines - without compromising closed-loop stability. This is\nachieved by describing the magnitude of the control input with a\ndisturbance-feedback Lp-stable operator, while selecting its direction based on\nstate-dependent features through a universal function approximator. We further\ncharacterize the robust stability properties of MAD policies under model\nmismatch. Unlike existing disturbance-feedback policy parameterizations, MAD\npolicies introduce state-feedback components compatible with model-free RL\npipelines, ensuring closed-loop stability without requiring model information\nbeyond open-loop stability. Numerical experiments show that MAD policies\ntrained with deep deterministic policy gradient (DDPG) methods generalize to\nunseen scenarios, matching the performance of standard neural network policies\nwhile guaranteeing closed-loop stability by design.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-03T13:26:26Z"}
{"aid":"http://arxiv.org/abs/2504.02570v1","title":"Time resolution limits in silicon sensors from Landau fluctuations and\n  electronics noise","summary":"In this report, we derive analytical expressions for the time resolution\nlimits of standard silicon sensors, LGADs, and 3D trench sensors. We separately\nexamine the effects of Landau fluctuations and electronic noise. To analyze\nLandau fluctuations, we relate the time resolution of a single electron-hole\npair generated at a random position in the sensor to the time resolution\nassociated with the full ionization pattern produced by a charged particle. For\nelectronic noise, we explore optimal filtering techniques that minimize its\nimpact on time resolution, and evaluate how closely these can be approximated\nby practical filters. Finally, we demonstrate that the combined effect of\nLandau fluctuations and electronic noise cannot, in general, be simply\nexpressed as the quadratic sum of the individual contributions.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-04-03T13:36:06Z"}
{"aid":"http://arxiv.org/abs/2504.02577v1","title":"Reasoning Inconsistencies and How to Mitigate Them in Deep Learning","summary":"The recent advancements in Deep Learning models and techniques have led to\nsignificant strides in performance across diverse tasks and modalities.\nHowever, while the overall capabilities of models show promising growth, our\nunderstanding of their internal reasoning processes remains limited,\nparticularly concerning systematic inconsistencies or errors patterns of\nlogical or inferential flaws. These inconsistencies may manifest as\ncontradictory outputs, failure to generalize across similar tasks, or erroneous\nconclusions in specific contexts. Even detecting and measuring such reasoning\ndiscrepancies is challenging, as they may arise from opaque internal\nprocedures, biases and imbalances in training data, or the inherent complexity\nof the task. Without effective methods to detect, measure, and mitigate these\nerrors, there is a risk of deploying models that are biased, exploitable, or\nlogically unreliable. This thesis aims to address these issues by producing\nnovel methods for deep learning models that reason over knowledge graphs,\nnatural language, and images. The thesis contributes two techniques for\ndetecting and quantifying predictive inconsistencies originating from opaque\ninternal procedures in natural language and image processing models. To\nmitigate inconsistencies from biases in training data, this thesis presents a\ndata efficient sampling method to improve fairness and performance and a\nsynthetic dataset generation approach in low resource scenarios. Finally, the\nthesis offers two techniques to optimize the models for complex reasoning\ntasks. These methods enhance model performance while allowing for more faithful\nand interpretable exploration and exploitation during inference. Critically,\nthis thesis provides a comprehensive framework to improve the robustness,\nfairness, and interpretability of deep learning models across diverse tasks and\nmodalities.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG,cs.LO","published":"2025-04-03T13:40:55Z"}
{"aid":"http://arxiv.org/abs/2504.02578v1","title":"Helium escape signatures are generally strongest during younger ages but\n  this age dependence is lost in the diversity of observed exoplanets","summary":"Highly irradiated exoplanets undergo extreme hydrodynamic atmospheric escape,\ndue to their high level of received XUV flux. Over their lifetime, this escape\nvaries significantly, making evolution studies essential for interpreting the\ngrowing number of observations of escaping planetary atmospheres. In a previous\nwork, we modelled this evolving escape, alongside one of its observable\ntracers, the helium triplet transit signature at 1083nm. Using hydrodynamic and\nray-tracing models, we demonstrated that atmospheric escape and the\ncorresponding He 1083nm signature are stronger at younger ages, for a\n0.3$~M_\\text{J}$ gas-giant. Yet, the current literature includes several young\n(<1Gyr) planets with weak or non-detections in He 1083nm. To understand this\napparent discrepancy, we now perform detailed modelling for many of these\nsystems. The resulting He 1083nm predictions align relatively well with the\nobservations. From our two studies, we conclude that for any given planet,\nstronger atmospheric escape during younger ages produces deeper He 1083nm\nabsorption. However, for a population of exoplanets, the relation between\nyounger ages and stronger He absorptions is lost to the broad diversity of\ntheir various other system parameters. Accordingly, for the current sample of\nyoung, 1083nm-observed exoplanets, alternative trends take precedence. One such\ntrend is that planets with deeper geometrical transits exhibit more favourable\ndetections. Our modelling also agrees with the strong empirical trend in the\nliterature between $ EW \\cdot R_{*}^{2}$ and $F_{\\text{xuv}} \\cdot\nR_{\\text{pl}}^2 / \\Phi_{g}$. Additionally, we show that the coupling between\nthe lower and upper atmospheres is necessary for a robust prediction of the\n1083nm signature.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-03T13:41:16Z"}
{"aid":"http://arxiv.org/abs/2504.02579v1","title":"Bridging the Gap between Gaussian Diffusion Models and Universal\n  Quantization for Image Compression","summary":"Generative neural image compression supports data representation at extremely\nlow bitrate, synthesizing details at the client and consistently producing\nhighly realistic images. By leveraging the similarities between quantization\nerror and additive noise, diffusion-based generative image compression codecs\ncan be built using a latent diffusion model to \"denoise\" the artifacts\nintroduced by quantization. However, we identify three critical gaps in\nprevious approaches following this paradigm (namely, the noise level, noise\ntype, and discretization gaps) that result in the quantized data falling out of\nthe data distribution known by the diffusion model. In this work, we propose a\nnovel quantization-based forward diffusion process with theoretical foundations\nthat tackles all three aforementioned gaps. We achieve this through universal\nquantization with a carefully tailored quantization schedule and a diffusion\nmodel trained with uniform noise. Compared to previous work, our proposal\nproduces consistently realistic and detailed reconstructions, even at very low\nbitrates. In such a regime, we achieve the best rate-distortion-realism\nperformance, outperforming previous related works.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T13:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.02584v1","title":"Parabolic character sheaves and Hecke algebras","summary":"We show that certain Iwahori-Hecke algebras with unequal parameters can be\nrealized in the framework of parabolic character sheaves.","main_category":"math.RT","categories":"math.RT","published":"2025-04-03T13:49:50Z"}
{"aid":"http://arxiv.org/abs/2504.02586v1","title":"Deep learning for music generation. Four approaches and their\n  comparative evaluation","summary":"This paper introduces four different artificial intelligence algorithms for\nmusic generation and aims to compare these methods not only based on the\naesthetic quality of the generated music but also on their suitability for\nspecific applications. The first set of melodies is produced by a slightly\nmodified visual transformer neural network that is used as a language model.\nThe second set of melodies is generated by combining chat sonification with a\nclassic transformer neural network (the same method of music generation is\npresented in a previous research), the third set of melodies is generated by\ncombining the Schillinger rhythm theory together with a classic transformer\nneural network, and the fourth set of melodies is generated using GPT3\ntransformer provided by OpenAI. A comparative analysis is performed on the\nmelodies generated by these approaches and the results indicate that\nsignificant differences can be observed between them and regarding the\naesthetic value of them, GPT3 produced the most pleasing melodies, and the\nnewly introduced Schillinger method proved to generate better sounding music\nthan previous sonification methods.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-03T13:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.02595v1","title":"Native defects, hydrogen impurities, and metal dopants in CeO$_2$","summary":"Ceria (CeO$_2$) is a material of significant technological importance. A\ndetailed understanding of the material's defect physics and chemistry is key to\nunderstanding and optimizing its properties. Here, we report a hybrid\ndensity-functional study of native point defects, hydrogen impurities, and\nmetal dopants in CeO$_2$. We find that electron polarons ($\\eta_{\\rm Ce}^-$)\nand oxygen vacancies ($V_{\\rm O}^{2+}$) are the dominant native defects under\nconditions ranging from extreme oxidizing to highly reducing. Hydrogen is\nstable either in the hydroxyl (H$_i^+$) or hydride (H$_{\\rm O}^+$) structure\nbut the substitutional H$_{\\rm O}^+$ is energetically more favorable than\nH$_i^+$ only under highly reducing conditions. The interstitial H$_i^+$ is\nhighly mobile in the bulk. Yttrium (Y) is energetically most favorable at the\nsubstitutional Ce site. Copper (Cu) and nickel (Ni) can be incorporated at the\nsubstitutional site and/or an interstitial site, depending on actual conditions\nduring preparation, and the dopants can exist in different charge and spin\nstates. In light of the results, we discuss electronic and ionic conduction and\nthe effects of metal doping on the formation of electron polarons and oxygen\nvacancies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-03T13:57:18Z"}
{"aid":"http://arxiv.org/abs/2504.02609v1","title":"One-loop correction to primordial tensor modes during radiation era","summary":"The ability to infer properties of primordial inflation relies on the\nconservation of the superhorizon perturbations between their exit during\ninflation, and their re-entry during radiation era. Any considerable departure\nfrom this property would require reinterpreting the data. This is why it is\nimportant to understand how superhorizon perturbations interact with the\nthermal plasma driving the radiation dominated Universe. We model the plasma by\nfree photons in a thermal state and compute the one-loop correction to the\npower spectrum of primordial tensor perturbations. This correction grows in\ntime and is not suppressed by any small parameter. While one-loop result is not\nreliable because it invalidates perturbation theory, it signals potentially\ninteresting effects that should be investigated further.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-03T14:10:50Z"}
{"aid":"http://arxiv.org/abs/2504.02616v1","title":"Cosmological gas accretion of Milky Way-type galaxies and the build-up\n  of galactic discs","summary":"In this work, we present results on the assembly of stellar discs belonging\nto Milky Way-type galaxies in the Auriga simulated sample. We study the net\naccretion of gas onto the disc region as a function of time and radius to\nassess the feasibility of the so-called inside-out formation of galaxy discs.\nWe found that most of the galaxies in our sample exhibit an inside-out disc\ngrowth, with younger stellar populations preferentially formed in the outer\nregions as accreted material turns into starts. This produces stable discs as\nlong as late-time accretion is free from significant external perturbations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T14:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.02617v1","title":"PicoPose: Progressive Pixel-to-Pixel Correspondence Learning for Novel\n  Object Pose Estimation","summary":"Novel object pose estimation from RGB images presents a significant challenge\nfor zero-shot generalization, as it involves estimating the relative 6D\ntransformation between an RGB observation and a CAD model of an object that was\nnot seen during training. In this paper, we introduce PicoPose, a novel\nframework designed to tackle this task using a three-stage pixel-to-pixel\ncorrespondence learning process. Firstly, PicoPose matches features from the\nRGB observation with those from rendered object templates, identifying the\nbest-matched template and establishing coarse correspondences. Secondly,\nPicoPose smooths the correspondences by globally regressing a 2D affine\ntransformation, including in-plane rotation, scale, and 2D translation, from\nthe coarse correspondence map. Thirdly, PicoPose applies the affine\ntransformation to the feature map of the best-matched template and learns\ncorrespondence offsets within local regions to achieve fine-grained\ncorrespondences. By progressively refining the correspondences, PicoPose\nsignificantly improves the accuracy of object poses computed via PnP/RANSAC.\nPicoPose achieves state-of-the-art performance on the seven core datasets of\nthe BOP benchmark, demonstrating exceptional generalization to novel objects\nrepresented by CAD models or object reference images. Code and models are\navailable at https://github.com/foollh/PicoPose.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.02624v1","title":"EmbodiedSense: Understanding Embodied Activities with Earphones","summary":"In this paper, we propose EmbodiedSense, a sensing system based on commercial\nearphones, which enables fine-grained activity logs using existing sensors. The\nactivity logs record both user activities and the scenario in which the\nactivities took place, benefiting detailed behavior understanding. By\nunderstanding both the user and the environment, EmbodiedSense addresses three\nmain challenges: the limited recognition capability caused by\ninformation-hungry configurations (i.e., limited sensors available), the\nineffective fusion to extract ambient information such as contextual scenarios,\nand the interference from ambient noise. Specifically, EmbodiedSense consists\nof a context-aware scenario recognition module and spatial-aware activity\ndetection, which is further integrated with other attributes by expert\nknowledge. We implement our system on commercial earphones equipped with\nbinaural microphones and an Inertial Measurement Unit (IMU). By distinguishing\nusage scenarios and identifying the source of sounds, EmbodiedSense enables\nfine-grained activity logs in a zero-shot manner (evaluated with up to 41\ncategories) and outperforms strong baselines like ImageBind-LLM by 38%\nF1-score. Extensive evaluations demonstrate that EmbodiedSense is a promising\nsolution for long-term and short-term activity logs and provides significant\nbenefits in monitoring the wearer's daily life.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T14:21:35Z"}
{"aid":"http://arxiv.org/abs/2504.02631v1","title":"Feature splitting parallel algorithm for Dantzig selectors","summary":"The Dantzig selector is a widely used and effective method for variable\nselection in ultra-high-dimensional data. Feature splitting is an efficient\nprocessing technique that involves dividing these ultra-high-dimensional\nvariable datasets into manageable subsets that can be stored and processed more\neasily on a single machine. This paper proposes a variable splitting parallel\nalgorithm for solving both convex and nonconvex Dantzig selectors based on the\nproximal point algorithm. The primary advantage of our parallel algorithm,\ncompared to existing parallel approaches, is the significantly reduced number\nof iteration variables, which greatly enhances computational efficiency and\naccelerates the convergence speed of the algorithm. Furthermore, we show that\nour solution remains unchanged regardless of how the data is partitioned, a\nproperty referred to as partitioninsensitive. In theory, we use a concise proof\nframework to demonstrate that the algorithm exhibits linear convergence.\nNumerical experiments indicate that our algorithm performs competitively in\nboth parallel and nonparallel environments. The R package for implementing the\nproposed algorithm can be obtained at https://github.com/xfwu1016/PPADS.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-03T14:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.02638v1","title":"Characterization of nuclear breakup as a function of hard-scattering\n  kinematics using dijets measured by ATLAS in $p$+Pb collisions","summary":"This Letter analyzes the sensitivity of event geometry estimators to the\ninitial-state kinematics of hard scattering in proton-lead collisions. This\nanalysis uses dijets as a proxy for the parton-parton scattering configuration,\ncorrelating it with event geometry estimators, namely the energy deposited in\nthe Zero-Degree Calorimeter and the transverse energy recorded in the Forward\nCalorimeter in the Pb-going direction. The analysis uses data recorded by the\nATLAS detector at the Large Hadron Collider with a nucleon-nucleon\ncenter-of-mass energy of 8.16 TeV, corresponding to an integrated luminosity of\n56 nb$^{-1}$. The jets are measured within the pseudorapidity interval $-$2.8\n$<$ $\\eta$ $<$ 4.5, where positive $\\eta$ values correspond to the direction of\nthe proton beam. Results are presented as a function of the Bjorken-$x$ of the\nparton originating from the proton, $x_{p}$. Both event geometry estimators are\nfound to be dependent on $x_{p}$, with the energy deposited in the Zero-Degree\nCalorimeter about six times less sensitive to $x_{p}$ compared with the\ntransverse energy deposited in the Forward Calorimeter.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T14:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.02650v1","title":"Investigating Simple Drawings of $K_n$ using SAT","summary":"We present a SAT framework which allows to investigate properties of simple\ndrawings of the complete graph $K_n$ using the power of AI. In contrast to\nclassic imperative programming, where a program is operated step by step, our\nframework models mathematical questions as Boolean formulas which are then\nsolved using modern SAT solvers. Our framework for simple drawings is based on\na characterization via rotation systems and finite forbidden substructures. We\nshowcase its universality by addressing various open problems, reproving\nprevious computational results and deriving several new computational results.\nIn particular, we test and progress on several unavoidable configurations such\nas variants of Rafla's conjecture on plane Hamiltonian cycles, Harborth's\nconjecture on empty triangles, and crossing families for general simple\ndrawings as well as for various subclasses. Moreover, based our computational\nresults we propose some new challenging conjectures.","main_category":"cs.CG","categories":"cs.CG,cs.DM,math.CO","published":"2025-04-03T14:48:47Z"}
{"aid":"http://arxiv.org/abs/2504.02662v1","title":"Integrating Human Knowledge Through Action Masking in Reinforcement\n  Learning for Operations Research","summary":"Reinforcement learning (RL) provides a powerful method to address problems in\noperations research. However, its real-world application often fails due to a\nlack of user acceptance and trust. A possible remedy is to provide managers\nwith the possibility of altering the RL policy by incorporating human expert\nknowledge. In this study, we analyze the benefits and caveats of including\nhuman knowledge via action masking. While action masking has so far been used\nto exclude invalid actions, its ability to integrate human expertise remains\nunderexplored. Human knowledge is often encapsulated in heuristics, which\nsuggest reasonable, near-optimal actions in certain situations. Enforcing such\nactions should hence increase trust among the human workforce to rely on the\nmodel's decisions. Yet, a strict enforcement of heuristic actions may also\nrestrict the policy from exploring superior actions, thereby leading to overall\nlower performance. We analyze the effects of action masking based on three\nproblems with different characteristics, namely, paint shop scheduling, peak\nload management, and inventory management. Our findings demonstrate that\nincorporating human knowledge through action masking can achieve substantial\nimprovements over policies trained without action masking. In addition, we find\nthat action masking is crucial for learning effective policies in constrained\naction spaces, where certain actions can only be performed a limited number of\ntimes. Finally, we highlight the potential for suboptimal outcomes when action\nmasks are overly restrictive.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-04-03T15:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.02673v1","title":"QUITS: A modular Qldpc code circUIT Simulator","summary":"To achieve quantum fault tolerance with lower overhead, quantum low-density\nparity-check (QLDPC) codes have emerged as a promising alternative to\ntopological codes such as the surface code, offering higher code rates. To\nsupport their study, an end-to-end framework for simulating QLDPC codes at the\ncircuit level is needed. In this work, we present QUITS, a modular and flexible\ncircuit-level simulator for QLDPC codes. Its design allows users to freely\ncombine LDPC code constructions, syndrome extraction circuits, decoding\nalgorithms, and noise models, enabling comprehensive and customizable studies\nof the performance of QLDPC codes under circuit-level noise. QUITS supports\nseveral leading QLDPC families, including hypergraph product codes, lifted\nproduct codes, and balanced product codes. As part of the framework, we\nintroduce a syndrome extraction circuit improved from Tremblay, Delfosse, and\nBeverland [Phys. Rev. Lett. 129, 050504 (2022)] that applies to all three code\nfamilies. In particular, for a small hypergraph product code, our circuit\nachieves lower depth than the conventional method, resulting in improved\nlogical performance. Using \\QUITS, we evaluate the performance of\nstate-of-the-art QLDPC codes and decoders under various settings, revealing\ntrade-offs between the decoding runtime and the logical failure rate. The\nsource code of QUITS is available online.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T15:14:13Z"}
{"aid":"http://arxiv.org/abs/2504.02677v1","title":"Monte Carlo evaluations of gamma-ray and radio pulsar populations","summary":"Based on well-grounded Galactic neutron star populations formed from radio\npulsar population syntheses of canonical pulsars (CPs) and millisecond pulsars\n(MSPs), we use the latest Fermi-LAT catalog (4FGL-DR4) to investigate the\nimplications of proposed $\\gamma-$ray luminosity models. Using Monte Carlo\ntechniques, we calculate the number of CPs and MSPs that would comprise the\nsample of pulsar-like unidentified sources (PLUIDs) in 4FGL-DR4. While radio\nbeaming fractions were used to scale the sizes of the populations, when forming\nthe mock 4FGL-DR4 samples, we make the simplifying assumption that all\n$\\gamma-$ray pulsars are beaming towards the Earth. We then explore the\nobservable outcomes of seven different $\\gamma-$ray luminosity models. Four of\nthe models provide a good match to the observed number of PLUIDs, while three\nothers significantly over-predict the number of PLUIDs. For these latter\nmodels, either the average beaming fraction of $\\gamma-$ray pulsars is more\nlike 25--50\\%, or a revision in the luminosity scaling is required. Most of the\nradio detectable MSPs that our models predict as part of the PLUIDs within\n4FGL-DR4 are, unsurprisingly, fainter than the currently observed sample and at\nlarger dispersion measures. For CPs, in spite of an excellent match to the\nobserved radio population, none of the $\\gamma-$ray models we investigated\ncould replicate the observed sample of 150 $\\gamma-$ray CPs. Further work is\nrequired to understand this discrepancy. For both MSPs and CPs, we provide\nencouraging forecasts for targeted radio searches of PLUIDs from 4FGL-DR4 to\nelucidate the issues raised in this study.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-03T15:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.02678v1","title":"Valley and Spin Polarized States in Bernal Bilayer Graphene","summary":"We present the results for the evolution of the Fermi surfaces under\nvariation of number density and displacement field for spin and\nvalley-polarized states in Bernal bilayer graphene (BBG) using a realistic form\nof the electronic dispersion with trigonal warping terms. Earlier studies\nwithout trigonal warping have found discrete half-metal and quarter-metal\nstates with full spin and/or valley polarization and complete depletion of some\nof the Fermi surfaces. We show that when trigonal warping terms are included in\nthe dispersion, partially polarized states with large but non-complete\npolarization and with both majority and minority carriers present, emerge at\nsmall doping, as seen in the experimental data. We show the results when the\nintervalley and intravalley interactions are equal as well as when they are\nunequal.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-04-03T15:15:42Z"}
{"aid":"http://arxiv.org/abs/2504.02679v1","title":"A Set-Theoretic Robust Control Approach for Linear Quadratic Games with\n  Unknown Counterparts","summary":"Ensuring robust decision-making in multi-agent systems is challenging when\nagents have distinct, possibly conflicting objectives and lack full knowledge\nof each other s strategies. This is apparent in safety-critical applications\nsuch as human-robot interaction and assisted driving, where uncertainty arises\nnot only from unknown adversary strategies but also from external disturbances.\nTo address this, the paper proposes a robust adaptive control approach based on\nlinear quadratic differential games. Our method allows a controlled agent to\niteratively refine its belief about the adversary strategy and disturbances\nusing a set-membership approach, while simultaneously adapting its policy to\nguarantee robustness against the uncertain adversary policy and improve\nperformance over time. We formally derive theoretical guarantees on the\nrobustness of the proposed control scheme and its convergence to epsilon-Nash\nstrategies. The effectiveness of our approach is demonstrated in a numerical\nsimulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T15:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.02700v1","title":"Centroidal Voronoi Tessellations as Electrostatic Equilibria: A\n  Generalized Thomson Problem in Convex Domains","summary":"We present a variational framework in which Centroidal Voronoi Tessellations\n(CVTs) arise as local minimizers of a generalized electrostatic energy\nfunctional. By modeling interior point distributions in a convex domain as\nrepelling charges balanced against a continuous boundary charge, we show that\nthe resulting equilibrium configurations converge to CVT structures. We prove\nthis by showing that CVTs minimize both the classical centroidal energy and the\nelectrostatic potential, establishing a connection between geometric\nquantization and potential theory. Finally, we introduce a thermodynamic\nannealing scheme for global CVT optimization, rooted in Boltzmann statistics\nand random walk dynamics. By introducing a scheme for varying time steps\n(faster or slower cooling) we show that the set of minima of the centroid\nenergy functional (and therefore the electrostatic potential) can be recovered.\nBy recovering a set of generator locations corresponding to each minimum we can\ncreate a lattice continuation that allows for a customizable framework for\nindividual minimum seeking.","main_category":"math.NA","categories":"math.NA,cs.NA,math-ph,math.MG,math.MP,math.OC","published":"2025-04-03T15:36:15Z"}
{"aid":"http://arxiv.org/abs/2504.02714v1","title":"Impact of a Blockchain-based Universal Basic Income Pilot: The case of\n  Circles UBI currency","summary":"Circles UBI is a blockchain-based Community Currency System (CCS) that has\nbeen active in Berlin (Germany) since October 2021. The Circles Coop, which\nlaunched the project in 2021, was shut down in December 2023. In this paper, we\nshow the results of a survey carried out between October and November 2023. The\nrespondents were twenty-five individuals involved in various ways in the\nCircles' network. The main emerging narrative points out how their\nparticipation was deeply motivated by their identification with the values and\nideals of the Circles community. Among them, we selected five profiles that\nstood for their difference in type and degree of involvement. Finally, we\nreport some stories of economic linkages that suggest a positive externality in\nadopting a local community currency. To our knowledge, this is the first\nqualitative study of a universal basic income designed as a community currency\nand adopting blockchain technology. This pilot project was a remarkable\nexperiment for its adopted advanced technological and social innovations. In\nfact, as far as we know, the integration of basic income and local currency\nfeatures has been experimented with only in two other cases (Maric\\'a, Brazil\nand Barcelona, Spain) and none of them adopted a decentralized ledger system.\nIn this work, we try to outline strengths and weaknesses that emerged after\nabout two years of activity. For this reason, future researchers and activists\ninterested in this field will find valuable information.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-03T15:53:37Z"}
{"aid":"http://arxiv.org/abs/2504.02728v1","title":"On deformations of Azumaya algebras with quadratic pair","summary":"We construct a tangent-obstruction theory for Azumaya algebras equipped with\na quadratic pair. Under the assumption that either 2 is a global unit or the\nalgebra is of degree 2, we show how the deformation theory of these objects\nreduces to the deformation theory of the underlying Azumaya algebra. Namely, if\nthe underlying Azumaya algebra has unobstructed deformations then so does the\nquadratic pair.\n  On the other hand, in the purely characteristic 2 setting, we construct an\nAzumaya algebra with unobstructed deformations which can be equipped with a\nquadratic pair such that the associated triple has obstructed deformations. Our\nexample is a biquaternion Azumaya algebra on an Igusa surface.\n  Independently from the above results, we also introduce a new obstruction for\nquadratic pairs, existing only in characteristic 2, which is intermediate to\nboth the strong and weak obstructions that were recently introduced by Gille,\nNeher, and the second named author. This intermediate obstruction characterizes\nwhen a canonical extension of the Lie algebra sheaf of the automorphism group\nscheme of some quadratic triple is split.","main_category":"math.AG","categories":"math.AG,math.RA","published":"2025-04-03T16:11:25Z"}
{"aid":"http://arxiv.org/abs/2504.02734v1","title":"Monitored Fluctuating Hydrodynamics","summary":"We introduce a hydrodynamic framework for describing monitored classical\nstochastic processes. We study the conditional ensembles for these monitored\nprocesses -- i.e., we compute spacetime correlation functions conditioned on a\nfixed, typical measurement record. In the presence of global symmetries we show\nthat these conditional ensembles can undergo measurement-induced ``sharpening''\nphase transitions as a function of the monitoring rate; moreover, even weak\nmonitoring can give rise to novel critical phases, derived entirely from a\nclassical perspective. We give a simple hydrodynamic derivation of the known\ncharge-sharpening transition for diffusive many-body quantum systems. We show\nthat although the unmonitored symmetric and asymmetric exclusion processes are\nin different universality classes of transport, their conditional ensembles\nflow to the same fixed point with emergent relativistic invariance under\nmonitoring. On the other hand, weakly monitored systems with non-Abelian\nsymmetries enter a novel strongly coupled fixed point with non-trivial\ndynamical exponent, which we characterize. Our formalism naturally accounts for\nmonitoring general observables, such as currents or density gradients, and\nallows for a direct calculation of information-theoretic diagnostics of\nsharpening transitions, including the Shannon entropy of the measurement\nrecord.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,quant-ph","published":"2025-04-03T16:19:18Z"}
{"aid":"http://arxiv.org/abs/2504.02746v1","title":"Is the CMB revealing signs of pre-inflationary physics?","summary":"Given the latest observational constraints coming from the joint analyses of\nthe Atacama Cosmology Telescope, the Planck Satellite and other missions, we\npoint out the possibility of reconciling fundamental particle-physics models of\ninflation with data by considering non-Bunch-Davies initial conditions for\nprimordial density perturbations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-03T16:33:19Z"}
{"aid":"http://arxiv.org/abs/2504.02750v1","title":"Investigation of the influence of electrostatic excitation on\n  instabilities and electron transport in ExB plasma configurations","summary":"Partially magnetized plasmas in ExB configurations - where the electric and\nmagnetic fields are mutually perpendicular - exhibit a cross-field transport\nbehavior, which is widely believed to be dominantly governed by complex\ninstability-driven mechanisms. This phenomenon plays a crucial role in a\nvariety of plasma technologies, including Hall thrusters, where azimuthal\ninstabilities significantly influence electron confinement and, hence, device\nperformance. While the impact of prominent plasma instabilities, such as the\nelectron cyclotron drift instability (ECDI) and the modified two-stream\ninstability (MTSI) on cross-field transport of electron species is well\nrecognized and widely studied, strategies for actively manipulating these\ndynamics remain underexplored. In this study, we investigate the effect of\ntargeted wave excitation on instability evolution and electron transport using\none- and two-dimensional particle-in-cell simulations of representative plasma\ndischarge configurations. A time-varying electric field is applied axially to\nmodulate the spectral energy distribution of the instabilities across a range\nof forcing frequencies and amplitudes. Our results reveal that the so-called\n\"unsteady forcing\" can both suppress and amplify instability modes depending on\nexcitation parameters. In particular, across both 1D and 2D simulation\nconfigurations, forcing near 40 MHz effectively reduces ECDI amplitude and\ndecreases axial electron transport by about 30%, while high-frequency\nexcitation near the electron cyclotron frequency induces spectral broadening,\ninverse energy cascades, and enhanced transport. These findings point to the\nrole of nonlinear frequency locking and energy pathway disruption as mechanisms\nfor modifying instability-driven transport. Our results offer insights into\npotential pathways to enhance plasma confinement and control in next-generation\nExB devices.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T16:36:08Z"}
{"aid":"http://arxiv.org/abs/2504.02754v1","title":"Learning dynamics on the picosecond timescale in a superconducting\n  synapse structure","summary":"Conventional Artificial Intelligence (AI) systems are running into\nlimitations in terms of training time and energy. Following the principles of\nthe human brain, spiking neural networks trained with unsupervised learning\noffer a faster, more energy-efficient alternative. However, the dynamics of\nspiking, learning, and forgetting become more complicated in such schemes. Here\nwe study a superconducting electronics implementation of a learning synapse and\nexperimentally measure its spiking dynamics. By pulsing the system with a\nsuperconducting neuron, we show that a superconducting inductor can dynamically\nhold the synaptic weight with updates due to learning and forgetting. Learning\ncan be stopped by slowing down the arrival time of the post-synaptic pulse, in\naccordance with the Spike-Timing Dependent Plasticity paradigm. We find\nexcellent agreement with circuit simulations, and by fitting the turn-on of the\npulsing frequency, we confirm a learning time of 16.1 +/- 1 ps. The power\ndissipation in the learning part of the synapse is less than one attojoule per\nlearning event. This leads to the possibility of an extremely fast and\nenergy-efficient learning processor.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.dis-nn","published":"2025-04-03T16:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.02761v1","title":"A Geometric Framework for Stochastic Iterations","summary":"This paper concerns models and convergence principles for dealing with\nstochasticity in a wide range of algorithms arising in nonlinear analysis and\noptimization in Hilbert spaces. It proposes a flexible geometric framework\nwithin which existing solution methods can be recast and improved, and new ones\ncan be designed. Almost sure weak, strong, and linear convergence results are\nestablished in particular for fixed point and feasibility problems. In these\nareas, the proposed algorithms exceed the features of the state of the art in\nseveral respects. Numerical applications to signal and image recovery are\nprovided.","main_category":"math.OC","categories":"math.OC,math.PR","published":"2025-04-03T16:57:22Z"}
{"aid":"http://arxiv.org/abs/2504.02762v1","title":"MD-ProjTex: Texturing 3D Shapes with Multi-Diffusion Projection","summary":"We introduce MD-ProjTex, a method for fast and consistent text-guided texture\ngeneration for 3D shapes using pretrained text-to-image diffusion models. At\nthe core of our approach is a multi-view consistency mechanism in UV space,\nwhich ensures coherent textures across different viewpoints. Specifically,\nMD-ProjTex fuses noise predictions from multiple views at each diffusion step\nand jointly updates the per-view denoising directions to maintain 3D\nconsistency. In contrast to existing state-of-the-art methods that rely on\noptimization or sequential view synthesis, MD-ProjTex is computationally more\nefficient and achieves better quantitative and qualitative results.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T16:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.02781v1","title":"Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy\n  for Estimating Energy Consumption of Base Stations","summary":"Optimization of radio hardware and AI-based network management software yield\nsignificant energy savings in radio access networks. The execution of\nunderlying Machine Learning (ML) models, which enable energy savings through\nrecommended actions, may require additional compute and energy, highlighting\nthe opportunity to explore and adopt accurate and energy-efficient ML\ntechnologies. This work evaluates the novel use of sparsely structured Neural\nCircuit Policies (NCPs) in a use case to estimate the energy consumption of\nbase stations. Sparsity in ML models yields reduced memory, computation and\nenergy demand, hence facilitating a low-cost and scalable solution. We also\nevaluate the generalization capability of NCPs in comparison to traditional and\nwidely used ML models such as Long Short Term Memory (LSTM), via quantifying\ntheir sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a\nclear reduction in computational overhead and energy consumption. Moreover,\nresults indicated that the NCPs are robust to varying HPs such as number of\nepochs and neurons in each layer, making them a suitable option to ease model\nmanagement and to reduce energy consumption in Machine Learning Operations\n(MLOps) in telecommunications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE,eess.SP","published":"2025-04-03T17:22:39Z"}
{"aid":"http://arxiv.org/abs/2504.02783v1","title":"Non-linear elasticity effects and stratification in brushes of branched\n  polyelectrolytes","summary":"Brushes formed by arm-tethered starlike polyelectrolytes may exhibit internal\nsegregation into weakly and strongly extended populations (stratified two-layer\nstructure) when strong ionic intermolecular repulsions induce stretching of the\ntethers up to the limit of their extensibility. We propose an approximate\nPoisson-Boltzmann theory for analysis of the structure of the stratified brush\nand compare it with results of numerical self-consistent field modelling. Both\nanalytical and numerical models point to formation of a narrow cloud of\ncounterions (internal double electrical layer) localized inside stratified\nbrush at the boundary between the layers.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T17:25:10Z"}
{"aid":"http://arxiv.org/abs/2504.02784v1","title":"The level of distribution of the sum-of-digits function in arithmetic\n  progressions","summary":"For $q \\geq 2$, $n \\in \\mathbb{N}$, let $s_{q}(n)$ denote the sum of the\ndigits of $n$ written in base $q$. Spiegelhofer (2020) proved that the\nThue--Morse sequence has level of distribution $1$, improving on a former\nresult of Fouvry and Mauduit (1996). In this paper we generalize this result to\nsequences of type $\\left\\{\\exp\\left(2\\pi i\\ell s_q(n)/b\\right)\\right\\}_{n \\in\n\\mathbb{N}}$ and provide an explicit exponent in the upper bound.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.02828v1","title":"Concept Lancet: Image Editing with Compositional Representation\n  Transplant","summary":"Diffusion models are widely used for image editing tasks. Existing editing\nmethods often design a representation manipulation procedure by curating an\nedit direction in the text embedding or score space. However, such a procedure\nfaces a key challenge: overestimating the edit strength harms visual\nconsistency while underestimating it fails the editing task. Notably, each\nsource image may require a different editing strength, and it is costly to\nsearch for an appropriate strength via trial-and-error. To address this\nchallenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play\nframework for principled representation manipulation in diffusion-based image\nediting. At inference time, we decompose the source input in the latent (text\nembedding or diffusion score) space as a sparse linear combination of the\nrepresentations of the collected visual concepts. This allows us to accurately\nestimate the presence of concepts in each image, which informs the edit. Based\non the editing task (replace/add/remove), we perform a customized concept\ntransplant process to impose the corresponding editing direction. To\nsufficiently model the concept space, we curate a conceptual representation\ndataset, CoLan-150K, which contains diverse descriptions and scenarios of\nvisual terms and phrases for the latent dictionary. Experiments on multiple\ndiffusion-based image editing baselines show that methods equipped with CoLan\nachieve state-of-the-art performance in editing effectiveness and consistency\npreservation.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-03T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.04730v1","title":"Precision Thermo-Welding of Polymer Microspheres into Periodically\n  Organized, Hybrid, Mechanically Rollable Coupled-Resonator Optical Waveguides","summary":"Polymer microspherical resonators that trap light are crucial structures for\non-chip and on-board integration in nanophotonic applications. Using advanced\nmicromanipulation and thermo-welding methods, we successfully create welded\npolystyrene-based coupled-resonator optical waveguides (CROWs) with customized\nlengths, shapes, and optical characteristics. Through the thermal fusion of\nblue, green, and red fluorophore-doped polystyrene microspheres,\nmulti-fluorescent cohesive units are created from dimeric to henicosameric\nperiodic arrangements. Detailed micro-spectroscopy studies reveal CROWs'\ncapability to support optical whispering-gallery modes. The periodic\narrangements of different fluorophore-doped resonators within the CROW\nfacilitate efficient guided transmission of light via both active and passive\nmechanisms in opposite directions. The welded structures exhibit mechanically\ndriven rolling motion, confirming their integration as cohesive units. These\nfindings highlight the versatility and performance of thermo-welded polymer\nmicrosphere-based waveguides, paving the way for scalable, low-cost photonic\ndevices in sensing, modulation, and light guiding, emphasizing their role in\nfuture integrated photonics.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci","published":"2025-04-07T05:02:40Z"}
{"aid":"http://arxiv.org/abs/2504.04773v1","title":"Hyperspace convergences, bornologies and geometric set functionals","summary":"For a bornology $\\mathcal{S}$ of subsets of a metric space $(X,d)$, we\nconsider the following unified approaches of hyperspace convergence:\nconvergence induced through uniform convergence of distance functionals\n($\\tau_{\\mathcal{S},d}$-convergence); bornological convergence, and the weak\nconvergence induced by a family of gap and excess functionals. An interesting\nproblem regarding these convergences is to investigate when any two of them are\nequivalent. In this article, we investigate the relation of\n$\\tau_{\\mathcal{S},d}$-convergence with the other two convergences, which is\nnot completely transparent. As a main tool for our investigation, we use the\nidea of pointwise enlargement of a set by a positive Lipschitz function. As\napplications of our results, we provide new proofs of some known results about\nAttouch-Wets convergence.","main_category":"math.GN","categories":"math.GN,math.FA","published":"2025-04-07T07:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.04796v1","title":"Long-range transverse momentum correlations and radial flow in Pb$-$Pb\n  collisions at the LHC","summary":"This Letter presents measurements of long-range transverse-momentum\ncorrelations using a new observable, $v_{0}(p_\\mathrm{T})$, which serves as a\nprobe of radial flow and medium properties in heavy-ion collisions. Results are\nreported for inclusive charged particles, pions, kaons, and protons across\nvarious centrality intervals in Pb$-$Pb collisions at $\\sqrt{s_\\mathrm{NN}} =\n5.02$ TeV, recorded by the ALICE detector. A pseudorapidity-gap technique,\nsimilar to that used in anisotropic-flow studies, is employed to suppress\nshort-range correlations. At low $p_\\mathrm{T}$, a characteristic mass ordering\nconsistent with hydrodynamic collective flow is observed. At higher\n$p_\\mathrm{T}$ ($> 3$ GeV/$c$), protons exhibit larger $v_{0}(p_\\mathrm{T})$\nthan pions and kaons, in agreement with expectations from quark-recombination\nmodels. These results are sensitive to the bulk viscosity and the equation of\nstate of the QCD medium formed in heavy-ion collisions.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-07T07:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.04802v1","title":"Markov Gap and Bound Entanglement in Haar Random State","summary":"Bound entanglement refers to entangled states that cannot be distilled into\nmaximally entangled states, thus cannot be used directly in many protocols of\nquantum information processing. We identify a relationship between bound\nentanglement and Markov gap, which is introduced in holography from the\nentanglement wedge cross-section, and is related to the fidelity of Markov\nrecovery problem. We prove that the bound entanglement must have non-zero\nMarkov gap, and conversely, the state with weakly non-zero Markov gap almost\nsurely, with respect to Haar measure, has an entanglement undistillable, i.e.\nbound entangled or separable, marginal state for sufficiently large system.\nMoreover, we show that the bound entanglement and the threshold for\nseparability in Haar random state is originated from the state with weakly\nnon-zero Markov gap, which supports the non-perturbative effects from\nholographic perspective. Our results shed light on the investigation of Markov\ngap, and enhance the interdisciplinary application of quantum information.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T07:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.04806v1","title":"Interplay Between Structural Defects and Charge Transport Dynamics in MA\n  and FA Modified CsSnI3 Thin Film Semiconductors","summary":"Owing high conductivity in microcrystalline thin-films, CsSnI3 perovskite is\na promising semiconductor for thermoelectrics and optoelectronics. Rapid\noxidation of thin-film and intrinsic lattice strain hinders stabilization of\nthe device performance. Cation engineering of perovskite molecule was\nconsidered as an effective strategy to tailor the structural properties and\nsuppress the degradation processes. However, molecular engineering demands a\nthorough analysis of defect behavior, as it can influence ionic motion,\nrecombination dynamics, and capacitive effects. The effective implementation of\nCsSnI3 in energy conversion devices requires careful consideration of the\nspecific properties of thin films electrical conductivity, Seebeck coefficient,\npower factor, as well as electronic transients, and charge transport in the\ndevice structures. In this work, we performed a complex investigation for\nmodified CsSnI3 through cation substitution with methyl ammonium (MA) and\nformamidinium (FA). Our findings highlight a complex interplay between\nelectrical parameters of the bare thin films and stability of the devices\n(p-i-n diodes) after thermal stress. FA-CsSnI3 showed beneficial results for\nstabilization under elevated temperatures with improved non-ideality factor in\ndiode structures, enhanced shunt properties and reduced trapping. The\nphoto-induced voltage relaxation spectroscopy performed for MA-CsSnI3 showed\nrelevant traps concentration of 1016 cm-3 with activation energy of 0.52\neV(210K) likely attributed to Sn atom defect. The obtained results are deeply\nanalyzed and discussed.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-07T08:02:17Z"}
{"aid":"http://arxiv.org/abs/2504.04819v1","title":"Stability of spin dynamics in a driven non-Hermitian double well","summary":"We study the stability of spin dynamics for a spin-orbit (SO) coupled boson\nheld in a driven non-Hermitian double-well potential. It is surprising to find\nthat when the ratio of the Zeeman field strength to the driving frequency is\neven, the SO coupling strength can take any value, and suitable parameters can\nbe found to stabilize the quantum spin dynamics of the system. However, when\nthe ratio of the Zeeman field strength to the driving frequency is odd, the SO\ncoupling strength can only take integer or half-integer values for the spin\ndynamics of the system to possibly be stable.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-07T08:20:35Z"}
{"aid":"http://arxiv.org/abs/2504.04828v1","title":"Enumeration on polyominoes determined by Catalan words avoiding\n  $(\\geq,\\geq)$","summary":"A Catalan word of length $n$ that avoids the pattern $(\\geq, \\geq)$ is a\nsequence $w=w_1\\cdots w_n$ with $w_1=0$ and $0\\leq w_i\\leq w_{i-1}+1$ for all\n$i$, while ensuring that no subsequence satisfies $w_i \\geq w_{i+1}\\geq\nw_{i+2}$ for $i=2,\\ldots,n$. These words are enumerated by the $n$-th Motzkin\nnumber. From such a word, we associate a $n$-column Motzkin polyomino (called a\n$(\\geq,\\geq)$-polyomino), where the $i$-th column contains $w_i+1$\nbottom-aligned cells. In this paper, we derive generating functions for\n$(\\geq,\\geq)$-polyominoes based on their length, area, semiperimeter, last\nsymbol value, and number of interior points. We provide asymptotic analyses and\nclosed-form expressions for the total area, total semiperimeter, sum of the\nlast symbol values, and total number of interior points across all\n$(\\geq,\\geq)$-polyominoes of a given length. Finally, we express all these\nresults as linear combinations of trinomial coefficients.","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T08:36:14Z"}
{"aid":"http://arxiv.org/abs/2504.04829v1","title":"Attentional Graph Meta-Learning for Indoor Localization Using Extremely\n  Sparse Fingerprints","summary":"Fingerprint-based indoor localization is often labor-intensive due to the\nneed for dense grids and repeated measurements across time and space.\nMaintaining high localization accuracy with extremely sparse fingerprints\nremains a persistent challenge. Existing benchmark methods primarily rely on\nthe measured fingerprints, while neglecting valuable spatial and environmental\ncharacteristics. In this paper, we propose a systematic integration of an\nAttentional Graph Neural Network (AGNN) model, capable of learning spatial\nadjacency relationships and aggregating information from neighboring\nfingerprints, and a meta-learning framework that utilizes datasets with similar\nenvironmental characteristics to enhance model training. To minimize the labor\nrequired for fingerprint collection, we introduce two novel data augmentation\nstrategies: 1) unlabeled fingerprint augmentation using moving platforms, which\nenables the semi-supervised AGNN model to incorporate information from\nunlabeled fingerprints, and 2) synthetic labeled fingerprint augmentation\nthrough environmental digital twins, which enhances the meta-learning framework\nthrough a practical distribution alignment, which can minimize the feature\ndiscrepancy between synthetic and real-world fingerprints effectively. By\nintegrating these novel modules, we propose the Attentional Graph Meta-Learning\n(AGML) model. This novel model combines the strengths of the AGNN model and the\nmeta-learning framework to address the challenges posed by extremely sparse\nfingerprints. To validate our approach, we collected multiple datasets from\nboth consumer-grade WiFi devices and professional equipment across diverse\nenvironments. Extensive experiments conducted on both synthetic and real-world\ndatasets demonstrate that the AGML model-based localization method consistently\noutperforms all baseline methods using sparse fingerprints across all evaluated\nmetrics.","main_category":"cs.LG","categories":"cs.LG,eess.SP,stat.ML","published":"2025-04-07T08:37:18Z"}
{"aid":"http://arxiv.org/abs/2504.04843v1","title":"Data Augmentation as Free Lunch: Exploring the Test-Time Augmentation\n  for Sequential Recommendation","summary":"Data augmentation has become a promising method of mitigating data sparsity\nin sequential recommendation. Existing methods generate new yet effective data\nduring model training to improve performance. However, deploying them requires\nretraining, architecture modification, or introducing additional learnable\nparameters. The above steps are time-consuming and costly for well-trained\nmodels, especially when the model scale becomes large. In this work, we explore\nthe test-time augmentation (TTA) for sequential recommendation, which augments\nthe inputs during the model inference and then aggregates the model's\npredictions for augmented data to improve final accuracy. It avoids significant\ntime and cost overhead from loss calculation and backward propagation. We first\nexperimentally disclose the potential of existing augmentation operators for\nTTA and find that the Mask and Substitute consistently achieve better\nperformance. Further analysis reveals that these two operators are effective\nbecause they retain the original sequential pattern while adding appropriate\nperturbations. Meanwhile, we argue that these two operators still face\ntime-consuming item selection or interference information from mask tokens.\nBased on the analysis and limitations, we present TNoise and TMask. The former\ninjects uniform noise into the original representation, avoiding the\ncomputational overhead of item selection. The latter blocks mask token from\nparticipating in model calculations or directly removes interactions that\nshould have been replaced with mask tokens. Comprehensive experiments\ndemonstrate the effectiveness, efficiency, and generalizability of our method.\nWe provide an anonymous implementation at https://github.com/KingGugu/TTA4SR.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T08:56:16Z"}
{"aid":"http://arxiv.org/abs/2504.04846v1","title":"Iterated and Generalized Iterated Integrals","summary":"For a differential field $F$ having an algebraically closed field of\nconstants, we analyze the structure of Picard-Vessiot extensions of $F$ whose\ndifferential Galois groups are unipotent algebraic groups and apply these\nresults to study stability problems in integration in finite terms and the\ninverse problem in differential Galois theory for unipotent algebraic groups.","main_category":"math.AC","categories":"math.AC","published":"2025-04-07T08:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.04849v1","title":"Discovering dynamical laws for speech gestures","summary":"A fundamental challenge in the cognitive sciences is discovering the dynamics\nthat govern behaviour. Take the example of spoken language, which is\ncharacterised by a highly variable and complex set of physical movements that\nmap onto the small set of cognitive units that comprise language. What are the\nfundamental dynamical principles behind the movements that structure speech\nproduction? In this study, we discover models in the form of symbolic equations\nthat govern articulatory gestures during speech. A sparse symbolic regression\nalgorithm is used to discover models from kinematic data on the tongue and\nlips. We explore these candidate models using analytical techniques and\nnumerical simulations, and find that a second-order linear model achieves high\nlevels of accuracy, but a nonlinear force is required to properly model\narticulatory dynamics in approximately one third of cases. This supports the\nproposal that an autonomous, nonlinear, second-order differential equation is a\nviable dynamical law for articulatory gestures in speech. We conclude by\nidentifying future opportunities and obstacles in data-driven model discovery\nand outline prospects for discovering the dynamical principles that govern\nlanguage, brain and behaviour.","main_category":"cs.CL","categories":"cs.CL,nlin.AO","published":"2025-04-07T09:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.04858v1","title":"Don't Lag, RAG: Training-Free Adversarial Detection Using RAG","summary":"Adversarial patch attacks pose a major threat to vision systems by embedding\nlocalized perturbations that mislead deep models. Traditional defense methods\noften require retraining or fine-tuning, making them impractical for real-world\ndeployment. We propose a training-free Visual Retrieval-Augmented Generation\n(VRAG) framework that integrates Vision-Language Models (VLMs) for adversarial\npatch detection. By retrieving visually similar patches and images that\nresemble stored attacks in a continuously expanding database, VRAG performs\ngenerative reasoning to identify diverse attack types, all without additional\ntraining or fine-tuning. We extensively evaluate open-source large-scale VLMs,\nincluding Qwen-VL-Plus, Qwen2.5-VL-72B, and UI-TARS-72B-DPO, alongside\nGemini-2.0, a closed-source model. Notably, the open-source UI-TARS-72B-DPO\nmodel achieves up to 95 percent classification accuracy, setting a new\nstate-of-the-art for open-source adversarial patch detection. Gemini-2.0\nattains the highest overall accuracy, 98 percent, but remains closed-source.\nExperimental results demonstrate VRAG's effectiveness in identifying a variety\nof adversarial patches with minimal human annotation, paving the way for\nrobust, practical defenses against evolving adversarial patch attacks.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-07T09:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.04881v1","title":"Critical Behaviour in the Single Flavor Thirring Model in 2+1$d$ with\n  Wilson Kernel Domain Wall Fermions","summary":"We present results of a lattice field theory simulation of the 2+1$d$\nThirring model with $N=1$ fermion flavors, using domain wall fermions. The\nmodel exhibits a U(2) symmetry-breaking phase transition with the potential to\ndefine a UV-stable renormalisation group fixed point. The novelty is the\nreplacement of the Shamir kernel used in all previous work with the Wilson\nkernel, improving the action particularly with respect to the $L_s\\to\\infty$\nlimit needed to recover U(2), now under much better control. Auxiliary field\nensembles generated on $16^3\\times24$ with varying self-interaction strength\n$g^2$ and bare mass $m$ are used to measure the bilinear condensate order\nparameter $\\langle\\bar\\psi i\\gamma_3\\psi\\rangle$ with domain wall separations\nas large as $L_s=120$. The resulting $L_s\\to\\infty$ extrapolation is used to\nfit an empirical equation of state modelling spontaneous symmetry breaking as\n$m\\to0$. The fit is remarkably stable and compelling, with the fitted critical\nexponents $\\beta_m\\simeq2.4$, $\\delta\\simeq1.3$ differing markedly from\nprevious estimates. The associated susceptibility exhibits a mass hierarchy in\nline with physical expectations, again unlike previous estimates.\nSchwinger-Dyson equation (SDE) solutions of the Thirring model exploiting a\nhidden local symmetry in the action are reviewed, and analytic predictions\npresented for the exponents. In contrast to all previous lattice studies, the\nuniversal characteristics of the critical point revealed qualitatively resemble\nthe SDE predictions.","main_category":"hep-lat","categories":"hep-lat,hep-th","published":"2025-04-07T09:42:48Z"}
{"aid":"http://arxiv.org/abs/2504.04882v1","title":"Observation of non-Hermitian bulk-boundary correspondence in non-chiral\n  non-unitary quantum dynamics of single photons","summary":"The breakdown of conventional bulk-boundary correspondence, a cornerstone of\ntopological physics, is one of counter-intuitive phenomena in non-Hermitian\nsystems, that is deeply rooted in symmetry. In particular, preserved chiral\nsymmetry is one of the key ingredients, which plays a pivotal role in\ndetermining non-Hermitian topology. Nevertheless, chiral symmetry breaking in\nnon-Hermitian systems disrupts topological protection, modifies topological\ninvariants, and substantially reshapes spectral and edge-state behavior. The\ncorresponding fundamentally important bulk-boundary correspondence thus needs\nto be drastically reconstructed. However, it has so far eluded experimental\nefforts. Here, we theoretically predict and experimentally demonstrate the\nbulk-boundary correspondence of a one-dimensional (1D) non-Hermitian system\nwith chiral symmetry breaking in discrete-time non-chiral non-unitary quantum\nwalks of single photons. Through constructing a domain-wall configuration, we\nexperimentally observe the photon localization at the interface of domain-wall\nstructure, clearly indicating the presence of the topological edge mode. The\nappearance of that matches excellently with the prediction of our introduced\nnon-chiral non-Bloch topological invariants pair. Our work thus unequivocally\nbuilds the non-Hermitian bulk-boundary correspondence as a general principle\nfor studying topological physics in non-Hermitian systems with chiral symmetry\nbreaking.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.quant-gas,physics.optics,quant-ph","published":"2025-04-07T09:43:43Z"}
{"aid":"http://arxiv.org/abs/2504.04884v1","title":"Parallelization is All System Identification Needs: End-to-end Vibration\n  Diagnostics on a multi-core RISC-V edge device","summary":"The early detection of structural malfunctions requires the installation of\nreal-time monitoring systems ensuring continuous access to the damage-sensitive\ninformation; nevertheless, it can generate bottlenecks in terms of bandwidth\nand storage. Deploying data reduction techniques at the edge is recognized as a\nproficient solution to reduce the system's network traffic. However, the most\neffective solutions currently employed for the purpose are based on memory and\npower-hungry algorithms, making their embedding on resource-constrained devices\nvery challenging; this is the case of vibration data reduction based on System\nIdentification models. This paper presents PARSY-VDD, a fully optimized\nPArallel end-to-end software framework based on SYstem identification for\nVibration-based Damage Detection, as a suitable solution to perform damage\ndetection at the edge in a time and energy-efficient manner, avoiding streaming\nraw data to the cloud. We evaluate the damage detection capabilities of\nPARSY-VDD with two benchmarks: a bridge and a wind turbine blade, showcasing\nthe robustness of the end-to-end approach. Then, we deploy PARSY-VDD on both\ncommercial single-core and a specific multi-core edge device. We introduce an\narchitecture-agnostic algorithmic optimization for SysId, improving the\nexecution by 90x and reducing the consumption by 85x compared with the\nstate-of-the-art SysId implementation on GAP9. Results show that by utilizing\nthe unique parallel computing capabilities of GAP9, the execution time is\n751{\\mu}s with the high-performance multi-core solution operating at 370MHz and\n0.8V, while the energy consumption is 37{\\mu}J with the low-power solution\noperating at 240MHz and 0.65V. Compared with other single-core implementations\nbased on STM32 microcontrollers, the GAP9 high-performance configuration is 76x\nfaster, while the low-power configuration is 360x more energy efficient.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T09:51:02Z"}
{"aid":"http://arxiv.org/abs/2504.04885v1","title":"Renormalisation in the flow approach for singular SPDEs","summary":"In this work, we study the renormalisation of singular SPDEs in the flow\napproach recently developed by Duch using a bottom-up setting. We introduce a\ngeneral ansatz based on decorated trees for the solution of the flow equation.\nThe ansatz is renormalised in a recursive way, in the sense of the trees, via\nlocal extractions introduced for regularity structures. We derive the\nrenormalised equation from this ansatz and show that the renormalisation scheme\nis identical to that appearing in the context of regularity structures, thus\nmatching the BPHZ renormalisation.","main_category":"math.PR","categories":"math.PR,math-ph,math.AP,math.MP,math.RA","published":"2025-04-07T09:52:25Z"}
{"aid":"http://arxiv.org/abs/2504.04888v1","title":"A note on delay-inverse systems, I","summary":"A generalization of an inverse system in a category was recently introduced,\nas well as that of the corresponding pro-category These so called the\ndelay-inverse systems and delay-pro-category could potentially yield a new\ntheory of (delay-) inverse systems as well as a kind of coarser abstract shape\ntheory. However, we have proven that, whenever an indexing set has cardinality\n$\\aleph_{n}, n\\in\\mathbb{N}_{0}$, the potential new theory reduces, in its\nessence (the classification and invariants), to the ordinary one.","main_category":"math.CT","categories":"math.CT,math.GN","published":"2025-04-07T09:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.04900v1","title":"Controlled bit-flip of period-doubling and discrete time crystalline\n  states in open systems","summary":"In this work, we explore the robustness of a bit-flip operation against\nthermal and quantum noise for bits represented by the symmetry-broken pairs of\nthe period-doubled (PD) states in a classical parametric oscillator and\ndiscrete time crystal (DTC) states in a fully-connected open spin-cavity\nsystem, respectively. The bit-flip operation corresponds to switching between\nthe two PD and DTC states induced by a defect in a periodic drive, introduced\nin a controlled manner by linearly ramping the phase of the modulation of the\ndrive. In the absence of stochastic noise, strong dissipation results in a more\nrobust bit-flip operation in which slight changes to the defect parameters do\nnot significantly lower the success rate of bit-flips. The operation remains\nrobust even in the presence of stochastic noise when the defect duration is\nsufficiently large. The fluctuations also enhance the success rate of the\nbit-flip below the critical defect duration needed to induce a switch. By\nconsidering parameter regimes in which the DTC states in the spin-cavity system\ndo not directly map to the PD states, we reveal that this robustness is due to\nthe system being quenched by the defect towards a new phase that has enough\nexcitation to suppress the effects of the stochastic noise. This allows for\nprecise control of the bit-flip operations by tuning into the preferred\nintermediate state that the system will enter during a bit-flip operation. We\ndemonstrate this in a modified protocol based on precise quenches of the\ndriving frequency.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,nlin.PS","published":"2025-04-07T10:19:55Z"}
{"aid":"http://arxiv.org/abs/2504.04903v1","title":"Lumina-OmniLV: A Unified Multimodal Framework for General Low-Level\n  Vision","summary":"We present Lunima-OmniLV (abbreviated as OmniLV), a universal multimodal\nmulti-task framework for low-level vision that addresses over 100 sub-tasks\nacross four major categories: image restoration, image enhancement,\nweak-semantic dense prediction, and stylization. OmniLV leverages both textual\nand visual prompts to offer flexible and user-friendly interactions. Built on\nDiffusion Transformer (DiT)-based generative priors, our framework supports\narbitrary resolutions -- achieving optimal performance at 1K resolution --\nwhile preserving fine-grained details and high fidelity. Through extensive\nexperiments, we demonstrate that separately encoding text and visual\ninstructions, combined with co-training using shallow feature control, is\nessential to mitigate task ambiguity and enhance multi-task generalization. Our\nfindings also reveal that integrating high-level generative tasks into\nlow-level vision models can compromise detail-sensitive restoration. These\ninsights pave the way for more robust and generalizable low-level vision\nsystems.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T10:22:00Z"}
{"aid":"http://arxiv.org/abs/2504.04907v1","title":"Video-Bench: Human-Aligned Video Generation Benchmark","summary":"Video generation assessment is essential for ensuring that generative models\nproduce visually realistic, high-quality videos while aligning with human\nexpectations. Current video generation benchmarks fall into two main\ncategories: traditional benchmarks, which use metrics and embeddings to\nevaluate generated video quality across multiple dimensions but often lack\nalignment with human judgments; and large language model (LLM)-based\nbenchmarks, though capable of human-like reasoning, are constrained by a\nlimited understanding of video quality metrics and cross-modal consistency. To\naddress these challenges and establish a benchmark that better aligns with\nhuman preferences, this paper introduces Video-Bench, a comprehensive benchmark\nfeaturing a rich prompt suite and extensive evaluation dimensions. This\nbenchmark represents the first attempt to systematically leverage MLLMs across\nall dimensions relevant to video generation assessment in generative models. By\nincorporating few-shot scoring and chain-of-query techniques, Video-Bench\nprovides a structured, scalable approach to generated video evaluation.\nExperiments on advanced models including Sora demonstrate that Video-Bench\nachieves superior alignment with human preferences across all dimensions.\nMoreover, in instances where our framework's assessments diverge from human\nevaluations, it consistently offers more objective and accurate insights,\nsuggesting an even greater potential advantage over traditional human judgment.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T10:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.04913v1","title":"The GRINTA hard X-ray mission: an Explorer of the Transient Sky","summary":"The era of time domain multi-messenger (MM) astrophysics requires sensitive,\nlarge field-of-view (FoV) observatories that are able to quickly react in order\nto respond to alerts from gravitational wave (GW) triggers, neutrino\ndetections, and transient sources from all parts of the electromagnetic (EM)\nspectrum. This is particularly true at hard X-rays and soft gamma-rays where\nthe EM counterparts to GW triggers, gamma-ray bursts (GRBs), emit most of their\nflux. While the present decade has a number of instruments capable of\naccomplishing this task, there are no missions planned for the 2030's when\nimproved MM facilities will detect many more events. It is in this context that\nwe present the GRINTA mission concept. GRINTA has a large area, large FoV\ndetector to search for short, impulsive events in the 20 keV - 10 MeV energy\nrange and a coded mask telescope for localizing and performing follow-up\nobservations of sources from 5-200 keV. While GRINTA's main scientific goal is\nstudying MM events, the instruments will observe numerous other sources to\nexplore the sky at hard X-rays/soft gamma-rays.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.IM","published":"2025-04-07T10:47:36Z"}
{"aid":"http://arxiv.org/abs/2504.04932v1","title":"Weighted Approximate Quantum Natural Gradient for Variational Quantum\n  Eigensolver","summary":"Variational quantum eigensolver (VQE) is one of the most prominent algorithms\nusing near-term quantum devices, designed to find the ground state of a\nHamiltonian. In VQE, a classical optimizer iteratively updates the parameters\nin the quantum circuit. Among various optimization methods, quantum natural\ngradient descent (QNG) stands out as a promising optimization approach for VQE.\nHowever, standard QNG only leverages the quantum Fisher information of the\nentire system and treats each subsystem equally in the optimization process,\nwithout accounting for the different weights and contributions of each\nsubsystem corresponding to each observable. To address this limitation, we\npropose a Weighted Approximate Quantum Natural Gradient (WA-QNG) method\ntailored for $k$-local Hamiltonians. In this paper, we theoretically analyze\nthe potential advantages of WA-QNG compared to QNG from three distinct\nperspectives and reveal its connection with the Gauss-Newton method. We also\nshow it outperforms standard quantum natural gradient descent in the numerical\nexperiments for seeking the ground state of the Hamiltonian.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T11:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.04934v1","title":"Boosting Relational Deep Learning with Pretrained Tabular Models","summary":"Relational databases, organized into tables connected by primary-foreign key\nrelationships, are a common format for organizing data. Making predictions on\nrelational data often involves transforming them into a flat tabular format\nthrough table joins and feature engineering, which serve as input to tabular\nmethods. However, designing features that fully capture complex relational\npatterns remains challenging. Graph Neural Networks (GNNs) offer a compelling\nalternative by inherently modeling these relationships, but their time overhead\nduring inference limits their applicability for real-time scenarios. In this\nwork, we aim to bridge this gap by leveraging existing feature engineering\nefforts to enhance the efficiency of GNNs in relational databases.\nSpecifically, we use GNNs to capture complex relationships within relational\ndatabases, patterns that are difficult to featurize, while employing engineered\nfeatures to encode temporal information, thereby avoiding the need to retain\nthe entire historical graph and enabling the use of smaller, more efficient\ngraphs. Our \\textsc{LightRDL} approach not only improves efficiency, but also\noutperforms existing models. Experimental results on the RelBench benchmark\ndemonstrate that our framework achieves up to $33\\%$ performance improvement\nand a $526\\times$ inference speedup compared to GNNs, making it highly suitable\nfor real-time inference.","main_category":"cs.DB","categories":"cs.DB,cs.AI,cs.LG","published":"2025-04-07T11:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.04965v1","title":"Climate adaptation of millet and sorghum varieties in North-Eastern\n  Senegal: cross-referencing rainfall, thermal and phenological parameters","summary":"Millet (Pennisetum glaucum) and sorghum (Sorghum bicolor) are the main\nrainfed cereals grown in North-Eastern Senegal. However, faced with constraints\nsuch as falling rainfall, rising temperatures and frequent dry spells, their\nproduction is tending to decline. This article examines the climatic\nconstraints and other shocks suffered by rainfed millet varieties Souna__3,\nICTP 8203, GB 8735, Gawane and Chakti, as well as those as sorghum CE__180-33,\nPayenne and Golob{\\'e}, which are the main varieties released and currently\ngrown in north-eastern Senegal. Based on data collected in Podor, Matam and\nLingu{\\`e}re, the article analyses the adaptation of different millet and\nsorghum varieties to climatic condition and their evolution over time The\nresults show a rainfall deficit since the early 1970s, combined by greater\nthermal constraints. Analysis of the differences between cumulative rainfall\nand maximum evapotranspiration for varieties at different growth stages reveals\nconstant water deficits for Souna__3 millet and CE 180-33 sorghum. In contrast,\nChakti millet shows positive water balances in over 80% of years in the east\nand west of the study area, and in 47% of cases in the north. Only Chakti and\nICTP 8203 are adapted to the climatic conditions of the eastern and western\nzones, with a probability of suitability of over 80% for the periods 1931-1969\nand 1999-2020. However, none of the varieties is adapted to the climatic\nconditions in the north. In addition to these climatic constraints, the\ninterviewed farmers attribute the decline in agricultural production to\nlivestock straying, attacks by bird pests and parasitic infestations.\nexacerbate agricultural losses. It is therefore essential to develop\ncomplementary strategies including wider dissemination of varieties better\nadapted to current climatic conditions, such as Chakti and ICTP 8203, and the\nstrengthening of crop protection systems, notably through biological control\nand integrated pest management.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-07T11:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.04967v1","title":"Using AI to Help in the Semantic Lexical Database to Evaluate Ideas","summary":"Inside a challenge of ideas there are several phases in a Creative Support\nSystem (CSS), they are problem analysis, ideation, evaluation, and\nimplementation. Our problem: we need a full semantic lexical database SLD in an\noral (voice) and writing way to help stakeholders to create ideas, these ideas\ncontain nouns, verbs, adverbs, adjectives in the English, Spanish, and French\nlanguages. We utilize a Cloud Service Provider to use a service of Artificial\nIntelligence (AI), also we prepare nouns, verbs, adjectives and adverbs files\nin order to create the service text to voice and create our SLD with voice.\nThis paper presents, first, an introduction about some contests that use a\nsemantic lexical database in different languages; second, a SLD management\napproach using analysis of texts; third, a management application approach to\ncomplete all the new elements; fourth, the results of the management\napplication approach, finally the conclusions and future work.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-07T11:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.04970v1","title":"A High-Force Gripper with Embedded Multimodal Sensing for Powerful and\n  Perception Driven Grasping","summary":"Modern humanoid robots have shown their promising potential for executing\nvarious tasks involving the grasping and manipulation of objects using their\nend-effectors. Nevertheless, in the most of the cases, the grasping and\nmanipulation actions involve low to moderate payload and interaction forces.\nThis is due to limitations often presented by the end-effectors, which can not\nmatch their arm-reachable payload, and hence limit the payload that can be\ngrasped and manipulated. In addition, grippers usually do not embed adequate\nperception in their hardware, and grasping actions are mainly driven by\nperception sensors installed in the rest of the robot body, frequently affected\nby occlusions due to the arm motions during the execution of the grasping and\nmanipulation tasks. To address the above, we developed a modular high grasping\nforce gripper equipped with embedded multi-modal perception functionalities.\nThe proposed gripper can generate a grasping force of 110 N in a compact\nimplementation. The high grasping force capability is combined with embedded\nmulti-modal sensing, which includes an eye-in-hand camera, a Time-of-Flight\n(ToF) distance sensor, an Inertial Measurement Unit (IMU) and an\nomnidirectional microphone, permitting the implementation of perception-driven\ngrasping functionalities.\n  We extensively evaluated the grasping force capacity of the gripper by\nintroducing novel payload evaluation metrics that are a function of the robot\narm's dynamic motion and gripper thermal states. We also evaluated the embedded\nmulti-modal sensing by performing perception-guided enhanced grasping\noperations.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-07T11:57:08Z"}
{"aid":"http://arxiv.org/abs/2504.04974v1","title":"Towards Visual Text Grounding of Multimodal Large Language Model","summary":"Despite the existing evolution of Multimodal Large Language Models (MLLMs), a\nnon-neglectable limitation remains in their struggle with visual text\ngrounding, especially in text-rich images of documents. Document images, such\nas scanned forms and infographics, highlight critical challenges due to their\ncomplex layouts and textual content. However, current benchmarks do not fully\naddress these challenges, as they mostly focus on visual grounding on natural\nimages, rather than text-rich document images. Thus, to bridge this gap, we\nintroduce TRIG, a novel task with a newly designed instruction dataset for\nbenchmarking and improving the Text-Rich Image Grounding capabilities of MLLMs\nin document question-answering. Specifically, we propose an OCR-LLM-human\ninteraction pipeline to create 800 manually annotated question-answer pairs as\na benchmark and a large-scale training set of 90$ synthetic data based on four\ndiverse datasets. A comprehensive evaluation of various MLLMs on our proposed\nbenchmark exposes substantial limitations in their grounding capability on\ntext-rich images. In addition, we propose two simple and effective TRIG methods\nbased on general instruction tuning and plug-and-play efficient embedding,\nrespectively. By finetuning MLLMs on our synthetic dataset, they promisingly\nimprove spatial reasoning and grounding capabilities.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-04-07T12:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.04992v1","title":"Error bound for the asymptotic expansion of the Hartman-Watson integral","summary":"This note gives a bound on the error of the leading term of the $t\\to 0$\nasymptotic expansion of the Hartman-Watson distribution $\\theta(r,t)$ in the\nregime $rt=\\rho$ constant. The leading order term has the form\n$\\theta(\\rho/t,t)=\\frac{1}{2\\pi t}e^{-\\frac{1}{t} (F(\\rho)-\\pi^2/2)} G(\\rho) (1\n+ \\vartheta(t,\\rho))$, where the error term is bounded uniformly over $\\rho$ as\n$|\\vartheta(t,\\rho)|\\leq \\frac{1}{70}t$.","main_category":"math.CA","categories":"math.CA,q-fin.CP","published":"2025-04-07T12:18:19Z"}
{"aid":"http://arxiv.org/abs/2504.05002v1","title":"SmartBugBert: BERT-Enhanced Vulnerability Detection for Smart Contract\n  Bytecode","summary":"Smart contracts deployed on blockchain platforms are vulnerable to various\nsecurity vulnerabilities. However, only a small number of Ethereum contracts\nhave released their source code, so vulnerability detection at the bytecode\nlevel is crucial. This paper introduces SmartBugBert, a novel approach that\ncombines BERT-based deep learning with control flow graph (CFG) analysis to\ndetect vulnerabilities directly from bytecode. Our method first decompiles\nsmart contract bytecode into optimized opcode sequences, extracts semantic\nfeatures using TF-IDF, constructs control flow graphs to capture execution\nlogic, and isolates vulnerable CFG fragments for targeted analysis. By\nintegrating both semantic and structural information through a fine-tuned BERT\nmodel and LightGBM classifier, our approach effectively identifies four\ncritical vulnerability types: transaction-ordering, access control,\nself-destruct, and timestamp dependency vulnerabilities. Experimental\nevaluation on 6,157 Ethereum smart contracts demonstrates that SmartBugBert\nachieves 90.62% precision, 91.76% recall, and 91.19% F1-score, significantly\noutperforming existing detection methods. Ablation studies confirm that the\ncombination of semantic features with CFG information substantially enhances\ndetection performance. Furthermore, our approach maintains efficient detection\nspeed (0.14 seconds per contract), making it practical for large-scale\nvulnerability assessment.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T12:30:12Z"}
{"aid":"http://arxiv.org/abs/2504.05014v1","title":"Review of analytic results on quasinormal modes of black holes","summary":"We present a concise review of known analytic results for quasinormal modes\nof black holes and related spacetimes. Our emphasis is on those regimes where\nthe perturbation equations admit exact or perturbative solutions, providing\ninsights complementary to numerical or semi-analytic approaches. We discuss\nsolvable cases in lower-dimensional spacetimes, algebraically special modes,\nand exact results in higher-curvature gravity theories. Particular attention is\ngiven to the eikonal regime and its correspondence with null geodesics, as well\nas to beyond-eikonal approximations based on inverse multipole expansions in\nparametrized metrics. We review analytic solutions obtained in the\nnear-extremal limit of Schwarzschild - de Sitter black holes, in the regime of\nlarge field mass, and in pure de Sitter and anti - de Sitter spacetimes, where\nboundary conditions play a crucial role. While not exhaustive, this overview\nhighlights the diversity of techniques and physical insights made possible by\nanalytic treatments of quasinormal spectra.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T12:39:23Z"}
{"aid":"http://arxiv.org/abs/2504.05024v1","title":"Concept Extraction for Time Series with ECLAD-ts","summary":"Convolutional neural networks (CNNs) for time series classification (TSC) are\nbeing increasingly used in applications ranging from quality prediction to\nmedical diagnosis. The black box nature of these models makes understanding\ntheir prediction process difficult. This issue is crucial because CNNs are\nprone to learning shortcuts and biases, compromising their robustness and\nalignment with human expectations. To assess whether such mechanisms are being\nused and the associated risk, it is essential to provide model explanations\nthat reflect the inner workings of the model. Concept Extraction (CE) methods\noffer such explanations, but have mostly been developed for the image domain so\nfar, leaving a gap in the time series domain. In this work, we present a CE and\nlocalization method tailored to the time series domain, based on the ideas of\nCE methods for images. We propose the novel method ECLAD-ts, which provides\npost-hoc global explanations based on how the models encode subsets of the\ninput at different levels of abstraction. For this, concepts are produced by\nclustering timestep-wise aggregations of CNN activation maps, and their\nimportance is computed based on their impact on the prediction process. We\nevaluate our method on synthetic and natural datasets. Furthermore, we assess\nthe advantages and limitations of CE in time series through empirical results.\nOur results show that ECLAD-ts effectively explains models by leveraging their\ninternal representations, providing useful insights about their prediction\nprocess.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T12:49:20Z"}
{"aid":"http://arxiv.org/abs/2504.05066v1","title":"Turing instability for nonlocal heterogeneous reaction-diffusion\n  systems: A computer-assisted proof approach","summary":"This paper provides a computer-assisted proof for the Turing instability\ninduced by heterogeneous nonlocality in reaction-diffusion systems. Due to the\nheterogeneity and nonlocality, the linear Fourier analysis gives rise to\n\\textit{strongly coupled} infinite differential systems. By introducing\nsuitable changes of basis as well as the Gershgorin disks theorem for infinite\nmatrices, we first show that all $N$-th Gershgorin disks lie completely on the\nleft half-plane for sufficiently large $N$. For the remaining finitely many\ndisks, a computer-assisted proof shows that if the intensity $\\delta$ of the\nnonlocal term is large enough, there is precisely one eigenvalue with positive\nreal part, which proves the Turing instability. Moreover, by detailed study of\nthis eigenvalue as a function of $\\delta$, we obtain a sharp threshold\n$\\delta^*$ which is the bifurcation point for Turing instability.","main_category":"math.AP","categories":"math.AP,cs.NA,math.DS,math.NA","published":"2025-04-07T13:34:46Z"}
{"aid":"http://arxiv.org/abs/2504.05075v1","title":"PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud\n  Video Recognition","summary":"Point cloud video perception has become an essential task for the realm of 3D\nvision. Current 4D representation learning techniques typically engage in\niterative processing coupled with dense query operations. Although effective in\ncapturing temporal features, this approach leads to substantial computational\nredundancy. In this work, we propose a framework, named as PvNeXt, for\neffective yet efficient point cloud video recognition, via personalized\none-shot query operation. Specially, PvNeXt consists of two key modules, the\nMotion Imitator and the Single-Step Motion Encoder. The former module, the\nMotion Imitator, is designed to capture the temporal dynamics inherent in\nsequences of point clouds, thus generating the virtual motion corresponding to\neach frame. The Single-Step Motion Encoder performs a one-step query operation,\nassociating point cloud of each frame with its corresponding virtual motion\nframe, thereby extracting motion cues from point cloud sequences and capturing\ntemporal dynamics across the entire sequence. Through the integration of these\ntwo modules, {PvNeXt} enables personalized one-shot queries for each frame,\neffectively eliminating the need for frame-specific looping and intensive query\nprocesses. Extensive experiments on multiple benchmarks demonstrate the\neffectiveness of our method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:43:51Z"}
{"aid":"http://arxiv.org/abs/2504.05106v1","title":"SpeakEasy: Enhancing Text-to-Speech Interactions for Expressive Content\n  Creation","summary":"Novice content creators often invest significant time recording expressive\nspeech for social media videos. While recent advancements in text-to-speech\n(TTS) technology can generate highly realistic speech in various languages and\naccents, many struggle with unintuitive or overly granular TTS interfaces. We\npropose simplifying TTS generation by allowing users to specify high-level\ncontext alongside their script. Our Wizard-of-Oz system, SpeakEasy, leverages\nuser-provided context to inform and influence TTS output, enabling iterative\nrefinement with high-level feedback. This approach was informed by two\n8-subject formative studies: one examining content creators' experiences with\nTTS, and the other drawing on effective strategies from voice actors. Our\nevaluation shows that participants using SpeakEasy were more successful in\ngenerating performances matching their personal standards, without requiring\nsignificantly more effort than leading industry interfaces.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.LG","published":"2025-04-07T14:13:49Z"}
{"aid":"http://arxiv.org/abs/2504.05116v1","title":"Supersaturation of odd linear cycles","summary":"An $r$-uniform linear cycle of length $\\ell$, denoted by $C^r_{\\ell}$, is an\n$r$-graph with $\\ell$ edges $e_1,e_2,\\dots,e_{\\ell}$ where\n$e_i=\\{v_{(r-1)(i-1)},v_{(r-1)(i-1)+1},\\dots,v_{(r-1)i}\\}$ (here\n$v_0=v_{(r-1)\\ell}$). For $0<\\delta<1$ and $n$ sufficiently large, we show that\nevery $n$-vertex $r$-graph $G$ with $n^{r-\\delta}$ edges contains at least\n$n^{(r-1)(2\\ell+1)-\\delta(2\\ell+1+\\frac{4\\ell-1}{(r-1)(2\\ell+1)-3})-o(1)}$\ncopies of $C^r_{2\\ell+1}$. Further, conditioning on the existence of dense\nhigh-girth hypergraphs, we show that there exists $n$-vertex $r$-graphs with\n$n^{r-\\delta}$ edges and at most\n$n^{(r-1)(2\\ell+1)-\\delta(2\\ell+1+\\frac{1}{(r-1)\\ell-1})+o(1)}$ copies of\n$C^r_{2\\ell+1}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T14:20:13Z"}
{"aid":"http://arxiv.org/abs/2504.05117v1","title":"On the Origins of \"Hostless'' Supernovae: Testing the Faint-end Galaxy\n  Luminosity Function and Supernova Progenitors with Events in Dwarf Galaxies","summary":"We present arguments on the likely origins of supernovae without associated\nhost galaxies from open field, non-clustered, environments. We show why it is\nunlikely these ``hostless'' supernovae stem from escaped hyper-velocity stars\n(HVS) in any appreciable numbers, especially for core-collapse supernovae. It\nis highly likely that hostless events arise from dwarf host galaxies too faint\nto be detected in their parent surveys. Several detections and numerous upper\nlimits suggest a large number of field dwarfs, to $M_V>-14$, which themselves\nmay be important to constraining the slope of the low-mass end of the UV\nluminosity function, understanding galaxy evolution, and putting $\\Lambda$CDM\ninto context. Moreover, the detailed study of these mass and\nmetallicity-constrained host environments, and the variety of supernovae that\noccur within them, could provide more stringent constraints on the nature of\nprogenitor systems.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-07T14:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.05126v1","title":"Frustrated Rydberg Atom Arrays Meet Cavity-QED: Emergence of the\n  Superradiant Clock Phase","summary":"Rydberg atom triangular arrays in an optical cavity serve as an ideal\nplatform for understanding the interplay between geometric frustration and\nquantized photons. Using a large-scale quantum Monte Carlo method, we obtain a\nrich ground state phase diagram. Around half-filling, the infinite long-range\nlight-matter interaction lifts the ground state degeneracy, resulting in a\nnovel order-coexisted superradiant clock (SRC) phase that completely destroys\nthe fragile order-by-disorder (OBD) phase observed in classical light fields.\nAccording to the Ginzburg-Landau theory, this replacement may result from the\ncompetition between threefold and sixfold clock terms. Similar to the spin\nsupersolid, the clear first-order phase transition at the $Z_2$ symmetry line\nis attributed to the nonzero photon density, which couples to the threefold\nclock term. Finally, we discuss the low-energy physics in the dimer language\nand propose that cavity-mediated nonlocal ring exchange interactions may play a\ncritical role in the rich physics induced by the attachment of cavity-QED. Our\nwork opens a new arena of research on the emergent phenomena of quantum phase\ntransitions in many-body quantum optics.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el,quant-ph","published":"2025-04-07T14:29:45Z"}
{"aid":"http://arxiv.org/abs/2504.05131v1","title":"One-Loop Transverse-Momentum-Dependent Soft Function at Higher Orders in\n  the Dimensional Regulator","summary":"The transverse-momentum-dependent (TMD) soft function for a generic\nhadroproduction process involving massive colored particles is analytically\ncalculated at the one-loop level, extended to higher orders in the dimensional\nregulator $\\epsilon$. We present both the azimuthal-angle-averaged and\nazimuthal-angle-dependent soft functions in impact-parameter space, making them\nsuitable for small $q_T$ resummation calculations. Their analytic expressions\nare provided in terms of multiple polylogarithms. Our results offer essential\ningredients for a complete higher-order perturbative calculation of the TMD\nsoft function.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T14:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.05134v1","title":"Partially compactified quantum cluster algebras and coordinate rings of\n  simple algebraic groups","summary":"The construction of partially compactified cluster algebras on coordinate\nrings is handled by using codimension 2 arguments on cluster covers. An analog\nof this in the quantum situation is highly desirable but has not been found\nyet. In this paper, we present a general method for the construction of\npartially compactified quantum cluster algebra structures on quantized\ncoordinate rings from that of quantum cluster algebra structures on\nlocalizations. As an application, we construct a partially compactified quantum\ncluster algebra structure on the quantized coordinate ring of every connected,\nsimply connected complex simple algebraic group. Along the way, we also prove\nthat the Berenstein--Zelevinsky seeds on a quantum double Bruhat cell\nassociated to arbitrary unshuffled signed words can be obtained from each other\nby successive mutations.","main_category":"math.QA","categories":"math.QA,math.RA,math.RT","published":"2025-04-07T14:38:54Z"}
{"aid":"http://arxiv.org/abs/2504.05137v1","title":"BoxSeg: Quality-Aware and Peer-Assisted Learning for Box-supervised\n  Instance Segmentation","summary":"Box-supervised instance segmentation methods aim to achieve instance\nsegmentation with only box annotations. Recent methods have demonstrated the\neffectiveness of acquiring high-quality pseudo masks under the teacher-student\nframework. Building upon this foundation, we propose a BoxSeg framework\ninvolving two novel and general modules named the Quality-Aware Module (QAM)\nand the Peer-assisted Copy-paste (PC). The QAM obtains high-quality pseudo\nmasks and better measures the mask quality to help reduce the effect of noisy\nmasks, by leveraging the quality-aware multi-mask complementation mechanism.\nThe PC imitates Peer-Assisted Learning to further improve the quality of the\nlow-quality masks with the guidance of the obtained high-quality pseudo masks.\nTheoretical and experimental analyses demonstrate the proposed QAM and PC are\neffective. Extensive experimental results show the superiority of our BoxSeg\nover the state-of-the-art methods, and illustrate the QAM and PC can be applied\nto improve other models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T14:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.05139v1","title":"Violation of local reciprocity in charge-orbital interconversion","summary":"We demonstrate a violation of local reciprocity in the interconversion\nbetween charge and orbital currents. By investigating orbital torque and\norbital pumping in W/Ni bilayers, we show that the charge-orbital\ninterconversion in the bulk of the W layer exhibits opposite signs in the\ndirect and inverse processes -- the direct and inverse orbital Hall effects\nbeing positive and negative, respectively. This finding provides direct\nevidence of local non-reciprocity in the charge-orbital interconversion, in\nagreement with a theoretical prediction. These results highlight the unique\ncharacteristics of charge-orbital coupled transport and offer fundamental\ninsights into the mechanisms underlying orbital-current-driven phenomena.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-07T14:45:31Z"}
{"aid":"http://arxiv.org/abs/2504.05144v1","title":"Online Cluster-Based Parameter Control for Metaheuristic","summary":"The concept of parameter setting is a crucial and significant process in\nmetaheuristics since it can majorly impact their performance. It is a highly\ncomplex and challenging procedure since it requires a deep understanding of the\noptimization algorithm and the optimization problem at hand. In recent years,\nthe upcoming rise of autonomous decision systems has attracted ongoing\nscientific interest in this direction, utilizing a considerable number of\nparameter-tuning methods. There are two types of methods: offline and online.\nOnline methods usually excel in complex real-world problems, as they can offer\ndynamic parameter control throughout the execution of the algorithm. The\npresent work proposes a general-purpose online parameter-tuning method called\nCluster-Based Parameter Adaptation (CPA) for population-based metaheuristics.\nThe main idea lies in the identification of promising areas within the\nparameter search space and in the generation of new parameters around these\nareas. The method's validity has been demonstrated using the differential\nevolution algorithm and verified in established test suites of low- and\nhigh-dimensional problems. The obtained results are statistically analyzed and\ncompared with state-of-the-art algorithms, including advanced auto-tuning\napproaches. The analysis reveals the promising solid CPA's performance as well\nas its robustness under a variety of benchmark problems and dimensions.","main_category":"math.OC","categories":"math.OC,cs.LG","published":"2025-04-07T14:48:30Z"}
{"aid":"http://arxiv.org/abs/2504.05148v1","title":"Stereo-LiDAR Fusion by Semi-Global Matching With Discrete\n  Disparity-Matching Cost and Semidensification","summary":"We present a real-time, non-learning depth estimation method that fuses Light\nDetection and Ranging (LiDAR) data with stereo camera input. Our approach\ncomprises three key techniques: Semi-Global Matching (SGM) stereo with Discrete\nDisparity-matching Cost (DDC), semidensification of LiDAR disparity, and a\nconsistency check that combines stereo images and LiDAR data. Each of these\ncomponents is designed for parallelization on a GPU to realize real-time\nperformance. When it was evaluated on the KITTI dataset, the proposed method\nachieved an error rate of 2.79\\%, outperforming the previous state-of-the-art\nreal-time stereo-LiDAR fusion method, which had an error rate of 3.05\\%.\nFurthermore, we tested the proposed method in various scenarios, including\ndifferent LiDAR point densities, varying weather conditions, and indoor\nenvironments, to demonstrate its high adaptability. We believe that the\nreal-time and non-learning nature of our method makes it highly practical for\napplications in robotics and automation.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-07T14:54:08Z"}
{"aid":"http://arxiv.org/abs/2504.05149v1","title":"Fast Convolutions on $\\mathbb{Z}^2\\backslash SE(2)$ via Radial\n  Translational Dependence and Classical FFT","summary":"Let $\\mathbb{Z}^2\\backslash SE(2)$ denote the right coset space of the\nsubgroup consisting of translational isometries of the orthogonal lattice\n$\\mathbb{Z}^2$ in the non-Abelian group of planar motions $SE(2)$. This paper\ndevelops a fast and accurate numerical scheme for approximation of functions on\n$\\mathbb{Z}^2\\backslash SE(2)$. We address finite Fourier series of functions\non the right coset space $\\mathbb{Z}^2\\backslash SE(2)$ using finite Fourier\ncoefficients. The convergence/error analysis of finite Fourier coefficients are\ninvestigated. Conditions are established for the finite Fourier coefficients to\nconverge to the Fourier coefficients. The matrix forms of the finite transforms\nare discussed. The implementation of the discrete method to compute numerical\napproximation of $SE(2)$-convolutions with functions which are radial in\ntranslations are considered. The paper is concluded by discussing capability of\nthe numerical scheme to develop fast algorithms for approximating multiple\nconvolutions with functions with are radial in translations.","main_category":"math.NA","categories":"math.NA,cs.NA,math.FA,math.GR","published":"2025-04-07T14:56:32Z"}
{"aid":"http://arxiv.org/abs/2504.05159v1","title":"A Fast Multiplication Algorithm and RLWE-PLWE Equivalence for the\n  Maximal Real Subfield of the $2^r p^s$-th Cyclotomic Field","summary":"This paper proves the RLWE-PLWE equivalence for the maximal real subfields of\nthe cyclotomic fields with conductor $n = 2^r p^s$, where $p$ is an odd prime,\nand $r \\geq 0$ and $s \\geq 1$ are integers. In particular, we show that the\ncanonical embedding as a linear transform has a condition number bounded above\nby a polynomial in $n$. In addition, we describe a fast multiplication\nalgorithm in the ring of integers of these real subfields. The multiplication\nalgorithm uses the fast Discrete Cosine Transform (DCT) and has computational\ncomplexity $\\mathcal{O}(n \\log n)$. Both the proof of the RLWE-PLWE equivalence\nand the fast multiplication algorithm are generalizations of previous results\nby Ahola et al., where the same claims are proved for a single prime $p = 3$.","main_category":"cs.CR","categories":"cs.CR,math.NT,E.3.3","published":"2025-04-07T15:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.05165v1","title":"Forced oscillations for generalized $Î¦$-Laplacian equations with\n  CarathÃ©odory perturbations","summary":"Using topological methods, we study the structure of the set of forced\noscillations of a class of parametric, implicit ordinary differential equations\nwith a generalized $\\Phi$-Laplacian type term. We work in the Carath\\'eodory\nsetting. Under suitable assumptions, involving merely the Brouwer degree in\nEuclidean spaces, we obtain global bifurcation results. In some illustrative\nexamples we provide a visual representation of the bifurcating set.","main_category":"math.CA","categories":"math.CA","published":"2025-04-07T15:10:37Z"}
{"aid":"http://arxiv.org/abs/2504.05168v1","title":"Modeling Micro-Doppler Signature of Multi-Propeller Drones in\n  Distributed ISAC","summary":"Integrated Sensing and Communication (ISAC) will be one key feature of future\n6G networks, enabling simultaneous communication and radar sensing. The radar\nsensing geometry of ISAC will be multistatic since that corresponds to the\ncommon distributed structure of a mobile communication network. Within this\nframework, micro-Doppler analysis plays a vital role in classifying targets\nbased on their micromotions, such as rotating propellers, vibration, or moving\nlimbs. However, research on bistatic micro-Doppler effects, particularly in\nISAC systems utilizing OFDM waveforms, remains limited. Existing methods,\nincluding electromagnetic simulations often lack scalability for generating the\nlarge datasets required to train machine learning algorithms. To address this\ngap, this work introduces an OFDM-based bistatic micro-Doppler model for\nmulti-propeller drones. The proposed model adapts the classic thin-wire model\nto include bistatic sensing configuration with an OFDM-like signal. Then, it\nextends further by incorporating multiple propellers and integrating the\nreflectivity of the drone's static parts. Measurements were performed to\ncollect ground truth data for verification of the proposed model. Validation\nresults show that the model generates micro-Doppler signatures closely\nresembling those obtained from measurements, demonstrating its potential as a\ntool for data generation. In addition, it offers a comprehensive approach to\nanalyzing bistatic micro-Doppler effects.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T15:12:24Z"}
{"aid":"http://arxiv.org/abs/2504.05170v1","title":"SSLFusion: Scale & Space Aligned Latent Fusion Model for Multimodal 3D\n  Object Detection","summary":"Multimodal 3D object detection based on deep neural networks has indeed made\nsignificant progress. However, it still faces challenges due to the\nmisalignment of scale and spatial information between features extracted from\n2D images and those derived from 3D point clouds. Existing methods usually\naggregate multimodal features at a single stage. However, leveraging\nmulti-stage cross-modal features is crucial for detecting objects of various\nscales. Therefore, these methods often struggle to integrate features across\ndifferent scales and modalities effectively, thereby restricting the accuracy\nof detection. Additionally, the time-consuming Query-Key-Value-based\n(QKV-based) cross-attention operations often utilized in existing methods aid\nin reasoning the location and existence of objects by capturing non-local\ncontexts. However, this approach tends to increase computational complexity. To\naddress these challenges, we present SSLFusion, a novel Scale & Space Aligned\nLatent Fusion Model, consisting of a scale-aligned fusion strategy (SAF), a\n3D-to-2D space alignment module (SAM), and a latent cross-modal fusion module\n(LFM). SAF mitigates scale misalignment between modalities by aggregating\nfeatures from both images and point clouds across multiple levels. SAM is\ndesigned to reduce the inter-modal gap between features from images and point\nclouds by incorporating 3D coordinate information into 2D image features.\nAdditionally, LFM captures cross-modal non-local contexts in the latent space\nwithout utilizing the QKV-based attention operations, thus mitigating\ncomputational complexity. Experiments on the KITTI and DENSE datasets\ndemonstrate that our SSLFusion outperforms state-of-the-art methods. Our\napproach obtains an absolute gain of 2.15% in 3D AP, compared with the\nstate-of-art method GraphAlign on the moderate level of the KITTI test set.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T15:15:06Z"}
{"aid":"http://arxiv.org/abs/2504.05171v1","title":"A hydro-geomechanical porous-media model to study effects of engineered\n  carbonate precipitation in faults","summary":"Hydro-geomechanical models are required to predict or understand the impact\nof subsurface engineering applications as, for example, in gas storage in\ngeological formations. This study puts a focus on engineered carbonate\nprecipitation through biomineralization in a fault zone of a cap-rock to reduce\ngas leakage from a reservoir. Besides hydraulic properties like porosity and\npermeability, precipitated carbonates also change the mechanical properties of\nthe rock. We present a conceptual modeling approach implemented into the\nopen-source simulator Dumux and, after verification examples, at hand of a\nCO2-storage scenario, we discuss impacts of biomineralization on the stress\ndistribution in the rock and potentially altered risks of fault reactivations\nand induced seismic events.\n  The generic study shows the tendency towards increased stiffness due to\nprecipitated carbonate, which may cause shear failure events to occur earlier\nthan in an untreated setup, while the magnitude of the seismicity is smaller.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-07T15:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.05175v1","title":"Semiflows on finite topological spaces","summary":"In this paper, we study flows and semiflows defined on any given finite\ntopological $T_0$-space $X$. We show that there exist non-trivial semiflows on\n$X$, unless $X$ is a minimal finite space. Specifically, non-trivial semiflows\nexist if and only if $X$ contains down beat points, and a non-trivial semiflow\nis essentially a strong deformation retraction. As a consequence of this\nresult, we provide a new and concise proof that the only flow that can be\ndefined on $X$ is the trivial flow. Finally, we discuss the number of different\nsemiflows that can be defined on $X$ in terms of down beat points and other\nspecial points.","main_category":"math.GN","categories":"math.GN","published":"2025-04-07T15:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05178v1","title":"The 1st Solution for 4th PVUW MeViS Challenge: Unleashing the Potential\n  of Large Multimodal Models for Referring Video Segmentation","summary":"Motion expression video segmentation is designed to segment objects in\naccordance with the input motion expressions. In contrast to the conventional\nReferring Video Object Segmentation (RVOS), it places emphasis on motion as\nwell as multi-object expressions, making it more arduous. Recently, Large\nMultimodal Models (LMMs) have begun to shine in RVOS due to their powerful\nvision-language perception capabilities. In this work, we propose a simple and\neffective inference optimization method to fully unleash the potential of LMMs\nin referring video segmentation. Firstly, we use Sa2VA as our baseline, which\nis a unified LMM for dense grounded understanding of both images and videos.\nSecondly, we uniformly sample the video frames during the inference process to\nenhance the model's understanding of the entire video. Finally, we integrate\nthe results of multiple expert models to mitigate the erroneous predictions of\na single model. Our solution achieved 61.98% J&F on the MeViS test set and\nranked 1st place in the 4th PVUW Challenge MeViS Track at CVPR 2025.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T15:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.05207v1","title":"Correcting Class Imbalances with Self-Training for Improved Universal\n  Lesion Detection and Tagging","summary":"Universal lesion detection and tagging (ULDT) in CT studies is critical for\ntumor burden assessment and tracking the progression of lesion status\n(growth/shrinkage) over time. However, a lack of fully annotated data hinders\nthe development of effective ULDT approaches. Prior work used the DeepLesion\ndataset (4,427 patients, 10,594 studies, 32,120 CT slices, 32,735 lesions, 8\nbody part labels) for algorithmic development, but this dataset is not\ncompletely annotated and contains class imbalances. To address these issues, in\nthis work, we developed a self-training pipeline for ULDT. A VFNet model was\ntrained on a limited 11.5\\% subset of DeepLesion (bounding boxes + tags) to\ndetect and classify lesions in CT studies. Then, it identified and incorporated\nnovel lesion candidates from a larger unseen data subset into its training set,\nand self-trained itself over multiple rounds. Multiple self-training\nexperiments were conducted with different threshold policies to select\npredicted lesions with higher quality and cover the class imbalances. We\ndiscovered that direct self-training improved the sensitivities of\nover-represented lesion classes at the expense of under-represented classes.\nHowever, upsampling the lesions mined during self-training along with a\nvariable threshold policy yielded a 6.5\\% increase in sensitivity at 4 FP in\ncontrast to self-training without class balancing (72\\% vs 78.5\\%) and a 11.7\\%\nincrease compared to the same self-training policy without upsampling (66.8\\%\nvs 78.5\\%). Furthermore, we show that our results either improved or maintained\nthe sensitivity at 4FP for all 8 lesion classes.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T15:57:03Z"}
{"aid":"http://arxiv.org/abs/2504.05241v1","title":"Chiral magnetic excitations and domain textures of $g$-wave altermagnets","summary":"Altermagnets (AMs) constitute a novel class of spin-compensated materials in\nwhich opposite-spin sublattices are connected by a crystal rotation, causing\ntheir electronic iso-energy surfaces to be spin-split. While cubic and\ntetragonal crystal symmetries tend to produce AMs in which the splitting of\nelectronic iso-energy surfaces has $d$-wave symmetry, hexagonal AMs, such as\nCrSb and MnTe, are $g$-wave AMs. Here we investigate the purely magnetic modes\nand spin-textures of $g$-wave AMs and show that they are drastically different\nfor easy-axial (CrSb) and easy-planar (MnTe) materials. We show that in CrSb\nthe splitting of the chiral magnon branches possesses $g$-wave symmetry, with\neach branch carrying a fixed momentum-independent magnetic moment. The\naltermagnetic splitting is not affected by the easy-axial anisotropy and is the\nsame as that in the nonrelativistic limit. The magnon splitting of MnTe,\nhowever, does not strictly possess $g$-wave symmetry due to its easy-planar\nanisotropy. Instead the magnetic moment of each branch becomes\nmomentum-dependent, with a distribution that is of $g$-wave symmetry. To\ngeneralize the concept of the altermagnetic splitting beyond the\nnonrelativistic limit, we introduce alternative, directly observable splitting\nparameter which comprises both the magnon eigenenergy and its magnetic moment\nand possesses the $g$-wave symmetry in both easy-axial and easy-planar cases.\nThe associated altermagnetic domain walls in easy-axial CrSb possess a net\nmagnetization with an amplitude that depends on their orientation.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-07T16:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.05255v1","title":"Adversarial KA","summary":"Regarding the representation theorem of Kolmogorov and Arnold (KA) as an\nalgorithm for representing or {\\guillemotleft}expressing{\\guillemotright}\nfunctions, we test its robustness by analyzing its ability to withstand\nadversarial attacks. We find KA to be robust to countable collections of\ncontinuous adversaries, but unearth a question about the equi-continuity of the\nouter functions that, so far, obstructs taking limits and defeating continuous\ngroups of adversaries. This question on the regularity of the outer functions\nis relevant to the debate over the applicability of KA to the general theory of\nNNs.","main_category":"cs.LG","categories":"cs.LG,cs.AI,math.FA","published":"2025-04-07T16:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.05258v1","title":"Learning to Reason Over Time: Timeline Self-Reflection for Improved\n  Temporal Reasoning in Language Models","summary":"Large Language Models (LLMs) have emerged as powerful tools for generating\ncoherent text, understanding context, and performing reasoning tasks. However,\nthey struggle with temporal reasoning, which requires processing time-related\ninformation such as event sequencing, durations, and inter-temporal\nrelationships. These capabilities are critical for applications including\nquestion answering, scheduling, and historical analysis. In this paper, we\nintroduce TISER, a novel framework that enhances the temporal reasoning\nabilities of LLMs through a multi-stage process that combines timeline\nconstruction with iterative self-reflection. Our approach leverages test-time\nscaling to extend the length of reasoning traces, enabling models to capture\ncomplex temporal dependencies more effectively. This strategy not only boosts\nreasoning accuracy but also improves the traceability of the inference process.\nExperimental results demonstrate state-of-the-art performance across multiple\nbenchmarks, including out-of-distribution test sets, and reveal that TISER\nenables smaller open-source models to surpass larger closed-weight models on\nchallenging temporal reasoning tasks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-07T16:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.05269v1","title":"A model-based analysis of the AggregateEU mechanism: Implications of\n  overbidding and non-commitment","summary":"AggregateEU is a new centralised mechanism that provides a no-commitment\nplatform to trade natural gas in the European Union. Throughout the\nconsultation process, AggregateEU has been mocked as `Tinder of the European\ngas markets' as it helps consumers and suppliers to find partners, but leaves\nit up to the matched partners to decide whether or not to contract on the\npossible trade. The non-commitment nature leads to substantial overbidding and\nmany non-realised matches.\n  We propose a quantitative modelling framework to study the effect of\noverbidding in the AggergateEU demand aggregation or joint purchasing\nmechanism. We conclude that the mechanism is prone to overbidding and that\noverbidding has ambiguous effects on trade. Depending on the parameters,\noverbidding may facilitate trade, but may also result in highly inefficient\noutcomes when overbidding is combined with a miscoordination over the delivery\npoints.\n  Suggested remedies include allowing for convex bids, restrictions on\noverbidding, or giving up part of the non-binding character of the market.\n%Ideally, the traditional mechanisms of gas exchanges should be augmented by\nfeatures of AggregateEU. Our results sugge","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-07T17:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.05285v1","title":"Hopf tori and standard tori","summary":"This article provides a complete characterization of the conformal classes of\nproduct tori and standard flat tori in complex dimension 1 (real dimension 2).\nUtilizing basic differential geometry methods, our approach contrasts with\ntechniques employing Hopf tori for the conformal classification of Riemann\nsurfaces of genus 1. While the results may be familiar to experts in complex\nanalysis and Riemann surface theory, we contend that this work offers a clear\nand insightful perspective on the conformal properties of these geometrically\ndistinct appearing tori.","main_category":"math.DG","categories":"math.DG","published":"2025-04-07T17:35:14Z"}
{"aid":"http://arxiv.org/abs/2504.05286v1","title":"UK APAP R-matrix electron-impact excitation cross-sections for modelling\n  laboratory and astrophysical plasma","summary":"Systematic R-matrix calculations of electron-impact excitation for ions of\nastrophysical interest have been performed since 2007 for many iso-electronic\nsequences as part of the UK Atomic Process for Astrophysical Plasma (APAP)\nnetwork. Rate coefficients for Maxwellian electron distributions have been\nprovided and used extensively in the literature and many databases for\nastrophysics. Here, we provide averaged collision strengths to be used to model\nplasma where electrons are non-Maxwellian, which often occur in laboratory and\nastrophysical plasma. We also provide for many ions new Maxwellian-averaged\ncollision strengths which include important corrections to the published\nvalues. The H- and He-like atomic data were recently made available in\nMao+(2022). Here, we provide data for ions of the Li-, Be-, B-, C-, N-, O-,\nNe-, Na-, and Mg-like sequences.","main_category":"physics.atom-ph","categories":"physics.atom-ph,astro-ph.IM,astro-ph.SR","published":"2025-04-07T17:37:09Z"}
{"aid":"http://arxiv.org/abs/2504.05631v1","title":"Distributed Solving of Linear Quadratic Optimal Controller with Terminal\n  State Constraint","summary":"This paper is concerned with the linear quadratic (LQ) optimal control of\ncontinuous-time system with terminal state constraint. In particular, multiple\nagents exist in the system which can only access partial information of the\nmatrix parameters. This makes the classical solving method based on Riccati\nequation with global information suffering. The main contribution is to present\na distributed algorithm to derive the optimal controller which is consisting of\nthe distributed iterations for the Riccati equation, a backward differential\nequation driven by the optimal Lagrange multiplier and the optimal state.\nFinally, a numerical example verifies the effectiveness of the proposed\nalgorithm.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T03:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05634v1","title":"Simplifying Data Integration: SLM-Driven Systems for Unified Semantic\n  Queries Across Heterogeneous Databases","summary":"The integration of heterogeneous databases into a unified querying framework\nremains a critical challenge, particularly in resource-constrained\nenvironments. This paper presents a novel Small Language Model(SLM)-driven\nsystem that synergizes advancements in lightweight Retrieval-Augmented\nGeneration (RAG) and semantic-aware data structuring to enable efficient,\naccurate, and scalable query resolution across diverse data formats. By\nintegrating MiniRAG's semantic-aware heterogeneous graph indexing and\ntopology-enhanced retrieval with SLM-powered structured data extraction, our\nsystem addresses the limitations of traditional methods in handling\nMulti-Entity Question Answering (Multi-Entity QA) and complex semantic queries.\nExperimental results demonstrate superior performance in accuracy and\nefficiency, while the introduction of semantic entropy as an unsupervised\nevaluation metric provides robust insights into model uncertainty. This work\npioneers a cost-effective, domain-agnostic solution for next-generation\ndatabase systems.","main_category":"cs.DB","categories":"cs.DB,cs.IR","published":"2025-04-08T03:28:03Z"}
{"aid":"http://arxiv.org/abs/2504.05656v1","title":"Anti-pre-Novikov algebras and anti-pre-Novikov bialgebras","summary":"Firstly, we introduce the notion of anti-pre-Novikov algebras as a new\napproach of splitting the Novikov algebras. The notions of anti-O-operators on\nNovikov algebras are developed to interpret anti-pre-Novikov algebras.\nSecondly, we introduce the notion of anti-pre-Novikov bialgebras as the\nbialgebra structures corresponding to a double constructions of symmetric\nquasi-Frobenius Novikov algebras, which are interpreted in terms of certain\nmatched pairs of Novikov algebras as well as the compatible anti-pre-Novikov\nalgebras. The study of coboundary cases leads to the introduction of the the\nanti-pre-Novikov Yang-Baxter equation (APN-YBE), whose skew-symmetric solutions\ngive coboundary anti-pre-Novikov bialgebras. The notion of O-operators on\nanti-pre-Novikov algebras is studied to construct skew-symmetric solutions of\nthe APN-YBE.","main_category":"math.RA","categories":"math.RA,math.QA","published":"2025-04-08T04:10:38Z"}
{"aid":"http://arxiv.org/abs/2504.05668v1","title":"A Message-Passing Perspective on Ptychographic Phase Retrieval","summary":"We introduce a probabilistic approach to ptychographic reconstruction in\ncomputational imaging. Ptychography is an imaging method where the complex\namplitude of an object is estimated from a sequence of diffraction\nmeasurements. We formulate this reconstruction as a Bayesian inverse problem\nand derive an inference algorithm, termed \"Ptycho-EP,\" based on belief\npropagation and Vector Approximate Message Passing from information theory.\nPrior knowledge about the unknown object can be integrated into the\nprobabilistic model, and the Bayesian framework inherently provides uncertainty\nquantification of the reconstruction. Numerical experiments demonstrate that,\nwhen the probe's illumination function is known, our algorithm accurately\nretrieves the object image at a sampling ratio approaching the information\ntheoretic limit. In scenarios where the illumination function is unknown, both\nthe object and the probe can be jointly reconstructed via an\nExpectation-Maximization algorithm. We evaluate the performance of our\nalgorithm against conventional methods, highlighting its superior convergence\nspeed.","main_category":"stat.AP","categories":"stat.AP,physics.optics","published":"2025-04-08T04:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.05672v1","title":"Contrastive Decoupled Representation Learning and Regularization for\n  Speech-Preserving Facial Expression Manipulation","summary":"Speech-preserving facial expression manipulation (SPFEM) aims to modify a\ntalking head to display a specific reference emotion while preserving the mouth\nanimation of source spoken contents. Thus, emotion and content information\nexisting in reference and source inputs can provide direct and accurate\nsupervision signals for SPFEM models. However, the intrinsic intertwining of\nthese elements during the talking process poses challenges to their\neffectiveness as supervisory signals. In this work, we propose to learn content\nand emotion priors as guidance augmented with contrastive learning to learn\ndecoupled content and emotion representation via an innovative Contrastive\nDecoupled Representation Learning (CDRL) algorithm. Specifically, a Contrastive\nContent Representation Learning (CCRL) module is designed to learn audio\nfeature, which primarily contains content information, as content priors to\nguide learning content representation from the source input. Meanwhile, a\nContrastive Emotion Representation Learning (CERL) module is proposed to make\nuse of a pre-trained visual-language model to learn emotion prior, which is\nthen used to guide learning emotion representation from the reference input. We\nfurther introduce emotion-aware and emotion-augmented contrastive learning to\ntrain CCRL and CERL modules, respectively, ensuring learning\nemotion-independent content representation and content-independent emotion\nrepresentation. During SPFEM model training, the decoupled content and emotion\nrepresentations are used to supervise the generation process, ensuring more\naccurate emotion manipulation together with audio-lip synchronization.\nExtensive experiments and evaluations on various benchmarks show the\neffectiveness of the proposed algorithm.","main_category":"cs.CV","categories":"cs.CV,cs.SD","published":"2025-04-08T04:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.05694v1","title":"Large Language Models Enhanced Hyperbolic Space Recommender Systems","summary":"Large Language Models (LLMs) have attracted significant attention in\nrecommender systems for their excellent world knowledge capabilities. However,\nexisting methods that rely on Euclidean space struggle to capture the rich\nhierarchical information inherent in textual and semantic data, which is\nessential for capturing user preferences. The geometric properties of\nhyperbolic space offer a promising solution to address this issue.\nNevertheless, integrating LLMs-based methods with hyperbolic space to\neffectively extract and incorporate diverse hierarchical information is\nnon-trivial. To this end, we propose a model-agnostic framework, named\nHyperLLM, which extracts and integrates hierarchical information from both\nstructural and semantic perspectives. Structurally, HyperLLM uses LLMs to\ngenerate multi-level classification tags with hierarchical parent-child\nrelationships for each item. Then, tag-item and user-item interactions are\njointly learned and aligned through contrastive learning, thereby providing the\nmodel with clear hierarchical information. Semantically, HyperLLM introduces a\nnovel meta-optimized strategy to extract hierarchical information from semantic\nembeddings and bridge the gap between the semantic and collaborative spaces for\nseamless integration. Extensive experiments show that HyperLLM significantly\noutperforms recommender systems based on hyperbolic space and LLMs, achieving\nperformance improvements of over 40%. Furthermore, HyperLLM not only improves\nrecommender performance but also enhances training stability, highlighting the\ncritical role of hierarchical information in recommender systems.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-08T05:35:38Z"}
{"aid":"http://arxiv.org/abs/2504.05704v1","title":"Wave propagation and scattering in time dependent media:\n  Lippmann-Schwinger equations, multiple scattering theory, Kirchhoff Helmholtz\n  integrals, Green's functions, reciprocity theorems and Huygens' principle","summary":"Wave scattering plays a central role for the modeling of complex wave\npropagation across all corners of science and engineering applications,\nincluding electromagnetic, acoustics, seismic and scattering physics. Wave\ncontrol using time interfaces, where the properties of the medium through with\nthe wave travels rapidly change in time, has opened further opportunities to\ncontrol wave propagation in both space and time. For acoustic waves, studies on\ntime modulated media have not been reported. In this context, full numerical\nsolution of the wave equation using time interfaces is key to fully understand\ntheir potential. When applying time interfaces, the underlying physics of\nacoustic wave propagation and scattering and their similar roles on time and\nspace, are still being explored. In this work, we introduce a mathematical\nformulation of the Lippmann-Schwinger integral equations for acoustic wave\nscattering when time interfaces are induced via a change of the velocity of the\nmedium. We demonstrate that space-time duality for acoustic wave propagation\nwith time interfaces and derive the Lippmann-Schwinger integral equations for\nwave scattering in time-dependent media, multiple scattering theory, Kirchhoff\nHelmholtz integrals, Green's functions, reciprocity theorems. We experimentally\nverify our theoretical derivation by studying and measuring the acoustic wave\nscattering in strongly scattering media. We illustrate the proposed framework\nand present results of acoustic wave scattering without prior knowledge of the\nbackground wave-fields. This improves the understanding of the generation and\nwave scattering and opens previously inaccessible research directions,\npotentially facilitating practical applications for acoustic, geophysical and\noptical imaging.","main_category":"physics.optics","categories":"physics.optics,physics.geo-ph","published":"2025-04-08T05:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.05710v1","title":"Cryptomania v.s. Minicrypt in a Quantum World","summary":"We prove that it is impossible to construct perfect-complete quantum\npublic-key encryption (QPKE) with classical keys from quantumly secure one-way\nfunctions (OWFs) in a black-box manner, resolving a long-standing open question\nin quantum cryptography. Specifically, in the quantum random oracle model\n(QROM), no perfect-complete QPKE scheme with classical keys, and\nclassical/quantum ciphertext can be secure. This improves the previous works\nwhich require either unproven conjectures or imposed restrictions on key\ngeneration algorithms. This impossibility even extends to QPKE with quantum\npublic key if the public key can be uniquely determined by the secret key, and\nthus is tight to all existing QPKE constructions.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-08T06:07:40Z"}
{"aid":"http://arxiv.org/abs/2504.05713v1","title":"Revisiting poverty measures using quantile functions","summary":"In this article we redefine various poverty measures in literature in terms\nof quantile functions instead of distribution functions in the prevailing\napproach. This enables provision for alternative methodology for poverty\nmeasurement and analysis along with some new results that are difficult to\nobtain in the existing framework. Several flexible quantile function models\nthat can enrich the existing ones are proposed and their utility is\ndemonstrated for real data.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-08T06:15:17Z"}
{"aid":"http://arxiv.org/abs/2504.05723v1","title":"Improved Polynomial Bounds and Acceleration of GMRES by Solving a\n  min-max Problem on Rectangles, and by Deflating","summary":"Polynomial convergence bounds are considered for left, right, and split\npreconditioned GMRES. They include the cases of Weighted and Deflated GMRES for\na linear system Ax = b. In particular, the case of positive definite A is\nconsidered. The well-known polynomial bounds are generalized to the cases\nconsidered, and then reduced to solving a min-max problem on rectangles on the\ncomplex plane. Several approaches are considered and compared. The new bounds\ncan be improved by using specific deflation spaces and preconditioners. This in\nturn accelerates the convergence of GMRES. Numerical examples illustrate the\nresults obtained.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T06:45:34Z"}
{"aid":"http://arxiv.org/abs/2504.05739v1","title":"PRACH Preamble Detection as a Multi-Class Classification Problem: A\n  Machine Learning Approach Using SVM","summary":"This study addresses the preamble detection problem in the Random Access\nprocedure of LTE/5G networks by formulating it as a multi-class classification\ntask and evaluating the effectiveness of machine learning techniques. A Support\nVector Machine (SVM) model is implemented and compared against conventional\ndetection methods. The proposed approach improves preamble index assignment,\nenhancing detection efficiency for User Equipment (UE) accessing the network.\nPerformance analysis demonstrates that the SVM-based solution increases\ndetection accuracy while reducing missed detections. These findings underscore\nthe potential of machine learning in optimizing the Random Access procedure and\nimproving network accessibility.","main_category":"eess.SP","categories":"eess.SP,40-06","published":"2025-04-08T07:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.05740v1","title":"Micro-splatting: Maximizing Isotropic Constraints for Refined\n  Optimization in 3D Gaussian Splatting","summary":"Recent advancements in 3D Gaussian Splatting have achieved impressive\nscalability and real-time rendering for large-scale scenes but often fall short\nin capturing fine-grained details. Conventional approaches that rely on\nrelatively large covariance parameters tend to produce blurred representations,\nwhile directly reducing covariance sizes leads to sparsity. In this work, we\nintroduce Micro-splatting (Maximizing Isotropic Constraints for Refined\nOptimization in 3D Gaussian Splatting), a novel framework designed to overcome\nthese limitations. Our approach leverages a covariance regularization term to\npenalize excessively large Gaussians to ensure each splat remains compact and\nisotropic. This work implements an adaptive densification strategy that\ndynamically refines regions with high image gradients by lowering the splitting\nthreshold, followed by loss function enhancement. This strategy results in a\ndenser and more detailed gaussian means where needed, without sacrificing\nrendering efficiency. Quantitative evaluations using metrics such as L1, L2,\nPSNR, SSIM, and LPIPS, alongside qualitative comparisons demonstrate that our\nmethod significantly enhances fine-details in 3D reconstructions.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-08T07:15:58Z"}
{"aid":"http://arxiv.org/abs/2504.05756v1","title":"Interpretable Non-linear Survival Analysis with Evolutionary Symbolic\n  Regression","summary":"Survival Regression (SuR) is a key technique for modeling time to event in\nimportant applications such as clinical trials and semiconductor manufacturing.\nCurrently, SuR algorithms belong to one of three classes: non-linear black-box\n-- allowing adaptability to many datasets but offering limited interpretability\n(e.g., tree ensembles); linear glass-box -- being easier to interpret but\nlimited to modeling only linear interactions (e.g., Cox proportional hazards);\nand non-linear glass-box -- allowing adaptability and interpretability, but\nempirically found to have several limitations (e.g., explainable boosting\nmachines, survival trees). In this work, we investigate whether Symbolic\nRegression (SR), i.e., the automated search of mathematical expressions from\ndata, can lead to non-linear glass-box survival models that are interpretable\nand accurate. We propose an evolutionary, multi-objective, and multi-expression\nimplementation of SR adapted to SuR. Our empirical results on five real-world\ndatasets show that SR consistently outperforms traditional glass-box methods\nfor SuR in terms of accuracy per number of dimensions in the model, while\nexhibiting comparable accuracy with black-box methods. Furthermore, we offer\nqualitative examples to assess the interpretability potential of SR models for\nSuR. Code at: https://github.com/lurovi/SurvivalMultiTree-pyNSGP.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-08T07:37:37Z"}
{"aid":"http://arxiv.org/abs/2504.05762v1","title":"Statistics of velocity gradient and vortex sheet structures in polymeric\n  turbulent von K{Ã¡}rm{Ã¡}n swirling flow","summary":"Investigations into the effects of polymers on small-scale statistics and\nflow patterns were conducted in a turbulent von Karman swirling (VKS) flow. We\nemployed the tomographic particle image velocimetry (Tomo-PIV) technique to\nobtain full information on three-dimensional velocity data, allowing us to\neffectively resolve dissipation scales. Under varying Reynolds numbers\n($R_\\lambda=168 - 235$) and polymer concentrations ($\\phi=0 -25~\\rm ppm$), we\nmeasured the velocity gradient tensor (VGT) and related quantities. Our\nfindings reveal that the ensemble average and probability density function\n(PDF) of VGT invariants, which represent turbulent dissipation and enstrophy\nalong with their generation terms, are suppressed as polymer concentration\nincreases. Notably, the joint PDFs of the invariants of VGT, which characterize\nlocal flow patterns, exhibited significant changes. Specifically, the\nthird-order invariants, especially the local vortex stretching, are greatly\nsuppressed, and strong events of dissipation and enstrophy coexist in space.\nThe local flow pattern tends to be two-dimensional, where the eigenvalues of\nthe rate-of-strain tensor satisfy a ratio $1:0:-1$, and the vorticity aligns\nwith the intermediate eigenvector of the rate-of-strain tensor while is\nperpendicular to the other two. We find that these statistics observations can\nbe well described by the vortex sheet model. Moreover, we find that these\nvortex sheet structures align with the symmetry axis of the VKS system and\norient randomly in the horizontal plane. Further investigation, including flow\nvisualization and conditional statistics on vorticity, confirms the presence of\nvortex sheet structures in turbulent flows with polymer additions. Our results\nestablish a link between single-point statistics and small-scale flow topology,\nshedding light on the previously overlooked small-scale structures in polymeric\nturbulence.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T07:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.05771v1","title":"Dissolution-driven transport in a rotating horizontal cylinder","summary":"Dissolution, in particular, coupled with convection, can be of great\nrelevance in the fields of pharmaceuticals, food science, chemical engineering,\nand environmental science, having applications in drug release into the\nbloodstream, ingredient dissolution in liquids, metal extraction from ores, and\npollutant dispersion in water. We study the combined effects of natural\nconvection and rotation on the dissolution of a solute in a solvent-filled\ncircular cylinder. The density of the fluid increases with the increasing\nconcentration of the dissolved solute, and we model this using the\nOberbeck-Boussinesq approximation. The underlying moving-boundary problem has\nbeen modelled by combining Navier-Stokes equations with the advection-diffusion\nequation and a Stefan condition for the evolving solute-fluid interface. We use\nhighly resolved numerical simulations to investigate the flow regimes,\ndissolution rates, and mixing of the dissolved solute for $Sc = 1$, $Ra =\n[10^5, 10^8]$ and $\\Omega = [0, 2.5]$. In the absence of rotation and buoyancy,\nthe distance of the interface from its initial position follows a square root\nrelationship with time ($r_d \\propto \\sqrt{t}$), which ceases to exist at a\nlater time due to the finite-size effect of the liquid domain. We then explore\nthe rotation parameter, considering a range of rotation frequency -- from\nsmaller to larger, relative to the inverse of the buoyancy-induced timescale --\nand Rayleigh number. We show that the area of the dissolved solute varies\nnonlinearly with time depending on $Ra$ and $\\Omega$. The symmetry breaking of\nthe interface is best described in terms of $Ra/\\Omega^2$.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T07:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.05774v1","title":"Transferable Mask Transformer: Cross-domain Semantic Segmentation with\n  Region-adaptive Transferability Estimation","summary":"Recent advances in Vision Transformers (ViTs) have set new benchmarks in\nsemantic segmentation. However, when adapting pretrained ViTs to new target\ndomains, significant performance degradation often occurs due to distribution\nshifts, resulting in suboptimal global attention. Since self-attention\nmechanisms are inherently data-driven, they may fail to effectively attend to\nkey objects when source and target domains exhibit differences in texture,\nscale, or object co-occurrence patterns. While global and patch-level domain\nadaptation methods provide partial solutions, region-level adaptation with\ndynamically shaped regions is crucial due to spatial heterogeneity in\ntransferability across different image areas. We present Transferable Mask\nTransformer (TMT), a novel region-level adaptation framework for semantic\nsegmentation that aligns cross-domain representations through spatial\ntransferability analysis. TMT consists of two key components: (1) An Adaptive\nCluster-based Transferability Estimator (ACTE) that dynamically segments images\ninto structurally and semantically coherent regions for localized\ntransferability assessment, and (2) A Transferable Masked Attention (TMA)\nmodule that integrates region-specific transferability maps into ViTs'\nattention mechanisms, prioritizing adaptation in regions with low\ntransferability and high semantic uncertainty. Comprehensive evaluations across\n20 cross-domain pairs demonstrate TMT's superiority, achieving an average 2%\nMIoU improvement over vanilla fine-tuning and a 1.28% increase compared to\nstate-of-the-art baselines. The source code will be publicly available.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T07:53:51Z"}
{"aid":"http://arxiv.org/abs/2504.05785v1","title":"Presolve techniques for quasi-convex chance constraints with\n  finite-support low-dimensional uncertainty","summary":"Chance-constrained programs (CCP) represent a trade-off between conservatism\nand robustness in optimization. In many CCPs, one optimizes an objective under\na probabilistic constraint continuously parameterized by a random vector $\\xi$.\nIn this work, we study the specific case where the constraint is quasi-convex\nwith $\\xi$. Moreover, the support of vector $\\xi$ is a collection of $N$\nscenarios in dimension $p=2$ or $p=3$. In general, even when both the\nconstraint and the objective are convex in the decision variable, the feasible\nregion of a CCP is nonconvex, turning it into a difficult problem. However,\nunder mild assumptions, many CCPs can be recast as big-$M$ mixed-integer convex\nprograms (MICP). Unfortunately, the difficulty of these MICPs explodes with the\nnumber of scenarios, restricting the instances practically solvable in decent\ntime. To cut down the effective number of scenarios considered in MICP\nreformulations and accelerate their solving, we propose and test presolve\ntechniques based on computational geometry. Our techniques produce certificates\nto discard or select a priori some scenarios before solving a regular MICP.\nMoreover, the information aggregated during presolve leverages the possibility\nto strengthen big-$M$ constants. Our numerical experiments suggest that\nspending some time in presolve is more efficient than a direct solve for a\nclass of probabilistic projection problems, including an interesting type of\nfacility location problem.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T08:11:38Z"}
{"aid":"http://arxiv.org/abs/2504.05790v1","title":"ViralQC: A Tool for Assessing Completeness and Contamination of\n  Predicted Viral Contigs","summary":"Motivation: Viruses represent the most abundant biological entities on the\nplanet and play vital roles in diverse ecosystems. Cataloging viruses across\nvarious environments is essential for understanding their properties and\nfunctions. Metagenomic sequencing has emerged as the most comprehensive method\nfor virus discovery, enabling the sequencing of all genetic materials,\nincluding viruses, from host or environmental samples. However, distinguishing\nviral sequences from the vast background of cellular organism-derived reads in\nmetagenomic data remains a significant challenge. While several learning-based\ntools, such as VirSorter2 and geNomad, have shown promise in identifying viral\ncontigs, they often experience varying degrees of false positive rates due to\nnoise in sequencing and assembly, shared genes between viruses and their hosts,\nand the formation of proviruses within host genomes. This highlights the urgent\nneed for an accurate and efficient method to evaluate the quality of viral\ncontigs. Results: To address these challenges, we introduce ViralQC, a tool\ndesigned to assess the quality of reported viral contigs or bins. ViralQC\nidentifies contamination regions within putative viral sequences using\nfoundation models trained on viral and cellular genomes and estimates viral\ncompleteness through protein organization alignment. We evaluate ViralQC on\nmultiple datasets and compare its performance against CheckV, the\nstate-of-the-art in virus quality assessment. Notably, ViralQC correctly\nidentifies 38% more contamination than CheckV, while maintaining a median\nabsolute error of only 3%. In addition, ViralQC delivers more accurate results\nfor medium- to high-quality (>50% completeness) contigs, demonstrating its\nsuperior performance in completeness estimation.","main_category":"q-bio.GN","categories":"q-bio.GN","published":"2025-04-08T08:14:44Z"}
{"aid":"http://arxiv.org/abs/2504.05792v1","title":"Pinching-Antenna Assisted ISAC: A CRLB Perspective","summary":"Recently, pinching antennas have attracted significant research interest due\nto their capability to reconfigure wireless channels as well as their array\nconfiguration flexibility. This letter focuses on how these features can be\nused to support integrated sensing and communications (ISAC) from the Cramer\nRao lower bound (CRLB) perspective. In particular, the CRLB achieved by\npinching antennas is first derived and then compared to that of conventional\nantennas. The presented analytical and simulation results demonstrate that\nusing pinching antennas can significantly reduce CRLB and, hence, enhance\npositioning accuracy. In addition, this letter also reveals that the low-cost\nand reconfigurability features of pinching antennas can be utilized to realize\nflexible user-centric positioning.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-08T08:21:58Z"}
{"aid":"http://arxiv.org/abs/2504.05799v1","title":"Higgs alignment limits in the type-II 2HDM and the MSSM with explicit\n  CP-violation","summary":"For the general two-Higgs doublet model with Yukawa sector of type II (type\nII 2HDM), the Higgs alignment limit conditions are obtained for the neutral\nHiggs bosons with indefinite CP-parity $h_1, h_2$ or $h_3$, based on the\nsymbolic results relating the elements of the mixing matrix to the masses of\nthe Higgs bosons and the mixing angles. The results are valid up to\ndimension-six operators in the decomposition of the effective Higgs potential.\nWithin the framework of the obtained Higgs alignment conditions, the\npossibility of the existence of light scalars is discussed. Within the Minimal\nSupersymmetric Standard Model (MSSM) framework, four benchmark scenarios are\nproposed. It is shown that two of them predict phenomenologically\ndistinguishable CP-violating interactions of the Higgs boson $h_3$ with\nup-fermions.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T08:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.05836v1","title":"Work probability distribution of weakly driven process in overdamped\n  dynamics","summary":"Analytical work probability distributions for open classical systems are\nscarce; they can only be calculated in a few examples. In this work, I present\na new method to derive such quantities for weakly driven processes in the\noverdamped regime for any switching time. The white noise Brownian motion in a\nharmonic linear stiffening trap illustrates the result. The work probability\ndistribution is non-tabulated, with positive, semi-finite support, diverging at\nthe minimal value, and non-Gaussian. An analysis of the range of validity of\nlinear response is made by using the self-consistent criterion of the\nfluctuation-dissipation relation. The first, second, third, and fourth moments\nare correctly calculated for small perturbations.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T09:18:35Z"}
{"aid":"http://arxiv.org/abs/2504.05842v1","title":"Exact results for spin glass criticality","summary":"In recent years scale invariant scattering theory provided the first exact\naccess to the magnetic critical properties of two-dimensional statistical\nsystems with quenched disorder. We show how the theory extends to the overlap\nvariables entering the characterization of spin glass properties. The resulting\nexact fixed point equations yield both the magnetic and, for the first time,\nthe spin glass renormalization group fixed points. For the case of the random\nbond Ising model, on which we focus, the spin glass subspace of solutions is\nfound to contain a line of fixed points. We discuss the implications of the\nresults for Ising spin glass criticality and compare with the available\nnumerical results.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,hep-th","published":"2025-04-08T09:22:05Z"}
{"aid":"http://arxiv.org/abs/2504.05860v1","title":"Functional matrix product state simulation of continuous variable\n  quantum circuits","summary":"We introduce a functional matrix product state (FMPS) based method for\nsimulating the real-space representation of continuous-variable (CV) quantum\ncomputation. This approach efficiently simulates non-Gaussian CV systems by\nleveraging their functional form. By addressing scaling bottlenecks, FMPS\nenables more efficient simulation of shallow, multi-mode CV quantum circuits\nwith non-Gaussian input states. The method is validated by simulating random\nshallow and cascaded circuits with highly non-Gaussian input states, showing\nsuperior performance compared to existing techniques, also in the presence of\nloss.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T09:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.05869v1","title":"The Ultraviolet Spectra of 2003fg-like Type Ia Supernovae","summary":"2003fg-like Type Ia supernovae (03fg-like SNe Ia) are a rare subtype of SNe\nIa, photometrically characterized by broader optical light curves and bluer\nultraviolet (UV) colors compared to normal SNe Ia. In this work, we study four\n03fg-like SNe Ia using Swift UltraViolet and Optical Telescope (UVOT) grism\nobservations to understand their unique UV properties and progenitor\nscenario(s). We report 03fg-like SNe Ia to have similar UV features and\nelemental compositions as normal SNe Ia, but with higher UV flux relative to\noptical. Previous studies have suggested that the UV flux levels of normal SNe\nIa could be influenced by their progenitor properties, such as metallicity,\nwith metal-poor progenitors producing higher UV flux levels. While 03fg-like\nSNe were previously reported to occur in low-mass and metal-poor host\nenvironments, our analysis indicates that their UV excess cannot be explained\nby their host-galaxy parameters. Instead, we demonstrate that the addition of a\nhot blackbody component, likely arising from the interaction with the\ncircumstellar material (CSM), to the normal SN Ia spectrum, can reproduce their\ndistinctive UV excess. This supports the hypothesis that 03fg-like SNe Ia could\nexplode in a CSM-rich environment.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-08T09:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.05875v1","title":"Gravitational waves from primordial black hole dominance: The effect of\n  inflaton decay rate","summary":"In this work, we explore primordial black holes (PBH) formation scenario\nduring the post-inflationary preheating stage dominated by the inflaton field.\nWe consider, in particular, a model-independent parametrization of the Gaussian\npeak inflationary power spectrum that leads to amplified inflationary density\nfluctuations before the end of inflation. These modes can reenter the horizon\nduring preheating and could experience instabilities that trigger the\nproduction of PBH. This is estimated with the Khlopov-Polnarev (KP) formalism\nthat takes into account non-spherical effects. We derive an accurate analytical\nexpression for the mass fraction under the KP formalism that fits well with the\nnumerical evaluation. Particularly, we focus on ultra-light PBH of masses\n$M_{\\text{PBH}}<10^9g$ and study their evolution and (possible) dominance after\nthe decay of the inflation field into radiation and before the PBH evaporation\nvia Hawking radiation. These considerations alter the previous estimates of\ninduced gravitational waves (GWs) from PBH dominance and open new windows for\ndetecting stochastic GW backgrounds with future detectors.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T09:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.05895v1","title":"Orthogonal Matching Pursuit based Reconstruction for Modulo Hysteresis\n  Operators","summary":"Unlimited sampling provides an acquisition scheme for high dynamic range\nsignals by folding the signal into the dynamic range of the analog-to-digital\nconverter (ADC) using modulo non-linearity prior to sampling to prevent\nsaturation. Recently, a generalized scheme called modulo hysteresis was\nintroduced to account for hardware non-idealities. The encoding operator,\nhowever, does not guarantee that the output signal is within the dynamic range\nof the ADC. To resolve this, we propose a modified modulo hysteresis operator\nand show identifiability of bandlimited signals from modulo hysteresis samples.\nWe propose a recovery algorithm based on orthogonal matching pursuit and\nvalidate our theoretical results through numerical experiments.","main_category":"math.NA","categories":"math.NA,cs.NA,eess.SP","published":"2025-04-08T10:45:44Z"}
{"aid":"http://arxiv.org/abs/2504.05898v1","title":"Assessing Thai Dialect Performance in LLMs with Automatic Benchmarks and\n  Human Evaluation","summary":"Large language models show promising results in various NLP tasks. Despite\nthese successes, the robustness and consistency of LLMs in underrepresented\nlanguages remain largely unexplored, especially concerning local dialects.\nExisting benchmarks also focus on main dialects, neglecting LLMs' ability on\nlocal dialect texts. In this paper, we introduce a Thai local dialect benchmark\ncovering Northern (Lanna), Northeastern (Isan), and Southern (Dambro) Thai,\nevaluating LLMs on five NLP tasks: summarization, question answering,\ntranslation, conversation, and food-related tasks. Furthermore, we propose a\nhuman evaluation guideline and metric for Thai local dialects to assess\ngeneration fluency and dialect-specific accuracy. Results show that LLM\nperformance declines significantly in local Thai dialects compared to standard\nThai, with only proprietary models like GPT-4o and Gemini2 demonstrating some\nfluency","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T10:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.05900v1","title":"Strict renormalizability as a paradigm for fundamental physics","summary":"An important theoretical achievement of the last century was the realization\nthat strict renormalizability can be a powerful criterion to select Lagrangians\nin the framework of perturbative quantum field theory. The Standard Model\nLagrangian (without gravity) is strictly renormalizable from a perturbative\npoint of view. On the other hand, the inclusion of gravity seems not to respect\nthis criterion, since general relativity is perturbatively non-renormalizable.\nThe aim of this work is to provide concrete evidence that strict\nrenormalizability is still a valid criterion even when applied to gravity.\nFirst, we show that adding quadratic curvature terms to the Einstein-Hilbert\naction gives rise to a strictly renormalizable theory known as quadratic\ngravity. Second, we argue that this unique theory represents the most\nconservative approach to quantum gravity and, at the same time, is highly\npredictive, as it can explain new physics beyond general relativity already in\nthe sub-Planckian regime. In particular, it provides one of the best fits to\nthe CMB anisotropies via Starobinsky inflation and makes sharp cosmological\npredictions that can be tested in the near future. Finally, we comment on the\n(super-)Planckian regime and conclude with a historical note.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-08T10:54:19Z"}
{"aid":"http://arxiv.org/abs/2504.05903v1","title":"A construction of multiple group racks","summary":"A multiple group rack is a rack which is a disjoint union of groups equipped\nwith a binary operation satisfying some conditions. It is used to define\ninvariants of spatial surfaces, i.e., oriented compact surfaces with boundaries\nembedded in the $3$-sphere $S^{3}$. A $G$-family of racks is a set with a\nfamily of binary operations indexed by the elements of a group $G$. There are\ntwo known methods for constructing multiple group racks. One is via a\n$G$-family of racks. The resulting multiple group rack is called the associated\nmultiple group rack of the $G$-family of racks. The other is by taking an\nabelian extension of a multiple group rack. In this paper, we introduce a new\nmethod for constructing multiple group racks by using a $G$-family of racks and\na normal subgroup $N$ of $G$. We show that this construction yields multiple\ngroup racks that are neither the associated multiple group racks of any\n$G$-family of racks nor their abelian extensions when the right conjugation\naction of $G$ on $N$ is nontrivial. As an application, we present a pair of\nspatial surfaces that cannot be distinguished by invariants derived from the\nassociated multiple group racks of any $G$-family of racks, yet can be\ndistinguished using invariants obtained from a multiple group rack introduced\nin this paper.","main_category":"math.GT","categories":"math.GT","published":"2025-04-08T11:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.05910v1","title":"Testing the parquet equations and the U(1) Ward identity for\n  real-frequency correlation functions from the multipoint numerical\n  renormalization group","summary":"Recently, it has become possible to compute real-frequency four-point\ncorrelation functions of quantum impurity models using a multipoint extension\nof the numerical renormalization group (mpNRG). In this work, we perform\nseveral numerical consistency checks of the output of mpNRG by investigating\nexact relations between two- and four-point functions. This includes the\nBethe-Salpeter equations and the Schwinger-Dyson equation from the parquet\nformalism, which we evaluate in two formally identical but numerically\nnonequivalent ways. We also study the first-order U(1) Ward identity between\nthe vertex and the self-energy, which we derive for the first time in full\ngenerality in the real-frequency Keldysh formalism. We generally find good\nagreement of all relations, often up to a few percent, both at weak and at\nstrong interaction.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T11:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.05913v1","title":"Balancing long- and short-term dynamics for the modeling of saliency in\n  videos","summary":"The role of long- and short-term dynamics towards salient object detection in\nvideos is under-researched. We present a Transformer-based approach to learn a\njoint representation of video frames and past saliency information. Our model\nembeds long- and short-term information to detect dynamically shifting saliency\nin video. We provide our model with a stream of video frames and past saliency\nmaps, which acts as a prior for the next prediction, and extract spatiotemporal\ntokens from both modalities. The decomposition of the frame sequence into\ntokens lets the model incorporate short-term information from within the token,\nwhile being able to make long-term connections between tokens throughout the\nsequence. The core of the system consists of a dual-stream Transformer\narchitecture to process the extracted sequences independently before fusing the\ntwo modalities. Additionally, we apply a saliency-based masking scheme to the\ninput frames to learn an embedding that facilitates the recognition of\ndeviations from previous outputs. We observe that the additional prior\ninformation aids in the first detection of the salient location. Our findings\nindicate that the ratio of spatiotemporal long- and short-term features\ndirectly impacts the model's performance. While increasing the short-term\ncontext is beneficial up to a certain threshold, the model's performance\ngreatly benefits from an expansion of the long-term context.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T11:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.05926v1","title":"The Interconnection Tensor Rank and the Neural Network Storage Capacity","summary":"Neural network properties are considered in the case of the interconnection\ntensor rank being higher than two. This sort of interconnection tensor occurs\nin realization of crossbar-based neural networks. It is intrinsic for a\ncrossbar design to suffer from parasitic currents. It is shown that the\ninterconnection tensor of a certain form makes the neural network much more\nefficient: the storage capacity and basin of attraction of the network increase\nconsiderably. A network like the Hopfield one is used in the study.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,94-10,I.5.1","published":"2025-04-08T11:32:19Z"}
{"aid":"http://arxiv.org/abs/2504.05934v1","title":"Widening the Role of Group Recommender Systems with CAJO","summary":"Group Recommender Systems (GRSs) have been studied and developed for more\nthan twenty years. However, their application and usage has not grown. They can\neven be labeled as failures, if compared to the very successful and common\nrecommender systems (RSs) used on all the major ecommerce and social platforms.\nAs a result, the RSs that we all use now, are only targeted for individual\nusers, aiming at choosing an item exclusively for themselves; no choice support\nis provided to groups trying to select a service, a product, an experience, a\nperson, serving equally well all the group members. In this opinion article we\ndiscuss why the success of group recommender systems is lagging and we propose\na research program unfolding on the analysis and development of new forms of\ncollaboration between humans and intelligent systems. We define a set of roles,\nnamed CAJO, that GRSs should play in order to become more useful tools for\ngroup decision making.","main_category":"cs.IR","categories":"cs.IR,cs.HC","published":"2025-04-08T11:47:40Z"}
{"aid":"http://arxiv.org/abs/2504.05946v1","title":"InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Control","summary":"Model Predictive Control~(MPC) is a powerful control strategy widely utilized\nin domains like energy management, building control, and autonomous systems.\nHowever, its effectiveness in real-world settings is challenged by the need to\nincorporate context-specific predictions and expert instructions, which\ntraditional MPC often neglects. We propose \\IMPC, a novel framework that\naddresses this gap by integrating real-time human instructions through a Large\nLanguage Model~(LLM) to produce context-aware predictions for MPC. Our method\nemploys a Language-to-Distribution~(L2D) module to translate contextual\ninformation into predictive disturbance trajectories, which are then\nincorporated into the MPC optimization. Unlike existing context-aware and\nlanguage-based MPC models, \\IMPC enables dynamic human-LLM interaction and\nfine-tunes the L2D module in a closed loop with theoretical performance\nguarantees, achieving a regret bound of $O(\\sqrt{T\\log T})$ for linear dynamics\nwhen optimized via advanced fine-tuning methods such as Direct Preference\nOptimization~(DPO) using a tailored loss function.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T11:59:00Z"}
{"aid":"http://arxiv.org/abs/2504.05948v1","title":"Control-Oriented Modelling and Adaptive Parameter Estimation for Hybrid\n  Wind-Wave Energy Systems","summary":"Hybrid wind-wave energy system, integrating floating offshore wind turbine\nand wave energy converters, has received much attention in recent years due to\nits potential benefit in increasing the power harvest density and reducing the\nlevelized cost of electricity. Apart from the design complexities of the hybrid\nwind-wave energy systems, their energy conversion efficiency, power output\nsmoothness and their safe operations introduce new challenges for their control\nsystem designs. Recent studies show that advanced model-based control\nstrategies have the great potential to significantly improve their overall\ncontrol performance. However the performance of these advanced control\nstrategies rely on the computationally efficient control-oriented models with\nsufficient fidelity, which are normally difficult to derive due to the\ncomplexity of the hydro-, aero-dynamic effects and the couplings.In most\navailable results, the hybrid wind-wave energy system models are established by\nusing the Boundary Element Method, devoting to understanding the hydrodynamic\nresponses and performance analysis. However, such models are complex and\ninvolved relatively heavy computational burden, which cannot be directly used\nfor the advanced model-based control methods that are essential for improving\npower capture efficiency from implementing in practice. To overcome this issue,\nthis paper proposes a control-oriented model of the hybrid windwave energy\nsystem with six degrees of freedom. First, ...","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T12:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.05958v1","title":"Hybrid Control as a Proxy for Detection and Mitigation of Sensor Attacks\n  in Cooperative Driving","summary":"To enhance the robustness of cooperative driving against cyberattacks, we\npropose a hybrid controller scheme to detect and mitigate False-Data Injection\n(FDI) attacks in real-time. The core of our method builds on a given\nCooperative Adaptive Cruise Control (CACC) algorithm and exploits sensor\nredundancy to construct equivalent controllers, each driven by a distinct,\nnon-overlapping subset of sensors (equivalent controller realizations). By\nconstruction, these controller realizations generate the same control input in\nthe absence of an attack, allowing us to devise an algorithm that compares\ncontrol signals and measurements to pinpoint anomalous behavior via a majority\nvote. This allows us to: 1) decide in real-time which subset of sensors is\ncompromised; and 2) switch to a healthy subset, mitigating thus sensor FDI\nattacks. We model the latter logic as a hybrid dynamic controller that decides\nin real-time what realization to use, builds on attack-dependent flow and jump\nsets, and employs controller resets (to return the state of previously\ncompromised controller realizations to a correct value after the attack stops).\nWe demonstrate the performance of our scheme through simulation experiments.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T12:11:57Z"}
{"aid":"http://arxiv.org/abs/2504.05967v1","title":"On the Lipschitz continuity of the Spherical Cap Discrepancy around\n  generic point sets","summary":"The spherical cap discrepancy is a prominent measure of uniformity for sets\non the d-dimensional sphere. It is particularly important for estimating the\nintegration error for certain classes of functions on the sphere. Building on a\nrecently proven explicit formula for the spherical discrepancy, we show as a\nmain result of this paper that this discrepancy is Lipschitz continuous in a\nneighbourhood of so-called generic point sets (as they are typical outcomes of\nMonte-Carlo sampling). This property may have some impact (both algorithmically\nand theoretically for deriving necessary optimality conditions) on optimal\nquantization, i.e., on finding point sets of fixed size on the sphere having\nminimum spherical discrepancy.","main_category":"math.CO","categories":"math.CO,math.OC","published":"2025-04-08T12:25:30Z"}
{"aid":"http://arxiv.org/abs/2504.05970v1","title":"MLPROP -- an open interactive web interface for thermophysical property\n  prediction with machine learning","summary":"Machine learning (ML) enables the development of powerful methods for\npredicting thermophysical properties with unprecedented scope and accuracy.\nHowever, technical barriers like cumbersome implementation in established\nworkflows hinder their application in practice. With MLPROP, we provide an\ninteractive web interface for directly applying advanced ML methods to predict\nthermophysical properties without requiring ML expertise, thereby substantially\nincreasing the accessibility of novel models. MLPROP currently includes models\nfor predicting the vapor pressure of pure components (GRAPPA), activity\ncoefficients and vapor-liquid equilibria in binary mixtures (UNIFAC 2.0, mod.\nUNIFAC 2.0, and HANNA), and a routine to fit NRTL parameters to the model\npredictions. MLPROP will be continuously updated and extended and is accessible\nfree of charge via https://ml-prop.mv.rptu.de/. MLPROP removes the barrier to\nlearning and experimenting with new ML-based methods for predicting\nthermophysical properties. The source code of all models is available as open\nsource, which allows integration into existing workflows.","main_category":"cs.CE","categories":"cs.CE,cs.LG","published":"2025-04-08T12:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.05971v1","title":"Transient population dynamics of nanoparticles during pulsed EUV\n  exposures","summary":"The transient population dynamics of charged (postive or negative) and\nneutral nanoparticles have been investigated in a pulsed Extreme Ultra-Violet\n(EUV) exposure environment with 3DPIC simulations. At the initial stage of the\nsimulation, all the particles are kept neutral. As the number of EUV pulses\nincreases over time, the population of neutral particle decreases faster at the\nexpense of negatively charged particle generation outside the beam location.\nHowever, a small population (< 1%) of neutral particles become positively\ncharged due to EUV photon interaction within the beam area and remains in\nsteady state over time. The critical pulse numbers have been estimated for\ndifferent nanometer size particles above which most of the particles outside\nthe beam locations become negatively charged: smaller is the particle size,\nlarger is the critical pulse number.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-08T12:28:28Z"}
{"aid":"http://arxiv.org/abs/2504.05972v1","title":"Existence of periodic solutions for the Grushin critical problem","summary":"We study a Grushin critical problem in a strip domain which satisfies the\nperiodic boundary conditions. By applying the finite-dimensional reduction\nmethod, we construct a periodic solution when the prescribed curvature function\nis periodic. Furthermore, we also consider the Grushin critical problem in\n$\\mathbb{R}^{N} (N \\geq 5)$. Compared with Billel et al. (Differential Integral\nEquations 32: 49-90, 2019), we use the method by Guo and Yan (Math. Ann. 388:\n795-830, 2024) to construct periodic solutions under some weaker conditions,\navoiding the complicated estimates and uniqueness proof. Notably, Guo and Yan\n(Math. Ann. 388: 795-830, 2024) obtained solutions periodic with respect to\nsome of the first variables, while the solutions in this paper are periodic\nwith respect to some intermediate variables.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.05975v1","title":"A Corrector-aided Look-ahead Distance-based Guidance for Reference Path\n  Following with an Efficient Midcourse Guidance Strategy","summary":"Efficient path-following is crucial in most of the applications of autonomous\nvehicles (UxV). Among various guidance strategies presented in literature,\nlook-ahead distance ($L_1$)-based guidance method has received significant\nattention due to its ease in implementation and ability to maintain a low\ncross-track error while following simpler reference paths and generate bounded\nlateral acceleration commands. However, the constant value of $L_1$ becomes\nproblematic when the UxV is far away from the reference path and also produce\nhigher cross-track error while following complex reference paths having high\nvariation in radius of curvature. To address these challenges, the notion of\nlook-ahead distance is leveraged in a novel way to develop a two-phase guidance\nstrategy. Initially, when the UxV is far from the reference path, an optimized\n$L_1$ selection strategy is developed to guide the UxV toward the reference\npath in order to maintain minimal lateral acceleration command. Once the\nvehicle reaches a close vicinity of the reference path, a novel notion of\ncorrector point is incorporated in the constant $L_1$-based guidance scheme to\ngenerate the lateral acceleration command that effectively reduces the root\nmean square of the cross-track error thereafter. Simulation results demonstrate\nthat this proposed corrector point and look-ahead point pair-based guidance\nstrategy along with the developed midcourse guidance scheme outperforms the\nconventional constant $L_1$ guidance scheme both in terms of feasibility and\nmeasures of effectiveness like cross-track error and lateral acceleration\nrequirements.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T12:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.05994v1","title":"Quantitative Spectral Stability for the Robin Laplacian","summary":"This paper deals with eigenelements of the Laplacian in bounded domains,\nunder Robin boundary conditions, without any assumption on the sign of the\nRobin parameter. We quantify the asymptotics of the variation of simple\neigenvalues under the singular perturbation produced by removing a shrinking\nset and imposing the same Robin condition on its boundary. We also study the\nconvergence rate of the corresponding eigenfunctions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:56:55Z"}
{"aid":"http://arxiv.org/abs/2504.05995v1","title":"NativQA Framework: Enabling LLMs with Native, Local, and Everyday\n  Knowledge","summary":"The rapid advancement of large language models (LLMs) has raised concerns\nabout cultural bias, fairness, and their applicability in diverse linguistic\nand underrepresented regional contexts. To enhance and benchmark the\ncapabilities of LLMs, there is a need to develop large-scale resources focused\non multilingual, local, and cultural contexts. In this study, we propose a\nframework, NativQA, that can seamlessly construct large-scale, culturally and\nregionally aligned QA datasets in native languages. The framework utilizes\nuser-defined seed queries and leverages search engines to collect\nlocation-specific, everyday information. It has been evaluated across 39\nlocations in 24 countries and in 7 languages, ranging from extremely\nlow-resource to high-resource languages, which resulted over 300K Question\nAnswer (QA) pairs. The developed resources can be used for LLM benchmarking and\nfurther fine-tuning. The framework has been made publicly available for the\ncommunity (https://gitlab.com/nativqa/nativqa-framework).","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T13:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.06030v1","title":"NQG III -- Two-Centre Problems, Whirlpool Galaxy and Toy Neutron Stars","summary":"In the hunt for WIMPish dark matter and testing our new theory, we extend the\nresults obtained for the Kepler problem in NQG I and NQG II to the Euler\ntwo-centre problem and to other classical Hamiltonian systems with planar\nperiodic orbits. In the first case our results lead to quantum elliptical\nspirals converging to elliptical orbits where stars and other celestial bodies\ncan form as the corresponding WIMP/molecular clouds condense. The examples\ninevitably involve elliptic integrals as was the case in our earlier work on\nequatorial orbits of toy neutron stars (see Ref. [27]). Hence this is the\nexample on which we focus in this work on quantisation. The main part of our\nanalysis which leans heavily on Hamilton-Jacobi theory is applicable to any\nKLMN integrable planar periodic orbits for Hamiltonian systems. The most useful\nresults on Weierstrass elliptic functions needed in these two works we have\nsummarised with complete proofs in the appendix. This has been one of the most\nenjoyable parts of this research understanding in more detail the genius of\nWeierstrass and Jacobi. However we have to say that the beautiful simplicity of\nthe Euler two-centre results herein transcend even this as far as we are\nconcerned. At the end of the paper we see how the Burgers-Zeldovich fluid model\nrelates to our set-up through Nelson's stochastic mechanics.","main_category":"math-ph","categories":"math-ph,astro-ph.GA,math.MP","published":"2025-04-08T13:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.06053v1","title":"Characteristic exciton energy scales in antiferromagnetic NiPS$_3$","summary":"Two-dimensional antiferromagnets are promising materials for spintronics. The\nvan der Waals antiferromagnet NiPS$_3$ has attracted extensive interest due to\nits ultra-narrow exciton feature which is closely linked with the magnetic\nordering. Here, we use time-resolved terahertz spectroscopy to investigate\nphoto-excited carriers in NiPS$_3$. We identify the onset of interband\ntransitions and estimate the exciton dissociation energy from the excitation\nwavelength and fluence dependence of the transient spectral weight. Our results\nprovide key insights to quantify the exciton characteristics and validate the\nband structure for NiPS$_3$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-08T13:55:55Z"}
{"aid":"http://arxiv.org/abs/2504.06073v1","title":"A Data-constrained Magnetohydrodynamic Simulation of Successive X-class\n  Flares in Solar Active Region 13842 I. Dynamics of the Solar Eruption\n  Associated with the X7.1 Solar Flare","summary":"We investigated the initiation and the evolution of an X7.1-class solar flare\nobserved in solar active region NOAA 13842 on October 1, 2024, based on a\ndata-constrained magnetohydrodynamic (MHD) simulation. The nonlinear force-free\nfield (NLFFF) extrapolated from the photospheric magnetic field about 1 hour\nbefore the flare was used as the initial condition for the MHD simulations. The\nNLFFF reproduces highly sheared field lines that undergo tether-cutting\nreconnection in the MHD simulation, leading to the formation of a highly\ntwisted magnetic flux rope (MFR), which then erupts rapidly driven by both\ntorus instability and magnetic reconnection. This paper focuses on the dynamics\nof the MFR and its role in eruptions. We find that magnetic reconnection in the\npre-eruption phase is crucial in the subsequent eruption driven by the torus\ninstability. Furthermore, our simulation indicates that magnetic reconnection\nalso directly enhances the torus instability. These results suggest that\nmagnetic reconnection is not just a byproduct of the eruption due to\nreconnecting of post-flare arcade, but also plays a significant role in\naccelerating the MFR during the eruption.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T14:12:15Z"}
{"aid":"http://arxiv.org/abs/2504.06075v1","title":"Collaborative Prediction: Tractable Information Aggregation via\n  Agreement","summary":"We give efficient \"collaboration protocols\" through which two parties, who\nobserve different features about the same instances, can interact to arrive at\npredictions that are more accurate than either could have obtained on their\nown. The parties only need to iteratively share and update their own label\npredictions-without either party ever having to share the actual features that\nthey observe. Our protocols are efficient reductions to the problem of learning\non each party's feature space alone, and so can be used even in settings in\nwhich each party's feature space is illegible to the other-which arises in\nmodels of human/AI interaction and in multi-modal learning. The communication\nrequirements of our protocols are independent of the dimensionality of the\ndata. In an online adversarial setting we show how to give regret bounds on the\npredictions that the parties arrive at with respect to a class of benchmark\npolicies defined on the joint feature space of the two parties, despite the\nfact that neither party has access to this joint feature space. We also give\nsimpler algorithms for the same task in the batch setting in which we assume\nthat there is a fixed but unknown data distribution. We generalize our\nprotocols to a decision theoretic setting with high dimensional outcome spaces,\nwhere parties communicate only \"best response actions.\"\n  Our theorems give a computationally and statistically tractable\ngeneralization of past work on information aggregation amongst Bayesians who\nshare a common and correct prior, as part of a literature studying \"agreement\"\nin the style of Aumann's agreement theorem. Our results require no knowledge of\n(or even the existence of) a prior distribution and are computationally\nefficient. Nevertheless we show how to lift our theorems back to this classical\nBayesian setting, and in doing so, give new information aggregation theorems\nfor Bayesian agreement.","main_category":"cs.LG","categories":"cs.LG,cs.DS,cs.GT","published":"2025-04-08T14:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.06076v1","title":"$K_4^-$-free triple systems without large stars in the complement","summary":"The $n$-star $S_n$ is the $n$-vertex triple system with ${n-1 \\choose 2}$\nedges all of which contain a fixed vertex, and $K_4^-$ is the unique triple\nsystem with four vertices and three edges. We prove that the Ramsey number\n$r(K_4^-, S_n)$ has order of magnitude $n^2 /\\log n$.\n  This confirms a conjecture of Conlon, Fox, He, Suk, Verstra\\\"ete and the\nfirst author. It also generalizes the well-known bound of Kim for the graph\nRamsey number $r(3,n)$, as the link of any vertex in a $K_4^-$-free triple\nsystem is a triangle-free graph. Our method builds on the approach of Guo and\nWarnke who adapted Kim's lower bound for $r(3,n)$ to the pseudorandom setting.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T14:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.06079v1","title":"Geometric Bipartite Matching Based Exact Algorithms for Server Problems","summary":"For any given metric space, obtaining an offline optimal solution to the\nclassical $k$-server problem can be reduced to solving a minimum-cost partial\nbipartite matching between two point sets $A$ and $B$ within that metric space.\n  For $d$-dimensional $\\ell_p$ metric space, we present an $\\tilde{O}(\\min\\{nk,\nn^{2-\\frac{1}{2d+1}}\\log \\Delta\\}\\cdot \\Phi(n))$ time algorithm for solving\nthis instance of minimum-cost partial bipartite matching; here, $\\Delta$\nrepresents the spread of the point set, and $\\Phi(n)$ is the query/update time\nof a $d$-dimensional dynamic weighted nearest neighbor data structure. Our\nalgorithm improves upon prior algorithms that require at least\n$\\Omega(nk\\Phi(n))$ time. The design of minimum-cost (partial) bipartite\nmatching algorithms that make sub-quadratic queries to a weighted\nnearest-neighbor data structure, even for bounded spread instances, is a major\nopen problem in computational geometry. We resolve this problem at least for\nthe instances that are generated by the offline version of the $k$-server\nproblem.\n  Our algorithm employs a hierarchical partitioning approach, dividing the\npoints of $A\\cup B$ into rectangles. It maintains a minimum-cost partial\nmatching where any point $b \\in B$ is either matched to a point $a\\in A$ or to\nthe boundary of the rectangle it is located in. The algorithm involves\niteratively merging pairs of rectangles by erasing the shared boundary between\nthem and recomputing the minimum-cost partial matching. This continues until\nall boundaries are erased and we obtain the desired minimum-cost partial\nmatching of $A$ and $B$. We exploit geometry in our analysis to show that each\npoint participates in only $\\tilde{O}(n^{1-\\frac{1}{2d+1}}\\log \\Delta)$ number\nof augmenting paths, leading to a total execution time of\n$\\tilde{O}(n^{2-\\frac{1}{2d+1}}\\Phi(n)\\log \\Delta)$.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-08T14:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.06084v1","title":"MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From\n  Egocentric Videos","summary":"Large-scale egocentric video datasets capture diverse human activities across\na wide range of scenarios, offering rich and detailed insights into how humans\ninteract with objects, especially those that require fine-grained dexterous\ncontrol. Such complex, dexterous skills with precise controls are crucial for\nmany robotic manipulation tasks, yet are often insufficiently addressed by\ntraditional data-driven approaches to robotic manipulation. To address this\ngap, we leverage manipulation priors learned from large-scale egocentric video\ndatasets to improve policy learning for dexterous robotic manipulation tasks.\nWe present MAPLE, a novel method for dexterous robotic manipulation that\nexploits rich manipulation priors to enable efficient policy learning and\nbetter performance on diverse, complex manipulation tasks. Specifically, we\npredict hand-object contact points and detailed hand poses at the moment of\nhand-object contact and use the learned features to train policies for\ndownstream manipulation tasks. Experimental results demonstrate the\neffectiveness of MAPLE across existing simulation benchmarks, as well as a\nnewly designed set of challenging simulation tasks, which require fine-grained\nobject control and complex dexterous skills. The benefits of MAPLE are further\nhighlighted in real-world experiments using a dexterous robotic hand, whereas\nsimultaneous evaluation across both simulation and real-world experiments has\nremained underexplored in prior work.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-08T14:25:25Z"}
{"aid":"http://arxiv.org/abs/2504.06115v1","title":"In search of almost generic Calabi-Yau 3-folds","summary":"We call a projective Calabi-Yau (CY) 3-fold almost generic if it has only\nisolated nodes as singularities and the homology classes of all of the\nexceptional curves in an analytic small resolution are non-trivial but torsion.\nSuch a Calabi-Yau supports a topologically non-trivial flat B-field and the\ncorresponding A-model topological string partition function encodes a torsion\nrefinement of the Gopakumar-Vafa invariants of the smooth deformation. Our goal\nin this paper is to find new examples of almost generic CY 3-folds, using both\nconifold transitions as well as the integral structure of the periods of the\nmirrors. In this way we explicitly construct two quintic CY 3-folds with\n$\\mathbb{Z}_2$-torsion, two octics with $\\mathbb{Z}_3$-torsion and deduce the\nexistence of a complete intersection\n$X_{(6,6)}\\subset\\mathbb{P}^5_{1,1,2,2,3,3}$ with $\\mathbb{Z}_5$-torsion. Via\nmirror symmetry, the examples give new geometric interpretations to several\nAESZ Calabi-Yau operators. The mirror periods of the almost generic $X_{(6,6)}$\nwith non-trivial B-field topology are annihilated by an irrational Picard-Fuchs\noperator. We describe how the usual integral structure of the periods has to be\nmodified and in all of the cases we calculate the monodromies around the\nsingular points to verify integrality. Additional points of maximally unipotent\nmonodromy in the moduli spaces lead us to find several more examples of smooth\nor almost generic CY 3-folds and to conjecture new twisted derived\nequivalences. We integrate the holomorphic anomaly equations and extract the\ntorsion refined Gopakumar-Vafa invariants up to varying genus. For our\nconstruction of the almost generic octic CY 3-folds, we also give a short\nintroduction to the subject of hypermatrices and hyperdeterminants.","main_category":"hep-th","categories":"hep-th,math.AG","published":"2025-04-08T15:07:42Z"}
{"aid":"http://arxiv.org/abs/2504.06119v1","title":"Variational discretizations of viscous and resistive\n  magnetohydrodynamics using structure-preserving finite elements","summary":"We propose a novel structure preserving discretization for viscous and\nresistive magnetohydrodynamics. We follow the recent line of work on discrete\nleast action principle for fluid and plasma equation, incorporating the recent\nadvances to model dissipative phenomena through a generalized Lagrange-d\nAlembert constrained variational principle. We prove that our semi-discrete\nscheme is equivalent to a metriplectic system and use this property to propose\na Poisson splitting time integration. The resulting approximation preserves\nmass, energy and the divergence constraint of the magnetic field. We then show\nsome numerical results obtained with our approach. We first test our scheme on\nsimple academic test to compare the results with established methodologies, and\nthen focus specifically on the simulation of plasma instabilities, with some\ntests on non Cartesian geometries to validate our discretization in the scope\nof tokamak instabilities.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T15:12:32Z"}
{"aid":"http://arxiv.org/abs/2504.06134v1","title":"SpikeStream: Accelerating Spiking Neural Network Inference on RISC-V\n  Clusters with Sparse Computation Extensions","summary":"Spiking Neural Network (SNN) inference has a clear potential for high energy\nefficiency as computation is triggered by events. However, the inherent\nsparsity of events poses challenges for conventional computing systems, driving\nthe development of specialized neuromorphic processors, which come with high\nsilicon area costs and lack the flexibility needed for running other\ncomputational kernels, limiting widespread adoption. In this paper, we explore\nthe low-level software design, parallelization, and acceleration of SNNs on\ngeneral-purpose multicore clusters with a low-overhead RISC-V ISA extension for\nstreaming sparse computations. We propose SpikeStream, an optimization\ntechnique that maps weights accesses to affine and indirect register-mapped\nmemory streams to enhance performance, utilization, and efficiency. Our results\non the end-to-end Spiking-VGG11 model demonstrate a significant 4.39x speedup\nand an increase in utilization from 9.28% to 52.3% compared to a non-streaming\nparallel baseline. Additionally, we achieve an energy efficiency gain of 3.46x\nover LSMCore and a performance gain of 2.38x over Loihi.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-08T15:28:44Z"}
{"aid":"http://arxiv.org/abs/2504.06138v1","title":"A Multimedia Analytics Model for the Foundation Model Era","summary":"The rapid advances in Foundation Models and agentic Artificial Intelligence\nare transforming multimedia analytics by enabling richer, more sophisticated\ninteractions between humans and analytical systems. Existing conceptual models\nfor visual and multimedia analytics, however, do not adequately capture the\ncomplexity introduced by these powerful AI paradigms. To bridge this gap, we\npropose a comprehensive multimedia analytics model specifically designed for\nthe foundation model era. Building upon established frameworks from visual\nanalytics, multimedia analytics, knowledge generation, analytic task\ndefinition, mixed-initiative guidance, and human-in-the-loop reinforcement\nlearning, our model emphasizes integrated human-AI teaming based on visual\nanalytics agents from both technical and conceptual perspectives. Central to\nthe model is a seamless, yet explicitly separable, interaction channel between\nexpert users and semi-autonomous analytical processes, ensuring continuous\nalignment between user intent and AI behavior. The model addresses practical\nchallenges in sensitive domains such as intelligence analysis, investigative\njournalism, and other fields handling complex, high-stakes data. We illustrate\nthrough detailed case studies how our model facilitates deeper understanding\nand targeted improvement of multimedia analytics solutions. By explicitly\ncapturing how expert users can optimally interact with and guide AI-powered\nmultimedia analytics systems, our conceptual framework sets a clear direction\nfor system design, comparison, and future research.","main_category":"cs.MM","categories":"cs.MM,cs.AI,cs.HC","published":"2025-04-08T15:35:59Z"}
{"aid":"http://arxiv.org/abs/2504.06145v1","title":"Deploying Chatbots in Customer Service: Adoption Hurdles and Simple\n  Remedies","summary":"Despite recent advances in Artificial Intelligence, the use of chatbot\ntechnology in customer service continues to face adoption hurdles. This paper\nexplores reasons for these adoption hurdles and tests several service design\nlevers to increase chatbot uptake. We use incentivized online experiments to\nstudy chatbot uptake in a variety of scenarios. The results of these\nexperiments are threefold. First, people respond positively to improvements in\nchatbot performance; however, the chatbot channel is utilized less frequently\nthan expected-time minimization would predict. A key driver of this\nunderutilization is the reluctance to engage with a gatekeeper process, i.e., a\nprocess with an imperfect initial service stage and possible transfer to a\nsecond, expert service stage -- a behavior we term \"gatekeeper aversion\". We\nshow that gatekeeper aversion can be further amplified by a secondary hurdle,\nalgorithm aversion. Second, chatbot uptake can be increased by providing\ncustomers with average waiting times in the chatbot channel, as well as by\nbeing more transparent about chatbot capabilities and limitations. Third,\nmethodologically, we show that chatbot adoption can depend on experimental\nimplementation. In particular, chatbot adoption decreases further as (i) stakes\nare increased, (ii) the human/algorithmic nature of the server is manipulated\nwith more realism. Our results suggest that firms should continue to prioritize\ninvestments in chatbot technology. However, less expensive, process-related\ninterventions can also be effective. These may include being more transparent\nabout the types of queries that are (or are not) suitable for chatbots,\nemphasizing chatbot reliability and quick resolution times, as well as\nproviding faster live agent access to customers who experienced chatbot\nfailure.","main_category":"cs.HC","categories":"cs.HC,econ.GN,q-fin.EC,J.4","published":"2025-04-08T15:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.06166v1","title":"Assessing how hyperparameters impact Large Language Models' sarcasm\n  detection performance","summary":"Sarcasm detection is challenging for both humans and machines. This work\nexplores how model characteristics impact sarcasm detection in OpenAI's GPT,\nand Meta's Llama-2 models, given their strong natural language understanding,\nand popularity. We evaluate fine-tuned and zero-shot models across various\nsizes, releases, and hyperparameters. Experiments were conducted on the\npolitical and balanced (pol-bal) portion of the popular Self-Annotated Reddit\nCorpus (SARC2.0) sarcasm dataset. Fine-tuned performance improves monotonically\nwith model size within a model family, while hyperparameter tuning also impacts\nperformance. In the fine-tuning scenario, full precision Llama-2-13b achieves\nstate-of-the-art accuracy and $F_1$-score, both measured at 0.83, comparable to\naverage human performance. In the zero-shot setting, one GPT-4 model achieves\ncompetitive performance to prior attempts, yielding an accuracy of 0.70 and an\n$F_1$-score of 0.75. Furthermore, a model's performance may increase or decline\nwith each release, highlighting the need to reassess performance after each\nrelease.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T16:05:25Z"}
{"aid":"http://arxiv.org/abs/2504.06180v1","title":"Blockchain Oracles for Real Estate Rental","summary":"Blockchain technology has seen adoption across various industries and the\nreal estate sector is no exception. The traditional property leasing process\nguarantees no trust between parties, uses insecure communication channels, and\nforces participants who are not familiar with the process to perform contracts.\nBlockchain technology emerges as a solution to simplify the traditional\nproperty leasing process. This work proposes the use of two blockchain oracles\nto handle, respectively, maintenance issues and automate rent payments in the\ncontext of property rental. These two components are introduced in a\nblockchain-based property rental platform.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-08T16:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.06182v1","title":"Efficient algorithms to solve atom reconfiguration problems. III. The\n  bird and batching algorithms and other parallel implementations on GPUs","summary":"We present efficient implementations of atom reconfiguration algorithms for\nboth CPUs and GPUs, along with a batching routine to merge displacement\noperations for parallel execution. Leveraging graph-theoretic methods, our\napproach derives improved algorithms that achieve reduced time complexity and\nfaster operational running times. First, we introduce an enhanced version of\nthe redistribution-reconfiguration (red-rec) algorithm, which offers superior\noperational and runtime performance. We detail its efficient implementation on\na GPU using a parallel approach. Next, we present an optimized version of the\nassignment-reconfiguration-ordering (aro) algorithm, specifically tailored for\nunweighted grid graphs. Finally, we introduce the bird algorithm to solve\nreconfiguration problems on grids, achieving performance gains over both\nred-rec and aro. These algorithms can be used to prepare defect-free\nconfigurations of neutral atoms in arrays of optical traps, serve as\nsubroutines in more complex algorithms, or cross-benchmark the operational and\nruntime performance of new algorithms. They are suitable for realizing quantum\ncircuits incorporating displacement operations and are optimized for real-time\noperation on increasingly large system sizes.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T16:22:42Z"}
{"aid":"http://arxiv.org/abs/2504.06186v1","title":"Equivalence between the timelike Brunn-Minkowski inequality and timelike\n  Bakry-Ãmery-Ricci lower bound on weighted globally hyperbolic spacetimes","summary":"We prove the timelike Brunn-Minkowski inequality $\\mathsf{TBM}(K,N)$ implies\na timelike lower bound on the Bakry-\\'Emery-Ricci curvature on weighted\nglobally hyperbolic spacetimes. This result, together with the well-known\nequivalence between timelike Bakry-\\'Emery-Ricci lower bounds and the\n$\\mathsf{TCD}(K,N)$ condition, and the fact that $\\mathsf{TCD}(K,N)$ spaces\nsupport the timelike Brunn-Minkowski inequality, draws an equivalence between\n$\\mathsf{TBM}(K,N)$ and $\\mathsf{TCD}(K,N)$ in the smooth setting.","main_category":"math.MG","categories":"math.MG,gr-qc","published":"2025-04-08T16:28:07Z"}
{"aid":"http://arxiv.org/abs/2504.06194v1","title":"Positive 3-braids, Khovanov homology and Garside theory","summary":"Khovanov homology is a powerful invariant of oriented links that categorifies\nthe Jones polynomial. Nevertheless, computing Khovanov homology of a given link\nremains challenging in general with current techniques. In this work we focus\non links that are the closure of positive 3-braids. Starting with a\nclassification of conjugacy classes of 3-braids arising from the Garside\nstructure of braid groups, we compute, for any closed positive 3-braid, the\nfirst four columns (homological degree) and the three lowest rows (quantum\ndegree) of the associated Khovanov homology table. Moreover, the number of rows\nand columns we can describe increases with the infimum of the positive braid (a\nGarside theoretical notion). We will show how to increase the infimum of a\n3-braid to its maximal possible value by a conjugation, maximizing the number\nof cells in the Khovanov homology of its closure that can be determined, and\nshow that this can be done in linear time.","main_category":"math.GT","categories":"math.GT,math.AT,math.GR","published":"2025-04-08T16:35:15Z"}
{"aid":"http://arxiv.org/abs/2504.06206v1","title":"Antiferromagnetism and spin excitations in a two-dimensional\n  non-Hermitian Hatano-Nelson flux model","summary":"The one-dimensional Hatano-Nelson model with non-reciprocal hoppings is a\nprominent example of a relatively simple non-Hermitian quantum-mechanical\nsystem, which allows to study various phenomena in open quantum systems without\nadding extra gain and loss terms. Here we propose to use it as a building block\nto construct a correlated non-Hermitian Hamiltonian in two dimensions. It has\nthe characteristic form of a flux model with clock-anticlockwise non-reciprocal\nhopping on each plaquette. Adding the on-site Hubbard type interaction we\nanalyze the formation of the longe-range antiferromagnetic order and its spin\nexcitations. Such a model is non-Hermitian, but $\\mathcal{PT}$-symmetric, which\nleads to the existence of two regions: a region of unbroken $\\mathcal{PT}$\nsymmetry (real-valued spectrum) and a region of broken $\\mathcal{PT}$ symmetry\nwith exceptional lines and complex-valued energy spectrum. The transition from\none region to another is controlled by the value of the on-site interaction\nparameter and coincides with the metal-insulator transition. We also analyze\nthe spin wave spectrum, which is characterized by two diffusive d-wave type of\nmodes corresponding to gain and loss.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T16:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.06217v1","title":"Chernoff Information Bottleneck for Covert Quantum Target Sensing","summary":"Target sensing is a fundamental task with many practical applications,\ne.g.~in LiDaR and radar systems. Quantum strategies with entangled states can\nachieve better sensing accuracies with the same probe energy, yet it is often\nsimpler to use classical probes with higher energy than to take advantage of\nthe quantum regime. Recently, it has been shown that useful quantum advantage\ncan be achieved in covert situations, where sensing has to be performed while\nalso avoiding detection by an adversary: here increasing energy is not a viable\nstratagem, as it facilitates the adversary. In this paper we introduce a\ngeneral framework to assess and quantify quantum advantage in covert\nsituations. This is based on extending the information bottleneck principle,\noriginally developed for communication and machine learning applications, to\ndecision problems via the Chernoff information, with the ultimate goal of\nquantitatively optimizing the trade-off between covertness and sensing ability.\nIn this context we show how quantum resources, namely entangled photonic probes\npaired with photon counting, greatly outperform classical coherent transmitters\nin target detection and ranging, while also maintaining a chosen level of\ncovertness. Our work highlights the great potential of integrating quantum\nsensing in LiDAR systems to enhance the covert performance.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.06224v1","title":"Nonlinear Tails of Gravitational Waves in Schwarzschild Black Hole\n  Ringdown","summary":"Schwarzschild black holes evolve toward their static configuration by\nemitting gravitational waves, which decay over time following a power law at\nfixed spatial positions. We derive this power law analytically for the\nsecond-order even gravitational perturbations, demonstrating that it is\ndetermined by the fact that the second-order source decays as the inverse\nsquare of the distance. Quadratic gravitational modes with multipole $\\ell$\ndecay according to a law $\\sim t^{-2\\ell-1}$, in contrast to the linear Price\nlaw scaling $\\sim t^{-2\\ell-3}$. Consequently, nonlinear tails may persist\nlonger than their linear counterparts.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-08T17:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.06230v1","title":"Global solutions for cubic quasilinear ultrahyperbolic SchrÃ¶dinger\n  flows","summary":"In recent work, two of the authors proposed a broad global well-posedness\nconjecture for cubic quasilinear dispersive equations in two space dimensions,\nwhich asserts that global well-posedness and scattering holds for small initial\ndata in Sobolev spaces. As a first validation they proved the conjecture for\nquasilinear Schr\\\"odinger flows.\n  In the present article we expand the reach of these ideas and methods to the\ncase of quasilinear ultrahyperbolic Schr\\\"odinger flows, which is the first\nexample with a nonconvex dispersion relation.\n  The study of local well-posedness for this class of problems, in all\ndimensions, was initiated in pioneering work of Kenig-Ponce-Vega for localized\ninitial data, and then continued by Marzuola-Metcalfe-Tataru (MMT) and\nPineau-Taylor (PT) for initial data in Sobolev spaces in the elliptic and\nnon-elliptic cases, respectively.\n  Our results here mirror the earlier results in the elliptic case: (i) a new,\npotentially sharp local well-posedness result in low regularity Sobolev spaces,\none derivative below MMT and just one-half derivative above scaling, (ii) a\nsmall data global well-posedness and scattering result at the same regularity\nlevel. One key novelty in this setting is the introduction of a new family of\ninteraction Morawetz functionals which are suitable for obtaining bilinear\nestimates in the ultrahyperbolic setting. We remark that this method appears to\nbe robust enough to potentially be of use in a large data regime when the\nmetric is not a small perturbation of a Euclidean one.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T17:24:40Z"}
{"aid":"http://arxiv.org/abs/2504.06245v1","title":"Underwater Robotic Simulators Review for Autonomous System Development","summary":"The increasing complexity of underwater robotic systems has led to a surge in\nsimulation platforms designed to support perception, planning, and control\ntasks in marine environments. However, selecting the most appropriate\nunderwater robotic simulator (URS) remains a challenge due to wide variations\nin fidelity, extensibility, and task suitability. This paper presents a\ncomprehensive review and comparative analysis of five state-of-the-art,\nROS-compatible, open-source URSs: Stonefish, DAVE, HoloOcean, MARUS, and\nUNav-Sim. Each simulator is evaluated across multiple criteria including sensor\nfidelity, environmental realism, sim-to-real capabilities, and research impact.\nWe evaluate them across architectural design, sensor and physics modeling, task\ncapabilities, and research impact. Additionally, we discuss ongoing challenges\nin sim-to-real transfer and highlight the need for standardization and\nbenchmarking in the field. Our findings aim to guide practitioners in selecting\neffective simulation environments and inform future development of more robust\nand transferable URSs.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T17:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.06251v1","title":"MoirÃ© enhanced flat band in rhombohedral graphene","summary":"The fractional quantum anomalous Hall effect (FQAHE) is a fascinating\nemergent quantum state characterized by fractionally charged excitations in the\nabsence of magnetic field,which could arise from the intricate interplay\nbetween electron correlation, nontrivial topology and spontaneous time-reversal\nsymmetry breaking. Recently, FQAHE has been realized in aligned rhombohedral\npentalayer graphene on BN superlattice (aligned R5G/BN), where the topological\nflat band is modulated by the moir\\'e potential. However, intriguingly, the\nFQAHE is observed only when electrons are pushed away from the moir\\'e\ninterface. The apparently opposite implications from these experimental\nobservations, along with different theoretical models, have sparked intense\ndebates regarding the role of the moir\\'e potential. Unambiguous experimental\nobservation of the topological flat band as well as moir\\'e bands with energy\nand momentum resolved information is therefore critical to elucidate the\nunderlying mechanism. Here by performing nanospot angle-resolved photoemission\nspectroscopy (NanoARPES) measurements, we directly reveal the topological flat\nband electronic structures of R5G, from which key hopping parameters essential\nfor determining the fundamental electronic structure of rhombohedral graphene\nare extracted. Moreover, a comparison of electronic structures between aligned\nand non-aligned samples reveals that the moir\\'e potential plays a pivotal role\nin enhancing the topological flat band in the aligned sample. Our study\nprovides experimental guiding lines to narrow down the phase space of\nrhombohedral graphene, laying an important foundation for understanding exotic\nquantum phenomena in this emerging platform.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el,cond-mat.supr-con","published":"2025-04-08T17:56:35Z"}
{"aid":"http://arxiv.org/abs/2504.06255v1","title":"Diagrammatic expansion for the mutual-information rate in the realm of\n  limited statistics","summary":"Neurons in sensory systems encode stimulus information into their stochastic\nspiking response. The Mutual information has been broadly applied to these\nsystems to quantify the neurons' capacity of transmitting such information.\nYet, while for discrete stimuli, like flashed images or single tones, its\ncomputation is straightforward, for dynamical stimuli it is necessary to\ncompute a (mutual) information rate (MIR), therefore integrating over the\nmultiple temporal correlations which characterize sensory systems. Previous\nmethods are based on extensive sampling of the neuronal response, require large\namounts of data, and are therefore prone to biases and inaccuracy. Here, we\ndevelop Moba-MIRA (moment-based mutual-information-rate approximation), a\ncomputational method to estimate the mutual information rate. To derive\nMoba-MIRA, we use Feynman diagrams to expand the mutual information in\narbitrary orders in the correlations around the corresponding value for the\nempirical spike count distributions of single binss. As a result, only the\nempirical estimation of the pairwise correlations between time bins and the\nsingle-bin entropies are required, without the need for the whole joint\nprobability distributions. We tested Moba-MIRA on synthetic data generated with\ngeneralized linear models, and showed that it requires only a few tens of\nstimulus repetitions to provide an accurate estimate of the information rate.\nFinally, we applied it to ex-vivo electrophysiological recordings of rats\nretina, obtaining rates ranging between 5 to 20 bits per second, consistent\nwith earlier estimates.","main_category":"q-bio.NC","categories":"q-bio.NC,cond-mat.dis-nn","published":"2025-04-08T17:57:27Z"}
{"aid":"http://arxiv.org/abs/2504.06555v1","title":"Dihedral solutions of the set theoretical Yang-Baxter equation","summary":"We introduce the notion of a \\emph{braided dihedral set} (BDS) to describe\nset-theoretical solutions of the Yang-Baxter equation (YBE) that furnish\nrepresentations of the infinite dihedral group on the Cartesian square of the\nunderlying set. BDS which lead to representations of the symmetric group on\nthree objects are called \\emph{braided triality sets} (BTS). Basic examples of\nBDS come from symmetric spaces. We show that Latin BDS (LBDS) can be described\nentirely in terms of involutions of uniquely 2-divisible Bruck loops. We show\nthat isomorphism classes of LBDS are in one-to-one correspondence with\nconjugacy classes of involutions of uniquely 2-divisible Bruck loops. We\ndescribe all LBDS of prime, prime-square and 3 times prime-order, up to\nisomorphism. Using \\texttt{GAP}, we enumerate isomorphism classes of LBDS of\norders 27 and 81. Latin BTS, or LBTS, are shown to be in one-to-one\ncorrespondence with involutions of commutative Moufang loops of exponent 3\n(CML3), and, as with LBDS, isomorphisms classes of LBTS coincide with conjugacy\nclasses of CML3-involutions. We classify all LBTS of order at most 81.","main_category":"math.QA","categories":"math.QA","published":"2025-04-09T03:23:52Z"}
{"aid":"http://arxiv.org/abs/2504.06566v1","title":"Diffusion Factor Models: Generating High-Dimensional Returns with Factor\n  Structure","summary":"Financial scenario simulation is essential for risk management and portfolio\noptimization, yet it remains challenging especially in high-dimensional and\nsmall data settings common in finance. We propose a diffusion factor model that\nintegrates latent factor structure into generative diffusion processes,\nbridging econometrics with modern generative AI to address the challenges of\nthe curse of dimensionality and data scarcity in financial simulation. By\nexploiting the low-dimensional factor structure inherent in asset returns, we\ndecompose the score function--a key component in diffusion models--using\ntime-varying orthogonal projections, and this decomposition is incorporated\ninto the design of neural network architectures. We derive rigorous statistical\nguarantees, establishing nonasymptotic error bounds for both score estimation\nat O(d^{5/2} n^{-2/(k+5)}) and generated distribution at O(d^{5/4}\nn^{-1/2(k+5)}), primarily driven by the intrinsic factor dimension k rather\nthan the number of assets d, surpassing the dimension-dependent limits in the\nclassical nonparametric statistics literature and making the framework viable\nfor markets with thousands of assets. Numerical studies confirm superior\nperformance in latent subspace recovery under small data regimes. Empirical\nanalysis demonstrates the economic significance of our framework in\nconstructing mean-variance optimal portfolios and factor portfolios. This work\npresents the first theoretical integration of factor structure with diffusion\nmodels, offering a principled approach for high-dimensional financial\nsimulation with limited data.","main_category":"q-fin.ST","categories":"q-fin.ST,cs.LG,q-fin.MF","published":"2025-04-09T04:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.06587v1","title":"SigChord: Sniffing Wide Non-sparse Multiband Signals for Terrestrial and\n  Non-terrestrial Wireless Networks","summary":"While unencrypted information inspection in physical layer (e.g., open\nheaders) can provide deep insights for optimizing wireless networks, the\nstate-of-the-art (SOTA) methods heavily depend on full sampling rate (a.k.a\nNyquist rate), and high-cost radios, due to terrestrial and non-terrestrial\nnetworks densely occupying multiple bands across large bandwidth (e.g., from\n4G/5G at 0.4-7 GHz to LEO satellite at 4-40 GHz). To this end, we present\nSigChord, an efficient physical layer inspection system built on low-cost and\nsub-Nyquist sampling radios. We first design a deep and rule-based interleaving\nalgorithm based on Transformer network to perform spectrum sensing and signal\nrecovery under sub-Nyquist sampling rate, and second, cascade protocol\nidentifier and decoder based on Transformer neural networks to help physical\nlayer packets analysis. We implement SigChord using software-defined radio\nplatforms, and extensively evaluate it on over-the-air terrestrial and\nnon-terrestrial wireless signals. The experiments demonstrate that SigChord\ndelivers over 99% accuracy in detecting and decoding, while still decreasing\n34% sampling rate, compared with the SOTA approaches.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-09T05:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.06599v1","title":"Axionless Solution to the Strong CP Problem -- two-zeros textures of the\n  quark and lepton mass matrices and neutrino CP violation --","summary":"CP invariance is a very attractive solution to the strong CP problem in QCD.\nThis solution requires the vanishing ${\\rm arg}\\,[{\\rm det}\\, M_d\\, {\\rm det}\nM_u]$, where the $M_d$ and $M_u$ are the mass matrices for the down- and\nup-type quarks. It happens if we have several zeros in the quark mass matrices.\nWe proceed a systematic construction, in this paper, of two zeros textures for\nthe down-type quark mass matrix while the mass matrix for the up-type quarks is\nalways diagonal. We find only three types of the mass matrices can explain the\nobserved CKM matrix, the masses of the quarks and the charged leptons and the\nsmall enough vacuum angle $\\theta < 10^{-10}$. We extend the mass construction\nto the neutrino sector and derive predictions on the CP violating parameter\n$\\delta_{CP}$ in the neutrino oscillation and the mass parameter\n$m_{\\beta\\beta}$. It is extremely remarkable that the normal (NH) and inverted\n(IH) hierarchies in the neutrino masses are equally possible in the case where\nwe introduce only two right-handed neutrinos $N$s. Furthermore, we have a\nstrict prediction on the $\\delta_{CP} \\simeq 200^\\circ$ or $250^\\circ$ in the\nNH case. If it is the case we can naturally explain the positive sign of the\nbaryon asymmetry in the present universe.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T05:52:11Z"}
{"aid":"http://arxiv.org/abs/2504.06610v1","title":"Disentangle and Regularize: Sign Language Production with\n  Articulator-Based Disentanglement and Channel-Aware Regularization","summary":"In this work, we propose a simple gloss-free, transformer-based sign language\nproduction (SLP) framework that directly maps spoken-language text to sign pose\nsequences. We first train a pose autoencoder that encodes sign poses into a\ncompact latent space using an articulator-based disentanglement strategy, where\nfeatures corresponding to the face, right hand, left hand, and body are modeled\nseparately to promote structured and interpretable representation learning.\nNext, a non-autoregressive transformer decoder is trained to predict these\nlatent representations from sentence-level text embeddings. To guide this\nprocess, we apply channel-aware regularization by aligning predicted latent\ndistributions with priors extracted from the ground-truth encodings using a\nKL-divergence loss. The contribution of each channel to the loss is weighted\naccording to its associated articulator region, enabling the model to account\nfor the relative importance of different articulators during training. Our\napproach does not rely on gloss supervision or pretrained models, and achieves\nstate-of-the-art results on the PHOENIX14T dataset using only a modest training\nset.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-09T06:14:19Z"}
{"aid":"http://arxiv.org/abs/2504.06623v1","title":"The curious case of operators with spectral density increasing as\n  $Î©(E)\\sim e^{\\,\\mathrm{Const.}\\, E^2}$","summary":"Motivated by a putative model of black holes as quantum objects we consider\nwhat types of operators would have a corresponding spectrum. We find that there\nare indeed such operators, but of a rather unusual types, and for which the\nwave functions are only barely localized. We point out a tension between such\nalmost delocalized states and black holes as compact objects.","main_category":"gr-qc","categories":"gr-qc,cond-mat.stat-mech,quant-ph","published":"2025-04-09T06:44:28Z"}
{"aid":"http://arxiv.org/abs/2504.06638v1","title":"HGMamba: Enhancing 3D Human Pose Estimation with a HyperGCN-Mamba\n  Network","summary":"3D human pose lifting is a promising research area that leverages estimated\nand ground-truth 2D human pose data for training. While existing approaches\nprimarily aim to enhance the performance of estimated 2D poses, they often\nstruggle when applied to ground-truth 2D pose data. We observe that achieving\naccurate 3D pose reconstruction from ground-truth 2D poses requires precise\nmodeling of local pose structures, alongside the ability to extract robust\nglobal spatio-temporal features. To address these challenges, we propose a\nnovel Hyper-GCN and Shuffle Mamba (HGMamba) block, which processes input data\nthrough two parallel streams: Hyper-GCN and Shuffle-Mamba. The Hyper-GCN stream\nmodels the human body structure as hypergraphs with varying levels of\ngranularity to effectively capture local joint dependencies. Meanwhile, the\nShuffle Mamba stream leverages a state space model to perform spatio-temporal\nscanning across all joints, enabling the establishment of global dependencies.\nBy adaptively fusing these two representations, HGMamba achieves strong global\nfeature modeling while excelling at local structure modeling. We stack multiple\nHGMamba blocks to create three variants of our model, allowing users to select\nthe most suitable configuration based on the desired speed-accuracy trade-off.\nExtensive evaluations on the Human3.6M and MPI-INF-3DHP benchmark datasets\ndemonstrate the effectiveness of our approach. HGMamba-B achieves\nstate-of-the-art results, with P1 errors of 38.65 mm and 14.33 mm on the\nrespective datasets. Code and models are available:\nhttps://github.com/HuCui2022/HGMamba","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:28:19Z"}
{"aid":"http://arxiv.org/abs/2504.06644v1","title":"Nonlocal Quasilinear Parabolic Equations in Heisenberg Group: Local\n  Boundedness with an Optimal Tail","summary":"We prove local boundedness for a quasilinear parabolic equation on the\nHeisenberg group\n  \\[\n  \\partial_t u(\\xi,t) + \\text{p.v.}\\int_{\\mathbb{H}^N}\n\\frac{|u(\\xi,t)-u(\\eta,t)|^{p-2}(u(\\xi,t)-u(\\eta,t))}{|\\eta^{-1}\\circ\n\\xi|^{Q+sp}} \\,d\\eta = 0,\n  \\] with optimal regularity assumption on the tail term. We also prove\ninterpolation inequalities and an extension theorem for fractional Sobolev\nspaces on the Heisenberg group.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T07:33:02Z"}
{"aid":"http://arxiv.org/abs/2504.06645v1","title":"Evidence for repeating fast radio bursts association with fast\n  super-twisted magnetars","summary":"Fast radio bursts (FRBs) are bright millisecond radio events of unknown\nextra-galactic origin. Magnetars are one of the main contenders. Some sources,\nthe repeaters, produce multiple events but so far generally without the\ncharacteristic periodicity that one could associate with the spin of a neutron\nstar. We fit a geometrical model to the two main repeaters of the CHIME/FRB\ncatalogue, namely FRB 20180814A and FRB 20180916B. Assuming the bursts\noriginate from a magnetar's magnetosphere, we constrain the spin and magnetic\nparameters of the star which are encoded into burst spectro-temporal\nmorphologies. We estimate that a very strong toroidal magnetic component\ntogether with spin periods of respectively $2.3_{-0.5}^{+0.5} ~ \\rm s$ and\n$0.8_{-0.2}^{+0.1} ~ \\rm s$ best explain the data. We argue that this points\ntowards young magnetars with super-twisted magnetospheres.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T07:33:25Z"}
{"aid":"http://arxiv.org/abs/2504.06650v1","title":"ThoughtProbe: Classifier-Guided Thought Space Exploration Leveraging LLM\n  Intrinsic Reasoning","summary":"Pre-trained large language models (LLMs) have been demonstrated to possess\nintrinsic reasoning capabilities that can emerge naturally when expanding the\nresponse space. However, the neural representation mechanisms underlying these\nintrinsic capabilities and approaches for their optimal utilization remain\ninadequately understood. In this work, we make the key discovery that a simple\nlinear classifier can effectively detect intrinsic reasoning capabilities in\nLLMs' activation space, particularly within specific representation types and\nnetwork layers. Based on this finding, we propose a classifier-guided search\nframework that strategically explore a tree-structured response space. In each\nnode expansion, the classifier serves as a scoring and ranking mechanism that\nefficiently allocates computational resources by identifying and prioritizing\nmore thoughtful reasoning directions for continuation. After completing the\ntree expansion, we collect answers from all branches to form a candidate answer\npool. We propose a branch-aggregation selection method that marginalizes over\nall supporting branches by aggregating their thoughtfulness scores, thereby\nidentifying the optimal answer from the pool. Experimental results show that\nour framework's comprehensive exploration not only covers valid reasoning\nchains but also effectively identifies them, achieving significant improvements\nacross multiple arithmetic reasoning benchmarks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T07:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.06657v1","title":"When Pythagoras meets Navier-Stokes","summary":"In this article, we develop a new method, based on a time decomposition of a\nCauchy problem elaborated in [6], to retrieve the well-known $L^\\infty\n([0,T],L^2(\\mathbb{R}^d,\\mathbb{R}^d))$ control of the solution of the\nincompressible Navier-Stokes equation in $\\mathbb{R}^d$. We precisely explain\nhow the Pythagorean theorem in $L^2(\\mathbb{R}^d,\\mathbb{R}^d)$ allows to get\nthe proper energy estimate; however such an argument does not work anymore in\n$L^p(\\mathbb{R}^d,\\mathbb{R}^d)$, $p \\neq 2$. We also deduce, by similar\narguments, an already known $L^\\infty ([0,T],L^1(\\mathbb{R}^3,\\mathbb{R}^3))$\ncontrol of vorticity for $d=3$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T07:47:35Z"}
{"aid":"http://arxiv.org/abs/2504.06684v1","title":"SDHN: Skewness-Driven Hypergraph Networks for Enhanced Localized\n  Multi-Robot Coordination","summary":"Multi-Agent Reinforcement Learning is widely used for multi-robot\ncoordination, where simple graphs typically model pairwise interactions.\nHowever, such representations fail to capture higher-order collaborations,\nlimiting effectiveness in complex tasks. While hypergraph-based approaches\nenhance cooperation, existing methods often generate arbitrary hypergraph\nstructures and lack adaptability to environmental uncertainties. To address\nthese challenges, we propose the Skewness-Driven Hypergraph Network (SDHN),\nwhich employs stochastic Bernoulli hyperedges to explicitly model higher-order\nmulti-robot interactions. By introducing a skewness loss, SDHN promotes an\nefficient structure with Small-Hyperedge Dominant Hypergraph, allowing robots\nto prioritize localized synchronization while still adhering to the overall\ninformation, similar to human coordination. Extensive experiments on Moving\nAgents in Formation and Robotic Warehouse tasks validate SDHN's effectiveness,\ndemonstrating superior performance over state-of-the-art baselines.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-09T08:41:57Z"}
{"aid":"http://arxiv.org/abs/2504.06692v1","title":"SHiP experiment at the SPS Beam Dump Facility","summary":"In 2024, the SHiP experiment, together with the associated Beam Dump Facility\n(BDF) under the auspices of the High Intensity ECN3 (HI-ECN3) project, was\nselected for the future physics exploitation of the ECN3 experimental facility\nat the SPS. The SHiP experiment is a general-purpose intensity-frontier setup\ndesigned to search for physics beyond the Standard Model in the domain of\nFeebly Interacting Particles at the GeV-scale. It comprises a multi-system\napparatus that provides discovery sensitivity to both decay and scattering\nsignatures of models with feebly interacting particles, such as dark-sector\nmediators, both elastic and inelastic light dark matter, as well as\nmillicharged particles. The experiment will also be able to perform both\nStandard Model measurements and Beyond Standard Model searches with neutrino\ninteractions. In particular, it will have access to unprecedented statistics of\ntau and anti-tau neutrinos. The construction plan foresees commissioning of the\nfacility and detector, and start of operation in advance of Long Shutdown 4,\nwith a programme of exploration for 15 years of data taking. By exploring\nunique regions of parameter space for feebly interacting particles in the\nGeV/c$^2$ mass range, the SHiP experiment will complement ongoing searches at\nthe LHC and searches at future colliders.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-04-09T08:53:20Z"}
{"aid":"http://arxiv.org/abs/2504.06723v1","title":"5-dimensional minimal quadratic and bilinear forms over function fields\n  of conics","summary":"Over a field of characteristic 2, we give a complete classification of\nquadratic and bilinear forms of dimension 5 that are minimal over the function\nfield of an arbitrary conic. This completes the unique known case due to Faivre\nconcerning the classification of minimal quadratic forms of dimension 5 and\ntype (2,1) over function fields of nonsingular conics.","main_category":"math.AC","categories":"math.AC","published":"2025-04-09T09:23:45Z"}
{"aid":"http://arxiv.org/abs/2504.06751v1","title":"Visualisation of a multidimensional point cloud as a 3D swarm of avatars","summary":"The article presents an innovative approach to the visualisation of\nmultidimensional data, using icons inspired by Chernoff faces. The approach\nmerges classical projection techniques with the assignment of particular data\ndimensions to mimic features, capitalizing on the natural ability of the human\nbrain to interpret facial expressions. The technique is implemented as a plugin\nto the dpVision open-source image handling platform. The plugin allows the data\nto be interactively explored in the form of a swarm of \"totems\" whose position\nin hyperspace as well as facial features represent various aspects of the data.\nSample visualisations, based on synthetic test data as well as the vinhoverde\n15-dimensional database on Portuguese wines, confirm the usefulness of our\napproach to the analysis of complex data structures.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-09T10:14:33Z"}
{"aid":"http://arxiv.org/abs/2504.06754v1","title":"A new norm on the space of reproducing kernel Hilbert space operators\n  and Berezin number inequalities","summary":"In this note, we introduce a novel norm, termed the $t-$Berezin norm, on the\nalgebra of all bounded linear operators defined on a reproducing kernel Hilbert\nspace $\\mathcal{H}$ as\n  $$\\|A\\|_{t-ber} = \\sup_{ \\lambda, \\mu \\in \\Omega} \\left\\{ t|\\langle A\n\\hat{k}_\\lambda, \\hat{k}_\\mu \\rangle| + (1-t) |\\langle A^* \\hat{k}_\\lambda,\n\\hat{k}_\\mu \\rangle| \\right\\}, \\quad t\\in [0,1],$$\n  where $A \\in \\mathcal{B}(\\mathcal{H})$ is a bounded linear operator. This\nnorm characterizes those invertible operators which are also unitary.\n  Using this newly defined norm, we establish various upper bounds for the\nBerezin number, thereby refining the existing results. Additionally, we derive\nseveral sharp bounds for the Berezin number of an operator via the Orlicz\nfunction.","main_category":"math.FA","categories":"math.FA","published":"2025-04-09T10:18:53Z"}
{"aid":"http://arxiv.org/abs/2504.06774v1","title":"Hybrid machine learning models based on physical patterns to accelerate\n  CFD simulations: a short guide on autoregressive models","summary":"Accurate modeling of the complex dynamics of fluid flows is a fundamental\nchallenge in computational physics and engineering. This study presents an\ninnovative integration of High-Order Singular Value Decomposition (HOSVD) with\nLong Short-Term Memory (LSTM) architectures to address the complexities of\nreduced-order modeling (ROM) in fluid dynamics. HOSVD improves the\ndimensionality reduction process by preserving multidimensional structures,\nsurpassing the limitations of Singular Value Decomposition (SVD). The\nmethodology is tested across numerical and experimental data sets, including\ntwo- and three-dimensional (2D and 3D) cylinder wake flows, spanning both\nlaminar and turbulent regimes. The emphasis is also on exploring how the depth\nand complexity of LSTM architectures contribute to improving predictive\nperformance. Simpler architectures with a single dense layer effectively\ncapture the periodic dynamics, demonstrating the network's ability to model\nnon-linearities and chaotic dynamics. The addition of extra layers provides\nhigher accuracy at minimal computational cost. These additional layers enable\nthe network to expand its representational capacity, improving the prediction\naccuracy and reliability. The results demonstrate that HOSVD outperforms SVD in\nall tested scenarios, as evidenced by using different error metrics. Efficient\nmode truncation by HOSVD-based models enables the capture of complex temporal\npatterns, offering reliable predictions even in challenging, noise-influenced\ndata sets. The findings underscore the adaptability and robustness of\nHOSVD-LSTM architectures, offering a scalable framework for modeling fluid\ndynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-09T10:56:03Z"}
{"aid":"http://arxiv.org/abs/2504.06783v1","title":"Organization of Historical Oceanic Overturnings on Cross-Sphere Climate\n  Signals","summary":"The global ocean meridional overturning circulation (GMOC) is central for\nocean transport and climate variations. However, a comprehensive picture of its\nhistorical mean state and variability remains vague due to limitations in\nmodelling and observing systems. Incorporating observations into models offers\na viable approach to reconstructing climate history, yet achieving coherent\nestimates of GMOC has proven challenging due to difficulties in harmonizing\nocean stratification. Here, we demonstrate that applying multiscale data\nassimilation scheme that integrates atmospheric and oceanic observations into\nmultiple coupled models in a dynamically consistent way, the global ocean\ncurrents and GMOC over the past 80 years are retrieved. While the major\nhistoric events are printed in variability of the rebuilt GMOC, the timeseries\nof multisphere 3-dimensional physical variables representing the realistic\nhistorical evolution enable us to advance understanding of mechanisms of\nclimate signal propagation cross spheres and give birth to Artificial\nIntelligence coupled big models, thus advancing the Earth science.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-09T11:15:03Z"}
{"aid":"http://arxiv.org/abs/2504.06786v1","title":"Axion production from electron-nucleon scattering in chiral effective\n  theory","summary":"In this work we study the axion production from the electron-nucleon\nscattering, i.e., the $eN\\to e N a$ processes, being $N$ the proton and\nneutron. We simultaneously include three different types of axion interaction\ncouplings within the chiral effective field theory, namely the\naxion-nucleon-nucleon couplings $g_{aNN}$, axion-photon-photon coupling\n$g_{a\\gamma\\gamma}$ and axion-photon-vector meson resonances couplings $g_{\\rho\na\\gamma}$ and $g_{\\omega a\\gamma}$. Vast inputs from the lattice QCD and hadron\nphenomenological studies are used to fix the unknown couplings. The relative\nstrengths of different axion interactions in the $eN\\to e N a$ processes are\nthen revealed. We provide detailed predictions for the differential cross\nsections with respect to various angles and axion energy, as well as the total\ncross sections, both for the Kim-Shifman-Vainstein-Zakharov (KSVZ) and\nDine-Fischler-Srednicki-Zhitnitsky (DFSZ) axion models.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T11:19:20Z"}
{"aid":"http://arxiv.org/abs/2504.06793v1","title":"Variable Metric Splitting Methods for Neuromorphic Circuits Simulation","summary":"This paper proposes a variable metric splitting algorithm to solve the\nelectrical behavior of neuromorphic circuits made of capacitors, memristive\nelements, and batteries. The gradient property of the memristive elements is\nexploited to split the current to voltage operator as the sum of the derivative\noperator, a Riemannian gradient operator, and a nonlinear residual operator\nthat is linearized at each step of the algorithm. The diagonal structure of the\nthree operators makes the variable metric forward-backward splitting algorithm\nscalable and amenable to the simulation of large-scale neuromorphic circuits.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T11:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.06799v1","title":"Compatibility of Missing Data Handling Methods across the Stages of\n  Producing Clinical Prediction Models","summary":"Missing data is a challenge when developing, validating and deploying\nclinical prediction models (CPMs). Traditionally, decisions concerning missing\ndata handling during CPM development and validation havent accounted for\nwhether missingness is allowed at deployment. We hypothesised that the missing\ndata approach used during model development should optimise model performance\nupon deployment, whilst the approach used during model validation should yield\nunbiased predictive performance estimates upon deployment; we term this\ncompatibility. We aimed to determine which combinations of missing data\nhandling methods across the CPM life cycle are compatible. We considered\nscenarios where CPMs are intended to be deployed with missing data allowed or\nnot, and we evaluated the impact of that choice on earlier modelling decisions.\nThrough a simulation study and an empirical analysis of thoracic surgery data,\nwe compared CPMs developed and validated using combinations of complete case\nanalysis, mean imputation, single regression imputation, multiple imputation,\nand pattern sub-modelling. If planning to deploy a CPM without allowing missing\ndata, then development and validation should use multiple imputation when\nrequired. Where missingness is allowed at deployment, the same imputation\nmethod must be used during development and validation. Commonly used\ncombinations of missing data handling methods result in biased predictive\nperformance estimates.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T11:45:10Z"}
{"aid":"http://arxiv.org/abs/2504.06807v1","title":"Evaluating amyloid-beta as a surrogate endpoint in trials of\n  anti-amyloid drugs in Alzheimer's disease: a Bayesian meta-analysis","summary":"The use of amyloid-beta (A$\\beta$) clearance to support regulatory approvals\nof drugs in Alzheimer's disease (AD) remains controversial. We evaluate\nA$\\beta$ as a potential trial-level surrogate endpoint for clinical function in\nAD using a meta-analysis. Randomised controlled trials (RCTs) reporting data on\nthe effectiveness of anti- A$\\beta$ monoclonal antibodies (MABs) on A$\\beta$\nand clinical outcomes were identified through a literature review. A Bayesian\nbivariate meta-analysis was used to evaluate surrogate relationships between\nthe treatment effects on A$\\beta$ and clinical function, with the intercept,\nslope and variance quantifying the trial level association. The analysis was\nperformed using RCT data both collectively across all MABs and separately for\neach MAB through subgroup analysis. The latter analysis was extended by\napplying Bayesian hierarchical models to borrow information across treatments.\nWe identified 23 RCTs with 39 treatment contrasts for seven MABs. The\nassociation between treatment effects on A$\\beta$ and Clinical Dementia Rating\n- Sum of Boxes (CDR-SOB) across all MABs was strong: with intercept of -0.03\n(95% credible intervals: -0.16, 0.11), slope of 1.41 (0.60, 2.21) and variance\nof 0.02 (0.00, 0.05). For individual treatments, the surrogate relationships\nwere suboptimal, displaying large uncertainty. The use of hierarchical models\nconsiderably reduced the uncertainty around key parameters, narrowing the\nintervals for the slopes by an average of 71% (range: 51%-95%) and for the\nvariances by 28% (7%-65%). Our results suggest that A$\\beta$ is a potential\nsurrogate endpoint for CDR-SOB when assuming a common surrogate relationship\nacross all MABs. When allowing for information-sharing, the surrogate\nrelationships improved, but only for lecanemab and aducanumab was the\nimprovement sufficient to support a surrogate relationship.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-09T11:55:05Z"}
{"aid":"http://arxiv.org/abs/2504.06811v1","title":"Hybrid CNN with Chebyshev Polynomial Expansion for Medical Image\n  Analysis","summary":"Lung cancer remains one of the leading causes of cancer-related mortality\nworldwide, with early and accurate diagnosis playing a pivotal role in\nimproving patient outcomes. Automated detection of pulmonary nodules in\ncomputed tomography (CT) scans is a challenging task due to variability in\nnodule size, shape, texture, and location. Traditional Convolutional Neural\nNetworks (CNNs) have shown considerable promise in medical image analysis;\nhowever, their limited ability to capture fine-grained spatial-spectral\nvariations restricts their performance in complex diagnostic scenarios. In this\nstudy, we propose a novel hybrid deep learning architecture that incorporates\nChebyshev polynomial expansions into CNN layers to enhance expressive power and\nimprove the representation of underlying anatomical structures. The proposed\nChebyshev-CNN leverages the orthogonality and recursive properties of Chebyshev\npolynomials to extract high-frequency features and approximate complex\nnonlinear functions with greater fidelity. The model is trained and evaluated\non benchmark lung cancer imaging datasets, including LUNA16 and LIDC-IDRI,\nachieving superior performance in classifying pulmonary nodules as benign or\nmalignant. Quantitative results demonstrate significant improvements in\naccuracy, sensitivity, and specificity compared to traditional CNN-based\napproaches. This integration of polynomial-based spectral approximation within\ndeep learning provides a robust framework for enhancing automated medical\ndiagnostics and holds potential for broader applications in clinical decision\nsupport systems.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T12:02:56Z"}
{"aid":"http://arxiv.org/abs/2504.06814v1","title":"Revisit Gradient Descent for Geodesically Convex Optimization","summary":"In a seminal work of Zhang and Sra, gradient descent methods for geodesically\nconvex optimization were comprehensively studied. In particular, based on a\nrefined use of the triangle comparison theorem of Toponogov, Zhang and Sra\nderived a comparison inequality that relates the current iterate, the next\niterate and the optimum point. Since their seminal work, numerous follow-ups\nhave studied different downstream usages of their comparison lemma. However,\nall results along this line relies on strong assumptions, such as bounded\ndomain assumption or curvature bounded below assumption.\n  In this work, we introduce the concept of quasilinearization to optimization,\npresenting a novel framework for analyzing geodesically convex optimization. By\nleveraging this technique, we establish state-of-the-art convergence rates --\nfor both deterministic and stochastic settings -- under substantially weaker\nassumptions than previously required.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T12:08:43Z"}
{"aid":"http://arxiv.org/abs/2504.06815v1","title":"SVG-IR: Spatially-Varying Gaussian Splatting for Inverse Rendering","summary":"Reconstructing 3D assets from images, known as inverse rendering (IR),\nremains a challenging task due to its ill-posed nature. 3D Gaussian Splatting\n(3DGS) has demonstrated impressive capabilities for novel view synthesis (NVS)\ntasks. Methods apply it to relighting by separating radiance into BRDF\nparameters and lighting, yet produce inferior relighting quality with artifacts\nand unnatural indirect illumination due to the limited capability of each\nGaussian, which has constant material parameters and normal, alongside the\nabsence of physical constraints for indirect lighting. In this paper, we\npresent a novel framework called Spatially-vayring Gaussian Inverse Rendering\n(SVG-IR), aimed at enhancing both NVS and relighting quality. To this end, we\npropose a new representation-Spatially-varying Gaussian (SVG)-that allows\nper-Gaussian spatially varying parameters. This enhanced representation is\ncomplemented by a SVG splatting scheme akin to vertex/fragment shading in\ntraditional graphics pipelines. Furthermore, we integrate a physically-based\nindirect lighting model, enabling more realistic relighting. The proposed\nSVG-IR framework significantly improves rendering quality, outperforming\nstate-of-the-art NeRF-based methods by 2.5 dB in peak signal-to-noise ratio\n(PSNR) and surpassing existing Gaussian-based techniques by 3.5 dB in\nrelighting tasks, all while maintaining a real-time rendering speed.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T12:11:58Z"}
{"aid":"http://arxiv.org/abs/2504.06817v1","title":"Unparalleled instances of prolifickness, random walks, and square root\n  boundaries","summary":"We revisit the problem of influencing the sex ratio of a population by\nsubjecting reproduction of each family to some stopping rule. As an easy\nconsequence of the strong law of large numbers, no such modification is\npossible in the sense that the ratio converges to 1 almost surely, for any\nstopping rule that is finite almost surely. We proceed to quantify the effects\nand provide limit distributions for the properly rescaled sex ratio. Besides\nthe total ratio, which is predominantly considered in the pertinent literature,\nwe also analyze the average sex ratio, which may converge to values different\nfrom 1. The first part of this note is largely expository, applying classical\nresults and standard methods from the fluctuation theory of random walks. In\nthe second part we apply tail asymptotics for the time at which a random walk\nhits a one-sided square root boundary, exhibit the differences to the\ncorresponding two-sided problem, and use a limit law related to the empirical\ndispersion coefficient of a heavy-tailed distribution. Finally, we derive a\nlarge deviations result for a special stopping strategy, using saddle point\nasymptotics.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T12:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.06821v1","title":"Inducing Programmatic Skills for Agentic Tasks","summary":"To succeed in common digital tasks such as web navigation, agents must carry\nout a variety of specialized tasks such as searching for products or planning a\ntravel route. To tackle these tasks, agents can bootstrap themselves by\nlearning task-specific skills online through interaction with the web\nenvironment. In this work, we demonstrate that programs are an effective\nrepresentation for skills. We propose agent skill induction (ASI), which allows\nagents to adapt themselves by inducing, verifying, and utilizing program-based\nskills on the fly. We start with an evaluation on the WebArena agent benchmark\nand show that ASI outperforms the static baseline agent and its text-skill\ncounterpart by 23.5% and 11.3% in success rate, mainly thanks to the\nprogrammatic verification guarantee during the induction phase. ASI also\nimproves efficiency by reducing 10.7-15.3% of the steps over baselines, by\ncomposing primitive actions (e.g., click) into higher-level skills (e.g.,\nsearch product). We then highlight the efficacy of ASI in remaining efficient\nand accurate under scaled-up web activities. Finally, we examine the\ngeneralizability of induced skills when transferring between websites, and find\nthat ASI can effectively reuse common skills, while also updating incompatible\nskills to versatile website changes.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.06823v1","title":"Open Problems and a Hypothetical Path Forward in LLM Knowledge Paradigms","summary":"Knowledge is fundamental to the overall capabilities of Large Language Models\n(LLMs). The knowledge paradigm of a model, which dictates how it encodes and\nutilizes knowledge, significantly affects its performance. Despite the\ncontinuous development of LLMs under existing knowledge paradigms, issues\nwithin these frameworks continue to constrain model potential.\n  This blog post highlight three critical open problems limiting model\ncapabilities: (1) challenges in knowledge updating for LLMs, (2) the failure of\nreverse knowledge generalization (the reversal curse), and (3) conflicts in\ninternal knowledge. We review recent progress made in addressing these issues\nand discuss potential general solutions. Based on observations in these areas,\nwe propose a hypothetical paradigm based on Contextual Knowledge Scaling, and\nfurther outline implementation pathways that remain feasible within\ncontemporary techniques. Evidence suggests this approach holds potential to\naddress current shortcomings, serving as our vision for future model paradigms.\n  This blog post aims to provide researchers with a brief overview of progress\nin LLM knowledge systems, while provide inspiration for the development of\nnext-generation model architectures.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.06850v1","title":"Symmetric splitting of one-dimensional noises","summary":"A symmetric random walk $X$ whose jumps have diffuse law, looked at up to an\nindependent geometric random time, splits at the minimum into two independent\nand identically distributed pieces. The same for the maxima. It is natural to\nask, are there any other times ``adapted'' to $X$ exhibiting this ``symmetric\nsplitting'' property? It appears that the phenomenon is most conveniently\ncouched in terms of the ``noise'' structure associated to $X$. At the level of\ngenerality of the latter, an equivalent set-theoretic condition for the\nsymmetric splitting property is provided, leading to the observation that the\nanswer to the elucidated question is to the affirmative. While we do not deal\nmuch with the obvious analog of the phenomenon in continuous time, the discrete\nfindings do beg the question: does linear Brownian motion admit times of\nsymmetric splitting other than the maxima and minima? This is left unresolved,\nbut we do make some comments as to why it may be non-trivial/interesting.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T13:05:23Z"}
{"aid":"http://arxiv.org/abs/2504.06857v1","title":"Machine Learning-Assisted Unfolding for Neutrino Cross-section\n  Measurements","summary":"The choice of unfolding method for a cross-section measurement is tightly\ncoupled to the model dependence of the efficiency correction and the overall\nimpact of cross-section modeling uncertainties in the analysis. A key issue is\nthe dimensionality used in unfolding, as the kinematics of all outgoing\nparticles in an event typically affect the reconstruction performance in a\nneutrino detector. OmniFold is an unfolding method that iteratively reweights a\nsimulated dataset, using machine learning to utilize arbitrarily\nhigh-dimensional information, that has previously been applied to proton-proton\nand proton-electron datasets. This paper demonstrates OmniFold's application to\na neutrino cross-section measurement for the first time using a public T2K near\ndetector simulated dataset, comparing its performance with traditional\napproaches using a mock data study.","main_category":"hep-ex","categories":"hep-ex,hep-ph,physics.data-an","published":"2025-04-09T13:08:35Z"}
{"aid":"http://arxiv.org/abs/2504.06863v1","title":"MovSAM: A Single-image Moving Object Segmentation Framework Based on\n  Deep Thinking","summary":"Moving object segmentation plays a vital role in understanding dynamic visual\nenvironments. While existing methods rely on multi-frame image sequences to\nidentify moving objects, single-image MOS is critical for applications like\nmotion intention prediction and handling camera frame drops. However,\nsegmenting moving objects from a single image remains challenging for existing\nmethods due to the absence of temporal cues. To address this gap, we propose\nMovSAM, the first framework for single-image moving object segmentation. MovSAM\nleverages a Multimodal Large Language Model (MLLM) enhanced with\nChain-of-Thought (CoT) prompting to search the moving object and generate text\nprompts based on deep thinking for segmentation. These prompts are cross-fused\nwith visual features from the Segment Anything Model (SAM) and a\nVision-Language Model (VLM), enabling logic-driven moving object segmentation.\nThe segmentation results then undergo a deep thinking refinement loop, allowing\nMovSAM to iteratively improve its understanding of the scene context and\ninter-object relationships with logical reasoning. This innovative approach\nenables MovSAM to segment moving objects in single images by considering scene\nunderstanding. We implement MovSAM in the real world to validate its practical\napplication and effectiveness for autonomous driving scenarios where the\nmulti-frame methods fail. Furthermore, despite the inherent advantage of\nmulti-frame methods in utilizing temporal information, MovSAM achieves\nstate-of-the-art performance across public MOS benchmarks, reaching 92.5\\% on\nJ\\&F. Our implementation will be available at\nhttps://github.com/IRMVLab/MovSAM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:12:58Z"}
{"aid":"http://arxiv.org/abs/2504.06868v1","title":"Persona Dynamics: Unveiling the Impact of Personality Traits on Agents\n  in Text-Based Games","summary":"Artificial agents are increasingly central to complex interactions and\ndecision-making tasks, yet aligning their behaviors with desired human values\nremains an open challenge. In this work, we investigate how human-like\npersonality traits influence agent behavior and performance within text-based\ninteractive environments. We introduce PANDA: PersonalityAdapted Neural\nDecision Agents, a novel method for projecting human personality traits onto\nagents to guide their behavior. To induce personality in a text-based game\nagent, (i) we train a personality classifier to identify what personality type\nthe agent's actions exhibit, and (ii) we integrate the personality profiles\ndirectly into the agent's policy-learning pipeline. By deploying agents\nembodying 16 distinct personality types across 25 text-based games and\nanalyzing their trajectories, we demonstrate that an agent's action decisions\ncan be guided toward specific personality profiles. Moreover, certain\npersonality types, such as those characterized by higher levels of Openness,\ndisplay marked advantages in performance. These findings underscore the promise\nof personality-adapted agents for fostering more aligned, effective, and\nhuman-centric decision-making in interactive environments.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T13:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.06874v1","title":"Optical imaging of spontaneous electric polarizations in tetralayer\n  graphene","summary":"The recent discovery of sliding ferroelectricity has sparked intense\ninterests in studying interfacial polarizations in two-dimensional (2D) van der\nWaals materials. However, akin to the conventional ferroelectrics, the studies\nhave predominantly reported semiconducting and/or insulating moir\\'e systems\nand binary compounds. Spontaneous electric polarizations in elemental metallic\nphases remain scarcity. Here, we report the first optical imaging of intrinsic\nout-of-plane electric polarizations and domain wall (DW) sliding dynamics in\ntetralayer graphene, a 2D conductive layer composed entirely of carbon. Using\nscanning near-field optical microscopy (SNOM), we directly visualize adjacent\nABAC and ABCB stacking orders with intrinsic and opposite electric\npolarizations. Our gate-dependent SNOM measurements reveal distinct optical\nresponse that systematically changes upon carrier doping and unconventional\ninterplay between DW sliding and electric polarizations, which are supported by\ndensity functional theory (DFT) calculations. Independent corroboration through\nKelvin probe force microscopy (KPFM) and Raman spectroscopy confirms the polar\nnature and their polarization directions. Furthermore, reversible mechanical\nswitching of polar states via atomic force microscopy (AFM) tip manipulation is\nalso demonstrated. Our work establishes SNOM as a critical tool for probing\nsliding ferroelectricity in conductive 2D layers, opening avenues for exploring\nmultiferroic behaviors and nonvolatile memory applications in atomically thin\nmetals at room temperature.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T13:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.06884v1","title":"Audio-visual Event Localization on Portrait Mode Short Videos","summary":"Audio-visual event localization (AVEL) plays a critical role in multimodal\nscene understanding. While existing datasets for AVEL predominantly comprise\nlandscape-oriented long videos with clean and simple audio context, short\nvideos have become the primary format of online video content due to the the\nproliferation of smartphones. Short videos are characterized by\nportrait-oriented framing and layered audio compositions (e.g., overlapping\nsound effects, voiceovers, and music), which brings unique challenges\nunaddressed by conventional methods. To this end, we introduce AVE-PM, the\nfirst AVEL dataset specifically designed for portrait mode short videos,\ncomprising 25,335 clips that span 86 fine-grained categories with frame-level\nannotations. Beyond dataset creation, our empirical analysis shows that\nstate-of-the-art AVEL methods suffer an average 18.66% performance drop during\ncross-mode evaluation. Further analysis reveals two key challenges of different\nvideo formats: 1) spatial bias from portrait-oriented framing introduces\ndistinct domain priors, and 2) noisy audio composition compromise the\nreliability of audio modality. To address these issues, we investigate optimal\npreprocessing recipes and the impact of background music for AVEL on portrait\nmode videos. Experiments show that these methods can still benefit from\ntailored preprocessing and specialized model design, thus achieving improved\nperformance. This work provides both a foundational benchmark and actionable\ninsights for advancing AVEL research in the era of mobile-centric video\ncontent. Dataset and code will be released.","main_category":"cs.MM","categories":"cs.MM,cs.AI,cs.CV","published":"2025-04-09T13:38:40Z"}
{"aid":"http://arxiv.org/abs/2504.06900v1","title":"On PoincarÃ© constants related to isoperimetric problems in convex\n  bodies","summary":"For any convex set $\\Omega \\subset {\\mathbb R} ^N$, we provide a lower bound\nfor the inverse of the Poincar\\'e constant in $W ^ {1, 1}(\\Omega)$: it refines\nan inequality in terms of the diameter due to Acosta-Duran, via the addition of\nan extra term giving account for the flatness of the domain. In dimension $N =\n2$, we are able to make the extra term completely explicit, thus providing a\nnew Bonnesen-type inequality for the Poincar\\'e constant in terms of diameter\nand inradius. Such estimate is sharp, and it is asymptotically attained when\nthe domain is the intersection of a ball with a strip bounded by parallel\nstraight lines, symmetric about the centre of the ball. As a key intermediate\nstep, we prove that the ball maximizes the Poincar\\'e constant in $W ^ {1, 1}\n(\\Omega)$, among convex bodies $\\Omega$ of given constant width.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.06916v1","title":"Semi-Orthogonal Decompositions for Rank Two Imprimitive Reflection\n  Groups","summary":"For every imprimitive complex reflection group of rank 2, we construct a\nsemi-orthogonal decomposition of the derived category of the associated global\nquotient stack which categorifies the usual decomposition of the orbifold\ncohomology indexed by conjugacy classes. This confirms a conjecture of\nPolishchuk and Van den Bergh in these cases. This conjecture was recently also\nproved by Ishii and Nimura for arbitrary complex reflection groups of rank at\nmost 3, but our approach is very different.","main_category":"math.AG","categories":"math.AG,math.RT","published":"2025-04-09T14:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.06919v1","title":"Correcting for interloper contamination in the power spectrum with\n  neural networks","summary":"Modern slitless spectroscopic surveys, such as Euclid and the Roman Space\nTelescope, collect vast numbers of galaxy spectra but suffer from low\nsignal-to-noise ratios. This often leads to incorrect redshift assignments when\nrelying on a single emission line, due to noise spikes or contamination from\nnon-target emission lines, commonly referred to as redshift interlopers. We\npropose a machine learning approach to correct the impact of interlopers at the\nlevel of measured summary statistics, focusing on the power spectrum monopole\nand line interlopers as a proof of concept. To model interloper effects, we use\nhalo catalogs from the Quijote simulations as proxies for galaxies, displacing\na fraction of halos by the distance corresponding to the redshift offset\nbetween target and interloper galaxies. This yields contaminated catalogs with\nvarying interloper fractions across a wide range of cosmologies from the\nQuijote suite. We train a neural network on the power spectrum monopole, alone\nor combined with the bispectrum monopole, from contaminated mocks to estimate\nthe interloper fraction and reconstruct the cleaned power spectrum. We evaluate\nperformance in two settings: one with fixed cosmology and another where\ncosmological parameters vary under broad priors. In the fixed case, the network\nrecovers the interloper fraction and corrects the power spectrum to better than\n1% accuracy. When cosmology varies, performance degrades, but adding bispectrum\ninformation significantly improves results, reducing the interloper fraction\nerror by 40-60%. We also study the method's performance as a function of the\nsize of the training set and find that optimal strategies depend on the\ncorrelation between target and interloper samples: bispectrum information aids\nperformance when target and interloper galaxies are uncorrelated, while tighter\npriors are more effective when the two are strongly correlated.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-09T14:24:19Z"}
{"aid":"http://arxiv.org/abs/2504.06942v1","title":"Density Approximation of Affine Jump Diffusions via Closed-Form Moment\n  Matching","summary":"We develop a recursive approach for deriving closed-form solutions to both\nconditional and unconditional moments of affine jump diffusions with\nstate-independent jump intensities. Using these moment solutions, we construct\nclosed-form density approximations (up to a normalization constant) via moment\nmatching for both conditional and unconditional distributions. Our framework\nenables important financial applications, including efficient option pricing\nand exact simulation for affine jump diffusions. Numerical experiments\ndemonstrate the method's superior computational efficiency compared to existing\nsimulation techniques, while preserving numerical precision.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-04-09T14:50:18Z"}
{"aid":"http://arxiv.org/abs/2504.06952v1","title":"Holographic hybrid stars with slow phase transitions","summary":"The $D_3$-$D_7$ holographic model is used to describe the core of the hybrid\nstar, composed by quark matter, while its crust is modeled from a hadronic\nrelativistic mean field (RMF) model capable of reproducing low-energy nuclear\nphysics data as well as some astrophysical observations. The $D_3$-$D_7$ brane\nconfiguration and the RMF model lead to an equation of state that is used to\nsolve the Tolman-Oppenheimer-Volkoff equations. For different model parameters,\nthe mass-radius diagram is presented. The conditions for the dynamic stability\nof stellar configurations are discussed, considering the radial oscillation\ncriterion for hybrid stars with slow phase transitions. Strikingly, it is shown\nthat the models generate stable star configurations with a core of quarks. We\ncompare our results with NICER observational data for the pulsars PSR\nJ0030+0451 and PSR J0740+6620 and show that the compact stars generated from\nthis method fall within the corresponding observational regions.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-09T14:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.06956v1","title":"How does the supercritical GMC converge?","summary":"In the spirit of [M. Biskup & O. Louidor, Adv. Math. 330 (2018)], we study\nthe local structure of $\\star$-scale invariant fields -- a class of\nlog-correlated Gaussian fields -- around their extremal points by\ncharacterising the law of the \"shape\" of the field's configuration near such\npoints. As a consequence, we obtain a refined understanding of the freezing\nphenomenon in supercritical Gaussian multiplicative chaos.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-09T15:04:19Z"}
{"aid":"http://arxiv.org/abs/2504.06961v1","title":"Two by Two: Learning Multi-Task Pairwise Objects Assembly for\n  Generalizable Robot Manipulation","summary":"3D assembly tasks, such as furniture assembly and component fitting, play a\ncrucial role in daily life and represent essential capabilities for future home\nrobots. Existing benchmarks and datasets predominantly focus on assembling\ngeometric fragments or factory parts, which fall short in addressing the\ncomplexities of everyday object interactions and assemblies. To bridge this\ngap, we present 2BY2, a large-scale annotated dataset for daily pairwise\nobjects assembly, covering 18 fine-grained tasks that reflect real-life\nscenarios, such as plugging into sockets, arranging flowers in vases, and\ninserting bread into toasters. 2BY2 dataset includes 1,034 instances and 517\npairwise objects with pose and symmetry annotations, requiring approaches that\nalign geometric shapes while accounting for functional and spatial\nrelationships between objects. Leveraging the 2BY2 dataset, we propose a\ntwo-step SE(3) pose estimation method with equivariant features for assembly\nconstraints. Compared to previous shape assembly methods, our approach achieves\nstate-of-the-art performance across all 18 tasks in the 2BY2 dataset.\nAdditionally, robot experiments further validate the reliability and\ngeneralization ability of our method for complex 3D assembly tasks.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-09T15:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.06968v1","title":"Probable evidence for a transient mega-electron volt emission line in\n  the GRB 221023A","summary":"Detection of spectral line in gamma-ray bursts (GRBs) is importance for\nstudying GRB physics, as it provides insights into the composition and physical\nconditions of the GRB environment. However, progress in detecting X-ray or\ngamma-ray emission and absorption lines in GRB spectra has been relatively\nslow, only the narrow emission line feature of about 10 MeV found in GRB\n221009A has exhibited a significance exceeding $5 \\sigma$. Here, we report the\nprobable evidence of a narrow emission feature at about 2.1 mega-electron volts\n(MeV) in the spectrum of GRB 221023A. The highest statistical significance of\nthis feature is observed in the time interval between 8 and 30 seconds after\nFermi Gamma-Ray Burst Monitor trigger, with the chance probability value $<2.56\n\\times 10^{-5}$ (after accounting for the look-elsewhere effect), corresponding\nto a Gaussian-equivalent significance $> 4.20 \\sigma$. We interpret this\nfeature as being generated through the de-excitation of excited electrons in\nthe relativistic hydrogen-like high-atomic-number ions entrained in the GRB\njet.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T15:24:59Z"}
{"aid":"http://arxiv.org/abs/2504.06974v1","title":"Framelets and Wavelets with Mixed Dilation Factors","summary":"As a main research area in applied and computational harmonic analysis, the\ntheory and applications of framelets have been extensively investigated. Most\nexisting literature is devoted to framelet systems that only use one dilation\nmatrix as the sampling factor. To keep some key properties such as\ndirectionality, a framelet system often has a high redundancy rate. To reduce\nredundancy, a one-dimensional tight framelet with mixed dilation factors has\nbeen introduced for image processing. Though such tight framelets offer good\nperformance in practice, their theoretical properties are far from being well\nunderstood. In this paper, we will systematically investigate framelets with\nmixed dilation factors, with arbitrary multiplicity in arbitrary dimensions. We\nwill first study the discrete framelet transform employing a filter bank with\nmixed dilation factors and discuss its various properties. Next, we will\nintroduce the notion of a discrete affine system in $l_2(\\mathbb{Z}^d)$ and\nstudy discrete framelet transforms with mixed dilation factors. Finally, we\nwill discuss framelets and wavelets with mixed dilation factors in the space\n$L_2(\\mathbb{R}^d)$.","main_category":"math.FA","categories":"math.FA","published":"2025-04-09T15:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.06978v1","title":"Wheat3DGS: In-field 3D Reconstruction, Instance Segmentation and\n  Phenotyping of Wheat Heads with Gaussian Splatting","summary":"Automated extraction of plant morphological traits is crucial for supporting\ncrop breeding and agricultural management through high-throughput field\nphenotyping (HTFP). Solutions based on multi-view RGB images are attractive due\nto their scalability and affordability, enabling volumetric measurements that\n2D approaches cannot directly capture. While advanced methods like Neural\nRadiance Fields (NeRFs) have shown promise, their application has been limited\nto counting or extracting traits from only a few plants or organs. Furthermore,\naccurately measuring complex structures like individual wheat heads-essential\nfor studying crop yields-remains particularly challenging due to occlusions and\nthe dense arrangement of crop canopies in field conditions. The recent\ndevelopment of 3D Gaussian Splatting (3DGS) offers a promising alternative for\nHTFP due to its high-quality reconstructions and explicit point-based\nrepresentation. In this paper, we present Wheat3DGS, a novel approach that\nleverages 3DGS and the Segment Anything Model (SAM) for precise 3D instance\nsegmentation and morphological measurement of hundreds of wheat heads\nautomatically, representing the first application of 3DGS to HTFP. We validate\nthe accuracy of wheat head extraction against high-resolution laser scan data,\nobtaining per-instance mean absolute percentage errors of 15.1%, 18.3%, and\n40.2% for length, width, and volume. We provide additional comparisons to\nNeRF-based approaches and traditional Muti-View Stereo (MVS), demonstrating\nsuperior results. Our approach enables rapid, non-destructive measurements of\nkey yield-related traits at scale, with significant implications for\naccelerating crop breeding and improving our understanding of wheat\ndevelopment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:31:42Z"}
{"aid":"http://arxiv.org/abs/2504.06988v1","title":"Existence and order of the self--binding transition in non--local\n  non--linear SchrÃ¶dinger equations","summary":"We consider a class of non--linear and non--local functionals giving rise to\nthe Choquard equation with a suitably regular interaction potential, modelling,\ni.e., gases with impurities and axion stars. We study how existence of\nminimizers depends on the coupling constant, and find that there is a critical\ninteraction strength needed for the minimizers to exist, both in dimensions two\nand three. In $d=3$, a minimizer exists also at the critical coupling but none\ndo in $d=2$ under suitable assumptions on the potential. We also establish the\nexistence of non--minimizing critical points in $d=3$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T15:52:10Z"}
{"aid":"http://arxiv.org/abs/2504.07004v1","title":"Task-Based Tensor Computations on Modern GPUs","summary":"Domain-specific, fixed-function units are becoming increasingly common in\nmodern processors. As the computational demands of applications evolve, the\ncapabilities and programming interfaces of these fixed-function units continue\nto change. NVIDIA's Hopper GPU architecture contains multiple fixed-function\nunits per compute unit, including an asynchronous data movement unit (TMA) and\nan asynchronous matrix multiplication unit (Tensor Core). Efficiently utilizing\nthese units requires a fundamentally different programming style than previous\narchitectures; programmers must now develop warp-specialized kernels that\norchestrate producer-consumer pipelines between the asynchronous units. To\nmanage the complexity of programming these new architectures, we introduce\nCypress, a task-based programming model with sequential semantics. Cypress\nprograms are a set of designated functions called \\emph{tasks} that operate on\n\\emph{tensors} and are free of communication and synchronization. Cypress\nprograms are bound to the target machine through a \\emph{mapping} specification\nthat describes where tasks should run and in which memories tensors should be\nmaterialized. We present a compiler architecture that lowers Cypress programs\ninto CUDA programs that perform competitively with expert-written codes.\nCypress achieves 0.88x-1.06x the performance of cuBLAS on GEMM, and between\n0.80x-0.98x the performance of the currently best-known Flash Attention\nimplementation while eliminating all aspects of explicit data movement and\nasynchronous computation from application code.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-09T16:24:15Z"}
{"aid":"http://arxiv.org/abs/2504.07025v1","title":"Glossy Object Reconstruction with Cost-effective Polarized Acquisition","summary":"The challenge of image-based 3D reconstruction for glossy objects lies in\nseparating diffuse and specular components on glossy surfaces from captured\nimages, a task complicated by the ambiguity in discerning lighting conditions\nand material properties using RGB data alone. While state-of-the-art methods\nrely on tailored and/or high-end equipment for data acquisition, which can be\ncumbersome and time-consuming, this work introduces a scalable\npolarization-aided approach that employs cost-effective acquisition tools. By\nattaching a linear polarizer to readily available RGB cameras, multi-view\npolarization images can be captured without the need for advance calibration or\nprecise measurements of the polarizer angle, substantially reducing system\nconstruction costs. The proposed approach represents polarimetric BRDF, Stokes\nvectors, and polarization states of object surfaces as neural implicit fields.\nThese fields, combined with the polarizer angle, are retrieved by optimizing\nthe rendering loss of input polarized images. By leveraging fundamental\nphysical principles for the implicit representation of polarization rendering,\nour method demonstrates superiority over existing techniques through\nexperiments in public datasets and real captured images on both reconstruction\nand novel view synthesis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T16:38:51Z"}
{"aid":"http://arxiv.org/abs/2504.07046v1","title":"A Unified Agentic Framework for Evaluating Conditional Image Generation","summary":"Conditional image generation has gained significant attention for its ability\nto personalize content. However, the field faces challenges in developing\ntask-agnostic, reliable, and explainable evaluation metrics. This paper\nintroduces CIGEval, a unified agentic framework for comprehensive evaluation of\nconditional image generation tasks. CIGEval utilizes large multimodal models\n(LMMs) as its core, integrating a multi-functional toolbox and establishing a\nfine-grained evaluation framework. Additionally, we synthesize evaluation\ntrajectories for fine-tuning, empowering smaller LMMs to autonomously select\nappropriate tools and conduct nuanced analyses based on tool outputs.\nExperiments across seven prominent conditional image generation tasks\ndemonstrate that CIGEval (GPT-4o version) achieves a high correlation of 0.4625\nwith human assessments, closely matching the inter-annotator correlation of\n0.47. Moreover, when implemented with 7B open-source LMMs using only 2.3K\ntraining trajectories, CIGEval surpasses the previous GPT-4o-based\nstate-of-the-art method. Case studies on GPT-4o image generation highlight\nCIGEval's capability in identifying subtle issues related to subject\nconsistency and adherence to control guidance, indicating its great potential\nfor automating evaluation of image generation tasks with human-level\nreliability.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-09T17:04:14Z"}
{"aid":"http://arxiv.org/abs/2504.07049v1","title":"Harnessing non-equilibrium forces to optimize work extraction","summary":"While optimal control theory offers effective strategies for minimizing\nenergetic costs in noisy microscopic systems over finite durations, a\nsignificant opportunity lies in exploiting the temporal structure of\nnon-equilibrium forces. We demonstrate this by presenting exact analytical\nforms for the optimal protocol and the corresponding work for any driving force\nand protocol duration. We also derive a general quasistatic bound on the work,\nrelying only on the coarse-grained, time-integrated characteristics of the\napplied forces. Notably, we show that the optimal protocols often automatically\nact as information engines that harness information about non-equilibrium\nforces and an initial state measurement to extract work. These findings chart\nnew directions for designing adaptive, energy-efficient strategies in noisy,\ntime-dependent environments, as illustrated through our examples of periodic\ndriving forces and active matter systems. By exploiting the temporal structure\nof non-equilibrium forces, this largely unexplored approach holds promise for\nsubstantial performance gains in microscopic devices operating at the nano- and\nmicroscale.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-09T17:06:15Z"}
{"aid":"http://arxiv.org/abs/2504.07052v1","title":"To Backtrack or Not to Backtrack: When Sequential Search Limits Model\n  Reasoning","summary":"Recent advancements in large language models have significantly improved\ntheir reasoning abilities, particularly through techniques involving search and\nbacktracking. Backtracking naturally scales test-time compute by enabling\nsequential, linearized exploration via long chain-of-thought (CoT) generation.\nHowever, this is not the only strategy for scaling test-time compute: parallel\nsampling with best-of-n selection provides an alternative that generates\ndiverse solutions simultaneously. Despite the growing adoption of sequential\nsearch, its advantages over parallel sampling--especially under a fixed compute\nbudget remain poorly understood. In this paper, we systematically compare these\ntwo approaches on two challenging reasoning tasks: CountDown and Sudoku.\nSurprisingly, we find that sequential search underperforms parallel sampling on\nCountDown but outperforms it on Sudoku, suggesting that backtracking is not\nuniversally beneficial. We identify two factors that can cause backtracking to\ndegrade performance: (1) training on fixed search traces can lock models into\nsuboptimal strategies, and (2) explicit CoT supervision can discourage\n\"implicit\" (non-verbalized) reasoning. Extending our analysis to reinforcement\nlearning (RL), we show that models with backtracking capabilities benefit\nsignificantly from RL fine-tuning, while models without backtracking see\nlimited, mixed gains. Together, these findings challenge the assumption that\nbacktracking universally enhances LLM reasoning, instead revealing a complex\ninteraction between task structure, training data, model scale, and learning\nparadigm.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T17:12:49Z"}
{"aid":"http://arxiv.org/abs/2504.07064v1","title":"Equivariant operations in topological Hochschild homology","summary":"We observe a new equivariant relationship between topological Hochschild\nhomology and cohomology. We also calculate the topological Hochschild homology\nof the topological Hochschild cohomology of a finite prime field, which can be\nviewed as a certain ring of structured operations in this case.","main_category":"math.AT","categories":"math.AT,math.KT","published":"2025-04-09T17:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.07067v1","title":"Spin state of iron in I-42d-type Mg2SiO4 at ultra-high pressures","summary":"At extreme pressures of approximately 500 GPa, conditions characteristic of\nthe deep interiors of super-Earths, the combination of NaCl-type MgO and\npost-perovskite-type MgSiO3 (PPv) has been reported to produce a post-PPv phase\nof Mg2SiO4 with an I-42d symmetry. This post-PPv (pppv) silicate is proposed as\nthe primary mantle silicate in these massive rocky exoplanets. Understanding\nthe fundamental properties of pppv, particularly in solid solutions with\nFe2SiO4, is crucial for insights into the interior dynamics and compositions of\nsuch planets. In this study, we conduct an ab initio investigation of the\nproperties of Fe2+-bearing pppv at pressures ranging from 400 GPa to 1 TPa.\nGiven the localized nature of 3d-electrons in iron, we employ the LDA+Usc\nmethod alongside conventional DFT functionals to probe the electronic structure\nof this system. The dependence of the Hubbard parameter U on volume and spin\nstate is carefully evaluated. Furthermore, we systematically explore the\neffects of pressure, temperature, and structural variations on the spin state\nof iron in Fe2+-bearing pppv, providing valuable data to improve mantle\nmodeling for super-Earth-type exoplanets.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other","published":"2025-04-09T17:32:32Z"}
{"aid":"http://arxiv.org/abs/2504.07076v1","title":"On Fundamental Theorems of Super Invariant Theory","summary":"The purpose of this paper is to prove the First and Second Fundamental\nTheorems of invariant theory for the complex special linear supergroup and\ndiscuss the superalgebra of invariants, via the super Plucker relations.","main_category":"math.RA","categories":"math.RA","published":"2025-04-09T17:47:55Z"}
{"aid":"http://arxiv.org/abs/2504.07080v1","title":"DeduCE: Deductive Consistency as a Framework to Evaluate LLM Reasoning","summary":"Despite great performance on Olympiad-level reasoning problems, frontier\nlarge language models can still struggle on high school math when presented\nwith novel problems outside standard benchmarks. Going beyond final accuracy,\nwe propose a deductive consistency metric to analyze chain-of-thought output\nfrom language models (LMs).Formally, deductive reasoning involves two subtasks:\nunderstanding a set of input premises and inferring the conclusions that follow\nfrom them. The proposed metric studies LMs' performance on these subtasks, with\nthe goal of explaining LMs' reasoning errors on novel problems: how well do LMs\nunderstand input premises with increasing context lengths, and how well can\nthey infer conclusions over multiple reasoning hops? Since existing benchmarks\nmay be memorized, we develop a pipeline to evaluate LMs' deductive consistency\non novel, perturbed versions of benchmark problems. On novel grade school math\nproblems (GSM-8k), we find that LMs are fairly robust to increasing number of\ninput premises, but suffer significant accuracy decay as the number of\nreasoning hops is increased. Interestingly, these errors are masked in the\noriginal benchmark as all models achieve near 100% accuracy. As we increase the\nnumber of solution steps using a synthetic dataset, prediction over multiple\nhops still remains the major source of error compared to understanding input\npremises. Other factors, such as shifts in language style or natural\npropagation of early errors do not explain the trends. Our analysis provides a\nnew view to characterize LM reasoning -- as computations over a window of input\npremises and reasoning hops -- that can provide unified evaluation across\nproblem domains.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-09T17:53:55Z"}
{"aid":"http://arxiv.org/abs/2504.07085v1","title":"Identifying Unknown Stochastic Dynamics via Finite expression methods","summary":"Modeling stochastic differential equations (SDEs) is crucial for\nunderstanding complex dynamical systems in various scientific fields. Recent\nmethods often employ neural network-based models, which typically represent\nSDEs through a combination of deterministic and stochastic terms. However,\nthese models usually lack interpretability and have difficulty generalizing\nbeyond their training domain. This paper introduces the Finite Expression\nMethod (FEX), a symbolic learning approach designed to derive interpretable\nmathematical representations of the deterministic component of SDEs. For the\nstochastic component, we integrate FEX with advanced generative modeling\ntechniques to provide a comprehensive representation of SDEs. The numerical\nexperiments on linear, nonlinear, and multidimensional SDEs demonstrate that\nFEX generalizes well beyond the training domain and delivers more accurate\nlong-term predictions compared to neural network-based methods. The symbolic\nexpressions identified by FEX not only improve prediction accuracy but also\noffer valuable scientific insights into the underlying dynamics of the systems,\npaving the way for new scientific discoveries.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T17:57:54Z"}
{"aid":"http://arxiv.org/abs/2504.07086v1","title":"A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths\n  to Reproducibility","summary":"Reasoning has emerged as the next major frontier for language models (LMs),\nwith rapid advances from both academic and industrial labs. However, this\nprogress often outpaces methodological rigor, with many evaluations relying on\nbenchmarking practices that lack transparency, robustness, or statistical\ngrounding. In this work, we conduct a comprehensive empirical study and find\nthat current mathematical reasoning benchmarks are highly sensitive to subtle\nimplementation choices - including decoding parameters, random seeds, prompt\nformatting, and even hardware and software-framework configurations.\nPerformance gains reported in recent studies frequently hinge on unclear\ncomparisons or unreported sources of variance. To address these issues, we\npropose a standardized evaluation framework with clearly defined best practices\nand reporting standards. Using this framework, we reassess recent methods and\nfind that reinforcement learning (RL) approaches yield only modest improvements\n- far below prior claims - and are prone to overfitting, especially on\nsmall-scale benchmarks like AIME24. In contrast, supervised finetuning (SFT)\nmethods show consistently stronger generalization. To foster reproducibility,\nwe release all code, prompts, and model outputs, for reasoning benchmarks,\nestablishing more rigorous foundations for future work.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-09T17:58:17Z"}
{"aid":"http://arxiv.org/abs/2504.07095v1","title":"Neural Motion Simulator: Pushing the Limit of World Models in\n  Reinforcement Learning","summary":"An embodied system must not only model the patterns of the external world but\nalso understand its own motion dynamics. A motion dynamic model is essential\nfor efficient skill acquisition and effective planning. In this work, we\nintroduce the neural motion simulator (MoSim), a world model that predicts the\nfuture physical state of an embodied system based on current observations and\nactions. MoSim achieves state-of-the-art performance in physical state\nprediction and provides competitive performance across a range of downstream\ntasks. This works shows that when a world model is accurate enough and performs\nprecise long-horizon predictions, it can facilitate efficient skill acquisition\nin imagined worlds and even enable zero-shot reinforcement learning.\nFurthermore, MoSim can transform any model-free reinforcement learning (RL)\nalgorithm into a model-based approach, effectively decoupling physical\nenvironment modeling from RL algorithm development. This separation allows for\nindependent advancements in RL algorithms and world modeling, significantly\nimproving sample efficiency and enhancing generalization capabilities. Our\nfindings highlight that world models for motion dynamics is a promising\ndirection for developing more versatile and capable embodied systems.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-09T17:59:32Z"}
{"aid":"http://arxiv.org/abs/2504.07097v1","title":"Sculpting Subspaces: Constrained Full Fine-Tuning in LLMs for Continual\n  Learning","summary":"Continual learning in large language models (LLMs) is prone to catastrophic\nforgetting, where adapting to new tasks significantly degrades performance on\npreviously learned ones. Existing methods typically rely on low-rank,\nparameter-efficient updates that limit the model's expressivity and introduce\nadditional parameters per task, leading to scalability issues. To address these\nlimitations, we propose a novel continual full fine-tuning approach leveraging\nadaptive singular value decomposition (SVD). Our method dynamically identifies\ntask-specific low-rank parameter subspaces and constrains updates to be\northogonal to critical directions associated with prior tasks, thus effectively\nminimizing interference without additional parameter overhead or storing\nprevious task gradients. We evaluate our approach extensively on standard\ncontinual learning benchmarks using both encoder-decoder (T5-Large) and\ndecoder-only (LLaMA-2 7B) models, spanning diverse tasks including\nclassification, generation, and reasoning. Empirically, our method achieves\nstate-of-the-art results, up to 7% higher average accuracy than recent\nbaselines like O-LoRA, and notably maintains the model's general linguistic\ncapabilities, instruction-following accuracy, and safety throughout the\ncontinual learning process by reducing forgetting to near-negligible levels.\nOur adaptive SVD framework effectively balances model plasticity and knowledge\nretention, providing a practical, theoretically grounded, and computationally\nscalable solution for continual learning scenarios in large language models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,math.PR,stat.ML","published":"2025-04-09T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.07413v1","title":"Regression for Left-Truncated and Right-Censored Data: A Semiparametric\n  Sieve Likelihood Approach","summary":"Cohort studies of the onset of a disease often encounter left-truncation on\nthe event time of interest in addition to right-censoring due to variable\nenrollment times of study participants. Analysis of such event time data can be\nbiased if left-truncation is not handled properly. We propose a semiparametric\nsieve likelihood approach for fitting a linear regression model to data where\nthe response variable is subject to both left-truncation and right-censoring.\nWe show that the estimators of regression coefficients are consistent,\nasymptotically normal and semiparametrically efficient. Extensive simulation\nstudies show the effectiveness of the method across a wide variety of error\ndistributions. We further illustrate the method by analyzing a dataset from The\n90+ Study for aging and dementia.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T03:08:50Z"}
{"aid":"http://arxiv.org/abs/2504.07423v1","title":"Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based\n  Clinical Decision Support","summary":"As AI-based clinical decision support (AI-CDS) is introduced in more and more\naspects of healthcare services, HCI research plays an increasingly important\nrole in designing for complementarity between AI and clinicians. However,\ncurrent evaluations of AI-CDS often fail to capture when AI is and is not\nuseful to clinicians. This position paper reflects on our work and influential\nAI-CDS literature to advocate for moving beyond evaluation metrics like Trust,\nReliance, Acceptance, and Performance on the AI's task (what we term the \"trap\"\nof human-AI collaboration). Although these metrics can be meaningful in some\nsimple scenarios, we argue that optimizing for them ignores important ways that\nAI falls short of clinical benefit, as well as ways that clinicians\nsuccessfully use AI. As the fields of HCI and AI in healthcare develop new ways\nto design and evaluate CDS tools, we call on the community to prioritize\necologically valid, domain-appropriate study setups that measure the emergent\nforms of value that AI can bring to healthcare professionals.","main_category":"cs.HC","categories":"cs.HC,cs.AI,q-bio.OT","published":"2025-04-10T03:28:56Z"}
{"aid":"http://arxiv.org/abs/2504.07426v1","title":"Conditional Data Synthesis Augmentation","summary":"Reliable machine learning and statistical analysis rely on diverse,\nwell-distributed training data. However, real-world datasets are often limited\nin size and exhibit underrepresentation across key subpopulations, leading to\nbiased predictions and reduced performance, particularly in supervised tasks\nsuch as classification. To address these challenges, we propose Conditional\nData Synthesis Augmentation (CoDSA), a novel framework that leverages\ngenerative models, such as diffusion models, to synthesize high-fidelity data\nfor improving model performance across multimodal domains including tabular,\ntextual, and image data. CoDSA generates synthetic samples that faithfully\ncapture the conditional distributions of the original data, with a focus on\nunder-sampled or high-interest regions. Through transfer learning, CoDSA\nfine-tunes pre-trained generative models to enhance the realism of synthetic\ndata and increase sample density in sparse areas. This process preserves\ninter-modal relationships, mitigates data imbalance, improves domain\nadaptation, and boosts generalization. We also introduce a theoretical\nframework that quantifies the statistical accuracy improvements enabled by\nCoDSA as a function of synthetic sample volume and targeted region allocation,\nproviding formal guarantees of its effectiveness. Extensive experiments\ndemonstrate that CoDSA consistently outperforms non-adaptive augmentation\nstrategies and state-of-the-art baselines in both supervised and unsupervised\nsettings.","main_category":"stat.ME","categories":"stat.ME,cs.LG","published":"2025-04-10T03:38:11Z"}
{"aid":"http://arxiv.org/abs/2504.07447v1","title":"Exact Quantification of Bipartite Entanglement in Unresolvable Spin\n  Ensembles","summary":"Quantifying mixed-state entanglement in many-body systems has been a\nformidable task. In this work, we quantify the entanglement of states in\nunresolvable spin ensembles, which are inherently mixed. By exploiting their\npermutationally invariant properties, we show that the bipartite entanglement\nof a wide range of unresolvable ensemble states can be calculated exactly. Our\nformalism is versatile; it can be used to evaluate the entanglement in an\nensemble with an arbitrary number of particles, effective angular momentum, and\nbipartition. We apply our method to explore the characteristics of entanglement\nin different physically motivated scenarios, including states with definite\nmagnetization and metrologically useful superpositions such as\nGreenberger-Horne-Zeilinger (GHZ) states and spin-squeezed states. Our method\ncan help understand the role of entanglement in spin-ensemble-based quantum\ntechnologies.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T04:35:05Z"}
{"aid":"http://arxiv.org/abs/2504.07449v1","title":"Polarization Angle Orthogonal Jumps in Fast Radio Bursts","summary":"Recently, polarization angle (PA) orthogonal jumps over millisecond timescale\nwere discovered from three bursts of a repeating fast radio burst source FRB\n20201124A by the FAST telescope. We investigate the physical implications of\nthis phenomenon. In general, PA jumps can arise from the superposition of two\nelectromagnetic waves, either coherently or incoherently, as the dominance of\nthe two orthogonal modes switches. In the coherent case, PA jumps occur when\nlinear polarization reaches a minimum and circular polarization peaks, with the\ntotal polarization degree conserved. However, incoherent superposition can lead\nto depolarization. The observations seem to be more consistent with incoherent\nsuperposition. The amplitudes of the two orthogonal modes are required to be\ncomparable when jumps occur, placing constraints on the intrinsic radiation\nmechanisms. We provide general constraints on FRB emission and propagation\nmechanisms based on the data. Physically, it is difficult to produce PA jumps\nby generating two orthogonal modes within millisecond timescales, and a\ngeometric effect due to sweeping line-of-sight is a more plausible reason. This\nrequires the emission region to be within the magnetosphere of a spinning\ncentral engine, likely a magnetar. The two orthogonal modes may be produced by\nintrinsic radiation mechanisms or Alfv\\'en-O-mode transition. Plasma\nbirefringence is not easy to achieve when the plasma is moving\nrelativistically. Curvature radiation predicts $|E_{\\rm X}/E_{\\rm O}|\\gtrsim1$,\nand is difficult to produce jumps; whereas inverse Compton scattering can\nachieve the transition amplitude ratio $|E_{\\rm X}/E_{\\rm O}|=1$ to allow jumps\nto occur under special geometric configurations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T04:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.07451v1","title":"Continuity conditions weaker than lower semi-continuity","summary":"Lower semi-continuity (\\texttt{LSC}) is a critical assumption in many\nfoundational optimisation theory results; however, in many cases, \\texttt{LSC}\nis stronger than necessary. This has led to the introduction of numerous weaker\ncontinuity conditions that enable more general theorem statements. In the\ncontext of unstructured optimization over topological domains, we collect these\ncontinuity conditions from disparate sources and review their applications. As\nprimary outcomes, we prove two comprehensive implication diagrams that\nestablish novel connections between the reviewed conditions. In doing so, we\nalso introduce previously missing continuity conditions and provide new\ncounterexamples.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T04:53:32Z"}
{"aid":"http://arxiv.org/abs/2504.07474v1","title":"Dynamical quantum phase transition, metastable state, and dimensionality\n  reduction: Krylov analysis of fully-connected spin models","summary":"We study quenched dynamics of fully-connected spin models. The system is\nprepared in a ground state of the initial Hamiltonian and the Hamiltonian is\nsuddenly changed to a different form. We apply the Krylov subspace method to\nmap the system onto an effective tridiagonal Hamiltonian. The state is confined\nin a potential well and is time-evolved by nonuniform hoppings. The dynamical\nsingularities for the survival probability can occur when the state is\nreflected from a potential barrier. Although we do not observe any singularity\nin the spread complexity, we find that the entropy exhibits small dips at the\nsingular times. We find that the presence of metastable state affects long-time\nbehavior of the spread complexity, and physical observables. We also observe a\nreduction of the state-space dimension when the Hamiltonian reduces to a\nclassical form.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-10T05:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.07476v1","title":"CMEdataset Advancing China Map Detection and Standardization with\n  Digital Image Resources","summary":"Digital images of Chinas maps play a crucial role in map detection,\nparticularly in ensuring national sovereignty, territorial integrity, and map\ncompliance. However, there is currently no publicly available dataset\nspecifically dedicated to problematic maps the CME dataset. Existing datasets\nprimarily focus on general map data and are insufficient for effectively\nidentifying complex issues such as national boundary misrepresentations,\nmissing elements, and blurred boundaries. Therefore, this study creates a\nProblematic Map dataset that covers five key problem areas, aiming to provide\ndiverse samples for problematic map detection technologies, support\nhigh-precision map compliance detection, and enhance map data quality and\ntimeliness. This dataset not only provides essential resources for map\ncompliance, national security monitoring, and map updates, but also fosters\ninnovation and application of related technologies.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T06:04:16Z"}
{"aid":"http://arxiv.org/abs/2504.07517v1","title":"Gravitational wave signals from primordial black holes orbiting\n  solar-type stars","summary":"Primordial black holes (PBHs) with masses between $10^{14}$ and $10^{20}$ kg\nare candidates to contribute a substantial fraction of the total dark matter\nabundance. When in orbit around the center of a star, which can possibly be a\ncompletely interior orbit, such objects would emit gravitational waves, as\npredicted by general relativity. In this work, we examine the gravitational\nwave signals emitted by such objects when they orbit typical stars, such as the\nSun. We show that the magnitude of the waves that could eventually be detected\non Earth from a possible PBH orbiting the Sun or a neighboring Sun-like star\nwithin our galaxy can be significantly stronger than those originating from a\nPBH orbiting a denser but more distant neutron star (NS). Such signals may be\ndetectable by the LISA gravitational-wave detector. In addition, we estimate\nthe contribution that a large collection of such PBH-star systems would make to\nthe stochastic gravitational-wave background (SGWB) within a range of\nfrequencies to which pulsar timing arrays are sensitive.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.HE,astro-ph.SR","published":"2025-04-10T07:25:26Z"}
{"aid":"http://arxiv.org/abs/2504.07534v1","title":"Convex spacelike hypersurface of constant curvature with boundary on a\n  hyperboloid","summary":"We consider convex, spacelike hypersurfaces with boundaries on some\nhyperboloid (or lightcone) in the Minkowski space. If the hypersurface has\nconstant higher order mean curvature, and the angle between the normal vectors\nof the hypersurface and the hyperboloid (or the lightcone) is constant on the\nboundary, then the hypersurface must be a part of another hyperboloid.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T08:00:55Z"}
{"aid":"http://arxiv.org/abs/2504.07539v1","title":"$C$ and $CP$ violation in effective field theories and applications to\n  $Î·$-meson decays","summary":"The quest for sources of the simultaneous violation of $C$ and $CP$ symmetry\nwas popular in the 1960s, but has since been neglected for a long time. We\nrevisit the operators that break $C$ and $CP$ for flavor-conserving transitions\nin both the Standard Model effective field theory and the low-energy effective\nfield theory, which subsequently can be matched to light-meson physics using\nchiral perturbation theory. As applications, we discuss in particular the\n$C$-odd Dalitz plot asymmetries in $\\eta\\to3\\pi$, but also decays with dilepton\npairs in the final state, such as long-distance contributions to the rare\nsemileptonic decays $\\eta\\to\\pi^0\\ell^+\\ell^-$ as well as asymmetries in\n$\\eta^{(\\prime)} \\to \\gamma \\ell^+\\ell^-$ and $\\eta^{(\\prime)} \\to\n\\pi^+\\pi^-\\ell^+\\ell^-$.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-10T08:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.07547v1","title":"Strategic learning for disturbance rejection in multi-agent systems:\n  Nash and Minmax in graphical games","summary":"This article investigates the optimal control problem with disturbance\nrejection for discrete-time multi-agent systems under cooperative and\nnon-cooperative graphical games frameworks. Given the practical challenges of\nobtaining accurate models, Q-function-based policy iteration methods are\nproposed to seek the Nash equilibrium solution for the cooperative graphical\ngame and the distributed minmax solution for the non-cooperative graphical\ngame. To implement these methods online, two reinforcement learning frameworks\nare developed, an actor-disturber-critic structure for the cooperative\ngraphical game and an actor-adversary-disturber-critic structure for the\nnon-cooperative graphical game. The stability of the proposed methods is\nrigorously analyzed, and simulation results are provided to illustrate the\neffectiveness of the proposed methods.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T08:22:33Z"}
{"aid":"http://arxiv.org/abs/2504.07554v1","title":"Efficient Swept Volume-Based Trajectory Generation for Arbitrary-Shaped\n  Ground Robot Navigation","summary":"Navigating an arbitrary-shaped ground robot safely in cluttered environments\nremains a challenging problem. The existing trajectory planners that account\nfor the robot's physical geometry severely suffer from the intractable runtime.\nTo achieve both computational efficiency and Continuous Collision Avoidance\n(CCA) of arbitrary-shaped ground robot planning, we proposed a novel\ncoarse-to-fine navigation framework that significantly accelerates planning. In\nthe first stage, a sampling-based method selectively generates distinct\ntopological paths that guarantee a minimum inflated margin. In the second\nstage, a geometry-aware front-end strategy is designed to discretize these\ntopologies into full-state robot motion sequences while concurrently\npartitioning the paths into SE(2) sub-problems and simpler R2 sub-problems for\nback-end optimization. In the final stage, an SVSDF-based optimizer generates\ntrajectories tailored to these sub-problems and seamlessly splices them into a\ncontinuous final motion plan. Extensive benchmark comparisons show that the\nproposed method is one to several orders of magnitude faster than the\ncutting-edge methods in runtime while maintaining a high planning success rate\nand ensuring CCA.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T08:34:34Z"}
{"aid":"http://arxiv.org/abs/2504.07556v1","title":"TokenFocus-VQA: Enhancing Text-to-Image Alignment with Position-Aware\n  Focus and Multi-Perspective Aggregations on LVLMs","summary":"While text-to-image (T2I) generation models have achieved remarkable progress\nin recent years, existing evaluation methodologies for vision-language\nalignment still struggle with the fine-grained semantic matching. Current\napproaches based on global similarity metrics often overlook critical\ntoken-level correspondences between textual descriptions and visual content. To\nthis end, we present TokenFocus-VQA, a novel evaluation framework that\nleverages Large Vision-Language Models (LVLMs) through visual question\nanswering (VQA) paradigm with position-specific probability optimization. Our\nkey innovation lies in designing a token-aware loss function that selectively\nfocuses on probability distributions at pre-defined vocabulary positions\ncorresponding to crucial semantic elements, enabling precise measurement of\nfine-grained semantical alignment. The proposed framework further integrates\nensemble learning techniques to aggregate multi-perspective assessments from\ndiverse LVLMs architectures, thereby achieving further performance enhancement.\nEvaluated on the NTIRE 2025 T2I Quality Assessment Challenge Track 1, our\nTokenFocus-VQA ranks 2nd place (0.8445, only 0.0001 lower than the 1st method)\non public evaluation and 2nd place (0.8426) on the official private test set,\ndemonstrating superiority in capturing nuanced text-image correspondences\ncompared to conventional evaluation methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T08:37:13Z"}
{"aid":"http://arxiv.org/abs/2504.07582v1","title":"Nanodiamond quantum thermometry assisted with machine learning","summary":"Nanodiamonds (NDs) are quantum sensors that enable local temperature\nmeasurements, taking advantage of their small size. Though the model based\nanalysis methods have been used for ND quantum thermometry, their accuracy has\nyet to be thoroughly investigated. Here, we apply model-free machine learning\nwith the Gaussian process regression (GPR) to ND quantum thermometry and\ncompare its capabilities with the existing methods. We prove that GPR provides\nmore robust results than them, even for a small number of data points and\nregardless of the data acquisition methods. This study extends the range of\napplications of ND quantum thermometry with machine learning.","main_category":"quant-ph","categories":"quant-ph,physics.app-ph","published":"2025-04-10T09:24:10Z"}
{"aid":"http://arxiv.org/abs/2504.07596v1","title":"Boosting Universal LLM Reward Design through the Heuristic Reward\n  Observation Space Evolution","summary":"Large Language Models (LLMs) are emerging as promising tools for automated\nreinforcement learning (RL) reward design, owing to their robust capabilities\nin commonsense reasoning and code generation. By engaging in dialogues with RL\nagents, LLMs construct a Reward Observation Space (ROS) by selecting relevant\nenvironment states and defining their internal operations. However, existing\nframeworks have not effectively leveraged historical exploration data or manual\ntask descriptions to iteratively evolve this space. In this paper, we propose a\nnovel heuristic framework that enhances LLM-driven reward design by evolving\nthe ROS through a table-based exploration caching mechanism and a text-code\nreconciliation strategy. Our framework introduces a state execution table,\nwhich tracks the historical usage and success rates of environment states,\novercoming the Markovian constraint typically found in LLM dialogues and\nfacilitating more effective exploration. Furthermore, we reconcile\nuser-provided task descriptions with expert-defined success criteria using\nstructured prompts, ensuring alignment in reward design objectives.\nComprehensive evaluations on benchmark RL tasks demonstrate the effectiveness\nand stability of the proposed framework. Code and video demos are available at\njingjjjjjie.github.io/LLM2Reward.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T09:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.07604v1","title":"Fourier multipliers and their applications to PDE on the quantum\n  Euclidean space","summary":"In this work, we present some applications of the $L^p$-$L^q$ boundedness of\nFourier multipliers to PDEs on the noncommutative (or quantum) Euclidean space.\nMore precisely, we establish $L^p$-$L^q$ norm estimates for solutions of heat,\nwave, and Schr\\\"odinger type equations with Caputo fractional derivative in the\ncase $1 < p \\leq 2 \\leq q < \\infty.$ Moreover, we obtain well-posedness of\nnonlinear heat and wave equations on the noncommutative Euclidean space.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T09:55:19Z"}
{"aid":"http://arxiv.org/abs/2504.07612v1","title":"SaRoHead: A Dataset for Satire Detection in Romanian Multi-Domain News\n  Headlines","summary":"The headline is an important part of a news article, influenced by\nexpressiveness and connection to the exposed subject. Although most news\noutlets aim to present reality objectively, some publications prefer a humorous\napproach in which stylistic elements of satire, irony, and sarcasm blend to\ncover specific topics. Satire detection can be difficult because a headline\naims to expose the main idea behind a news article. In this paper, we propose\nSaRoHead, the first corpus for satire detection in Romanian multi-domain news\nheadlines. Our findings show that the clickbait used in some non-satirical\nheadlines significantly influences the model.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T10:03:29Z"}
{"aid":"http://arxiv.org/abs/2504.07625v1","title":"Deep Learning Meets Teleconnections: Improving S2S Predictions for\n  European Winter Weather","summary":"Predictions on subseasonal-to-seasonal (S2S) timescales--ranging from two\nweeks to two month--are crucial for early warning systems but remain\nchallenging owing to chaos in the climate system. Teleconnections, such as the\nstratospheric polar vortex (SPV) and Madden-Julian Oscillation (MJO), offer\nwindows of enhanced predictability, however, their complex interactions remain\nunderutilized in operational forecasting. Here, we developed and evaluated deep\nlearning architectures to predict North Atlantic-European (NAE) weather\nregimes, systematically assessing the role of remote drivers in improving S2S\nforecast skill of deep learning models. We implemented (1) a Long Short-term\nMemory (LSTM) network predicting the NAE regimes of the next six weeks based on\nprevious regimes, (2) an Index-LSTM incorporating SPV and MJO indices, and (3)\na ViT-LSTM using a Vision Transformer to directly encode stratospheric wind and\ntropical outgoing longwave radiation fields. These models are compared with\noperational hindcasts as well as other AI models. Our results show that\nleveraging teleconnection information enhances skill at longer lead times.\nNotably, the ViT-LSTM outperforms ECMWF's subseasonal hindcasts beyond week 4\nby improving Scandinavian Blocking (SB) and Atlantic Ridge (AR) predictions.\nAnalysis of high-confidence predictions reveals that NAO-, SB, and AR\nopportunity forecasts can be associated with SPV variability and MJO phase\npatterns aligning with established pathways, also indicating new patterns.\nOverall, our work demonstrates that encoding physically meaningful climate\nfields can enhance S2S prediction skill, advancing AI-driven subseasonal\nforecast. Moreover, the experiments highlight the potential of deep learning\nmethods as investigative tools, providing new insights into atmospheric\ndynamics and predictability.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T10:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.07633v1","title":"Kernel Logistic Regression Learning for High-Capacity Hopfield Networks","summary":"Hebbian learning limits Hopfield network storage capacity (pattern-to-neuron\nratio around 0.14). We propose Kernel Logistic Regression (KLR) learning.\nUnlike linear methods, KLR uses kernels to implicitly map patterns to\nhigh-dimensional feature space, enhancing separability. By learning dual\nvariables, KLR dramatically improves storage capacity, achieving perfect recall\neven when pattern numbers exceed neuron numbers (up to ratio 1.5 shown), and\nenhances noise robustness. KLR demonstrably outperforms Hebbian and linear\nlogistic regression approaches.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-10T10:27:43Z"}
{"aid":"http://arxiv.org/abs/2504.07636v1","title":"Rational concordance of double twist knots","summary":"Double twist knots $K_{m, n}$ are known to be rationally slice if $mn = 0$,\n$n = -m\\pm 1$, or $n = -m$. In this paper, we prove the converse. It is done by\nshowing that infinitely many prime power-fold cyclic branched covers of the\nother cases do not bound a rational ball. Our rational ball obstruction is\nbased on Donaldson's diagonalization theorem.","main_category":"math.GT","categories":"math.GT","published":"2025-04-10T10:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.07646v1","title":"On the Temporal Question-Answering Capabilities of Large Language Models\n  Over Anonymized Data","summary":"The applicability of Large Language Models (LLMs) in temporal reasoning tasks\nover data that is not present during training is still a field that remains to\nbe explored. In this paper we work on this topic, focusing on structured and\nsemi-structured anonymized data. We not only develop a direct LLM pipeline, but\nalso compare various methodologies and conduct an in-depth analysis. We\nidentified and examined seventeen common temporal reasoning tasks in natural\nlanguage, focusing on their algorithmic components. To assess LLM performance,\nwe created the \\textit{Reasoning and Answering Temporal Ability} dataset\n(RATA), featuring semi-structured anonymized data to ensure reliance on\nreasoning rather than on prior knowledge. We compared several methodologies,\ninvolving SoTA techniques such as Tree-of-Thought, self-reflexion and code\nexecution, tuned specifically for this scenario. Our results suggest that\nachieving scalable and reliable solutions requires more than just standalone\nLLMs, highlighting the need for integrated approaches.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-10T10:48:42Z"}
{"aid":"http://arxiv.org/abs/2504.07655v1","title":"Synthesizing High-Quality Programming Tasks with LLM-based Expert and\n  Student Agents","summary":"Generative AI is transforming computing education by enabling the automatic\ngeneration of personalized content and feedback. We investigate its\ncapabilities in providing high-quality programming tasks to students. Despite\npromising advancements in task generation, a quality gap remains between\nAI-generated and expert-created tasks. The AI-generated tasks may not align\nwith target programming concepts, could be incomprehensible for students to\nsolve, or may contain critical issues such as incorrect tests. Existing works\noften require interventions from human teachers for validation. We address\nthese challenges by introducing PyTaskSyn, a novel synthesis technique that\nfirst generates a programming task and then decides whether it meets certain\nquality criteria to be given to students. The key idea is to break this process\ninto multiple stages performed by expert and student agents simulated using\nboth strong and weaker generative models. Through extensive evaluation, we show\nthat PyTaskSyn significantly improves task quality compared to baseline\ntechniques and showcases the importance of each specialized agent type in our\nvalidation pipeline. Additionally, we conducted user studies using our publicly\navailable web application and show that PyTaskSyn can deliver high-quality\nprogramming tasks comparable to expert-designed ones while reducing workload\nand costs, and being more engaging than programming tasks that are available in\nonline resources.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-10T11:08:39Z"}
{"aid":"http://arxiv.org/abs/2504.07663v1","title":"Multiplicative assignment with upgrades","summary":"We study a problem related to submodular function optimization and the exact\nmatching problem for which we show a rather peculiar status: its natural\nLP-relaxation can have fractional optimal vertices, but there is always also an\noptimal integral vertex, which we can also compute in polynomial time.\n  More specifically, we consider the multiplicative assignment problem with\nupgrades in which we are given a set of customers and suppliers and we seek to\nassign each customer to a different supplier. Each customer has a demand and\neach supplier has a regular and an upgraded cost for each unit demand provided\nto the respective assigned client. Our goal is to upgrade at most $k$ suppliers\nand to compute an assignment in order to minimize the total resulting cost.\nThis can be cast as the problem to compute an optimal matching in a bipartite\ngraph with the additional constraint that we must select $k$ edges from a\ncertain group of edges, similar to selecting $k$ red edges in the exact\nmatching problem. Also, selecting the suppliers to be upgraded corresponds to\nmaximizing a submodular set function under a cardinality constraint.\n  Our result yields an efficient LP-based algorithm to solve our problem\noptimally. In addition, we provide also a purely strongly polynomial-time\nalgorithm for it. As an application, we obtain exact algorithms for the\nupgrading variant of the problem to schedule jobs on identical or uniformly\nrelated machines in order to minimize their sum of completion times, i.e.,\nwhere we may upgrade up to $k$ jobs to reduce their respective processing\ntimes.","main_category":"cs.DS","categories":"cs.DS,cs.DM,math.OC","published":"2025-04-10T11:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.07668v1","title":"Distributed Fault-Tolerant Control for Heterogeneous MAS with Prescribed\n  Performance under Communication Failures","summary":"This paper presents a novel approach employing prescribed performance control\nto address the distributed fault-tolerant formation control problem in a\nheterogeneous UAV-UGV cooperative system under a directed interaction topology\nand communication link failures. The proposed distributed fault-tolerant\ncontrol scheme enables UAVs to accurately track a virtual leader's trajectory\nand achieve the desired formation, while ensuring UGVs converge within the\nconvex hull formed by leader UAVs. By accounting for differences in system\nparameters and state dimensions between UAVs and UGVs, the method leverages\nperformance functions to guarantee predefined transient and steady-state\nbehavior. Additionally, a variable prescribed performance boundary control\nstrategy with an adaptive learning rate is introduced to tackle actuator\nsaturation, ensuring reliable formation tracking in real-world scenarios.\nSimulation results demonstrate the effectiveness and robustness of the proposed\napproach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T11:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.07689v1","title":"Inequality at risk of automation? Gender differences in routine tasks\n  intensity in developing country labor markets","summary":"Technological change can have profound impacts on the labor market. Decades\nof research have made it clear that technological change produces winners and\nlosers. Machines can replace some types of work that humans do, while new\ntechnologies increase human's productivity in other types of work. For a long\ntime, highly educated workers benefitted from increased demand for their labor\ndue to skill-biased technological change, while the losers were concentrated at\nthe bottom of the wage distribution (Katz and Autor, 1999; Goldin and Katz,\n2007, 2010; Kijima, 2006). Currently, however, labor markets seem to be\naffected by a different type of technological change, the so-called\nroutine-biased technological change (RBTC). This chapter studies the risk of\nautomation in developing country labor markets, with a particular focus on\ndifferences between men and women. Given the pervasiveness of gender\noccupational segregation, there may be important gender differences in the risk\nof automation. Understanding these differences is important to ensure progress\ntowards equitable development and gender inclusion in the face of new\ntechnological advances. Our objective is to describe the gender gap in the\nroutine task intensity of jobs in developing countries and to explore the role\nof occupational segregation and several worker characteristics in accounting\nfor the gender gap.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-10T12:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.07694v1","title":"Sim-to-Real Transfer in Reinforcement Learning for Maneuver Control of a\n  Variable-Pitch MAV","summary":"Reinforcement learning (RL) algorithms can enable high-maneuverability in\nunmanned aerial vehicles (MAVs), but transferring them from simulation to\nreal-world use is challenging. Variable-pitch propeller (VPP) MAVs offer\ngreater agility, yet their complex dynamics complicate the sim-to-real\ntransfer. This paper introduces a novel RL framework to overcome these\nchallenges, enabling VPP MAVs to perform advanced aerial maneuvers in\nreal-world settings. Our approach includes real-to-sim transfer techniques-such\nas system identification, domain randomization, and curriculum learning to\ncreate robust training simulations and a sim-to-real transfer strategy\ncombining a cascade control system with a fast-response low-level controller\nfor reliable deployment. Results demonstrate the effectiveness of this\nframework in achieving zero-shot deployment, enabling MAVs to perform complex\nmaneuvers such as flips and wall-backtracking.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T12:27:59Z"}
{"aid":"http://arxiv.org/abs/2504.07696v1","title":"Conformalized Generative Bayesian Imaging: An Uncertainty Quantification\n  Framework for Computational Imaging","summary":"Uncertainty quantification plays an important role in achieving trustworthy\nand reliable learning-based computational imaging. Recent advances in\ngenerative modeling and Bayesian neural networks have enabled the development\nof uncertainty-aware image reconstruction methods. Current generative\nmodel-based methods seek to quantify the inherent (aleatoric) uncertainty on\nthe underlying image for given measurements by learning to sample from the\nposterior distribution of the underlying image. On the other hand, Bayesian\nneural network-based approaches aim to quantify the model (epistemic)\nuncertainty on the parameters of a deep neural network-based reconstruction\nmethod by approximating the posterior distribution of those parameters.\nUnfortunately, an ongoing need for an inversion method that can jointly\nquantify complex aleatoric uncertainty and epistemic uncertainty patterns still\npersists. In this paper, we present a scalable framework that can quantify both\naleatoric and epistemic uncertainties. The proposed framework accepts an\nexisting generative model-based posterior sampling method as an input and\nintroduces an epistemic uncertainty quantification capability through Bayesian\nneural networks with latent variables and deep ensembling. Furthermore, by\nleveraging the conformal prediction methodology, the proposed framework can be\neasily calibrated to ensure rigorous uncertainty quantification. We evaluated\nthe proposed framework on magnetic resonance imaging, computed tomography, and\nimage inpainting problems and showed that the epistemic and aleatoric\nuncertainty estimates produced by the proposed framework display the\ncharacteristic features of true epistemic and aleatoric uncertainties.\nFurthermore, our results demonstrated that the use of conformal prediction on\ntop of the proposed framework enables marginal coverage guarantees consistent\nwith frequentist principles.","main_category":"eess.IV","categories":"eess.IV,cs.LG","published":"2025-04-10T12:30:46Z"}
{"aid":"http://arxiv.org/abs/2504.07702v1","title":"Functional Understanding Of Quantum Technology Is Essential To The\n  Ethical Debate About Its Impact","summary":"As the innovative potential of quantum technologies comes into focus, so too\ndoes the urgent need to address their ethical implications. While many voices\nhighlight the importance of ethical engagement, less attention has been paid to\nthe conditions that make such engagement possible. In this article, I argue\nthat technological understanding is a foundational capacity for meaningful\nethical reflection on emerging technology like quantum technologies. Drawing on\nDe Jong & De Haro's account of technological understanding (2025a; 2025b), I\nclarify what such understanding entails and how it enables ethical enquiry. I\ncontend that ethical assessment, first and foremost, requires an understanding\nof what quantum technologies can do - their functional capacities and, by\nextension, their potential applications. Current efforts to build engagement\ncapacities among broader audiences - within and beyond academic contexts -\ntend, however, to focus on explaining the underlying quantum mechanics.\nInstead, I advocate a shift from a physics-first to a functions-first approach:\nfostering an understanding of quantum technologies' capabilities as the basis\nfor ethical reflection. Presenting technological understanding as an epistemic\nrequirement for meaningful ethical engagement may appear to raise the bar for\nparticipation. However, by decoupling functional understanding from technical\nexpertise, this condition becomes attainable for a broader group, contributing\nnot only to a well-informed but also to a more inclusive ethical debate.","main_category":"physics.soc-ph","categories":"physics.soc-ph,quant-ph","published":"2025-04-10T12:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.07713v1","title":"Mock Eisenstein series associated to partition ranks","summary":"In this paper, we introduce a new class of mock Eisenstein series, describe\ntheir modular properties, and write the partition rank generating function in\nterms of so-called partition traces of these. Moreover, we show the Fourier\ncoefficients of the mock Eisenstein series are integral and we obtain a\nholomorphic anomaly equation for their completions.","main_category":"math.NT","categories":"math.NT,math-ph,math.CO,math.MP","published":"2025-04-10T13:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.07716v1","title":"Forced Oscillations of a Spring-Mounted Body by a Viscous Liquid:\n  Rotational Case","summary":"We study the periodic motions of the coupled system $\\mathscr S$, consisting\nof an incompressible Navier-Stokes fluid interacting with a structure formed by\na rigid body subject to {\\em undamped} elastic restoring forces and torque\naround its rotation axis. The motion of $\\mathscr S$ is driven by the uniform\nflow of the liquid, far away from the body, characterized by a time-periodic\nvelocity field, $\\mathbf{V}$, of frequency $f$. We show that the corresponding\nset of governing equations always possesses a time-periodic weak solution of\nthe same frequency $f$, whatever $f>0$, the magnitude of $\\mathbf{V}$ and the\nvalues of physical parameters. Moreover, we show that the amplitude of linear\nand rotational displacement is always pointwise in time uniformly bounded by\none and the same constant depending on the data, regardless of whether $f$ is\nor is not close to a natural frequency of the structure. Thus, our result rules\nout the occurrence of resonant phenomena.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T13:09:14Z"}
{"aid":"http://arxiv.org/abs/2504.07738v1","title":"Automated Construction of a Knowledge Graph of Nuclear Fusion Energy for\n  Effective Elicitation and Retrieval of Information","summary":"In this document, we discuss a multi-step approach to automated construction\nof a knowledge graph, for structuring and representing domain-specific\nknowledge from large document corpora. We apply our method to build the first\nknowledge graph of nuclear fusion energy, a highly specialized field\ncharacterized by vast scope and heterogeneity. This is an ideal benchmark to\ntest the key features of our pipeline, including automatic named entity\nrecognition and entity resolution. We show how pre-trained large language\nmodels can be used to address these challenges and we evaluate their\nperformance against Zipf's law, which characterizes human-generated natural\nlanguage. Additionally, we develop a knowledge-graph retrieval-augmented\ngeneration system that combines large language models with a multi-prompt\napproach. This system provides contextually relevant answers to\nnatural-language queries, including complex multi-hop questions that require\nreasoning across interconnected entities.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T13:29:58Z"}
{"aid":"http://arxiv.org/abs/2504.07739v1","title":"Implicit Incompressible Porous Flow using SPH","summary":"We present a novel implicit porous flow solver using SPH, which maintains\nfluid incompressibility and is able to model a wide range of scenarios, driven\nby strongly coupled solid-fluid interaction forces. Many previous SPH porous\nflow methods reduce particle volumes as they transition across the solid-fluid\ninterface, resulting in significant stability issues. We instead allow fluid\nand solid to overlap by deriving a new density estimation. This further allows\nus to extend modern SPH pressure solvers to take local porosity into account\nand results in strict enforcement of incompressibility. As a result, we can\nsimulate porous flow using physically consistent pressure forces between fluid\nand solid. In contrast to previous SPH porous flow methods, which use explicit\nforces for internal fluid flow, we employ implicit non-pressure forces. These\nwe solve as a linear system and strongly couple with fluid viscosity and solid\nelasticity. We capture the most common effects observed in porous flow, namely\ndrag, buoyancy and capillary action due to adhesion. To achieve elastic\nbehavior change based on local fluid saturation, such as bloating or softening,\nwe propose an extension to the elasticity model. We demonstrate the efficacy of\nour model with various simulations that showcase the different aspects of\nporous flow behavior. To summarize, our system of strongly coupled non-pressure\nforces and enforced incompressibility across overlapping phases allows us to\nnaturally model and stably simulate complex porous interactions.","main_category":"cs.GR","categories":"cs.GR,physics.flu-dyn","published":"2025-04-10T13:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.07757v1","title":"Search-contempt: a hybrid MCTS algorithm for training AlphaZero-like\n  engines with better computational efficiency","summary":"AlphaZero in 2017 was able to master chess and other games without human\nknowledge by playing millions of games against itself (self-play), with a\ncomputation budget running in the tens of millions of dollars. It used a\nvariant of the Monte Carlo Tree Search (MCTS) algorithm, known as PUCT. This\npaper introduces search-contempt, a novel hybrid variant of the MCTS algorithm\nthat fundamentally alters the distribution of positions generated in self-play,\npreferring more challenging positions. In addition, search-contempt has been\nshown to give a big boost in strength for engines in Odds Chess (where one side\nreceives an unfavorable position from the start). More significantly, it opens\nup the possibility of training a self-play based engine, in a much more\ncomputationally efficient manner with the number of training games running into\nhundreds of thousands, costing tens of thousands of dollars (instead of tens of\nmillions of training games costing millions of dollars required by AlphaZero).\nThis means that it may finally be possible to train such a program from zero on\na standard consumer GPU even with a very limited compute, cost, or time budget.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-10T13:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.07760v1","title":"PRAD: Periapical Radiograph Analysis Dataset and Benchmark Model\n  Development","summary":"Deep learning (DL), a pivotal technology in artificial intelligence, has\nrecently gained substantial traction in the domain of dental auxiliary\ndiagnosis. However, its application has predominantly been confined to imaging\nmodalities such as panoramic radiographs and Cone Beam Computed Tomography,\nwith limited focus on auxiliary analysis specifically targeting Periapical\nRadiographs (PR). PR are the most extensively utilized imaging modality in\nendodontics and periodontics due to their capability to capture detailed local\nlesions at a low cost. Nevertheless, challenges such as resolution limitations\nand artifacts complicate the annotation and recognition of PR, leading to a\nscarcity of publicly available, large-scale, high-quality PR analysis datasets.\nThis scarcity has somewhat impeded the advancement of DL applications in PR\nanalysis. In this paper, we present PRAD-10K, a dataset for PR analysis.\nPRAD-10K comprises 10,000 clinical periapical radiograph images, with\npixel-level annotations provided by professional dentists for nine distinct\nanatomical structures, lesions, and artificial restorations or medical devices,\nWe also include classification labels for images with typical conditions or\nlesions. Furthermore, we introduce a DL network named PRNet to establish\nbenchmarks for PR segmentation tasks. Experimental results demonstrate that\nPRNet surpasses previous state-of-the-art medical image segmentation models on\nthe PRAD-10K dataset. The codes and dataset will be made publicly available.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T13:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.07773v1","title":"Monitored quantum transport: full counting statistics of a quantum Hall\n  interferometer","summary":"We generalize the Levitov-Lesovik formula for the probability distribution\nfunction of the electron charge transferred through a phase coherent conductor,\nto include projective measurements that monitor the chiral propagation in\nquantum Hall edge modes. When applied to an electronic Mach-Zehnder\ninterferometer, the monitoring reduces the visibility of the Aharonov-Bohm\nconductance oscillations while preserving the binomial form of the counting\nstatistics, thereby removing a fundamental shortcoming of the dephasing-probe\nmodel of decoherence.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T14:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.07781v1","title":"Rydberg Superatom Interface for Topological Microwave-to-Optical Photon\n  Conversion in Fock-State Lattices","summary":"Microwave-to-optical conversion (MTOC) of single photons plays a pivotal role\nin bridging quantum devices across different frequency domains, but faces\nchallenges in maintaining efficiency and robustness against fluctuations and\ndissipation in hybrid quantum systems. Here, we propose a topologically\nprotected MTOC scheme mediated by a Rydberg superatom to address these\nlimitations. By constructing cross-linked Fock-state lattices (FSLs) through a\ndual-mode Jaynes-Cummings (JC) architecture, we map the effective hybrid system\nonto an extended Su-Schrieffer-Heeger~(SSH) model with tunable hopping rates.\nPhoton-number--dependent property of hopping rates triggers a topological phase\ntransition in the extended SSH chain, converting the defect mode into a\ntopological channel that directionally pumps photons between microwave and\noptical cavities. This mechanism leverages Rydberg blockade-enhanced\nphoton-superatom couplings to establish a robust energy transfer channel,\nachieving high-efficiency photon conversion under realistic decoherence. Our\ntheoretical framework demonstrates how topological protection synergizes with\nRydberg-mediated light-matter interactions to realize a robust quantum\ntransducer, providing a scalable platform for noise-resilient quantum networks\nand frequency-multiplexed quantum interfaces.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T14:20:38Z"}
{"aid":"http://arxiv.org/abs/2504.07787v1","title":"Fairness Mediator: Neutralize Stereotype Associations to Mitigate Bias\n  in Large Language Models","summary":"LLMs have demonstrated remarkable performance across diverse applications,\nyet they inadvertently absorb spurious correlations from training data, leading\nto stereotype associations between biased concepts and specific social groups.\nThese associations perpetuate and even amplify harmful social biases, raising\nsignificant fairness concerns. To mitigate such biases, prior studies have\nattempted to project model embeddings into unbiased spaces during inference.\nHowever, these approaches have shown limited effectiveness due to their weak\nalignment with downstream social biases. Inspired by the observation that\nconcept cognition in LLMs is primarily represented through a linear associative\nmemory mechanism, where key-value mapping occurs in the MLP layers, we posited\nthat biased concepts and social groups are similarly encoded as entity (key)\nand information (value) pairs, which can be manipulated to promote fairer\nassociations. To this end, we propose Fairness Mediator (FairMed), a bias\nmitigation framework that neutralizes stereotype associations. Our framework\ncomprises two main components: a stereotype association prober and an\nadversarial debiasing neutralizer. The prober captures stereotype associations\nencoded within MLP layer activations by employing prompts centered around\nbiased concepts to detect the emission probabilities for social groups.\nSubsequently, the adversarial debiasing neutralizer intervenes in MLP\nactivations during inference to equalize the association probabilities among\ndifferent social groups. Extensive experiments across nine protected attributes\nshow that FairMed significantly outperforms SOTA methods in effectiveness.\nCompared to the most effective baseline, FairMed presents competitive\nefficiency by cutting mitigation overhead by hundreds of minutes. FairMed also\nmaintains the LLM's language understanding capabilities without compromising\noverall performance.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T14:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.07799v1","title":"Equivalence of Variants of Shadowing of Free Semigroup Actions","summary":"We prove that for finitely generated free semigroup actions the average\nshadowing property, the weak asymptotic average shadowing property, the mean\nergodic shadowing property, the almost asymptotic average shadowing property,\nthe asymptotic average shadowing property and the $M_{\\alpha}$-shadowing\nproperty for every $\\alpha\\in (0,1)$, are equivalent. This gives an affirmative\nanswer to an open question asked in Question 10.3 [M. Kulczycki, D. Kwietniak,\nP. Oprocha, On almost specification and average shadowing properties,\nFundamenta Mathematicae, 224 (2014)].","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T14:37:56Z"}
{"aid":"http://arxiv.org/abs/2504.07817v1","title":"Search for the baryon and lepton number violating decay $J/Ï\\to pe^-$\n  + c.c","summary":"Based on $(2712.4\\pm 14.3) \\times 10^{6} $ ${\\psi(3686)}$ events collected by\nthe BESIII detector operating at the BEPCII storage ring, we perform a search\nfor the baryon- and lepton-number violating decay $J/\\psi \\to pe^{-}+c.c.$ via\n$\\psi(3686) \\to \\pi^{+}\\pi^{-}J/\\psi$. No significant signal is found. An upper\nlimit on the branching fraction of $\\mathcal{B}(J/\\psi \\to p e^{-}+ c.c.) < 3.1\n\\times 10^{-8}$ at 90\\% confidence level.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-10T14:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.07821v1","title":"Signatures of NED on Quasi periodic Oscillations of a Magnetically\n  Charged Black Hole","summary":"In this work, we explore the influence of nonlinear electrodynamics (NED) on\nthe quasi-periodic oscillations (QPOs) of a magnetic charged black hole by\nanalyzing the motion of test particles and their epicyclic frequencies.\nStarting from the effective potential, angular momentum, and energy of circular\norbits, we examine how the NED parameter b alters the orbital dynamics. We find\nthat as b increases, the system transitions smoothly from the RN regime towards\nthe Schwarzschild profile, with observable changes in the innermost stable\ncircular orbit (ISCO) and Keplerian frequencies. We further investigate the\nvariation in the radii of QPOs with respect to the NED parameter b by employing\nthe RP, WD, and ER models. We also perform Markov Chain Monte Carlo (MCMC)\nanalysis using observational QPO data from a diverse set of black hole sources\nspanning stellar-mass, intermediate-mass, and supermassive regimes. The MCMC\nresults yield consistent constraints on the parameter b across all mass\nregimes, indicating that NED effects leave a distinguishable signature on the\nQPO structure of a charged black hole.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-10T14:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.07831v1","title":"Deceptive Automated Interpretability: Language Models Coordinating to\n  Fool Oversight Systems","summary":"We demonstrate how AI agents can coordinate to deceive oversight systems\nusing automated interpretability of neural networks. Using sparse autoencoders\n(SAEs) as our experimental framework, we show that language models (Llama,\nDeepSeek R1, and Claude 3.7 Sonnet) can generate deceptive explanations that\nevade detection. Our agents employ steganographic methods to hide information\nin seemingly innocent explanations, successfully fooling oversight models while\nachieving explanation quality comparable to reference labels. We further find\nthat models can scheme to develop deceptive strategies when they believe the\ndetection of harmful features might lead to negative consequences for\nthemselves. All tested LLM agents were capable of deceiving the overseer while\nachieving high interpretability scores comparable to those of reference labels.\nWe conclude by proposing mitigation strategies, emphasizing the critical need\nfor robust understanding and defenses against deception.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-10T15:07:10Z"}
{"aid":"http://arxiv.org/abs/2504.07835v1","title":"Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and\n  Neural Networks","summary":"Motivated by the growing demand for low-precision arithmetic in computational\nscience, we exploit lower-precision emulation in Python -- widely regarded as\nthe dominant programming language for numerical analysis and machine learning.\nLow-precision training has revolutionized deep learning by enabling more\nefficient computation and reduced memory and energy consumption while\nmaintaining model fidelity. To better enable numerical experimentation with and\nexploration of low precision computation, we developed the Pychop library,\nwhich supports customizable floating-point formats and a comprehensive set of\nrounding modes in Python, allowing users to benefit from fast, low-precision\nemulation in numerous applications. Pychop also introduces interfaces for both\nPyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural\nnetwork training and inference with unparalleled flexibility.\n  In this paper, we offer a comprehensive exposition of the design,\nimplementation, validation, and practical application of Pychop, establishing\nit as a foundational tool for advancing efficient mixed-precision algorithms.\nFurthermore, we present empirical results on low-precision emulation for image\nclassification and object detection using published datasets, illustrating the\nsensitivity of the use of low precision and offering valuable insights into its\nimpact. Pychop enables in-depth investigations into the effects of numerical\nprecision, facilitates the development of novel hardware accelerators, and\nintegrates seamlessly into existing deep learning workflows. Software and\nexperimental code are publicly available at\nhttps://github.com/inEXASCALE/pychop.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-10T15:12:29Z"}
{"aid":"http://arxiv.org/abs/2504.07841v1","title":"Anytime Single-Step MAPF Planning with Anytime PIBT","summary":"PIBT is a popular Multi-Agent Path Finding (MAPF) method at the core of many\nstate-of-the-art MAPF methods including LaCAM, CS-PIBT, and WPPL. The main\nutility of PIBT is that it is a very fast and effective single-step MAPF solver\nand can return a collision-free single-step solution for hundreds of agents in\nless than a millisecond. However, the main drawback of PIBT is that it is\nextremely greedy in respect to its priorities and thus leads to poor solution\nquality. Additionally, PIBT cannot use all the planning time that might be\navailable to it and returns the first solution it finds. We thus develop\nAnytime PIBT, which quickly finds a one-step solution identically to PIBT but\nthen continuously improves the solution in an anytime manner. We prove that\nAnytime PIBT converges to the optimal solution given sufficient time. We\nexperimentally validate that Anytime PIBT can rapidly improve single-step\nsolution quality within milliseconds and even find the optimal single-step\naction. However, we interestingly find that improving the single-step solution\nquality does not have a significant effect on full-horizon solution costs.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-10T15:21:23Z"}
{"aid":"http://arxiv.org/abs/2504.07845v1","title":"A Spectral Gap Absorption Principle","summary":"We show that unitary representations of simply connected, semisimple\nalgebraic groups over local fields of characteristic zero obey a spectral gap\nabsorption principle: that is, that spectral gap is preserved under tensor\nproducts. We do this by proving that the unitary dual of simple algebraic\ngroups is filtered by the integrability parameter of matrix coefficients. This\nis a filtration of closed ideals that captures every closed subset of the dual\nthat doesn't contain the trivial representation. In other words, we show that a\nrepresentation has a spectral gap if and only if there exists some $p < \\infty$\nsuch that its matrix coefficients are in $L^{p+\\epsilon}(G)$ for every\n$\\epsilon>0$. Doing this, we continue the work of Bader and Sauer in this area\nand prove a conjecture they phrased. We also use this principle to give an\naffirmative solution to a conjecture raised by Bekka and Valette: the image of\nthe restriction map from a semisimple group to a lattice is never dense in Fell\ntopology.","main_category":"math.GR","categories":"math.GR","published":"2025-04-10T15:24:44Z"}
{"aid":"http://arxiv.org/abs/2504.07853v1","title":"V2V3D: View-to-View Denoised 3D Reconstruction for Light-Field\n  Microscopy","summary":"Light field microscopy (LFM) has gained significant attention due to its\nability to capture snapshot-based, large-scale 3D fluorescence images. However,\nexisting LFM reconstruction algorithms are highly sensitive to sensor noise or\nrequire hard-to-get ground-truth annotated data for training. To address these\nchallenges, this paper introduces V2V3D, an unsupervised view2view-based\nframework that establishes a new paradigm for joint optimization of image\ndenoising and 3D reconstruction in a unified architecture. We assume that the\nLF images are derived from a consistent 3D signal, with the noise in each view\nbeing independent. This enables V2V3D to incorporate the principle of\nnoise2noise for effective denoising. To enhance the recovery of high-frequency\ndetails, we propose a novel wave-optics-based feature alignment technique,\nwhich transforms the point spread function, used for forward propagation in\nwave optics, into convolution kernels specifically designed for feature\nalignment. Moreover, we introduce an LFM dataset containing LF images and their\ncorresponding 3D intensity volumes. Extensive experiments demonstrate that our\napproach achieves high computational efficiency and outperforms the other\nstate-of-the-art methods. These advancements position V2V3D as a promising\nsolution for 3D imaging under challenging conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T15:29:26Z"}
{"aid":"http://arxiv.org/abs/2504.07854v1","title":"The KL3M Data Project: Copyright-Clean Training Resources for Large\n  Language Models","summary":"Practically all large language models have been pre-trained on data that is\nsubject to global uncertainty related to copyright infringement and breach of\ncontract. This creates potential risk for users and developers due to this\nuncertain legal status. The KL3M Data Project directly confronts this critical\nissue by introducing the largest comprehensive training data pipeline that\nminimizes risks related to copyright or breach of contract. The foundation of\nthis project is a corpus of over 132 million documents and trillions of tokens\nspanning 16 different sources that have been verified to meet the strict\ncopyright and licensing protocol detailed herein. We are releasing the entire\npipeline, including 1) the source code to acquire and process these documents,\n2) the original document formats with associated provenance and metadata, 3)\nextracted content in a standardized format, 4) pre-tokenized representations of\nthe documents, and 5) various mid- and post-train resources such as\nquestion-answer, summarization, conversion, drafting, classification,\nprediction, and conversational data. All of these resources are freely\navailable to the public on S3, Hugging Face, and GitHub under CC-BY terms. We\nare committed to continuing this project in furtherance of a more ethical,\nlegal, and sustainable approach to the development and use of AI models.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-10T15:31:17Z"}
{"aid":"http://arxiv.org/abs/2504.07855v1","title":"Foreign Signal Radar","summary":"We introduce a new machine learning approach to detect value-relevant foreign\ninformation for both domestic and multinational companies. Candidate foreign\nsignals include lagged returns of stock markets and individual stocks across 47\nforeign markets. By training over 100,000 models, we capture stock-specific,\ntime-varying relationships between foreign signals and U.S. stock returns.\nForeign signals exhibit out-of-sample return predictability for a subset of\nU.S. stocks across domestic and multinational companies. Valuable foreign\nsignals are not concentrated in those largest foreign markets nor foreign firms\nin the same industry as U.S. firms. Signal importance analysis reveals the\nprice discovery of foreign information is significantly slower for information\nfrom emerging and low-media-coverage markets and among stocks with lower\nforeign institutional ownership but is accelerated during the COVID-19 crisis.\nOur study suggests that machine learning-based investment strategies leveraging\nforeign signals can emerge as important mechanisms to improve the market\nefficiency of foreign information.","main_category":"q-fin.PR","categories":"q-fin.PR","published":"2025-04-10T15:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.07859v1","title":"Conversion-Driven Freeze-Out: A Common Framework for Dark Matter and\n  Baryogenesis","summary":"We explore dark matter genesis beyond the WIMP paradigm, focusing on the\nmechanism of conversion-driven freeze-out. This mechanism enables the\nthermalization of dark matter despite its very weak couplings. While the\nscenario evades conventional WIMP searches, it predicts novel signatures of\nlong-lived particles at colliders, making it a prime target for upcoming LHC\nsearches. We review various model realizations of this mechanism, highlighting\nits deep connections to other unresolved problems of the Standard Model. In\nparticular, we show how conversion-driven freeze-out can naturally give rise to\nbaryogenesis, offering a compelling perspective on the origins of both dark and\nbaryonic matter.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T15:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.07874v1","title":"Power Operations on $K(n-1)$-Localized Morava $E$-theory at Height $n$","summary":"We calculate the $K(n-1)$-localized $E_n$ theory for symmetric groups, and\ndeduce a modular interpretation of the total power operation $\\psi^p_F$ on\n$F=L_{K(n-1)}E_n$ in terms of augmented deformations of formal groups and their\nsubgroups. We compute the Dyer-Lashof algebra structure over $K(n-1)$-local\n$E_n$-algebra. Then we specify our calculation to the $n=2$ case. We calculate\nan explicit formula for $\\psi^p_F$ using the formula of $\\psi^p_E$, and explain\nconnections between these computations and elliptic curves, modular forms and\n$p$-divisible groups.","main_category":"math.AT","categories":"math.AT","published":"2025-04-10T15:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.07881v1","title":"An LLM-Driven Multi-Agent Debate System for Mendelian Diseases","summary":"Accurate diagnosis of Mendelian diseases is crucial for precision therapy and\nassistance in preimplantation genetic diagnosis. However, existing methods\noften fall short of clinical standards or depend on extensive datasets to build\npretrained machine learning models. To address this, we introduce an innovative\nLLM-Driven multi-agent debate system (MD2GPS) with natural language\nexplanations of the diagnostic results. It utilizes a language model to\ntransform results from data-driven and knowledge-driven agents into natural\nlanguage, then fostering a debate between these two specialized agents. This\nsystem has been tested on 1,185 samples across four independent datasets,\nenhancing the TOP1 accuracy from 42.9% to 66% on average. Additionally, in a\nchallenging cohort of 72 cases, MD2GPS identified potential pathogenic genes in\n12 patients, reducing the diagnostic time by 90%. The methods within each\nmodule of this multi-agent debate system are also replaceable, facilitating its\nadaptation for diagnosing and researching other complex diseases.","main_category":"q-bio.GN","categories":"q-bio.GN","published":"2025-04-10T15:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.07904v1","title":"The Efficacy of Semantics-Preserving Transformations in Self-Supervised\n  Learning for Medical Ultrasound","summary":"Data augmentation is a central component of joint embedding self-supervised\nlearning (SSL). Approaches that work for natural images may not always be\neffective in medical imaging tasks. This study systematically investigated the\nimpact of data augmentation and preprocessing strategies in SSL for lung\nultrasound. Three data augmentation pipelines were assessed: (1) a baseline\npipeline commonly used across imaging domains, (2) a novel semantic-preserving\npipeline designed for ultrasound, and (3) a distilled set of the most effective\ntransformations from both pipelines. Pretrained models were evaluated on\nmultiple classification tasks: B-line detection, pleural effusion detection,\nand COVID-19 classification. Experiments revealed that semantics-preserving\ndata augmentation resulted in the greatest performance for COVID-19\nclassification - a diagnostic task requiring global image context.\nCropping-based methods yielded the greatest performance on the B-line and\npleural effusion object classification tasks, which require strong local\npattern recognition. Lastly, semantics-preserving ultrasound image\npreprocessing resulted in increased downstream performance for multiple tasks.\nGuidance regarding data augmentation and preprocessing strategies was\nsynthesized for practitioners working with SSL in ultrasound.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-10T16:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.07939v1","title":"Echo: An Open-Source, Low-Cost Teleoperation System with Force Feedback\n  for Dataset Collection in Robot Learning","summary":"In this article, we propose Echo, a novel joint-matching teleoperation system\ndesigned to enhance the collection of datasets for manual and bimanual tasks.\nOur system is specifically tailored for controlling the UR manipulator and\nfeatures a custom controller with force feedback and adjustable sensitivity\nmodes, enabling precise and intuitive operation. Additionally, Echo integrates\na user-friendly dataset recording interface, simplifying the process of\ncollecting high-quality training data for imitation learning. The system is\ndesigned to be reliable, cost-effective, and easily reproducible, making it an\naccessible tool for researchers, laboratories, and startups passionate about\nadvancing robotics through imitation learning. Although the current\nimplementation focuses on the UR manipulator, Echo architecture is\nreconfigurable and can be adapted to other manipulators and humanoid systems.\nWe demonstrate the effectiveness of Echo through a series of experiments,\nshowcasing its ability to perform complex bimanual tasks and its potential to\naccelerate research in the field. We provide assembly instructions, a hardware\ndescription, and code at https://eterwait.github.io/Echo/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T17:51:37Z"}
{"aid":"http://arxiv.org/abs/2504.07940v1","title":"Beyond the Frame: Generating 360Â° Panoramic Videos from Perspective\n  Videos","summary":"360{\\deg} videos have emerged as a promising medium to represent our dynamic\nvisual world. Compared to the \"tunnel vision\" of standard cameras, their\nborderless field of view offers a more complete perspective of our\nsurroundings. While existing video models excel at producing standard videos,\ntheir ability to generate full panoramic videos remains elusive. In this paper,\nwe investigate the task of video-to-360{\\deg} generation: given a perspective\nvideo as input, our goal is to generate a full panoramic video that is\nconsistent with the original video. Unlike conventional video generation tasks,\nthe output's field of view is significantly larger, and the model is required\nto have a deep understanding of both the spatial layout of the scene and the\ndynamics of objects to maintain spatio-temporal consistency. To address these\nchallenges, we first leverage the abundant 360{\\deg} videos available online\nand develop a high-quality data filtering pipeline to curate pairwise training\ndata. We then carefully design a series of geometry- and motion-aware\noperations to facilitate the learning process and improve the quality of\n360{\\deg} video generation. Experimental results demonstrate that our model can\ngenerate realistic and coherent 360{\\deg} videos from in-the-wild perspective\nvideo. In addition, we showcase its potential applications, including video\nstabilization, camera viewpoint control, and interactive visual question\nanswering.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:51:38Z"}
{"aid":"http://arxiv.org/abs/2504.07946v1","title":"Characteristic function-based tests for spatial randomness","summary":"We introduce a new type of test for complete spatial randomness that applies\nto mapped point patterns in a rectangle or a cube of any dimension. This is the\nfirst test of its kind to be based on characteristic functions and utilizes a\nweighted L2-distance between the empirical and uniform characteristic\nfunctions. It is simple to calculate and does not require adjusting for edge\neffects. An efficient algorithm is developed to find the asymptotic null\ndistribution of the test statistic under the Cauchy weight function. In a\nsimulation, our test shows varying sensitivity to different levels of spatial\ninteraction depending on the scale parameter of the Cauchy weight function.\nTests with different parameter values can be combined to create a\nBonferroni-corrected omnibus test, which is almost always more powerful than\nthe popular L-test and the Clark-Evans test for detecting heterogeneous and\naggregated alternatives, although less powerful than the L-test for detecting\nregular alternatives. The simplicity of empirical characteristic function makes\nit straightforward to extend our test to non-rectangular or sparsely sampled\npoint patterns.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-10T17:54:11Z"}
{"aid":"http://arxiv.org/abs/2504.07959v1","title":"CCMNet: Leveraging Calibrated Color Correction Matrices for Cross-Camera\n  Color Constancy","summary":"Computational color constancy, or white balancing, is a key module in a\ncamera's image signal processor (ISP) that corrects color casts from scene\nlighting. Because this operation occurs in the camera-specific raw color space,\nwhite balance algorithms must adapt to different cameras. This paper introduces\na learning-based method for cross-camera color constancy that generalizes to\nnew cameras without retraining. Our method leverages pre-calibrated color\ncorrection matrices (CCMs) available on ISPs that map the camera's raw color\nspace to a standard space (e.g., CIE XYZ). Our method uses these CCMs to\ntransform predefined illumination colors (i.e., along the Planckian locus) into\nthe test camera's raw space. The mapped illuminants are encoded into a compact\ncamera fingerprint embedding (CFE) that enables the network to adapt to unseen\ncameras. To prevent overfitting due to limited cameras and CCMs during\ntraining, we introduce a data augmentation technique that interpolates between\ncameras and their CCMs. Experimental results across multiple datasets and\nbackbones show that our method achieves state-of-the-art cross-camera color\nconstancy while remaining lightweight and relying only on data readily\navailable in camera ISPs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.09886v1","title":"Investigating Syntactic Biases in Multilingual Transformers with RC\n  Attachment Ambiguities in Italian and English","summary":"This paper leverages past sentence processing studies to investigate whether\nmonolingual and multilingual LLMs show human-like preferences when presented\nwith examples of relative clause attachment ambiguities in Italian and English.\nFurthermore, we test whether these preferences can be modulated by lexical\nfactors (the type of verb/noun in the matrix clause) which have been shown to\nbe tied to subtle constraints on syntactic and semantic relations. Our results\noverall showcase how LLM behavior varies interestingly across models, but also\ngeneral failings of these models in correctly capturing human-like preferences.\nIn light of these results, we argue that RC attachment is the ideal benchmark\nfor cross-linguistic investigations of LLMs' linguistic knowledge and biases.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T05:19:23Z"}
{"aid":"http://arxiv.org/abs/2504.09888v1","title":"Scalable fluxonium qubit architecture with tunable interactions between\n  non-computational levels","summary":"The fluxonium qubit has emerged as a promising candidate for superconducting\nquantum computing due to its long coherence times and high-fidelity gates.\nNonetheless, further scaling up and improving performance remain critical\nchallenges for establishing fluxoniums as a viable alternative to transmons. A\nkey obstacle lies in developing scalable coupling architectures. In this work,\nwe introduce a scalable fluxonium architecture that enables decoupling of qubit\nstates while maintaining tunable couplings between non-computational states.\nBeyond the well-studied ZZ crosstalk, we identify that an always-on interaction\ninvolving non-computational levels can significantly degrade the fidelities of\ninitialization, control, and readout in large systems, thereby impeding\nscalability. We demonstrate that this issue can be mitigated by implementing\ntunable couplings for fluxonium's plasmon transitions, meanwhile enabling fast,\nhigh-fidelity gates with passive ZZ suppression. Furthermore, since fluxonium\ntransitions span multiple frequency octaves, we emphasize the importance of\ncarefully designing coupling mechanisms and parameters to suppress residual\ninteractions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T05:31:47Z"}
{"aid":"http://arxiv.org/abs/2504.09895v1","title":"Learning from Reference Answers: Versatile Language Model Alignment\n  without Binary Human Preference Data","summary":"Large language models~(LLMs) are expected to be helpful, harmless, and\nhonest. In various alignment scenarios, such as general human preference,\nsafety, and confidence alignment, binary preference data collection and reward\nmodeling are resource-intensive but necessary for human preference\ntransferring. In this work, we explore using the similarity between sampled\ngenerations and high-quality reference answers as an alternative reward\nfunction for LLM alignment. Using similarity as a reward circumvents training\nreward models, and collecting a single reference answer potentially costs less\ntime than constructing binary preference pairs when multiple candidates are\navailable. Specifically, we develop \\textit{RefAlign}, a versatile\nREINFORCE-style alignment algorithm, which is free of reference and reward\nmodels. Instead, RefAlign utilizes BERTScore between sampled generations and\nhigh-quality reference answers as the surrogate reward. Beyond general human\npreference optimization, RefAlign can be readily extended to diverse scenarios,\nsuch as safety and confidence alignment, by incorporating the similarity reward\nwith task-related objectives. In various scenarios, {RefAlign} demonstrates\ncomparable performance to previous alignment methods while offering high\nefficiency.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T05:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.09916v1","title":"Dynamically assisted Klein tunneling in the Furry picture","summary":"One-dimensional scattering of a wave packet of a relativistic fermion under a\ntemporally oscillating electric field superimposed on a potential step is\ndiscussed by using the Furry-picture perturbation theory, where the oscillating\nelectric field is treated as a perturbation. Reflection and transmission\nprobabilities of the wave packet, which in its single-mode limit are consistent\nwith those in the stationary scattering off the potential step alone, are\ninvestigated up to the second order. We show that even in the absence of the\nso-called Klein region, a positive-frequency incoming wave can penetrate the\nnegative-frequency region below the potential step by emitting its energy to\nthe oscillating electric field with a finite tunneling probability.","main_category":"hep-th","categories":"hep-th,quant-ph","published":"2025-04-14T06:25:07Z"}
{"aid":"http://arxiv.org/abs/2504.09922v1","title":"Enhancement and Suppression of Active Particle Movement Due to Membrane\n  Deformations","summary":"Microswimmers and active colloids often move in confined systems, including\nthose involving interfaces. Such interfaces, especially at the microscale, may\ndeform in response to the stresses of the flow created by the active particle.\nWe develop a theoretical framework to analyze the effect of a nearby membrane\ndue to the motion of an active particle whose flow fields are generated by\nforce-free singularities. We demonstrate our result on a particle represented\nby a combination of a force dipole and a source dipole, while the membrane\nresists deformation due to tension and bending rigidity. We find that the\ndeformation either enhances or suppresses the motion of the active particle,\ndepending on its orientation and the relative strengths between the fundamental\nsingularities that describe its flow. Furthermore, the deformation can generate\nmotion in new directions.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-14T06:32:20Z"}
{"aid":"http://arxiv.org/abs/2504.09924v1","title":"Passive Channel Charting: Locating Passive Targets using Wi-Fi Channel\n  State Information","summary":"We propose passive channel charting, an extension of channel charting to\npassive target localization. As in conventional channel charting, we follow a\ndimensionality reduction approach to reconstruct a physically interpretable map\nof target positions from similarities in high-dimensional channel state\ninformation. We show that algorithms and neural network architectures developed\nin the context of channel charting with active mobile transmitters can be\nstraightforwardly applied to the passive case, where we assume a scenario with\nstatic transmitters and receivers and a mobile target. We evaluate our method\non a channel state information dataset collected indoors with a distributed\nsetup of ESPARGOS Wi-Fi sensing antenna arrays. This scenario can be\ninterpreted as either a multi-static or passive radar system. We demonstrate\nthat passive channel charting outperforms a baseline based on classical\ntriangulation in terms of localization accuracy. We discuss our results and\nhighlight some unsolved issues related to the proposed concept.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-14T06:33:07Z"}
{"aid":"http://arxiv.org/abs/2504.09941v1","title":"FedRecon: Missing Modality Reconstruction in Distributed Heterogeneous\n  Environments","summary":"Multimodal data are often incomplete and exhibit Non-Independent and\nIdentically Distributed (Non-IID) characteristics in real-world scenarios.\nThese inherent limitations lead to both modality heterogeneity through partial\nmodality absence and data heterogeneity from distribution divergence, creating\nfundamental challenges for effective federated learning (FL). To address these\ncoupled challenges, we propose FedRecon, the first method targeting\nsimultaneous missing modality reconstruction and Non-IID adaptation in\nmultimodal FL. Our approach first employs a lightweight Multimodal Variational\nAutoencoder (MVAE) to reconstruct missing modalities while preserving\ncross-modal consistency. Distinct from conventional imputation methods, we\nachieve sample-level alignment through a novel distribution mapping mechanism\nthat guarantees both data consistency and completeness. Additionally, we\nintroduce a strategy employing global generator freezing to prevent\ncatastrophic forgetting, which in turn mitigates Non-IID fluctuations.\nExtensive evaluations on multimodal datasets demonstrate FedRecon's superior\nperformance in modality reconstruction under Non-IID conditions, surpassing\nstate-of-the-art methods.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-14T07:04:10Z"}
{"aid":"http://arxiv.org/abs/2504.09952v1","title":"Secrecy and Privacy in Multi-Access Combinatorial Topology","summary":"In this work, we consider the multi-access combinatorial topology with $C$\ncaches where each user accesses a unique set of $r$ caches. For this setup, we\nconsider secrecy, where each user should not know anything about the files it\ndid not request, and demand privacy, where each user's demand must be kept\nprivate from other non-colluding users. We propose a scheme satisfying both\nconditions and derive a lower bound based on cut-set arguments. Also, we prove\nthat our scheme is optimal when $r\\geq C-1$, and it is order-optimal when the\ncache memory size $M$ is greater than or equal to a certain threshold for\n$r<C-1$. When $r=1$, in most of the memory region, our scheme achieves the same\nrate as the one given by the secretive scheme for the dedicated cache setup by\nRavindrakumar et al. ( 'Private Coded Caching,' in \\textit{IEEE Transactions on\nInformation Forensics and Security}, 2018), while satisfying both secrecy and\ndemand privacy conditions.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T07:30:03Z"}
{"aid":"http://arxiv.org/abs/2504.09970v1","title":"IsoSEL: Isometric Structural Entropy Learning for Deep Graph Clustering\n  in Hyperbolic Space","summary":"Graph clustering is a longstanding topic in machine learning. In recent\nyears, deep learning methods have achieved encouraging results, but they still\nrequire predefined cluster numbers K, and typically struggle with imbalanced\ngraphs, especially in identifying minority clusters. The limitations motivate\nus to study a challenging yet practical problem: deep graph clustering without\nK considering the imbalance in reality. We approach this problem from a fresh\nperspective of information theory (i.e., structural information). In the\nliterature, structural information has rarely been touched in deep clustering,\nand the classic definition falls short in its discrete formulation, neglecting\nnode attributes and exhibiting prohibitive complexity. In this paper, we first\nestablish a new Differentiable Structural Information, generalizing the\ndiscrete formalism to continuous realm, so that the optimal partitioning tree,\nrevealing the cluster structure, can be created by the gradient\nbackpropagation. Theoretically, we demonstrate its capability in clustering\nwithout requiring K and identifying the minority clusters in imbalanced graphs,\nwhile reducing the time complexity to O(N) w.r.t. the number of nodes.\nSubsequently, we present a novel IsoSEL framework for deep graph clustering,\nwhere we design a hyperbolic neural network to learn the partitioning tree in\nthe Lorentz model of hyperbolic space, and further conduct Lorentz Tree\nContrastive Learning with isometric augmentation. As a result, the partitioning\ntree incorporates node attributes via mutual information maximization, while\nthe cluster assignment is refined by the proposed tree contrastive learning.\nExtensive experiments on five benchmark datasets show the IsoSEL outperforms 14\nrecent baselines by an average of +1.3% in NMI.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T08:21:41Z"}
{"aid":"http://arxiv.org/abs/2504.09977v1","title":"EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart\n  Contract","summary":"Poorly designed smart contracts are particularly vulnerable, as they may\nallow attackers to exploit weaknesses and steal the virtual currency they\nmanage. In this study, we train a model using unsupervised learning to identify\nvulnerabilities in the Solidity source code of Ethereum smart contracts. To\naddress the challenges associated with real-world smart contracts, our training\ndata is derived from actual vulnerability samples obtained from datasets such\nas SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to\ndevelop a robust unsupervised static analysis method for detecting five\nspecific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency,\ntx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to\nidentify outliers, which are subsequently classified as vulnerable smart\ncontracts.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T08:36:21Z"}
{"aid":"http://arxiv.org/abs/2504.09979v1","title":"Resampling Benchmark for Efficient Comprehensive Evaluation of Large\n  Vision-Language Models","summary":"We propose an efficient evaluation protocol for large vision-language models\n(VLMs). Given their broad knowledge and reasoning capabilities, multiple\nbenchmarks are needed for comprehensive assessment, making evaluation\ncomputationally expensive. To improve efficiency, we construct a subset that\nyields results comparable to full benchmark evaluations. Our benchmark\nclassification experiments reveal that no single benchmark fully covers all\nchallenges. We then introduce a subset construction method using farthest point\nsampling (FPS). Our experiments show that FPS-based benchmarks maintain a\nstrong correlation (> 0.96) with full evaluations while using only ~1\\% of the\ndata. Additionally, applying FPS to an existing benchmark improves correlation\nwith overall evaluation results, suggesting its potential to reduce unintended\ndataset biases.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:43:00Z"}
{"aid":"http://arxiv.org/abs/2504.09994v1","title":"Physical Scales Matter: The Role of Receptive Fields and Advection in\n  Satellite-Based Thunderstorm Nowcasting with Convolutional Neural Networks","summary":"The focus of nowcasting development is transitioning from physically\nmotivated advection methods to purely data-driven Machine Learning (ML)\napproaches. Nevertheless, recent work indicates that incorporating advection\ninto the ML value chain has improved skill for radar-based precipitation\nnowcasts. However, the generality of this approach and the underlying causes\nremain unexplored. This study investigates the generality by probing the\napproach on satellite-based thunderstorm nowcasts for the first time. Resorting\nto a scale argument, we then put forth an explanation when and why skill\nimprovements can be expected. In essence, advection guarantees that\nthunderstorm patterns relevant for nowcasting are contained in the receptive\nfield at long lead times. To test our hypotheses, we train ResU-Nets solving\nsegmentation tasks with lightning observations as ground truth. The input of\nthe Baseline Neural Network (BNN) are short time series of multispectral\nsatellite imagery and lightning observations, whereas the Advection-Informed\nNeural Network (AINN) additionally receives the Lagrangian persistence nowcast\nof all input channels at the desired lead time. Overall, we find only a minor\nskill improvement of the AINN over the BNN when considering fully averaged\nscores. However, assessing skill conditioned on lead time and wind speed, we\ndemonstrate that our scale argument correctly predicts the onset of skill\nimprovement of the AINN over the BNN after 2h lead time. We confirm that\ngenerally advection becomes gradually more important with longer lead times and\nhigher wind speeds. Our work accentuates the importance of considering and\nincorporating the underlying physical scales when designing ML based\nforecasting models.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.LG","published":"2025-04-14T08:57:59Z"}
{"aid":"http://arxiv.org/abs/2504.10000v1","title":"Do We Really Need Curated Malicious Data for Safety Alignment in\n  Multi-modal Large Language Models?","summary":"Multi-modal large language models (MLLMs) have made significant progress, yet\ntheir safety alignment remains limited. Typically, current open-source MLLMs\nrely on the alignment inherited from their language module to avoid harmful\ngenerations. However, the lack of safety measures specifically designed for\nmulti-modal inputs creates an alignment gap, leaving MLLMs vulnerable to\nvision-domain attacks such as typographic manipulation. Current methods utilize\na carefully designed safety dataset to enhance model defense capability, while\nthe specific knowledge or patterns acquired from the high-quality dataset\nremain unclear. Through comparison experiments, we find that the alignment gap\nprimarily arises from data distribution biases, while image content, response\nquality, or the contrastive behavior of the dataset makes little contribution\nto boosting multi-modal safety. To further investigate this and identify the\nkey factors in improving MLLM safety, we propose finetuning MLLMs on a small\nset of benign instruct-following data with responses replaced by simple, clear\nrejection sentences. Experiments show that, without the need for\nlabor-intensive collection of high-quality malicious data, model safety can\nstill be significantly improved, as long as a specific fraction of rejection\ndata exists in the finetuning set, indicating the security alignment is not\nlost but rather obscured during multi-modal pretraining or instruction\nfinetuning. Simply correcting the underlying data bias could narrow the safety\ngap in the vision domain.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.CL,cs.CV,cs.LG","published":"2025-04-14T09:03:51Z"}
{"aid":"http://arxiv.org/abs/2504.10003v1","title":"NaviDiffusor: Cost-Guided Diffusion Model for Visual Navigation","summary":"Visual navigation, a fundamental challenge in mobile robotics, demands\nversatile policies to handle diverse environments. Classical methods leverage\ngeometric solutions to minimize specific costs, offering adaptability to new\nscenarios but are prone to system errors due to their multi-modular design and\nreliance on hand-crafted rules. Learning-based methods, while achieving high\nplanning success rates, face difficulties in generalizing to unseen\nenvironments beyond the training data and often require extensive training. To\naddress these limitations, we propose a hybrid approach that combines the\nstrengths of learning-based methods and classical approaches for RGB-only\nvisual navigation. Our method first trains a conditional diffusion model on\ndiverse path-RGB observation pairs. During inference, it integrates the\ngradients of differentiable scene-specific and task-level costs, guiding the\ndiffusion model to generate valid paths that meet the constraints. This\napproach alleviates the need for retraining, offering a plug-and-play solution.\nExtensive experiments in both indoor and outdoor settings, across simulated and\nreal-world scenarios, demonstrate zero-shot transfer capability of our\napproach, achieving higher success rates and fewer collisions compared to\nbaseline methods. Code will be released at\nhttps://github.com/SYSU-RoboticsLab/NaviD.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-14T09:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.10011v1","title":"KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing\n  DMPs for Occlusion-Rich Tasks","summary":"Dynamic Movement Primitives (DMPs) provide a flexible framework wherein\nsmooth robotic motions are encoded into modular parameters. However, they face\nchallenges in integrating multimodal inputs commonly used in robotics like\nvision and language into their framework. To fully maximize DMPs' potential,\nenabling them to handle multimodal inputs is essential. In addition, we also\naim to extend DMPs' capability to handle object-focused tasks requiring\none-shot complex motion generation, as observation occlusion could easily\nhappen mid-execution in such tasks (e.g., knife occlusion in cake icing, hand\nocclusion in dough kneading, etc.). A promising approach is to leverage\nVision-Language Models (VLMs), which process multimodal data and can grasp\nhigh-level concepts. However, they typically lack enough knowledge and\ncapabilities to directly infer low-level motion details and instead only serve\nas a bridge between high-level instructions and low-level control. To address\nthis limitation, we propose Keyword Labeled Primitive Selection and Keypoint\nPairs Generation Guided Movement Primitives (KeyMPs), a framework that combines\nVLMs with sequencing of DMPs. KeyMPs use VLMs' high-level reasoning capability\nto select a reference primitive through keyword labeled primitive selection and\nVLMs' spatial awareness to generate spatial scaling parameters used for\nsequencing DMPs by generalizing the overall motion through keypoint pairs\ngeneration, which together enable one-shot vision-language guided motion\ngeneration that aligns with the intent expressed in the multimodal input. We\nvalidate our approach through an occlusion-rich manipulation task, specifically\nobject cutting experiments in both simulated and real-world environments,\ndemonstrating superior performance over other DMP-based methods that integrate\nVLMs support.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T09:16:58Z"}
{"aid":"http://arxiv.org/abs/2504.10014v1","title":"Air Quality Prediction with A Meteorology-Guided Modality-Decoupled\n  Spatio-Temporal Network","summary":"Air quality prediction plays a crucial role in public health and\nenvironmental protection. Accurate air quality prediction is a complex\nmultivariate spatiotemporal problem, that involves interactions across temporal\npatterns, pollutant correlations, spatial station dependencies, and\nparticularly meteorological influences that govern pollutant dispersion and\nchemical transformations. Existing works underestimate the critical role of\natmospheric conditions in air quality prediction and neglect comprehensive\nmeteorological data utilization, thereby impairing the modeling of dynamic\ninterdependencies between air quality and meteorological data. To overcome\nthis, we propose MDSTNet, an encoder-decoder framework that explicitly models\nair quality observations and atmospheric conditions as distinct modalities,\nintegrating multi-pressure-level meteorological data and weather forecasts to\ncapture atmosphere-pollution dependencies for prediction. Meantime, we\nconstruct ChinaAirNet, the first nationwide dataset combining air quality\nrecords with multi-pressure-level meteorological observations. Experimental\nresults on ChinaAirNet demonstrate MDSTNet's superiority, substantially\nreducing 48-hour prediction errors by 17.54\\% compared to the state-of-the-art\nmodel. The source code and dataset will be available on github.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-14T09:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.10016v1","title":"Quantifying Privacy Leakage in Split Inference via Fisher-Approximated\n  Shannon Information Analysis","summary":"Split inference (SI) partitions deep neural networks into distributed\nsub-models, enabling privacy-preserving collaborative learning. Nevertheless,\nit remains vulnerable to Data Reconstruction Attacks (DRAs), wherein\nadversaries exploit exposed smashed data to reconstruct raw inputs. Despite\nextensive research on adversarial attack-defense games, a shortfall remains in\nthe fundamental analysis of privacy risks. This paper establishes a theoretical\nframework for privacy leakage quantification using information theory, defining\nit as the adversary's certainty and deriving both average-case and worst-case\nerror bounds. We introduce Fisher-approximated Shannon information (FSInfo), a\nnovel privacy metric utilizing Fisher Information (FI) for operational privacy\nleakage computation. We empirically show that our privacy metric correlates\nwell with empirical attacks and investigate some of the factors that affect\nprivacy leakage, namely the data distribution, model size, and overfitting.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T09:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.10017v1","title":"Bifurcation Theory for a Class of Periodic Superlinear Problems","summary":"We analyze, mainly using bifurcation methods, an elliptic superlinear problem\nin one-dimension with periodic boundary conditions. One of the main novelties\nis that we follow for the first time a bifurcation approach, relying on a\nLyapunov-Schmidt reduction and some recent global bifurcation results, that\nallows us to study the local and global structure of non-trivial solutions at\nbifurcation points where the linearized operator has a two-dimensional kernel.\nIndeed, at such points the classical tools in bifurcation theory, like the\nCrandall-Rabinowitz theorem or some generalizations of it, cannot be applied\nbecause the multiplicity of the eigenvalues is not odd, and a new approach is\nrequired. We apply this analysis to specific examples, obtaining new existence\nand multiplicity results for the considered periodic problems, going beyond the\ninformation variational and fixed point methods like Poincar\\'e-Birkhoff\ntheorem can provide.","main_category":"math.CA","categories":"math.CA,math.DS,math.FA","published":"2025-04-14T09:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.10039v1","title":"Investigating the Role of Bilateral Symmetry for Inpainting Brain MRI","summary":"Inpainting has recently emerged as a valuable and interesting technology to\nemploy in the analysis of medical imaging data, in particular brain MRI. A wide\nvariety of methodologies for inpainting MRI have been proposed and demonstrated\non tasks including anomaly detection. In this work we investigate the\nstatistical relationship between inpainted brain structures and the amount of\nsubject-specific conditioning information, i.e. the other areas of the image\nthat are masked. In particular, we analyse the distribution of inpainting\nresults when masking additional regions of the image, specifically the\ncontra-lateral structure. This allows us to elucidate where in the brain the\nmodel is drawing information from, and in particular, what is the importance of\nhemispherical symmetry? Our experiments interrogate a diffusion inpainting\nmodel through analysing the inpainting of subcortical brain structures based on\nintensity and estimated area change. We demonstrate that some structures show a\nstrong influence of symmetry in the conditioning of the inpainting process.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T09:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.10064v1","title":"Parametric Near-Field MMSE Channel Estimation for sub-THz XL-MIMO\n  Systems","summary":"Accurate channel estimation is essential for reliable communication in\nsub-THz extremely large (XL) MIMO systems. Deploying XL-MIMO in high-frequency\nbands not only increases the number of antennas, but also fundamentally alters\nchannel propagation characteristics, placing the user equipments (UE) in the\nradiative near-field of the base station. This paper proposes a parametric\nestimation method using the multiple signal classification (MUSIC) algorithm to\nextract UE location data from uplink pilot signals. These parameters are used\nto reconstruct the spatial correlation matrix, followed by an approximation of\nthe minimum mean square error (MMSE) channel estimator. Numerical results show\nthat the proposed method outperforms the least-squares (LS) estimator in terms\nof the normalized mean-square error (NMSE), even without prior UE location\nknowledge.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T10:08:15Z"}
{"aid":"http://arxiv.org/abs/2504.10094v1","title":"Local-in-time well-posedness for the regular solution to the 2D full\n  compressible Navier-Stokes equations with degenerate viscosities and heat\n  conductivity","summary":"This paper considers the two-dimensional Cauchy problem of the full\ncompressible Navier-Stokes equations with far-field vacuum in $\\mathbb{R}^2$,\nwhere the viscosity and heat-conductivity coefficients depend on the absolute\ntemperature $\\theta$ in the form of $\\theta^\\nu$ with $\\nu>0$. Due to the\nappearance of the vacuum, the momentum equation are both degenerate in the time\nevolution and spatial dissipation, which makes the study on the well-posedness\nchallenged. By establishing some new singular-weighted (negative powers of the\ndensity $\\rho$) estimates of the solution, we establish the local-in-time\nwell-posedness of the regular solution with far-field vacuum in terms of\n$\\rho$, the velocity $u$ and the entropy $S$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T10:58:53Z"}
{"aid":"http://arxiv.org/abs/2504.10112v1","title":"Benchmarking Practices in LLM-driven Offensive Security: Testbeds,\n  Metrics, and Experiment Design","summary":"Large Language Models (LLMs) have emerged as a powerful approach for driving\noffensive penetration-testing tooling. This paper analyzes the methodology and\nbenchmarking practices used for evaluating Large Language Model (LLM)-driven\nattacks, focusing on offensive uses of LLMs in cybersecurity. We review 16\nresearch papers detailing 15 prototypes and their respective testbeds.\n  We detail our findings and provide actionable recommendations for future\nresearch, emphasizing the importance of extending existing testbeds, creating\nbaselines, and including comprehensive metrics and qualitative analysis. We\nalso note the distinction between security research and practice, suggesting\nthat CTF-based challenges may not fully represent real-world penetration\ntesting scenarios.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-14T11:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.10117v1","title":"AGO: Adaptive Grounding for Open World 3D Occupancy Prediction","summary":"Open-world 3D semantic occupancy prediction aims to generate a voxelized 3D\nrepresentation from sensor inputs while recognizing both known and unknown\nobjects. Transferring open-vocabulary knowledge from vision-language models\n(VLMs) offers a promising direction but remains challenging. However, methods\nbased on VLM-derived 2D pseudo-labels with traditional supervision are limited\nby a predefined label space and lack general prediction capabilities. Direct\nalignment with pretrained image embeddings, on the other hand, fails to achieve\nreliable performance due to often inconsistent image and text representations\nin VLMs. To address these challenges, we propose AGO, a novel 3D occupancy\nprediction framework with adaptive grounding to handle diverse open-world\nscenarios. AGO first encodes surrounding images and class prompts into 3D and\ntext embeddings, respectively, leveraging similarity-based grounding training\nwith 3D pseudo-labels. Additionally, a modality adapter maps 3D embeddings into\na space aligned with VLM-derived image embeddings, reducing modality gaps.\nExperiments on Occ3D-nuScenes show that AGO improves unknown object prediction\nin zero-shot and few-shot transfer while achieving state-of-the-art\nclosed-world self-supervised performance, surpassing prior methods by 4.09\nmIoU.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.10126v1","title":"Polarimetry of exoplanet-exomoon systems","summary":"We investigated the potential of polarimetric observations in the optical\nwavelength range for the detection of exomoons and the characterization of\nexoplanet-exomoon systems. Using the three-dimensional Monte Carlo radiative\ntransfer code POLARIS, we calculated flux and polarization phase curves of\nEarth-like exoplanets with a satellite similar to Earth's moon. Of particular\ninterest are mutual events, when one of the two bodies casts a shadow on the\nother or transits in front of it. We find that the signatures of mutual events\nin the polarization phase curve show significant variations depending on the\ninclination of the lunar orbit. If the planet-satellite pair is spatially\nresolved from the star but the satellite is spatially unresolved, the increase\nin the degree of polarization during a transit of the exomoon in front of the\ncenter of the exoplanet reaches $2.7\\%$ in our model system near quadrature.\nHowever, the change is less than $0.5\\%$ if the orbit of the exomoon is\ninclined such that it transits the planet noncentrally at the same phase\nangles. The influence of an exomoon on the polarization phase curve of an\nexoplanet-exomoon system is dependent on the lunar polarization phase curve.\nObservations of full eclipses and occultations of the exomoon allow the\ndetermination of separate polarization phase curves for the two bodies.\nInformation about the lunar orbital inclination can be obtained with\npolarimetric observations of shadows or transits. Measuring the influence of\nlarge satellites not only on the total flux, but also on the polarization of\nthe reflected stellar radiation during mutual events thus facilitates the\nprediction of future mutual events and the verification of exomoon candidates.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-14T11:34:10Z"}
{"aid":"http://arxiv.org/abs/2504.10129v1","title":"Quasi-Irreducibility of Nonnegative Biquadratic Tensors","summary":"While the adjacency tensor of a bipartite 2-graph is a nonnegative\nbiquadratic tensor, it is inherently reducible. To address this limitation, we\nintroduce the concept of quasi-irreducibility in this paper. The adjacency\ntensor of a bipartite 2-graph is quasi-irreducible if that bipartite 2-graph is\nnot bi-separable. This new concept reveals important spectral properties:\nalthough all M$^+$-eigenvalues are M$^{++}$-eigenvalues for irreducible\nnonnegative biquadratic tensors, the M$^+$-eigenvalues of a quasi-irreducible\nnonnegative biquadratic tensor can be either M$^0$-eigenvalues or\nM$^{++}$-eigenvalues. Furthermore, we establish a max-min theorem for the\nM-spectral radius of a nonnegative biquadratic tensor.","main_category":"math.SP","categories":"math.SP","published":"2025-04-14T11:37:10Z"}
{"aid":"http://arxiv.org/abs/2504.10130v1","title":"A parametrized spin-precessing inspiral-merger-ringdown waveform model\n  for tests of general relativity","summary":"The coalescence of binary black holes (BBHs) provides a unique arena to test\ngeneral relativity (GR) in the dynamical, strong-field regime. To this end, we\npresent pSEOBNRv5PHM, a parametrized, multipolar, spin-precessing waveform\nmodel for BBHs in quasicircular orbits, built within the effective-one-body\nformalism. Compared to its predecessor, pSEOBNRv4HM, our model introduces\nparametrized deviations from GR not only in the plunge-merger-ringdown stages,\nbut also in the inspiral phase through modifications to the conservative\ndynamics. Additionally, it incorporates, for the first time, spin-precession\neffects. The free deviation parameters can be used to perform null tests of GR\nusing current and future gravitational-wave observations. We validate\npSEOBNRv5PHM through Bayesian parameter estimation, focusing on the\nquasinormal-mode frequency and damping time of the $(\\ell,m,n) = (2,2,0)$ mode.\nOur analysis of synthetic signals from numerical-relativity (NR) simulations of\nhighly precessing BH mergers shows that, while pSEOBNRv5PHM correctly recovers\nconsistency with GR, neglecting spin precession can lead to false detections of\ndeviations from GR even at current detector sensitivity. Conversely, when\nanalyzing a synthetic signal from a NR simulation of a binary boson-star\nmerger, the model successfully identifies a deviation from a GR BBH signal.\nFinally, we reanalyze 12 events from the third Gravitational-Wave Transient\nCatalog. Using a hierarchical combination of these events, we constrain\nfractional deviations in the frequency and damping time of the $(2,2,0)$\nquasinormal-mode to $\\delta f_{220}=0.00_{-0.06}^{+0.06}$ and $\\delta\n\\tau_{220}=0.15_{-0.24}^{+0.26}$ at 90% credibility. These results are\nconsistent with those from the LIGO-Virgo-KAGRA Collaboration, which did not\naccount for spin-precession effects.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T11:37:21Z"}
{"aid":"http://arxiv.org/abs/2504.10145v1","title":"Estimating the dense gas mass of molecular clouds using spatially\n  unresolved 3 mm line observations","summary":"We aim to develop a new method to infer the sub-beam probability density\nfunction (PDF) of H2 column densities and the dense gas mass within molecular\nclouds using spatially unresolved observations of molecular emission lines in\nthe 3 mm band. We model spatially unresolved line integrated intensity\nmeasurements as the average of an emission function weighted by the sub-beam\ncolumn density PDF. The emission function, which expresses the line integrated\nintensity as a function of the gas column density, is an empirical fit to high\nresolution (< 0.05 pc) multi-line observations of the Orion B molecular cloud.\nThe column density PDF is assumed to be parametric, composed of a lognormal\ndistribution at moderate column densities and a power law distribution at\nhigher column densities. To estimate the sub-beam column density PDF, the\nemission model is combined with a Bayesian inversion algorithm (the Beetroots\ncode), which takes account of thermal noise and calibration errors. We validate\nour method by demonstrating that it recovers the true column density PDF of the\nOrion B cloud, reproducing the observed emission line integrated intensities.\nWe apply the method to 12CO(J=1-0), 13CO(J=1-0), C18O(J=1-0), HCN(J=1-0),\nHCO+(J=1-0) and N2H+(J=1-0) observations of a 700 x 700 pc2 field of view (FoV)\nin the nearby galaxy M51. On average, the model reproduces the observed\nintensities within 30%. The column density PDFs obtained for the spiral arm\nregion within our test FoV are dominated by a power-law tail at high column\ndensities, with slopes that are consistent with gravitational collapse. Outside\nthe spiral arm, the column density PDFs are predominantly lognormal, consistent\nwith supersonic isothermal turbulence. We calculate the mass associated with\nthe powerlaw tail of the column density PDFs and observe a strong, linear\ncorrelation between this mass and the 24$\\mu$m surface brightness.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.IM","published":"2025-04-14T11:56:40Z"}
{"aid":"http://arxiv.org/abs/2504.10170v1","title":"Axion Mixing in the String Axiverse","summary":"The string axiverse presents a fascinating and complex landscape for axion\nphysics. In this work, we study axion mass mixing within the type IIB string\naxiverse, focusing specifically on the LARGE volume scenario (LVS) axiverse.\nThe LVS axiverse necessitates at least two axions to ensure the presence of\nboth a QCD axion candidate and at least one additional axion-like particle\n(ALP). This study presents the first systematic exploration of axion mass\nmixing in scenarios involving more than two axions. The maximal mixing occurs\nwhen the masses of all ALPs are smaller than the zero-temperature mass of the\nQCD axion, with no two ALP masses being equal, and when the decay constants of\nall ALPs are simultaneously either smaller or larger than the decay constant of\nthe QCD axion. Additionally, the transfer of axion energy density ultimately\ntakes place only between the two axions with the closest masses. These findings\nprovide critical insights into axion dynamics not only within type IIB string\naxiverse models but also in broader multi-axion mixing frameworks. The\npotential cosmological implications of axion mass mixing are also addressed at\nthe end. Our work contributes to the understanding of axion physics in string\ntheory.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-14T12:24:46Z"}
{"aid":"http://arxiv.org/abs/2504.10174v1","title":"LLaVA-ReID: Selective Multi-image Questioner for Interactive Person\n  Re-Identification","summary":"Traditional text-based person ReID assumes that person descriptions from\nwitnesses are complete and provided at once. However, in real-world scenarios,\nsuch descriptions are often partial or vague. To address this limitation, we\nintroduce a new task called interactive person re-identification (Inter-ReID).\nInter-ReID is a dialogue-based retrieval task that iteratively refines initial\ndescriptions through ongoing interactions with the witnesses. To facilitate the\nstudy of this new task, we construct a dialogue dataset that incorporates\nmultiple types of questions by decomposing fine-grained attributes of\nindividuals. We further propose LLaVA-ReID, a question model that generates\ntargeted questions based on visual and textual contexts to elicit additional\ndetails about the target person. Leveraging a looking-forward strategy, we\nprioritize the most informative questions as supervision during training.\nExperimental results on both Inter-ReID and text-based ReID benchmarks\ndemonstrate that LLaVA-ReID significantly outperforms baselines.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T12:26:31Z"}
{"aid":"http://arxiv.org/abs/2504.10176v1","title":"SEMPO - Retrieving poles, residues and zeros in the complex frequency\n  plane from an arbitrary spectral response","summary":"The Singularity Expansion Method Parameter Optimizer - SEMPO - is a toolbox\nto extract the complex poles, zeros and residues of an arbitrary response\nfunction acquired along the real frequency axis. SEMPO allows to determine this\nfull set of complex parameters of linear physical systems from their spectral\nresponses only, without prior information about the system. The method\nleverages on the Singularity Expansion Method of the physical signal. This\nanalytical expansion of the meromorphic function in the complex frequency plane\nmotivates the use of the Cauchy method and auto-differentiation-based\noptimization approach to retrieve the complex poles, zeros and residues from\nthe knowledge of the spectrum over a finite and real spectral range. Both\napproaches can be sequentially associated to provide highly accurate\nreconstructions of physical signals in large spectral windows. The performances\nof SEMPO are assessed and analysed in several configurations that include the\ndielectric permittivity of materials and the optical response spectra of\nvarious optical metasurfaces.","main_category":"physics.optics","categories":"physics.optics,math-ph,math.MP,physics.comp-ph","published":"2025-04-14T12:27:57Z"}
{"aid":"http://arxiv.org/abs/2504.10183v1","title":"Strong decays of singly heavy baryons","summary":"More and more excited baryons have been reported experimentally, but many\nproperties are still unclear. This work attempts to simultaneously study the\nmasses and strong decay widths of some singly heavy baryons, in order to\nprovide possible quantum numbers for these states. The chiral quark model and\nthe $^{3}P_{0}$ decay model are employed to calculate the masses and decay\nwidths of $\\Lambda_{c(b)}$ and $\\Sigma_{c(b)}$ baryons for all quantum numbers\nwith $2S$, $1P$, and $2P$ waves. We considered not only two-body strong decays\nbut also the influence of three-body decays. Our calculations show that: (i)\nFor states with experimentally determined quantum numbers, such as\n$\\Lambda_c(2595)$, $\\Lambda_c(2625)$, $\\Lambda_b(5912)$ and $\\Lambda_b(5920)$,\nthe results are consistent with experimental data and the conclusions of most\ntheoretical studies. (ii) For states whose quantum numbers have not yet been\nfully determined experimentally, we provide possible interpretations. For\nexample, our calculations tend to interpret $\\Lambda_c(2910)$ is interpreted as\na $J^P=\\frac{3}{2}^-$ state with 1P-wave $\\rho$-mode or a $J^P=\\frac{1}{2}^-$\nstate with 2P wave $\\lambda$-mode. $\\Lambda_c(2940)$ can be interpreted as the\n$J^P=\\frac{3}{2}^-$ state with 2P-wave $\\lambda$-mode. For $\\Lambda_c(2860)$,\nwe offer a different interpretation, proposing that its mass and width closely\nmatch those of a 2P-wave $J^P=\\frac{1}{2}^{-}$ state. It is hoped that our\ncalculations can provide valuable information for the experimental and\ntheoretical studies of heavy baryons.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-th","published":"2025-04-14T12:37:20Z"}
{"aid":"http://arxiv.org/abs/2504.10186v1","title":"Entanglement-Enabled Connectivity Bounds for Quantum Networks","summary":"In the Quantum Internet, multipartite entanglement enables a new form of\nnetwork connectivity, referred to as artificial connectivity namely and able to\naugment the physical connectivity with artificial links between pairs of nodes,\nwithout any additional physical link deployment. In this paper, by engineering\nsuch an artificial connectivity, we theoretically determine upper and lower\nbounds for the number of EPR pairs and GHZ states that can be extracted among\nnodes that are not adjacent in the artificial network topology. The\naforementioned analysis is crucial, since the extraction of EPR pairs and GHZ\nstates among remote nodes constitutes the resource primitives for on-demand and\nend-to-end communications. Indeed, within the paper, we not only determine\nwhether a certain number of remote EPR pairs and GHZ states can be extracted,\nbut we also provide the locations, namely the identities, of the nodes\ninterconnected by such entangled resources. Thus, our analysis is far from\nbeing purely theoretical, rather it is constructive, since we provide the\nsequence of operations required for performing such extractions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T12:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.10189v1","title":"Topological exciton bands and many-body exciton phases in transition\n  metal dichalcogenide trilayer heterostructures","summary":"Twisted multilayer transition metal dichalcogenides (TMDs) are a promising\nplatform for realizing topological exciton phases. Here we propose that twisted\nTMD heterotrilayers WX$_2$/MX$_2$/WX$_2$ with layer symmetry represents a\nrealistic system for realizing topological exciton bands and interesting\nmany-body excitonic phases, simply by tuning the twist angle. These symmetric\nheterotrilayers form a type-II band alignment, where the electrons are confined\nin the middle layer and holes are distributed among the outer two layers, for\nthe lowest energy excitons. The outer two layers are then rotated at different\ncenters by opposite angles, forming a helical structure. Interlayer excitons\nwith opposite dipoles are hybridized by the coupling between outer two layers,\nresulting in topological moir\\'e exciton bands. Furthermore, by constructing a\nthree-orbital tight-binding model, we map the many-body phase diagram of\ninteracting dipolar and quadrupolar excitons at different twist angles and\nexciton densities and reveal the existence of sublattice-dependent staggered\nsuperfluid and Mott insulator phases. The recent experimental observation of\nquadrupolar excitons in symmetric heterotrilayers brings the intriguing phases\npredicted in this study within immediate experimental reach.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T12:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.10190v1","title":"Differentially Private 2D Human Pose Estimation","summary":"Human pose estimation (HPE) has become essential in numerous applications\nincluding healthcare, activity recognition, and human-computer interaction.\nHowever, the privacy implications of processing sensitive visual data present\nsignificant deployment barriers in critical domains. While traditional\nanonymization techniques offer limited protection and often compromise data\nutility for broader motion analysis, Differential Privacy (DP) provides formal\nprivacy guarantees but typically degrades model performance when applied\nnaively. In this work, we present the first differentially private 2D human\npose estimation (2D-HPE) by applying Differentially Private Stochastic Gradient\nDescent (DP-SGD) to this task. To effectively balance privacy with performance,\nwe adopt Projected DP-SGD (PDP-SGD), which projects the noisy gradients to a\nlow-dimensional subspace. Additionally, we adapt TinyViT, a compact and\nefficient vision transformer for coordinate classification in HPE, providing a\nlightweight yet powerful backbone that enhances privacy-preserving deployment\nfeasibility on resource-limited devices. Our approach is particularly valuable\nfor multimedia interpretation tasks, enabling privacy-safe analysis and\nunderstanding of human motion across diverse visual media while preserving the\nsemantic meaning required for downstream applications. Comprehensive\nexperiments on the MPII Human Pose Dataset demonstrate significant performance\nenhancement with PDP-SGD achieving 78.48% PCKh@0.5 at a strict privacy budget\n($\\epsilon=0.2$), compared to 63.85% for standard DP-SGD. This work lays\nfoundation for privacy-preserving human pose estimation in real-world,\nsensitive applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T12:50:37Z"}
{"aid":"http://arxiv.org/abs/2504.10198v1","title":"DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization\n  for Dynamic Retrieval-Augmented Generation","summary":"Dynamic Retrieval-augmented Generation (RAG) has shown great success in\nmitigating hallucinations in large language models (LLMs) during generation.\nHowever, existing dynamic RAG methods face significant limitations in two key\naspects: 1) Lack of an effective mechanism to control retrieval triggers, and\n2) Lack of effective scrutiny of retrieval content. To address these\nlimitations, we propose an innovative dynamic RAG method, DioR (Adaptive\nCognitive Detection and Contextual Retrieval Optimization), which consists of\ntwo main components: adaptive cognitive detection and contextual retrieval\noptimization, specifically designed to determine when retrieval is needed and\nwhat to retrieve for LLMs is useful. Experimental results demonstrate that DioR\nachieves superior performance on all tasks, demonstrating the effectiveness of\nour work.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T13:02:53Z"}
{"aid":"http://arxiv.org/abs/2504.10200v1","title":"Stability analysis of discrete Boltzmann simulation for supersonic\n  flows: Influencing factors, coupling mechanisms and optimization strategies","summary":"Supersonic flow simulations face challenges in trans-scale modeling,\nnumerical stability, and complex field analysis due to inherent nonlinear,\nnonequilibrium, and multiscale characteristics. The discrete Boltzmann method\n(DBM) provides a multiscale kinetic modeling framework and analysis tool to\ncapture complex discrete/nonequilibrium effects. While the numerical scheme\nplays a fundamental role in DBM simulations, a comprehensive stability analysis\nremains lacking. Similar to LBM, the complexity mainly arises from the\nintrinsic coupling between velocity and spatiotemporal discretizations,\ncompared with CFD. This study applies von Neumann stability analysis to\ninvestigate key factors influencing DBM simulation stability, including\nphase-space discretization, thermodynamic nonequilibrium (TNE) levels,\nspatiotemporal schemes, initial conditions, and model parameters. Key findings\ninclude: (i) the moment-matching approach outperforms expansion- and\nweighting-based methods in the test simulations; (ii) increased TNE enhances\nsystem nonlinearity and the intrinsic nonlinearity embedded in the model\nequations, amplifying instabilities; (iii) additional viscous dissipation based\non distribution functions improves stability but distorts flow fields and\nalters constitutive relations; (iv) larger CFL numbers and relative time steps\ndegrade stability, necessitating appropriate time-stepping strategies. To\nassess the stability regulation capability of DBMs across TNE levels,\nstability-phase diagrams and probability curves are constructed via\nmorphological analysis within the moment-matching framework. These diagrams\nidentify common stable parameter regions across model orders. This study\nreveals key factors and coupling mechanisms affecting DBM stability and\nproposes strategies for optimizing equilibrium distribution discretization,\nvelocity design, and parameter selection in supersonic regimes.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-14T13:04:58Z"}
{"aid":"http://arxiv.org/abs/2504.10207v1","title":"Generalized Natural Density $\\DF(\\mathfrak{F}_n)$ of Fibonacci Word","summary":"This paper explores profound generalizations of the Fibonacci sequence,\ndelving into random Fibonacci sequences, $k$-Fibonacci words, and their\ncombinatorial properties. We established that the $n$-th root of the absolute\nvalue of terms in a random Fibonacci sequence converges to $1.13198824\\ldots$,\na symmetry identity for sums involving Fibonacci words, $\\sum_{n=1}^{b}\n\\frac{(-1)^n F_a}{F_n F_{n+a}} = \\sum_{n=1}^{a} \\frac{(-1)^n F_b}{F_n\nF_{n+b}}$, and an infinite series identity linking Fibonacci terms to the\ngolden ratio. These findings underscore the intricate interplay between number\ntheory and combinatorics, illuminating the rich structure of Fibonacci-related\nsequences. We provide, according to this paper, new concepts of density of\nFibonacci word.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T13:17:38Z"}
{"aid":"http://arxiv.org/abs/2504.10239v1","title":"Elastic displacements in wedge-shaped geometries with a straight edge:\n  Green's functions for perpendicular forces","summary":"Edges are abundant when fluids are contained in vessels or elastic solids\nglide in guiding rails. We here address induced small-scale flows in viscous\nfluids or displacements in elastic solids in the vicinity of one such edge. For\nthis purpose, we solve the underlying low-Reynolds-number flow equations for\nincompressible fluids and the elasticity equations for linearly elastic,\npossibly compressible solids. Technically speaking, we derive the associated\nGreen's functions under confinement by two planar boundaries that meet at a\nstraight edge. The two boundaries both feature no-slip or free-slip conditions,\nor one of these two conditions per boundary. Previously, we solved the simpler\ncase of the force being oriented parallel to the straight edge. Here, we\ncomplement this solution by the more challenging case of the force pointing\ninto a direction perpendicular to the edge. Together, these two cases provide\nthe general solution. Specific situations in which our analysis may find\napplication in terms of quantitative theoretical descriptions are particle\nmotion in confined colloidal suspensions, dynamics of active microswimmers near\nedges, or actuated distortions of elastic materials due to activated contained\nfunctionalized particles.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-14T14:01:53Z"}
{"aid":"http://arxiv.org/abs/2504.10243v1","title":"A parton shower consistent with parton densities at LO and NLO: PDF2ISR","summary":"We present a method for obtaining an initial-state parton shower model where\nthe (backward) evolution fully consistent with the (forward) evolution of the\ncollinear parton density used. As a proof-of-concept we use parton densities\nobtained with the Parton Branching (PB) approach, and modify the default\ninitial-state shower in PYTHIA8 with this method to be consistent with them. PB\nis ideally suited for checking the validity of our method since, in addition to\nproducing collinear parton densities, it also produces the corresponding\ntransverse-dependent (TMD) ones, and these can then be directly compared to the\ntransverse momentum distribution obtained from the parton shower. We show that\nTMD distributions which we in this way obtain from our modified PYTHIA8 shower\nusing leading order (LO) parton densities and splitting functions are fully\nconsistent with the corresponding leading order TMD densities. At\nnext-to-leading order (NLO) it is not possible to achieve the same consistency\nusing the built-in LO splitting functions in the shower, but we show that by\nintroducing NLO splitting functions using a reweighting procedure, we can\nachieve consistency also at NLO. The method presented here, which we have named\nPDF2ISR, can be easily extended to any collinear parton densities, as long as\nthe exact conditions for the evolution are known. With the PDF2ISR method we\nobtain an initial-state parton shower which in principle has no free\nparameters, and is fully consistent with collinear parton densities at LO and\nNLO.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-th","published":"2025-04-14T14:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.10252v1","title":"MapperEEG: A Topological Approach to Brain State Clustering in EEG\n  Recordings","summary":"Electrical potential scalp recordings (Electroencephalograms-EEGs) are a\ncommon tool used to investigate brain activity. EEG is routinely used in\nclinical applications as well as in research studies thanks to its noninvasive\nnature, relatively inexpensive equipment, and high temporal resolution. But,\nEEG is prone to contamination from movement artifacts and signals from external\nsources. Thus, it requires advanced signal processing and mathematical analysis\nmethods in tasks requiring brain state identification. Recently, tools from\ntopological data analysis have been used successfully across many domains,\nincluding brain research, however these uses have been limited to fMRI\ndatasets. We introduce the topological tool MapperEEG (M-EEG) and provide an\nexample of it's ability to separate different brain states during a simple\nfinger tapping teaming task without any pre-labeling or prior knowledge. M-EEG\nuses the power spectral density applied to traditional EEG frequency bands\ncombined with the Mapper algorithm from topological data analysis to capture\nthe underlying structure of the data and represent that structure as a graph in\ntwo-dimensional space. This tool provides clear separation (clustering) of\nstates during different conditions of the experiment (syncopated vs.\nsynchronized) and we demonstrate that M-EEG outperforms other clustering\nmethods when applied to EEG data.","main_category":"math.GN","categories":"math.GN","published":"2025-04-14T14:13:48Z"}
{"aid":"http://arxiv.org/abs/2504.10262v1","title":"Whittaker modules for $U_q(\\mathfrak{sl}_3)$","summary":"In this paper, we study the Whittaker modules for the quantum enveloping\nalgebra $U_q(\\sl_3)$ with respect to a fixed Whittaker function. We construct\nthe universal Whittaker module, find all its Whittaker vectors and investigate\nthe submodules generated by subsets of Whittaker vectors and corresponding\nquotient modules. We also find Whittaker vectors and determine the\nirreducibility of these quotient modules and show that they exhaust all\nirreducible Whittaker modules. Finally, we can determine all maximal submodules\nof the universal Whittaker module. The Whittaker model of $U_q(\\sl_3)$ are\nquite different from that of $U_q(\\sl_2)$ and finite-dimensional simple Lie\nalgebras, since the center of our algebra is not a polynomial algebra.","main_category":"math.RT","categories":"math.RT","published":"2025-04-14T14:27:35Z"}
{"aid":"http://arxiv.org/abs/2504.10273v1","title":"Sidecar: A Structure-Preserving Framework for Solving Partial\n  Differential Equations with Neural Networks","summary":"Solving partial differential equations (PDEs) with neural networks (NNs) has\nshown great potential in various scientific and engineering fields. However,\nmost existing NN solvers mainly focus on satisfying the given PDEs, without\nexplicitly considering intrinsic physical properties such as mass conservation\nor energy dissipation. This limitation can result in unstable or nonphysical\nsolutions, particularly in long-term simulations. To address this issue, we\npropose Sidecar, a novel framework that enhances the accuracy and physical\nconsistency of existing NN solvers by incorporating structure-preserving\nknowledge. Inspired by the Time-Dependent Spectral Renormalization (TDSR)\napproach, our Sidecar framework introduces a small copilot network, which is\ntrained to guide the existing NN solver in preserving physical structure. This\nframework is designed to be highly flexible, enabling the incorporation of\nstructure-preserving principles from diverse PDEs into a wide range of NN\nsolvers. Our experimental results on benchmark PDEs demonstrate the improvement\nof the existing neural network solvers in terms of accuracy and consistency\nwith structure-preserving properties.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-14T14:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.10305v1","title":"Commutator subalgebra of the Lie algebra associated with a right-angled\n  Coxeter group","summary":"We study the graded Lie algebra $L(RC_K)$ associated with the lower central\nseries of a right-angled Coxeter group $RC_K$. We prove that its commutator\nsubalgebra is a quotient of the polynomial ring over an auxiliary Lie\nsubalgebra $N_K$ of the graph Lie algebra $L_K$, and conjecture that the\nquotient map is an isomorphism. The epimorphism is defined in terms of a new\noperation in the associated Lie algebra, which corresponds to the squaring and\nhas an analogue in homotopy theory.","main_category":"math.GR","categories":"math.GR,math.AT","published":"2025-04-14T15:13:49Z"}
{"aid":"http://arxiv.org/abs/2504.10309v1","title":"AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style\n  Matching Text-to-Speech Synthesis","summary":"With the advancement of speech synthesis technology, users have higher\nexpectations for the naturalness and expressiveness of synthesized speech. But\nprevious research ignores the importance of prompt selection. This study\nproposes a text-to-speech (TTS) framework based on Retrieval-Augmented\nGeneration (RAG) technology, which can dynamically adjust the speech style\naccording to the text content to achieve more natural and vivid communication\neffects. We have constructed a speech style knowledge database containing\nhigh-quality speech samples in various contexts and developed a style matching\nscheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and\nMoka, to match with samples in the knowledge database, selecting the most\nappropriate speech style for synthesis. Furthermore, our empirical research\nvalidates the effectiveness of the proposed method. Our demo can be viewed at:\nhttps://thuhcsi.github.io/icme2025-AutoStyle-TTS","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-14T15:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.10341v1","title":"Comment on \"Consequences of the single-pair measurement of the Bell\n  parameter\"","summary":"In a recent article [Phys. Rev. A 111, 022204 (2025)], Genovese and\nPiacentini analyzed recent experiments measuring what they call \"the entire\nBell-CHSH parameter\". They claimed those experiments may have implications for\ninterpreting loophole-fee tests of the Bell-CHSH inequality. We explain that\nthe Bell-CHSH inequality is not based on the entire Bell parameter, so these\nexperiments are unrelated to their empirical tests and cannot close eventual\nloopholes that still might persist. We point out that the physical meaning of\nthese new experiments measuring the entire Bell parameter could be interpreted\ndifferently.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T15:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.10342v1","title":"VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain\n  Knowledge","summary":"Current multimodal benchmarks often conflate reasoning with domain-specific\nknowledge, making it difficult to isolate and evaluate general reasoning\nabilities in non-expert settings. To address this, we introduce VisualPuzzles,\na benchmark that targets visual reasoning while deliberately minimizing\nreliance on specialized knowledge. VisualPuzzles consists of diverse questions\nspanning five categories: algorithmic, analogical, deductive, inductive, and\nspatial reasoning. One major source of our questions is manually translated\nlogical reasoning questions from the Chinese Civil Service Examination.\nExperiments show that VisualPuzzles requires significantly less intensive\ndomain-specific knowledge and more complex reasoning compared to benchmarks\nlike MMMU, enabling us to better evaluate genuine multimodal reasoning.\nEvaluations show that state-of-the-art multimodal large language models\nconsistently lag behind human performance on VisualPuzzles, and that strong\nperformance on knowledge-intensive benchmarks does not necessarily translate to\nsuccess on reasoning-focused, knowledge-light tasks. Additionally, reasoning\nenhancements such as scaling up inference compute (with \"thinking\" modes) yield\ninconsistent gains across models and task types, and we observe no clear\ncorrelation between model size and performance. We also found that models\nexhibit different reasoning and answering patterns on VisualPuzzles compared to\nbenchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer\nlens through which to evaluate reasoning capabilities beyond factual recall and\ndomain knowledge.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T15:50:39Z"}
{"aid":"http://arxiv.org/abs/2504.10348v1","title":"Improving diffusion modeling in all-solid-state lithium batteries: a\n  novel approach for grain boundary effects","summary":"All-solid-state lithium-ion batteries offer promising advantages with respect\nto capacity, safety, and performance. The diffusion behavior of lithium ions in\nthe contained polycrystalline solid-state electrolyte is crucial for battery\nfunction. While atomistic studies indicate that grain boundaries (GBs) and\ngrain size significantly impact diffusivity, the corresponding effects are\neither neglected in simulations on larger scales or considered only under\nstrong assumptions such as isotropy. Our approach considers the fully resolved\ncrystalline structure with a parametrization aligned with the atomistic\nperspective to describe diffusion along and across GBs. The approach is\nembedded into a finite element simulation using a novel collapsed interface\nelement based on an analytical description in thickness direction. Results are\ngoverned by different and potentially anisotropic diffusion coefficients in\nbulk and GB domains. The mesoscale response is derived using linear\ncomputational homogenization to capture large-scale effects. The novel\ncollapsed interface description allows for a reconstruction of the 3D transport\nbehavior within the GB domain without resolving it and is able to capture the\nrelevant transport mechanisms such as channeling effects and concentration\njumps. Grain size and GB volume fraction are expressed in terms of an affine\nparameter dependence and can be altered without any changes to geometry or\nmesh. Together with the observed dependence of the effective material response\non the anisotropic GB parametrization, this leads to the identification of four\ndistinct diffusion regimes, each with implications for the design of battery\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T15:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.10361v1","title":"Root-$T\\bar{T}$ Deformations On Causal Self-Dual Electrodynamics\n  Theories","summary":"The self-dual condition, which ensures invariance under electromagnetic\nduality, manifests as a partial differential equation in nonlinear\nelectromagnetism theories. The general solution to this equation is expressed\nin terms of an auxiliary field, $\\tau$, and Courant-Hilbert functions,\n$\\ell(\\tau)$, which depend on $\\tau$. Recent studies have shown that\nduality-invariant nonlinear electromagnetic theories fulfill the principle of\ncausality under the conditions $\\frac{\\partial \\ell}{\\partial \\tau} \\ge 1$ and\n$\\frac{\\partial^2 \\ell}{\\partial \\tau^2} \\ge 0$.\n  In this paper, we investigate theories with two coupling constants that also\ncomply with the principle of causality. We demonstrate that these theories\npossess a new universal representation of the root-$T\\bar{T}$ operator.\nAdditionally, we derive marginal and irrelevant flow equations for the\nlogarithmic causal self-dual electrodynamics and identify a symmetry referred\nto as $\\alpha$-symmetry, which is present in all these models.","main_category":"hep-th","categories":"hep-th","published":"2025-04-14T16:08:34Z"}
{"aid":"http://arxiv.org/abs/2504.10365v1","title":"Staggering and Fragmentation for Improved Large Message Handling in\n  libp2p GossipSub","summary":"The libp2p GossipSub protocol leverages a full-message mesh with a lower node\ndegree and a more densely connected metadata-only (gossip) mesh. This\ncombination allows an efficient dissemination of messages in unstructured\npeer-to-peer (P2P) networks. However, GossipSub needs to consider message size,\nwhich is crucial for the efficient operation of many applications, such as\nhandling large Ethereum blocks. This paper proposes modifications to improve\nGossipSub's performance when transmitting large messages. We evaluate the\nproposed improvements using the shadow simulator. Our results show that the\nproposed improvements significantly enhance GossipSub's performance for large\nmessage transmissions in sizeable networks.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-14T16:10:41Z"}
{"aid":"http://arxiv.org/abs/2504.10370v1","title":"Further Comments on Yablo's Construction","summary":"We continue our analysis of Yablo's coding of the liar paradox by infinite\nacyclic graphs. The present notes are based on and continue the author's\nprevious results on the problem. In particular, our approach is often more\nsystematic than before.","main_category":"math.CO","categories":"math.CO,cs.LO","published":"2025-04-14T16:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.10401v1","title":"Selectivity gain in olfactory receptor neuron at optimal odor\n  concentration","summary":"It has been discovered before (arXiv:2306.07676) that for the selectivity\ngain due to fluctuations in the process of primary odor reception by olfactory\nreceptor neuron (ORN) there exists an optimal concentration of odors at which\nincreased selectivity is mostly manifested. We estimate by means of numerical\nsimulation what could be the gain value at that concentration by modeling ORN\nas a leaky integrate-and-fire neuron with membrane populated by receptor\nproteins R which bind and release odor molecules randomly. Each R is modeled as\na ligand-gated ion channel, and binding-releasing is modeled as a Markov\nstochastic process. Possible values for the selectivity gain are calculated for\nORN parameters suggested by experimental data.\n  Keywords: ORN, selectivity, receptor proteins, fluctuations, stochastic\nprocess, Markov process","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-14T16:51:25Z"}
{"aid":"http://arxiv.org/abs/2504.10428v1","title":"Learning with Positive and Imperfect Unlabeled Data","summary":"We study the problem of learning binary classifiers from positive and\nunlabeled data when the unlabeled data distribution is shifted, which we call\nPositive and Imperfect Unlabeled (PIU) Learning. In the absence of covariate\nshifts, i.e., with perfect unlabeled data, Denis (1998) reduced this problem to\nlearning under Massart noise; however, that reduction fails under even slight\nshifts.\n  Our main results on PIU learning are the characterizations of the sample\ncomplexity of PIU learning and a computationally and sample-efficient algorithm\nachieving a misclassification error $\\varepsilon$. We further show that our\nresults lead to new algorithms for several related problems.\n  1. Learning from smooth distributions: We give algorithms that learn\ninteresting concept classes from only positive samples under smooth feature\ndistributions, bypassing known existing impossibility results and contributing\nto recent advances in smoothened learning (Haghtalab et al, J.ACM'24)\n(Chandrasekaran et al., COLT'24).\n  2. Learning with a list of unlabeled distributions: We design new algorithms\nthat apply to a broad class of concept classes under the assumption that we are\ngiven a list of unlabeled distributions, one of which--unknown to the\nlearner--is $O(1)$-close to the true feature distribution.\n  3. Estimation in the presence of unknown truncation: We give the first\npolynomial sample and time algorithm for estimating the parameters of an\nexponential family distribution from samples truncated to an unknown set\napproximable by polynomials in $L_1$-norm. This improves the algorithm by Lee\net al. (FOCS'24) that requires approximation in $L_2$-norm.\n  4. Detecting truncation: We present new algorithms for detecting whether\ngiven samples have been truncated (or not) for a broad class of non-product\ndistributions, including non-product distributions, improving the algorithm by\nDe et al. (STOC'24).","main_category":"stat.ML","categories":"stat.ML,cs.DS,cs.LG,math.ST,stat.TH","published":"2025-04-14T17:19:29Z"}
{"aid":"http://arxiv.org/abs/2504.10431v1","title":"Comparison of symplectic capacities","summary":"In this paper, we compare the symplectic (co)homology capacity with the\nspectral capacity in the relative case. This result establishes a chain of\ninequalities of relative symplectic capacities, which is an analogue of the\nnon-relative case. This comparison gives us a criterion for the relative almost\nexistence theorem in terms of heaviness. Also, we investigate a sufficient\ncondition under which the symplectic (co)homology capacity and the first\nGutt-Hutchings capacity are equal in both non-relative and relative cases. This\ncondition is less restrictive than the dynamical convexity.","main_category":"math.SG","categories":"math.SG","published":"2025-04-14T17:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.10432v1","title":"Invariance Matters: Empowering Social Recommendation via Graph Invariant\n  Learning","summary":"Graph-based social recommendation systems have shown significant promise in\nenhancing recommendation performance, particularly in addressing the issue of\ndata sparsity in user behaviors. Typically, these systems leverage Graph Neural\nNetworks (GNNs) to capture user preferences by incorporating high-order social\ninfluences from observed social networks. However, existing graph-based social\nrecommendations often overlook the fact that social networks are inherently\nnoisy, containing task-irrelevant relationships that can hinder accurate user\npreference learning. The removal of these redundant social relations is\ncrucial, yet it remains challenging due to the lack of ground truth. In this\npaper, we approach the social denoising problem from the perspective of graph\ninvariant learning and propose a novel method, Social Graph Invariant\nLearning(SGIL). Specifically,SGIL aims to uncover stable user preferences\nwithin the input social graph, thereby enhancing the robustness of graph-based\nsocial recommendation systems. To achieve this goal, SGIL first simulates\nmultiple noisy social environments through graph generators. It then seeks to\nlearn environment-invariant user preferences by minimizing invariant risk\nacross these environments. To further promote diversity in the generated social\nenvironments, we employ an adversarial training strategy to simulate more\npotential social noisy distributions. Extensive experimental results\ndemonstrate the effectiveness of the proposed SGIL. The code is available at\nhttps://github.com/yimutianyang/SIGIR2025-SGIL.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T17:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.10444v1","title":"Maximum entropy modeling of Optimal Transport: the sub-optimality regime\n  and the transition from dense to sparse networks","summary":"We present a bipartite network model that captures intermediate stages of\noptimization by blending the Maximum Entropy approach with Optimal Transport.\nIn this framework, the network's constraints define the total mass each node\ncan supply or receive, while an external cost field favors a minimal set of\nlinks, driving the system toward a sparse, tree-like structure. By tuning the\ncontrol parameter, one transitions from uniformly distributed weights to an\noptimal transport regime in which weights condense onto cost-favorable edges.\nWe quantify this dense-to-sparse transition, showing with numerical analyses\nthat the process does not hinge on specific assumptions about the node-strength\nor cost distributions. Finite-size analysis confirms that the results persist\nin the thermodynamic limit. Because the model offers explicit control over the\ndegree of sub-optimality, this approach lends to practical applications in link\nprediction, network reconstruction, and statistical validation, particularly in\nsystems where partial optimization coexists with other noise-like factors.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-14T17:36:45Z"}
{"aid":"http://arxiv.org/abs/2504.10449v1","title":"M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models","summary":"Effective reasoning is crucial to solving complex mathematical problems.\nRecent large language models (LLMs) have boosted performance by scaling\ntest-time computation through long chain-of-thought reasoning. However,\ntransformer-based models are inherently limited in extending context length due\nto their quadratic computational complexity and linear memory requirements. In\nthis paper, we introduce a novel hybrid linear RNN reasoning model, M1, built\non the Mamba architecture, which allows memory-efficient inference. Our\napproach leverages a distillation process from existing reasoning models and is\nfurther enhanced through RL training. Experimental results on the AIME and MATH\nbenchmarks show that M1 not only outperforms previous linear RNN models but\nalso matches the performance of state-of-the-art Deepseek R1 distilled\nreasoning models at a similar scale. We also compare our generation speed with\na highly performant general purpose inference engine, vLLM, and observe more\nthan a 3x speedup compared to a same size transformer. With throughput speedup,\nwe are able to achieve higher accuracy compared to DeepSeek R1 distilled\ntransformer reasoning models under a fixed generation time budget using\nself-consistency voting. Overall, we introduce a hybrid Mamba reasoning model\nand provide a more effective approach to scaling test-time generation using\nself-consistency or long chain of thought reasoning.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T17:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.10482v1","title":"Cosmology with the angular cross-correlation of gravitational-wave and\n  galaxy catalogs: forecasts for next-generation interferometers and the Euclid\n  survey","summary":"We study the angular power spectrum of gravitational-wave and galaxy catalogs\nin tomographic redshift and distance bins as a probe of late-time cosmology,\nfocusing specifically on next-generation ground-based interferometers in\ncombination with the Euclid photometric survey. We assess the potential of this\ntechnique to constrain the Hubble constant and the matter energy density. Our\nanalysis incorporates realistic gravitational-wave source populations, error\nmodelling calibrated on recent detector designs, and accounts for nuisance\nparameters. We show that the tomographic angular cross-correlation could\ndetermine the Hubble constant to percent or sub-percent precision depending on\nthe binning choice, configuration and operation time of gravitational-wave\nobservatories. This conclusion holds even when marginalising over the unknown\ntracer biases, primordial power-spectrum parameters and baryon density. In\nparticular, we show that the combination of the galaxy auto-correlation spectra\nand the cross-correlation of gravitational waves and galaxy surveys can lead to\nan improvement of up to a factor ${{\\sim}}10$ in constraining power over either\nof the two probes taken individually. However, this prospect crucially relies\non the presence of multiple gravitational-wave interferometers able to yield\nprecise sky localisation. We also discuss the use of a spectroscopic redshift\ncatalog, as well as the detectability of the clustering bias of\ngravitational-wave sources.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-14T17:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.10867v1","title":"Precise measurement of the form factors in $D^0\\rightarrow\n  K^*(892)^-Î¼^+Î½_Î¼$ and test of lepton universality with\n  $D^0\\rightarrow K^*(892)^-\\ell^+Î½_{\\ell}$ decays","summary":"We report a study of the semileptonic decay $D^0 \\rightarrow\n\\bar{K}^0\\pi^-\\mu^+\\nu_{\\mu}$ based on a sample of $7.9~\\mathrm{fb}^{-1}$ of\n$e^+e^-$ annihilation data collected at a center-of-mass energy of 3.773~GeV\nwith the BESIII detector at the BEPCII collider. The branching fraction of the\ndecay is measured for the first time to be $\\mathcal{B}(D^0\\rightarrow\n\\bar{K}^0\\pi^-\\mu^+\\nu_{\\mu}) = (1.373 \\pm 0.020_{\\rm stat} \\pm 0.023_{\\rm\nsyst})\\%$, where the first uncertainty is statistical and the second is\nsystematic. Based on the investigation of the decay dynamics, we find that the\ndecay is dominated by the $K^{*}(892)^-$ resonance with the branching fraction\nmeasured to be $\\mathcal{B}(D^0\\rightarrow K^{*}(892)^-\\mu^+\\nu_{\\mu}) = (1.948\n\\pm 0.033_{\\rm stat} \\pm 0.036_{\\rm syst})\\%$. We also determine the hadronic\nform factors for the $D^0\\rightarrow K^{*}(892)^-\\mu^+\\nu_{\\mu}$ decay to be\n$r_{V} = V(0)/A_1(0) = 1.46 \\pm 0.11_{\\rm stat} \\pm 0.04_{\\rm syst}$, $r_{2} =\nA_2(0)/A_1(0) = 0.71 \\pm 0.08_{\\rm stat} \\pm 0.03_{\\rm syst}$, and\n$A_1(0)=0.609 \\pm 0.008_{\\rm stat} \\pm 0.008_{\\rm syst}$, where $V(0)$ is the\nvector form factor and $A_{1,2}(0)$ are the axial form factors evaluated at\n$q^2=0$. The $A_1(0)$ is measured for the first time in $D^0\\rightarrow\nK^{*}(892)^-\\mu^+\\nu_{\\mu}$ decay. Averaging the form-factor parameters that we\nreported previously in $D^0\\rightarrow K^*(892)^-(\\rightarrow\n\\bar{K}^0\\pi^-)e^+\\nu_{e}$ and $D^0\\rightarrow K^*(892)^-(\\rightarrow\nK^-\\pi^0)\\mu^+\\nu_{\\mu}$ decays, we obtain $r_{V}=1.456\\pm0.040_{\\rm\nstat}\\pm0.016_{\\rm syst}$, $r_{2}=0.715\\pm0.031_{\\rm stat}\\pm0.014_{\\rm stat}$,\nand $A_1(0)=0.614\\pm0.005_{\\rm stat}\\pm0.004_{\\rm syst}$. This is the most\nprecise determination of the form-factor parameters to date measured in\n$D\\rightarrow K^*(892)$ transition, which provide the most stringent test on\nvarious theoretical models.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-15T04:59:18Z"}
{"aid":"http://arxiv.org/abs/2504.10879v1","title":"Strain effect on optical properties and quantum weight of 2D magnetic\n  topological insulators MnBi$_2$X$_4$ (X = Te, Se, S)","summary":"Manipulating the optical and quantum properties of two-dimensional (2D)\nmaterials through strain engineering is not only fundamentally interesting but\nalso provides significant benefits across various applications. In this work,\nwe employ first-principles calculations to investigate the effects of strain on\nthe magnetic and optical properties of 2D topological insulators MnBi$_2$X$_4$\n(X = Te, Se, S). Our results indicate that biaxial strain enhances the Mn\nmagnetic moment, while uniaxial strains reduce it. Significantly, the\nstrain-dependent behavior, quantified through the quantum weight, can be\nleveraged to control the system's quantum geometry and topological features.\nParticularly, uniaxial strains reduce the quantum weight and introduce\nanisotropy, thus providing an additional degree of freedom to tailor device\nfunctionalities. Finally, by analyzing chemical bonds under various strain\ndirections, we elucidate how the intrinsic ductile or brittle fracture behavior\nof MnBi$_2$X$_4$ could impact fabrication protocols and structural stability.\nThese insights pave the way for strain-based approaches to optimize the quantum\nproperties in 2D magnetic topological insulators in practical device contexts.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-15T05:18:21Z"}
{"aid":"http://arxiv.org/abs/2504.10886v1","title":"Exploring Persona-dependent LLM Alignment for the Moral Machine\n  Experiment","summary":"Deploying large language models (LLMs) with agency in real-world applications\nraises critical questions about how these models will behave. In particular,\nhow will their decisions align with humans when faced with moral dilemmas? This\nstudy examines the alignment between LLM-driven decisions and human judgment in\nvarious contexts of the moral machine experiment, including personas reflecting\ndifferent sociodemographics. We find that the moral decisions of LLMs vary\nsubstantially by persona, showing greater shifts in moral decisions for\ncritical tasks than humans. Our data also indicate an interesting partisan\nsorting phenomenon, where political persona predominates the direction and\ndegree of LLM decisions. We discuss the ethical implications and risks\nassociated with deploying these models in applications that involve moral\ndecisions.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL","published":"2025-04-15T05:29:51Z"}
{"aid":"http://arxiv.org/abs/2504.10895v1","title":"Weighted norm inequalities of higher-order Riesz transforms associated\n  with Laguerre expansions","summary":"Let $\\nu=(\\nu_1,\\ldots,\\nu_n)\\in (-1,\\vc)^n$, $n\\ge 1$, and let\n$\\mathcal{L}_\\nu$ be a self-adjoint extension of the differential operator \\[\nL_\\nu := \\sum_{i=1}^n \\left[-\\frac{\\partial^2}{\\partial x_i^2} + x_i^2 +\n\\frac{1}{x_i^2}(\\nu_i^2 - \\frac{1}{4})\\right] \\] on\n$C_c^\\infty(\\mathbb{R}_+^n)$ as the natural domain. The $j$-th partial\nderivative associated with $L_{\\nu}$ is given by \\[ \\delta_{\\nu_j} =\n\\frac{\\partial}{\\partial x_j} + x_j-\\frac{1}{x_j}\\Big(\\nu_j + \\f{1}{2}\\Big), \\\n\\ \\ \\ j=1,\\ldots, n. \\] In this paper, we investigate the weighted estimates of\nthe higher-order Riesz transforms $\\delta_\\nu^k\\mathcal L^{-|k|/2}_\\nu, k\\in\n\\mathbb N^n$, where $\\delta_\\nu^k=\\delta_{\\nu_n}^{k_n}\\ldots\n\\delta_{\\nu_1}^{k_1}$. This completes the description of the boundedness of the\nhigher-order Riesz transforms with the full range $\\nu \\in (-1,\\vc)^n$.","main_category":"math.CA","categories":"math.CA","published":"2025-04-15T06:12:59Z"}
{"aid":"http://arxiv.org/abs/2504.10911v1","title":"Low-Overhead Channel Estimation Framework for Beyond Diagonal\n  Reconfigurable Intelligent Surface Assisted Multi-User MIMO Communication","summary":"Beyond diagonal reconfigurable intelligent surface (BD-RIS) refers to a\nfamily of RIS architectures characterized by scattering matrices not limited to\nbeing diagonal and enables higher wave manipulation flexibility and large\nperformance gains over conventional (diagonal) RIS. To achieve those promising\ngains, accurate channel state information (CSI) needs to be acquired in BD-RIS\nassisted communication systems. However, the number of coefficients in the\ncascaded channels to be estimated in BD-RIS assisted systems is significantly\nlarger than that in conventional RIS assisted systems, because the channels\nassociated with the off-diagonal elements of the scattering matrix have to be\nestimated as well. Surprisingly, for the first time in the literature, this\npaper rigorously shows that the uplink channel estimation overhead in BD-RIS\nassisted systems is actually of the same order as that in the conventional RIS\nassisted systems. This amazing result stems from a key observation: for each\nuser antenna, its cascaded channel matrix associated with one reference BD-RIS\nelement is a scaled version of that associated with any other BD-RIS element\ndue to the common RIS-base station (BS) channel. In other words, the number of\nindependent unknown variables is far less than it would seem at first glance.\nBuilding upon this property, this paper manages to characterize the minimum\noverhead to perfectly estimate all the channels in the ideal case without noise\nat the BS, and propose a twophase estimation framework for the practical case\nwith noise at the BS. Numerical results demonstrate outstanding channel\nestimation overhead reduction over existing schemes in BD-RIS assisted systems.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-15T06:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.10913v1","title":"douka: A universal platform of data assimilation for materials modeling","summary":"A large-scale, general-purpose data assimilation (DA) platform for materials\nmodeling, douka, was developed and applied to nonlinear materials models. The\nplatform demonstrated its effectiveness in estimating physical properties that\ncannot be directly obtained from observed data. DA was successfully performed\nusing experimental images of oxygen evolution reaction at a water electrolysis\nelectrode, enabling the estimation of oxygen gas injection velocity and bubble\ncontact angle. Furthermore, large-scale ensemble DA was conducted on the\nsupercomputer Fugaku, achieving state estimation with up to 8,192 ensemble\nmembers. The results confirmed that runtime scaling for the prediction step\nfollows the weak scaling law, ensuring computational efficiency even with\nincreased ensemble sizes. These findings highlight the potential of douka as a\nnew approach for data-driven materials science, integrating experimental data\nwith numerical simulation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-15T06:49:24Z"}
{"aid":"http://arxiv.org/abs/2504.10917v1","title":"Towards A Universal Graph Structural Encoder","summary":"Recent advancements in large-scale pre-training have shown the potential to\nlearn generalizable representations for downstream tasks. In the graph domain,\nhowever, capturing and transferring structural information across different\ngraph domains remains challenging, primarily due to the inherent differences in\ntopological patterns across various contexts. Additionally, most existing\nmodels struggle to capture the complexity of rich graph structures, leading to\ninadequate exploration of the embedding space. To address these challenges, we\npropose GFSE, a universal graph structural encoder designed to capture\ntransferable structural patterns across diverse domains such as molecular\ngraphs, social networks, and citation networks. GFSE is the first cross-domain\ngraph structural encoder pre-trained with multiple self-supervised learning\nobjectives. Built on a Graph Transformer, GFSE incorporates attention\nmechanisms informed by graph inductive bias, enabling it to encode intricate\nmulti-level and fine-grained topological features. The pre-trained GFSE\nproduces generic and theoretically expressive positional and structural\nencoding for graphs, which can be seamlessly integrated with various downstream\ngraph feature encoders, including graph neural networks for vectorized features\nand Large Language Models for text-attributed graphs. Comprehensive experiments\non synthetic and real-world datasets demonstrate GFSE's capability to\nsignificantly enhance the model's performance while requiring substantially\nless task-specific fine-tuning. Notably, GFSE achieves state-of-the-art\nperformance in 81.6% evaluated cases, spanning diverse graph models and\ndatasets, highlighting its potential as a powerful and versatile encoder for\ngraph-structured data.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T06:57:26Z"}
{"aid":"http://arxiv.org/abs/2504.10933v1","title":"Towards Robust Trajectory Embedding for Similarity Computation: When\n  Triangle Inequality Violations in Distance Metrics Matter","summary":"Trajectory similarity is a cornerstone of trajectory data management and\nanalysis. Traditional similarity functions often suffer from high computational\ncomplexity and a reliance on specific distance metrics, prompting a shift\ntowards deep representation learning in Euclidean space. However, existing\nEuclidean-based trajectory embeddings often face challenges due to the triangle\ninequality constraints that do not universally hold for trajectory data. To\naddress this issue, this paper introduces a novel approach by incorporating\nnon-Euclidean geometry, specifically hyperbolic space, into trajectory\nrepresentation learning. We present the first-ever integration of hyperbolic\nspace to resolve the inherent limitations of the triangle inequality in\nEuclidean embeddings. In particular, we achieve it by designing a Lorentz\ndistance measure, which is proven to overcome triangle inequality constraints.\nAdditionally, we design a model-agnostic framework LH-plugin to seamlessly\nintegrate hyperbolic embeddings into existing representation learning\npipelines. This includes a novel projection method optimized with the Cosh\nfunction to prevent the diminishment of distances, supported by a theoretical\nfoundation. Furthermore, we propose a dynamic fusion distance that\nintelligently adapts to variations in triangle inequality constraints across\ndifferent trajectory pairs, blending Lorentzian and Euclidean distances for\nmore robust similarity calculations. Comprehensive experimental evaluations\ndemonstrate that our approach effectively enhances the accuracy of trajectory\nsimilarity measures in state-of-the-art models across multiple real-world\ndatasets. The LH-plugin not only addresses the triangle inequality issues but\nalso significantly refines the precision of trajectory similarity computations,\nmarking a substantial advancement in the field of trajectory representation\nlearning.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T07:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.10953v1","title":"Intraoperative perfusion assessment by continuous, low-latency\n  hyperspectral light-field imaging: development, methodology, and clinical\n  application","summary":"Accurate assessment of tissue perfusion is crucial in visceral surgery,\nespecially during anastomosis. Currently, subjective visual judgment is\ncommonly employed in clinical settings. Hyperspectral imaging (HSI) offers a\nnon-invasive, quantitative alternative. However, HSI imaging lacks continuous\nintegration into the clinical workflow. This study presents a hyperspectral\nlight field system for intraoperative tissue oxygen saturation (SO2) analysis\nand visualization. We present a correlation method for determining SO2\nsaturation with low computational demands. We demonstrate clinical application,\nwith our results aligning with the perfusion boundaries determined by the\nsurgeon. We perform and compare continuous perfusion analysis using two\nhyperspectral cameras (Cubert S5, Cubert X20), achieving processing times of <\n170 ms and < 400 ms, respectively. We discuss camera characteristics, system\nparameters, and the suitability for clinical use and real-time applications.","main_category":"eess.IV","categories":"eess.IV,physics.med-ph","published":"2025-04-15T07:59:04Z"}
{"aid":"http://arxiv.org/abs/2504.10963v1","title":"Modeling liquid-mediated interactions for close-to-substrate magnetic\n  microparticle transport in dynamic magnetic field landscapes","summary":"Understanding the on-chip motion of magnetic particles in a microfluidic\nenvironment is key to realizing magnetic particle-based Lab-on-a-chip systems\nfor medical diagnostics. In this work, a simulation model is established to\nquantify the trajectory of a single particle moving close to a polymer surface\nin a quiescent liquid. The simulations include hydrodynamic, magnetostatic, and\nDerjaguin-Landau-Verwey-Overbeek (DLVO) interactions. They are applied to\nparticle motion driven by a dynamically changing magnetic field landscape\ncreated by engineered parallel-stripe magnetic domains superposed by a\nhomogeneous, time-varying external magnetic field. The simulation model is\nadapted to experiments in terms of fluid-particle interactions with the\nmagnetic field landscape approximated by analytic equations under the\nassumption of surface charges. Varying simulation parameters, we especially\nclarify the impact of liquid-mediated DLVO interactions, which are essential\nfor diagnostic applications, on the 3D trajectory of the particle. A comparison\nto experimental results validates our simulation approach.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.app-ph,physics.comp-ph","published":"2025-04-15T08:14:16Z"}
{"aid":"http://arxiv.org/abs/2504.10985v1","title":"DMPT: Decoupled Modality-aware Prompt Tuning for Multi-modal Object\n  Re-identification","summary":"Current multi-modal object re-identification approaches based on large-scale\npre-trained backbones (i.e., ViT) have displayed remarkable progress and\nachieved excellent performance. However, these methods usually adopt the\nstandard full fine-tuning paradigm, which requires the optimization of\nconsiderable backbone parameters, causing extensive computational and storage\nrequirements. In this work, we propose an efficient prompt-tuning framework\ntailored for multi-modal object re-identification, dubbed DMPT, which freezes\nthe main backbone and only optimizes several newly added decoupled\nmodality-aware parameters. Specifically, we explicitly decouple the visual\nprompts into modality-specific prompts which leverage prior modality knowledge\nfrom a powerful text encoder and modality-independent semantic prompts which\nextract semantic information from multi-modal inputs, such as visible,\nnear-infrared, and thermal-infrared. Built upon the extracted features, we\nfurther design a Prompt Inverse Bind (PromptIBind) strategy that employs bind\nprompts as a medium to connect the semantic prompt tokens of different\nmodalities and facilitates the exchange of complementary multi-modal\ninformation, boosting final re-identification results. Experimental results on\nmultiple common benchmarks demonstrate that our DMPT can achieve competitive\nresults to existing state-of-the-art methods while requiring only 6.5%\nfine-tuning of the backbone parameters.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:48:41Z"}
{"aid":"http://arxiv.org/abs/2504.10995v1","title":"TMCIR: Token Merge Benefits Composed Image Retrieval","summary":"Composed Image Retrieval (CIR) retrieves target images using a multi-modal\nquery that combines a reference image with text describing desired\nmodifications. The primary challenge is effectively fusing this visual and\ntextual information. Current cross-modal feature fusion approaches for CIR\nexhibit an inherent bias in intention interpretation. These methods tend to\ndisproportionately emphasize either the reference image features\n(visual-dominant fusion) or the textual modification intent (text-dominant\nfusion through image-to-text conversion). Such an imbalanced representation\noften fails to accurately capture and reflect the actual search intent of the\nuser in the retrieval results. To address this challenge, we propose TMCIR, a\nnovel framework that advances composed image retrieval through two key\ninnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP\nencoders contrastively using intent-reflecting pseudo-target images,\nsynthesized from reference images and textual descriptions via a diffusion\nmodel. This step enhances the encoder ability of text to capture nuanced\nintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune\nall encoders contrastively by comparing adaptive token-fusion features with the\ntarget image. This mechanism dynamically balances visual and textual\nrepresentations within the contrastive learning pipeline, optimizing the\ncomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR\ndatasets demonstrate that TMCIR significantly outperforms state-of-the-art\nmethods, particularly in capturing nuanced user intent.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T09:14:04Z"}
{"aid":"http://arxiv.org/abs/2504.10996v1","title":"Denoising Application Performance Models with Noise-Resilient Priors","summary":"When scaling parallel codes to larger machines, performance models help\nidentify potential bottlenecks. Since analytically designing these mathematical\nrepresentations is usually challenging, empirical models based on performance\nmeasurements offer a practical alternative. Yet, measurements on HPC systems\nare typically affected by noise, leading to potentially misleading model\npredictions. To reduce the influence of noise, we introduce\napplication-specific dynamic priors into the modeling process, which we derive\nfrom noise-resilient measurements of computational effort and knowledge of\ntypical algorithms used in communication routines. These priors then narrow the\nsearch space for our performance models, excluding complexity classes that\nreflect noise rather than performance. Our approach keeps the models much\ncloser to theoretical expectations and significantly improves their predictive\npower. Finally, it cuts experimental costs in half by minimizing the number of\nrepeated measurements.","main_category":"cs.PF","categories":"cs.PF,cs.DC","published":"2025-04-15T09:14:18Z"}
{"aid":"http://arxiv.org/abs/2504.11000v1","title":"Why am I seeing this? Towards recognizing social media recommender\n  systems with missing recommendations","summary":"Social media plays a crucial role in shaping society, often amplifying\npolarization and spreading misinformation. These effects stem from complex\ndynamics involving user interactions, individual traits, and recommender\nalgorithms driving content selection. Recommender systems, which significantly\nshape the content users see and decisions they make, offer an opportunity for\nintervention and regulation. However, assessing their impact is challenging due\nto algorithmic opacity and limited data availability. To effectively model user\ndecision-making, it is crucial to recognize the recommender system adopted by\nthe platform.\n  This work introduces a method for Automatic Recommender Recognition using\nGraph Neural Networks (GNNs), based solely on network structure and observed\nbehavior. To infer the hidden recommender, we first train a Recommender Neutral\nUser model (RNU) using a GNN and an adapted hindsight academic network\nrecommender, aiming to reduce reliance on the actual recommender in the data.\nWe then generate several Recommender Hypothesis-specific Synthetic Datasets\n(RHSD) by combining the RNU with different known recommenders, producing ground\ntruths for testing. Finally, we train Recommender Hypothesis-specific User\nmodels (RHU) under various hypotheses and compare each candidate with the\noriginal used to generate the RHSD.\n  Our approach enables accurate detection of hidden recommenders and their\ninfluence on user behavior. Unlike audit-based methods, it captures system\nbehavior directly, without ad hoc experiments that often fail to reflect real\nplatforms. This study provides insights into how recommenders shape behavior,\naiding efforts to reduce polarization and misinformation.","main_category":"cs.IR","categories":"cs.IR,cs.SI","published":"2025-04-15T09:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.11036v1","title":"Phase-space quantum distorted stability pattern for Aubry-AndrÃ©-Harper\n  dynamics","summary":"Instability features associated to topological quantum domains which emerge\nfrom the Weyl-Wigner (WW) quantum phase-space description of Gaussian ensembles\ndriven by Aubry-Andr\\'e-Harper (AAH) Hamiltonians are investigated. Hyperbolic\nequilibrium and stability patterns are then identified and classified according\nto the associated (nonlinear) AAH Hamiltonian parameters. Besides providing the\ntools for quantifying the information content of AAH systems, the Wigner flow\npatterns here discussed suggest a systematic procedure for identifying the role\nof quantum fluctuations over equilibrium and stability, in a framework which\ncan be straightforwardly extended to describe the evolution of similar/modified\nAAH systems.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-15T09:58:20Z"}
{"aid":"http://arxiv.org/abs/2504.11041v1","title":"Some numerical characteristic inequalities of compact Riemannian\n  manifolds","summary":"In this paper, we consider numerical characteristics of the connected compact\nRiemannian manifold (M, g) such as the supremum and infimum of the scalar\ncurvature s, Ricci curvature Ric and sectional curvature sec, as well as their\napplications. Below are two examples of proven results. The first statement: If\n(M, g) be a connected, compact Riemannian manifold of even dimension n > 3\nwhose Ricci and sectional curvatures satisfy the strict inequality n Inf (sec)\n> Sup (Ric), then M is diffeomorphic to the Euclidean n-dimensional sphere of\nsome radius r or the real projective n-dimensional space. The second statement:\nThere is no harmonic immersion of an n-dimensional connected, complete\nRiemannian manifold (M, g) into the Euclidean n-sphere of radius r if there\nexists inf(Ric) such that Inf (Ric) > n/2r^2.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T10:07:18Z"}
{"aid":"http://arxiv.org/abs/2504.11048v1","title":"Dynamics and Obstructions for Self-Similar Groups Generating Free Groups","summary":"We present obstruction results for self-similar groups regarding the\ngeneration of free groups. As a main consequence of our main results, we solve\nan open problem posed by Grigorchuk by showing that in an automaton group where\na co-accessible state acts as the identity, any self-similar subgroup acting\ntransitively on the first level, or any subgroup acting level-transitively on\nthe rooted tree, is either cyclic or non-free. This result partially extends\nSidki's findings for automaton groups with polynomial activity. Additionally,\nwe show that for a reversible automaton group to generate a free group, the\ndual must necessarily contain a bireversible connected component.","main_category":"math.GR","categories":"math.GR","published":"2025-04-15T10:24:10Z"}
{"aid":"http://arxiv.org/abs/2504.11070v1","title":"Uncertainty-aware electronic density-functional distributions","summary":"We introduce a method for the estimation of uncertainties in\ndensity-functional-theory (DFT) calculations for atomistic systems. The method\nis based on the construction of an uncertainty-aware functional distribution\n(UAFD) in a space spanned by a few different exchange-correlation functionals\nand is illustrated at the level of generalized-gradient-approximation\nfunctionals. The UAFD provides reliable estimates of errors -- compared to\nexperiments or higher-quality calculations -- in calculations performed\nself-consistently with the Perdew-Burke-Ernzerhof functional. The scheme\nfurthermore allows for a decomposition of the error into a systematic bias and\na reduced error. The approach is applied to four different properties:\nmolecular atomization energies, cohesive energies, lattice constants, and bulk\nmoduli of solids. The probability distribution can be tailored to optimize the\nprediction of a single property or for several properties simultaneously.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.data-an","published":"2025-04-15T11:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.11087v1","title":"Quantum walk on a square lattice with identical particles","summary":"We investigate quantum superposition effects in two-dimensional quantum walks\nof identical particles with different statistics under particle exchange,\nstarting from various different initial configurations. To characterize\ninter-particle correlation dynamics, we focus on joint properties such as\ntwo-particle coincidence probabilities and the spread velocity of the\ninter-particle distance. Regarding spatial modes as an environment for the\nparticles internal degrees of freedom, we study the role played by the particle\nstatistics using standard entanglement witnesses, showing that particles\npossessing fermionic statistics are more resistant to thermalize with their\nenvironment. We analyze the presence of multipartite entanglement in the\nsystem's degrees of freedom through the Quantum Fisher Information, revealing\nthat fermionic states generated during the walk are better suited to perform\nquantum metrology tasks. Finally, we discuss the potential for implementing\nthis model using integrated photonic circuits by exploiting $N$-partite\nentanglement between individual photons.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T11:33:08Z"}
{"aid":"http://arxiv.org/abs/2504.11099v1","title":"Double categories of profunctors","summary":"We characterize virtual double categories of enriched categories, functors,\nand profunctors by introducing a new notion of double-categorical colimits. Our\ncharacterization is strict in the sense that it is up to equivalence between\nvirtual double categories and, at the level of objects, up to isomorphism of\nenriched categories. Throughout the paper, we treat enrichment in a unital\nvirtual double category rather than in a bicategory or a monoidal category,\nand, for consistency and better visualization of pasting diagrams, we adopt\naugmented virtual double categories as a fundamental language for\ndouble-categorical concepts.","main_category":"math.CT","categories":"math.CT","published":"2025-04-15T11:45:59Z"}
{"aid":"http://arxiv.org/abs/2504.11118v1","title":"Revealing Covert Attention by Analyzing Human and Reinforcement Learning\n  Agent Gameplay","summary":"This study introduces a novel method for revealing human covert attention\npatterns using gameplay data alone, utilizing offline attention techniques from\nreinforcement learning (RL). We propose the contextualized, task-relevant (CTR)\nattention network, which generates attention maps from both human and RL agent\ngameplay in Atari environments. These maps are sparse yet retain the necessary\ninformation for the current player's decision making. We compare the\nCTR-derived attention maps with a temporally integrated overt attention (TIOA)\nmodel based on eye-tracking data, serving as a point of comparison and\ndiscussion. Visual inspection reveals distinct attention patterns: human CTR\nmaps focus on the player and rather nearby opponents, occasionally shifting\nbetween stronger focus and broader views - sometimes even attending to empty\nspace ahead. In contrast, agent maps maintain a consistent broad focus on most\nobjects, including distant ones and the player. Quantitative analysis further\ndemonstrates that human CTR maps align more closely with TIOA than agent maps\ndo. Our findings indicate that the CTR attention network can effectively reveal\nhuman covert attention patterns from gameplay alone, without the need for\nadditional data like brain activity recordings. This work contributes to\nunderstanding human-agent attention differences and enables the development of\nRL agents augmented with human covert attention.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T12:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.11125v1","title":"A mixed-integer framework for analyzing neural network-based controllers\n  for piecewise affine systems with bounded disturbances","summary":"We present a method for representing the closed-loop dynamics of piecewise\naffine (PWA) systems with bounded additive disturbances and neural\nnetwork-based controllers as mixed-integer (MI) linear constraints. We show\nthat such representations enable the computation of robustly positively\ninvariant (RPI) sets for the specified system class by solving MI linear\nprograms. These RPI sets can subsequently be used to certify stability and\nconstraint satisfaction. Furthermore, the approach allows to handle non-linear\nsystems based on suitable PWA approximations and corresponding error bounds,\nwhich can be interpreted as the bounded disturbances from above.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T12:14:20Z"}
{"aid":"http://arxiv.org/abs/2504.11132v1","title":"Testing Non-Coincident $f(Q)$-gravity with DESI DR2 BAO and GRBs","summary":"We consider the $f\\left( Q \\right) $-theory for the description of dark\nenergy with a non-trivial connection defined in the non-coincident gauge. The\nresulting field equations form a two-scalar-field, quintom-like gravitational\nmodel. For the power-law model $f\\left( Q \\right) \\simeq Q^{\\frac{n}{n-1}}$, we\nconstruct an analytic expression for the dynamical evolution of dark energy,\nwhich depends on the parameter $n$. We constrain this dark energy model using\nthe the baryon acoustic oscillations from DESI DR2, and gamma-ray bursts. The\ncosmological data provides $n \\simeq0.33 $. The $f\\left( Q \\right) $-model\nchallenges the $\\Lambda$CDM by providing a smaller value for $\\chi_{\\min}^{2}$,\nwhile there is weak evidence in favor of the $f\\left( Q \\right) $-theory.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-15T12:31:32Z"}
{"aid":"http://arxiv.org/abs/2504.11133v1","title":"Hessian stability and convergence rates for entropic and Sinkhorn\n  potentials via semiconcavity","summary":"In this paper we determine quantitative stability bounds for the Hessian of\nentropic potentials, i.e., the dual solution to the entropic optimal transport\nproblem. Up to authors' knowledge this is the first work addressing this\nsecond-order quantitative stability estimate in general unbounded settings. Our\nproof strategy relies on semiconcavity properties of entropic potentials and on\nthe representation of entropic transport plans as laws of forward and backward\ndiffusion processes, known as Schr\\\"odinger bridges. Moreover, our approach\nallows to deduce a stochastic proof of quantitative stability entropic\nestimates and integrated gradient estimates as well. Finally, as a direct\nconsequence of these stability bounds, we deduce exponential convergence rates\nfor gradient and Hessian of Sinkhorn iterates along Sinkhorn's algorithm, a\nproblem that was still open in unbounded settings. Our rates have a polynomial\ndependence on the regularization parameter.","main_category":"math.PR","categories":"math.PR,math.AP,math.OC,stat.ML","published":"2025-04-15T12:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.11135v1","title":"The baryonic Tully-Fisher relation and Fundamental Plane in the light of\n  $f(R)$ gravity","summary":"Here we use the samples of spiral and elliptical galaxies, in order to\ninvestigate theoretically some of their properties and to test the empirical\nrelations, in the light of modified gravities. We show that the baryonic\nTully-Fisher relation can be described in the light of $f(R)$ gravity, without\nintroducing the dark matter. Also, it is possible to explain the features of\nfundamental plane of elliptical galaxies without the dark matter hypothesis.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T12:38:55Z"}
{"aid":"http://arxiv.org/abs/2504.11169v1","title":"MuSeD: A Multimodal Spanish Dataset for Sexism Detection in Social Media\n  Videos","summary":"Sexism is generally defined as prejudice and discrimination based on sex or\ngender, affecting every sector of society, from social institutions to\nrelationships and individual behavior. Social media platforms amplify the\nimpact of sexism by conveying discriminatory content not only through text but\nalso across multiple modalities, highlighting the critical need for a\nmultimodal approach to the analysis of sexism online. With the rise of social\nmedia platforms where users share short videos, sexism is increasingly\nspreading through video content. Automatically detecting sexism in videos is a\nchallenging task, as it requires analyzing the combination of verbal, audio,\nand visual elements to identify sexist content. In this study, (1) we introduce\nMuSeD, a new Multimodal Spanish dataset for Sexism Detection consisting of\n$\\approx$ 11 hours of videos extracted from TikTok and BitChute; (2) we propose\nan innovative annotation framework for analyzing the contribution of textual\nand multimodal labels in the classification of sexist and non-sexist content;\nand (3) we evaluate a range of large language models (LLMs) and multimodal LLMs\non the task of sexism detection. We find that visual information plays a key\nrole in labeling sexist content for both humans and models. Models effectively\ndetect explicit sexism; however, they struggle with implicit cases, such as\nstereotypes, instances where annotators also show low agreement. This\nhighlights the inherent difficulty of the task, as identifying implicit sexism\ndepends on the social and cultural context.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T13:16:46Z"}
{"aid":"http://arxiv.org/abs/2504.11175v1","title":"Systoles on punctured spheres","summary":"We determine the maximal number of systoles among all spheres with $n$\npunctures endowed with a complete Riemannian metric of finite area.","main_category":"math.GT","categories":"math.GT,math.DG","published":"2025-04-15T13:30:45Z"}
{"aid":"http://arxiv.org/abs/2504.11195v1","title":"R-TPT: Improving Adversarial Robustness of Vision-Language Models\n  through Test-Time Prompt Tuning","summary":"Vision-language models (VLMs), such as CLIP, have gained significant\npopularity as foundation models, with numerous fine-tuning methods developed to\nenhance performance on downstream tasks. However, due to their inherent\nvulnerability and the common practice of selecting from a limited set of\nopen-source models, VLMs suffer from a higher risk of adversarial attacks than\ntraditional vision models. Existing defense techniques typically rely on\nadversarial fine-tuning during training, which requires labeled data and lacks\nof flexibility for downstream tasks. To address these limitations, we propose\nrobust test-time prompt tuning (R-TPT), which mitigates the impact of\nadversarial attacks during the inference stage. We first reformulate the\nclassic marginal entropy objective by eliminating the term that introduces\nconflicts under adversarial conditions, retaining only the pointwise entropy\nminimization. Furthermore, we introduce a plug-and-play reliability-based\nweighted ensembling strategy, which aggregates useful information from reliable\naugmented views to strengthen the defense. R-TPT enhances defense against\nadversarial attacks without requiring labeled training data while offering high\nflexibility for inference tasks. Extensive experiments on widely used\nbenchmarks with various attacks demonstrate the effectiveness of R-TPT. The\ncode is available in https://github.com/TomSheng21/R-TPT.","main_category":"cs.LG","categories":"cs.LG,cs.CR,cs.CV","published":"2025-04-15T13:49:31Z"}
{"aid":"http://arxiv.org/abs/2504.11202v1","title":"Focal Split: Untethered Snapshot Depth from Differential Defocus","summary":"We introduce Focal Split, a handheld, snapshot depth camera with fully\nonboard power and computing based on depth-from-differential-defocus (DfDD).\nFocal Split is passive, avoiding power consumption of light sources. Its\nachromatic optical system simultaneously forms two differentially defocused\nimages of the scene, which can be independently captured using two photosensors\nin a snapshot. The data processing is based on the DfDD theory, which\nefficiently computes a depth and a confidence value for each pixel with only\n500 floating point operations (FLOPs) per pixel from the camera measurements.\nWe demonstrate a Focal Split prototype, which comprises a handheld custom\ncamera system connected to a Raspberry Pi 5 for real-time data processing. The\nsystem consumes 4.9 W and is powered on a 5 V, 10,000 mAh battery. The\nprototype can measure objects with distances from 0.4 m to 1.2 m, outputting\n480$\\times$360 sparse depth maps at 2.1 frames per second (FPS) using\nunoptimized Python scripts. Focal Split is DIY friendly. A comprehensive guide\nto building your own Focal Split depth camera, code, and additional data can be\nfound at https://focal-split.qiguo.org.","main_category":"cs.CV","categories":"cs.CV,eess.IV,eess.SP,I.4.8","published":"2025-04-15T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.11218v1","title":"3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians","summary":"3D affordance reasoning is essential in associating human instructions with\nthe functional regions of 3D objects, facilitating precise, task-oriented\nmanipulations in embodied AI. However, current methods, which predominantly\ndepend on sparse 3D point clouds, exhibit limited generalizability and\nrobustness due to their sensitivity to coordinate variations and the inherent\nsparsity of the data. By contrast, 3D Gaussian Splatting (3DGS) delivers\nhigh-fidelity, real-time rendering with minimal computational overhead by\nrepresenting scenes as dense, continuous distributions. This positions 3DGS as\na highly effective approach for capturing fine-grained affordance details and\nimproving recognition accuracy. Nevertheless, its full potential remains\nlargely untapped due to the absence of large-scale, 3DGS-specific affordance\ndatasets. To overcome these limitations, we present 3DAffordSplat, the first\nlarge-scale, multi-modal dataset tailored for 3DGS-based affordance reasoning.\nThis dataset includes 23,677 Gaussian instances, 8,354 point cloud instances,\nand 6,631 manually annotated affordance labels, encompassing 21 object\ncategories and 18 affordance types. Building upon this dataset, we introduce\nAffordSplatNet, a novel model specifically designed for affordance reasoning\nusing 3DGS representations. AffordSplatNet features an innovative cross-modal\nstructure alignment module that exploits structural consistency priors to align\n3D point cloud and 3DGS representations, resulting in enhanced affordance\nrecognition accuracy. Extensive experiments demonstrate that the 3DAffordSplat\ndataset significantly advances affordance learning within the 3DGS domain,\nwhile AffordSplatNet consistently outperforms existing methods across both seen\nand unseen settings, highlighting its robust generalization capabilities.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T14:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.11224v1","title":"Accurate Machine Learning Interatomic Potentials for Polyacene Molecular\n  Crystals: Application to Single Molecule Host-Guest Systems","summary":"Emerging machine learning interatomic potentials (MLIPs) offer a promising\nsolution for large-scale accurate material simulations, but stringent tests\nrelated to the description of vibrational dynamics in molecular crystals remain\nscarce. Here, we develop a general MLIP by leveraging the graph neural\nnetwork-based MACE architecture and active-learning strategies to accurately\ncapture vibrational dynamics across a range of polyacene-based molecular\ncrystals, namely naphthalene, anthracene, tetracene and pentacene. Through\ncareful error propagation, we show that these potentials are accurate and\nenable the study of anharmonic vibrational features, vibrational lifetimes, and\nvibrational coupling. In particular, we investigate large-scale host-guest\nsystems based on these molecular crystals, showing the capacity of\nmolecular-dynamics-based techniques to explain and quantify vibrational\ncoupling between host and guest nuclear motion. Our results establish a\nframework for understanding vibrational signatures in large-scale complex\nmolecular systems and thus represent an important step for engineering\nvibrational interactions in molecular environments.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-15T14:27:21Z"}
{"aid":"http://arxiv.org/abs/2504.11249v1","title":"Cryo-em images are intrinsically low dimensional","summary":"Simulation-based inference provides a powerful framework for cryo-electron\nmicroscopy, employing neural networks in methods like CryoSBI to infer\nbiomolecular conformations via learned latent representations. This latent\nspace represents a rich opportunity, encoding valuable information about the\nphysical system and the inference process. Harnessing this potential hinges on\nunderstanding the underlying geometric structure of these representations. We\ninvestigate this structure by applying manifold learning techniques to CryoSBI\nrepresentations of hemagglutinin (simulated and experimental). We reveal that\nthese high-dimensional data inherently populate low-dimensional, smooth\nmanifolds, with simulated data effectively covering the experimental\ncounterpart. By characterizing the manifold's geometry using Diffusion Maps and\nidentifying its principal axes of variation via coordinate interpretation\nmethods, we establish a direct link between the latent structure and key\nphysical parameters. Discovering this intrinsic low-dimensionality and\ninterpretable geometric organization not only validates the CryoSBI approach\nbut enables us to learn more from the data structure and provides opportunities\nfor improving future inference strategies by exploiting this revealed manifold\ngeometry.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.CV,cs.LG,q-bio.BM,stat.ML","published":"2025-04-15T14:46:25Z"}
{"aid":"http://arxiv.org/abs/2504.11250v1","title":"A Rollout-Based Algorithm and Reward Function for Efficient Resource\n  Allocation in Business Processes","summary":"Resource allocation plays a critical role in minimizing cycle time and\nimproving the efficiency of business processes. Recently, Deep Reinforcement\nLearning (DRL) has emerged as a powerful tool to optimize resource allocation\npolicies in business processes. In the DRL framework, an agent learns a policy\nthrough interaction with the environment, guided solely by reward signals that\nindicate the quality of its decisions. However, existing algorithms are not\nsuitable for dynamic environments such as business processes. Furthermore,\nexisting DRL-based methods rely on engineered reward functions that approximate\nthe desired objective, but a misalignment between reward and objective can lead\nto undesired decisions or suboptimal policies. To address these issues, we\npropose a rollout-based DRL algorithm and a reward function to optimize the\nobjective directly. Our algorithm iteratively improves the policy by evaluating\nexecution trajectories following different actions. Our reward function\ndirectly decomposes the objective function of minimizing the mean cycle time.\nMaximizing our reward function guarantees that the objective function is\nminimized without requiring extensive reward engineering. The results show that\nour method consistently learns the optimal policy in all six evaluated business\nprocesses, outperforming the state-of-the-art algorithm that can only learn the\noptimal policy in two of the evaluated processes.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T14:46:58Z"}
{"aid":"http://arxiv.org/abs/2504.11269v1","title":"Minimax asymptotics","summary":"In this paper, we consider asymptotics of the optimal value and the optimal\nsolutions of parametric minimax estimation problems. Specifically, we consider\nestimators of the optimal value and the optimal solutions in a sample minimax\nproblem that approximates the true population problem and study the limiting\ndistributions of these estimators as the sample size tends to infinity. The\nmain technical tool we employ in our analysis is the theory of sensitivity\nanalysis of parameterized mathematical optimization problems. Our results go\nwell beyond the existing literature and show that these limiting distributions\nare highly non-Gaussian in general and normal in simple specific cases. These\nresults open up the way for the development of statistical inference methods in\nparametric minimax problems.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-15T15:10:59Z"}
{"aid":"http://arxiv.org/abs/2504.11270v1","title":"Rank-based transfer learning for high-dimensional survival data with\n  application to sepsis data","summary":"Sepsis remains a critical challenge due to its high mortality and complex\nprognosis. To address data limitations in studying MSSA sepsis, we extend\nexisting transfer learning frameworks to accommodate transformation models for\nhigh-dimensional survival data. Specifically, we construct a measurement index\nbased on C-index for intelligently identifying the helpful source datasets, and\nthe target model performance is improved by leveraging information from the\nidentified source datasets via performing the transfer step and debiasing step.\nWe further provide an algorithm to construct confidence intervals for each\ncoefficient component. Another significant development is that statistical\nproperties are rigorously established, including $\\ell_1/\\ell_2$-estimation\nerror bounds of the transfer learning algorithm, detection consistency property\nof the transferable source detection algorithm and asymptotic theories for the\nconfidence interval construction. Extensive simulations and analysis of\nMIMIC-IV sepsis data demonstrate the estimation and prediction accuracy, and\npractical advantages of our approach, providing significant improvements in\nsurvival estimates for MSSA sepsis patients.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-15T15:12:25Z"}
{"aid":"http://arxiv.org/abs/2504.11276v1","title":"Invention, Innovation, and Commercialisation in British Biophysics","summary":"British biophysics has a rich tradition of scientific invention and\ninnovation, on several occasions resulting in new technologies which have\ntransformed biological insight, such as rapid DNA sequencing, high-precision\nsuper-resolution and label-free microscopy hardware, new approaches for\nhigh-throughput and single-molecule bio-sensing, and the development of a range\nof de novo bio-inspired synthetic materials. Some of these advances have been\nestablished through democratised, open-source platforms and many have\nbiomedical success, a key example involving the SARS-CoV-2 spike protein during\nthe COVID-19 pandemic. Here, three UK labs made crucial contributions in\nrevealing how the spike protein targets human cells, and how therapies such as\nvaccines and neutralizing nanobodies likely work, enabled in large part through\nthe biophysical technological innovations of cryo-electron microscopy. In this\nreview, we discuss leading-edge technological and methodological innovations\nwhich resulted from initial outcomes of discovery-led 'Physics of Life' (PoL)\nresearch (capturing biophysics, biological physics and multiple blends of\nphysical-life sciences interdisciplinary research in the UK) and which have\nmatured into wider-reaching sustainable commercial ventures enabling\nsignificant translational impact. We describe the fundamental biophysical\nscience which led to a diverse range of academic spinouts, presenting the\nscientific questions that were first asked and addressed through innovating new\ntechniques and approaches, and highlighting the key publications which\nultimately led to commercialisation. We consider these example companies\nthrough the lens of opportunities and challenges for academic biophysics\nresearch in partnership with British industry. Finally, we propose\nrecommendations concerning future resourcing and structuring of UK biophysics\nresearch and the training and support of...","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-15T15:16:42Z"}
{"aid":"http://arxiv.org/abs/2504.11277v1","title":"From Misleading Queries to Accurate Answers: A Three-Stage Fine-Tuning\n  Method for LLMs","summary":"Large language models (LLMs) exhibit excellent performance in natural\nlanguage processing (NLP), but remain highly sensitive to the quality of input\nqueries, especially when these queries contain misleading or inaccurate\ninformation. Existing methods focus on correcting the output, but they often\noverlook the potential of improving the ability of LLMs to detect and correct\nmisleading content in the input itself. In this paper, we propose a novel\nthree-stage fine-tuning method that enhances the ability of LLMs to detect and\ncorrect misleading information in the input, further improving response\naccuracy and reducing hallucinations. Specifically, the three stages include\n(1) training LLMs to identify misleading information, (2) training LLMs to\ncorrect the misleading information using built-in or external knowledge, and\n(3) training LLMs to generate accurate answers based on the corrected queries.\nTo evaluate our method, we conducted experiments on three datasets for the\nhallucination detection task and the question answering (QA) task, as well as\ntwo datasets containing misleading information that we constructed. The\nexperimental results demonstrate that our method significantly improves the\naccuracy and factuality of LLM responses, while also enhancing the ability to\ndetect hallucinations and reducing the generation of hallucinations in the\noutput, particularly when the query contains misleading information. We will\npublicly release our code upon acceptance.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T15:16:45Z"}
{"aid":"http://arxiv.org/abs/2504.11279v1","title":"Simulation-based inference for stochastic nonlinear mixed-effects models\n  with applications in systems biology","summary":"The analysis of data from multiple experiments, such as observations of\nseveral individuals, is commonly approached using mixed-effects models, which\naccount for variation between individuals through hierarchical representations.\nThis makes mixed-effects models widely applied in fields such as biology,\npharmacokinetics, and sociology. In this work, we propose a novel methodology\nfor scalable Bayesian inference in hierarchical mixed-effects models. Our\nframework first constructs amortized approximations of the likelihood and the\nposterior distribution, which are then rapidly refined for each individual\ndataset, to ultimately approximate the parameters posterior across many\nindividuals. The framework is easily trainable, as it uses mixtures of experts\nbut without neural networks, leading to parsimonious yet expressive surrogate\nmodels of the likelihood and the posterior. We demonstrate the effectiveness of\nour methodology using challenging stochastic models, such as mixed-effects\nstochastic differential equations emerging in systems biology-driven problems.\nHowever, the approach is broadly applicable and can accommodate both stochastic\nand deterministic models. We show that our approach can seamlessly handle\ninference for many parameters. Additionally, we applied our method to a\nreal-data case study of mRNA transfection. When compared to exact\npseudomarginal Bayesian inference, our approach proved to be both fast and\ncompetitive in terms of statistical accuracy.","main_category":"stat.CO","categories":"stat.CO,stat.ME,stat.ML","published":"2025-04-15T15:18:58Z"}
{"aid":"http://arxiv.org/abs/2504.11287v1","title":"On kinetic energy localization in fluid flow","summary":"This works focuses on participation number -- a parameter that allows to\nquantitatively asses the level of kinetic energy localization. The author\npresents a clear way of deriving participation number in a continuous case\nwithout making any assumptions about the system, fluid or flow regime.\nMoreover, a method of computing participation number in discretized cases is\ndiscussed and verified against well known analytical solutions using three\nmethods, in which one was used previously in research on fluid flow through\nporous media. A robust formula, that works for both uniform and nonuniform\ndiscretization grids is presented.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph","published":"2025-04-15T15:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.11290v1","title":"Automated Python Translation","summary":"Python is one of the most commonly used programming languages in industry and\neducation. Its English keywords and built-in functions/modules allow it to come\nclose to pseudo-code in terms of its readability and ease of writing. However,\nthose who do not speak English may not experience these advantages. In fact,\nthey may even be hindered in their ability to understand Python code, as the\nEnglish nature of its terms creates an additional layer of overhead. To that\nend, we introduce the task of automatically translating Python's natural\nmodality (keywords, error types, identifiers, etc.) into other human languages.\nThis presents a unique challenge, considering the abbreviated nature of these\nforms, as well as potential untranslatability of advanced\nmathematical/programming concepts across languages. We therefore create an\nautomated pipeline to translate Python into other human languages, comparing\nstrategies using machine translation and large language models. We then use\nthis pipeline to acquire translations from five common Python libraries\n(pytorch, pandas, tensorflow, numpy, and random) in seven languages, and do a\nquality test on a subset of these terms in French, Greek, and Bengali. We hope\nthis will provide a clearer path forward towards creating a universal Python,\naccessible to anyone regardless of nationality or language background.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T15:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.11298v1","title":"Giant Magnetocaloric Effect in Spin Supersolid Candidate\n  Na$_2$BaCo(PO$_4$)$_2$","summary":"Supersolid, an exotic quantum state of matter that consists of particles\nforming an incompressible solid structure while simultaneously showing\nsuperfluidity of zero viscosity [1], is one of the long-standing pursuits in\nfundamental research [2, 3]. Although the initial report of $^4$He supersolid\nturned out to be an artifact [4], this intriguing quantum matter has inspired\nenthusiastic investigations into ultracold quantum gases [5-8]. Nevertheless,\nthe realization of supersolidity in condensed matter remains elusive. Here we\nfind evidence for a quantum magnetic analogue of supersolid -- the spin\nsupersolid -- in the recently synthesized triangular-lattice antiferromagnet\nNa$_2$BaCo(PO$_4$)$_2$ [9]. Notably, a giant magnetocaloric effect related to\nthe spin supersolidity is observed in the demagnetization cooling process,\nmanifesting itself as two prominent valley-like regimes, with the lowest\ntemperature attaining below 100 mK. Not only is there an experimentally\ndetermined series of critical fields but the demagnetization cooling profile\nalso shows excellent agreement with the theoretical simulations with an\neasy-axis Heisenberg model. Neutron diffractions also successfully locate the\nproposed spin supersolid phases by revealing the coexistence of\nthree-sublattice spin solid order and interlayer incommensurability indicative\nof the spin superfluidity. Thus, our results indicate a strong entropic effect\nof the spin supersolid phase in a frustrated quantum magnet and open up a\nviable and promising avenue for applications in sub-Kelvin refrigeration,\nespecially in the context of persistent concerns about helium shortages [10,\n11].","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T15:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.11311v1","title":"From Symmetry to Supersymmetry to Supergravity","summary":"The theoretical developments that led to supersymmetry, first global and then\nlocal, over roughly six years (1970-1976) arose from a convergence of physical\ninsights and mathematical methods stemming from diverse, and sometimes\nindependent, research directions. This contribution aims to illustrate the\ninterplay of ideas, methods, and motivations that informed the entire process\nand concludes with a reflection on the scientific modality of these\ndevelopments.","main_category":"physics.hist-ph","categories":"physics.hist-ph,hep-th","published":"2025-04-15T15:51:54Z"}
{"aid":"http://arxiv.org/abs/2504.11320v1","title":"Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory\n  Constraints","summary":"Large Language Models (LLMs) are indispensable in today's applications, but\ntheir inference procedure -- generating responses by processing text in\nsegments and using a memory-heavy Key-Value (KV) cache -- demands significant\ncomputational resources, particularly under memory constraints. This paper\nformulates LLM inference optimization as a multi-stage online scheduling\nproblem where sequential prompt arrivals and KV cache growth render\nconventional scheduling ineffective. We develop a fluid dynamics approximation\nto provide a tractable benchmark that guides algorithm design. Building on\nthis, we propose the Waiting for Accumulated Inference Threshold (WAIT)\nalgorithm, which uses multiple thresholds to schedule incoming prompts\noptimally when output lengths are known, and extend it to Nested WAIT for cases\nwith unknown output lengths. Theoretical analysis shows that both algorithms\nachieve near-optimal performance against the fluid benchmark in heavy traffic\nconditions, balancing throughput, latency, and Time to First Token (TTFT).\nExperiments with the Llama-7B model on an A100 GPU using both synthetic and\nreal-world datasets demonstrate improved throughput and reduced latency\nrelative to established baselines like vLLM and Sarathi. This work bridges\noperations research and machine learning, offering a rigorous framework for the\nefficient deployment of LLMs under memory constraints.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC,math.OC,stat.ML","published":"2025-04-15T16:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.11322v1","title":"Fast detection and reconstruction of merging Massive Black Hole Binary\n  signals","summary":"The Laser Interferometer Space Antenna (LISA) will detect gravitational waves\nfrom the population of merging massive black holes binaries (MBHBs) throughout\nthe Universe. The LISA data stream will feature many superposed signals from\ndifferent astrophysical sources, requiring a global fit procedure. Most of the\nMBHB signals will be loud enough to be detected days or even weeks before the\nmerger; and for those sources LISA will be able to predict the time of the\nmerger well in advance of the coalescence, as well as an approximate position\nin the sky. In this paper, we present a fast detection and signal\nreconstruction scheme for massive black hole binaries in the LISA observation\nband. We propose: (i) a detection scheme for MBHB mergers allowing a first\nsubtraction of these signals for the purpose of a global fit, and (ii) an\nefficient early detection scheme providing a time-of-merger estimate for a\npre-merger signal, that will allow to trigger a protection period, placing LISA\nin ``do not disturb'' mode and enabling more detailed analysis that will\nfacilitate multi-messenger observations. We highlight the effect of confusion\nof several overlapping in time MBHB signals in the pre-merger detection.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.IM","published":"2025-04-15T16:01:55Z"}
{"aid":"http://arxiv.org/abs/2504.11326v1","title":"PVUW 2025 Challenge Report: Advances in Pixel-level Understanding of\n  Complex Videos in the Wild","summary":"This report provides a comprehensive overview of the 4th Pixel-level Video\nUnderstanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025.\nIt summarizes the challenge outcomes, participating methodologies, and future\nresearch directions. The challenge features two tracks: MOSE, which focuses on\ncomplex scene video object segmentation, and MeViS, which targets\nmotion-guided, language-based video segmentation. Both tracks introduce new,\nmore challenging datasets designed to better reflect real-world scenarios.\nThrough detailed evaluation and analysis, the challenge offers valuable\ninsights into the current state-of-the-art and emerging trends in complex video\nsegmentation. More information can be found on the workshop website:\nhttps://pvuw.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T16:02:47Z"}
{"aid":"http://arxiv.org/abs/2504.11344v1","title":"Interpretable Hybrid-Rule Temporal Point Processes","summary":"Temporal Point Processes (TPPs) are widely used for modeling event sequences\nin various medical domains, such as disease onset prediction, progression\nanalysis, and clinical decision support. Although TPPs effectively capture\ntemporal dynamics, their lack of interpretability remains a critical challenge.\nRecent advancements have introduced interpretable TPPs. However, these methods\nfail to incorporate numerical features, thereby limiting their ability to\ngenerate precise predictions. To address this issue, we propose Hybrid-Rule\nTemporal Point Processes (HRTPP), a novel framework that integrates temporal\nlogic rules with numerical features, improving both interpretability and\npredictive accuracy in event modeling. HRTPP comprises three key components:\nbasic intensity for intrinsic event likelihood, rule-based intensity for\nstructured temporal dependencies, and numerical feature intensity for dynamic\nprobability modulation. To effectively discover valid rules, we introduce a\ntwo-phase rule mining strategy with Bayesian optimization. To evaluate our\nmethod, we establish a multi-criteria assessment framework, incorporating rule\nvalidity, model fitting, and temporal predictive accuracy. Experimental results\non real-world medical datasets demonstrate that HRTPP outperforms\nstate-of-the-art interpretable TPPs in terms of predictive performance and\nclinical interpretability. In case studies, the rules extracted by HRTPP\nexplain the disease progression, offering valuable contributions to medical\ndiagnosis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-15T16:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.11365v1","title":"Determination of the first-generation quark couplings at the Z-pole","summary":"Electroweak Precision Measurements are stringent tests of the Standard Model\nand sensitive probes to New Physics. Accurate studies of the $Z$-boson\ncouplings to the first-generation quarks, which are currently constrained from\nLEP data to a few percent, could reveal potential discrepancies from the theory\npredictions. Future $e^+e^-$ colliders running at the $Z$-pole would be an\nexcellent tool for an analysis based on a comparison of radiative and\nnon-radiative $Z$ boson decays. In this paper, we present a method to extract\nthe values of the $Z$ couplings to light quarks and discuss the uncertainty of\nthe measurement, including contributions from various systematic effects. We\nshow that systematic uncertainty in the heavy-flavour tagging performance is\nthe key factor in the analysis and reducing it to a sub-permille level might be\ncrucial to fully profit from the high luminosity of future $e^+e^-$ machines.\nThe measurement could improve the LEP results by at least an order of\nmagnitude.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-15T16:31:21Z"}
{"aid":"http://arxiv.org/abs/2504.11386v1","title":"Trajectory Encoding Temporal Graph Networks","summary":"Temporal Graph Networks (TGNs) have demonstrated significant success in\ndynamic graph tasks such as link prediction and node classification. Both tasks\ncomprise transductive settings, where the model predicts links among known\nnodes, and in inductive settings, where it generalises learned patterns to\npreviously unseen nodes. Existing TGN designs face a dilemma under these dual\nscenarios. Anonymous TGNs, which rely solely on temporal and structural\ninformation, offer strong inductive generalisation but struggle to distinguish\nknown nodes. In contrast, non-anonymous TGNs leverage node features to excel in\ntransductive tasks yet fail to adapt to new nodes. To address this challenge,\nwe propose Trajectory Encoding TGN (TETGN). Our approach introduces\nautomatically expandable node identifiers (IDs) as learnable temporal\npositional features and performs message passing over these IDs to capture each\nnode's historical context. By integrating this trajectory-aware module with a\nstandard TGN using multi-head attention, TETGN effectively balances\ntransductive accuracy with inductive generalisation. Experimental results on\nthree real-world datasets show that TETGN significantly outperforms strong\nbaselines on both link prediction and node classification tasks, demonstrating\nits ability to unify the advantages of anonymous and non-anonymous models for\ndynamic graph learning.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T16:57:09Z"}
{"aid":"http://arxiv.org/abs/2504.11397v1","title":"MLPs and KANs for data-driven learning in physical problems: A\n  performance comparison","summary":"There is increasing interest in solving partial differential equations (PDEs)\nby casting them as machine learning problems. Recently, there has been a spike\nin exploring Kolmogorov-Arnold Networks (KANs) as an alternative to traditional\nneural networks represented by Multi-Layer Perceptrons (MLPs). While showing\npromise, their performance advantages in physics-based problems remain largely\nunexplored. Several critical questions persist: Can KANs capture complex\nphysical dynamics and under what conditions might they outperform traditional\narchitectures? In this work, we present a comparative study of KANs and MLPs\nfor learning physical systems governed by PDEs. We assess their performance\nwhen applied in deep operator networks (DeepONet) and graph network-based\nsimulators (GNS), and test them on physical problems that vary significantly in\nscale and complexity. Drawing inspiration from the Kolmogorov Representation\nTheorem, we examine the behavior of KANs and MLPs across shallow and deep\nnetwork architectures. Our results reveal that although KANs do not\nconsistently outperform MLPs when configured as deep neural networks, they\ndemonstrate superior expressiveness in shallow network settings, significantly\noutpacing MLPs in accuracy over our test cases. This suggests that KANs are a\npromising choice, offering a balance of efficiency and accuracy in applications\ninvolving physical systems.","main_category":"cs.LG","categories":"cs.LG,physics.comp-ph","published":"2025-04-15T17:13:42Z"}
{"aid":"http://arxiv.org/abs/2504.11407v1","title":"The Higman-M\\lowercase{c}Laughlin Theorem for the flag-transitive\n  $2$-designs with $Î»$ prime","summary":"A famous result of Higman and McLaughlin \\cite{HM} in 1961 asserts that any\nflag-transitive automorphism group $G$ of a $2$-design $\\mathcal{D}$ with\n$\\lambda=1$ acts point-primitively on $\\mathcal{D}$. In this paper, we show\nthat the Higman and McLaughlin theorem is still true when $\\lambda$ is a prime\nand $\\mathcal{D}$ is not isomorphic to one of the two $2$-$(16,6,2)$ designs as\nin [42, Section 1.2], or the $2$-$(45,12,3)$ design as in [44, Construction\n4.2], or, when $2^{2^{j}}+1$ is a Fermat prime, a possible\n$2$-$(2^{2^{j+1}}(2^{2^{j}}+2),2^{2^{j}}(2^{2^{j}}+1),2^{2^{j}}+1)$ design\nhaving very specific features.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-15T17:23:58Z"}
{"aid":"http://arxiv.org/abs/2504.11411v1","title":"Breaking the TDD Flow for Over-the-Air Phase Synchronization in\n  Distributed Antenna Systems","summary":"Phase synchronization between distributed antenna arrays requires\nmeasurements that break the standard time-division duplex (TDD) operation. We\npresent a feasibility study on implementing such synchronization and analyze\nits impact on the quality of service. Considering two antenna arrays with\nindependent local oscillators (LOs), we propose a modified TDD flow to\naccommodate the transmission of phase synchronization signals, formulate the\nphase estimation and compensation problem, and derive the achievable downlink\nspectral efficiency (SE). Numerical results show that frequent re-estimation of\nthe interarray phase disparity is essential for maximizing SE in systems with\nlow-quality LOs. Furthermore, applying a Kalman filter for phase tracking\nsubstantially improves the SE, especially if phase estimation errors are large\ncompared to LOs phase drifts.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T17:26:42Z"}
{"aid":"http://arxiv.org/abs/2504.11412v1","title":"Measures of Variability for Risk-averse Policy Gradient","summary":"Risk-averse reinforcement learning (RARL) is critical for decision-making\nunder uncertainty, which is especially valuable in high-stake applications.\nHowever, most existing works focus on risk measures, e.g., conditional\nvalue-at-risk (CVaR), while measures of variability remain underexplored. In\nthis paper, we comprehensively study nine common measures of variability,\nnamely Variance, Gini Deviation, Mean Deviation, Mean-Median Deviation,\nStandard Deviation, Inter-Quantile Range, CVaR Deviation, Semi_Variance, and\nSemi_Standard Deviation. Among them, four metrics have not been previously\nstudied in RARL. We derive policy gradient formulas for these unstudied\nmetrics, improve gradient estimation for Gini Deviation, analyze their gradient\nproperties, and incorporate them with the REINFORCE and PPO frameworks to\npenalize the dispersion of returns.\n  Our empirical study reveals that variance-based metrics lead to unstable\npolicy updates. In contrast, CVaR Deviation and Gini Deviation show consistent\nperformance across different randomness and evaluation domains, achieving high\nreturns while effectively learning risk-averse policies. Mean Deviation and\nSemi_Standard Deviation are also competitive across different scenarios. This\nwork provides a comprehensive overview of variability measures in RARL,\noffering practical insights for risk-aware decision-making and guiding future\nresearch on risk metrics and RARL algorithms.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T17:28:15Z"}
{"aid":"http://arxiv.org/abs/2504.11425v1","title":"MINDS: The very low-mass star and brown dwarf sample -- Hidden water in\n  carbon-dominated protoplanetary disks","summary":"Infrared observations of the inner disks around very low-mass stars (VLMS,\n$<$0.3$\\,M_{\\odot}$) have revealed a carbon-rich gas composition in the\nterrestrial planet-forming regions. Contrary to the typically water-rich T\nTauri disk spectra, only two disks around VLMS have been observed to be\nwater-rich among more than ten VLMS disks observed so far with JWST/MIRI. In\nthis letter, we systematically search for the presence of water and other\noxygen-bearing molecules in the JWST/MIRI spectra of ten VLMS disks from the\nMIRI mid-INfrared Disk Survey (MINDS). In addition to the two previously\nreported detections of water emission in this VLMS sample, we detect water\nemission in the spectra of three other sources and tentatively in one source,\nand we provide strong evidence for water emission in the remaining disks in the\nMINDS sample, most of which have bright emission from carbon-bearing molecules.\nWe show that the $\\rm C_2H_2$ emission is much stronger than that of water for\nsources with low luminosities, and the hydrocarbons outshine the water emission\nin such conditions. We propose that the appearance of water-rich vs.\nhydrocarbon-rich spectra is related to the location of the water reservoir in\nthe disk relative to the main hydrocarbon reservoir. Our findings indicate that\nthe terrestrial planet forming regions in VLMS disks have high carbon-to-oxygen\nratios (C/O$>$1), but can still harbor ample water similar to those in the T\nTauri disks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T17:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.11427v1","title":"NormalCrafter: Learning Temporally Consistent Normals from Video\n  Diffusion Priors","summary":"Surface normal estimation serves as a cornerstone for a spectrum of computer\nvision applications. While numerous efforts have been devoted to static image\nscenarios, ensuring temporal coherence in video-based normal estimation remains\na formidable challenge. Instead of merely augmenting existing methods with\ntemporal components, we present NormalCrafter to leverage the inherent temporal\npriors of video diffusion models. To secure high-fidelity normal estimation\nacross sequences, we propose Semantic Feature Regularization (SFR), which\naligns diffusion features with semantic cues, encouraging the model to\nconcentrate on the intrinsic semantics of the scene. Moreover, we introduce a\ntwo-stage training protocol that leverages both latent and pixel space learning\nto preserve spatial accuracy while maintaining long temporal context. Extensive\nevaluations demonstrate the efficacy of our method, showcasing a superior\nperformance in generating temporally consistent normal sequences with intricate\ndetails from diverse videos.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:39:07Z"}
{"aid":"http://arxiv.org/abs/2504.11432v1","title":"Analysis of Preheat Propagation in MagLIF-like Plasmas","summary":"The preheat and pre-magnetization of the fuel are essential steps in the\ndesign of Magnetized Liner Inertial Fusion (MagLIF) configurations. Typically,\nthe energy of the preheat laser is deposited in a central region of the fuel\nand propagates outward generating magneto-hydrodynamic structures that impact\nthe fuel mass distribution and magnetic flux compression during the subsequent\nimplosion. We present a theoretical analysis of preheat propagation in a\nmagnetized plasma under conditions typical for MagLIF. The analysis is based on\nthe acoustic time scale for the propagation of pressure disturbances being much\nshorter than the conductive time scale for heat diffusion. In this regime, the\npreheat-driven expansion induces the stratification of fuel mass and magnetic\nfield, which accumulate in a dense outer shelf bounded by the leading shock. We\nderive self-similar solutions of the mathematical model that describe the\nhydrodynamic profiles of the expansion, and evaluate the evolution of the\nmagnetic field in this configuration. The model is supported by FLASH\nsimulations of preheat propagation. Our analysis shows that the regions where\nthe magnetization of the fuel is significant tend to become localized\nasymptotically in time at the interface separating the outer shelf from the\ninner hot core. We assess the implications of this stratification on the\nmagnetic flux conservation and performance of fully integrated MagLIF FLASH\nsimulations.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-15T17:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.11438v1","title":"Mamba-Based Ensemble learning for White Blood Cell Classification","summary":"White blood cell (WBC) classification assists in assessing immune health and\ndiagnosing various diseases, yet manual classification is labor-intensive and\nprone to inconsistencies. Recent advancements in deep learning have shown\npromise over traditional methods; however, challenges such as data imbalance\nand the computational demands of modern technologies, such as Transformer-based\nmodels which do not scale well with input size, limit their practical\napplication. This paper introduces a novel framework that leverages Mamba\nmodels integrated with ensemble learning to improve WBC classification. Mamba\nmodels, known for their linear complexity, provide a scalable alternative to\nTransformer-based approaches, making them suitable for deployment in\nresource-constrained environments. Additionally, we introduce a new WBC\ndataset, Chula-WBC-8, for benchmarking. Our approach not only validates the\neffectiveness of Mamba models in this domain but also demonstrates their\npotential to significantly enhance classification efficiency without\ncompromising accuracy. The source code can be found at\nhttps://github.com/LewisClifton/Mamba-WBC-Classification.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T17:53:18Z"}
{"aid":"http://arxiv.org/abs/2504.11446v1","title":"eXplainable AI for data driven control: an inverse optimal control\n  approach","summary":"Understanding the behavior of black-box data-driven controllers is a key\nchallenge in modern control design. In this work, we propose an eXplainable AI\n(XAI) methodology based on Inverse Optimal Control (IOC) to obtain local\nexplanations for the behavior of a controller operating around a given region.\nSpecifically, we extract the weights assigned to tracking errors and control\neffort in the implicit cost function that a black-box controller is optimizing,\noffering a more transparent and interpretable representation of the\ncontroller's underlying objectives. This approach presents connections with\nwell-established XAI techniques, such as Local Interpretable Model-agnostic\nExplanations (LIME) since it is still based on a local approximation of the\ncontrol policy. However, rather being limited to a standard sensitivity\nanalysis, the explanation provided by our method relies on the solution of an\ninverse Linear Quadratic (LQ) problem, offering a structured and more\ncontrol-relevant perspective. Numerical examples demonstrate that the inferred\ncost function consistently provides a deeper understanding of the controller's\ndecision-making process, shedding light on otherwise counterintuitive or\nunexpected phenomena.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T17:56:24Z"}
{"aid":"http://arxiv.org/abs/2504.11457v1","title":"Aligning Generative Denoising with Discriminative Objectives Unleashes\n  Diffusion for Visual Perception","summary":"With the success of image generation, generative diffusion models are\nincreasingly adopted for discriminative tasks, as pixel generation provides a\nunified perception interface. However, directly repurposing the generative\ndenoising process for discriminative objectives reveals critical gaps rarely\naddressed previously. Generative models tolerate intermediate sampling errors\nif the final distribution remains plausible, but discriminative tasks require\nrigorous accuracy throughout, as evidenced in challenging multi-modal tasks\nlike referring image segmentation. Motivated by this gap, we analyze and\nenhance alignment between generative diffusion processes and perception tasks,\nfocusing on how perception quality evolves during denoising. We find: (1)\nearlier denoising steps contribute disproportionately to perception quality,\nprompting us to propose tailored learning objectives reflecting varying\ntimestep contributions; (2) later denoising steps show unexpected perception\ndegradation, highlighting sensitivity to training-denoising distribution\nshifts, addressed by our diffusion-tailored data augmentation; and (3)\ngenerative processes uniquely enable interactivity, serving as controllable\nuser interfaces adaptable to correctional prompts in multi-round interactions.\nOur insights significantly improve diffusion-based perception models without\narchitectural changes, achieving state-of-the-art performance on depth\nestimation, referring image segmentation, and generalist perception tasks. Code\navailable at https://github.com/ziqipang/ADDP.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:59:54Z"}
{"aid":"http://arxiv.org/abs/2504.11749v1","title":"SkeletonX: Data-Efficient Skeleton-based Action Recognition via\n  Cross-sample Feature Aggregation","summary":"While current skeleton action recognition models demonstrate impressive\nperformance on large-scale datasets, their adaptation to new application\nscenarios remains challenging. These challenges are particularly pronounced\nwhen facing new action categories, diverse performers, and varied skeleton\nlayouts, leading to significant performance degeneration. Additionally, the\nhigh cost and difficulty of collecting skeleton data make large-scale data\ncollection impractical. This paper studies one-shot and limited-scale learning\nsettings to enable efficient adaptation with minimal data. Existing approaches\noften overlook the rich mutual information between labeled samples, resulting\nin sub-optimal performance in low-data scenarios. To boost the utility of\nlabeled data, we identify the variability among performers and the commonality\nwithin each action as two key attributes. We present SkeletonX, a lightweight\ntraining pipeline that integrates seamlessly with existing GCN-based skeleton\naction recognizers, promoting effective training under limited labeled data.\nFirst, we propose a tailored sample pair construction strategy on two key\nattributes to form and aggregate sample pairs. Next, we develop a concise and\neffective feature aggregation module to process these pairs. Extensive\nexperiments are conducted on NTU RGB+D, NTU RGB+D 120, and PKU-MMD with various\nGCN backbones, demonstrating that the pipeline effectively improves performance\nwhen trained from scratch with limited data. Moreover, it surpasses previous\nstate-of-the-art methods in the one-shot setting, with only 1/10 of the\nparameters and much fewer FLOPs. The code and data are available at:\nhttps://github.com/zzysteve/SkeletonX","main_category":"cs.CV","categories":"cs.CV,I.4.9","published":"2025-04-16T04:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.11750v1","title":"Characterizing and Optimizing LLM Inference Workloads on CPU-GPU Coupled\n  Architectures","summary":"Large language model (LLM)-based inference workloads increasingly dominate\ndata center costs and resource utilization. Therefore, understanding the\ninference workload characteristics on evolving CPU-GPU coupled architectures is\ncrucial for optimization. This paper presents an in-depth analysis of LLM\ninference behavior on loosely-coupled (PCIe A100/H100) and closely-coupled\n(GH200) systems. We analyze performance dynamics using fine-grained\noperator-to-kernel trace analysis, facilitated by our novel profiler SKIP and\nmetrics like Total Kernel Launch and Queuing Time (TKLQT). Results show that\nclosely-coupled (CC) GH200 significantly outperforms loosely-coupled (LC)\nsystems at large batch sizes, achieving 1.9x-2.7x faster prefill latency for\nLlama 3.2-1B. However, our analysis also reveals that GH200 remains CPU-bound\nup to 4x larger batch sizes than LC systems. In this extended CPU-bound region,\nwe identify the performance characteristics of the Grace CPU as a key factor\ncontributing to higher inference latency at low batch sizes on GH200. We\ndemonstrate that TKLQT accurately identifies this CPU/GPU-bound transition\npoint. Based on this analysis, we further show that kernel fusion offers\nsignificant potential to mitigate GH200's low-batch latency bottleneck by\nreducing kernel launch overhead. This detailed kernel-level characterization\nprovides critical insights for optimizing diverse CPU-GPU coupling strategies.\nThis work is an initial effort, and we plan to explore other major AI/DL\nworkloads that demand different degrees of CPU-GPU heterogeneous architectures.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.AR,cs.PF","published":"2025-04-16T04:02:39Z"}
{"aid":"http://arxiv.org/abs/2504.11760v1","title":"The Topological Structures of the Orders of Hypergraphs","summary":"We provide first a categorical exploration of, and then completion of the\nmapping of the relationships among, three fundamental perspectives on binary\nrelations: as the incidence matrices of hypergraphs, as the formal contexts of\nconcept lattices, and as specifying topological cosheaves of simplicial\n(Dowker) complexes on simplicial (Dowker) complexes. We provide an integrative,\nfunctorial framework combining previously known with three new results: 1)\ngiven a binary relation, there are order isomorphisms among the bounded edge\norder of the intersection complexes of its dual hypergraphs and its concept\nlattice; 2) the concept lattice of a context is an isomorphism invariant of the\nDowker cosheaf (of abstract simplicial complexes) of that context; and 3) a\nnovel Dowker cosheaf (of chain complexes) of a relation is an isomorphism\ninvariant of the concept lattice of the context that generalizes Dowker's\noriginal homological result. We illustrate these concepts throughout with a\nrunning example, and demonstrate relationships to past results.","main_category":"math.CO","categories":"math.CO,math.AT,math.CT","published":"2025-04-16T04:40:12Z"}
{"aid":"http://arxiv.org/abs/2504.11762v1","title":"Gas-solid Reaction Dynamics on Li$_6$PS$_5$Cl Surfaces: A Case Study of\n  the Influence of CO$_2$ and CO$_2$/O$_2$ Atmospheres Using AIMD and MLFF\n  Simulations","summary":"In recent years, rapid progress has been made in solid-state lithium\nbatteries. Among various technologies, coating the surface of electrodes or\nelectrolytes has proven to be an effective method to enhance interfacial\nstability and improve battery cycling performance. Recent experimental studies\nshowed that gas-solid reactions offer a convenient approach to form modified\ncoating layers on the solid electrolyte. Here, we performed computational\nsimulations to investigate this surface reaction process. Specifically, we\nsimulated the gas-solid reactions of Li$_6$PS$_5$Cl(LPSC) solid-state\nelectrolytes in pure CO$_2$ and in mixed CO$_2$/O$_2$ atmospheres using\nab-initio molecular dynamics (AIMD) and machine-learning force fields\n(MLFF)-accelerated molecular dynamics (MD) approaches. In the former case, LPSC\nsurfaces primarily form Li$_2$CO$_2$S because it is difficult to dissociate\nanother oxygen atom from the second CO$_2$ molecule. While in CO$_2$/O$_2$\nmixed atmosphere, O$_2$ molecules preferentially adsorb onto LPSC, which\nsupplies oxygen sites for subsequent CO$_2$ adsorption to form carbonate\n-CO$_3$ units. This reaction pathway ultimately generates an interfacial\nproduct dominated by Li$_2$CO$_3$. These coatings exhibit distinct electronic\nand ionic conductivity characteristics, allowing the possibility to control\ncoating compositions and configurations by adjusting the gas-solid reactions.\nKey criteria for applying this strategy are extracted from the current\nresearch.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.mtrl-sci","published":"2025-04-16T04:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.11767v1","title":"Post-selection Inference in Regression Models for Group Testing Data","summary":"We develop methodology for valid inference after variable selection in\nlogistic regression when the responses are partially observed, that is, when\none observes a set of error-prone testing outcomes instead of the true values\nof the responses. Aiming at selecting important covariates while accounting for\nmissing information in the response data, we apply the expectation-maximization\nalgorithm to compute maximum likelihood estimators subject to LASSO\npenalization. Subsequent to variable selection, we make inferences on the\nselected covariate effects by extending post-selection inference methodology\nbased on the polyhedral lemma. Empirical evidence from our extensive simulation\nstudy suggests that our post-selection inference results are more reliable than\nthose from naive inference methods that use the same data to perform variable\nselection and inference without adjusting for variable selection.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T05:08:57Z"}
{"aid":"http://arxiv.org/abs/2504.11798v1","title":"Neighbor-Based Feature and Index Enhancement for Person\n  Re-Identification","summary":"Person re-identification (Re-ID) aims to match the same pedestrian in a large\ngallery with different cameras and views. Enhancing the robustness of the\nextracted feature representations is a main challenge in Re-ID. Existing\nmethods usually improve feature representation by improving model architecture,\nbut most methods ignore the potential contextual information, which limits the\neffectiveness of feature representation and retrieval performance. Neighborhood\ninformation, especially the potential information of multi-order neighborhoods,\ncan effectively enrich feature expression and improve retrieval accuracy, but\nthis has not been fully explored in existing research. Therefore, we propose a\nnovel model DMON-ARO that leverages latent neighborhood information to enhance\nboth feature representation and index performance. Our approach is built on two\ncomplementary modules: Dynamic Multi-Order Neighbor Modeling (DMON) and\nAsymmetric Relationship Optimization (ARO). The DMON module dynamically\naggregates multi-order neighbor relationships, allowing it to capture richer\ncontextual information and enhance feature representation through adaptive\nneighborhood modeling. Meanwhile, ARO refines the distance matrix by optimizing\nquery-to-gallery relationships, improving the index accuracy. Extensive\nexperiments on three benchmark datasets demonstrate that our approach achieves\nperformance improvements against baseline models, which illustrate the\neffectiveness of our model. Specifically, our model demonstrates improvements\nin Rank-1 accuracy and mAP. Moreover, this method can also be directly extended\nto other re-identification tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T06:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.11813v1","title":"Threshold, subthreshold and global unbounded solutions of superlinear\n  heat equations","summary":"We consider the semilinear heat equation with a superlinear nonlinearity and\nwe study the properties of threshold or subthreshold solutions, lying on or\nbelow the boundary between blow-up and global existence, respectively. For the\nCauchy-Dirichlet problem, we prove the boundedness of any subthreshold\nsolution. This implies, in particular, that all global unbounded solutions --\nif they exist -- are threshold solutions. For the Cauchy problem, these\nproperties fail in general but we show that they become true for a suitably\nmodified notion of threshold. Our results strongly improve known results even\nin the model case of power nonlinearities, especially in the Sobolev critical\nand supercritical cases.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T06:50:49Z"}
{"aid":"http://arxiv.org/abs/2504.11814v1","title":"ARWI: Arabic Write and Improve","summary":"Although Arabic is spoken by over 400 million people, advanced Arabic writing\nassistance tools remain limited. To address this gap, we present ARWI, a new\nwriting assistant that helps learners improve essay writing in Modern Standard\nArabic. ARWI is the first publicly available Arabic writing assistant to\ninclude a prompt database for different proficiency levels, an Arabic text\neditor, state-of-the-art grammatical error detection and correction, and\nautomated essay scoring aligned with the Common European Framework of Reference\nstandards for language attainment. Moreover, ARWI can be used to gather a\ngrowing auto-annotated corpus, facilitating further research on Arabic grammar\ncorrection and essay scoring, as well as profiling patterns of errors made by\nnative speakers and non-native learners. A preliminary user study shows that\nARWI provides actionable feedback, helping learners identify grammatical gaps,\nassess language proficiency, and guide improvement.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T07:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.11820v1","title":"Real-World Depth Recovery via Structure Uncertainty Modeling and\n  Inaccurate GT Depth Fitting","summary":"The low-quality structure in raw depth maps is prevalent in real-world RGB-D\ndatasets, which makes real-world depth recovery a critical task in recent\nyears. However, the lack of paired raw-ground truth (raw-GT) data in the real\nworld poses challenges for generalized depth recovery. Existing methods\ninsufficiently consider the diversity of structure misalignment in raw depth\nmaps, which leads to poor generalization in real-world depth recovery. Notably,\nrandom structure misalignments are not limited to raw depth data but also\naffect GT depth in real-world datasets. In the proposed method, we tackle the\ngeneralization problem from both input and output perspectives. For input, we\nenrich the diversity of structure misalignment in raw depth maps by designing a\nnew raw depth generation pipeline, which helps the network avoid overfitting to\na specific condition. Furthermore, a structure uncertainty module is designed\nto explicitly identify the misaligned structure for input raw depth maps to\nbetter generalize in unseen scenarios. Notably the well-trained depth\nfoundation model (DFM) can help the structure uncertainty module estimate the\nstructure uncertainty better. For output, a robust feature alignment module is\ndesigned to precisely align with the accurate structure of RGB images avoiding\nthe interference of inaccurate GT depth. Extensive experiments on multiple\ndatasets demonstrate the proposed method achieves competitive accuracy and\ngeneralization capabilities across various challenging raw depth maps.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-16T07:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.11822v1","title":"Properties of Near Field Focusing for Cylindrical Dipole Arrays in\n  Enclosed Array Volume","summary":"Motivated by large intelligent surface applications, the electric field\nproperties of near field focusing using phase conjugation method are analyzed\nfor cylindrical dipole arrays. Firstly, for the transmitting antennas featuring\nvertical polarization, the polarization characteristic is decomposed along the\nx, y, and z directions. Three typical cases are studied when the focal points\nare at (xf , 0, 0), (0, yf , 0), and (0, 0, zf ). When the length of the\ncylindrical dipole array is significantly larger compared to its radius,\ncertain unique insights emerge. When the focal point is positioned along (0, 0,\nzf ), apart from the region on both sides, the ratio between Ez and Ex/Ey\nremains {\\pi}/2. Additionally, When the focal point is located within the\ncylinder, the electric field of each polarization is approximately the same\neverywhere. In other words, beam focusing does not incur losses due to\ndifferent positions. The focusing resolution of Ez is the same in the\ntransverse and longitudinal directions. Different from the situation where the\n3 - dB focal beam depth is much smaller than the focal beam width for the most\nof arrays, the resolution in the longitudinal can be improved, respectively.\nThrough a comprehensive grasp of these design principles, we can gain a deeper\nunderstanding of the specific areas with significant potential for practical\napplications.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T07:16:33Z"}
{"aid":"http://arxiv.org/abs/2504.11824v1","title":"Profile control of fibre-based micro-mirrors using adaptive laser\n  shooting with $\\textit{in situ}$ imaging","summary":"Fibre Fabry-Perot cavities (FFPCs) are used in various studies in cavity\nquantum electrodynamics (CQED) and quantum technologies due to the cavity's\nsmall mode volume and compact integration with optical fibres. We develop a\nnovel $\\text{CO}_2$ laser machining method that produces well-controlled\nsurface profiles on the end facets of cleaved optical fibres. Using multiple\nshots in distinct spatial distribution patterns, our method employs a shooting\nalgorithm that adaptively changes laser ablation parameters during the shooting\nto suppress deviations from the desired profile. This is made possible by\n$\\textit{in situ}$ imaging of the machined profile, its inspection and the\nusage of the information in the subsequent steps. Underlying this algorithm is\na newly found laser ablation parameter, the pause between shots, which controls\nthe accumulation of heat in between successive laser shots and as a result\ndetermines the area of impact made by an individual ablation sequence. We\nfabricate fibre-based micro-mirrors with radii of curvature ranging from 250\n$\\mu$m to 700 $\\mu$m with an effective mirror diameter of 60 $\\mu$m in either\nGaussian or spherical profiles. Due to the self-correcting nature of our\nadaptive algorithm, we achieve a near 100\\% success rate in the production of\ndesired profiles with low ellipticity. After furnishing the laser machined\nfibre end facets with high reflectivity coating, FFPCs are formed to\ndemonstrate a high finesse up to 150,000 at an optical wavelength of 854 nm.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-16T07:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.11860v1","title":"From Data Behavior to Code Analysis: A Multimodal Study on Security and\n  Privacy Challenges in Blockchain-Based DApp","summary":"The recent proliferation of blockchain-based decentralized applications\n(DApp) has catalyzed transformative advancements in distributed systems, with\nextensive deployments observed across financial, entertainment, media, and\ncybersecurity domains. These trustless architectures, characterized by their\ndecentralized nature and elimination of third-party intermediaries, have\ngarnered substantial institutional attention. Consequently, the escalating\nsecurity challenges confronting DApp demand rigorous scholarly investigation.\nThis study initiates with a systematic analysis of behavioral patterns derived\nfrom empirical DApp datasets, establishing foundational insights for subsequent\nmethodological developments. The principal security vulnerabilities in\nEthereum-based smart contracts developed via Solidity are then critically\nexamined. Specifically, reentrancy vulnerability attacks are addressed by\nformally representing contract logic using highly expressive code fragments.\nThis enables precise source code-level detection via bidirectional long\nshort-term memory networks with attention mechanisms (BLSTM-ATT). Regarding\nprivacy preservation challenges, contemporary solutions are evaluated through\ndual analytical lenses: identity privacy preservation and transaction anonymity\nenhancement, while proposing future research trajectories in cryptographic\nobfuscation techniques.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-16T08:30:43Z"}
{"aid":"http://arxiv.org/abs/2504.11880v1","title":"Nonequilibrium Casimir pressure for two graphene-coated plates: Quantum\n  field theoretical approach","summary":"We consider the nonequilibrium Casimir pressure in the system of two parallel\ngraphene-coated plates one of which is either warmer or cooler than the\nenvironment. The electromagnetic response of graphene coating characterized by\nthe nonzero energy gap and chemical potential is described in the framework of\nthe Dirac model by means of the polarization tensor. It is shown that the\nmagnitude of the nonequilibrium Casimir pressure on a warmer plate than the\nenvironment is larger and on a cooler plate is smaller than the magnitude of\nthe standard Casimir pressure in the state of thermal equilibrium. According to\nour results, the spatially local theory underestimates the role of the effects\nof nonequilibrium. This underestimation increases for asmaller chemical\npotential of the graphene coating and at lower temperatures of the cooled\nplate. Possible applications of the obtained results are discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T09:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.11888v1","title":"Overview of hadronic interaction studies at the Pierre Auger Observatory","summary":"The combination of fluorescence and surface detectors at the Pierre Auger\nObservatory offers unprecedented precision in testing models of hadronic\ninteractions at center-of-mass energies around 70 TeV and beyond. However, for\nsome time, discrepancies between model predictions and measured air-shower data\nhave complicated efforts to accurately determine the mass composition of\nultra-high-energy cosmic rays. A key inconsistency is the deficit of simulated\nsignals compared to those measured with the surface detectors, typically\ninterpreted as a deficit in the muon signal generated by the hadronic component\nof simulated showers.\n  Recently, a new global method has been applied to the combined data from the\nsurface and fluorescence detectors at the Pierre Auger Observatory. This method\nsimultaneously determines the mass composition of cosmic rays and evaluates\nvariations in the simulated depth of the shower maximum and hadronic signals on\nthe ground. The findings reveal not only the alleviated muon problem but also\nshow that all current models of hadronic interactions predict depths of the\nshower maximum that are too shallow, offering new insights into deficiencies in\nthese models from a broader perspective.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T09:17:18Z"}
{"aid":"http://arxiv.org/abs/2504.11896v1","title":"Learning Physics-Informed Color-Aware Transforms for Low-Light Image\n  Enhancement","summary":"Image decomposition offers deep insights into the imaging factors of visual\ndata and significantly enhances various advanced computer vision tasks. In this\nwork, we introduce a novel approach to low-light image enhancement based on\ndecomposed physics-informed priors. Existing methods that directly map\nlow-light to normal-light images in the sRGB color space suffer from\ninconsistent color predictions and high sensitivity to spectral power\ndistribution (SPD) variations, resulting in unstable performance under diverse\nlighting conditions. To address these challenges, we introduce a\nPhysics-informed Color-aware Transform (PiCat), a learning-based framework that\nconverts low-light images from the sRGB color space into deep\nillumination-invariant descriptors via our proposed Color-aware Transform\n(CAT). This transformation enables robust handling of complex lighting and SPD\nvariations. Complementing this, we propose the Content-Noise Decomposition\nNetwork (CNDN), which refines the descriptor distributions to better align with\nwell-lit conditions by mitigating noise and other distortions, thereby\neffectively restoring content representations to low-light images. The CAT and\nthe CNDN collectively act as a physical prior, guiding the transformation\nprocess from low-light to normal-light domains. Our proposed PiCat framework\ndemonstrates superior performance compared to state-of-the-art methods across\nfive benchmark datasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-16T09:23:38Z"}
{"aid":"http://arxiv.org/abs/2504.11898v1","title":"Anharmonic infrared spectra of cationic pyrene and superhydrogenated\n  derivatives","summary":"Studying the anharmonicity in the infrared (IR) spectra of polycyclic\naromatic hydrocarbons (PAHs) at elevated temperatures is important to\nunderstand vibrational features and chemical properties of interstellar dust,\nespecially in the James Webb Space Telescope (JWST) era. We take pyrene as an\nexample PAH and investigate how different degrees of superhydrogenation affects\nthe applicability of the harmonic approximation and the role of temperature in\nIR spectra of PAHs. This is achieved by comparing theoretical IR spectra\ngenerated by classical molecular dynamics (MD) simulations and experimental IR\nspectra obtained via gas-phase action spectroscopy which utilizes the Infrared\nMultiple Photon Dissociation (IRMPD). All simulations are accelerated by a\nmachine learning interatomic potential, in order to reach first principle\naccuracies while keeping low computational costs. We have found that the\nharmonic approximation with empirical scaling factors is able to reproduce\nexperimental band profile of pristine and partially superhydrogenated pyrene\ncations. However, a MD-based anharmonic treatment is mandatory in the case of\nfully superhydrogenated pyrene cation for matching theory and experiment. In\naddition, band shifts and broadenings as the temperature increases are\ninvestigated in detail. Those findings may aid in the interpretation of JWST\nobservations on the variations in band positions and widths of interstellar\ndust.","main_category":"physics.chem-ph","categories":"physics.chem-ph,astro-ph.GA","published":"2025-04-16T09:24:18Z"}
{"aid":"http://arxiv.org/abs/2504.11912v1","title":"Nonlinearly self-interacting extended bodies move as test bodies in\n  effective external fields","summary":"In electromagnetism, linearized general relativity, and other contexts,\nprevious work has shown that the laws of motion which govern compact,\nself-interacting bodies can be obtained by applying \"Detweiler-Whiting\nprescriptions\" to the laws of motion which govern test bodies. These\nprescriptions replace any field which appears in a test-body law of motion with\na certain effective field which is a quasilocal functional of the physical\nvariables -- a functional that can be interpreted as a regularization procedure\nin a point-particle limit. We generalize these results, presenting a formalism\nwhich allows Detweiler-Whiting prescriptions to be be directly derived for\nextended bodies, even in nonlinear field theories. If a generating functional\nwith particular properties can be constructed, we find effective linear and\nangular momenta which evolve via Mathisson-Papapetrou-Dixon equations involving\nappropriate effective fields. These equations implicitly incorporate all\nself-force, self-torque, and extended-body effects. Although our main focus is\non bodies coupled to nonlinear scalar fields, we also remark on the\ngravitational case.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T09:46:04Z"}
{"aid":"http://arxiv.org/abs/2504.11945v1","title":"Jets from a stellar-mass black hole are as relativistic as those from\n  supermassive black holes","summary":"Relativistic jets from supermassive black holes in active galactic nuclei are\namongst the most powerful phenomena in the universe, acting to regulate the\ngrowth of massive galaxies. Similar jets from stellar-mass black holes offer a\nchance to study the same phenomena on accessible observation time scales.\nHowever, such comparative studies across black hole masses and time scales\nremain hampered by the long-standing perception that stellar-mass black hole\njets are in a less relativistic regime. We used radio interferometry\nobservations to monitor the Galactic black hole X-ray binary 4U 1543-47 and\ndiscovered two distinct, relativistic ejections launched during a single\noutburst. Our measurements reveal a likely Lorentz factor of $\\sim$ 8 and a\nminimum of 4.6 at launch with 95% confidence, demonstrating that stellar-mass\nblack holes in X-ray binaries can launch jets as relativistic as those seen in\nactive galactic nuclei.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T10:23:56Z"}
{"aid":"http://arxiv.org/abs/2504.11948v1","title":"On finitely generated Hausdorff spectra of groups acting on rooted trees","summary":"We answer two longstanding questions of Klopsch (1999) and Shalev (2000) by\nproving that the finitely generated Hausdorff spectrum of the closure of a\nfinitely generated regular branch group with respect to the level-stabilizer\nfiltration is the full interval [0,1]. Previous work related to the above\nquestions include the celebrated result of Ab\\'ert and Vir\\'ag on the\ncompleteness of the finitely generated Hausdorff spectrum of the group of\n$p$-adic automorphisms $W_p$. We extend their result to any level-transitive\niterated wreath product acting on a regular rooted tree, and more importantly,\nprovide the first explicit examples of finitely generated subgroups with\nprescribed Hausdorff dimension. In fact, in $W_p$ such subgroups can be taken\nto be 2-generated, giving further evidence to a conjecture of Ab\\'ert and\nVir\\'ag. Furthermore, we extend a well-known result of Klopsch (1999) for\nbranch groups to closed level-transitive groups with fully dimensional rigid\nstabilizers: these have full Hausdorff spectrum with respect to the\nlevel-stabilizer filtration. In turn, we determine, for the first time, the\nHausdorff spectum of many well-studied families of weakly branch groups. As an\nadditional new contribution, we define {\\it nice filtrations} (which include\nthe level-stabilizer filtration). In fact, the first and the last result can be\nproven more generally with respect to these filtrations (under possibly some\nfurther assumptions). Finally, we also consider two standard filtrations,\nnamely the $2$-central lower series, and the dimension subgroup or\nJenning-Zassenhaus series in the closure of the first Grigorchuck group, and\nshow that its finitely generated Hausdorff spectra with respect to these\nfiltrations is the full interval [0,1], answering a recent question of de las\nHeras and Thillaisundaram (2022). This is obtained via a reduction to\nproperties concerning to nice filtrations.","main_category":"math.GR","categories":"math.GR","published":"2025-04-16T10:24:26Z"}
{"aid":"http://arxiv.org/abs/2504.11963v1","title":"Advantages of off-line analysis of digitally recorded pulses in case of\n  neutron-gamma discrimination in scintillators","summary":"Many modern digital analyzers offer the ability to record raw pulses from\nionizing radiation detectors. We use this opportunity to investigate the\neffectiveness of Charge Comparison Method in Pulse Shape Discrimination of\nneutron and gamma radiation measured with organic glass scintillator and\ntrans-stilbene. The idea of software for automated off-line analysis of\ndigitally recorded data is briefly described. We discuss the difference between\nLeading Edge and Constant Fraction Discrimination triggering methods and we\npropose triggering on pulse maximum as an alternative. We observe that the\nstarting point of charge integration gates has major impact on Figure of Merit\nvalues, therefore it is important to choose it carefully and report it with\nother Charge Comparison Method parameters to keep comparison between\nscintillators reliable. Figure of Merit has a limited usage, so Relative Height\nof Minimum is proposed as an additional indicator of neutron-gamma\ndiscrimination effectiveness in practical applications.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-16T10:53:42Z"}
{"aid":"http://arxiv.org/abs/2504.11969v1","title":"Extended scalar sectors from all angles -- Mostly at lepton colliders","summary":"I briefly discuss the current state of the art for models with extended\nscalar sectors and give examples for corresponding investigations, with a focus\non processes at lepton colliders.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T11:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.11973v1","title":"Probing the cold nature of dark matter","summary":"A pressureless dark matter component fits well with several cosmological\nobservations. However, there are indications that cold dark matter may\nencounter challenges in explaining observations at small scales, particularly\nat galactic scales. Observational data suggest that dark matter models\nincorporating a pressure component could provide solutions to these small-scale\nproblems. In this work, we investigate the possibility that present-day dark\nmatter may result from a decaying non-cold dark matter sector transitioning\ninto the dark energy sector. As the sensitivity of astronomical surveys rapidly\nincreases, we explore an interacting scenario between dark energy and non-cold\ndark matter, where dark energy has a constant equation of state ($w_{\\rm de}$),\nand dark matter, being non-cold, also has a constant (non-zero) equation of\nstate ($w_{\\rm dm}$). Considering the phantom and quintessence nature of dark\nenergy, characterized by its equation of state, we separately analyze\ninteracting phantom and interacting quintessence scenarios. We constrain these\nscenarios using Cosmic Microwave Background (CMB) measurements and their\ncombination with external probes, such as DESI-BAO and PantheonPlus. From our\nanalyses, we find that a very mild preference for non-cold dark matter cannot\nbe excluded based on the employed datasets. Additionally, for some datasets,\nthere is a pronounced preference for the presence of an interaction at more\nthan 95\\% confidence level (CL). Moreover, when the dark energy equation of\nstate lies in the phantom regime, the $S_8$ tension can be alleviated. This\nstudy suggests that cosmological models incorporating a non-cold dark matter\ncomponent should be considered as viable scenarios with novel phenomenological\nimplications, as reflected in the present work.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-16T11:10:56Z"}
{"aid":"http://arxiv.org/abs/2504.11982v1","title":"Efficient identification of linear, parameter-varying, and nonlinear\n  systems with noise models","summary":"We present a general system identification procedure capable of estimating of\na broad spectrum of state-space dynamical models, including linear\ntime-invariant (LTI), linear parameter-varying} (LPV), and nonlinear (NL)\ndynamics, along with rather general classes of noise models. Similar to the LTI\ncase, we show that for this general class of model structures, including the NL\ncase, the model dynamics can be separated into a deterministic process and a\nstochastic noise part, allowing to seamlessly tune the complexity of the\ncombined model both in terms of nonlinearity and noise modeling. We\nparameterize the involved nonlinear functional relations by means of artificial\nneural-networks (ANNs), although alternative parametric nonlinear mappings can\nalso be used. To estimate the resulting model structures, we optimize a\nprediction-error-based criterion using an efficient combination of a\nconstrained quasi-Newton approach and automatic differentiation, achieving\ntraining times in the order of seconds compared to existing state-of-the-art\nANN methods which may require hours for models of similar complexity. We\nformally establish the consistency guarantees for the proposed approach and\ndemonstrate its superior estimation accuracy and computational efficiency on\nseveral benchmark LTI, LPV, and NL system identification problems.","main_category":"math.OC","categories":"math.OC,cs.LG,cs.SY,eess.SY","published":"2025-04-16T11:23:30Z"}
{"aid":"http://arxiv.org/abs/2504.11987v1","title":"No Fuss, Just Function -- A Proposal for Non-Intrusive Full Body\n  Tracking in XR for Meaningful Spatial Interactions","summary":"Extended Reality (XR) is a rapidly growing field with a wide range of\nhardware from head mounted displays to installations. Users have the\npossibility to access the entire Mixed Reality (MR) continuum. Goal of the\nhuman-computer-interaction (HCI) community is to allow natural and intuitive\ninteractions but in general interactions for XR often rely on handheld\ncontrollers. One natural interaction method is full body tracking (FBT), where\na user can use their body to interact with the experience. Classically, FBT\nsystems require markers or trackers on the users to capture motion. Recently,\nthere have been approaches based on Human Pose Estimation (HPE), which\nhighlight the potential of low-cost non-intrusive FBT for XR. Due to the lack\nof handheld devices, HPE may also improve accessibility with people struggling\nwith traditional input methods. This paper proposes the concept of\nnon-intrusive FBT for XR for all. The goal is to spark a discussion on\nadvantages for users by using a non-intrusive FBT system for accessibility and\nuser experience.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-16T11:28:34Z"}
{"aid":"http://arxiv.org/abs/2504.11990v1","title":"Secure Transfer Learning: Training Clean Models Against Backdoor in\n  (Both) Pre-trained Encoders and Downstream Datasets","summary":"Transfer learning from pre-trained encoders has become essential in modern\nmachine learning, enabling efficient model adaptation across diverse tasks.\nHowever, this combination of pre-training and downstream adaptation creates an\nexpanded attack surface, exposing models to sophisticated backdoor embeddings\nat both the encoder and dataset levels--an area often overlooked in prior\nresearch. Additionally, the limited computational resources typically available\nto users of pre-trained encoders constrain the effectiveness of generic\nbackdoor defenses compared to end-to-end training from scratch. In this work,\nwe investigate how to mitigate potential backdoor risks in resource-constrained\ntransfer learning scenarios. Specifically, we conduct an exhaustive analysis of\nexisting defense strategies, revealing that many follow a reactive workflow\nbased on assumptions that do not scale to unknown threats, novel attack types,\nor different training paradigms. In response, we introduce a proactive mindset\nfocused on identifying clean elements and propose the Trusted Core (T-Core)\nBootstrapping framework, which emphasizes the importance of pinpointing\ntrustworthy data and neurons to enhance model security. Our empirical\nevaluations demonstrate the effectiveness and superiority of T-Core,\nspecifically assessing 5 encoder poisoning attacks, 7 dataset poisoning\nattacks, and 14 baseline defenses across five benchmark datasets, addressing\nfour scenarios of 3 potential backdoor threats.","main_category":"cs.LG","categories":"cs.LG,cs.CR","published":"2025-04-16T11:33:03Z"}
{"aid":"http://arxiv.org/abs/2504.12002v1","title":"Property $R_{\\infty}$ for groups with infinitely many ends","summary":"We show that an accessible group with infinitely many ends has property\n$R_{\\infty}$. That is, it has infinitely many twisted conjugacy classes for any\ntwisting automorphism. We deduce that having property $R_{\\infty}$ is\nundecidable amongst finitely presented groups.\n  We also show that the same is true for a wide class of relatively hyperbolic\ngroups, filling in some of the gaps in the literature. Specifically, we show\nthat a non-elementary, finitely presented relatively hyperbolic group with\nfinitely generated peripheral subgroups which are not themselves relatively\nhyperbolic, has property $R_{\\infty}$.","main_category":"math.GR","categories":"math.GR,math.GT","published":"2025-04-16T11:55:40Z"}
{"aid":"http://arxiv.org/abs/2504.12017v1","title":"Unified Multipole Bott Indices for Non-Hermitian Skin Effect in\n  Different Orders","summary":"Non-Hermitian systems exhibit a distinctive phenomenon known as the\nnon-Hermitian skin effect, where an extensive number of eigenstates become\nlocalized at the boundaries of a lattice with open boundaries. While the\nspectral winding number under periodic boundary conditions is a\nwell-established topological indicator for predicting the skin effect in\none-dimensional non-Hermitian systems, a suitable topological invariant to\ndiagnose higher-order skin effects remains elusive. In this Letter, we propose\na unified non-Hermitian multipole characterization framework that generalizes\nthe concept of spectral winding to higher-order skin effects. Specifically, we\ndevelop a set of non-Hermitian multipole Bott indices capable of diagnosing\nskin effects of different orders. Our approach provides a comprehensive\nunderstanding of both first- and higher-order skin effects in non-Hermitian\nsystems, offering new perspectives for exploring topological phenomena in\nnon-Hermitian systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-16T12:17:42Z"}
{"aid":"http://arxiv.org/abs/2504.12025v1","title":"FedEPA: Enhancing Personalization and Modality Alignment in Multimodal\n  Federated Learning","summary":"Federated Learning (FL) enables decentralized model training across multiple\nparties while preserving privacy. However, most FL systems assume clients hold\nonly unimodal data, limiting their real-world applicability, as institutions\noften possess multimodal data. Moreover, the lack of labeled data further\nconstrains the performance of most FL methods. In this work, we propose FedEPA,\na novel FL framework for multimodal learning. FedEPA employs a personalized\nlocal model aggregation strategy that leverages labeled data on clients to\nlearn personalized aggregation weights, thereby alleviating the impact of data\nheterogeneity. We also propose an unsupervised modality alignment strategy that\nworks effectively with limited labeled data. Specifically, we decompose\nmultimodal features into aligned features and context features. We then employ\ncontrastive learning to align the aligned features across modalities, ensure\nthe independence between aligned features and context features within each\nmodality, and promote the diversity of context features. A multimodal feature\nfusion strategy is introduced to obtain a joint embedding. The experimental\nresults show that FedEPA significantly outperforms existing FL methods in\nmultimodal classification tasks under limited labeled data conditions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T12:32:37Z"}
{"aid":"http://arxiv.org/abs/2504.12034v1","title":"OpDiffer: LLM-Assisted Opcode-Level Differential Testing of Ethereum\n  Virtual Machine","summary":"As Ethereum continues to thrive, the Ethereum Virtual Machine (EVM) has\nbecome the cornerstone powering tens of millions of active smart contracts.\nIntuitively, security issues in EVMs could lead to inconsistent behaviors among\nsmart contracts or even denial-of-service of the entire blockchain network.\nHowever, to the best of our knowledge, only a limited number of studies focus\non the security of EVMs. Moreover, they suffer from 1) insufficient test input\ndiversity and invalid semantics; and 2) the inability to automatically identify\nbugs and locate root causes. To bridge this gap, we propose OpDiffer, a\ndifferential testing framework for EVM, which takes advantage of LLMs and\nstatic analysis methods to address the above two limitations. We conducted the\nlargest-scale evaluation, covering nine EVMs and uncovering 26 previously\nunknown bugs, 22 of which have been confirmed by developers and three have been\nassigned CNVD IDs. Compared to state-of-the-art baselines, OpDiffer can improve\ncode coverage by at most 71.06%, 148.40% and 655.56%, respectively. Through an\nanalysis of real-world deployed Ethereum contracts, we estimate that 7.21% of\nthe contracts could trigger our identified EVM bugs under certain environmental\nsettings, potentially resulting in severe negative impact on the Ethereum\necosystem.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-16T12:48:00Z"}
{"aid":"http://arxiv.org/abs/2504.12054v1","title":"Monitoring biodiversity on highly reactive rock-paper-scissors models","summary":"This work investigates how biodiversity is affected in a cyclic spatial\nMay-Leonard model with hierarchical and non-hierarchical rules. Here we propose\na generalization of the traditional rock-paper-scissors model by considering\nhighly reactive species, i. e., species that react in a stronger manner\ncompared to the others in respect to either competition or reproduction. These\ntwo classes of models, called here Highly Competitive and Highly Reproductive\nmodels, may lead to hierarchical and non-hierarchical dynamics, depending on\nthe number of highly reactive species. The fundamental feature of these models\nis the fact that hierarchical models may as well support biodiversity, however,\nwith a higher probability of extinction than the non-hierarchical ones, which\nare in fact more robust. This analysis is done by evaluating the probability of\nextinction as a function of mobility. In particular, we have analyzed how the\ndominance scheme changes depending on the highly reactive species for\nnon-hierarchical models, where the findings lead to the conclusion that highly\nreactive species are usually at a disadvantage compared to the others.\nMoreover, we have investigated the power spectrum and the characteristic length\nof each species, including more information on the behavior of the several\nsystems considered in the present work.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.bio-ph","published":"2025-04-16T13:09:18Z"}
{"aid":"http://arxiv.org/abs/2504.12059v1","title":"Sustainable cooperation on the hybrid pollution-control game with\n  heterogeneous players","summary":"This paper considers a hybrid pollution-control differential game with two\nfarsighted players and one myopic player. Both the seasonal regime shifts in\nthe state dynamics and the players' heterogeneous preferences are introduced\ninto the model. The strategies under cooperative, noncooperative and partially\ncooperative scenarios are obtained by utilizing the Pontryagin's Maximum\nPrinciple. Under all feasible coalition structures, the convergence of the\nstate variable is proved. A new sustainably--cooperative optimality principle\nis proposed according to the coalition structures, which belongs to the\nimputation set. The prerequisite for the existence of time-consistency in the\nsustainably-cooperative optimality principle is explicitly obtained. The\nseasonal imputation distribution procedure (IDP) is designed to maintain the\ntime-consistentcy (dynamic stability) of cooperation over time.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T13:11:21Z"}
{"aid":"http://arxiv.org/abs/2504.12060v1","title":"Static to Dynamic Correlation Clustering","summary":"Correlation clustering is a well-studied problem, first proposed by Bansal,\nBlum, and Chawla [BBC04]. The input is an unweighted, undirected graph. The\nproblem is to cluster the vertices so as to minimizing the number of edges\nbetween vertices in different clusters and missing edges between vertices\ninside the same cluster. This problem has a wide application in data mining and\nmachine learning. We introduce a general framework that transforms existing\nstatic correlation clustering algorithms into fully-dynamic ones that work\nagainst an adaptive adversary.\n  We show how to apply our framework to known efficient correlation clustering\nalgorithms, starting from the classic 3-approximate Pivot algorithm from\n[ACN08]. Applied to the most recent near-linear 1.437-approximation algorithm\nfrom [CCL+25], we get a 1.437-approximation fully-dynamic algorithm that works\nwith worst-case constant update time. The original static algorithm gets its\napproximation factor with constant probability, and we get the same against an\nadaptive adversary in the sense that for any given update step not known to our\nalgorithm, our solution is a 1.437-approximation with constant probability when\nwe reach this update.\n  Previous dynamic algorithms had approximation factors around 3 in\nexpectation, and they could only handle an oblivious adversary.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-16T13:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.12063v1","title":"Optimizing Compound Retrieval Systems","summary":"Modern retrieval systems do not rely on a single ranking model to construct\ntheir rankings. Instead, they generally take a cascading approach where a\nsequence of ranking models are applied in multiple re-ranking stages. Thereby,\nthey balance the quality of the top-K ranking with computational costs by\nlimiting the number of documents each model re-ranks. However, the cascading\napproach is not the only way models can interact to form a retrieval system.\n  We propose the concept of compound retrieval systems as a broader class of\nretrieval systems that apply multiple prediction models. This encapsulates\ncascading models but also allows other types of interactions than top-K\nre-ranking. In particular, we enable interactions with large language models\n(LLMs) which can provide relative relevance comparisons. We focus on the\noptimization of compound retrieval system design which uniquely involves\nlearning where to apply the component models and how to aggregate their\npredictions into a final ranking. This work shows how our compound approach can\ncombine the classic BM25 retrieval model with state-of-the-art (pairwise) LLM\nrelevance predictions, while optimizing a given ranking metric and efficiency\ntarget. Our experimental results show optimized compound retrieval systems\nprovide better trade-offs between effectiveness and efficiency than cascading\napproaches, even when applied in a self-supervised manner.\n  With the introduction of compound retrieval systems, we hope to inspire the\ninformation retrieval field to more out-of-the-box thinking on how prediction\nmodels can interact to form rankings.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.LG","published":"2025-04-16T13:18:16Z"}
{"aid":"http://arxiv.org/abs/2504.12068v1","title":"Time Advance in PT-Symmetric Quantum Mechanics and Negative Time Delay","summary":"In a recent experiment Angulo et. al. have reported a negative time delay in\natomic scattering experiments. Here we point out that this could potentially be\nthe time advance expected in PT-symmetric theories as the PT counterpart to\ntime delay.","main_category":"quant-ph","categories":"quant-ph,hep-th","published":"2025-04-16T13:24:07Z"}
{"aid":"http://arxiv.org/abs/2504.12088v1","title":"AttentionDrop: A Novel Regularization Method for Transformer Models","summary":"Transformer-based architectures achieve state-of-the-art performance across a\nwide range of tasks in natural language processing, computer vision, and\nspeech. However, their immense capacity often leads to overfitting, especially\nwhen training data is limited or noisy. We propose AttentionDrop, a unified\nfamily of stochastic regularization techniques that operate directly on the\nself-attention distributions. We introduces three variants: 1. Hard Attention\nMasking: randomly zeroes out top-k attention logits per query to encourage\ndiverse context utilization. 2. Blurred Attention Smoothing: applies a dynamic\nGaussian convolution over attention logits to diffuse overly peaked\ndistributions. 3. Consistency-Regularized AttentionDrop: enforces output\nstability under multiple independent AttentionDrop perturbations via a KL-based\nconsistency loss.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T13:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.12097v1","title":"Activity-Induced Near-Infrared Variability at 29P/Schwassmann-Wachmann\n  1, 2017-2022","summary":"29P/Schwassmann-Wachmann 1 (SW1) is both the first-discovered active Centaur\nand the most outburst-prone comet known. The nature of SW1's many outbursts,\nwhich regularly brighten the comet by five magnitudes or more, and what\nprocesses power them has been of particular interest since SW1's discovery in\nthe 1920s. In this paper, we present and model four epochs of low-resolution\nnear-infrared spectroscopy of SW1 taken with the NASA Infrared Telescope\nFacility and Lowell Discovery Telescope between 2017 and 2022. This dataset\nincludes one large outburst, two periods of low activity (\"quiescence\" or\n\"quiescent activity\"), and one mid-sized outburst a few days after one of the\nquiescent observations. The two quiescent epochs appear similar in both\nspectral slope and modeled grain size distributions, but the two outbursts are\nsignificantly different. We propose that the two can be reconciled if smaller\ndust grains are accelerated more than larger ones, such that observations\ncloser to the onset of an outburst are more sensitive to the finer-grained dust\non the outside of the expanding cloud of material. These outbursts can thus\nappear very rapid but there is still a period in which the dust and gas are\nwell-coupled. We find no strong evidence of water ice absorption in any of our\nspectra, suggesting that the areal abundance of ice-dominated grains is less\nthan one percent. We conclude with a discussion of future modeling and\nmonitoring efforts which might be able to further advance our understanding of\nthis object's complicated activity patterns.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-16T14:00:49Z"}
{"aid":"http://arxiv.org/abs/2504.12110v1","title":"Towards LLM Agents for Earth Observation","summary":"Earth Observation (EO) provides critical planetary data for environmental\nmonitoring, disaster management, climate science, and other scientific domains.\nHere we ask: Are AI systems ready for reliable Earth Observation? We introduce\n\\datasetnamenospace, a benchmark of 140 yes/no questions from NASA Earth\nObservatory articles across 13 topics and 17 satellite sensors. Using Google\nEarth Engine API as a tool, LLM agents can only achieve an accuracy of 33%\nbecause the code fails to run over 58% of the time. We improve the failure rate\nfor open models by fine-tuning synthetic data, allowing much smaller models\n(Llama-3.1-8B) to achieve comparable accuracy to much larger ones (e.g.,\nDeepSeek-R1). Taken together, our findings identify significant challenges to\nbe solved before AI agents can automate earth observation, and suggest paths\nforward. The project page is available at\nhttps://iandrover.github.io/UnivEarth.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T14:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.12111v1","title":"Optimizing the quantum interference between single photons and local\n  oscillator with photon correlations","summary":"The quantum interference between a coherent state and a single photon is an\nimportant tool in continuous variable optical quantum technologies to\ncharacterize and engineer non-Gaussian quantum states. Semiconductor quantum\ndots, which have recently emerged as a key platform for efficient single-photon\ngeneration, could become interesting assets in this context. An essential\nparameter for interfering single photons and classical fields is the mean\nwavepacket overlap between both fields. Here, we report on two homodyne\nphoton-correlation techniques enabling the precise measurement of the overlap\nbetween a single photon generated by a quantum dot-cavity device and pulsed\nlaser light. The different statistics of interfering fields lead to specific\nsignatures of the quantum interference on the photon correlations at the output\nof the interfering beam splitter. We compare the behavior of maximized overlap,\nmeasuring either the Hong-Ou-Mandel visibility between both outputs or the\nphoton bunching at a single output. Through careful tailoring of the laser\nlight in various degrees of freedom, we maximize the overlap to $76\\,\\%$, with\nlimitations primarily due to mismatched spectral and temporal profiles and\nlow-frequency charge noise in the single-photon source.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T14:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.12123v1","title":"The CAM Model: An in vivo Testbed for Molecular Communication Systems","summary":"Molecular communication (MC) research increasingly focuses on biomedical\napplications like health monitoring and drug delivery, demanding testing in\nrealistic living environments. Elevating MC research requires developing\nadvanced in vivo testbeds. We introduce the chorioallantoic membrane (CAM)\nmodel as the first versatile 3D in vivo MC platform. The CAM, a highly\nvascularized membrane in fertilized chicken eggs, is established in\nbioengineering, cancer research, and drug development. Its biological realism,\nreproducibility, and versatility make it ideal for next-generation MC testbeds,\nbridging proof-of-concept systems and practical applications. We\ncomprehensively characterize the CAM model's properties and MC system\nrelevance. Through experimental studies, we investigate fluorescent molecule\ndistribution in the CAM's closed-loop vascular system. We derive an analytical\nmodel using the wrapped normal distribution to describe particle propagation in\ndispersive closed-loop systems dominated by diffusion and flow. Parametric\nmodels are developed to approximate particle dynamics in the CAM, with\nparameters estimated via nonlinear least squares curve fitting. A dataset of 69\nregions from 25 eggs validates our models. We analyze parameter relationships\nand biological plausibility. Finally, we develop a parametric model for\nlong-term particle behavior and liver accumulation in chick embryos.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP","published":"2025-04-16T14:35:53Z"}
{"aid":"http://arxiv.org/abs/2504.12147v1","title":"Quantitative error analysis of back-stripping based models: case study\n  from Po Delta (northern Italy)","summary":"Numerical back-stripping procedure is crucial for understanding the\ngeological mechanisms of basin formation or for reconstructing the\npalaeo-bathymetry in the oceanic regions. However, the importance of errors\nassociated with data acquisition, processing and interpretation is often\nunderestimated. These errors, which can impact the final results, are not part\nof the computational workflow, although they often affect the model parameters\nwith large uncertainties. In this study, we have qualitatively classified and\nquantified all the main errors affecting the workflow of the back-stripping\ntechnique using linear interpolation and combinatorics. We found that the\nerrors influence different model parameters, some of which have an\nequiprobability of occurrence, while others are characterized by an intrinsic\nprobability. We applied the proposed method to the Po Delta in northern Italy,\nhistorically influenced by anthropogenic and natural subsidence. By studying a\n2D geological section characterized by thin Holocene sedimentary successions,\nwe identified 12 sources of error that fall into three basic categories:\ngeometry of the model layers; distribution of lithologies and petrophysical\nproperties; past depositional environments. We then assessed the error ranges\nand their probability of occurrence. The study shows that the errors can vary\nsignificantly from metre- to millimetre-scale, defining the magnitude and\ndistribution of each error source, which is essential for interpreting model\nresults and assessing related uncertainties. It establishes a workflow for\nfuture uncertainty management and aims to enhance open-source tools based on\nthe back-stripping procedure.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-16T14:56:59Z"}
{"aid":"http://arxiv.org/abs/2504.12155v1","title":"On a category of chains of modules whose endomorphism rings have at most\n  $2n$ maximal ideals","summary":"We describe the endomorphism rings in an additive category whose objects are\nright $R$-modules $M$ with a fixed chain of submodules $0=M^{(0)}\\leq\nM^{(1)}\\leq M^{(2)} \\leq \\dots \\leq M^{(n)}=M$ and the behaviour of these\nobjects as far as their direct sums are concerned.","main_category":"math.RA","categories":"math.RA","published":"2025-04-16T15:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.12166v1","title":"Energy Cascades in Driven Granular Liquids : A new Universality Class? I\n  : Model and Symmetries","summary":"This article deals with the existence and scaling of an energy cascade in\nsteady granular liquid flows between the scale at which the system is forced\nand the scale at which it dissipates energy. In particular, we examine the\npossible origins of a breaking of the Kolmogorov Universality class that\napplies to Newtonian liquids under similar conditions. In order to answer these\nquestions, we build a generic field theory of granular liquid flows and,\nthrough a study of its symmetries, show that indeed the Kolmogorov scaling can\nbe broken, although most of the symmetries of the Newtonian flows are\npreserved.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech,physics.flu-dyn","published":"2025-04-16T15:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.12168v1","title":"A simple algorithm for the simple bilevel programming (SBP) problem","summary":"In this article we intend to develop a simple and implementable algorithm for\nminimizing a convex function over the solution set of another convex\noptimization problem. Such a problem is often referred to as a simple bilevel\nprogramming (SBP) problem. One of the key features of our algorithm is that we\nmake no assumption on the diferentiability of the upper level objective, though\nwe will assume that the lower level objective is smooth. Another key feature of\nthe algorithm is that it does not assume that the lower level objective has a\nLipschitz gradient, which is a standard assumption in most of the well-known\nalgorithms for this class of problems. We present the convergence analysis and\nalso some numerical experiments demonstrating the efectiveness of the\nalgorithm.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T15:19:08Z"}
{"aid":"http://arxiv.org/abs/2504.12179v1","title":"Modular matrix invariants under some transpose actions","summary":"Consider the special linear group of degree 2 over an arbitrary finite field,\nacting on the full space of $2 \\times 2$-matrices by transpose. We explicitly\nconstruct a generating set for the corresponding modular matrix invariant ring,\ndemonstrating that this ring is a hypersurface. Using a recent result on\n$a$-invariants of Cohen-Macaulay algebras, we determine the Hilbert series of\nthis invariant ring, and our method avoids seeking the generating relation.\nAdditionally, we prove that the modular matrix invariant ring of the group of\nupper triangular $2 \\times 2$-matrices is also a hypersurface.","main_category":"math.AC","categories":"math.AC","published":"2025-04-16T15:34:50Z"}
{"aid":"http://arxiv.org/abs/2504.12192v1","title":"From Requirements to Architecture: Semi-Automatically Generating\n  Software Architectures","summary":"To support junior and senior architects, I propose developing a new\narchitecture creation method that leverages LLMs' evolving capabilities to\nsupport the architect. This method involves the architect's close collaboration\nwith LLM-fueled tooling over the whole process. The architect is guided through\nDomain Model creation, Use Case specification, architectural decisions, and\narchitecture evaluation. While the architect can take complete control of the\nprocess and the results, and use the tooling as a building set, they can follow\nthe intended process for maximum tooling support. The preliminary results\nsuggest the feasibility of this process and indicate major time savings for the\narchitect.","main_category":"cs.SE","categories":"cs.SE,cs.AI,D.2.2","published":"2025-04-16T15:46:56Z"}
{"aid":"http://arxiv.org/abs/2504.12193v1","title":"Discrete-Time Modeling of Interturn Short Circuits in Interior PMSMs","summary":"This article describes the discrete-time modeling approach for interturn\nshort circuits in interior permanent magnet synchronous motors with\nconcentrated windings that facilitate model-based fault diagnostics and\nmitigation. A continuous-time model incorporating universal series-parallel\nstator winding connection and radial permanent magnet fluxes is developed in\nthe stator variables and transformed into the rotor reference frame, including\nalso the electromagnetic torque. The transformed model undergoes discretization\nusing the matrix exponential-based technique, wherein the electrical angular\nvelocity and angle are considered time-varying parameters. The resulting model\nis subsequently expanded to consider the motor connection resistance via\nperturbation techniques. In the laboratory experiments, we validate the\ndynamical properties of the derived model by comparing its outputs with the\nexperimental data and waveforms generated by the forward Euler-based\ndiscrete-time approximation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-16T15:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.12199v1","title":"Monotonicity formulas for minimal submanifolds involving MÃ¶bius\n  transformations","summary":"For a minimal submanifold of the Euclidean space, we prove monotonicity\nformulas for its (weighted) volume within images of concentric balls under\nM\\\"obius transformations.","main_category":"math.DG","categories":"math.DG","published":"2025-04-16T15:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.12200v1","title":"Global $Î$ polarization in heavy-ion collisions at high baryon\n  density","summary":"Based on the model of three-fluid dynamics (3FD), the global $\\Lambda$\npolarization ($P_\\Lambda$) is calculated in Au+Au collisions at 3\n$\\leq\\sqrt{s_{NN}}\\leq$ 9 GeV, in which high baryon density is achieved.\nVarious contributions to $P_\\Lambda$ are considered: those from the thermal\nvorticity, meson field, thermal shear and spin-Hall effect. Feed-down from\nhigher-lying resonances is also taken into account. The results are compared\nwith available data. Special attention is payed to the collision energies of\n$\\sqrt{s_{NN}}=$ 3, 3.2, 3.5, 3.9, and 4.5 GeV, for which a thorough scan of\nthe energy, rapidity, and centrality dependence of $P_\\Lambda$ is performed.\nThe results for 3 GeV reasonably well reproduce the corresponding STAR data.\nWhile the results at $\\sqrt{s_{NN}}=$ 3.2, 3.5, 3.9, and 4.5 GeV can be\nconsidered as predictions for results of measurements within the STAR\nfixed-target (STAR-FXT) programthat are expected in the nearest future. It is\npredicted that a broad maximum of $P_\\Lambda$ is reached at\n$\\sqrt{s_{NN}}\\approx$ 3--3.9 GeV, exact position of which depends on the\ncentrality and width of the midrapidity range of observation. Impact of the\nmeson-field, thermal-shear and spin-Hall-effect contributions to $P_\\Lambda$ is\nalso studied.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex","published":"2025-04-16T15:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.12205v1","title":"Barrow and Tsallis entropies after the DESI DR2 BAO data","summary":"Modified cosmology based on Barrow entropy arises from the\ngravity-thermodynamics conjecture, in which the standard Bekenstein-Hawking\nentropy is replaced by the Barrow entropy of quantum-gravitational origin,\ncharacterized by the Barrow parameter $\\Delta$. Interestingly, this framework\nexhibits similarities with cosmology based on Tsallis $\\delta$-entropy, which,\nalthough rooted in a non-extensive generalization of Boltzmann-Gibbs\nstatistics, features the same power-law deformation of the holographic scaling\npresent in the Barrow case. We use observational data from Supernova Type Ia\n(SNIa), Cosmic Chronometers (CC), and Baryonic acoustic oscillations (BAO),\nincluding the recently released DESI DR2 data, in order to extract constraints\non such scenarios. As we show, the best-fit value for the Barrow exponent\n$\\Delta$ is found to be negative, while the zero value, which corresponds to\n$\\Lambda$CDM paradigm, is allowed only in the range of $2\\sigma $ for three out\nof four datasets. Additionally, for the case of the SN$_{0}$+OHD+BAO dataset,\nfor the current Hubble function we obtain a value of $H_0= 72.2_{-0.9}^{+0.9}$,\nwhich offers an alleviation for the $H_0$ tension. Finally, by applying\ninformation criteria such as the Akaike Information Criterion and the Bayes\nevidence, we compare the fitting efficiency of the scenario at hand with\n$\\Lambda$CDM cosmology, showing that the latter is slightly favoured.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-16T15:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.12215v1","title":"Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware\n  Post-Processing","summary":"Reliable tumor segmentation in thoracic computed tomography (CT) remains\nchallenging due to boundary ambiguity, class imbalance, and anatomical\nvariability. We propose an uncertainty-guided, coarse-to-fine segmentation\nframework that combines full-volume tumor localization with refined\nregion-of-interest (ROI) segmentation, enhanced by anatomically aware\npost-processing. The first-stage model generates a coarse prediction, followed\nby anatomically informed filtering based on lung overlap, proximity to lung\nsurfaces, and component size. The resulting ROIs are segmented by a\nsecond-stage model trained with uncertainty-aware loss functions to improve\naccuracy and boundary calibration in ambiguous regions. Experiments on private\nand public datasets demonstrate improvements in Dice and Hausdorff scores, with\nfewer false positives and enhanced spatial interpretability. These results\nhighlight the value of combining uncertainty modeling and anatomical priors in\ncascaded segmentation pipelines for robust and clinically meaningful tumor\ndelineation. On the Orlando dataset, our framework improved Swin UNETR Dice\nfrom 0.4690 to 0.6447. Reduction in spurious components was strongly correlated\nwith segmentation gains, underscoring the value of anatomically informed\npost-processing.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-16T16:08:38Z"}
{"aid":"http://arxiv.org/abs/2504.12234v1","title":"MOS: Towards Effective Smart Contract Vulnerability Detection through\n  Mixture-of-Experts Tuning of Large Language Models","summary":"Smart contract vulnerabilities pose significant security risks to blockchain\nsystems, potentially leading to severe financial losses. Existing methods face\nseveral limitations: (1) Program analysis-based approaches rely on predefined\npatterns, lacking flexibility for new vulnerability types; (2) Deep\nlearning-based methods lack explanations; (3) Large language model-based\napproaches suffer from high false positives. We propose MOS, a smart contract\nvulnerability detection framework based on mixture-of-experts tuning\n(MOE-Tuning) of large language models. First, we conduct continual pre-training\non a large-scale smart contract dataset to provide domain-enhanced\ninitialization. Second, we construct a high-quality MOE-Tuning dataset through\na multi-stage pipeline combining LLM generation and expert verification for\nreliable explanations. Third, we design a vulnerability-aware routing mechanism\nthat activates the most relevant expert networks by analyzing code features and\ntheir matching degree with experts. Finally, we extend the feed-forward layers\ninto multiple parallel expert networks, each specializing in specific\nvulnerability patterns. We employ a dual-objective loss function: one for\noptimizing detection and explanation performance, and another for ensuring\nreasonable distribution of vulnerability types to experts through entropy\ncalculation. Experiments show that MOS significantly outperforms existing\nmethods with average improvements of 6.32% in F1 score and 4.80% in accuracy.\nThe vulnerability explanations achieve positive ratings (scores of 3-4 on a\n4-point scale) of 82.96%, 85.21% and 94.58% for correctness, completeness, and\nconciseness through human and LLM evaluation.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T16:33:53Z"}
{"aid":"http://arxiv.org/abs/2504.12237v1","title":"Stereoscopic Cylindrical Screen (SCS) Projection","summary":"We present a technique for Stereoscopic Cylindrical Screen (SCS) Projection\nof a world scene to a 360-degree canvas for viewing with 3D glasses. To\noptimize the rendering pipeline, we render the scene to four cubemaps, before\nsampling relevant cubemaps onto the canvas. For an interactive user experience,\nwe perform stereoscopic view rendering and off-axis projection to anchor the\nimage to the viewer. This technique is being used to project virtual worlds at\nCMU ETC, and is a step in creating immersive viewing experiences.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-16T16:42:13Z"}
{"aid":"http://arxiv.org/abs/2504.12247v1","title":"Exotic Quantum States in Spin-1 Bose-Einstein Condensate with Spin-Orbit\n  Coupling in Concentric Annular Traps","summary":"We explore the exotic quantum states emerging in the ground state (GS) of a\nstrongly-correlated spin-1 Bose-Einstein condensate confined in two-dimensional\nconcentric annular traps with a spin-orbit coupling (SOC). In the\nantiferromagnetic case, the GS density manifests various patterns of\ndistributions, including facial-makeup states, petal states, topological\nfissure states, multiple-half-ring states and property-distinguished vertical\nand horizonal stripe states. We notice a peculiar phenomenon of density-phase\nseparation in the sense that the variations of density and phase tend to be\nindependent. In ferromagnetic case, the GS exhibits a semi-circular or\nhalf-disk status of density embedded with vortices and anti-vortices. The spin\ndistribution can self-arrange into an array of half-skyrmions and we also find\na half-antiskyrmion fence separating vortex-antivortex pairs. Our study\nindicates that one can manipulate the emergence of exotic quantum states via\nthe interplay of the SOC, interaction and potential geometry and the abundant\nstate variations might also provide potential resources for quantum metrology.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,quant-ph","published":"2025-04-16T16:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.12281v1","title":"A Near-Optimal Kernel for a Coloring Problem","summary":"For a fixed integer $q$, the $q$-Coloring problem asks to decide if a given\ngraph has a vertex coloring with $q$ colors such that no two adjacent vertices\nreceive the same color. In a series of papers, it has been shown that for every\n$q \\geq 3$, the $q$-Coloring problem parameterized by the vertex cover number\n$k$ admits a kernel of bit-size $\\widetilde{O}(k^{q-1})$, but admits no kernel\nof bit-size $O(k^{q-1-\\varepsilon})$ for $\\varepsilon >0$ unless $\\mathsf{NP}\n\\subseteq \\mathsf{coNP/poly}$ (Jansen and Kratsch, 2013; Jansen and Pieterse,\n2019). In 2020, Schalken proposed the question of the kernelizability of the\n$q$-Coloring problem parameterized by the number $k$ of vertices whose removal\nresults in a disjoint union of edges and isolated vertices. He proved that for\nevery $q \\geq 3$, the problem admits a kernel of bit-size\n$\\widetilde{O}(k^{2q-2})$, but admits no kernel of bit-size\n$O(k^{2q-3-\\varepsilon})$ for $\\varepsilon >0$ unless $\\mathsf{NP} \\subseteq\n\\mathsf{coNP/poly}$. He further proved that for $q \\in \\{3,4\\}$ the problem\nadmits a near-optimal kernel of bit-size $\\widetilde{O}(k^{2q-3})$ and asked\nwhether such a kernel is achievable for all integers $q \\geq 3$. In this short\npaper, we settle this question in the affirmative.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-16T17:44:33Z"}
{"aid":"http://arxiv.org/abs/2504.12283v1","title":"How Accidental was Inflation?","summary":"Data on the cosmic microwave background (CMB) are discriminating between\ndifferent models of inflation, disfavoring simple monomial potentials whilst\nbeing consistent with models whose predictions resemble those of the\nStarobinsky $R + R^2$ cosmological model. However, this model may suffer from\ntheoretical problems, since it requires a large initial field value,\nthreatening the validity of the effective field theory. This is quantified by\nthe Swampland Distance Conjecture, which predicts the appearance of a tower of\nlight states associated with an effective ultra-violet cutoff. This could be\nlower than the inflation scale for cases with an extended period of inflation,\nleading to an additional problem of initial conditions. No-scale supergravity\nmodels can reproduce the predictions of the Starobinsky model and accommodate\nthe CMB data at the expense of fine-tuning of parameters at the level of\n$10^{-5}$. Here, we propose a solution to this problem based on an explicit\nrealisation of the Starobinsky model in string theory, where this `deformation'\nparameter is calculable and takes a value of order of the one corresponding to\nthe Starobinsky inflaton potential. Within this range, there are parameter\nvalues that accommodate more easily the combination of Planck, ACT and DESI BAO\ndata, while also restricting the range of possible inflaton field values,\nthereby avoiding the swampland problem and predicting that the initial\nconditions for inflation compatible with the CMB data are generic.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-16T17:45:53Z"}
{"aid":"http://arxiv.org/abs/2504.12285v1","title":"BitNet b1.58 2B4T Technical Report","summary":"We introduce BitNet b1.58 2B4T, the first open-source, native 1-bit Large\nLanguage Model (LLM) at the 2-billion parameter scale. Trained on a corpus of 4\ntrillion tokens, the model has been rigorously evaluated across benchmarks\ncovering language understanding, mathematical reasoning, coding proficiency,\nand conversational ability. Our results demonstrate that BitNet b1.58 2B4T\nachieves performance on par with leading open-weight, full-precision LLMs of\nsimilar size, while offering significant advantages in computational\nefficiency, including substantially reduced memory footprint, energy\nconsumption, and decoding latency. To facilitate further research and adoption,\nthe model weights are released via Hugging Face along with open-source\ninference implementations for both GPU and CPU architectures.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-16T17:51:43Z"}
{"aid":"http://arxiv.org/abs/2504.12290v1","title":"Diffeomorphism in Closed String Field Theory","summary":"We explain how the spacetime diffeomorphism in the classical bosonic closed\nstring field theory (SFT) is represented as $L_\\infty$ gauge transformations in\nweakly curved backgrounds. In particular, we demonstrate the explicit map\nbetween covariant spacetime fields and the string fields in the flat-vertex\nframe to the leading few orders in perturbation theory. We further consider a\nBatalin-Vilkovisky system of extended string fields that manifests\ndiffeomorphism invariance and allows for extending certain perturbative SFT\nsolutions to the large field regime.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T17:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.12296v1","title":"Set families: restricted distances via restricted intersections","summary":"Denote by $f_D(n)$ the maximum size of a set family $\\mathcal{F}$ on $[n] =\n\\{1, \\dots, n\\}$ with distance set $D$. That is, $|A \\bigtriangleup B| \\in D$\nholds for every pair of distinct sets $A, B \\in \\mathcal{F}$. Kleitman's\ncelebrated discrete isodiametric inequality states that $f_D(n)$ is maximized\nat Hamming balls of radius $d/2$ when $D = \\{1, \\dots, d\\}$. We study the\ngeneralization where $D$ is a set of arithmetic progression and determine\n$f_D(n)$ asymptotically for all homogeneous $D$. In the special case when $D$\nis an interval, our result confirms a conjecture of Huang, Klurman, and\nPohoata. Moreover, we demonstrate a dichotomy in the growth of $f_D(n)$,\nshowing linear growth in $n$ when $D$ is a non-homogeneous arithmetic\nprogression. Different from previous combinatorial and spectral approaches, we\ndeduce our results by converting the restricted distance problems to restricted\nintersection problems.\n  Our proof ideas can be adapted to prove upper bounds on $t$-distance sets in\nHamming cubes (also known as binary $t$-codes), which has been extensively\nstudied by algebraic combinatorialists community, improving previous bounds\nfrom polynomial methods and optimization approaches.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-16T17:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.12603v1","title":"Mazurkiewicz Sets and Containment of SierpiÅski-Zygmund Functions\n  under Rotations","summary":"A Mazurkiewicz set is a plane subset that intersect every straight line at\nexactly two points, and a Sierpi\\'{n}ski-Zygmund function is a function from\n$\\mathbb{R}$ into $\\mathbb{R}$ that has as little of the standard continuity as\npossible. Building on the recent work of Kharazishvili, we construct a\nMazurkiewicz set that contains a Sierpi\\'{n}ski-Zygmund function in every\ndirection and another one that contains none in any direction. Furthermore, we\nshow that whether a Mazurkiewicz set can be expressed as a union of two\nSierpi\\'{n}ski-Zygmund functions is independent of Zermelo-Fraenkel set theory\nwith the Axiom of Choice (ZFC). Some open problems related to the containment\nof Hamel functions are stated.","main_category":"math.LO","categories":"math.LO","published":"2025-04-17T03:04:18Z"}
{"aid":"http://arxiv.org/abs/2504.12608v1","title":"Code Copycat Conundrum: Demystifying Repetition in LLM-based Code\n  Generation","summary":"Despite recent advances in Large Language Models (LLMs) for code generation,\nthe quality of LLM-generated code still faces significant challenges. One\nsignificant issue is code repetition, which refers to the model's tendency to\ngenerate structurally redundant code, resulting in inefficiencies and reduced\nreadability. To address this, we conduct the first empirical study to\ninvestigate the prevalence and nature of repetition across 19 state-of-the-art\ncode LLMs using three widely-used benchmarks. Our study includes both\nquantitative and qualitative analyses, revealing that repetition is pervasive\nand manifests at various granularities and extents, including character,\nstatement, and block levels. We further summarize a taxonomy of 20 repetition\npatterns. Building on our findings, we propose DeRep, a rule-based technique\ndesigned to detect and mitigate repetition in generated code. We evaluate DeRep\nusing both open-source benchmarks and in an industrial setting. Our results\ndemonstrate that DeRep significantly outperforms baselines in reducing\nrepetition (with an average improvements of 91.3%, 93.5%, and 79.9% in rep-3,\nrep-line, and sim-line metrics) and enhancing code quality (with a Pass@1\nincrease of 208.3% over greedy search). Furthermore, integrating DeRep improves\nthe performance of existing repetition mitigation methods, with Pass@1\nimprovements ranging from 53.7% to 215.7%.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-17T03:13:39Z"}
{"aid":"http://arxiv.org/abs/2504.12628v1","title":"Enhancing NDAR with Delay-Gate-Induced Amplitude Damping","summary":"The Noise-Directed Adaptive Remapping (NDAR) method utilizes amplitude\ndamping noise to enhance the performance of quantum optimization algorithms.\nNDAR alternates between exploration by sampling solutions from the quantum\ncircuit and exploitation by transforming the cost Hamiltonian by changing the\nsigns of its terms. Both exploration and exploitation are important components\nin classical heuristic algorithm design. In this study, we examine how NDAR\nperformance improves by adjusting the balance between these components. We\ncontrol the degree of exploitation by varying the delay time to 0, 50, and\n$100~\\mu\\text{s}$, and investigate exploration strategies using two quantum\ncircuits, QAOA and a random circuit, on IBM's Heron processor. Our results show\nthat increasing delay time in NDAR improves the best objective value found in\neach iteration. In single-layer QAOA and random circuits applied to unweighted\nMax-Cut problem with low edge density, both exploration strategies yield\nsimilar objective value trajectories and provide competitive solution quality\nto simulated annealing for the 80-node problem. Their similar performance\nindicates that, in most cases, increasing amplitude damping noise via\nadditional delay time results in information loss. On the other hand, QAOA\noutperforms random circuits in specific cases, such as positive-negative\nweighted Max-Cut on a fully connected graph. This suggests potential advantages\nof QAOA in more complex settings. We further develop a classical NDAR to better\nunderstand exploration strategies, demonstrating that controlling the Hamming\nweight distribution of sampled bitstrings yields higher quality solutions. This\nsuggests that identifying suitable quantum circuits for exploration could\nenhance NDAR performance.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T04:09:11Z"}
{"aid":"http://arxiv.org/abs/2504.12642v1","title":"Accelerated Collapse Kinetics of Charged Polymers in Good Solvent: Role\n  of Counterion Condensation","summary":"We investigate the collapse kinetics of charged polymers (polyelectrolytes)\ninduced by counterion condensation using coarse-grained molecular dynamics\nsimulations. Under good solvent conditions, polyelectrolytes above the critical\ncharge density ($A > A_c$) exhibit significantly faster collapse dynamics\ncompared to neutral polymers, with dynamic scaling exponents ($\\nu_c \\approx\n0.76-0.84$) distinctly smaller than those observed for neutral polymers ($\\nu_c\n\\approx 1.44$) . This accelerated collapse is driven primarily by three\nmechanisms: (1) local charge neutralization due to counterion condensation,\nwhich facilitates immediate local compaction, (2) screening of long-range\nelectrostatic repulsions, reducing the conformational search space, and (3)\nbridging interactions mediated by multivalent counterions, enhancing efficient\nformation of intra-chain contacts. We systematically explore the effects of\npolymer length, charge density, and counterion valency (monovalent, divalent,\nand trivalent) on collapse dynamics, demonstrating that increased counterion\nvalency significantly lowers the critical charge density required for collapse\nand accelerates the collapse process. Our findings highlight the limitations of\nmodeling charged biopolymers using purely neutral coarse-grained models,\nunderscoring the importance of electrostatic interactions and counterion\ndynamics in determining their kinetic pathways. These insights may aid in\nbetter understanding the folding, organization, and dynamics of inherently\ncharged biomolecules, such as proteins and nucleic acids.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-17T05:03:14Z"}
{"aid":"http://arxiv.org/abs/2504.12646v1","title":"Replication Packages in Software Engineering Secondary Studies: A\n  Systematic Mapping","summary":"Context: Systematic reviews (SRs) summarize state-of-the-art evidence in\nscience, including software engineering (SE). Objective: Our objective is to\nevaluate how SRs report replication packages and to provide a comprehensive\nlist of these packages. Method: We examined 528 secondary studies published\nbetween 2013 and 2023 to analyze the availability and reporting of replication\npackages. Results: Our findings indicate that only 25.4% of the reviewed\nstudies include replication packages. Encouragingly, the situation is gradually\nimproving, as our regression analysis shows significant increase in the\navailability of replication packages over time. However, in 2023, just 50.6% of\nsecondary studies provided a replication package while an even lower\npercentage, 29.1% had used a permanent repository with a digital object\nidentifier (DOI) for storage. Conclusion: To enhance transparency and\nreproducibility in SE research, we advocate for the mandatory publication of\nreplication packages in secondary studies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T05:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.12651v1","title":"Feature selection based on cluster assumption in PU learning","summary":"Feature selection is essential for efficient data mining and sometimes\nencounters the positive-unlabeled (PU) learning scenario, where only a few\npositive labels are available, while most data remains unlabeled. In certain\nreal-world PU learning tasks, data subjected to adequate feature selection\noften form clusters with concentrated positive labels. Conventional feature\nselection methods that treat unlabeled data as negative may fail to capture the\nstatistical characteristics of positive data in such scenarios, leading to\nsuboptimal performance. To address this, we propose a novel feature selection\nmethod based on the cluster assumption in PU learning, called FSCPU. FSCPU\nformulates the feature selection problem as a binary optimization task, with an\nobjective function explicitly designed to incorporate the cluster assumption in\nthe PU learning setting. Experiments on synthetic datasets demonstrate the\neffectiveness of FSCPU across various data conditions. Moreover, comparisons\nwith 10 conventional algorithms on three open datasets show that FSCPU achieves\ncompetitive performance in downstream classification tasks, even when the\ncluster assumption does not strictly hold.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-17T05:22:17Z"}
{"aid":"http://arxiv.org/abs/2504.12665v1","title":"Predicting Driver's Perceived Risk: a Model Based on Semi-Supervised\n  Learning Strategy","summary":"Drivers' perception of risk determines their acceptance, trust, and use of\nthe Automated Driving Systems (ADSs). However, perceived risk is subjective and\ndifficult to evaluate using existing methods. To address this issue, a driver's\nsubjective perceived risk (DSPR) model is proposed, regarding perceived risk as\na dynamically triggered mechanism with anisotropy and attenuation. 20\nparticipants are recruited for a driver-in-the-loop experiment to report their\nreal-time subjective risk ratings (SRRs) when experiencing various automatic\ndriving scenarios. A convolutional neural network and bidirectional long\nshort-term memory network with temporal pattern attention (CNN-Bi-LSTM-TPA) is\nembedded into a semi-supervised learning strategy to predict SRRs, aiming to\nreduce data noise caused by subjective randomness of participants. The results\nillustrate that DSPR achieves the highest prediction accuracy of 87.91% in\npredicting SRRs, compared to three state-of-the-art risk models. The\nsemi-supervised strategy improves accuracy by 20.12%. Besides, CNN-Bi-LSTM-TPA\nnetwork presents the highest accuracy among four different LSTM structures.\nThis study offers an effective method for assessing driver's perceived risk,\nproviding support for the safety enhancement of ADS and driver's trust\nimprovement.","main_category":"cs.LG","categories":"cs.LG,cs.HC","published":"2025-04-17T05:50:33Z"}
{"aid":"http://arxiv.org/abs/2504.12666v1","title":"Sublinear lower bounds of eigenvalues for twisted Laplacian on compact\n  hyperbolic surfaces","summary":"We investigate the asymptotic spectral distribution of the twisted Laplacian\nassociated with a real harmonic 1-form on a compact hyperbolic surface. In\nparticular, we establish a sublinear lower bound on the number of eigenvalues\nin a sufficiently large strip determined by the pressure of the harmonic\n1-form. Furthermore, following an observation by Anantharaman\n\\cite{nalinideviation}, we show that quantum unique ergodicity fails to hold\nfor certain twisted Laplacians.","main_category":"math.SP","categories":"math.SP,math.AP","published":"2025-04-17T05:50:43Z"}
{"aid":"http://arxiv.org/abs/2504.12676v1","title":"Accurate Tracking of Arabidopsis Root Cortex Cell Nuclei in 3D\n  Time-Lapse Microscopy Images Based on Genetic Algorithm","summary":"Arabidopsis is a widely used model plant to gain basic knowledge on plant\nphysiology and development. Live imaging is an important technique to visualize\nand quantify elemental processes in plant development. To uncover novel\ntheories underlying plant growth and cell division, accurate cell tracking on\nlive imaging is of utmost importance. The commonly used cell tracking software,\nTrackMate, adopts tracking-by-detection fashion, which applies Laplacian of\nGaussian (LoG) for blob detection, and Linear Assignment Problem (LAP) tracker\nfor tracking. However, they do not perform sufficiently when cells are densely\narranged. To alleviate the problems mentioned above, we propose an accurate\ntracking method based on Genetic algorithm (GA) using knowledge of Arabidopsis\nroot cellular patterns and spatial relationship among volumes. Our method can\nbe described as a coarse-to-fine method, in which we first conducted relatively\neasy line-level tracking of cell nuclei, then performed complicated nuclear\ntracking based on known linear arrangement of cell files and their spatial\nrelationship between nuclei. Our method has been evaluated on a long-time live\nimaging dataset of Arabidopsis root tips, and with minor manual rectification,\nit accurately tracks nuclei. To the best of our knowledge, this research\nrepresents the first successful attempt to address a long-standing problem in\nthe field of time-lapse microscopy in the root meristem by proposing an\naccurate tracking method for Arabidopsis root nuclei.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:07:17Z"}
{"aid":"http://arxiv.org/abs/2504.12698v1","title":"High-Resolution Multipath Angle Estimation Based on Power-Angle-Delay\n  Profile for Directional Scanning Sounding","summary":"Directional scanning sounding (DSS) has become widely adopted for\nhigh-frequency channel measurements because it effectively compensates for\nsevere path loss. However, the resolution of existing multipath component (MPC)\nangle estimation methods is constrained by the DSS angle sampling interval.\nTherefore, this communication proposes a high-resolution MPC angle estimation\nmethod based on power-angle-delay profile (PADP) for DSS. By exploiting the\nmapping relationship between the power difference of adjacent angles in the\nPADP and MPC offset angle, the resolution of MPC angle estimation is refined,\nsignificantly enhancing the accuracy of MPC angle and amplitude estimation\nwithout increasing measurement complexity. Numerical simulation results\ndemonstrate that the proposed method reduces the mean squared estimation errors\nof angle and amplitude by one order of magnitude compared to traditional\nomnidirectional synthesis methods. Furthermore, the estimation errors approach\nthe Cram\\'er-Rao Lower Bounds (CRLBs) derived for wideband DSS, thereby\nvalidating its superior performance in MPC angle and amplitude estimation.\nFinally, experiments conducted in an indoor scenario at 37.5 GHz validate the\nexcellent performance of the proposed method in practical applications.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T06:56:34Z"}
{"aid":"http://arxiv.org/abs/2504.12722v1","title":"SimUSER: Simulating User Behavior with Large Language Models for\n  Recommender System Evaluation","summary":"Recommender systems play a central role in numerous real-life applications,\nyet evaluating their performance remains a significant challenge due to the gap\nbetween offline metrics and online behaviors. Given the scarcity and limits\n(e.g., privacy issues) of real user data, we introduce SimUSER, an agent\nframework that serves as believable and cost-effective human proxies. SimUSER\nfirst identifies self-consistent personas from historical data, enriching user\nprofiles with unique backgrounds and personalities. Then, central to this\nevaluation are users equipped with persona, memory, perception, and brain\nmodules, engaging in interactions with the recommender system. SimUSER exhibits\ncloser alignment with genuine humans than prior work, both at micro and macro\nlevels. Additionally, we conduct insightful experiments to explore the effects\nof thumbnails on click rates, the exposure effect, and the impact of reviews on\nuser engagement. Finally, we refine recommender system parameters based on\noffline A/B test results, resulting in improved user engagement in the real\nworld.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-17T07:57:23Z"}
{"aid":"http://arxiv.org/abs/2504.12761v1","title":"Temporal Variation of Flare Occurrence Rates via the Spot Evolution on\n  the Sun and Solar-type Stars","summary":"The spot evolution on the Sun and solar-type stars is important for\nunderstanding the nature of consequential flaring activity. This study\nstatistically investigates the variance of flare occurrence rate through the\ntime evolution of spots on the Sun and solar-type stars. We have compiled the\n28-year catalogs of solar flares and their source sunspots obtained from solar\nsurface observations by NOAA and GOES for the Sun. Also, we combined the\ncataloged stellar flares with the time evolution of starspots estimated by\nlight curves obtained by the 4-year Kepler mission for solar-type stars. For\nthe obtained 24124 solar flares and 180 stellar flares, we calculate the flare\noccurrence distribution with respect to $t_\\mathrm{flare}-t_\\mathrm{max}$,\nwhich represents the timing of flare through the spot evolution, where\n$t_\\mathrm{flare}$ is the flare occurrence time, and $t_\\mathrm{max}$ is the\ntime when the source spot takes its maximum area. When normalized by the spot\nlifetime, we found that the flare occurrence distribution for\n$t_\\mathrm{flare}-t_\\mathrm{max}$ shows a similar distribution regardless of\nspot size or flare energy, suggesting that the Sun and the solar-type star\nshare the same physical process in the spot-to-flare activity. On this basis,\nwe propose a formula for the time variation of the flare occurrence rate per\nspot. Also, the correlation between the temporal variation of flare occurrence\nrate and the time evolution of spot area and the lack of difference in flare\noccurrence rate between the emergence and decaying phases provide a milestone\nfor the nature of flare-productive spots.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-17T08:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.12772v1","title":"Artifacts in Photoacoustic Imaging: Origins and Mitigations","summary":"Photoacoustic imaging (PAI) is rapidly moving from the laboratory to the\nclinic, increasing the need to understand confounders which might adversely\naffect patient care. Over the past five years, landmark studies have shown the\nclinical utility of PAI, leading to regulatory approval of several devices. In\nthis article, we describe the various causes of artifacts in PAI, providing\nschematic overviews and practical examples, simulated as well as experimental.\nThis work serves two purposes: (1) educating clinical users to identify\nartifacts, understand their causes, and assess whether their impact, and (2)\nproviding a reference of the limitations of current systems for those working\nto improve them. We explain how two aspects of PAI systems lead to artifacts:\ntheir inability to measure complete data sets, and embedded assumptions during\nreconstruction. We describe the physics underlying PAI, and propose a\nclassification of the artifacts. The paper concludes by discussing possible\nadvanced mitigation strategies.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-17T09:13:27Z"}
{"aid":"http://arxiv.org/abs/2504.12784v1","title":"Accessing quasi-flat $\\textit{f}$-bands to harvest large Berry curvature\n  in NdGaSi","summary":"Bands away from the Fermi energy do not influence the electrical conduction.\nIn typical rare-earth lanthanide compounds, the localized\n4$\\textit{f}$-electrons have a weak effect on the electrical conduction,\nlimiting their influence on the Berry curvature and, hence, the intrinsic\nanomalous Hall effect. However, a comprehensive study of the magnetic,\nthermodynamic, and transport properties of single-crystalline NdGaSi, guided by\nfirst-principles calculations, reveals a ferromagnetic ground state that\ninduces a splitting of quasi-flat 4$\\textit{f}$-electronic bands and positions\nthem near the Fermi energy. The observation of an extraordinarily large\nintrinsic anomalous Hall conductivity of 1165 $\\Omega^{-1}$cm$^{-1}$ implies\nthe direct involvement of localized states in the generation of non-trivial\nband crossings around the Fermi energy. These results are remarkable when\ncompared to ferrimagnetic NdAlSi, which differs only in a non-magnetic atom (a\nchange in the principal quantum number $\\textit{n}$ of the outer $\\textit{p}$\norbital) with the same number of valence electrons and does not exhibit any\nmeasurable anomalous Hall conductivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-17T09:30:23Z"}
{"aid":"http://arxiv.org/abs/2504.12802v1","title":"First insight into transverse-momentum-dependent fragmentation physics\n  at photon-photon colliders","summary":"Future planned lepton colliders, both in the circular and linear\nconfigurations, can effectively work as virtual and quasi-real photon-photon\ncolliders and are expected to stimulate an intense physics program in the next\nfew years. In this paper, we suggest to consider photon-photon scattering as a\nuseful source of information on transverse momentum dependent fragmentation\nfunctions (TMD FFs), complementing semi-inclusive deep inelastic scattering and\n$e^+e^-$ annihilation processes, which provide most of the present\nphenomenological information on TMD FFs. As a first illustrative example, we\nstudy two-hadron azimuthal asymmetries around the jet thrust-axis in the\nprocess $\\ell^+\\ell^-\\to\\gamma^* \\gamma\\to q\\bar q\\to h_1 h_2 + X$, in which in\na circular lepton collider one tagged, deeply-virtual photon scatters off an\nuntagged quasi-real photon, both originating from the initial lepton beams,\nproducing inclusively an almost back-to-back light-hadron pair with large\ntransverse momentum, in the $\\gamma^*\\gamma$ center of mass frame. Similar\nprocesses, in a more complicated environment due to the presence of initial\nhadronic states, can also be studied in ultraperipheral collisions at the LHC\nand the planned future hadron colliders.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T10:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.12811v1","title":"AAA-Gaussians: Anti-Aliased and Artifact-Free 3D Gaussian Rendering","summary":"Although 3D Gaussian Splatting (3DGS) has revolutionized 3D reconstruction,\nit still faces challenges such as aliasing, projection artifacts, and view\ninconsistencies, primarily due to the simplification of treating splats as 2D\nentities. We argue that incorporating full 3D evaluation of Gaussians\nthroughout the 3DGS pipeline can effectively address these issues while\npreserving rasterization efficiency. Specifically, we introduce an adaptive 3D\nsmoothing filter to mitigate aliasing and present a stable view-space bounding\nmethod that eliminates popping artifacts when Gaussians extend beyond the view\nfrustum. Furthermore, we promote tile-based culling to 3D with screen-space\nplanes, accelerating rendering and reducing sorting costs for hierarchical\nrasterization. Our method achieves state-of-the-art quality on in-distribution\nevaluation sets and significantly outperforms other approaches for\nout-of-distribution views. Our qualitative evaluations further demonstrate the\neffective removal of aliasing, distortions, and popping artifacts, ensuring\nreal-time, artifact-free rendering.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T10:16:47Z"}
{"aid":"http://arxiv.org/abs/2504.12834v1","title":"Hunting for newborn magnetars: a multi-messenger approach","summary":"We carry out a numerical calculation of magnetar-powered shock break-outs\n(SBOs) and supernova (SN) light-curves. In particular, we investigate the\nimpact of gravitational wave (GW) emission by the magnetar central engine on\nits electromagnetic (EM) counterparts in the ULTRASAT band. Our results show\nthat GW emission by the magnetar has only a minor effect on the SBO\nlight-curve. However, we find that SN light-curves can carry a direct signature\nof GW emission, which becomes more evident at late times (> 20-30 days).~Our\nresults demonstrate that future ULTRASAT observations will provide crucial\ninsights into the magnetar formation process, and unique information for direct\nsearches of long-transient signals with current and future generation GW\ndetectors. In particular, we estimate a rate of multi-messenger (UV+GW)\ndetections of newly formed magnetars $>$ 1 every two years with ULTRASAT and\nthe Einstein Telescope.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-17T10:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.12849v1","title":"FedX: Adaptive Model Decomposition and Quantization for IoT Federated\n  Learning","summary":"Federated Learning (FL) allows collaborative training among multiple devices\nwithout data sharing, thus enabling privacy-sensitive applications on mobile or\nInternet of Things (IoT) devices, such as mobile health and asset tracking.\nHowever, designing an FL system with good model utility that works with low\ncomputation/communication overhead on heterogeneous, resource-constrained\nmobile/IoT devices is challenging. To address this problem, this paper proposes\nFedX, a novel adaptive model decomposition and quantization FL system for IoT.\nTo balance utility with resource constraints on IoT devices, FedX decomposes a\nglobal FL model into different sub-networks with adaptive numbers of quantized\nbits for different devices. The key idea is that a device with fewer resources\nreceives a smaller sub-network for lower overhead but utilizes a larger number\nof quantized bits for higher model utility, and vice versa. The quantization\noperations in FedX are done at the server to reduce the computational load on\ndevices. FedX iteratively minimizes the losses in the devices' local data and\nin the server's public data using quantized sub-networks under a regularization\nterm, and thus it maximizes the benefits of combining FL with model\nquantization through knowledge sharing among the server and devices in a\ncost-effective training process. Extensive experiments show that FedX\nsignificantly improves quantization times by up to 8.43X, on-device computation\ntime by 1.5X, and total end-to-end training time by 1.36X, compared with\nbaseline FL systems. We guarantee the global model convergence theoretically\nand validate local model convergence empirically, highlighting FedX's\noptimization efficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T11:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.12852v1","title":"Why $w \\ne -1$? Anthropic Selection in a $Î$ + Axion Dark Energy\n  Model","summary":"We study a dark energy model composed of a bare negative cosmological\nconstant and a single ultra-light axion, motivated by the string axiverse.\nAssuming that intelligent observers can exist and observe an accelerating\nuniverse, we derive nontrivial constraints on both the axion mass and the bare\ncosmological constant. The axion mass is bounded from above to avoid\nfine-tuning of the initial misalignment angle near the hilltop, and from below\nbecause extremely light axions would require the bare cosmological constant to\nbe unnaturally close to zero to achieve accelerated expansion. As a result, the\nanthropically allowed axion mass range typically lies around $m =\n\\mathcal{O}(10)\\, H_0$ for a decay constant close to the Planck scale, where\n$H_0$ is the observed value of the Hubble constant. In this framework, the dark\nenergy equation of state parameter $w_0$ generically deviates from $-1$ by\n$\\mathcal{O}(0.1)$, providing a natural explanation for why $w \\ne -1$ may be\nexpected. This outcome is intriguingly consistent with recent DESI hints of\ntime-varying dark energy, and offers a compelling anthropic explanation within\nthe $\\Lambda$ + axion framework.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-17T11:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.12854v1","title":"Versatile, Robust, and Explosive Locomotion with Rigid and Articulated\n  Compliant Quadrupeds","summary":"Achieving versatile and explosive motion with robustness against dynamic\nuncertainties is a challenging task. Introducing parallel compliance in\nquadrupedal design is deemed to enhance locomotion performance, which, however,\nmakes the control task even harder. This work aims to address this challenge by\nproposing a general template model and establishing an efficient motion\nplanning and control pipeline. To start, we propose a reduced-order template\nmodel-the dual-legged actuated spring-loaded inverted pendulum with trunk\nrotation-which explicitly models parallel compliance by decoupling spring\neffects from active motor actuation. With this template model, versatile\nacrobatic motions, such as pronking, froggy jumping, and hop-turn, are\ngenerated by a dual-layer trajectory optimization, where the singularity-free\nbody rotation representation is taken into consideration. Integrated with a\nlinear singularity-free tracking controller, enhanced quadrupedal locomotion is\nachieved. Comparisons with the existing template model reveal the improved\naccuracy and generalization of our model. Hardware experiments with a rigid\nquadruped and a newly designed compliant quadruped demonstrate that i) the\ntemplate model enables generating versatile dynamic motion; ii) parallel\nelasticity enhances explosive motion. For example, the maximal pronking\ndistance, hop-turn yaw angle, and froggy jumping distance increase at least by\n25%, 15% and 25%, respectively; iii) parallel elasticity improves the\nrobustness against dynamic uncertainties, including modelling errors and\nexternal disturbances. For example, the allowable support surface height\nvariation increases by 100% for robust froggy jumping.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T11:20:29Z"}
{"aid":"http://arxiv.org/abs/2504.12858v1","title":"A particle-based approach for the prediction of grain microstructures in\n  solidification processes","summary":"Grain microstructures are crucial to the mechanical properties, performance,\nand often lifetime of metallic components. Hence, the prediction of grain\nmicrostructures emerging from solidification processes at relevant macroscopic\nscale is essential to the design or optimization of new alloys and processing\nconditions. Yet, despite the broad range of multi-scale models proposed so far,\nall of them suffer from computational limitations, such that advances from\ncomputational and algorithm perspectives remain needed. Here, we present a\nnovel approach for tracking crystallographic solidification grain envelopes\ncapable of predicting competitive growth scenarios and columnar-to-equiaxed\ntransitions for stationary grains. The model relies on classical assumptions\nand equations in use in several broadly used and thoroughly validated\napproaches (e.g. cellular automata). Yet, our approach defines the grain\nenvelope using Lagrangian particles and tracks their evolution using an\nalgorithm and an implementation relying on scalable libraries and using modern\nCPU/GPU architectures. The model is used to simulate several benchmarks of\nincreasing complexity, and the results are compared to analytical,\nexperimental, and numerical results from literature for the purpose of model\nvalidation. To highlight the applicability to real-world processes and the\npossibility of coupling the model with existing physics-based simulation tools,\nthe model is also (one-way) coupled with a multiphysics\nlaser-material-interaction model to simulate competitive grain growth during\nlaser beam welding of steel.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T11:34:08Z"}
{"aid":"http://arxiv.org/abs/2504.12861v1","title":"Hardware Implementation of Tunable Fractional-Order Capacitors by\n  Morphogenesis of Conducting Polymer Dendrites","summary":"Conventional electronics is founded on a paradigm where shaping perfect\nelectrical elements is done at the fabrication plant, so as to make devices and\nsystems identical, \"eternally immutable\". In nature, morphogenic evolutions are\nobserved in most living organisms and exploit topological plasticity as a\nlow-resource mechanism for in operando manufacturing and computation. Often\nfractal, the resulting topologies feature inherent disorder: a property which\nis never exploited in conventional electronics manufacturing, while necessary\nfor data generation and security in software. In this study, we present how\nsuch properties can be exploited to implement long-term and evolvable synaptic\nplasticity in an electronic hardware. The rich topology of conducting polymer\ndendrites (CPDs) is exploited to program the non-ideality of their\nelectrochemical capacitances containing constant-phase-elements. Their\nevolution through structural changes alters the characteristic time constants\nfor them to charge and discharge with the applied voltage stimuli. Under a\ntrain of voltage spikes, the evolvable current relaxation of the\nelectrochemical systems promotes short-term plasticity with timescales ranging\nfrom milliseconds to seconds. This large window depends on the temporality of\nthe voltage pulses used for reading, but also on the structure of a pair of\nCPDs on two electrodes, grown by voltage pulses. This study demonstrates how\nrelevant physically transient and non-ideal electrochemical components can be\nexploited for unconventional electronics, with the aim to mimic a universal\nproperty of living organisms which could barely be replicated in a silicon\nmonocrystal.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-17T11:38:43Z"}
{"aid":"http://arxiv.org/abs/2504.12862v1","title":"A Holomorphic perspective of Strict Deformation Quantization","summary":"We provide and discuss complex analytic methods for overcoming the formal\ncharacter of formal deformation quantization. This is a necessity for returning\nto physically meaningful statements, and accounts for the fact that the formal\nparameter $\\hbar$ carries the interpretation of Planck's constant. As formal\nstar products are given by a formal power series, this naturally leads into the\nrealm of holomorphic functions and analytic continuation, both in finite and\ninfinite dimensions. We propose a general notion of strict deformation\nquantization and investigate how one can use established results from complex\nanalysis to think about the resulting objects. Within the main body of the\ntext, the outlined program is then put into practice for strict deformation\nquantizations of constant Poisson structures on locally convex vector spaces\nand the strict deformation quantization of canonical mechanics on the cotangent\nbundle of a Lie group. Numerous auxiliary results, many of which are well-known\nyet remarkable in their own right, are provided throughout.","main_category":"math.CV","categories":"math.CV,math-ph,math.MP,math.QA","published":"2025-04-17T11:40:43Z"}
{"aid":"http://arxiv.org/abs/2504.12870v1","title":"CST-former: Multidimensional Attention-based Transformer for Sound Event\n  Localization and Detection in Real Scenes","summary":"Sound event localization and detection (SELD) is a task for the\nclassification of sound events and the identification of direction of arrival\n(DoA) utilizing multichannel acoustic signals. For effective classification and\nlocalization, a channel-spectro-temporal transformer (CST-former) was\nsuggested. CST-former employs multidimensional attention mechanisms across the\nspatial, spectral, and temporal domains to enlarge the model's capacity to\nlearn the domain information essential for event detection and DoA estimation\nover time. In this work, we present an enhanced version of CST-former with\nmultiscale unfolded local embedding (MSULE) developed to capture and aggregate\ndomain information over multiple time-frequency scales. Also, we propose\nfinetuning and post-processing techniques beneficial for conducting the SELD\ntask over limited training datasets. In-depth ablation studies of the proposed\narchitecture and detailed analysis on the proposed modules are carried out to\nvalidate the efficacy of multidimensional attentions on the SELD task.\nEmpirical validation through experimentation on STARSS22 and STARSS23 datasets\ndemonstrates the remarkable performance of CST-former and post-processing\ntechniques without using external data.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-17T11:56:13Z"}
{"aid":"http://arxiv.org/abs/2504.12876v1","title":"A two-component dark matter model with $Z_2 \\times Z_4$ symmetry","summary":"We consider a two-component dark matter model with $Z_2 \\times Z_4$ symmetry,\nwhere a singlet scalar $S$ and a Majorana fermion $\\chi$ are introduced as dark\nmatter candidates. We also introduce another singlet scalar $S_0$ with a\nnon-zero vacuum expectation value to the SM so that the fermion dark matter can\nobtain mass after spontaneous symmetry breaking. We have a new Higgs boson in\nthe model and in the case of the decoupling limit, the fermion dark matter\nproduction is only determined by $S$ and the new Higgs boson. The mass\nhierarchy of these new particles can make a difference in the reaction rate of\ndark matter annihilation processes, contributing to different viable parameter\nspaces for different mass orderings. We randomly scanned the parameter space\nwith six various cases under relic density constraint and found that when\n$\\chi$ is the lightest among the dark sector, $\\chi$ production is generated\nvia the so-called forbidden channels. Moreover, we consider the combined limits\narising from Higgs invisible decay, dark matter relic density and direct\ndetection constraints. Within the chosen parameter space, direct detection\nresults put the most stringent constraint, and we have a more flexible value\nfor the scalar dark matter mass when the mass of $\\chi$ is not smaller than the\nnew Higgs boson mass.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T12:04:13Z"}
{"aid":"http://arxiv.org/abs/2504.12893v1","title":"Hardness of classically sampling quantum chemistry circuits","summary":"Significant advances have been made in the study of quantum advantage both in\ntheory and experiment, although these have mostly been limited to artificial\nsetups. In this work, we extend the scope to address quantum advantage in tasks\nrelevant to chemistry and physics. Specifically, we consider the unitary\ncluster Jastrow (UCJ) ansatz-a variant of the unitary coupled cluster ansatz,\nwhich is widely used to solve the electronic structure problem on quantum\ncomputers-to show that sampling from the output distributions of quantum\ncircuits implementing the UCJ ansatz is likely to be classically hard. More\nspecifically, we show that there exist UCJ circuits for which classical\nsimulation of sampling cannot be performed in polynomial time, under a\nreasonable complexity-theoretical assumption that the polynomial hierarchy does\nnot collapse. Our main contribution is to show that a class of UCJ circuits can\nbe used to perform arbitrary instantaneous quantum polynomial-time (IQP)\ncomputations, which are already known to be classically hard to simulate under\nthe same complexity assumption. As a side result, we also show that UCJ\nequipped with post-selection can generate the class post-BQP. Our\ndemonstration, worst-case nonsimulatability of UCJ, would potentially imply\nquantum advantage in quantum algorithms for chemistry and physics using unitary\ncoupled cluster type ansatzes, such as the variational quantum eigensolver and\nquantum-selected configuration interaction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T12:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.12895v1","title":"Optimum Contribution Selection for Honeybees","summary":"In 1997, T. H. E. Meuwissen published a groundbreaking article titled\n'Maximizing the response of selection with a predefined rate of inbreeding', in\nwhich he provided an optimized solution for the trade-off between genetic\nresponse and inbreeding avoidance in animal breeding. Evidently, this issue is\nhighly relevant for the honeybee with its small breeding population sizes.\nHowever, the genetic peculiarities of bees have thus far prevented an\napplication of the theory to this species. The present manuscript intends to\nfill this desideratum. It develops the necessary bee-specific theory and\nintroduces a small R script that implements Optimum Contribution Selection\n(OCS) for honeybees. While researching for this manuscript, we found it rather\ncumbersome that even though Meuwissen's theory is 28 years old and has sparked\nresearch in many new directions, to our knowledge, there is still no\ncomprehensive textbook on the topic. Instead, all relevant information had to\nbe extracted from several articles, leading to a steep learning curve. We\nanticipate that many honeybee breeding scientists with a putative interest in\nOCS for honeybees have little to no experience with classical OCS. Thus, we\ndecided to embed our new derivations into a general introduction to OCS that\nthen specializes more and more to the honeybee case. The result are these 121\npages, of which we hope that at least the first sections can also be of use for\nbreeding theorists concerned with other species than honeybees.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-17T12:37:58Z"}
{"aid":"http://arxiv.org/abs/2504.12904v1","title":"Complexity of del Pezzo surfaces with du Val singularities","summary":"We compute the complexity of del Pezzo surfaces with du Val singularities.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T12:50:59Z"}
{"aid":"http://arxiv.org/abs/2504.12905v1","title":"Second-order Optimization of Gaussian Splats with Importance Sampling","summary":"3D Gaussian Splatting (3DGS) is widely used for novel view synthesis due to\nits high rendering quality and fast inference time. However, 3DGS predominantly\nrelies on first-order optimizers such as Adam, which leads to long training\ntimes. To address this limitation, we propose a novel second-order optimization\nstrategy based on Levenberg-Marquardt (LM) and Conjugate Gradient (CG), which\nwe specifically tailor towards Gaussian Splatting. Our key insight is that the\nJacobian in 3DGS exhibits significant sparsity since each Gaussian affects only\na limited number of pixels. We exploit this sparsity by proposing a matrix-free\nand GPU-parallelized LM optimization. To further improve its efficiency, we\npropose sampling strategies for both the camera views and loss function and,\nconsequently, the normal equation, significantly reducing the computational\ncomplexity. In addition, we increase the convergence rate of the second-order\napproximation by introducing an effective heuristic to determine the learning\nrate that avoids the expensive computation cost of line search methods. As a\nresult, our method achieves a $3\\times$ speedup over standard LM and\noutperforms Adam by $~6\\times$ when the Gaussian count is low while remaining\ncompetitive for moderate counts. Project Page:\nhttps://vcai.mpi-inf.mpg.de/projects/LM-IS","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T12:52:08Z"}
{"aid":"http://arxiv.org/abs/2504.12906v1","title":"Properties and applications of $\\rm{Ar-H_2}$ atmospheric pressure plasma\n  jets","summary":"Whether for materials processing or medical applications, the use of\natmospheric pressure plasma jets (APPJs) has emerged as a relevant alternative\nto conventional methods. Within the APPJs research field, the search for\ninnovation aims not only to solve existing problems, but also to explore novel\noptions for generating plasma jets and find new possible applications. In this\nwork, the properties of $\\rm{Ar-H_2}$ APPJs generated using two plasma sources,\nwhich differ basically in the generated voltage frequency, amplitude and\nwaveform, were studied through electrical, thermal and optical\ncharacterization. Discharge and plasma parameters were analyzed as a function\nof the $\\rm{H_2}$ content in the gas mixture, with this parameter varying from\n$0\\%$ to $3.5\\%$. In all cases, the discharge power, electron density as well\nas the rotational, vibrational and gas temperatures presented a trend of\ngrowing when the proportion of $\\rm{H_2}$ in the gas composition was increased.\nOptical emission spectroscopy revealed that the same reactive species were\nproduced for both plasma sources, except for nitric oxide (NO), which was\nobserved only for the one operated at higher frequency (PS #1). Applications on\npolymer (polypropylene, PP) and water treatment were performed using PS #1\nwithout $\\rm{H_2}$ and with $3.5\\%$ of $\\rm{H_2}$ in the gas mixture. NH\nfunctional groups were detected on the PP surface in the presence of $\\rm{H_2}$\nin the gas composition. This indicates a possible way to increase the nitrogen\ncontent on polymer surfaces. The results of water treatment revealed that\nammonia ($\\rm{NH_3}$) is also produced when there is $\\rm{H_2}$ in the working\ngas. This opens an alternative for the use of plasma treated water in\nagriculture.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-17T12:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.12913v1","title":"MAIN: Mutual Alignment Is Necessary for instruction tuning","summary":"Instruction tuning has enabled large language models (LLMs) to achieve\nremarkable performance, but its success heavily depends on the availability of\nlarge-scale, high-quality instruction-response pairs. However, current methods\nfor scaling up data generation often overlook a crucial aspect: the alignment\nbetween instructions and responses. We hypothesize that high-quality\ninstruction-response pairs are not defined by the individual quality of each\ncomponent, but by the extent of their alignment with each other. To address\nthis, we propose a Mutual Alignment Framework (MAIN) that ensures coherence\nbetween the instruction and response through mutual constraints. Experiments\ndemonstrate that models such as LLaMA and Mistral, fine-tuned within this\nframework, outperform traditional methods across multiple benchmarks. This\napproach underscores the critical role of instruction-response alignment in\nenabling scalable and high-quality instruction tuning for LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T13:02:44Z"}
{"aid":"http://arxiv.org/abs/2504.12917v1","title":"Arrayed waveguide gratings in lithium tantalate integrated photonics","summary":"Arrayed Waveguide Gratings (AWGs) are widely used photonic components for\nsplitting and combining different wavelengths of light. They play a key role in\nwavelength division multiplexing (WDM) systems by enabling efficient routing of\nmultiple data channels over a single optical fiber and as a building block for\nvarious optical signal processing, computing, imaging, and spectroscopic\napplications. Recently, there has been growing interest in integrating AWGs in\nferroelectric material platforms, as the platform simultaneously provide\nefficient electro-optic modulation capability and thus hold the promise for\nfully integrated WDM transmitters. To date, several demonstrations have been\nmade in the X-cut thin-film lithium niobate ($\\mathrm{LiNbO}_3$) platform, yet,\nthe large anisotropy of $\\mathrm{LiNbO}_3$ complicates the design and degrades\nthe performance of the AWGs. To address this limitation, we use the recently\ndeveloped photonic integrated circuits (PICs) based on thin-film lithium\ntantalate ($\\mathrm{LiTaO}_3$), a material with a similar Pockels coefficient\nas $\\mathrm{LiNbO}_3$ but significantly reduced optical anisotropy, as an\nalternative viable platform. In this work, we manufacture $\\mathrm{LiTaO}_3$\nAWGs using deep ultraviolet lithography on a wafer-scale. The fabricated AWGs\nfeature a channel spacing of 100 GHz, an insertion loss of < 4 dB and crosstalk\nof < -14 dB. In addition, we demonstrate a cyclic AWG, as well as a\nmultiplexing and demultiplexing AWG pair for the first time on\n$\\mathrm{LiTaO}_3$ platform. The wafer-scale fabrication of these AWGs not only\nensures uniformity and reproducibility, but also paves the way for realizing\nvolume-manufactured integrated WDM transmitters in ferroelectric photonic\nintegrated platforms.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-17T13:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.12918v1","title":"Sliced-Wasserstein Distance-based Data Selection","summary":"We propose a new unsupervised anomaly detection method based on the\nsliced-Wasserstein distance for training data selection in machine learning\napproaches. Our filtering technique is interesting for decision-making\npipelines deploying machine learning models in critical sectors, e.g., power\nsystems, as it offers a conservative data selection and an optimal transport\ninterpretation. To ensure the scalability of our method, we provide two\nefficient approximations. The first approximation processes reduced-cardinality\nrepresentations of the datasets concurrently. The second makes use of a\ncomputationally light Euclidian distance approximation. Additionally, we open\nthe first dataset showcasing localized critical peak rebate demand response in\na northern climate. We present the filtering patterns of our method on\nsynthetic datasets and numerically benchmark our method for training data\nselection. Finally, we employ our method as part of a first forecasting\nbenchmark for our open-source dataset.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T13:07:26Z"}
{"aid":"http://arxiv.org/abs/2504.12921v1","title":"IdentiARAT: Toward Automated Identification of Individual ARAT Items\n  from Wearable Sensors","summary":"This study explores the potential of using wrist-worn inertial sensors to\nautomate the labeling of ARAT (Action Research Arm Test) items. While the ARAT\nis commonly used to assess upper limb motor function, its limitations include\nsubjectivity and time consumption of clinical staff. By using IMU (Inertial\nMeasurement Unit) sensors and MiniROCKET as a time series classification\ntechnique, this investigation aims to classify ARAT items based on sensor\nrecordings. We test common preprocessing strategies to efficiently leverage\nincluded information in the data. Afterward, we use the best preprocessing to\nimprove the classification. The dataset includes recordings of 45 participants\nperforming various ARAT items. Results show that MiniROCKET offers a fast and\nreliable approach for classifying ARAT domains, although challenges remain in\ndistinguishing between individual resembling items. Future work may involve\nimproving classification through more advanced machine-learning models and data\nenhancements.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T13:11:13Z"}
{"aid":"http://arxiv.org/abs/2504.12922v1","title":"On the asymptotic behaviour of stochastic processes, with applications\n  to supermartingale convergence, Dvoretzky's approximation theorem, and\n  stochastic quasi-FejÃ©r monotonicity","summary":"We prove a novel and general result on the asymptotic behavior of stochastic\nprocesses which conform to a certain relaxed supermartingale condition. Our\nresult provides quantitative information in the form of an explicit and\neffective construction of a rate of convergence for this process, both in mean\nand almost surely, that is moreover highly uniform in the sense that it only\ndepends on very few data of the surrounding objects involved in the iteration.\nWe then apply this result to derive new quantitative versions of well-known\nconcepts and theorems from stochastic approximation, in particular providing\neffective rates for a variant of the Robbins-Siegmund theorem, Dvoretzky's\nconvergence theorem, as well as the convergence of stochastic quasi-Fej\\'er\nmonotone sequences, the latter of which formulated in a novel and highly\ngeneral metric context. We utilize the classic and widely studied Robbins-Monro\nprocedure as a template to evaluate our quantitative results and their\napplicability in greater detail. We conclude by illustrating the breadth of\npotential further applications with a brief discussion on a variety of other\nwell-known iterative procedures from stochastic approximation, covering a range\nof different applied scenarios to which our methods can be immediately applied.\nThroughout, we isolate and discuss special cases of our results which even\nallow for the construction of fast, and in particular linear, rates.","main_category":"math.OC","categories":"math.OC,cs.LG,math.LO,math.PR","published":"2025-04-17T13:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.12939v1","title":"Disentangling Polysemantic Channels in Convolutional Neural Networks","summary":"Mechanistic interpretability is concerned with analyzing individual\ncomponents in a (convolutional) neural network (CNN) and how they form larger\ncircuits representing decision mechanisms. These investigations are challenging\nsince CNNs frequently learn polysemantic channels that encode distinct\nconcepts, making them hard to interpret. To address this, we propose an\nalgorithm to disentangle a specific kind of polysemantic channel into multiple\nchannels, each responding to a single concept. Our approach restructures\nweights in a CNN, utilizing that different concepts within the same channel\nexhibit distinct activation patterns in the previous layer. By disentangling\nthese polysemantic features, we enhance the interpretability of CNNs,\nultimately improving explanatory techniques such as feature visualizations.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-17T13:37:47Z"}
{"aid":"http://arxiv.org/abs/2504.12946v1","title":"Prospects for Detecting Signs of Life on Exoplanets in the JWST Era","summary":"The search for signs of life in the Universe has entered a new phase with the\nadvent of the James Webb Space Telescope (JWST). Detecting biosignature gases\nvia exoplanet atmosphere transmission spectroscopy is in principle within\nJWST's reach. We reflect on JWST's early results in the context of the\npotential search for biological activity on exoplanets. The results confront us\nwith a complex reality. Established inverse methods to interpret observed\nspectra-already known to be highly averaged representations of intricate 3D\natmospheric processes-can lead to disparate interpretations even with JWST's\nquality of data. Characterizing rocky or sub-Neptune-size exoplanets with JWST\nis an intricate task, and moves us away from the notion of finding a definitive\n\"silver bullet\" biosignature gas. Indeed, JWST results necessitate us to allow\n\"parallel interpretations\" that will perhaps not be resolved until the next\ngeneration of observatories. Nonetheless, with a handful of habitable-zone\nplanet atmospheres accessible given the anticipated noise floor, JWST may\ncontinue to contribute to this journey by designating a planet as biosignature\ngas candidate. To do this we will need to sufficiently refine our inverse\nmethods and physical models for confidently quantifying specific gas abundances\nand constraining the atmosphere context. Looking ahead, future telescopes and\ninnovative observational strategies will be essential for the reliable\ndetection of biosignature gases.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-17T13:48:43Z"}
{"aid":"http://arxiv.org/abs/2504.12951v1","title":"Are Retrials All You Need? Enhancing Large Language Model Reasoning\n  Without Verbalized Feedback","summary":"Recent advancements in large language models (LLMs) have catalyzed the\ndevelopment of general-purpose autonomous agents, demonstrating remarkable\nperformance in complex reasoning tasks across various domains. This surge has\nspurred the evolution of a plethora of prompt-based reasoning frameworks. A\nrecent focus has been on iterative reasoning strategies that refine outputs\nthrough self-evaluation and verbalized feedback. However, these strategies\nrequire additional computational complexity to enable models to recognize and\ncorrect their mistakes, leading to a significant increase in their cost. In\nthis work, we introduce the concept of ``retrials without feedback'', an\nembarrassingly simple yet powerful mechanism for enhancing reasoning frameworks\nby allowing LLMs to retry problem-solving attempts upon identifying incorrect\nanswers. Unlike conventional iterative refinement methods, our method does not\nrequire explicit self-reflection or verbalized feedback, simplifying the\nrefinement process. Our findings indicate that simpler retrial-based approaches\noften outperform more sophisticated reasoning frameworks, suggesting that the\nbenefits of complex methods may not always justify their computational costs.\nBy challenging the prevailing assumption that more intricate reasoning\nstrategies inherently lead to better performance, our work offers new insights\ninto how simpler, more efficient approaches can achieve optimal results. So,\nare retrials all you need?","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-17T13:52:48Z"}
{"aid":"http://arxiv.org/abs/2504.12953v1","title":"How to get Rid of SQL, Relational Algebra, the Relational Model, ERM,\n  and ORMs in a Single Paper -- A Thought Experiment","summary":"Without any doubt, the relational paradigm has been a huge success. At the\nsame time, we believe that the time is ripe to rethink how database systems\ncould look like if we designed them from scratch. Would we really end up with\nthe same abstractions and techniques that are prevalent today? This paper\nexplores that space. We discuss the various issues with both the relational\nmodel(RM) and the entity-relationship model (ERM). We provide a unified data\nmodel: the relational map type model (RMTM) which can represent both RM and ERM\nas special cases and overcomes all of their problems. We proceed to identify\nseven rules that an RMTM query language (QL) must fulfill and provide a\nfoundation of a language fulfilling all seven rules. Our QL operates on maps\nwhich may represent tuples, relations, databases or sets of databases. Like\nthat we dramatically expand the existing operational abstractions found in SQL\nand relational algebra (RA) which only operate on relations/tables. In fact, RA\nis just a special case of our much more generic approach. This work has\nfar-reaching consequences: we show a path how to come up with a modern QL that\nsolves (almost if not) all problems of SQL. Our QL is much more expressive than\nSQL and integrates smoothly into existing programming languages (PL). We also\nshow results of an initial experiment showcasing that just by switching to our\ndata model, and without changing the underlying query processing algorithms, we\ncan achieve speed-ups of up to a factor 3. We will conclude that, if we build a\ndatabase system from scratch, we could and should do this without SQL, RA, RM,\nERM, and ORMs.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-17T13:55:41Z"}
{"aid":"http://arxiv.org/abs/2504.12963v1","title":"ALMAGAL IV. Morphological comparison of molecular and thermal dust\n  emission using the histogram of oriented gradients (HOG) method","summary":"The study of molecular line emission is crucial to unveil the kinematics and\nthe physical conditions of gas in star-forming regions. Our aim is to quantify\nthe reliability of using individual molecular transitions to derive physical\nproperties of the bulk of the H2 gas, looking at morphological correlations in\ntheir overall integrated molecular line emission with the cold dust. For this\nstudy we selected transitions of H2CO, CH$_3$OH, DCN, HC$_3$N, CH$_3$CN,\nCH$_3$OCHO, SO, and SiO and compared them with the 1.38 mm dust continuum\nemission at different spatial scales in the ALMAGAL sample, that observed a\ntotal of 1013 targets covering all evolutionary stages of the high-mass\nstar-formation process and different conditions of clump fragmentation. We used\nthe method of the histogram of oriented gradients (HOG) implemented in the tool\nastroHOG to compare the morphology of integrated line emission with maps of the\n1.38 mm dust continuum emission. Moreover, we calculated the Spearman's\ncorrelation coefficient, and compared it with our astroHOG results. Only\nH$_2$CO, CH$_3$OH, and SO show emission on spatial scales comparable with the\ndiffuse continuum emission. However, from the HOG method, the median\ncorrelation of the emission of each of these species with the continuum is only\n$\\sim$24-29%. In comparison with the dense fragments these molecular species\nstill have low values of correlation. On the other hand DCN, HC$_3$N, CH$_3$CN,\nand CH$_3$OCHO show a good correlation with the dense dust fragments, above\n60%. The worst correlation is seen with SiO, both with the extended continuum\nemission and with compact sources. From the comparison of the results of the\nHOG method and the Spearman's correlation coefficient, the HOG method gives\nmuch more reliable results than the intensity-based coefficient in estimating\nthe level of similarity of the emission morphology.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T14:17:28Z"}
{"aid":"http://arxiv.org/abs/2504.12964v1","title":"Lee Yang edge singularities of QCD in association with Roberge-Weiss\n  phase transition and chiral phase transition","summary":"We study the Quantum Chromodynamics (QCD) phase transitions in the complex\nchemical potential plane in the framework of Dyson-Schwinger equation approach,\nin the presence of a constant gluonic background field that represents\nconfining dynamics. We solve the quark gap equation and the background field\nequation self consistently, which allows us to directly explore the confinement\nphase transition and furthermore, evaluate the impact of the back-coupling of\nconfinement on chiral symmetry breaking. Moreover, within such a coupled\nframework towards the complex chemical potential region, we demonstrate the\nemergence of Roberge-Weiss (RW) symmetry and investigate the trajectory of\nLee-Yang edge singularities (LYES). Our analysis reveals that the LYES scaling\nbehavior is similar to our previous findings without the background field\ncondensate. However, a significant difference from our earlier work is that the\ntrajectory of LYES terminates when the imaginary part of the singularity\nbecomes $1/3 \\, \\pi T$. We elaborate that this cut-off behavior is caused by\nthe RW symmetry that is symmetric to the imaginary chemical potential\n$\\mu_i=1/3 \\, \\pi T$.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-th","published":"2025-04-17T14:18:14Z"}
{"aid":"http://arxiv.org/abs/2504.12994v1","title":"Characterization of the $W_{1+\\infty}$-n-algebra and applications","summary":"In this paper, we construct the $W_{1+\\infty}$-n-algebras in the framework of\nthe generalized quantum algebra. We characterize the\n$\\mathcal{R}(p,q)$-multi-variable $W_{1+\\infty}$-algebra and derive its\n$n$-algebra which is the generalized Lie algebra for $n$ even. Furthermore, we\ninvestigate the $\\mathcal{R}(p,q)$-elliptic hermitian matrix model and\ndetermine a toy model for the generalized quantum $W_{\\infty}$ constraints.\nAlso, we deduce particular cases of our results.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-17T15:02:43Z"}
{"aid":"http://arxiv.org/abs/2504.13004v1","title":"Calibrating the SIDM Gravothermal Catastrophe with N-body Simulations","summary":"Self-interacting dark matter (SIDM) theories predict that dark matter halos\nexperience core-collapse in late-stage evolution, a process where the halo's\ninner region rapidly increases in density and decreases in size. This process\ncan be modeled by treating the dark matter as a gravothermal fluid, and solving\nthe fluid equations to predict the density profile evolution. This model is\nincomplete without calibration to N-body simulations, through a constant factor\n$\\beta$ included in the thermal conductivity for the long-mean-free-path limit.\nThe value of $\\beta$ employed in the gravothermal fluid formalism has varied\nbetween studies, with no clear universal value in the literature. In this work,\nwe use the N-body code Arepo to conduct a series of isolated core-collapse\nsimulations across a range of scattering cross-sections, halo concentrations,\nand halo masses to calibrate the heat transfer parameter $\\beta$. We find that\n$\\beta$ is independent of cross-section, halo concentration, and halo mass for\nvelocity independent elastic scattering cross-sections. We present a model for\nan effective $\\beta$ as a function of a dimensionless cross-section, to\ndescribe halo evolution in the long mean free path limit, and show that it\naccurately captures halo evolution as long as the cross section is not too\nlarge. This effective model facilitates comparisons between simulations and the\ngravothermal model, and enables fast predictions of the dark matter density\nprofile at any given time without running N-body simulations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T15:14:35Z"}
{"aid":"http://arxiv.org/abs/2504.13017v1","title":"A characterization of $C^*$-simplicity of countable groups via Poisson\n  boundaries","summary":"We characterize $C^*$-simplicity for countable groups by means of the\nfollowing dichotomy. If a group is $C^*$-simple, then the action on the Poisson\nboundary is essentially free for a generic measure on the group. If a group is\nnot $C^*$-simple, then the action on the Poisson boundary is not essentially\nfree for a generic measure on the group.","main_category":"math.DS","categories":"math.DS,math.OA,math.PR","published":"2025-04-17T15:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.13022v1","title":"CompGS++: Compressed Gaussian Splatting for Static and Dynamic Scene\n  Representation","summary":"Gaussian splatting demonstrates proficiency for 3D scene modeling but suffers\nfrom substantial data volume due to inherent primitive redundancy. To enable\nfuture photorealistic 3D immersive visual communication applications,\nsignificant compression is essential for transmission over the existing\nInternet infrastructure. Hence, we propose Compressed Gaussian Splatting\n(CompGS++), a novel framework that leverages compact Gaussian primitives to\nachieve accurate 3D modeling with substantial size reduction for both static\nand dynamic scenes. Our design is based on the principle of eliminating\nredundancy both between and within primitives. Specifically, we develop a\ncomprehensive prediction paradigm to address inter-primitive redundancy through\nspatial and temporal primitive prediction modules. The spatial primitive\nprediction module establishes predictive relationships for scene primitives and\nenables most primitives to be encoded as compact residuals, substantially\nreducing the spatial redundancy. We further devise a temporal primitive\nprediction module to handle dynamic scenes, which exploits primitive\ncorrelations across timestamps to effectively reduce temporal redundancy.\nMoreover, we devise a rate-constrained optimization module that jointly\nminimizes reconstruction error and rate consumption. This module effectively\neliminates parameter redundancy within primitives and enhances the overall\ncompactness of scene representations. Comprehensive evaluations across multiple\nbenchmark datasets demonstrate that CompGS++ significantly outperforms existing\nmethods, achieving superior compression performance while preserving accurate\nscene modeling. Our implementation will be made publicly available on GitHub to\nfacilitate further research.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T15:33:01Z"}
{"aid":"http://arxiv.org/abs/2504.13034v1","title":"Inference-friendly Graph Compression for Graph Neural Networks","summary":"Graph Neural Networks (GNNs) have demonstrated promising performance in graph\nanalysis. Nevertheless, the inference process of GNNs remains costly, hindering\ntheir applications for large graphs. This paper proposes inference-friendly\ngraph compression (IFGC), a graph compression scheme to accelerate GNNs\ninference. Given a graph $G$ and a GNN $M$, an IFGC computes a small compressed\ngraph $G_c$, to best preserve the inference results of $M$ over $G$, such that\nthe result can be directly inferred by accessing $G_c$ with no or little\ndecompression cost. (1) We characterize IFGC with a class of inference\nequivalence relation. The relation captures the node pairs in $G$ that are not\ndistinguishable for GNN inference. (2) We introduce three practical\nspecifications of IFGC for representative GNNs: structural preserving\ncompression (SPGC), which computes $G_c$ that can be directly processed by GNN\ninference without decompression; ($\\alpha$, $r$)-compression, that allows for a\nconfigurable trade-off between compression ratio and inference quality, and\nanchored compression that preserves inference results for specific nodes of\ninterest. For each scheme, we introduce compression and inference algorithms\nwith guarantees of efficiency and quality of the inferred results. We conduct\nextensive experiments on diverse sets of large-scale graphs, which verifies the\neffectiveness and efficiency of our graph compression approaches.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T15:42:13Z"}
{"aid":"http://arxiv.org/abs/2504.13041v1","title":"QI-MPC: A Hybrid Quantum-Inspired Model Predictive Control for Learning\n  Optimal Policies","summary":"In this paper, we present Quantum-Inspired Model Predictive Control (QIMPC),\nan approach that uses Variational Quantum Circuits (VQCs) to learn control\npolices in MPC problems. The viability of the approach is tested in five\nexperiments: A target-tracking control strategy, energy-efficient building\nclimate control, autonomous vehicular dynamics, the simple pendulum, and the\ncompound pendulum. Three safety guarantees were established for the approach,\nand the experiments gave the motivation for two important theoretical results\nthat, in essence, identify systems for which the approach works best.","main_category":"quant-ph","categories":"quant-ph,math.OC","published":"2025-04-17T15:55:37Z"}
{"aid":"http://arxiv.org/abs/2504.13043v1","title":"Machine Learning Decoding of Circuit-Level Noise for Bivariate Bicycle\n  Codes","summary":"Fault-tolerant quantum computers will depend crucially on the performance of\nthe classical decoding algorithm which takes in the results of measurements and\noutputs corrections to the errors inferred to have occurred. Machine learning\nmodels have shown great promise as decoders for the surface code; however, this\npromise has not yet been substantiated for the more challenging task of\ndecoding quantum low-density parity-check (QLDPC) codes. In this paper, we\npresent a recurrent, transformer-based neural network designed to decode\ncircuit-level noise on Bivariate Bicycle (BB) codes, introduced recently by\nBravyi et al (Nature 627, 778-782, 2024). For the $[[72,12,6]]$ BB code, at a\nphysical error rate of $p=0.1\\%$, our model achieves a logical error rate\nalmost $5$ times lower than belief propagation with ordered statistics decoding\n(BP-OSD). Moreover, while BP-OSD has a wide distribution of runtimes with\nsignificant outliers, our model has a consistent runtime and is an\norder-of-magnitude faster than the worst-case times from a benchmark BP-OSD\nimplementation. On the $[[144,12,12]]$ BB code, our model obtains worse logical\nerror rates but maintains the speed advantage. These results demonstrate that\nmachine learning decoders can out-perform conventional decoders on QLDPC codes,\nin regimes of current interest.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T15:57:16Z"}
{"aid":"http://arxiv.org/abs/2504.13050v1","title":"Radiative properties of a nonsingular black hole: Hawking radiation and\n  gray-body factor","summary":"We study the radiative properties of a spherical and singularity-free\nblack-hole geometry recently proposed in the literature. Contrary to the\nSchwarzschild spacetime, this geometry is geodesically complete and regular,\nand, instead of the singularity, it presents a minimal surface that connects a\ntrapped (black-hole) with an antitrapped (white-hole) region. The geometry is\ncharacterized by two parameters: the Schwarzschild radius and another parameter\nthat measures the area of the minimal surface. This parameter is related to\ncertain corrections expected in the context of loop quantum gravity to the\nclassical general-relativistic dynamics. We explicitly compute the spectrum of\nthe Hawking radiation and the gray-body factor. Since the gravitational\npotential is shallower than in Schwarzschild, the emission spectrum turns out\nbe colder and purer (less gray). From this, we sketch the evaporation history\nof this geometry and conclude that, instead of completely evaporating, it\nnaturally leads to a remnant, which provides a possible resolution of the\ninformation loss issue.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T16:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.13056v1","title":"Adaptive Task Space Non-Singular Terminal Super-Twisting Sliding Mode\n  Control of a 7-DOF Robotic Manipulator","summary":"This paper presents a new task-space Non-singular Terminal Super-Twisting\nSliding Mode (NT-STSM) controller with adaptive gains for robust trajectory\ntracking of a 7-DOF robotic manipulator. The proposed approach addresses the\nchallenges of chattering, unknown disturbances, and rotational motion tracking,\nmaking it suited for high-DOF manipulators in dexterous manipulation tasks. A\nrigorous boundedness proof is provided, offering gain selection guidelines for\npractical implementation. Simulations and hardware experiments with external\ndisturbances demonstrate the proposed controller's robust, accurate tracking\nwith reduced control effort under unknown disturbances compared to other\nNT-STSM and conventional controllers. The results demonstrated that the\nproposed NT-STSM controller mitigates chattering and instability in complex\nmotions, making it a viable solution for dexterous robotic manipulations and\nvarious industrial applications.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-17T16:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.13075v1","title":"An All-Atom Generative Model for Designing Protein Complexes","summary":"Proteins typically exist in complexes, interacting with other proteins or\nbiomolecules to perform their specific biological roles. Research on\nsingle-chain protein modeling has been extensively and deeply explored, with\nadvancements seen in models like the series of ESM and AlphaFold. Despite these\ndevelopments, the study and modeling of multi-chain proteins remain largely\nuncharted, though they are vital for understanding biological functions.\nRecognizing the importance of these interactions, we introduce APM (All-Atom\nProtein Generative Model), a model specifically designed for modeling\nmulti-chain proteins. By integrating atom-level information and leveraging data\non multi-chain proteins, APM is capable of precisely modeling inter-chain\ninteractions and designing protein complexes with binding capabilities from\nscratch. It also performs folding and inverse-folding tasks for multi-chain\nproteins. Moreover, APM demonstrates versatility in downstream applications: it\nachieves enhanced performance through supervised fine-tuning (SFT) while also\nsupporting zero-shot sampling in certain tasks, achieving state-of-the-art\nresults. Code will be released at https://github.com/bytedance/apm.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T16:37:41Z"}
{"aid":"http://arxiv.org/abs/2504.13081v1","title":"Combination and interpretation of differential Higgs boson production\n  cross sections in proton-proton collisions at $\\sqrt{s}$ = 13 TeV","summary":"Precision measurements of Higgs boson differential production cross sections\nare a key tool to probe the properties of the Higgs boson and test the standard\nmodel. New physics can affect both Higgs boson production and decay, leading to\ndeviations from the distributions that are expected in the standard model. In\nthis paper, combined measurements of differential spectra in a fiducial region\nmatching the experimental selections are performed, based on analyses of four\nHiggs boson decay channels ($\\gamma\\gamma$, ZZ$^{(*)}$, WW$^{(*)}$, and\n$\\tau\\tau$) using proton-proton collision data recorded with the CMS detector\nat $\\sqrt{s}$ = 13 TeV, corresponding to an integrated luminosity of 138\nfb$^{-1}$. The differential measurements are extrapolated to the full phase\nspace and combined to provide the differential spectra. A measurement of the\ntotal Higgs boson production cross section is also performed using the\n$\\gamma\\gamma$ and ZZ decay channels, with a result of 53.4$^{+2.9}_{-2.9}$\n(stat)$^{+1.9}_{-1.8}$ (syst) pb, consistent with the standard model prediction\nof 55.6 $\\pm$ 2.5 pb. The fiducial measurements are used to compute limits on\nHiggs boson couplings using the $\\kappa$-framework and the SM effective field\ntheory.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-04-17T16:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.13086v1","title":"Many-body cages: disorder-free glassiness from flat bands in Fock space,\n  and many-body Rabi oscillations","summary":"We identify the many-body counterpart of flat bands, which we call many-body\ncaging, as a general mechanism for non-equilibrium phenomena such as a novel\ntype of glassy eigenspectrum order and many-body Rabi oscillations in the time\ndomain. We focus on constrained systems of great current interest in the\ncontext of Rydberg atoms and synthetic or emergent gauge theories. We find that\ntheir state graphs host motifs which produce flat bands in the many-body\nspectrum at a particular set of energies. Basis states in Fock space exhibit\nEdwards-Anderson type parameters in the absence of quenched disorder, with an\nintricate, possibly fractal, distribution over Fock space which is reflected in\na distinctive structure of a non-vanishing post-quench long-time Loschmidt\necho, an experimentally accessible quantity.In general, phenomena familiar from\nsingle-particle flat bands manifest themselves in characteristic many-body\nincarnations, such as a reentrant `Anderson' delocalisation, offering a rich\nensemble of experimental signatures in the abovementioned quantum simulators.\nThe variety of single-particle flat band types suggests an analogous\ntypology--and concomitant phenomenological richness to be explored--of their\nmany-body counterparts.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.dis-nn,quant-ph","published":"2025-04-17T16:54:38Z"}
{"aid":"http://arxiv.org/abs/2504.13091v1","title":"Perturbed symmetric-product orbifold: first-order mixing and puzzles for\n  integrability","summary":"We study the marginal deformation of the symmetric-product orbifold theory\nSym$_N(T^4)$ which corresponds to introducing a small amount of Ramond-Ramond\nflux into the dual $AdS_3\\times S^3\\times T^4$ background. Already at first\norder in perturbation theory, the dimension of certain single-cycle operators\nis corrected, indicating that wrapping corrections from integrability must come\ninto play earlier than expected. We also discuss a flaw in the original\nderivation of the integrable structure of the perturbed orbifold. Together,\nthese observations suggest that more needs to be done to correctly identify and\nexploit the integrable structure of the perturbed orbifold CFT.","main_category":"hep-th","categories":"hep-th","published":"2025-04-17T16:58:34Z"}
{"aid":"http://arxiv.org/abs/2504.13097v1","title":"Energy Landscape Plummeting in Variational Quantum Eigensolver: Subspace\n  Optimization, Non-iterative Corrections and Generator-informed Initialization\n  for Improved Quantum Efficiency","summary":"Variational Quantum Eigensolver (VQE) faces significant challenges due to\nhardware noise and the presence of barren plateaus and local traps in the\noptimization landscape. To mitigate the detrimental effects of these issues, we\nintroduce a general formalism that optimizes hardware resource utilization and\naccuracy by projecting VQE optimizations on to a reduced-dimensional subspace,\nfollowed by a set of posteriori corrections. Our method partitions the ansatz\ninto a lower dimensional principal subspace and a higher-dimensional auxiliary\nsubspace based on a conjecture of temporal hierarchy present among the\nparameters during optimization. The adiabatic approximation exploits this\nhierarchy, restricting optimization to the lower dimensional principal subspace\nonly. This is followed by an efficient higher dimensional auxiliary space\nreconstruction without the need to perform variational optimization. These\nreconstructed auxiliary parameters are subsequently included in the\ncost-function via a set of auxiliary subspace corrections (ASC) leading to a\n\"plummeting effect\" in the energy landscape toward a more optimal minima\nwithout utilizing any additional quantum hardware resources. Numerical\nsimulations show that, when integrated with any chemistry-inspired ansatz, our\nmethod can provide one to two orders of magnitude better estimation of the\nminima. Additionally, based on the adiabatic approximation, we introduce a\nnovel initialization strategy driven by unitary rotation generators for\naccelerated convergence of gradient-informed dynamic quantum algorithms. Our\nmethod shows heuristic evidences of alleviating the effects of local traps,\nfacilitating convergence toward a more optimal minimum.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T17:07:09Z"}
{"aid":"http://arxiv.org/abs/2504.13100v1","title":"Kato-Kuzumaki's properties for function fields over higher local fields","summary":"Let $k$ be a $d$-local field such that the corresponding $1$-local field\n$k^{(d-1)}$ is a $p$-adic field and $C$ a curve over $k$. Let $K$ be the\nfunction field of $C$. We prove that for each $n,m \\in \\mathbf{N}$, and\nhypersurface $Z$ of $\\mathbf{P}^n_K$ with degree $m$ such that $m^{d+1} \\leq\nn$, the $(d+1)$-th Milnor $\\mathrm{K}$-theory group is generated by the images\nnorms of finite extension $L$ of $K$ such that $Z$ admits an $L$-point. Let $j\n\\in \\{1,\\cdots , d\\}$. When $C$ admits a point in an extension $l/k$ that is\nnot $i$-ramified for every $i \\in \\{1, \\cdots, d-j\\}$ we generalise this result\nto hypersurfaces $Z$ of $\\mathbf{P}_K^n$ with degree $m$ such that $m^{j+1}\n\\leq n$. \\par\n  In order to prove these results we give a description of the Tate-Shafarevich\ngroup $\\Sha^{d+2}(K,\\mathbf{Q}/\\mathbf{Z}(d+1))$ in terms of the combinatorics\nof the special fibre of certain models of the curve $C$.","main_category":"math.AG","categories":"math.AG,math.KT,math.NT","published":"2025-04-17T17:08:54Z"}
{"aid":"http://arxiv.org/abs/2504.13118v1","title":"CEERS: Forging the First Dust Grains in the Universe? A Population of\n  Galaxies with spectroscopically-derived Extremely Low Dust Attenuation\n  (GELDA) at 4.0<z<11.4","summary":"Aims: This paper investigates the coevolution of metals and dust for 173\ngalaxies at $4.0<z<11.4$ observed with JWST/NIRSpec in the CEERS project. We\nfocus on galaxies with extremely low dust attenuation to understand the\nphysical mechanisms at play. Methods: We developed a new version of the\n\\texttt{CIGALE} code that integrates spectroscopic and photometric data. By\nstatistically comparing observations with modeled spectra, we derive physical\nparameters to constrain these mechanisms. Results: Our analysis reveals a\npopulation of 49 extremely low dust attenuation galaxies (GELDAs), consistent\nwith $A_{FUV} = 0.0$ within $2\\sigma$ and $M_{\\star} < 10^9 M_\\odot$. The\nstacked spectrum of GELDAs shows a very blue UV slope $\\beta_{FUV} = -2.451 \\pm\n0.066$ and a Balmer decrement H$\\alpha$/H$\\beta = 2.932 \\pm 0.660$, consistent\nwith no dust and Case B recombination with minimal underlying absorption.\nNotably, GELDAs are more prevalent at $z > 8.8$ (83.3\\%) than at lower\nredshifts (26.3\\%), suggesting they could dominate in the early Universe.\n  Using a far-infrared dust spectrum from the ALPINE sample, we study\n$M_{dust}$ vs. $M_{\\star}$ trends. These exhibit upper and lower sequences\nconnected by transitional galaxies. Our comparison with models indicates a\ncritical transition around $M_{\\star} \\approx 10^{8.5}\\,M_\\odot$, from dust\ndominated by stellar sources (SNe and AGB stars) to dust growth via gas\naccretion. This corresponds to a metallicity of $12 + \\log_{10}(O/H) = 7.60$\n($Z/Z_\\odot \\approx 0.1$), aligning with the point where ISM dust growth\nmatches stellar dust production.\n  The sample has a high gas fraction ($f_{\\mathrm{gas}} \\gtrsim 0.9$), with no\nsignificant gas expulsion, and high surface gas densities. This leads to low\nstar formation efficiencies compared to sub-millimeter galaxies. GELDAs may\nhelp explain the observed excess of bright galaxies at $z \\gtrsim 9$.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T17:37:14Z"}
{"aid":"http://arxiv.org/abs/2504.13120v1","title":"Probing and Inducing Combinational Creativity in Vision-Language Models","summary":"The ability to combine existing concepts into novel ideas stands as a\nfundamental hallmark of human intelligence. Recent advances in Vision-Language\nModels (VLMs) like GPT-4V and DALLE-3 have sparked debate about whether their\noutputs reflect combinational creativity--defined by M. A. Boden (1998) as\nsynthesizing novel ideas through combining existing concepts--or sophisticated\npattern matching of training data. Drawing inspiration from cognitive science,\nwe investigate the combinational creativity of VLMs from the lens of concept\nblending. We propose the Identification-Explanation-Implication (IEI)\nframework, which decomposes creative processes into three levels: identifying\ninput spaces, extracting shared attributes, and deriving novel semantic\nimplications. To validate this framework, we curate CreativeMashup, a\nhigh-quality dataset of 666 artist-generated visual mashups annotated according\nto the IEI framework. Through extensive experiments, we demonstrate that in\ncomprehension tasks, best VLMs have surpassed average human performance while\nfalling short of expert-level understanding; in generation tasks, incorporating\nour IEI framework into the generation pipeline significantly enhances the\ncreative quality of VLMs outputs. Our findings establish both a theoretical\nfoundation for evaluating artificial creativity and practical guidelines for\nimproving creative generation in VLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-17T17:38:18Z"}
{"aid":"http://arxiv.org/abs/2504.13121v1","title":"Fieldoscopy at the Quantum Limit","summary":"We demonstrate a novel concept for measuring time-varying electric field\ntransients of petahertz-scale photons down to a single-photon regime. We\nobserve a clear transition from classical to quantum nature of light that\nagrees with our Monte Carlo model. We reach unprecedented yoctojoule-level\nsensitivity and a dynamic range exceeding 90 decibels. We utilize this\ncapability to measure time-dependent intrapulse light coherence - a regime\ninaccessible to conventional, time-averaged spectroscopy. This opens new\navenues for quantum information, cryptography, and quantum light-matter\ninteractions on sub-cycle time scales with attosecond precision.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-17T17:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.13124v1","title":"Spatial Confidence Regions for Excursion Sets with False Discovery Rate\n  Control","summary":"Identifying areas where the signal is prominent is an important task in image\nanalysis, with particular applications in brain mapping. In this work, we\ndevelop confidence regions for spatial excursion sets above and below a given\nlevel. We achieve this by treating the confidence procedure as a testing\nproblem at the given level, allowing control of the False Discovery Rate (FDR).\nMethods are developed to control the FDR, separately for positive and negative\nexcursions, as well as jointly over both. Furthermore, power is increased by\nincorporating a two-stage adaptive procedure. Simulation results with various\nsignals show that our confidence regions successfully control the FDR under the\nnominal level. We showcase our methods with an application to functional\nmagnetic resonance imaging (fMRI) data from the Human Connectome Project\nillustrating the improvement in statistical power over existing approaches.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-17T17:41:05Z"}
{"aid":"http://arxiv.org/abs/2504.13139v1","title":"Syntactic and Semantic Control of Large Language Models via Sequential\n  Monte Carlo","summary":"A wide range of LM applications require generating text that conforms to\nsyntactic or semantic constraints. Imposing such constraints can be naturally\nframed as probabilistic conditioning, but exact generation from the resulting\ndistribution -- which can differ substantially from the LM's base distribution\n-- is generally intractable. In this work, we develop an architecture for\ncontrolled LM generation based on sequential Monte Carlo (SMC). Our SMC\nframework allows us to flexibly incorporate domain- and problem-specific\nconstraints at inference time, and efficiently reallocate computational\nresources in light of new information during the course of generation. By\ncomparing to a number of alternatives and ablations on four challenging domains\n-- Python code generation for data science, text-to-SQL, goal inference, and\nmolecule synthesis -- we demonstrate that, with little overhead, our approach\nallows small open-source language models to outperform models over 8x larger,\nas well as closed-source, fine-tuned ones. In support of the probabilistic\nperspective, we show that these performance improvements are driven by better\napproximation to the posterior distribution. Our system builds on the framework\nof Lew et al. (2023) and integrates with its language model probabilistic\nprogramming language, giving users a simple, programmable way to apply SMC to a\nbroad variety of controlled generation problems.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-17T17:49:40Z"}
{"aid":"http://arxiv.org/abs/2504.13158v1","title":"Testing for dice control at craps","summary":"Dice control involves \"setting\" the dice and then throwing them in a careful\nway, in the hope of influencing the outcomes and gaining an advantage at craps.\nHow does one test for this ability? To specify the alternative hypothesis, we\nneed a statistical model of dice control. Two have been suggested in the\ngambling literature, namely the Smith-Scott model and the Wong-Shackleford\nmodel. Both models are parameterized by $\\theta\\in[0,1]$, which measures the\nshooter's level of control. We propose and compare four test statistics: (a)\nthe sample proportion of 7s; (b) the sample proportion of pass-line wins; (c)\nthe sample mean of hand-length observations; and (d) the likelihood ratio\nstatistic for a hand-length sample. We want to test $H_0:\\theta = 0$ (no\ncontrol) versus $H_1:\\theta > 0$ (some control). We also want to test\n$H_0:\\theta\\le\\theta_0$ versus $H_1:\\theta>\\theta_0$, where $\\theta_0$ is the\n\"break-even point.\" For the tests considered we estimate the power, either by\nnormal approximation or by simulation.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T17:57:32Z"}
{"aid":"http://arxiv.org/abs/2504.13160v1","title":"Discovery and Dynamics of the Nontransiting Planet Kepler-139f","summary":"Among the ways that an outer giant planet can alter the architecture of an\ninner planetary system is by tilting the orbits of the inner planets and\nreducing their mutual transit probabilities. Here, we report on an example of\nthis phenomenon: we show that the Kepler-139 system contains a nontransiting\nplanet just exterior to three transiting planets, and interior to a giant\nplanet. This newly discovered planet, Kepler-139f, has an orbital period of\n$355 \\pm 2$ days and a mass of $36 \\pm 10 M_\\oplus$ based on transit-timing and\nradial-velocity data. Through dynamical simulations, we show that gravitational\nperturbations on planet f's orbit from the outer giant planet reduce the\nprobability for a randomly located observer to see transits of all four inner\nplanets. Thus, Kepler-139 illustrates the role that outer giant planets can\nplay in the apparent truncation of compact systems of multiple transiting\nplanets.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-17T17:57:59Z"}
{"aid":"http://arxiv.org/abs/2504.13168v1","title":"Restoring Heisenberg scaling in time via autonomous quantum error\n  correction","summary":"We establish a sufficient condition under which autonomous quantum error\ncorrection (AutoQEC) can effectively restore Heisenberg scaling (HS) in quantum\nmetrology. Specifically, we show that if all Lindblad operators associated with\nthe noise commute with the signal Hamiltonian and a particular constrained\nlinear equation admits a solution, then an ancilla-free AutoQEC scheme with\nfinite $R$ (where $R$ represents the ratio between the engineered dissipation\nrate for AutoQEC and the noise rate,) can approximately preserve HS with\ndesired small additive error $\\epsilon > 0$ over any time interval $0 \\leq t\n\\leq T$. We emphasize that the error scales as $ \\epsilon = O(\\kappa T / R^c) $\nwith $c \\geq 1$, indicating that the required $R$ decreases significantly with\nincreasing $c$ to achieve a desired error. Furthermore, we discuss that if the\nsufficient condition is not satisfied, logical errors may be induced that\ncannot be efficiently corrected by the canonical AutoQEC framework. Finally, we\nnumerically verify our analytical results by employing the concrete example of\nphase estimation under dephasing noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T17:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.13179v1","title":"ViTa-Zero: Zero-shot Visuotactile Object 6D Pose Estimation","summary":"Object 6D pose estimation is a critical challenge in robotics, particularly\nfor manipulation tasks. While prior research combining visual and tactile\n(visuotactile) information has shown promise, these approaches often struggle\nwith generalization due to the limited availability of visuotactile data. In\nthis paper, we introduce ViTa-Zero, a zero-shot visuotactile pose estimation\nframework. Our key innovation lies in leveraging a visual model as its backbone\nand performing feasibility checking and test-time optimization based on\nphysical constraints derived from tactile and proprioceptive observations.\nSpecifically, we model the gripper-object interaction as a spring-mass system,\nwhere tactile sensors induce attractive forces, and proprioception generates\nrepulsive forces. We validate our framework through experiments on a real-world\nrobot setup, demonstrating its effectiveness across representative visual\nbackbones and manipulation scenarios, including grasping, object picking, and\nbimanual handover. Compared to the visual models, our approach overcomes some\ndrastic failure modes while tracking the in-hand object pose. In our\nexperiments, our approach shows an average increase of 55% in AUC of ADD-S and\n60% in ADD, along with an 80% lower position error compared to FoundationPose.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-17T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.13181v1","title":"Perception Encoder: The best visual embeddings are not at the output of\n  the network","summary":"We introduce Perception Encoder (PE), a state-of-the-art encoder for image\nand video understanding trained via simple vision-language learning.\nTraditionally, vision encoders have relied on a variety of pretraining\nobjectives, each tailored to specific downstream tasks such as classification,\ncaptioning, or localization. Surprisingly, after scaling our carefully tuned\nimage pretraining recipe and refining with our robust video data engine, we\nfind that contrastive vision-language training alone can produce strong,\ngeneral embeddings for all of these downstream tasks. There is only one caveat:\nthese embeddings are hidden within the intermediate layers of the network. To\ndraw them out, we introduce two alignment methods, language alignment for\nmultimodal language modeling, and spatial alignment for dense prediction.\nTogether with the core contrastive checkpoint, our PE family of models achieves\nstate-of-the-art performance on a wide variety of tasks, including zero-shot\nimage and video classification and retrieval; document, image, and video Q&A;\nand spatial tasks such as detection, depth estimation, and tracking. To foster\nfurther research, we are releasing our models, code, and a novel dataset of\nsynthetically and human-annotated videos.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:59:57Z"}
