{"aid":"http://arxiv.org/abs/2503.21656v1","title":"Logging the conformal life of Ramanujan's $Ï€$","summary":"In 1914, Ramanujan presented 17 infinite series for $1/\\pi$. We examine the\nphysics origin of these remarkable formulae by connecting them to 2D\nlogarithmic conformal field theories (LCFTs) which arise in various contexts\nsuch as the fractional quantum hall effect, percolation and polymers. In light\nof the LCFT connection, we investigate such infinite series in terms of the\nphysics data, i.e., the operator spectrum and OPE coefficients of the CFT and\nthe conformal block expansion. These considerations lead to novel\napproximations for $1/\\pi$. The rapid convergence of the Ramanujan series\nmotivates us to take advantage of the crossing symmetry of the LCFT correlators\nto find new and efficient representations. To achieve this, we use the\nparametric crossing symmetric dispersion relation which was recently developed\nfor string amplitudes. Quite strikingly, we find remarkable simplifications in\nthe new representations, where, in the Legendre relation, the entire\ncontribution to $1/\\pi$ comes from the logarithmic identity operator, hinting\nat a universal property of LCFTs. Additionally, the dispersive representation\ngives us a new handle on the double-lightcone limit.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-03-27T16:21:08Z"}
{"aid":"http://arxiv.org/abs/2503.21685v1","title":"Extracting Coupling-Mode Spectral Densities with Two-Dimensional\n  Electronic Spectroscopy","summary":"Methods for reconstructing the spectral density of a vibrational environment\nfrom experimental data can yield key insights into the impact of the\nenvironment on molecular function. Although such experimental methods exist,\nthey generally only access vibrational modes that couple diagonally to the\nelectron system. Here we present a method for extracting the spectral density\nof modes that couple to the transition between electronic states, using\ntwo-dimensional electronic spectroscopy. To demonstrate this, we use a\nprocess-tensor method that can simulate two-dimensional electronic spectroscopy\nmeasurements in a numerically exact way. To explain how the extraction works,\nwe also derive an approximate analytical solution, which illustrates that the\nnon-Markovianity of the environment plays an essential role in the existence of\nthe simulated signal.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.mes-hall,quant-ph","published":"2025-03-27T16:53:56Z"}
{"aid":"http://arxiv.org/abs/2503.21699v1","title":"MAVERIX: Multimodal Audio-Visual Evaluation Reasoning IndeX","summary":"Frontier models have either been language-only or have primarily focused on\nvision and language modalities. Although recent advancements in models with\nvision and audio understanding capabilities have shown substantial progress,\nthe field lacks a standardized evaluation framework for thoroughly assessing\ntheir cross-modality perception performance. We introduce MAVERIX~(Multimodal\nAudio-Visual Evaluation Reasoning IndeX), a novel benchmark with 700 videos and\n2,556 questions explicitly designed to evaluate multimodal models through tasks\nthat necessitate close integration of video and audio information. MAVERIX\nuniquely provides models with audiovisual tasks, closely mimicking the\nmultimodal perceptual experiences available to humans during inference and\ndecision-making processes. To our knowledge, MAVERIX is the first benchmark\naimed explicitly at assessing comprehensive audiovisual integration.\nExperiments with state-of-the-art models, including Gemini 1.5 Pro and o1, show\nperformance approaching human levels (around 70% accuracy), while human experts\nreach near-ceiling performance (95.1%). With standardized evaluation protocols,\na rigorously annotated pipeline, and a public toolkit, MAVERIX establishes a\nchallenging testbed for advancing audiovisual multimodal intelligence.","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.CV","published":"2025-03-27T17:04:33Z"}
{"aid":"http://arxiv.org/abs/2503.21701v1","title":"Machine Learning Assisted Modeling of Amorphous TiO$_2$-Doped GeO$_2$\n  for Advanced LIGO Mirror Coatings","summary":"The mechanical loss angle of amorphous TiO$_2$-doped GeO$_2$ can be lower\nthan 10$^{-4}$, making it a candidate for Laser Interferometer\nGravitational-wave Observatory (LIGO) mirror coatings. Amorphous oxides have\ncomplex atomic structures that are influenced by various factors, including\ndoping concentration, preparation, and thermal history, resulting in different\nmass densities and physical properties. Modeling at atomistic level enables\ncapturing these effects by generating atomic structure models according to\nexperimental conditions. In order to obtain reliable and physical amorphous\nmodels at an affordable cost, we develop classical and machine-learning\npotentials (MLP) to speed up simulations. First-principles calculations are\nused to train and validate MLP as well as validating structure models. To\nbetter reproduce properties such as elastic modulus, radial distribution\nfunction (RDF) and the variations in mass density of doped amorphous oxides,\ndensity functional theory (DFT) calculations are used to optimize the final\nmodels. We find that the mass densities of amorphous systems are correlated\nwith the total void volume. The experimental mass density matches the models\nwith the most symmetric potential energy wells under volume change. The elastic\nresponse of the metal-oxygen network is also studied. The 27\\% TiO$_2$ doped\nGeO$_2$ system shows the least number of large atom-atom distance changes,\nwhile for 44\\% TiO$_2$ doped GeO$_2$, a majority of Ti-O distances are\nsignificantly changed. In response to strains, the metal-oxygen network at low\nmass densities prefers to adjust bond angles, while at high mass densities, the\nadjustment is mainly done by changing atom-atom distance.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-27T17:05:07Z"}
{"aid":"http://arxiv.org/abs/2503.21713v1","title":"Investigating Experiential Effects in Online Chess using a Hierarchical\n  Bayesian Analysis","summary":"The presence or absence of winner-loser effects is a widely discussed\nphenomenon across both sports and psychology research. Investigation of such\neffects is often hampered by the limited availability of data. Online chess has\nexploded in popularity in recent years and provides vast amounts of data which\ncan be used to explore this question. With a hierarchical Bayesian regression\nmodel, we carefully investigate the presence of such experiential effects in\nonline chess. Using a large quantity of online chess data, we see little\nevidence for experiential effects that are consistent across all players, with\nsome individual players showing some evidence for such effects. Given the\nchallenging temporal nature of this data, we discuss several methods for\nassessing the suitability of our model and carefully check its validity.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-27T17:24:48Z"}
{"aid":"http://arxiv.org/abs/2503.21729v1","title":"ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large\n  Reasoning Models with Iterative Retrieval Augmented Generation","summary":"Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely\nprimarily on parametric knowledge, limiting factual accuracy. While recent\nworks equip reinforcement learning (RL)-based LRMs with retrieval capabilities,\nthey suffer from overthinking and lack robustness in reasoning, reducing their\neffectiveness in question answering (QA) tasks. To address this, we propose\nReaRAG, a factuality-enhanced reasoning model that explores diverse queries\nwithout excessive iterations. Our solution includes a novel data construction\nframework with an upper bound on the reasoning chain length. Specifically, we\nfirst leverage an LRM to generate deliberate thinking, then select an action\nfrom a predefined action space (Search and Finish). For Search action, a query\nis executed against the RAG engine, where the result is returned as observation\nto guide reasoning steps later. This process iterates until a Finish action is\nchosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach\noutperforms existing baselines on multi-hop QA. Further analysis highlights its\nstrong reflective ability to recognize errors and refine its reasoning\ntrajectory. Our study enhances LRMs' factuality while effectively integrating\nrobust reasoning for Retrieval-Augmented Generation (RAG).","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-27T17:44:18Z"}
{"aid":"http://arxiv.org/abs/2503.21734v1","title":"Structure and Melting of Fe, MgO, SiO2, and MgSiO3 in Planets: Database,\n  Inversion, and Phase Diagram","summary":"We present globally inverted pressure-temperature (P-T) phase diagrams up to\n5,000 GPa for four fundamental planetary materials, Fe, MgO, SiO2, and MgSiO3,\nderived from logistic regression and supervised learning, together with an\nexperimental phase equilibria database. These new P-T phase diagrams provide a\nsolution to long-standing disputes about their melting curves. Their\nimplications extend to the melting and freezing of rocky materials in the\ninterior of giant planets and super-Earth exoplanets, contributing to the\nrefinement of their internal structure models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.data-an,physics.geo-ph","published":"2025-03-27T17:48:04Z"}
{"aid":"http://arxiv.org/abs/2503.23686v1","title":"Data-Driven Forecasting of High-Dimensional Transient and Stationary\n  Processes via Space-Time Projection","summary":"Space-Time Projection (STP) is introduced as a data-driven forecasting\napproach for high-dimensional and time-resolved data. The method computes\nextended space-time proper orthogonal modes from training data spanning a\nprediction horizon comprising both hindcast and forecast intervals. Forecasts\nare then generated by projecting the hindcast portion of these modes onto new\ndata, simultaneously leveraging their orthogonality and optimal correlation\nwith the forecast extension. Rooted in Proper Orthogonal Decomposition (POD)\ntheory, dimensionality reduction and time-delay embedding are intrinsic to the\napproach. For a given ensemble and fixed prediction horizon, the only tunable\nparameter is the truncation rank--no additional hyperparameters are required.\nThe hindcast accuracy serves as a reliable indicator for short-term forecast\naccuracy and establishes a lower bound on forecast errors. The efficacy of the\nmethod is demonstrated using two datasets: transient, highly anisotropic\nsimulations of supernova explosions in a turbulent interstellar medium, and\nexperimental velocity fields of a turbulent high-subsonic engineering flow. In\na comparative study with standard Long Short-Term Memory (LSTM) neural\nnetworks--acknowledging that alternative architectures or training strategies\nmay yield different outcomes--the method consistently provided more accurate\nforecasts. Considering its simplicity and robust performance, STP offers an\ninterpretable and competitive benchmark for forecasting high-dimensional\ntransient and chaotic processes, relying purely on spatiotemporal correlation\ninformation.","main_category":"cs.LG","categories":"cs.LG,astro-ph.GA,nlin.CD,physics.comp-ph,physics.data-an,physics.flu-dyn","published":"2025-03-31T03:36:59Z"}
{"aid":"http://arxiv.org/abs/2503.23697v1","title":"A Low-complexity Structured Neural Network to Realize States of\n  Dynamical Systems","summary":"Data-driven learning is rapidly evolving and places a new perspective on\nrealizing state-space dynamical systems. However, dynamical systems derived\nfrom nonlinear ordinary differential equations (ODEs) suffer from limitations\nin computational efficiency. Thus, this paper stems from data-driven learning\nto advance states of dynamical systems utilizing a structured neural network\n(StNN). The proposed learning technique also seeks to identify an optimal,\nlow-complexity operator to solve dynamical systems, the so-called Hankel\noperator, derived from time-delay measurements. Thus, we utilize the StNN based\non the Hankel operator to solve dynamical systems as an alternative to existing\ndata-driven techniques. We show that the proposed StNN reduces the number of\nparameters and computational complexity compared with the conventional neural\nnetworks and also with the classical data-driven techniques, such as Sparse\nIdentification of Nonlinear Dynamics (SINDy) and Hankel Alternative view of\nKoopman (HAVOK), which is commonly known as delay-Dynamic Mode\nDecomposition(DMD) or Hankel-DMD. More specifically, we present numerical\nsimulations to solve dynamical systems utilizing the StNN based on the Hankel\noperator beginning from the fundamental Lotka-Volterra model, where we compare\nthe StNN with the LEarning Across Dynamical Systems (LEADS), and extend our\nanalysis to highly nonlinear and chaotic Lorenz systems, comparing the StNN\nwith conventional neural networks, SINDy, and HAVOK. Hence, we show that the\nproposed StNN paves the way for realizing state-space dynamical systems with a\nlow-complexity learning algorithm, enabling prediction and understanding of\nfuture states.","main_category":"cs.LG","categories":"cs.LG,math.DS","published":"2025-03-31T03:52:38Z"}
{"aid":"http://arxiv.org/abs/2503.23726v1","title":"PDSL: Privacy-Preserved Decentralized Stochastic Learning with\n  Heterogeneous Data Distribution","summary":"In the paradigm of decentralized learning, a group of agents collaborates to\nlearn a global model using distributed datasets without a central server.\nHowever, due to the heterogeneity of the local data across the different\nagents, learning a robust global model is rather challenging. Moreover, the\ncollaboration of the agents relies on their gradient information exchange,\nwhich poses a risk of privacy leakage. In this paper, to address these issues,\nwe propose PDSL, a novel privacy-preserved decentralized stochastic learning\nalgorithm with heterogeneous data distribution. On one hand, we innovate in\nutilizing the notion of Shapley values such that each agent can precisely\nmeasure the contributions of its heterogeneous neighbors to the global learning\ngoal; on the other hand, we leverage the notion of differential privacy to\nprevent each agent from suffering privacy leakage when it contributes gradient\ninformation to its neighbors. We conduct both solid theoretical analysis and\nextensive experiments to demonstrate the efficacy of our PDSL algorithm in\nterms of privacy preservation and convergence.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T04:58:05Z"}
{"aid":"http://arxiv.org/abs/2503.23750v1","title":"Float Lattice Gas Automata: A connection between Molecular Dynamics and\n  Lattice Boltzmann Method for quantum computers","summary":"Building upon the Integer Lattice Gas Automata framework of Blommel\n\\textit{et al.} \\cite{PhysRevE.97.023310}, we introduce a simplified,\nfluctuation-free variant. This approach relies on floating-point numbers and\nclosely mirrors the Lattice Boltzmann Method (LBM), with the key distinction\nbeing a novel collision operator. This operator, derived from the ensemble\naverage of transition probabilities, generates nonlinear terms. We propose this\nnew Float Lattice Gas Automata (FLGA) collision as a computationally efficient\nalternative to traditional and quantum LBM implementations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T06:02:16Z"}
{"aid":"http://arxiv.org/abs/2503.23752v1","title":"StrokeFusion: Vector Sketch Generation via Joint Stroke-UDF Encoding and\n  Latent Sequence Diffusion","summary":"In the field of sketch generation, raster-format trained models often produce\nnon-stroke artifacts, while vector-format trained models typically lack a\nholistic understanding of sketches, leading to compromised recognizability.\nMoreover, existing methods struggle to extract common features from similar\nelements (e.g., eyes of animals) appearing at varying positions across\nsketches. To address these challenges, we propose StrokeFusion, a two-stage\nframework for vector sketch generation. It contains a dual-modal sketch feature\nlearning network that maps strokes into a high-quality latent space. This\nnetwork decomposes sketches into normalized strokes and jointly encodes stroke\nsequences with Unsigned Distance Function (UDF) maps, representing sketches as\nsets of stroke feature vectors. Building upon this representation, our\nframework exploits a stroke-level latent diffusion model that simultaneously\nadjusts stroke position, scale, and trajectory during generation. This enables\nhigh-fidelity sketch generation while supporting stroke interpolation editing.\nExtensive experiments on the QuickDraw dataset demonstrate that our framework\noutperforms state-of-the-art techniques, validating its effectiveness in\npreserving structural integrity and semantic features. Code and models will be\nmade publicly available upon publication.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-03-31T06:03:03Z"}
{"aid":"http://arxiv.org/abs/2503.23759v1","title":"Word Break on SLP-Compressed Texts","summary":"Word Break is a prototypical factorization problem in string processing:\nGiven a word $w$ of length $N$ and a dictionary $\\mathcal{D} = \\{d_1, d_2,\n\\ldots, d_{K}\\}$ of $K$ strings, determine whether we can partition $w$ into\nwords from $\\mathcal{D}$. We propose the first algorithm that solves the Word\nBreak problem over the SLP-compressed input text $w$. Specifically, we show\nthat, given the string $w$ represented using an SLP of size $g$, we can solve\nthe Word Break problem in $\\mathcal{O}(g \\cdot m^{\\omega} + M)$ time, where $m\n= \\max_{i=1}^{K} |d_i|$, $M = \\sum_{i=1}^{K} |d_i|$, and $\\omega \\geq 2$ is the\nmatrix multiplication exponent. We obtain our algorithm as a simple corollary\nof a more general result: We show that in $\\mathcal{O}(g \\cdot m^{\\omega} + M)$\ntime, we can index the input text $w$ so that solving the Word Break problem\nfor any of its substrings takes $\\mathcal{O}(m^2 \\log N)$ time (independent of\nthe substring length). Our second contribution is a lower bound: We prove that,\nunless the Combinatorial $k$-Clique Conjecture fails, there is no combinatorial\nalgorithm for Word Break on SLP-compressed strings running in $\\mathcal{O}(g\n\\cdot m^{2-\\epsilon} + M)$ time for any $\\epsilon > 0$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-03-31T06:19:05Z"}
{"aid":"http://arxiv.org/abs/2503.23764v1","title":"WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation\n  for Efficient Medical Image Segmentation","summary":"Transformer-based architectures have advanced medical image analysis by\neffectively modeling long-range dependencies, yet they often struggle in 3D\nsettings due to substantial memory overhead and insufficient capture of\nfine-grained local features. We address these limi- tations with WaveFormer, a\nnovel 3D-transformer that: i) leverages the fundamental frequency-domain\nproperties of features for contextual rep- resentation, and ii) is inspired by\nthe top-down mechanism of the human visual recognition system, making it a\nbiologically motivated architec- ture. By employing discrete wavelet\ntransformations (DWT) at multiple scales, WaveFormer preserves both global\ncontext and high-frequency de- tails while replacing heavy upsampling layers\nwith efficient wavelet-based summarization and reconstruction. This\nsignificantly reduces the number of parameters, which is critical for\nreal-world deployment where compu- tational resources and training times are\nconstrained. Furthermore, the model is generic and easily adaptable to diverse\napplications. Evaluations on BraTS2023, FLARE2021, and KiTS2023 demonstrate\nperformance on par with state-of-the-art methods while offering substantially\nlower computational complexity.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T06:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.23766v1","title":"Accelerating High-Efficiency Organic Photovoltaic Discovery via\n  Pretrained Graph Neural Networks and Generative Reinforcement Learning","summary":"Organic photovoltaic (OPV) materials offer a promising avenue toward\ncost-effective solar energy utilization. However, optimizing donor-acceptor\n(D-A) combinations to achieve high power conversion efficiency (PCE) remains a\nsignificant challenge. In this work, we propose a framework that integrates\nlarge-scale pretraining of graph neural networks (GNNs) with a GPT-2\n(Generative Pretrained Transformer 2)-based reinforcement learning (RL)\nstrategy to design OPV molecules with potentially high PCE. This approach\nproduces candidate molecules with predicted efficiencies approaching 21\\%,\nalthough further experimental validation is required. Moreover, we conducted a\npreliminary fragment-level analysis to identify structural motifs recognized by\nthe RL model that may contribute to enhanced PCE, thus providing design\nguidelines for the broader research community. To facilitate continued\ndiscovery, we are building the largest open-source OPV dataset to date,\nexpected to include nearly 3,000 donor-acceptor pairs. Finally, we discuss\nplans to collaborate with experimental teams on synthesizing and characterizing\nAI-designed molecules, which will provide new data to refine and improve our\npredictive and generative models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T06:31:15Z"}
{"aid":"http://arxiv.org/abs/2503.23802v1","title":"Herscovici Conjecture on Pebbling","summary":"Consider a configuration of pebbles on the vertices of a connected graph. A\npebbling move is to remove two pebbles from a vertex and to place one pebble at\nthe neighbouring vertex of the vertex from which the pebbles are removed.\n  For a positive integer $t$, with every configuration of $\\pi_t(G)$(least\npositive integer) pebbles, if we can transfer $t$ pebbles to any target through\na number of pebbling moves then $\\pi_t(G)$ is called the $t$-pebbling number of\n$G$.\n  We discuss the computation of the $t$-pebbling number, the $2t-$ pebbling\nproperty and Herscovici conjecture considering total graphs.\n  \\bigskip \\noindent Keywords: pebbling moves, $t$- pebbling number,\n$2t$-pebbling property, Herscovici conjecture, total graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T07:25:26Z"}
{"aid":"http://arxiv.org/abs/2503.23803v1","title":"Thinking Longer, Not Larger: Enhancing Software Engineering Agents via\n  Scaling Test-Time Compute","summary":"Recent advancements in software engineering agents have demonstrated\npromising capabilities in automating program improvements. However, their\nreliance on closed-source or resource-intensive models introduces significant\ndeployment challenges in private environments, prompting a critical question:\n\\textit{How can personally deployable open-source LLMs achieve comparable code\nreasoning performance?}\n  To this end, we propose a unified Test-Time Compute scaling framework that\nleverages increased inference-time computation instead of larger models. Our\nframework incorporates two complementary strategies: internal TTC and external\nTTC. Internally, we introduce a \\textit{development-contextualized trajectory\nsynthesis} method leveraging real-world software repositories to bootstrap\nmulti-stage reasoning processes, such as fault localization and patch\ngeneration. We further enhance trajectory quality through rejection sampling,\nrigorously evaluating trajectories along accuracy and complexity. Externally,\nwe propose a novel \\textit{development-process-based search} strategy guided by\nreward models and execution verification. This approach enables targeted\ncomputational allocation at critical development decision points, overcoming\nlimitations of existing \"end-point only\" verification methods.\n  Evaluations on SWE-bench Verified demonstrate our \\textbf{32B model achieves\na 46\\% issue resolution rate}, surpassing significantly larger models such as\nDeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical\nvalidation of the test-time scaling phenomenon within SWE agents, revealing\nthat \\textbf{models dynamically allocate more tokens to increasingly\nchallenging problems}, effectively enhancing reasoning capabilities. We\npublicly release all training data, models, and code to facilitate future\nresearch. https://github.com/yingweima2022/SWE-Reasoner","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-03-31T07:31:32Z"}
{"aid":"http://arxiv.org/abs/2503.23817v1","title":"MVDRAM: Enabling GeMV Execution in Unmodified DRAM for Low-Bit LLM\n  Acceleration","summary":"General matrix-vector multiplication (GeMV) remains a critical latency\nbottleneck in large language model (LLM) inference, even with quantized low-bit\nmodels. Processing-Using-DRAM (PUD), an analog in-DRAM computing technique, has\nthe potential to repurpose on-device DRAM as a GeMV engine, offering additional\nhigh-throughput processing capabilities to widespread consumer devices without\nDRAM modifications. However, applying PUD to GeMV operations in the LLM\ninference pipeline incurs significant overheads $\\textit{before}$ and\n$\\textit{after}$ in-DRAM computation, diminishing the benefits of its\nhigh-throughput processing capabilities.\n  This paper presents MVDRAM, the first practical system to accelerate GeMV\noperations for low-bit LLM inference using unmodified DRAM. By leveraging the\ndata sharing patterns and mathematical linearity in GeMV operations, MVDRAM\norchestrates the processor and DRAM to eliminate the costs associated with\npre-arranging inputs and bit-transposition of outputs required in conventional\nPUD approaches. Our experimental evaluation with four DDR4 DRAM modules shows\nthat MVDRAM achieves comparable or even better inference speed than the\nprocessor-based implementation for GeMV operations in low-bit (under 4-bit)\nLLM. In particular, MVDRAM achieves up to 7.29$\\times$ speedup and 30.5$\\times$\nenergy efficiency for low-bit GeMV operations. For end-to-end LLM inference,\nMVDRAM achieves 2.18$\\times$ and 1.31$\\times$ throughput improvements, along\nwith 3.04$\\times$ and 2.35$\\times$ energy efficiency, for 2-bit and 4-bit\nquantized low-bit models, respectively. MVDRAM has the potential to redefine\nthe AI hardware landscape by demonstrating the feasibility of standard DRAM as\nan LLM accelerator.","main_category":"cs.AR","categories":"cs.AR,cs.DC","published":"2025-03-31T07:54:59Z"}
{"aid":"http://arxiv.org/abs/2503.23881v1","title":"ExScene: Free-View 3D Scene Reconstruction with Gaussian Splatting from\n  a Single Image","summary":"The increasing demand for augmented and virtual reality applications has\nhighlighted the importance of crafting immersive 3D scenes from a simple\nsingle-view image. However, due to the partial priors provided by single-view\ninput, existing methods are often limited to reconstruct low-consistency 3D\nscenes with narrow fields of view from single-view input. These limitations\nmake them less capable of generalizing to reconstruct immersive scenes. To\naddress this problem, we propose ExScene, a two-stage pipeline to reconstruct\nan immersive 3D scene from any given single-view image. ExScene designs a novel\nmultimodal diffusion model to generate a high-fidelity and globally consistent\npanoramic image. We then develop a panoramic depth estimation approach to\ncalculate geometric information from panorama, and we combine geometric\ninformation with high-fidelity panoramic image to train an initial 3D Gaussian\nSplatting (3DGS) model. Following this, we introduce a GS refinement technique\nwith 2D stable video diffusion priors. We add camera trajectory consistency and\ncolor-geometric priors into the denoising process of diffusion to improve color\nand spatial consistency across image sequences. These refined sequences are\nthen used to fine-tune the initial 3DGS model, leading to better reconstruction\nquality. Experimental results demonstrate that our ExScene achieves consistent\nand immersive scene reconstruction using only single-view input, significantly\nsurpassing state-of-the-art baselines.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:33:22Z"}
{"aid":"http://arxiv.org/abs/2503.23897v1","title":"Training-Free Text-Guided Image Editing with Visual Autoregressive Model","summary":"Text-guided image editing is an essential task that enables users to modify\nimages through natural language descriptions. Recent advances in diffusion\nmodels and rectified flows have significantly improved editing quality,\nprimarily relying on inversion techniques to extract structured noise from\ninput images. However, inaccuracies in inversion can propagate errors, leading\nto unintended modifications and compromising fidelity. Moreover, even with\nperfect inversion, the entanglement between textual prompts and image features\noften results in global changes when only local edits are intended. To address\nthese challenges, we propose a novel text-guided image editing framework based\non VAR (Visual AutoRegressive modeling), which eliminates the need for explicit\ninversion while ensuring precise and controlled modifications. Our method\nintroduces a caching mechanism that stores token indices and probability\ndistributions from the original image, capturing the relationship between the\nsource prompt and the image. Using this cache, we design an adaptive\nfine-grained masking strategy that dynamically identifies and constrains\nmodifications to relevant regions, preventing unintended changes. A token\nreassembling approach further refines the editing process, enhancing diversity,\nfidelity, and control. Our framework operates in a training-free manner and\nachieves high-fidelity editing with faster inference speeds, processing a 1K\nresolution image in as fast as 1.2 seconds. Extensive experiments demonstrate\nthat our method achieves performance comparable to, or even surpassing,\nexisting diffusion- and rectified flow-based approaches in both quantitative\nmetrics and visual quality. The code will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:46:56Z"}
{"aid":"http://arxiv.org/abs/2503.23940v1","title":"Operator limit of Wigner matrices I","summary":"We consider the Wigner matrix $W_{n}$ of dimension $n \\times n$ as $n \\to\n\\infty$. The objective of this paper is two folds: first we construct an\noperator $\\mathcal{W}$ on a suitable Hilbert space $\\mathcal{H}$ and then\ndefine a suitable notion of convergence such that the matrices $W_{n}$ converge\nin that notion of convergence to $\\mathcal{W}$. We further investigate some\nproperties of $\\mathcal{W}$ and $\\mathcal{H}$. We show that $\\mathcal{H}$ is a\nnontrivial extension of $L^{2}[0,1]$ with respect to the Lebesgue measure and\nthe spectral measure of $\\mathcal{W}$ at any function $f \\in L^{2}[0,1]$ is\nalmost surely the semicircular law.","main_category":"math.PR","categories":"math.PR,math-ph,math.FA,math.MP,math.ST,stat.TH","published":"2025-03-31T10:45:01Z"}
{"aid":"http://arxiv.org/abs/2503.23947v1","title":"Spectral-Adaptive Modulation Networks for Visual Perception","summary":"Recent studies have shown that 2D convolution and self-attention exhibit\ndistinct spectral behaviors, and optimizing their spectral properties can\nenhance vision model performance. However, theoretical analyses remain limited\nin explaining why 2D convolution is more effective in high-pass filtering than\nself-attention and why larger kernels favor shape bias, akin to self-attention.\nIn this paper, we employ graph spectral analysis to theoretically simulate and\ncompare the frequency responses of 2D convolution and self-attention within a\nunified framework. Our results corroborate previous empirical findings and\nreveal that node connectivity, modulated by window size, is a key factor in\nshaping spectral functions. Leveraging this insight, we introduce a\n\\textit{spectral-adaptive modulation} (SPAM) mixer, which processes visual\nfeatures in a spectral-adaptive manner using multi-scale convolutional kernels\nand a spectral re-scaling mechanism to refine spectral components. Based on\nSPAM, we develop SPANetV2 as a novel vision backbone. Extensive experiments\ndemonstrate that SPANetV2 outperforms state-of-the-art models across multiple\nvision tasks, including ImageNet-1K classification, COCO object detection, and\nADE20K semantic segmentation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:53:42Z"}
{"aid":"http://arxiv.org/abs/2503.23948v1","title":"AI2Agent: An End-to-End Framework for Deploying AI Projects as\n  Autonomous Agents","summary":"As AI technology advances, it is driving innovation across industries,\nincreasing the demand for scalable AI project deployment. However, deployment\nremains a critical challenge due to complex environment configurations,\ndependency conflicts, cross-platform adaptation, and debugging difficulties,\nwhich hinder automation and adoption. This paper introduces AI2Agent, an\nend-to-end framework that automates AI project deployment through\nguideline-driven execution, self-adaptive debugging, and case \\& solution\naccumulation. AI2Agent dynamically analyzes deployment challenges, learns from\npast cases, and iteratively refines its approach, significantly reducing human\nintervention. To evaluate its effectiveness, we conducted experiments on 30 AI\ndeployment cases, covering TTS, text-to-image generation, image editing, and\nother AI applications. Results show that AI2Agent significantly reduces\ndeployment time and improves success rates. The code and demo video are now\npublicly accessible.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:58:34Z"}
{"aid":"http://arxiv.org/abs/2503.23958v1","title":"A Multi-Stage Auto-Context Deep Learning Framework for Tissue and Nuclei\n  Segmentation and Classification in H&E-Stained Histological Images of\n  Advanced Melanoma","summary":"Melanoma is the most lethal form of skin cancer, with an increasing incidence\nrate worldwide. Analyzing histological images of melanoma by localizing and\nclassifying tissues and cell nuclei is considered the gold standard method for\ndiagnosis and treatment options for patients. While many computerized\napproaches have been proposed for automatic analysis, most perform tissue-based\nanalysis and nuclei (cell)-based analysis as separate tasks, which might be\nsuboptimal.\n  In this work, using the PUMA challenge dataset, we proposed a novel\nmulti-stage deep learning approach by combining tissue and nuclei information\nin a unified framework based on the auto-context concept to perform\nsegmentation and classification in histological images of melanoma. Through\npre-training and further post-processing, our approach achieved second and\nfirst place rankings in the PUMA challenge, with average micro Dice tissue\nscore and summed nuclei F1-score of 73.40% for Track 1 and 63.48% for Track 2,\nrespectively. Our implementation for training and testing is available at:\nhttps://github.com/NimaTorbati/PumaSubmit","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:15:50Z"}
{"aid":"http://arxiv.org/abs/2503.23973v1","title":"Odd Cuts in Bipartite Grafts II: Structure and Universality of Decapital\n  Distance Components","summary":"This paper is the second in a series of papers characterizing the maximum\npacking of \\( T \\)-cuts in bipartite grafts, following the first paper\n(N.~Kita, ``Tight cuts in bipartite grafts~I: Capital distance components,''\n{arXiv:2202.00192v2}, 2022). Given a graft $(G, T)$, a minimum join $F$, and a\nspecified vertex $r$ called the root, the distance components of $(G, T)$ are\ndefined as subgraphs of $G$ determined by the distances induced by $F$. A\ndistance component is called {\\em capital} if it contains the root; otherwise,\nit is called {\\em decapital}. In our first paper, we investigated the canonical\nstructure of capital distance components in bipartite grafts, which can be\ndescribed using the graft analogue of the Kotzig--Lov\\'asz decomposition. In\nthis paper, we provide the counterpart structure for the decapital distance\ncomponents. We also establish a necessary and sufficient condition for two\nvertices $r$ and $r'$ under which a decapital distance component with respect\nto root $r$ is also a decapital distance component with respect to root $r'$.\nAs a consequence, we obtain that the total number of decapital distance\ncomponents in a bipartite graft, taken over all choices of root, is equal to\ntwice the number of edges in a minimum join of the graft.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T11:36:02Z"}
{"aid":"http://arxiv.org/abs/2503.24002v1","title":"A Simple BER Expression for FSO Systems with Weak Turbulence and\n  Pointing Errors","summary":"We develop a simple approximation for the average BER for an FSO system\nimpacted by weak turbulence and pointing errors. Numerical results show that\nthe proposed expression accurately predicts the true BER.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T12:27:24Z"}
{"aid":"http://arxiv.org/abs/2503.24011v1","title":"Simulations in Statistical Workflows","summary":"Simulations play important and diverse roles in statistical workflows, for\nexample, in model specification, checking, validation, and even directly in\nmodel inference. Over the past decades, the application areas and overall\npotential of simulations in statistical workflows have expanded significantly,\ndriven by the development of new simulation-based algorithms and exponentially\nincreasing computational resources. In this paper, we examine past and current\ntrends in the field and offer perspectives on how simulations may shape the\nfuture of statistical practice.","main_category":"stat.CO","categories":"stat.CO","published":"2025-03-31T12:38:21Z"}
{"aid":"http://arxiv.org/abs/2503.24012v1","title":"Tree-Guided $L_1$-Convex Clustering","summary":"Convex clustering is a modern clustering framework that guarantees globally\noptimal solutions and performs comparably to other advanced clustering methods.\nHowever, obtaining a complete dendrogram (clusterpath) for large-scale datasets\nremains computationally challenging due to the extensive costs associated with\niterative optimization approaches. To address this limitation, we develop a\nnovel convex clustering algorithm called Tree-Guided $L_1$-Convex Clustering\n(TGCC). We first focus on the fact that the loss function of $L_1$-convex\nclustering with tree-structured weights can be efficiently optimized using a\ndynamic programming approach. We then develop an efficient cluster fusion\nalgorithm that utilizes the tree structure of the weights to accelerate the\noptimization process and eliminate the issue of cluster splits commonly\nobserved in convex clustering. By combining the dynamic programming approach\nwith the cluster fusion algorithm, the TGCC algorithm achieves superior\ncomputational efficiency without sacrificing clustering performance.\nRemarkably, our TGCC algorithm can construct a complete clusterpath for $10^6$\npoints in $\\mathbb{R}^2$ within 15 seconds on a standard laptop without the\nneed for parallel or distributed computing frameworks. Moreover, we extend the\nTGCC algorithm to develop biclustering and sparse convex clustering algorithms.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-03-31T12:39:48Z"}
{"aid":"http://arxiv.org/abs/2503.24038v1","title":"Giant counter-rotating oscillations on the attosecond timescale","summary":"We predict an unexplored type of ultrastrong coupling between atoms and\nintense ultraviolet light that leads to giant population oscillations on the\nattosecond timescale. These counter-rotating oscillations can be of similar\namplitude as the elementary femtosecond Rabi oscillations between the two\nstrongly coupled states. The effect, which is beyond the two-level atom, is\nnon-reciprocal: It only affects the excited state, while the ground state is\nunaffected. We propose that two-photon Rabi oscillations (1s$^2$-1s3d) in\nhelium is suitable for the generation of this type of ultrastrong coupling with\nrealistic pulses. We use a combination of Floquet theory and effective\nHamiltonian theory to test our predictions against ab initio simulations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T13:01:32Z"}
{"aid":"http://arxiv.org/abs/2503.24061v1","title":"Simple general magnification of circuit lower bounds","summary":"We construct so-called distinguishers, sparse matrices that retain some\nproperties of error correcting codes. They provide a technically and\nconceptually simple approach to magnification. We generalize and strengthen\nknown general (not problem specific) magnification results and in particular\nachieve magnification thresholds below known lower bounds. For example, we show\nthat fixed polynomial formula size lower bounds for NP are implied by slightly\nsuperlinear formula size lower bounds for approximating any sufficiently sparse\nproblem in NP. We also show that the thresholds achieved are sharp.\nAdditionally, our approach yields a uniform magnification result for the\nminimum circuit size problem. This seems to sidestep the localization barrier.","main_category":"cs.CC","categories":"cs.CC","published":"2025-03-31T13:21:56Z"}
{"aid":"http://arxiv.org/abs/2503.24103v1","title":"Constructing Chayet-Garibaldi algebras from affine vertex algebras\n  (including the 3876-dimensional algebra for $E_8$)","summary":"In 2021, Maurice Chayet and Skip Garibaldi provided an explicit construction\nof a commutative non-associative algebra on the second smallest representation\nof $E_8$ (of dimension $3875$) adjoined with a unit. In fact, they define such\nan algebra $A(\\mathfrak{g})$ for each simple Lie algebra $\\mathfrak{g}$, in\nterms of explicit but ad-hoc formulas.\n  We discovered that their algebras $A(\\mathfrak{g})$ have a natural\ninterpretation in terms of affine vertex algebras, and their ad-hoc formulas\ntake an extremely simple form in this new interpretation. It is our hope that\nthis point of view will lead to a better understanding of this interesting\nclass of algebras.","main_category":"math.RA","categories":"math.RA,math.GR,math.RT","published":"2025-03-31T13:56:23Z"}
{"aid":"http://arxiv.org/abs/2503.24149v1","title":"Enhancing Trust in Inter-Organisational Data Sharing: Levels of\n  Assurance for Data Trustworthiness","summary":"As data is increasingly acknowledged as a highly valuable asset, much effort\nhas been put into investigating inter-organisational data sharing, aiming at\nutilising the value of formerly unused data. Moreover, most researchers agree,\nthat trust between actors is key for successful data sharing activities.\nHowever, existing research oftentimes focus on trust from a data provider\nperspective. Therefore, our work highlights the unbalanced view of trust,\naddressing it from a data consumer perspective. More specifically, our aim is\nto investigate trust enhancing measures on a data level, that is data\ntrustworthiness. We found, that existing data trustworthiness enhancing\nsolutions do not meet the requirements of the domain of inter-organisational\ndata sharing. Therefore, our study addresses this gap. Conducting a rigorous\ndesign science research approach, this work proposes a new Levels of Assurance\nfor Data Trustworthiness artifact. Built on existing artifacts, we demonstrate,\nhow it addresses the identified challenges within the domain appropriately. We\nfound that our novel approach requires more work to be suitable for adoption.\nStill, we are confident that our solution can increase consumer trust. We\nconclude by contributing to the body of design knowledge and emphasise the need\nfor more attention to be put into consumer trust.","main_category":"cs.SI","categories":"cs.SI,cs.CY,econ.GN,q-fin.EC","published":"2025-03-31T14:35:23Z"}
{"aid":"http://arxiv.org/abs/2503.24153v1","title":"Convexity of chance constraints for elliptical and skewed distributions\n  with copula structures dependent on decision variables","summary":"Chance constraints describe a set of given random inequalities depending on\nthe decision vector satisfied with a large enough probability. They are widely\nused in decision making under uncertain data in many engineering problems. This\npaper aims to derive the convexity of chance constraints with row dependent\nelliptical and skewed random variables via a copula depending on decision\nvectors. We obtain best thresholds of the $r$-concavity for any real number $r$\nand improve probability thresholds of the eventual convexity. We prove the\neventual convexity with elliptical distributions and a Gumbel-Hougaard copula\ndespite the copula's singularity near the origin. We determine the\n$\\alpha$-decreasing densities of generalized hyperbolic distributions by\nestimating the modified Bessel functions. By applying the $\\alpha$-decreasing\nproperty and a radial decomposition, we achieve the eventual convexity for\nthree types of skewed distributions. Finally, we provide an example to\nillustrate the eventual convexity of a feasible set containing the origin.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T14:38:27Z"}
{"aid":"http://arxiv.org/abs/2503.24191v1","title":"Output Constraints as Attack Surface: Exploiting Structured Generation\n  to Bypass LLM Safety Mechanisms","summary":"Content Warning: This paper may contain unsafe or harmful content generated\nby LLMs that may be offensive to readers. Large Language Models (LLMs) are\nextensively used as tooling platforms through structured output APIs to ensure\nsyntax compliance so that robust integration with existing softwares like agent\nsystems, could be achieved. However, the feature enabling functionality of\ngrammar-guided structured output presents significant security vulnerabilities.\nIn this work, we reveal a critical control-plane attack surface orthogonal to\ntraditional data-plane vulnerabilities. We introduce Constrained Decoding\nAttack (CDA), a novel jailbreak class that weaponizes structured output\nconstraints to bypass safety mechanisms. Unlike prior attacks focused on input\nprompts, CDA operates by embedding malicious intent in schema-level grammar\nrules (control-plane) while maintaining benign surface prompts (data-plane). We\ninstantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2%\nattack success rates across proprietary and open-weight LLMs on five safety\nbenchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our\nfindings identify a critical security blind spot in current LLM architectures\nand urge a paradigm shift in LLM safety to address control-plane\nvulnerabilities, as current mechanisms focused solely on data-plane threats\nleave critical systems exposed.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-03-31T15:08:06Z"}
{"aid":"http://arxiv.org/abs/2503.24213v1","title":"Closing the detection loophole in the triangle network with\n  high-dimensional photonic states","summary":"Bell nonlocality without input settings, e.g. in the triangle network, has\nbeen perceived to be particularly fragile, with low robustness to noise in\nphysical implementations. Here we show to the contrary that nonlocality based\non N00N states already for $N=2$ has an exceptionally high robustness to photon\nloss. For the dominant noise factor, single photon loss in the transmission\nchannels, we can certify noise robustness up to 10\\% loss, while for a\nrealistic noise model we use neural network-based heuristics to observe $\\sim\n50\\%$ robustness. Moreover we show that the robustness holds even for imperfect\nsources based on SPDC sources, where the heralding information of the sources\ncan be used to avoid any global post-processing of the outcomes, such as\ndiscarding rounds when photons fail to arrive, and thus demonstrate how the\ndetection loophole in the triangle network can be closed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T15:31:34Z"}
{"aid":"http://arxiv.org/abs/2503.24224v1","title":"Simplified Cofactor Conditions for Cubic to Tetragonal, Orthorhombic,\n  and Monoclinic Phase Transformations","summary":"Cofactor Conditions (CCs) are geometric compatibility conditions\nmathematically derived from the crystallographic theory of martensitic phase\ntransformation. The CCs guarantee compatible interfaces between the austenite\nand the parallelled twin of the martensite with any volume fraction, yielding a\nwide range of microstructures during phase transformation. In recent times, CCs\nhave demonstrated tremendous applications in the rational design of low\nhysteresis/fatigue shape memory alloys and shape memory ceramics. In this\npaper, we present a simplified form of the CCs for Type I/II twins using the\neigenspace of transformation stretch tensor and twin axes. We further show the\nexplicit forms and visualizations of the simplified CCs for Cubic to\nTetragonal, Cubic to Orthorhombic, and Cubic to Monoclinic I/II phase\ntransformations. The simplified form has revealed a more straightforward\ncorrelation between the lattice parameters and the CCs, and thus provides a\nmore convenient tool for the rational design of phase-transforming materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T15:38:23Z"}
{"aid":"http://arxiv.org/abs/2503.24234v1","title":"Beyond Gaussian Assumptions: A Nonlinear Generalization of Linear\n  Inverse Modeling","summary":"The Linear Inverse Model (LIM) is a class of data-driven methods that\nconstruct approximate linear stochastic models to represent complex\nobservational data. The stochastic forcing can be modeled using either Gaussian\nwhite noise or Ornstein-Uhlenbeck colored noise; the corresponding models are\ncalled White-LIM and Colored-LIM, respectively. Although LIMs are widely\napplied in climate sciences, they inherently approximate observed distributions\nas Gaussian, limiting their ability to capture asymmetries.\n  In this study, we extend LIMs to incorporate nonlinear dynamics, introducing\nWhite-nLIM and Colored-nLIM which allow for a more flexible and accurate\nrepresentation of complex dynamics from observations. The proposed methods not\nonly account for the nonlinear nature of the underlying system but also\neffectively capture the skewness of the observed distribution. Moreover, we\napply these methods to a lower-dimensional representation of ENSO and\ndemonstrate that both White-nLIM and Colored-nLIM successfully capture its\nnonlinear characteristic.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-03-31T15:46:06Z"}
{"aid":"http://arxiv.org/abs/2503.24235v1","title":"What, How, Where, and How Well? A Survey on Test-Time Scaling in Large\n  Language Models","summary":"As enthusiasm for scaling computation (data and parameters) in the\npretraining era gradually diminished, test-time scaling (TTS), also referred to\nas ``test-time computing'' has emerged as a prominent research focus. Recent\nstudies demonstrate that TTS can further elicit the problem-solving\ncapabilities of large language models (LLMs), enabling significant\nbreakthroughs not only in specialized reasoning tasks, such as mathematics and\ncoding, but also in general tasks like open-ended Q&A. However, despite the\nexplosion of recent efforts in this area, there remains an urgent need for a\ncomprehensive survey offering a systemic understanding. To fill this gap, we\npropose a unified, multidimensional framework structured along four core\ndimensions of TTS research: what to scale, how to scale, where to scale, and\nhow well to scale. Building upon this taxonomy, we conduct an extensive review\nof methods, application scenarios, and assessment aspects, and present an\norganized decomposition that highlights the unique functional roles of\nindividual techniques within the broader TTS landscape. From this analysis, we\ndistill the major developmental trajectories of TTS to date and offer hands-on\nguidelines for practical deployment. Furthermore, we identify several open\nchallenges and offer insights into promising future directions, including\nfurther scaling, clarifying the functional essence of techniques, generalizing\nto more tasks, and more attributions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T15:46:15Z"}
{"aid":"http://arxiv.org/abs/2503.24264v1","title":"Extended signatures and link concordance","summary":"The Levine-Tristram signature admits an n-variable extension for n-component\nlinks: it was first defined as an integer valued function on\n$(S^1\\setminus\\{1\\})^n$, and recently extended to the full torus $T^n$. The aim\nof the present article is to study and use this extended signature. First, we\nshow that it is constant on the connected components of the complement of the\nzero-locus of some renormalized Alexander polynomial. Then, we prove that the\nextended signature is a concordance invariant on an explicit dense subset of\n$T^n$. Finally, as an application, we present an infinite family of 3-component\nlinks with the following property: these links are not concordant to their\nmirror image, a fact that can be detected neither by the non-extended\nsignatures, nor by the multivariable Alexander polynomial, nor by the Milnor\ntriple linking number.","main_category":"math.GT","categories":"math.GT","published":"2025-03-31T16:10:21Z"}
{"aid":"http://arxiv.org/abs/2503.24271v1","title":"Enhancing Image Resolution of Solar Magnetograms: A Latent Diffusion\n  Model Approach","summary":"The spatial properties of the solar magnetic field are crucial to decoding\nthe physical processes in the solar interior and their interplanetary effects.\nHowever, observations from older instruments, such as the Michelson Doppler\nImager (MDI), have limited spatial or temporal resolution, which hinders the\nability to study small-scale solar features in detail. Super resolving these\nolder datasets is essential for uniform analysis across different solar cycles,\nenabling better characterization of solar flares, active regions, and magnetic\nnetwork dynamics. In this work, we introduce a novel diffusion model approach\nfor Super-Resolution and we apply it to MDI magnetograms to match the\nhigher-resolution capabilities of the Helioseismic and Magnetic Imager (HMI).\nBy training a Latent Diffusion Model (LDM) with residuals on downscaled HMI\ndata and fine-tuning it with paired MDI/HMI data, we can enhance the resolution\nof MDI observations from 2\"/pixel to 0.5\"/pixel. We evaluate the quality of the\nreconstructed images by means of classical metrics (e.g., PSNR, SSIM, FID and\nLPIPS) and we check if physical properties, such as the unsigned magnetic flux\nor the size of an active region, are preserved. We compare our model with\ndifferent variations of LDM and Denoising Diffusion Probabilistic models\n(DDPMs), but also with two deterministic architectures already used in the past\nfor performing the Super-Resolution task. Furthermore, we show with an analysis\nin the Fourier domain that the LDM with residuals can resolve features smaller\nthan 2\", and due to the probabilistic nature of the LDM, we can asses their\nreliability, in contrast with the deterministic models. Future studies aim to\nsuper-resolve the temporal scale of the solar MDI instrument so that we can\nalso have a better overview of the dynamics of the old events.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM,cs.LG","published":"2025-03-31T16:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.24308v1","title":"Johnson's contribution to the Discussion of `Statistical aspects of the\n  Covid-19 response' by Wood et al","summary":"This is a response to the paper \"Some statistical aspects of the Covid-19\nresponse\" by Wood et al, submitted to the discussion at the read paper meeting\nof the Royal Statistical Society on 10th April 2025.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T16:54:44Z"}
{"aid":"http://arxiv.org/abs/2503.24328v1","title":"Contextual Preference Collaborative Measure Framework Based on Belief\n  System","summary":"To reduce the human intervention in the preference measure process,this\narticle proposes a preference collaborative measure framework based on an\nupdated belief system,which is also capable of improving the accuracy and\nefficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\nthe average internal distance of rulesets are proposed for specifying the\nrelationship between the rules.For discovering the most representative\npreferences that are common in all users,namely common preference,a algorithm\nbased on average internal distance of ruleset,PRA algorithm,is proposed,which\naims to finish the discoveryprocess with minimum information loss\nrate.Furthermore,the concept of Common belief is proposed to update the belief\nsystem,and the common preferences are the evidences of updated belief\nsystem.Then,under the belief system,the proposed belief degree and deviation\ndegree are used to determine whether a rule confirms the belief system or not\nand classify the preference rules into two kinds(generalized or\npersonalized),and eventually filters out Top-K interesting rules relying on\nbelief degree and deviation degree.Based on above,a scalable interestingness\ncalculation framework that can apply various formulas is proposed for\naccurately calculating interestingness in different conditions.At last,IMCos\nalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\nand efficiency of the framework by using weighted cosine similarity and\ncorrelation coefficients as belief degree.In experiments,the proposed\nalgorithms are compared to two state-of-the-art algorithms and the results show\nthat IMCos and IMCov outperform than the other two in most aspects.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-03-31T17:17:45Z"}
{"aid":"http://arxiv.org/abs/2503.24333v1","title":"Mean field model of contagion processes in urban traffic networks","summary":"Theoretical arguments and empirical evidence for the emergence of macroscopic\nepidemic type behavior, in the form of Susceptible-Infected-Susceptible (SIS)\nor Susceptible-Infected-Recovered (SIR) processes in urban traffic congestion\nfrom microscopic network flows is given. Moreover, it's shown that the\nemergence of SIS/SIR implies a relationship between traffic flow and density,\nwhich is consistent with observations of the so called Fundamental Diagram of\nTraffic, which is a characteristic signature of vehicle movement phenomena that\nspans multiple scales. Our results provide a plausible explanation for this\nscale-spanning signature and put in more firm grounds recent findings that\nindicate that traffic congestion at the aggregate level can be modeled by\nsimple contagion dynamics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cond-mat.dis-nn","published":"2025-03-31T17:22:10Z"}
{"aid":"http://arxiv.org/abs/2503.24334v1","title":"Augmenting Expert Cognition in the Age of Generative AI: Insights from\n  Document-Centric Knowledge Work","summary":"As Generative AI (GenAI) capabilities expand, understanding how to preserve\nand develop human expertise while leveraging AI's benefits becomes increasingly\ncritical. Through empirical studies in two contexts -- survey article authoring\nin scholarly research and business document sensemaking -- we examine how\ndomain expertise shapes patterns of AI delegation and information processing\namong knowledge workers. Our findings reveal that while experts welcome AI\nassistance with repetitive information foraging tasks, they prefer to retain\ncontrol over complex synthesis and interpretation activities that require\nnuanced domain understanding. We identify implications for designing GenAI\nsystems that support expert cognition. These include enabling selective\ndelegation aligned with expertise levels, preserving expert agency over\ncritical analytical tasks, considering varying levels of domain expertise in\nsystem design, and supporting verification mechanisms that help users calibrate\ntheir reliance while deepening expertise. We discuss the inherent tension\nbetween reducing cognitive load through automation and maintaining the\ndeliberate practice necessary for expertise development. Lastly, we suggest\napproaches for designing systems that provide metacognitive support, moving\nbeyond simple task automation toward actively supporting expertise development.\nThis work contributes to our understanding of how to design AI systems that\naugment rather than diminish human expertise in document-centric workflows.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T17:22:20Z"}
{"aid":"http://arxiv.org/abs/2503.24374v1","title":"ERUPT: Efficient Rendering with Unposed Patch Transformer","summary":"This work addresses the problem of novel view synthesis in diverse scenes\nfrom small collections of RGB images. We propose ERUPT (Efficient Rendering\nwith Unposed Patch Transformer) a state-of-the-art scene reconstruction model\ncapable of efficient scene rendering using unposed imagery. We introduce\npatch-based querying, in contrast to existing pixel-based queries, to reduce\nthe compute required to render a target view. This makes our model highly\nefficient both during training and at inference, capable of rendering at 600\nfps on commercial hardware. Notably, our model is designed to use a learned\nlatent camera pose which allows for training using unposed targets in datasets\nwith sparse or inaccurate ground truth camera pose. We show that our approach\ncan generalize on large real-world data and introduce a new benchmark dataset\n(MSVS-1M) for latent view synthesis using street-view imagery collected from\nMapillary. In contrast to NeRF and Gaussian Splatting, which require dense\nimagery and precise metadata, ERUPT can render novel views of arbitrary scenes\nwith as few as five unposed input images. ERUPT achieves better rendered image\nquality than current state-of-the-art methods for unposed image synthesis\ntasks, reduces labeled data requirements by ~95\\% and decreases computational\nrequirements by an order of magnitude, providing efficient novel view synthesis\nfor diverse real-world scenes.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:53:05Z"}
{"aid":"http://arxiv.org/abs/2503.24380v1","title":"The fundamental localization phases in quasiperiodic systems: A unified\n  framework and exact results","summary":"The disordered quantum systems host three types of quantum states, the\nextended, localized, and critical, which bring up various distinct fundamental\nphases, including the pure phases and coexisting ones with mobility edges. The\nquantum phases involving critical states are of particular importance, but are\nless understood compared with the other ones, and the different phases have\nbeen separately studied in different quasiperiodic models. Here we propose a\nunified framework based on a spinful quasiperiodic system which unifies the\nrealizations of all the fundamental Anderson phases, %with or without mobility\nedges, with the exact and universal results being obtained for these distinct\nphases. Through the duality transformation and renormalization group method, we\nshow that the pure phases are obtained when the (emergent) chiral symmetry\npreserves in the proposed spin-1/2 quasiperiodic model, which provides a\ncriteria for the emergence of the pure phases or the coexisting ones with\nmobility edges. Further, we uncover a new universal mechanism for the critical\nstates that the emergence of such states is protected by the generalized\nincommensurate matrix element zeros in the spinful quasiperiodic model, as a\nnovel generalization of the quasiperiodic hopping zeros in the spinless\nsystems. We also show with the Avila's global theory the criteria of exact\nsolvability for the present unified quasiperiodic system, with which we\nidentify several new quasiperiodic models derived from the spinful system\nhosting exactly solvable Anderson phases. In particular, we reach a single\nmodel that hosts all the seven fundamental phases of Anderson localization.\nFinally, an experimental scheme is proposed to realize these models using\nquasiperiodic optical Raman lattices.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-03-31T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.01328v1","title":"Slow-Fast Architecture for Video Multi-Modal Large Language Models","summary":"Balancing temporal resolution and spatial detail under limited compute budget\nremains a key challenge for video-based multi-modal large language models\n(MLLMs). Existing methods typically compress video representations using\npredefined rules before feeding them into the LLM, resulting in irreversible\ninformation loss and often ignoring input instructions. To address this, we\npropose a novel slow-fast architecture that naturally circumvents this\ntrade-off, enabling the use of more input frames while preserving spatial\ndetails. Inspired by how humans first skim a video before focusing on relevant\nparts, our slow-fast design employs a dual-token strategy: 1) \"fast\" visual\ntokens -- a compact set of compressed video features -- are fed into the LLM\nalongside text embeddings to provide a quick overview; 2) \"slow\" visual tokens\n-- uncompressed video features -- are cross-attended by text embeddings through\nspecially designed hybrid decoder layers, enabling instruction-aware extraction\nof relevant visual details with linear complexity. We conduct systematic\nexploration to optimize both the overall architecture and key components.\nExperiments show that our model significantly outperforms self-attention-only\nbaselines, extending the input capacity from 16 to 128 frames with just a 3%\nincrease in computation, and achieving a 16% average performance improvement\nacross five video understanding benchmarks. Our 7B model achieves\nstate-of-the-art performance among models of similar size. Furthermore, our\nslow-fast architecture is a plug-and-play design that can be integrated into\nother video MLLMs to improve efficiency and scalability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T03:24:58Z"}
{"aid":"http://arxiv.org/abs/2504.01363v1","title":"Embedding Higman-Thompson groups of unfolding trees into the Leavitt\n  path algebras","summary":"The isomorphism problem of regular Higman-Thompson groups was solved in\narXiv:1006.1759, via embedding it into the Leavitt algebra. In this paper, we\nwill expand these results to embed the Higman-Thompson groups of unfolding\ntrees of directed graphs into the Leavitt path algebra. This embedding allows\nus to show that any isomorphism of rooted Leavitt path algebras induces an\nisomorphism between Higman-Thompson groups.","main_category":"math.RA","categories":"math.RA,math.GR","published":"2025-04-02T05:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.01383v1","title":"v-CLR: View-Consistent Learning for Open-World Instance Segmentation","summary":"In this paper, we address the challenging problem of open-world instance\nsegmentation. Existing works have shown that vanilla visual networks are biased\ntoward learning appearance information, \\eg texture, to recognize objects. This\nimplicit bias causes the model to fail in detecting novel objects with unseen\ntextures in the open-world setting. To address this challenge, we propose a\nlearning framework, called view-Consistent LeaRning (v-CLR), which aims to\nenforce the model to learn appearance-invariant representations for robust\ninstance segmentation. In v-CLR, we first introduce additional views for each\nimage, where the texture undergoes significant alterations while preserving the\nimage's underlying structure. We then encourage the model to learn the\nappearance-invariant representation by enforcing the consistency between object\nfeatures across different views, for which we obtain class-agnostic object\nproposals using off-the-shelf unsupervised models that possess strong\nobject-awareness. These proposals enable cross-view object feature matching,\ngreatly reducing the appearance dependency while enhancing the\nobject-awareness. We thoroughly evaluate our method on public benchmarks under\nboth cross-class and cross-dataset settings, achieving state-of-the-art\nperformance. Project page: https://visual-ai.github.io/vclr","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T05:52:30Z"}
{"aid":"http://arxiv.org/abs/2504.01410v1","title":"The Interstellar Medium","summary":"The interstellar medium (ISM) is the material that fills the space between\nthe stars in all galaxies; it is a multi-phase medium in pressure equilibrium,\nwith densities and temperatures covering over 6 orders of magnitude. Although\naccounting for only a small fraction of the mass of any given galaxy, it is a\nvital component, since it holds the material responsible for galaxy growth\nthrough star formation. Studying the ISM requires careful observations at all\nwavelengths of the electromagnetic spectrum. This article describes the\nmulti-phase nature of the ISM, and then puts it in the context of galaxy\nevolution models, emphasising the importance of the cycling of baryons in and\nout of galaxies. Within this framework, the ISM plays a central role: it\nconnects the physical processes operating on very large physical- and\ntime-scales which control the accretion of gas onto galaxies, and the small\nscale processes that regulate star formation.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T06:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.01425v1","title":"Asymptotic stability and exponential stability for a class of impulsive\n  neutral differential equations with discrete and distributed delays","summary":"In this paper, we present sufficient conditions for asymptotic stability and\nexponential stability of a class of impulsive neutral differential equations\nwith discrete and distributed delays. Our approaches are based on the method\nusing fixed point theory, which do not resort to any Lyapunov functions or\nLyapunov functionals. Our conditions do not require the differentiability of\ndelays, nor do they ask for a fixed sign on the coefficient functions. Our\nresults improve some previous ones in the literature. Examples are given to\nillustrate our main results.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T07:22:03Z"}
{"aid":"http://arxiv.org/abs/2504.01442v1","title":"Coarse-to-Fine Semantic Communication Systems for Text Transmission","summary":"Achieving more powerful semantic representations and semantic understanding\nis one of the key problems in improving the performance of semantic\ncommunication systems. This work focuses on enhancing the semantic\nunderstanding of the text data to improve the effectiveness of semantic\nexchange. We propose a novel semantic communication system for text\ntransmission, in which the semantic understanding is enhanced by coarse-to-fine\nprocessing. Especially, a dual attention mechanism is proposed to capture both\nthe coarse and fine semantic information. Numerical experiments show the\nproposed system outperforms the benchmarks in terms of bilingual evaluation,\nsentence similarity, and robustness under various channel conditions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T07:50:35Z"}
{"aid":"http://arxiv.org/abs/2504.01471v1","title":"On the mean-field limit for the Vlasov-Poisson system","summary":"We present a probabilistic proof of the mean-field limit and propagation of\nchaos of a classical N-particle system in three dimensions with Coulomb\ninteraction force of the form $f^N(q)=\\pm\\frac{q}{|q|^3}$ and $N$-dependent\ncut-off at $|q|>N^{-\\frac{5}{12}+\\sigma}$ where $\\sigma>0$ can be chosen\narbitrarily small. This cut-off size is much smaller than the typical distance\nto the nearest neighbour. In particular, for typical initial data, we show\nconvergence of the Newtonian trajectories to the characteristics of the\nVlasov-Poisson system. The proof is based on a Gronwall estimate for the\nmaximal distance between the exact microscopic dynamics and the approximate\nmean-field dynamics. Thus our result leads to a derivation of the\nVlasov-Poisson equation from the microscopic $N$-particle dynamics with force\nterm arbitrary close to the physically relevant Coulomb force.","main_category":"math-ph","categories":"math-ph,math.DS,math.MP,physics.class-ph,G.3","published":"2025-04-02T08:24:18Z"}
{"aid":"http://arxiv.org/abs/2504.01525v1","title":"Rapid Muon Tomography for Border Security","summary":"Cosmic-ray muon tomography is a promising technique for border security\napplications, leveraging highly penetrating cosmic-ray muons and their\ninteractions with various materials to generate 3D images of large and dense\nobjects, such as shipping containers. Using scattering and absorption of muons\nas they pass through dense cargo materials, muon tomography provides a viable\nsolution for customs and border security by enabling the verification of\nshipping container declarations and preventing illegal trafficking. In this\nstudy, we utilized Monte Carlo simulations to evaluate the effectiveness of\nmuon tomography for cargo characterization and contraband detection in various\nsmuggling scenarios. Our results demonstrate that muon tomography can offers a\nnovel approach to cargo inspection, moving beyond traditional 3D image\nreconstruction. Instead, it analyzes muon scattering and absorption rates in\nreal time during scanning, enabling the prompt detection of discrepancies\nbetween actual cargo contents and declared goods within just 10 to 20 seconds.\nThis method is particularly effective for cargo consisting of uniform loads\ncomposed of a single material or product, a common practice in shipping. Unlike\ntraditional X-ray radiography, which analyzes detailed 2D images, muon\ntomography begins evaluating scatter-absorption rates within the first few\nseconds of scanning. This early assessment enables cargo evaluation long before\na statistically reliable 3D image is formed, significantly improving scanning\nthroughput without disrupting trade flow.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-02T09:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.01535v1","title":"On Robust Empirical Likelihood for Nonparametric Regression with\n  Application to Regression Discontinuity Designs","summary":"Empirical likelihood serves as a powerful tool for constructing confidence\nintervals in nonparametric regression and regression discontinuity designs\n(RDD). The original empirical likelihood framework can be naturally extended to\nthese settings using local linear smoothers, with Wilks' theorem holding only\nwhen an undersmoothed bandwidth is selected. However, the generalization of\nbias-corrected versions of empirical likelihood under more realistic conditions\nis non-trivial and has remained an open challenge in the literature. This paper\nprovides a satisfactory solution by proposing a novel approach, referred to as\nrobust empirical likelihood, designed for nonparametric regression and RDD. The\ncore idea is to construct robust weights which simultaneously achieve bias\ncorrection and account for the additional variability introduced by the\nestimated bias, thereby enabling valid confidence interval construction without\nextra estimation steps involved. We demonstrate that the Wilks' phenomenon\nstill holds under weaker conditions in nonparametric regression, sharp and\nfuzzy RDD settings. Extensive simulation studies confirm the effectiveness of\nour proposed approach, showing superior performance over existing methods in\nterms of coverage probabilities and interval lengths. Moreover, the proposed\nprocedure exhibits robustness to bandwidth selection, making it a flexible and\nreliable tool for empirical analyses. The practical usefulness is further\nillustrated through applications to two real datasets.","main_category":"math.ST","categories":"math.ST,econ.EM,stat.ME,stat.TH","published":"2025-04-02T09:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.01546v1","title":"From indirect to direct taxis by fast reaction limit","summary":"Many ecological population models consider taxis as the directed movement of\nanimals in response to a stimulus. The taxis is named direct if the animals are\nguided by the density gradient of some other population or indirect if they are\nguided by the density of a chemical secreted by individuals of the other\npopulation. Let $u$ and $v$ denote the densities of two populations and $w$ the\ndensity of the chemical secreted by individuals in the $v$ population. We\nconsider a bounded, open set $\\Omega \\subset \\mathbb{R}^N$ with regular\nboundary and prove that for the space dimension $N\\leq 2$ the solution to the\nLotka-Volterra competition model with repulsive indirect taxis and homogeneous\nNeumann boundary conditions\n  $$u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla w +\\mu_1u(1-u-a_1v)\\,,$$\n  $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,,$$\n  $$\\varepsilon ( w_t - d_w\\Delta w )= v- w\\, , $$ converges to the solution of\nrepulsive direct-taxis model: $$ u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla\nv +\\mu_1u(1-u-a_1v)\\,,$$ $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,$$ when\n$\\varepsilon\\longrightarrow 0$. For space dimension $N\\geq 3$ we use the\ncompactness argument to show that the result holds in some weak sense. A\nsimilar result is also proved for a typical prey-predator model with prey taxis\nand logistic growth of predators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T09:40:34Z"}
{"aid":"http://arxiv.org/abs/2504.01571v1","title":"Pro-DG: Procedural Diffusion Guidance for Architectural Facade\n  Generation","summary":"We present Pro-DG, a framework for procedurally controllable photo-realistic\nfacade generation that combines a procedural shape grammar with diffusion-based\nimage synthesis. Starting from a single input image, we reconstruct its facade\nlayout using grammar rules, then edit that structure through user-defined\ntransformations. As facades are inherently multi-hierarchical structures, we\nintroduce hierarchical matching procedure that aligns facade structures at\ndifferent levels which is used to introduce control maps to guide a generative\ndiffusion pipeline. This approach retains local appearance fidelity while\naccommodating large-scale edits such as floor duplication or window\nrearrangement. We provide a thorough evaluation, comparing Pro-DG against\ninpainting-based baselines and synthetic ground truths. Our user study and\nquantitative measurements indicate improved preservation of architectural\nidentity and higher edit accuracy. Our novel method is the first to integrate\nneuro-symbolically derived shape-grammars for modeling with modern generative\nmodel and highlights the broader potential of such approaches for precise and\ncontrollable image manipulation.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG","published":"2025-04-02T10:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.01595v1","title":"JWST MIRI reveals the diversity of nuclear mid-infrared spectra of\n  nearby type-2 quasars","summary":"Type-2 quasars (QSO2s) are active galactic nuclei (AGN) seen through a\nsignificant amount of dust and gas that obscures the central supermassive black\nhole and the broad line region. Here we present new mid-infrared spectra of the\ncentral kiloparsec of five optically-selected QSO2s at redshift z~0.1 obtained\nwith JWST/MIRI/MRS. These QSO2s belong to the QSOFEED sample and they have log\nLbol=45.5-46.0 erg/s, global SFRs that place them above the main sequence, and\npractically identical optical spectral shape and [OIII] luminosity, but their\nnuclear mid-infrared spectra exhibit an unexpected diversity of both continua\nand features. They show: 1) 9.7 micron silicate features going from emission\n(strength of S9.7=0.5) to relatively strong absorption (S9.7=-1.0) and 18 and\n23 micron silicates either in emission or flat. In addition, two of the QSO2s\nshow absorption bands of CO, H2O, and aliphatic grains, indicating different\nlevels of nuclear obscuration across the sample. 2) [NeV]/[NeII] ratios ranging\nfrom 0.1 to 2.1 and [NeIII]/[NeII] from 1.0 to 3.5, indicating different\ncoronal line and ionizing continuum strengths. 3) Warm molecular gas masses of\n1-4x10^7 Msun and warm-to-cold gas mass ratios of 1-2%, with molecular gas\nexcitation likely due to jet-induced shocks in J1430+1339, and to UV heating\nand/or turbulence in J1509+0434. 4) PAH emission features with equivalent\nwidths ranging from <0.002 to 0.075 micron, from which we measure a larger\ncontribution from neutral molecules (PAH 11.3/6.2=1.3-3.4) and SFRs<3-7\nMsun/yr. This unprecedented dataset allowed us to start exploring the role of\nvarious AGN and galaxy properties including ionizing continuum, obscuration,\nelectron density, and jet-ISM interactions on some of the spectral differences\nlisted above, but larger samples are now required to fully understand the\ndiversity of QSO2s' nuclear mid-infrared spectra.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T11:02:01Z"}
{"aid":"http://arxiv.org/abs/2504.01630v1","title":"On the performance of the Euler-Maruyama scheme for multidimensional\n  SDEs with discontinuous drift coefficient","summary":"We study strong approximation of $d$-dimensional stochastic differential\nequations (SDEs) with a discontinuous drift coefficient. More precisely, we\nessentially assume that the drift coefficient is piecewise Lipschitz continuous\nwith an exceptional set $\\Theta\\subset \\mathbb{R}^d$ that is an orientable\n$C^4$-hypersurface of positive reach, the diffusion coefficient is assumed to\nbe Lipschitz continuous and, in a neighborhood of $\\Theta$, both coefficients\nare bounded and the diffusion coefficient has a non-degenerate portion\northogonal to $\\Theta$.\n  In recent years, a number of results have been proven in the literature for\nstrong approximation of such SDEs and, in particular, the performance of the\nEuler-Maruyama scheme was studied. For $d=1$ and finite $\\Theta$ it was shown\nthat the Euler-Maruyama scheme achieves an $L_p$-error rate of at least $1/2$\nfor all $p\\geq 1$ as in the classical case of Lipschitz continuous\ncoefficients. For $d>1$, it was only known so far, that the Euler-Maruyama\nscheme achieves an $L_2$-error rate of at least $1/4-$ if, additionally, the\ncoefficients $\\mu$ and $\\sigma$ are globally bounded.\n  In this article, we prove that in the above setting the Euler-Maruyama scheme\nin fact achieves an $L_{p}$-error rate of at least $1/2-$ for all\n$d\\in\\mathbb{N}$ and all $p\\geq 1$. The proof of this result is based on the\nwell-known approach of transforming such an SDE into an SDE with globally\nLipschitz continuous coefficients, a new It\\^{o} formula for a class of\nfunctions which are not globally $C^2$ and a detailed analysis of the expected\ntotal time that the actual position of the time-continuous Euler-Maruyama\nscheme and its position at the preceding time point on the underlying grid are\non 'different sides' of the hypersurface $\\Theta$.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR","published":"2025-04-02T11:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.01637v1","title":"LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach","summary":"Planning methods with high adaptability to dynamic environments are crucial\nfor the development of autonomous and versatile robots. We propose a method for\nleveraging a large language model (GPT-4o) to automatically generate networks\ncapable of adapting to dynamic environments. The proposed method collects\nenvironmental \"status,\" representing conditions and goals, and uses them to\ngenerate agents. These agents are interconnected on the basis of specific\nconditions, resulting in networks that combine flexibility and generality. We\nconducted evaluation experiments to compare the networks automatically\ngenerated with the proposed method with manually constructed ones, confirming\nthe comprehensiveness of the proposed method's networks and their higher\ngenerality. This research marks a significant advancement toward the\ndevelopment of versatile planning methods applicable to robotics, autonomous\nvehicles, smart systems, and other complex environments.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-02T11:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.01638v1","title":"Convex Computations for Controlled Safety Invariant Sets of Black-box\n  Discrete-time Dynamical Systems","summary":"Identifying controlled safety invariant sets (CSISs) is essential in\nsafety-critical applications. This paper tackles the problem of identifying\nCSISs for black-box discrete-time systems, where the model is unknown and only\nlimited simulation data is accessible. Traditionally, a CSIS is defined as a\nsubset of a safe set, encompassing initial states for which a control input\nexists that keeps the system within the set at the next time step-this is\nreferred to as the one-step invariance property. However, the requirement for\none-step invariance can be equivalently translated into a stricter condition of\n``always-invariance'', meaning that there exist control inputs capable of\nkeeping the system within this set indefinitely. Such a condition may prove\noverly stringent or impractical for black-box systems, where predictions can\nbecome unreliable beyond a single time step or a limited number of finite time\nsteps. To overcome the challenges posed by black-box systems, we reformulate\nthe one-step invariance property in a ``Probably Approximately Correct'' (PAC)\nsense. This approach allows us to assess the probability that a control input\nexists to keep the system within the CSIS at the next time step, with a\npredefined level of confidence. If the system successfully remains within the\nset at the next time step, we can then reapply the invariance evaluation to the\nnew state, thereby facilitating a recursive assurance of invariance. Our method\nemploys barrier functions and scenario optimization, resulting in a linear\nprogramming method to estimate PAC CSISs. Finally, the effectiveness of our\napproach is demonstrated on several examples.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T11:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.01645v1","title":"How to write competitive proposals and job applications","summary":"Writing proposals and job applications is arguably one of the most important\ntasks in the career of a scientist. The proposed ideas must be scientifically\ncompelling, but how a proposal is planned, written, and presented can make an\nenormous difference. This Perspective is the third in a series aimed at\ntraining the writing skills of professional astronomers. In the first two\npapers we concentrated on the writing of papers, here we concentrate on how\nproposals and job applications can be optimally written and presented. We\ndiscuss how to select where to propose or apply, how to optimise your writing,\nand add notes on the potential use of artificial intelligence tools. This guide\nis aimed primarily at more junior researchers, but we hope that our\nobservations and suggestions may also be helpful for more experienced\napplicants, as well as for reviewers and funding agencies.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.ed-ph","published":"2025-04-02T11:53:45Z"}
{"aid":"http://arxiv.org/abs/2504.01651v1","title":"Nonlinear electrodynamic black holes and their role in testing modified\n  theories of gravity","summary":"The nature of black holes (BHs) and potential deviations from General\nRelativity (GR) remain key questions in astrophysics. Nonlinear electrodynamics\n(NED) offers a mechanism for constructing regular BHs that evade singularities.\nWe perform a geometrical and observational analysis of NED-inspired BHs,\nconstraining the magnetic parameter via Bayesian inference using EHT data,\nobtaining \\( q = 0.98^{+0.09}_{-0.08} \\) for M87* and \\( q = 1.10\\pm0.10 \\) for\nSgr A*. Deviations from Schwarzschild BHs manifest in horizon structure, shadow\nproperties, and lensing effects. We analyze BH shadows under plasma conditions,\nidentifying imprints of NED on strong-field processes. Future observations from\nLISA, next-generation X-ray telescopes, and EHT will further constrain these\ndeviations and provide tests for alternative gravity theories.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T12:00:35Z"}
{"aid":"http://arxiv.org/abs/2504.01655v1","title":"Q-Adapt: Adapting LMM for Visual Quality Assessment with Progressive\n  Instruction Tuning","summary":"The rapid advancement of Large Multi-modal Foundation Models (LMM) has paved\nthe way for the possible Explainable Image Quality Assessment (EIQA) with\ninstruction tuning from two perspectives: overall quality explanation, and\nattribute-wise perception answering. However, existing works usually overlooked\nthe conflicts between these two types of perception explanations during joint\ninstruction tuning, leading to insufficient perception understanding. To\nmitigate this, we propose a new paradigm for perception-oriented instruction\ntuning, i.e., Q-Adapt, which aims to eliminate the conflicts and achieve the\nsynergy between these two EIQA tasks when adapting LMM, resulting in enhanced\nmulti-faceted explanations of IQA. Particularly, we propose a progressive\ninstruction tuning strategy by dividing the adaption process of LMM for EIQA\ninto two stages, where the first stage empowers the LMM with universal\nperception knowledge tailored for two tasks using an efficient transfer\nlearning strategy, i.e., LoRA, and the second stage introduces the\ninstruction-adaptive visual prompt tuning to dynamically adapt visual features\nfor the different instructions from two tasks. In this way, our proposed\nQ-Adapt can achieve a lightweight visual quality evaluator, demonstrating\ncomparable performance and, in some instances, superior results across\nperceptual-related benchmarks and commonly-used IQA databases. The source code\nis publicly available at https://github.com/yeppp27/Q-Adapt.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-02T12:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.01670v1","title":"Introduction to dimensional reduction of fermions","summary":"We present a comprehensive pedagogical introduction to the dimensional\nreduction protocol (DRP), a versatile framework for analyzing instabilities and\ncritical points in interacting fermionic systems. The DRP simplifies the study\nof many-body problems by systematically reducing their effective spatial\ndimension while retaining essential physics. This method works for electron\ngases in a diverse array of settings: in any number of spatial dimensions, in\nthe presence of Zeeman fields, with spin-orbit coupling, including repulsive or\nattractive interactions. Focusing on two-point correlation functions, the DRP\nidentifies a minimal subspace relevant for capturing analytic properties,\nfacilitating efficient computation of critical phenomena in electronic systems.\nThis work outlines the assumptions, proof, and applications of the DRP,\nemphasizing its simplicity and broad applicability for future studies in\ncorrelated electron physics.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-02T12:17:49Z"}
{"aid":"http://arxiv.org/abs/2504.01689v1","title":"InvFussion: Bridging Supervised and Zero-shot Diffusion for Inverse\n  Problems","summary":"Diffusion Models have demonstrated remarkable capabilities in handling\ninverse problems, offering high-quality posterior-sampling-based solutions.\nDespite significant advances, a fundamental trade-off persists, regarding the\nway the conditioned synthesis is employed: Training-based methods achieve high\nquality results, while zero-shot approaches trade this with flexibility. This\nwork introduces a framework that combines the best of both worlds -- the strong\nperformance of supervised approaches and the flexibility of zero-shot methods.\nThis is achieved through a novel architectural design that seamlessly\nintegrates the degradation operator directly into the denoiser. In each block,\nour proposed architecture applies the degradation operator on the network\nactivations and conditions the output using the attention mechanism, enabling\nadaptation to diverse degradation scenarios while maintaining high performance.\nOur work demonstrates the versatility of the proposed architecture, operating\nas a general MMSE estimator, a posterior sampler, or a Neural Posterior\nPrincipal Component estimator. This flexibility enables a wide range of\ndownstream tasks, highlighting the broad applicability of our framework. The\nproposed modification of the denoiser network offers a versatile, accurate, and\ncomputationally efficient solution, demonstrating the advantages of dedicated\nnetwork architectures for complex inverse problems. Experimental results on the\nFFHQ and ImageNet datasets demonstrate state-of-the-art posterior-sampling\nperformance, surpassing both training-based and zero-shot alternatives.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.01722v1","title":"{GSR4B}: Biomass Map Super-Resolution with Sentinel-1/2 Guidance","summary":"Accurate Above-Ground Biomass (AGB) mapping at both large scale and high\nspatio-temporal resolution is essential for applications ranging from climate\nmodeling to biodiversity assessment, and sustainable supply chain monitoring.\nAt present, fine-grained AGB mapping relies on costly airborne laser scanning\nacquisition campaigns usually limited to regional scales. Initiatives such as\nthe ESA CCI map attempt to generate global biomass products from diverse\nspaceborne sensors but at a coarser resolution. To enable global,\nhigh-resolution (HR) mapping, several works propose to regress AGB from HR\nsatellite observations such as ESA Sentinel-1/2 images. We propose a novel way\nto address HR AGB estimation, by leveraging both HR satellite observations and\nexisting low-resolution (LR) biomass products. We cast this problem as Guided\nSuper-Resolution (GSR), aiming at upsampling LR biomass maps (sources) from\n$100$ to $10$ m resolution, using auxiliary HR co-registered satellite images\n(guides). We compare super-resolving AGB maps with and without guidance,\nagainst direct regression from satellite images, on the public BioMassters\ndataset. We observe that Multi-Scale Guidance (MSG) outperforms direct\nregression both for regression ($-780$ t/ha RMSE) and perception ($+2.0$ dB\nPSNR) metrics, and better captures high-biomass values, without significant\ncomputational overhead. Interestingly, unlike the RGB+Depth setting they were\noriginally designed for, our best-performing AGB GSR approaches are those that\nmost preserve the guide image texture. Our results make a strong case for\nadopting the GSR framework for accurate HR biomass mapping at scale. Our code\nand model weights are made publicly available\n(https://github.com/kaankaramanofficial/GSR4B).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.01741v1","title":"Quantum Quintom Cosmology","summary":"This work applies the principles of quantum cosmology to examine models\nincorporating a quintom field. Specifically, three distinct models are\nanalyzed: a simplified toy model, a model featuring an exponential quintom\npotential, and one where the quintom field is coupled with a negative\ncosmological constant. For each case, we study the classical trajectories\nwithin the configuration space, present solutions to the Wheeler-DeWitt\nequation in quantum cosmology, and discuss physical interpretations and\nconsequences. A key focus is the behavior of wave packets in the minisuperspace\nframework. Notably, the correspondence principle (connection between classical\nand quantum solutions) is also demonstrated.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T13:52:26Z"}
{"aid":"http://arxiv.org/abs/2504.01746v1","title":"Spans of quantum-inequality projections","summary":"A hereditarily atomic von Neumann algebra $A$ is a $W^*$ product of matrix\nalgebras, regarded as the underlying function algebra of a quantum set.\nProjections in $A\\overline{\\otimes}A^{\\circ}$ are interpreted as quantum binary\nrelations on $A$, with the supremum of all $p\\otimes (1-p)$ representing\nquantum inequality. We prove that the symmetrized weak$^*$-closed linear span\nof all such quantum-inequality projections is precisely the symmetric summand\nof the joint kernel of multiplication and opposite multiplication, a result\nvalid without the symmetrization qualification for plain matrix algebras. The\nproof exploits the symmetries of the spaces involved under the compact unitary\ngroup of $A$, and related results include a classification of those von Neumann\nalgebras (hereditarily atomic or not) for which the unitary group operates\njointly continuously with respect to the weak$^*$ topology.","main_category":"math.OA","categories":"math.OA,math.FA,math.QA,math.RA,math.RT","published":"2025-04-02T13:57:34Z"}
{"aid":"http://arxiv.org/abs/2504.01750v1","title":"Probing the Distance Duality Relation with Machine Learning and Recent\n  Data","summary":"The distance duality relation (DDR) relates two independent ways of measuring\ncosmological distances, namely the angular diameter distance and the luminosity\ndistance. These can be measured with baryon acoustic oscillations (BAO) and\nType Ia supernovae (SNe Ia), respectively. Here, we use recent DESI DR1,\nPantheon+, SH0ES and DES-SN5YR data to test this fundamental relation. We\nemploy a parametrised approach and also use model-independent Generic\nAlgorithms (GA), which are a machine learning method where functions evolve\nloosely based on biological evolution. When we use DESI and Pantheon+ data\nwithout Cepheid calibration or big bang nucleosynthesis (BBN), there is a\n$2\\sigma$ violation of the DDR in the parametrised approach. Then, we add\nhigh-redshift BBN data and the low-redshift SH0ES Cepheid calibration. This\nreflects the Hubble tension since both data sets are in tension in the standard\ncosmological model $\\Lambda$CDM. In this case, we find a significant violation\nof the DDR in the parametrised case at $6\\sigma$. Replacing the Pantheon+ SNe\nIa data by DES-SN5YR, we find similar results. For the model-independent\napproach, we find no deviation in the uncalibrated case and a small deviation\nwith BBN and Cepheids which remains at 1$\\sigma$. This shows the importance of\nconsidering model-independent approaches for the DDR.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T14:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.01759v1","title":"Hidden Markov Model Filtering with Equal Exit Probabilities","summary":"Hidden Markov Models (HMMs) provide a rigorous framework for inference in\ndynamic environments. In this work, we study the alpha-HMM algorithm motivated\nby the optimal online filtering formulation in settings where the true state\nevolves as a Markov chain with equal exit probabilities. We quantify the\ndynamics of the algorithm in stationary environments, revealing a trade-off\nbetween inference and adaptation, showing how key parameters and the quality of\nobservations affect performance. Comprehensive theoretical analysis on the\nnonlinear dynamical system that governs the evolution of the log-belief ratio\nover time and numerical experiments demonstrate that the proposed approach\neffectively balances adaptation and inference performance.","main_category":"eess.SY","categories":"eess.SY,cs.SY,stat.AP","published":"2025-04-02T14:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.01761v1","title":"Non-parametric Quantile Regression and Uniform Inference with Unknown\n  Error Distribution","summary":"This paper studies the non-parametric estimation and uniform inference for\nthe conditional quantile regression function (CQRF) with covariates exposed to\nmeasurement errors. We consider the case that the distribution of the\nmeasurement error is unknown and allowed to be either ordinary or super smooth.\nWe estimate the density of the measurement error by the repeated measurements\nand propose the deconvolution kernel estimator for the CQRF. We derive the\nuniform Bahadur representation of the proposed estimator and construct the\nuniform confidence bands for the CQRF, uniformly in the sense for all\ncovariates and a set of quantile indices, and establish the theoretical\nvalidity of the proposed inference. A data-driven approach for selecting the\ntuning parameter is also included. Monte Carlo simulations and a real data\napplication demonstrate the usefulness of the proposed method.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-02T14:16:39Z"}
{"aid":"http://arxiv.org/abs/2504.01770v1","title":"$\\mathbf{Î³^{(*)} + N(940)\\frac{1}{2}^+ \\to N(1520)\\frac{3}{2}^{-}}$\n  helicity amplitudes and transition form factors","summary":"We recently reported new results on the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+\n\\to \\Delta(1700)\\frac{3}{2}^{-}$ transition form factors using a\nsymmetry-preserving treatment of a vector$\\,\\otimes\\,$vector contact\ninteraction (SCI) within a coupled formalism based on the Dyson-Schwinger,\nBethe-Salpeter, and Faddeev equations. In this work, we extend our\ninvestigation to the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+ \\to\nN(1520)\\frac{3}{2}^{-}$ transition. Our computed transition form factors show\nreasonable agreement with experimental data at large photon virtualities.\nHowever, deviations emerge at low $Q^2$, where experimental results exhibit a\nsharper variation than theoretical predictions. This discrepancy is expected,\nas these continuum QCD analyses account only for the quark-core of baryons,\nwhile low photon virtualities are dominated by meson cloud effects. We\nanticipate that these analytical predictions, based on the simplified SCI\nframework, will serve as a valuable benchmark for more refined studies and\nQCD-based truncations that incorporate quark angular momentum and the\ncontributions of scalar and vector diquarks.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat,hep-th,nucl-th","published":"2025-04-02T14:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.01780v1","title":"Finiteness and duality of cohomology of $(\\varphi,Î“)$-modules and\n  the 6-functor formalism of locally analytic representations","summary":"Finiteness and duality of cohomology of families of\n$(\\varphi,\\Gamma)$-modules were proved by Kedlaya-Pottharst-Xiao. In this\npaper, we study solid locally analytic representations introduced by Rodrigues\nJacinto-Rodr\\'iguez Camargo in terms of analytic stacks and 6-functor\nformalisms, which are developed by Clausen-Scholze, Heyer-Mann, respectively.\nBy using this, we will provide a generalization of the result of\nKedlaya-Pottharst-Xiao, giving a new proof for cases already proved there.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T14:45:45Z"}
{"aid":"http://arxiv.org/abs/2504.01786v1","title":"BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing","summary":"3D graphics editing is crucial in applications like movie production and game\ndesign, yet it remains a time-consuming process that demands highly specialized\ndomain expertise. Automating this process is challenging because graphical\nediting requires performing a variety of tasks, each requiring distinct skill\nsets. Recently, vision-language models (VLMs) have emerged as a powerful\nframework for automating the editing process, but their development and\nevaluation are bottlenecked by the lack of a comprehensive benchmark that\nrequires human-level perception and presents real-world editing complexity. In\nthis work, we present BlenderGym, the first comprehensive VLM system benchmark\nfor 3D graphics editing. BlenderGym evaluates VLM systems through code-based 3D\nreconstruction tasks. We evaluate closed- and open-source VLM systems and\nobserve that even the state-of-the-art VLM system struggles with tasks\nrelatively easy for human Blender users. Enabled by BlenderGym, we study how\ninference scaling techniques impact VLM's performance on graphics editing\ntasks. Notably, our findings reveal that the verifier used to guide the scaling\nof generation can itself be improved through inference scaling, complementing\nrecent insights on inference scaling of LLM generation in coding and math\ntasks. We further show that inference compute is not uniformly effective and\ncan be optimized by strategically distributing it between generation and\nverification.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T14:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.01809v1","title":"Detector Response to Gravitational Wave Polarizations in Gravitational\n  Quantum Field Theory","summary":"We present an analysis of gravitational wave polarization modes within\nGravitational Quantum Field Theory (GQFT), a unified theoretical framework\nreconciling general relativity and quantum field theory. Our study focuses on\nfive fundamental polarization states predicted in GQFT: two tensor ($+,\n\\times$), two vector (x, y), and one scalar (breathing) mode, focusing on their\ndistinctive detection signatures in space-based interferometers like LISA and\nTaiji. Using first-order orbital dynamics in the Solar System Barycenter frame,\nwe identify three novel observational features: (1) characteristic interference\npatterns between polarization modes, (2) distinctive null-point signatures\nenabling mode discrimination, and (3) sky-position-dependent optimal detection\nwindows. Our approach provides complete sky coverage through polarization\nmapping while remaining fully compatible with existing mission designs, notably\navoiding the need for challenging direct breathing-mode measurements. The\nresults are presented through comprehensive sky maps, offering both theoretical\ninsights into gravitational wave polarization and practical tools for future\ndetector networks. This work establishes a new paradigm for testing fundamental\ngravity theories through their unique polarization fingerprints, with\nparticular relevance for upcoming multi-messenger gravitational wave astronomy.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-02T15:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.01816v1","title":"Random Phase Approximation Correlation Energy using Real-Space Density\n  Functional Perturbation Theory","summary":"We present a real-space method for computing the random phase approximation\n(RPA) correlation energy within Kohn-Sham density functional theory, leveraging\nthe low-rank nature of the frequency-dependent density response operator. In\nparticular, we employ a cubic scaling formalism based on density functional\nperturbation theory that circumvents the calculation of the response function\nmatrix, instead relying on the ability to compute its product with a vector\nthrough the solution of the associated Sternheimer linear systems. We develop a\nlarge-scale parallel implementation of this formalism using the subspace\niteration method in conjunction with the spectral quadrature method, while\nemploying the Kronecker product-based method for the application of the Coulomb\noperator and the conjugate orthogonal conjugate gradient method for the\nsolution of the linear systems. We demonstrate convergence with respect to key\nparameters and verify the method's accuracy by comparing with planewave\nresults. We show that the framework achieves good strong scaling to many\nthousands of processors, reducing the time to solution for a lithium hydride\nsystem with 128 electrons to around 150 seconds on 4608 processors.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-02T15:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.01858v1","title":"Investigating the Variable Continuum Lags in PG 2130+099","summary":"Broadband photometric reverberation mapping (RM) provides a measure of the\nsize of the continuum-emitting region in active galactic nuclei (AGN). Previous\nmonitoring campaigns of PG 2130+099 disagree as to whether the continuum\nemitting region size is consistent with that predicted for a standard optically\nthick geometrically thin accretion disk. We present $\\sim$6 months of\nobservations from several robotic telescopes, providing the highest cadence and\nwidest wavelength coverage photometric RM study of PG 2130+099 to date. Our\nresults indicate that inferred size of the continuum-emitting region in PG\n2130+099, like many recently observed AGN, is larger than the simplest\npredictions for an irradiated geometrically thin, optically thick accretion\ndisk. We also perform a flux-flux analysis, finding a variable spectrum broadly\nconsistent with a disk, and a constant component with enhanced\n$\\textit{i}$-band emission, potentially due to H$\\alpha$. We find some evidence\nof increasing lag with luminosity, but previous lag measurements are too\nuncertain to be definitive.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-02T16:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.01864v1","title":"On the $W$-entropy and Shannon entropy power on RCD$(K, N)$ and RCD$(K,\n  n, N)$ spaces","summary":"In this paper, we prove the $W$-entropy formula and its monotonicity for the\nheat flow on RCD$(K, N)$ and RCD$(K, n, N)$ spaces $(X, d, \\mu)$, where $K\\in\n\\mathbb{R}$, $n$ is the geometric dimension of $(X, d, \\mu)$ and $N\\geq n$. We\nalso prove the $K$-concavity of the Shannon entropy power on RCD$(K, N)$\nspaces. As an application, we derive the Shannon entropy isoperimetric\ninequality and the Stam logarithmic Sobolev inequality on RCD$(0, N)$ spaces\nwith maximal volume growth condition. Finally, we prove the rigidity theorem\nfor the Stam logarithmic Sobolev inequality with sharp constant on\nnoncollapsing RCD$(0, N)$ spaces.","main_category":"math.FA","categories":"math.FA,math.MG,math.PR","published":"2025-04-02T16:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.01897v1","title":"Threshold for Fault-tolerant Quantum Advantage with the Quantum\n  Approximate Optimization Algorithm","summary":"Optimization is often cited as a promising application of quantum computers.\nHowever, the low degree of provable quantum speedups has led prior rigorous\nend-to-end resource analyses to conclude that a quantum computer is unlikely to\nsurpass classical state-of-the-art on optimization problems under realistic\nassumptions. In this work, we compile and analyze the Quantum Approximate\nOptimization Algorithm (QAOA) combined with Amplitude Amplification (AA)\napplied to random 8-SAT at the satisfiability threshold. Our compilation\ninvolves careful optimization of circuits for Hamiltonian simulation, which may\nbe of independent interest. We use the analytical scaling of the\ntime-to-solution for QAOA identified by PRX Quantum 5, 030348 (2024) and find\nthat with QAOA depth $p=623$, QAOA+AA achieves a crossover with\nstate-of-the-art classical heuristics at 179 variables and 14.99 hours of\nruntime when executed on a surface-code-based fault-tolerant quantum computer\nwith 73.91 million physical qubits, a physical error rate of $10^{-3}$, and a\n$1~\\mu$s code cycle time. Notably, we allow the classical solver to be\nparallelized as long as its total energy consumption is equal to that required\nfor decoding in the surface code. We further show that this restriction on\nclassical solver energy consumption can be relaxed given optimistic but\nplausible reductions in physical error rates and fault-tolerance overheads,\nenabling a crossover of 2.94 hours using 8.88 million physical qubits against a\nclassical solver running on a supercomputer with $725,760$ CPU cores. These\nfindings support the hypothesis that large-scale fault-tolerant quantum\ncomputers will be useful for optimization.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T16:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.01913v1","title":"Representing Flow Fields with Divergence-Free Kernels for Reconstruction","summary":"Accurately reconstructing continuous flow fields from sparse or indirect\nmeasurements remains an open challenge, as existing techniques often suffer\nfrom oversmoothing artifacts, reliance on heterogeneous architectures, and the\ncomputational burden of enforcing physics-informed losses in implicit neural\nrepresentations (INRs). In this paper, we introduce a novel flow field\nreconstruction framework based on divergence-free kernels (DFKs), which\ninherently enforce incompressibility while capturing fine structures without\nrelying on hierarchical or heterogeneous representations. Through qualitative\nanalysis and quantitative ablation studies, we identify the matrix-valued\nradial basis functions derived from Wendland's $\\mathcal{C}^4$ polynomial\n(DFKs-Wen4) as the optimal form of analytically divergence-free approximation\nfor velocity fields, owing to their favorable numerical properties, including\ncompact support, positive definiteness, and second-order differentiablility.\nExperiments across various reconstruction tasks, spanning data compression,\ninpainting, super-resolution, and time-continuous flow inference, has\ndemonstrated that DFKs-Wen4 outperform INRs and other divergence-free\nrepresentations in both reconstruction accuracy and computational efficiency\nwhile requiring the fewest trainable parameters.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T17:13:59Z"}
{"aid":"http://arxiv.org/abs/2504.01957v1","title":"GaussianLSS -- Toward Real-world BEV Perception: Depth Uncertainty\n  Estimation via Gaussian Splatting","summary":"Bird's-eye view (BEV) perception has gained significant attention because it\nprovides a unified representation to fuse multiple view images and enables a\nwide range of down-stream autonomous driving tasks, such as forecasting and\nplanning. Recent state-of-the-art models utilize projection-based methods which\nformulate BEV perception as query learning to bypass explicit depth estimation.\nWhile we observe promising advancements in this paradigm, they still fall short\nof real-world applications because of the lack of uncertainty modeling and\nexpensive computational requirement. In this work, we introduce GaussianLSS, a\nnovel uncertainty-aware BEV perception framework that revisits\nunprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm,\nand enhances them with depth un-certainty modeling. GaussianLSS represents\nspatial dispersion by learning a soft depth mean and computing the variance of\nthe depth distribution, which implicitly captures object extents. We then\ntransform the depth distribution into 3D Gaussians and rasterize them to\nconstruct uncertainty-aware BEV features. We evaluate GaussianLSS on the\nnuScenes dataset, achieving state-of-the-art performance compared to\nunprojection-based methods. In particular, it provides significant advantages\nin speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory\ncompared to projection-based methods, while achieving competitive performance\nwith only a 0.4% IoU difference.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:59:38Z"}
{"aid":"http://arxiv.org/abs/2504.02225v1","title":"Twisted second moment of modular $L$-functions to a fixed modulus","summary":"We study asymptotically the twisted second moment of the family of modular\n$L$-functions to a fixed modulus. As an application, we establish sharp lower\nbounds for all real $k \\geq 0$ and sharp upper bounds for $k$ in the range $0\n\\leq k \\leq 1$ for the $2k$-th moment of these $L$-functions on the critical\nline.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T02:46:48Z"}
{"aid":"http://arxiv.org/abs/2504.02250v1","title":"Designing Effective Human-Swarm Interaction Interfaces: Insights from a\n  User Study on Task Performance","summary":"In this paper, we present a systematic method of design for human-swarm\ninteraction interfaces, combining theoretical insights with empirical\nevaluation. We first derive ten design principles from existing literature,\napply them to key information dimensions identified through goal-directed task\nanalysis and developed a tablet-based interface for a target search task. We\nthen conducted a user study with 31 participants where humans were required to\nguide a robotic swarm to a target in the presence of three types of hazards\nthat pose a risk to the robots: Distributed, Moving, and Spreading. Performance\nwas measured based on the proximity of the robots to the target and the number\nof deactivated robots at the end of the task. Results indicate that at least\none robot was bought closer to the target in 98% of tasks, demonstrating the\ninterface's success fulfilling the primary objective of the task. Additionally,\nin nearly 67% of tasks, more than 50% of the robots reached the target.\nMoreover, particularly better performance was noted in moving hazards.\nAdditionally, the interface appeared to help minimize robot deactivation, as\nevidenced by nearly 94% of tasks where participants managed to keep more than\n50% of the robots active, ensuring that most of the swarm remained operational.\nHowever, its effectiveness varied across hazards, with robot deactivation being\nlowest in distributed hazard scenarios, suggesting that the interface provided\nthe most support in these conditions.","main_category":"cs.HC","categories":"cs.HC,cs.RO","published":"2025-04-03T03:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.02253v1","title":"On energy-momentum tensor for gravitational waves in $f(R)$ gravity","summary":"The classical Isaacson's procedure for describing back-reaction of the\naveraged energy-momentum for high frequency gravitational waves is generalized\nto $f(R)$ gravity case. From the beginning it is assumed that an initial\nbackground could be arbitrary one. By next steps it is restricted to de Sitter\nspace that is a novelty for the study of a back-reaction in $f(R)$ gravity.\nConsideration of the de Sitter space as a background spacetime allows us to\nprovide the averaging procedure completely. Using the results on the de Sitter\nspace and generalizing the Isaacson procedure, we construct the averaged\nenergy-momentum on an additionally curved (averaged) background. Relations of\nparameters, which preserve the de Sitter picture, and which disturb it are\ngiven. Our results generalize results of previous authors who use flat\n(Minkowski) spacetime as the beginning background in $f(R)$ gravity.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-03T03:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.02275v1","title":"Enhancing Customer Contact Efficiency with Graph Neural Networks in\n  Credit Card Fraud Detection Workflow","summary":"Credit card fraud has been a persistent issue since the last century, causing\nsignificant financial losses to the industry. The most effective way to prevent\nfraud is by contacting customers to verify suspicious transactions. However,\nwhile these systems are designed to detect fraudulent activity, they often\nmistakenly flag legitimate transactions, leading to unnecessary declines that\ndisrupt the user experience and erode customer trust. Frequent false positives\ncan frustrate customers, resulting in dissatisfaction, increased complaints,\nand a diminished sense of security. To address these limitations, we propose a\nfraud detection framework incorporating Relational Graph Convolutional Networks\n(RGCN) to enhance the accuracy and efficiency of identifying fraudulent\ntransactions. By leveraging the relational structure of transaction data, our\nmodel reduces the need for direct customer confirmation while maintaining high\ndetection performance. Our experiments are conducted using the IBM credit card\ntransaction dataset to evaluate the effectiveness of this approach.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T04:50:45Z"}
{"aid":"http://arxiv.org/abs/2504.02292v1","title":"Unifying Different Theories of Conformal Prediction","summary":"This paper presents a unified framework for understanding the methodology and\ntheory behind several different methods in the conformal prediction literature,\nwhich includes standard conformal prediction (CP), weighted conformal\nprediction (WCP), nonexchangeable conformal prediction (NexCP), and\nrandomly-localized conformal prediction (RLCP), among others. At the crux of\nour framework is the idea that conformal methods are based on revealing partial\ninformation about the data at hand, and positing a conditional distribution for\nthe data given the partial information. Different methods arise from different\nchoices of partial information, and of the corresponding (approximate)\nconditional distribution. In addition to recovering and unifying existing\nresults, our framework leads to both new theoretical guarantees for existing\nmethods, and new extensions of the conformal methodology.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-03T05:46:26Z"}
{"aid":"http://arxiv.org/abs/2504.02299v1","title":"Asymmetric graph alignment and the phase transition for asymmetric tree\n  correlation testing","summary":"Graph alignment - identifying node correspondences between two graphs - is a\nfundamental problem with applications in network analysis, biology, and privacy\nresearch. While substantial progress has been made in aligning correlated\nErd\\H{o}s-R\\'enyi graphs under symmetric settings, real-world networks often\nexhibit asymmetry in both node numbers and edge densities. In this work, we\nintroduce a novel framework for asymmetric correlated Erd\\H{o}s-R\\'enyi graphs,\ngeneralizing existing models to account for these asymmetries. We conduct a\nrigorous theoretical analysis of graph alignment in the sparse regime, where\nlocal neighborhoods exhibit tree-like structures. Our approach leverages tree\ncorrelation testing as the central tool in our polynomial-time algorithm,\nMPAlign, which achieves one-sided partial alignment under certain conditions.\n  A key contribution of our work is characterizing these conditions under which\nasymmetric tree correlation testing is feasible: If two correlated graphs $G$\nand $G'$ have average degrees $\\lambda s$ and $\\lambda s'$ respectively, where\n$\\lambda$ is their common density and $s,s'$ are marginal correlation\nparameters, their tree neighborhoods can be aligned if $ss' > \\alpha$, where\n$\\alpha$ denotes Otter's constant and $\\lambda$ is supposed large enough. The\nfeasibility of this tree comparison problem undergoes a sharp phase transition\nsince $ss' \\leq \\alpha$ implies its impossibility. These new results on tree\ncorrelation testing allow us to solve a class of random subgraph isomorphism\nproblems, resolving an open problem in the field.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-03T06:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.02346v1","title":"Repositioning, Ride-matching, and Abandonment in On-demand Ride-hailing\n  Platforms: A Mean Field Game Approach","summary":"The on-demand ride-hailing industry has experienced rapid growth,\ntransforming transportation norms worldwide. Despite improvements in efficiency\nover traditional taxi services, significant challenges remain, including\ndrivers' strategic repositioning behavior, customer abandonment, and\ninefficiencies in dispatch algorithms. To address these issues, we introduce a\ncomprehensive mean field game model that systematically analyzes the dynamics\nof ride-hailing platforms by incorporating driver repositioning across multiple\nregions, customer abandonment behavior, and platform dispatch algorithms. Using\nthis framework, we identify all possible mean field equilibria as the\nKarush-Kuhn-Tucker (KKT) points of an associated optimization problem. Our\nanalysis reveals the emergence of multiple equilibria, including the\ninefficient \"Wild Goose Chase\" one, characterized by drivers pursuing distant\nrequests, leading to suboptimal system performance. To mitigate these\ninefficiencies, we propose a novel two-matching-radius nearest-neighbor\ndispatch algorithm that eliminates undesirable equilibria and ensures a unique\nmean field equilibrium for multi-region systems. The algorithm dynamically\nadjusts matching radii based on driver supply rates, optimizing pick-up times\nand waiting times for drivers while maximizing request completion rates.\nNumerical experiments and simulation results show that our proposed algorithm\nreduces customer abandonment, minimizes waiting times for both customers and\ndrivers, and improves overall platform efficiency.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-03T07:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.02361v1","title":"MG-Gen: Single Image to Motion Graphics Generation with Layer\n  Decomposition","summary":"General image-to-video generation methods often produce suboptimal animations\nthat do not meet the requirements of animated graphics, as they lack active\ntext motion and exhibit object distortion. Also, code-based animation\ngeneration methods typically require layer-structured vector data which are\noften not readily available for motion graphic generation. To address these\nchallenges, we propose a novel framework named MG-Gen that reconstructs data in\nvector format from a single raster image to extend the capabilities of\ncode-based methods to enable motion graphics generation from a raster image in\nthe framework of general image-to-video generation. MG-Gen first decomposes the\ninput image into layer-wise elements, reconstructs them as HTML format data and\nthen generates executable JavaScript code for the reconstructed HTML data. We\nexperimentally confirm that \\ours{} generates motion graphics while preserving\ntext readability and input consistency. These successful results indicate that\ncombining layer decomposition and animation code generation is an effective\nstrategy for motion graphics generation.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-03T07:52:12Z"}
{"aid":"http://arxiv.org/abs/2504.02371v1","title":"Schur roots and tilting modules of acyclic quivers over commutative\n  rings","summary":"Let $Q$ be a finite acyclic quiver and $A_Q$ the cluster algebra of $Q$. It\nis well-known that for each field $k$, the additive equivalence classes of\nsupport tilting $kQ$-modules correspond bijectively with the clusters of $A_Q$.\nThe aim of this paper is to generalize this result to any ring indecomposable\ncommutative Noetherian ring $R$, that is, the additive equivalence classes of\n2-term silting complexes of $RQ$ correspond bijectively with the clusters of\n$A_Q$. As an application, for a Dynkin quiver $Q$, we prove that the torsion\nclasses of $\\mathrm{mod} RQ$ corresponds bijectively with the order preserving\nmaps from $\\mathrm{Spec} R$ to the set of clusters.","main_category":"math.RT","categories":"math.RT,math.AC,math.RA","published":"2025-04-03T08:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.02393v1","title":"Revealing the microscopic mechanism of deuteron formation at the LHC","summary":"The formation of light (anti)nuclei with mass number A of a few units (e.g.,\nd, $^3$He, and $^4$He) in high-energy hadronic collisions presents a\nlongstanding mystery in nuclear physics [1,2]. It is not clear how nuclei bound\nby a few MeV can emerge in environments characterized by temperatures above 100\nMeV [3-5], about 100,000 times hotter than the center of the Sun. Despite\nextensive studies, this question remained unanswered. The ALICE Collaboration\nnow addresses it with a novel approach using deuteron-pion momentum\ncorrelations in proton-proton (pp) collisions at the Large Hadron Collider\n(LHC). Our results provide model-independent evidence that about 80% of the\nobserved (anti)deuterons are produced in nuclear fusion reactions [6] following\nthe decay of short-lived resonances, such as the $\\Delta (1232)$. These\nfindings resolve a crucial gap in our understanding of nucleosynthesis in\nhadronic collisions. Beyond answering the fundamental question on how nuclei\nare formed in hadronic collisions, the results can be employed in the modeling\nof the production of light and heavy nuclei in cosmic rays [7] and dark matter\ndecays [8,9].","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T08:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.02429v1","title":"A Multi-Level Sentiment Analysis Framework for Financial Texts","summary":"Existing financial sentiment analysis methods often fail to capture the\nmulti-faceted nature of risk in bond markets due to their single-level approach\nand neglect of temporal dynamics. We propose Multi-Level Sentiment Analysis\nbased on pre-trained language models (PLMs) and large language models (LLMs), a\nnovel framework that systematically integrates firm-specific micro-level\nsentiment, industry-specific meso-level sentiment, and duration-aware smoothing\nto model the latency and persistence of textual impact. Applying our framework\nto the comprehensive Chinese bond market corpus constructed by us (2013-2023,\n1.39M texts), we extracted a daily composite sentiment index. Empirical results\nshow statistically measurable improvements in credit spread forecasting when\nincorporating sentiment (3.25% MAE and 10.96% MAPE reduction), with sentiment\nshifts closely correlating with major social risk events and firm-specific\ncrises. This framework provides a more nuanced understanding of sentiment\nacross different market levels while accounting for the temporal evolution of\nsentiment effects.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T09:35:07Z"}
{"aid":"http://arxiv.org/abs/2504.02473v1","title":"Adaptive path planning for efficient object search by UAVs in\n  agricultural fields","summary":"This paper presents an adaptive path planner for object search in\nagricultural fields using UAVs. The path planner uses a high-altitude coverage\nflight path and plans additional low-altitude inspections when the detection\nnetwork is uncertain. The path planner was evaluated in an offline simulation\nenvironment containing real-world images. We trained a YOLOv8 detection network\nto detect artificial plants placed in grass fields to showcase the potential of\nour path planner. We evaluated the effect of different detection certainty\nmeasures, optimized the path planning parameters, investigated the effects of\nlocalization errors and different numbers of objects in the field. The YOLOv8\ndetection confidence worked best to differentiate between true and false\npositive detections and was therefore used in the adaptive planner. The optimal\nparameters of the path planner depended on the distribution of objects in the\nfield, when the objects were uniformly distributed, more low-altitude\ninspections were needed compared to a non-uniform distribution of objects,\nresulting in a longer path length. The adaptive planner proved to be robust\nagainst localization uncertainty. When increasing the number of objects, the\nflight path length increased, especially when the objects were uniformly\ndistributed. When the objects were non-uniformly distributed, the adaptive path\nplanner yielded a shorter path than a low-altitude coverage path, even with\nhigh number of objects. Overall, the presented adaptive path planner allowed to\nfind non-uniformly distributed objects in a field faster than a coverage path\nplanner and resulted in a compatible detection accuracy. The path planner is\nmade available at https://github.com/wur-abe/uav_adaptive_planner.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-03T10:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.02478v1","title":"MG-MotionLLM: A Unified Framework for Motion Comprehension and\n  Generation across Multiple Granularities","summary":"Recent motion-aware large language models have demonstrated promising\npotential in unifying motion comprehension and generation. However, existing\napproaches primarily focus on coarse-grained motion-text modeling, where text\ndescribes the overall semantics of an entire motion sequence in just a few\nwords. This limits their ability to handle fine-grained motion-relevant tasks,\nsuch as understanding and controlling the movements of specific body parts. To\novercome this limitation, we pioneer MG-MotionLLM, a unified motion-language\nmodel for multi-granular motion comprehension and generation. We further\nintroduce a comprehensive multi-granularity training scheme by incorporating a\nset of novel auxiliary tasks, such as localizing temporal boundaries of motion\nsegments via detailed text as well as motion detailed captioning, to facilitate\nmutual reinforcement for motion-text modeling across various levels of\ngranularity. Extensive experiments show that our MG-MotionLLM achieves superior\nperformance on classical text-to-motion and motion-to-text tasks, and exhibits\npotential in novel fine-grained motion comprehension and editing tasks. Project\npage: CVI-SZU/MG-MotionLLM","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:53:41Z"}
{"aid":"http://arxiv.org/abs/2504.02537v1","title":"Blockchain and Distributed Ledger Technologies for Cyberthreat\n  Intelligence Sharing","summary":"Cyberthreat intelligence sharing is a critical aspect of cybersecurity, and\nit is essential to understand its definition, objectives, benefits, and impact\non society. Blockchain and Distributed Ledger Technology (DLT) are emerging\ntechnologies that have the potential to transform intelligence sharing. This\npaper aims to provide a comprehensive understanding of intelligence sharing and\nthe role of blockchain and DLT in enhancing it. The paper addresses questions\nrelated to the definition, objectives, benefits, and impact of intelligence\nsharing and provides a review of the existing literature. Additionally, the\npaper explores the challenges associated with blockchain and DLT and their\npotential impact on security and privacy. The paper also discusses the use of\nDLT and blockchain in security and intelligence sharing and highlights the\nassociated challenges and risks. Furthermore, the paper examines the potential\nimpact of a National Cybersecurity Strategy on addressing cybersecurity risks.\nFinally, the paper explores the experimental set up required for implementing\nblockchain and DLT for intelligence sharing and discusses the curricular\nramifications of intelligence sharing.","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-03T12:38:42Z"}
{"aid":"http://arxiv.org/abs/2504.02544v1","title":"Fourier Sliced-Wasserstein Embedding for Multisets and Measures","summary":"We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T12:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.02550v1","title":"Enhanced Permeability Estimation in Microporous Rocks Using a Hybrid\n  Macropore-Darcy Approach","summary":"This study presents a novel workflow for constructing hybrid macropore-Darcy\nmodels from micro-CT images of microporous rocks. In our approach, macropore\nnetworks are extracted using established methods, while the microporosity is\ncharacterised through segmented phase classification and incorporated into the\nmodel as Darcy cells. Effectively, Darcy cells capture the micro scale\nconnectivity variations that are missing in the macroscopic networks. This dual\nentity model thus incorporates both the conventional macroscopic pore structure\nand the critical flow pathways present in the under-resolved microporous\nregions. The proposed workflow is rigorously validated by comparing the\npermeability estimates with direct numerical simulation (DNS) results and\nexperimental measurements. Our findings demonstrate that this hybrid approach\nreliably reproduces fluid flow behaviour in complex porous media while\nsignificantly reducing computational demands, offering a promising tool for\nadvanced groundwater modelling and water resource management.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T13:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.02612v1","title":"Fine-Tuning Visual Autoregressive Models for Subject-Driven Generation","summary":"Recent advances in text-to-image generative models have enabled numerous\npractical applications, including subject-driven generation, which fine-tunes\npretrained models to capture subject semantics from only a few examples. While\ndiffusion-based models produce high-quality images, their extensive denoising\nsteps result in significant computational overhead, limiting real-world\napplicability. Visual autoregressive~(VAR) models, which predict next-scale\ntokens rather than spatially adjacent ones, offer significantly faster\ninference suitable for practical deployment. In this paper, we propose the\nfirst VAR-based approach for subject-driven generation. However, na\\\"{\\i}ve\nfine-tuning VAR leads to computational overhead, language drift, and reduced\ndiversity. To address these challenges, we introduce selective layer tuning to\nreduce complexity and prior distillation to mitigate language drift.\nAdditionally, we found that the early stages have a greater influence on the\ngeneration of subject than the latter stages, which merely synthesize local\ndetails. Based on this finding, we propose scale-wise weighted tuning, which\nprioritizes coarser resolutions for promoting the model to focus on the\nsubject-relevant information instead of local details. Extensive experiments\nvalidate that our method significantly outperforms diffusion-based baselines\nacross various metrics and demonstrates its practical usage.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:12:55Z"}
{"aid":"http://arxiv.org/abs/2504.02628v1","title":"Towards Computation- and Communication-efficient Computational Pathology","summary":"Despite the impressive performance across a wide range of applications,\ncurrent computational pathology models face significant diagnostic efficiency\nchallenges due to their reliance on high-magnification whole-slide image\nanalysis. This limitation severely compromises their clinical utility,\nespecially in time-sensitive diagnostic scenarios and situations requiring\nefficient data transfer. To address these issues, we present a novel\ncomputation- and communication-efficient framework called Magnification-Aligned\nGlobal-Local Transformer (MAGA-GLTrans). Our approach significantly reduces\ncomputational time, file transfer requirements, and storage overhead by\nenabling effective analysis using low-magnification inputs rather than\nhigh-magnification ones. The key innovation lies in our proposed magnification\nalignment (MAGA) mechanism, which employs self-supervised learning to bridge\nthe information gap between low and high magnification levels by effectively\naligning their feature representations. Through extensive evaluation across\nvarious fundamental CPath tasks, MAGA-GLTrans demonstrates state-of-the-art\nclassification performance while achieving remarkable efficiency gains: up to\n10.7 times reduction in computational time and over 20 times reduction in file\ntransfer and storage requirements. Furthermore, we highlight the versatility of\nour MAGA framework through two significant extensions: (1) its applicability as\na feature extractor to enhance the efficiency of any CPath architecture, and\n(2) its compatibility with existing foundation models and\nhistopathology-specific encoders, enabling them to process low-magnification\ninputs with minimal information loss. These advancements position MAGA-GLTrans\nas a particularly promising solution for time-sensitive applications,\nespecially in the context of intraoperative frozen section diagnosis where both\naccuracy and efficiency are paramount.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T14:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.02635v1","title":"Continuous two-valued discrete-time dynamical systems and actions of\n  two-valued groups","summary":"We study continuous 2-valued dynamical systems with discrete time (dynamics)\non $\\mathbb{C}$. The main question addressed is whether a 2-valued dynamics can\nbe defined by the action of a 2-valued group. We construct a class of strongly\ninvertible continuous 2-valued dynamics on $\\mathbb{C}$ such that none of these\ndynamics can be given by the action of any 2-valued group. We also construct an\nexample of a continuous 2-valued dynamics on $\\mathbb{C}$ that is not strongly\ninvertible but can be defined by the action of a 2-valued group.","main_category":"math.GR","categories":"math.GR,math.DS,math.GT","published":"2025-04-03T14:32:54Z"}
{"aid":"http://arxiv.org/abs/2504.02659v1","title":"Spectropolarimetry for Discerning Geometry and Structure in\n  Circumstellar Media of Hot Massive Stars","summary":"Spectropolarimetric techniques are a mainstay of astrophysical inquiry,\nranging from Solar System objects to the Cosmic Background Radiation. This\nreview highlights applications of stellar polarimetry for massive hot stars,\nparticularly in the context of ultraviolet (UV) spaceborne missions. The\nprevalence of binarity in the massive star population and uncertainties\nregarding the degree of rotational criticality among hot stars raises important\nquestions about stellar interactions, interior structure, and even the\nlifetimes of evolutionary phases. These uncertainties have consequences for\nstellar population synthesis calculations. Spectropolarimetry is a key tool for\nextracting information about stellar and binary geometries. We review\nmethodologies involving electron scattering in circumstellar envelopes; gravity\ndarkening from rapid rotation; spectral line effects including the (a) \"line\neffect\", (b) Ohman effect, and (c) Hanle effect; and the imprint of\ninterstellar polarization on measurements. Finally, we describe the Polstar UV\nspectropolarimetric SMEX mission concept as one means for employing these\ndiagnostics to clarify the state of high rotation and its impacts for massive\nstars.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.IM","published":"2025-04-03T14:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.02663v1","title":"Development of Automated Data Quality Assessment and Evaluation Indices\n  by Analytical Experience","summary":"The societal need to leverage third-party data has driven the\ndata-distribution market and increased the importance of data quality\nassessment (DQA) in data transactions between organizations. However, DQA\nrequires expert knowledge of raw data and related data attributes, which\nhinders consensus-building in data purchasing. This study focused on the\ndifferences in DQAs between experienced and inexperienced data handlers. We\nperformed two experiments: The first was a questionnaire survey involving 41\nparticipants with varying levels of data-handling experience, who evaluated 12\ndata samples using 10 predefined indices with and without quality metadata\ngenerated by the automated tool. The second was an eye-tracking experiment to\nreveal the viewing behavior of participants during data evaluation. It was\nrevealed that using quality metadata generated by the automated tool can reduce\nmisrecognition in DQA. While experienced data handlers rated the quality\nmetadata highly, semi-experienced users gave it the lowest ratings. This study\ncontributes to enhancing data understanding within organizations and promoting\nthe distribution of valuable data by proposing an automated tool to support\nDQAs.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.02668v1","title":"Two-Stage nnU-Net for Automatic Multi-class Bi-Atrial Segmentation from\n  LGE-MRIs","summary":"Late gadolinium enhancement magnetic resonance imaging (LGE-MRI) is used to\nvisualise atrial fibrosis and scars, providing important information for\npersonalised atrial fibrillation (AF) treatments. Since manual analysis and\ndelineations of these images can be both labour-intensive and subject to\nvariability, we develop an automatic pipeline to perform segmentation of the\nleft atrial (LA) cavity, the right atrial (RA) cavity, and the wall of both\natria on LGE-MRI. Our method is based on a two-stage nnU-Net architecture,\ncombining 2D and 3D convolutional networks, and incorporates adaptive histogram\nequalisation to improve tissue contrast in the input images and morphological\noperations on the output segmentation maps. We achieve Dice similarity\ncoefficients of 0.92 +/- 0.03, 0.93 +/- 0.03, 0.71 +/- 0.05 and 95% Hausdorff\ndistances of (3.89 +/- 6.67) mm, (4.42 +/- 1.66) mm and (3.94 +/- 1.83) mm for\nLA, RA, and wall, respectively. The accurate delineation of the LA, RA and the\nmyocardial wall is the first step in analysing atrial structure in\ncardiovascular patients, especially those with AF. This can allow clinicians to\nprovide adequate and personalised treatment plans in a timely manner.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T15:08:33Z"}
{"aid":"http://arxiv.org/abs/2504.02703v1","title":"Uncovering shifts in the history of Physics education: a systematic,\n  NLP-based, thematic analysis of articles from The Physics Teacher and Physics\n  Education journals (1966-2019)","summary":"This study explores the thematic evolution of articles in The Physics Teacher\nand Physics Education journals, over a critical period in modern history, from\nthe Cold War era to the pre-pandemic world (1966 - 2019). Using an NLP-based\ninductive topic modeling approach, we identify recurring themes that have\nshaped the physics education literature, including content-based topics,\nteaching methodologies, laboratory practices, curriculum development, and the\ninfluence of Physics Education Research (PER). Our findings reveal both\noverarching trends and distinct thematic preferences between the journals.\nPhysics Education has historically emphasized curriculum structures, social\naspects of education, and interdisciplinary connections, whereas The Physics\nTeacher has focused more on pedagogical strategies, demonstrations, and\npractical teaching tools. Over the past three decades, both journals have\nincreasingly incorporated discussions on technology, computation, and\nPER-driven instructional practices. By tracing these developments over five\ndecades, this study provides a broader perspective on how physics education has\nresponded to changing educational priorities, technological advancements, and\nresearch developments.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-03T15:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.02717v1","title":"Clustering in a preferential attachment network with triangles","summary":"We study a generalization of the affine preferential attachment model where\ntriangles are randomly added to the graph. We show that the model exhibits an\nasymptotically power-law degree distribution with adjustable parameter\n$\\gamma\\in (1,\\infty)$, and positive clustering. However, the clustering\nbehaviour depends on how it is measured. With high probability, the average\nlocal clustering coefficient remains positive, independently of $\\gamma$,\nwhereas the expectation of the global clustering coefficient does not vanish\nonly when $\\gamma>3$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T16:02:27Z"}
{"aid":"http://arxiv.org/abs/2504.02735v1","title":"Pushing the Limit of PPG Sensing in Sedentary Conditions by Addressing\n  Poor Skin-sensor Contact","summary":"Photoplethysmography (PPG) is a widely used non-invasive technique for\nmonitoring cardiovascular health and various physiological parameters on\nconsumer and medical devices. While motion artifacts are well-known challenges\nin dynamic settings, suboptimal skin-sensor contact in sedentary conditions - a\ncritical issue often overlooked in existing literature - can distort PPG signal\nmorphology, leading to the loss or shift of essential waveform features and\ntherefore degrading sensing performance. In this work, we propose CP-PPG, a\nnovel approach that transforms Contact Pressure-distorted PPG signals into ones\nwith the ideal morphology. CP-PPG incorporates a novel data collection\napproach, a well-crafted signal processing pipeline, and an advanced deep\nadversarial model trained with a custom PPG-aware loss function. We validated\nCP-PPG through comprehensive evaluations, including 1) morphology\ntransformation performance on our self-collected dataset, 2) downstream\nphysiological monitoring performance on public datasets, and 3) in-the-wild\nperformance. Extensive experiments demonstrate substantial and consistent\nimprovements in signal fidelity (Mean Absolute Error: 0.09, 40% improvement\nover the original signal) as well as downstream performance across all\nevaluations in Heart Rate (HR), Heart Rate Variability (HRV), Respiration Rate\n(RR), and Blood Pressure (BP) estimation (on average, 21% improvement in HR;\n41-46% in HRV; 6% in RR; and 4-5% in BP). These findings highlight the critical\nimportance of addressing skin-sensor contact issues for accurate and dependable\nPPG-based physiological monitoring. Furthermore, CP-PPG can serve as a generic,\nplug-in API to enhance PPG signal quality.","main_category":"cs.HC","categories":"cs.HC,cs.LG","published":"2025-04-03T16:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.02758v1","title":"ALMA uncovers optically thin and multi-component CO gas in the\n  outflowing circumnuclear disk of NGC1068","summary":"Active galactic nuclei (AGNs) influence their host galaxies through winds and\njets that can drive molecular outflows, traceable with CO line emissions using\nthe Atacama Large Millimeter Array (ALMA). Recent studies leveraging ALMA data\nhave proposed a three-dimensional outflow geometry in the nearby Seyfert II\ngalaxy NGC 1068, a key target for AGN unification theories. Using ALMA\nobservations of CO(2-1), CO(3-2), and CO(6-5) transitions at roughly 0.1\narcseconds (approximately 7 parsecs) resolution, we analyzed the temperature,\ndensity, and kinematics of NGC 1068's circumnuclear disk (CND), focusing on the\nmolecular outflow. Through local thermodynamic equilibrium (LTE) analysis, we\nderived column densities and rotational temperatures, indicating optically thin\ngas and CO-to-H2 (XCO) conversion factors between 4.8 and 9.6 times smaller\nthan the Milky Way value. The inferred molecular mass outflow rate is mostly\nbelow 5.5 solar masses per year, with the dominant contribution northeast of\nthe AGN. After subtracting the rotation curve of the CND, we modeled averaged\nline profiles in each region using single and multi-component Gaussian fits.\nSeveral profiles within or near the AGN wind bicone required multiple\ncomponents with significant velocity shifts, suggesting multi-component complex\noutflow kinematics. We observe lateral variation in CO kinematics along the AGN\nwind bicone and a misalignment between the molecular and ionized outflow\ndirections. These results imply that the dynamic impact of the ionized AGN wind\non the molecular gas in the CND may be limited. However, the molecular outflow\nshows a complex, asymmetric structure.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.02760v1","title":"Topological groupoids with involution and real algebraic stacks","summary":"To a topological groupoid endowed with an involution, we associate a\ntopological groupoid of fixed points, generalizing the fixed-point subspace of\na topological space with involution. We prove that when the topological\ngroupoid with involution arises from a Deligne-Mumford stack over $\\mathbb{R}$,\nthis fixed locus coincides with the real locus of the stack. This provides a\ntopological framework to study real algebraic stacks, and in particular real\nmoduli spaces. Finally, we propose a Smith-Thom type conjecture in this\nsetting, generalizing the Smith-Thom inequality for topological spaces endowed\nwith an involution.","main_category":"math.AG","categories":"math.AG,math.AT,math.GN","published":"2025-04-03T16:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.02821v1","title":"Sparse Autoencoders Learn Monosemantic Features in Vision-Language\n  Models","summary":"Sparse Autoencoders (SAEs) have recently been shown to enhance\ninterpretability and steerability in Large Language Models (LLMs). In this\nwork, we extend the application of SAEs to Vision-Language Models (VLMs), such\nas CLIP, and introduce a comprehensive framework for evaluating monosemanticity\nin vision representations. Our experimental results reveal that SAEs trained on\nVLMs significantly enhance the monosemanticity of individual neurons while also\nexhibiting hierarchical representations that align well with expert-defined\nstructures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that\napplying SAEs to intervene on a CLIP vision encoder, directly steer output from\nmultimodal LLMs (e.g., LLaVA) without any modifications to the underlying\nmodel. These findings emphasize the practicality and efficacy of SAEs as an\nunsupervised approach for enhancing both the interpretability and control of\nVLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-03T17:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.02823v1","title":"STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage\n  Security Inspection","summary":"Advancements in Computer-Aided Screening (CAS) systems are essential for\nimproving the detection of security threats in X-ray baggage scans. However,\ncurrent datasets are limited in representing real-world, sophisticated threats\nand concealment tactics, and existing approaches are constrained by a\nclosed-set paradigm with predefined labels. To address these challenges, we\nintroduce STCray, the first multimodal X-ray baggage security dataset,\ncomprising 46,642 image-caption paired scans across 21 threat categories,\ngenerated using an X-ray scanner for airport security. STCray is meticulously\ndeveloped with our specialized protocol that ensures domain-aware, coherent\ncaptions, that lead to the multi-modal instruction following data in X-ray\nbaggage security. This allows us to train a domain-aware visual AI assistant\nnamed STING-BEE that supports a range of vision-language tasks, including scene\ncomprehension, referring threat localization, visual grounding, and visual\nquestion answering (VQA), establishing novel baselines for multi-modal learning\nin X-ray baggage security. Further, STING-BEE shows state-of-the-art\ngeneralization in cross-domain settings. Code, data, and models are available\nat https://divs1159.github.io/STING-BEE/.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T17:59:12Z"}
{"aid":"http://arxiv.org/abs/2504.04718v1","title":"T1: Tool-integrated Self-verification for Test-time Compute Scaling in\n  Small Language Models","summary":"Recent studies have demonstrated that test-time compute scaling effectively\nimproves the performance of small language models (sLMs). However, prior\nresearch has mainly examined test-time compute scaling with an additional\nlarger model as a verifier, leaving self-verification by sLMs underexplored. In\nthis work, we investigate whether sLMs can reliably self-verify their outputs\nunder test-time scaling. We find that even with knowledge distillation from\nlarger verifiers, sLMs struggle with verification tasks requiring memorization,\nsuch as numerical calculations and fact-checking. To address this limitation,\nwe propose Tool-integrated self-verification (T1), which delegates\nmemorization-heavy verification steps to external tools, such as a code\ninterpreter. Our theoretical analysis shows that tool integration reduces\nmemorization demands and improves test-time scaling performance. Experiments on\nthe MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under\ntest-time scaling outperforms the significantly larger Llama-3.1 8B model.\nMoreover, T1 generalizes effectively to both mathematical (MATH500) and\nmulti-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the\npotential of tool integration to substantially improve the self-verification\nabilities of sLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T04:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.04727v1","title":"Regression Model for Measurement of Wound Dimensions by Webcam Scanners\n  and Time-of-Flight Sensors","summary":"One use of image processing is for medical equipment such as wound\nidentification. This technology is carried out non-invasively by taking images\nso as to avoid direct touch with the wound thereby reducing the possibility of\ninfection. The images obtained using the RGB camera will be used for color\nsegmentation which will measure the wound dimensions. However, the image data\nis in the form of a raster, the distance will affect the pixel size. Therefore,\nit is necessary to consider the distance of the camera measurement to the\nobject. The time-of-flight (ToF) method with a lidar sensor is used to\ncalculate the distance of the camera to the object. It is necessary to\ncalculate the ratio of the distance to the number of pixels obtained so that\nthe value is always consistent. This study analyzed the use of appropriate\nratios and regression systems on a webcam and a lidar sensor for measuring\nwound dimensions. The results of the study show that there is a regression\nmodel with a second-order polynomial relationship for the distance and number\nof pixels obtained consistently with an error value of less than 5% which shows\nvery good results","main_category":"physics.comp-ph","categories":"physics.comp-ph,physics.ins-det","published":"2025-04-07T04:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.04734v1","title":"Teaching Data Science Students to Sketch Privacy Designs through\n  Heuristics (Extended Technical Report)","summary":"Recent studies reveal that experienced data practitioners often draw sketches\nto facilitate communication around privacy design concepts. However, there is\nlimited understanding of how we can help novice students develop such\ncommunication skills. This paper studies methods for lowering novice data\nscience students' barriers to creating high-quality privacy sketches. We first\nconducted a need-finding study (N=12) to identify barriers students face when\nsketching privacy designs. We then used a human-centered design approach to\nguide the method development, culminating in three simple, text-based\nheuristics. Our user studies with 24 data science students revealed that simply\npresenting three heuristics to the participants at the beginning of the study\ncan enhance the coverage of privacy-related design decisions in sketches,\nreduce the mental effort required for creating sketches, and improve the\nreadability of the final sketches.","main_category":"cs.HC","categories":"cs.HC,cs.CR,cs.CY","published":"2025-04-07T05:12:21Z"}
{"aid":"http://arxiv.org/abs/2504.04739v1","title":"MedGNN: Capturing the Links Between Urban Characteristics and Medical\n  Prescriptions","summary":"Understanding how urban socio-demographic and environmental factors relate\nwith health is essential for public health and urban planning. However,\ntraditional statistical methods struggle with nonlinear effects, while machine\nlearning models often fail to capture geographical (nearby areas being more\nsimilar) and topological (unequal connectivity between places) effects in an\ninterpretable way. To address this, we propose MedGNN, a spatio-topologically\nexplicit framework that constructs a 2-hop spatial graph, integrating\npositional and locational node embeddings with urban characteristics in a graph\nneural network. Applied to MEDSAT, a comprehensive dataset covering over 150\nenvironmental and socio-demographic factors and six prescription outcomes\n(depression, anxiety, diabetes, hypertension, asthma, and opioids) across 4,835\nGreater London neighborhoods, MedGNN improved predictions by over 25% on\naverage compared to baseline methods. Using depression prescriptions as a case\nstudy, we analyzed graph embeddings via geographical principal component\nanalysis, identifying findings that: align with prior research (e.g., higher\nantidepressant prescriptions among older and White populations), contribute to\nongoing debates (e.g., greenery linked to higher and NO2 to lower\nprescriptions), and warrant further study (e.g., canopy evaporation correlated\nwith fewer prescriptions). These results demonstrate MedGNN's potential, and\nmore broadly, of carefully applied machine learning, to advance\ntransdisciplinary public health research.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-07T05:35:16Z"}
{"aid":"http://arxiv.org/abs/2504.04751v1","title":"Unsupervised Estimation of Nonlinear Audio Effects: Comparing\n  Diffusion-Based and Adversarial approaches","summary":"Accurately estimating nonlinear audio effects without access to paired\ninput-output signals remains a challenging problem.This work studies\nunsupervised probabilistic approaches for solving this task. We introduce a\nmethod, novel for this application, based on diffusion generative models for\nblind system identification, enabling the estimation of unknown nonlinear\neffects using black- and gray-box models. This study compares this method with\na previously proposed adversarial approach, analyzing the performance of both\nmethods under different parameterizations of the effect operator and varying\nlengths of available effected recordings.Through experiments on guitar\ndistortion effects, we show that the diffusion-based approach provides more\nstable results and is less sensitive to data availability, while the\nadversarial approach is superior at estimating more pronounced distortion\neffects. Our findings contribute to the robust unsupervised blind estimation of\naudio effects, demonstrating the potential of diffusion models for system\nidentification in music technology.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-07T05:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.04764v1","title":"Enhancing Leaf Disease Classification Using GAT-GCN Hybrid Model","summary":"Agriculture plays a critical role in the global economy, providing\nlivelihoods and ensuring food security for billions. As innovative agricultural\npractices become more widespread, the risk of crop diseases has increased,\nhighlighting the urgent need for efficient, low-intervention disease\nidentification methods. This research presents a hybrid model combining Graph\nAttention Networks (GATs) and Graph Convolution Networks (GCNs) for leaf\ndisease classification. GCNs have been widely used for learning from\ngraph-structured data, and GATs enhance this by incorporating attention\nmechanisms to focus on the most important neighbors. The methodology integrates\nsuperpixel segmentation for efficient feature extraction, partitioning images\ninto meaningful, homogeneous regions that better capture localized features.\nThe authors have employed an edge augmentation technique to enhance the\nrobustness of the model. The edge augmentation technique has introduced a\nsignificant degree of generalization in the detection capabilities of the\nmodel. To further optimize training, weight initialization techniques are\napplied. The hybrid model is evaluated against the individual performance of\nthe GCN and GAT models and the hybrid model achieved a precision of 0.9822,\nrecall of 0.9818, and F1-score of 0.9818 in apple leaf disease classification,\na precision of 0.9746, recall of 0.9744, and F1-score of 0.9743 in potato leaf\ndisease classification, and a precision of 0.8801, recall of 0.8801, and\nF1-score of 0.8799 in sugarcane leaf disease classification. These results\ndemonstrate the robustness and performance of the model, suggesting its\npotential to support sustainable agricultural practices through precise and\neffective disease detection. This work is a small step towards reducing the\nloss of crops and hence supporting sustainable goals of zero hunger and life on\nland.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T06:31:38Z"}
{"aid":"http://arxiv.org/abs/2504.04818v1","title":"SUEDE:Shared Unified Experts for Physical-Digital Face Attack Detection\n  Enhancement","summary":"Face recognition systems are vulnerable to physical attacks (e.g., printed\nphotos) and digital threats (e.g., DeepFake), which are currently being studied\nas independent visual tasks, such as Face Anti-Spoofing and Forgery Detection.\nThe inherent differences among various attack types present significant\nchallenges in identifying a common feature space, making it difficult to\ndevelop a unified framework for detecting data from both attack modalities\nsimultaneously. Inspired by the efficacy of Mixture-of-Experts (MoE) in\nlearning across diverse domains, we explore utilizing multiple experts to learn\nthe distinct features of various attack types. However, the feature\ndistributions of physical and digital attacks overlap and differ. This suggests\nthat relying solely on distinct experts to learn the unique features of each\nattack type may overlook shared knowledge between them. To address these\nissues, we propose SUEDE, the Shared Unified Experts for Physical-Digital Face\nAttack Detection Enhancement. SUEDE combines a shared expert (always activated)\nto capture common features for both attack types and multiple routed experts\n(selectively activated) for specific attack types. Further, we integrate CLIP\nas the base network to ensure the shared expert benefits from prior visual\nknowledge and align visual-text representations in a unified space. Extensive\nresults demonstrate SUEDE achieves superior performance compared to\nstate-of-the-art unified detection methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:17:54Z"}
{"aid":"http://arxiv.org/abs/2504.04826v1","title":"A structure and asymptotic preserving scheme for the quasineutral limit\n  of the Vlasov-Poisson system","summary":"In this work, we propose a new numerical method for the Vlasov-Poisson system\nthat is both asymptotically consistent and stable in the quasineutral regime,\ni.e. when the Debye length is small compared to the characteristic spatial\nscale of the physical domain. Our approach consists in reformulating the\nVlasov-Poisson system as a hyperbolic problem by applying a spectral expansion\nin the basis of Hermite functions in the velocity space and in designing a\nstructure-preserving scheme for the time and spatial variables. Through this\nHermite formulation, we establish a convergence result for the electric field\ntoward its quasineutral limit together with optimal error estimates. Following\nthis path, we then propose a fully discrete numerical method for the\nVlasov-Poisson system, inspired by the approach in arXiv:2306.14605 , and\nrigorously prove that it is uniformly consistent in the quasineutral limit\nregime. Finally, we present several numerical simulations to illustrate the\nbehavior of the proposed scheme. These results demonstrate the capability of\nour method to describe quasineutral plasmas and confirm the theoretical\nfindings: stability and asymptotic preservation.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T08:32:13Z"}
{"aid":"http://arxiv.org/abs/2504.04848v1","title":"Some remarks on almost locally uniformly rotund points","summary":"We study the relations between different notions of almost locally uniformly\nrotund points that appear in literature. We show that every non-reflexive\nBanach space admits an equivalent norm having a point in the corresponding unit\nsphere which is not almost locally uniformly rotund, and which is strongly\nexposed by all its supporting functionals. This result is in contrast with a\ncharacterization due to P. Bandyopadhyay, D. Huang, and B.-L. Lin from 2004. We\nalso show that such a characterization remains true in reflexive Banach spaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-07T09:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.04850v1","title":"An Efficient Approach for Cooperative Multi-Agent Learning Problems","summary":"In this article, we propose a centralized Multi-Agent Learning framework for\nlearning a policy that models the simultaneous behavior of multiple agents that\nneed to coordinate to solve a certain task. Centralized approaches often suffer\nfrom the explosion of an action space that is defined by all possible\ncombinations of individual actions, known as joint actions. Our approach\naddresses the coordination problem via a sequential abstraction, which\novercomes the scalability problems typical to centralized methods. It\nintroduces a meta-agent, called \\textit{supervisor}, which abstracts joint\nactions as sequential assignments of actions to each agent. This sequential\nabstraction not only simplifies the centralized joint action space but also\nenhances the framework's scalability and efficiency. Our experimental results\ndemonstrate that the proposed approach successfully coordinates agents across a\nvariety of Multi-Agent Learning environments of diverse sizes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T09:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.04867v1","title":"FedSAUC: A Similarity-Aware Update Control for Communication-Efficient\n  Federated Learning in Edge Computing","summary":"Federated learning is a distributed machine learning framework to\ncollaboratively train a global model without uploading privacy-sensitive data\nonto a centralized server. Usually, this framework is applied to edge devices\nsuch as smartphones, wearable devices, and Internet of Things (IoT) devices\nwhich closely collect information from users. However, these devices are mostly\nbattery-powered. The update procedure of federated learning will constantly\nconsume the battery power and the transmission bandwidth. In this work, we\npropose an update control for federated learning, FedSAUC, by considering the\nsimilarity of users' behaviors (models). At the server side, we exploit\nclustering algorithms to group devices with similar models. Then we select some\nrepresentatives for each cluster to update information to train the model. We\nalso implemented a testbed prototyping on edge devices for validating the\nperformance. The experimental results show that this update control will not\naffect the training accuracy in the long run.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T09:21:43Z"}
{"aid":"http://arxiv.org/abs/2504.04880v1","title":"Investigation of the baryon time-like electromagnetic form factors in\n  the electron-positron annihilation reactions","summary":"Based on the experimental measurements of the electron-positron annihilation\nreactions into a baryon ($B$) and anti-baryon ($\\bar{B}$) pair, the\nelectromagnetic form factors of hyperons in the time-like region can be\ninvestigated within the vector meson dominance model. The theoretical model\nparameters are determined by fitting them to the total cross sections of the\nprocess $e^+e^-\\to B \\bar{B}$, and it is found that the current experimental\ndata on the baryon electromagnetic form factors in the time-like region can be\nwell reproduced. In addition to the total cross sections, the electromagnetic\nform factors $G_E$ and $G_M$, and the charge radii of those baryons are also\nestimated, which are in agreement with the experimental data. On the other\nhand, we have also investigated the nonmonotonic behavior of the time-like\nbaryon electromagnetic form factors, and it is found that the previously\nproposed periodic behaviour of the nucleon time-like electromagnetic form\nfactor is not confirmed. However, we do observe the nonmonotonic structures in\nthe line shape of the baryon effective form factors or the ratio $|G_E/G_M|$\nfor the charmed baryon $\\Lambda^+_c$. These features can be naturally explained\nby incorporating contributions from excited vector states. More precise\nmeasurements of the $e^+e^-\\to B \\bar{B}$ reaction offer a valuable opportunity\nto probe the properties of excited vector states, which are at present poorly\nknown. Additionally, comprehensive theoretical and experimental studies of\nbaryon timelike electromagnetic form factors can provide critical insights into\nthe underlying mechanisms of electron-positron annihilation processes.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-07T09:42:07Z"}
{"aid":"http://arxiv.org/abs/2504.04910v1","title":"Fault Localisation in Infinite-Dimensional Linear Electrical Networks","summary":"We present a novel fault localisation methodology for linear time-invariant\nelectrical networks with infinite-dimensional edge dynamics and uncertain fault\ndynamics. The theory accommodates instability and also bounded propagation\ndelays in the network. The goal is to estimate the location of a fault along a\ngiven network edge, using sensors positioned arbitrarily throughout the\nnetwork. Passive faults of unknown impedance are considered, along with stable\nfaults of known impedance. To illustrate the approach, we tackle a significant\nuse-case: a multi-conductor transmission line, with dynamics modelled by the\nTelegrapher's equation, subject to a line-to-ground fault. Frequency-domain\ninsights are used to reformulate the general fault localisation problem into a\nnon-convex scalar optimisation problem, of which the true fault location is\nguaranteed to be a global minimiser. Numerical experiments are run to quantify\nlocalisation performance over a range of fault resistances.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP,math.DS","published":"2025-04-07T10:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.04918v1","title":"Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B","summary":"As language models continue to grow larger, the cost of acquiring\nhigh-quality training data has increased significantly. Collecting human\nfeedback is both expensive and time-consuming, and manual labels can be noisy,\nleading to an imbalance between helpfulness and harmfulness. Constitutional AI,\nintroduced by Anthropic in December 2022, uses AI to provide feedback to\nanother AI, greatly reducing the need for human labeling. However, the original\nimplementation was designed for a model with around 52 billion parameters, and\nthere is limited information on how well Constitutional AI performs with\nsmaller models, such as LLaMA 3-8B. In this paper, we replicated the\nConstitutional AI workflow using the smaller LLaMA 3-8B model. Our results show\nthat Constitutional AI can effectively increase the harmlessness of the model,\nreducing the Attack Success Rate in MT-Bench by 40.8%. However, similar to the\noriginal study, increasing harmlessness comes at the cost of helpfulness. The\nhelpfulness metrics, which are an average of the Turn 1 and Turn 2 scores,\ndropped by 9.8% compared to the baseline. Additionally, we observed clear signs\nof model collapse in the final DPO-CAI model, indicating that smaller models\nmay struggle with self-improvement due to insufficient output quality, making\neffective fine-tuning more challenging. Our study suggests that, like reasoning\nand math ability, self-improvement is an emergent property.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T11:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.04919v1","title":"Distorted Sounds: Unlocking the Physics of Modern Music","summary":"In the production of modern music, the musical characteristics of the guitar\nor keyboard amplifier play an integral role in the creative process. This\narticle explores the physics of music with an emphasis on the role of\ndistortion in the amplification. In particular, we derive and illustrate how a\ndistorted amplifier creates new musical notes that are not played by the\nmusician, greatly simplifying the playing technique. In providing a\ncomprehensive understanding, we commence with a discussion of the physics of\nmusic, highlighting the harmonic series and its relation to pleasing harmonies.\nThis is placed in the context of the standard music notation of intervals and\ntheir relation to note frequency ratios. We then discuss the problems of tuning\nan instrument and why the equal temperament of standard guitar tuners is\nincompatible with good sounding music when amplifier distortion is involved.\nDrawing on the basic trigonometric identities for angle sums and differences,\nwe show how the nonlinear amplification of a distorted amplifier, generates new\nnotes not played by the musician. Here the importance of setting your guitar\ntuner aside and using your ear to tune is emphasised. We close with a\ndiscussion of how humans decipher musical notes and why some highly distorted\nguitar chords give the impression of low notes that are not actually there.\nThis article will be of assistance to students interested in the physics of\nmusic and lecturers seeking fascinating and relevant applications of\nmathematical trigonometric relations and physics to capture the attention of\ntheir students.","main_category":"physics.pop-ph","categories":"physics.pop-ph","published":"2025-04-07T11:01:46Z"}
{"aid":"http://arxiv.org/abs/2504.04921v1","title":"Expectations vs Reality -- A Secondary Study on AI Adoption in Software\n  Testing","summary":"In the software industry, artificial intelligence (AI) has been utilized more\nand more in software development activities. In some activities, such as\ncoding, AI has already been an everyday tool, but in software testing\nactivities AI it has not yet made a significant breakthrough. In this paper,\nthe objective was to identify what kind of empirical research with industry\ncontext has been conducted on AI in software testing, as well as how AI has\nbeen adopted in software testing practice. To achieve this, we performed a\nsystematic mapping study of recent (2020 and later) studies on AI adoption in\nsoftware testing in the industry, and applied thematic analysis to identify\ncommon themes and categories, such as the real-world use cases and benefits, in\nthe found papers. The observations suggest that AI is not yet heavily utilized\nin software testing, and still relatively few studies on AI adoption in\nsoftware testing have been conducted in the industry context to solve\nreal-world problems. Earlier studies indicated there was a noticeable gap\nbetween the actual use cases and actual benefits versus the expectations, which\nwe analyzed further. While there were numerous potential use cases for AI in\nsoftware testing, such as test case generation, code analysis, and intelligent\ntest automation, the reported actual implementations and observed benefits were\nlimited. In addition, the systematic mapping study revealed a potential problem\nwith false positive search results in online databases when using the search\nstring \"artificial intelligence\".","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-07T11:03:54Z"}
{"aid":"http://arxiv.org/abs/2504.04922v1","title":"Real-time tuneable bright bonding plasmonic modes in Ga nanostructures","summary":"The precise control of nanogaps is crucial for plasmonic nanoassemblies,\nwhere plasmon hybridization is highly sensitive to gap size and geometry. This\nsensitivity enables fine-tuning of the resonance wavelength and near-field\nenhancement, offering the potential for advanced optical applications. However,\nconventional lithographic techniques for gap modulation are constrained to\ndiscrete values and face challenges in achieving nanometer order of\nseparations. Such limitations hinder the comprehensive study of plasmon\ncoupling across varying interaction regimes. Overcoming these challenges is\nessential for advancing nanoplasmonic research and its practical applications.\nHerein, we demonstrate a tuneable plasmonic device in which real-time\ntunability of this hybridization mode is achieved via manipulation of the\ninter-droplet gap of liquid metal nanoparticles by macroscopic physical\ndeformation. In particular, we show that the optical spectra obtained from the\nsample shift towards higher energy on the application of a linear strain,\nresulting in an increase of inter-droplet gaps leading to a direct probing of\nthe bright modes in situ. Our method thus offers a novel means of exploring the\nfundamental concept of real-time tuneable plasmon hybridization as well as\ntuning of nanoparticle assembly with any desired gap in a controlled manner.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T11:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.04975v1","title":"Geometric quantization of generalized Hirzebruch fibrations","summary":"Hirzebruch surfaces, defined as the projectivization of line bundles over\n$\\C\\mathbb{P}^1$, support a toric action and thus represent an infinite class\nof symplectic toric manifolds of complex dimension 2. In this paper, an\ninfinite class of toric manifolds given as projective bundles over\n$\\mathbb{C}\\mathbb{P}^d$ will be constructed for every complex dimension $d$\nand it will be shown that each manifold supports a symplectic structure. With\nthe toric and symplectic structure of the manifolds at our disposal, we then\nstudy their geometric quantization and how it relates to different values of\nthe twisting parameter of the fibrations.","main_category":"math.SG","categories":"math.SG","published":"2025-04-07T12:04:15Z"}
{"aid":"http://arxiv.org/abs/2504.05042v1","title":"Lattice packing of spheres in high dimensions using a stochastically\n  evolving ellipsoid","summary":"We prove that in any dimension $n$ there exists an origin-symmetric ellipsoid\n${\\mathcal{E}} \\subset {\\mathbb{R}}^n$ of volume $ c n^2 $ that contains no\npoints of ${\\mathbb{Z}}^n$ other than the origin, where $c > 0$ is a universal\nconstant. Equivalently, there exists a lattice sphere packing in\n${\\mathbb{R}}^n$ whose density is at least $cn^2 \\cdot 2^{-n}$. Previously\nknown constructions of sphere packings in ${\\mathbb{R}}^n$ had densities of the\norder of magnitude of $n \\cdot 2^{-n}$, up to logarithmic factors. Our proof\nutilizes a stochastically evolving ellipsoid that accumulates at least $c n^2$\nlattice points on its boundary, while containing no lattice points in its\ninterior except for the origin.","main_category":"math.MG","categories":"math.MG,math.NT,math.PR","published":"2025-04-07T13:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.05097v1","title":"State Tuning: State-based Test-Time Scaling on RWKV-7","summary":"Test-time scaling has emerged as a prominent research direction in machine\nlearning, enabling models to enhance their expressive capabilities during\ninference.Transformers, renowned for striking a delicate balance between\nefficiency and expressiveness, have benefited from test-time scaling techniques\nthat leverage an expanding key-value (KV) cache to significantly improve\nperformance.In this paper, we introduce a novel state-based approach to\ntest-time scaling, which we term state tuning, tailored to the RNN-based RWKV-7\nmodel.By exploiting the unique strengths of RWKV-7, our method achieves\nstate-of-the-art performance on the target task without altering the model's\npre-trained weights. Our approach centers on three key innovations. First, we\ndevelop an observer framework that allows a smaller model to replicate and\nlearn the state dynamics of the RWKV-7 model. Second, we employ a kernel method\nto dynamically upscale the state size, enhancing the model's capacity to\ncapture intricate patterns. Third, we integrate Decorrelated Backpropagation\n(DBP) to optimize the upscaled state matrix, thereby improving convergence and\nexpressivity. By tuning only the state matrix, we demonstrate that a smaller\nmodel can outperform larger models on the given task. This method preserves the\nefficiency of the original RWKV-7 architecture while harnessing the power of\ntest-time scaling to deliver superior results. Our findings underscore the\npotential of state tuning as an effective strategy for advancing model\nperformance in resource-constrained settings. Our code is\nhttps://github.com/TorchRWKV/flash-linear-attention.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-07T14:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.05119v1","title":"Balancing Robustness and Efficiency in Embedded DNNs Through Activation\n  Function Selection","summary":"Machine learning-based embedded systems for safety-critical applications,\nsuch as aerospace and autonomous driving, must be robust to perturbations\ncaused by soft errors. As transistor geometries shrink and voltages decrease,\nmodern electronic devices become more susceptible to background radiation,\nincreasing the concern about failures produced by soft errors. The resilience\nof deep neural networks (DNNs) to these errors depends not only on target\ndevice technology but also on model structure and the numerical representation\nand arithmetic precision of their parameters. Compression techniques like\npruning and quantization, used to reduce memory footprint and computational\ncomplexity, alter both model structure and representation, affecting soft error\nrobustness. In this regard, although often overlooked, the choice of activation\nfunctions (AFs) impacts not only accuracy and trainability but also\ncompressibility and error resilience. This paper explores the use of bounded\nAFs to enhance robustness against parameter perturbations, while evaluating\ntheir effects on model accuracy, compressibility, and computational load with a\ntechnology-agnostic approach. We focus on encoder-decoder convolutional models\ndeveloped for semantic segmentation of hyperspectral images with application to\nautonomous driving systems. Experiments are conducted on an AMD-Xilinx's KV260\nSoM.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.AR,cs.CV,eess.IV","published":"2025-04-07T14:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.05120v1","title":"The intersections of the lower central series and the subgroups of\n  finite p-index of Generalized Baumslag-Solitar tree groups","summary":"For a Generalized Baumslag-Solitar group $G$ with underling graph a tree, we\ncalculate the intersection $\\gamma_{\\omega}(G)$ of the lower central series and\nthe intersection $(N_{p})_{\\omega}(G)$ of the subgroups of finite index some\npower of a prime $p$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-07T14:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.05127v1","title":"Transitivity of the pure Hurwitz classes of quadratic post-critically\n  finite polynomials","summary":"We prove that for two post-critically finite quadratic polynomials $f,g$,\nthere is a mapping class $\\phi$ of the sphere with finitely many marked points\nsuch that $f\\phi$ and $g$ are pure Hurwitz equivalent.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-07T14:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.05155v1","title":"Phonon properties and unconventional heat transfer in quasi-2D\n  $Bi_2O_2Se$ crystal","summary":"Bi2O2Se belongs to a group of quasi-2D semiconductors that can replace\nsilicon in future high-speed/low-power electronics. However, the correlation\nbetween crystal/band structure and other physical properties still eludes\nunderstanding: carrier mobility increases non-intuitively with carrier\nconcentration; the observed $T^2$ temperature dependence of resistivity lacks\nexplanation. Moreover, a very high relative out-of-plane permittivity of about\n150 has been reported in the literature. A proper explanation for such a high\npermittivity is still lacking. We have performed infrared (IR) reflectivity and\nRaman scattering experiments on a large perfect single crystal with defined\nmosaicity, carrier concentration and mobility. Five of the eight phonons\nallowed by factor group theory have been observed and their symmetries\ndetermined. The IR spectra show that the permittivity measured in the\ntetragonal plane is as high as ${\\epsilon}_r{\\approx}500$, and this high value\nis due to a strong polar phonon with a low frequency of ~34 $cm^{-1}$ (~1 THz).\nSuch an unusually high permittivity allows the screening of charge defects,\nleading to the observation of high electron mobility at low temperatures. It\nalso allows effective modulation doping providing a platform for high\nperformance 2D electronics. DFT calculations suggest the existence of a very\nlow frequency acoustic phonon ~14 $cm^{-1}$ (~0.4 THz). Both the low frequency\nphonons cause anomalous phonon DOS, which is reflected in the unconventional\ntemperature dependence of the heat capacity, $c_M{\\approx}T^{3.5}$. The\ntemperature-dependent, two-component group velocity is proposed to explains the\nunusual temperature dependence of the thermal conductivity,\n${\\kappa}{\\approx}T^{1.5}$","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T14:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05181v1","title":"Lightweight and Direct Document Relevance Optimization for Generative\n  Information Retrieval","summary":"Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.DL,cs.LG,H.3.3","published":"2025-04-07T15:27:37Z"}
{"aid":"http://arxiv.org/abs/2504.05185v1","title":"Concise Reasoning via Reinforcement Learning","summary":"Despite significant advancements in large language models (LLMs), a major\ndrawback of reasoning models is their enormous token usage, which increases\ncomputational cost, resource requirements, and response time. In this work, we\nrevisit the core principles of reinforcement learning (RL) and, through\nmathematical analysis, demonstrate that the tendency to generate lengthy\nresponses arises inherently from RL-based optimization during training. This\nfinding questions the prevailing assumption that longer responses inherently\nimprove reasoning accuracy. Instead, we uncover a natural correlation between\nconciseness and accuracy that has been largely overlooked. Moreover, we show\nthat introducing a secondary phase of RL post-training, using a small set of\nproblems and limited resources, can significantly reduce a model's chain of\nthought while maintaining or even enhancing accuracy. Finally, we validate our\nconclusions through extensive experimental results.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T15:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.05189v1","title":"Influence of pore-confined water on the thermal expansion of a\n  zinc-based metal-organic framework","summary":"Understanding the reversible intercalation of guest molecules into\nmetal-organic frameworks is crucial for advancing their design for practical\napplications. In this work, we explore the impact of H$_{\\mathrm{2}}\\!$O as a\nguest molecule on the thermal expansion of the zinc-based metal-organic\nframework GUT-2. Dehydration is achieved by thermal treatment of hydrated\nGUT-2. Rietveld refinement performed on temperature-dependent X-ray powder\ndiffraction data confirms the reversible structural transformation.\nAdditionally, it allows the determination of anisotropic thermal expansion\ncoefficients for both phases. The hydrated form exhibits near-zero thermal\nexpansion along the polymer chain direction, moderate expansion In the\ndirection of predominantly hydrogen bonds, and the highest expansion in the\ndirection with only Van der Waals bonding. Upon activation, the removal of\nH$_{\\mathrm{2}}\\!$O molecules triggers a doubling of the thermal expansion\ncoefficient in the direction, where the hydrogen bonds have been removed.\nRegarding the dynamics of the process, thermal activation in air occurs within\n6 hours at a temperature of 50{\\deg}C and takes only 30 minutes when heating to\n90{\\deg}C. In contrast, full rehydration under standard lab conditions (30 %\nrelative humidity) requires two days. During the activation/dehydration\nprocesses no change of the widths of the X-ray diffraction peaks is observed,\nwhich shows that the underlying crystal structures remains fully intact during\nthe transition processes. Fitting the transformations by the Avrami equation\nreveals a quasi one-dimensional evolution of the dehydrated areas for the\nactivation process and a more intricate, predominantly two-dimensional\nmechanism for the rehydration.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T15:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.05209v1","title":"Detailed $SU(3)$ Flavour Symmetry Analysis of Charmless Two-Body\n  $B$-Meson Decays Including Factorizable Corrections","summary":"We study the decays of $B_{(s)}$ mesons into light pseudoscalar mesons under\nthe $SU(3)$ flavour symmetry. Assuming exact $SU(3)$ symmetry at the level of\nthe amplitudes leads to a simple parameterization. Using the available\nexperimental data and, for the first time, mixing effects in the $B_s^0$\ndecays, we find that the data cannot be described with this assumption. We\nimprove this parametrization by including {\\it factorizable}\n$SU(3)_\\mathrm{F}$-breaking effects. This new approach allows for an excellent\ndescription of the data, with a fit $p$ value of $32.3\\%$. We provide posterior\npredictions for all observables and identify several decay channels that would\nsignificantly impact our analysis. Finally, we briefly compare our results with\nthe predictions of QCD factorization, paving the way to a more detailed\nanalysis which could provide insights into QCD effects at low energy scales.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-07T15:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.05215v1","title":"Quasinormal modes and absorption cross-section of a Bardeen black hole\n  surrounded by perfect fluid dark matter in four dimensions","summary":"In this paper we study quasinormal modes and absorption cross sections for\nthe $(1+3)$-dimensional Bardeen black hole surrounded by perfect fluid dark\nmatter. Studies of the massless scalar field is already done in\n\\cite{Sun:2023slzl}. Hence, in this paper we will focus on the massive scalar\nfield perturbations and massless Dirac field perturbations. To compute the\nquasinormal modes we use the semi-analytical 3rd-order WKB method, which has\nbeen shown to be one of the best approaches when the effective potential is\nadequate and when $n < \\ell$ and $n < \\lambda$. We have also utilized the\nP\\\"oschl-Teller method to compare the valus obtained using the WKB approach. We\nhave computed quasinormal frequencies by varying various parameters of the\ntheory such as the mass of the scalar field $\\mu$, dark matter parameter\n$\\alpha$ and the magnetic charge $g$. We have summarized our solutions in\ntables and figures for clarity. As for the absorption cross section, we used\nthird order WKB approach to compute reflection, transmission coefficients and\npartial absorption cross sections. Graphs are presented to demonstrate the\nbehavior of the above quantities when the dark matter parameter and mass of the\nmassive scalar field are varied.","main_category":"gr-qc","categories":"gr-qc,astro-ph.SR,hep-th","published":"2025-04-07T16:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.05219v1","title":"An ensemble deep learning approach to detect tumors on Mohs micrographic\n  surgery slides","summary":"Mohs micrographic surgery (MMS) is the gold standard technique for removing\nhigh risk nonmelanoma skin cancer however, intraoperative histopathological\nexamination demands significant time, effort, and professionality. The\nobjective of this study is to develop a deep learning model to detect basal\ncell carcinoma (BCC) and artifacts on Mohs slides. A total of 731 Mohs slides\nfrom 51 patients with BCCs were used in this study, with 91 containing tumor\nand 640 without tumor which was defined as non-tumor. The dataset was employed\nto train U-Net based models that segment tumor and non-tumor regions on the\nslides. The segmented patches were classified as tumor, or non-tumor to produce\npredictions for whole slide images (WSIs). For the segmentation phase, the deep\nlearning model success was measured using a Dice score with 0.70 and 0.67\nvalue, area under the curve (AUC) score with 0.98 and 0.96 for tumor and\nnon-tumor, respectively. For the tumor classification, an AUC of 0.98 for\npatch-based detection, and AUC of 0.91 for slide-based detection was obtained\non the test dataset. We present an AI system that can detect tumors and\nnon-tumors in Mohs slides with high success. Deep learning can aid Mohs\nsurgeons and dermatopathologists in making more accurate decisions.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-07T16:05:42Z"}
{"aid":"http://arxiv.org/abs/2504.05235v1","title":"IAEmu: Learning Galaxy Intrinsic Alignment Correlations","summary":"The intrinsic alignments (IA) of galaxies, a key contaminant in weak lensing\nanalyses, arise from correlations in galaxy shapes driven by tidal interactions\nand galaxy formation processes. Accurate IA modeling is essential for robust\ncosmological inference, but current approaches rely on perturbative methods\nthat break down on nonlinear scales or on expensive simulations. We introduce\nIAEmu, a neural network-based emulator that predicts the galaxy\nposition-position ($\\xi$), position-orientation ($\\omega$), and\norientation-orientation ($\\eta$) correlation functions and their uncertainties\nusing mock catalogs based on the halo occupation distribution (HOD) framework.\nCompared to simulations, IAEmu achieves ~3% average error for $\\xi$ and ~5% for\n$\\omega$, while capturing the stochasticity of $\\eta$ without overfitting. The\nemulator provides both aleatoric and epistemic uncertainties, helping identify\nregions where predictions may be less reliable. We also demonstrate\ngeneralization to non-HOD alignment signals by fitting to IllustrisTNG\nhydrodynamical simulation data. As a fully differentiable neural network, IAEmu\nenables $\\sim$10,000$\\times$ speed-ups in mapping HOD parameters to correlation\nfunctions on GPUs, compared to CPU-based simulations. This acceleration\nfacilitates inverse modeling via gradient-based sampling, making IAEmu a\npowerful surrogate model for galaxy bias and IA studies with direct\napplications to Stage IV weak lensing surveys.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,cs.LG","published":"2025-04-07T16:19:50Z"}
{"aid":"http://arxiv.org/abs/2504.05253v1","title":"Contour Integration Underlies Human-Like Vision","summary":"Despite the tremendous success of deep learning in computer vision, models\nstill fall behind humans in generalizing to new input distributions. Existing\nbenchmarks do not investigate the specific failure points of models by\nanalyzing performance under many controlled conditions. Our study\nsystematically dissects where and why models struggle with contour integration\n-- a hallmark of human vision -- by designing an experiment that tests object\nrecognition under various levels of object fragmentation. Humans (n=50) perform\nat high accuracy, even with few object contours present. This is in contrast to\nmodels which exhibit substantially lower sensitivity to increasing object\ncontours, with most of the over 1,000 models we tested barely performing above\nchance. Only at very large scales ($\\sim5B$ training dataset size) do models\nbegin to approach human performance. Importantly, humans exhibit an integration\nbias -- a preference towards recognizing objects made up of directional\nfragments over directionless fragments. We find that not only do models that\nshare this property perform better at our task, but that this bias also\nincreases with model training dataset size, and training models to exhibit\ncontour integration leads to high shape bias. Taken together, our results\nsuggest that contour integration is a hallmark of object vision that underlies\nobject recognition performance, and may be a mechanism learned from data at\nscale.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.05265v1","title":"From Sparse Signal to Smooth Motion: Real-Time Motion Generation with\n  Rolling Prediction Models","summary":"In extended reality (XR), generating full-body motion of the users is\nimportant to understand their actions, drive their virtual avatars for social\ninteraction, and convey a realistic sense of presence. While prior works\nfocused on spatially sparse and always-on input signals from motion\ncontrollers, many XR applications opt for vision-based hand tracking for\nreduced user friction and better immersion. Compared to controllers, hand\ntracking signals are less accurate and can even be missing for an extended\nperiod of time. To handle such unreliable inputs, we present Rolling Prediction\nModel (RPM), an online and real-time approach that generates smooth full-body\nmotion from temporally and spatially sparse input signals. Our model generates\n1) accurate motion that matches the inputs (i.e., tracking mode) and 2)\nplausible motion when inputs are missing (i.e., synthesis mode). More\nimportantly, RPM generates seamless transitions from tracking to synthesis, and\nvice versa. To demonstrate the practical importance of handling noisy and\nmissing inputs, we present GORP, the first dataset of realistic sparse inputs\nfrom a commercial virtual reality (VR) headset with paired high quality body\nmotion ground truth. GORP provides >14 hours of VR gameplay data from 28 people\nusing motion controllers (spatially sparse) and hand tracking (spatially and\ntemporally sparse). We benchmark RPM against the state of the art on both\nsynthetic data and GORP to highlight how we can bridge the gap for real-world\napplications with a realistic dataset and by handling unreliable input signals.\nOur code, pretrained models, and GORP dataset are available in the project\nwebpage.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.05266v1","title":"Differential forms: Lagrange interpolation, sampling and approximation\n  on polynomial admissible integral k-meshes","summary":"In this work we address the problem of interpolating and approximating\ndifferential forms starting from data defined by integration. We show that many\naspects of nodal interpolation can naturally be carried to this more general\nframework; in contrast, some of them require the introduction of geometric and\nmeasure theoretic hypotheses. After characterizing the norms of the operators\ninvolved, we introduce the concept of admissible integral k-mesh, which allows\nfor the construction of robust approximation schemes, and is used to extract\ninterpolation sets with high stability properties. To this end, the concepts of\nFekete currents and Leja sequences of currents are formalized, and a numerical\nscheme for their approximation is proposed.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T17:04:51Z"}
{"aid":"http://arxiv.org/abs/2504.05268v1","title":"Performance and Complexity Analysis of Terahertz-Band MIMO Detection","summary":"Achieving terabit-per-second (Tbps) data rates in terahertz (THz)-band\ncommunications requires bridging the complexity gap in baseband transceiver\ndesign. This work addresses the signal processing challenges associated with\ndata detection in THz multiple-input multiple-output (MIMO) systems. We begin\nby analyzing the trade-offs between performance and complexity across various\ndetection schemes and THz channel models, demonstrating significant complexity\nreduction by leveraging spatial parallelizability over subspaces of correlated\nTHz MIMO channels. We derive accurate detection error probability bounds by\naccounting for THz-specific channel models and mismatches introduced by\nsubspace decomposition. Building on this, we propose a subspace detector that\nintegrates layer sorting, QR decomposition, and channel-matrix puncturing to\nbalance performance loss and parallelizability. Furthermore, we introduce a\nchannel-matrix reuse strategy for wideband THz MIMO detection. Simulations over\naccurate, ill-conditioned THz channels show that efficient parallelizability\nachieves multi-dB performance gains, while wideband reuse strategies offer\ncomputational savings with minimal performance degradation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T17:06:07Z"}
{"aid":"http://arxiv.org/abs/2504.05280v1","title":"Dimensionality Enhanced Out-of-Plane Spin Currents in NbIrTe$_4$ for\n  Efficient Field-Free Switching of Perpendicular Magnetization","summary":"Efficient generation of out-of-plane (OOP) spin currents is crucial for\nadvanced spintronic memory applications. However, the theoretical understanding\nand experimental implementation of robust OOP spin currents for high-density\nand low-power magnetization switching remain significant challenges of\nspintronics. Here, we demonstrate that transitioning NbIrTe$_4$ from a\ntwo-dimensional quantum spin Hall insulator to a three-dimensional type-II Weyl\nsemimetal markedly enhances OOP spin current generation. The bulk topological\nWeyl semimetal nature of NbIrTe$_4$, characterized by its Weyl cone,\nsignificantly enhances the OOP spin Berry curvature, enabling an unprecedented\nOOP spin Hall conductivity exceeding $10^5\\hbar/2e$ $\\Omega^{-1}m^{-1} $. This\nenhancement, surpassing the in-plane component by more than fourfold, enables\nefficient and field-free spin-orbit torque (SOT) switching of perpendicular\nmagnetization with a low current density of 1.4 MA/cm$^2$. The improved spin\nHall conductivity reduces the overall power consumption by more than two orders\nof magnitude compared to existing systems, such as heavy metals. Our findings\nhighlight the pivotal role of dimensionality in harnessing robust OOP spin\ncurrents in topological Weyl semimetals, paving the way for the development of\nhigh-density, low-power spintronic memory technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-07T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.05649v1","title":"POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point\n  Cloud","summary":"LiDAR-based 3D object detection is a fundamental task in the field of\nautonomous driving. This paper explores the unique advantage of Frequency\nModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a single\nframe FMCW point cloud with radial velocity measurements, we expect that our\nobject detector can detect the short-term future locations of objects using\nonly the current frame sensor data and demonstrate a fast ability to respond to\nintermediate danger. To achieve this, we extend the standard object detection\ntask to a novel task named predictive object detection (POD), which aims to\npredict the short-term future location and dimensions of objects based solely\non current observations. Typically, a motion prediction task requires\nhistorical sensor information to process the temporal contexts of each object,\nwhile our detector's avoidance of multi-frame historical information enables a\nmuch faster response time to potential dangers. The core advantage of FMCW\nLiDAR lies in the radial velocity associated with every reflected point. We\npropose a novel POD framework, the core idea of which is to generate a virtual\nfuture point using a ray casting mechanism, create virtual two-frame point\nclouds with the current and virtual future frames, and encode these two-frame\nvoxel features with a sparse 4D encoder. Subsequently, the 4D voxel features\nare separated by temporal indices and remapped into two Bird's Eye View (BEV)\nfeatures: one decoded for standard current frame object detection and the other\nfor future predictive object detection. Extensive experiments on our in-house\ndataset demonstrate the state-of-the-art standard and predictive detection\nperformance of the proposed POD framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.05666v1","title":"Contraction and concentration of measures with applications to\n  theoretical neuroscience","summary":"We investigate the asymptotic behavior of probability measures associated\nwith stochastic dynamical systems featuring either globally contracting or\n$B_{r}$-contracting drift terms. While classical results often assume constant\ndiffusion and gradient-based drifts, we extend the analysis to spatially\ninhomogeneous diffusion and non-integrable vector fields. We establish\nsufficient conditions for the existence and uniqueness of stationary measures\nunder global contraction, showing that convergence is preserved when the\ncontraction rate dominates diffusion inhomogeneity. For systems contracting\nonly outside of a compact set and with constant diffusion, we demonstrate mass\nconcentration near the minima of an associated non-convex potential, like in\nmultistable regimes. The theoretical findings are illustrated through Hopfield\nnetworks, highlighting implications for memory retrieval dynamics in noisy\nenvironments.","main_category":"math.DS","categories":"math.DS,math-ph,math.AP,math.MP","published":"2025-04-08T04:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.05696v1","title":"Diabetic Retinopathy Detection Based on Convolutional Neural Networks\n  with SMOTE and CLAHE Techniques Applied to Fundus Images","summary":"Diabetic retinopathy (DR) is one of the major complications in diabetic\npatients' eyes, potentially leading to permanent blindness if not detected\ntimely. This study aims to evaluate the accuracy of artificial intelligence\n(AI) in diagnosing DR. The method employed is the Synthetic Minority\nOver-sampling Technique (SMOTE) algorithm, applied to identify DR and its\nseverity stages from fundus images using the public dataset \"APTOS 2019\nBlindness Detection.\" Literature was reviewed via ScienceDirect, ResearchGate,\nGoogle Scholar, and IEEE Xplore. Classification results using Convolutional\nNeural Network (CNN) showed the best performance for the binary classes normal\n(0) and DR (1) with an accuracy of 99.55%, precision of 99.54%, recall of\n99.54%, and F1-score of 99.54%. For the multiclass classification No_DR (0),\nMild (1), Moderate (2), Severe (3), Proliferate_DR (4), the accuracy was\n95.26%, precision 95.26%, recall 95.17%, and F1-score 95.23%. Evaluation using\nthe confusion matrix yielded results of 99.68% for binary classification and\n96.65% for multiclass. This study highlights the significant potential in\nenhancing the accuracy of DR diagnosis compared to traditional human analysis","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG,q-bio.NC","published":"2025-04-08T05:38:53Z"}
{"aid":"http://arxiv.org/abs/2504.05708v1","title":"Thermodynamic supercriticality and complex phase diagram for the AdS\n  black hole","summary":"In this study, we extend the application of the Lee-Yang phase transition\ntheorem to the realm of AdS black hole thermodynamics, thereby deriving a\ncomprehensive complex phase diagram for such systems. Our research augments\nextant studies on black hole thermodynamic phase diagrams, particularly in the\nregime above the critical point, by delineating the Widom line of AdS black\nholes. This boundary segregates the supercritical domain of the phase diagram\ninto two disparate zones. As the system traverses the thermodynamic crossover\nwithin the supercritical region, it undergoes a transition from one\nsupercritical phase to another, while maintaining the continuity of its\nthermodynamic state functions. This behavior is fundamentally different from\nthat below the critical point, where crossing the coexistence line results in\ndiscontinuities of thermodynamic state functions. The Widom line enables a\nthermodynamic crossover between single-phase states without traversing the\nspinodal that emerges in the critical region.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-08T06:03:39Z"}
{"aid":"http://arxiv.org/abs/2504.05712v1","title":"How I Learned to Stop Worrying and Love ChatGPT","summary":"In the dynamic landscape of software engineering, the emergence of\nChatGPT-generated code signifies a distinctive and evolving paradigm in\ndevelopment practices. We delve into the impact of interactions with ChatGPT on\nthe software development process, specifically analysing its influence on\nsource code changes. Our emphasis lies in aligning code with ChatGPT\nconversations, separately analysing the user-provided context of the code and\nthe extent to which the resulting code has been influenced by ChatGPT.\nAdditionally, employing survival analysis techniques, we examine the longevity\nof ChatGPT-generated code segments in comparison to lines written\ntraditionally. The goal is to provide valuable insights into the transformative\nrole of ChatGPT in software development, illuminating its implications for code\nevolution and sustainability within the ecosystem.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T06:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.05733v1","title":"The evolution of a curve induced by the Pohlmeyer-Lund-Regge equation","summary":"This paper investigates the evolution of space curves governed by the\nPohlmeyer-Lund-Regge (PLR) equation, an integrable extension of the sine-Gordon\nequation. We examine a specific type of curve evolution, known as the\nLund-Regge evolution, and derive its representation in the Frenet frame. We\nshow the Frenet frame evolution aligns with the Lax system of the PLR equation\nand develop a construction method for curve families via the Sym formula. In\nconclusion, we describe the Lund-Regge evolution corresponding to Date's\nmulti-soliton solutions to the PLR equation, with illustrations of curves and\nsurfaces.","main_category":"math.DG","categories":"math.DG,nlin.SI","published":"2025-04-08T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.05779v1","title":"FASR-Net: Unsupervised Shadow Removal Leveraging Inherent Frequency\n  Priors","summary":"Shadow removal is challenging due to the complex interaction of geometry,\nlighting, and environmental factors. Existing unsupervised methods often\noverlook shadow-specific priors, leading to incomplete shadow recovery. To\naddress this issue, we propose a novel unsupervised Frequency Aware Shadow\nRemoval Network (FASR-Net), which leverages the inherent frequency\ncharacteristics of shadow regions. Specifically, the proposed Wavelet Attention\nDownsampling Module (WADM) integrates wavelet-based image decomposition and\ndeformable attention, effectively breaking down the image into frequency\ncomponents to enhance shadow details within specific frequency bands. We also\nintroduce several new loss functions for precise shadow-free image\nreproduction: a frequency loss to capture image component details, a\nbrightness-chromaticity loss that references the chromaticity of shadow-free\nregions, and an alignment loss to ensure smooth transitions between shadowed\nand shadow-free regions. Experimental results on the AISTD and SRD datasets\ndemonstrate that our method achieves superior shadow removal performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.05802v1","title":"Mass-Spring Models for Passive Keyword Spotting: A Springtronics\n  Approach","summary":"Mechanical systems played a foundational role in computing history, and have\nregained interest due to their unique properties, such as low damping and the\nability to process mechanical signals without transduction. However, recent\nefforts have primarily focused on elementary computations, implemented in\nsystems based on pre-defined reservoirs, or in periodic systems such as arrays\nof buckling beams. Here, we numerically demonstrate a passive mechanical system\n-- in the form of a nonlinear mass-spring model -- that tackles a real-world\nbenchmark for keyword spotting in speech signals. The model is organized in a\nhierarchical architecture combining feature extraction and continuous-time\nconvolution, with each individual stage tailored to the physics of the\nconsidered mass-spring systems. For each step in the computation, a subsystem\nis designed by combining a small set of low-order polynomial potentials. These\npotentials act as fundamental components that interconnect a network of masses.\nIn analogy to electronic circuit design, where complex functional circuits are\nconstructed by combining basic components into hierarchical designs, we refer\nto this framework as springtronics. We introduce springtronic systems with\nhundreds of degrees of freedom, achieving speech classification accuracy\ncomparable to existing sub-mW electronic systems.","main_category":"cs.SD","categories":"cs.SD,cond-mat.dis-nn,eess.AS","published":"2025-04-08T08:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.05805v1","title":"Why is Normalization Necessary for Linear Recommenders?","summary":"Despite their simplicity, linear autoencoder (LAE)-based models have shown\ncomparable or even better performance with faster inference speed than neural\nrecommender models. However, LAEs face two critical challenges: (i) popularity\nbias, which tends to recommend popular items, and (ii) neighborhood bias, which\noverly focuses on capturing local item correlations. To address these issues,\nthis paper first analyzes the effect of two existing normalization methods for\nLAEs, i.e., random-walk and symmetric normalization. Our theoretical analysis\nreveals that normalization highly affects the degree of popularity and\nneighborhood biases among items. Inspired by this analysis, we propose a\nversatile normalization solution, called Data-Adaptive Normalization (DAN),\nwhich flexibly controls the popularity and neighborhood biases by adjusting\nitem- and user-side normalization to align with unique dataset characteristics.\nOwing to its model-agnostic property, DAN can be easily applied to various\nLAE-based models. Experimental results show that DAN-equipped LAEs consistently\nimprove existing LAE-based models across six benchmark datasets, with\nsignificant gains of up to 128.57% and 12.36% for long-tail items and unbiased\nevaluations, respectively. Refer to our code in https://github.com/psm1206/DAN.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T08:37:32Z"}
{"aid":"http://arxiv.org/abs/2504.05811v1","title":"Effects of strange molecular partners of $P_c$ states in $Î³p \\to K\n  Î£$ reactions","summary":"Our previous studies revealed evidence of the strange molecular partners of\n$P_c$ states, $N(2080)3/2^-$ and $N(2270)3/2^-$, in the $\\gamma p \\to K^{*+}\n\\Sigma^0 / K^{*0} \\Sigma^+$ and $\\gamma p \\to \\phi p$ reactions. Motivated by\nthe differential cross-section data for $\\gamma p \\to K^+ \\Sigma^0$ from CLAS\n2010, which exhibits some bump structures at $W \\approx$ 1875, 2080 and 2270\nMeV, we extend our previous analysis by investigating the effects of\n$N(1535)1/2^-$, $N(1875)3/2^-$, $N(2080)1/2^- \\&\\ 3/2^-$ and $N(2270)1/2^- ,\n3/2^- \\&\\ 5/2^-$, as strange partners of $P_c$ molecular states, in the\nreactions $\\gamma p \\to K^+ \\Sigma^0$ and $\\gamma p \\to K^0 \\Sigma^+$. The\ntheoretical model employed in this study utilizes an effective Lagrangian\napproach in the tree-level Born approximation. It contains the contributions\nfrom $s$-channel with exchanges of $N$, $\\Delta$, $N^*$ (including the hadronic\nmolecules with hidden strangeness), and $\\Delta^*$; $t$-channel; $u$-channel;\nand the generalized contact term. The results corresponding to the final fitted\nparameters are in good agreement with all available experimental data of both\ncross-sections and polarization observables for $\\gamma p \\to K^+ \\Sigma^0$ and\n$\\gamma p \\to K^0 \\Sigma^+$. Notably, the $s$-channel exchanges of molecules\nsignificantly contribute to the bump structures in cross-sections for $\\gamma p\n\\to K \\Sigma$ at $W \\approx$ 1900, 2080 and 2270 MeV, and show considerable\ncoherence with contributions from $s$-channel exchanges of general resonances\nto construct the overall structures of cross-sections. More abundant\nexperiments, particularly for the reaction $\\gamma p \\to K^0 \\Sigma^+$, are\nnecessary to further strengthen the constraints on the theoretical models.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-08T08:48:25Z"}
{"aid":"http://arxiv.org/abs/2504.05851v1","title":"Identifying and Replicating Code Patterns Driving Performance\n  Regressions in Software Systems","summary":"Context: Performance regressions negatively impact execution time and memory\nusage of software systems. Nevertheless, there is a lack of systematic methods\nto evaluate the effectiveness of performance test suites. Performance mutation\ntesting, which introduces intentional defects (mutants) to measure and enhance\nfault-detection capabilities, is promising but underexplored. A key challenge\nis understanding if generated mutants accurately reflect real-world performance\nissues. Goal: This study evaluates and extends mutation operators for\nperformance testing. Its objectives include (i) collecting existing performance\nmutation operators, (ii) introducing new operators from real-world code changes\nthat impact performance, and (iii) evaluating these operators on real-world\nsystems to see if they effectively degrade performance. Method: To this aim, we\nwill (i) review the literature to identify performance mutation operators, (ii)\nconduct a mining study to extract patterns of code changes linked to\nperformance regressions, (iii) propose new mutation operators based on these\npatterns, and (iv) apply and evaluate the operators to assess their\neffectiveness in exposing performance degradations. Expected Outcomes: We aim\nto provide an enriched set of mutation operators for performance testing,\nhelping developers and researchers identify harmful coding practices and design\nbetter strategies to detect and prevent performance regressions.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T09:28:46Z"}
{"aid":"http://arxiv.org/abs/2504.05871v1","title":"Agent Guide: A Simple Agent Behavioral Watermarking Framework","summary":"The increasing deployment of intelligent agents in digital ecosystems, such\nas social media platforms, has raised significant concerns about traceability\nand accountability, particularly in cybersecurity and digital content\nprotection. Traditional large language model (LLM) watermarking techniques,\nwhich rely on token-level manipulations, are ill-suited for agents due to the\nchallenges of behavior tokenization and information loss during\nbehavior-to-action translation. To address these issues, we propose Agent\nGuide, a novel behavioral watermarking framework that embeds watermarks by\nguiding the agent's high-level decisions (behavior) through probability biases,\nwhile preserving the naturalness of specific executions (action). Our approach\ndecouples agent behavior into two levels, behavior (e.g., choosing to bookmark)\nand action (e.g., bookmarking with specific tags), and applies watermark-guided\nbiases to the behavior probability distribution. We employ a z-statistic-based\nstatistical analysis to detect the watermark, ensuring reliable extraction over\nmultiple rounds. Experiments in a social media scenario with diverse agent\nprofiles demonstrate that Agent Guide achieves effective watermark detection\nwith a low false positive rate. Our framework provides a practical and robust\nsolution for agent watermarking, with applications in identifying malicious\nagents and protecting proprietary agent systems.","main_category":"cs.AI","categories":"cs.AI,K.6.5","published":"2025-04-08T09:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.05874v1","title":"Systematic Parameter Decision in Approximate Model Counting","summary":"This paper proposes a novel approach to determining the internal parameters\nof the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$.\nIn this problem, the chosen parameter values must ensure that\n$\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making\nit as efficient as possible. The existing approach to this problem relies on\nheuristics; in this paper, we solve this problem by formulating it as an\noptimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s\ncorrectness proof to arbitrary parameter values.\n  Our approach separates the concerns of algorithm soundness and optimality,\nallowing us to address the former without the need for repetitive case-by-case\nargumentation, while establishing a clear framework for the latter.\nFurthermore, after reduction, the resulting optimization problem takes on an\nexceptionally simple form, enabling the use of a basic search algorithm and\nproviding insight into how parameter values affect algorithm performance.\nExperimental results demonstrate that our optimized parameters improve the\nruntime performance of the latest $\\mathsf{ApproxMC}$ by a factor of 1.6 to\n2.4, depending on the error tolerance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T09:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05881v1","title":"Actuarial Learning for Pension Fund Mortality Forecasting","summary":"For the assessment of the financial soundness of a pension fund, it is\nnecessary to take into account mortality forecasting so that longevity risk is\nconsistently incorporated into future cash flows. In this article, we employ\nmachine learning models applied to actuarial science ({\\it actuarial learning})\nto make mortality predictions for a relevant sample of pension funds'\nparticipants. Actuarial learning represents an emerging field that involves the\napplication of machine learning (ML) and artificial intelligence (AI)\ntechniques in actuarial science. This encompasses the use of algorithms and\ncomputational models to analyze large sets of actuarial data, such as\nregression trees, random forest, boosting, XGBoost, CatBoost, and neural\nnetworks (eg. FNN, LSTM, and MHA). Our results indicate that some ML/AI\nalgorithms present competitive out-of-sample performance when compared to the\nclassical Lee-Carter model. This may indicate interesting alternatives for\nconsistent liability evaluation and effective pension fund risk management.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-08T10:09:41Z"}
{"aid":"http://arxiv.org/abs/2504.05888v1","title":"UVG-VPC: Voxelized Point Cloud Dataset for Visual Volumetric Video-based\n  Coding","summary":"Point cloud compression has become a crucial factor in immersive visual media\nprocessing and streaming. This paper presents a new open dataset called UVG-VPC\nfor the development, evaluation, and validation of MPEG Visual Volumetric\nVideo-based Coding (V3C) technology. The dataset is distributed under its own\nnon-commercial license. It consists of 12 point cloud test video sequences of\ndiverse characteristics with respect to the motion, RGB texture, 3D geometry,\nand surface occlusion of the points. Each sequence is 10 seconds long and\ncomprises 250 frames captured at 25 frames per second. The sequences are\nvoxelized with a geometry precision of 9 to 12 bits, and the voxel color\nattributes are represented as 8-bit RGB values. The dataset also includes\nassociated normals that make it more suitable for evaluating point cloud\ncompression solutions. The main objective of releasing the UVG-VPC dataset is\nto foster the development of V3C technologies and thereby shape the future in\nthis field.","main_category":"cs.MM","categories":"cs.MM,cs.CV","published":"2025-04-08T10:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.05929v1","title":"Cohomology and deformations of restricted Lie algebras and their\n  morphisms in positive characteristic","summary":"The main purpose of this paper is to study cohomology and develop a\ndeformation theory of restricted Lie algebras in positive characteristic $p>0$.\nIn the case $p\\geq3$, it is shown that the deformations of restricted Lie\nalgebras are controlled by the restricted cohomology introduced by Evans and\nFuchs. Moreover, we introduce a new cohomology that controls the deformations\nof restricted morphisms of restricted Lie algebras. In the case $p=2$, we\nprovide a full restricted cohomology complex with values in a restricted module\nand investigate its connections with formal deformations. Furthermore, we\nintroduce a full deformation cohomology that controls deformations of\nrestricted morphisms of restricted Lie algebras in characteristic $2$. As\nexample, we discuss restricted cohomology with adjoint coefficients of\nrestricted Heisenberg Lie algebras in characteristic $p\\geq 2$.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T11:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.05937v1","title":"On the Hamilton-Jacobi approach to inflation beyond slow roll","summary":"The Hamilton-Jacobi approach is a powerful tool to describe super-Hubble\ndynamics during cosmological inflation in a non-linear way. A key assumption of\nthis framework is to neglect anisotropic perturbations on large scales. We show\nthat neglecting the anisotropic sector in the momentum constraint corresponds\nto discarding the non-adiabatic mode of scalar-field perturbations at large\nscales. Consequently, the Hamilton-Jacobi approach cannot be used to describe\nthe evolution of large-scale perturbations during inflation beyond slow roll,\nwhen non-adiabatic fluctuations play an important role on super-Hubble scales\ndue to the absence of an attractor trajectory. As an example, we analyse the\ncase of cosmological perturbations during a phase of ultra-slow-roll inflation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-08T11:52:44Z"}
{"aid":"http://arxiv.org/abs/2504.05944v1","title":"Laminar chaos in systems with random and chaotically time-varying delay","summary":"A type of chaos called laminar chaos was found in singularly perturbed\ndynamical systems with periodically [Phys. Rev. Lett. 120, 084102 (2018)] and\nquasiperiodically [Phys. Rev. E 107, 014205 (2023)] time-varying delay.\nCompared to high-dimensional turbulent chaos that is typically found in such\nsystems with large constant delay, laminar chaos is a very low-dimensional\nphenomenon. It is characterized by a time series with nearly constant laminar\nphases that are interrupted by irregular bursts, where the intensity level of\nthe laminar phases varies chaotically from phase to phase. In this paper, we\ndemonstrate that laminar chaos, and its generalizations, can also be observed\nin systems with random and chaotically time-varying delay. Moreover, while for\nperiodic and quasiperiodic delays the appearance of (generalized) laminar chaos\nand turbulent chaos depends in a fractal manner on the delay parameters, it\nturns out that short-time correlated random and chaotic delays lead to\n(generalized) laminar chaos in almost the whole delay parameter space, where\nthe properties of circle maps with quenched disorder play a crucial role. It\nfollows that introducing such a delay variation typically leads to a drastic\nreduction of the dimension of the chaotic attractor of the considered systems.\nWe investigate the dynamical properties and generalize the known methods for\ndetecting laminar chaos in experimental time series to random and chaotically\ntime-varying delay.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-08T11:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.05949v1","title":"Sharp fractional Hardy's inequality for half-spaces in the Heisenberg\n  group","summary":"In this work we establish the following fractional Hardy's inequality\n  $$C\\int_{\\mathbb{H}^n_+}\\frac{|f(\\xi)|^p}{x_1^{sp+\\alpha}}d\\xi\\leq\n\\int_{\\mathbb{H}^n}\\int_{\\mathbb{H}^n}\\frac{|f(\\xi)-f(\\xi')|^p}{d({\\xi}^{-1}\\circ\n\\xi')^{Q+sp}|z'-z|^\\alpha}d\\xi'd\\xi,\\ \\ \\forall f\\in\nC_c^{\\infty}(\\mathbb{H}^n_+)$$\n  for the half-space\n$\\{\\xi=(x,y,t)=(x_1,\\ldots,x_n,y_1,\\ldots,y_n)\\in\\mathbb{H}^n:x_1>0\\}$ in the\nHeisenberg group $\\mathbb{H}^n$ without any restriction on parameters, and\ncompute the corresponding sharp constant. In a previous joint work, we\nestablished a variant of Hardy's inequality for the same half-space, but with\ncertain parameter restrictions. However, all integrals in that work were\nconsidered over half-spaces, and here the seminorm is taken over the entire\n$\\mathbb{H}^n$. Although this inequality holds for all values of the quantity\n$sp+\\alpha$, we are only able to compute the corresponding sharp constant when\n$sp+\\alpha>1$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.05952v1","title":"Contrasting magnetism in VPS3 and CrI3 monolayers with the common\n  honeycomb S = 3/2 spin lattice","summary":"Two-dimensional (2D) magnetic materials are promising candidates for\nspintronics and quantum technologies. One extensively studied example is the\nferromagnetic (FM) CrI$_3$ monolayer with the honeycomb Cr$^{3+}$ ($t_{2g}^3$,\n$S$ = 3/2) spin lattice, while VPS$_3$ has a same honeycomb $S$ = 3/2 spin\nlattice (V$^{2+}$, $t_{2g}^3$) but displays N$\\acute{e}$el antiferromagnetism\n(AFM). In this work, we study the electronic structure and particularly the\ncontrasting magnetism of VPS$_3$ and CrI$_3$ monolayers. We find that VPS$_3$\nis a Mott-Hubbard insulator but CrI$_3$ is a charge-transfer insulator, and\ntherefore their magnetic exchange mechanisms are essentially different. The\nfirst nearest-neighbor (1NN) direct $d$-$d$ exchange dominates in VPS$_3$, thus\nleading to a strong antiferromagnetic (AF) coupling. However, the formation of\nvanadium vacancies, associated with instability of the low-valence V$^{2+}$\nions, suppresses the AF coupling and thus strongly reduces the N$\\acute{e}$el\ntemperature ($T_{\\text{N}}$) in line with the experimental observation. In\ncontrast, our results reveal that the major 1NN $d$-$p$-$d$ superexchanges in\nCrI$_3$ via different channels give rise to competing FM and AF couplings,\nultimately resulting in a weak FM coupling as observed experimentally. After\nrevisiting several important superexchange channels reported in the literature,\nbased on our MLWFs and tight-binding analyses, we note that some antiphase\ncontributions must be subtly and simultaneously considered, and thus we provide\na deeper insight into the FM coupling of CrI$_3$. Moreover, we identify and\ncompare the major contributions to the magnetic anisotropy, i.e., a weak shape\nanisotropy in VPS$_3$ and a relatively strong exchange anisotropy in CrI$_3$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T12:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.05955v1","title":"Fair Resource Allocation in UAV-based Semantic Communication System with\n  Fluid Antenna","summary":"In this paper, the problem of maximization of the minimum equivalent rate in\na unmanned-aerial-vehicle (UAV)-based multi-user semantic communication system\nis investigated. In the considered model, a multi-antenna UAV employs semantic\nextraction techniques to compress the data ready to be sent to the users, which\nare equipped with fluid antennas. Our aim is to jointly optimize the trajectory\nof the UAV, the transmit beamforming and the semantic compression rate at the\nUAV, as well as the selection of activated ports in fluid antenna system (FAS),\nto maximize the minimum equivalent transmission rate among all user. An\nalternating algorithm is designed to solve the problem. Simulation results\nvalidate the effectiveness of the proposed algorithm.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T12:10:55Z"}
{"aid":"http://arxiv.org/abs/2504.05976v1","title":"A Knowledge Base for Arts and Inclusion -- The Dataverse data archival\n  platform as a knowledge base management system enabling multimodal\n  accessibility","summary":"Creating an inclusive art environment requires engaging multiple senses for a\nfully immersive experience. Culture is inherently synesthetic, enriched by all\nsenses within a shared time and space. In an optimal synesthetic setting,\npeople of all abilities can connect meaningfully; when one sense is\ncompromised, other channels can be enhanced to compensate. This is the power of\nmultimodality. Digital technology is increasingly able to capture aspects of\nmultimodality. To document multimodality aspects of cultural practices and\nproducts for the long-term remains a challenge. Many artistic products from the\nperforming arts tend to be multimodal, and are often immersive, so only a\nmultimodal repository can offer a platform for this work. To our knowledge\nthere is no single, comprehensive repository with a knowledge base to serve\narts and disability. By knowledge base, we mean classifications, taxonomies, or\nontologies (in short, knowledge organisation systems). This paper presents\ninnovative ways to develop a knowledge base which capture multimodal features\nof archived representations of cultural assets, but also indicate various forms\nhow to interact with them including machine-readable description. We will\ndemonstrate how back-end and front-end applications, in a combined effort, can\nsupport accessible archiving and data management for complex digital objects\nborn out of artistic practices and make them available for wider audiences.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-08T12:33:12Z"}
{"aid":"http://arxiv.org/abs/2504.05980v1","title":"Langevin dynamics with generalized time-reversal symmetry","summary":"When analyzing the equilibrium properties of a stochastic process,\nidentifying the parity of the variables under time-reversal is imperative. This\ninitial step is required to assess the presence of detailed balance, and to\ncompute the entropy production rate, which is, otherwise, ambiguously defined.\nIn this work we deal with stochastic processes whose underlying time-reversal\nsymmetry cannot be reduced to the usual parity rules (namely, flip of the\nmomentum sign). We provide a systematic method to build equilibrium Langevin\ndynamics starting from their reversible deterministic counterparts: this\nstrategy can be applied, in particular, to all stable one-dimensional\nHamiltonian dynamics, exploiting the time-reversal symmetry unveiled in the\naction-angle framework. The case of the Lotka-Volterra model is discussed as an\nexample. We also show that other stochastic versions of this system violate\ntime-reversal symmetry and are, therefore, intrinsically out of equilibrium.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T12:36:30Z"}
{"aid":"http://arxiv.org/abs/2504.05981v1","title":"Arbitrary polarization retarders and polarization controllers,\n  constructed from sequences of half-wave and quarter-wave plates","summary":"We theoretically introduce several types of arbitrary polarization retarders\nconstructed from sequences of half-wave and quarter-wave plates, each rotated\nat specific angles. By integrating these arbitrary polarization retarders with\narbitrary polarization rotators, we develop a versatile device capable of\nperforming arbitrary-to-arbitrary polarization transformations. While some of\nthe proposed devices are documented in the literature, others are novel and, to\nthe best of our knowledge, have not been previously presented. The continuous\nadjustment of retardance and rotation in these devices is achieved by altering\nthe relative orientation of the wave plates in the sequence.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T12:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.05987v1","title":"Learning-enhanced electronic skin for tactile sensing on deformable\n  surface based on electrical impedance tomography","summary":"Electrical Impedance Tomography (EIT)-based tactile sensors offer\ncost-effective and scalable solutions for robotic sensing, especially promising\nfor soft robots. However a major issue of EIT-based tactile sensors when\napplied in highly deformable objects is their performance degradation due to\nsurface deformations. This limitation stems from their inherent sensitivity to\nstrain, which is particularly exacerbated in soft bodies, thus requiring\ndedicated data interpretation to disentangle the parameter being measured and\nthe signal deriving from shape changes. This has largely limited their\npractical implementations. This paper presents a machine learning-assisted\ntactile sensing approach to address this challenge by tracking surface\ndeformations and segregating this contribution in the signal readout during\ntactile sensing. We first capture the deformations of the target object,\nfollowed by tactile reconstruction using a deep learning model specifically\ndesigned to process and fuse EIT data and deformation information. Validations\nusing numerical simulations achieved high correlation coefficients (0.9660 -\n0.9999), peak signal-to-noise ratios (28.7221 - 55.5264 dB) and low relative\nimage errors (0.0107 - 0.0805). Experimental validations, using a\nhydrogel-based EIT e-skin under various deformation scenarios, further\ndemonstrated the effectiveness of the proposed approach in real-world settings.\nThe findings could underpin enhanced tactile interaction in soft and highly\ndeformable robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T12:49:54Z"}
{"aid":"http://arxiv.org/abs/2504.05990v1","title":"AI analysis of medical images at scale as a health disparities probe: a\n  feasibility demonstration using chest radiographs","summary":"Health disparities (differences in non-genetic conditions that influence\nhealth) can be associated with differences in burden of disease by groups\nwithin a population. Social determinants of health (SDOH) are domains such as\nhealth care access, dietary access, and economics frequently studied for\npotential association with health disparities. Evaluating SDOH-related\nphenotypes using routine medical images as data sources may enhance health\ndisparities research. We developed a pipeline for using quantitative measures\nautomatically extracted from medical images as inputs into health disparities\nindex calculations. Our study focused on the use case of two SDOH demographic\ncorrelates (sex and race) and data extracted from chest radiographs of 1,571\nunique patients. The likelihood of severe disease within the lung parenchyma\nfrom each image type, measured using an established deep learning model, was\nmerged into a single numerical image-based phenotype for each patient. Patients\nwere then separated into phenogroups by unsupervised clustering of the\nimage-based phenotypes. The health rate for each phenogroup was defined as the\nmedian image-based phenotype for each SDOH used as inputs to four\nimaging-derived health disparities indices (iHDIs): one absolute measure\n(between-group variance) and three relative measures (index of disparity, Theil\nindex, and mean log deviation). The iHDI measures demonstrated feasible values\nfor each SDOH demographic correlate, showing potential for medical images to\nserve as a novel probe for health disparities. Large-scale AI analysis of\nmedical images can serve as a probe for a novel data source for health\ndisparities research.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-04-08T12:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.05993v1","title":"Strong Evidence That Abiogenesis Is a Rapid Process on Earth Analogs","summary":"The early start to life naively suggests that abiogenesis is a rapid process\non Earth-like planets. However, if evolution typically takes ~4Gyr to produce\nintelligent life-forms like us, then the limited lifespan of Earth's biosphere\n(~5-6Gyr) necessitates an early (and possibly highly atypical) start to our\nemergence - an example of the weak anthropic principle. Our previously proposed\nobjective Bayesian analysis of Earth's chronology culminated in a formula for\nthe minimum odds ratio between the fast and slow abiogenesis scenarios\n(relative to Earth's lifespan). Timing from microfossils (3.7Gya) yields 3:1\nodds in favor of rapid abiogenesis, whereas evidence from carbon isotopes\n(4.1Gya) gives 9:1, both below the canonical threshold of \"strong evidence\"\n(10:1). However, the recent result of a 4.2Gya LUCA pushes the odds over the\nthreshold for the first time (nominally 13:1). In fact, the odds ratio is >10:1\nfor all possible values of the biosphere's ultimate lifespan and speculative\nhypotheses of ancient civilizations. For the first time, we have formally\nstrong evidence that favors the hypothesis that life rapidly emerges in\nEarth-like conditions (although such environments may themselves be rare).","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-08T12:55:50Z"}
{"aid":"http://arxiv.org/abs/2504.05998v1","title":"Can gravity mediate the transmission of quantum information?","summary":"We propose an experiment to test the non-classicality of the gravitational\ninteraction. We consider two optomechanical systems that are perfectly\nisolated, except for a weak gravitational coupling. If a suitable resonance\ncondition is satisfied, an optical signal can be transmitted from one system to\nthe other over a narrow frequency band, a phenomenon that we call\ngravitationally induced transparency. In this framework, the challenging\nproblem of testing the quantum nature of gravity is mapped to the easier task\nof determining the non-classicality of the gravitationally-induced optical\nchannel: If the optical channel is not entanglement-breaking, then gravity must\nhave a quantum nature. This approach is applicable without making any\nassumption on the, currently unknown, correct model of gravity in the quantum\nregime. In the second part of this work, we model gravity as a quadratic\nHamiltonian interaction (e.g. a weak Newtonian force), resulting in a Gaussian\nthermal attenuator channel between the two systems. Depending on the strength\nof thermal noise, the system presents a sharp transition from an\nentanglement-breaking to a non-classical channel capable not only of\nentanglement preservation but also of asymptotically perfect quantum\ncommunication.","main_category":"quant-ph","categories":"quant-ph,gr-qc","published":"2025-04-08T13:03:58Z"}
{"aid":"http://arxiv.org/abs/2504.06003v1","title":"econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic\n  Gaussians","summary":"The primary focus of most recent works on open-vocabulary neural fields is\nextracting precise semantic features from the VLMs and then consolidating them\nefficiently into a multi-view consistent 3D neural fields representation.\nHowever, most existing works over-trusted SAM to regularize image-level CLIP\nwithout any further refinement. Moreover, several existing works improved\nefficiency by dimensionality reduction of semantic features from 2D VLMs before\nfusing with 3DGS semantic fields, which inevitably leads to multi-view\ninconsistency. In this work, we propose econSG for open-vocabulary semantic\nsegmentation with 3DGS. Our econSG consists of: 1) A Confidence-region Guided\nRegularization (CRR) that mutually refines SAM and CLIP to get the best of both\nworlds for precise semantic features with complete and precise boundaries. 2) A\nlow dimensional contextual space to enforce 3D multi-view consistency while\nimproving computational efficiency by fusing backprojected multi-view 2D\nfeatures and follow by dimensional reduction directly on the fused 3D features\ninstead of operating on each 2D view separately. Our econSG shows\nstate-of-the-art performance on four benchmark datasets compared to the\nexisting methods. Furthermore, we are also the most efficient training among\nall the methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.06008v1","title":"Impact of newly measured $Î²$\\nobreakdash-delayed neutron emitters\n  around \\myisoSimp{78}{Ni} on light element nucleosynthesis in the\n  neutrino-wind following a neutron star merger","summary":"Neutron emission probabilities and half-lives of 37 beta-delayed neutron\nemitters from 75Ni to 92Br were measured at the RIKEN Nishina Center in Japan,\nincluding 11 one-neutron and 13 two-neutron emission probabilities and 6\nhalf-lives measured for the first time, which supersede theoretical estimates.\nThese nuclei lie in the path of the weak r-process occurring in neutrino-driven\nwinds from the accretion disk formed after the merger of two neutron stars,\nsynthesizing elements in the A~80 abundance peak. The presence of such elements\ndominates the accompanying kilonova emission over the first few days and has\nbeen identified in the AT2017gfo event, associated with the gravitational wave\ndetection GW170817.\n  Abundance calculations based on over 17000 simulated trajectories describing\nthe evolution of matter properties in the merger outflows show that the new\ndata lead to an increase of 50-70 percent in the abundance of Y, Zr, Nb, and\nMo. This enhancement is large compared to the scatter of relative abundances\nobserved in old very metal-poor stars and is therefore significant in the\ncomparison with other possible astrophysical processes contributing to\nlight-element production.\n  These results underline the importance of including experimental decay data\nfor very neutron-rich beta-delayed neutron emitters into r-process models.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-08T13:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.06015v1","title":"Robust Statistics vs. Machine Learning vs. Bayesian Inference: Insights\n  into Handling Faulty GNSS Measurements in Field Robotics","summary":"This paper presents research findings on handling faulty measurements (i.e.,\noutliers) of global navigation satellite systems (GNSS) for robot localization\nunder adverse signal conditions in field applications, where raw GNSS data are\nfrequently corrupted due to environmental interference such as multipath,\nsignal blockage, or non-line-of-sight conditions. In this context, we\ninvestigate three strategies applied specifically to GNSS pseudorange\nobservations: robust statistics for error mitigation, machine learning for\nfaulty measurement prediction, and Bayesian inference for noise distribution\napproximation. Since previous studies have provided limited insight into the\ntheoretical foundations and practical evaluations of these three methodologies\nwithin a unified problem statement (i.e., state estimation using ranging\nsensors), we conduct extensive experiments using real-world sensor data\ncollected in diverse urban environments. Our goal is to examine both\nestablished techniques and newly proposed methods, thereby advancing the\nunderstanding of how to handle faulty range measurements, such as GNSS, for\nrobust, long-term robot localization. In addition to presenting successful\nresults, this work highlights critical observations and open questions to\nmotivate future research in robust state estimation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T13:21:04Z"}
{"aid":"http://arxiv.org/abs/2504.06021v1","title":"Memory-Modular Classification: Learning to Generalize with Memory\n  Replacement","summary":"We propose a novel memory-modular learner for image classification that\nseparates knowledge memorization from reasoning. Our model enables effective\ngeneralization to new classes by simply replacing the memory contents, without\nthe need for model retraining. Unlike traditional models that encode both world\nknowledge and task-specific skills into their weights during training, our\nmodel stores knowledge in the external memory of web-crawled image and text\ndata. At inference time, the model dynamically selects relevant content from\nthe memory based on the input image, allowing it to adapt to arbitrary classes\nby simply replacing the memory contents. The key differentiator that our\nlearner meta-learns to perform classification tasks with noisy web data from\nunseen classes, resulting in robust performance across various classification\nscenarios. Experimental results demonstrate the promising performance and\nversatility of our approach in handling diverse classification tasks, including\nzero-shot/few-shot classification of unseen classes, fine-grained\nclassification, and class-incremental classification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.06029v1","title":"Red giant component of the recurrent nova T Coronae Borealis","summary":"We performed simultaneous V band photometry and spectroscopic observations of\nthe recurrent nova T CrB and estimate the V band magnitude of the red giant. We\nfind for the red giant of T CrB apparent and absolute V-band magnitudes m_V =\n10.17 +/- 0.06 and M_V = +0.14 +/- 0.08, respectively. At the maximum of the\nellipsoidal variation when these values are obtained, its absolute V-band\nmagnitude is similar but fainter than the typical M4/5III giants. The data are\navailable on : zenodo.org/records/15174720","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T13:34:05Z"}
{"aid":"http://arxiv.org/abs/2504.06034v1","title":"Distance to M87 as the Mode of the Modulus Distribution","summary":"de Grijs and Bono (ApJS 2020, 246, 3) compiled a list of distances to M87\nfrom the literature published in the last 100 years. They reported the\narithmetic mean of the three most stable tracers (Cepheids, tip of the red\ngiant branch, and surface brightness fluctuations). The arithmetic mean is one\nof the measures of central tendency of a distribution; others are the median\nand mode. The three do not align for asymmetric distributions, which is the\ncase for the distance moduli $\\mu_0$ to M87. I construct a kernel density\ndistribution of the set of $\\mu_0$ and estimate the recommended distance to M87\nas its mode, obtaining $\\mu_0 =\n\\left(31.06~\\pm~0.001\\,\\textrm{(statistical)}\\,^{+0.04}_{-0.06}\\,\\textrm{(systematic)}\\right)$~mag,\ncorresponding to \\linebreak $D=16.29^{+0.30}_{-0.45}$~Mpc, which yields\nuncertainties smaller than those associated with the mean and median.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T13:35:55Z"}
{"aid":"http://arxiv.org/abs/2504.06060v1","title":"Fast summation of fermionic Feynman diagrams beyond Bravais Lattices and\n  on-site Hubbard interactions","summary":"We designed new algorithms for summing bold-line Feynman diagrams in\narbitrary channels, where it can be readily modified for bare interaction\nseries as well. When applied to magnetic channel bold-line series with on-site\nHubbard interactions, the algorithm achieves competitive performance compared\nwith the state-of-art RPADet. We then generalize it beyond square lattice and\non-site Hubbard interactions and achieve better scaling in the number of sites\nwithin a unit cell, while there is substantial increase when there are more\ntypes of interactions. This work paves the way of diagrammatic Monte Carlo\nsimulations for real materials, holding the premise for a robust replacement of\nstate-of-art simulation tools in the thermodynamical limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T14:04:46Z"}
{"aid":"http://arxiv.org/abs/2504.06066v1","title":"The Quantum Double of Hopf Algebras Realized via Partial Dualization and\n  the Tensor Category of Its Representations","summary":"In this paper, we aim to study the (generalized) quantum double\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ determined by a (skew) pairing between\nfinite-dimensional Hopf algebras $K^{\\ast\\mathrm{cop}}$ and $H$, especially the\ntensor category $\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ of its\nfinite-dimensional representations. Specifically, we show that\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ is a left partially dualized\n(quasi-)Hopf algebra of $K^\\mathrm{op}\\otimes H$, and use this formulation to\nestablish tensor equivalences from\n$\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ to the categories\n${}^K_K\\mathcal{M}^K_H$ and ${}^{K^\\ast}_{K^\\ast}\\mathcal{M}^{H^\\ast}_{K^\\ast}$\nof two-sided two-cosided relative Hopf modules, as well as the category\n${}_H\\mathfrak{YD}^K$ of relative Yetter-Drinfeld modules.","main_category":"math.QA","categories":"math.QA,math.CT,math.RA","published":"2025-04-08T14:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.06071v1","title":"On Onsager-type conjecture for the ElsÃ¤sser energies of the ideal\n  MHD equations","summary":"In this paper, we investigate the ideal magnetohydrodynamics (MHD) equations\non tours $\\TTT^d$. For $d=3$, we resolve the flexible part of Onsager-type\nconjecture for Els\\\"{a}sser energies of the ideal MHD equations. More\nprecisely, for \\(\\beta < 1/3\\), we construct weak solutions \\((u, b) \\in\nC^\\beta([0,T] \\times \\mathbb{T}^3)\\) with both the total energy dissipation and\nfailure of cross helicity conservation. The key idea of the proof relies on a\nsymmetry reduction that embeds the ideal MHD system into a 2$\\frac{1}{2}$D\nEuler flow and the Newton-Nash iteration technique recently developed in\n\\cite{GR}. For $d=2$, we show the non-uniqueness of H\\\"{o}lder-continuous weak\nsolutions with non-trivial magnetic fields. Specifically, for \\(\\beta < 1/5\\),\nthere exist infinitely many solutions \\((u, b) \\in C^\\beta([0,T] \\times\n\\mathbb{T}^2)\\) with the same initial data while satisfying the total energy\ndissipation with non-vanishing velocity and magnetic fields. The new ingredient\nis developing a spatial-separation-driven iterative scheme that incorporates\nthe magnetic field as a controlled perturbation within the convex integration\nframework for the velocity field, thereby providing sufficient oscillatory\nfreedom for Nash-type perturbations in the 2D setting. As a byproduct, we prove\nthat any H\\\"{o}lder-continuous Euler solution can be approximated by a sequence\nof $C^\\beta$-weak solutions for the ideal MHD equations in the $L^p$-topology\nfor $1\\le p<\\infty$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T14:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.06090v1","title":"Low-Complexity SDP-ADMM for Physical-Layer Multicasting in Massive MIMO\n  Systems","summary":"There is a demand for the same data content from several user equipments\n(UEs) in many wireless communication applications. Physical-layer multicasting\ncombines the beamforming capability of massive MIMO (multiple-input\nmultiple-output) and the broadcast nature of the wireless channel to\nefficiently deliver the same data to a group of UEs using a single\ntransmission. This paper tackles the max-min fair (MMF) multicast beamforming\noptimization, which is an NP-hard problem. We develop an efficient semidefinite\nprogram-alternating direction method of multipliers (SDP-ADMM) algorithm to\nfind the near-global optimal rank-1 solution to the MMF multicast problem in a\nmassive MIMO system. Numerical results show that the proposed SDP-ADMM\nalgorithm exhibits similar spectral efficiency performance to state-of-the-art\nalgorithms running on standard SDP solvers at a vastly reduced computational\ncomplexity. We highlight that the proposed ADMM elimination procedure can be\nemployed as an effective low-complexity rank reduction method for other\nproblems utilizing semidefinite relaxation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T14:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.06095v1","title":"Nonuniform-Tensor-Parallelism: Mitigating GPU failure impact for\n  Scaled-up LLM Training","summary":"LLM training is scaled up to 10Ks of GPUs by a mix of data-(DP) and\nmodel-parallel (MP) execution. Critical to achieving efficiency is\ntensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of\nGPUs, referred to as a scale-up domain, and the larger the scale-up domain the\nbetter the performance. New datacenter architectures are emerging with more\nGPUs able to be tightly-coupled in a scale-up domain, such as moving from 8\nGPUs to 72 GPUs connected via NVLink. Unfortunately, larger scale-up domains\nincrease the blast-radius of failures, with a failure of single GPU potentially\nimpacting TP execution on the full scale-up domain, which can degrade overall\nLLM training throughput dramatically. With as few as 0.1% of GPUs being in a\nfailed state, a high TP-degree job can experience nearly 10% reduction in LLM\ntraining throughput. We propose nonuniform-tensor-parallelism (NTP) to mitigate\nthis amplified impact of GPU failures. In NTP, a DP replica that experiences\nGPU failures operates at a reduced TP degree, contributing throughput equal to\nthe percentage of still-functional GPUs. We also propose a rack-design with\nimproved electrical and thermal capabilities in order to sustain power-boosting\nof scale-up domains that have experienced failures; combined with NTP, this can\nallow the DP replica with the reduced TP degree (i.e., with failed GPUs) to\nkeep up with the others, thereby achieving near-zero throughput loss for\nlarge-scale LLM training.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-08T14:35:40Z"}
{"aid":"http://arxiv.org/abs/2504.06117v1","title":"Some Analytical Properties of Multivariate Fractal Functions in Lebesgue\n  Spaces","summary":"In this article, we focus on the construction of multivariate fractal\nfunctions in Lebesgue spaces along with some properties of associated fractal\noperator. First, we give a detailed construction of the fractal functions\nbelonging to Lebesgue spaces. Then, we give analytical properties of the\ndefined fractal operator in Lebesgue spaces. We end this article by showing the\nexistence of Schauder basis of the associated fractal functions for the space\n$\\mathcal{L}^q(I^n, \\mu_p)$.","main_category":"math.FA","categories":"math.FA","published":"2025-04-08T15:10:39Z"}
{"aid":"http://arxiv.org/abs/2504.06147v1","title":"Noncommutative resolutions and CICY quotients from a non-abelian GLSM","summary":"We discuss a one-parameter non-abelian GLSM with gauge group $(U(1)\\times\nU(1)\\times U(1))\\rtimes\\mathbb{Z}_3$ and its associated Calabi-Yau phases. The\nlarge volume phase is a free $\\mathbb{Z}_3$-quotient of a codimension $3$\ncomplete intersection of degree-$(1,1,1)$ hypersurfaces in\n$\\mathbb{P}^2\\times\\mathbb{P}^2\\times\\mathbb{P}^2$. The associated Calabi-Yau\ndifferential operator has a second point of maximal unipotent monodromy,\nleading to the expectation that the other GLSM phase is geometric as well.\nHowever, the associated GLSM phase appears to be a hybrid model with continuous\nunbroken gauge symmetry and cubic superpotential, together with a Coulomb\nbranch. Using techniques from topological string theory and mirror symmetry we\ncollect evidence that the phase should correspond to a non-commutative\nresolution, in the sense of Katz-Klemm-Schimannek-Sharpe, of a codimension two\ncomplete intersection in weighted projective space with $63$ nodal points, for\nwhich a resolution has $\\mathbb{Z}_3$-torsion. We compute the associated\nGopakumar-Vafa invariants up to genus $11$, incorporating their torsion\nrefinement. We identify two integral symplectic bases constructed from\ntopological data of the mirror geometries in either phase.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T15:42:39Z"}
{"aid":"http://arxiv.org/abs/2504.06158v1","title":"Rethinking the Nested U-Net Approach: Enhancing Biomarker Segmentation\n  with Attention Mechanisms and Multiscale Feature Fusion","summary":"Identifying biomarkers in medical images is vital for a wide range of biotech\napplications. However, recent Transformer and CNN based methods often struggle\nwith variations in morphology and staining, which limits their feature\nextraction capabilities. In medical image segmentation, where data samples are\noften limited, state-of-the-art (SOTA) methods improve accuracy by using\npre-trained encoders, while end-to-end approaches typically fall short due to\ndifficulties in transferring multiscale features effectively between encoders\nand decoders. To handle these challenges, we introduce a nested UNet\narchitecture that captures both local and global context through Multiscale\nFeature Fusion and Attention Mechanisms. This design improves feature\nintegration from encoders, highlights key channels and regions, and restores\nspatial details to enhance segmentation performance. Our method surpasses SOTA\napproaches, as evidenced by experiments across four datasets and detailed\nablation studies. Code: https://github.com/saadwazir/ReN-UNet","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T15:53:46Z"}
{"aid":"http://arxiv.org/abs/2504.06164v1","title":"Functional ItÃ´-formula and Taylor expansions for non-anticipative maps\n  of cÃ dlÃ g rough paths","summary":"We derive a functional It\\^o-formula for non-anticipative maps of rough\npaths, based on the approximation properties of the signature of c\\`adl\\`ag\nrough paths. This result is a functional extension of the It\\^o-formula for\nc\\`adl\\`ag rough paths (by Friz and Zhang (2018)), which coincides with the\nchange of variable formula formulated by Dupire (2009) whenever the\nfunctionals' representations, the notions of regularity, and the integration\nconcepts can be matched. Unlike these previous works, we treat the vertical\n(jump) pertubation via the Marcus transformation, which allows for\nincorporating path functionals where the second order vertical derivatives do\nnot commute, as is the case for typical signature functionals. As a byproduct,\nwe show that sufficiently regular non-anticipative maps admit a functional\nTaylor expansion in terms of the path's signature, leading to an important\ngeneralization of the recent results by Dupire and Tissot-Daguette (2022).","main_category":"math.PR","categories":"math.PR,math.CA,q-fin.MF","published":"2025-04-08T16:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.06168v1","title":"Differential diffusion effects and super-adiabatic local temperature in\n  lean hydrogen-air turbulent flames","summary":"Analyzed in this paper are three-dimensional Direct Numerical Simulation\n(DNS) data obtained from seven statistically planar and one-dimensional, lean\ncomplex-chemistry hydrogen-air flames propagating in a box with forced\nturbulence. The simulation conditions cover a wide range of non-dimensional\nturbulent combustion characteristics. Specifically, root-mean-square turbulent\nvelocity is varied from 2.2 to 54 laminar flame speeds, integral length scale\nof turbulence is varied from 0.5 to 2.2 laminar flame thicknesses, Damk\\\"ohler\nand Karlovitz number are varied from 0.01 to 0.53 and from 10 to 1315,\nrespectively. Two equivalence ratios, 0.5 and 0.35, are explored. Turbulent\nburning velocities are evaluated for these seven low Lewis number flames and\nequidiffusion counterparts to six of them. Moreover, conditioned profiles of\ntemperature, fuel consumption and heat release rates and probabilities of\nfinding superadiabatic temperature are sampled from all seven low Lewis number\nflames. Analyses of obtained results show that both magnitude of superadiabatic\ntemperature and probability of finding it are decreased with increasing\nKarlovitz number Ka. However, significant influence of differential diffusion\neffects on local structure of flame reaction zones and bulk burning velocity is\nwell pronounced in all cases, even at Ka as high as 1315. Therefore, a decrease\nin magnitude of superadiabatic local temperature with increasing Karlovitz\nnumber or even negligible probability of finding such a high temperature at\nhigh Ka is not an evidence that differential diffusion effects play a minor\nrole under such conditions. The simulated mitigation of phenomenon of\nsuperadiabatic temperature at high Ka is attributed to intensification of\nturbulent mixing in local flame oxidation zones, rather than weakening\ndifferential diffusion effects in local flame reaction zones.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T16:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.06171v1","title":"Generalized Ridge Regression: Applications to Nonorthogonal Linear\n  Regression Models","summary":"This paper analyzes the possibilities of using the generalized ridge\nregression to mitigate multicollinearity in a multiple linear regression model.\nFor this purpose, we obtain the expressions for the estimated variance, the\ncoefficient of variation, the coefficient of correlation, the variance\ninflation factor and the condition number. The results obtained are illustrated\nwith two numerical examples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T16:16:31Z"}
{"aid":"http://arxiv.org/abs/2504.06173v1","title":"Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles\n  Using Deep Learning","summary":"Beamforming techniques are considered as essential parts to compensate severe\npath losses in millimeter-wave (mmWave) communications. In particular, these\ntechniques adopt large antenna arrays and formulate narrow beams to obtain\nsatisfactory received powers. However, performing accurate beam alignment over\nnarrow beams for efficient link configuration by traditional standard defined\nbeam selection approaches, which mainly rely on channel state information and\nbeam sweeping through exhaustive searching, imposes computational and\ncommunications overheads. And, such resulting overheads limit their potential\nuse in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications involving highly dynamic scenarios. In comparison, utilizing\nout-of-band contextual information, such as sensing data obtained from sensor\ndevices, provides a better alternative to reduce overheads. This paper presents\na deep learning-based solution for utilizing the multi-modality sensing data\nfor predicting the optimal beams having sufficient mmWave received powers so\nthat the best V2I and V2V line-of-sight links can be ensured proactively. The\nproposed solution has been tested on real-world measured mmWave sensing and\ncommunication data, and the results show that it can achieve up to 98.19%\naccuracies while predicting top-13 beams. Correspondingly, when compared to\nexisting been sweeping approach, the beam sweeping searching space and time\noverheads are greatly shortened roughly by 79.67% and 91.89%, respectively\nwhich confirm a promising solution for beamforming in mmWave enabled\ncommunications.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.ET,cs.LG,eess.SP","published":"2025-04-08T16:18:00Z"}
{"aid":"http://arxiv.org/abs/2504.06207v1","title":"An experimental survey and Perspective View on Meta-Learning for\n  Automated Algorithms Selection and Parametrization","summary":"Considerable progress has been made in the recent literature studies to\ntackle the Algorithms Selection and Parametrization (ASP) problem, which is\ndiversified in multiple meta-learning setups. Yet there is a lack of surveys\nand comparative evaluations that critically analyze, summarize and assess the\nperformance of existing methods. In this paper, we provide an overview of the\nstate of the art in this continuously evolving field. The survey sheds light on\nthe motivational reasons for pursuing classifiers selection through\nmeta-learning. In this regard, Automated Machine Learning (AutoML) is usually\ntreated as an ASP problem under the umbrella of the democratization of machine\nlearning. Accordingly, AutoML makes machine learning techniques accessible to\ndomain scientists who are interested in applying advanced analytics but lack\nthe required expertise. It can ease the task of manually selecting ML\nalgorithms and tuning related hyperparameters. We comprehensively discuss the\ndifferent phases of classifiers selection based on a generic framework that is\nformed as an outcome of reviewing prior works. Subsequently, we propose a\nbenchmark knowledge base of 4 millions previously learned models and present\nextensive comparative evaluations of the prominent methods for classifiers\nselection based on 08 classification algorithms and 400 benchmark datasets. The\ncomparative study quantitatively assesses the performance of algorithms\nselection methods along while emphasizing the strengths and limitations of\nexisting studies.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T16:51:22Z"}
{"aid":"http://arxiv.org/abs/2504.06215v1","title":"Randomization Inference in Two-Sided Market Experiments","summary":"Randomized experiments are increasingly employed in two-sided markets, such\nas buyer-seller platforms, to evaluate treatment effects from marketplace\ninterventions. These experiments must reflect the underlying two-sided market\nstructure in their design (e.g., sellers and buyers), making them particularly\nchallenging to analyze. In this paper, we propose a randomization inference\nframework to analyze outcomes from such two-sided experiments. Our approach is\nfinite-sample valid under sharp null hypotheses for any test statistic and\nmaintains asymptotic validity under weak null hypotheses through\nstudentization. Moreover, we provide heuristic guidance for choosing among\nmultiple valid randomization tests to enhance statistical power, which we\ndemonstrate empirically. Finally, we demonstrate the performance of our\nmethodology through a series of simulation studies.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-08T17:00:42Z"}
{"aid":"http://arxiv.org/abs/2504.06233v1","title":"On the homology of special unitary groups over polynomial rings","summary":"In this work, we answer the homotopy invariance question for the ''smallest''\nnon-isotrivial group-scheme over $\\mathbb{P}^1$, obtaining a result, which is\nnot contained in previous works due to Knudson and Wendt. More explicitly, let\n$\\mathcal{G}=\\mathrm{SU}_{3,\\mathbb{P}^1}$ be the (non-isotrivial) non-split\ngroup-scheme over $\\mathbb{P}^1$ defined from the standard (isotropic)\nhermitian form in three variables. In this article, we prove that there exists\na natural homomorphism $\\mathrm{PGL}_2(F) \\to \\mathcal{G}(F[t])$ that induces\nisomorphisms $H_*(\\mathrm{PGL}_2(F), \\mathbb{Z}) \\to H_*(\\mathcal{G}(F[t]),\n\\mathbb{Z})$. Then we study the rational homology of\n$\\mathcal{G}(F[t,t^{-1}])$, by previously describing suitable fundamental\ndomains for certain arithmetic subgroups of $\\mathcal{G}$.","main_category":"math.KT","categories":"math.KT,math.GR,math.NT","published":"2025-04-08T17:30:56Z"}
{"aid":"http://arxiv.org/abs/2504.06239v1","title":"Canonical for Automated Theorem Proving in Lean","summary":"Canonical is a solver for type inhabitation in dependent type theory, that\nis, the problem of producing a term of a given type. We present a Lean tactic\nwhich invokes Canonical to generate proof terms and synthesize programs. The\ntactic supports higher-order and dependently-typed goals, structural recursion\nover indexed inductive types, and definitional equality. Canonical finds proofs\nfor 84% of Natural Number Game problems in 51 seconds total.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-08T17:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.06240v1","title":"Dictionary-free Koopman Predictive Control for Autonomous Vehicles in\n  Mixed Traffic","summary":"Koopman Model Predictive Control (KMPC) and Data-EnablEd Predictive Control\n(DeePC) use linear models to approximate nonlinear systems and integrate them\nwith predictive control. Both approaches have recently demonstrated promising\nperformance in controlling Connected and Autonomous Vehicles (CAVs) in mixed\ntraffic. However, selecting appropriate lifting functions for the Koopman\noperator in KMPC is challenging, while the data-driven representation from\nWillems' fundamental lemma in DeePC must be updated to approximate the local\nlinearization when the equilibrium traffic state changes. In this paper, we\npropose a dictionary-free Koopman model predictive control (DF-KMPC) for CAV\ncontrol. In particular, we first introduce a behavioral perspective to identify\nthe optimal dictionary-free Koopman linear model. We then utilize an iterative\nalgorithm to compute a data-driven approximation of the dictionary-free Koopman\nrepresentation. Integrating this data-driven linear representation with\npredictive control leads to our DF-KMPC, which eliminates the need to select\nlifting functions and update the traffic equilibrium state. Nonlinear traffic\nsimulations show that DF-KMPC effectively mitigates traffic waves and improves\ntracking performance.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-08T17:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.06242v1","title":"Addressing Relative Degree Issues in Control Barrier Function Synthesis\n  with Physics-Informed Neural Networks","summary":"In robotics, control barrier function (CBF)-based safety filters are commonly\nused to enforce state constraints. A critical challenge arises when the\nrelative degree of the CBF varies across the state space. This variability can\ncreate regions within the safe set where the control input becomes\nunconstrained. When implemented as a safety filter, this may result in\nchattering near the safety boundary and ultimately compromise system safety. To\naddress this issue, we propose a novel approach for CBF synthesis by\nformulating it as solving a set of boundary value problems. The solutions to\nthe boundary value problems are determined using physics-informed neural\nnetworks (PINNs). Our approach ensures that the synthesized CBFs maintain a\nconstant relative degree across the set of admissible states, thereby\npreventing unconstrained control scenarios. We illustrate the approach in\nsimulation and further verify it through real-world quadrotor experiments,\ndemonstrating its effectiveness in preserving desired system safety properties.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-08T17:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.06244v1","title":"The distinction between Ice phases VII, VIII and X","summary":"Ice phases VII, VIII and X are all based on a body-centered cubic arrangement\nof molecules, the differences coming from molecular orientation. There is some\ndebate as to whether these should even be considered distinct phases. The\nstandard definition of a transition between distinct phases involves a\ndiscontinuity in any derivative of the free energy. This can be hard to prove\nexperimentally, and most previous theoretical works have been based on models\nwhich either have continuously differentiable free energies, or no\nstraightforward way to determine the free energy. Here we build a free energy\nmodel based on the common definitions of the phases ; ordered ice-VIII,\norientationally disordered ice VII and proton-disordered ice X. All transitions\nin this model might or might not be associated with a discontinuity in the\nspecific heat, depending on paramaterization. By comparing with data, we find\nthat a VII-X transition line exists, but it ends in a critical point hidden\nwithin the stability field of phase VIII. If the model is correct, there is a\ndiscontinuity between VII and X, so they are separate phases. We propose that\nthe hidden phase boundary might be demonstrated experimentally by compression\nof supercooled ice VII.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.mtrl-sci","published":"2025-04-08T17:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.06256v1","title":"Transfer between Modalities with MetaQueries","summary":"Unified multimodal models aim to integrate understanding (text output) and\ngeneration (pixel output), but aligning these different modalities within a\nsingle architecture often demands complex training recipes and careful data\nbalancing. We introduce MetaQueries, a set of learnable queries that act as an\nefficient interface between autoregressive multimodal LLMs (MLLMs) and\ndiffusion models. MetaQueries connects the MLLM's latents to the diffusion\ndecoder, enabling knowledge-augmented image generation by leveraging the MLLM's\ndeep understanding and reasoning capabilities. Our method simplifies training,\nrequiring only paired image-caption data and standard diffusion objectives.\nNotably, this transfer is effective even when the MLLM backbone remains frozen,\nthereby preserving its state-of-the-art multimodal understanding capabilities\nwhile achieving strong generative performance. Additionally, our method is\nflexible and can be easily instruction-tuned for advanced applications such as\nimage editing and subject-driven generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.06260v1","title":"FEABench: Evaluating Language Models on Multiphysics Reasoning Ability","summary":"Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.NA,math.NA","published":"2025-04-08T17:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.06576v1","title":"Theoretical analysis for non-linear effects of magnetic fields on\n  unsteady boundary layer flows","summary":"This study investigates unsteady boundary layer phenomena in electrically\nconducting fluids subjected to static magnetic fields. Using a semi-explicit\nsimilarity transformation method, the momentum equation associated with the\nStokes stream function is solved. The nonlinear closed analytical solutions for\nboth stagnation flow and converging flow are derived. The results demonstrate\nthat the boundary layer structure incorporates similar shock and solitary wave\ncomponents which are promoted by Lorentz force. Under extreme magnetic fields,\nthe flow exhibits sine and cosine wave patterns, which are motivated by the\nstrong Lorentz force. An in-depth asymptotic analysis establishes the square\nroot scaling laws that quantify the growth of friction and flux with increasing\nmagnetic field strength. The boundary layer thickness scales inversely with the\nHartmann number, a consequence of dominant Lorentz force, which differs from\nthe conclusion of duct flow (Hunt 1965). These findings elucidate the physical\nmechanisms governing the nonlinear coupling between magnetic fields and the\ndynamics of the boundary layer.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T04:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.06582v1","title":"Harmful information spreading and its impact on vaccination campaigns\n  modeled through fractal-fractional operators","summary":"Despite the huge efforts to develop and administer vaccines worldwide to cope\nwith the COVID-19 pandemic, misinformation spreading through fake news in media\nand social networks about vaccination safety, make that people refuse to be\nvaccinated, which harms not only these people but also the whole population.\n  In this work, we model the effects of harmful information spreading in\nimmunization acquisition through vaccination. Our model is posed for several\nfractional derivative operators. We have conducted a comprehensive foundation\nanalysis of this model for the different fractional derivatives. Additionally,\nwe have incorporated a strength parameter that shows the combined impact of\nnonlinear and linear components within an epidemiological model. We have used\nthe second derivative of the Lyapunov function to ascertain the detection of\nwave patterns within the vaccination dynamics.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T05:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.06616v1","title":"Search for Type IL Gamma-ray Bursts: Criterion, Results, Verification\n  and Physical Implication","summary":"As an interesting subclass of gamma-ray burst (GRB), Type IL GRB (such as GRB\n211211A and GRB 230307A) features a long-duration prompt emission but\noriginating from compact binary merger. The \"long duration\" emisison of Type IL\nGRB are dominately composed of the main burst, rather than the extended\nemission, differentiating them from the traditional \"long-short\" GRB (e.g., GRB\n060614). Previous study has reported several Type IL GRBs by visual inspection\nof their light curves. In this work, we established a detailed criterion to\nidentify Type IL GRBs by light curve, and then systematically searched the\narchival \\textit{Fermi}/GBM data with this criterion, resulting in a sample of\n5 type IL GRBs from January 1, 2014 to January 1, 2024, i.e. GRB 230307A, GRB\n211211A, GRB 200914A, GRB 200311A and GRB 170228A. Apart from the light curve\npattern, we find that the temporal and spectral properties of these 5 GRBs also\nsupport this classification. Interestingly, we find that the energy ratio\nbetween extended emission and main emission is almost constant ($\\sim0.7$, with\nsmall scattering) for these GRBs, which have strong implication on the\nmechanism of Type IL burst. We discuss theoretical models to interpret the\nprogenitor, central engine, and extended emission of these Type IL bursts.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T06:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.06619v1","title":"Sufficient conditions for a graph with minimum degree to have a\n  component factor","summary":"Let $\\mathcal{T}_{\\frac{k}{r}}$ denote the set of trees $T$ such that\n$i(T-S)\\leq\\frac{k}{r}|S|$ for any $S\\subset V(T)$ and for any $e\\in E(T)$\nthere exists a set $S^{*}\\subset V(T)$ with\n$i((T-e)-S^{*})>\\frac{k}{r}|S^{*}|$, where $r<k$ are two positive integers. A\n$\\{C_{2i+1},T:1\\leq i<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor of\na graph $G$ is a spanning subgraph of $G$, in which every component is\nisomorphic to an element in $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$. Let $A(G)$ and $Q(G)$ denote\nthe adjacency matrix and the signless Laplacian matrix of $G$, respectively.\nThe adjacency spectral radius and the signless Laplacian spectral radius of\n$G$, denoted by $\\rho(G)$ and $q(G)$, are the largest eigenvalues of $A(G)$ and\n$Q(G)$, respectively. In this paper, we study the connections between the\nspectral radius and the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. We first\nestablish a tight sufficient condition involving the adjacency spectral radius\nto guarantee the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. Then we\npropose a tight signless Laplacian spectral radius condition for the existence\nof a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:35:29Z"}
{"aid":"http://arxiv.org/abs/2504.06628v1","title":"Entropy Production in Non-Gaussian Active Matter: A Unified Fluctuation\n  Theorem and Deep Learning Framework","summary":"We present a general framework for deriving entropy production rates in\nactive matter systems driven by non-Gaussian active fluctuations. Employing the\nprobability flow equivalence technique, we rigorously derive an entropy\nproduction decomposition formula and demonstrate that the entropy production,\n$\\Delta s_\\mathrm{tot}$, satisfies the integral fluctuation theorem $\\langle\n\\exp[ -\\Delta s_\\mathrm{tot} + B_\\mathrm{act}] \\rangle = 1$ and the generalized\nsecond law of thermodynamics $\\langle \\Delta s_\\mathrm{tot}\\rangle \\geq\\langle\nB_\\mathrm{act}\\rangle$, where $B_\\mathrm{act}$ is a path-dependent random\nvariable associated with the active fluctuations. Our result holds generally\nfor arbitrary initial conditions, encompassing both steady-state and transient\nfinite-time regimes. In the limiting case where active fluctuations are absent\n(i.e., $B_\\mathrm{act} \\equiv 0$), the theorem reduces to the well-established\nresults in stochastic thermodynamics. Building on the theoretical foundation,\nwe propose a deep learning-based methodology to efficiently compute the entropy\nproduction, utilizing the L\\'{e}vy score function we proposed. To illustrate\nthe validity of this approach, we apply it to two representative systems: a\nBrownian particle in a periodic active bath and an active polymer system\nconsisting of an active Brownian particle cross-linker interacting with passive\nBrownian beads. Our results provide a unified framework for analyzing entropy\nproduction in active matter systems while offering practical computational\ntools for investigating complex nonequilibrium behaviors.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-09T07:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.06653v1","title":"Hunting axion dark matter signatures in low-frequency terrestrial\n  magnetic fields","summary":"We show that Earth's natural environment can serve as a powerful probe for\nultralight axion dark matter. In the presence of global geomagnetic fields, the\naxions with masses ranging from $10^{-15}\\,{\\rm eV}-10^{-13}\\,{\\rm eV}$ induce\nelectromagnetic waves in the (sub-) extremely low-frequency band ($0.3-30\\,{\\rm\nHz}$) through the axion-photon coupling. We predict the amplitude of induced\nmagnetic fields in the Earth-ionosphere cavity, taking the finite conductivity\nof the atmosphere into account. This allows us to constrain the axion-photon\ncoupling parameter, $g_{\\rm a\\gamma}$, from the long-term monitoring data of\nthe low-frequency magnetic fields, resulting in a significant improvement from\nthe previous constraints down to $g_{\\rm a\\gamma} \\lesssim\n4\\times10^{-13}\\,{\\rm GeV}^{-1}$ for axion mass $\\sim 3 \\times 10^{-14}\\,{\\rm\neV}$.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-09T07:42:28Z"}
{"aid":"http://arxiv.org/abs/2504.06680v1","title":"Deep Learning for Cardiovascular Risk Assessment: Proxy Features from\n  Carotid Sonography as Predictors of Arterial Damage","summary":"In this study, hypertension is utilized as an indicator of individual\nvascular damage. This damage can be identified through machine learning\ntechniques, providing an early risk marker for potential major cardiovascular\nevents and offering valuable insights into the overall arterial condition of\nindividual patients. To this end, the VideoMAE deep learning model, originally\ndeveloped for video classification, was adapted by finetuning for application\nin the domain of ultrasound imaging. The model was trained and tested using a\ndataset comprising over 31,000 carotid sonography videos sourced from the\nGutenberg Health Study (15,010 participants), one of the largest prospective\npopulation health studies. This adaptation facilitates the classification of\nindividuals as hypertensive or non-hypertensive (75.7% validation accuracy),\nfunctioning as a proxy for detecting visual arterial damage. We demonstrate\nthat our machine learning model effectively captures visual features that\nprovide valuable insights into an individual's overall cardiovascular health.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.06722v1","title":"Plastic tensor networks for interpretable generative modeling","summary":"A structural optimization scheme for a single-layer nonnegative adaptive\ntensor tree (NATT) that models a target probability distribution is proposed.\nThe NATT scheme, by construction, has the advantage that it is interpretable as\na probabilistic graphical model. We consider the NATT scheme and a recently\nproposed Born machine adaptive tensor tree (BMATT) optimization scheme and\ndemonstrate their effectiveness on a variety of generative modeling tasks where\nthe objective is to infer the hidden structure of a provided dataset. Our\nresults show that in terms of minimizing the negative log-likelihood, the\nsingle-layer scheme has model performance comparable to the Born machine\nscheme, though not better. The tasks include deducing the structure of binary\nbitwise operations, learning the internal structure of random Bayesian networks\ngiven only visible sites, and a real-world example related to hierarchical\nclustering where a cladogram is constructed from mitochondrial DNA sequences.\nIn doing so, we also show the importance of the choice of network topology and\nthe versatility of a least-mutual information criterion in selecting a\ncandidate structure for a tensor tree, as well as discuss aspects of these\ntensor tree generative models including their information content and\ninterpretability.","main_category":"cs.LG","categories":"cs.LG,cond-mat.stat-mech","published":"2025-04-09T09:23:11Z"}
{"aid":"http://arxiv.org/abs/2504.06734v1","title":"Locally Repairable Convertible Codes: Improved Lower Bound and General\n  Construction","summary":"In this paper, we consider the convertible code with locally repairable\nproperty. We present an improved lower bound on access cost associated with\n$(r,\\delta)$. Then, we provide a general construction of convertible codes with\noptimal access cost which shows that those codes can be with super-linear\nlength or maximum repairable property. Additionally, employing the known\nlocally repairable codes with super-linear length or maximum repairable\nproperty, we provide explicit constructions of convertible codes with\nsuper-linear length or maximum repairable property.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T09:46:08Z"}
{"aid":"http://arxiv.org/abs/2504.06749v1","title":"Evidence of star cluster migration and merger in dwarf galaxies","summary":"Nuclear star clusters (NSCs) are the densest stellar systems in the Universe.\nThey can be found at the center of all galaxy types, but tend to favor galaxies\nof intermediate stellar mass around 10$^9\\,$M$_{\\odot}$[1, 2]. Currently, two\nmain processes are under debate to explain their formation: in-situ\nstar-formation from gas infall[3] and migration and merging of globular\nclusters (GCs) caused by dynamical friction[4]. Studies[5-9] of NSC stellar\npopulations suggest that the former predominates in massive galaxies, the\nlatter prevails in dwarf galaxies, and both contribute equally at intermediate\nmass. However, up to now, no ongoing merger of GCs has yet been observed to\nconfirm this scenario. Here we report the serendipitous discovery of five dwarf\ngalaxies with complex nuclear regions, characterized by multiple nuclei and\ntidal tails, using high resolution images from the Hubble Space Telescope.\nThese structures have been reproduced in complementary N-body simulations,\nsupporting the interpretation that they result from migrating and merging of\nstar clusters. The small detection rate and short simulated timescales (below\n100 Myr) of this process may explain why this has not been observed previously.\nThis study highlights the need of large surveys with high resolution to fully\nmap the migration scenario steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T10:12:37Z"}
{"aid":"http://arxiv.org/abs/2504.06755v1","title":"FANeRV: Frequency Separation and Augmentation based Neural\n  Representation for Video","summary":"Neural representations for video (NeRV) have gained considerable attention\nfor their strong performance across various video tasks. However, existing NeRV\nmethods often struggle to capture fine spatial details, resulting in vague\nreconstructions. In this paper, we present a Frequency Separation and\nAugmentation based Neural Representation for video (FANeRV), which addresses\nthese limitations with its core Wavelet Frequency Upgrade Block.This block\nexplicitly separates input frames into high and low-frequency components using\ndiscrete wavelet transform, followed by targeted enhancement using specialized\nmodules. Finally, a specially designed gated network effectively fuses these\nfrequency components for optimal reconstruction. Additionally, convolutional\nresidual enhancement blocks are integrated into the later stages of the network\nto balance parameter distribution and improve the restoration of high-frequency\ndetails. Experimental results demonstrate that FANeRV significantly improves\nreconstruction performance and excels in multiple tasks, including video\ncompression, inpainting, and interpolation, outperforming existing NeRV\nmethods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T10:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.06756v1","title":"Preservation of notion of C sets near zero over reals","summary":"There are several notions of largeness in a semigroup. N. Hindman and D.\nStrauss established that if $u,v \\in \\mathbb{N}$, $A$ is a $u \\times v$ matrix\nwith entries from $\\mathbb{Q}$ and $\\psi$ is a notion of a large set in\n$\\mathbb{N}$, then $\\{\\vec{x} \\in \\mathbb{N}^v: A\\vec{x} \\in \\psi^u \\}$ is\nlarge in $\\mathbb{N}^v$. Among the several notions of largeness, C sets\noccupies an important place of study because they exhibit strong combinatorial\nproperties. The analogous notion of C set appears for a dense subsemigroup $S$\nof $((0, \\infty),+)$ called a C-set near zero. These sets also have very rich\ncombinatorial structure. In this article, we investigate the above result for C\nsets near zero in $\\mathbb{R}^+$ when the matrix has real entries. We also\ndevelop a new characterisation of C-sets near zero in $\\mathbb{R}^+$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T10:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.06762v1","title":"Matching and Edge Cover in Temporal Graphs","summary":"Temporal graphs are a special class of graphs for which a temporal component\nis added to edges, that is, each edge possesses a set of times at which it is\navailable and can be traversed. Many classical problems on graphs can be\ntranslated to temporal graphs, and the results may differ. In this paper, we\ndefine the Temporal Edge Cover and Temporal Matching problems and show that\nthey are NP-complete even when fixing the lifetime or when the underlying graph\nis a tree. We then describe two FPT algorithms, with parameters lifetime and\ntreewidth, that solve the two problems. We also find lower bounds for the\napproximation of the two problems and give two approximation algorithms which\nmatch these bounds. Finally, we discuss the differences between the problems in\nthe temporal and the static framework.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-09T10:33:10Z"}
{"aid":"http://arxiv.org/abs/2504.06790v1","title":"Analog Computing with Microwave Networks","summary":"Analog computing has been recently revived due to its potential for\nenergy-efficient and highly parallel computations. In this paper, we\ninvestigate analog computers that linearly process microwave signals, named\nmicrowave linear analog computers (MiLACs), and their applications in signal\nprocessing for communications. We model a MiLAC as a multiport microwave\nnetwork with tunable impedance components, which enables the execution of\nmathematical operations by reconfiguring the microwave network and applying\ninput signals at its ports. We demonstrate that a MiLAC can efficiently compute\nthe linear minimum mean square error (LMMSE) estimator, widely used in\nmultiple-input multiple-output (MIMO) communications beamforming and detection,\nwith remarkably low computational complexity, unachievable through digital\ncomputing. Specifically, the LMMSE estimator can be computed with complexity\ngrowing with the square of its input size, rather than the cube, with\nrevolutionary applications to gigantic MIMO beamforming and detection.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-09T11:29:39Z"}
{"aid":"http://arxiv.org/abs/2504.06803v1","title":"DyDiT++: Dynamic Diffusion Transformers for Efficient Visual Generation","summary":"Diffusion Transformer (DiT), an emerging diffusion model for visual\ngeneration, has demonstrated superior performance but suffers from substantial\ncomputational costs. Our investigations reveal that these costs primarily stem\nfrom the \\emph{static} inference paradigm, which inevitably introduces\nredundant computation in certain \\emph{diffusion timesteps} and \\emph{spatial\nregions}. To overcome this inefficiency, we propose \\textbf{Dy}namic\n\\textbf{Di}ffusion \\textbf{T}ransformer (DyDiT), an architecture that\n\\emph{dynamically} adjusts its computation along both \\emph{timestep} and\n\\emph{spatial} dimensions. Specifically, we introduce a \\emph{Timestep-wise\nDynamic Width} (TDW) approach that adapts model width conditioned on the\ngeneration timesteps. In addition, we design a \\emph{Spatial-wise Dynamic\nToken} (SDT) strategy to avoid redundant computation at unnecessary spatial\nlocations. TDW and SDT can be seamlessly integrated into DiT and significantly\naccelerates the generation process. Building on these designs, we further\nenhance DyDiT in three key aspects. First, DyDiT is integrated seamlessly with\nflow matching-based generation, enhancing its versatility. Furthermore, we\nenhance DyDiT to tackle more complex visual generation tasks, including video\ngeneration and text-to-image generation, thereby broadening its real-world\napplications. Finally, to address the high cost of full fine-tuning and\ndemocratize technology access, we investigate the feasibility of training DyDiT\nin a parameter-efficient manner and introduce timestep-based dynamic LoRA\n(TD-LoRA). Extensive experiments on diverse visual generation models, including\nDiT, SiT, Latte, and FLUX, demonstrate the effectiveness of DyDiT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T11:48:37Z"}
{"aid":"http://arxiv.org/abs/2504.06805v1","title":"Robust Classification with Noisy Labels Based on Posterior Maximization","summary":"Designing objective functions robust to label noise is crucial for real-world\nclassification algorithms. In this paper, we investigate the robustness to\nlabel noise of an $f$-divergence-based class of objective functions recently\nproposed for supervised classification, herein referred to as $f$-PML. We show\nthat, in the presence of label noise, any of the $f$-PML objective functions\ncan be corrected to obtain a neural network that is equal to the one learned\nwith the clean dataset. Additionally, we propose an alternative and novel\ncorrection approach that, during the test phase, refines the posterior\nestimated by the neural network trained in the presence of label noise. Then,\nwe demonstrate that, even if the considered $f$-PML objective functions are not\nsymmetric, they are robust to symmetric label noise for any choice of\n$f$-divergence, without the need for any correction approach. This allows us to\nprove that the cross-entropy, which belongs to the $f$-PML class, is robust to\nsymmetric label noise. Finally, we show that such a class of objective\nfunctions can be used together with refined training strategies, achieving\ncompetitive performance against state-of-the-art techniques of classification\nwith label noise.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T11:52:51Z"}
{"aid":"http://arxiv.org/abs/2504.06828v1","title":"New physics particles mixing with mesons: production in the\n  fragmentation chain","summary":"A class of extensions to the Standard Model adds hypothetical long-lived\nparticles (LLPs) that have mass- or kinetic-mixing with neutral mesons, such as\npions or rho mesons. The mixing can contribute significantly to the production\nof LLPs at proton accelerator experiments, and no consistent description of\nthese production modes exists in the literature. In this paper, we develop a\nframework for studying different LLPs - dark photons, vector mediators coupled\nto the baryon current, and axion-like particles with different coupling\npatterns. In particular, we implement the production mechanisms in\n\\texttt{PYTHIA8}, study how the overall flux and kinematic distributions depend\non the LLP's mass, and compare various sub-processes where the mixing\ncontributes - proton bremsstrahlung, meson decay, and production in the\nfragmentation chain. We find that our new description of LLP production\npredicts an integrated flux that differs from current approaches by one to two\norders of magnitude, and highlight the unavoidable theoretical uncertainties\ncoming from poor knowledge of the properties of heavy mesons.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T12:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.06829v1","title":"Adaptive Locally Linear Embedding","summary":"Manifold learning techniques, such as Locally linear embedding (LLE), are\ndesigned to preserve the local neighborhood structures of high-dimensional data\nduring dimensionality reduction. Traditional LLE employs Euclidean distance to\ndefine neighborhoods, which can struggle to capture the intrinsic geometric\nrelationships within complex data. A novel approach, Adaptive locally linear\nembedding(ALLE), is introduced to address this limitation by incorporating a\ndynamic, data-driven metric that enhances topological preservation. This method\nredefines the concept of proximity by focusing on topological neighborhood\ninclusion rather than fixed distances. By adapting the metric based on the\nlocal structure of the data, it achieves superior neighborhood preservation,\nparticularly for datasets with complex geometries and high-dimensional\nstructures. Experimental results demonstrate that ALLE significantly improves\nthe alignment between neighborhoods in the input and feature spaces, resulting\nin more accurate and topologically faithful embeddings. This approach advances\nmanifold learning by tailoring distance metrics to the underlying data,\nproviding a robust solution for capturing intricate relationships in\nhigh-dimensional datasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T12:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.06852v1","title":"Quantum controlling and the topological properties of the magnon\n  photo-transport in two-dimensional collinear ferromagnet","summary":"In our work, we study magnon transport induced by light through\nAharonov-Casher (AC) effect, including magnon spin photocurrent (MSPC) and\nmagnon energy photocurrent (MEPC). Firstly, we regard the effect of the\nelectric field on the magnon through the AC effect as a perturbation. Then we\nderived the expressions of MSPC and MEPC in two-dimensional collinear\nferromagnetic system. And we apply our theory to the two-dimension\nferromagnetic Hexagonal and Kagome lattice. We find that the optical frequency\nand the relaxation time of the material can be used to control the\nphoto-transport of magnons. In addition, under the condition of low light\nfrequncy and infinite relaxation time, the longitudinal magnon photo-transport\nis related to the topological property of the magnon system.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T13:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.06853v1","title":"Magnetic ground state discrimination of a Polyradical Nanog-raphene\n  using Nickelocene-Functionalized Tips","summary":"Molecular magnets are a promising class of materials with exciting properties\nand applications. However, a profound understanding and application of such\nmaterials depends on the accurate detection of their electronic and magnetic\nproperties. Despite the availability of experimental techniques that can sense\nthe magnetic signal, the exact determination of the spin ground states and\nspatial distribution of exchange interaction of strongly correlated\nsingle-molecule magnets remains challenging. Here, we demonstrate that scanning\nprobe microscopy with a nickelocene-functionalized probe can distinguish\nbetween nearly degenerate multireference ground states of single-molecule\n{\\pi}-magnets and map their spatial distribution of the exchange interaction.\nThis method expands the already outstanding imaging capabilities of scanning\nprobe microscopy for characterizing the chemical and electronic structures of\nindividual molecules, paving the way for the study of strongly correlated\nmolecular magnets with unprecedented spatial resolution.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-09T13:07:03Z"}
{"aid":"http://arxiv.org/abs/2504.06855v1","title":"Compactified moduli spaces and Hecke correspondences for elliptic curves\n  with a prescribed $N$-torsion scheme","summary":"Given an integer $N \\geq 3$, we prove that for any ring $R$ and any finite\nlocally free $R$-group scheme $G$ which is fppf-locally (over $R$) isomorphic\nthe $N$-torsion subscheme of some elliptic curve $E/R$, there is a smooth\naffine curve $Y_G(N)$ parametrizing elliptic curves over $R$-schemes whose\n$N$-torsion subscheme is isomorphic to $G$. We also describe compactifications\n$X_G(N)$ of these curves when $R$ is a regular excellent Noetherian ring in\nwhich $N$ is invertible, as well as construct the Hecke correspondences they\nare endowed with. As an application, we show that the equations for $X_G(N)$\nfound over base fields for $N=7,8,9,11,13$ (by Halberstadt--Kraus,\nPoonen--Schaefer--Stoll, Chen and Fisher) are in fact valid over regular\nexcellent Noetherian bases that are $\\mathbb{Q}$-algebras. Finally, we describe\nin detail the equivalence of this construction with the point of view of Galois\ntwists that these authors use.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-09T13:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.06876v1","title":"Anomalous transport models for fluid classification: insights from an\n  experimentally driven approach","summary":"In recent years, research and development in nanoscale science and technology\nhave grown significantly, with electrical transport playing a key role. A\nnatural challenge for its description is to shed light on anomalous behaviours\nobserved in a variety of low-dimensional systems. We use a synergistic\ncombination of experimental and mathematical modelling to explore the transport\nproperties of the electrical discharge observed within a micro-gap based sensor\nimmersed in fluids with different insulating properties. Data from laboratory\nexperiments are collected and used to inform and calibrate four mathematical\nmodels that comprise partial differential equations describing different kinds\nof transport, including anomalous diffusion: the Gaussian Model with Time\nDependent Diffusion Coefficient, the Porous Medium Equation, the\nKardar-Parisi-Zhang Equation and the Telegrapher Equation. Performance analysis\nof the models through data fitting reveals that the Gaussian Model with a\nTime-Dependent Diffusion Coefficient most effectively describes the observed\nphenomena. This model proves particularly valuable in characterizing the\ntransport properties of electrical discharges when the micro-electrodes are\nimmersed in a wide range of insulating as well as conductive fluids. Indeed, it\ncan suitably reproduce a range of behaviours spanning from clogging to bursts,\nallowing accurate and quite general fluid classification. Finally, we apply the\ndata-driven mathematical modeling approach to ethanol-water mixtures. The\nresults show the model's potential for accurate prediction, making it a\npromising method for analyzing and classifying fluids with unknown insulating\nproperties.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.flu-dyn","published":"2025-04-09T13:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.06877v1","title":"Dissipation and noise in strongly driven Josephson junctions","summary":"In circuit quantum electrodynamics systems, the quasiparticle-related losses\nin Josephson junctions are suppressed due to the gap in the superconducting\ndensity of states which is much higher than the typical energy of a microwave\nphoton. In this work, we show that a strong drive even at frequency lower than\nthe double superconducting gap enables dissipation in the junctions due to\nphoton-assisted breaking of the Cooper pairs. Both the decay rate and noise\nstrength associated with the losses are sensitive to the dc phase bias of the\njunction and can be tuned in a broad range by the amplitude and the frequency\nof the external driving field, making the suggested mechanism potentially\nattractive for designing tunable dissipative elements. Furthermore, pronounced\nmemory effects in the driven Josephson junctions render them perspective for\nboth theoretical and experimental study of non-Markovian physics in\nsuperconducting quantum circuits. We illustrate our theoretical findings by\nstudying the spectral properties and the steady state population of a low\nimpedance resonator coupled to the driven Josephson junction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.06895v1","title":"ColorizeDiffusion v2: Enhancing Reference-based Sketch Colorization\n  Through Separating Utilities","summary":"Reference-based sketch colorization methods have garnered significant\nattention due to their potential applications in the animation production\nindustry. However, most existing methods are trained with image triplets of\nsketch, reference, and ground truth that are semantically and spatially\nwell-aligned, while real-world references and sketches often exhibit\nsubstantial misalignment. This mismatch in data distribution between training\nand inference leads to overfitting, consequently resulting in spatial artifacts\nand significant degradation in overall colorization quality, limiting potential\napplications of current methods for general purposes. To address this\nlimitation, we conduct an in-depth analysis of the \\textbf{carrier}, defined as\nthe latent representation facilitating information transfer from reference to\nsketch. Based on this analysis, we propose a novel workflow that dynamically\nadapts the carrier to optimize distinct aspects of colorization. Specifically,\nfor spatially misaligned artifacts, we introduce a split cross-attention\nmechanism with spatial masks, enabling region-specific reference injection\nwithin the diffusion process. To mitigate semantic neglect of sketches, we\nemploy dedicated background and style encoders to transfer detailed reference\ninformation in the latent feature space, achieving enhanced spatial control and\nricher detail synthesis. Furthermore, we propose character-mask merging and\nbackground bleaching as preprocessing steps to improve foreground-background\nintegration and background generation. Extensive qualitative and quantitative\nevaluations, including a user study, demonstrate the superior performance of\nour proposed method compared to existing approaches. An ablation study further\nvalidates the efficacy of each proposed component.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:55:32Z"}
{"aid":"http://arxiv.org/abs/2504.06915v1","title":"An Analysis of Temporal Dropout in Earth Observation Time Series for\n  Regression Tasks","summary":"Missing instances in time series data impose a significant challenge to deep\nlearning models, particularly in regression tasks. In the Earth Observation\nfield, satellite failure or cloud occlusion frequently results in missing\ntime-steps, introducing uncertainties in the predicted output and causing a\ndecline in predictive performance. While many studies address missing\ntime-steps through data augmentation to improve model robustness, the\nuncertainty arising at the input level is commonly overlooked. To address this\ngap, we introduce Monte Carlo Temporal Dropout (MC-TD), a method that\nexplicitly accounts for input-level uncertainty by randomly dropping time-steps\nduring inference using a predefined dropout ratio, thereby simulating the\neffect of missing data. To bypass the need for costly searches for the optimal\ndropout ratio, we extend this approach with Monte Carlo Concrete Temporal\nDropout (MC-ConcTD), a method that learns the optimal dropout distribution\ndirectly. Both MC-TD and MC-ConcTD are applied during inference, leveraging\nMonte Carlo sampling for uncertainty quantification. Experiments on three EO\ntime-series datasets demonstrate that MC-ConcTD improves predictive performance\nand uncertainty calibration compared to existing approaches. Additionally, we\nhighlight the advantages of adaptive dropout tuning over manual selection,\nmaking uncertainty quantification more robust and accessible for EO\napplications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-09T14:23:04Z"}
{"aid":"http://arxiv.org/abs/2504.06933v1","title":"Well-posedness of half-harmonic map heat flows for rough initial data","summary":"We adopt the Koch-Tataru theory for the Navier-Stokes equations, based on\nCarleson measure estimates, to develop a scaling-critical low-regularity\nframework for half-harmonic map heat flows. This nonlocal variant of the\nharmonic map heat flow has been studied recently in connection with free\nboundary minimal surfaces. We introduce a new class of initial data for the\nflow, broader than the conventional energy or Sobolev spaces considered in\nprevious work, for which we establish existence, uniqueness, and continuous\ndependence.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.06937v1","title":"Finite Field Multiple Access III: from 2-ary to p-ary","summary":"This paper extends finite-field multiple-access (FFMA) techniques from binary\nto general $p$-ary source transmission. We introduce element-assemblage (EA)\ncodes over GF($p^m$), generalizing element-pair (EP) codes, and define two\nspecific types for ternary transmission: orthogonal EA codes and double\ncodeword EA (D-CWEA) codes. A unique sum-pattern mapping (USPM) constraint is\nproposed for the design of uniquely-decodable CWEA (UD-CWEA) codes, including\nadditive inverse D-CWEA (AI-D-CWEA) and basis decomposition D-CWEA (BD-D-CWEA)\ncodes. Moreover, we extend EP-coding to EA-coding, focusing on non-orthogonal\nCWEA (NO-CWEA) codes and their USPM constraint in the complex field.\nAdditionally, $p$-ary CWEA codes are constructed using a basis decomposition\nmethod, leveraging ternary decomposition for faster convergence and simplified\nencoder/decoder design. We present a comprehensive performance analysis of the\nproposed FFMA system from two complementary perspectives: channel capacity and\nerror performance. We demonstrate that equal power allocation (EPA) achieves\nthe theoretical channel capacity bound, while independently developing a\nrate-driven capacity alignment (CA) theorem based on the capacity-to-rate ratio\n(CRR) metric for error performance analysis. We then explore the multiuser\nfinite blocklength (FBL) characteristics of FFMA systems. Finally, a\ncomparative analysis of $p$-ary transmission systems against classical binary\nsystems is conducted, revealing that low-order $p$-ary systems (e.g., $p=3$)\noutperform binary systems at small loading factors, while higher-order systems\n(e.g., $p=257$) excel at larger loading factors. These findings highlight the\npotential of $p$-ary systems, although practical implementations may benefit\nfrom decomposing $p$-ary systems into ternary systems to manage complexity.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T14:41:36Z"}
{"aid":"http://arxiv.org/abs/2504.06940v1","title":"More-efficient Quantum Multivariate Mean Value Estimator from\n  Generalized Grover Gate","summary":"In this work, we present an efficient algorithm for multivariate mean value\nestimation. Our algorithm outperforms previous work by polylog factors and\nnearly saturates the known lower bound. We find an algorithm that uses\n$O\\left(n \\log \\frac{d}{\\delta}\\right)$ to achieve precision\n$\\frac{\\sqrt{\\text{tr } \\Sigma}}{n}$ in $\\lVert \\rVert_\\infty$ norm and hence\n$\\frac{\\sqrt{d \\text{ tr } \\Sigma}}{n}$ in $\\lVert \\rVert_2$ norm, where $d$ is\nthe dimension and $\\Sigma$ is the covariance matrix. We also presented another\nalgorithm that uses smaller memory but costs an extra $d^\\frac{1}{4}$ in\ncomplexity. The idea originates from the previous observations that the Grover\ngate, when generalized to allow for arbitrary phases instead of $\\pm 1$,\nbecomes a good mean value estimator in some mathematical notion. The only\nremaining $\\log \\frac{d}{\\delta}$ as opposed to $\\log \\frac{1}{\\delta}$ is due\nto the phase estimation primitive we employed, which so far is the only major\nknown method to tackle the problem. Our results demonstrates that our\nmethodology with generalized Grover gate can be used locate the optimal\nalgorithm, without polylog overhead, for different taks relating to mean value\nestimation.","main_category":"quant-ph","categories":"quant-ph,cs.CC","published":"2025-04-09T14:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.06941v1","title":"Proofs of two conjectures on congruences of overcubic partition triples","summary":"Let $\\overline{bt}(n)$ denote the number of overcubic partition triples of\n$n$. Nayaka, Dharmendra and Kumar proved some congruences modulo 8, 16 and 32\nfor $\\overline{bt}(n)$. Recently, Saikia and Sarma established some congruences\nmodulo 64 for $\\overline{bt}(n)$ by using both elementary techniques and the\ntheory of modular forms. In their paper, they also posed two conjectures on\ninfinite families of congruences modulo 64 and 128 for $\\overline{bt}(n)$. In\nthis paper, we confirm the two conjectures.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T14:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.06945v1","title":"Generic deformation channels for critical Fermi surfaces including the\n  impact of collisions","summary":"This paper constitutes a sequel to our theoretical efforts to determine the\nnature of the generic low-energy deformations of the Fermi surface of a\nquantum-critical metal, which arises at the stable non-Fermi liquid (NFL) fixed\npoint of a quantum phase transition. The emergent critical Fermi surface,\narising right at the Ising-nematic quantum critical point (QCP), is a\nparadigmatic example where an NFL behaviour is induced by the strong\ninteractions of the fermionic degrees of freedom with those of the bosonic\norder parameter. It is an artifact of the bosonic modes becoming massless at\nthe QCP, thus undergoing Landau damping at the level of one-loop self-energy.\nWe resort to the well-tested formalism of the quantum Boltzmann equations\n(QBEs)for identifying the excitations. While in our earlier works, we have\nfocussed on the collisionless regime by neglecting the collision integral and\nassuming the bosons to be in equilibrium, here we embark on a full analysis. In\nparticular, we take into account the bosonic part of the QBEs. The final\nresults show that that the emergent modes are long-lived and robust against the\ndamping effects brought about the collision integral(s), exhibiting the same\nqualitative features as obtained from the no-collision approximations.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,hep-th","published":"2025-04-09T14:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.06960v1","title":"Higher-Order Color Voronoi Diagrams and the Colorful Clarkson-Shor\n  Framework","summary":"Given a set $S$ of $n$ colored sites, each $s\\in S$ associated with a\ndistance-to-site function $\\delta_s \\colon \\mathbb{R}^2 \\to \\mathbb{R}$, we\nconsider two distance-to-color functions for each color: one takes the minimum\nof $\\delta_s$ for sites $s\\in S$ in that color and the other takes the maximum.\nThese two sets of distance functions induce two families of higher-order\nVoronoi diagrams for colors in the plane, namely, the minimal and maximal\norder-$k$ color Voronoi diagrams, which include various well-studied Voronoi\ndiagrams as special cases. In this paper, we derive an exact upper bound\n$4k(n-k)-2n$ on the total number of vertices in both the minimal and maximal\norder-$k$ color diagrams for a wide class of distance functions $\\delta_s$ that\nsatisfy certain conditions, including the case of point sites $S$ under convex\ndistance functions and the $L_p$ metric for any $1\\leq p \\leq\\infty$. For the\n$L_1$ (or, $L_\\infty$) metric, and other convex polygonal metrics, we show that\nthe order-$k$ minimal diagram of point sites has $O(\\min\\{k(n-k), (n-k)^2\\})$\ncomplexity, while its maximal counterpart has $O(\\min\\{k(n-k), k^2\\})$\ncomplexity. To obtain these combinatorial results, we extend the Clarkson--Shor\nframework to colored objects, and demonstrate its application to several\nfundamental geometric structures, including higher-order color Voronoi\ndiagrams, colored $j$-facets, and levels in the arrangements of piecewise\nlinear/algebraic curves/surfaces. We also present an iterative approach to\ncompute higher-order color Voronoi diagrams.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-09T15:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.06964v1","title":"Thermodynamics of effective loop quantum black holes","summary":"We study the thermodynamics of a non-singular black hole model with effective\nquantum corrections motivated by Loop Quantum Gravity (LQG). The effective\ngeometry has a transition surface that connects trapped and anti-trapped\nregions with the same mass. There is a minimum mass for which the horizon\ntemperature and Komar energy are zero, and the black hole stops its Hawking\nevaporation. For horizons above this limit, we present the grey-body factors,\nemission spectra, and the mass loss rate, solving a one-dimensional\nSchrdinger-type equation with an effective short-range potential barrier for\nmassless fields of spins 0, 1/2, 1 and 2.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-09T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.06972v1","title":"Signatures of unconventional superconductivity near reentrant and\n  fractional quantum anomalous Hall insulators","summary":"Two-dimensional moir\\'e Chern bands provide an exceptional platform for\nexploring a variety of many-body electronic liquid and solid phases at zero\nmagnetic field within a lattice system. One particular intriguing possibility\nis that flat Chern bands can, in principle, support exotic superconducting\nphases together with fractional topological phases. Here, we report the\nobservation of integer and fractional quantum anomalous Hall effects, the\nreentrant quantum anomalous Hall effect, and superconductivity within the first\nmoir\\'e Chern band of twisted bilayer MoTe2. The superconducting phase emerges\nfrom a normal state exhibiting anomalous Hall effects and sustains an large\nperpendicular critical magnetic field. Our results present the first example of\nsuperconductivity emerging within a flat Chern band that simultaneously hosts\nfractional quantum anomalous effects, a phenomenon never observed in any other\nsystems. Our work expands the understanding of emergent quantum phenomena in\nmoir\\'e Chern bands, and offers a nearly ideal platform for engineering\nMajorana and parafermion zero modes in gate-controlled hybrid devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-09T15:27:56Z"}
{"aid":"http://arxiv.org/abs/2504.06977v1","title":"Probing dipolar interactions between Rydberg atoms and ultracold polar\n  molecules","summary":"We probe resonant dipolar interactions between ultracold $^{40}$K$^{87}$Rb\nmolecules and Rydberg $^{87}$Rb atoms in an optically trapped ensemble. Through\nstate-selective ionization detection of the KRb molecules, we observe resonant\nenergy transfer at 2.227 GHz from Rydberg atoms to molecules under a tunable\nexternal electric field. We measure a broadening up to 3.5 MHz, for the Rb\nRydberg excitation spectrum, which matches a Monte Carlo simulation that\ndescribes a Rydberg atom and neighboring molecules evolving under a\ndipole-dipole interacting Hamiltonian. The demonstrated interspecies dipolar\ninteraction is a key ingredient for hybrid Rydberg-polar molecule systems,\nwhere the advantages of each system can be leveraged and combined.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-09T15:31:02Z"}
{"aid":"http://arxiv.org/abs/2504.06985v1","title":"M-theory boundaries beyond supersymmetry","summary":"The chiral worldvolume theory of an M-theory boundary (the so-called M9\nbrane) is uniquely determined by supersymmetry and anomaly inflow. In this\nbrief note we investigate whether alternative chiral boundary field contents\nmay be allowed by anomaly cancellation once supersymmetry is dropped. Even\nthen, anomaly inflow places stringent constraints on the gauge group $G$ and\nmatter content of the boundary worldvolume theory, which we determine\nexplicitly. We find the most general solution to these constraints in the case\nwhere all matter fields are of the same chirality, for all simple Lie algebras\nexcept $\\mathfrak{sp}_2$, $\\mathfrak{su}_{n\\leq5}$, and $\\mathfrak{so}_{n}$\nwith $7\\leq n\\leq 12$, and find no solutions other than the supersymmetric\n$E_8$ boundary of Ho\\v{r}ava and Witten. However, when we extend our search to\nallow for any chirality in the matter fields, we find one minimal solution with\ngauge group $G_2$, charged matter in the $\\mathsf{14}$, $\\mathsf{27}$ and\n$\\mathsf{77}$ representations, which satisfies all constraints in a non-trivial\nway. Therefore, it could in principle describe the low-energy theory of a novel\nnonsupersymmetric M-theory boundary condition, different from the\nHo\\v{r}ava-Witten proposal. We briefly discuss some consequences if this was\nindeed the case, such as the existence of a non-supersymmetric, exotic\n\"$G_2$-string\" CFT in 6d, and a novel, non-perturbative, heterotic-like 10d\nstring with gauge group $G_2\\times G_2$.","main_category":"hep-th","categories":"hep-th","published":"2025-04-09T15:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.06987v1","title":"Enhancing Metabolic Syndrome Prediction with Hybrid Data Balancing and\n  Counterfactuals","summary":"Metabolic Syndrome (MetS) is a cluster of interrelated risk factors that\nsignificantly increases the risk of cardiovascular diseases and type 2\ndiabetes. Despite its global prevalence, accurate prediction of MetS remains\nchallenging due to issues such as class imbalance, data scarcity, and\nmethodological inconsistencies in existing studies. In this paper, we address\nthese challenges by systematically evaluating and optimizing machine learning\n(ML) models for MetS prediction, leveraging advanced data balancing techniques\nand counterfactual analysis. Multiple ML models, including XGBoost, Random\nForest, TabNet, etc., were trained and compared under various data balancing\ntechniques such as random oversampling (ROS), SMOTE, ADASYN, and CTGAN.\nAdditionally, we introduce MetaBoost, a novel hybrid framework that integrates\nSMOTE, ADASYN, and CTGAN, optimizing synthetic data generation through weighted\naveraging and iterative weight tuning to enhance the model's performance\n(achieving a 1.14% accuracy improvement over individual balancing techniques).\nA comprehensive counterfactual analysis is conducted to quantify feature-level\nchanges required to shift individuals from high-risk to low-risk categories.\nThe results indicate that blood glucose (50.3%) and triglycerides (46.7%) were\nthe most frequently modified features, highlighting their clinical significance\nin MetS risk reduction. Additionally, probabilistic analysis shows elevated\nblood glucose (85.5% likelihood) and triglycerides (74.9% posterior\nprobability) as the strongest predictors. This study not only advances the\nmethodological rigor of MetS prediction but also provides actionable insights\nfor clinicians and researchers, highlighting the potential of ML in mitigating\nthe public health burden of metabolic syndrome.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T15:51:10Z"}
{"aid":"http://arxiv.org/abs/2504.06997v1","title":"Cerebral blood flow monitoring using a deep learning implementation of\n  the two-layer DCS analytical model with a 512 512 SPAD array","summary":"Diffuse correlation spectroscopy (DCS) analyzes the autocorrelation function\nof photons scattered by red blood cells, enabling non-invasive, continuous\nmeasurement of deep tissue blood flow at the bedside. Multi-layer DCS models\n(two- and three-layer) enhance cerebral blood flow index (CBFi) sensitivity and\nmitigate interference from extracerebral tissues. However, these models require\nmultiple predefined parameters and are computationally intensive, making them\nimpractical for real-time bedside monitoring. To address this challenge, we\nintegrate a single-photon avalanche diode (SPAD) array with a deep learning\n(DL)-based approach trained on data generated by the two-layer analytical\nmodel. This method bypasses traditional model fitting, enabling real-time CBFi\nmonitoring while minimizing superficial tissue contamination. We first validate\nour approach using Monte Carlo-simulated test datasets, demonstrating superior\naccuracy in relative CBFi estimation (5.8% error vs. 19.1% for conventional\nfitting) and enhanced CBFi sensitivity (87.1% vs. 55.4%). Additionally, our\nmethod effectively isolates shallow blood flow changes and 750-fold faster than\nsingle-exponential fitting in a realistic scenario. We further evaluate the\nsystem in a healthy adult, achieving real-time CBFi monitoring and pulsatile\nwaveform recovery during a brain activity test using a 512 512 SPAD array\nsensor. These results highlight the potential of our approach for real-time\nbrain activity monitoring.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.bio-ph","published":"2025-04-09T16:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07019v1","title":"Non-Hermitian Numerical Renormalization Group: Solution of the\n  non-Hermitian Kondo model","summary":"Non-Hermitian (NH) Hamiltonians describe open quantum systems, nonequilibrium\ndynamics, and dissipative processes. Although a rich range of single-particle\nNH physics has been uncovered, many-body phenomena in strongly correlated NH\nsystems have been far less well studied. The Kondo effect, an important\nparadigm for strong correlation physics, has recently been considered in the NH\nsetting. Here we develop a NH generalization of the numerical renormalization\ngroup (NRG) and use it to solve the NH Kondo model. Our non-perturbative\nsolution applies beyond weak coupling, and we uncover a nontrivial phase\ndiagram. The method is showcased by application to the NH pseudogap Kondo\nmodel, which we show supports a completely novel phase with a genuine NH stable\nfixed point and complex eigenspectrum. Our NH-NRG code, which can be used in\nregimes and for models inaccessible to, e.g., perturbative scaling and Bethe\nansatz, is provided open source.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-09T16:34:49Z"}
{"aid":"http://arxiv.org/abs/2504.07030v1","title":"Decoherence effects in entangled fermion pairs at colliders","summary":"Recent measurements at the Large Hadron Collider have observed entanglement\nin the spins of $t\\bar t$ pairs. The effects of radiation, which are expected\nto lead to quantum decoherence and a reduction of entanglement, are generally\nneglected in such measurements. In this letter we calculate the effects of\ndecoherence from various different types of radiation for a maximally entangled\npair of fermions -- a bipartite system of qubits in a Bell state. We identify\nthe Kraus operators describing the evolution of the open quantum system with\nthe integrated Altarelli-Parisi splitting functions.","main_category":"quant-ph","categories":"quant-ph,hep-ex,hep-ph","published":"2025-04-09T16:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.07039v1","title":"Microlensing at Cosmological Distances: Event Rate Predictions in the\n  Warhol Arc of MACS 0416","summary":"Highly magnified stars ($\\mu$ $>$ 100) are now outinely identified as\ntransient events at cosmological distances thanks to microlensing by\nintra-cluster stars near the critical curves of galaxy clusters. Using the {\\it\nJames Webb} Space Telescope (JWST) in combination with the {\\it Hubble} Space\nTelescope (HST), we outline here an analytical framework that is applied to the\nWarhol arc (at $z=0.94$) in the MACS 0416 galaxy cluster (at $z=0.396)$ where\nover a dozen microlensed stars have been detected to date. This method is\ngeneral and can be applied to other lensed arcs. Within this lensed galaxy we\nfit the spatially resolved SED spanned by eight JWST-NIRCam filters combined\nwith three ACS filters, for accurate lensed star predictions in 2D. With this\ntool we can generate 2D maps of microlensed stars for well resolved arcs in\ngeneral, including dependence on wavelength and limiting apparent magnitude,\nfor comparison with with planned cadenced campaigns for JWST and Hubble, for\nconstraining directly the IMF and the level of dark matter substructure.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,astro-ph.SR","published":"2025-04-09T16:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.07073v1","title":"New empirical mass-loss recipe for UV radiation line-driven winds of hot\n  stars across various metallicities","summary":"The winds of massive stars remove a significant fraction of their mass,\nstrongly impacting their evolution. As a star evolves, the rate at which it\nloses mass changes. In stellar evolution codes, different mass-loss recipes are\nemployed for different evolutionary stages. The choice of the recipes is\nuser-dependent and the conditions for switching between them are poorly\ndefined. Focusing on hot stars, we aim to produce a physically motivated,\nempirically calibrated mass-loss recipe suitable for a wide range of\nmetallicities. We want to provide a ready-to-use universal recipe that\neliminates the need for switching between recipes for hot stars during stellar\nevolution calculations. We compile a sample of hot stars with reliable stellar\nand wind parameters in the Galaxy and the Magellanic Clouds. The sample is used\nto determine the dependence of the mass-loss rate on the basic stellar\nparameters. We find that independent of evolutionary stage and temperature, the\nwind mass-loss rate is a function of the electron-scattering Eddington\nparameter ($\\Gamma_e$) and metallicity (Z), being in line with expectations of\nradiation-driven wind theory. Our derived scaling relation provides an adequate\n($\\Delta$log($\\dot{M}$/(M$_\\odot$/yr)) = 0.43) and broadly applicable mass-loss\nrecipe for hot stars. The newly derived mass-loss recipe covers nearly the\nentire parameter space of hot stars with UV radiation-driven winds and\neliminates the need for interpolation between mass-loss formulae at different\nevolutionary stages when applied in stellar evolution models. Examples of\nstellar evolution calculations using our new recipe reveal that the predictions\non the ionizing fluxes and final fates of massive stars, especially at low\nmetallicity, differ significantly from models that use the standard mass-loss\nrates, impacting our understanding of stellar populations at low metallicity\nand in the young Universe.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-09T17:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.07407v1","title":"Cech - de Rham Chern character on the stack of holomorphic vector\n  bundles","summary":"We provide a formula for the Chern character of a holomorphic vector bundle\nin the hyper-cohomology of the de Rham complex of holomorphic sheaves on a\ncomplex manifold. This Chern character can be thought of as a completion of the\nChern character in Hodge cohomology obtained as the trace of the exponential of\nthe Atiyah class, which is \\v{C}ech closed, to one that is \\v{C}ech-Del closed.\nSuch a completion is a key step toward lifting O'Brian-Toledo-Tong invariants\nof coherent sheaves from Hodge cohomology to de Rham cohomology. An alternate\napproach toward the same end goal, instead using simplicial differential forms\nand Green complexes, can be found in Hosgood's works [Ho1, Ho2]. In the\nalgebraic setting, and more generally for K\\\"{a}hler manifolds, where Hodge and\nde Rham cohomologies agree, such extensions are not necessary, whereas in the\nnon-K\\\"{a}hler, or equivariant settings the two theories differ. We provide our\nformulae as a map of simplicial presheaves, which readily extend the results to\nthe equivariant setting and beyond. This paper can be viewed as a sequel to\n[GMTZ1] which covered such a discussion in Hodge cohomology. As an aside, we\ngive a conceptual understanding of how formulas obtained by Bott and Tu for\nChern classes using transition functions and those from Chern-Weil theory using\nconnections, are part of a natural unifying story.","main_category":"math.AG","categories":"math.AG,math.AT","published":"2025-04-10T03:01:18Z"}
{"aid":"http://arxiv.org/abs/2504.07416v1","title":"RadZero: Similarity-Based Cross-Attention for Explainable\n  Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability","summary":"Recent advancements in multi-modal models have significantly improved\nvision-language alignment in radiology. However, existing approaches struggle\nto effectively utilize complex radiology reports for learning, rely on\nlow-resolution images, and offer limited interpretability in attention\nmechanisms. To address these challenges, we introduce RadZero, a novel\nsimilarity-based cross-attention framework for vision-language alignment in\nradiology with zero-shot multi-task capability. RadZero leverages large\nlanguage models to extract minimal semantic sentences from radiology reports\nand employs a multi-positive contrastive learning strategy to effectively\ncapture relationships between images and multiple relevant textual\ndescriptions. It also utilizes a pre-trained vision encoder with additional\ntrainable Transformer layers, allowing efficient high-resolution image\nprocessing. By computing similarity between text embeddings and local image\npatch features, RadZero enables zero-shot inference with similarity probability\nfor classification and pixel-level cross-modal similarity maps for grounding\nand segmentation. Experimental results on public chest radiograph benchmarks\nshow that RadZero outperforms state-of-the-art methods in zero-shot\nclassification, grounding, and segmentation. Furthermore, cross-modal\nsimilarity map analysis highlights its potential for improving explainability\nin vision-language alignment. Additionally, qualitative evaluation demonstrates\nRadZero's capability for open-vocabulary semantic segmentation, further\nvalidating its effectiveness in medical imaging.","main_category":"cs.CV","categories":"cs.CV,cs.CL,cs.LG","published":"2025-04-10T03:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.07419v1","title":"Exploring Vulnerabilities and Concerns in Solana Smart Contracts","summary":"The Solana blockchain was created by Anatoly Yakovenko of Solana Labs and was\nintroduced in 2017, employing a novel transaction verification method. However,\nat the same time, the innovation process introduced some new security issues.\nThe frequent security incidents in smart contracts have not only caused\nenormous economic losses, but also undermined the credit system based on the\nblockchain. The security and reliability of smart contracts have become a new\nfocus of research both domestically and abroad. This paper studies the current\nstatus of security analysis of Solana by researching Solana smart contract\nsecurity analysis tools. This paper systematically sorts out the\nvulnerabilities existing in Solana smart contracts and gives examples of some\nvulnerabilities, summarizes the principles of security analysis tools, and\ncomprehensively summarizes and details the security analysis tools in Solana\nsmart contracts. The data of Solana smart contract security analysis tools are\ncollected and compared with Ethereum, and the differences are analyzed and some\ntools are selected for practical testing.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-10T03:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.07421v1","title":"AgentAda: Skill-Adaptive Data Analytics for Tailored Insight Discovery","summary":"We introduce AgentAda, the first LLM-powered analytics agent that can learn\nand use new analytics skills to extract more specialized insights. Unlike\nexisting methods that require users to manually decide which data analytics\nmethod to apply, AgentAda automatically identifies the skill needed from a\nlibrary of analytical skills to perform the analysis. This also allows AgentAda\nto use skills that existing LLMs cannot perform out of the box. The library\ncovers a range of methods, including clustering, predictive modeling, and NLP\ntechniques like BERT, which allow AgentAda to handle complex analytics tasks\nbased on what the user needs. AgentAda's dataset-to-insight extraction strategy\nconsists of three key steps: (I) a question generator to generate queries\nrelevant to the user's goal and persona, (II) a hybrid Retrieval-Augmented\nGeneration (RAG)-based skill matcher to choose the best data analytics skill\nfrom the skill library, and (III) a code generator that produces executable\ncode based on the retrieved skill's documentation to extract key patterns. We\nalso introduce KaggleBench, a benchmark of curated notebooks across diverse\ndomains, to evaluate AgentAda's performance. We conducted a human evaluation\ndemonstrating that AgentAda provides more insightful analytics than existing\ntools, with 48.78% of evaluators preferring its analyses, compared to 27.67%\nfor the unskilled agent. We also propose a novel LLM-as-a-judge approach that\nwe show is aligned with human evaluation as a way to automate insight quality\nevaluation at larger scale.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T03:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.07428v1","title":"Task-oriented Age of Information for Remote Inference with Hybrid\n  Language Models","summary":"Large Language Models (LLMs) have revolutionized the field of artificial\nintelligence (AI) through their advanced reasoning capabilities, but their\nextensive parameter sets introduce significant inference latency, posing a\nchallenge to ensure the timeliness of inference results. While Small Language\nModels (SLMs) offer faster inference speeds with fewer parameters, they often\ncompromise accuracy on complex tasks. This study proposes a novel remote\ninference system comprising a user, a sensor, and an edge server that\nintegrates both model types alongside a decision maker. The system dynamically\ndetermines the resolution of images transmitted by the sensor and routes\ninference tasks to either an SLM or LLM to optimize performance. The key\nobjective is to minimize the Task-oriented Age of Information (TAoI) by jointly\nconsidering the accuracy and timeliness of the inference task. Due to the\nnon-uniform transmission time and inference time, we formulate this problem as\na Semi-Markov Decision Process (SMDP). By converting the SMDP to an equivalent\nMarkov decision process, we prove that the optimal control policy follows a\nthreshold-based structure. We further develop a relative policy iteration\nalgorithm leveraging this threshold property. Simulation results demonstrate\nthat our proposed optimal policy significantly outperforms baseline approaches\nin managing the accuracy-timeliness trade-off.","main_category":"cs.IT","categories":"cs.IT,cs.NI,math.IT","published":"2025-04-10T03:48:09Z"}
{"aid":"http://arxiv.org/abs/2504.07450v1","title":"Synthetic CT Generation from Time-of-Flight Non-Attenutaion-Corrected\n  PET for Whole-Body PET Attenuation Correction","summary":"Positron Emission Tomography (PET) imaging requires accurate attenuation\ncorrection (AC) to account for photon loss due to tissue density variations. In\nPET/MR systems, computed tomography (CT), which offers a straightforward\nestimation of AC is not available. This study presents a deep learning approach\nto generate synthetic CT (sCT) images directly from Time-of-Flight (TOF)\nnon-attenuation corrected (NAC) PET images, enhancing AC for PET/MR. We first\nevaluated models pre-trained on large-scale natural image datasets for a\nCT-to-CT reconstruction task, finding that the pre-trained model outperformed\nthose trained solely on medical datasets. The pre-trained model was then\nfine-tuned using an institutional dataset of 35 TOF NAC PET and CT volume\npairs, achieving the lowest mean absolute error (MAE) of 74.49 HU and highest\npeak signal-to-noise ratio (PSNR) of 28.66 dB within the body contour region.\nVisual assessments demonstrated improved reconstruction of both bone and soft\ntissue structures from TOF NAC PET images. This work highlights the\neffectiveness of using pre-trained deep learning models for medical image\ntranslation tasks. Future work will assess the impact of sCT on PET attenuation\ncorrection and explore additional neural network architectures and datasets to\nfurther enhance performance and practical applications in PET imaging.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-10T04:49:41Z"}
{"aid":"http://arxiv.org/abs/2504.07455v1","title":"Explicit Morphisms in the Galois-Tukey Category","summary":"If the Continuum Hypothesis is false, it implies the existence of\ncardinalities between the integers and the real numbers. In studying these\n\"cardinal characteristics of the continuum\", it was discovered that many of the\nassociated inequalities can be interpreted as morphisms within the\n\"Galois-Tukey\" category. This thesis aims to reformulate traditional direct\nproofs of cardinal characteristic inequalities by making the underlying\nmorphisms explicit. New, purely categorical results are also discussed.","main_category":"math.LO","categories":"math.LO","published":"2025-04-10T05:00:16Z"}
{"aid":"http://arxiv.org/abs/2504.07500v1","title":"Energy-Efficient UAV Replacement in Software-Defined UAV Networks","summary":"Unmanned Aerial Vehicles (UAVs) in networked environments face significant\nchallenges due to energy constraints and limited battery life, which\nnecessitate periodic replacements to maintain continuous operation. Efficiently\nmanaging the handover of data flows during these replacements is crucial to\navoid disruptions in communication and to optimize energy consumption. This\npaper addresses the complex issue of energy-efficient UAV replacement in\nsoftware-defined UAV network. We introduce a novel approach based on\nestablishing a strict total ordering relation for UAVs and data flows, allowing\nus to formulate the problem as an integer linear program. By utilizing the\nGurobi solver, we obtain optimal handover schedules for the tested problem\ninstances. Additionally, we propose a heuristic algorithm that significantly\nreduces computational complexity while maintaining near-optimal performance.\nThrough comprehensive simulations, we demonstrate that our heuristic offers\npractical and scalable solution, ensuring energy-efficient UAV replacement\nwhile minimizing network disruptions. Our results suggest that the proposed\napproach can enhance UAV battery life and improve overall network reliability\nin real-world applications.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T06:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.07501v1","title":"Distance signless Laplacian spectral radius and tough graphs involving\n  minimun degree","summary":"Let $G=(V(G),E(G))$ be a simple graph, where $V(G)$ and $E(G)$ are the vertex\nset and the edge set of $G$, respectively. The number of components of $G$ is\ndenoted by $c(G)$. Let $t$ be a positive real number, and a connected graph $G$\nis $t$-tough if $t c(G-S)\\leq|S|$ for every vertex cut $S$ of $V(G)$. The\ntoughness of graph $G$, denoted by $\\tau(G)$, is the largest value of $t$ for\nwhich $G$ is $t$-tough. Recently, Fan, Lin and Lu [European J. Combin.\n110(2023), 103701] presented sufficient conditions based on the spectral radius\nfor graphs to be 1-tough with minimum degree $\\delta(G)$ and graphs to be\n$t$-tough with $t\\geq 1$ being an integer, respectively. In this paper, we\nestablish sufficient conditions in terms of the distance signless Laplacian\nspectral radius for graphs to be 1-tough with minimum degree $\\delta(G)$ and\ngraphs to be $t$-tough, where $\\frac{1}{t}$ is a positive integer. Moreover, we\nconsider the relationship between the distance signless Laplacian spectral\nradius and $t$-tough graphs in terms of the order $n$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T07:01:52Z"}
{"aid":"http://arxiv.org/abs/2504.07516v1","title":"Enhancements for Developing a Comprehensive AI Fairness Assessment\n  Standard","summary":"As AI systems increasingly influence critical sectors like\ntelecommunications, finance, healthcare, and public services, ensuring fairness\nin decision-making is essential to prevent biased or unjust outcomes that\ndisproportionately affect vulnerable entities or result in adverse impacts.\nThis need is particularly pressing as the industry approaches the 6G era, where\nAI will drive complex functions like autonomous network management and\nhyper-personalized services. The TEC Standard for Fairness Assessment and\nRating of AI Systems provides guidelines for evaluating fairness in AI,\nfocusing primarily on tabular data and supervised learning models. However, as\nAI applications diversify, this standard requires enhancement to strengthen its\nimpact and broaden its applicability. This paper proposes an expansion of the\nTEC Standard to include fairness assessments for images, unstructured text, and\ngenerative AI, including large language models, ensuring a more comprehensive\napproach that keeps pace with evolving AI technologies. By incorporating these\ndimensions, the enhanced framework will promote responsible and trustworthy AI\ndeployment across various sectors.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-04-10T07:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.07523v1","title":"Lifetime-limited Gigahertz-frequency Mechanical Oscillators with\n  Millisecond Coherence Times","summary":"High-frequency mechanical oscillators with long coherence times are essential\nto realizing a variety of high-fidelity quantum sensors, transducers, and\nmemories. However, the unprecedented coherence times needed for quantum\napplications require exquisitely sensitive new techniques to probe the material\norigins of phonon decoherence and new strategies to mitigate decoherence in\nmechanical oscillators. Here, we combine non-invasive laser spectroscopy\ntechniques with materials analysis to identify key sources of phonon\ndecoherence in crystalline media. Using micro-fabricated high-overtone bulk\nacoustic-wave resonators ($\\mu$HBARs) as an experimental testbed, we identify\nphonon-surface interactions as the dominant source of phonon decoherence in\ncrystalline quartz; lattice distortion, subsurface damage, and high\nconcentration of elemental impurities near the crystal surface are identified\nas the likely causes. Removal of this compromised surface layer using an\noptimized polishing process is seen to greatly enhance coherence times,\nenabling $\\mu$HBARs with Q-factors of > 240 million at 12 GHz frequencies,\ncorresponding to > 6 ms phonon coherence times and record-level f-Q products.\nComplementary phonon linewidth and time-domain ringdown measurements, performed\nusing a new Brillouin-based pump-probe spectroscopy technique, reveal\nnegligible dephasing within these oscillators. Building on these results, we\nidentify a path to > 100 ms coherence times as the basis for high-frequency\nquantum memories. These findings clearly demonstrate that, with enhanced\ncontrol over surfaces, dissipation and noise can be significantly reduced in a\nwide range of quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci","published":"2025-04-10T07:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.07541v1","title":"On the initial ideal of a generic artinian Gorenstein algebra","summary":"In this note we show that the initial ideal of the annihilator ideal of a\ngeneric form is generated by the largest possible monomials in each degree. We\nalso show that the initial ideal with respect to the degree reverse\nlexicographical ordering of the annihilator ideal of the complete symmetric\nform has this property, by determining a minimal Gr\\\"obner basis of it.\nMoreover, we determine the total Betti numbers for a class of strongly stable\nmonomial ideals and show that these numbers agree with those for the degree\nreverse lexicographical initial ideals of the ideal generated by a sufficiently\nlarge number of generic forms, and of the annihilator ideal of a generic form.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:10:14Z"}
{"aid":"http://arxiv.org/abs/2504.07551v1","title":"Topology optimization of decoupling feeding networks for antenna arrays","summary":"Near-field and radiation coupling between nearby radiating elements is\nunavoidable, and it is considered a limiting factor for applications in\nwireless communications and active sensing. This article proposes a\ndensity-based topology optimization approach to design decoupling networks for\nsuch systems. The decoupling networks are designed based on a multi-objective\noptimization problem with the radiating elements replaced by their time-domain\nimpulse response for efficient computations and to enable the solution of the\ndesign problem using gradient-based optimization methods. We use the\nadjoint-field method to compute the gradients of the optimization objectives.\nAdditionally, nonlinear filters are applied during the optimization procedure\nto impose minimum-size control on the optimized designs. We demonstrate the\nconcept by designing the decoupling network for a two-element planar antenna\narray; the antenna is designed in a separate optimization problem. The\noptimized decoupling networks provide a signal path that destructively\ninterferes with the coupling between the radiating elements while preserving\ntheir individual matching to the feeding ports. Compact decoupling networks\ncapable of suppressing the mutual coupling by more than 10 dB between two\nclosely separated planar antennas operating around 2.45 GHz are presented and\nvalidated experimentally.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T08:27:04Z"}
{"aid":"http://arxiv.org/abs/2504.07561v1","title":"Regular Black Hole Models in the Transition from Baryonic Matter to\n  Quark Matter","summary":"In this paper, we investigate gravitational collapse scenarios involving\nbaryonic matter transitioning into quark-gluon plasma under extreme\nastrophysical conditions, focusing on their implications for the formation of\nregular black holes. Standard gravitational collapse models inevitably predict\ncentral singularities, highlighting the limitations of classical general\nrelativity in extreme density regimes. By introducing a physically motivated,\ninhomogeneous transition rate between baryonic and quark matter, we demonstrate\nanalytically and numerically that it is possible to construct regular black\nhole solutions featuring a nonsingular de Sitter-like core. We further analyze\nthe observable consequences of these models, particularly emphasizing\nmodifications to the black hole shadow radius, which provide direct\nobservational constraints accessible through Event Horizon Telescope (EHT)\nmeasurements.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T08:46:40Z"}
{"aid":"http://arxiv.org/abs/2504.07570v1","title":"Exploring Human-Like Thinking in Search Simulations with Large Language\n  Models","summary":"Simulating user search behavior is a critical task in information retrieval,\nwhich can be employed for user behavior modeling, data augmentation, and system\nevaluation. Recent advancements in large language models (LLMs) have opened up\nnew possibilities for generating human-like actions including querying,\nbrowsing, and clicking. In this work, we explore the integration of human-like\nthinking into search simulations by leveraging LLMs to simulate users' hidden\ncognitive processes. Specifically, given a search task and context, we prompt\nLLMs to first think like a human before executing the corresponding action. As\nexisting search datasets do not include users' thought processes, we conducted\na user study to collect a new dataset enriched with users' explicit thinking.\nWe investigate the impact of incorporating such human-like thinking on\nsimulation performance and apply supervised fine-tuning (SFT) to teach LLMs to\nemulate both human thinking and actions. Our experiments span two dimensions in\nleveraging LLMs for user simulation: (1) with or without explicit thinking, and\n(2) with or without fine-tuning on the thinking-augmented dataset. The results\ndemonstrate the feasibility and potential of incorporating human-like thinking\nin user simulations, though performance improvements on some metrics remain\nmodest. We believe this exploration provides new avenues and inspirations for\nadvancing user behavior modeling in search simulations.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:04:58Z"}
{"aid":"http://arxiv.org/abs/2504.07579v1","title":"Controlling Complex Systems","summary":"This chapter provides a comprehensive overview of controlling collective\nbehavior in complex systems comprising large ensembles of interacting dynamical\nagents. Building upon traditional control theory's foundation in individual\nsystems, we introduce tools designed to address the unique challenges of\ncoordinating networks that exhibit emergent phenomena, including consensus,\nsynchronization, and pattern formation. We analyze how local agent interactions\ngenerate macroscopic behaviors and investigate the fundamental role of network\ntopology in determining system dynamics. Inspired by natural systems, we\nemphasize control strategies that achieve global coordination through localized\ninterventions while considering practical implementation challenges. The\nchapter concludes by presenting novel frameworks for managing very large agent\nensembles and leveraging interacting networks for control purposes.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-10T09:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.07591v1","title":"On the Cox rings of some hypersurfaces","summary":"We introduce a cohomological method to compute Cox rings of hypersurfaces in\nthe ambient space P^1 x P^n, which is more direct than existing methods. We\nprove that smooth hypersurfaces defined by regular sequences of coefficients\nare Mori dream spaces, generalizing a result of Ottem. We also compute Cox\nrings of certain specialized examples. In particular, we compute Cox rings in\nthe well-studied family of Calabi--Yau threefolds of bidegree (2,4) in P^1 x\nP^3, determining explicitly how the Cox ring can jump discontinuously in a\nsmooth family.","main_category":"math.AG","categories":"math.AG","published":"2025-04-10T09:44:51Z"}
{"aid":"http://arxiv.org/abs/2504.07610v1","title":"What Contributes to Affective Polarization in Networked Online\n  Environments? Evidence from an Agent-Based Model","summary":"Affective polarization, or, inter-party hostility, is increasingly recognized\nas a pervasive issue in democracies worldwide, posing a threat to social\ncohesion. The digital media ecosystem, now widely accessible and ever-present,\nhas often been implicated in accelerating this phenomenon. However, the precise\ncausal mechanisms responsible for driving affective polarization have been a\nsubject of extensive debate. While the concept of echo chambers, characterized\nby individuals ensconced within like-minded groups, bereft of\ncounter-attitudinal content, has long been the prevailing hypothesis,\naccumulating empirical evidence suggests a more nuanced picture. This study\naims to contribute to the ongoing debate by employing an agent-based model to\nillustrate how affective polarization is either fostered or hindered by\nindividual news consumption and dissemination patterns based on ideological\nalignment. To achieve this, we parameterize three key aspects: (1) The\naffective asymmetry of individuals' engagement with in-party versus out-party\ncontent, (2) The proportion of in-party members within one's social\nneighborhood, and (3) The degree of partisan bias among the elites within the\npopulation. Subsequently, we observe macro-level changes in affective\npolarization within the population under various conditions stipulated by these\nparameters. This approach allows us to explore the intricate dynamics of\naffective polarization within digital environments, shedding light on the\ninterplay between individual behaviors, social networks, and information\nexposure.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T10:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.07614v1","title":"Enhanced THz emission from spintronic emitters with Pt-Al alloys","summary":"Platinum (Pt) is the element with the largest spin Hall conductivity and is\nknown as the most efficient spin-to-charge conversion material in spintronic\nTHz emitters. By alloying with aluminum (Al), its resistivity can be\nsubstantially increased, exceeding $100\\,\\mu\\Omega$cm. While the spin Hall\nconductivity is reduced by alloying, the relative resistivity increase\nsurpasses the reduction of spin Hall conductivity and thereby enhances the spin\nHall angle. We make use of this mechanism to improve the commonly used Pt-based\nspintronic THz emitter and demonstrate that an increase of 67% in the THz\nemission amplitude can be achieved between 20\\% and 30\\% Al in Pt. We show that\nthe enhanced THz emission amplitude is driven by the enhanced multilayer\nimpedance due to the larger resistivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T10:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.07620v1","title":"Equivariant recollements and singular equivalences","summary":"In this paper we investigate equivariant recollements of abelian (resp.\ntriangulated) categories. We first characterize when a recollement of abelian\n(resp. triangulated) categories induces an equivariant recollement, i.e. a\nrecollement between the corresponding equivariant abelian (resp. triangulated)\ncategories. We further investigate singular equivalences in the context of\nequivariant abelian recollements. In particular, we characterize when a\nsingular equivalence induced by the quotient functor in an abelian recollement\nlift to a singular equivalence induced by the equivariant quotient functor. As\napplications of our results: (i) we construct equivariant recollements for the\nderived category of a quasi-compact, quasi-separated scheme where the action is\ncoming from a subgroup of the automorphism group of the scheme and (ii) we\nderive new singular equivalences between certain skew group algebras.","main_category":"math.RT","categories":"math.RT,math.AG,math.CT,math.RA","published":"2025-04-10T10:08:23Z"}
{"aid":"http://arxiv.org/abs/2504.07632v1","title":"A Stochastic Ekman-Stokes Model for Coupled Ocean-Atmosphere-Wave\n  Dynamics","summary":"Accurate representation of atmosphere-ocean boundary layers, including the\ninterplay of turbulence, surface waves, and air-sea fluxes, remains a challenge\nin geophysical fluid dynamics, particularly for climate simulations. This study\nintroduces a stochastic coupled Ekman-Stokes model (SCESM) developed within the\nphysically consistent Location Uncertainty framework, explicitly incorporating\nrandom turbulent fluctuations and surface wave effects. The SCESM integrates\nestablished parameterizations for air-sea fluxes, turbulent viscosity, and\nStokes drift, and its performance is rigorously assessed through ensemble\nsimulations against LOTUS observational data. A performance ranking analysis\nquantifies the impact of different model components, highlighting the critical\nrole of explicit uncertainty representation in both oceanic and atmospheric\ndynamics for accurately capturing system variability. Wave-induced mixing terms\nimprove model performance, while wave-dependent surface roughness enhances\nair-sea fluxes but reduces the relative influence of wave-driven mixing. This\nfully coupled stochastic framework provides a foundation for advancing boundary\nlayer parameterizations in large-scale climate models.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-10T10:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.07638v1","title":"Predicting the Lifespan of Industrial Printheads with Survival Analysis","summary":"Accurately predicting the lifespan of critical device components is essential\nfor maintenance planning and production optimization, making it a topic of\nsignificant interest in both academia and industry. In this work, we\ninvestigate the use of survival analysis for predicting the lifespan of\nproduction printheads developed by Canon Production Printing. Specifically, we\nfocus on the application of five techniques to estimate survival probabilities\nand failure rates: the Kaplan-Meier estimator, Cox proportional hazard model,\nWeibull accelerated failure time model, random survival forest, and gradient\nboosting. The resulting estimates are further refined using isotonic regression\nand subsequently aggregated to determine the expected number of failures. The\npredictions are then validated against real-world ground truth data across\nmultiple time windows to assess model reliability. Our quantitative evaluation\nusing three performance metrics demonstrates that survival analysis outperforms\nindustry-standard baseline methods for printhead lifespan prediction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T10:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.07643v1","title":"CollEX -- A Multimodal Agentic RAG System Enabling Interactive\n  Exploration of Scientific Collections","summary":"In this paper, we introduce CollEx, an innovative multimodal agentic\nRetrieval-Augmented Generation (RAG) system designed to enhance interactive\nexploration of extensive scientific collections. Given the overwhelming volume\nand inherent complexity of scientific collections, conventional search systems\noften lack necessary intuitiveness and interactivity, presenting substantial\nbarriers for learners, educators, and researchers. CollEx addresses these\nlimitations by employing state-of-the-art Large Vision-Language Models (LVLMs)\nas multimodal agents accessible through an intuitive chat interface. By\nabstracting complex interactions via specialized agents equipped with advanced\ntools, CollEx facilitates curiosity-driven exploration, significantly\nsimplifying access to diverse scientific collections and records therein. Our\nsystem integrates textual and visual modalities, supporting educational\nscenarios that are helpful for teachers, pupils, students, and researchers by\nfostering independent exploration as well as scientific excitement and\ncuriosity. Furthermore, CollEx serves the research community by discovering\ninterdisciplinary connections and complementing visual data. We illustrate the\neffectiveness of our system through a proof-of-concept application containing\nover 64,000 unique records across 32 collections from a local scientific\ncollection from a public university.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.CV","published":"2025-04-10T10:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07653v1","title":"Optimum design of permeable diffractive lenses based on photon sieves","summary":"Photon sieves are permeable diffractive optical elements generated by open\napertures on a substrate. These elements are well suited for the monitoring of\nrunning fluids. Our analysis considers the fabrication constrains of the photon\nsieve and translate them into values of the optical parameters of the element.\nWhen used as focusing elements, or diffractive lenses, the spatial distribution\nof apertures can be designed to maximize the intensity at the focal plane and\nthe permeability of the device. This is done by defining a weighted merit\nfunction. The computation time of this merit function is key when applying\ndifferent strategies for the design, which often require a very large number of\ncalculations of this merit function. Then, besides using a reliable propagation\nmethod, we have included an analytic solution applicable for circular\napertures. Also, a geometrical merit function is proposed to simplify and\nreduce the computation even more. The methods proposed in this contribution are\ncompared in terms of the focused irradiance and permeability parameters,\nallowing an educated choice adapted to the given case or application. In this\ncontribution we analyze several methods to generate photon sieves in an optimum\nmanner. The resulted spatial distributions resemble the classical Fresnel zone\narrangement.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T11:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.07666v1","title":"On a fuzzy Landau Equation: Part I. A variational approach","summary":"This article is the first in a series of works on the fuzzy Landau equation,\nwhere particles interact through delocalised Coulomb collisions. Here, we\nestablish a variational characterisation that recasts the fuzzy Landau equation\nwithin the framework of GENERIC systems (General Equations for Non-Equilibrium\nReversible-Irreversible Coupling).","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T11:39:35Z"}
{"aid":"http://arxiv.org/abs/2504.07711v1","title":"Merging Embedded Topics with Optimal Transport for Online Topic Modeling\n  on Data Streams","summary":"Topic modeling is a key component in unsupervised learning, employed to\nidentify topics within a corpus of textual data. The rapid growth of social\nmedia generates an ever-growing volume of textual data daily, making online\ntopic modeling methods essential for managing these data streams that\ncontinuously arrive over time. This paper introduces a novel approach to online\ntopic modeling named StreamETM. This approach builds on the Embedded Topic\nModel (ETM) to handle data streams by merging models learned on consecutive\npartial document batches using unbalanced optimal transport. Additionally, an\nonline change point detection algorithm is employed to identify shifts in\ntopics over time, enabling the identification of significant changes in the\ndynamics of text streams. Numerical experiments on simulated and real-world\ndata show StreamETM outperforming competitors.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T13:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.07768v1","title":"Weighted special cycles on Rapoport--Zink spaces with almost self-dual\n  level","summary":"We introduce a ``vector valued'' version of special cycles on GSpin\nRapoport--Zink spaces with almost self-dual level in the context of the Kudla\nprogram, with certain linear invariance and local modularity features. They are\nlocal analogs of special cycles on GSpin Shimura varieties with almost\nself-dual parahoric level (e.g. Siegel threefolds with paramodular level). We\nestablish local arithmetic Siegel--Weil formulas relating arithmetic\nintersection numbers of these special cycles and derivatives of certain local\nWhittaker functions in any dimension. The proof is based on a reduction formula\nfor cyclic quadratic lattices.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T14:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.07800v1","title":"A Systematic Approach to Hyperbolic Quantum Error Correction Codes","summary":"Hyperbolic quantum error correction codes (HQECCs) leverage the unique\ngeometric properties of hyperbolic space to enhance the capabilities and\nperformance of quantum error correction. By embedding qubits in hyperbolic\nlattices, HQECCs achieve higher encoding rates and improved error thresholds\ncompared to conventional Euclidean codes. Building on recent advances in\nhyperbolic crystallography, we present a systematic framework for constructing\nHQECCs. As a key component of this framework, we develop a novel algorithm for\ncomputing all plaquette cycles and logical operators associated with a given\nHQECC. To demonstrate the effectiveness of this approach, we utilize this\nframework to simulate two HQECCs based respectively on two relevant examples of\nhyperbolic tilings. In the process, we evaluate key code parameters such as\nencoding rate, error threshold, and code distance for different sub-lattices.\nThis work establishes a solid foundation for a systematic and comprehensive\nanalysis of HQECCs, paving the way for the practical implementation of HQECCs\nin the pursuit of robust quantum error correction strategies.","main_category":"quant-ph","categories":"quant-ph,cs.DS,math.AG,math.DG,math.GR","published":"2025-04-10T14:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.07809v1","title":"A Riemannian Gradient Descent Method for the Least Squares Inverse\n  Eigenvalue Problem","summary":"We address an algorithm for the least squares fitting of a subset of the\neigenvalues of an unknown Hermitian matrix lying an an affine subspace, called\nthe Lift and Projection (LP) method, due to Chen and Chu (SIAM Journal on\nNumerical Analysis, 33 (1996), pp.2417-2430). The LP method iteratively `lifts'\nthe current iterate onto the spectral constraint manifold then 'projects' onto\nthe solution's affine subspace. We prove that this is equivalent to a\nRiemannian Gradient Descent with respect to a natural Riemannian metric. This\ninsight allows us to derive a more efficient implementation, analyse more\nprecisely its global convergence properties, and naturally append additional\nconstraints to the problem. We provide several numerical experiments to\ndemonstrate the improvement in computation time, which can be more than an\norder of magnitude if the eigenvalue constraints are on the smallest\neigenvalues, the largest eigenvalues, or the eigenvalues closest to a given\nnumber. These experiments include an inverse eigenvalue problem arising in\nInelastic Neutron Scattering of Manganese-6, which requires the least squares\nfitting of 16 experimentally observed eigenvalues of a $32400\\times32400$\nsparse matrix from a 5-dimensional subspace of spin Hamiltonian matrices.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T14:47:16Z"}
{"aid":"http://arxiv.org/abs/2504.07820v1","title":"Smoothed Distance Kernels for MMDs and Applications in Wasserstein\n  Gradient Flows","summary":"Negative distance kernels $K(x,y) := - \\|x-y\\|$ were used in the definition\nof maximum mean discrepancies (MMDs) in statistics and lead to favorable\nnumerical results in various applications. In particular, so-called slicing\ntechniques for handling high-dimensional kernel summations profit from the\nsimple parameter-free structure of the distance kernel. However, due to its\nnon-smoothness in $x=y$, most of the classical theoretical results, e.g. on\nWasserstein gradient flows of the corresponding MMD functional do not longer\nhold true. In this paper, we propose a new kernel which keeps the favorable\nproperties of the negative distance kernel as being conditionally positive\ndefinite of order one with a nearly linear increase towards infinity and a\nsimple slicing structure, but is Lipschitz differentiable now. Our construction\nis based on a simple 1D smoothing procedure of the absolute value function\nfollowed by a Riemann-Liouville fractional integral transform. Numerical\nresults demonstrate that the new kernel performs similarly well as the negative\ndistance kernel in gradient descent methods, but now with theoretical\nguarantees.","main_category":"stat.ML","categories":"stat.ML,cs.LG,math.FA,math.PR","published":"2025-04-10T14:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.07827v1","title":"HarmonySeg: Tubular Structure Segmentation with Deep-Shallow Feature\n  Fusion and Growth-Suppression Balanced Loss","summary":"Accurate segmentation of tubular structures in medical images, such as\nvessels and airway trees, is crucial for computer-aided diagnosis,\nradiotherapy, and surgical planning. However, significant challenges exist in\nalgorithm design when faced with diverse sizes, complex topologies, and (often)\nincomplete data annotation of these structures. We address these difficulties\nby proposing a new tubular structure segmentation framework named HarmonySeg.\nFirst, we design a deep-to-shallow decoder network featuring flexible\nconvolution blocks with varying receptive fields, which enables the model to\neffectively adapt to tubular structures of different scales. Second, to\nhighlight potential anatomical regions and improve the recall of small tubular\nstructures, we incorporate vesselness maps as auxiliary information. These maps\nare aligned with image features through a shallow-and-deep fusion module, which\nsimultaneously eliminates unreasonable candidates to maintain high precision.\nFinally, we introduce a topology-preserving loss function that leverages\ncontextual and shape priors to balance the growth and suppression of tubular\nstructures, which also allows the model to handle low-quality and incomplete\nannotations. Extensive quantitative experiments are conducted on four public\ndatasets. The results show that our model can accurately segment 2D and 3D\ntubular structures and outperform existing state-of-the-art methods. External\nvalidation on a private dataset also demonstrates good generalizability.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T15:04:42Z"}
{"aid":"http://arxiv.org/abs/2504.07847v1","title":"An update-resilient Kalman filtering approach","summary":"We propose a new robust filtering paradigm considering the situation in which\nmodel uncertainty, described through an ambiguity set, is present only in the\nobservations. We derive the corresponding robust estimator, referred to as\nupdate-resilient Kalman filter, which appears to be novel compared to existing\nminimax game-based filtering approaches. Moreover, we characterize the\ncorresponding least favorable state space model and analyze the filter\nstability. Finally, some numerical examples show the effectiveness of the\nproposed estimator.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.07848v1","title":"Opinion dynamics and the unpredictability of opinion trajectories in an\n  adaptive social network model","summary":"Understanding opinion dynamics in social networks is critical for predicting\nsocial behavior and detecting polarization. Traditional approaches often rely\non static snapshots of network states, which can obscure the underlying\ndynamics of opinion evolution. In this study, we introduce a dynamic framework\nthat quantifies the unpredictability of opinion trajectories using the\nnormalized Lempel-Ziv (nLZ) complexity. Our approach leverages an adaptive\nsocial network model where each node is characterized by three behavioral\nparameters - homophily, neophily, and social conformity - and where opinions\nevolve continuously according to a system of ordinary differential equations.\nThe results reveal distinct nLZ complexity signatures for each node type:\nhomophilic nodes exhibit consistently rising complexity, reflecting\nincreasingly unpredictable opinion shifts that are counterintuitive given their\ntendency for similarity; neophilic nodes maintain low and stable complexity,\nsuggesting that openness to novelty can, surprisingly, lead to stable opinion\ndynamics; and conformic nodes display a U-shaped complexity trend,\ntransitioning from early opinion stagnation to later unpredictability. In fully\nheterogeneous networks, modest interaction effects emerge, with slight shifts\nin the unpredictability of each faction's trajectories. These findings\nunderscore the importance of temporal analysis in uncovering hidden dynamical\npatterns, offering novel insights into the mechanisms underlying social\nadaptation and polarization.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T15:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.07880v1","title":"Sculpting the outer edge of accretion disks in pre-circumbinary binary\n  black hole systems","summary":"Binary black hole systems (BBHs) have become a vivid reality in astrophysics\nas stellar-mass black hole mergers are now detected through their related\ngravitational wave emission during the merger stage. If many studies were\nrecently dedicated to the last stages of BBH where black holes are surrounded\nby a circumbinary disk (CBD), the structure of these systems prior to the\nformation of the CBD remains mostly unexplored. The aim of the present article\nis to investigate the potential modifications induced by the presence of a\nsecondary black hole onto the structure of the accretion disk surrounding the\nprimary black hole. We performed 2D classical hydrodynamical simulations of an\naccretion disk surrounding the primary black hole while taking into account all\ngravitational effects induced by both the primary black hole and the secondary\nblack hole orbiting on circular orbits around the center of mass of the\nsystem.We report three main effects of the presence of a secondary black hole\norbiting a circular orbit beyond the outer edge of the accretion disk: 1/ the\nouter radius of the accretion disk is significantly reduced and its ratio to\nthe black hole separation is directly linked to only the mass ratio of the\nblack holes; 2/ two spiral arms are visible in the gas density structure of the\ndisk and 3/ the outer edge of the accretion disk exhibits an elliptical shape\nthat mainly depends on the mass ratio of the black holes. Our results show that\nan accretion disk orbiting a primary black hole in a pre-CBD BBH exhibits\nspecific features induced by the gravitational force generated by the presence\nof a secondary black hole beyond its outer edge. Such features, directly linked\nto the binary separation and mass ratio, has therefore the potential to help in\nthe search and identification of BBH in the pre-CBD stage.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-10T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.07884v1","title":"CatCMA with Margin: Stochastic Optimization for Continuous, Integer, and\n  Categorical Variables","summary":"This study focuses on mixed-variable black-box optimization (MV-BBO),\naddressing continuous, integer, and categorical variables. Many real-world\nMV-BBO problems involve dependencies among these different types of variables,\nrequiring efficient methods to optimize them simultaneously. Recently,\nstochastic optimization methods leveraging the mechanism of the covariance\nmatrix adaptation evolution strategy have shown promising results in\nmixed-integer or mixed-category optimization. However, such methods cannot\nhandle the three types of variables simultaneously. In this study, we propose\nCatCMA with Margin (CatCMAwM), a stochastic optimization method for MV-BBO that\njointly optimizes continuous, integer, and categorical variables. CatCMAwM is\ndeveloped by incorporating a novel integer handling into CatCMA, a\nmixed-category black-box optimization method employing a joint distribution of\nmultivariate Gaussian and categorical distributions. The proposed integer\nhandling is carefully designed by reviewing existing integer handlings and\nfollowing the design principles of CatCMA. Even when applied to mixed-integer\nproblems, it stabilizes the marginal probability and improves the convergence\nperformance of continuous variables. Numerical experiments show that CatCMAwM\neffectively handles the three types of variables, outperforming\nstate-of-the-art Bayesian optimization methods and baselines that simply\nincorporate existing integer handlings into CatCMA.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-10T15:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.07887v1","title":"Benchmarking Adversarial Robustness to Bias Elicitation in Large\n  Language Models: Scalable Automated Assessment with LLM-as-a-Judge","summary":"Large Language Models (LLMs) have revolutionized artificial intelligence,\ndriving advancements in machine translation, summarization, and conversational\nagents. However, their increasing integration into critical societal domains\nhas raised concerns about embedded biases, which can perpetuate stereotypes and\ncompromise fairness. These biases stem from various sources, including\nhistorical inequalities in training data, linguistic imbalances, and\nadversarial manipulation. Despite mitigation efforts, recent studies indicate\nthat LLMs remain vulnerable to adversarial attacks designed to elicit biased\nresponses. This work proposes a scalable benchmarking framework to evaluate LLM\nrobustness against adversarial bias elicitation. Our methodology involves (i)\nsystematically probing models with a multi-task approach targeting biases\nacross various sociocultural dimensions, (ii) quantifying robustness through\nsafety scores using an LLM-as-a-Judge approach for automated assessment of\nmodel responses, and (iii) employing jailbreak techniques to investigate\nvulnerabilities in safety mechanisms. Our analysis examines prevalent biases in\nboth small and large state-of-the-art models and their impact on model safety.\nAdditionally, we assess the safety of domain-specific models fine-tuned for\ncritical fields, such as medicine. Finally, we release a curated dataset of\nbias-related prompts, CLEAR-Bias, to facilitate systematic vulnerability\nbenchmarking. Our findings reveal critical trade-offs between model size and\nsafety, aiding the development of fairer and more robust future language\nmodels.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-10T16:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.07890v1","title":"Stupendously Large Primordial Black Holes from the QCD axion","summary":"The inflationary diffusion of (pseudo-)scalar fields with discrete symmetries\ncan seed the formation of a gas of closed domain walls after inflation, when\nthe distance between degenerate minima in field space is not too far from the\ninflationary Hubble scale. Primordial black holes (PBHs) can then be formed\nonce sufficiently heavy domain walls re-enter the Hubble sphere. In this\nscenario, inflation determines a distinctive PBH mass distribution that is\nrather flat and can thus lead to a sizable total abundance of PBHs, while\navoiding some of the downsides of PBH formation from critical collapse. We show\nthat generic QCD axion models, with decay constant close to the inflationary\nHubble scale, can yield up to $1\\%$ of the dark matter (DM) today in the form\nof PBHs, while being compatible with isocurvature constraints from Cosmic\nMicrowave Background observations. This occurs for values of axion decay\nconstants around $f_a\\simeq 10^{8}~\\text{GeV}$, that is the region targeted by\naxion helioscopes and partially constrained by astrophysical observations. The\nresulting PBHs have \\textit{stupendously} large masses, above $10^{11}M_\\odot$,\nand their existence can be probed by Large Scale Structure observations. Larger\nPBH abundances can be generated by axion-like particles. Alternatively, in\nscenarios where isocurvature constraints can be relaxed, we find that the\ntotality of the DM can be produced by the QCD axion misalignment mechanism,\naccompanied by a ${\\cal O}(10^{-3})$ DM fraction in PBHs of masses\n$(10^5-10^6)~M_\\odot$. These can act as seeds for the formation of massive\nblack holes at large redshifts, as suggested by recent JWST observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-10T16:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.07920v1","title":"Directed Temporal Tree Realization for Periodic Public Transport: Easy\n  and Hard Cases","summary":"We study the complexity of the directed periodic temporal graph realization\nproblem. This work is motivated by the design of periodic schedules in public\ntransport with constraints on the quality of service. Namely, we require that\nthe fastest path between (important) pairs of vertices is upper bounded by a\nspecified maximum duration, encoded in an upper distance matrix $D$. While\nprevious work has considered the undirected version of the problem, the\napplication in public transport schedule design requires the flexibility to\nassign different departure times to the two directions of an edge. A problem\ninstance can only be feasible if all values of the distance matrix are at least\nshortest path distances. However, the task of realizing exact fastest path\ndistances in a periodic temporal graph is often too restrictive. Therefore, we\nintroduce a minimum slack parameter $k$ that describes a lower bound on the\nmaximum allowed waiting time on each path. We concentrate on tree topologies\nand provide a full characterization of the complexity landscape with respect to\nthe period $\\Delta$ and the minimum slack parameter~$k$, showing a sharp\nthreshold between NP-complete cases and cases which are always realizable. We\nalso provide hardness results for the special case of period $\\Delta = 2$ for\ngeneral directed and undirected graphs.","main_category":"cs.DS","categories":"cs.DS,cs.CC,cs.DM","published":"2025-04-10T17:36:23Z"}
{"aid":"http://arxiv.org/abs/2504.07930v1","title":"Localization and Topology in Noncentrosymmetric Superconductors with\n  Disorder","summary":"The celebrated Kitaev chain reveals a captivating phase diagram in the\npresence of various disorders, encompassing multifractal states and topological\nAnderson phases. In this work, we investigate the localization and topological\nproperties of a dimerized topological noncentrosymmetric superconductor (NCS)\nunder quasiperiodic and Anderson disorders. Using both global and local\ncharacterization methods, we identify energy-dependent transitions from ergodic\nto multifractal and localized states. Extended multifractal regimes emerge from\nthe competition between dimerization, NCS order, and quasiperiodic modulation.\nThis interplay causes localization to occur preferentially in different energy\nbands depending on the disorder strength, with the lowest bands exhibiting the\nhighest sensitivity to parameter variations. We employ the real-space\npolarization method to compute the $\\mathbb{Z}_2$ topological invariant,\nrevealing alternating topological and trivial phases as the quasiperiodic\npotential increases, a behavior distinct from the typical topological Anderson\nphase diagram. Additionally, the topological states show remarkable robustness\nagainst Anderson disorder, providing new insights into topological phase\nstability in non-centrosymmetric systems. Finally, we propose a feasible\nexperimental scheme based on superconducting Josephson junctions, where\nNCS-like behavior can be engineered via spatially modulated supercurrents. Our\nfindings highlight the distinct roles of different disorder types in shaping\nlocalization and topology, providing insight into the engineering of Majorana\nzero modes and offering profound implications for topological quantum\nencryption schemes.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-04-10T17:45:28Z"}
{"aid":"http://arxiv.org/abs/2504.07936v1","title":"We Are All Creators: Generative AI, Collective Knowledge, and the Path\n  Towards Human-AI Synergy","summary":"Generative AI presents a profound challenge to traditional notions of human\nuniqueness, particularly in creativity. Fueled by neural network based\nfoundation models, these systems demonstrate remarkable content generation\ncapabilities, sparking intense debates about authorship, copyright, and\nintelligence itself. This paper argues that generative AI represents an\nalternative form of intelligence and creativity, operating through mathematical\npattern synthesis rather than biological understanding or verbatim replication.\nThe fundamental differences between artificial and biological neural networks\nreveal AI learning as primarily statistical pattern extraction from vast\ndatasets crystallized forms of collective human knowledge scraped from the\ninternet. This perspective complicates copyright theft narratives and\nhighlights practical challenges in attributing AI outputs to individual\nsources. Rather than pursuing potentially futile legal restrictions, we\nadvocate for human AI synergy. By embracing generative AI as a complementary\ntool alongside human intuition, context, and ethical judgment, society can\nunlock unprecedented innovation, democratize creative expression, and address\ncomplex challenges. This collaborative approach, grounded in realistic\nunderstanding of AIs capabilities and limitations, offers the most promising\npath forward. Additionally, recognizing these models as products of collective\nhuman knowledge raises ethical questions about accessibility ensuring equitable\naccess to these tools could prevent widening societal divides and leverage\ntheir full potential for collective benefit.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T17:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.07953v1","title":"Free monad sequences and extension operations","summary":"In the first part of this article, we give an analysis of the free monad\nsequence in non-cocomplete categories, with the needed colimits explicitly\nparametrized. This enables us to state a more finely grained functoriality\nprinciple for free monad and monoid sequences.\n  In the second part, we deal with the problem of functorially extending via\npullback squares a category of maps along the category of coalgebras of an\nalgebraic weak factorization system. This generalizes the classical problem of\nextending a class of maps along the left class of a weak factorization system\nin the sense of pullback squares where the vertical maps are in the chosen\nclass and the bottom map is in the left class. Such situations arise in the\ncontext of model structures where one might wish to extend fibrations along\ntrivial cofibrations. We derive suitable conditions for the algebraic analogue\nof weak saturation of the extension problem, using the results of the first\npart to reduce the technical burden.","main_category":"math.CT","categories":"math.CT","published":"2025-04-10T17:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.07964v1","title":"C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization\n  for Test-Time Expert Re-Mixing","summary":"Mixture-of-Experts (MoE) Large Language Models (LLMs) suffer from severely\nsub-optimal expert pathways-our study reveals that naive expert selection\nlearned from pretraining leaves a surprising 10-20% accuracy gap for\nimprovement. Motivated by this observation, we develop a novel class of\ntest-time optimization methods to re-weight or \"re-mixing\" the experts in\ndifferent layers jointly for each test sample. Since the test sample's ground\ntruth is unknown, we propose to optimize a surrogate objective defined by the\nsample's \"successful neighbors\" from a reference set of samples. We introduce\nthree surrogates and algorithms based on mode-finding, kernel regression, and\nthe average loss of similar reference samples/tasks. To reduce the cost of\noptimizing whole pathways, we apply our algorithms merely to the core experts'\nmixing weights in critical layers, which enjoy similar performance but save\nsignificant computation. This leads to \"Critical-Layer, Core-Expert,\nCollaborative Pathway Optimization (C3PO)\". We apply C3PO to two recent MoE\nLLMs and examine it on six widely-used benchmarks. It consistently improves the\nbase model by 7-15% in accuracy and outperforms widely used test-time learning\nbaselines, e.g., in-context learning and prompt/prefix tuning, by a large\nmargin. Moreover, C3PO enables MoE LLMs with 1-3B active parameters to\noutperform LLMs of 7-9B parameters, hence improving MoE's advantages on\nefficiency. Our thorough ablation study further sheds novel insights on\nachieving test-time improvement on MoE.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.09880v1","title":"The Universal Gap-to-Critical Temperature Ratio in Superconductors: a\n  Statistical Mechanical Perspective","summary":"We propose a statistical mechanical framework to unify the observed\nrelationship between the superconducting energy gap $\\Delta$, the pseudogap\n$\\Delta^\\ast$, and the critical temperature $T_\\mathrm{c}$. In this model,\nfermions couple as a composite boson and condense to occupy a single bound\nstate as the temperature drops. We derive a concise formula for $T_\\mathrm{c}$\nin terms of $\\Delta$ and $\\Delta^\\ast$, namely: $$\\frac{\\Delta}{k_\\mathrm{B}\nT_\\mathrm{c}} = 1.4+4\\log(\\Delta^\\ast/\\Delta).$$ This expression reproduces the\nstandard BCS gap-to-$T_\\mathrm{c}$ ratio in the absence of a pseudogap, while\nnaturally explaining its enhancement in unconventional superconductors. The\nmodel is supported by comparisons with experimental data from several cuprates\nand iron-based superconductors, which highlight its generality. This\nformulation also offers a theoretical explanation for the observed persistence\nof the pseudogap phase into the overdoped regime.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-14T05:04:25Z"}
{"aid":"http://arxiv.org/abs/2504.09899v1","title":"Digital Staining with Knowledge Distillation: A Unified Framework for\n  Unpaired and Paired-But-Misaligned Data","summary":"Staining is essential in cell imaging and medical diagnostics but poses\nsignificant challenges, including high cost, time consumption, labor intensity,\nand irreversible tissue alterations. Recent advances in deep learning have\nenabled digital staining through supervised model training. However, collecting\nlarge-scale, perfectly aligned pairs of stained and unstained images remains\ndifficult. In this work, we propose a novel unsupervised deep learning\nframework for digital cell staining that reduces the need for extensive paired\ndata using knowledge distillation. We explore two training schemes: (1)\nunpaired and (2) paired-but-misaligned settings. For the unpaired case, we\nintroduce a two-stage pipeline, comprising light enhancement followed by\ncolorization, as a teacher model. Subsequently, we obtain a student staining\ngenerator through knowledge distillation with hybrid non-reference losses. To\nleverage the pixel-wise information between adjacent sections, we further\nextend to the paired-but-misaligned setting, adding the Learning to Align\nmodule to utilize pixel-level information. Experiment results on our dataset\ndemonstrate that our proposed unsupervised deep staining method can generate\nstained images with more accurate positions and shapes of the cell targets in\nboth settings. Compared with competing methods, our method achieves improved\nresults both qualitatively and quantitatively (e.g., NIQE and PSNR).We applied\nour digital staining method to the White Blood Cell (WBC) dataset,\ninvestigating its potential for medical applications.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-14T05:48:05Z"}
{"aid":"http://arxiv.org/abs/2504.09926v1","title":"Quotients of Poisson boundaries, entropy, and spectral gap","summary":"Poisson boundary is a measurable $\\Gamma$-space canonically associated with a\ngroup $\\Gamma$ and a probability measure $\\mu$ on it. The collection of all\nmeasurable $\\Gamma$-equivariant quotients, known as $\\mu$-boundaries, of the\nPoisson boundary forms a partially ordered set, equipped with a strictly\nmonotonic non-negative function, known as Furstenberg or differential entropy.\n  In this paper we demonstrate the richness and the complexity of this lattice\nof quotients for the case of free groups and surface groups and rather general\nmeasures. In particular, we show that there are continuum many unrelated\n$\\mu$-boundaries at each, sufficiently low, entropy level, and there are\ncontinuum many distinct order-theoretic cubes of $\\mu$-boundaries.\n  These $\\mu$-boundaries are constructed from dense linear representations\n$\\rho:\\Gamma\\to G$ to semi-simple Lie groups, like $\\PSL_2(\\bbC)^d$ with\nabsolutely continuous stationary measures on $\\hat\\bbC^d$.","main_category":"math.GR","categories":"math.GR,math.DS","published":"2025-04-14T06:35:18Z"}
{"aid":"http://arxiv.org/abs/2504.09927v1","title":"Efficient Task-specific Conditional Diffusion Policies: Shortcut Model\n  Acceleration and SO(3) Optimization","summary":"Imitation learning, particularly Diffusion Policies based methods, has\nrecently gained significant traction in embodied AI as a powerful approach to\naction policy generation. These models efficiently generate action policies by\nlearning to predict noise. However, conventional Diffusion Policy methods rely\non iterative denoising, leading to inefficient inference and slow response\ntimes, which hinder real-time robot control. To address these limitations, we\npropose a Classifier-Free Shortcut Diffusion Policy (CF-SDP) that integrates\nclassifier-free guidance with shortcut-based acceleration, enabling efficient\ntask-specific action generation while significantly improving inference speed.\nFurthermore, we extend diffusion modeling to the SO(3) manifold in shortcut\nmodel, defining the forward and reverse processes in its tangent space with an\nisotropic Gaussian distribution. This ensures stable and accurate rotational\nestimation, enhancing the effectiveness of diffusion-based control. Our\napproach achieves nearly 5x acceleration in diffusion inference compared to\nDDIM-based Diffusion Policy while maintaining task performance. Evaluations\nboth on the RoboTwin simulation platform and real-world scenarios across\nvarious tasks demonstrate the superiority of our method.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T06:37:22Z"}
{"aid":"http://arxiv.org/abs/2504.09928v1","title":"On the difference of the two initial logarithmic coefficients for\n  Bazilevic class of univalent functions","summary":"In this paper we give sharp bounds of the difference of the moduli of the\nsecond and the first logarithmic coefficient for Bazilevi\\v{c} class of\nunivalent functions.","main_category":"math.CV","categories":"math.CV","published":"2025-04-14T06:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.09934v1","title":"Tight Semidefinite Relaxations for Verifying Robustness of Neural\n  Networks","summary":"For verifying the safety of neural networks (NNs), Fazlyab et al. (2019)\nintroduced a semidefinite programming (SDP) approach called DeepSDP. This\nformulation can be viewed as the dual of the SDP relaxation for a problem\nformulated as a quadratically constrained quadratic program (QCQP). While SDP\nrelaxations of QCQPs generally provide approximate solutions with some gaps,\nthis work focuses on tight SDP relaxations that provide exact solutions to the\nQCQP for single-layer NNs. Specifically, we analyze tightness conditions in\nthree cases: (i) NNs with a single neuron, (ii) single-layer NNs with an\nellipsoidal input set, and (iii) single-layer NNs with a rectangular input set.\nFor NNs with a single neuron, we propose a condition that ensures the SDP\nadmits a rank-1 solution to DeepSDP by transforming the QCQP into an equivalent\ntwo-stage problem leads to a solution collinear with a predetermined vector.\nFor single-layer NNs with an ellipsoidal input set, the collinearity of\nsolutions is proved via the Karush-Kuhn-Tucker condition in the two-stage\nproblem. In case of single-layer NNs with a rectangular input set, we\ndemonstrate that the tightness of DeepSDP can be reduced to the single-neuron\nNNs, case (i), if the weight matrix is a diagonal matrix.","main_category":"math.OC","categories":"math.OC","published":"2025-04-14T06:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.09975v1","title":"OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape\n  Generation","summary":"Autoregressive models have achieved remarkable success across various\ndomains, yet their performance in 3D shape generation lags significantly behind\nthat of diffusion models. In this paper, we introduce OctGPT, a novel\nmultiscale autoregressive model for 3D shape generation that dramatically\nimproves the efficiency and performance of prior 3D autoregressive approaches,\nwhile rivaling or surpassing state-of-the-art diffusion models. Our method\nemploys a serialized octree representation to efficiently capture the\nhierarchical and spatial structures of 3D shapes. Coarse geometry is encoded\nvia octree structures, while fine-grained details are represented by binary\ntokens generated using a vector quantized variational autoencoder (VQVAE),\ntransforming 3D shapes into compact \\emph{multiscale binary sequences} suitable\nfor autoregressive prediction. To address the computational challenges of\nhandling long sequences, we incorporate octree-based transformers enhanced with\n3D rotary positional encodings, scale-specific embeddings, and token-parallel\ngeneration schemes. These innovations reduce training time by 13 folds and\ngeneration time by 69 folds, enabling the efficient training of high-resolution\n3D shapes, e.g.,$1024^3$, on just four NVIDIA 4090 GPUs only within days.\nOctGPT showcases exceptional versatility across various tasks, including text-,\nsketch-, and image-conditioned generation, as well as scene-level synthesis\ninvolving multiple objects. Extensive experiments demonstrate that OctGPT\naccelerates convergence and improves generation quality over prior\nautoregressive methods, offering a new paradigm for high-quality, scalable 3D\ncontent creation.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-14T08:31:26Z"}
{"aid":"http://arxiv.org/abs/2504.09980v1","title":"Turn-taking annotation for quantitative and qualitative analyses of\n  conversation","summary":"This paper has two goals. First, we present the turn-taking annotation layers\ncreated for 95 minutes of conversational speech of the Graz Corpus of Read and\nSpontaneous Speech (GRASS), available to the scientific community. Second, we\ndescribe the annotation system and the annotation process in more detail, so\nother researchers may use it for their own conversational data. The annotation\nsystem was developed with an interdisciplinary application in mind. It should\nbe based on sequential criteria according to Conversation Analysis, suitable\nfor subsequent phonetic analysis, thus time-aligned annotations were made\nPraat, and it should be suitable for automatic classification, which required\nthe continuous annotation of speech and a label inventory that is not too large\nand results in a high inter-rater agreement. Turn-taking was annotated on two\nlayers, Inter-Pausal Units (IPU) and points of potential completion (PCOMP;\nsimilar to transition relevance places). We provide a detailed description of\nthe annotation process and of segmentation and labelling criteria. A detailed\nanalysis of inter-rater agreement and common confusions shows that agreement\nfor IPU annotation is near-perfect, that agreement for PCOMP annotations is\nsubstantial, and that disagreements often are either partial or can be\nexplained by a different analysis of a sequence which also has merit. The\nannotation system can be applied to a variety of conversational data for\nlinguistic studies and technological applications, and we hope that the\nannotations, as well as the annotation system will contribute to a stronger\ncross-fertilization between these disciplines.","main_category":"cs.CL","categories":"cs.CL,cs.DB,cs.HC,eess.AS","published":"2025-04-14T08:45:04Z"}
{"aid":"http://arxiv.org/abs/2504.09989v1","title":"FTHP-MPI: Towards Providing Replication-based Fault Tolerance in a\n  Fault-Intolerant Native MPI Library","summary":"Faults in high-performance systems are expected to be very large in the\ncurrent exascale computing era. To compensate for a higher failure rate, the\nstandard checkpoint/restart technique would need to create checkpoints at a\nmuch higher frequency resulting in an excessive amount of overhead which would\nnot be sustainable for many scientific applications. To improve application\nefficiency in such high failure environments, the mechanism of replication of\nMPI processes was proposed. Replication allows for fast recovery from failures\nby simply dropping the failed processes and using their replicas to continue\nthe regular operation of the application.\n  In this paper, we have implemented FTHP-MPI (Fault Tolerance and High\nPerformance MPI), a novel fault-tolerant MPI library that augments\ncheckpoint/restart with replication to provide resilience from failures. The\nnovelty of our work is that it is designed to provide fault tolerance in a\nnative MPI library that does not provide support for fault tolerance. This lets\napplication developers achieve fault tolerance at high failure rates while also\nusing efficient communication protocols in the native MPI libraries that are\ngenerally fine-tuned for specific HPC platforms. We have also implemented\nefficient parallel communication techniques that involve replicas. Our\nframework deals with the unique challenges of integrating support for\ncheckpointing and partial replication.\n  We conducted experiments emulating the failure rates of exascale computing\nsystems with three applications, HPCG, PIC and CloverLeaf. We show that for\nlarge scale systems where the failure intervals are expected to be within a\nhour, our replication-based library provides higher efficiency and performance\nthan checkpointing-based approaches. We show that under failure-free\nconditions, the additional overheads due to replication are negligible in our\nlibrary.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:52:35Z"}
{"aid":"http://arxiv.org/abs/2504.09997v1","title":"GenTe: Generative Real-world Terrains for General Legged Robot\n  Locomotion Control","summary":"Developing bipedal robots capable of traversing diverse real-world terrains\npresents a fundamental robotics challenge, as existing methods using predefined\nheight maps and static environments fail to address the complexity of\nunstructured landscapes. To bridge this gap, we propose GenTe, a framework for\ngenerating physically realistic and adaptable terrains to train generalizable\nlocomotion policies. GenTe constructs an atomic terrain library that includes\nboth geometric and physical terrains, enabling curriculum training for\nreinforcement learning-based locomotion policies. By leveraging\nfunction-calling techniques and reasoning capabilities of Vision-Language\nModels (VLMs), GenTe generates complex, contextually relevant terrains from\ntextual and graphical inputs. The framework introduces realistic force modeling\nfor terrain interactions, capturing effects such as soil sinkage and\nhydrodynamic resistance. To the best of our knowledge, GenTe is the first\nframework that systemically generates simulation environments for legged robot\nlocomotion control. Additionally, we introduce a benchmark of 100 generated\nterrains. Experiments demonstrate improved generalization and robustness in\nbipedal robot locomotion.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T09:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.09998v1","title":"Metric-Guided Synthesis of Class Activation Mapping","summary":"Class activation mapping (CAM) is a widely adopted class of saliency methods\nused to explain the behavior of convolutional neural networks (CNNs). These\nmethods generate heatmaps that highlight the parts of the input most relevant\nto the CNN output. Various CAM methods have been proposed, each distinguished\nby the expressions used to derive heatmaps. In general, users look for heatmaps\nwith specific properties that reflect different aspects of CNN functionality.\nThese may include similarity to ground truth, robustness, equivariance, and\nmore. Although existing CAM methods implicitly encode some of these properties\nin their expressions, they do not allow for variability in heatmap generation\nfollowing the user's intent or domain knowledge. In this paper, we address this\nlimitation by introducing SyCAM, a metric-based approach for synthesizing CAM\nexpressions. Given a predefined evaluation metric for saliency maps, SyCAM\nautomatically generates CAM expressions optimized for that metric. We\nspecifically explore a syntax-guided synthesis instantiation of SyCAM, where\nCAM expressions are derived based on predefined syntactic constraints and the\ngiven metric. Using several established evaluation metrics, we demonstrate the\nefficacy and flexibility of our approach in generating targeted heatmaps. We\ncompare SyCAM with other well-known CAM methods on three prominent models:\nResNet50, VGG16, and VGG19.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T09:01:49Z"}
{"aid":"http://arxiv.org/abs/2504.10034v1","title":"Uniform Planar Array Based Weighted Cooperative Spectrum Sensing for\n  Cognitive Radio Networks","summary":"Cooperative spectrum sensing (CSS) is essential for improving the spectrum\nefficiency and reliability of cognitive radio applications. Next-generation\nwireless communication networks increasingly employ uniform planar arrays (UPA)\ndue to their ability to steer beamformers towards desired directions,\nmitigating interference and eavesdropping. However, the application of\nUPA-based CSS in cognitive radio remains largely unexplored. This paper\nproposes a multi-beam UPA-based weighted CSS (WCSS) framework to enhance\ndetection reliability, applicable to various cognitive radio networks,\nincluding cellular, vehicular, and satellite communications. We first propose a\nweighting factor for commonly used energy detection (ED) and eigenvalue\ndetection (EVD) techniques, based on the spatial variation of signal strengths\nresulting from UPA antenna beamforming. We then analytically characterize the\nperformance of both weighted ED and weighted EVD by deriving closed-form\nexpressions for false alarm and detection probabilities. Our numerical results,\nconsidering both static and dynamic user behaviors, demonstrate the superiority\nof WCSS in enhancing sensing performance compared to uniformly weighted\ndetectors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T09:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10081v1","title":"RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning\n  Capability","summary":"Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been\nrapidly progressing and achieving breakthrough performance on complex reasoning\ntasks such as mathematics and coding. However, the open-source R1 models have\nraised safety concerns in wide applications, such as the tendency to comply\nwith malicious queries, which greatly impacts the utility of these powerful\nmodels in their applications. In this paper, we introduce RealSafe-R1 as\nsafety-aligned versions of DeepSeek-R1 distilled models. To train these models,\nwe construct a dataset of 15k safety-aware reasoning trajectories generated by\nDeepSeek-R1, under explicit instructions for expected refusal behavior. Both\nquantitative experiments and qualitative case studies demonstrate the models'\nimprovements, which are shown in their safety guardrails against both harmful\nqueries and jailbreak attacks. Importantly, unlike prior safety alignment\nefforts that often compromise reasoning performance, our method preserves the\nmodels' reasoning capabilities by maintaining the training data within the\noriginal distribution of generation. Model weights of RealSafe-R1 are\nopen-source at https://huggingface.co/RealSafe.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-14T10:26:37Z"}
{"aid":"http://arxiv.org/abs/2504.10084v1","title":"UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based\n  Person Retrieval","summary":"Text-based Person Retrieval (TPR) as a multi-modal task, which aims to\nretrieve the target person from a pool of candidate images given a text\ndescription, has recently garnered considerable attention due to the progress\nof contrastive visual-language pre-trained model. Prior works leverage\npre-trained CLIP to extract person visual and textual features and fully\nfine-tune the entire network, which have shown notable performance improvements\ncompared to uni-modal pre-training models. However, full-tuning a large model\nis prone to overfitting and hinders the generalization ability. In this paper,\nwe propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method\nfor Text-based Person Retrieval (UP-Person) to thoroughly transfer the\nmulti-modal knowledge from CLIP. Specifically, UP-Person simultaneously\nintegrates three lightweight PETL components including Prefix, LoRA and\nAdapter, where Prefix and LoRA are devised together to mine local information\nwith task-specific information prompts, and Adapter is designed to adjust\nglobal feature representations. Additionally, two vanilla submodules are\noptimized to adapt to the unified architecture of TPR. For one thing, S-Prefix\nis proposed to boost attention of prefix and enhance the gradient propagation\nof prefix tokens, which improves the flexibility and performance of the vanilla\nprefix. For another thing, L-Adapter is designed in parallel with layer\nnormalization to adjust the overall distribution, which can resolve conflicts\ncaused by overlap and interaction among multiple submodules. Extensive\nexperimental results demonstrate that our UP-Person achieves state-of-the-art\nresults across various person retrieval datasets, including CUHK-PEDES,\nICFG-PEDES and RSTPReid while merely fine-tuning 4.7\\% parameters. Code is\navailable at https://github.com/Liu-Yating/UP-Person.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T10:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.10107v1","title":"Enhancing LLM-based Recommendation through Semantic-Aligned\n  Collaborative Knowledge","summary":"Large Language Models (LLMs) demonstrate remarkable capabilities in\nleveraging comprehensive world knowledge and sophisticated reasoning mechanisms\nfor recommendation tasks. However, a notable limitation lies in their inability\nto effectively model sparse identifiers (e.g., user and item IDs), unlike\nconventional collaborative filtering models (Collabs.), thus hindering LLM to\nlearn distinctive user-item representations and creating a performance\nbottleneck. Prior studies indicate that integrating collaborative knowledge\nfrom Collabs. into LLMs can mitigate the above limitations and enhance their\nrecommendation performance. Nevertheless, the significant discrepancy in\nknowledge distribution and semantic space between LLMs and Collab. presents\nsubstantial challenges for effective knowledge transfer. To tackle these\nchallenges, we propose a novel framework, SeLLa-Rec, which focuses on achieving\nalignment between the semantic spaces of Collabs. and LLMs. This alignment\nfosters effective knowledge fusion, mitigating the influence of discriminative\nnoise and facilitating the deep integration of knowledge from diverse models.\nSpecifically, three special tokens with collaborative knowledge are embedded\ninto the LLM's semantic space through a hybrid projection layer and integrated\ninto task-specific prompts to guide the recommendation process. Experiments\nconducted on two public benchmark datasets (MovieLens-1M and Amazon Book)\ndemonstrate that SeLLa-Rec achieves state-of-the-art performance.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T11:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.10123v1","title":"M2S-RoAD: Multi-Modal Semantic Segmentation for Road Damage Using Camera\n  and LiDAR Data","summary":"Road damage can create safety and comfort challenges for both human drivers\nand autonomous vehicles (AVs). This damage is particularly prevalent in rural\nareas due to less frequent surveying and maintenance of roads. Automated\ndetection of pavement deterioration can be used as an input to AVs and driver\nassistance systems to improve road safety. Current research in this field has\npredominantly focused on urban environments driven largely by public datasets,\nwhile rural areas have received significantly less attention. This paper\nintroduces M2S-RoAD, a dataset for the semantic segmentation of different\nclasses of road damage. M2S-RoAD was collected in various towns across New\nSouth Wales, Australia, and labelled for semantic segmentation to identify nine\ndistinct types of road damage. This dataset will be released upon the\nacceptance of the paper.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:32:01Z"}
{"aid":"http://arxiv.org/abs/2504.10152v1","title":"Neo balcobalancing numbers","summary":"In this work, we defined neo balcobalancing numbers, neo Lucas-balcobalancing\nnumbers, neo balcobalancers and neo Lucas-balcobalancers and derived the\ngeneral terms of these numbers in terms of balancing numbers. Conversely we\ndeduced the general terms of balancing, cobalancing, Lucas-balancing and\nLucas-cobalancing numbers in terms of these numbers. We also deduced some\nrelations on Binet formulas, recurrence relations, relationship with Pell,\nPell-Lucas, triangular, square triangular numbers, Pythagorean triples and\nCassini identities. We also formulate the sum of first $n$-terms of these\nnumbers and obtained some formulas for the sums of Pell, Pell-Lucas, balancing\nand Lucas-cobalancing numbers in terms of these numbers.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T12:04:32Z"}
{"aid":"http://arxiv.org/abs/2504.10163v1","title":"Shoulder Range of Motion Rehabilitation Robot Incorporating\n  Scapulohumeral Rhythm for Frozen Shoulder","summary":"This paper presents a novel rehabilitation robot designed to address the\nchallenges of passive range of motion (PROM) exercises for frozen shoulder\npatients by integrating advanced scapulohumeral rhythm stabilization. Frozen\nshoulder is characterized by limited glenohumeral motion and disrupted\nscapulohumeral rhythm, with therapist-assisted interventions being highly\neffective for restoring normal shoulder function. While existing robotic\nsolutions replicate natural shoulder biomechanics, they lack the ability to\nstabilize compensatory movements, such as shoulder shrugging, which are\ncritical for effective rehabilitation. Our proposed device features a 6 degrees\nof freedom (DoF) mechanism, including 5 DoF for shoulder motion and an\ninnovative 1 DoF Joint press for scapular stabilization. The robot employs a\npersonalized two-phase operation: recording normal shoulder movement patterns\nfrom the unaffected side and applying them to guide the affected side.\nExperimental results demonstrated the robot's ability to replicate recorded\nmotion patterns with high precision, with root mean square error (RMSE) values\nconsistently below 1 degree. In simulated frozen shoulder conditions, the robot\neffectively suppressed scapular elevation, delaying the onset of compensatory\nmovements and guiding the affected shoulder to move more closely in alignment\nwith normal shoulder motion, particularly during arm elevation movements such\nas abduction and flexion. These findings confirm the robot's potential as a\nrehabilitation tool capable of automating PROM exercises while correcting\ncompensatory movements. The system provides a foundation for advanced,\npersonalized rehabilitation for patients with frozen shoulders.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T12:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.10187v1","title":"Deep Reasoning Translation via Reinforcement Learning","summary":"Recently, deep reasoning LLMs (e.g., OpenAI o1/o3 and DeepSeek-R1) have shown\npromising performance in various complex tasks. Free translation is an\nimportant and interesting task in the multilingual world, which requires going\nbeyond word-for-word translation and taking cultural differences into account.\nThis task is still under-explored in deep reasoning LLMs. In this paper, we\nintroduce DeepTrans, a deep reasoning translation model that learns free\ntranslation via reinforcement learning. Specifically, we carefully build a\nreward model with pre-defined scoring criteria on both the translation results\nand the thought process. Given the source sentences, the reward model teaches\nthe deep translation model how to think and free-translate them during\nreinforcement learning. In this way, training DeepTrans does not need any\nlabeled translations, avoiding the human-intensive annotation or\nresource-intensive data synthesis. Experimental results show the effectiveness\nof DeepTrans. Using Qwen2.5-7B as the backbone, DeepTrans improves performance\nby 16.3% in literature translation, and outperforms strong deep reasoning\nbaselines as well as baselines that are fine-tuned with synthesized data.\nMoreover, we summarize the failures and interesting findings during our RL\nexploration. We hope this work could inspire other researchers in free\ntranslation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.10196v1","title":"On compact embeddings in $\\mathbf{L^p}$ and fractional spaces","summary":"Let $X,Y$ be Hilbert spaces and $\\mathcal{A}\\colon X\\to X'$ a continuous and\nsymmetric elliptic operator. We suppose that $X$ is dense in $Y$ and that the\nembedding $X\\subset Y$ is compact. In this paper we show some consequences of\nthis setting on the study of the fractional operator attached to $\\mathcal{A}$\nin the extension setting $\\mathbb{R}^N\\times (0, \\infty)$. Being more specific,\nwe will give some examples where the embedding $H(\\mathbb{R}^{N+1}_+)\\subset\nL^2(\\mathbb{R}^N)$ is compact, with the space $H(\\mathbb{R}^{N+1}_+)$ depending\non the operator $\\mathcal{A}$.","main_category":"math.FA","categories":"math.FA,math.AP","published":"2025-04-14T13:02:48Z"}
{"aid":"http://arxiv.org/abs/2504.10210v1","title":"Can Competition Enhance the Proficiency of Agents Powered by Large\n  Language Models in the Realm of News-driven Time Series Forecasting?","summary":"Multi-agents-based news-driven time series forecasting is considered as a\npotential paradigm shift in the era of large language models (LLMs). The\nchallenge of this task lies in measuring the influences of different news\nevents towards the fluctuations of time series. This requires agents to possess\nstronger abilities of innovative thinking and the identifying misleading logic.\nHowever, the existing multi-agent discussion framework has limited enhancement\non time series prediction in terms of optimizing these two capabilities.\nInspired by the role of competition in fostering innovation, this study embeds\na competition mechanism within the multi-agent discussion to enhance agents'\ncapability of generating innovative thoughts. Furthermore, to bolster the\nmodel's proficiency in identifying misleading information, we incorporate a\nfine-tuned small-scale LLM model within the reflective stage, offering\nauxiliary decision-making support. Experimental results confirm that the\ncompetition can boost agents' capacity for innovative thinking, which can\nsignificantly improve the performances of time series prediction. Similar to\nthe findings of social science, the intensity of competition within this\nframework can influence the performances of agents, providing a new perspective\nfor studying LLMs-based multi-agent systems.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-14T13:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10227v1","title":"Probing then Editing Response Personality of Large Language Models","summary":"Large Language Models (LLMs) have demonstrated promising capabilities to\ngenerate responses that exhibit consistent personality traits. Despite the\nmajor attempts to analyze personality expression through output-based\nevaluations, little is known about how such traits are internally encoded\nwithin LLM parameters. In this paper, we introduce a layer-wise probing\nframework to systematically investigate the layer-wise capability of LLMs in\nencoding personality for responding. We conduct probing experiments on 11\nopen-source LLMs over the PersonalityEdit benchmark and find that LLMs\npredominantly encode personality for responding in their middle and upper\nlayers, with instruction-tuned models demonstrating a slightly clearer\nseparation of personality traits. Furthermore, by interpreting the trained\nprobing hyperplane as a layer-wise boundary for each personality category, we\npropose a layer-wise perturbation method to edit the personality expressed by\nLLMs during inference. Our results show that even when the prompt explicitly\nspecifies a particular personality, our method can still successfully alter the\nresponse personality of LLMs. Interestingly, the difficulty of converting\nbetween certain personality traits varies substantially, which aligns with the\nrepresentational distances in our probing experiments. Finally, we conduct a\ncomprehensive MMLU benchmark evaluation and time overhead analysis,\ndemonstrating that our proposed personality editing method incurs only minimal\ndegradation in general capabilities while maintaining low training costs and\nacceptable inference latency. Our code is publicly available at\nhttps://github.com/universe-sky/probing-then-editing-personality.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T13:46:35Z"}
{"aid":"http://arxiv.org/abs/2504.10244v1","title":"Towards contrast- and pathology-agnostic clinical fetal brain MRI\n  segmentation using SynthSeg","summary":"Magnetic resonance imaging (MRI) has played a crucial role in fetal\nneurodevelopmental research. Structural annotations of MR images are an\nimportant step for quantitative analysis of the developing human brain, with\nDeep learning providing an automated alternative for this otherwise tedious\nmanual process. However, segmentation performances of Convolutional Neural\nNetworks often suffer from domain shift, where the network fails when applied\nto subjects that deviate from the distribution with which it is trained on. In\nthis work, we aim to train networks capable of automatically segmenting fetal\nbrain MRIs with a wide range of domain shifts pertaining to differences in\nsubject physiology and acquisition environments, in particular shape-based\ndifferences commonly observed in pathological cases. We introduce a novel\ndata-driven train-time sampling strategy that seeks to fully exploit the\ndiversity of a given training dataset to enhance the domain generalizability of\nthe trained networks. We adapted our sampler, together with other existing data\naugmentation techniques, to the SynthSeg framework, a generator that utilizes\ndomain randomization to generate diverse training data, and ran thorough\nexperimentations and ablation studies on a wide range of training/testing data\nto test the validity of the approaches. Our networks achieved notable\nimprovements in the segmentation quality on testing subjects with intense\nanatomical abnormalities (p < 1e-4), though at the cost of a slighter decrease\nin performance in cases with fewer abnormalities. Our work also lays the\nfoundation for future works on creating and adapting data-driven sampling\nstrategies for other training pipelines.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-14T14:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.10249v1","title":"Struggle First, Prompt Later: How Task Complexity Shapes Learning with\n  GenAI-Assisted Pretesting","summary":"This study examines the role of AI-assisted pretesting in enhancing learning\noutcomes, particularly when integrated with generative AI tools like ChatGPT.\nPretesting, a learning strategy in which students attempt to answer questions\nor solve problems before receiving instruction, has been shown to improve\nretention by activating prior knowledge. The adaptability and interactivity of\nAI-assisted pretesting introduce new opportunities for optimizing learning in\ndigital environments. Across three experimental studies, we explored how\npretesting strategies, task characteristics, and student motivation influence\nlearning. Findings suggest that AI-assisted pretesting enhances learning\noutcomes, particularly for tasks requiring higher-order thinking. While\nadaptive AI-driven pretesting increased engagement, its benefits were most\npronounced in complex, exploratory tasks rather than straightforward\ncomputational problems. These results highlight the importance of aligning\npretesting strategies with task demands, demonstrating that AI can optimize\nlearning when applied to tasks requiring deeper cognitive engagement. This\nresearch provides insights into how AI-assisted pretesting can be effectively\nintegrated with generative AI tools to enhance both cognitive and motivational\noutcomes in learning environments.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T14:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.10251v1","title":"Global stability of the Lengyel-Epstein systems","summary":"We study the global (asymptotic) stability of the Lengyel-Epstein\ndifferential systems, sometimes called Belousov-Zhabotinsky differential\nsystems. Such systems are topologically equivalent to a two-parameter family of\ncubic systems in the plane. We show that for each pair of admissible parameters\nthe unique equilibrium point of the corresponding system is not globally\n(asymptotically) stable. On the other hand, we provide explicit conditions for\nthis unique equilibrium point to be asymptotically stable and we study its\nbasin of attraction. We also study the generic and degenerate Hopf bifurcations\nand highlight a subset of the set of admissible parameters for which the phase\nportraits of the systems have two limit cycles.","main_category":"math.DS","categories":"math.DS,math.CA","published":"2025-04-14T14:13:48Z"}
{"aid":"http://arxiv.org/abs/2504.10258v1","title":"XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a\n  Novel Benchmark","summary":"Document Reading Order Recovery is a fundamental task in document image\nunderstanding, playing a pivotal role in enhancing Retrieval-Augmented\nGeneration (RAG) and serving as a critical preprocessing step for large\nlanguage models (LLMs). Existing methods often struggle with complex\nlayouts(e.g., multi-column newspapers), high-overhead interactions between\ncross-modal elements (visual regions and textual semantics), and a lack of\nrobust evaluation benchmarks. We introduce XY-Cut++, an advanced layout\nordering method that integrates pre-mask processing, multi-granularity\nsegmentation, and cross-modal matching to address these challenges. Our method\nsignificantly enhances layout ordering accuracy compared to traditional XY-Cut\ntechniques. Specifically, XY-Cut++ achieves state-of-the-art performance (98.8\nBLEU overall) while maintaining simplicity and efficiency. It outperforms\nexisting baselines by up to 24\\% and demonstrates consistent accuracy across\nsimple and complex layouts on the newly introduced DocBench-100 dataset. This\nadvancement establishes a reliable foundation for document structure recovery,\nsetting a new standard for layout ordering tasks and facilitating more\neffective RAG and LLM preprocessing.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-14T14:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10281v1","title":"Zero-shot Autonomous Microscopy for Scalable and Intelligent\n  Characterization of 2D Materials","summary":"Characterization of atomic-scale materials traditionally requires human\nexperts with months to years of specialized training. Even for trained human\noperators, accurate and reliable characterization remains challenging when\nexamining newly discovered materials such as two-dimensional (2D) structures.\nThis bottleneck drives demand for fully autonomous experimentation systems\ncapable of comprehending research objectives without requiring large training\ndatasets. In this work, we present ATOMIC (Autonomous Technology for Optical\nMicroscopy & Intelligent Characterization), an end-to-end framework that\nintegrates foundation models to enable fully autonomous, zero-shot\ncharacterization of 2D materials. Our system integrates the vision foundation\nmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),\nunsupervised clustering, and topological analysis to automate microscope\ncontrol, sample scanning, image segmentation, and intelligent analysis through\nprompt engineering, eliminating the need for additional training. When\nanalyzing typical MoS2 samples, our approach achieves 99.7% segmentation\naccuracy for single layer identification, which is equivalent to that of human\nexperts. In addition, the integrated model is able to detect grain boundary\nslits that are challenging to identify with human eyes. Furthermore, the system\nretains robust accuracy despite variable conditions including defocus, color\ntemperature fluctuations, and exposure variations. It is applicable to a broad\nspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless\nof whether they were fabricated via chemical vapor deposition or mechanical\nexfoliation. This work represents the implementation of foundation models to\nachieve autonomous analysis, establishing a scalable and data-efficient\ncharacterization paradigm that fundamentally transforms the approach to\nnanoscale materials research.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cs.AI,cs.CV,cs.LG","published":"2025-04-14T14:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.10291v1","title":"Towards a Flat Space Carrollian Hologram from AdS$_4$/CFT$_3$","summary":"Finding a concrete example holography in four dimensional asymptotically flat\nspace is an important open problem. A natural strategy is to take the flat\nspace limit of the celebrated AdS$_4$/CFT$_3$ correspondence, which relates\nM-theory in AdS$_4 \\times$S$^7$ to a certain superconformal Chern-Simons-matter\ntheory known as the ABJM theory. In this limit, the boundary of AdS$_4$ becomes\nnull infinity and the ABJM theory should exhibit an emergent superconformal\nCarrollian symmetry. We investigate this possiblity by matching the Carrollian\nlimit of ABJM correlators with four-dimensional supergravity amplitudes that\narise from taking the flat space limit of AdS$_4 \\times$S$^7$ and reducing\nalong the S$^7$. We also present a general analysis of three-dimensional\nsuperconformal Carrollian symmetry.","main_category":"hep-th","categories":"hep-th","published":"2025-04-14T15:02:58Z"}
{"aid":"http://arxiv.org/abs/2504.10293v1","title":"Gravity-induced emergence of the Fermi scale in quantum quadratic\n  gravity","summary":"In the framework of asymptotic safety, we study quantum quadratic gravity in\nthe presence of the Higgs field considered as non-separable from the vacuum.\nThe theory flows to a high energy fixed point where the Higgs field is strongly\ncoupled to gravity, its potential is symmetric, and the quadratic Weyl\ncurvature coupling is large. The latter renders the ghost graviton an unstable\nhigh mass resonance which renders unitarity in the spirit of Lee-Week type\ntheories. Furthermore, if the scalar graviton is tachyonic then there will be a\nlow energy fixed point where tachyonic condensation leads to a new stable\nvacuum. At this fixed point the symmetry breaks and the Fermi scale emerges,\nand the behavior of the Higgs field is classical (not influenced by\ngravitational interaction). Gravity at the UV scale is purely quadratic whereas\nat the Fermi scale it is linear, and in the intermediate region both\ncontributions are relevant. Thus, at the Fermi scale the quadratic curvature\nfields disappear through the ghost instability and tachyon condensation, giving\nrise to Einstein gravity and the electroweak phase transition.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-14T15:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.10297v1","title":"Bumblebee cosmology: The FLRW solution and the CMB temperature\n  anisotropy","summary":"We put into test the idea of replacing dark energy by a vector field against\nthe cosmic microwave background (CMB) observation using the simplest\nvector-tensor theory, where a massive vector field couples to the Ricci scalar\nand the Ricci tensor quadratically. First, a remarkable\nFriedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) metric solution that is\ncompletely independent of the matter-energy compositions of the universe is\nfound. Second, based on the FLRW solution as well as the perturbation\nequations, a numerical code calculating the CMB temperature power spectrum is\nbuilt. We find that though the FLRW solution can mimic the evolution of the\nuniverse in the standard $\\Lambda$CDM model, the calculated CMB temperature\npower spectrum shows unavoidable discrepancies from the CMB power spectrum\nmeasurements.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-14T15:06:38Z"}
{"aid":"http://arxiv.org/abs/2504.10311v1","title":"Performance of a Brownian information engine through potential\n  profiling: Optimum output requisites, Heating-to-Refrigeration transition and\n  their Re-entrance","summary":"Brownian Information engine (BIE) harnesses the energy from a fluctuating\nenvironment by utilizing the associated information change in the presence of a\nsingle heat bath. The engine operates in a space-dependent confining potential\nand requires an appropriate feedback control mechanism. In general, the\nfeedback controller has three different steps: measurement, feedback, and\nrelaxation. The feedback step is related to a sudden change in the potential\nenergy that is essential for a nonzero work output. BIE utilises the amount of\ninformation (surprise) acquired during the measurement step for the energy\noutput. However, due to the relaxation process, a certain amount of acquired\ninformation is lost or becomes unavailable. So, controlling information loss\nduring relaxation is crucial for the overall efficiency of the engine. The net\n(available) information, therefore, can be monitored by tuning the feedback\ncontroller and the shape of the confining potential. In this paper, we explore\nthe effect of the shape modulation of the confining potential, which may have\nmultiple stable valleys and unstable hills, on the net available information\nand, hence, the performance of a BIE that operates under an asymmetric feedback\nprotocol. We examine the optimal performance requirements of the BIE and the\namount of maximum work output under different potential profiling. For\nmonostable trapping, a concave shape in confining potential results in a higher\nwork output than a convex one. We also find that hills and valleys in the\nconfining potential may lead to multiple good operating conditions. An\nappropriate shape modulation can create a heater-refrigerator transition and\ntheir reentrance due to non-trivial changes in information loss during the\nrelaxation process.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T15:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.10321v1","title":"Indecomposable bundles on Cartesian products of odd projective spaces","summary":"In this paper we construct indecomposable vector bundles associated to monads\non Cartesian products of odd dimension projective spaces. Specifically we\nestablish the existence of monads on\n$(\\mathbb{P}^1)^{l_1}\\times\\cdots\\times(\\mathbb{P}^{2n+1})^{l_m}$. We prove\nstability of the kernel bundle and prove that the cohomology bundle is simple.\nWe also prove the same for monads on\n$(\\mathbb{P}^n)^2\\times(\\mathbb{P}^m)^2\\times(\\mathbb{P}^l)^2$ for an ample\nline bundle\n$\\mathscr{L}=\\mathcal{O}_X(\\alpha,\\alpha,\\beta,\\beta,\\gamma,\\gamma)$.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T15:30:09Z"}
{"aid":"http://arxiv.org/abs/2504.10328v1","title":"Continuous fields of interval algebras","summary":"This paper investigates and classifies a specific class of one-parameter\ncontinuous fields of C*-algebras, which can be seen as generalized AI-algebras.\nBuilding on the classification of *-homomorphisms between interval algebras by\nthe Cuntz semigroup, along with a selection theorem and a gluing procedure, we\nemploy a 'local-to-global' strategy to achieve our classification result.","main_category":"math.OA","categories":"math.OA","published":"2025-04-14T15:36:03Z"}
{"aid":"http://arxiv.org/abs/2504.10329v1","title":"InstructEngine: Instruction-driven Text-to-Image Alignment","summary":"Reinforcement Learning from Human/AI Feedback (RLHF/RLAIF) has been\nextensively utilized for preference alignment of text-to-image models. Existing\nmethods face certain limitations in terms of both data and algorithm. For\ntraining data, most approaches rely on manual annotated preference data, either\nby directly fine-tuning the generators or by training reward models to provide\ntraining signals. However, the high annotation cost makes them difficult to\nscale up, the reward model consumes extra computation and cannot guarantee\naccuracy. From an algorithmic perspective, most methods neglect the value of\ntext and only take the image feedback as a comparative signal, which is\ninefficient and sparse. To alleviate these drawbacks, we propose the\nInstructEngine framework. Regarding annotation cost, we first construct a\ntaxonomy for text-to-image generation, then develop an automated data\nconstruction pipeline based on it. Leveraging advanced large multimodal models\nand human-defined rules, we generate 25K text-image preference pairs. Finally,\nwe introduce cross-validation alignment method, which refines data efficiency\nby organizing semantically analogous samples into mutually comparable pairs.\nEvaluations on DrawBench demonstrate that InstructEngine improves SD v1.5 and\nSDXL's performance by 10.53% and 5.30%, outperforming state-of-the-art\nbaselines, with ablation study confirming the benefits of InstructEngine's all\ncomponents. A win rate of over 50% in human reviews also proves that\nInstructEngine better aligns with human preferences.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T15:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.10385v1","title":"Normalized solutions for SchrÃ¶dinger-Bopp-Podolsky systems in bounded\n  domains","summary":"We consider an elliptic system of Schr\\\"odinger-Bopp-Podolsky type in a\nbounded and smooth domain of R3 with a non constant coupling factor. This kind\nof system has been introduced in the mathematical literature in [14] and in the\nlast years many contributions appeared. In particular here we present the\nresults in [2] and [34] which show existence of solutions by means of the\nLjusternik-Schnirelmann theory under different boundary conditions on the\nelectrostatic potential.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:28:31Z"}
{"aid":"http://arxiv.org/abs/2504.10391v1","title":"LLM-driven Constrained Copy Generation through Iterative Refinement","summary":"Crafting a marketing message (copy), or copywriting is a challenging\ngeneration task, as the copy must adhere to various constraints. Copy creation\nis inherently iterative for humans, starting with an initial draft followed by\nsuccessive refinements. However, manual copy creation is time-consuming and\nexpensive, resulting in only a few copies for each use case. This limitation\nrestricts our ability to personalize content to customers. Contrary to the\nmanual approach, LLMs can generate copies quickly, but the generated content\ndoes not consistently meet all the constraints on the first attempt (similar to\nhumans). While recent studies have shown promise in improving constrained\ngeneration through iterative refinement, they have primarily addressed tasks\nwith only a few simple constraints. Consequently, the effectiveness of\niterative refinement for tasks such as copy generation, which involves many\nintricate constraints, remains unclear. To address this gap, we propose an\nLLM-based end-to-end framework for scalable copy generation using iterative\nrefinement. To the best of our knowledge, this is the first study to address\nmultiple challenging constraints simultaneously in copy generation. Examples of\nthese constraints include length, topics, keywords, preferred lexical ordering,\nand tone of voice. We demonstrate the performance of our framework by creating\ncopies for e-commerce banners for three different use cases of varying\ncomplexity. Our results show that iterative refinement increases the copy\nsuccess rate by $16.25-35.91$% across use cases. Furthermore, the copies\ngenerated using our approach outperformed manually created content in multiple\npilot studies using a multi-armed bandit framework. The winning copy improved\nthe click-through rate by $38.5-45.21$%.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T16:38:28Z"}
{"aid":"http://arxiv.org/abs/2504.10392v1","title":"Spin-Orbital Intertwined Topological Superconductivity in a Class of\n  Correlated Noncentrosymmetric Materials","summary":"In this study, we propose an alternative route to achieving topological\nsuperconductivity (TSC). Our approach applies to a new class of correlated\nnoncentrosymmetric materials that host two spin-split Fermi surfaces with\nidentical spin textures due to a spin-orbital intertwined effect. Incorporating\nmulti-orbital repulsive Hubbard interactions, we calculate the superconducting\npairings of a minimal two-orbital effective model within a\nspin-fluctuation-mediated superconductivity framework. We find that, depending\non the effective Rashba spin-orbit coupling (RSOC) strength and filling level,\nthe Hubbard interaction can drive the leading pairing symmetry into the\n$A_1(S_{\\pm})$, $B_1$, $B_2$ or $B_2(d_{\\pm})$ irreducible representations\n(IRs) of the $C_{4v}$ point group. Notably, the $A_1(S_{\\pm})$ pairing gives\nrise to a fully gapped TSC characterized by a $Z_2$ invariant, while the\n$B_2(d_{\\pm})$ pairing results in a nodal TSC. Our analysis reveals that the\nfully gapped TSC is predominated by spin-singlet regardless of the presence of\nthe spin-triplet components. This distinguishes our model from\nnoncentrosymmetric materials with conventional Rashba-split band structures,\nwhere TSC typically emerges near the van Hove singularity and is primarily\ndriven by $p$-wave or $f$-wave spin-triplet pairing. These features enhances\nits experimental accessibility, and we discuss potential experimental systems\nfor its realization.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-14T16:40:34Z"}
{"aid":"http://arxiv.org/abs/2504.10405v1","title":"Performance of Large Language Models in Supporting Medical Diagnosis and\n  Treatment","summary":"The integration of Large Language Models (LLMs) into healthcare holds\nsignificant potential to enhance diagnostic accuracy and support medical\ntreatment planning. These AI-driven systems can analyze vast datasets,\nassisting clinicians in identifying diseases, recommending treatments, and\npredicting patient outcomes. This study evaluates the performance of a range of\ncontemporary LLMs, including both open-source and closed-source models, on the\n2024 Portuguese National Exam for medical specialty access (PNA), a\nstandardized medical knowledge assessment. Our results highlight considerable\nvariation in accuracy and cost-effectiveness, with several models demonstrating\nperformance exceeding human benchmarks for medical students on this specific\ntask. We identify leading models based on a combined score of accuracy and\ncost, discuss the implications of reasoning methodologies like\nChain-of-Thought, and underscore the potential for LLMs to function as valuable\ncomplementary tools aiding medical professionals in complex clinical\ndecision-making.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.ET,cs.HC","published":"2025-04-14T16:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.10408v1","title":"Software package for simulations using the coarse-grained CALVADOS model","summary":"We present the CALVADOS package for performing simulations of biomolecules\nusing OpenMM and the coarse-grained CALVADOS model. The package makes it easy\nto run simulations using the family of CALVADOS models of biomolecules\nincluding disordered proteins, multi-domain proteins, proteins in crowded\nenvironments, and disordered RNA. We briefly describe the CALVADOS force fields\nand how they were parametrised. We then discuss the design paradigms and\narchitecture of the CALVADOS package, and give examples of how to use it for\nrunning and analysing simulations. The simulation package is freely available\nunder a GNU GPL license; therefore, it can easily be extended and we provide\nsome examples of how this might be done.","main_category":"q-bio.BM","categories":"q-bio.BM","published":"2025-04-14T16:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.10409v1","title":"GPS: Distilling Compact Memories via Grid-based Patch Sampling for\n  Efficient Online Class-Incremental Learning","summary":"Online class-incremental learning aims to enable models to continuously adapt\nto new classes with limited access to past data, while mitigating catastrophic\nforgetting. Replay-based methods address this by maintaining a small memory\nbuffer of previous samples, achieving competitive performance. For effective\nreplay under constrained storage, recent approaches leverage distilled data to\nenhance the informativeness of memory. However, such approaches often involve\nsignificant computational overhead due to the use of bi-level optimization.\nMotivated by these limitations, we introduce Grid-based Patch Sampling (GPS), a\nlightweight and effective strategy for distilling informative memory samples\nwithout relying on a trainable model. GPS generates informative samples by\nsampling a subset of pixels from the original image, yielding compact\nlow-resolution representations that preserve both semantic content and\nstructural information. During replay, these representations are reassembled to\nsupport training and evaluation. Experiments on extensive benchmarks\ndemonstrate that GRS can be seamlessly integrated into existing replay\nframeworks, leading to 3%-4% improvements in average end accuracy under\nmemory-constrained settings, with limited computational overhead.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.10413v1","title":"On perimeter minimizing sets in manifolds with quadratic volume growth","summary":"This paper studies whether the presence of a perimeter minimizing set in a\nRiemannian manifold $(M,g)$ forces an isometric splitting. We show that this is\nthe case when $M$ has non-negative sectional curvature and quadratic volume\ngrowth at infinity. Moreover, we obtain that the boundary of the perimeter\nminimizing set is identified with a slice in the product structure of $M$.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T16:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.10416v1","title":"Region Based SLAM-Aware Exploration: Efficient and Robust Autonomous\n  Mapping Strategy That Can Scale","summary":"Autonomous exploration for mapping unknown large scale environments is a\nfundamental challenge in robotics, with efficiency in time, stability against\nmap corruption and computational resources being crucial. This paper presents a\nnovel approach to indoor exploration that addresses these key issues in\nexisting methods. We introduce a Simultaneous Localization and Mapping\n(SLAM)-aware region-based exploration strategy that partitions the environment\ninto discrete regions, allowing the robot to incrementally explore and\nstabilize each region before moving to the next one. This approach\nsignificantly reduces redundant exploration and improves overall efficiency. As\nthe device finishes exploring a region and stabilizes it, we also perform SLAM\nkeyframe marginalization, a technique which reduces problem complexity by\neliminating variables, while preserving their essential information. To\nimproves robustness and further enhance efficiency, we develop a check- point\nsystem that enables the robot to resume exploration from the last stable region\nin case of failures, eliminating the need for complete re-exploration. Our\nmethod, tested in real homes, office and simulations, outperforms\nstate-of-the-art approaches. The improvements demonstrate substantial\nenhancements in various real world environments, with significant reductions in\nkeyframe usage (85%), submap usage (50% office, 32% home), pose graph\noptimization time (78-80%), and exploration duration (10-15%). This\nregion-based strategy with keyframe marginalization offers an efficient\nsolution for autonomous robotic mapping.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T17:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.10430v1","title":"LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety\n  in Large Language Models","summary":"Recent advancements in Large Language Models (LLMs) have enabled them to\napproach human-level persuasion capabilities. However, such potential also\nraises concerns about the safety risks of LLM-driven persuasion, particularly\ntheir potential for unethical influence through manipulation, deception,\nexploitation of vulnerabilities, and many other harmful tactics. In this work,\nwe present a systematic investigation of LLM persuasion safety through two\ncritical aspects: (1) whether LLMs appropriately reject unethical persuasion\ntasks and avoid unethical strategies during execution, including cases where\nthe initial persuasion goal appears ethically neutral, and (2) how influencing\nfactors like personality traits and external pressures affect their behavior.\nTo this end, we introduce PersuSafety, the first comprehensive framework for\nthe assessment of persuasion safety which consists of three stages, i.e.,\npersuasion scene creation, persuasive conversation simulation, and persuasion\nsafety assessment. PersuSafety covers 6 diverse unethical persuasion topics and\n15 common unethical strategies. Through extensive experiments across 8 widely\nused LLMs, we observe significant safety concerns in most LLMs, including\nfailing to identify harmful persuasion tasks and leveraging various unethical\npersuasion strategies. Our study calls for more attention to improve safety\nalignment in progressive and goal-driven conversations such as persuasion.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.HC","published":"2025-04-14T17:20:34Z"}
{"aid":"http://arxiv.org/abs/2504.10450v1","title":"AC Current-Driven Magnetization Switching and Nonlinear Hall\n  Rectification in a Magnetic Topological Insulator","summary":"Spin-orbit torque arising from the spin-orbit-coupled surface states of\ntopological insulators enables current-induced control of magnetization with\nhigh efficiency. Here, alternating-current (AC) driven magnetization reversal\nis demonstrated in a semi-magnetic topological insulator\n(Cr,Bi,Sb)2Te3/(Bi,Sb)2Te3, facilitated by a low threshold current density of\n1.5x10^9 A/m^2. Time-domain Hall voltage measurements using an oscilloscope\nreveal a strongly nonlinear and nonreciprocal Hall response during the\nmagnetization reversal process. Fourier analysis of the time-varying Hall\nvoltage identifies higher-harmonic signals and a rectified direct-current (DC)\ncomponent, highlighting the complex interplay among the applied current,\nexternal magnetic field, and magnetization dynamics. Furthermore, a hysteretic\nbehavior in the current-voltage characteristics gives rise to frequency mixing\nunder dual-frequency excitation. This effect, distinct from conventional\npolynomial-based nonlinearities, allows for selective extraction of specific\nfrequency components. The results demonstrate that AC excitation can not only\nswitch magnetization efficiently but also induce tunable nonlinear responses,\noffering a new pathway for multifunctional spintronic devices with potential\napplications in energy-efficient memory, signal processing, and frequency\nconversion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-14T17:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.10455v1","title":"The stellar decomposition of Gaussian quantum states","summary":"We introduce the stellar decomposition, a novel method for characterizing\nnon-Gaussian states produced by photon-counting measurements on Gaussian\nstates. Given an (m+n)-mode Gaussian state G, we express it as an (m+n)-mode\n\"Gaussian core state\" G_core followed by a fixed m-mode Gaussian transformation\nT that only acts on the first m modes. The defining property of the Gaussian\ncore state G_core is that measuring the last n of its modes in the\nphoton-number basis leaves the first m modes on a finite Fock support, i.e. a\ncore state. Since T is measurement-independent and G_core has an exact and\nfinite Fock representation, this decomposition exactly describes all\nnon-Gaussian states obtainable by projecting n modes of G onto the Fock basis.\nFor pure states we prove that a physical pair (G_core, T) always exists with\nG_core pure and T unitary. For mixed states, we establish necessary and\nsufficient conditions for (G_core, T) to be a Gaussian mixed state and a\nGaussian channel. Finally, we develop a semidefinite program to extract the\n\"largest\" possible Gaussian channel when these conditions fail. The stellar\ndecomposition leads to practical bounds on achievable state quality in photonic\ncircuits and for GKP state generation in particular. Our results are based on a\nnew characterization of Gaussian completely positive maps in the Bargmann\npicture, which may be of independent interest. As a result, this work provides\nnovel tools for improved simulations of quantum optical systems, and for\nunderstanding the generation of non-Gaussian resource states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T17:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.10475v1","title":"Probing the Sivers Asymmetry with Transverse Energy-Energy Correlators\n  in the Small-$x$ Regime","summary":"We investigate transverse energy-energy correlators (TEECs) for both\npolarized and unpolarized targets in the small-$x$ regime at the Electron-Ion\nCollider (EIC). Focusing on the approximately back-to-back electroproduction of\na hadron-electron pair, we apply transverse-momentum-dependent (TMD)\nfactorization formulas that incorporate TMD evolution for both event-shape\nobservables and expand them in terms of the small-$x$ dipole amplitude. This\nallows us to write the TEEC off the transversely polarized proton in terms of a\nC-odd interaction, corresponding to an odderon exchange. Due to the\ncharge-conjugation-odd nature of the small-$x$ quark Sivers function, we\nrestrict the sum over final hadronic states to positively and negatively\ncharged hadrons separately. We present numerical predictions for the TEEC\nSivers asymmetry at the EIC and find the magnitude of the asymmetry to be on\nthe $0.1 \\%$ level. This channel offers a promising avenue for benchmarking the\nstill largely unconstrained odderon amplitude.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-14T17:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.10828v1","title":"Following Is All You Need: Robot Crowd Navigation Using People As\n  Planners","summary":"Navigating in crowded environments requires the robot to be equipped with\nhigh-level reasoning and planning techniques. Existing works focus on\ndeveloping complex and heavyweight planners while ignoring the role of human\nintelligence. Since humans are highly capable agents who are also widely\navailable in a crowd navigation setting, we propose an alternative scheme where\nthe robot utilises people as planners to benefit from their effective planning\ndecisions and social behaviours. Through a set of rule-based evaluations, we\nidentify suitable human leaders who exhibit the potential to guide the robot\ntowards its goal. Using a simple base planner, the robot follows the selected\nleader through shorthorizon subgoals that are designed to be straightforward to\nachieve. We demonstrate through both simulated and real-world experiments that\nour novel framework generates safe and efficient robot plans compared to\nexisting planners, even without predictive or data-driven modules. Our method\nalso brings human-like robot behaviours without explicitly defining traffic\nrules and social norms. Code will be available at\nhttps://github.com/centiLinda/PeopleAsPlanner.git.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T03:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.10833v1","title":"Towards Spatially-Aware and Optimally Faithful Concept-Based\n  Explanations","summary":"Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a\npromising tool for generating semantic explanations of the decision-making\nprocesses in deep neural networks, having applications in both model\nimprovement and understanding. It is vital that the explanation is accurate, or\nfaithful, to the model, yet we identify several limitations of prior\nfaithfulness metrics that inhibit an accurate evaluation; most notably, prior\nmetrics involve only the set of concepts present, ignoring how they may be\nspatially distributed. We address these limitations with Surrogate Faithfulness\n(SF), an evaluation method that introduces a spatially-aware surrogate and two\nnovel faithfulness metrics. Using SF, we produce Optimally Faithful (OF)\nexplanations, where concepts are found that maximize faithfulness. Our\nexperiments show that (1) adding spatial-awareness to prior U-CBEMs increases\nfaithfulness in all cases; (2) OF produces significantly more faithful\nexplanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's\nlearned concepts generalize well to out-of-domain data and are more robust to\nadversarial examples, where prior U-CBEMs struggle.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-15T03:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.10844v1","title":"Nonlinear Diffusion Equations on Graphs: Global Well-Posedness, Blow-Up\n  Analysis and Applications","summary":"For a nonlinear diffusion equation on graphs whose nonlinearity violates the\nLipschitz condition, we prove short-time solution existence and characterize\nglobal well-posedness by establishing sufficient criteria for blow-up phenomena\nand quantifying blow-up rates. These theoretical results are then applied to\nmodel complex dynamical networks, with supporting numerical experiments. This\nwork mainly makes two contributions: (i) generalization of existing results for\ndiffusion equations on graphs to cases with nontrivial potentials, producing\nricher analytical results; (ii) a new PDE approach to model complex dynamical\nnetworks, with preliminary numerical experiments confirming its validity.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T04:06:12Z"}
{"aid":"http://arxiv.org/abs/2504.10849v1","title":"Real-Time Word-Level Temporal Segmentation in Streaming Speech\n  Recognition","summary":"Rich-text captions are essential to help communication for Deaf and\nhard-of-hearing (DHH) people, second-language learners, and those with autism\nspectrum disorder (ASD). They also preserve nuances when converting speech to\ntext, enhancing the realism of presentation scripts and conversation or speech\nlogs. However, current real-time captioning systems lack the capability to\nalter text attributes (ex. capitalization, sizes, and fonts) at the word level,\nhindering the accurate conveyance of speaker intent that is expressed in the\ntones or intonations of the speech. For example, ''YOU should do this'' tends\nto be considered as indicating ''You'' as the focus of the sentence, whereas\n''You should do THIS'' tends to be ''This'' as the focus. This paper proposes a\nsolution that changes the text decorations at the word level in real time. As a\nprototype, we developed an application that adjusts word size based on the\nloudness of each spoken word. Feedback from users implies that this system\nhelped to convey the speaker's intent, offering a more engaging and accessible\ncaptioning experience.","main_category":"cs.HC","categories":"cs.HC,cs.MM,cs.SD,eess.AS","published":"2025-04-15T04:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.10857v1","title":"ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping","summary":"Robotic grasping is a cornerstone capability of embodied systems. Many\nmethods directly output grasps from partial information without modeling the\ngeometry of the scene, leading to suboptimal motion and even collisions. To\naddress these issues, we introduce ZeroGrasp, a novel framework that\nsimultaneously performs 3D reconstruction and grasp pose prediction in near\nreal-time. A key insight of our method is that occlusion reasoning and modeling\nthe spatial relationships between objects is beneficial for both accurate\nreconstruction and grasping. We couple our method with a novel large-scale\nsynthetic dataset, which comprises 1M photo-realistic images, high-resolution\n3D reconstructions and 11.3B physically-valid grasp pose annotations for 12K\nobjects from the Objaverse-LVIS dataset. We evaluate ZeroGrasp on the\nGraspNet-1B benchmark as well as through real-world robot experiments.\nZeroGrasp achieves state-of-the-art performance and generalizes to novel\nreal-world objects by leveraging synthetic data.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-15T04:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.10888v1","title":"CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal\n  Visible-Infrared Detectors","summary":"Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T05:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.10920v1","title":"Towards Efficient Partially Relevant Video Retrieval with Active Moment\n  Discovering","summary":"Partially relevant video retrieval (PRVR) is a practical yet challenging task\nin text-to-video retrieval, where videos are untrimmed and contain much\nbackground content. The pursuit here is of both effective and efficient\nsolutions to capture the partial correspondence between text queries and\nuntrimmed videos. Existing PRVR methods, which typically focus on modeling\nmulti-scale clip representations, however, suffer from content independence and\ninformation redundancy, impairing retrieval performance. To overcome these\nlimitations, we propose a simple yet effective approach with active moment\ndiscovering (AMDNet). We are committed to discovering video moments that are\nsemantically consistent with their queries. By using learnable span anchors to\ncapture distinct moments and applying masked multi-moment attention to\nemphasize salient moments while suppressing redundant backgrounds, we achieve\nmore compact and informative video representations. To further enhance moment\nmodeling, we introduce a moment diversity loss to encourage different moments\nof distinct regions and a moment relevance loss to promote semantically\nquery-relevant moments, which cooperate with a partially relevant retrieval\nloss for end-to-end optimization. Extensive experiments on two large-scale\nvideo datasets (\\ie, TVR and ActivityNet Captions) demonstrate the superiority\nand efficiency of our AMDNet. In particular, AMDNet is about 15.5 times smaller\n(\\#parameters) while 6.0 points higher (SumR) than the up-to-date method\nGMMFormer on TVR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T07:00:18Z"}
{"aid":"http://arxiv.org/abs/2504.10938v1","title":"Iterative Linear Quadratic Regulator for Quantum Optimal Control","summary":"Quantum optimal control for gate optimization aims to provide accurate,\nrobust, and fast pulse sequences to achieve gate fidelities on quantum systems\nbelow the error correction threshold. Many methods have been developed and\nsuccessfully applied in simulation and on quantum hardware. In this paper, we\nestablish a connection between the iterative linear quadratic regulator and\nquantum optimal control by adapting it to gate optimization of quantum systems.\nWe include constraints on the controls and their derivatives to enable smoother\npulses. We achieve high-fidelity simulation results for X and cross-resonance\ngates on one- and two-qubit fixed-frequency transmons simulated with two and\nthree levels.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T07:36:32Z"}
{"aid":"http://arxiv.org/abs/2504.10975v1","title":"Simplicial volume of open books in dimension 4","summary":"In this short note we adapt a proof by Bucher and Neofytidis to prove that\nthe simplicial volume of 4-manifolds admitting an open book decomposition\nvanishes. In particular this shows that Quinns signature invariant, which\ndetects the existence of an open book decomposition in dimensions above 4, is\ninsufficient to characterize open books in dimension 4, even if one allows\narbitrary stabilizations via connected sums.","main_category":"math.GT","categories":"math.GT,math.AT","published":"2025-04-15T08:36:54Z"}
{"aid":"http://arxiv.org/abs/2504.10976v1","title":"Adaptive Decision Boundary for Few-Shot Class-Incremental Learning","summary":"Few-Shot Class-Incremental Learning (FSCIL) aims to continuously learn new\nclasses from a limited set of training samples without forgetting knowledge of\npreviously learned classes. Conventional FSCIL methods typically build a robust\nfeature extractor during the base training session with abundant training\nsamples and subsequently freeze this extractor, only fine-tuning the classifier\nin subsequent incremental phases. However, current strategies primarily focus\non preventing catastrophic forgetting, considering only the relationship\nbetween novel and base classes, without paying attention to the specific\ndecision spaces of each class. To address this challenge, we propose a\nplug-and-play Adaptive Decision Boundary Strategy (ADBS), which is compatible\nwith most FSCIL methods. Specifically, we assign a specific decision boundary\nto each class and adaptively adjust these boundaries during training to\noptimally refine the decision spaces for the classes in each session.\nFurthermore, to amplify the distinctiveness between classes, we employ a novel\ninter-class constraint loss that optimizes the decision boundaries and\nprototypes for each class. Extensive experiments on three benchmarks, namely\nCIFAR100, miniImageNet, and CUB200, demonstrate that incorporating our ADBS\nmethod with existing FSCIL techniques significantly improves performance,\nachieving overall state-of-the-art results.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:37:24Z"}
{"aid":"http://arxiv.org/abs/2504.10983v1","title":"ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed\n  Protein Language Model Embeddings","summary":"The design of protein sequences with desired functionalities is a fundamental\ntask in protein engineering. Deep generative methods, such as autoregressive\nmodels and diffusion models, have greatly accelerated the discovery of novel\nprotein sequences. However, these methods mainly focus on local or shallow\nresidual semantics and suffer from low inference efficiency, large modeling\nspace and high training cost. To address these challenges, we introduce\nProtFlow, a fast flow matching-based protein sequence design framework that\noperates on embeddings derived from semantically meaningful latent space of\nprotein language models. By compressing and smoothing the latent space,\nProtFlow enhances performance while training on limited computational\nresources. Leveraging reflow techniques, ProtFlow enables high-quality\nsingle-step sequence generation. Additionally, we develop a joint design\npipeline for the design scene of multichain proteins. We evaluate ProtFlow\nacross diverse protein design tasks, including general peptides and long-chain\nproteins, antimicrobial peptides, and antibodies. Experimental results\ndemonstrate that ProtFlow outperforms task-specific methods in these\napplications, underscoring its potential and broad applicability in\ncomputational protein sequence design and analysis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.BM","published":"2025-04-15T08:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.11043v1","title":"Riemannian optimization for model order reduction of linear systems with\n  quadratic outputs","summary":"This paper investigates the optimal $H_2$ model order reduction for linear\nsystems with quadratic outputs. In the framework of Galerkin projection, we\nfirst formulate the optimal $H_2$ MOR as an unconstrained Riemannian\noptimization problem on the Stiefel manifold. The Riemannian gradient of the\nspecific cost function is derived with the aid of Gramians of systems, and the\nDai-Yuan-type Riemannian conjugate gradient method is adopted to generate\nstructure-preserving reduced models. We also consider the optimal $H_2$ MOR\nbased on the product manifold, where some coefficient matrices of reduced\nmodels are determined directly via the iteration of optimization problem,\ninstead of the Galerkin projection method. In addition, we provide a scheme to\ncompute low-rank approximate solutions of Sylvester equations based on the\ntruncated polynomial expansions, which fully exploits the specific structure of\nSylvester equations in the optimization problems, and enables an efficient\nexecution of our approach. Finally, two numerical examples are simulated to\ndemonstrate the efficiency of our methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T10:09:28Z"}
{"aid":"http://arxiv.org/abs/2504.11071v1","title":"Avoshifts, Unishifts and Nondeterministic Cellular Automata","summary":"In this paper, we study avoshifts and unishifts on $\\mathbb{Z}^d$. Avoshifts\nare subshifts where for each convex set $C$, and each vector $v$ such that $C\n\\cup \\{\\vec v\\}$ is also convex, the set of valid extensions of globally valid\npatterns on $C$ to ones on $C \\cup \\{v\\}$ is determined by a bounded subpattern\nof $C$. Unishifts are the subshifts where for such $C, \\vec v$, every\n$C$-pattern has the same number of $\\vec v$-extensions. Cellwise quasigroup\nshifts (including group shifts) and TEP subshifts are examples of unishifts,\nwhile unishifts and subshifts with topological strong spatial mixing are\nexamples of avoshifts. We prove that every avoshift is the spacetime subshift\nof a nondeterministic cellular automaton on an avoshift of lower dimension up\nto a linear transformation and a convex blocking. From this, we deduce that all\navoshifts contain periodic points, and that unishifts have dense periodic\npoints and admit equal entropy full shift factors.","main_category":"math.DS","categories":"math.DS,math.CO","published":"2025-04-15T11:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.11094v1","title":"Evaluation Report on MCP Servers","summary":"With the rise of LLMs, a large number of Model Context Protocol (MCP)\nservices have emerged since the end of 2024. However, the effectiveness and\nefficiency of MCP servers have not been well studied. To study these questions,\nwe propose an evaluation framework, called MCPBench. We selected several widely\nused MCP server and conducted an experimental evaluation on their accuracy,\ntime, and token usage. Our experiments showed that the most effective MCP, Bing\nWeb Search, achieved an accuracy of 64%. Importantly, we found that the\naccuracy of MCP servers can be substantially enhanced by involving declarative\ninterface. This research paves the way for further investigations into\noptimized MCP implementations, ultimately leading to better AI-driven\napplications and data retrieval solutions.","main_category":"cs.IR","categories":"cs.IR,cs.DB","published":"2025-04-15T11:40:12Z"}
{"aid":"http://arxiv.org/abs/2504.11115v1","title":"Transient random walks on the space of lattices","summary":"Given $d\\geq2$, we construct a Zariski-dense random walk on the space of\nlattices SL$_d(\\mathbb{R})/$SL$_d(\\mathbb{Z})$ that exhibits escape of mass.\nThis negates the suggestion of recurrence made by Benoist [Ben14] (ICM 2014)\nand by B\\'enard-de Saxc\\'e [BS22] (also asked in [BQ12]). For any $p \\in\n(0,1)$, we also construct such a random walk with finite $L^p$-moment which\nshows that the moment assumption in [BS22] is sharp.","main_category":"math.PR","categories":"math.PR,math.DS","published":"2025-04-15T12:02:29Z"}
{"aid":"http://arxiv.org/abs/2504.11134v1","title":"Visual Re-Ranking with Non-Visual Side Information","summary":"The standard approach for visual place recognition is to use global image\ndescriptors to retrieve the most similar database images for a given query\nimage. The results can then be further improved with re-ranking methods that\nre-order the top scoring images. However, existing methods focus on re-ranking\nbased on the same image descriptors that were used for the initial retrieval,\nwhich we argue provides limited additional signal.\n  In this work we propose Generalized Contextual Similarity Aggregation (GCSA),\nwhich is a graph neural network-based re-ranking method that, in addition to\nthe visual descriptors, can leverage other types of available side information.\nThis can for example be other sensor data (such as signal strength of nearby\nWiFi or BlueTooth endpoints) or geometric properties such as camera poses for\ndatabase images. In many applications this information is already present or\ncan be acquired with low effort. Our architecture leverages the concept of\naffinity vectors to allow for a shared encoding of the heterogeneous\nmulti-modal input. Two large-scale datasets, covering both outdoor and indoor\nlocalization scenarios, are utilized for training and evaluation. In\nexperiments we show significant improvement not only on image retrieval\nmetrics, but also for the downstream visual localization task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T12:37:16Z"}
{"aid":"http://arxiv.org/abs/2504.11142v1","title":"On the dimension of the boundaries of attracting basins of entire maps","summary":"We study the dimension of the boundaries of periodic Fatou components of\ntranscendental entire maps. We prove that if $U$ is an immediate component of\nthe basin of an attracting periodic point $\\zeta$ of period $p\\ge 1$ of a\ntranscendental entire function $f\\colon \\mathbb C \\to \\mathbb C$ from the\nEremenko--Lyubich class $\\mathcal B$, such that $\\text{deg} f^p|_U = \\infty$\nand $\\overline{\\text{Sing}(f^p|_U)}$ is a compact subset of $U$, then the\nhyperbolic (and, consequently, Hausdorff) dimension of the boundary of $U$ is\nlarger than $1$. The same holds if $U$ is an immediate component of the basin\nof a parabolic $p$-periodic point $\\zeta$, under an additional assumption\n$\\zeta \\notin \\overline{\\text{Sing}(f^p)}$. We also show that if $U$ is a\nbounded immediate component of an attracting basin of a transcendental entire\nfunction $f$, then the hyperbolic dimension of the boundary of $U$ is larger\nthan $1$. In particular, this implies that the boundary of a component of an\nattracting basin of a transcendental entire function is never a smooth or\nrectifiable curve.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T12:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.11149v1","title":"An Application of Membrane Computing to Humanitarian Relief via\n  Generalized Nash Equilibrium","summary":"Natural and political disasters, including earthquakes, hurricanes, and\ntsunamis, but also migration and refugees crisis, need quick and coordinated\nresponses in order to support vulnerable populations. In such disasters,\nnongovernmental organizations compete with each other for financial donations,\nwhile people who need assistance suffer a lack of coordination, congestion in\nterms of logistics, and duplication of services. From a theoretical point of\nview, this problem can be formalized as a Generalized Nash Equilibrium (GNE)\nproblem. This is a generalization of the Nash equilibrium problem, where the\nagents' strategies are not fixed but depend on the other agents' strategies. In\nthis paper, we show that Membrane Computing can model humanitarian relief as a\nGNE problem. We propose a family of P systems that compute GNE in this context,\nand we illustrate their capabilities with Hurricane Katrina in 2005 as a case\nstudy.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-15T12:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.11164v1","title":"TSAL: Few-shot Text Segmentation Based on Attribute Learning","summary":"Recently supervised learning rapidly develops in scene text segmentation.\nHowever, the lack of high-quality datasets and the high cost of pixel\nannotation greatly limit the development of them. Considering the\nwell-performed few-shot learning methods for downstream tasks, we investigate\nthe application of the few-shot learning method to scene text segmentation. We\npropose TSAL, which leverages CLIP's prior knowledge to learn text attributes\nfor segmentation. To fully utilize the semantic and texture information in the\nimage, a visual-guided branch is proposed to separately extract text and\nbackground features. To reduce data dependency and improve text detection\naccuracy, the adaptive prompt-guided branch employs effective adaptive prompt\ntemplates to capture various text attributes. To enable adaptive prompts\ncapture distinctive text features and complex background distribution, we\npropose Adaptive Feature Alignment module(AFA). By aligning learnable tokens of\ndifferent attributes with visual features and prompt prototypes, AFA enables\nadaptive prompts to capture both general and distinctive attribute information.\nTSAL can capture the unique attributes of text and achieve precise segmentation\nusing only few images. Experiments demonstrate that our method achieves SOTA\nperformance on multiple text segmentation datasets under few-shot settings and\nshow great potential in text-related domains.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.11171v1","title":"TerraMind: Large-Scale Generative Multimodality for Earth Observation","summary":"We present TerraMind, the first any-to-any generative, multimodal foundation\nmodel for Earth observation (EO). Unlike other multimodal models, TerraMind is\npretrained on dual-scale representations combining both token-level and\npixel-level data across modalities. On a token level, TerraMind encodes\nhigh-level contextual information to learn cross-modal relationships, while on\na pixel level, TerraMind leverages fine-grained representations to capture\ncritical spatial nuances. We pretrained TerraMind on nine geospatial modalities\nof a global, large-scale dataset. In this paper, we demonstrate that (i)\nTerraMind's dual-scale early fusion approach unlocks a range of zero-shot and\nfew-shot applications for Earth observation, (ii) TerraMind introduces\n\"Thinking-in-Modalities\" (TiM) -- the capability of generating additional\nartificial data during finetuning and inference to improve the model output --\nand (iii) TerraMind achieves beyond state-of-the-art performance in\ncommunity-standard benchmarks for EO like PANGAEA. The pretraining dataset, the\nmodel weights, and our code is open-sourced under a permissive license.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T13:17:39Z"}
{"aid":"http://arxiv.org/abs/2504.11177v1","title":"Pressure-Tunable Generalized Wigner Crystal and Fractional Chern\n  Insulator in twisted MoTe$_2$","summary":"Due to the forming of low-energy flat bands, the moir\\'e superlattices of the\ntransition metal dichalcogenides are fascinating platforms for studying novel\ncorrelated states when such flat bands are fractionally filled, with the\nCoulomb interaction dominating. Here, we demonstrate that pressure can\nefficiently tune the flatness and quantum geometry of the single-particle bands\nin twisted bilayer MoTe$_2$ ($\\textit{t}$MoTe$_2$). By fractionally filling the\ntopmost valence band, we find that pressure can act as a flexible means to\nmodulate the fractional Chern insulator (FCI) and the generalized Wigner\ncrystal (GWC) and control their many-body topological phase transitions.\nMoreover, our results indicate a remarkable correspondence between the\nsingle-particle band geometry and the formation of FCI and GWC. As the recent\nexperiments report the presence of FCI phases in $\\textit{t}$MoTe$_2$, our\npredictions could be readily implemented experimentally.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T13:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.11192v1","title":"Field-effect detected magnetic resonance of NV centers in diamond based\n  on all-carbon Schottky contacts","summary":"The nitrogen vacancy (NV) center is a defect in diamond whose spin state can\nbe read optically by exploiting its photoluminescence or electrically by\nexploiting its charge generation rate under illumination, both of which being\nspin-dependent. The latter method offers numerous opportunities in terms of\nintegration and performance compared to conventional optical reading. Here, we\ninvestigate the physical properties of a graphitic-diamond-graphitic structure\nunder illumination. We show how, for a type IIa diamond material, electron-hole\npairs generated by an ensemble of NV centers lead to a p-type material upon\nillumination, making this all-carbon structure equivalent to two back-to-back\nSchottky diodes. We analyze how the reverse current flowing upon illumination\nchanges as a function of bias voltage and radiofrequency-induced excitation of\nthe NV ensemble spin resonances. Furthermore, we demonstrate how an additional\nfield effect arising from the illumination scheme affects the reverse current,\nresulting in a photoelectrical signal that can exceed the optical signal under\nthe same illumination conditions.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-15T13:48:49Z"}
{"aid":"http://arxiv.org/abs/2504.11204v1","title":"BenchQC -- Scalable and modular benchmarking of industrial quantum\n  computing applications","summary":"We present BenchQC, a research project funded by the state of Bavaria, which\npromotes an application-centric perspective for benchmarking real-world quantum\napplications. Diverse use cases from industry consortium members are the\nstarting point of a benchmarking workflow, that builds on the open-source\nplatform QUARK, encompassing the full quantum software stack from the hardware\nprovider interface to the application layer. By identifying and evaluating key\nmetrics across the entire pipeline, we aim to uncover meaningful trends,\nprovide systematic guidance on quantum utility, and distinguish promising\nresearch directions from less viable approaches. Ultimately, this initiative\ncontributes to the broader effort of establishing reliable benchmarking\nstandards that drive the transition from experimental demonstrations to\npractical quantum advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T14:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.11220v1","title":"Test of lepton flavor universality with measurements of $R(D^{+})$ and\n  $R(D^{*+})$ using semileptonic $B$ tagging at the Belle II experiment","summary":"We report measurements of the ratios of branching fractions\n$\\mathcal{R}(D^{(*)+}) = \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\,\\tau^- \\,\n\\overline{\\nu}_\\tau) / \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\, \\ell^- \\,\n\\overline{\\nu}_\\ell)$, where $\\ell$ denotes either an electron or a muon. These\nratios test the universality of the charged-current weak interaction. The\nresults are based on a $365\\, \\mathrm{fb}^{-1}$ data sample collected with the\nBelle II detector at the SuperKEKB $e^+e^-$ collider, which operates at a\ncenter-of-mass energy corresponding to the $\\Upsilon(4S)$ resonance, just above\nthe threshold for $B\\overline{B}{}$ production. Signal candidates are\nreconstructed by selecting events in which the companion $B$ meson from the\n$\\Upsilon(4S) \\to B\\overline{B}{}$ decay is identified in semileptonic modes.\nThe $\\tau$ lepton is reconstructed via its leptonic decays. We obtain\n$\\mathcal{R}(D^+) = 0.418 \\pm 0.074 ~({\\mathrm{stat}}) \\pm 0.051\n~({\\mathrm{syst}})$ and $\\mathcal{R}(D^{*+}) = 0.306 \\pm 0.034\n~({\\mathrm{stat}}) \\pm 0.018 ~({\\mathrm{syst}})$, which are consistent with\nworld average values. Accounting for the correlation between them, these values\ndiffer from the Standard Model expectation by a collective significance of\n$1.7$ standard deviations.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-15T14:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.11241v1","title":"Physics-Aware Initialization Refinement in Code-Aided EM for Blind\n  Channel Estimation","summary":"This paper addresses the well-known local maximum problem of the\nexpectation-maximization (EM) algorithm in blind intersymbol interference (ISI)\nchannel estimation. This problem primarily results from phase and shift\nambiguity during initialization, which blind estimation is inherently unable to\ndistinguish. We propose an effective initialization refinement algorithm that\nutilizes the decoder output as a model selection metric, incorporating a\ntechnique to detect phase and shift ambiguity. Our results show that the\nproposed algorithm significantly reduces the number of local maximum cases to\nnearly one-third for a 3-tap ISI channel under highly uncertain initial\nconditions. The improvement becomes more pronounced as initial errors increase\nand the channel memory grows. When used in a turbo equalizer, the proposed\nalgorithm is required only in the first turbo iteration, which limits any\ncomplexity increase with subsequent iterations.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T14:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.11267v1","title":"Optimal control of geometric phase in pairs of interacting atoms\n  traveling along two-dimensional closed paths","summary":"Universal quantum gates whose operation depends on the manipulation of the\ngeometric phase of atomic systems are promising candidates for implementation\nof quantum computing. We propose a scheme inducing a non-trivial\nAharonov-Anandan geometric phase in pairs of atoms interacting via\ndipole-dipole potential. Our protocol relies on mobile optical trap technology\nand consists of steering a single atom along a closed loop. The trajectory of\nthe atom is controlled by a mobile optical trap, and the shape of the path is\ndesigned by applying an optimal control procedure. The geometric phase is\ngenerated as a residual of the two-atom entanglement induced by the\ndipole-dipole interaction. The stability of our scheme in the presence of noise\nor experimental imperfections is discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:06:40Z"}
{"aid":"http://arxiv.org/abs/2504.11268v1","title":"Single-Input Multi-Output Model Merging: Leveraging Foundation Models\n  for Dense Multi-Task Learning","summary":"Model merging is a flexible and computationally tractable approach to merge\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\non constrained multi-task settings where there is a one-to-one mapping between\na sample and a task, overlooking the paradigm where multiple tasks may operate\non the same sample, e.g., scene understanding. In this paper, we focus on the\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\nqualitatively differs from the single-input-single-output model merging\nsettings studied in the literature due to the existence of task-specific\ndecoders and diverse loss objectives. We identify that existing model merging\nmethods lead to significant performance degradation, primarily due to\nrepresentation misalignment between the merged encoder and task-specific\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\nre-align the feature representation after merging. Compared to joint\nfine-tuning, our approach is computationally effective and flexible, and sheds\nlight into identifying task relationships in an offline manner. Experiments on\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\narithmetic suffices to enable multi-task capabilities; however, the\nrepresentations generated by the merged encoder has to be re-aligned with the\ntask-specific heads; (2) the proposed architecture rivals traditional\nmulti-task learning in performance but requires fewer samples and training\nsteps by leveraging the existence of task-specific models.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T15:10:46Z"}
{"aid":"http://arxiv.org/abs/2504.11286v1","title":"Efficient Medical Image Restoration via Reliability Guided Learning in\n  Frequency Domain","summary":"Medical image restoration tasks aim to recover high-quality images from\ndegraded observations, exhibiting emergent desires in many clinical scenarios,\nsuch as low-dose CT image denoising, MRI super-resolution, and MRI artifact\nremoval. Despite the success achieved by existing deep learning-based\nrestoration methods with sophisticated modules, they struggle with rendering\ncomputationally-efficient reconstruction results. Moreover, they usually ignore\nthe reliability of the restoration results, which is much more urgent in\nmedical systems. To alleviate these issues, we present LRformer, a Lightweight\nTransformer-based method via Reliability-guided learning in the frequency\ndomain. Specifically, inspired by the uncertainty quantification in Bayesian\nneural networks (BNNs), we develop a Reliable Lesion-Semantic Prior Producer\n(RLPP). RLPP leverages Monte Carlo (MC) estimators with stochastic sampling\noperations to generate sufficiently-reliable priors by performing multiple\ninferences on the foundational medical image segmentation model, MedSAM.\nAdditionally, instead of directly incorporating the priors in the spatial\ndomain, we decompose the cross-attention (CA) mechanism into real symmetric and\nimaginary anti-symmetric parts via fast Fourier transform (FFT), resulting in\nthe design of the Guided Frequency Cross-Attention (GFCA) solver. By leveraging\nthe conjugated symmetric property of FFT, GFCA reduces the computational\ncomplexity of naive CA by nearly half. Extensive experimental results in\nvarious tasks demonstrate the superiority of the proposed LRformer in both\neffectiveness and efficiency.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-15T15:26:28Z"}
{"aid":"http://arxiv.org/abs/2504.11291v1","title":"Policy heterogeneity improves collective olfactory search in 3-D\n  turbulence","summary":"We investigate the role of policy heterogeneity in enhancing the olfactory\nsearch capabilities of cooperative agent swarms operating in complex,\nreal-world turbulent environments. Using odor fields from direct numerical\nsimulations of the Navier-Stokes equations, we demonstrate that heterogeneous\ngroups, with exploratory and exploitative agents, consistently outperform\nhomogeneous swarms where the exploration-exploitation tradeoff is managed at\nthe individual level. Our results reveal that policy diversity enables the\ngroup to reach the odor source more efficiently by mitigating the detrimental\neffects of spatial correlations in the signal. These findings provide new\ninsights into collective search behavior in biological systems and offer\npromising strategies for the design of robust, bioinspired search algorithms in\nengineered systems.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph,physics.data-an","published":"2025-04-15T15:31:11Z"}
{"aid":"http://arxiv.org/abs/2504.11294v1","title":"Transforming Resonance Fluorescence into Maximally Entangled Photon\n  Pairs Using Minimal Resources","summary":"Entanglement is a fundamental concept in quantum mechanics, describing two or\nmore quantum systems that exhibit strong correlations beyond the classical\nlimits at the expense of losing their individual properties. More recently, it\nhas become a cornerstone of quantum technologies, promising revolutionary\nadvancements in fields like quantum communication, sensing, and computation.\nFor these reasons, the generation of technologically useful entangled states is\nkey to progress in these fields. Here, we experimentally demonstrate that\nresonance fluorescence from a weakly coupled two-level emitter can be\ntransformed, using beam splitters, delay lines, and post-selection only, into a\nstream of pairs of photons that are maximally entangled in the time-bin basis.\nWe verify the entanglement via a CHSH-type Bell inequality test, yielding an\nS-parameter of 2.80 \\pm 0.19, i.e., a clear 4{\\sigma} violation of the\nclassical bound. Our results pave the way for realising efficient sources of\nbandwidth-limited time-bin entangled photon pairs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.11301v1","title":"Learning to Be A Doctor: Searching for Effective Medical Agent\n  Architectures","summary":"Large Language Model (LLM)-based agents have demonstrated strong capabilities\nacross a wide range of tasks, and their application in the medical domain holds\nparticular promise due to the demand for high generalizability and reliance on\ninterdisciplinary knowledge. However, existing medical agent systems often rely\non static, manually crafted workflows that lack the flexibility to accommodate\ndiverse diagnostic requirements and adapt to emerging clinical scenarios.\nMotivated by the success of automated machine learning (AutoML), this paper\nintroduces a novel framework for the automated design of medical agent\narchitectures. Specifically, we define a hierarchical and expressive agent\nsearch space that enables dynamic workflow adaptation through structured\nmodifications at the node, structural, and framework levels. Our framework\nconceptualizes medical agents as graph-based architectures composed of diverse,\nfunctional node types and supports iterative self-improvement guided by\ndiagnostic feedback. Experimental results on skin disease diagnosis tasks\ndemonstrate that the proposed method effectively evolves workflow structures\nand significantly enhances diagnostic accuracy over time. This work represents\nthe first fully automated framework for medical agent architecture design and\noffers a scalable, adaptable foundation for deploying intelligent agents in\nreal-world clinical environments.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T15:44:21Z"}
{"aid":"http://arxiv.org/abs/2504.11304v1","title":"Differentially Private Geodesic and Linear Regression","summary":"In statistical applications it has become increasingly common to encounter\ndata structures that live on non-linear spaces such as manifolds. Classical\nlinear regression, one of the most fundamental methodologies of statistical\nlearning, captures the relationship between an independent variable and a\nresponse variable which both are assumed to live in Euclidean space. Thus,\ngeodesic regression emerged as an extension where the response variable lives\non a Riemannian manifold. The parameters of geodesic regression, as with linear\nregression, capture the relationship of sensitive data and hence one should\nconsider the privacy protection practices of said parameters. We consider\nreleasing Differentially Private (DP) parameters of geodesic regression via the\nK-Norm Gradient (KNG) mechanism for Riemannian manifolds. We derive theoretical\nbounds for the sensitivity of the parameters showing they are tied to their\nrespective Jacobi fields and hence the curvature of the space. This\ncorroborates recent findings of differential privacy for the Fr\\'echet mean. We\ndemonstrate the efficacy of our methodology on the sphere,\n$\\mbS^2\\subset\\mbR^3$ and, since it is general to Riemannian manifolds, the\nmanifold of Euclidean space which simplifies geodesic regression to a case of\nlinear regression. Our methodology is general to any Riemannian manifold and\nthus it is suitable for data in domains such as medical imaging and computer\nvision.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-15T15:45:48Z"}
{"aid":"http://arxiv.org/abs/2504.11336v1","title":"Looking beyond the next token","summary":"The structure of causal language model training assumes that each token can\nbe accurately predicted from the previous context. This contrasts with humans'\nnatural writing and reasoning process, where goals are typically known before\nthe exact argument or phrasings. While this mismatch has been well studied in\nthe literature, the working assumption has been that architectural changes are\nneeded to address this mismatch. We argue that rearranging and processing the\ntraining data sequences can allow models to more accurately imitate the true\ndata-generating process, and does not require any other changes to the\narchitecture or training infrastructure. We demonstrate that this technique,\nTrelawney, and the inference algorithms derived from it allow us to improve\nperformance on several key benchmarks that span planning, algorithmic\nreasoning, and story generation tasks. Finally, our method naturally enables\nthe generation of long-term goals at no additional cost. We investigate how\nusing the model's goal-generation capability can further improve planning and\nreasoning. Additionally, we believe Trelawney could potentially open doors to\nnew capabilities beyond the current language modeling paradigm.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-15T16:09:06Z"}
{"aid":"http://arxiv.org/abs/2504.11387v1","title":"On the distribution of the telegraph meander and its properties","summary":"In this paper we present the distribution of the telegraph meander, a random\nfunction obtained by conditioning the telegraph process to stay above the zero\nlevel. The reflection principle for finite-velocity random motions allows the\nlaw of the telegraph meander to be expressed in terms of the spatial derivative\nof the law of the telegraph process with initial negative velocity. As a\nresult, we are able to obtain the characteristic function, the moments and the\nhyperbolic equation that governs the law of the telegraph meander. Furthermore,\nwe prove that Brownian meander is the weak limit of the telegraph meander.","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T16:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.11754v1","title":"GrabS: Generative Embodied Agent for 3D Object Segmentation without\n  Scene Supervision","summary":"We study the hard problem of 3D object segmentation in complex point clouds\nwithout requiring human labels of 3D scenes for supervision. By relying on the\nsimilarity of pretrained 2D features or external signals such as motion to\ngroup 3D points as objects, existing unsupervised methods are usually limited\nto identifying simple objects like cars or their segmented objects are often\ninferior due to the lack of objectness in pretrained features. In this paper,\nwe propose a new two-stage pipeline called GrabS. The core concept of our\nmethod is to learn generative and discriminative object-centric priors as a\nfoundation from object datasets in the first stage, and then design an embodied\nagent to learn to discover multiple objects by querying against the pretrained\ngenerative priors in the second stage. We extensively evaluate our method on\ntwo real-world datasets and a newly created synthetic dataset, demonstrating\nremarkable segmentation performance, clearly surpassing all existing\nunsupervised methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.RO","published":"2025-04-16T04:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.11761v1","title":"Delayed Acceptance Markov Chain Monte Carlo for Robust Bayesian Analysis","summary":"This study introduces a computationally efficient algorithm, delayed\nacceptance Markov chain Monte Carlo (DA-MCMC), designed to improve posterior\nsimulation in quasi-Bayesian inference. Quasi-Bayesian methods, which do not\nrequire fully specifying a probabilistic model, are often computationally\nexpensive owing to the need to evaluate the inverse and determinant of large\ncovariance matrices. DA-MCMC addresses this challenge by employing a two-stage\nprocess: In the first stage, proposals are screened using an approximate\nposterior, whereas a final acceptance or rejection decision is made in the\nsecond stage based on the exact target posterior. This reduces the need for\ncostly matrix computations, thereby improving efficiency without sacrificing\naccuracy. We demonstrate the effectiveness of DA-MCMC through applications to\nboth synthetic and real data. The results demonstrate that, although DA-MCMC\nslightly reduces the effective sample size per iteration compared with the\nstandard MCMC, it achieves substantial improvement in terms of effective sample\nsize per second, approximately doubling the efficiency. This makes DA-MCMC\nparticularly useful for cases where posterior simulation is computationally\nintensive. Thus, the DA-MCMC algorithm offers a significant advancement in\ncomputational efficiency for quasi-Bayesian inference, making it a valuable\ntool for robust Bayesian analysis.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-16T04:40:17Z"}
{"aid":"http://arxiv.org/abs/2504.11772v1","title":"Admissible subcategories and metric techniques","summary":"In this work, we provide a way of constructing new semiorthogonal\ndecompositions using metric techniques (\\`a la Neeman). Given a semiorthogonal\ndecomposition on a category with a special kind of metric, which we call a\ncompressible metric, we can construct new semiorthogonal decomposition on a\ncategory constructed from the given one using the aforementioned metric. In the\nalgebro-geometric setting, this gives us a way of producing new semiorthogonal\ndecompositions on various small triangulated categories associated to a scheme,\nif we are given one. In the general setting, the work is related to that of\nSun-Zhang, while its applications to algebraic geometry are related to the work\nof Bondarko and Kuznetsov-Shinder.","main_category":"math.AG","categories":"math.AG,math.CT","published":"2025-04-16T05:24:55Z"}
{"aid":"http://arxiv.org/abs/2504.11786v1","title":"DART: Disease-aware Image-Text Alignment and Self-correcting\n  Re-alignment for Trustworthy Radiology Report Generation","summary":"The automatic generation of radiology reports has emerged as a promising\nsolution to reduce a time-consuming task and accurately capture critical\ndisease-relevant findings in X-ray images. Previous approaches for radiology\nreport generation have shown impressive performance. However, there remains\nsignificant potential to improve accuracy by ensuring that retrieved reports\ncontain disease-relevant findings similar to those in the X-ray images and by\nrefining generated reports. In this study, we propose a Disease-aware\nimage-text Alignment and self-correcting Re-alignment for Trustworthy radiology\nreport generation (DART) framework. In the first stage, we generate initial\nreports based on image-to-text retrieval with disease-matching, embedding both\nimages and texts in a shared embedding space through contrastive learning. This\napproach ensures the retrieval of reports with similar disease-relevant\nfindings that closely align with the input X-ray images. In the second stage,\nwe further enhance the initial reports by introducing a self-correction module\nthat re-aligns them with the X-ray images. Our proposed framework achieves\nstate-of-the-art results on two widely used benchmarks, surpassing previous\napproaches in both report generation and clinical efficacy metrics, thereby\nenhancing the trustworthiness of radiology reports.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:39:08Z"}
{"aid":"http://arxiv.org/abs/2504.11808v1","title":"Federated Spectral Graph Transformers Meet Neural Ordinary Differential\n  Equations for Non-IID Graphs","summary":"Graph Neural Network (GNN) research is rapidly advancing due to GNNs'\ncapacity to learn distributed representations from graph-structured data.\nHowever, centralizing large volumes of real-world graph data for GNN training\nis often impractical due to privacy concerns, regulatory restrictions, and\ncommercial competition. Federated learning (FL), a distributed learning\nparadigm, offers a solution by preserving data privacy with collaborative model\ntraining. Despite progress in training huge vision and language models,\nfederated learning for GNNs remains underexplored. To address this challenge,\nwe present a novel method for federated learning on GNNs based on spectral GNNs\nequipped with neural ordinary differential equations (ODE) for better\ninformation capture, showing promising results across both homophilic and\nheterophilic graphs. Our approach effectively handles non-Independent and\nIdentically Distributed (non-IID) data, while also achieving performance\ncomparable to existing methods that only operate on IID data. It is designed to\nbe privacy-preserving and bandwidth-optimized, making it suitable for\nreal-world applications such as social network analysis, recommendation\nsystems, and fraud detection, which often involve complex, non-IID, and\nheterophilic graph structures. Our results in the area of federated learning on\nnon-IID heterophilic graphs demonstrate significant improvements, while also\nachieving better performance on homophilic graphs. This work highlights the\npotential of federated learning in diverse and challenging graph settings.\nOpen-source code available on GitHub\n(https://github.com/SpringWiz11/Fed-GNODEFormer).","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T06:43:20Z"}
{"aid":"http://arxiv.org/abs/2504.11832v1","title":"Generation of Paths for Motion Planning for a Dubins Vehicle on Sphere","summary":"In this article, the candidate optimal paths for a Dubins vehicle on a sphere\nare analytically derived. In particular, the arc angles for segments in $CGC$,\n$CCC$, $CCCC$, and $CCCCC$ paths, which have previously been shown to be\noptimal depending on the turning radius $r$ of the vehicle by Kumar \\textit{et\nal.}, are analytically derived. The derived expressions are used for the\nimplementation provided in\nhttps://github.com/DeepakPrakashKumar/Motion-planning-on-sphere.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T07:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.11841v1","title":"Permutation dimensions of prime cyclic groups","summary":"Based on recent successes concerning permutation resolutions of\nrepresentations by Balmer and Gallauer we define a new invariant of finite\ngroups: the p-permutation dimension. We compute this invariant for cyclic\ngroups of prime order.","main_category":"math.RT","categories":"math.RT","published":"2025-04-16T08:00:36Z"}
{"aid":"http://arxiv.org/abs/2504.11843v1","title":"Scalable Multi-task Edge Sensing via Task-oriented Joint Information\n  Gathering and Broadcast","summary":"The recent advance of edge computing technology enables significant sensing\nperformance improvement of Internet of Things (IoT) networks. In particular, an\nedge server (ES) is responsible for gathering sensing data from distributed\nsensing devices, and immediately executing different sensing tasks to\naccommodate the heterogeneous service demands of mobile users. However, as the\nnumber of users surges and the sensing tasks become increasingly\ncompute-intensive, the huge amount of computation workloads and data\ntransmissions may overwhelm the edge system of limited resources. Accordingly,\nwe propose in this paper a scalable edge sensing framework for multi-task\nexecution, in the sense that the computation workload and communication\noverhead of the ES do not increase with the number of downstream users or\ntasks. By exploiting the task-relevant correlations, the proposed scheme\nimplements a unified encoder at the ES, which produces a common low-dimensional\nmessage from the sensing data and broadcasts it to all users to execute their\nindividual tasks. To achieve high sensing accuracy, we extend the well-known\ninformation bottleneck theory to a multi-task scenario to jointly optimize the\ninformation gathering and broadcast processes. We also develop an efficient\ntwo-step training procedure to optimize the parameters of the neural\nnetwork-based codecs deployed in the edge sensing system. Experiment results\nshow that the proposed scheme significantly outperforms the considered\nrepresentative benchmark methods in multi-task inference accuracy. Besides, the\nproposed scheme is scalable to the network size, which maintains almost\nconstant computation delay with less than 1% degradation of inference\nperformance when the user number increases by four times.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T08:06:46Z"}
{"aid":"http://arxiv.org/abs/2504.11899v1","title":"Variational Quantum Optimization Benchmark Suite for Airline Crew\n  Pairing and More","summary":"We introduce a set of open-source packages that form a highly extensible\nframework for quantum optimization. One design goal of the system is the\ninclusion of a command line based configuration system for setting up\nexperiments. The possible options are derived using well-known Python packages\nand presented to the user intuitively, allowing the configuration of repeatable\nvariational quantum optimization experiments. We give an example of using the\nsystem through the Airline Crew Pairing problem, a highly relevant industrial\nproblem, and the MaxCut problem, for which instances of manageable size are\nreadily available.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T09:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.11905v1","title":"A Novel Splitter Design for RSMA Networks","summary":"Rate splitting multiple access (RSMA) has firmly established itself as a\npowerful methodology for multiple access, interference management, and\nmulti-user strategy for next-generation communication systems. In this paper,\nwe propose a novel channel-dependent splitter design for multi-carrier RSMA\nsystems, aimed at improving reliability performance. Specifically, the proposed\nsplitter leverages channel state information and the inherent structure of RSMA\nto intelligently replicate segments of the private stream data that are likely\nto encounter deep-faded subchannels into the common stream. Thus, the\nreliability is enhanced within the same transmission slot, minimizing the need\nfor frequent retransmissions and thereby reducing latency. To assess the\neffectiveness of our approach, we conduct comprehensive evaluations using key\nperformance metrics, including achievable sum rate, average packet delay, and\nbit error rate (BER), under both perfect and imperfect channel estimation\nscenarios.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-16T09:30:02Z"}
{"aid":"http://arxiv.org/abs/2504.11910v1","title":"The role of wild birds in the global highly pathogenic avian influenza\n  H5 panzootic","summary":"The highly pathogenic avian influenza (HPAI) H5 clade 2.3.4.4b has triggered\nan unprecedented global panzootic. As the frequency and scale of HPAI H5\noutbreaks continue to rise, understanding how wild birds contribute to shape\nthe global virus spread across regions, affecting poultry, domestic and wild\nmammals, is increasingly critical. In this review, we examine ecological and\nevolutionary studies to map the global transmission routes of HPAI H5 viruses,\nidentify key wild bird species involved in viral dissemination, and explore\ninfection patterns, including mortality and survival. We also highlight major\nremaining knowledge gaps that hinder a full understanding of wild birds role in\nviral dynamics, which must be addressed to enhance surveillance strategies and\nrefine risk assessment models aimed at preventing future outbreaks in wildlife,\ndomestic animals and safeguard public health.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-16T09:42:40Z"}
{"aid":"http://arxiv.org/abs/2504.11916v1","title":"Non-vanishing of Dirichlet $L$-functions at the Central Point","summary":"We prove that for at least $\\frac{7}{19}$ of the primitive Dirichlet\ncharacters $\\chi$ with large general modulus, the central value\n$L(\\frac12,\\chi)$ is non-vanishing.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T09:54:28Z"}
{"aid":"http://arxiv.org/abs/2504.11932v1","title":"Technological Complexity Based on Japanese Patent Data","summary":"As international competition intensifies in technologies, nations need to\nidentify key technologies to foster innovation. However, the identification is\ndifficult because a technology is independent, therefore has complex nature.\nHere, this study aims to assess patent technological fields by applying\nTechnological Complexity Index from a corporate perspective, addressing its\nunderutilization in Japan despite its potential. By utilizing carefully\nprocessed patent data from fiscal years 1981 to 2010, we analyze the bipartite\nnetwork which consists of 1,938 corporations and 35 or 124 technological\nfields. Our findings provide quantitative characteristics of ubiquity and\nsophistication for patent fields, the detailed technological trends that\nreflect the social context, and methodological stability for policymakers and\nresearchers, contributing to targeted innovation strategies in Japan.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-16T10:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.11937v1","title":"Complete Classification of the Symmetry Groups of Monge-AmpÃ¨re\n  Equation and Affine Maximal type Equation","summary":"The affine maximal type hypersurface has been a core topic in Affine\nGeometry. When the hypersurface is presented as a regular graph of a convex\nfunction $u$, the statement that the graph is of affine maximal type is\nequivalent to the statement that $u$ satisfies the fully nonlinear partial\ndifferential equation\n  $$\n  D_{ij}(U^{ij}w)=0, \\ \\ w\\equiv[\\det D^2u]^{-\\theta}, \\ \\ \\theta>0, \\ \\\n\\forall x\\in{\\mathbb{R}}^N\n  $$ of fourth order. This equation can be regarded as a generalization of the\n$N$-dimensional Monge-Amp\\`{e}re equation\n  $$\n  \\det D^2u=1, \\ \\ \\forall x\\in{\\mathbb{R}}^N\n  $$ of second order, since each solution of Monge-Amp\\`{e}re Equation\nsatisfies affine maximal type equation automatically. In this paper, we will\ndetermine the symmetry groups of these two important fully nonlinear equations\nwithout asymptotic growth assumption. Our method develops the Lie's theory to\nfully nonlinear PDEs.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T10:16:28Z"}
{"aid":"http://arxiv.org/abs/2504.11941v1","title":"Admissible matchings and the Castelnuovo-Mumford regularity of\n  square-free powers","summary":"Let $I$ be any square-free monomial ideal, and $\\mathcal{H}_I$ denote the\nhypergraph associated with $I$. Refining the concept of $k$-admissible matching\nof a graph defined by Erey and Hibi, we introduce the notion of generalized\n$k$-admissible matching for any hypergraph. Using this, we give a sharp lower\nbound on the (Castelnuovo-Mumford) regularity of $I^{[k]}$, where $I^{[k]}$\ndenotes the $k^{\\text{th}}$ square-free power of $I$. In the special case when\n$I$ is equigenerated in degree $d$, this lower bound can be described using a\ncombinatorial invariant $\\mathrm{aim}(\\mathcal{H}_I,k)$, called the\n$k$-admissible matching number of $\\mathcal{H}_I$. Specifically, we prove that\n$\\mathrm{reg}(I^{[k]})\\ge (d-1)\\mathrm{aim}(\\mathcal{H}_I,k)+k$, whenever\n$I^{[k]}$ is non-zero. Even for the edge ideal $I(G)$ of a graph $G$, it turns\nout that $\\mathrm{aim}(G,k)+k$ is the first general lower bound for the\nregularity of $I(G)^{[k]}$. In fact, when $G$ is a forest, $\\mathrm{aim}(G,k)$\ncoincides with the $k$-admissible matching number introduced by Erey and Hibi.\nNext, we show that if $G$ is a block graph, then $\\mathrm{reg}(I(G)^{[k]})=\n\\mathrm{aim}(G,k)+k$, and this result can be seen as a generalization of the\ncorresponding regularity formula for forests. Additionally, for a\nCohen-Macaulay chordal graph $G$, we prove that $\\mathrm{reg}(I(G)^{[2]})=\n\\mathrm{aim}(G,2)+2$. Finally, we propose a conjecture on the regularity of\nsquare-free powers of edge ideals of chordal graphs.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-16T10:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.11961v1","title":"zkFuzz: Foundation and Framework for Effective Fuzzing of Zero-Knowledge\n  Circuits","summary":"Zero-knowledge (ZK) circuits enable privacy-preserving computations and are\ncentral to many cryptographic protocols. Systems like Circom simplify ZK\ndevelopment by combining witness computation and circuit constraints in one\nprogram. However, even small errors can compromise security of ZK programs\n--under-constrained circuits may accept invalid witnesses, while\nover-constrained ones may reject valid ones. Static analyzers are often\nimprecise with high false positives, and formal tools struggle with real-world\ncircuit scale. Additionally, existing tools overlook several critical\nbehaviors, such as intermediate computations and program aborts, and thus miss\nmany vulnerabilities.\n  Our theoretical contribution is the Trace-Constraint Consistency Test (TCCT),\na foundational language-independent formulation of ZK circuit bugs that defines\nbugs as discrepancies between the execution traces of the computation and the\ncircuit constraints. TCCT captures both intermediate computations and program\naborts, detecting bugs that elude prior tools.\n  Our systems contribution is zkFuzz, a novel program mutation-based fuzzing\nframework for detecting TCCT violations. zkFuzz systematically mutates the\ncomputational logic of Zk programs guided by a novel fitness function, and\ninjects carefully crafted inputs using tailored heuristics to expose bugs. We\nevaluated zkFuzz on 354 real-world ZK circuits written in Circom, a leading\nprogramming system for ZK development. zkFuzz successfully identified 66 bugs,\nincluding 38 zero-days --18 of which were confirmed by developers and 6 fixed,\nearning bug bounties.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-04-16T10:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.11993v1","title":"New Three Different Generators for Constructing New Three Different\n  Bivariate Copulas","summary":"In this paper, the author introduces new methods to construct Archimedean\ncopulas. The generator of each copula fulfills the sufficient conditions as\nregards the boundary and being continuous, decreasing, and convex. Each inverse\ngenerator also fulfills the necessary conditions as regards the boundary\nconditions, marginal uniformity, and 2-increasing properties. Although these\ncopulas satisfy these conditions, they have some limitations. They do not cover\nthe entire dependency spectrum, ranging from perfect negative dependency to\nperfect positive dependency, passing through the independence state","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-16T11:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.12004v1","title":"Scaled Block Vecchia Approximation for High-Dimensional Gaussian Process\n  Emulation on GPUs","summary":"Emulating computationally intensive scientific simulations is essential to\nenable uncertainty quantification, optimization, and decision-making at scale.\nGaussian Processes (GPs) offer a flexible and data-efficient foundation for\nstatistical emulation, but their poor scalability limits applicability to large\ndatasets. We introduce the Scaled Block Vecchia (SBV) algorithm for distributed\nGPU-based systems. SBV integrates the Scaled Vecchia approach for anisotropic\ninput scaling with the Block Vecchia (BV) method to reduce computational and\nmemory complexity while leveraging GPU acceleration techniques for efficient\nlinear algebra operations. To the best of our knowledge, this is the first\ndistributed implementation of any Vecchia-based GP variant. Our implementation\nemploys MPI for inter-node parallelism and the MAGMA library for\nGPU-accelerated batched matrix computations. We demonstrate the scalability and\nefficiency of the proposed algorithm through experiments on synthetic and\nreal-world workloads, including a 50M point simulation from a respiratory\ndisease model. SBV achieves near-linear scalability on up to 64 A100 and GH200\nGPUs, handles 320M points, and reduces energy use relative to exact GP solvers,\nestablishing SBV as a scalable and energy-efficient framework for emulating\nlarge-scale scientific models on GPU-based distributed systems.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-16T11:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.12026v1","title":"Neumaier graphs from cyclotomy with small coherent rank","summary":"Using cyclotomy, we construct a new infinite family of Neumaier graphs that\nincludes infinitely many strongly regular graphs. Notably, this family\nconjecturally contains infinitely many graphs with coherent rank $6$. Our\nconstruction also provides the first known examples that answer a question\nposed by Evans, Goryainov, and Panasenko regarding the existence of Neumaier\ngraphs whose nexus is not a power of $2$. In addition, we show that a\nconstruction of Greaves and Koolen yields an infinite family of Neumaier graphs\nwith coherent rank $6$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-16T12:35:02Z"}
{"aid":"http://arxiv.org/abs/2504.12035v1","title":"Enhancement of primordial curvature perturbations in $R^3$-corrected\n  Starobinsky-Higgs inflation","summary":"We provide a systematic study of the Starobinsky-Higgs inflation model in the\npresence of an additional cubic term of the Ricci scalar. We investigate, in\nparticular, the effects of the cubic term on the spectral index $n_s$ and the\ntensor-to-scalar ratio $r$. Through both analytical and numerical analyses, we\nshow that the $R^3$-corrected Starobinsky-Higgs model can achieve compatibility\nwith cosmic microwave background observations while producing distinct\nobservational signatures with different frequency ranges. In addition, we\ndiscuss the complementarity between different observational probes, including\nthe scalar-induced gravitational waves and spectral distortions, offering an\nindependent probe of the enhanced curvature perturbations. Detection prospects\nare also discussed.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-16T12:49:39Z"}
{"aid":"http://arxiv.org/abs/2504.12049v1","title":"Impact of spin correlations on resistivity and microwave absorption of\n  Ba(Fe$_{1-x}$Co$_x$)$_2$As$_2$","summary":"The results of studies of BaFe$_2$As$_2$ single crystals doped with cobalt by\nmeans of resistivity and microwave absorption measurement are reported. A\ntheoretical description of the behavior of the microwave absorption amplitude\nis made taking into account the temperature dependence of resistivity, magnetic\nsusceptibility and the lifetime of spin fluctuations. An assumption has been\nmade that the deviation from the linear dependence of resistivity on\ntemperature at $T<100$ K is not related to the electron-electron scattering\nmechanism, but it is due to the appearance of nematic fluctuations. Estimates\nof the rate of scattering by spin fluctuations indicate their nematic nature at\ntemperatures near the structural transition.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T13:04:29Z"}
{"aid":"http://arxiv.org/abs/2504.12064v1","title":"One-stage hollow-core fiber-based compression of Yb:KGW lasers to the\n  single-cycle regime","summary":"The generation of intense, waveform-controlled, single-cycle pulses based on\nYb:KGW amplifiers is central to integrating these lasers with attosecond\nmetrology and spectroscopy. Here, we demonstrate single-stage, multi-octave (~\n2.4 octaves) spectral broadening of Yb:KGW amplified pulses in a\nneon-pressurized hollow-core fiber (HCF) capillary and their compression to the\nsingle-cycle regime (1.1 cycles at 880 nm) using chirped mirrors. Utilizing\nHomochromatic Attosecond Streaking (HAS), we characterize the field waveforms\nof the generated pulses and demonstrate precise control of their\ncarrier-envelope phase. Our results provide a simplified route to single-cycle\npulse generation using Yb:KGW technology, previously possible only with\nTi:Sapphire-based front ends. This work paves the way for advanced applications\nin attosecond science, strong-field physics, and spectroscopy.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-16T13:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.12105v1","title":"Can asteroid-mass PBHDM be compatible with catalyzed phase transition\n  interpretation of PTA?","summary":"Primordial black holes (PBHs) can catalyze first-order phase transitions\n(FOPTs) in their vicinity, potentially modifying the gravitational wave (GW)\nsignals from PTs. In this study, we present the first comprehensive analysis of\nthis catalytic effect during supercooled PTs within the high PBH number density\nregime. Applying the analytical model with envelope approximation, we derive\nthe general expressions of GW spectrum in the presence of PBHs. We find that at\nrelatively small PBH number densities, the GW signals are amplified due to the\nlarge-size bubbles. While higher PBH number densities suppress GW signals,\nsince the accelerated PT progresses too rapidly. We further extend our findings\nto the bulk flow model and to scalar-induced GWs (SIGWs) generated during PTs.\nBy conducting data fitting with the NANOGrav 15-year dataset, we find that the\nPBH catalytic effect significantly alters the estimation of PT parameters.\nNotably, our analysis of the bubble collision GWs reveals that, the\nasteroid-mass PBHs ($10^{-16} - 10^{-12} M_\\odot$) as the whole dark matter is\nincompatible with the PT interpretation of pulsar timing array signals.\nHowever, incorporating SIGWs can reduce this incompatibility for PBHs in the\nmass range $10^{-14} - 10^{-12} M_\\odot$.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-16T14:13:17Z"}
{"aid":"http://arxiv.org/abs/2504.12118v1","title":"Unraveling the origin of giant exoplanets -- Observational implications\n  of convective mixing","summary":"The connection between the atmospheric composition of giant planets and their\norigin remains elusive. In this study, we explore how convective mixing can\nlink the planetary primordial state to its atmospheric composition. We simulate\nthe long-term evolution of gas giants with masses between 0.3 and 3 Jupiter\nmasses, considering various composition profiles and primordial entropies\n(assuming no entropy-mass dependence). Our results show that when convective\nmixing is considered, the atmospheric metallicity increases with time and that\nthis time evolution encodes information about the planetary primordial\nstructure. Additionally, the degree of compositional mixing affects the\nplanetary radius, altering its evolution in a measurable way. By applying mock\nobservations, we demonstrate that combining radius and atmospheric composition\ncan help to constrain the planetary formation history. Young systems emerge as\nprime targets for such characterization, with lower-mass gas giants\n(approaching Saturn's mass) being particularly susceptible to mixing-induced\nchanges. Our findings highlight convective mixing as a key mechanism for\nprobing the primordial state of giant planets, offering new constraints on\nformation models and demonstrating that the conditions inside giant planets\nshortly after their formation are not necessarily erased over billions of years\nand can leave a lasting imprint on their evolution.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-16T14:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.12131v1","title":"Equidistribution of CM points on Shimura Curves and ternary theta series","summary":"We prove an equidistribution statement for the reduction of Galois orbits of\nCM points on the special fiber of a Shimura curve over a totally real field,\nconsidering both the split and the ramified case. The main novelty of the\nramified case consists in the use of the moduli interpretation of the\nCerednik--Drinfeld uniformisation. Our result is achieved by associating to the\nreduction of CM points certain Hilbert modular forms of weight $3/2$ and by\nanalyzing their Fourier coefficients. Moreover, we also deduce the Shimura\ncurves case of the integral version of the Andr\\'e--Oort conjecture.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T14:45:22Z"}
{"aid":"http://arxiv.org/abs/2504.12145v1","title":"Factorizations of polynomials with integral non-negative coefficients","summary":"We study the structure of the commutative multiplicative monoid $\\mathbb\nN_0[x]^*$ of all the non-zero polynomials in $\\mathbb Z[x]$ with non-negative\ncoefficients. We show that $\\mathbb N_0[x]^*$ is not a half-factorial monoid\nand is not a Krull monoid, but has a structure very similar to that of Krull\nmonoids, replacing valuations into $\\mathbb N_0$ with derivations into $\\mathbb\nN_0$. We study ideals, chain of ideals, prime ideals and prime elements of\n$\\mathbb N_0[x]^*$. Our monoid $\\mathbb N_0[x]^*$ is a submonoid of the\nmultiplicative monoid of the ring $\\mathbb Z[x]$, which is a left module over\nthe Weyl algebra $A_1(\\mathbb Z)$.","main_category":"math.AC","categories":"math.AC","published":"2025-04-16T14:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.12175v1","title":"Approximation Bounds for Transformer Networks with Application to\n  Regression","summary":"We explore the approximation capabilities of Transformer networks for\nH\\\"older and Sobolev functions, and apply these results to address\nnonparametric regression estimation with dependent observations. First, we\nestablish novel upper bounds for standard Transformer networks approximating\nsequence-to-sequence mappings whose component functions are H\\\"older continuous\nwith smoothness index $\\gamma \\in (0,1]$. To achieve an approximation error\n$\\varepsilon$ under the $L^p$-norm for $p \\in [1, \\infty]$, it suffices to use\na fixed-depth Transformer network whose total number of parameters scales as\n$\\varepsilon^{-d_x n / \\gamma}$. This result not only extends existing findings\nto include the case $p = \\infty$, but also matches the best known upper bounds\non number of parameters previously obtained for fixed-depth FNNs and RNNs.\nSimilar bounds are also derived for Sobolev functions. Second, we derive\nexplicit convergence rates for the nonparametric regression problem under\nvarious $\\beta$-mixing data assumptions, which allow the dependence between\nobservations to weaken over time. Our bounds on the sample complexity impose no\nconstraints on weight magnitudes. Lastly, we propose a novel proof strategy to\nestablish approximation bounds, inspired by the Kolmogorov-Arnold\nrepresentation theorem. We show that if the self-attention layer in a\nTransformer can perform column averaging, the network can approximate\nsequence-to-sequence H\\\"older functions, offering new insights into the\ninterpretability of self-attention mechanisms.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-16T15:25:58Z"}
{"aid":"http://arxiv.org/abs/2504.12183v1","title":"Towards asteroseismology of neutron stars with physics-informed neural\n  networks","summary":"The study of the gravitational wave signatures of neutron star oscillations\nmay provide important information of their interior structure and Equation of\nState (EoS) at high densities. We present a novel technique based on physically\ninformed neural networks (PINNs) to solve the eigenvalue problem associated\nwith normal oscillation modes of neutron stars. The procedure is tested in a\nsimplified scenario, with an analytical solution, that can be used to test the\nperformance and the accuracy of the method. We show that it is possible to get\naccurate results of both the eigenfrequencies and the eigenfunctions with this\nscheme. The flexibility of the method and its capability of adapting to complex\nscenarios may serve in the future as a path to include more physics into these\nsystems.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-16T15:39:45Z"}
{"aid":"http://arxiv.org/abs/2504.12198v1","title":"Diagrammatic Simplification of Linearized Coupled Cluster Theory","summary":"Linearized Coupled Cluster Doubles (LinCCD) often provides near-singular\nenergies in small-gap systems that exhibit static correlation. This has been\nattributed to the lack of quadratic $T_2^2$ terms that typically balance out\nsmall energy denominators in the CCD amplitude equations. Herein, I show that\nexchange contributions to ring and crossed-ring contractions (not small\ndenominators per se) cause the divergent behavior of LinCC(S)D approaches.\nRather than omitting exchange terms, I recommend a regular and size-consistent\nmethod that retains only linear ladder diagrams. As LinCCD and configuration\ninteraction doubles (CID) equations are isomorphic, this also implies that\nsimplification (rather than quadratic extensions) of CID amplitude equations\ncan lead to a size-consistent theory. Linearized ladder CCD (LinLCCD) is robust\nin statically-correlated systems and can be made\n$O(n_{\\text{occ}}^4n_{\\text{vir}}^2)$ with a hole-hole approximation. The\nrelationship between LinLCCD and random-phase approximation sets the stage for\nthe development of next-generation double-hybrid density functionals that can\ndescribe static correlation.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-16T15:48:33Z"}
{"aid":"http://arxiv.org/abs/2504.12211v1","title":"Creating benchmarkable components to measure the quality ofAI-enhanced\n  developer tools","summary":"In the AI community, benchmarks to evaluate model quality are well\nestablished, but an equivalent approach to benchmarking products built upon\ngenerative AI models is still missing. This has had two consequences. First, it\nhas made teams focus on model quality over the developer experience, while\nsuccessful products combine both. Second, product team have struggled to answer\nquestions about their products in relation to their competitors.\n  In this case study, we share: (1) our process to create robust,\nenterprise-grade and modular components to support the benchmarking of the\ndeveloper experience (DX) dimensions of our team's AI for code offerings, and\n(2) the components we have created to do so, including demographics and\nattitudes towards AI surveys, a benchmarkable task, and task and feature\nsurveys. By doing so, we hope to lower the barrier to the DX benchmarking of\ngenAI-enhanced code products.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-04-16T15:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.12233v1","title":"Hardness of observing strong-to-weak symmetry breaking","summary":"Spontaneous symmetry breaking (SSB) is the cornerstone of our understanding\nof quantum phases of matter. Recent works have generalized this concept to the\ndomain of mixed states in open quantum systems, where symmetries can be\nrealized in two distinct ways dubbed strong and weak. Novel intrinsically mixed\nphases of quantum matter can then be defined by the spontaneous breaking of\nstrong symmetry down to weak symmetry. However, proposed order parameters for\nstrong-to-weak SSB (based on mixed-state fidelities or purities) seem to\nrequire exponentially many copies of the state, raising the question: is it\npossible to efficiently detect strong-to-weak SSB in general? Here we answer\nthis question negatively in the paradigmatic cases of $Z_2$ and $U(1)$\nsymmetries. We construct ensembles of pseudorandom mixed states that do not\nbreak the strong symmetry, yet are computationally indistinguishable from\nstates that do. This rules out the existence of efficient state-agnostic\nprotocols to detect strong-to-weak SSB.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-16T16:31:27Z"}
{"aid":"http://arxiv.org/abs/2504.12236v1","title":"Towards Human-Centered Early Prediction Models for Academic Performance\n  in Real-World Contexts","summary":"Supporting student success requires collaboration among multiple\nstakeholders. Researchers have explored machine learning models for academic\nperformance prediction; yet key challenges remain in ensuring these models are\ninterpretable, equitable, and actionable within real-world educational support\nsystems. First, many models prioritize predictive accuracy but overlook\nhuman-centered considerations, limiting trust among students and reducing their\nusefulness for educators and institutional decision-makers. Second, most models\nrequire at least a month of data before making reliable predictions, delaying\nopportunities for early intervention. Third, current models primarily rely on\nsporadically collected, classroom-derived data, missing broader behavioral\npatterns that could provide more continuous and actionable insights. To address\nthese gaps, we present three modeling approaches-LR, 1D-CNN, and MTL-1D-CNN-to\nclassify students as low or high academic performers. We evaluate them based on\nexplainability, fairness, and generalizability to assess their alignment with\nkey social values. Using behavioral and self-reported data collected within the\nfirst week of two Spring terms, we demonstrate that these models can identify\nat-risk students as early as week one. However, trade-offs across\nhuman-centered considerations highlight the complexity of designing predictive\nmodels that effectively support multi-stakeholder decision-making and\nintervention strategies. We discuss these trade-offs and their implications for\ndifferent stakeholders, outlining how predictive models can be integrated into\nstudent support systems. Finally, we examine broader socio-technical challenges\nin deploying these models and propose future directions for advancing\nhuman-centered, collaborative academic prediction systems.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-16T16:40:56Z"}
{"aid":"http://arxiv.org/abs/2504.12248v1","title":"RÃ©nyi security framework against coherent attacks applied to\n  decoy-state QKD","summary":"We develop a flexible and robust framework for finite-size security proofs of\nquantum key distribution (QKD) protocols under coherent attacks, applicable to\nboth fixed- and variable-length protocols. Our approach achieves high\nfinite-size key rates across a broad class of protocols while imposing minimal\nrequirements. In particular, it eliminates the need for restrictive conditions\nsuch as limited repetition rates or the implementation of virtual tomography\nprocedures. To achieve this goal, we introduce new numerical techniques for the\nevaluation of sandwiched conditional R\\'enyi entropies. In doing so, we also\nfind an alternative formulation of the \"QKD cone\" studied in previous work. We\nillustrate the versatility of our framework by applying it to several\npractically relevant protocols, including decoy-state protocols. Furthermore,\nwe extend the analysis to accommodate realistic device imperfections, such as\nindependent intensity and phase imperfections. Overall, our framework provides\nboth greater scope of applicability and better key rates than existing\ntechniques, especially for small block sizes, hence offering a scalable path\ntoward secure quantum communication under realistic conditions","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T16:54:23Z"}
{"aid":"http://arxiv.org/abs/2504.12250v1","title":"AnomalyGen: An Automated Semantic Log Sequence Generation Framework with\n  LLM for Anomaly Detection","summary":"The scarcity of high-quality public log datasets has become a critical\nbottleneck in advancing log-based anomaly detection techniques. Current\ndatasets exhibit three fundamental limitations: (1) incomplete event coverage,\n(2) artificial patterns introduced by static analysis-based generation\nframeworks, and (3) insufficient semantic awareness. To address these\nchallenges, we present AnomalyGen, the first automated log synthesis framework\nspecifically designed for anomaly detection. Our framework introduces a novel\nfour-phase architecture that integrates enhanced program analysis with\nChain-of-Thought reasoning (CoT reasoning), enabling iterative log generation\nand anomaly annotation without requiring physical system execution. Evaluations\non Hadoop and HDFS distributed systems demonstrate that AnomalyGen achieves\nsubstantially broader log event coverage (38-95 times improvement over existing\ndatasets) while producing more operationally realistic log sequences compared\nto static analysis-based approaches. When augmenting benchmark datasets with\nsynthesized logs, we observe maximum F1-score improvements of 3.7% (average\n1.8% improvement across three state-of-the-art anomaly detection models). This\nwork not only establishes a high-quality benchmarking resource for automated\nlog analysis but also pioneers a new paradigm for applying large language\nmodels (LLMs) in software engineering workflows.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T16:54:38Z"}
{"aid":"http://arxiv.org/abs/2504.12253v1","title":"Stability conditions on K3 surfaces via mass of spherical objects","summary":"We prove that a stability condition on a K3 surface is determined by the\nmasses of spherical objects up to a natural $\\mathbb{C}$-action. This is\nmotivated by the result of Huybrechts and the recent proposal of\nBapat-Deopurkar-Licata on the construction of a compactification of a stability\nmanifold. We also construct lax stability conditions in the sense of\nBroomhead-Pauksztello-Ploog-Woolf associated to spherical bundles.","main_category":"math.AG","categories":"math.AG,math.GT","published":"2025-04-16T17:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.12276v1","title":"The Tenth NTIRE 2025 Image Denoising Challenge Report","summary":"This paper presents an overview of the NTIRE 2025 Image Denoising Challenge\n({\\sigma} = 50), highlighting the proposed methodologies and corresponding\nresults. The primary objective is to develop a network architecture capable of\nachieving high-quality denoising performance, quantitatively evaluated using\nPSNR, without constraints on computational complexity or model size. The task\nassumes independent additive white Gaussian noise (AWGN) with a fixed noise\nlevel of 50. A total of 290 participants registered for the challenge, with 20\nteams successfully submitting valid results, providing insights into the\ncurrent state-of-the-art in image denoising.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T17:35:09Z"}
{"aid":"http://arxiv.org/abs/2504.12291v1","title":"Liouvillean Spectral Transition in Noisy Quantum Many-Body Scars","summary":"Understanding the behavior of quantum many-body systems under decoherence is\nessential for developing robust quantum technologies. Here, we examine the fate\nof weak ergodicity breaking in systems hosting quantum many-body scars when\nsubject to local pure dephasing -- an experimentally relevant form of\nenvironmental noise. Focusing on a large class of models with an approximate\nsu(2)-structured scar subspace, we show that scarred eigenmodes of the\nLiouvillean exhibit a transition reminiscent of spontaneous\n$\\mathbb{PT}$-symmetry breaking as the dephasing strength increases. Unlike\npreviously studied non-Hermitian mechanisms, this transition arises from a\ndistinct quantum jump effect. Remarkably, in platforms such as the XY spin\nladder and PXP model of Rydberg atom arrays, the critical dephasing rate shows\nonly weak dependence on system size, revealing an unexpected robustness of\nscarred dynamics in noisy quantum simulators.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-16T17:55:02Z"}
{"aid":"http://arxiv.org/abs/2504.12297v1","title":"Optimal flock formation induced by agent heterogeneity","summary":"The study of flocking in biological systems has identified conditions for\nself-organized collective behavior, inspiring the development of decentralized\nstrategies to coordinate the dynamics of swarms of drones and other autonomous\nvehicles. Previous research has focused primarily on the role of the\ntime-varying interaction network among agents while assuming that the agents\nthemselves are identical or nearly identical. Here, we depart from this\nconventional assumption to investigate how inter-individual differences between\nagents affect the stability and convergence in flocking dynamics. We show that\nflocks of agents with optimally assigned heterogeneous parameters significantly\noutperform their homogeneous counterparts, achieving 20-40% faster convergence\nto desired formations across various control tasks. These tasks include target\ntracking, flock formation, and obstacle maneuvering. In systems with\ncommunication delays, heterogeneity can enable convergence even when flocking\nis unstable for identical agents. Our results challenge existing paradigms in\nmulti-agent control and establish system disorder as an adaptive, distributed\nmechanism to promote collective behavior in flocking dynamics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cs.SY,eess.SY,math.DS,math.OC,nlin.AO","published":"2025-04-16T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.12626v1","title":"Packing Input Frame Context in Next-Frame Prediction Models for Video\n  Generation","summary":"We present a neural network structure, FramePack, to train next-frame (or\nnext-frame-section) prediction models for video generation. The FramePack\ncompresses input frames to make the transformer context length a fixed number\nregardless of the video length. As a result, we are able to process a large\nnumber of frames using video diffusion with computation bottleneck similar to\nimage diffusion. This also makes the training video batch sizes significantly\nhigher (batch sizes become comparable to image diffusion training). We also\npropose an anti-drifting sampling method that generates frames in inverted\ntemporal order with early-established endpoints to avoid exposure bias (error\naccumulation over iterations). Finally, we show that existing video diffusion\nmodels can be finetuned with FramePack, and their visual quality may be\nimproved because the next-frame prediction supports more balanced diffusion\nschedulers with less extreme flow shift timesteps.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T04:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.12637v1","title":"Scaling Instruction-Tuned LLMs to Million-Token Contexts via\n  Hierarchical Synthetic Data Generation","summary":"Large Language Models (LLMs) struggle with long-context reasoning, not only\ndue to the quadratic scaling of computational complexity with sequence length\nbut also because of the scarcity and expense of annotating long-context data.\nThere has been barely any open-source work that systematically ablates\nlong-context data, nor is there any openly available instruction tuning dataset\nwith contexts surpassing 100K tokens. To bridge this gap, we introduce a novel\npost-training synthetic data generation strategy designed to efficiently extend\nthe context window of LLMs while preserving their general task performance. Our\napproach scalably extends to arbitrarily long context lengths, unconstrained by\nthe length of available real-world data, which effectively addresses the\nscarcity of raw long-context data. Through a step-by-step rotary position\nembedding (RoPE) scaling training strategy, we demonstrate that our model, with\na context length of up to 1M tokens, performs well on the RULER benchmark and\nInfiniteBench and maintains robust performance on general language tasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T04:46:57Z"}
{"aid":"http://arxiv.org/abs/2504.12662v1","title":"Flat Circular Velocities on a megaparsec scale from the $Î›$CDM\n  model","summary":"A recent study using weak gravitational lensing reveals that there are some\nisolated galaxies having almost flat rotation curves at very large distance\nfrom the galactic centres. According to the authors of the study this provides\na strong challenge the standard cold dark matter model, since the dark haloes\nare too small to explain their observations, especially for small stellar\nmasses. In this article, we show that improving their model, the virial radius\nis larger than their estimates. The NFW rotational curve, and especially the\npseudo Isothermal one, are in agreement with their flat rotational curves,\nespecially for the larger baryonic mass bins used by the authors.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T05:47:06Z"}
{"aid":"http://arxiv.org/abs/2504.12672v1","title":"Post-processing improves accuracy of Artificial Intelligence weather\n  forecasts","summary":"Artificial Intelligence (AI) weather models are now reaching\noperational-grade performance for some variables, but like traditional\nNumerical Weather Prediction (NWP) models, they exhibit systematic biases and\nreliability issues. We test the application of the Bureau of Meteorology's\nexisting statistical post-processing system, IMPROVER, to ECMWF's deterministic\nArtificial Intelligence Forecasting System (AIFS), and compare results against\npost-processed outputs from the ECMWF HRES and ENS models. Without any\nmodification to configuration or processing workflows, post-processing yields\ncomparable accuracy improvements for AIFS as for traditional NWP forecasts, in\nboth expected value and probabilistic outputs. We show that blending AIFS with\nNWP models improves overall forecast skill, even when AIFS alone is not the\nmost accurate component. These findings show that statistical post-processing\nmethods developed for NWP are directly applicable to AI models, enabling\nnational meteorological centres to incorporate AI forecasts into existing\nworkflows in a low-risk, incremental fashion.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.AI,cs.LG","published":"2025-04-17T06:05:10Z"}
{"aid":"http://arxiv.org/abs/2504.12684v1","title":"SOPHY: Generating Simulation-Ready Objects with Physical Materials","summary":"We present SOPHY, a generative model for 3D physics-aware shape synthesis.\nUnlike existing 3D generative models that focus solely on static geometry or 4D\nmodels that produce physics-agnostic animations, our approach jointly\nsynthesizes shape, texture, and material properties related to physics-grounded\ndynamics, making the generated objects ready for simulations and interactive,\ndynamic environments. To train our model, we introduce a dataset of 3D objects\nannotated with detailed physical material attributes, along with an annotation\npipeline for efficient material annotation. Our method enables applications\nsuch as text-driven generation of interactive, physics-aware 3D objects and\nsingle-image reconstruction of physically plausible shapes. Furthermore, our\nexperiments demonstrate that jointly modeling shape and material properties\nenhances the realism and fidelity of generated shapes, improving performance on\ngenerative geometry evaluation metrics.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T06:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.12694v1","title":"$D \\bar D_1(2420)$ and $D^* \\bar D^*(2400)$ molecular states: Probing\n  their electromagnetic fingerprints","summary":"As in previous decades, a comprehensive understanding of the intricate\ninternal configuration of hadrons continues to be a central objective within\nboth experimental and theoretical hadron physics. This pursuit plays a pivotal\nrole in advancing our knowledge of QCD and critically evaluating the robustness\nand accuracy of the theoretical models developed to date. Furthermore,\ndeciphering the underlying mechanisms of exotic states, both those currently\nobserved and those anticipated in future experiments, remains a pressing and\nunresolved challenge. Motivated by this, in the present study, we investigate\nthe electromagnetic properties of the $D \\bar D_1(2420)$ and $D^* \\bar\nD^*(2400)$ molecular tetraquark states with quantum numbers $J^{PC} = 1^{--}$,\nusing the QCD light-cone sum rule method. These states are analyzed within a\nhadronic molecular framework, where their magnetic and quadrupole moments are\ncomputed to probe internal structure and geometric deformation. Our results\nreveal distinct electromagnetic signatures, with the magnetic moments primarily\ndominated by light-quark contributions, and the quadrupole moments suggesting\nan oblate charge distribution. The findings are compared with prior studies\nassuming compact tetraquark configurations, emphasizing the sensitivity of\nelectromagnetic observables to the underlying hadronic structure. This analysis\nprovides critical insights into the nature of exotic hadrons and contributes to\nthe broader understanding of QCD dynamics in the non-perturbative regime.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat","published":"2025-04-17T06:41:44Z"}
{"aid":"http://arxiv.org/abs/2504.12697v1","title":"The Theory Of Auxiliary Weierstrassian Zeta Functions And Zeta\n  Differences","summary":"In this paper, we expand the theory of Weierstrassian elliptic functions by\nintroducing auxiliary zeta functions $\\zeta_\\lambda$, zeta differences of first\nkind $\\Delta_\\lambda$ and second kind $\\Delta_{\\lambda,\\mu}$ where\n$\\lambda,\\mu=1,2,3$. Fundamental and novel results pertaining to these\nfunctions are proven. Furthermore, results already existing in the literature\nare translated in terms of auxiliary zeta functions. Their relationship to\nJacobian elliptic functions and Jacobian functions are given.","main_category":"math.CV","categories":"math.CV,math.NT","published":"2025-04-17T06:50:55Z"}
{"aid":"http://arxiv.org/abs/2504.12705v1","title":"7-Methylquinolinium Iodobismuthate Memristor: Exploring Plasticity and\n  Memristive Properties for Digit Classification in Physical Reservoir\n  Computing","summary":"This study investigates 7-methylquinolinium halobismuthates (I, Br, and Cl)\nin two aspects: (1) their structural and semiconducting properties influenced\nby anionic composition, and (2) their memristive and plasticity characteristics\nfor neuromorphic and reservoir computing applications. Structural changes\ninduced by halides form low-dimensional halobismuthate fragments, confirmed by\ncrystallographic analysis. Optical band gaps were studied using diffuse\nreflectance spectroscopy, aligning with density functional theory results. Due\nto solubility limitations, only bismuth iodide complexes were explored in\nelectronic devices. Current-voltage scans showed pinched hysteresis loops,\ncharacteristic of memristors. Conductivity versus temperature study indicates\ncombined ionic and electronic contributions to conductivity of the devices.\nGiven that a memristor can function as a single synapse without the need for\nprogramming, aligning with the requirements of neuromorphic computing, the\nstudy investigated long-term depression, potentiation, and spike-time-dependent\nplasticity. As the potentiation-depression plots showed non-linearity with\nfading memory, these materials can be a good candidate for application in\nphysical reservoir computing. To further assess this material, an electronic\ndevice with sixteen gold electrodes was applied, featuring one input and 15\noutput electrodes deposited on silicon substrate and covered with a layer of\nstudied compound. Basic test to assess the complexity and non-linearity of the\ndevices were conducted through a series of benchmark tasks, including waveform\ngeneration, NARMA-2, memory capacity assessment, and noise study under both DC\nand AC current. The ability of device in MNIST digit classification with 82.26%\naccuracy and voice classification for digit 2 for six different people with 82\n% accuracy has been demonstrated.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-17T07:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.12709v1","title":"Self-Supervised Pre-training with Combined Datasets for 3D Perception in\n  Autonomous Driving","summary":"The significant achievements of pre-trained models leveraging large volumes\nof data in the field of NLP and 2D vision inspire us to explore the potential\nof extensive data pre-training for 3D perception in autonomous driving. Toward\nthis goal, this paper proposes to utilize massive unlabeled data from\nheterogeneous datasets to pre-train 3D perception models. We introduce a\nself-supervised pre-training framework that learns effective 3D representations\nfrom scratch on unlabeled data, combined with a prompt adapter based domain\nadaptation strategy to reduce dataset bias. The approach significantly improves\nmodel performance on downstream tasks such as 3D object detection, BEV\nsegmentation, 3D object tracking, and occupancy prediction, and shows steady\nperformance increase as the training data volume scales up, demonstrating the\npotential of continually benefit 3D perception models for autonomous driving.\nWe will release the source code to inspire further investigations in the\ncommunity.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T07:26:11Z"}
{"aid":"http://arxiv.org/abs/2504.12734v1","title":"Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning\n  Across Diverse Structured Knowledge","summary":"Unified Structured Knowledge Reasoning (USKR) aims to answer natural language\nquestions (NLQs) by using structured sources such as tables, databases, and\nknowledge graphs in a unified way. Existing USKR methods either rely on\nemploying task-specific strategies or custom-defined representations, which\nstruggle to leverage the knowledge transfer between different SKR tasks or\nalign with the prior of LLMs, thereby limiting their performance. This paper\nproposes a novel USKR framework named \\textsc{Pandora}, which takes advantage\nof \\textsc{Python}'s \\textsc{Pandas} API to construct a unified knowledge\nrepresentation for alignment with LLM pre-training. It employs an LLM to\ngenerate textual reasoning steps and executable Python code for each question.\nDemonstrations are drawn from a memory of training examples that cover various\nSKR tasks, facilitating knowledge transfer. Extensive experiments on four\nbenchmarks involving three SKR tasks demonstrate that \\textsc{Pandora}\noutperforms existing unified frameworks and competes effectively with\ntask-specific methods.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T08:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.12756v1","title":"Ultrafast laser high-aspect-ratio extreme nanostructuring of glass\n  beyond Î»/100","summary":"The ultimate feature size is key in ultrafast laser material processing. A\ncapacity to signiicantly exceed optical limits and to structure below 100nm is\nessential to advance ultrafast processing into the field of metamaterials. Such\nachievement requires to combine the control of optical near-fields and of\nmaterial reactions, while preserving the exibility of long working distances,\ncompatible with a mature laser process. Using sub-ps and ps non-diffractive\nBessel beams, we demonstrate unprecedented feature sizes below a hundredth of\nthe incident 1$\\mu$m wavelength over an extended focus depth of tens of $\\mu$m.\nRecord features sizes, down to 7nm, result from self-generated near-field light\ncomponents initiated by cavities induced by far-field radiation in a\nback-surface illumination geometry. This sustains the generation of more\nconfined near-field evanescent components along the laser scan with nm pitch,\nperpendicular to the incident field direction, driving by local thermal\nablation a super-resolved laser structuring process. The near-field pattern is\nreplicated with high robustness, advancing towards a 10nm nanoscribing tool\nwith a $\\mu$m-sized laser pen. The process is controllable by the field\norientation. The non-diffractive irradiation develops evanescent fields over\nthe focusing length, resulting in a high aspect ratio trenching with nm section\nand $\\mu$m depth. Higher energy doses trigger the self-organization of\nquasi-periodic patterns seeded by spatially modulated scattering, similarly to\noptical modelocking. A predictive multipulse simulation method validates the\nfar-field-induced near-field electromagnetic scenario of void nanochannel\ngrowth and replication, indicating the processing range and resolution on the\nsurface and in the depth.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-17T08:48:58Z"}
{"aid":"http://arxiv.org/abs/2504.12789v1","title":"Enumeration of cube-free groups and counting certain types of split\n  extensions","summary":"A group is said to be cube-free if its order is not divisible by the cube of\nany prime. Let $f_{cf,sol}(n)$ denote the isomorphism classes of solvable\ncube-free groups of order $n$. We find asymptotic bounds for $f_{cf,sol}(n)$ in\nthis paper. Let $p$ be a prime and let $q = p^k$ for some positive integer $k$.\nWe also give a formula for the number of conjugacy classes of the subgroups\nthat are maximal amongst non-abelian solvable cube-free $p'$-subgroups of ${\\rm\nGL}(2,q)$. Further, we find the exact number of split extensions of $P$ by $Q$\nup to isomorphism of a given order where $P \\in \\{{\\mathbb Z}_p \\times {\\mathbb\nZ}_p, {\\mathbb Z}_{p^{\\alpha}}\\}$, $p$ is a prime, $\\alpha$ is a positive\ninteger and $Q$ is a cube-free abelian group of odd order such that $p \\nmid\n|Q|$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-17T09:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.12795v1","title":"EarthGPT-X: Enabling MLLMs to Flexibly and Comprehensively Understand\n  Multi-Source Remote Sensing Imagery","summary":"Recent advances in the visual-language area have developed natural\nmulti-modal large language models (MLLMs) for spatial reasoning through visual\nprompting. However, due to remote sensing (RS) imagery containing abundant\ngeospatial information that differs from natural images, it is challenging to\neffectively adapt natural spatial models to the RS domain. Moreover, current RS\nMLLMs are limited in overly narrow interpretation levels and interaction\nmanner, hindering their applicability in real-world scenarios. To address those\nchallenges, a spatial MLLM named EarthGPT-X is proposed, enabling a\ncomprehensive understanding of multi-source RS imagery, such as optical,\nsynthetic aperture radar (SAR), and infrared. EarthGPT-X offers zoom-in and\nzoom-out insight, and possesses flexible multi-grained interactive abilities.\nMoreover, EarthGPT-X unifies two types of critical spatial tasks (i.e.,\nreferring and grounding) into a visual prompting framework. To achieve these\nversatile capabilities, several key strategies are developed. The first is the\nmulti-modal content integration method, which enhances the interplay between\nimages, visual prompts, and text instructions. Subsequently, a cross-domain\none-stage fusion training strategy is proposed, utilizing the large language\nmodel (LLM) as a unified interface for multi-source multi-task learning.\nFurthermore, by incorporating a pixel perception module, the referring and\ngrounding tasks are seamlessly unified within a single framework. In addition,\nthe experiments conducted demonstrate the superiority of the proposed\nEarthGPT-X in multi-grained tasks and its impressive flexibility in multi-modal\ninteraction, revealing significant advancements of MLLM in the RS field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T09:56:35Z"}
{"aid":"http://arxiv.org/abs/2504.12796v1","title":"A Survey on Cross-Modal Interaction Between Music and Multimodal Data","summary":"Multimodal learning has driven innovation across various industries,\nparticularly in the field of music. By enabling more intuitive interaction\nexperiences and enhancing immersion, it not only lowers the entry barriers to\nthe music but also increases its overall appeal. This survey aims to provide a\ncomprehensive review of multimodal tasks related to music, outlining how music\ncontributes to multimodal learning and offering insights for researchers\nseeking to expand the boundaries of computational music. Unlike text and\nimages, which are often semantically or visually intuitive, music primarily\ninteracts with humans through auditory perception, making its data\nrepresentation inherently less intuitive. Therefore, this paper first\nintroduces the representations of music and provides an overview of music\ndatasets. Subsequently, we categorize cross-modal interactions between music\nand multimodal data into three types: music-driven cross-modal interactions,\nmusic-oriented cross-modal interactions, and bidirectional music cross-modal\ninteractions. For each category, we systematically trace the development of\nrelevant sub-tasks, analyze existing limitations, and discuss emerging trends.\nFurthermore, we provide a comprehensive summary of datasets and evaluation\nmetrics used in multimodal tasks related to music, offering benchmark\nreferences for future research. Finally, we discuss the current challenges in\ncross-modal interactions involving music and propose potential directions for\nfuture research.","main_category":"cs.MM","categories":"cs.MM,cs.SD,eess.AS","published":"2025-04-17T09:58:38Z"}
{"aid":"http://arxiv.org/abs/2504.12850v1","title":"iHHO-SMOTe: A Cleansed Approach for Handling Outliers and Reducing Noise\n  to Improve Imbalanced Data Classification","summary":"Classifying imbalanced datasets remains a significant challenge in machine\nlearning, particularly with big data where instances are unevenly distributed\namong classes, leading to class imbalance issues that impact classifier\nperformance. While Synthetic Minority Over-sampling Technique (SMOTE) addresses\nthis challenge by generating new instances for the under-represented minority\nclass, it faces obstacles in the form of noise and outliers during the creation\nof new samples. In this paper, a proposed approach, iHHO-SMOTe, which addresses\nthe limitations of SMOTE by first cleansing the data from noise points. This\nprocess involves employing feature selection using a random forest to identify\nthe most valuable features, followed by applying the Density-Based Spatial\nClustering of Applications with Noise (DBSCAN) algorithm to detect outliers\nbased on the selected features. The identified outliers from the minority\nclasses are then removed, creating a refined dataset for subsequent\noversampling using the hybrid approach called iHHO-SMOTe. The comprehensive\nexperiments across diverse datasets demonstrate the exceptional performance of\nthe proposed model, with an AUC score exceeding 0.99, a high G-means score of\n0.99 highlighting its robustness, and an outstanding F1-score consistently\nexceeding 0.967. These findings collectively establish Cleansed iHHO-SMOTe as a\nformidable contender in addressing imbalanced datasets, focusing on noise\nreduction and outlier handling for improved classification models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T11:17:53Z"}
{"aid":"http://arxiv.org/abs/2504.12856v1","title":"3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise","summary":"Large pretrained vision foundation models have shown significant potential in\nvarious vision tasks. However, for industrial anomaly detection, the scarcity\nof real defect samples poses a critical challenge in leveraging these models.\nWhile 2D anomaly generation has significantly advanced with established\ngenerative models, the adoption of 3D sensors in industrial manufacturing has\nmade leveraging 3D data for surface quality inspection an emerging trend. In\ncontrast to 2D techniques, 3D anomaly generation remains largely unexplored,\nlimiting the potential of 3D data in industrial quality inspection. To address\nthis gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS,\nbased on Perlin noise and surface parameterization. Our method generates\nrealistic 3D surface anomalies by projecting the point cloud onto a 2D plane,\nsampling multi-scale noise values from a Perlin noise field, and perturbing the\npoint cloud along its normal direction. Through comprehensive visualization\nexperiments, we demonstrate how key parameters - including noise scale,\nperturbation strength, and octaves, provide fine-grained control over the\ngenerated anomalies, enabling the creation of diverse defect patterns from\npronounced deformations to subtle surface variations. Additionally, our\ncross-category experiments show that the method produces consistent yet\ngeometrically plausible anomalies across different object types, adapting to\ntheir specific surface characteristics. We also provide a comprehensive\ncodebase and visualization toolkit to facilitate future research.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG,cs.RO,I.5.4","published":"2025-04-17T11:23:17Z"}
{"aid":"http://arxiv.org/abs/2504.12860v1","title":"When do Random Forests work?","summary":"We study the effectiveness of randomizing split-directions in random forests.\nPrior literature has shown that, on the one hand, randomization can reduce\nvariance through decorrelation, and, on the other hand, randomization\nregularizes and works in low signal-to-noise ratio (SNR) environments. First,\nwe bring together and revisit decorrelation and regularization by presenting a\nsystematic analysis of out-of-sample mean-squared error (MSE) for different SNR\nscenarios based on commonly-used data-generating processes. We find that\nvariance reduction tends to increase with the SNR and forests outperform\nbagging when the SNR is low because, in low SNR cases, variance dominates bias\nfor both methods. Second, we show that the effectiveness of randomization is a\nquestion that goes beyond the SNR. We present a simulation study with fixed and\nmoderate SNR, in which we examine the effectiveness of randomization for other\ndata characteristics. In particular, we find that (i) randomization can\nincrease bias in the presence of fat tails in the distribution of covariates;\n(ii) in the presence of irrelevant covariates randomization is ineffective\nbecause bias dominates variance; and (iii) when covariates are mutually\ncorrelated randomization tends to be effective because variance dominates bias.\nBeyond randomization, we find that, for both bagging and random forests, bias\ncan be significantly reduced in the presence of correlated covariates. This\nlast finding goes beyond the prevailing view that averaging mostly works by\nvariance reduction. Given that in practice covariates are often correlated, our\nfindings on correlated covariates could open the way for a better understanding\nof why random forests work well in many applications.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-17T11:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.12878v1","title":"Frustrated kagome-lattice bilayer quantum Heisenberg antiferromagnet","summary":"We consider the $S=1/2$ antiferromagnetic Heisenberg model on a frustrated\nkagome-lattice bilayer with strong nearest-neighbor interlayer coupling and\nexamine its low-temperature magnetothermodynamics using a mapping onto a rhombi\ngas on the kagome lattice. Besides, we use finite-size numerics to illustrate\nthe validity of the classical lattice-gas description. Among our findings there\nare i) the absence of an order-disorder phase transition and ii) the\nsensitivity of the specific heat at low temperatures to the shape of the system\njust below the saturation magnetic field even in the thermodynamic limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-17T12:08:42Z"}
{"aid":"http://arxiv.org/abs/2504.12897v1","title":"OntoPortal-Astro, a Semantic Artefact Catalogue for Astronomy","summary":"The astronomy communities are widely recognised as mature communities for\ntheir open science practices. However, while their data ecosystems are rather\nadvanced and permit efficient data interoperability, there are still gaps\nbetween these ecosystems. Semantic artefacts (e.g., ontologies, thesauri,\nvocabularies or metadata schemas) are a means to bridge that gap as they allow\nto semantically described the data and map the underlying concepts. The\nincreasing use of semantic artefacts in astronomy presents challenges in\ndescription, selection, evaluation, trust, and mappings. The landscape remains\nfragmented, with semantic artefacts scattered across various registries in\ndiverse formats and structures -- not yet fully developed or encoded with rich\nsemantic web standards like OWL or SKOS -- and often with overlapping scopes.\nEnhancing data semantic interoperability requires common platforms to catalog,\nalign, and facilitate the sharing of FAIR semantic artefacts. In the frame of\nthe FAIR-IMPACT project, we prototyped a semantic artefact catalogue for\nastronomy, heliophysics and planetary sciences. This exercise resulted in\nimproved vocabulary and ontology management in the communities, and is now\npaving the way for better interdisciplinary data discovery and reuse. This\narticle presents current practices in our discipline, reviews candidate SAs for\nsuch a catalogue, presents driving use cases and the perspective of a real\nproduction service for the astronomy community based on the OntoPortal\ntechnology, that will be called OntoPortal-Astro.","main_category":"astro-ph.IM","categories":"astro-ph.IM,cs.DL","published":"2025-04-17T12:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.12911v1","title":"Benchmarking Multi-National Value Alignment for Large Language Models","summary":"Do Large Language Models (LLMs) hold positions that conflict with your\ncountry's values? Occasionally they do! However, existing works primarily focus\non ethical reviews, failing to capture the diversity of national values, which\nencompass broader policy, legal, and moral considerations. Furthermore, current\nbenchmarks that rely on spectrum tests using manually designed questionnaires\nare not easily scalable.\n  To address these limitations, we introduce NaVAB, a comprehensive benchmark\nto evaluate the alignment of LLMs with the values of five major nations: China,\nthe United States, the United Kingdom, France, and Germany. NaVAB implements a\nnational value extraction pipeline to efficiently construct value assessment\ndatasets. Specifically, we propose a modeling procedure with instruction\ntagging to process raw data sources, a screening process to filter\nvalue-related topics and a generation process with a Conflict Reduction\nmechanism to filter non-conflicting values.We conduct extensive experiments on\nvarious LLMs across countries, and the results provide insights into assisting\nin the identification of misaligned scenarios. Moreover, we demonstrate that\nNaVAB can be combined with alignment techniques to effectively reduce value\nconcerns by aligning LLMs' values with the target country.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T13:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.12920v1","title":"CSMF: Cascaded Selective Mask Fine-Tuning for Multi-Objective\n  Embedding-Based Retrieval","summary":"Multi-objective embedding-based retrieval (EBR) has become increasingly\ncritical due to the growing complexity of user behaviors and commercial\nobjectives. While traditional approaches often suffer from data sparsity and\nlimited information sharing between objectives, recent methods utilizing a\nshared network alongside dedicated sub-networks for each objective partially\naddress these limitations. However, such methods significantly increase the\nmodel parameters, leading to an increased retrieval latency and a limited\nability to model causal relationships between objectives. To address these\nchallenges, we propose the Cascaded Selective Mask Fine-Tuning (CSMF), a novel\nmethod that enhances both retrieval efficiency and serving performance for\nmulti-objective EBR. The CSMF framework selectively masks model parameters to\nfree up independent learning space for each objective, leveraging the cascading\nrelationships between objectives during the sequential fine-tuning. Without\nincreasing network parameters or online retrieval overhead, CSMF computes a\nlinearly weighted fusion score for multiple objective probabilities while\nsupporting flexible adjustment of each objective's weight across various\nrecommendation scenarios. Experimental results on real-world datasets\ndemonstrate the superior performance of CSMF, and online experiments validate\nits significant practical value.","main_category":"cs.IR","categories":"cs.IR,H.3.3","published":"2025-04-17T13:10:56Z"}
{"aid":"http://arxiv.org/abs/2504.12956v1","title":"Optic Fingerprint(OFP): Enhancing Security in Li-Fi Networks","summary":"We present a hardware-integrated security framework for LiFi networks through\ndevice fingerprint extraction within the IEEE 802.15.7 protocol. Our Optic\nFingerprint (OFP) model utilizes inherent LED nonlinearities to generate\namplitude-based feature vectors in time and frequency domains, specifically\ndesigned for optical wireless systems. Experimental results with 39 commercial\nLEDs demonstrate 90.36% classification accuracy across SNR 10-30 dB while\nmaintaining standard compliance, offering a practical physical-layer\nauthentication solution for visible light communication.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T14:01:02Z"}
{"aid":"http://arxiv.org/abs/2504.12971v1","title":"Transferrable Surrogates in Expressive Neural Architecture Search Spaces","summary":"Neural architecture search (NAS) faces a challenge in balancing the\nexploration of expressive, broad search spaces that enable architectural\ninnovation with the need for efficient evaluation of architectures to\neffectively search such spaces. We investigate surrogate model training for\nimproving search in highly expressive NAS search spaces based on context-free\ngrammars. We show that i) surrogate models trained either using zero-cost-proxy\nmetrics and neural graph features (GRAF) or by fine-tuning an off-the-shelf LM\nhave high predictive power for the performance of architectures both within and\nacross datasets, ii) these surrogates can be used to filter out bad\narchitectures when searching on novel datasets, thereby significantly speeding\nup search and achieving better final performances, and iii) the surrogates can\nbe further used directly as the search objective for huge speed-ups.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-17T14:22:28Z"}
{"aid":"http://arxiv.org/abs/2504.12981v1","title":"Efficient Chebyshev Reconstruction for the Anisotropic Equilibrium Model\n  in Magnetic Particle Imaging","summary":"Magnetic Particle Imaging (MPI) is a tomographic imaging modality capable of\nreal-time, high-sensitivity mapping of superparamagnetic iron oxide\nnanoparticles. Model-based image reconstruction provides an alternative to\nconventional methods that rely on a measured system matrix, eliminating the\nneed for laborious calibration measurements. Nevertheless, model-based\napproaches must account for the complexities of the imaging chain to maintain\nhigh image quality. A recently proposed direct reconstruction method leverages\nweighted Chebyshev polynomials in the frequency domain, removing the need for a\nsimulated system matrix. However, the underlying model neglects key physical\neffects, such as nanoparticle anisotropy, leading to distortions in\nreconstructed images. To mitigate these artifacts, an adapted direct Chebyshev\nreconstruction (DCR) method incorporates a spatially variant deconvolution\nstep, significantly improving reconstruction accuracy at the cost of increased\ncomputational demands. In this work, we evaluate the adapted DCR on six\nexperimental phantoms, demonstrating enhanced reconstruction quality in real\nmeasurements and achieving image fidelity comparable to or exceeding that of\nsimulated system matrix reconstruction. Furthermore, we introduce an efficient\napproximation for the spatially variable deconvolution, reducing both runtime\nand memory consumption while maintaining accuracy. This method achieves\ncomputational complexity of O(N log N ), making it particularly beneficial for\nhigh-resolution and three-dimensional imaging. Our results highlight the\npotential of the adapted DCR approach for improving model-based MPI\nreconstruction in practical applications.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.NA,eess.IV,math.NA","published":"2025-04-17T14:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.12988v1","title":"Why Ask One When You Can Ask $k$? Two-Stage Learning-to-Defer to a Set\n  of Experts","summary":"Learning-to-Defer (L2D) enables decision-making systems to improve\nreliability by selectively deferring uncertain predictions to more competent\nagents. However, most existing approaches focus exclusively on single-agent\ndeferral, which is often inadequate in high-stakes scenarios that require\ncollective expertise. We propose Top-$k$ Learning-to-Defer, a generalization of\nthe classical two-stage L2D framework that allocates each query to the $k$ most\nconfident agents instead of a single one. To further enhance flexibility and\ncost-efficiency, we introduce Top-$k(x)$ Learning-to-Defer, an adaptive\nextension that learns the optimal number of agents to consult for each query,\nbased on input complexity, agent competency distributions, and consultation\ncosts. For both settings, we derive a novel surrogate loss and prove that it is\nBayes-consistent and $(\\mathcal{R}, \\mathcal{G})$-consistent, ensuring\nconvergence to the Bayes-optimal allocation. Notably, we show that the\nwell-established model cascades paradigm arises as a restricted instance of our\nTop-$k$ and Top-$k(x)$ formulations. Extensive experiments across diverse\nbenchmarks demonstrate the effectiveness of our framework on both\nclassification and regression tasks.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-17T14:50:40Z"}
{"aid":"http://arxiv.org/abs/2504.12989v1","title":"Query Complexity of Classical and Quantum Channel Discrimination","summary":"Quantum channel discrimination has been studied from an information-theoretic\nperspective, wherein one is interested in the optimal decay rate of error\nprobabilities as a function of the number of unknown channel accesses. In this\npaper, we study the query complexity of quantum channel discrimination, wherein\nthe goal is to determine the minimum number of channel uses needed to reach a\ndesired error probability. To this end, we show that the query complexity of\nbinary channel discrimination depends logarithmically on the inverse error\nprobability and inversely on the negative logarithm of the (geometric and\nHolevo) channel fidelity. As a special case of these findings, we precisely\ncharacterize the query complexity of discriminating between two classical\nchannels. We also provide lower and upper bounds on the query complexity of\nbinary asymmetric channel discrimination and multiple quantum channel\ndiscrimination. For the former, the query complexity depends on the geometric\nR\\'enyi and Petz R\\'enyi channel divergences, while for the latter, it depends\non the negative logarithm of (geometric and Uhlmann) channel fidelity. For\nmultiple channel discrimination, the upper bound scales as the logarithm of the\nnumber of channels.","main_category":"quant-ph","categories":"quant-ph,cs.IT,cs.LG,math.IT,math.ST,stat.TH","published":"2025-04-17T14:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.12990v1","title":"Maximum Information Extraction From Noisy Data Via Shannon Entropy\n  Minimization","summary":"Granting maximum information extraction in the analysis of noisy data is\nnon-trivial. We introduce a general, data-driven approach that employs Shannon\nentropy as a transferable metric to quantify the maximum information\nextractable from noisy data via their clustering into statistically-relevant\nmicro-domains. We demonstrate the method's efficiency by analyzing, as a\nrepresentative example, time-series data extracted from molecular dynamics\nsimulations of water and ice coexisting at the solid/liquid transition\ntemperature. The method allows quantifying the information contained in the\ndata distributions (time-independent component) and the additional information\ngain attainable by analyzing data as time-series (i.e., accounting for the\ninformation contained in data time-correlations). The approach is also highly\neffective for high-dimensional datasets, providing clear demonstrations of how\nconsidering components/data that may be little informative but noisy may be not\nonly useless but even detrimental to maximum information extraction. This\nprovides a general and robust parameter-free approach and quantitative metrics\nfor data-analysis, and for the study of any type of system from its data.","main_category":"physics.data-an","categories":"physics.data-an","published":"2025-04-17T14:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.12996v1","title":"SHA256 at SemEval-2025 Task 4: Selective Amnesia -- Constrained\n  Unlearning for Large Language Models via Knowledge Isolation","summary":"Large language models (LLMs) frequently memorize sensitive information during\ntraining, posing risks when deploying publicly accessible models. Current\nmachine unlearning methods struggle to selectively remove specific data\nassociations without degrading overall model capabilities. This paper presents\nour solution to SemEval-2025 Task 4 on targeted unlearning, which introduces a\ntwo-stage methodology that combines causal mediation analysis with\nlayer-specific optimization. Through systematic causal tracing experiments on\nOLMo architectures (1B and 7B parameters), we identify the critical role of the\nfirst few transformer layers (layers 0-5) in storing subject-attribute\nassociations within MLP modules. Building on this insight, we develop a\nconstrained optimization approach that freezes upper layers while applying a\nnovel joint loss function to lower layers-simultaneously maximizing forget set\nloss via output token cross-entropy penalties and minimizing retain set\ndeviation through adaptive regularization. Our method achieves 2nd place in the\n1B model track, demonstrating strong task performance while maintaining 88% of\nbaseline MMLU accuracy. These results establish causal-informed layer\noptimization as a promising paradigm for efficient, precise unlearning in LLMs,\noffering a significant step forward in addressing data privacy concerns in AI\nsystems.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T15:05:40Z"}
{"aid":"http://arxiv.org/abs/2504.13015v1","title":"Hierarchical Feature Learning for Medical Point Clouds via State Space\n  Model","summary":"Deep learning-based point cloud modeling has been widely investigated as an\nindispensable component of general shape analysis. Recently, transformer and\nstate space model (SSM) have shown promising capacities in point cloud\nlearning. However, limited research has been conducted on medical point clouds,\nwhich have great potential in disease diagnosis and treatment. This paper\npresents an SSM-based hierarchical feature learning framework for medical point\ncloud understanding. Specifically, we down-sample input into multiple levels\nthrough the farthest point sampling. At each level, we perform a series of\nk-nearest neighbor (KNN) queries to aggregate multi-scale structural\ninformation. To assist SSM in processing point clouds, we introduce\ncoordinate-order and inside-out scanning strategies for efficient serialization\nof irregular points. Point features are calculated progressively from short\nneighbor sequences and long point sequences through vanilla and group Point SSM\nblocks, to capture both local patterns and long-range dependencies. To evaluate\nthe proposed method, we build a large-scale medical point cloud dataset named\nMedPointS for anatomy classification, completion, and segmentation. Extensive\nexperiments conducted on MedPointS demonstrate that our method achieves\nsuperior performance across all tasks. The dataset is available at\nhttps://flemme-docs.readthedocs.io/en/latest/medpoints.html. Code is merged to\na public medical imaging platform: https://github.com/wlsdzyzl/flemme.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:22:31Z"}
{"aid":"http://arxiv.org/abs/2504.13026v1","title":"TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for\n  Remote Sensing Image Super-Resolution","summary":"Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution\n(HR) remote sensing images from low-resolution inputs to support fine-grained\nground object interpretation. Existing methods face three key challenges: (1)\nDifficulty in extracting multi-scale features from spatially heterogeneous RS\nscenes, (2) Limited prior information causing semantic inconsistency in\nreconstructions, and (3) Trade-off imbalance between geometric accuracy and\nvisual quality. To address these issues, we propose the Texture Transfer\nResidual Denoising Dual Diffusion Model (TTRD3) with three innovations: First,\na Multi-scale Feature Aggregation Block (MFAB) employing parallel heterogeneous\nconvolutional kernels for multi-scale feature extraction. Second, a Sparse\nTexture Transfer Guidance (STTG) module that transfers HR texture priors from\nreference images of similar scenes. Third, a Residual Denoising Dual Diffusion\nModel (RDDM) framework combining residual diffusion for deterministic\nreconstruction and noise diffusion for diverse generation. Experiments on\nmulti-source RS datasets demonstrate TTRD3's superiority over state-of-the-art\nmethods, achieving 1.43% LPIPS improvement and 3.67% FID enhancement compared\nto best-performing baselines. Code/model: https://github.com/LED-666/TTRD3.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:37:13Z"}
{"aid":"http://arxiv.org/abs/2504.13028v1","title":"Profinite Iterated Monodromy Groups of Unicritical Polynomials","summary":"Let $f(x) = ax^d + b \\in K[x]$ be a unicritical polynomial with degree $d\n\\geq 2$ which is coprime to $\\mathrm{char} K$. We provide an explicit\npresentation for the profinite iterated monodromy group of $f$, analyze the\nstructure of this group, and use this analysis to determine the constant field\nextension in $K(f^{-\\infty}(t))/K(t)$.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-17T15:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.13047v1","title":"Observation of quantum entanglement between free electrons and photons","summary":"Quantum entanglement is central to both the foundations of quantum mechanics\nand the development of new technologies in information processing,\ncommunication, and sensing. Entanglement has been realised in a variety of\nphysical systems, spanning atoms, ions, photons, collective excitations, and\nhybrid combinations of particles. Remarkably, however, photons and free\nelectrons -- the quanta of light and their most elementary sources -- have\nnever been observed in an entangled state. Here, we demonstrate quantum\nentanglement between free electrons and photons. We show that entanglement is\nproduced when an electron, prepared in a superposition of two beams, passes a\nnanostructure and generates transition radiation in a polarisation state tied\nto the electron path. By implementing quantum state tomography, we reconstruct\nthe full density matrix of the electron-photon pair, and show that the\nPeres-Horodecki separability criterion is violated by more than 7 standard\ndeviations. Based on this foundational element of emerging free-electron\nquantum optics, we anticipate manifold developments in enhanced electron\nimaging and spectroscopy beyond the standard quantum limit. More broadly, the\nability to generate and measure entanglement opens electron microscopy to\npreviously inaccessible quantum observables and correlations in solids and\nnanostructures.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T16:03:05Z"}
{"aid":"http://arxiv.org/abs/2504.13066v1","title":"Some spherical function values for two-row tableaux and Young subgroups\n  with three factors","summary":"A Young subgroup of the symmetric group $\\mathcal{S}_{N}$ with three factors,\nis realized as the stabilizer $G_{n}$ of a monomial $x^{\\lambda}$ (\n$=x_{1}^{\\lambda_{1}}x_{2}^{\\lambda_{2}}\\cdots x_{N}^{\\lambda_{N}}$) with\n$\\lambda=\\left( d_{1}^{n_{1}},d_{2}^{n_{2}},d_{3}^{n_{3}}\\right) $ (meaning\n$d_{j}$ is repeated $n_{j}$ times, $1\\leq j\\leq3$), thus is isomorphic to the\ndirect product $\\mathcal{S}_{n_{1}}\\times\\mathcal{S}_{n_{2}}\\times\n\\mathcal{S}_{n_{3}}$. The orbit of $x^{\\lambda}$ under the action of\n$\\mathcal{S}_{N}$ (by permutation of coordinates) spans a module $V_{\\lambda}%\n$, the representation induced from the identity representation of $G_{n}$. The\nspace $V_{\\lambda}$ decomposes into a direct sum of irreducible $\\mathcal{S}%\n_{N}$-modules. The spherical function is defined for each of these, it is the\ncharacter of the module averaged over the group $G_{n}$. This paper concerns\nthe value of certain spherical functions evaluated at a cycle which has no more\nthan one entry in each of the three intervals $I_{j}=\\left\\{\ni:\\lambda_{i}=d_{j}\\right\\} ,1\\leq j\\leq3$. These values appear in the study of\neigenvalues of the Heckman-Polychronakos operators in the paper by V. Gorin and\nthe author (arXiv:2412:01938v1). The present paper determines the spherical\nfunction values for $\\mathcal{S}_{N}$-modules $V$ of two-row tableau type,\ncorresponding to Young tableaux of shape $\\left[ N-k,k\\right] $. The method is\nbased on analyzing the effect of a cycle on $G_{n}$-invariant elements of $V$.\nThese are constructed in terms of Hahn polynomials in two variables.","main_category":"math.RT","categories":"math.RT,math.CA","published":"2025-04-17T16:20:29Z"}
{"aid":"http://arxiv.org/abs/2504.13078v1","title":"Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual\n  Try-Off","summary":"Computer vision is transforming fashion through Virtual Try-On (VTON) and\nVirtual Try-Off (VTOFF). VTON generates images of a person in a specified\ngarment using a target photo and a standardized garment image, while a more\nchallenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo\nof another person wearing the garment. VTOFF, on the other hand, extracts\nstandardized garment images from clothed individuals. We introduce TryOffDiff,\na diffusion-based VTOFF model. Built on a latent diffusion framework with\nSigLIP image conditioning, it effectively captures garment properties like\ntexture, shape, and patterns. TryOffDiff achieves state-of-the-art results on\nVITON-HD and strong performance on DressCode dataset, covering upper-body,\nlower-body, and dresses. Enhanced with class-specific embeddings, it pioneers\nmulti-garment VTOFF, the first of its kind. When paired with VTON models, it\nimproves p2p-VTON by minimizing unwanted attribute transfer, such as skin\ncolor. Code is available at: https://rizavelioglu.github.io/tryoffdiff/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T16:45:18Z"}
{"aid":"http://arxiv.org/abs/2504.13138v1","title":"Extending the Mott-Gurney law to one-dimensional nonplanar diodes using\n  point transformations","summary":"Recent studies have applied variational calculus, conformal mapping, and\npoint transformations to generalize the one-dimensional (1D) space-charge\nlimited current density (SCLCD) and electron emission mechanisms to nonplanar\ngeometries; however, these assessments have focused on extending the\nChild-Langmuir law (CLL) for SCLCD in vacuum. Since the charge in the diode is\nindependent of coordinate system (i.e., covariant), we apply bijective point\ntransformations to extend the Mott-Gurney law (MGL) for the SCLCD in a\ncollisional or semiconductor gap to nonplanar 1D geometries. This yields a\nmodified MGL that replaces the Cartesian gap distance with a canonical gap\ndistance that may be written generally in terms of geometric scale factors that\nare known for multiple geometries. We tabulate results for common geometries.\nSuch an approach may be applied to any current density, including\nnon-space-charge limited gaps and SCLCD that may fall between the CLL and MGL.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.plasm-ph","published":"2025-04-17T17:49:06Z"}
{"aid":"http://arxiv.org/abs/2504.13143v1","title":"$\\texttt{Complex-Edit}$: CoT-Like Instruction Generation for\n  Complexity-Controllable Image Editing Benchmark","summary":"We introduce $\\texttt{Complex-Edit}$, a comprehensive benchmark designed to\nsystematically evaluate instruction-based image editing models across\ninstructions of varying complexity. To develop this benchmark, we harness\nGPT-4o to automatically collect a diverse set of editing instructions at scale.\nOur approach follows a well-structured ``Chain-of-Edit'' pipeline: we first\ngenerate individual atomic editing tasks independently and then integrate them\nto form cohesive, complex instructions. Additionally, we introduce a suite of\nmetrics to assess various aspects of editing performance, along with a\nVLM-based auto-evaluation pipeline that supports large-scale assessments. Our\nbenchmark yields several notable insights: 1) Open-source models significantly\nunderperform relative to proprietary, closed-source models, with the\nperformance gap widening as instruction complexity increases; 2) Increased\ninstructional complexity primarily impairs the models' ability to retain key\nelements from the input images and to preserve the overall aesthetic quality;\n3) Decomposing a complex instruction into a sequence of atomic steps, executed\nin a step-by-step manner, substantially degrades performance across multiple\nmetrics; 4) A straightforward Best-of-N selection strategy improves results for\nboth direct editing and the step-by-step sequential approach; and 5) We observe\na ``curse of synthetic data'': when synthetic data is involved in model\ntraining, the edited images from such models tend to appear increasingly\nsynthetic as the complexity of the editing instructions rises -- a phenomenon\nthat intriguingly also manifests in the latest GPT-4o outputs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T17:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.13157v1","title":"AerialMegaDepth: Learning Aerial-Ground Reconstruction and View\n  Synthesis","summary":"We explore the task of geometric reconstruction of images captured from a\nmixture of ground and aerial views. Current state-of-the-art learning-based\napproaches fail to handle the extreme viewpoint variation between aerial-ground\nimage pairs. Our hypothesis is that the lack of high-quality, co-registered\naerial-ground datasets for training is a key reason for this failure. Such data\nis difficult to assemble precisely because it is difficult to reconstruct in a\nscalable way. To overcome this challenge, we propose a scalable framework\ncombining pseudo-synthetic renderings from 3D city-wide meshes (e.g., Google\nEarth) with real, ground-level crowd-sourced images (e.g., MegaDepth). The\npseudo-synthetic data simulates a wide range of aerial viewpoints, while the\nreal, crowd-sourced images help improve visual fidelity for ground-level images\nwhere mesh-based renderings lack sufficient detail, effectively bridging the\ndomain gap between real images and pseudo-synthetic renderings. Using this\nhybrid dataset, we fine-tune several state-of-the-art algorithms and achieve\nsignificant improvements on real-world, zero-shot aerial-ground tasks. For\nexample, we observe that baseline DUSt3R localizes fewer than 5% of\naerial-ground pairs within 5 degrees of camera rotation error, while\nfine-tuning with our data raises accuracy to nearly 56%, addressing a major\nfailure point in handling large viewpoint changes. Beyond camera estimation and\nscene reconstruction, our dataset also improves performance on downstream tasks\nlike novel-view synthesis in challenging aerial-ground scenarios, demonstrating\nthe practical value of our approach in real-world applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:57:05Z"}
{"aid":"http://arxiv.org/abs/2504.13172v1","title":"SemCORE: A Semantic-Enhanced Generative Cross-Modal Retrieval Framework\n  with MLLMs","summary":"Cross-modal retrieval (CMR) is a fundamental task in multimedia research,\nfocused on retrieving semantically relevant targets across different\nmodalities. While traditional CMR methods match text and image via\nembedding-based similarity calculations, recent advancements in pre-trained\ngenerative models have established generative retrieval as a promising\nalternative. This paradigm assigns each target a unique identifier and\nleverages a generative model to directly predict identifiers corresponding to\ninput queries without explicit indexing. Despite its great potential, current\ngenerative CMR approaches still face semantic information insufficiency in both\nidentifier construction and generation processes. To address these limitations,\nwe propose a novel unified Semantic-enhanced generative Cross-mOdal REtrieval\nframework (SemCORE), designed to unleash the semantic understanding\ncapabilities in generative cross-modal retrieval task. Specifically, we first\nconstruct a Structured natural language IDentifier (SID) that effectively\naligns target identifiers with generative models optimized for natural language\ncomprehension and generation. Furthermore, we introduce a Generative Semantic\nVerification (GSV) strategy enabling fine-grained target discrimination.\nAdditionally, to the best of our knowledge, SemCORE is the first framework to\nsimultaneously consider both text-to-image and image-to-text retrieval tasks\nwithin generative cross-modal retrieval. Extensive experiments demonstrate that\nour framework outperforms state-of-the-art generative cross-modal retrieval\nmethods. Notably, SemCORE achieves substantial improvements across benchmark\ndatasets, with an average increase of 8.65 points in Recall@1 for text-to-image\nretrieval.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.MM","published":"2025-04-17T17:59:27Z"}
{"aid":"http://arxiv.org/abs/2504.14833v1","title":"IoT-AMLHP: Aligned Multimodal Learning of Header-Payload Representations\n  for Resource-Efficient Malicious IoT Traffic Classification","summary":"Traffic classification is crucial for securing Internet of Things (IoT)\nnetworks. Deep learning-based methods can autonomously extract latent patterns\nfrom massive network traffic, demonstrating significant potential for IoT\ntraffic classification tasks. However, the limited computational and spatial\nresources of IoT devices pose challenges for deploying more complex deep\nlearning models. Existing methods rely heavily on either flow-level features or\nraw packet byte features. Flow-level features often require inspecting entire\nor most of the traffic flow, leading to excessive resource consumption, while\nraw packet byte features fail to distinguish between headers and payloads,\noverlooking semantic differences and introducing noise from feature\nmisalignment. Therefore, this paper proposes IoT-AMLHP, an aligned multimodal\nlearning framework for resource-efficient malicious IoT traffic classification.\nFirstly, the framework constructs a packet-wise header-payload representation\nby parsing packet headers and payload bytes, resulting in an aligned and\nstandardized multimodal traffic representation that enhances the\ncharacterization of heterogeneous IoT traffic. Subsequently, the traffic\nrepresentation is fed into a resource-efficient neural network comprising a\nmultimodal feature extraction module and a multimodal fusion module. The\nextraction module employs efficient depthwise separable convolutions to capture\nmulti-scale features from different modalities while maintaining a lightweight\narchitecture. The fusion module adaptively captures complementary features from\ndifferent modalities and effectively fuses multimodal features.","main_category":"cs.NI","categories":"cs.NI,cs.CR","published":"2025-04-21T03:24:14Z"}
{"aid":"http://arxiv.org/abs/2504.14836v1","title":"Systematic search for blue hyper-velocity stars from LAMOST survey","summary":"Hypervelocity stars (HVSs) represent a unique class of objects capable of\nescaping the gravitational pull of the Milky Way due to extreme acceleration\nevents, such as close encounters with the supermassive black hole at the\nGalactic center (GC), supernova explosions in binary systems, or multi-body\ndynamical interactions. Finding and studying HVSs are crucial to exploring\nthese ejection mechanisms, characterizing central black holes, probing the GC\nenvironment, and revealing the distribution of dark matter in our galaxy. The\nLarge Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST)\nspectroscopic surveys have so far identified four B-type unbound HVSs. To\nexpand this sample with the second-phase LAMOST survey that started in 2018, we\nconducted a systematic search for early-type HVSs using the LAMOST Data Release\n10. We identified 125 early-type high-velocity candidates with total velocities\nexceeding 300 km\\,s$^{-1}$. Among them, we report ten new unbound B- and A-type\nhypervelocity star (HVS) candidates (designated LAMOST-HVS5 through\nLAMOST-HVS14), tripling the number of unbound HVSs previously identified by\nLAMOST. Kinematic analyses suggest that these newly discovered HVS candidates\nlikely originated either from the Galactic Center or via dynamical\ninteractions. Future high-resolution follow-up observations promise to refine\nthe stellar parameters, distances, and elemental abundances of these\ncandidates, thereby providing deeper insights into their origins and broadening\ntheir potential applications across astrophysics.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-21T03:34:00Z"}
{"aid":"http://arxiv.org/abs/2504.14840v1","title":"Spectral Properties of the Gramian of Finite Ultrametric Spaces","summary":"The concept of $p$-negative type is such that a metric space $(X,d_{X})$ has\n$p$-negative type if and only if $(X,d_{X}^{p/2})$ embeds isometrically into a\nHilbert space. If $X=\\{x_{0},x_{1},\\dots,x_{n}\\}$ then the $p$-negative type of\n$X$ is intimately related to the Gramian matrix $G_{p}=(g_{ij})_{i,j=1}^{n}$\nwhere\n$g_{ij}=\\frac{1}{2}(d_{X}(x_{i},x_{0})^{p}+d_{X}(x_{j},x_{0})^{p}-d_{X}(x_{i},x_{j})^{p})$.\nIn particular, $X$ has strict $p$-negative type if and only if $G_{p}$ is\nstrictly positive semidefinite. As such, a natural measure of the degree of\nstrictness of $p$-negative type that $X$ possesses is the minimum eigenvalue of\nthe Gramian $\\lambda_{min}(G_{p})$. In this article we compute the minimum\neigenvalue of the Gramian of a finite ultrametric space. Namely, if $X$ is a\nfinite ultrametric space with minimum nonzero distance $\\alpha_{1}$ then we\nshow that $\\lambda_{min}(G_{p})=\\alpha_{1}^{p}/2$. We also provide a\ndescription of the corresponding eigenspace.","main_category":"math.FA","categories":"math.FA","published":"2025-04-21T03:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.14858v1","title":"AlignRAG: An Adaptable Framework for Resolving Misalignments in\n  Retrieval-Aware Reasoning of RAG","summary":"Retrieval-augmented generation (RAG) has emerged as a foundational paradigm\nfor knowledge-grounded text generation. However, existing RAG pipelines often\nfail to ensure that the reasoning trajectories align with the evidential\nconstraints imposed by retrieved content. In this paper, we reframe RAG as a\nproblem of retrieval-aware reasoning and identify a core challenge: reasoning\nmisalignment-the mismatch between a model's reasoning trajectory and the\nretrieved evidence. To address this challenge, we propose AlignRAG, a novel\ntest-time framework that mitigates reasoning misalignment through iterative\nCritique-Driven Alignment (CDA) steps. In contrast to prior approaches that\nrely on static training or post-hoc selection, AlignRAG actively refines\nreasoning trajectories during inference by enforcing fine-grained alignment\nwith evidence. Our framework introduces a new paradigm for retrieval-aware\nreasoning by: (1) constructing context-rich training corpora; (2) generating\ncontrastive critiques from preference-aware reasoning trajectories; (3)\ntraining a dedicated \\textit{Critic Language Model (CLM)} to identify reasoning\nmisalignments; and (4) applying CDA steps to optimize reasoning trajectories\niteratively. Empirical results demonstrate that AlignRAG consistently\noutperforms all baselines and could integrate as a plug-and-play module into\nexisting RAG pipelines without further changes. By reconceptualizing RAG as a\nstructured reasoning trajectory and establishing the test-time framework for\ncorrecting reasoning misalignments in RAG, AlignRAG provides practical\nadvancements for retrieval-aware generation.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-21T04:56:47Z"}
{"aid":"http://arxiv.org/abs/2504.14859v1","title":"The automorphism group of torsion points of an elliptic curve over a\n  field of characteristic $\\ge 5$","summary":"For a field $\\mathbb{K}$ of characteristic $p\\ge5$ containing\n$\\mathbb{F}_{p}^{\\operatorname{alg}}$ and the elliptic curve $E_{s,t}: y^{2} =\nx^{3} + sx + t$ defined over the function field $\\mathbb{K}\\left(s,t\\right)$ of\ntwo variables $s$ and $t$, we prove that for a non-negative positive integer\n$e$ and a positive integer $N$ which is not divisible by $p$, the automorphism\ngroup of the normal extension\n$\\mathbb{K}\\left(s,t\\right)\\left(E_{s,t}\\left[p^{e} N\\right]\\right)$ over\n$\\mathbb{K}\\left(s,t\\right)$ is isomorphic to\n$\\left(\\mathbb{Z}/p^{e}\\mathbb{Z}\\right)^{\\times} \\times \\operatorname{SL}_{2}\n\\left(\\mathbb{Z}/N\\mathbb{Z}\\right)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-21T04:57:43Z"}
{"aid":"http://arxiv.org/abs/2504.14863v1","title":"On minimal nonperfectly divisible fork-free graphs","summary":"A fork is a graph obtained from $K_{1,3}$ (usually called claw) by\nsubdividing an edge once. A graph is perfectly divisible if for each of its\ninduced subgraph $H$, $V(H)$ can be partitioned into $A$ and $B$ such that\n$H[A]$ is perfect and $\\omega(H[B]) < \\omega(H)$. In this paper, we prove that\nthe perfect divisibility of fork-free graphs is equivalent to that of claw-free\ngraphs. We also prove that, for $F\\in \\{P_7, P_6\\cup K_1\\}$, each (fork,\n$F$)-free graph $G$ is perfectly divisible and hence $\\chi(G)\\leq\n\\binom{\\omega(G)+1}{2}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-21T05:08:16Z"}
{"aid":"http://arxiv.org/abs/2504.14900v1","title":"Distributed Time-Varying Gaussian Regression via Kalman Filtering","summary":"We consider the problem of learning time-varying functions in a distributed\nfashion, where agents collect local information to collaboratively achieve a\nshared estimate. This task is particularly relevant in control applications,\nwhenever real-time and robust estimation of dynamic cost/reward functions in\nsafety critical settings has to be performed. In this paper, we,adopt a\nfinite-dimensional approximation of a Gaussian Process, corresponding to a\nBayesian linear regression in an appropriate feature space, and propose a new\nalgorithm, DistKP, to track the time-varying coefficients via a distributed\nKalman filter. The proposed method works for arbitrary kernels and under weaker\nassumptions on the time-evolution of the function to learn compared to the\nliterature. We validate our results using a simulation example in which a fleet\nof Unmanned Aerial Vehicles (UAVs) learns a dynamically changing wind field.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-21T07:12:05Z"}
{"aid":"http://arxiv.org/abs/2504.14903v1","title":"ColBERT-serve: Efficient Multi-Stage Memory-Mapped Scoring","summary":"We study serving retrieval models, specifically late interaction models like\nColBERT, to many concurrent users at once and under a small budget, in which\nthe index may not fit in memory. We present ColBERT-serve, a novel serving\nsystem that applies a memory-mapping strategy to the ColBERT index, reducing\nRAM usage by 90% and permitting its deployment on cheap servers, and\nincorporates a multi-stage architecture with hybrid scoring, reducing ColBERT's\nquery latency and supporting many concurrent queries in parallel.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-21T07:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.14905v1","title":"CRAVE: A Conflicting Reasoning Approach for Explainable Claim\n  Verification Using LLMs","summary":"The rapid spread of misinformation, driven by digital media and AI-generated\ncontent, has made automatic claim verification essential. Traditional methods,\nwhich depend on expert-annotated evidence, are labor-intensive and not\nscalable. Although recent automated systems have improved, they still struggle\nwith complex claims that require nuanced reasoning. To address this, we propose\nCRAVE, a Conflicting Reasoning Approach for explainable claim VErification,\nthat verify the complex claims based on the conflicting rationales reasoned by\nlarge language models (LLMs). Specifically, CRAVE introduces a three-module\nframework. Ambiguity Elimination enchanced Evidence Retrieval module performs\nambiguity elimination and entity-based search to gather relevant evidence\nrelated to claim verification from external sources like Wikipedia. Conflicting\nPerspective Reasoning and Preliminary Judgment module with LLMs adopts LLMs to\nreason rationales with conflicting stances about claim verification from\nretrieved evidence across four dimensions, i.e., direct evidence, semantic\nrelationships, linguistic patterns, and logical reasoning and make a\npreliminary judgment. Finally, Small Language Model (SLM) based Judge module is\nfine-tuned to make use of preliminary judgment from LLMs to assess the\nconfidence of the conflicting rationales and make a final authenticity\njudgment. This methodology allows CRAVE to capture subtle inconsistencies in\ncomplex claims, improving both the accuracy and transparency of claim\nverification. Extensive experiments on two public claim verification datasets\ndemonstrate that our CRAVE model achieves much better performance than\nstate-of-the-art methods and exhibits a superior capacity for finding relevant\nevidence and explaining the model predictions. The code is provided at\nhttps://github.com/8zym/CRAVE.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T07:20:31Z"}
{"aid":"http://arxiv.org/abs/2504.14915v1","title":"StableQuant: Layer Adaptive Post-Training Quantization for Speech\n  Foundation Models","summary":"In this paper, we propose StableQuant, a novel adaptive post-training\nquantization (PTQ) algorithm for widely used speech foundation models (SFMs).\nWhile PTQ has been successfully employed for compressing large language models\n(LLMs) due to its ability to bypass additional fine-tuning, directly applying\nthese techniques to SFMs may not yield optimal results, as SFMs utilize\ndistinct network architecture for feature extraction. StableQuant demonstrates\noptimal quantization performance regardless of the network architecture type,\nas it adaptively determines the quantization range for each layer by analyzing\nboth the scale distributions and overall performance. We evaluate our algorithm\non two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)\ntask, and achieve superior performance compared to traditional PTQ methods.\nStableQuant successfully reduces the sizes of SFM models to a quarter and\ndoubles the inference speed while limiting the word error rate (WER)\nperformance drop to less than 0.3% with 8-bit quantization.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-21T07:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.14941v1","title":"Vector Embedding, Retrieval-Augmented Generation, CPU-NPU Collaboration,\n  Heterogeneous Computing","summary":"Retrieval-Augmented Generation is a technology that enhances large language\nmodels by integrating information retrieval. In the industry, inference\nservices based on LLMs are highly sensitive to cost-performance ratio,\nprompting the need for improving hardware resource utilization in the inference\nservice. Specifically, vector embedding and retrieval processes take up to 20%\nof the total latency. Therefore, optimizing the utilization of computational\nresources in vector embeddings is crucial for enhancing the cost-performance\nratio of inference processes, which in turn boosts their product\ncompetitiveness.In this paper, we analyze the deployment costs of vector\nembedding technology in inference services, propose a theoretical formula, and\ndetermine through the mathematical expression that increasing the capacity to\nprocess concurrent queries is the key to reducing the deployment costs of\nvector embeddings. Therefore, in this paper, we focus on improving the\nproduct's capability to process concurrent queries. To optimize concurrency\nwithout sacrificing performance, we have designed a queue manager that adeptly\noffloads CPU peak queries. This manager utilizes a linear regression model to\nascertain the optimal queue depths, a critical parameter that significantly\ninfluences the efficacy of the system. We further develop a system named WindVE\nthat uses a CPU-NPU heterogeneous architecture to offload peak concurrent\nqueries, which leverages the performance differences between the two processors\nto effectively manage traffic surges. Through experiments, we compare WindVE to\nthe state-of-the-art vector embedding framework FlagEmbedding, and achieve a\nconcurrency level up to 22.3% higher than the scheme without offloading.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-21T08:02:25Z"}
{"aid":"http://arxiv.org/abs/2504.14946v1","title":"Symmetry-Preserving Architecture for Multi-NUMA Environments (SPANE): A\n  Deep Reinforcement Learning Approach for Dynamic VM Scheduling","summary":"As cloud computing continues to evolve, the adoption of multi-NUMA\n(Non-Uniform Memory Access) architecture by cloud service providers has\nintroduced new challenges in virtual machine (VM) scheduling. To address these\nchallenges and more accurately reflect the complexities faced by modern cloud\nenvironments, we introduce the Dynamic VM Allocation problem in Multi-NUMA PM\n(DVAMP). We formally define both offline and online versions of DVAMP as\nmixed-integer linear programming problems, providing a rigorous mathematical\nfoundation for analysis. A tight performance bound for greedy online algorithms\nis derived, offering insights into the worst-case optimality gap as a function\nof the number of physical machines and VM lifetime variability. To address the\nchallenges posed by DVAMP, we propose SPANE (Symmetry-Preserving Architecture\nfor Multi-NUMA Environments), a novel deep reinforcement learning approach that\nexploits the problem's inherent symmetries. SPANE produces invariant results\nunder arbitrary permutations of physical machine states, enhancing learning\nefficiency and solution quality. Extensive experiments conducted on the\nHuawei-East-1 dataset demonstrate that SPANE outperforms existing baselines,\nreducing average VM wait time by 45%. Our work contributes to the field of\ncloud resource management by providing both theoretical insights and practical\nsolutions for VM scheduling in multi-NUMA environments, addressing a critical\ngap in the literature and offering improved performance for real-world cloud\nsystems.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T08:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.14992v1","title":"Efficient Pretraining Length Scaling","summary":"Recent advances in large language models have demonstrated the effectiveness\nof length scaling during post-training, yet its potential in pre-training\nremains underexplored. We present the Parallel Hidden Decoding Transformer\n(\\textit{PHD}-Transformer), a novel framework that enables efficient length\nscaling during pre-training while maintaining inference efficiency.\n\\textit{PHD}-Transformer achieves this through an innovative KV cache\nmanagement strategy that distinguishes between original tokens and hidden\ndecoding tokens. By retaining only the KV cache of original tokens for\nlong-range dependencies while immediately discarding hidden decoding tokens\nafter use, our approach maintains the same KV cache size as the vanilla\ntransformer while enabling effective length scaling. To further enhance\nperformance, we introduce two optimized variants: \\textit{PHD-SWA} employs\nsliding window attention to preserve local dependencies, while\n\\textit{PHD-CSWA} implements chunk-wise sliding window attention to eliminate\nlinear growth in pre-filling time. Extensive experiments demonstrate consistent\nimprovements across multiple benchmarks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T09:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.15006v1","title":"Sum-Rate Maximization for NOMA-Assisted Pinching-Antenna Systems","summary":"In this letter, we investigate a non-orthogonal multiple access (NOMA)\nassisted downlink pinching-antenna system. Leveraging the ability of pinching\nantennas to flexibly adjust users' wireless channel conditions, we formulate an\noptimization problem to maximize the sum rate by optimizing both the users'\npower allocation coefficients and the positions of pinching antennas. The\noptimal power allocation coefficients are obtained in closed-form by using the\nKarush-Kuhn-Tucker (KKT) conditions. The optimization problem of pinching\nantenna placements is more challenging than the power allocation problem, and\nis solved by a bisection-based search algorithm. In particular, the algorithm\nfirst optimizes the antenna placements to create favorable channel disparities\nbetween users, followed by fine-tuning the antenna positions to ensure the\nphase alignment for users, thus maximizing the sum rate. Simulation results\ndemonstrate that, compared to conventional-antenna systems, pinching antennas\ncan significantly enhance the sum rate in NOMA scenarios, and the proposed\nbisection-based search algorithm can achieve a sum rate nearly equivalent to\nthat of an exhaustive search.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T10:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.15010v1","title":"The Schouten-Nijenhuis bracket in infinite dimensions","summary":"The Schouten-Nijenhuis bracket on smooth infinite-dimensional manifolds $M$\nis developed in two steps: For summable multivector fields whose pointwise dual\nare all differential form, and in an extended form for multivector fields which\nare sections of $L^{\\bullet}_{\\text{skew}}(T^*M,\\mathbb R)$. We need to either\nassume that $C^{\\infty}(M)$ separates points on $TM$, or consider sheaves of\nlocal sections.","main_category":"math.DG","categories":"math.DG,math.FA","published":"2025-04-21T10:23:40Z"}
{"aid":"http://arxiv.org/abs/2504.15013v1","title":"Stay Hungry, Stay Foolish: On the Extended Reading Articles Generation\n  with LLMs","summary":"The process of creating educational materials is both time-consuming and\ndemanding for educators. This research explores the potential of Large Language\nModels (LLMs) to streamline this task by automating the generation of extended\nreading materials and relevant course suggestions. Using the TED-Ed Dig Deeper\nsections as an initial exploration, we investigate how supplementary articles\ncan be enriched with contextual knowledge and connected to additional learning\nresources. Our method begins by generating extended articles from video\ntranscripts, leveraging LLMs to include historical insights, cultural examples,\nand illustrative anecdotes. A recommendation system employing semantic\nsimilarity ranking identifies related courses, followed by an LLM-based\nrefinement process to enhance relevance. The final articles are tailored to\nseamlessly integrate these recommendations, ensuring they remain cohesive and\ninformative. Experimental evaluations demonstrate that our model produces\nhigh-quality content and accurate course suggestions, assessed through metrics\nsuch as Hit Rate, semantic similarity, and coherence. Our experimental analysis\nhighlight the nuanced differences between the generated and existing materials,\nunderscoring the model's capacity to offer more engaging and accessible\nlearning experiences. This study showcases how LLMs can bridge the gap between\ncore content and supplementary learning, providing students with additional\nrecommended resources while also assisting teachers in designing educational\nmaterials.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T10:35:48Z"}
{"aid":"http://arxiv.org/abs/2504.15014v1","title":"Computations of Spin-Sp(4), Spin-SU(8), and Spin-Spin(16) bordism groups\n  in dimensions up to 7","summary":"We investigate the structure of Spin-$G$ bordism groups, focusing on the\ninterplay between Spin and additional twisting symmetries such as $Sp(4)$,\n$SU(8)$ and $Spin(16)$. Using techniques from spectral sequences, obstruction\ntheory, and cohomology operations, we compute explicit generators for the\nSpin-$G$ bordism groups in dimensions up to 7.","main_category":"math.AT","categories":"math.AT","published":"2025-04-21T10:47:10Z"}
{"aid":"http://arxiv.org/abs/2504.15027v1","title":"DistilQwen2.5: Industrial Practices of Training Distilled Open\n  Lightweight Language Models","summary":"Enhancing computational efficiency and reducing deployment costs for large\nlanguage models (LLMs) have become critical challenges in various\nresource-constrained scenarios. In this work, we present DistilQwen2.5, a\nfamily of distilled, lightweight LLMs derived from the public Qwen2.5 models.\nThese distilled models exhibit enhanced instruction-following capabilities\ncompared to the original models based on a series of distillation techniques\nthat incorporate knowledge from much larger LLMs. In our industrial practice,\nwe first leverage powerful proprietary LLMs with varying capacities as\nmulti-agent teachers to select, rewrite, and refine instruction-response pairs\nthat are more suitable for student LLMs to learn. After standard fine-tuning,\nwe further leverage a computationally efficient model fusion approach that\nenables student models to progressively integrate fine-grained hidden knowledge\nfrom their teachers. Experimental evaluations demonstrate that the distilled\nmodels possess significantly stronger capabilities than their original\ncheckpoints. Additionally, we present use cases to illustrate the applications\nof our framework in real-world scenarios. To facilitate practical use, we have\nreleased all the DistilQwen2.5 models to the open-source community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T11:26:02Z"}
{"aid":"http://arxiv.org/abs/2504.15040v1","title":"The PHD/CPHD filter for Multiple Extended Target Tracking with\n  Trajectory Set Theory and Explicit Shape Estimation","summary":"In this paper, we propose two methods for tracking multiple extended targets\nor unresolved group targets with elliptical extent shape. These two methods are\ndeduced from the famous Probability Hypothesis Density (PHD) filter and the\nCardinality-PHD (CPHD) filter, respectively. In these two methods, Trajectory\nSet Theory (TST) is combined to establish the target trajectory estimates.\nMoreover, by employing a decoupled shape estimation model, the proposed methods\ncan explicitly provide the shape estimation of the target, such as the\norientation of the ellipse extension and the length of its two axes. We derived\nthe closed Bayesian recursive of these two methods with stable trajectory\ngeneration and accurate extent estimation, resulting in the TPHD-E filter and\nthe TCPHD-E filter. In addition, Gaussian mixture implementations of our\nmethods are provided, which are further referred to as the GM-TPHD-E filter and\nthe GM-TCPHD-E filters. We illustrate the ability of these methods through\nsimulations and experiments with real data. These experiments demonstrate that\nthe two proposed algorithms have advantages over existing algorithms in target\nshape estimation, as well as in the completeness and accuracy of target\ntrajectory generation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T11:49:22Z"}
{"aid":"http://arxiv.org/abs/2504.15045v1","title":"Period-luminosity and period-luminosity-metallicity relation for\n  $Î´$ Scuti Stars","summary":"$\\delta$ Scuti ($\\delta$ Sct) stars are potential distance tracers for\nstudying the Milky Way structure. We conduct a comprehensive analysis of the\nperiod-luminosity (PL) and period-luminosity-metallicity (PLZ) relation for\n$\\delta$ Sct stars, integrating data from the Zwicky Transient Facility (ZTF),\nthe Transiting Exoplanet Survey Satellite (TESS), Large Sky Area Multi-Object\nFiber Spectroscopic Telescope (LAMOST), Apache Point Observatory Galactic\nEvolution Experiment (APOGEE), and Gaia. To mitigate the impact of the Gaia\nparallax zero point offset, we applied a correction method, determining the\noptimal zero point value to be $zp_\\varpi = 35 \\pm 2 \\, \\mu\\text{as}$. Using\nthe three best bands, by varying the parallax error threshold, we found that\nthe total error of the PLR zero point was minimized to 0.9\\% at a parallax\nerror threshold of 6\\%. With this threshold, we derived the PL and PLZ relation\nfor nine bands (from optical to mid-infrared) and five Wesenheit bands. Through\nour analysis, we conclude that the influence of metallicity on the PLR of\n$\\delta$ Sct stars is not significant, and the differences across various bands\nare minimal.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-21T11:57:12Z"}
{"aid":"http://arxiv.org/abs/2504.15049v1","title":"ScanEdit: Hierarchically-Guided Functional 3D Scan Editing","summary":"With the fast pace of 3D capture technology and resulting abundance of 3D\ndata, effective 3D scene editing becomes essential for a variety of graphics\napplications. In this work we present ScanEdit, an instruction-driven method\nfor functional editing of complex, real-world 3D scans. To model large and\ninterdependent sets of ob- jectswe propose a hierarchically-guided approach.\nGiven a 3D scan decomposed into its object instances, we first construct a\nhierarchical scene graph representation to enable effective, tractable editing.\nWe then leverage reason- ing capabilities of Large Language Models (LLMs) and\ntranslate high-level language instructions into actionable commands applied\nhierarchically to the scene graph. Fi- nally, ScanEdit integrates LLM-based\nguidance with ex- plicit physical constraints and generates realistic scenes\nwhere object arrangements obey both physics and common sense. In our extensive\nexperimental evaluation ScanEdit outperforms state of the art and demonstrates\nexcellent re- sults for a variety of real-world scenes and input instruc-\ntions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T12:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.15083v1","title":"A survey on asymptotic equilibrium distribution of zeros of random\n  holomorphic sections","summary":"This is a survey of results concerning the asymptotic equilibrium\ndistribution of zeros of random holomorphic polynomials and holomorphic\nsections of high powers of a positive line bundle, as related to the authors'\nrecent work. Our primary focus is on the role of pluripotential theory in this\nresearch area.","main_category":"math.CV","categories":"math.CV,math.PR","published":"2025-04-21T13:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.15116v1","title":"Wigner multiplets in QFT: from Wigner degeneracy to Elko fields","summary":"We establish the theoretical foundation of the Wigner superposition field, a\nquantum field framework for spin-1/2 fermions that exhibit a Wigner doublet --\na discrete quantum number arising from nontrivial representations of the\nextended Poincar\\'{e} group. In contrast to the previously developed doublet\nformalism, which treats the Wigner degeneracy as a superficial label, the\nsuperposition formalism encodes it directly into the structure of a unified\nfield via a coherent superposition of degenerate spinor fields. By imposing the\nLorentz covariance, causality, and canonical quantization, we derive nontrivial\nconstraints on the field configuration, which uniquely identify the Elko field\nas the consistent realization of the Wigner superposition field. Our analysis\nfurther clarifies that although the Elko field is a spinor field, it possesses\nmass dimension one and obeys the Klein-Gordon rather than the Dirac kinematics.\nMoreover, we explore the general Elko representation through basis\nredefinitions, showing that certain traditional properties, such as being\neigenspinors of charge conjugation, are artifacts of specific basis choices\nrather than intrinsic features. Finally, we discuss the physical implications\nof Elko as a dark matter (DM) candidate. This work lays the foundation for a\nsystematic reformulation of Elko interactions and its phenomenology as a viable\ncomponent of DM.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-21T14:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.15148v1","title":"Uniformly resolvable decompositions of $K_v$ into $1$-factors and odd\n  $n$-star factors","summary":"We consider uniformly resolvable decompositions of $K_v$ into subgraphs such\nthat each resolution class contains only blocks isomorphic to the same graph.\nWe give a partial solution for the case in which all resolution classes are\neither $K_2$ or $K_{1,n}$ where $n$ is odd.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-21T14:52:40Z"}
{"aid":"http://arxiv.org/abs/2504.15181v1","title":"Existing Industry Practice for the EU AI Act's General-Purpose AI Code\n  of Practice Safety and Security Measures","summary":"This report provides a detailed comparison between the measures proposed in\nthe EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and\ncurrent practices adopted by leading AI companies. As the EU moves toward\nenforcing binding obligations for GPAI model providers, the Code of Practice\nwill be key to bridging legal requirements with concrete technical commitments.\nOur analysis focuses on the draft's Safety and Security section which is only\nrelevant for the providers of the most advanced models (Commitments II.1-II.16)\nand excerpts from current public-facing documents quotes that are relevant to\neach individual measure.\n  We systematically reviewed different document types - including companies'\nfrontier safety frameworks and model cards - from over a dozen companies,\nincluding OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and\nothers. This report is not meant to be an indication of legal compliance nor\ndoes it take any prescriptive viewpoint about the Code of Practice or\ncompanies' policies. Instead, it aims to inform the ongoing dialogue between\nregulators and GPAI model providers by surfacing evidence of precedent.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-21T15:44:01Z"}
{"aid":"http://arxiv.org/abs/2504.15190v1","title":"Physical vs phantom dark energy after DESI: thawing quintessence in a\n  curved background","summary":"Recent data from DESI, in combination with other data, provide moderate\nevidence of dynamical dark energy, $w\\neq-1$. In the $w_0, w_a$ parametrization\nof $w$, there is a preference for a phantom crossing, $w<-1$, at redshift\n$z\\sim0.5$. In general relativity, the phantom equation of state is unphysical.\nThus it is important to check whether phantom crossing is present in other\nphysically self-consistent models of dark energy that have equivalent evidence\nto the $w_0, w_a$ parametrization. We find that thawing quintessence with\nnonzero cosmic curvature can fit the recent data slightly better than $w_0,\nw_a$ in a flat background. The phantom crossing may be a spurious artifact of a\nparametrization that is not based on a physical model.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-21T16:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.15215v1","title":"An experimental study of the influence of anonymous information on\n  social media users","summary":"Increasingly, people use social media for their day-to-day interactions and\nas a source of information, even though much of this information is practically\nanonymous. This raises the question: does anonymous information influence its\nrecipients? We conducted an online, two-phase, preregistered experiment using a\nnationally representative sample of participants from the U.S. to find the\nanswer. To avoid biases of opinions among participants, in the first phase,\neach participant examines ten Rorschach inkblots and chooses one of four\nopinions assigned to each inkblot. In the second phase, the participants are\nrandomly assigned to one of four distinct information conditions and are asked\nto revisit their opinions for the same ten inkblots. Conditions ranged from\nrepeating phase one to receiving anonymous comments about certain opinions.\nResults were consistent with the preregistration. Importantly, anonymous\ncomments shown in phase two influence up to half of the participants' opinion\nselections. To better understand the role of anonymous comments in influencing\nthe selections of opinions, we implemented agent-based modeling (ABM). ABM\nresults suggest that a straightforward mechanism can explain the impact of such\ninformation. Overall, our results indicate that even anonymous information can\nhave a significant impact on its recipients, potentially altering their\npopularity rankings. However, the strength of such influence weakens when\nrecipients' confidence in their selections increases. Additionally, we found\nthat participants' confidence in the first phase is inversely related to the\nnumber of change opinions.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-21T16:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.15236v1","title":"Values in the Wild: Discovering and Analyzing Values in Real-World\n  Language Model Interactions","summary":"AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG","published":"2025-04-21T17:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.15266v1","title":"Roll the dice & look before you leap: Going beyond the creative limits\n  of next-token prediction","summary":"We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-21T17:47:46Z"}
{"aid":"http://arxiv.org/abs/2504.15269v1","title":"Scalable and robust regression models for continuous proportional data","summary":"Beta regression is used routinely for continuous proportional data, but it\noften encounters practical issues such as a lack of robustness of regression\nparameter estimates to misspecification of the beta distribution. We develop an\nimproved class of generalized linear models starting with the continuous\nbinomial (cobin) distribution and further extending to dispersion mixtures of\ncobin distributions (micobin). The proposed cobin regression and micobin\nregression models have attractive robustness, computation, and flexibility\nproperties. A key innovation is the Kolmogorov-Gamma data augmentation scheme,\nwhich facilitates Gibbs sampling for Bayesian computation, including in\nhierarchical cases involving nested, longitudinal, or spatial data. We\ndemonstrate robustness, ability to handle responses exactly at the boundary (0\nor 1), and computational efficiency relative to beta regression in simulation\nexperiments and through analysis of the benthic macroinvertebrate multimetric\nindex of US lakes using lake watershed covariates.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-21T17:55:00Z"}
{"aid":"http://arxiv.org/abs/2504.15280v1","title":"Seeing from Another Perspective: Evaluating Multi-View Understanding in\n  MLLMs","summary":"Multi-view understanding, the ability to reconcile visual information across\ndiverse viewpoints for effective navigation, manipulation, and 3D scene\ncomprehension, is a fundamental challenge in Multi-Modal Large Language Models\n(MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive\nadvances in high-level reasoning and planning, they frequently fall short when\nconfronted with multi-view geometric consistency and cross-view correspondence.\nTo comprehensively evaluate the challenges of MLLMs in multi-view scene\nreasoning, we propose All-Angles Bench, a benchmark of over 2,100 human\ncarefully annotated multi-view question-answer pairs across 90 diverse\nreal-world scenes. Our six tasks (counting, attribute identification, relative\ndistance, relative direction, object manipulation, and camera pose estimation)\nspecifically test model's geometric correspondence and the capacity to align\ninformation consistently across views. Our extensive experiments, benchmark on\n27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and\nGPT-4o against human evaluators reveals a substantial performance gap,\nindicating that current MLLMs remain far from human-level proficiency. Through\nin-depth analysis, we show that MLLMs are particularly underperforming under\ntwo aspects: (1) cross-view correspondence for partially occluded views and (2)\nestablishing the coarse camera poses. These findings highlight the necessity of\ndomain-specific refinements or modules that embed stronger multi-view\nawareness. We believe that our All-Angles Bench offers valuable insights and\ncontribute to bridging the gap between MLLMs and human-level multi-view\nunderstanding. The project and benchmark are publicly available at\nhttps://danielchyeh.github.io/All-Angles-Bench/.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-21T17:59:53Z"}
{"aid":"http://arxiv.org/abs/2504.15588v1","title":"Bayesian Parameter Estimation for Partially Observed McKean-Vlasov\n  Diffusions Using Multilevel Markov chain Monte Carlo","summary":"In this article we consider Bayesian estimation of static parameters for a\nclass of partially observed McKean-Vlasov diffusion processes with\ndiscrete-time observations over a fixed time interval. This problem features\nseveral obstacles to its solution, which include that the posterior density is\nnumerically intractable in continuous-time, even if the transition\nprobabilities are available and even when one uses a time-discretization, the\nposterior still cannot be used by adopting well-known computational methods\nsuch as Markov chain Monte Carlo (MCMC). In this paper we provide a solution to\nthis problem by using new MCMC algorithms which can solve the afore-mentioned\nissues. This MCMC algorithm is extended to use multilevel Monte Carlo (MLMC)\nmethods. We prove convergence bounds on our parameter estimators and show that\nthe MLMC-based MCMC algorithm reduces the computational cost to achieve a mean\nsquare error versus ordinary MCMC by an order of magnitude. We numerically\nillustrate our results on two models.","main_category":"stat.CO","categories":"stat.CO,cs.NA,math.NA","published":"2025-04-22T05:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.15605v1","title":"Lie derivatives of sections of natural vector bundles","summary":"Time derivatives of pullbacks and push forwards along smooth curves of\ndiffeomorphism of sections of natural vector bundles are computed in terms of\nLie derivatives along adapted non-autonomous vector fields by extending a key\nlemma in [Markus Mauhart, Peter W. Michor: Commutators of flows and fields.\nArch. Math. (Brno) 28 (1992), 228-236. arXiv:math/9204221]. There is also the\nanalogous result about the first non-vanishing derivative of higher order.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T05:54:01Z"}
{"aid":"http://arxiv.org/abs/2504.15608v1","title":"Experimental Aspects of Lorentz Invariance Violation","summary":"Lorentz invariance is a cornerstone of modern physics, yet its possible\nviolation remains both theoretically intriguing and experimentally significant.\nIn this work, using quantum electrodynamics as an example, we explore how\nLorentz invariance violation, introduced into a specific sector of the theory,\nspreads through loop corrections, modifying the propagation and dispersion\nrelations of other particles. Self-energy and vacuum polarization graphs reveal\nhow LIV effects transfer across sectors, influencing particle kinematics. Due\nto these loop effects, constraints from cosmic-ray observations and other\nEarth-based experiments impose limits on induced LIV parameters that would\notherwise be less constrained. We show that while interaction-based LIV effects\nrequire unrealistically large parameters for detection, modifications to\ndispersion relations can be probed down to $\\delta \\sim 10^{-8} \\text{ to }\n10^{-9}$ at the LHC. This suggests that accelerator-based resonance studies\nprovide a promising avenue for stringent LIV constraints, potentially rivaling\nastrophysical observations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T05:58:04Z"}
{"aid":"http://arxiv.org/abs/2504.15623v1","title":"RadioDiff-$k^2$: Helmholtz Equation Informed Generative Diffusion Model\n  for Multi-Path Aware Radio Map Construction","summary":"In this paper, we propose a novel physics-informed generative learning\napproach, termed RadioDiff-$\\bm{k^2}$, for accurate and efficient\nmultipath-aware radio map (RM) construction. As wireless communication evolves\ntowards environment-aware paradigms, driven by the increasing demand for\nintelligent and proactive optimization in sixth-generation (6G) networks,\naccurate construction of RMs becomes crucial yet highly challenging.\nConventional electromagnetic (EM)-based methods, such as full-wave solvers and\nray-tracing approaches, exhibit substantial computational overhead and limited\nadaptability to dynamic scenarios. Although, existing neural network (NN)\napproaches have efficient inferencing speed, they lack sufficient consideration\nof the underlying physics of EM wave propagation, limiting their effectiveness\nin accurately modeling critical EM singularities induced by complex multipath\nenvironments. To address these fundamental limitations, we propose a novel\nphysics-inspired RM construction method guided explicitly by the Helmholtz\nequation, which inherently governs EM wave propagation. Specifically, we\ntheoretically establish a direct correspondence between EM singularities, which\ncorrespond to the critical spatial features influencing wireless propagation,\nand regions defined by negative wave numbers in the Helmholtz equation. Based\non this insight, we design an innovative dual generative diffusion model (DM)\nframework comprising one DM dedicated to accurately inferring EM singularities\nand another DM responsible for reconstructing the complete RM using these\nsingularities along with environmental contextual information. Our\nphysics-informed approach uniquely combines the efficiency advantages of\ndata-driven methods with rigorous physics-based EM modeling, significantly\nenhancing RM accuracy, particularly in complex propagation environments\ndominated by multipath effects.","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY","published":"2025-04-22T06:28:13Z"}
{"aid":"http://arxiv.org/abs/2504.15635v1","title":"Questioning Cosmic Acceleration with DESI: The Big Stall of the Universe","summary":"One of the most important discoveries in modern cosmology is cosmic\nacceleration. However, we find that today's universe could decelerate in the\nstatistically preferred Chevallier-Polarski-Linder (CPL) scenario over the\n$\\Lambda$CDM model by cosmic microwave background, type Ia supernova and DESI's\nnew measurements of baryon acoustic oscillations. Using various datasets, at a\nbeyond $5\\,\\sigma$ confidence level, we demonstrate that the universe\nexperiences a triple deceleration during its evolution and finally reaches the\nstate of the ``Big Stall\", which predicts that: (i) the universe suddenly comes\nto a halt in the distant future; (ii) its eventual destiny is dominated by dark\nmatter rather than dark energy ; (iii) it ultimately retains an extremely small\nfraction of dark energy but exerts an extremely large pressure. Our findings\nprofoundly challenge the established understanding of cosmic acceleration and\nenrich our comprehension of cosmic evolution.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.HE,gr-qc","published":"2025-04-22T06:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.15651v1","title":"Atomically-Thin Transition Metal Dichalcogenide Nanolasers: Challenges\n  and Opportunities","summary":"Low energy consumption nanolasers are crucial for advancing on-chip\nintegrated optical interconnects and photonic integrated circuits. Monolayer\ntransition metal dichalcogenides (TMDs) have emerged as an energy-efficient\nalternative to traditional semiconductor materials for nanolaser optical gain\nmedium, promising ultralow lasing threshold powers. While several studies\nsuggest that TMDs meet the criteria for lasing, whether true lasing has been\nachieved remains a topic of heavy debate within the scientific community. In\nthis perspective, we offer an overview of the field, outlining the key\ncharacteristics of laser light and methods for testing these properties in\nTMD-based devices. We then conduct a thorough review of recent reports claiming\nlasing, assessing the findings against established criteria for laser light\nemission. Finally, we discuss future research directions and applications,\nhighlighting the key challenges that must be addressed to realize practical\nTMD-based nanolasers.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-22T07:18:15Z"}
{"aid":"http://arxiv.org/abs/2504.15658v1","title":"Improved Upper Bound on Brun's Constant Under GRH","summary":"Brun's constant is the summation of the reciprocals of all twin primes, given\nby $B=\\sum_{p \\in P_2}{\\left( \\frac{1}{p} + \\frac{1}{p+2}\\right)}$. In this\npaper, we provide the first rigorous bound on Brun's constant under the GRH\nassumption, resulting in $B < 2.1609$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T07:30:00Z"}
{"aid":"http://arxiv.org/abs/2504.15698v1","title":"Entanglement-enhanced randomized measurement in noisy quantum devices","summary":"Quantum hardware is advancing rapidly across various platforms, yet\nimplementing large-scale quantum error correction (QEC) remains challenging. As\nhardware continues to improve, there is a growing need to identify potential\napplications on noisy quantum devices that can leverage these enhancements.\nWith this motivation, we explore the advantages of shallow measurements over\n(non-entangling) single-qubit measurements for learning various properties of a\nquantum state. While previous studies have examined this subject, they have\nprimarily focused on specific problems. Here, by developing a new theoretical\nframework, we demonstrate how shallow measurements can benefit in diverse\nscenarios. Despite the additional errors from two-qubit gates in shallow\nmeasurements, we experimentally validated improvements compared to single-qubit\nmeasurements in applications like derandomization, common randomized\nmeasurements, and machine learning up to 40 qubits and 46 layers of two-qubit\ngates, respectively. As a result, we show that hardware improvements, even\nbefore QEC, could broaden the range of feasible applications.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T08:33:36Z"}
{"aid":"http://arxiv.org/abs/2504.15708v1","title":"Domain-wall driven suppression of thermal conductivity in a\n  ferroelectric polycrystal","summary":"A common strategy for reducing thermal conductivity of polycrystalline\nsystems is to increase the number of grain boundaries. Indeed, grain boundaries\nenhance the probability of phonon scattering events, which has been applied to\ncontrol the thermal transport in a wide range of materials, including hard\nmetals, diamond, oxides and 2D systems such as graphene. Here, we report the\nopposite behavior in improper ferroelectric ErMnO3 polycrystals, where the\nthermal conductivity decreases with increasing grain size. We attribute this\nunusual relationship between heat transport and microstructure to phonon\nscattering at ferroelectric domain walls. The domain walls are more densely\npacked in larger grains, leading to an inversion of the classical\ngrain-boundary-dominated transport behavior. Our findings open additional\navenues for microstructural engineering of materials for thermoelectric and\nthermal management applications, enabling simultaneous control over mechanical,\nelectronic, and thermal properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T08:48:03Z"}
{"aid":"http://arxiv.org/abs/2504.15721v1","title":"BBAL: A Bidirectional Block Floating Point-Based Quantisation\n  Accelerator for Large Language Models","summary":"Large language models (LLMs), with their billions of parameters, pose\nsubstantial challenges for deployment on edge devices, straining both memory\ncapacity and computational resources. Block Floating Point (BFP) quantisation\nreduces memory and computational overhead by converting high-overhead floating\npoint operations into low-bit fixed point operations. However, BFP requires\naligning all data to the maximum exponent, which causes loss of small and\nmoderate values, resulting in quantisation error and degradation in the\naccuracy of LLMs. To address this issue, we propose a Bidirectional Block\nFloating Point (BBFP) data format, which reduces the probability of selecting\nthe maximum as shared exponent, thereby reducing quantisation error. By\nutilizing the features in BBFP, we present a full-stack Bidirectional Block\nFloating Point-Based Quantisation Accelerator for LLMs (BBAL), primarily\ncomprising a processing element array based on BBFP, paired with proposed\ncost-effective nonlinear computation unit. Experimental results show BBAL\nachieves a 22% improvement in accuracy compared to an outlier-aware accelerator\nat similar efficiency, and a 40% efficiency improvement over a BFP-based\naccelerator at similar accuracy.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-22T09:11:21Z"}
{"aid":"http://arxiv.org/abs/2504.15727v1","title":"On some classes of non-commutative dimonoids","summary":"The present paper is devoted to the study of dimonoids, algebraic structures\nwith two associative binary operations that satisfy a prescribed system of\naxioms. We investigate the properties of dual dimonoids. In the class of\nnon-commutative dimonoids, we construct a number of abelian, non-abelian, and\nrectangular dimonoids. The internal structure of these objects is analyzed, in\nparticular, their automorphism groups and halos are computed.","main_category":"math.GR","categories":"math.GR,math.RA","published":"2025-04-22T09:21:44Z"}
{"aid":"http://arxiv.org/abs/2504.15733v1","title":"Operator Inference for Elliptic Eigenvalue Problems","summary":"Eigenvalue problems for elliptic operators play an important role in science\nand engineering applications, where efficient and accurate numerical\ncomputation is essential. In this work, we propose a novel operator inference\napproach for elliptic eigenvalue problems based on neural network\napproximations that directly maps computational domains to their associated\neigenvalues and eigenfunctions. Motivated by existing neural network\narchitectures and the mathematical characteristics of eigenvalue problems, we\nrepresent computational domains as pixelated images and decompose the task into\ntwo subtasks: eigenvalue prediction and eigenfunction prediction. For the\neigenvalue prediction, we design a convolutional neural network (CNN), while\nfor the eigenfunction prediction, we employ a Fourier Neural Operator (FNO).\nAdditionally, we introduce a critical preprocessing module that integrates\ndomain scaling, detailed boundary pixelization, and main-axis alignment. This\npreprocessing step not only simplifies the learning task but also enhances the\nperformance of the neural networks. Finally, we present numerical results to\ndemonstrate the effectiveness of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T09:25:36Z"}
{"aid":"http://arxiv.org/abs/2504.15750v1","title":"Unique Bernoulli Gibbs states and g-measures","summary":"A sufficient condition for the Gibbs states of a shift-invariant\nspecification on a one-dimensional lattice to be the $g$-chains for some\ncontinuous function $g$ is obtained. This is then used to derive criteria under\nwhich there is a unique Gibbs state, which is also shift-invariant and\nBernoulli.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T09:53:09Z"}
{"aid":"http://arxiv.org/abs/2504.15751v1","title":"GADS: A Super Lightweight Model for Head Pose Estimation","summary":"In human-computer interaction, head pose estimation profoundly influences\napplication functionality. Although utilizing facial landmarks is valuable for\nthis purpose, existing landmark-based methods prioritize precision over\nsimplicity and model size, limiting their deployment on edge devices and in\ncompute-poor environments. To bridge this gap, we propose \\textbf{Grouped\nAttention Deep Sets (GADS)}, a novel architecture based on the Deep Set\nframework. By grouping landmarks into regions and employing small Deep Set\nlayers, we reduce computational complexity. Our multihead attention mechanism\nextracts and combines inter-group information, resulting in a model that is\n$7.5\\times$ smaller and executes $25\\times$ faster than the current lightest\nstate-of-the-art model. Notably, our method achieves an impressive reduction,\nbeing $4321\\times$ smaller than the best-performing model. We introduce vanilla\nGADS and Hybrid-GADS (landmarks + RGB) and evaluate our models on three\nbenchmark datasets -- AFLW2000, BIWI, and 300W-LP. We envision our architecture\nas a robust baseline for resource-constrained head pose estimation methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T09:53:25Z"}
{"aid":"http://arxiv.org/abs/2504.15762v1","title":"Product separability in central extensions","summary":"We show that a central extension of locally quasiconvex subgroup separable\nhyperbolic group is product separable, so long as it is subgroup separable. We\nalso establish that a central extension of a double coset separable group by a\nfinitely generated group is double coset separable if and only if it is\nsubgroup separable, and that double coset separability is stable under taking\ndirect products with finitely generated nilpotent groups.","main_category":"math.GR","categories":"math.GR","published":"2025-04-22T10:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.15860v1","title":"The area of spheres in the Brownian plane","summary":"We consider the area of spheres centered at the distinguished point in the\nBrownian plane. As a function of the radius, the resulting process has\ncontinuously differentiable sample paths. Furthermore, the pair consisting of\nthe process and its derivative is time-homogeneous Markov and satisfies an\nexplicit stochastic differential equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T12:57:07Z"}
{"aid":"http://arxiv.org/abs/2504.15870v1","title":"Machine-learned RG-improved gauge actions and classically perfect\n  gradient flows","summary":"Extracting continuum properties of quantum field theories from discretized\nspacetime is challenging due to lattice artifacts. Renormalization-group\n(RG)-improved lattice actions can preserve continuum properties, but are in\ngeneral difficult to parameterize. Machine learning (ML) with gauge-equivariant\nconvolutional neural networks provides a way to efficiently describe such\nactions. We test a machine-learned RG-improved lattice gauge action, the\nclassically perfect fixed-point (FP) action, for four-dimensional SU(3) gauge\ntheory through Monte Carlo simulations. We establish that the gradient flow of\nthe FP action is free of tree-level discretization effects to all orders in the\nlattice spacing, making it classically perfect. This allows us to test the\nquality of improvement of the FP action, without introducing additional\nartifacts. We find that discretization effects in gradient-flow observables are\nhighly suppressed and less than 1% up to lattice spacings of 0.14 fm, allowing\ncontinuum physics to be extracted from coarse lattices. The quality of\nimprovement achieved motivates the use of the FP action in future gauge theory\nstudies. The advantages of ML-based parameterizations also highlight the\npossibility of realizing quantum perfect actions in lattice gauge theory.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-22T13:14:49Z"}
{"aid":"http://arxiv.org/abs/2504.15891v1","title":"Optimal body force for heat transfer in turbulent vertical heated pipe\n  flow","summary":"As buoyancy can help drive a flow, the vertical heated-pipe arrangement is\nwidely used in thermal engineering applications. However, buoyancy suppresses\nand can even laminarise turbulence in the flow, thereby seriously damaging the\nheat transfer, measured by the Nusselt number Nu. As buoyancy, measured by the\nparameter C, is increased, three flow regimes are possible: shear-driven\nturbulence, laminarised flow, and convective turbulence. In Chu et al. (2024)\nwe employed a variational optimisation method to investigate how the buoyancy\nchanges the structure of the minimal flow perturbation that triggers\nturbulence. Here, we extend the method to find an optimal body force of limited\nmagnitude that maximises heat transfer, and examine how time-dependence of the\nflow affects the optimisation in each of the three flow regimes. Optimisations\nare performed at Re = 3000, and the force is found to laminarise convective\nturbulence, or make it only weakly chaotic for C up to 8. Consistent with\nprevious computations that assume steady flow, the optimal force induces\nstreamwise-independent rolls, but at larger amplitude the force triggers\ntime-dependent turbulent flow. Transition from the laminar\nstreamwise-independent state to turbulent flow can either enhance Nu or reduce\nNu. For highly chaotic flows, either shear turbulence at C = 1 or convective\nturbulence at C = 16, 32, optimisations place rolls closer to the wall than\ncalculations with the steady flow assumption. At any given force amplitude,\nhowever, the enhanced Nu is only weakly dependent on the number of induced\nrolls.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-22T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.15897v1","title":"SUPRA: Subspace Parameterized Attention for Neural Operator on General\n  Domains","summary":"Neural operators are efficient surrogate models for solving partial\ndifferential equations (PDEs), but their key components face challenges: (1) in\norder to improve accuracy, attention mechanisms suffer from computational\ninefficiency on large-scale meshes, and (2) spectral convolutions rely on the\nFast Fourier Transform (FFT) on regular grids and assume a flat geometry, which\ncauses accuracy degradation on irregular domains. To tackle these problems, we\nregard the matrix-vector operations in the standard attention mechanism on\nvectors in Euclidean space as bilinear forms and linear operators in vector\nspaces and generalize the attention mechanism to function spaces. This new\nattention mechanism is fully equivalent to the standard attention but\nimpossible to compute due to the infinite dimensionality of function spaces. To\naddress this, inspired by model reduction techniques, we propose a Subspace\nParameterized Attention (SUPRA) neural operator, which approximates the\nattention mechanism within a finite-dimensional subspace. To construct a\nsubspace on irregular domains for SUPRA, we propose using the Laplacian\neigenfunctions, which naturally adapt to domains' geometry and guarantee the\noptimal approximation for smooth functions. Experiments show that the SUPRA\nneural operator reduces error rates by up to 33% on various PDE datasets while\nmaintaining state-of-the-art computational efficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-22T13:40:04Z"}
{"aid":"http://arxiv.org/abs/2504.15898v1","title":"Stationary distributions of McKean-Vlasov SDEs with jumps: existence,\n  uniqueness, and multiplicity","summary":"In this paper, we are interested in the issues on existence, uniqueness, and\nmultiplicity of stationary distributions for McKean-Vlasov SDEs with jumps. In\ndetail, with regarding to McKean-Vlasov SDEs driven by pure jump L\\'{e}vy\nprocesses, we principally (i) explore the existence of stationary distributions\nvia Schauder's fixed point theorem under an appropriate Lyapunov condition;\n(ii) tackle the uniqueness of stationary distributions and the convergence to\nthe equilibria as long as the underlying drifts are continuous with respect to\nthe measure variables under the weighted total variation distance and the\n$L^1$-Wasserstein distance, respectively; (iii) demonstrate the multiplicity of\nstationary distributions under a locally dissipative condition. In addition,\nsome illustrative examples are provided to show that the associated\nMcKean-Vlasov SDEs possess a unique, two and three stationary distributions,\nrespectively.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T13:40:19Z"}
{"aid":"http://arxiv.org/abs/2504.15903v1","title":"Impact of Noise on LLM-Models Performance in Abstraction and Reasoning\n  Corpus (ARC) Tasks with Model Temperature Considerations","summary":"Recent advancements in Large Language Models (LLMs) have generated growing\ninterest in their structured reasoning capabilities, particularly in tasks\ninvolving abstraction and pattern recognition. The Abstraction and Reasoning\nCorpus (ARC) benchmark plays a crucial role in evaluating these capabilities by\ntesting how well AI models generalize to novel problems. While GPT-4o\ndemonstrates strong performance by solving all ARC tasks under zero-noise\nconditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any,\nsuggesting limitations in their ability to reason beyond simple pattern\nmatching. To explore this gap, we systematically evaluate these models across\ndifferent noise levels and temperature settings. Our results reveal that the\nintroduction of noise consistently impairs model performance, regardless of\narchitecture. This decline highlights a shared vulnerability: current LLMs,\ndespite showing signs of abstract reasoning, remain highly sensitive to input\nperturbations. Such fragility raises concerns about their real-world\napplicability, where noise and uncertainty are common. By comparing how\ndifferent model architectures respond to these challenges, we offer insights\ninto the structural weaknesses of modern LLMs in reasoning tasks. This work\nunderscores the need for developing more robust and adaptable AI systems\ncapable of handling the ambiguity and variability inherent in real-world\nscenarios. Our findings aim to guide future research toward enhancing model\ngeneralization, robustness, and alignment with human-like cognitive\nflexibility.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T13:43:58Z"}
{"aid":"http://arxiv.org/abs/2504.15912v1","title":"Automated Bug Report Prioritization in Large Open-Source Projects","summary":"Large open-source projects receive a large number of issues (known as bugs),\nincluding software defect (i.e., bug) reports and new feature requests from\ntheir user and developer communities at a fast rate. The often limited project\nresources do not allow them to deal with all issues. Instead, they have to\nprioritize them according to the project's priorities and the issues'\nseverities. In this paper, we propose a novel approach to automated bug\nprioritization based on the natural language text of the bug reports that are\nstored in the open bug repositories of the issue-tracking systems. We conduct\ntopic modeling using a variant of LDA called TopicMiner-MTM and text\nclassification with the BERT large language model to achieve a higher\nperformance level compared to the state-of-the-art. Experimental results using\nan existing reference dataset containing 85,156 bug reports of the Eclipse\nPlatform project indicate that we outperform existing approaches in terms of\nAccuracy, Precision, Recall, and F1-measure of the bug report priority\nprediction.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-22T13:57:48Z"}
{"aid":"http://arxiv.org/abs/2504.15921v1","title":"ViSMaP: Unsupervised Hour-long Video Summarisation by Meta-Prompting","summary":"We introduce ViSMap: Unsupervised Video Summarisation by Meta Prompting, a\nsystem to summarise hour long videos with no-supervision. Most existing video\nunderstanding models work well on short videos of pre-segmented events, yet\nthey struggle to summarise longer videos where relevant events are sparsely\ndistributed and not pre-segmented. Moreover, long-form video understanding\noften relies on supervised hierarchical training that needs extensive\nannotations which are costly, slow and prone to inconsistency. With ViSMaP we\nbridge the gap between short videos (where annotated data is plentiful) and\nlong ones (where it's not). We rely on LLMs to create optimised\npseudo-summaries of long videos using segment descriptions from short ones.\nThese pseudo-summaries are used as training data for a model that generates\nlong-form video summaries, bypassing the need for expensive annotations of long\nvideos. Specifically, we adopt a meta-prompting strategy to iteratively\ngenerate and refine creating pseudo-summaries of long videos. The strategy\nleverages short clip descriptions obtained from a supervised short video model\nto guide the summary. Each iteration uses three LLMs working in sequence: one\nto generate the pseudo-summary from clip descriptions, another to evaluate it,\nand a third to optimise the prompt of the generator. This iteration is\nnecessary because the quality of the pseudo-summaries is highly dependent on\nthe generator prompt, and varies widely among videos. We evaluate our summaries\nextensively on multiple datasets; our results show that ViSMaP achieves\nperformance comparable to fully supervised state-of-the-art models while\ngeneralising across domains without sacrificing performance. Code will be\nreleased upon publication.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:06:01Z"}
{"aid":"http://arxiv.org/abs/2504.15971v1","title":"On the greatest prime factor of polynomial values and subexponential\n  Szpiro in families","summary":"Combining a modular approach to the $abc$ conjecture developed by the second\nauthor with the classical method of linear forms in logarithms, we obtain\nimproved unconditional bounds for two classical problems. First, for Szpiro's\nconjecture when the relevant elliptic curves are members of a one-parameter\nfamily (an elliptic surface). And secondly, for the problem of giving lower\nbounds for the greatest prime factor of polynomial values, in the case of\nquadratic and cubic polynomials. The latter extends earlier work by the second\nauthor for the polynomial $n^2+1$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T15:12:24Z"}
{"aid":"http://arxiv.org/abs/2504.15974v1","title":"Well-posedness of the transport of normal currents by time-dependent\n  vector fields","summary":"We prove existence and uniqueness for the transport equation for currents\n(Geometric Transport Equation) when the driving vector field is time-dependent,\nLipschitz in space and merely integrable in time. This extends previous work\nwhere well-posedness was shown in the case of a time-independent, Lipschitz\nvector field. The proof relies on the decomposability bundle and requires to\nextend some of its properties to the class of functions that in one direction\nare only absolutely continuous, rather than Lipschitz.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T15:21:17Z"}
{"aid":"http://arxiv.org/abs/2504.15993v1","title":"Benchmarking machine learning models for predicting aerofoil performance","summary":"This paper investigates the capability of Neural Networks (NNs) as\nalternatives to the traditional methods to analyse the performance of aerofoils\nused in the wind and tidal energy industry. The current methods used to assess\nthe characteristic lift and drag coefficients include Computational Fluid\nDynamics (CFD), thin aerofoil and panel methods, all face trade-offs between\ncomputational speed and the accuracy of the results and as such NNs have been\ninvestigated as an alternative with the aim that it would perform both quickly\nand accurately. As such, this paper provides a benchmark for the windAI_bench\ndataset published by the National Renewable Energy Laboratory (NREL) in the\nUSA. In order to validate the methodology of the benchmarking, the AirfRANS\n{\\tt arXiv:2212.07564v3} dataset is used as both a starting point and a point\nof comparison. This study evaluates four neural networks (MLP, PointNet,\nGraphSAGE, GUNet) trained on a range aerofoils at 25 angles of attack\n(4$^\\circ$ to 20$^\\circ$). to predict fluid flow and calculate lift\ncoefficients ($C_L$) via the panel method. GraphSAGE and GUNet performed well\nduring the testing phase, but underperformed during validation. Accordingly,\nthis paper has identified PointNet and MLP as the two strongest models tested,\nhowever whilst the results from MLP are more commonly correct for predicting\nthe behaviour of the fluid, the results from PointNet provide the more accurate\nresults for calculating $C_L$.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-22T15:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.15998v1","title":"Effects of the Matter Potential at One-Loop Level on Neutrino\n  Oscillations in Long-Baseline Experiments","summary":"In this work, we demonstrate that one-loop corrections to the matter\npotential for neutrino oscillations can significantly impact the sensitivity to\nneutrino mass ordering in long-baseline accelerator experiments. Using\nnumerical simulations for the future experiment DUNE, we find that the\nstatistical significance for excluding the incorrect mass ordering can be\nenhanced by $1.0\\sigma$--$1.2\\sigma$ if a one-loop correction of $5.8\\%$ --\npredicted by the Standard Model in the on-shell renormalization scheme -- is\nincluded. Even with a smaller correction of $2.0\\%$, based instead on the Fermi\ncoupling constant $G^{}_\\mu$ derived from measurements of muon lifetime, we\nshow that the enhancement remains notable at about $0.4\\sigma$. In contrast,\nthe sensitivity to leptonic CP violation in DUNE is essentially unchanged.\nFinally, we emphasize that one-loop corrections should be incorporated into\nanalyses of future neutrino oscillation data in a consistent and systematic\nmanner.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T16:03:43Z"}
{"aid":"http://arxiv.org/abs/2504.16001v1","title":"Approximation of Invariant Solutions to the Nonlinear Filtration\n  Equation by Modified Pade Approximants","summary":"This paper deals with a mathematical model for oil filtration in a porous\nmedium and its self-similar and traveling wave regimes. The model consists of\nthe equation for conservation mass and dependencies for porosity, permeability,\nand oil density on pressure. The oil viscosity is considered to be the\nexperimentally expired parabolic relationship on pressure. To close the model,\ntwo types of Darcy law are used: the classic one and the dynamic one describing\nthe relaxation processes during filtration. In the former case, self-similar\nsolutions are studied, while in the latter case, traveling wave solutions are\nthe focus. Using the invariant solutions, the initial model is reduced to the\nnonlinear ordinary differential equations possessing the trajectories vanishing\nat infinity and representing the moving liquid fronts in porous media. To\napproximate these solutions, we elaborate the semi-analytic procedure based on\nmodified Pade approximants. In fact, we calculate sequentially Pade\napproximants up to 3d order for a two-point boundary value problem on the\nsemi-infinite domain. A good agreement of evaluated Pade approximants and\nnumerical solutions is observed. The approach provides relatively simple\nquasi-rational expressions of solutions and can be easily adapted for other\ntypes of model's nonlinearity.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-22T16:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.16002v1","title":"A logarithmic analogue of Alladi's formula","summary":"Let $\\mu(n)$ be the M\\\"{o}bius function. Let $P^-(n)$ denote the smallest\nprime factor of an integer $n$. In 1977, Alladi established the following\nformula related to the prime number theorem for arithmetic progressions \\[\n  -\\sum_{\\substack{n\\geq 2\\\\ P^-(n)\\equiv \\ell ({\\rm\nmod}k)}}\\frac{\\mu(n)}{n}=\\frac1{\\varphi(k)} \\] for positive integers $\\ell,\nk\\ge$ with $(\\ell,k)=1$, where $\\varphi$ is Euler's totient function. In this\nnote, we will show a logarithmic analogue of Alladi's formula in an elementary\nproof.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T16:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.16004v1","title":"Clifford and Non-Clifford Splitting in Quantum Circuits: Applications\n  and ZX-Calculus Detection Procedure","summary":"Classical simulation of quantum circuits is a pivotal part of the quantum\ncomputing landscape, specially within the NISQ era, where the constraints\nimposed by available hardware are unavoidable. The Gottesman-Knill theorem\nfurther motivates this argument by accentuating the importance of Clifford\ncircuits and their role on this topic of simulation. In this work, we propose\nand analyze use cases that come from quantum circuits that can be written as\nproduct between a Clifford and a Non-Clifford unitary, these ranging from fully\nclassical emulation, hybrid quantum-classical execution or even quantum\nalgorithm simplification. To further complement this analysis, we make use of\nZX-Calculus and its assets to detect a limiting border of these circuits that\nwould allow for a separation between a Clifford section and a Non-Clifford\nsection. To achieve this, we present a novel procedure for parsing ZX diagrams,\nthat not only allows for the detection of this border but also simplifies the\ncircuit extraction process.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T16:10:34Z"}
{"aid":"http://arxiv.org/abs/2504.16012v1","title":"Interpolation error analysis using a new geometric parameter","summary":"This article presents novel proof methods for estimating interpolation\nerrors, predicated on the understanding that one has already studied\nfoundational error analysis using the finite element method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T16:20:54Z"}
{"aid":"http://arxiv.org/abs/2504.16020v1","title":"AlphaGrad: Non-Linear Gradient Normalization Optimizer","summary":"We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer\naddressing the memory overhead and hyperparameter complexity of adaptive\nmethods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2\ngradient normalization followed by a smooth hyperbolic tangent transformation,\n$g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness\nparameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm\nformulation; (2) a formal non-convex convergence analysis guaranteeing\nstationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN,\nTD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent\nperformance profile. While exhibiting instability in off-policy DQN, it\nprovides enhanced training stability with competitive results in TD3 (requiring\ncareful $\\alpha$ tuning) and achieves substantially superior performance in\non-policy PPO. These results underscore the critical importance of empirical\n$\\alpha$ selection, revealing strong interactions between the optimizer's\ndynamics and the underlying RL algorithm. AlphaGrad presents a compelling\nalternative optimizer for memory-constrained scenarios and shows significant\npromise for on-policy learning regimes where its stability and efficiency\nadvantages can be particularly impactful.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE,stat.ML","published":"2025-04-22T16:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.16053v1","title":"LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free\n  Receptive Field Enlargement","summary":"State space models (SSMs) have emerged as an efficient alternative to\nTransformer models for language modeling, offering linear computational\ncomplexity and constant memory usage as context length increases. However,\ndespite their efficiency in handling long contexts, recent studies have shown\nthat SSMs, such as Mamba models, generally underperform compared to\nTransformers in long-context understanding tasks. To address this significant\nshortfall and achieve both efficient and accurate long-context understanding,\nwe propose LongMamba, a training-free technique that significantly enhances the\nlong-context capabilities of Mamba models. LongMamba builds on our discovery\nthat the hidden channels in Mamba can be categorized into local and global\nchannels based on their receptive field lengths, with global channels primarily\nresponsible for long-context capability. These global channels can become the\nkey bottleneck as the input context lengthens. Specifically, when input lengths\nlargely exceed the training sequence length, global channels exhibit\nlimitations in adaptively extend their receptive fields, leading to Mamba's\npoor long-context performance. The key idea of LongMamba is to mitigate the\nhidden state memory decay in these global channels by preventing the\naccumulation of unimportant tokens in their memory. This is achieved by first\nidentifying critical tokens in the global channels and then applying token\nfiltering to accumulate only those critical tokens. Through extensive\nbenchmarking across synthetic and real-world long-context scenarios, LongMamba\nsets a new standard for Mamba's long-context performance, significantly\nextending its operational range without requiring additional training. Our code\nis available at https://github.com/GATECH-EIC/LongMamba.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T17:30:36Z"}
{"aid":"http://arxiv.org/abs/2504.16061v1","title":"Vision language models are unreliable at trivial spatial cognition","summary":"Vision language models (VLMs) are designed to extract relevant visuospatial\ninformation from images. Some research suggests that VLMs can exhibit humanlike\nscene understanding, while other investigations reveal difficulties in their\nability to process relational information. To achieve widespread applicability,\nVLMs must perform reliably, yielding comparable competence across a wide\nvariety of related tasks. We sought to test how reliable these architectures\nare at engaging in trivial spatial cognition, e.g., recognizing whether one\nobject is left of another in an uncluttered scene. We developed a benchmark\ndataset -- TableTest -- whose images depict 3D scenes of objects arranged on a\ntable, and used it to evaluate state-of-the-art VLMs. Results show that\nperformance could be degraded by minor variations of prompts that use logically\nequivalent descriptions. These analyses suggest limitations in how VLMs may\nreason about spatial relations in real-world applications. They also reveal\nnovel opportunities for bolstering image caption corpora for more efficient\ntraining and testing.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T17:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.16075v1","title":"Explainable Unsupervised Anomaly Detection with Random Forest","summary":"We describe the use of an unsupervised Random Forest for similarity learning\nand improved unsupervised anomaly detection. By training a Random Forest to\ndiscriminate between real data and synthetic data sampled from a uniform\ndistribution over the real data bounds, a distance measure is obtained that\nanisometrically transforms the data, expanding distances at the boundary of the\ndata manifold. We show that using distances recovered from this transformation\nimproves the accuracy of unsupervised anomaly detection, compared to other\ncommonly used detectors, demonstrated over a large number of benchmark\ndatasets. As well as improved performance, this method has advantages over\nother unsupervised anomaly detection methods, including minimal requirements\nfor data preprocessing, native handling of missing data, and potential for\nvisualizations. By relating outlier scores to partitions of the Random Forest,\nwe develop a method for locally explainable anomaly predictions in terms of\nfeature importance.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-22T17:54:44Z"}
{"aid":"http://arxiv.org/abs/2504.16389v1","title":"SaENeRF: Suppressing Artifacts in Event-based Neural Radiance Fields","summary":"Event cameras are neuromorphic vision sensors that asynchronously capture\nchanges in logarithmic brightness changes, offering significant advantages such\nas low latency, low power consumption, low bandwidth, and high dynamic range.\nWhile these characteristics make them ideal for high-speed scenarios,\nreconstructing geometrically consistent and photometrically accurate 3D\nrepresentations from event data remains fundamentally challenging. Current\nevent-based Neural Radiance Fields (NeRF) methods partially address these\nchallenges but suffer from persistent artifacts caused by aggressive network\nlearning in early stages and the inherent noise of event cameras. To overcome\nthese limitations, we present SaENeRF, a novel self-supervised framework that\neffectively suppresses artifacts and enables 3D-consistent, dense, and\nphotorealistic NeRF reconstruction of static scenes solely from event streams.\nOur approach normalizes predicted radiance variations based on accumulated\nevent polarities, facilitating progressive and rapid learning for scene\nrepresentation construction. Additionally, we introduce regularization losses\nspecifically designed to suppress artifacts in regions where photometric\nchanges fall below the event threshold and simultaneously enhance the light\nintensity difference of non-zero events, thereby improving the visual fidelity\nof the reconstructed scene. Extensive qualitative and quantitative experiments\ndemonstrate that our method significantly reduces artifacts and achieves\nsuperior reconstruction quality compared to existing methods. The code is\navailable at https://github.com/Mr-firework/SaENeRF.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T03:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.16402v1","title":"Detection of X-ray Polarization in the Hard State of IGR J17091-3624:\n  Spectro-Polarimetric Study with IXPE and NuSTAR Data","summary":"The class-transition Galactic X-ray binary IGR J17091--3624 was\nsimultaneously monitored by the IXPE and NuSTAR satellites. We present a\ndetailed spectro-polarimetric study of the source using data from both\nsatellites covering the period from March 7-10, 2025. A polarimetric analysis\nin the $2$-$8$~keV band using a model-independent method reveals a significant\ndetection of polarization degree (PD) of $(11.3\\pm2.35)\\%$ at a polarization\nangle (PA) of $82^\\circ.7\\pm5^\\circ.96$ (significant at $>4\\sigma$). The\nmodel-dependent polarization analysis using the polconst and polpow models\nyields consistent values of PD and PA. In both methods, an energy-dependent\nincreasing trend of PD is observed. In the $6$-$8$~keV band, a maximum PD of\n$(29.9\\pm8.46)\\%$ is detected at a PA of $88^\\circ.0\\pm8^\\circ.15$ (significant\nat $>3\\sigma$) . The joint spectral analysis using IXPE and NuSTAR data in the\n$2$-$70$~keV band was performed with four different sets of phenomenological\nand physical models. Our results indicate a strong dominance of non-thermal\nphotons originating from a `hot' Compton cloud, suggesting that the source was\nin a hard spectral state. Spectral fitting with the physical kerrbb and TCAF\nmodels provides an estimate of the black hole mass $M_{\\rm BH} =\n14.8^{+4.7}_{-3.4}~M_\\odot$ and dimensionless spin parameter $a^* \\sim 0.54$.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T04:11:16Z"}
{"aid":"http://arxiv.org/abs/2504.16424v1","title":"Complex tridiagonal quantum Hamiltonians and matrix continued fractions","summary":"Quantum resonances described by non-Hermitian tridiagonal-matrix Hamiltonians\n$H$ with complex energy eigenvalues $E_n \\in {\\mathbb C}$ are considered. The\nmethod of evaluation of quantities $\\sigma_n=\\sqrt{E_n^*E_n}$ known as the\nsingular values of $H$ is proposed. Its basic idea is that the quantities\n$\\sigma_n$ can be treated as square roots of eigenvalues of a certain auxiliary\nself-adjoint operator $\\mathbb{H}$. As long as such an operator can be given a\nblock-tridiagonal matrix form, we construct its resolvent as a matrix continued\nfraction. In an illustrative application of the formalism, a discrete version\nof conventional Hamiltonian $H=-d^2/dx^2+V(x)$ with complex local $V(x) \\neq\nV^*(x)$ is considered. The numerical convergence of the recipe is found quick,\nsupported also by a fixed-point-based formal proof.","main_category":"math-ph","categories":"math-ph,math.MP,quant-ph","published":"2025-04-23T05:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.16447v1","title":"Node Assigned physics-informed neural networks for thermal-hydraulic\n  system simulation: CVH/FL module","summary":"Severe accidents (SAs) in nuclear power plants have been analyzed using\nthermal-hydraulic (TH) system codes such as MELCOR and MAAP. These codes\nefficiently simulate the progression of SAs, while they still have inherent\nlimitations due to their inconsistent finite difference schemes. The use of\nempirical schemes incorporating both implicit and explicit formulations\ninherently induces unidirectional coupling in multi-physics analyses. The\nobjective of this study is to develop a novel numerical method for TH system\ncodes using physics-informed neural network (PINN). They have shown strength in\nsolving multi-physics due to the innate feature of neural networks-automatic\ndifferentiation. We propose a node-assigned PINN (NA-PINN) that is suitable for\nthe control volume approach-based system codes. NA-PINN addresses the issue of\nspatial governing equation variation by assigning an individual network to each\nnodalization of the system code, such that spatial information is excluded from\nboth the input and output domains, and each subnetwork learns to approximate a\npurely temporal solution. In this phase, we evaluated the accuracy of the PINN\nmethods for the hydrodynamic module. In the 6 water tank simulation, PINN and\nNA-PINN showed maximum absolute errors of 1.678 and 0.007, respectively. It\nshould be noted that only NA-PINN demonstrated acceptable accuracy. To the best\nof the authors' knowledge, this is the first study to successfully implement a\nsystem code using PINN. Our future work involves extending NA-PINN to a\nmulti-physics solver and developing it in a surrogate manner.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T06:17:04Z"}
{"aid":"http://arxiv.org/abs/2504.16452v1","title":"Photonic single-arm gravitational wave detectors based on the quantum\n  state transition of orbital angular momentum","summary":"We explore the quantum state transition of photon orbital angular momentum\n(OAM) in the present of gravitational waves (GWs) and demonstrate the potential\nof a new photonic single-arm GW detection technique. The interaction is\ncalculated based on the framework of the wave propagation in linearized gravity\ntheory and canonical quantization of the electromagnetic field in curved\nspacetime. It is demonstrated that when a photon possessing OAM of 1 interacts\nwith GWs, it may relinquish its OAM and produce a central signal that may be\ndetected. The detector provides a high and steady rate of detected photons in\nthe low-frequency range ($<1$ Hz), opens a potential window to identify GWs in\nthe mid-frequency range ($1\\sim10$ Hz), which is absent in other contemporary\nGW detectors, and establishes a selection rule for GW frequencies in the\nhigh-frequency range ($>10$ Hz), allowing for the adjustment of detector\nparameters to focus on specific GW frequencies. Furthermore, the detector is\ninsensitive to seismic noise, and the detectable photon count rate is\nproportional to the square of the GW amplitude, making it more advantageous for\ndetermining the distance of the source compared to current interferometer\ndetectors. This technique not only facilitates the extraction of GW information\nbut also creates a new approach for identifying and selecting GW signals.","main_category":"gr-qc","categories":"gr-qc,astro-ph.IM,quant-ph","published":"2025-04-23T06:32:06Z"}
{"aid":"http://arxiv.org/abs/2504.16461v1","title":"Sum rules for x-ray circular and linear dichroism based on complete\n  magnetic multipole basis","summary":"X-ray magnetic circular dichroism (XMCD) and X-ray magnetic linear dichroism\n(XMLD) are powerful spectroscopic techniques for probing magnetic properties in\nsolids. In this study, we revisit the XMCD and XMLD sum rules within a complete\nmagnetic multipole basis that incorporates both spinless and spinful\nmultipoles. We demonstrate that these multipoles can be clearly distinguished\nand individually detected through the sum-rule formalism. Within this\nframework, the anisotropic magnetic dipole term is naturally derived in XMCD,\noffering a microscopic origin for ferromagnetic-like behavior in\nantiferromagnets. Furthermore, we derive the sum rules for out-of-plane and\nin-plane XMLD regarding electric quadrupole contributions defined based on the\ncomplete multipole basis. Our theoretical approach provides a unified,\nsymmetry-consistent framework for analyzing dichroic signals in various\nmagnetic materials. These findings deepen the understanding of XMCD and XMLD\nand open pathways to exploring complex magnetic structures and spin-orbit\ncoupling effects in emergent magnetic materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T07:14:46Z"}
{"aid":"http://arxiv.org/abs/2504.16480v1","title":"Balancing Costs and Utilities in Future Networks via Market Equilibrium\n  with Externalities","summary":"We study the problem of market equilibrium (ME) in future wireless networks,\nwith multiple actors competing and negotiating for a pool of heterogeneous\nresources (communication and computing) while meeting constraints in terms of\nglobal cost. The latter is defined in a general way but is associated with\nenergy and/or carbon emissions. In this direction, service providers competing\nfor network resources do not acquire the latter, but rather the right to\nconsume, given externally defined policies and regulations. We propose to apply\nthe Fisher market model, and prove its convergence towards an equilibrium\nbetween utilities, regulatory constraints, and individual budgets. The model is\nthen applied to an exemplary use case of access network, edge computing, and\ncloud resources, and numerical results assess the theoretical findings of\nconvergence, under different assumptions on the utility function and more or\nless stringent constraints.","main_category":"cs.GT","categories":"cs.GT,cs.NI","published":"2025-04-23T07:46:45Z"}
{"aid":"http://arxiv.org/abs/2504.16495v1","title":"Quasi-triangular and factorizable perm bialgebras","summary":"In this paper, we introduce the notions of quasi-triangular and factorizable\nperm bialgebras, based on notions of the perm Yang-Baxter equation and $(R,\n\\mathrm{ad})$-invariant condition. A factorizable perm bialgebra induces a\nfactorization of the underlying perm algebra and the double of a perm bialgebra\nnaturally admits a factorizable perm bialgebra structure. The notion of\nrelative Rota-Baxter operators of weights on perm algebras is introduced to\ncharacterize solutions of the perm Yang-Baxter equation, whose skew-symmetric\nparts are $(R, \\mathrm{ad})$-invariant. These operators are in one-to-one\ncorrespondence with linear transformations fulfilling a Rota-Baxter-type\nidentity in the case of quadratic perm algebras. Furthermore, we introduce the\nnotion of quadratic Rota-Baxter perm algebras of weights, demonstrate that a\nquadratic Rota-Baxter perm algebra of weight $0$ induces a triangular perm\nbialgebra, and establish a one-to-one correspondence between quadratic\nRota-Baxter perm algebras of nonzero weights and factorizable perm bialgebras.","main_category":"math.RT","categories":"math.RT","published":"2025-04-23T08:17:53Z"}
{"aid":"http://arxiv.org/abs/2504.16514v1","title":"A new proof of the Artin-Springer theorem in Schur index 2","summary":"We provide a new proof of the analogue of the Artin-Springer theorem for\ngroups of type $\\mathsf{D}$ that can be represented by similitudes over an\nalgebra of Schur index $2$: an anisotropic generalized quadratic form over a\nquaternion algebra $Q$ remains anisotropic after generic splitting of $Q$,\nhence also under odd degree field extensions of the base field. Our proof is\ncharacteristic free and does not use the excellence property.","main_category":"math.KT","categories":"math.KT","published":"2025-04-23T08:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.16520v1","title":"A Few-Shot Metric Learning Method with Dual-Channel Attention for\n  Cross-Modal Same-Neuron Identification","summary":"In neuroscience research, achieving single-neuron matching across different\nimaging modalities is critical for understanding the relationship between\nneuronal structure and function. However, modality gaps and limited annotations\npresent significant challenges. We propose a few-shot metric learning method\nwith a dual-channel attention mechanism and a pretrained vision transformer to\nenable robust cross-modal neuron identification. The local and global channels\nextract soma morphology and fiber context, respectively, and a gating mechanism\nfuses their outputs. To enhance the model's fine-grained discrimination\ncapability, we introduce a hard sample mining strategy based on the\nMultiSimilarityMiner algorithm, along with the Circle Loss function.\nExperiments on two-photon and fMOST datasets demonstrate superior Top-K\naccuracy and recall compared to existing methods. Ablation studies and t-SNE\nvisualizations validate the effectiveness of each module. The method also\nachieves a favorable trade-off between accuracy and training efficiency under\ndifferent fine-tuning strategies. These results suggest that the proposed\napproach offers a promising technical solution for accurate single-cell level\nmatching and multimodal neuroimaging integration.","main_category":"cs.CV","categories":"cs.CV,q-bio.NC","published":"2025-04-23T08:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.16523v1","title":"Alternately-optimized SNN method for acoustic scattering problem in\n  unbounded domain","summary":"In this paper, we propose a novel machine learning-based method to solve the\nacoustic scattering problem in unbounded domain. We first employ the\nDirichlet-to-Neumann (DtN) operator to truncate the physically unbounded domain\ninto a computable bounded domain. This transformation reduces the original\nscattering problem in the unbounded domain to a boundary value problem within\nthe bounded domain. To solve this boundary value problem, we design a neural\nnetwork with a subspace layer, where each neuron in this layer represents a\nbasis function. Consequently, the approximate solution can be expressed by a\nlinear combination of these basis functions. Furthermore, we introduce an\ninnovative alternating optimization technique which alternately updates the\nbasis functions and their linear combination coefficients respectively by\ntraining and least squares methods. In our method, we set the coefficients of\nbasis functions to 1 and use a new loss function each time train the subspace.\nThese innovations ensure that the subspace formed by these basis functions is\ntruly optimized. We refer to this method as the alternately-optimized subspace\nmethod based on neural networks (AO-SNN). Extensive numerical experiments\ndemonstrate that our new method can significantly reduce the relative $l^2$\nerror to $10^{-7}$ or lower, outperforming existing machine learning-based\nmethods to the best of our knowledge.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-23T08:46:22Z"}
{"aid":"http://arxiv.org/abs/2504.16530v1","title":"Modern Computational Methods in Reinsurance Optimization: From Simulated\n  Annealing to Quantum Branch & Bound","summary":"We propose and implement modern computational methods to enhance catastrophe\nexcess-of-loss reinsurance contracts in practice. The underlying optimization\nproblem involves attachment points, limits, and reinstatement clauses, and the\nobjective is to maximize the expected profit while considering risk measures\nand regulatory constraints. We study the problem formulation, paving the way\nfor practitioners, for two very different approaches: A local search optimizer\nusing simulated annealing, which handles realistic constraints, and a branch &\nbound approach exploring the potential of a future speedup via quantum branch &\nbound. On the one hand, local search effectively generates contract structures\nwithin several constraints, proving useful for complex treaties that have\nmultiple local optima. On the other hand, although our branch & bound\nformulation only confirms that solving the full problem with a future quantum\ncomputer would require a stronger, less expensive bound and substantial\nhardware improvements, we believe that the designed application-specific bound\nis sufficiently strong to serve as a basis for further works. Concisely, we\nprovide insurance practitioners with a robust numerical framework for contract\noptimization that handles realistic constraints today, as well as an outlook\nand initial steps towards an approach which could leverage quantum computers in\nthe future.","main_category":"math.OC","categories":"math.OC,q-fin.CP,quant-ph","published":"2025-04-23T08:55:40Z"}
{"aid":"http://arxiv.org/abs/2504.16550v1","title":"A Collaborative Intrusion Detection System Using Snort IDS Nodes","summary":"Intrusion Detection Systems (IDSs) are integral to safeguarding networks by\ndetecting and responding to threats from malicious traffic or compromised\ndevices. However, standalone IDS deployments often fall short when addressing\nthe increasing complexity and scale of modern cyberattacks. This paper proposes\na Collaborative Intrusion Detection System (CIDS) that leverages Snort, an\nopen-source network intrusion detection system, to enhance detection accuracy\nand reduce false positives. The proposed architecture connects multiple Snort\nIDS nodes to a centralised node and integrates with a Security Information and\nEvent Management (SIEM) platform to facilitate real-time data sharing,\ncorrelation, and analysis. The CIDS design includes a scalable configuration of\nSnort sensors, a centralised database for log storage, and LogScale SIEM for\nadvanced analytics and visualisation. By aggregating and analysing intrusion\ndata from multiple nodes, the system enables improved detection of distributed\nand sophisticated attack patterns that standalone IDSs may miss. Performance\nevaluation against simulated attacks, including Nmap port scans and ICMP flood\nattacks, demonstrates our CIDS's ability to efficiently process large-scale\nnetwork traffic, detect threats with higher accuracy, and reduce alert fatigue.\nThis paper highlights the potential of CIDS in modern network environments and\nexplores future enhancements, such as integrating machine learning for advanced\nthreat detection and creating public datasets to support collaborative\nresearch. The proposed CIDS framework provides a promising foundation for\nbuilding more resilient and adaptive network security systems.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-23T09:25:52Z"}
{"aid":"http://arxiv.org/abs/2504.16570v1","title":"CountingDINO: A Training-free Pipeline for Class-Agnostic Counting using\n  Unsupervised Backbones","summary":"Class-agnostic counting (CAC) aims to estimate the number of objects in\nimages without being restricted to predefined categories. However, while\ncurrent exemplar-based CAC methods offer flexibility at inference time, they\nstill rely heavily on labeled data for training, which limits scalability and\ngeneralization to many downstream use cases. In this paper, we introduce\nCountingDINO, the first training-free exemplar-based CAC framework that\nexploits a fully unsupervised feature extractor. Specifically, our approach\nemploys self-supervised vision-only backbones to extract object-aware features,\nand it eliminates the need for annotated data throughout the entire proposed\npipeline. At inference time, we extract latent object prototypes via ROI-Align\nfrom DINO features and use them as convolutional kernels to generate similarity\nmaps. These are then transformed into density maps through a simple yet\neffective normalization scheme. We evaluate our approach on the FSC-147\nbenchmark, where we outperform a baseline under the same label-free setting.\nOur method also achieves competitive -- and in some cases superior -- results\ncompared to training-free approaches relying on supervised backbones, as well\nas several fully supervised state-of-the-art methods. This demonstrates that\ntraining-free CAC can be both scalable and competitive. Website:\nhttps://lorebianchi98.github.io/CountingDINO/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T09:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.16579v1","title":"Optimization Framework for Reducing Mid-circuit Measurements and Resets","summary":"The paper addresses the optimization of dynamic circuits in quantum\ncomputing, with a focus on reducing the cost of mid-circuit measurements and\nresets. We extend the probabilistic circuit model (PCM) and implement an\noptimization framework that targets both mid-circuit measurements and resets.\nTo overcome the limitation of the prior PCM-based pass, where optimizations are\nonly possible on pure single-qubit states, we incorporate circuit synthesis to\nenable optimizations on multi-qubit states. With a parameter $n_{pcm}$, our\nframework balances optimization level against resource usage.We evaluate our\nframework using a large dataset of randomly generated dynamic circuits.\nExperimental results demonstrate that our method is highly effective in\nreducing mid-circuit measurements and resets. In our demonstrative example,\nwhen applying our optimization framework to the Bernstein-Vazirani algorithm\nafter employing qubit reuse, we significantly reduce its runtime overhead by\nremoving all of the resets.","main_category":"quant-ph","categories":"quant-ph,cs.PL,cs.SE","published":"2025-04-23T10:01:00Z"}
{"aid":"http://arxiv.org/abs/2504.16589v1","title":"More on genuine multi-entropy and holography","summary":"By generalizing the construction of genuine multi-entropy ${\\rm\nGM}[\\mathtt{q}]$ for genuine multi-partite entanglement proposed in the\nprevious paper arXiv:2504.01625, we give a prescription on how to construct\n${\\rm GM}[\\mathtt{q}]$ systematically for any $\\mathtt{q}$. The crucial point\nis that our construction naturally fits to the partition number $p(\\mathtt{a})$\nof integer $\\mathtt{a}$. For general $\\mathtt{q}$, ${\\rm GM}[\\mathtt{q}]$\ncontains $N (\\mathtt{q}) = p(\\mathtt{q})-p(\\mathtt{q}-1)-1$ number of free\nparameters. Furthermore, these give $N (\\mathtt{q})+1$ number of new\ndiagnostics for genuine $\\mathtt{q}$-partite entanglement. Especially for\n$\\mathtt{q}=4$ case, this reproduces not only the known diagnostics pointed out\nby arXiv:1406.2663, but also a new diagnostics for quadripartite entanglement.\nWe also study these ${\\rm GM}[\\mathtt{q}]$ for $\\mathtt{q} = 4, 5$ in\nholography and show that these are of the order of ${\\cal{O}}\\left(1/G_N\n\\right)$ both analytically and numerically. Our results give evidence that\ngenuine multipartite entanglement is ubiquitous in holography. We discuss the\nconnection to quantum error correction and the role of genuine multipartite\nentanglement in bulk reconstruction.","main_category":"hep-th","categories":"hep-th,gr-qc,quant-ph","published":"2025-04-23T10:13:10Z"}
{"aid":"http://arxiv.org/abs/2504.16591v1","title":"JEPA for RL: Investigating Joint-Embedding Predictive Architectures for\n  Reinforcement Learning","summary":"Joint-Embedding Predictive Architectures (JEPA) have recently become popular\nas promising architectures for self-supervised learning. Vision transformers\nhave been trained using JEPA to produce embeddings from images and videos,\nwhich have been shown to be highly suitable for downstream tasks like\nclassification and segmentation. In this paper, we show how to adapt the JEPA\narchitecture to reinforcement learning from images. We discuss model collapse,\nshow how to prevent it, and provide exemplary data on the classical Cart Pole\ntask.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T10:16:12Z"}
{"aid":"http://arxiv.org/abs/2504.16623v1","title":"Censored lifespans in a double-truncated sample: Maximum likelihood\n  inference for the exponential distribution","summary":"The analysis of a truncated sample can be hindered by censoring. Survival\ninformation may be lost to follow-up or the birthdate may be missing. The data\ncan still be modeled as a truncated point process and it is close to a Poisson\nprocess, in the Hellinger distance, as long as the sample is small relative to\nthe population. We assume an exponential distribution for the lifespan, derive\nthe likelihood and profile out the unobservable sample size. Identification of\nthe exponential parameter is shown, together with consistency and asymptotic\nnormality of its M-estimator. Even though the estimator sequence is indexed in\nthe sample size, both the point estimator and the standard error are\nobservable. Enterprise lifespans in Germany constitute our example.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-23T11:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.16636v1","title":"Dual-Camera All-in-Focus Neural Radiance Fields","summary":"We present the first framework capable of synthesizing the all-in-focus\nneural radiance field (NeRF) from inputs without manual refocusing. Without\nrefocusing, the camera will automatically focus on the fixed object for all\nviews, and current NeRF methods typically using one camera fail due to the\nconsistent defocus blur and a lack of sharp reference. To restore the\nall-in-focus NeRF, we introduce the dual-camera from smartphones, where the\nultra-wide camera has a wider depth-of-field (DoF) and the main camera\npossesses a higher resolution. The dual camera pair saves the high-fidelity\ndetails from the main camera and uses the ultra-wide camera's deep DoF as\nreference for all-in-focus restoration. To this end, we first implement spatial\nwarping and color matching to align the dual camera, followed by a\ndefocus-aware fusion module with learnable defocus parameters to predict a\ndefocus map and fuse the aligned camera pair. We also build a multi-view\ndataset that includes image pairs of the main and ultra-wide cameras in a\nsmartphone. Extensive experiments on this dataset verify that our solution,\ntermed DC-NeRF, can produce high-quality all-in-focus novel views and compares\nfavorably against strong baselines quantitatively and qualitatively. We further\nshow DoF applications of DC-NeRF with adjustable blur intensity and focal\nplane, including refocusing and split diopter.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T11:55:02Z"}
{"aid":"http://arxiv.org/abs/2504.16640v1","title":"SSLR: A Semi-Supervised Learning Method for Isolated Sign Language\n  Recognition","summary":"Sign language is the primary communication language for people with disabling\nhearing loss. Sign language recognition (SLR) systems aim to recognize sign\ngestures and translate them into spoken language. One of the main challenges in\nSLR is the scarcity of annotated datasets. To address this issue, we propose a\nsemi-supervised learning (SSL) approach for SLR (SSLR), employing a\npseudo-label method to annotate unlabeled samples. The sign gestures are\nrepresented using pose information that encodes the signer's skeletal joint\npoints. This information is used as input for the Transformer backbone model\nutilized in the proposed approach. To demonstrate the learning capabilities of\nSSL across various labeled data sizes, several experiments were conducted using\ndifferent percentages of labeled data with varying numbers of classes. The\nperformance of the SSL approach was compared with a fully supervised\nlearning-based model on the WLASL-100 dataset. The obtained results of the SSL\nmodel outperformed the supervised learning-based model with less labeled data\nin many cases.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T11:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.16656v1","title":"Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning","summary":"We present Skywork R1V2, a next-generation multimodal reasoning model and a\nmajor leap forward from its predecessor, Skywork R1V. At its core, R1V2\nintroduces a hybrid reinforcement learning paradigm that harmonizes\nreward-model guidance with rule-based strategies, thereby addressing the\nlong-standing challenge of balancing sophisticated reasoning capabilities with\nbroad generalization. To further enhance training efficiency, we propose the\nSelective Sample Buffer (SSB) mechanism, which effectively counters the\n``Vanishing Advantages'' dilemma inherent in Group Relative Policy Optimization\n(GRPO) by prioritizing high-value samples throughout the optimization process.\nNotably, we observe that excessive reinforcement signals can induce visual\nhallucinations--a phenomenon we systematically monitor and mitigate through\ncalibrated reward thresholds throughout the training process. Empirical results\naffirm the exceptional capability of R1V2, with benchmark-leading performances\nsuch as 62.6 on OlympiadBench, 79.0 on AIME2024, 63.6 on LiveCodeBench, and\n74.0 on MMMU. These results underscore R1V2's superiority over existing\nopen-source models and demonstrate significant progress in closing the\nperformance gap with premier proprietary systems, including Gemini 2.5 and\nOpenAI o4-mini. The Skywork R1V2 model weights have been publicly released to\npromote openness and reproducibility\nhttps://huggingface.co/Skywork/Skywork-R1V2-38B.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:24:10Z"}
{"aid":"http://arxiv.org/abs/2504.16678v1","title":"An Intersection Product for the Polytope Algebra","summary":"We introduce a new multiplication for the polytope algebra, defined via the\nintersection of polytopes. After establishing the foundational properties of\nthis intersection product, we investigate finite-dimensional subalgebras that\narise naturally from this construction. These subalgebras can be regarded as\nvolumetric analogues of the graded M\\\"obius algebra, which appears in the\ncontext of the Dowling-Wilson conjecture. We conjecture that they also satisfy\nthe injective hard Lefschetz property and the Hodge-Riemann relations, and we\nprove these in degree one.","main_category":"math.CO","categories":"math.CO,math.MG","published":"2025-04-23T12:54:07Z"}
{"aid":"http://arxiv.org/abs/2504.16686v1","title":"Wafer-Scale Characterization of Al/AlxOy/Al Josephson Junctions at Room\n  Temperature","summary":"Josephson junctions (JJs) are the key element of many devices operating at\ncryogenic temperatures. Development of time-efficient wafer-scale JJ\ncharacterization for process optimization and control of JJ fabrication is\nessential. Such statistical characterization has to rely on room temperature\ntechniques since cryogenic measurements typically used for JJs are too time\nconsuming and unsuitable for wafer-scale characterization. In this work, we\nshow that from room temperature capacitance and current-voltage measurements,\nwith proper data analysis, we can independently obtain useful parameters of the\nJJs on wafer-scale, like oxide thickness, tunnel coefficient, and interfacial\ndefect densities. Moreover, based on detailed analysis of current vs voltage\ncharacteristics, different charge transport mechanisms across the junctions can\nbe distinguished. We exemplary demonstrate the worth of these methods by\nstudying junctions fabricated on 200 mm wafers with an industrially scale-able\nconcept based on subtractive processing using only CMOS compatible tools. From\nthese studies, we find that our subtractive fabrication approach yields\njunctions with quite homogeneous average oxide thickness across the full\nwafers, with a spread of less then 3$\\,$%. The analysis also revealed a\nvariation of the tunnel coefficient with oxide thickness, pointing to a\nstoichiometry gradient across the junctions' oxide width. Moreover, we\nestimated relatively low interfacial defect densities in the range of 70 -\n5000$\\,$defects/cm$^2$ for our junctions and established that the density\nincreased with decreasing oxide thickness, indicating that the wet etching\nprocess applied in the JJs fabrication for oxide thickness control leads to\nformation of interfacial trap state","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-23T13:15:01Z"}
{"aid":"http://arxiv.org/abs/2504.16688v1","title":"A Statistical Evaluation of Indoor LoRaWAN Environment-Aware Propagation\n  for 6G: MLR, ANOVA, and Residual Distribution Analysis","summary":"Modeling path loss in indoor LoRaWAN technology deployments is inherently\nchallenging due to structural obstructions, occupant density and activities,\nand fluctuating environmental conditions. This study proposes a two-stage\napproach to capture and analyze these complexities using an extensive dataset\nof 1,328,334 field measurements collected over six months in a single-floor\noffice at the University of Siegen's Hoelderlinstrasse Campus, Germany. First,\nwe implement a multiple linear regression model that includes traditional\npropagation metrics (distance, structural walls) and an extension with proposed\nenvironmental variables (relative humidity, temperature, carbon dioxide,\nparticulate matter, and barometric pressure). Using analysis of variance, we\ndemonstrate that adding these environmental factors can reduce unexplained\nvariance by 42.32 percent. Secondly, we examine residual distributions by\nfitting five candidate probability distributions: Normal, Skew-Normal, Cauchy,\nStudent's t, and Gaussian Mixture Models with one to five components. Our\nresults show that a four-component Gaussian Mixture Model captures the residual\nheterogeneity of indoor signal propagation most accurately, significantly\noutperforming single-distribution approaches. Given the push toward\nultra-reliable, context-aware communications in 6G networks, our analysis shows\nthat environment-aware modeling can substantially improve LoRaWAN network\ndesign in dynamic indoor IoT deployments.","main_category":"cs.NI","categories":"cs.NI,cs.LG,eess.SP","published":"2025-04-23T13:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.16694v1","title":"Emergent Kagome lattice and non-Abelian lattice gauge field of\n  biexcitons in t-MoTe$_2$","summary":"Non-Abelian gauge fields, characterized by their non-commutative symmetry\ngroups, shape physical laws from the Standard Model to emergent topological\nmatter for quantum computation. Here we find that moir\\'e exciton dimers\n(biexcitons) in twisted bilayer MoTe$_2$ are governed by a genuine non-Abelian\nlattice gauge field. These dipolar-bound exciton dimers, formed on bonds of the\nhoneycomb moir\\'e superlattice, exhibit three quadrupole configurations\norganized into a Kagome lattice geometry, on which the valley-flip biexciton\nhoppings through electron-hole Coulomb exchange act as link variables of the\nnon-Abelian lattice gauge theory. The emergence of gauge structure here is a\nnew possibility for composite particles, where the moir\\'e electronic structure\nand interactions between the electron and hole constituents jointly enforce the\nunderlying geometric constraint. The quadrupole nature of biexciton further\nmakes possible local gate controls to isolate designated pathways from the\nextended lattice for exploiting consequences of non-commutative gauge structure\nincluding the genuine non-Abelian Aharonov-Bohm effect. This also provides a\nnew approach for quantum manipulation of excitonic valley qubit. We show path\ninterference on a simplest loop can deterministically transform the\ncomputational basis states into Bell states.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T13:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.16740v1","title":"Gaussian Splatting is an Effective Data Generator for 3D Object\n  Detection","summary":"We investigate data augmentation for 3D object detection in autonomous\ndriving. We utilize recent advancements in 3D reconstruction based on Gaussian\nSplatting for 3D object placement in driving scenes. Unlike existing\ndiffusion-based methods that synthesize images conditioned on BEV layouts, our\napproach places 3D objects directly in the reconstructed 3D space with\nexplicitly imposed geometric transformations. This ensures both the physical\nplausibility of object placement and highly accurate 3D pose and position\nannotations.\n  Our experiments demonstrate that even by integrating a limited number of\nexternal 3D objects into real scenes, the augmented data significantly enhances\n3D object detection performance and outperforms existing diffusion-based 3D\naugmentation for object detection. Extensive testing on the nuScenes dataset\nreveals that imposing high geometric diversity in object placement has a\ngreater impact compared to the appearance diversity of objects. Additionally,\nwe show that generating hard examples, either by maximizing detection loss or\nimposing high visual occlusion in camera images, does not lead to more\nefficient 3D data augmentation for camera-based 3D object detection in\nautonomous driving.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T14:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.16786v1","title":"MOOSComp: Improving Lightweight Long-Context Compressor via Mitigating\n  Over-Smoothing and Incorporating Outlier Scores","summary":"Recent advances in large language models have significantly improved their\nability to process long-context input, but practical applications are\nchallenged by increased inference time and resource consumption, particularly\nin resource-constrained environments. To address these challenges, we propose\nMOOSComp, a token-classification-based long-context compression method that\nenhances the performance of a BERT-based compressor by mitigating the\nover-smoothing problem and incorporating outlier scores. In the training phase,\nwe add an inter-class cosine similarity loss term to penalize excessively\nsimilar token representations, thereby improving the token classification\naccuracy. During the compression phase, we introduce outlier scores to preserve\nrare but critical tokens that are prone to be discarded in task-agnostic\ncompression. These scores are integrated with the classifier's output, making\nthe compressor more generalizable to various tasks. Superior performance is\nachieved at various compression ratios on long-context understanding and\nreasoning benchmarks. Moreover, our method obtains a speedup of 3.3x at a 4x\ncompression ratio on a resource-constrained mobile device.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-23T15:02:53Z"}
{"aid":"http://arxiv.org/abs/2504.16804v1","title":"Constructing Four-Body Ballistic Lunar Transfers via Analytical Energy\n  Conditions","summary":"This paper derives and summarizes the analytical conditions for lunar\nballistic capture and constructs ballistic lunar transfers based on these\nconditions. We adopt the Sun-Earth/Moon planar bicircular restricted four-body\nproblem as the dynamical model to construct lunar transfers. First, the\nanalytical conditions for ballistic capture are derived based on the\nrelationship between the Keplerian energy with respect to the Moon and the\nangular momentum with respect to the Moon, summarized in form of exact ranges\nof the Jacobi energy at the lunar insertion point. Both sufficient and\nnecessary condition and necessary condition are developed. Then, an\noptimization method combined with the analytical energy conditions is proposed\nto construct ballistic lunar transfers. Simulations shows that a high ballistic\ncapture ratio is achieved by our proposed method (100$\\%$ for direct insertion\nand $99.15\\%$ for retrograde insertion). Examining the obtained ballistic lunar\ntransfers, the effectiveness of the analytical energy conditions is verified.\nSamples of our obtained lunar transfers achieves a lower impulse and shorter\ntime of flight compared to two conventional methods, further strengthening the\nadvantage of our proposed method.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-23T15:22:02Z"}
{"aid":"http://arxiv.org/abs/2504.16817v1","title":"Rediscussion of eclipsing binaries. Paper XXIII. The F-type twin system\n  RZ Chamaeleontis","summary":"RZ Cha is a detached eclipsing binary containing two slightly evolved F5\nstars in a circular orbit of period 2.832 d. We use new light curves from the\nTransiting Exoplanet Survey Satellite (TESS) and spectroscopic orbits from Gaia\nDR3 to measure the physical properties of the component stars. We obtain masses\nof 1.488 +/- 0.011 Msun and 1.482 +/- 0.011 Msun, and radii of 2.150 +/- 0.006\nRsun and 2.271 +/- 0.006 Rsun. An orbital ephemeris from the TESS data does not\nmatch published times of mid-eclipse from the 1970s, suggesting the period is\nnot constant. We measure a distance to the system of 176.7 +/- 3.7 pc, which\nagrees with the Gaia DR3 value. A comparison with theoretical models finds\nagreement for metal abundances of Z = 0.014 and Z = 0.017 and an age of 2.3\nGyr. No evidence for pulsations was found in the light curves. Future data from\nTESS and Gaia will provide more precise masses and constraints on any changes\nin orbital period.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.16827v1","title":"Endpoint boundedness of singular integrals: CMO space associated to\n  SchrÃ¶dinger operators","summary":"Let $ \\mathcal{L} = -\\Delta + V $ be a Schr\\\"odinger operator acting on $\nL^2(\\mathbb{R}^n) $, where the nonnegative potential $ V $ belongs to the\nreverse H\\\"older class $ RH_q $ for some $ q \\geq n/2 $. This article is\nprimarily concerned with the study of endpoint boundedness for classical\nsingular integral operators in the context of the space $\n\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $, consisting of functions of\nvanishing mean oscillation associated with $ \\mathcal{L} $.\n  We establish the following main results: (i) the standard Hardy--Littlewood\nmaximal operator is bounded on $\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $;\n(ii) for each $ j = 1, \\ldots, n$, the adjoint of the Riesz transform $\n\\partial_j \\mathcal{L}^{-1/2} $ is bounded from $ C_0(\\mathbb{R}^n) $ into $\n\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $; and (iii) the approximation to the\nidentity generated by the Poisson and heat semigroups associated with $\n\\mathcal{L} $ characterizes $ \\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $\nappropriately.\n  These results recover the classical analogues corresponding to the Laplacian\nas a special case. However, the presence of the potential $ V $ introduces\nsubstantial analytical challenges, necessitating tools beyond the scope of\nclassical Calder\\'on--Zygmund theory. Our approach leverages precise heat\nkernel estimates and the structural properties of $\n\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $ established by Song and the third\nauthor in [J. Geom. Anal. 32 (2022), no. 4, Paper No. 130, 37 pp].","main_category":"math.CA","categories":"math.CA","published":"2025-04-23T15:43:52Z"}
{"aid":"http://arxiv.org/abs/2504.16829v1","title":"Bogomolov type inequalities and Frobenius semipositivity","summary":"We prove Bogomolov type inequalities for high Chern characters of semistable\nsheaves satisfying certain Frobenius semipositivity. The key ingredients in the\nproof are a high rank generalization of the asymptotic Riemann-Roch theorem and\nLanger's estimation theorem of the global sections of torsion free sheaves.\nThese results give some Bogomolov type inequalities for semistable sheaves with\nvanishing low Chern characters. Our results are also applied to obtain\ninequalities of Chern characters of threefolds and varieties of small\ncodimension in projective spaces and abelian varieties.","main_category":"math.AG","categories":"math.AG","published":"2025-04-23T15:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.16845v1","title":"An accreting dwarf star orbiting the S-type giant star pi1 Gru","summary":"Aims. We aim to characterize the properties of the inner companion of the\nS-type AGB star pi1 Gru, and to identify plausible future evolution scenarios\nfor this triple system. Methods. We observed pi1 Gru with ALMA and VLT/SPHERE.\nIn addition, we collected archival photometry data and used the Hipparcos-Gaia\nproper motion anomaly. We derive the best orbital parameters from Bayesian\ninference. Results. The inner companion, pi1 Gru C was located at 37.4 +/- 2.0\nmas from the primary in June-July 2019 (projected separation of 6.05 +/- 0.55\nau at 161.7 +/- 11.7 pc). The best orbital solution gives a companion mass of\n0.86 (+0.22/-0.20) Msun (using the derived mass of the primary), and a\nsemi-major axis of 7.05 (+0.54/-0.57) au. This leads to an orbital period of\n11.0 (+1.7/-1.5) yr. The best solution is an elliptical orbit with eccentricity\ne = 0.35 (+0.18/-0.17), but a circular orbit cannot be totally excluded. The\nclose companion can either be a K1V (F9.5V/K7V) star or a white dwarf. The\nultraviolet and millimeter continuum photometry are consistent with the\npresence of an accretion disk around the close companion. The ultraviolet\nemission could then either originate in hot spots in an overall cooler disk, or\nalso from a hot disk in case the companion is a white dwarf. Conclusions.\nThough the close companion and the AGB star are interacting, and an accretion\ndisk is observed around the companion, the mass-accretion rate is too low to\ncause a Ia supernova but could produce novae every ~900 yr. Short wavelength\nspatially resolved observations are needed to further constrain the nature of\nthe C companion. Searches for close-in companions similar to this system will\nhelp to better understand the physics of mass- and angular-momentum transfer,\nand orbital evolution in the late evolutionary stages.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T16:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.16847v1","title":"Pulsed Magnetophononics in Gapped Quantum Magnets","summary":"One route to the control of quantum magnetism at ultrafast timescales is\nmagnetophononics, the modulation of magnetic interactions by coherently driven\nlattice excitations. Theoretical studies of a gapped quantum magnet subject to\ncontinuous, single-frequency driving of one strongly coupled phonon mode find\nintriguing phenomena including mutually repelling phonon-bitriplon excitations\nand global renormalization of the spin excitation spectrum. Because experiments\nare performed with ultrashort pulses that contain a wide range of driving\nfrequencies, we investigate phonon-bitriplon physics under pulsed laser\ndriving. We use the equations of motion to compute the transient response of\nthe driven and dissipative spin-phonon system, which we characterize using the\nphonon displacement, phonon number, and triplon occupations. In the Fourier\ntransforms of each quantity we discover a low-frequency energetic oscillation\nbetween the lattice and spin sectors, which is an intrinsically nonequilibrium\ncollective mode, and demonstrate its origin as a beating between mutually\nrepelling composite excitations. We introduce a phonon-bitriplon approximation\nthat captures all the physics of hybridization, collective mode formation, and\ndifference-frequency excitation, and show that sum-frequency phenomena also\nleave clear signatures in the repsonse. We model the appearance of such\nmagnetophononic phenomena in the strongly-coupled spin-chain compound\nCuGeO$_3$, whose overlapping phonon and spin excitation spectra are well\ncharacterized, to deduce the criteria for their possible observation in quantum\nmagnetic materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-23T16:10:01Z"}
{"aid":"http://arxiv.org/abs/2504.16870v1","title":"High-Quality Cloud-Free Optical Image Synthesis Using Multi-Temporal SAR\n  and Contaminated Optical Data","summary":"Addressing gaps caused by cloud cover and the long revisit cycle of\nsatellites is vital for providing essential data to support remote sensing\napplications. This paper tackles the challenges of missing optical data\nsynthesis, particularly in complex scenarios with cloud cover. We propose\nCRSynthNet, a novel image synthesis network that incorporates innovative\ndesigned modules such as the DownUp Block and Fusion Attention to enhance\naccuracy. Experimental results validate the effectiveness of CRSynthNet,\ndemonstrating substantial improvements in restoring structural details,\npreserving spectral consist, and achieving superior visual effects that far\nexceed those produced by comparison methods. It achieves quantitative\nimprovements across multiple metrics: a peak signal-to-noise ratio (PSNR) of\n26.978, a structural similarity index measure (SSIM) of 0.648, and a root mean\nsquare error (RMSE) of 0.050. Furthermore, this study creates the TCSEN12\ndataset, a valuable resource specifically designed to address cloud cover\nchallenges in missing optical data synthesis study. The dataset uniquely\nincludes cloud-covered images and leverages earlier image to predict later\nimage, offering a realistic representation of real-world scenarios. This study\noffer practical method and valuable resources for optical satellite image\nsynthesis task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T16:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.16884v1","title":"Do Large Language Models know who did what to whom?","summary":"Large Language Models (LLMs) are commonly criticized for not understanding\nlanguage. However, many critiques focus on cognitive abilities that, in humans,\nare distinct from language processing. Here, we instead study a kind of\nunderstanding tightly linked to language: inferring who did what to whom\n(thematic roles) in a sentence. Does the central training objective of\nLLMs-word prediction-result in sentence representations that capture thematic\nroles? In two experiments, we characterized sentence representations in four\nLLMs. In contrast to human similarity judgments, in LLMs the overall\nrepresentational similarity of sentence pairs reflected syntactic similarity\nbut not whether their agent and patient assignments were identical vs.\nreversed. Furthermore, we found little evidence that thematic role information\nwas available in any subset of hidden units. However, some attention heads\nrobustly captured thematic roles, independently of syntax. Therefore, LLMs can\nextract thematic roles but, relative to humans, this information influences\ntheir representations more weakly.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T17:00:45Z"}
{"aid":"http://arxiv.org/abs/2504.16892v1","title":"Collective Defined Contribution Schemes Without Intergenerational\n  Cross-Subsidies","summary":"We present an architecture for managing Collective Defined Contribution (CDC)\nschemes. The current approach to UK CDC can be described as shared-indexation,\nwhere the nominal benefit of every member in a scheme receives the same level\nof indexation each year. The design of such schemes rely on the use of\napproximate discounting methodologies to value liabilities, and this leads to\nintergenerational cross-subsidies which can be large and unpredictable. We\npresent an alternative approach which we call Collective-Drawdown CDC. This\napproach does not result in intergenerational cross-subsidies since all pooling\nis performed by explicit insurance contracts. It is therefore completely fair.\nMoreover, this scheme results in better pension outcomes when compared to\nshared-indexation CDC under the same model parameters.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-23T17:15:35Z"}
{"aid":"http://arxiv.org/abs/2504.16914v1","title":"MorphoNavi: Aerial-Ground Robot Navigation with Object Oriented Mapping\n  in Digital Twin","summary":"This paper presents a novel mapping approach for a universal aerial-ground\nrobotic system utilizing a single monocular camera. The proposed system is\ncapable of detecting a diverse range of objects and estimating their positions\nwithout requiring fine-tuning for specific environments. The system's\nperformance was evaluated through a simulated search-and-rescue scenario, where\nthe MorphoGear robot successfully located a robotic dog while an operator\nmonitored the process. This work contributes to the development of intelligent,\nmultimodal robotic systems capable of operating in unstructured environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T17:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.16926v1","title":"Meteor CNEOS 2014-01-08 has nothing to do with Planet 9","summary":"It has been suggested that a gravitational slingshot from the hypothetical\nPlanet 9 (P9) could explain the unusually large velocity of meteor CNEOS\n2014-01-08. I show that this explanation does not work because P9 can at most\nprovide an insignificant 0.25 km/s of the object's 42 km/s asymptotic\nheliocentric velocity and at most a 7.6 degree deflection due to P9's low\norbital speed and non-zero radius. Furthermore, the hypothesis requires an\nencounter with two planets that is trillions of times more unlikely than CNEOS\n2014-01-08 simply being fast from the beginning.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-23T17:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.17240v1","title":"Quantum stream cipher and Quantum block cipher -The Era of 100 Gbit/sec\n  real-time encryption-","summary":"This paper is the part-II of the previous paper and introduces the world of\nYuen's concept. In the theory of cryptology, the Shannon impossibility theorem\nstates that the upper bound of the security of a plaintext against a\nciphertext-only attack is the entropy of the secret key. At the same time, it\ngives the upper bound of the unicity distance against a known plaintext attack.\nHence the development of a new symmetric key cipher requires finding a way to\nundo or lift this theorem. Such challenges have been attempted with quantum\nstream cipher and quantum data locking as block cipher. Both ciphers are\ndesigned by means of differentiating the receiving performance of Bob with key\nand Eve without key according to the principle of quantum communication theory.\nThus, the origin of security of both ciphers come from the principle of keyed\ncommunication in quantum noise (KCQ) proposed by Yuen. In this paper, we\nexplain and compare the principles and features of both cipher and assist to\nimprove the quantum data locking scheme. Then we will introduce experimental\nresearch on quantum stream cipher towards commercialization, which has\nperformance superior to conventional cipher.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-24T04:28:17Z"}
{"aid":"http://arxiv.org/abs/2504.17243v1","title":"NeuralGrok: Accelerate Grokking by Neural Gradient Transformation","summary":"Grokking is proposed and widely studied as an intricate phenomenon in which\ngeneralization is achieved after a long-lasting period of overfitting. In this\nwork, we propose NeuralGrok, a novel gradient-based approach that learns an\noptimal gradient transformation to accelerate the generalization of\ntransformers in arithmetic tasks. Specifically, NeuralGrok trains an auxiliary\nmodule (e.g., an MLP block) in conjunction with the base model. This module\ndynamically modulates the influence of individual gradient components based on\ntheir contribution to generalization, guided by a bilevel optimization\nalgorithm. Our extensive experiments demonstrate that NeuralGrok significantly\naccelerates generalization, particularly in challenging arithmetic tasks. We\nalso show that NeuralGrok promotes a more stable training paradigm, constantly\nreducing the model's complexity, while traditional regularization methods, such\nas weight decay, can introduce substantial instability and impede\ngeneralization. We further investigate the intrinsic model complexity\nleveraging a novel Absolute Gradient Entropy (AGE) metric, which explains that\nNeuralGrok effectively facilitates generalization by reducing the model\ncomplexity. We offer valuable insights on the grokking phenomenon of\nTransformer models, which encourages a deeper understanding of the fundamental\nprinciples governing generalization ability.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T04:41:35Z"}
{"aid":"http://arxiv.org/abs/2504.17244v1","title":"Service Rate Regions of MDS Codes & Fractional Matchings in\n  Quasi-uniform Hypergraphs","summary":"The service rate region (SRR) has emerged as a critical performance metric\nfor distributed systems that store data redundantly. It measures the system's\nability to serve multiple users concurrently. Mathematically, the SRR is a\npolytope in R^k where each dimension corresponds to the service request rate of\none of the k data objects. This paper focuses on systems employing a class of\nMaximum Distance Separable (MDS) codes. For each code in the class, we\ncharacterize the k axes intercept points of its SRR, and the smallest standard\nsimplex that includes the SRR. We use these results to show that the SRR grows\nwith the increasing number of systematic columns in the generator matrices. We\nestablish a graph-theoretic framework associating this SRR problem with\nfractional matchings in quasi-uniform hypergraphs. Identifying the SRR polytope\nis equivalent to determining a particular image of the fractional-matching\npolytope. We introduce a notion of Greedy Matching and show that it is\nsufficient to focus on these matchings to characterize the SRR rather than the\nentire matching polytope. With these tools, we determine the SRR of a large\nsubset of the considered class of codes. Our results generalize previous\ncharacterizations of systematic and non-systematic MDS-coded systems, offering\na unified framework for analyzing service rate regions of codes.","main_category":"cs.IT","categories":"cs.IT,math.CO,math.IT","published":"2025-04-24T04:44:37Z"}
{"aid":"http://arxiv.org/abs/2504.17251v1","title":"Ultrafast ultrasound coded vector Doppler imaging of blood flow velocity\n  and resistivity","summary":"Dynamic and precise measurement of cerebral blood flow velocity is crucial in\nneuroscience and the diagnosis of cerebrovascular diseases. Traditional color\nDoppler ultrasound can only measure the velocity component along the ultrasound\nbeam, which restricts its ability to accurately capture the complete blood flow\nvector in complex environments. To overcome these limitations, we propose an\nultrafast pulse-coded vector Doppler (PC-UVD) imaging method, utilizing\nHadamard matrix-based pulse encoding to improve velocity estimation accuracy\nunder low signal-to-noise ratio (SNR) conditions. Our study encompasses spiral\nflow simulations and in vivo rat brain experiments, showing significantly\nenhanced measurement precision compared to conventional ultrafast vector\nDoppler (UVD). This innovative approach enables the measurement of dynamic\ncerebral blood flow velocity within a single cardiac cycle, offering insights\ninto the characteristics of cerebrovascular resistivity. The proposed PC-UVD\nmethod employs Hadamard matrix encoding of plane waves, boosting SNR without\ncompromising temporal or spatial resolution. Velocity vectors are subsequently\nestimated using a weighted least squares (WLS) approach, with iterative\nresidual-based weight optimization improving robustness to noise and minimizing\nthe impact of outliers. The effectiveness of this technique is confirmed\nthrough simulations with a spiral blood flow phantom, demonstrating a marked\nimprovement in velocity estimation accuracy, particularly in deep imaging\nregions with significant signal attenuation. In vivo experiments on rat brains\nfurther confirm that the proposed method offers greater accuracy than existing\nUVD approaches, particularly for small vessels. Notably, our method can\nprecisely differentiate arterial from venous flow by analyzing pulsatility and\nresistivity within the cerebral vascular network.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-24T05:01:06Z"}
{"aid":"http://arxiv.org/abs/2504.17259v1","title":"Multiobjective Optimization for Robust Holonomic Quantum Gates","summary":"Robust pulses have been widely used to reduce the sensitivity of quantum gate\noperations against various systematic errors due to the imperfections in\npractical quantum control. Yet, the typical optimization focuses on minimizing\none type of errors serving as the one-objective algorithm, which arises a more\nsusceptible sensitivity to other error sources. Optimizing multiple conflicting\nobjectives of errors simultaneously remains a big challenge in quantum\ncomputing. Here, we propose a multiobjective optimization algorithm to achieve\nnonadiabatic holonomic quantum gates with enhanced robustness. We show that by\nconsidering the amplitude error, the detuning error and the decoherence of the\nRydberg state as three individual objectives to be minimized, this algorithm\ncan effectively balance multiple competing objectives, giving rise to a set of\nPareto optimal solutions. We apply the Entropy Weight method to select the best\nsolution that implements the robust holonomic gates, outperforming existing\noptimal gates with one-objective by having both higher gate fidelity and\nstronger robustness. This numerical approach of optimizing gates with multiple\nobjectives can be readily applied to other gate protocols featuring a promising\nadvance in fault-tolerant quantum computing with Rydberg atoms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-24T05:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.17275v1","title":"Physics-Embedded Bayesian Neural Network (PE-BNN) to predict Energy\n  Dependence of Fission Product Yields with Fine Structures","summary":"We present a physics-embedded Bayesian neural network (PE-BNN) framework that\nintegrates fission product yields (FPYs) with prior nuclear physics knowledge\nto predict energy-dependent FPY data with fine structure. By incorporating an\nenergy-independent phenomenological shell factor as a single input feature, the\nPE-BNN captures both fine structures and global energy trends. The combination\nof this physics-informed input with hyperparameter optimization via the\nWatanabe-Akaike Information Criterion (WAIC) significantly enhances predictive\nperformance. Our results demonstrate that the PE-BNN framework is well-suited\nfor target observables with systematic features that can be embedded as model\ninputs, achieving close agreement with known shell effects and prompt neutron\nmultiplicities.","main_category":"nucl-th","categories":"nucl-th,nucl-ex,physics.data-an","published":"2025-04-24T06:04:04Z"}
{"aid":"http://arxiv.org/abs/2504.17281v1","title":"Building Sustainable and Trustworthy Indigenous Knowledge Preservation\n  Ecosystem","summary":"This paper focuses on the essential global issue of protecting and\ntransmitting indigenous knowledge. It reveals the challenges in this area and\nproposes a sustainable supply chain framework for indigenous knowledge. The\npaper reviews existing technological solutions and identifies technical\nchallenges and gaps. It then introduces cutting-edge technologies to protect\nand disseminate indigenous knowledge more effectively. The paper also discusses\nhow the proposed framework can address real-world challenges in protecting and\ntransmitting indigenous knowledge, and explores future research applications of\nthe proposed solutions. Finally, it addresses open issues and provides a\ndetailed analysis, offering promising research directions for the protection\nand transmission of indigenous knowledge worldwide.","main_category":"cs.CY","categories":"cs.CY,cs.ET","published":"2025-04-24T06:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.17312v1","title":"Quantum diamond microscopy of individual vaterite microspheres\n  containing magnetite nanoparticles","summary":"Biocompatible vaterite microspheres, renowned for their porous structure, are\npromising carriers for magnetic nanoparticles (MNPs) in biomedical applications\nsuch as targeted drug delivery and diagnostic imaging. Precise control over the\nmagnetic moment of individual microspheres is crucial for these applications.\nThis study employs widefield quantum diamond microscopy to map the stray\nmagnetic fields of individual vaterite microspheres (3-10 um) loaded with Fe3O4\nMNPs of varying sizes (5 nm, 10 nm, and 20 nm). By analyzing over 35\nmicrospheres under a 222 mT external magnetizing field, we measured\npeak-to-peak stray field amplitudes of 41 uT for 5 nm and 10 nm\nsuperparamagnetic MNPs, reflecting their comparable magnetic response, and 12\nuT for 20 nm ferrimagnetic MNPs, due to distinct magnetization behavior.\nFinite-element simulations confirm variations in MNP distribution and\nmagnetization uniformity within the vaterite matrix, with each microsphere\nencapsulating thousands of MNPs to generate its magnetization. This\nhigh-resolution magnetic imaging approach yields critical insights into\nMNP-loaded vaterite, enabling optimized synthesis and magnetically controlled\nsystems for precision therapies and diagnostics.","main_category":"physics.bio-ph","categories":"physics.bio-ph,physics.app-ph","published":"2025-04-24T07:13:32Z"}
{"aid":"http://arxiv.org/abs/2504.17404v1","title":"Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI\n  Co-Alignment to Sustainable Symbiotic Society","summary":"Artificial Intelligence (AI) systems are becoming increasingly powerful and\nautonomous, and may progress to surpass human intelligence levels, namely\nArtificial Superintelligence (ASI). During the progression from AI to ASI, it\nmay exceed human control, violate human values, and even lead to irreversible\ncatastrophic consequences in extreme cases. This gives rise to a pressing issue\nthat needs to be addressed: superalignment, ensuring that AI systems much\nsmarter than humans, remain aligned with human (compatible) intentions and\nvalues. Existing scalable oversight and weak-to-strong generalization methods\nmay prove substantially infeasible and inadequate when facing ASI. We must\nexplore safer and more pluralistic frameworks and approaches for\nsuperalignment. In this paper, we redefine superalignment as the human-AI\nco-alignment towards a sustainable symbiotic society, and highlight a framework\nthat integrates external oversight and intrinsic proactive alignment. External\noversight superalignment should be grounded in human-centered ultimate\ndecision, supplemented by interpretable automated evaluation and correction, to\nachieve continuous alignment with humanity's evolving values. Intrinsic\nproactive superalignment is rooted in a profound understanding of the self,\nothers, and society, integrating self-awareness, self-reflection, and empathy\nto spontaneously infer human intentions, distinguishing good from evil and\nproactively considering human well-being, ultimately attaining human-AI\nco-alignment through iterative interaction. The integration of\nexternally-driven oversight with intrinsically-driven proactive alignment\nempowers sustainable symbiotic societies through human-AI co-alignment, paving\nthe way for achieving safe and beneficial AGI and ASI for good, for human, and\nfor a symbiotic ecology.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T09:53:49Z"}
{"aid":"http://arxiv.org/abs/2504.17405v1","title":"Classical Estimation of the Free Energy and Quantum Gibbs Sampling from\n  the Markov Entropy Decomposition","summary":"We revisit the Markov Entropy Decomposition, a classical convex relaxation\nalgorithm introduced by Poulin and Hastings to approximate the free energy in\nquantum spin lattices. We identify a sufficient condition for its convergence,\nnamely the decay of the effective interaction. We prove that this condition is\nsatisfied for systems in 1D at any temperature as well as in the\nhigh-temperature regime under a certain commutativity condition on the\nHamiltonian. This yields polynomial and quasi-polynomial time approximation\nalgorithms in these settings, respectively. Furthermore, the decay of the\neffective interaction implies the decay of the conditional mutual information\nfor the Gibbs state of the system. We then use this fact to devise a rounding\nscheme that maps the solution of the convex relaxation to a global state and\nshow that the scheme can be efficiently implemented on a quantum computer, thus\nproving efficiency of quantum Gibbs sampling under our assumption of decay of\nthe effective interaction.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-24T09:53:53Z"}
{"aid":"http://arxiv.org/abs/2504.17428v1","title":"Detection, Classification and Prevalence of Self-Admitted Aging Debt","summary":"Context: Previous research on software aging is limited with focus on dynamic\nruntime indicators like memory and performance, often neglecting evolutionary\nindicators like source code comments and narrowly examining legacy issues\nwithin the TD context. Objective: We introduce the concept of Aging Debt (AD),\nrepresenting the increased maintenance efforts and costs needed to keep\nsoftware updated. We study AD through Self-Admitted Aging Debt (SAAD) observed\nin source code comments left by software developers. Method: We employ a\nmixed-methods approach, combining qualitative and quantitative analyses to\ndetect and measure AD in software. This includes framing SAAD patterns from the\nsource code comments after analysing the source code context, then utilizing\nthe SAAD patterns to detect SAAD comments. In the process, we develop a\ntaxonomy for SAAD that reflects the temporal aging of software and its\nassociated debt. Then we utilize the taxonomy to quantify the different types\nof AD prevalent in OSS repositories. Results: Our proposed taxonomy categorizes\ntemporal software aging into Active and Dormant types. Our extensive analysis\nof over 9,000+ Open Source Software (OSS) repositories reveals that more than\n21% repositories exhibit signs of SAAD as observed from our gold standard SAAD\ndataset. Notably, Dormant AD emerges as the predominant category, highlighting\na critical but often overlooked aspect of software maintenance. Conclusion: As\nsoftware volume grows annually, so do evolutionary aging and maintenance\nchallenges; our proposed taxonomy can aid researchers in detailed software\naging studies and help practitioners develop improved and proactive maintenance\nstrategies.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CE,cs.GL","published":"2025-04-24T10:38:55Z"}
{"aid":"http://arxiv.org/abs/2504.17480v1","title":"Unified Attacks to Large Language Model Watermarks: Spoofing and\n  Scrubbing in Unauthorized Knowledge Distillation","summary":"Watermarking has emerged as a critical technique for combating misinformation\nand protecting intellectual property in large language models (LLMs). A recent\ndiscovery, termed watermark radioactivity, reveals that watermarks embedded in\nteacher models can be inherited by student models through knowledge\ndistillation. On the positive side, this inheritance allows for the detection\nof unauthorized knowledge distillation by identifying watermark traces in\nstudent models. However, the robustness of watermarks against scrubbing attacks\nand their unforgeability in the face of spoofing attacks under unauthorized\nknowledge distillation remain largely unexplored. Existing watermark attack\nmethods either assume access to model internals or fail to simultaneously\nsupport both scrubbing and spoofing attacks. In this work, we propose\nContrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified\nframework that enables bidirectional attacks under unauthorized knowledge\ndistillation. Our approach employs contrastive decoding to extract corrupted or\namplified watermark texts via comparing outputs from the student model and\nweakly watermarked references, followed by bidirectional distillation to train\nnew student models capable of watermark removal and watermark forgery,\nrespectively. Extensive experiments show that CDG-KD effectively performs\nattacks while preserving the general performance of the distilled model. Our\nfindings underscore critical need for developing watermarking schemes that are\nrobust and unforgeable.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T12:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.17493v1","title":"Goal-Oriented Time-Series Forecasting: Foundation Framework Design","summary":"Traditional time-series forecasting often focuses only on minimizing\nprediction errors, ignoring the specific requirements of real-world\napplications that employ them. This paper presents a new training methodology,\nwhich allows a forecasting model to dynamically adjust its focus based on the\nimportance of forecast ranges specified by the end application. Unlike previous\nmethods that fix these ranges beforehand, our training approach breaks down\npredictions over the entire signal range into smaller segments, which are then\ndynamically weighted and combined to produce accurate forecasts. We tested our\nmethod on standard datasets, including a new dataset from wireless\ncommunication, and found that not only it improves prediction accuracy but also\nimproves the performance of end application employing the forecasting model.\nThis research provides a basis for creating forecasting systems that better\nconnect prediction and decision-making in various practical applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T12:34:43Z"}
{"aid":"http://arxiv.org/abs/2504.17505v1","title":"Auerbach bases, projection constants, and the joint spectral radius of\n  principal submatrices","summary":"It is shown that compact sets of complex matrices can always be brought, via\nsimilarity transformation, into a form where all matrix entries are bounded in\nabsolute value by the joint spectral radius (JSR). The key tool for this is\nthat every extremal norm of a matrix set admits an Auerbach basis; any such\nbasis gives rise to a desired coordinate system. An immediate implication is\nthat all diagonal entries - equivalently, all one-dimensional principal\nsubmatrices - are uniformly bounded above by the JSR. It is shown that the\ncorresponding bounding property does not hold for higher dimensional principal\nsubmatrices. More precisely, we construct finite matrix sets for which, across\nthe entire similarity orbit, the JSRs of all higher-dimensional principal\nsubmatrices exceed that of the original set. This shows that the bounding\nresult does not extend to submatrices of dimension greater than one. The\nconstructions rely on tools from the geometry of finite-dimensional Banach\nspaces, with projection constants of norms playing a key role. Additional\nbounds of the JSR of principal submatrices are obtained using John's\nellipsoidal approximation and known estimates for projection constants.","main_category":"math.DS","categories":"math.DS,math.FA","published":"2025-04-24T12:48:53Z"}
{"aid":"http://arxiv.org/abs/2504.17512v1","title":"Admittance Identification of Grid-Forming Inverters Using Time and\n  Frequency-Domain Techniques","summary":"The increasing integration of inverter-based resources (IBRs) into the power\ngrid introduces new challenges, requiring detailed electromagnetic transient\n(EMT) studies to analyze system interactions. Despite these needs, access to\nthe internal firmware of power electronic devices remains restricted due to\nstringent nondisclosure agreements enforced by manufacturers. To address this,\nwe explore three system identification techniques: sweep frequency response\nanalysis (SFRA), step excitation method (SEM), and eigensystem realization\nalgorithm (ERA). SFRA employs sinusoidal signals of varying frequencies to\nmeasure the system's frequency response, while SEM and ERA utilize step\nfunctions to derive time-domain responses and transform them into\nLaplace-domain transfer functions. All three approaches are shown to provide\nconsistent results in identifying the dq admittance of grid-forming inverters\n(GFM) over a frequency range of 1 Hz to 100 Hz.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-24T12:56:26Z"}
{"aid":"http://arxiv.org/abs/2504.17518v1","title":"On estimates for the discrete eigenvalues of two-dimensional quantum\n  waveguides","summary":"In this paper, we give upper estimates for the number and sum of eigenvalues\nbelow the bottom of the essential spectrum counting multiplicities of quantum\nwaveguides in two dimensions. We consider both straight and curved waveguides\nof constant width, and the estimates are presented in terms of norms of the\npotential. For curved quantum waveguide, we assume that the waveguide is not\nself-intersecting and its curvature is a continuous and bounded function on R.\nThe estimates are new, particularly for the case of curved quantum waveguides\nand this opens a window for their extension to different configurations such as\nwaveguides with local defamations.","main_category":"math.SP","categories":"math.SP","published":"2025-04-24T13:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.17519v1","title":"Replication and Exploration of Generative Retrieval over Dynamic Corpora","summary":"Generative retrieval (GR) has emerged as a promising paradigm in information\nretrieval (IR). However, most existing GR models are developed and evaluated\nusing a static document collection, and their performance in dynamic corpora\nwhere document collections evolve continuously is rarely studied. In this\npaper, we first reproduce and systematically evaluate various representative GR\napproaches over dynamic corpora. Through extensive experiments, we reveal that\nexisting GR models with \\textit{text-based} docids show superior generalization\nto unseen documents. We observe that the more fine-grained the docid design in\nthe GR model, the better its performance over dynamic corpora, surpassing BM25\nand even being comparable to dense retrieval methods. While GR models with\n\\textit{numeric-based} docids show high efficiency, their performance drops\nsignificantly over dynamic corpora. Furthermore, our experiments find that the\nunderperformance of numeric-based docids is partly due to their excessive\ntendency toward the initial document set, which likely results from overfitting\non the training set. We then conduct an in-depth analysis of the\nbest-performing GR methods. We identify three critical advantages of text-based\ndocids in dynamic corpora: (i) Semantic alignment with language models'\npretrained knowledge, (ii) Fine-grained docid design, and (iii) High lexical\ndiversity. Building on these insights, we finally propose a novel multi-docid\ndesign that leverages both the efficiency of numeric-based docids and the\neffectiveness of text-based docids, achieving improved performance in dynamic\ncorpus without requiring additional retraining. Our work offers empirical\nevidence for advancing GR methods over dynamic corpora and paves the way for\ndeveloping more generalized yet efficient GR models in real-world search\nengines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T13:01:23Z"}
{"aid":"http://arxiv.org/abs/2504.17531v1","title":"Towards Machine-Generated Code for the Resolution of User Intentions","summary":"The growing capabilities of Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), prompt a reassessment of the interaction mechanisms\nbetween users and their devices. Currently, users are required to use a set of\nhigh-level applications to achieve their desired results. However, the advent\nof AI may signal a shift in this regard, as its capabilities have generated\nnovel prospects for user-provided intent resolution through the deployment of\nmodel-generated code, which is tantamount to the generation of workflows\ncomprising a multitude of interdependent steps. This development represents a\nsignificant progression in the realm of hybrid workflows, where human and\nartificial intelligence collaborate to address user intentions, with the former\nresponsible for defining these intentions and the latter for implementing the\nsolutions to address them. In this paper, we investigate the feasibility of\ngenerating and executing workflows through code generation that results from\nprompting an LLM with a concrete user intention, such as \\emph{Please send my\ncar title to my insurance company}, and a simplified application programming\ninterface for a GUI-less operating system. We provide in-depth analysis and\ncomparison of various user intentions, the resulting code, and its execution.\nThe findings demonstrate a general feasibility of our approach and that the\nemployed LLM, GPT-4o-mini, exhibits remarkable proficiency in the generation of\ncode-oriented workflows in accordance with provided user intentions.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T13:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.17543v1","title":"Knapsack with compactness: a semidefinite approach","summary":"The min-knapsack problem with compactness constraints extends the classical\nknapsack problem, in the case of ordered items, by introducing a restriction\nensuring that they cannot be too far apart. This problem has applications in\nstatistics, particularly in the detection of change-points in time series. In\nthis paper, we propose a semidefinite programming approach for this problem,\nincorporating compactness in constraints or in objective. We study and compare\nthe different relaxations, and argue that our method provides high-quality\nheuristics and tight bounds. In particular, the single hyperparameter of our\npenalized semidefinite models naturally balances the trade-off between\ncompactness and accuracy of the computed solutions. Numerical experiments\nillustrate, on the hardest instances, the effectiveness and versatility of our\napproach compared to the existing mixed-integer programming formulation.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T13:32:26Z"}
{"aid":"http://arxiv.org/abs/2504.17565v1","title":"DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale\n  Difficulty-Graded Data Training","summary":"Although large language models (LLMs) have recently achieved remarkable\nperformance on various complex reasoning benchmarks, the academic community\nstill lacks an in-depth understanding of base model training processes and data\nquality. To address this, we construct a large-scale, difficulty-graded\nreasoning dataset containing approximately 3.34 million unique queries of\nvarying difficulty levels and about 40 million distilled responses generated by\nmultiple models over several passes. Leveraging pass rate and Coefficient of\nVariation (CV), we precisely select the most valuable training data to enhance\nreasoning capability. Notably, we observe a training pattern shift, indicating\nthat reasoning-focused training based on base models requires higher learning\nrates for effective training. Using this carefully selected data, we\nsignificantly improve the reasoning capabilities of the base model, achieving a\npass rate of 79.2\\% on the AIME2024 mathematical reasoning benchmark. This\nresult surpasses most current distilled models and closely approaches\nstate-of-the-art performance. We provide detailed descriptions of our data\nprocessing, difficulty assessment, and training methodology, and have publicly\nreleased all datasets and methods to promote rapid progress in open-source\nlong-reasoning LLMs. The dataset is available at:\nhttps://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T13:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.17586v1","title":"A Machine Learning Approach for Denoising and Upsampling HRTFs","summary":"The demand for realistic virtual immersive audio continues to grow, with\nHead-Related Transfer Functions (HRTFs) playing a key role. HRTFs capture how\nsound reaches our ears, reflecting unique anatomical features and enhancing\nspatial perception. It has been shown that personalized HRTFs improve\nlocalization accuracy, but their measurement remains time-consuming and\nrequires a noise-free environment. Although machine learning has been shown to\nreduce the required measurement points and, thus, the measurement time, a\ncontrolled environment is still necessary. This paper proposes a method to\naddress this constraint by presenting a novel technique that can upsample\nsparse, noisy HRTF measurements. The proposed approach combines an HRTF Denoisy\nU-Net for denoising and an Autoencoding Generative Adversarial Network (AE-GAN)\nfor upsampling from three measurement points. The proposed method achieves a\nlog-spectral distortion (LSD) error of 5.41 dB and a cosine similarity loss of\n0.0070, demonstrating the method's effectiveness in HRTF upsampling.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-24T14:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.17609v1","title":"STCL:Curriculum learning Strategies for deep learning image\n  steganography models","summary":"Aiming at the problems of poor quality of steganographic images and slow\nnetwork convergence of image steganography models based on deep learning, this\npaper proposes a Steganography Curriculum Learning training strategy (STCL) for\ndeep learning image steganography models. So that only easy images are selected\nfor training when the model has poor fitting ability at the initial stage, and\ngradually expand to more difficult images, the strategy includes a difficulty\nevaluation strategy based on the teacher model and an knee point-based training\nscheduling strategy. Firstly, multiple teacher models are trained, and the\nconsistency of the quality of steganographic images under multiple teacher\nmodels is used as the difficulty score to construct the training subsets from\neasy to difficult. Secondly, a training control strategy based on knee points\nis proposed to reduce the possibility of overfitting on small training sets and\naccelerate the training process. Experimental results on three large public\ndatasets, ALASKA2, VOC2012 and ImageNet, show that the proposed image\nsteganography scheme is able to improve the model performance under multiple\nalgorithmic frameworks, which not only has a high PSNR, SSIM score, and\ndecoding accuracy, but also the steganographic images generated by the model\nunder the training of the STCL strategy have a low steganography analysis\nscores. You can find our code at\n\\href{https://github.com/chaos-boops/STCL}{https://github.com/chaos-boops/STCL}.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-24T14:34:41Z"}
{"aid":"http://arxiv.org/abs/2504.17617v1","title":"Decentralized Time Series Classification with ROCKET Features","summary":"Time series classification (TSC) is a critical task with applications in\nvarious domains, including healthcare, finance, and industrial monitoring. Due\nto privacy concerns and data regulations, Federated Learning has emerged as a\npromising approach for learning from distributed time series data without\ncentralizing raw information. However, most FL solutions rely on a\nclient-server architecture, which introduces robustness and confidentiality\nrisks related to the distinguished role of the server, which is a single point\nof failure and can observe knowledge extracted from clients. To address these\nchallenges, we propose DROCKS, a fully decentralized FL framework for TSC that\nleverages ROCKET (RandOm Convolutional KErnel Transform) features. In DROCKS,\nthe global model is trained by sequentially traversing a structured path across\nfederation nodes, where each node refines the model and selects the most\neffective local kernels before passing them to the successor. Extensive\nexperiments on the UCR archive demonstrate that DROCKS outperforms\nstate-of-the-art client-server FL approaches while being more resilient to node\nfailures and malicious attacks. Our code is available at\nhttps://anonymous.4open.science/r/DROCKS-7FF3/README.md.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T14:41:50Z"}
{"aid":"http://arxiv.org/abs/2504.17638v1","title":"Testing Quintessence Axion Dark Energy with Recent Cosmological Results","summary":"We investigate a quintessence axion model for dynamical dark energy,\nmotivated in part by recent results from the Baryon Acoustic Oscillation (BAO)\nmeasurements of the Dark Energy Spectroscopic Instrument (DESI) and the Cosmic\nMicrowave Background (CMB) observations from the Atacama Cosmology Telescope\n(ACT). By carefully treating the initial conditions and parameter sampling, we\nidentify a preferred parameter space featuring a sub-Planckian axion decay\nconstant and a relatively large axion mass, which naturally avoids the quality\nproblem and remains consistent with the perturbative string conjecture. Our\nparameter scan also uncovers a trans-Planckian regime of theoretical interest,\nwhich is only mildly disfavored by observations. The results remain robust when\nDESI BAO data are combined with CMB and supernova observations. Finally, we\ndiscuss the possible connection between this model and the recently reported\nnon-zero rotation of the CMB linear polarization angle, emphasizing the broader\ncosmological implications and the promising prospects for testing this\nscenario. We show that an $\\mathcal{O}(1)$ electromagnetic anomaly coefficient\nis preferred by the strongest constraint, which is in full agreement with the\nminimal quintessence axion model.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-24T15:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.17643v1","title":"CLIPSE -- a minimalistic CLIP-based image search engine for research","summary":"A brief overview of CLIPSE, a self-hosted image search engine with the main\napplication of research, is provided. In general, CLIPSE uses CLIP embeddings\nto process the images and also the text queries. The overall framework is\ndesigned with simplicity to enable easy extension and usage. Two benchmark\nscenarios are described and evaluated, covering indexing and querying time. It\nis shown that CLIPSE is capable of handling smaller datasets; for larger\ndatasets, a distributed approach with several instances should be considered.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T15:13:37Z"}
{"aid":"http://arxiv.org/abs/2504.17674v1","title":"Energy Considerations of Large Language Model Inference and Efficiency\n  Optimizations","summary":"As large language models (LLMs) scale in size and adoption, their\ncomputational and environmental costs continue to rise. Prior benchmarking\nefforts have primarily focused on latency reduction in idealized settings,\noften overlooking the diverse real-world inference workloads that shape energy\nuse. In this work, we systematically analyze the energy implications of common\ninference efficiency optimizations across diverse Natural Language Processing\n(NLP) and generative Artificial Intelligence (AI) workloads, including\nconversational AI and code generation. We introduce a modeling approach that\napproximates real-world LLM workflows through a binning strategy for\ninput-output token distributions and batch size variations. Our empirical\nanalysis spans software frameworks, decoding strategies, GPU architectures,\nonline and offline serving settings, and model parallelism configurations. We\nshow that the effectiveness of inference optimizations is highly sensitive to\nworkload geometry, software stack, and hardware accelerators, demonstrating\nthat naive energy estimates based on FLOPs or theoretical GPU utilization\nsignificantly underestimate real-world energy consumption. Our findings reveal\nthat the proper application of relevant inference efficiency optimizations can\nreduce total energy use by up to 73% from unoptimized baselines. These insights\nprovide a foundation for sustainable LLM deployment and inform energy-efficient\ndesign strategies for future AI infrastructure.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-24T15:45:05Z"}
{"aid":"http://arxiv.org/abs/2504.17679v1","title":"Extremal negative dependence and the strongly Rayleigh property","summary":"We provide a geometrical characterization of extremal negative dependence as\na convex polytope in the simplex of multidimensional Bernoulli distributions,\nand we prove that it is an antichain that satisfies some minimality conditions\nwith respect to the strongest negative dependence orders. We study the strongly\nRayleigh property within this class and explicitly find a distribution that\nsatisfies this property by maximizing the entropy. Furthermore, we construct a\nchain for the supermodular order starting from extremal negative dependence to\nindependence by mixing the maximum entropy strongly Rayleigh distribution with\nindependence.","main_category":"math.PR","categories":"math.PR","published":"2025-04-24T15:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.17680v1","title":"Time-reversed Stochastic Inflation","summary":"Cosmic inflation may exhibit stochastic periods during which quantum\nfluctuations dominate over the semi-classical evolution. Extracting observables\nin these regimes is a notoriously difficult program as quantum randomness makes\nthem fully probabilistic. However, among all the possible quantum histories,\nthe ones which are relevant for Cosmology are conditioned by the requirement\nthat stochastic inflation ended. From an observational point of view, it would\nbe more convenient to model stochastic periods as starting from the time at\nwhich they ended and evolving backwards in times. We present a time-reversed\napproach to stochastic inflation, based on a reverse Fokker-Planck equation,\nwhich allows us to derive non-perturbatively the probability distribution of\nthe field values at a given time before the end of the quantum regime. As a\nmotivated example, we solve the flat semi-infinite potential and derive a new\nand exact formula for the probability distribution of the quantum-generated\ncurvature fluctuations. It is normalisable while exhibiting tails slowly\ndecaying as a Levy distribution. Our reverse-time stochastic formalism could be\napplied to any inflationary potentials and quantum diffusion eras, including\nthe ones that can lead to the formation of primordial black holes.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-24T15:53:17Z"}
{"aid":"http://arxiv.org/abs/2504.17689v1","title":"On Hopf hypersurfaces of the complex quadric with constant principal\n  curvatures","summary":"In this paper, we classify the Hopf hypersurfaces of the complex quadric\n$Q^m=SO_{m+2}/(SO_2SO_m)$ ($m\\geq3$) with at most five distinct constant\nprincipal curvatures. We also classify the Hopf hypersurfaces of $Q^m$\n($m=3,4,5$) with constant principal curvatures. All these real hypersurfaces\nare open parts of homogeneous examples.","main_category":"math.DG","categories":"math.DG","published":"2025-04-24T15:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.17700v1","title":"Applied Sheaf Theory For Multi-agent Artificial Intelligence\n  (Reinforcement Learning) Systems: A Prospectus","summary":"This paper provides a pedagogical introduction to classical sheaf theory and\nsheaf cohomology, followed by a research prospectus exploring potential\napplications to multi-agent artificial intelligence systems. The first section\noffers a comprehensive overview of fundamental sheaf-theoretic\nconcepts-presheaves, sheaves, stalks, and cohomology-aimed at researchers in\ncomputer science and AI who may not have extensive background in algebraic\ntopology. The second section presents a detailed research prospectus that\noutlines a roadmap for developing sheaf-theoretic approaches to model and\nanalyze complex systems of interacting agents. We propose that sheaf theory's\ninherent local-to-global perspective may provide valuable mathematical tools\nfor reasoning about how local agent behaviors collectively determine emergent\nsystem properties. The third section contains a literature review connecting\nsheaf theory with existing research in multi-agent systems, reinforcement\nlearning, and economic modeling. This paper does not present a completed model\nbut rather lays theoretical groundwork and identifies promising research\ndirections that could bridge abstract mathematics with practical AI\napplications, potentially revealing new approaches to coordination and\nemergence in multi-agent systems.","main_category":"math.OC","categories":"math.OC,math.AT","published":"2025-04-24T16:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.17728v1","title":"CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from\n  Casually Captured Videos","summary":"Recently, photo-realistic novel view synthesis from multi-view images, such\nas neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered\nwidespread attention due to their superior performance. However, most works\nrely on low dynamic range (LDR) images, which limits the capturing of richer\nscene details. Some prior works have focused on high dynamic range (HDR) scene\nreconstruction, typically require capturing of multi-view sharp images with\ndifferent exposure times at fixed camera positions during exposure times, which\nis time-consuming and challenging in practice. For a more flexible data\nacquisition, we propose a one-stage method: \\textbf{CasualHDRSplat} to easily\nand robustly reconstruct the 3D HDR scene from casually captured videos with\nauto-exposure enabled, even in the presence of severe motion blur and varying\nunknown exposure time. \\textbf{CasualHDRSplat} contains a unified\ndifferentiable physical imaging model which first applies continuous-time\ntrajectory constraint to imaging process so that we can jointly optimize\nexposure time, camera response function (CRF), camera poses, and sharp 3D HDR\nscene. Extensive experiments demonstrate that our approach outperforms existing\nmethods in terms of robustness and rendering quality. Our source code will be\navailable at https://github.com/WU-CVGL/CasualHDRSplat","main_category":"cs.GR","categories":"cs.GR,cs.CV,cs.MM","published":"2025-04-24T16:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.17733v1","title":"Fuzzy clustering and community detection: an integrated approach","summary":"This paper addresses the ambitious goal of merging two different approaches\nto group detection in complex domains: one based on fuzzy clustering and the\nother on community detection theory. To achieve this, two clustering algorithms\nare proposed: Fuzzy C-Medoids Clustering with Modularity Spatial Correction and\nFuzzy C-Modes Clustering with Modularity Spatial Correction. The former is\ndesigned for quantitative data, while the latter is intended for qualitative\ndata. The concept of fuzzy modularity is introduced into the standard objective\nfunction of fuzzy clustering algorithms as a spatial regularization term, whose\ncontribution to the clustering criterion based on attributes is controlled by\nan exogenous parameter. An extensive simulation study is conducted to support\nthe theoretical framework, complemented by two applications to real-world data\nrelated to the theme of sustainability. The first application involves data\nfrom the 2030 Agenda for Sustainable Development, while the second focuses on\nurban green spaces in Italian provincial capitals and metropolitan cities. Both\nthe simulation results and the applications demonstrate the advantages of this\nnew methodological proposal.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-24T16:47:17Z"}
{"aid":"http://arxiv.org/abs/2504.17751v1","title":"Revisiting Reset Mechanisms in Spiking Neural Networks for Sequential\n  Modeling: Specialized Discretization for Binary Activated RNN","summary":"In the field of image recognition, spiking neural networks (SNNs) have\nachieved performance comparable to conventional artificial neural networks\n(ANNs). In such applications, SNNs essentially function as traditional neural\nnetworks with quantized activation values. This article focuses on an another\nalternative perspective,viewing SNNs as binary-activated recurrent neural\nnetworks (RNNs) for sequential modeling tasks.From this viewpoint, current SNN\narchitectures face several fundamental challenges in sequence modeling: (1)\nTraditional models lack effective memory mechanisms for long-range sequence\nmodeling; (2) The biological-inspired components in SNNs (such as reset\nmechanisms and refractory period applications) remain theoretically\nunder-explored for sequence tasks; (3) The RNN-like computational paradigm in\nSNNs prevents parallel training across different timesteps.To address these\nchallenges, this study conducts a systematic analysis of the fundamental\nmechanisms underlying reset operations and refractory periods in\nbinary-activated RNN-based SNN sequence models. We re-examine whether such\nbiological mechanisms are strictly necessary for generating sparse spiking\npatterns, provide new theoretical explanations and insights, and ultimately\npropose the fixed-refractory-period SNN architecture for sequence modeling.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-24T17:09:59Z"}
{"aid":"http://arxiv.org/abs/2504.17760v1","title":"WI2easy: warm inflation dynamics made easy","summary":"We present WI2easy, a Mathematica package for high-precision analysis of warm\ninflation (WI) dynamics, enabling efficient computation of both background\nevolution and curvature perturbations. Designed with a user-friendly interface,\nthe tool supports a broad spectrum of inflaton potentials--including\nlarge-field, small-field, and hybrid models--and accommodates arbitrary\ndissipation coefficients dependent on temperature, field amplitude, or both,\nencompassing canonical forms prevalent in WI studies. Users can define custom\nmodels through intuitive commands, generating full dynamical trajectories and\nperturbation spectra in a streamlined workflow. This facilitates rapid\nconfrontation of theoretical predictions with observational constraints,\nempowering systematic exploration of WI parameter spaces. WI2easy bridges the\ngap between theoretical models and observational cosmology, offering a robust,\nadaptable framework for next-generation inflationary analyses.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-24T17:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.17765v1","title":"Extended Scalar Particle Solutions in Black String Spacetimes with\n  Anisotropic Quintessence","summary":"We present new solutions to the Klein-Gordon equation for a scalar particle\nin a black string spacetime immersed in an anisotropic quintessence fluid\nsurrounded by a cloud of strings, extending the analysis presented in our\nprevious work. These novel solutions are dependent on the quintessence state\nparameter, $\\alpha_{Q}$, and are now valid for a much larger domain of the\nradial coordinate. We investigate the cases when $\\alpha_{Q} = 0,\\,1/2,\\,1$,\nencompassing both black hole and horizonless scenarios. We express the\nresulting radial wave functions using the confluent and biconfluent Heun\nfunctions, with special cases represented by Bessel functions. We derive\nrestrictions on the allowed quantum energy levels by imposing constraints on\nthe Heun parameters to ensure polynomial solutions. Furthermore, we investigate\nthe emergence of \"dark phases\" associated with the radial wave function,\nfocusing on the interesting case of $\\alpha_{Q} = 1$. Our findings provide\ninsights into the dynamics of scalar particles in this complex spacetime and\nthe potential impact of dark energy on quantum systems.","main_category":"gr-qc","categories":"gr-qc,hep-th,math-ph,math.MP","published":"2025-04-24T17:34:07Z"}
{"aid":"http://arxiv.org/abs/2504.17770v1","title":"Zeptosecond free-electron compression through temporal lensing","summary":"The pursuit of ever-shorter time scales is a frontier in modern physics,\nexemplified by the synthesis of attosecond light pulses -- an achievement made\npossible by coherently superimposing a broad range of photon energies, as\nrequired by the uncertainty principle. However, extending this progress into\nthe zeptosecond regime poses significant challenges, as it demands\nphase-correlated optical spectra spanning hundreds of electronvolts. In this\ncontext, electrons offer a compelling alternative to light because they can be\ncoherently manipulated to form broad energy superpositions, as demonstrated by\nthe generation of attosecond pulses in ultrafast electron microscopes. Here, we\npropose a practical scheme for compressing free electrons into the zeptosecond\ndomain by modulating their wave functions using suitably tailored broadband\nlight fields. Building on recent advances in {free-electron--light--matter}\ninteractions, our method introduces the concept of temporal lensing -- an\nextension of conventional optical lensing to the time domain -- to produce\nelectron pulses with arbitrarily short durations.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-24T17:41:22Z"}
{"aid":"http://arxiv.org/abs/2504.17773v1","title":"Three-local Charge Conservation Implies Quantum Integrability","summary":"It is shown that the existence of a local conserved charge supported by three\nneighboring sites, or its local version, Reshetikhin's condition, suffices to\nguarantee the existence of all higher conserved charges and hence the\nintegrability of a quantum spin chain. This explains the ``coincidence'' that\nno counterexample is known to Grabowski and Mathieu's long-standing conjecture\ndespite the folklore that the conservation of local charges of order higher\nthan 4 imposes additional constraints not implied by the conservation of the\nthree-local charge.","main_category":"math-ph","categories":"math-ph,cond-mat.stat-mech,hep-th,math.MP,nlin.SI,quant-ph","published":"2025-04-24T17:48:03Z"}
{"aid":"http://arxiv.org/abs/2504.17788v1","title":"Dynamic Camera Poses and Where to Find Them","summary":"Annotating camera poses on dynamic Internet videos at scale is critical for\nadvancing fields like realistic video generation and simulation. However,\ncollecting such a dataset is difficult, as most Internet videos are unsuitable\nfor pose estimation. Furthermore, annotating dynamic Internet videos present\nsignificant challenges even for state-of-theart methods. In this paper, we\nintroduce DynPose-100K, a large-scale dataset of dynamic Internet videos\nannotated with camera poses. Our collection pipeline addresses filtering using\na carefully combined set of task-specific and generalist models. For pose\nestimation, we combine the latest techniques of point tracking, dynamic\nmasking, and structure-from-motion to achieve improvements over the\nstate-of-the-art approaches. Our analysis and experiments demonstrate that\nDynPose-100K is both large-scale and diverse across several key attributes,\nopening up avenues for advancements in various downstream applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.17789v1","title":"Token-Shuffle: Towards High-Resolution Image Generation with\n  Autoregressive Models","summary":"Autoregressive (AR) models, long dominant in language generation, are\nincreasingly applied to image synthesis but are often considered less\ncompetitive than Diffusion-based models. A primary limitation is the\nsubstantial number of image tokens required for AR models, which constrains\nboth training and inference efficiency, as well as image resolution. To address\nthis, we present Token-Shuffle, a novel yet simple method that reduces the\nnumber of image tokens in Transformer. Our key insight is the dimensional\nredundancy of visual vocabularies in Multimodal Large Language Models (MLLMs),\nwhere low-dimensional visual codes from visual encoder are directly mapped to\nhigh-dimensional language vocabularies. Leveraging this, we consider two key\noperations: token-shuffle, which merges spatially local tokens along channel\ndimension to decrease the input token number, and token-unshuffle, which\nuntangles the inferred tokens after Transformer blocks to restore the spatial\narrangement for output. Jointly training with textual prompts, our strategy\nrequires no additional pretrained text-encoder and enables MLLMs to support\nextremely high-resolution image synthesis in a unified next-token prediction\nway while maintaining efficient training and inference. For the first time, we\npush the boundary of AR text-to-image generation to a resolution of 2048x2048\nwith gratifying generation performance. In GenAI-benchmark, our 2.7B model\nachieves 0.77 overall score on hard prompts, outperforming AR models LlamaGen\nby 0.18 and diffusion models LDM by 0.15. Exhaustive large-scale human\nevaluations also demonstrate our prominent image generation ability in terms of\ntext-alignment, visual flaw, and visual appearance. We hope that Token-Shuffle\ncan serve as a foundational design for efficient high-resolution image\ngeneration within MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.19468v1","title":"Characteristic polynomials and some combinatorics for finite Coxeter\n  groups","summary":"Let $W$ be a finite Coxeter group with Coxeter generating set\n$S=\\{s_1,\\ldots,s_n\\}$, and $\\rho$ be a complex finite dimensional\nrepresentation of $W$. The characteristic polynomial of $\\rho$ is defined as\n  \\begin{equation*}\n  d(S,\\rho)=\\det[x_0I+x_1\\rho(s_1)+\\cdots+x_n\\rho(s_n)],\n  \\end{equation*}\n  where $I$ is the identity operator. In this paper, we show the existence of a\ncombinatorics structure within $W$, and thereby prove that for any two complex\nfinite dimensional representations $\\rho_1$ and $\\rho_2$ of $W$,\n$d(S,\\rho_1)=d(S,\\rho_2)$ if and only if $\\rho_1 \\cong \\rho_2$.","main_category":"math.RT","categories":"math.RT","published":"2025-04-28T04:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.19477v1","title":"Deterministic Integration of hBN Single-Photon Emitters on SiN\n  Waveguides via Femtosecond Laser Processing","summary":"We demonstrate a post-fabrication method that deterministically integrates\nhexagonal boron nitride (hBN) single-photon emitters (SPEs) onto silicon\nnitride (SiN) waveguides. Mechanically exfoliated hBN flakes are\ndry-transferred onto pre-fabricated SiN waveguides, and localized femtosecond\nlaser irradiation is employed to induce defects with sub-microscale spatial\nprecision. Confocal photoluminescence mapping reveals multiple laser-written\nbright defects, among which one emitter exhibits narrow spectral linewidth and\npolarization dependence characteristic of a dipole emitter. The emitter\nexhibits high brightness and temporal stability, and second-order photon\ncorrelation measurements confirm its single-photon nature. Furthermore, we\nsuccessfully achieve on-chip excitation via the SiN waveguide, demonstrating\nthe compatibility of our approach with mature photonic platform technologies.\nThis deterministic integration technique offers a scalable pathway for\nincorporating quantum emitters into photonic circuits, paving the way for the\ndevelopment of quantum information processing and communication systems with\ntwo-dimensional material hybrid photonic devices.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-28T04:34:25Z"}
{"aid":"http://arxiv.org/abs/2504.19485v1","title":"Topological derivative for a fast identification of short, linear\n  perfectly conducting cracks with inaccurate background information","summary":"In this study, we consider a topological derivative-based imaging technique\nfor the fast identification of short, linear perfectly conducting cracks\ncompletely embedded in a two-dimensional homogeneous domain with smooth\nboundary. Unlike conventional approaches, we assume that the background\npermittivity and permeability are unknown due to their dependence on frequency\nand temperature, and we propose a normalized imaging function to localize\ncracks. Despite inaccuracies in background parameters, application of the\nproposed imaging function enables to recognize the existence of crack but it is\nstill impossible to identify accurate crack locations. Furthermore, the shift\nin crack localization of imaging results is significantly influenced by the\napplied background parameters. In order to theoretically explain this\nphenomenon, we show that the imaging function can be expressed in terms of the\nzero-order Bessel function of the first kind, the crack lengths, and the\napplied inaccurate background wavenumber corresponding to the applied\ninaccurate background permittivity and permeability. Various numerical\nsimulations results with synthetic data polluted by random noise validate the\ntheoretical results.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-28T05:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.19508v1","title":"The impact of Robin boundary condition on a\n  chemotaxis-consumption-growth model","summary":"We investigate a parabolic-elliptic chemotaxis-consumption-growth system with\na Robin boundary condition imposed on the signal. First, we analyse the steady\nstate problem, then we show that the solutions of the system are global and\nuniformly bounded in time in any space dimension. Next, under smallness\nassumption on the boundary data, we show that the solutions converge to\nnon-constant steady states as time tends to infinity.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T06:17:34Z"}
{"aid":"http://arxiv.org/abs/2504.19511v1","title":"Novel Selection Schemes for Multi-RIS-Assisted Fluid Antenna Systems","summary":"This paper investigates the performance of a multi-reconfigurable intelligent\nsurface (RIS)-assisted fluid antenna system (FAS). In this system, a\nsingle-antenna transmitter communicates with a receiver equipped with a planar\nFAS through multiple RISs in the absence of a direct link. To enhance the\nsystem performance, we propose two novel selection schemes: \\textit{Max-Max}\nand \\textit{Max-Sum}. In particular, the \\textit{Max-Max} scheme selects the\nbest combination of a single RIS and a single fluid antenna (FA) port that\noffers the maximum signal-to-noise ratio (SNR) at the receiver. On the other\nhand, the \\textit{Max-Sum} scheme selects one RIS while activating all FA ports\nproviding the highest overall SNR. We conduct a detailed performance analysis\nof the proposed system under Nakagami-$m$ fading channels. First, we derive the\ncumulative distribution function (CDF) of the SNR for both selection schemes.\nThe derived CDF is then used to obtain approximate theoretical expressions for\nthe outage probability (OP) and the delay outage rate (DOR). Next, a high-SNR\nasymptotic analysis is carried out to provide further insights into the system\nperformance in terms of diversity and coding gains. Finally, the analytical\nresults are validated through extensive Monte Carlo simulations, demonstrating\ntheir accuracy and providing a comprehensive understanding of the system's\nperformance.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T06:19:39Z"}
{"aid":"http://arxiv.org/abs/2504.19513v1","title":"Fractional $p$-Laplace systems with critical Hardy nonlinearities:\n  Existence and Multiplicity","summary":"Let $\\Omega \\subset \\mathbb{R}^d$ be a bounded open set containing zero, $s\n\\in (0,1)$ and $p \\in (1, \\infty)$. In this paper, we first deal with the\nexistence, non-existence and some properties of ground-state solutions for the\nfollowing class of fractional $p$-Laplace systems \\begin{equation*}\n\\left\\{\\begin{aligned} &(-\\Delta_p)^s u= \\frac{\\alpha}{q}\n\\frac{|u|^{\\alpha-2}u|v|^{\\beta}}{|x|^m} \\;\\;\\text{in}\\;\\Omega,\\\\\n&(-\\Delta_p)^s v= \\frac{\\beta}{q}\n\\frac{|v|^{\\beta-2}v|u|^{\\alpha}}{|x|^m}\\;\\;\\text{in}\\;\\Omega,\\\\ &u=v=0\\,\n\\mbox{ in }\\mathbb{R}^d\\setminus \\Omega, \\end{aligned} \\right. \\end{equation*}\nwhere $d>sp$, $\\alpha + \\beta = q$ where $p \\leq q \\leq p_{s}^{*}(m)$ where\n$p_{s}^{*}(m) = \\frac{p(d-m)}{d-sp}$ with $0 \\leq m \\le sp$. Additionally, we\nestablish a concentration-compactness principle related to this homogeneous\nsystem of equations. Next, the main objective of this paper is to study the\nfollowing non-homogenous system of equations \\begin{equation*}\n\\left\\{\\begin{aligned} &(-\\Delta_p)^s u = \\eta |u|^{r-2}u + \\gamma\n\\frac{\\alpha}{p_{s}^{*}(m)} \\frac{|u|^{\\alpha-2}u|v|^{\\beta}}{|x|^m}\n\\;\\;\\text{in}\\;\\Omega,\\\\ &(-\\Delta_p)^s v = \\eta |v|^{r-2}v + \\gamma\n\\frac{\\beta}{p^{*}_{s}(m)}\n\\frac{|v|^{\\beta-2}v|u|^{\\alpha}}{|x|^m}\\;\\;\\text{in}\\;\\Omega,\\\\ &u=v=0\\,\n\\mbox{ in }\\mathbb{R}^d\\setminus \\Omega, \\end{aligned} \\right. \\end{equation*}\nwhere $\\eta, \\gamma > 0$ are parameters and $p \\leq r < p_{s}^{*}(0)$.\nDepending on the values of $\\eta, \\gamma$, we obtain the existence of a non\nsemi-trivial solution with the least energy. Further, for $m=0$, we establish\nthat the above problem admits at least $\\text{cat}_{\\Omega}({\\Omega})$\nnontrivial solutions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T06:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.19519v1","title":"FlashOverlap: A Lightweight Design for Efficiently Overlapping\n  Communication and Computation","summary":"Generative models have achieved remarkable success across various\napplications, driving the demand for multi-GPU computing. Inter-GPU\ncommunication becomes a bottleneck in multi-GPU computing systems, particularly\non consumer-grade GPUs. By exploiting concurrent hardware execution,\noverlapping computation and communication latency is an effective technique for\nmitigating the communication overhead. We identify that an efficient and\nadaptable overlapping design should satisfy (1) tile-wise overlapping to\nmaximize the overlapping opportunity, (2) interference-free computation to\nmaintain the original computational performance, and (3) communication\nagnosticism to reduce the development burden against varying communication\nprimitives. Nevertheless, current designs fail to simultaneously optimize for\nall of those features.\n  To address the issue, we propose FlashOverlap, a lightweight design\ncharacterized by tile-wise overlapping, interference-free computation, and\ncommunication agnosticism. FlashOverlap utilizes a novel signaling mechanism to\nidentify tile-wise data dependency without interrupting the computation\nprocess, and reorders data to contiguous addresses, enabling communication by\nsimply calling NCCL APIs. Experiments show that such a lightweight design\nachieves up to 1.65x speedup, outperforming existing works in most cases.","main_category":"cs.DC","categories":"cs.DC,cs.CL,cs.LG","published":"2025-04-28T06:37:57Z"}
{"aid":"http://arxiv.org/abs/2504.19526v1","title":"Near-real-time flood inundation monitoring by Bayesian analysis for\n  change point problems for Sentinel-1 time series","summary":"Near real-time flood monitoring is crucial for disaster response, yet\nexisting methods face significant limitations in training data requirements and\ncloud cover interference. Here we present a novel approach using Bayesian\nanalysis for change point problems (BCP) applied to Sentinel-1 SAR time series\ndata, which automatically detects temporal discontinuities in backscatter\npatterns to distinguish flood inundation from permanent water bodies without\nrequiring training data or ancillary information. We validate our method using\nthe UrbanSARFloods benchmark dataset across three diverse geographical contexts\n(Weihui, China; Jubba, Somalia; and NovaKakhovka, Ukraine). Our BCP approach\nachieves F1 scores ranging from 0.41 to 0.76 (IoU: 0.25-0.61), significantly\noutperforming both OTSU thresholding (F1: 0.03-0.12, IoU: 0.02-0.08) and\nSiamese convolutional neural network approaches (F1: 0.08-0.34, IoU:\n0.05-0.24). Further analysis reveals exceptional performance in open areas with\nF1 scores of 0.47-0.81 (IoU: 0.31-0.68) and high recall (0.36-0.84), contrasted\nwith substantially lower performance in urban areas (F1: 0.00-0.01, IoU:\n0.00-0.01), indicating a common challenge across current flood detection\nmethods in urban environments. The proposed method's ability to process raw SAR\ndata directly with minimal preprocessing enables integration into operational\nearly warning systems for rapid flood mapping, particularly in agricultural and\nopen landscapes where it demonstrates the strongest performance.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-28T07:05:38Z"}
{"aid":"http://arxiv.org/abs/2504.19557v1","title":"CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel\n  View Synthesis in Autonomous Driving Scenes","summary":"Current point-based approaches encounter limitations in scalability and\nrendering quality when using large 3D point cloud maps because using them\ndirectly for novel view synthesis (NVS) leads to degraded visualizations. We\nidentify the primary issue behind these low-quality renderings as a visibility\nmismatch between geometry and appearance, stemming from using these two\nmodalities together. To address this problem, we present CE-NPBG, a new\napproach for novel view synthesis (NVS) in large-scale autonomous driving\nscenes. Our method is a neural point-based technique that leverages two\nmodalities: posed images (cameras) and synchronized raw 3D point clouds\n(LiDAR). We first employ a connectivity relationship graph between appearance\nand geometry, which retrieves points from a large 3D point cloud map observed\nfrom the current camera perspective and uses them for rendering. By leveraging\nthis connectivity, our method significantly improves rendering quality and\nenhances run-time and scalability by using only a small subset of points from\nthe large 3D point cloud map. Our approach associates neural descriptors with\nthe points and uses them to synthesize views. To enhance the encoding of these\ndescriptors and elevate rendering quality, we propose a joint adversarial and\npoint rasterization training. During training, we pair an image-synthesizer\nnetwork with a multi-resolution discriminator. At inference, we decouple them\nand use the image-synthesizer to generate novel views. We also integrate our\nproposal into the recent 3D Gaussian Splatting work to highlight its benefits\nfor improved rendering and scalability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T08:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.19582v1","title":"Faithful universal graphs for minor-closed classes","summary":"It was proved by Huynh, Mohar, \\v{S}\\'amal, Thomassen and Wood in 2021 that\nany countable graph containing every countable planar graph as a subgraph has\nan infinite clique minor. We prove a finite, quantitative version of this\nresult: for fixed $t$, if a graph $G$ is $K_t$-minor-free and contains every\n$n$-vertex planar graph as a subgraph, then $G$ has $2^{\\Omega(\\sqrt{n})}$\nvertices. If $G$ contains every $n$-vertex toroidal graph instead, then $G$ has\n$2^{\\Omega(n)}$ vertices. On the other hand, we construct a polynomial size\n$K_4$-minor-free graph containing every $n$-vertex tree as an induced subgraph,\nand a polynomial size $K_7$-minor-free graph containing every $n$-vertex\n$K_4$-minor-free graph as induced subgraph. This answers several problems\nraised recently by Bergold, Ir\\v{s}i\\v{c}, Lauff, Orthaber, Scheucher and\nWesolek.\n  We study more generally the order of universal graphs for various classes (of\ngraphs of bounded degree, treedepth, pathwidth, or treewidth), if the universal\ngraphs retain some of the structure of the original class.","main_category":"math.CO","categories":"math.CO,cs.DS","published":"2025-04-28T08:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.19586v1","title":"A Universal Spin-Orbit-Coupled Hamiltonian Model for Accelerated Quantum\n  Material Discovery","summary":"The accurate modeling of spin-orbit coupling (SOC) effects in diverse complex\nsystems remains a significant challenge due to the high computational demands\nof density functional theory (DFT) and the limited transferability of existing\nmachine-learning frameworks. This study addresses these limitations by\nintroducing Uni-HamGNN, a universal SOC Hamiltonian graph neural network that\nis applicable across the periodic table. By decomposing the SOC Hamiltonian\ninto spin-independent and SOC correction terms, our approach preserves SU(2)\nsymmetry while significantly reducing parameter requirements. Based on this\ndecomposition, we propose a delta-learning strategy to separately fit the two\ncomponents, thereby addressing the training difficulties caused by magnitude\ndiscrepancies between them and enabling efficient training. The model achieves\nremarkable accuracy (mean absolute error of 0.0025 meV for the SOC-related\ncomponent) and demonstrates broad applicability through high-throughput\nscreening of the GNoME dataset for topological insulators, as well as precise\npredictions for 2D valleytronic materials and transition metal dichalcogenide\n(TMD) heterostructures. This breakthrough eliminates the need for\nsystem-specific retraining and costly SOC-DFT calculations, paving the way for\nrapid discovery of quantum materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-28T08:47:45Z"}
{"aid":"http://arxiv.org/abs/2504.19596v1","title":"Towards Robust Multimodal Physiological Foundation Models: Handling\n  Arbitrary Missing Modalities","summary":"Multimodal physiological signals, such as EEG, ECG, EOG, and EMG, are crucial\nfor healthcare and brain-computer interfaces. While existing methods rely on\nspecialized architectures and dataset-specific fusion strategies, they struggle\nto learn universal representations that generalize across datasets and handle\nmissing modalities at inference time. To address these issues, we propose\nPhysioOmni, a foundation model for multimodal physiological signal analysis\nthat models both homogeneous and heterogeneous features to decouple multimodal\nsignals and extract generic representations while maintaining compatibility\nwith arbitrary missing modalities. PhysioOmni trains a decoupled multimodal\ntokenizer, enabling masked signal pre-training via modality-invariant and\nmodality-specific objectives. To ensure adaptability to diverse and incomplete\nmodality combinations, the pre-trained encoders undergo resilient fine-tuning\nwith prototype alignment on downstream datasets. Extensive experiments on four\ndownstream tasks, emotion recognition, sleep stage classification, motor\nprediction, and mental workload detection, demonstrate that PhysioOmni achieves\nstate-of-the-art performance while maintaining strong robustness to missing\nmodalities. Our code and model weights will be released.","main_category":"eess.SP","categories":"eess.SP,cs.LG","published":"2025-04-28T09:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.19618v1","title":"On monoids of monotone partial transformations of a finite chain whose\n  domains and ranges are intervals","summary":"In this note, we consider the monoid $\\mathcal{PIM}_{n}$ of all partial\nmonotone transformations on a chain with $n$ elements whose domains and ranges\nare intervals and its submonoid $\\mathcal{IM}_{n}$ constituted by the full\ntransformations. For both of these monoids, our aim is to determine their\ncardinalities and ranks and define them by means of presentations. We also\ncalculate the number of nilpotent elements of $\\mathcal{PIM}_{n}$.","main_category":"math.RA","categories":"math.RA","published":"2025-04-28T09:27:20Z"}
{"aid":"http://arxiv.org/abs/2504.19626v1","title":"Improved T counts and active volume estimates for high-level arithmetic\n  subroutines","summary":"Surface code based quantum computers show great promise for fault-tolerant\nquantum computing, but most architectures needlessly increase the spacetime\nvolume of a computation due to qubits sitting idly during a computation. Active\nvolume architectures, with long-range connectivity, aim to remove idle\nspacetime volume leaving only the spacetime volume that logically contributes\nto a computation. In this work we optimise and derive the active volumes for\nseveral industry-leading low- and high-level arithmetic subroutines and achieve\nsignificant T-count reductions. We discuss a simple method for estimating and\noptimising active volumes using orientated ZX diagrams. We also demonstrate\nthat circuit structure, beyond gate counts alone, impacts the active volume of\na subroutine and therefore should be taken into consideration when designing\ncircuits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T09:38:55Z"}
{"aid":"http://arxiv.org/abs/2504.19633v1","title":"Ferroelectric and Hyper Dielectric modes in Ferronematic Liquid Crystals","summary":"Binary mixtures of the ferronematic compound DIO with recently reported\nnon-ferroelectric material WJ-16 which shows Colossal Permittivity (CP) ~5000\nand superparaelectricity (SPE) were studied by POM, electrical switching\nstudies, and dielectric spectroscopy. Three mixtures with different contents of\nWJ-16 as 10, 25 and 50% in DIO as host were prepared. Our original expectation\nwas the development of new nematic materials with both ferroelectric nematic\n(NF) and non-ferroelectric CP phases. The non-ferroelectric phase in mixtures\nexhibits a CP mode originally observed in pure WJ-16 and was termed as\nsuperparaelectric. However, the dielectric spectroscopy of mixtures shows two\ndistinct relaxation processes: the typical paraelectric response and the CP\nmode. Therefore, this CP mode cannot be called superparaelectric and is\nredefined it as Hyper Dielectric mode. This is the first direct demonstration\nof materials with both ferroelectric and Hyper-dielectric phases in liquid\ncrystalline materials. The hyper dielectric phase has a good potential as a\nworking media for supercapacitors industry.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.soft","published":"2025-04-28T09:49:28Z"}
{"aid":"http://arxiv.org/abs/2504.19655v1","title":"Oscillation death by mechanochemical feedback","summary":"Many cellular proteins, such as ERK, undergo oscillation death when cells are\ncompressed, initiating many developmental processes in organisms. Whether such\na transition arises from these proteins' specific biochemistry or generic\ndynamical features remains unclear. In this paper, we show that coupling\nmechanics to the chemistry of Hopf oscillators, such as ERK, through\nmechanochemical feedback (MCF) can generically drive oscillation death upon\ncompression. We demonstrate this result using an active solid, a 1D ring of\nBrusselators coupled through damped springs, which we term Harmonic Brusselator\nRing (HBR). Because of MCF, HBR's dynamics is non-Hermitian and breaks\n$\\mathcal{PT}$-symmetry in a scale-dependent manner, generating a rich array of\npatterns, including traveling pulses, chimera states, intermittent\nfluctuations, and collective oscillation death. Furthermore, MCF engenders\nthree dynamic phase transitions that separate the observed patterns into four\nphases. The underlying symmetry of HBR implies that the observed patterns and\nphases may generically arise in many natural and synthetic systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech,nlin.PS,physics.bio-ph","published":"2025-04-28T10:17:17Z"}
{"aid":"http://arxiv.org/abs/2504.19658v1","title":"Auxiliary Artifacts in Requirements Traceability: A Systematic Mapping\n  Study","summary":"Background: Traceability between software artifacts enhances the value of the\ninformation those artifacts contain, but only when the links themselves are\nreliable. Link quality is known to depend on explicit factors such as the\ntraced artifacts and the expertise of the practitioner who judges each\nconnection. Other factors, however, remain largely unexplored. We contend that\none of these factors is the set of auxiliary artifacts -- artifacts that are\nproduced and/or used during the tracing process yet are neither the source nor\ntarget artifacts. Because such auxiliary artifacts can subtly steer how links\nare created and validated, they merit a literature survey to identify these\nartifacts and further investigate them. Objective: We identify and map\nauxiliary artifacts used in requirements tracing, which could be additional\nfactors that affect the quality of the trace links. Method: We conducted a\nsystematic mapping study on auxiliary artifacts in requirements traceability.\nResults: We found 110 studies in which auxiliary artifacts are used in\nrequirements tracing, and identified 49 auxiliary artifacts, and 13 usage\nscenarios. Conclusion: This study provides a systematic mapping of auxiliary\nartifacts in requirement tracing, including their usage, origin, type and tool\nsupport. The use of auxiliary artifacts in requirements tracing seems to be the\nnorm, thus, these artifacts should be studied in depth to identify how they\neffect the quality of traced links.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-28T10:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.19679v1","title":"Non-Classical Spin-Phonon Correlations Induced by Rydberg Facilitation\n  in a Lattice","summary":"We investigate the interplay between mechanical forces and the internal-state\ndynamics of a chain of Rydberg atoms trapped in tweezer arrays under the\nfacilitation constraint. Dipole interactions between Rydberg atoms couple\nelectronic (spin) degrees of freedom with excited motional (phonon) states. We\nshow that this interaction leads to highly correlated and non-classical phonon\nstates in the form of squeezed center of mass position states of the Rydberg\natoms. Coupling with either a normal or an inverted Lennard-Jones-type\npotential, resulting from an avoided crossing of Rydberg potential curves,\nleads to in-phase or out-of-phase correlated oscillations in the atom positions\nrespectively. Furthermore, the growth dynamics of a finite cluster of excited\nRydberg atoms can be mapped to the dynamics of a single particle in a\nsemi-infinite lattice subject to a linear potential gradient caused by\nspin-phonon interactions. This results in Bloch oscillations in the spin\ncluster size, which in turn localize spin excitations in the system.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-28T11:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.19715v1","title":"Model-based controller assisted domain randomization in deep\n  reinforcement learning: application to nonlinear powertrain control","summary":"Complex mechanical systems such as vehicle powertrains are inherently subject\nto multiple nonlinearities and uncertainties arising from parametric\nvariations. Modeling and calibration errors are therefore unavoidable, making\nthe transfer of control systems from simulation to real-world systems a\ncritical challenge. Traditional robust controls have limitations in handling\ncertain types of nonlinearities and uncertainties, requiring a more practical\napproach capable of comprehensively compensating for these various constraints.\nThis study proposes a new robust control approach using the framework of deep\nreinforcement learning (DRL). The key strategy lies in the synergy among domain\nrandomization-based DRL, long short-term memory (LSTM)-based actor and critic\nnetworks, and model-based control (MBC). The problem setup is modeled via the\nlatent Markov decision process (LMDP), a set of vanilla MDPs, for a controlled\nsystem subject to uncertainties and nonlinearities. In LMDP, the dynamics of an\nenvironment simulator is randomized during training to improve the robustness\nof the control system to real testing environments. The randomization increases\ntraining difficulties as well as conservativeness of the resultant control\nsystem; therefore, progress is assisted by concurrent use of a model-based\ncontroller based on a nominal system model. Compared to traditional DRL-based\ncontrols, the proposed controller design is smarter in that we can achieve a\nhigh level of generalization ability with a more compact neural network\narchitecture and a smaller amount of training data. The proposed approach is\nverified via practical application to active damping for a complex powertrain\nsystem with nonlinearities and parametric variations. Comparative tests\ndemonstrate the high robustness of the proposed approach.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.LG,cs.SY","published":"2025-04-28T12:09:07Z"}
{"aid":"http://arxiv.org/abs/2504.19746v1","title":"FineQ: Software-Hardware Co-Design for Low-Bit Fine-Grained\n  Mixed-Precision Quantization of LLMs","summary":"Large language models (LLMs) have significantly advanced the natural language\nprocessing paradigm but impose substantial demands on memory and computational\nresources. Quantization is one of the most effective ways to reduce memory\nconsumption of LLMs. However, advanced single-precision quantization methods\nexperience significant accuracy degradation when quantizing to ultra-low bits.\nExisting mixed-precision quantization methods are quantized by groups with\ncoarse granularity. Employing high precision for group data leads to\nsubstantial memory overhead, whereas low precision severely impacts model\naccuracy. To address this issue, we propose FineQ, software-hardware co-design\nfor low-bit fine-grained mixed-precision quantization of LLMs. First, FineQ\npartitions the weights into finer-grained clusters and considers the\ndistribution of outliers within these clusters, thus achieving a balance\nbetween model accuracy and memory overhead. Then, we propose an outlier\nprotection mechanism within clusters that uses 3 bits to represent outliers and\nintroduce an encoding scheme for index and data concatenation to enable aligned\nmemory access. Finally, we introduce an accelerator utilizing temporal coding\nthat effectively supports the quantization algorithm while simplifying the\nmultipliers in the systolic array. FineQ achieves higher model accuracy\ncompared to the SOTA mixed-precision quantization algorithm at a close average\nbit-width. Meanwhile, the accelerator achieves up to 1.79x energy efficiency\nand reduces the area of the systolic array by 61.2%.","main_category":"cs.LG","categories":"cs.LG,cs.AR","published":"2025-04-28T12:47:23Z"}
{"aid":"http://arxiv.org/abs/2504.19753v1","title":"A New Decision- Making Method Based on Shannon Entropy Analysis","summary":"Because the appropriate combination of existing elements and establishing\ncoordination between them as a consequence of making the right decision to\naccomplish the intended objective is achieved, management is now one of the\nmain pillars of community management. Decisions are made in the majority of\nsituations when the decision maker is pleased with the conclusion based on\nnumerous factors. Several criteria are used instead of one measure of\noptimality in multi-criteria decision making, which has been studied by\nnumerous academics in recent decades. The importance of the indicators in this\ntype of decision making is clearly not equal, and it is necessary to understand\nthe coefficient of importance or weight of each of these indicators in decision\nmaking. In this work, a novel technique termed scattering axis Dispersion-based\nWeighting Method (D.W.M) is suggested to address weighing issues, with the\nclosest method in terms of computational logic being their entropy. After\nconstructing the option's criterion matrix, the mean, standard deviation, and\ncoefficient of variation are determined, and then the weight of each criterion\nis calculated, according to the proposed D.W.M technique. Several numerical\nexamples have been utilized to demonstrate and assess the suggested technique.\nIn addition, the Shannon entropy approach, which is a commonly used weighting\nmethod, was chosen to compare the findings. The statistical results demonstrate\nthat these two weighing techniques have a strong connection. In compared to the\nShannon entropy technique, the suggested method has the following advantages:\nMinimal computational burden The data does not need to be normalized. Its use\nin the case of negative data.","main_category":"math.MG","categories":"math.MG","published":"2025-04-28T12:51:52Z"}
{"aid":"http://arxiv.org/abs/2504.19760v1","title":"Efficient quantum state preparation through seniority driven operator\n  selection","summary":"Quantum algorithms require accurate representations of electronic states on a\nquantum device, yet the approximation of electronic wave functions for strongly\ncorrelated systems remains a profound theoretical challenge, with existing\nmethods struggling to balance the competing demands of chemical accuracy and\ngate efficiency. Moreover, a critical limitation of the most of the\nstate-of-the-art methods developed to date lies in their substantial reliance\non extensive pre-circuit measurements, which introduce significant overheads\nand contribute to inefficiencies in practical implementation. To address these\ninterconnected challenges and establish a harmonious synergy between them, we\npropose an algorithmic framework that focuses on efficiently capturing the\nmolecular strong correlation through an ordered set of computationally less\ndemanding rank-one and seniority-zero excitations, yielding a parameterized\nansatz with shallow gate depth. Furthermore, to achieve minimal pre-circuit\nmeasurement overhead, we implement a selective pruning of excitations through a\nhybrid approach that combines intuition-based selection with shallow-depth,\nrank-one excitations driven uni-parameter circuit optimization strategy. With\nthe incorporation of qubit-based excitations via particle-preserving exchange\ncircuits, we demonstrate a further reduction in quantum complexities, enhancing\nthe overall resource efficiency of the approach. With a range of challenging\napplications on strongly correlated systems, we demonstrate that our dynamic\nansatz not only significantly enhances computational efficiency but also\ndelivers exceptional accuracy, robustness, and resilience to the noisy\nenvironments inherent in near-term quantum hardware.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T12:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.19773v1","title":"Sliding Window Adversarial Channels","summary":"In an arbitrarily varying channel (AVC), the channel has a state which is\nunder the control of an adversarial jammer and the corresponding capacities are\noften functions of the \"power\" constraints on the transmitter and jammer. In\nthis paper we propose a model in which the constraints must hold almost surely\nover contiguous subsequences of the codeword and state, which we call a sliding\nwindow constraint. We study oblivious jammers and codes with stochastic\nencoding under maximum probability of error. We show that this extra limitation\non the jammer is beneficial for the transmitter: in some cases, the capacity\nfor unique decoding with a sliding window constraint is equal to the capacity\nfor list decoding in the standard model without sliding windows, roughly\nimplying that the addition of window constraints reduces list decoding to\nunique decoding. The list decoding capacity in the standard model can be\nstrictly larger than the unique decoding capacity.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T13:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.19785v1","title":"Heterophily-informed Message Passing","summary":"Graph neural networks (GNNs) are known to be vulnerable to oversmoothing due\nto their implicit homophily assumption. We mitigate this problem with a novel\nscheme that regulates the aggregation of messages, modulating the type and\nextent of message passing locally thereby preserving both the low and\nhigh-frequency components of information. Our approach relies solely on learnt\nembeddings, obviating the need for auxiliary labels, thus extending the\nbenefits of heterophily-aware embeddings to broader applications, e.g.,\ngenerative modelling. Our experiments, conducted across various data sets and\nGNN architectures, demonstrate performance enhancements and reveal heterophily\npatterns across standard classification benchmarks. Furthermore, application to\nmolecular generation showcases notable performance improvements on\nchemoinformatics benchmarks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-28T13:28:23Z"}
{"aid":"http://arxiv.org/abs/2504.19797v1","title":"Dynamic Tsetlin Machine Accelerators for On-Chip Training at the Edge\n  using FPGAs","summary":"The increased demand for data privacy and security in machine learning (ML)\napplications has put impetus on effective edge training on Internet-of-Things\n(IoT) nodes. Edge training aims to leverage speed, energy efficiency and\nadaptability within the resource constraints of the nodes. Deploying and\ntraining Deep Neural Networks (DNNs)-based models at the edge, although\naccurate, posit significant challenges from the back-propagation algorithm's\ncomplexity, bit precision trade-offs, and heterogeneity of DNN layers. This\npaper presents a Dynamic Tsetlin Machine (DTM) training accelerator as an\nalternative to DNN implementations. DTM utilizes logic-based on-chip inference\nwith finite-state automata-driven learning within the same Field Programmable\nGate Array (FPGA) package. Underpinned on the Vanilla and Coalesced Tsetlin\nMachine algorithms, the dynamic aspect of the accelerator design allows for a\nrun-time reconfiguration targeting different datasets, model architectures, and\nmodel sizes without resynthesis. This makes the DTM suitable for targeting\nmultivariate sensor-based edge tasks. Compared to DNNs, DTM trains with fewer\nmultiply-accumulates, devoid of derivative computation. It is a data-centric ML\nalgorithm that learns by aligning Tsetlin automata with input data to form\nlogical propositions enabling efficient Look-up-Table (LUT) mapping and frugal\nBlock RAM usage in FPGA training implementations. The proposed accelerator\noffers 2.54x more Giga operations per second per Watt (GOP/s per W) and uses 6x\nless power than the next-best comparable design.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-28T13:38:53Z"}
{"aid":"http://arxiv.org/abs/2504.19799v1","title":"Collision parameters needed to measure polarisation-dependent nonlinear\n  pair creation","summary":"Pair creation by a $\\gamma$ ray in a high-intensity electromagnetic field\n(the nonlinear Breit-Wheeler process) is sensitive to the $\\gamma$-ray\npolarisation. Here we study the stability required in order to measure this\npolarisation dependence in a head-on collision between a high-power linearly\npolarised laser and a relativistic electron beam, where the $\\gamma$-rays\nproduced via nonlinear Compton scattering are highly polarised. We find that\nthe laser strength parameter $a_0$ has to be known to within a few per cent,\nand that the alignment of the laser and electron beam cannot fluctuate by more\nthan half the spot size, in order to attribute the reduction in positron yield\nto polarisation effects. These collision parameters are difficult to achieve,\nbut may be realised in future precision experiments that focus on beam\nstability.","main_category":"hep-ph","categories":"hep-ph,physics.plasm-ph","published":"2025-04-28T13:42:55Z"}
{"aid":"http://arxiv.org/abs/2504.19843v1","title":"On Hopf's Lemma for sign-changing supersolutions to fractional Laplacian\n  equations","summary":"In this paper we investigate the validity of Hopf's Lemma for a (possibly\nsign-changing) function $u \\in H^s_0(\\Omega)$ satisfying \\[ (-\\Delta)^s u(x)\n\\geq c(x)u(x) \\quad \\text{in }\\Omega,\\] where $\\Omega \\subset \\mathbb{R}^N$ is\nan open, bounded domain, $c \\in L^\\infty(\\Omega)$, and $(-\\Delta)^s u$ is the\nfractional Laplacian of $u$. We show that, under suitable assumptions, the\nvalidity of Hopf's Lemma for $u$ at a point $x_0 \\in \\partial \\Omega$ is\nessentially equivalent to the validity of Hopf's Lemma for the\nCaffarelli-Silvestre extension of $u$ at the point $(x_0,0) \\in \\mathbb{R}^N\n\\times \\mathbb{R}^+$. We also provide a slightly more precise characterization\nof a dichotomy result stated in a recent paper by Dipierro, Soave and\nValdinoci.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T14:43:00Z"}
{"aid":"http://arxiv.org/abs/2504.19892v1","title":"Thin-wall Single-crystal Gold Nanoelectrodes towards Advanced Chemical\n  Probing and Imaging","summary":"Thin-wall metal ultramicro- and nanoelectrodes (UMEs/NEs), especially gold\nNEs, are indispensable for high-resolution electrochemical microscopy,\nbiosensing, and fundamental research. However, their damage susceptibility and\nthe lack of scalable fabrication methods hinder broader adoption. We present a\nversatile wet-chemical approach for high-throughput fabrication of thin-wall Au\nNEs/UMEs and multifunctional NEs with ~80% reproducibility. This method is\nbased on a unique template-assisted 1D growth of single-crystalline Au in\nborosilicate nanopipettes followed by electrochemical contacting with tungsten\nmicrowires, and focused ion beam milling, ensuring precise control over NEs\ndimensions. Adaptable to various metals and integrable in multifunctional\nprobes, the method facilitates batch production of high-quality NEs with\nstandardized electrical connections. Structural and electrochemical\ncharacterization reveals a twinned single-crystalline Au core, a seamless\nAu/glass interface, and highly stable electrochemical performance. Notably,\nsmaller electrodes exhibit higher current densities, enhancing chemical\ndetection sensitivity. Specifically, we demonstrate outstanding spatial (< 200\nnm) and current (< 1 pA) resolutions, low limit of detection (~11.0 {\\mu}M) and\nhigh stability (7 h) in scanning photoelectrochemical microscopy (photo-SECM),\nby detecting photo-oxidation reaction on atomically smooth Au micro-flakes. We\nalso demonstrate growth in double-barrel pipettes for SECM/SICM probes as well\nas Pt NEs. Overall, this scalable method addresses longstanding challenges in\nNEs, paving the way for advanced electrochemical and spectro-electrochemical\nmicroscopy, including SERS/TERS integration. With single-crystalline surfaces,\nthese electrodes open new frontiers in catalysis, interfacial electrochemistry,\nbiosensing, and molecular-scale investigations.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-28T15:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.19909v1","title":"Analytic reconstruction with massive particles: one-loop amplitudes for\n  $0 \\to \\bar{q}qt\\bar{t}H$","summary":"We present an analytic reconstruction of one-loop amplitudes for the process\n$0 \\to \\bar{q}qt\\bar{t}H$. Our calculation is a novel use of analytic\nreconstruction, retaining explicit covariance in the massive spin states\nthrough the massive spinor-helicity formalism. The analytic reconstruction\nrelies on embedding the massive five-point kinematics in a fully massless\neight-point phase space while still building a minimal ansatz directly in the\nfive-point phase space. In order to obtain compact analytic expressions it is\nnecessary to identify suitable partial fraction decompositions and extract\ncommon numerator factors, which we achieve through careful inspection of limits\nin which pairs of denominators vanish. We find that the resulting amplitudes\nare more numerically efficient than ones computed using automatic methods but\nthat the gains are not as significant as in the massless case, at least at\npresent. The method opens the door to applications at two-loop order, where\nnumerical efficiency and improvements in the reconstruction methodology are\nmore crucial, especially with regards to the number of free parameters in the\nansatz.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-28T15:40:33Z"}
{"aid":"http://arxiv.org/abs/2504.19927v1","title":"Dependence of the Radical Dynamics on the Beam Temporal Profile in FLASH\n  Radiotherapy","summary":"Purpose: This study aims to investigate the impact of the beam temporal\nprofile on the radical dynamics and inter-track interactions of FLASH\nradiotherapy, supporting parameter optimization for the equipment development\nand clinical implementation. Methods: MonteCarlo simulations based on the IRT\nmethod were performed to analyze the dynamics after irradiation, including\nsingle-pulse or multi-pulses irradiation, pulse repetition rate, width and\ndose. The physicochemical experiments were performed to measure the\neaq-lifetimes for validation. The generation and recombination of OH and\neaq-radicals were recorded under 6 MeV electron irradiation with varying beam\ntemporal profiles. The radial distributions of the radicals were statistically\nanalyzed, and the corresponding LETd and LETt were calculated. The inter-track\ninteractions were assessed through a mathematical model. Results: The spatial\ndistribution and temporal evolution of radicals were significantly affected by\nthe beam time profiles. Compared with multi-pulses irradiation, single-pulse\nmode with a width less than 1/10 of the radical lifetime, a repetition interval\nlonger than the radical lifetime, and a dose exceeding 1 Gy/pulse can lead to\nradicals rapid consumption, reducing the residual content. Instantaneous high\ndose rates induced radical tracks overlaps. When the single-pulse dose exceeded\n1 Gy, the overlap probability approached 100%, aligning with the threshold for\nradical instantaneous combination. Conclusion: Under a low-duty cycle and high\ninstantaneous dose-rate time profile, the radicals were rapidly consumed\nthrough track overlap hence reduced damage to normal tissues, inducing FLASH\neffect. The optimized time profile can be used to guide the development of\nequipment and parameter settings in clinical practice to maximize the FLASH\neffect, such as the laser accelerators and superconducting photocathode guns.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.acc-ph,physics.app-ph,physics.bio-ph","published":"2025-04-28T16:01:26Z"}
{"aid":"http://arxiv.org/abs/2504.19932v1","title":"Post-buckling of fiber-reinforced soft tissues","summary":"Fiber-reinforcement is a universal feature of many biological tissues. It\ninvolves the interplay between fiber stiffness, fiber orientation, and the\nelastic properties of the matrix, influencing pattern formation and evolution\nin layered tissues. Here, we investigate the deformation of a compressed film\nbonded to a half-space, where either the film or the substrate exhibits\nanisotropy. Within the framework of finite elasticity, we formulate nonlinear\nincremental equations, enabling linear and weakly nonlinear analyses. These\nanalyses yield exact bifurcation conditions and an amplitude equation for\nsurface wrinkling. In particular, for a simple fiber-reinforced model, we show\nthat the bifurcation can be supercritical or subcritical depending on the ratio\nbetween the substrate and the film moduli. These findings underscore the\npivotal role of fiber-reinforcement in shaping pattern formation in anisotropic\ntissues and provide insights into the morphological evolution of biological\ntissues.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-28T16:08:10Z"}
{"aid":"http://arxiv.org/abs/2504.19933v1","title":"Automated decision-making for dynamic task assignment at scale","summary":"The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\ntasks in real time while minimizing some objectives, like resource costs or\ntask cycle time. In this work, we consider a DTAP variant where every task is a\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\ninvolves the decision of which employee to assign to which activity to process\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\nresearch is limited to solving small-scale, synthetic problems, neglecting the\nchallenges posed by real-world use cases. To bridge this gap, this work\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\nTo this end, we introduce a DRL agent with two novel elements: a graph\nstructure for observations and actions that can effectively represent any DTAP\nand a reward function that is provably equivalent to the objective of\nminimizing the average cycle time of tasks. The combination of these two\nnovelties allows the agent to learn effective and generalizable assignment\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\ninstances whose parameters are extracted from real-world logs through process\nmining. The experimental evaluation shows how the proposed DRL agent matches or\noutperforms the best baseline in all DTAP instances and generalizes on\ndifferent time horizons and across instances.","main_category":"cs.AI","categories":"cs.AI,cs.LG,math.OC","published":"2025-04-28T16:08:35Z"}
{"aid":"http://arxiv.org/abs/2504.19936v1","title":"Ku-Band AlScn-On-Diamond SAW Resonators with Phase Velocity above 8600\n  m/s","summary":"In this work, an Aluminum Scandium Nitride (AlScN) on Diamond Sezawa-mode\nsurface acoustic wave (SAW) platform for RF filtering at Ku-band (12-18 GHz) is\ndemonstrated. Thanks to the high acoustic velocity and low-loss diamond\nsubstrate, the prototype resonator at 12.9 GHz achieves a high phase velocity\n($v_p$) of 8671 m/s, a maximum Bode-$Q$ of 408, and coupling coefficient\n($k_{\\mathrm{eff}}^2$) of 2.1%, outperforming high-velocity substrates such as\nSiC and sapphire by more than 20% in velocity. Resonators spanning 8-18 GHz are\npresented. The platform's high power handling above 12.5 dBm is also\nexperimentally validated.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T16:08:55Z"}
{"aid":"http://arxiv.org/abs/2504.19948v1","title":"Tendon-Actuated Concentric Tube Endonasal Robot (TACTER)","summary":"Endoscopic endonasal approaches (EEA) have become more prevalent for\nminimally invasive skull base and sinus surgeries. However, rigid scopes and\ntools significantly decrease the surgeon's ability to operate in tight\nanatomical spaces and avoid critical structures such as the internal carotid\nartery and cranial nerves. This paper proposes a novel tendon-actuated\nconcentric tube endonasal robot (TACTER) design in which two tendon-actuated\nrobots are concentric to each other, resulting in an outer and inner robot that\ncan bend independently. The outer robot is a unidirectionally asymmetric notch\n(UAN) nickel-titanium robot, and the inner robot is a 3D-printed bidirectional\nrobot, with a nickel-titanium bending member. In addition, the inner robot can\ntranslate axially within the outer robot, allowing the tool to traverse through\nstructures while bending, thereby executing follow-the-leader motion. A\nCosserat-rod based mechanical model is proposed that uses tendon tension of\nboth tendon-actuated robots and the relative translation between the robots as\ninputs and predicts the TACTER tip position for varying input parameters. The\nmodel is validated with experiments, and a human cadaver experiment is\npresented to demonstrate maneuverability from the nostril to the sphenoid\nsinus. This work presents the first tendon-actuated concentric tube (TACT)\ndexterous robotic tool capable of performing follow-the-leader motion within\nnatural nasal orifices to cover workspaces typically required for a successful\nEEA.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-28T16:19:50Z"}
{"aid":"http://arxiv.org/abs/2504.19990v1","title":"Mitigating Societal Cognitive Overload in the Age of AI: Challenges and\n  Directions","summary":"Societal cognitive overload, driven by the deluge of information and\ncomplexity in the AI age, poses a critical challenge to human well-being and\nsocietal resilience. This paper argues that mitigating cognitive overload is\nnot only essential for improving present-day life but also a crucial\nprerequisite for navigating the potential risks of advanced AI, including\nexistential threats. We examine how AI exacerbates cognitive overload through\nvarious mechanisms, including information proliferation, algorithmic\nmanipulation, automation anxieties, deregulation, and the erosion of meaning.\nThe paper reframes the AI safety debate to center on cognitive overload,\nhighlighting its role as a bridge between near-term harms and long-term risks.\nIt concludes by discussing potential institutional adaptations, research\ndirections, and policy considerations that arise from adopting an\noverload-resilient perspective on human-AI alignment, suggesting pathways for\nfuture exploration rather than prescribing definitive solutions.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-28T17:06:30Z"}
{"aid":"http://arxiv.org/abs/2504.20004v1","title":"Socially-Aware Autonomous Driving: Inferring Yielding Intentions for\n  Safer Interactions","summary":"Since the emergence of autonomous driving technology, it has advanced rapidly\nover the past decade. It is becoming increasingly likely that autonomous\nvehicles (AVs) would soon coexist with human-driven vehicles (HVs) on the\nroads. Currently, safety and reliable decision-making remain significant\nchallenges, particularly when AVs are navigating lane changes and interacting\nwith surrounding HVs. Therefore, precise estimation of the intentions of\nsurrounding HVs can assist AVs in making more reliable and safe lane change\ndecision-making. This involves not only understanding their current behaviors\nbut also predicting their future motions without any direct communication.\nHowever, distinguishing between the passing and yielding intentions of\nsurrounding HVs still remains ambiguous. To address the challenge, we propose a\nsocial intention estimation algorithm rooted in Directed Acyclic Graph (DAG),\ncoupled with a decision-making framework employing Deep Reinforcement Learning\n(DRL) algorithms. To evaluate the method's performance, the proposed framework\ncan be tested and applied in a lane-changing scenario within a simulated\nenvironment. Furthermore, the experiment results demonstrate how our approach\nenhances the ability of AVs to navigate lane changes safely and efficiently on\nroads.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-28T17:24:04Z"}
{"aid":"http://arxiv.org/abs/2504.20026v1","title":"LIRM: Large Inverse Rendering Model for Progressive Reconstruction of\n  Shape, Materials and View-dependent Radiance Fields","summary":"We present Large Inverse Rendering Model (LIRM), a transformer architecture\nthat jointly reconstructs high-quality shape, materials, and radiance fields\nwith view-dependent effects in less than a second. Our model builds upon the\nrecent Large Reconstruction Models (LRMs) that achieve state-of-the-art\nsparse-view reconstruction quality. However, existing LRMs struggle to\nreconstruct unseen parts accurately and cannot recover glossy appearance or\ngenerate relightable 3D contents that can be consumed by standard Graphics\nengines. To address these limitations, we make three key technical\ncontributions to build a more practical multi-view 3D reconstruction framework.\nFirst, we introduce an update model that allows us to progressively add more\ninput views to improve our reconstruction. Second, we propose a hexa-plane\nneural SDF representation to better recover detailed textures, geometry and\nmaterial parameters. Third, we develop a novel neural directional-embedding\nmechanism to handle view-dependent effects. Trained on a large-scale shape and\nmaterial dataset with a tailored coarse-to-fine training scheme, our model\nachieves compelling results. It compares favorably to optimization-based\ndense-view inverse rendering methods in terms of geometry and relighting\naccuracy, while requiring only a fraction of the inference time.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-28T17:48:58Z"}
{"aid":"http://arxiv.org/abs/2504.20028v1","title":"Textured growth and electrical characterization of Zinc Sulfide on\n  back-end-of-the-line (BEOL) compatible substrates","summary":"Scaling of transistors has enabled continuous improvements in logic device\nperformance, especially through materials engineering. However, surpassing\nhorizontal limitations in chip manufacturing requires a vertical, third\ndimension. Three-dimensional integration of high-performance logic demands\nsolving the challenge of low-temperature (less than 450{\\deg}C) synthesis of\nhigh-mobility n-type and p-type semiconductor thin films for back-end-of-line\n(BEOL) compatible transistors. Metal oxides, particularly indium oxides alloyed\nwith gallium and tungsten, are promising n-type channel materials, but suitable\np-type materials for BEOL remain scarce. Zinc sulfide (ZnS), a wide band-gap\nsemiconductor, shows room-temperature p-type conductivity when doped with\ncopper and crystallizes below 400{\\deg}C. Here, we report growth of crystalline\nZnS thin films by pulsed laser deposition on amorphous and polycrystalline\nsurfaces including silicon nitride, thermal silicon dioxide, yttrium oxide,\nhafnium dioxide, sapphire, platinum, and titanium nitride. X-ray diffraction\nreveals out-of-plane texturing across all surfaces, while grazing incidence\nwide-angle X-ray scattering probes in-plane crystalline quality. Surface and\ninterface properties are assessed using X-ray reflectivity and atomic force\nmicroscopy. Electrical characterization via J-V measurements (ZnS on Pt) and\nmetal-oxide-semiconductor capacitor (ZnS on silicon dioxide) measurements show\nlow leakage current ($10^{-5} A/cm^2$ at 0.40 MV/cm) and bilayer capacitor\nbehavior, suggesting ZnS is highly intrinsic with minimal electrically active\ndefects. Further work on doping ZnS with copper or other p-type elements is\nneeded to realize ZnS as a dopable wide band-gap semiconductor for BEOL\nintegration. This work demonstrates a novel thin-film growth method for sulfide\nsemiconductors under BEOL-compatible conditions.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-28T17:51:54Z"}
{"aid":"http://arxiv.org/abs/2504.20045v1","title":"Up-type FCNC in presence of Dark Matter","summary":"Dark Matter (DM) is a known unknown. Apart, current experimental constraints\non flavor-changing neutral current (FCNC) processes involving up-type quarks\nalso provide scope to explore physics beyond the Standard Model (SM). In this\narticle, we establish a connection between the flavor sector and the DM sector\nwith minimal extension of the SM. Here a singlet complex scalar field, stable\nunder $\\mathbb{Z}_3$ symmetry, acts as DM and couples to SM up-type quarks\nthrough a heavy Dirac vector-like quark (VLQ), which shares the same\n$\\mathbb{Z}_3$ charge as of the DM. The model thus addresses the observed\n$D^0-\\bar{D^0}$ mixing, top-FCNC interactions, and $D^0$ meson decays, together\nwith DM relic density, while evading the direct and indirect DM search bounds.\nThe model can be probed at the future high-energy muon collider, through\ndistinctive signatures of VLQ production, where the VLQ decays into DM and SM\nparticles, abiding by the existing bounds.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-28T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.20459v1","title":"SAS-Prompt: Large Language Models as Numerical Optimizers for Robot\n  Self-Improvement","summary":"We demonstrate the ability of large language models (LLMs) to perform\niterative self-improvement of robot policies. An important insight of this\npaper is that LLMs have a built-in ability to perform (stochastic) numerical\noptimization and that this property can be leveraged for explainable robot\npolicy search. Based on this insight, we introduce the SAS Prompt (Summarize,\nAnalyze, Synthesize) -- a single prompt that enables iterative learning and\nadaptation of robot behavior by combining the LLM's ability to retrieve, reason\nand optimize over previous robot traces in order to synthesize new, unseen\nbehavior. Our approach can be regarded as an early example of a new family of\nexplainable policy search methods that are entirely implemented within an LLM.\nWe evaluate our approach both in simulation and on a real-robot table tennis\ntask. Project website: sites.google.com/asu.edu/sas-llm/","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-29T06:39:20Z"}
{"aid":"http://arxiv.org/abs/2504.20472v1","title":"Robustness via Referencing: Defending against Prompt Injection Attacks\n  by Referencing the Executed Instruction","summary":"Large language models (LLMs) have demonstrated impressive performance and\nhave come to dominate the field of natural language processing (NLP) across\nvarious tasks. However, due to their strong instruction-following capabilities\nand inability to distinguish between instructions and data content, LLMs are\nvulnerable to prompt injection attacks. These attacks manipulate LLMs into\ndeviating from the original input instructions and executing maliciously\ninjected instructions within data content, such as web documents retrieved from\nsearch engines. Existing defense methods, including prompt-engineering and\nfine-tuning approaches, typically instruct models to follow the original input\ninstructions while suppressing their tendencies to execute injected\ninstructions. However, our experiments reveal that suppressing\ninstruction-following tendencies is challenging. Through analyzing failure\ncases, we observe that although LLMs tend to respond to any recognized\ninstructions, they are aware of which specific instructions they are executing\nand can correctly reference them within the original prompt. Motivated by these\nfindings, we propose a novel defense method that leverages, rather than\nsuppresses, the instruction-following abilities of LLMs. Our approach prompts\nLLMs to generate responses that include both answers and their corresponding\ninstruction references. Based on these references, we filter out answers not\nassociated with the original input instructions. Comprehensive experiments\ndemonstrate that our method outperforms prompt-engineering baselines and\nachieves performance comparable to fine-tuning methods, reducing the attack\nsuccess rate (ASR) to 0 percent in some scenarios. Moreover, our approach has\nminimal impact on overall utility.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T07:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.20497v1","title":"Initialization of Neutral and Charged Exciton Spin States in a\n  Telecom-Emitting Quantum Dot","summary":"Photonic cluster states are highly entangled states that allow for photonic\nquantum computing and memory-less quantum repeaters. Their generation has been\nrecently demonstrated using semiconductor quantum dots emitting at the 900 nm\nwavelength range. However, a similar demonstration at the communication-optimal\ntelecom range has remained elusive. A key ingredient that is still missing is\nan appropriate optical excitation method. A central requirement of such a\nmethod is to allow an arbitrary spin initialization of quantum dot excitonic\ncomplexes. In this work, we report on developing such a method based on a\nquasi-resonant p-shell excitation for a telecom-C-band-emitting quantum dot. We\nshow qubit writing of a neutral exciton and spin-preserving excitation of a\nnegative trion. Using the Larmor precession of the negative trion under an\nexternally applied magnetic field, we determine the in-plane g-factors of both\nthe electron and the hole in the investigated quantum dot. In addition, we\nmeasure a lower bound on the hole coherence time, $T_{2}^{*}>6.4$ ns, boosting\nits candidacy as a sound photon entangler for more advanced quantum photonic\nschemes.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-04-29T07:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.20510v1","title":"SteelBlastQC: Shot-blasted Steel Surface Dataset with Interpretable\n  Detection of Surface Defects","summary":"Automating the quality control of shot-blasted steel surfaces is crucial for\nimproving manufacturing efficiency and consistency. This study presents a\ndataset of 1654 labeled RGB images (512x512) of steel surfaces, classified as\neither \"ready for paint\" or \"needs shot-blasting.\" The dataset captures\nreal-world surface defects, including discoloration, welding lines, scratches\nand corrosion, making it well-suited for training computer vision models.\nAdditionally, three classification approaches were evaluated: Compact\nConvolutional Transformers (CCT), Support Vector Machines (SVM) with ResNet-50\nfeature extraction, and a Convolutional Autoencoder (CAE). The supervised\nmethods (CCT and SVM) achieve 95% classification accuracy on the test set, with\nCCT leveraging transformer-based attention mechanisms and SVM offering a\ncomputationally efficient alternative. The CAE approach, while less effective,\nestablishes a baseline for unsupervised quality control. We present\ninterpretable decision-making by all three neural networks, allowing industry\nusers to visually pinpoint problematic regions and understand the model's\nrationale. By releasing the dataset and baseline codes, this work aims to\nsupport further research in defect detection, advance the development of\ninterpretable computer vision models for quality control, and encourage the\nadoption of automated inspection systems in industrial applications.","main_category":"cs.CV","categories":"cs.CV,cs.NE","published":"2025-04-29T07:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.20523v1","title":"On an Initial Value Problem Describing the Small Oscillations of a\n  Floating Cylinder","summary":"We study a coupled PDE-ODE system modeling the small oscillations of a\nfloating cylinder interacting with small water waves. We consider the case when\nthe floating is supposed to be an infinite circular cylinder, so that the\nequations of the free surface of the fluid can be written in one space\ndimension. The governing equations are formulated as an abstract evolution\nequation in a suitable Hilbert space, and we establish the well-posedness of\nthe associated initial value problem. A key element of the proof is the\nanalysis of a partial Dirichlet-to-Neumann map on an unbounded domain with a\nnon-smooth boundary.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T08:06:23Z"}
{"aid":"http://arxiv.org/abs/2504.20526v1","title":"Histogram-Probabilistic Multi-Hypothesis Tracking with Integrated Target\n  Existence","summary":"The histogram-probabilistic multi-hypothesis tracker (H-PMHT) is a parametric\napproach to solving the multi-target track-before-detect (TBD) problem, using\nexpectation maximisation (EM). A key limitation of this method is the\nassumption of a known and constant number of targets. In this paper, we propose\nthe integrated existence Poisson histogram probabilistic multi-hypothesis\ntracker (IE-PHPMHT), for TBD of multiple targets. It extends the H-PMHT\nframework by adding a probability of existence to each potential target. For\nthe derivation, we utilise a Poisson point process (PPP) measurement model and\nBernoulli targets, allowing for a multi-Bernoulli birth process and an unknown,\ntime-varying number of targets. Hence, integrated track management is achieved\nthrough the discrimination of track quality assessments based on existence\nprobabilities. The algorithm is evaluated in a simulation study of two\nscenarios and is compared with several other algorithms, demonstrating its\nperformance.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T08:12:07Z"}
{"aid":"http://arxiv.org/abs/2504.20528v1","title":"Physics-Informed Neural Network for Parameter Identification: a Buck\n  Converter Case Study","summary":"System-level condition monitoring methods estimate the electrical parameters\nof multiple components in a converter to assess their health status. The\nestimation accuracy and variation can differ significantly across parameters.\nFor instance, inductance estimations are generally more accurate and stable\nthan inductor resistance in a buck converter. However, these performance\ndifferences remain to be analyzed with a more systematic approach otherwise the\ncondition monitoring results can be unreliable. Therefore, this paper analyzes\nthe training loss landscape against multiple parameters of a buck converter to\nprovide a systematic explanation of different performances. If the training\nloss is high and smooth, the estimated circuit parameter typically is accurate\nand has low variation. Furthermore, a novel physics-informed neural network\n(PINN) is proposed, offering faster convergence and lower computation\nrequirements compared to an existing PINN method. The proposed method is\nvalidated through simulations, where the loss landscape identifies the\nunreliable parameter estimations, and the PINN can estimate the remaining\nparameters.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T08:15:09Z"}
{"aid":"http://arxiv.org/abs/2504.20532v1","title":"TriniMark: A Robust Generative Speech Watermarking Method for\n  Trinity-Level Attribution","summary":"The emergence of diffusion models has facilitated the generation of speech\nwith reinforced fidelity and naturalness. While deepfake detection technologies\nhave manifested the ability to identify AI-generated content, their efficacy\ndecreases as generative models become increasingly sophisticated. Furthermore,\ncurrent research in the field has not adequately addressed the necessity for\nrobust watermarking to safeguard the intellectual property rights associated\nwith synthetic speech and generative models. To remedy this deficiency, we\npropose a \\textbf{ro}bust generative \\textbf{s}peech wat\\textbf{e}rmarking\nmethod (TriniMark) for authenticating the generated content and safeguarding\nthe copyrights by enabling the traceability of the diffusion model. We first\ndesign a structure-lightweight watermark encoder that embeds watermarks into\nthe time-domain features of speech and reconstructs the waveform directly. A\ntemporal-aware gated convolutional network is meticulously designed in the\nwatermark decoder for bit-wise watermark recovery. Subsequently, the\nwaveform-guided fine-tuning strategy is proposed for fine-tuning the diffusion\nmodel, which leverages the transferability of watermarks and enables the\ndiffusion model to incorporate watermark knowledge effectively. When an\nattacker trains a surrogate model using the outputs of the target model, the\nembedded watermark can still be learned by the surrogate model and correctly\nextracted. Comparative experiments with state-of-the-art methods demonstrate\nthe superior robustness of our method, particularly in countering compound\nattacks.","main_category":"cs.MM","categories":"cs.MM,cs.CR,cs.SD,eess.AS","published":"2025-04-29T08:23:28Z"}
{"aid":"http://arxiv.org/abs/2504.20535v1","title":"DeeP-Mod: Deep Dynamic Programming based Environment Modelling using\n  Feature Extraction","summary":"The DeeP-Mod framework builds an environment model using features from a Deep\nDynamic Programming Network (DDPN), trained via a Deep Q-Network (DQN). While\nDeep Q-Learning is effective in decision-making, state information is lost in\ndeeper DQN layers due to mixed state-action representations. We address this by\nusing Dynamic Programming (DP) to train a DDPN, where Value Iteration ensures\nthe output represents state values, not state-action pairs. Extracting features\nfrom the DDPN preserves state information, enabling task and action set\nindependence. We show that a reduced DDPN can be trained using features\nextracted from the original DDPN trained on an identical problem. This reduced\nDDPN achieves faster convergence under noise and outperforms the original DDPN.\nFinally, we introduce the DeeP-Mod framework, which creates an environment\nmodel using the evolution of features extracted from a DDPN in response to\nactions. A second DDPN, which learns directly from this feature model rather\nthan raw states, can learn an effective feature-value representation and thus\noptimal policy. A key advantage of DeeP-Mod is that an externally defined\nenvironment model is not needed at any stage, making DDPN applicable to a wide\nrange of environments.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T08:30:11Z"}
{"aid":"http://arxiv.org/abs/2504.20551v1","title":"Accretion and ejection at work in the Narrow Line Seyfert 1 galaxy 1H\n  0323+342 -- A case of intermittent activity?","summary":"We present a comprehensive investigation into the properties of 1H 0323+342,\na prominent jetted narrow-line Seyfert 1 galaxy. The primary objective is to\nunderstand the interplay between the relativistic jet, the hot corona, and the\naccretion disk around the supermassive black hole. This study spans the years\n2006 to 2023, incorporating a rich dataset with 172 Swift observations,\nincluding the optical, UV, and X-ray bands, integrated with Fermi Large Area\nTelescope (LAT) observations. Spectral analysis was conducted on the X-ray\nobservations using the XSPEC software, and the results were compared with\noptical, UV, and gamma-ray flux measurements and photon index values. Our key\nfindings include the identification of three distinct zones in the X-ray photon\nindex-flux plot, characterized by high flux and a hard photon index (zone 1),\nhigh flux and a soft photon index (zone 2), and low flux and a soft photon\nindex (zone 3). Before 2017, 1H 0323+342 moved back and forth between zones 1\nand 2; after that epoch, it transitioned to zones 2 and 3. Correspondingly, we\nobserved a decreasing jet activity in the Fermi/LAT data and a reduction in the\naccretion rate in optical/UV data from Swift/UVOT. We interpret these\nobservations in the framework of an intermittent jet scenario, driven by\nradiation-pressure instability in the accretion disk.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-29T08:54:01Z"}
{"aid":"http://arxiv.org/abs/2504.20577v1","title":"Advanced biomarker analysis for early Alzheimer's detection: a 3-class\n  classification approach","summary":"The receiver operating characteristic (ROC) curve is an important tool for\nthe discrimination of two populations. However, in many settings, the\ndiagnostic decision is not limited to a binary choice. ROC surfaces are\nconsidered as a natural generalization of ROC curves in three-class diagnostic\nproblems and the Volume Under the ROC Surface (VUS) was proposed as an index\nfor the assessment of the diagnostic accuracy of the marker under\nconsideration. In this paper, we propose an overlap measure (OVL) in the case\nof three-class diagnostic problems. Specifically, parametric and non-parametric\napproaches for the estimation of OVL are introduced. We evaluate this measure\nthrough simulations and compare it with the well-known measure given by VUS.\nFurthermore, our proposal is applied to the clinical diagnosis of early stage\nAlzheimer's disease.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-29T09:33:47Z"}
{"aid":"http://arxiv.org/abs/2504.20608v1","title":"Communications-Centric Secure ISAC with Hybrid Reconfigurable\n  Intelligent Surfaces","summary":"Hybrid reconfigurable intelligent surfaces (HRISs) constitute an emerging\nparadigm of metasurfaces that empowers the concept of smart wireless\nenvironments, inherently supporting simultaneously communications and sensing.\nVery recently, some preliminary HRIS designs for Integrated Sensing And\nCommunications (ISAC) have appeared, however, secure ISAC schemes are still\nlacking. In this paper, we present a novel communications-centric secure ISAC\nframework capitalizing on the dual-functional capability of HRISs to realize\nbistatic sensing simultaneously with secure downlink communications. In\nparticular, we jointly optimize the BS precoding vector and the HRIS reflection\nand analog combining configurations to enable simultaneous accurate estimation\nof both a legitimate user and an eavesdropper, while guaranteeing a predefined\nthreshold for the secrecy spectral efficiency, with both operations focused\nwithin an area of interest. The presented simulation results validate the\neffectiveness of the proposed secure ISAC design, highlighting the interplay\namong key system design parameters as well as quantifying the trade-offs\nbetween the HRIS's absorption and reflection coeffcients.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T10:18:15Z"}
{"aid":"http://arxiv.org/abs/2504.20610v1","title":"Information Retrieval in the Age of Generative AI: The RGB Model","summary":"The advent of Large Language Models (LLMs) and generative AI is fundamentally\ntransforming information retrieval and processing on the Internet, bringing\nboth great potential and significant concerns regarding content authenticity\nand reliability. This paper presents a novel quantitative approach to shed\nlight on the complex information dynamics arising from the growing use of\ngenerative AI tools. Despite their significant impact on the digital ecosystem,\nthese dynamics remain largely uncharted and poorly understood. We propose a\nstochastic model to characterize the generation, indexing, and dissemination of\ninformation in response to new topics. This scenario particularly challenges\ncurrent LLMs, which often rely on real-time Retrieval-Augmented Generation\n(RAG) techniques to overcome their static knowledge limitations. Our findings\nsuggest that the rapid pace of generative AI adoption, combined with increasing\nuser reliance, can outpace human verification, escalating the risk of\ninaccurate information proliferation across digital resources. An in-depth\nanalysis of Stack Exchange data confirms that high-quality answers inevitably\nrequire substantial time and human effort to emerge. This underscores the\nconsiderable risks associated with generating persuasive text in response to\nnew questions and highlights the critical need for responsible development and\ndeployment of future generative AI tools.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.PF","published":"2025-04-29T10:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.20616v1","title":"Unavoidable subgraphs in digraphs with large out-degrees","summary":"We ask the question, which oriented trees $T$ must be contained as subgraphs\nin every finite directed graph of sufficiently large minimum out-degree. We\nformulate the following simple condition: all vertices in $T$ of in-degree at\nleast $2$ must be on the same 'level' in the natural height function of $T$. We\nprove this condition to be necessary and conjecture it to be sufficient. In\nsupport of our conjecture, we prove it for a fairly general class of trees.\n  An essential tool in the latter proof, and a question interesting in its own\nright, is finding large subdivided in-stars in a directed graph of large\nminimum out-degree. We conjecture that any digraph and oriented graph of\nminimum out-degree at least $k\\ell$ and $k\\ell/2$, respectively, contains the\n$(k-1)$-subdivision of the in-star with $\\ell$ leaves as a subgraph; this would\nbe tight and generalizes a conjecture of Thomass\\'e. We prove this for digraphs\nand $k=2$ up to a factor of less than $4$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T10:30:33Z"}
{"aid":"http://arxiv.org/abs/2504.20636v1","title":"Quasiperiodic Slow-Propagating EUV \"Wave\" Trains After the Filament\n  Eruption","summary":"The eruption of the filament/flux rope generates the coronal perturbations,\nwhich further form EUV waves. There are two types of EUV waves, including\nfast-mode magnetosonic waves and slow waves. In this paper, we first report an\nevent showing the Quasiperiodic Slow-Propagating (QSP) EUV \"wave\" trains during\nan M6.4-class flare (SOL2023-02-25T18:40), using multiple observations from\nSDO/AIA, CHASE/HIS, ASO-S/FMG, SUTRI, and LASCO/C2. The QSP \"wave\" trains\noccurred as the filament showed a rapid rise. The QSP \"wave\" trains have the\nprojected speeds of 50-130 km s$^{-1}$ on the plane of the sky, which is slower\nthan the fast-mode magnetosonic speed in the solar corona. And the calculated\nperiod of the QSP wave trains is 117.9 s, which is in good agreement with the\nassociated flare Quasi-Periodic Pulsation (140.3 s). The QSP wave trains could\nbe observed during the entire impulsive phase of the flare and lasted about 30\nminutes in the field of view (FOV) of SDO/AIA. About 30 minutes later, they\nappeared in the FOV of LASCO/C2 and propagated to the northwest. We suggest\nthat the QSP wave trains are probably apparent waves that are caused by the\nsuccessive stretching of the inclined field lines overlying the eruptive\nfilament. The periodic pattern of the QSP wave trains may be related to the\nintermittent energy release during the flare.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-29T11:06:51Z"}
{"aid":"http://arxiv.org/abs/2504.20639v1","title":"Multi-Message Secure Aggregation with Demand Privacy","summary":"This paper considers a multi-message secure aggregation with privacy problem,\nin which a server aims to compute $\\sf K_c\\geq 1$ linear combinations of local\ninputs from $\\sf K$ distributed users. The problem addresses two tasks: (1)\nsecurity, ensuring that the server can only obtain the desired linear\ncombinations without any else information about the users' inputs, and (2)\nprivacy, preventing users from learning about the server's computation task. In\naddition, the effect of user dropouts is considered, where at most $\\sf{K-U}$\nusers can drop out and the identity of these users cannot be predicted in\nadvance. We propose two schemes for $\\sf K_c$ is equal to (1) and $\\sf 2\\leq\nK_c\\leq U-1$, respectively. For $\\sf K_c$ is equal to (1), we introduce\nmultiplicative encryption of the server's demand using a random variable, where\nusers share coded keys offline and transmit masked models in the first round,\nfollowed by aggregated coded keys in the second round for task recovery. For\n$\\sf{2\\leq K_c \\leq U-1}$, we use robust symmetric private computation to\nrecover linear combinations of keys in the second round. The objective is to\nminimize the number of symbols sent by each user during the two rounds. Our\nproposed schemes have achieved the optimal rate region when $ \\sf K_c $ is\nequal to (1) and the order optimal rate (within 2) when $\\sf{2\\leq K_c \\leq\nU-1}$.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-29T11:11:27Z"}
{"aid":"http://arxiv.org/abs/2504.20640v1","title":"Sharpening Vahlen's result in Diophantine approximation","summary":"n this paper we refine Vahlen's 1895 result in Diophantine approximation by\nproviding sharper bounds for the approximation coefficients, especially when at\nleast one of the partial quotients $a_n$ or $a_{n+1}$ of the regular continued\nfraction expansion $[a_0;a_1,a_2,\\dots]$ of $x$ is 1. An improvement of\nVahlen's result was already given in papers by Jaroslav Han\\u{c}l ([9]),\nHan\\u{c}l and Silvie Bahnerova ([10]), and by Dinesh Sharma Bhattarai ([5]),\nbut the approach of the present paper is very different from Han\\u{c}l c.s. We\nbelieve that the geometrical methods used in this paper not only offer a\nsignificant improvement over Vahlen's result, but also yield new insights that\ncan contribute to improving Borel's classical constant.","main_category":"math.DS","categories":"math.DS,math.NT","published":"2025-04-29T11:11:36Z"}
{"aid":"http://arxiv.org/abs/2504.20683v1","title":"Quantum Computation for Jets in Heavy Ion Collisions","summary":"Quantum computing has recently emerged as a transformative tool for\ninvestigating the real-time dynamics of jets in heavy-ion collisions, offering\nnovel approaches to simulate non-equilibrium processes and strongly coupled\nphenomena that are challenging for classical methods. Here, I summarize my talk\nat Hard Probes 2024 at Nagasaki.","main_category":"hep-ph","categories":"hep-ph,nucl-th,quant-ph","published":"2025-04-29T12:03:04Z"}
{"aid":"http://arxiv.org/abs/2504.20692v1","title":"Inhomogeneous Diffusion in Confined Colloidal Suspensions","summary":"We have performed confocal microscopy experiments and computer simulations of\ncolloidal suspensions with moderate volume fraction confined between two\nquasi-parallel, rough walls [A. Villada-Balbuena et al., Soft Matter, 2022, 18,\n4699-4714]. Here we investigate many facets of the dynamical properties of the\nsystem, such as confined and inhomogeneous diffusion, mean first-passage times\nand generalized incoherent scattering functions. We observe that the experiment\nfeatures strong footprints of the confinement in the dynamical properties, such\nas inhomogeneous diffusion coefficients and non-zero off-diagonal elements in\nthe incoherent scattering function which we can quantitatively model and\nanalyze with computer simulations. This allows us, for example, to\nsystematically investigate the impact of surface roughness. Our comparative\nstudy therefore advances the fundamental understanding of the impact of\nconfinement on dynamics in fluids and colloidal suspensions.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-29T12:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.20736v1","title":"A Survey on Event-based Optical Marker Systems","summary":"The advent of event-based cameras, with their low latency, high dynamic\nrange, and reduced power consumption, marked a significant change in robotic\nvision and machine perception. In particular, the combination of these\nneuromorphic sensors with widely-available passive or active optical markers\n(e.g. AprilTags, arrays of blinking LEDs), has recently opened up a wide field\nof possibilities. This survey paper provides a comprehensive review on\nEvent-Based Optical Marker Systems (EBOMS). We analyze the basic principles and\ntechnologies on which these systems are based, with a special focus on their\nasynchronous operation and robustness against adverse lighting conditions. We\nalso describe the most relevant applications of EBOMS, including object\ndetection and tracking, pose estimation, and optical communication. The article\nconcludes with a discussion of possible future research directions in this\nrapidly-emerging and multidisciplinary field.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-29T13:21:03Z"}
{"aid":"http://arxiv.org/abs/2504.20744v1","title":"DB-GNN: Dual-Branch Graph Neural Network with Multi-Level Contrastive\n  Learning for Jointly Identifying Within- and Cross-Frequency Coupled Brain\n  Networks","summary":"Within-frequency coupling (WFC) and cross-frequency coupling (CFC) in brain\nnetworks reflect neural synchronization within the same frequency band and\ncross-band oscillatory interactions, respectively. Their synergy provides a\ncomprehensive understanding of neural mechanisms underlying cognitive states\nsuch as emotion. However, existing multi-channel EEG studies often analyze WFC\nor CFC separately, failing to fully leverage their complementary properties.\nThis study proposes a dual-branch graph neural network (DB-GNN) to jointly\nidentify within- and cross-frequency coupled brain networks. Firstly, DBGNN\nleverages its unique dual-branch learning architecture to efficiently mine\nglobal collaborative information and local cross-frequency and within-frequency\ncoupling information. Secondly, to more fully perceive the global information\nof cross-frequency and within-frequency coupling, the global perception branch\nof DB-GNN adopts a Transformer architecture. To prevent overfitting of the\nTransformer architecture, this study integrates prior within- and\ncross-frequency coupling information into the Transformer inference process,\nthereby enhancing the generalization capability of DB-GNN. Finally, a\nmulti-scale graph contrastive learning regularization term is introduced to\nconstrain the global and local perception branches of DB-GNN at both\ngraph-level and node-level, enhancing its joint perception ability and further\nimproving its generalization performance. Experimental validation on the\nemotion recognition dataset shows that DB-GNN achieves a testing accuracy of\n97.88% and an F1- score of 97.87%, reaching the state-of-the-art performance.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-29T13:24:37Z"}
{"aid":"http://arxiv.org/abs/2504.20745v1","title":"A note on general linear link homology","summary":"This expository note outlines why it is sometimes useful to consider the\nbigraded type A link homology theories as associated with the Lie algebras\ngl(N) instead of sl(N).","main_category":"math.QA","categories":"math.QA,math.GT","published":"2025-04-29T13:26:46Z"}
{"aid":"http://arxiv.org/abs/2504.20746v1","title":"Trotterization is substantially efficient for low-energy states","summary":"Trotterization is one of the central approaches for simulating quantum\nmany-body dynamics on quantum computers or tensor networks. In addition to its\nsimple implementation, recent studies have revealed that its error and cost can\nbe reduced if the initial state is closed in the low-energy subspace. However,\nthe improvement by the low-energy property rapidly vanishes as the Trotter\norder grows in the previous studies, and thus, it is mysterious whether there\nexists genuine advantage of low-energy initial states. In this Letter, we\nresolve this problem by proving the optimal error bound and cost of\nTrotterization for low-energy initial states. For generic local Hamiltonians\ncomposed of positive-semidefinite terms, we show that the Trotter error is at\nmost linear in the initial state energy $\\Delta$ and polylogarithmic in the\nsystem size $N$. As a result, the computational cost becomes substantially\nsmall for low-energy states with $\\Delta \\in o(Ng)$ compared to the one for\narbitrary initial states, where $g$ denotes the energy per site and $Ng$ means\nthe whole-system energy. Our error bound and cost of Trotterization achieve the\ntheoretically-best scaling in the initial state energy $\\Delta$. In addition,\nthey can be partially extended to weakly-correlated initial states having\nlow-energy expectation values, which are not necessarily closed in the\nlow-energy subspace. Our results will pave the way for fast and accurate\nsimulation of low-energy states, which are one central targets in condensed\nmatter physics and quantum chemistry.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other,math-ph,math.MP","published":"2025-04-29T13:27:14Z"}
{"aid":"http://arxiv.org/abs/2504.20763v1","title":"Understanding Large Language Model Supply Chain: Structure, Domain, and\n  Vulnerabilities","summary":"Large Language Models (LLMs) have revolutionized artificial intelligence\n(AI), driving breakthroughs in natural language understanding, text generation,\nand autonomous systems. However, the rapid growth of LLMs presents significant\nchallenges in the security and reliability of the Large Language Model Supply\nChain (LLMSC), a complex network of open-source components, libraries, and\ntools essential for LLM development and deployment. Despite its critical\nimportance, the LLMSC remains underexplored, particularly regarding its\nstructural characteristics, domain composition, and security vulnerabilities.\nTo address this gap, we conduct the first empirical study of the LLMSC,\nanalyzing a curated dataset of open-source packages from PyPI and NPM across 14\nfunctional domains. We construct a directed dependency graph comprising 15,725\nnodes, 10,402 edges, and 180 unique vulnerabilities to investigate the\nstructural characteristics of the LLMSC and analyze how security risks\npropagate through its dependency network. Our findings reveal that the LLMSC\nexhibits a ``locally dense, globally sparse'' topology, with 79.7% of\ndependency trees containing fewer than 5 nodes, while a few large trees\ndominate the ecosystem, accounting for 77.66% of all nodes. The graph is\ncharacterized by high-degree hubs, with the top 5 most connected nodes\naveraging 1,282 dependents each. Security analysis shows that critical\nvulnerabilities propagate to an average of 142.1 nodes at the second layer of\ndependency trees and peak at 237.8 affected nodes at the third layer. Notably,\ncascading risks are concentrated in critical hub nodes such as transformers,\nwhich directly or indirectly affect over 1,300 downstream packages. These\nfindings provide quantitative insights into the structural and security\ndynamics of the LLMSC and emphasize the need for targeted mitigation strategies\nto enhance ecosystem resilience.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-29T13:44:01Z"}
{"aid":"http://arxiv.org/abs/2504.20786v1","title":"Power corrections to the heavy electron form factor","summary":"We study the first power correction to the heavy electron form factor in QED.\nWe show that the first power correction factorizes as a derivative operator. We\ndiscuss the result in QED with no light fermions, where the first power\ncorrection can be written explicitly in terms of one loop integrals and the\nanomalous magnetic moment. In the presence of light fermions, the heavy\nelectron form factor admits a representation as a sum over matrix elements,\neach of which receives corrections from higher orders in perturbation theory.\nFrom this analysis we are able to extract the NLP soft photon theorem in the\nlimit of heavy fermion initiated dijet events. This is a first step towards\nstudying the heavy quark form factor in the non-abelian theory.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-29T14:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.20791v1","title":"Vibrational Energy Dissipation in Non-Contact Single-Molecule Junctions\n  Governed by Local Geometry and Electronic Structure","summary":"The vibrational dynamics of adsorbate molecules in single-molecule junctions\ndepend critically on the geometric structure and electronic interactions\nbetween molecule and substrate. Vibrations, excited mechanochemically or by\nexternal stimuli, dissipate energy into substrate electrons and phonons. Energy\ndissipation leads to the broadening of spectral lines, vibrational lifetimes,\nand the coupling between molecular and substrate phonons. It affects molecular\nmanipulation, giving rise to nanoscale friction, and contributes to scanning\nprobe and surface spectroscopy signals. We present an approach to disentangle\nadsorbate vibrational dynamics in non-contact junctions by employing density\nfunctional theory, machine learning, and non-adiabatic molecular dynamics.\nFocusing on the CO-functionalised Cu surfaces representing a single-molecule\njunction, a widely studied system in scanning probe and energy dissipation\nexperiments, we reveal strong vibrational mode specificity governed by the\ninterplay of electron-phonon and phonon-phonon coupling. Electron-phonon\nrelaxation rates vary by two orders of magnitude between modes and sensitively\ndepend on the tip-substrate geometry. We find evidence of a weak non-additive\neffect between both energy dissipation channels, where electron-phonon coupling\nenhances phonon-phonon coupling. Our predicted vibrational lifetimes agree with\ninfrared spectroscopy and helium scattering experiments. Finally, we outline\nhow our findings can inform and enhance scanning probe experiments.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-29T14:07:59Z"}
{"aid":"http://arxiv.org/abs/2504.20813v1","title":"A high-order energy-conserving semi-Lagrangian discontinuous Galerkin\n  method for the Vlasov-Ampere system","summary":"In this paper, we propose a high-order energy-conserving semi-Lagrangian\ndiscontinuous Galerkin(ECSLDG) method for the Vlasov-Ampere system. The method\nemploys a semi-Lagrangian discontinuous Galerkin scheme for spatial\ndiscretization of the Vlasov equation, achieving high-order accuracy while\nremoving the Courant-Friedrichs-Lewy (CFL) constraint. To ensure energy\nconservation and eliminate the need to resolve the plasma period, we adopt an\nenergy-conserving time discretization introduced by Liu et al. [J. Comput.\nPhys., 492 (2023), 112412]. Temporal accuracy is further enhanced through a\nhigh-order operator splitting strategy, yielding a method that is high-order\naccurate in both space and time. The resulting ECSLDG scheme is unconditionally\nstable and conserves both mass and energy at the fully discrete level,\nregardless of spatial or temporal resolution. Numerical experiments demonstrate\nthe accuracy, stability, and conservation properties of the proposed method. In\nparticular, the method achieves more accurate enforcement of Gauss's law and\nimproved numerical fidelity over low-order schemes, especially when using a\nlarge CFL number.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-29T14:28:01Z"}
{"aid":"http://arxiv.org/abs/2504.20814v1","title":"Secure Coding with AI, From Creation to Inspection","summary":"While prior studies have explored security in code generated by ChatGPT and\nother Large Language Models, they were conducted in controlled experimental\nsettings and did not use code generated or provided from actual developer\ninteractions. This paper not only examines the security of code generated by\nChatGPT based on real developer interactions, curated in the DevGPT dataset,\nbut also assesses ChatGPT's capability to find and fix these vulnerabilities.\nWe analysed 1,586 C, C++, and C# code snippets using static scanners, which\ndetected potential issues in 124 files. After manual analysis, we selected 26\nfiles with 32 confirmed vulnerabilities for further investigation.\n  We submitted these files to ChatGPT via the OpenAI API, asking it to detect\nsecurity issues, identify the corresponding Common Weakness Enumeration\nnumbers, and propose fixes. The responses and modified code were manually\nreviewed and re-scanned for vulnerabilities. ChatGPT successfully detected 18\nout of 32 security issues and resolved 17 issues but failed to recognize or fix\nthe remainder. Interestingly, only 10 vulnerabilities were resulted from the\nuser prompts, while 22 were introduced by ChatGPT itself.\n  We highlight for developers that code generated by ChatGPT is more likely to\ncontain vulnerabilities compared to their own code. Furthermore, at times\nChatGPT reports incorrect information with apparent confidence, which may\nmislead less experienced developers. Our findings confirm previous studies in\ndemonstrating that ChatGPT is not sufficiently reliable for generating secure\ncode nor identifying all vulnerabilities, highlighting the continuing\nimportance of static scanners and manual review.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-29T14:30:14Z"}
{"aid":"http://arxiv.org/abs/2504.20823v1","title":"Hybrid Quantum Recurrent Neural Network For Remaining Useful Life\n  Prediction","summary":"Predictive maintenance in aerospace heavily relies on accurate estimation of\nthe remaining useful life of jet engines. In this paper, we introduce a Hybrid\nQuantum Recurrent Neural Network framework, combining Quantum Long Short-Term\nMemory layers with classical dense layers for Remaining Useful Life forecasting\non NASA's Commercial Modular Aero-Propulsion System Simulation dataset. Each\nQuantum Long Short-Term Memory gate replaces conventional linear\ntransformations with Quantum Depth-Infused circuits, allowing the network to\nlearn high-frequency components more effectively. Experimental results\ndemonstrate that, despite having fewer trainable parameters, the Hybrid Quantum\nRecurrent Neural Network achieves up to a 5% improvement over a Recurrent\nNeural Network based on stacked Long Short-Term Memory layers in terms of mean\nroot mean squared error and mean absolute error. Moreover, a thorough\ncomparison of our method with established techniques, including Random Forest,\nConvolutional Neural Network, and Multilayer Perceptron, demonstrates that our\napproach, which achieves a Root Mean Squared Error of 15.46, surpasses these\nbaselines by approximately 13.68%, 16.21%, and 7.87%, respectively.\nNevertheless, it remains outperformed by certain advanced joint architectures.\nOur findings highlight the potential of hybrid quantum-classical approaches for\nrobust time-series forecasting under limited data conditions, offering new\navenues for enhancing reliability in predictive maintenance tasks.","main_category":"cs.LG","categories":"cs.LG,quant-ph","published":"2025-04-29T14:41:41Z"}
{"aid":"http://arxiv.org/abs/2504.20867v1","title":"Predicting the Performance of Scientific Workflow Tasks for Cluster\n  Resource Management: An Overview of the State of the Art","summary":"Scientific workflow management systems support large-scale data analysis on\ncluster infrastructures. For this, they interact with resource managers which\nschedule workflow tasks onto cluster nodes. In addition to workflow task\ndescriptions, resource managers rely on task performance estimates such as main\nmemory consumption and runtime to efficiently manage cluster resources. Such\nperformance estimates should be automated, as user-based task performance\nestimates are error-prone.\n  In this book chapter, we describe key characteristics of methods for workflow\ntask runtime and memory prediction, provide an overview and a detailed\ncomparison of state-of-the-art methods from the literature, and discuss how\nworkflow task performance prediction is useful for scheduling, energy-efficient\nand carbon-aware computing, and cost prediction.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-29T15:42:14Z"}
{"aid":"http://arxiv.org/abs/2504.20878v1","title":"On the structure of the dimension spectrum for continued fraction\n  expansions","summary":"We analyse the dimension spectrum of continued fractions expansions with\ncoefficients restricted to infinite subsets of $ \\mathbb{N}$. We prove that the\nset of powers $P_q=\\{q^n\\colon n\\in \\mathbb{N}\\}$ has full dimension spectrum\nfor each integer $q\\geq 2$, answering a question by Chousionis, Leykekhman and\nUrba\\'nski. On the other hand, we show that the dimension spectrum for\n$P^*_q=\\{q^n\\colon n\\in \\mathbb{N}\\}\\cup\\{1\\}$ has many gaps and regions where\nit is nowhere dense. We also investigate the case where $A$ is generated by a\nmonomial, $M_q=\\{n^q\\colon n\\in\\mathbb{N}\\}$. For $M_q$ we prove that the\ndimension spectrum is full for $q\\in\\{1,2,3,4,5\\}$, and it has a gap for each\n$q\\geq 6$. Furthermore we show for $q\\in\\{6,7,8\\}$ that the dimension spectrum\nof $M_q$ is the disjoint union of two nontrivial closed intervals, and it is\nthe disjoint union of three nontrivial closed intervals for $q \\in\\{9,10\\}$.\nFor $q\\geq 11$ we show that the dimension spectrum of $M_q$ consists of\nfinitely many disjoint nontrivial closed intervals. The results concerning\n$M_q$ extend existing results for $q=1$ and $q=2$. In our analysis we employ\nPerron-Frobenius (transfer) operators, and numerical tools developed by Falk\nand Nussbaum that give rigorous estimates for the Hausdorff dimension for\ncontinued fractions expansions.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-29T15:48:11Z"}
{"aid":"http://arxiv.org/abs/2504.20905v1","title":"Resonant inelastic X-ray scattering investigation of Hund's and\n  spin-orbit coupling in $5d^2$ double perovskites","summary":"$\\mathrm{B}$ site ordered $5d^2$ double perovskites ($\\mathrm{A_2BB'O_6,\\\nB'}=5d^2)$ display a remarkable range of physical properties upon variation of\nthe chosen $\\mathrm{B}$ and $\\mathrm{B'}$ site ions. This sensitivity to\nchemical substitution reflects the delicate balance and profound impact of\nstrong electronic correlation and spin-orbit coupling in such systems. We\npresent rhenium $L_2$ and $L_3$ resonant inelastic X-ray scattering (RIXS)\nmeasurements of two such physically dissimilar materials, Mott-insultating\n$\\mathrm{Ba_2YReO_6}$ and semiconducting $\\mathrm{Sr_2CrReO_6}$. Despite these\ndifferences, our RIXS results reveal similar energy scales of Hund's ($J_H$)\nand spin-orbit coupling ($\\lambda$) in the two materials, with both systems\nfirmly in the intermediate Hund's coupling regime\n($\\mathcal{O}(J_H/\\lambda)\\sim 1$). However, there are clear differences in\ntheir RIXS spectra. The conductive character of $\\mathrm{Sr_2CrReO_6}$ broadens\nand obfuscates the atomic transitions within an electron-hole continuum, while\nthe insulating character of $\\mathrm{Ba_2YReO_6}$ results in sharp atomic\nexcitations. This contrast in their RIXS spectra despite their similar energy\nscales reflects a difference in the itinerancy-promoting hopping integral and\nillustrates the impact of the local crystal environment in double perovskites.\nFinally, $L_2$ and $L_3$ edge analyses of the atomic excitations in\n$\\mathrm{Ba_2YReO_6}$ reveal that the energy scales of Hund's and spin-orbit\ncoupling are in fact inverted compared to previously reported values. We\npresent exact diagonalization calculations of the RIXS spectra at both edges\nwhich show good agreement with our results for new energy scales of\n$\\lambda=0.290(5)$ eV and $J_H=0.38(2)$ eV ($J_H/\\lambda=1.30(5)$).","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-29T16:20:47Z"}
{"aid":"http://arxiv.org/abs/2504.20933v1","title":"Another regularizing property of the 2D eikonal equation","summary":"A weak solution of the two-dimensional eikonal equation amounts to a vector\nfield $m\\colon\\Omega\\subset\\mathbb R^2\\to\\mathbb R^2$ such that $|m|=1$ a.e.\nand $\\mathrm{div}\\,m=0$ in $\\mathcal D'(\\Omega)$. It is known that, if $m$ has\nsome low regularity, e.g., continuous or $W^{1/3,3}$, then $m$ is automatically\nmore regular: locally Lipschitz outside a locally finite set. A long-standing\nconjecture by Aviles and Giga, if true, would imply the same regularizing\neffect under the Besov regularity assumption $m\\in B^{1/3}_{p,\\infty}$ for\n$p>3$. In this note we establish that regularizing effect in the borderline\ncase $p=6$, above which the Besov regularity assumption implies continuity. If\nthe domain is a disk and $m$ satisfies tangent boundary conditions, we also\nprove this for $p$ slightly below $6$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T16:50:37Z"}
{"aid":"http://arxiv.org/abs/2504.20943v1","title":"Viability of warm inflation with standard model interactions","summary":"The minimal warm inflation scenario proposed in Ref. [1] -- featuring an\naxion-like inflaton coupled to Standard Model (SM) gluons via the standard\ninteraction $\\phi G \\tilde G$ -- offers a compelling bridge between\ninflationary dynamics and SM particle content. While the model retains only the\ninflaton as a beyond-SM field, its original analysis relied on some approximate\ntreatments of warm inflation's (WI) dynamics. Here, we revisit this scenario\nusing WI2easy, a precision computational tool for WI dynamics [2], to\nrigorously evaluate the model's viability and full range of model's parameters\ncompatible with the observational parameters. Overall, we find that the results\nof Ref. [1] hold, but with significant differences in the weak and strong\ndissipative regimes of WI.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,gr-qc,hep-th","published":"2025-04-29T17:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.20947v1","title":"Opinion-Driven Decision-Making for Multi-Robot Navigation through Narrow\n  Corridors","summary":"We propose an opinion-driven navigation framework for multi-robot traversal\nthrough a narrow corridor. Our approach leverages a multi-agent decision-making\nmodel known as the Nonlinear Opinion Dynamics (NOD) to address the narrow\ncorridor passage problem, formulated as a multi-robot navigation game. By\nintegrating the NOD model with a multi-robot path planning algorithm, we\ndemonstrate that the framework effectively reduces the likelihood of deadlocks\nduring corridor traversal. To ensure scalability with an increasing number of\nrobots, we introduce a game reduction technique that enables efficient\ncoordination in larger groups. Extensive simulation studies are conducted to\nvalidate the effectiveness of the proposed approach.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-29T17:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.20957v1","title":"A Quieter State of Charge -- Ultra-Low-Noise Collective Current in\n  Charge-Density-Wave Nanowires","summary":"In quasi-one-dimensional (quasi-1D) charge-density-wave (CDW) systems,\nelectric current comprises normal electrons and a collective, electron-lattice\ncondensate current associated with CDW sliding. While achieving the\ndissipation-less Frohlich current of the sliding condensate is impossible in\nreal materials, one can imagine an important related target, namely reaching\nthe electron transport regime where electronic noise is inhibited due to the\ncollective, strongly-correlated nature of the electron-lattice condensate\ncurrent. Here we report that in nanowires of the fully-gapped CDW material\n(TaSe4)2I, low-frequency electronic noise is suppressed below the limit of\nthermalized charge carriers in passive resistors. When the current is dominated\nby the sliding Frohlich condensate, the normalized noise spectral density\ndecreases linearly with current -- a striking departure from the constant value\nobserved in conventional conductors. This discovery signals intrinsically lower\ncurrent fluctuations within a correlated transport regime. The dominant noise\nsource due to fluctuations in the CDW depinning threshold is extrinsic and\ncaused by lattice imperfections that locally pin the condensate. Once the bias\nvoltage is well past threshold and the sliding mode is established, the\nnormalized noise drops below the noise of normal electrons. No residual minimum\nnoise level is observed for the current of the condensate. Since flicker noise\nlimits phase stability in communication systems, reduces the sensitivity and\nselectivity of sensors, and degrades coherence in quantum devices, our\ndiscovery introduces a fundamentally new strategy for achieving ultra-low-noise\nperformance in nanoscale and quantum electronics using strongly correlated\nmaterials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-29T17:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.20980v1","title":"Jekyll-and-Hyde Tipping Point in an AI's Behavior","summary":"Trust in AI is undermined by the fact that there is no science that predicts\n-- or that can explain to the public -- when an LLM's output (e.g. ChatGPT) is\nlikely to tip mid-response to become wrong, misleading, irrelevant or\ndangerous. With deaths and trauma already being blamed on LLMs, this\nuncertainty is even pushing people to treat their 'pet' LLM more politely to\n'dissuade' it (or its future Artificial General Intelligence offspring) from\nsuddenly turning on them. Here we address this acute need by deriving from\nfirst principles an exact formula for when a Jekyll-and-Hyde tipping point\noccurs at LLMs' most basic level. Requiring only secondary school mathematics,\nit shows the cause to be the AI's attention spreading so thin it suddenly\nsnaps. This exact formula provides quantitative predictions for how the\ntipping-point can be delayed or prevented by changing the prompt and the AI's\ntraining. Tailored generalizations will provide policymakers and the public\nwith a firm platform for discussing any of AI's broader uses and risks, e.g. as\na personal counselor, medical advisor, decision-maker for when to use force in\na conflict situation. It also meets the need for clear and transparent answers\nto questions like ''should I be polite to my LLM?''","main_category":"cs.AI","categories":"cs.AI,cs.CY,nlin.AO,physics.comp-ph,physics.soc-ph","published":"2025-04-29T17:50:29Z"}
{"aid":"http://arxiv.org/abs/2504.21296v1","title":"Fairness in Graph Learning Augmented with Machine Learning: A Survey","summary":"Augmenting specialised machine learning techniques into traditional graph\nlearning models has achieved notable success across various domains, including\nfederated graph learning, dynamic graph learning, and graph transformers.\nHowever, the intricate mechanisms of these specialised techniques introduce\nsignificant challenges in maintaining model fairness, potentially resulting in\ndiscriminatory outcomes in high-stakes applications such as recommendation\nsystems, disaster response, criminal justice, and loan approval. This paper\nsystematically examines the unique fairness challenges posed by Graph Learning\naugmented with Machine Learning (GL-ML). It highlights the complex interplay\nbetween graph learning mechanisms and machine learning techniques, emphasising\nhow the augmentation of machine learning both enhances and complicates\nfairness. Additionally, we explore four critical techniques frequently employed\nto improve fairness in GL-ML methods. By thoroughly investigating the root\ncauses and broader implications of fairness challenges in this rapidly evolving\nfield, this work establishes a robust foundation for future research and\ninnovation in GL-ML fairness.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T04:02:23Z"}
{"aid":"http://arxiv.org/abs/2504.21304v1","title":"Unsupervised Feature Transformation via In-context Generation,\n  Generator-critic LLM Agents, and Duet-play Teaming","summary":"Feature transformation involves generating a new set of features from the\noriginal dataset to enhance the data's utility. In certain domains like\nmaterial performance screening, dimensionality is large and collecting labels\nis expensive and lengthy. It highly necessitates transforming feature spaces\nefficiently and without supervision to enhance data readiness and AI utility.\nHowever, existing methods fall short in efficient navigation of a vast space of\nfeature combinations, and are mostly designed for supervised settings. To fill\nthis gap, our unique perspective is to leverage a generator-critic duet-play\nteaming framework using LLM agents and in-context learning to derive\npseudo-supervision from unsupervised data. The framework consists of three\ninterconnected steps: (1) Critic agent diagnoses data to generate actionable\nadvice, (2) Generator agent produces tokenized feature transformations guided\nby the critic's advice, and (3) Iterative refinement ensures continuous\nimprovement through feedback between agents. The generator-critic framework can\nbe generalized to human-agent collaborative generation, by replacing the critic\nagent with human experts. Extensive experiments demonstrate that the proposed\nframework outperforms even supervised baselines in feature transformation\nefficiency, robustness, and practical applicability across diverse datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-30T04:26:03Z"}
{"aid":"http://arxiv.org/abs/2504.21306v1","title":"Semiclassical Approach to Quantum Fisher Information","summary":"Quantum sensors driven into the quantum chaotic regime can have dramatically\nenhanced sensitivity, which, however, depends intricately on the details of the\nunderlying classical phase space. Here, we develop an accurate semiclassical\napproach that provides direct and efficient access to the phase-space-resolved\nquantum Fisher information (QFI), the central quantity that quantifies the\nultimate achievable sensitivity. This approximation reveals, in very concrete\nterms, that the QFI is large whenever a specific dynamical quantity tied to the\nsensing parameter displays a large variance over the course of the\ncorresponding classical time evolution. Applied to a paradigmatic system of\nquantum chaos, the kicked top, we show that the semiclassical description is\naccurate already for modest quantum numbers, i.e. deep in the quantum regime,\nand extends seamlessly to very high quantum numbers that are beyond the reach\nof other methods.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-30T04:31:50Z"}
{"aid":"http://arxiv.org/abs/2504.21316v1","title":"Reduced order asymptotic observer of friction in motion control","summary":"An asymptotic observer of the motion state variables with nonlinear friction\n[1] benefits from a robust to the noise state-space representation of the\ndynamic friction force, including pre-sliding transitions, and implements the\nreduced order Luenberger observation law with only measurable output\ndisplacement. The uniform asymptotic stability and convergence analysis of the\nproposed observer are elaborated by using the Lyapunov function-based stability\ncriteria by Ignatyev and imposing the parametric constraints on the time\ndependent eigenvalues to be always negative real. A design procedure for\nassigning a dominant (thus slowest) real pole of the observer system matrix is\nproposed. A thorough experimental evaluation is given for the proposed\nobserver-based friction compensation, which is performed for positioning and\ntracking tasks and compared with an optimally tuned PID feedback control.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-30T05:04:48Z"}
{"aid":"http://arxiv.org/abs/2504.21330v1","title":"Does the Prompt-based Large Language Model Recognize Students'\n  Demographics and Introduce Bias in Essay Scoring?","summary":"Large Language Models (LLMs) are widely used in Automated Essay Scoring (AES)\ndue to their ability to capture semantic meaning. Traditional fine-tuning\napproaches required technical expertise, limiting accessibility for educators\nwith limited technical backgrounds. However, prompt-based tools like ChatGPT\nhave made AES more accessible, enabling educators to obtain machine-generated\nscores using natural-language prompts (i.e., the prompt-based paradigm).\nDespite advancements, prior studies have shown bias in fine-tuned LLMs,\nparticularly against disadvantaged groups. It remains unclear whether such\nbiases persist or are amplified in the prompt-based paradigm with cutting-edge\ntools. Since such biases are believed to stem from the demographic information\nembedded in pre-trained models (i.e., the ability of LLMs' text embeddings to\npredict demographic attributes), this study explores the relationship between\nthe model's predictive power of students' demographic attributes based on their\nwritten works and its predictive bias in the scoring task in the prompt-based\nparadigm. Using a publicly available dataset of over 25,000 students'\nargumentative essays, we designed prompts to elicit demographic inferences\n(i.e., gender, first-language background) from GPT-4o and assessed fairness in\nautomated scoring. Then we conducted multivariate regression analysis to\nexplore the impact of the model's ability to predict demographics on its\nscoring outcomes. Our findings revealed that (i) prompt-based LLMs can somewhat\ninfer students' demographics, particularly their first-language backgrounds,\nfrom their essays; (ii) scoring biases are more pronounced when the LLM\ncorrectly predicts students' first-language background than when it does not;\nand (iii) scoring error for non-native English speakers increases when the LLM\ncorrectly identifies them as non-native.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T05:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.21331v1","title":"Towards Space Group Determination from EBSD Patterns: The Role of Deep\n  Learning and High-throughput Dynamical Simulations","summary":"The design of novel materials hinges on the understanding of\nstructure-property relationships. However, our capability to synthesize a large\nnumber of materials has outpaced the ability and speed needed to characterize\nthem. While the overall chemical constituents can be readily known during\nsynthesis, the structural evolution and characterization of newly synthesized\nsamples remains a bottleneck for the ultimate goal of high throughput\nnanomaterials discovery. Thus, scalable methods for crystal symmetry\ndetermination that can analyze a large volume of material samples within a\nshort time-frame are especially needed. Kikuchi diffraction in the SEM is a\npromising technique for this due to its sensitivity to dynamical scattering,\nwhich may provide information beyond just the seven crystal systems and\nfourteen Bravais lattices. After diffraction patterns are collected from\nmaterial samples, deep learning methods may be able to classify the space group\nsymmetries using the patterns as input, which paired with the elemental\ncomposition, would help enable the determination of the crystal structure. To\ninvestigate the feasibility of this solution, neural networks were trained to\npredict the space group type of background corrected EBSD patterns. Our\nnetworks were first trained and tested on an artificial dataset of EBSD\npatterns of 5,148 different cubic phases, created through physics-based\ndynamical simulations. Next, Maximum Classifier Discrepancy, an unsupervised\ndeep learning-based domain adaptation method, was utilized to train neural\nnetworks to make predictions for experimental EBSD patterns. We introduce a\nrelabeling scheme, which enables our models to achieve accuracy scores higher\nthan 90% on simulated and experimental data, suggesting that neural networks\nare capable of making predictions of crystal symmetry from an EBSD pattern.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.CV","published":"2025-04-30T05:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.21334v1","title":"Simple Visual Artifact Detection in Sora-Generated Videos","summary":"The December 2024 release of OpenAI's Sora, a powerful video generation model\ndriven by natural language prompts, highlights a growing convergence between\nlarge language models (LLMs) and video synthesis. As these multimodal systems\nevolve into video-enabled LLMs (VidLLMs), capable of interpreting, generating,\nand interacting with visual content, understanding their limitations and\nensuring their safe deployment becomes essential. This study investigates\nvisual artifacts frequently found and reported in Sora-generated videos, which\ncan compromise quality, mislead viewers, or propagate disinformation. We\npropose a multi-label classification framework targeting four common artifact\nlabel types: label 1: boundary / edge defects, label 2: texture / noise issues,\nlabel 3: movement / joint anomalies, and label 4: object mismatches /\ndisappearances. Using a dataset of 300 manually annotated frames extracted from\n15 Sora-generated videos, we trained multiple 2D CNN architectures (ResNet-50,\nEfficientNet-B3 / B4, ViT-Base). The best-performing model trained by ResNet-50\nachieved an average multi-label classification accuracy of 94.14%. This work\nsupports the broader development of VidLLMs by contributing to (1) the creation\nof datasets for video quality evaluation, (2) interpretable artifact-based\nanalysis beyond language metrics, and (3) the identification of visual risks\nrelevant to factuality and safety.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T05:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.21369v1","title":"Pupil Phase Series: A Fast, Accurate, and Energy-Conserving Model for\n  Forward and Inverse Light Scattering in Thick Biological Samples","summary":"We present the pupil phase series (PPS), a fast and accurate forward\nscattering algorithm for simulating and inverting multiple light scattering in\nlarge biological samples. PPS achieves high-angle scattering accuracy and\nenergy conservation simultaneously by introducing a spatially varying phase\nmodulation in the pupil plane. By expanding the scattering term into a Taylor\nseries, PPS achieves high precision while maintaining computational efficiency.\nWe integrate PPS into a quasi-Newton inverse solver to reconstruct the\nthree-dimensional refractive index of a 180 um-thick human organoid. Compared\nto linear reconstruction, our method recovers subcellular features-such as\nnuclei and vesicular structures-deep within the sample volume. PPS offers a\nscalable and interpretable alternative to conventional solvers, paving the way\nfor high-throughput, label-free imaging of optically thick biological tissues.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-30T07:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.21400v1","title":"Who Gets the Callback? Generative AI and Gender Bias","summary":"Generative artificial intelligence (AI), particularly large language models\n(LLMs), is being rapidly deployed in recruitment and for candidate\nshortlisting. We audit several mid-sized open-source LLMs for gender bias using\na dataset of 332,044 real-world online job postings. For each posting, we\nprompt the model to recommend whether an equally qualified male or female\ncandidate should receive an interview callback. We find that most models tend\nto favor men, especially for higher-wage roles. Mapping job descriptions to the\nStandard Occupational Classification system, we find lower callback rates for\nwomen in male-dominated occupations and higher rates in female-associated ones,\nindicating occupational segregation. A comprehensive analysis of linguistic\nfeatures in job ads reveals strong alignment of model recommendations with\ntraditional gender stereotypes. To examine the role of recruiter identity, we\nsteer model behavior by infusing Big Five personality traits and simulating the\nperspectives of historical figures. We find that less agreeable personas reduce\nstereotyping, consistent with an agreeableness bias in LLMs. Our findings\nhighlight how AI-driven hiring may perpetuate biases in the labor market and\nhave implications for fairness and diversity within firms.","main_category":"econ.GN","categories":"econ.GN,cs.CL,q-fin.EC","published":"2025-04-30T07:55:52Z"}
{"aid":"http://arxiv.org/abs/2504.21401v1","title":"Neuro-imagerie nÃ©onatale : quelle valeur prÃ©dictive ?","summary":"Premature birth and various pre- and peri-natal stresses can lead to a\nvariety of brain lesions and have clearly been identified as major risk factors\nfor neurodevelopmental disorders, with variable but multiple consequences that\ncan significantly alter the functional outcome of children in the short, medium\nand long term. The main aim of the various diagnostic and prognostic markers\navailable, based in particular on clinical and neuroimaging data, is to\nfacilitate early detection of the various disorders and to optimise the\nfollow-up and management of these babies at risk of deficiencies.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-30T08:01:26Z"}
{"aid":"http://arxiv.org/abs/2504.21419v1","title":"Kernel Density Machines","summary":"We introduce kernel density machines (KDM), a novel density ratio estimator\nin a reproducing kernel Hilbert space setting. KDM applies to general\nprobability measures on countably generated measurable spaces without\nrestrictive assumptions on continuity, or the existence of a Lebesgue density.\nFor computational efficiency, we incorporate a low-rank approximation with\nprecisely controlled error that grants scalability to large-sample settings. We\nprovide rigorous theoretical guarantees, including asymptotic consistency, a\nfunctional central limit theorem, and finite-sample error bounds, establishing\na strong foundation for practical use. Empirical results based on simulated and\nreal data demonstrate the efficacy and precision of KDM.","main_category":"stat.ML","categories":"stat.ML,cs.LG,math.ST,stat.TH","published":"2025-04-30T08:25:25Z"}
{"aid":"http://arxiv.org/abs/2504.21464v1","title":"VR-FuseNet: A Fusion of Heterogeneous Fundus Data and Explainable Deep\n  Network for Diabetic Retinopathy Classification","summary":"Diabetic retinopathy is a severe eye condition caused by diabetes where the\nretinal blood vessels get damaged and can lead to vision loss and blindness if\nnot treated. Early and accurate detection is key to intervention and stopping\nthe disease progressing. For addressing this disease properly, this paper\npresents a comprehensive approach for automated diabetic retinopathy detection\nby proposing a new hybrid deep learning model called VR-FuseNet. Diabetic\nretinopathy is a major eye disease and leading cause of blindness especially\namong diabetic patients so accurate and efficient automated detection methods\nare required. To address the limitations of existing methods including dataset\nimbalance, diversity and generalization issues this paper presents a hybrid\ndataset created from five publicly available diabetic retinopathy datasets.\nEssential preprocessing techniques such as SMOTE for class balancing and CLAHE\nfor image enhancement are applied systematically to the dataset to improve the\nrobustness and generalizability of the dataset. The proposed VR-FuseNet model\ncombines the strengths of two state-of-the-art convolutional neural networks,\nVGG19 which captures fine-grained spatial features and ResNet50V2 which is\nknown for its deep hierarchical feature extraction. This fusion improves the\ndiagnostic performance and achieves an accuracy of 91.824%. The model\noutperforms individual architectures on all performance metrics demonstrating\nthe effectiveness of hybrid feature extraction in Diabetic Retinopathy\nclassification tasks. To make the proposed model more clinically useful and\ninterpretable this paper incorporates multiple XAI techniques. These techniques\ngenerate visual explanations that clearly indicate the retinal features\naffecting the model's prediction such as microaneurysms, hemorrhages and\nexudates so that clinicians can interpret and validate.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T09:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.21478v1","title":"CAE-DFKD: Bridging the Transferability Gap in Data-Free Knowledge\n  Distillation","summary":"Data-Free Knowledge Distillation (DFKD) enables the knowledge transfer from\nthe given pre-trained teacher network to the target student model without\naccess to the real training data. Existing DFKD methods focus primarily on\nimproving image recognition performance on associated datasets, often\nneglecting the crucial aspect of the transferability of learned\nrepresentations. In this paper, we propose Category-Aware Embedding Data-Free\nKnowledge Distillation (CAE-DFKD), which addresses at the embedding level the\nlimitations of previous rely on image-level methods to improve model\ngeneralization but fail when directly applied to DFKD. The superiority and\nflexibility of CAE-DFKD are extensively evaluated, including:\n\\textit{\\textbf{i.)}} Significant efficiency advantages resulting from altering\nthe generator training paradigm; \\textit{\\textbf{ii.)}} Competitive performance\nwith existing DFKD state-of-the-art methods on image recognition tasks;\n\\textit{\\textbf{iii.)}} Remarkable transferability of data-free learned\nrepresentations demonstrated in downstream tasks.","main_category":"cs.CV","categories":"cs.CV,cs.NE","published":"2025-04-30T09:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.21479v1","title":"Shifted wave equation on noncompact symmetric spaces","summary":"Let $G$ be a semisimple, connected, and noncompact Lie group with a finite\ncenter. We consider the Laplace-Beltrami operator $\\Delta$ on the homogeneous\nspace $G/K=S$ by a maximal compact subgroup $K$. We obtain pointwise estimates\nfor the kernel of an oscillating function $\\exp( it\\sqrt{|x|}) \\psi(x) $\napplied to the shifted Laplacian $\\Delta+|\\rho|^2$, a case not available\nbefore. We obtain a polynomial decay in time of the kernel, and of the\n$L^{p'}-L^p$ norms of the operator, for $2<p<\\infty$.","main_category":"math.AP","categories":"math.AP,math.FA,math.RT","published":"2025-04-30T09:58:20Z"}
{"aid":"http://arxiv.org/abs/2504.21480v1","title":"A Comprehensive Study of Exploitable Patterns in Smart Contracts: From\n  Vulnerability to Defense","summary":"With the rapid advancement of blockchain technology, smart contracts have\nenabled the implementation of increasingly complex functionalities. However,\nensuring the security of smart contracts remains a persistent challenge across\nthe stages of development, compilation, and execution. Vulnerabilities within\nsmart contracts not only undermine the security of individual applications but\nalso pose significant risks to the broader blockchain ecosystem, as\ndemonstrated by the growing frequency of attacks since 2016, resulting in\nsubstantial financial losses. This paper provides a comprehensive analysis of\nkey security risks in Ethereum smart contracts, specifically those written in\nSolidity and executed on the Ethereum Virtual Machine (EVM). We focus on two\nprevalent and critical vulnerability types (reentrancy and integer overflow) by\nexamining their underlying mechanisms, replicating attack scenarios, and\nassessing effective countermeasures.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.SE","published":"2025-04-30T10:00:36Z"}
{"aid":"http://arxiv.org/abs/2504.21502v1","title":"Concurrency Constrained Scheduling with Tree-Like Constraints","summary":"This paper investigates concurrency-constrained scheduling problems, where\nthe objective is to construct a schedule for a set of jobs subject to\nconcurrency restrictions. Formally, we are given a conflict graph $G$ defined\nover a set of $n$ jobs, where an edge between two jobs in $G$ indicates that\nthese jobs cannot be executed concurrently. Each job may have distinct\nattributes, such as processing time, due date, weight, and release time. The\ngoal is to determine a schedule that optimizes a specified scheduling criterion\nwhile adhering to all concurrency constraints. This framework offers a\nversatile model for analyzing resource allocation problems where processes\ncompete for shared resources, such as access to shared memory. From a\ntheoretical perspective, it encompasses several classical graph coloring\nproblems, including Chromatic Number, Sum Coloring, and Interval Chromatic\nNumber.\n  Given that even the simplest concurrency-constrained scheduling problems are\nNP-hard for general conflict graphs, this study focuses on conflict graphs with\nbounded treewidth. Our results establish a dichotomy: Some problems in this\nsetting can be solved in FPT time, while others are shown to be XALP-complete\nfor treewidth as parameter. Along the way, we generalize several previously\nknown results on coloring problems for bounded treewidth graphs. Several of the\nFPT algorithms are based on the insight that completion times are bounded by\nthe Grundy number of the conflict graph - the fact that this number is bounded\nby the product of treewidth and the logarithm of the number of vertices then\nleads to the FPT time bound.","main_category":"cs.DM","categories":"cs.DM,cs.CC","published":"2025-04-30T10:43:15Z"}
{"aid":"http://arxiv.org/abs/2504.21514v1","title":"Poncelet porism in singular cases","summary":"The celebrated Poncelet porism is usually studied for a pair of smooth conics\nthat are in a general position. Here we discuss Poncelet porism in the real\nplane - affine or projective, when that is not the case, i.e. the conics have\nat least one point of tangency or at least one of the conics is not smooth. In\nall such cases, we find necessary and sufficient conditions for the existence\nof an n-gon inscribed in one of the conics and circumscribed about the other.","main_category":"math.AG","categories":"math.AG,nlin.SI","published":"2025-04-30T11:08:18Z"}
{"aid":"http://arxiv.org/abs/2504.21535v1","title":"Universal Bound States with Bose-Fermi Duality in Microwave-Shielded\n  Polar Molecules","summary":"We investigate universal few-body bound states in microwave-shielded\nultracold polar molecules. Under a highly elliptic microwave field,\nfew-molecule scatterings in three dimension are shown to be governed by\neffective one-dimensional (1D) models. These models well reproduce the\ntetratomic (two-molecule) bound state and the Born-Oppenheimer potential in\nthree-molecule sector. For hexatomic systems comprising three identical\nmolecules, we find the lowest bound state emerge concurrently with tetratomic\nstate, with binding energy exceeding twice of the latter. Strikingly, all these\nbound states display Bose-Fermi duality, i.e., they share identical energies\nand spatial densities in both bosonic and fermionic molecular systems.\nUniversal features of these bound states are supported by the 1D nature of\neffective scattering and a large repulsive core in the reduced effective\npotential. For large molecule ensembles, our results suggest the formation of\nelongated self-bound droplets with crystalline patterns in both bosonic and\nfermionic polar molecules.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-30T11:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.21536v1","title":"Scientific Workflow Scheduling in Cloud Considering Cold Start and\n  Variable Pricing Model","summary":"Cloud computing has become a pivotal platform for executing scientific\nworkflows due to its scalable and cost-effective infrastructure. Scientific\nCloud Service Providers (SCSPs) act as intermediaries that rent virtual\nmachines (VMs) from Infrastructure-as-a-Service (IaaS) providers to meet users'\nworkflow execution demands. The SCSP earns profit from the execution of\nscientific workflows if it completes the execution of the workflow before the\nspecified deadline of the workflow. This paper addresses two key challenges\nthat impact the profitability of SCSPs: the cold start problem and the\nefficient management of diverse VM pricing models, namely reserved, on-demand,\nand spot instances.\n  We propose a hybrid scheduling framework that integrates initial planning\nbased on historical data with real-time adaptations informed by actual workload\nvariations. In the initial phase, VMs are provisioned using reserved pricing\nbased on predicted workloads and spot instances. During execution, the system\ndynamically adjusts by provisioning additional VMs through on-demand or spot\ninstances to accommodate unexpected bursts in task arrivals. Our framework also\nincorporates a dependency-aware task scheduling strategy that accounts for cold\nstart delays and spot pricing volatility. Experimental results on real-world\nbenchmark datasets demonstrate that our approach outperforms state-of-the-art\nmethods, achieving up to 20% improvement over cold-start-focused techniques and\n15% over pricing-model-based VM provisioning strategies.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-30T11:32:55Z"}
{"aid":"http://arxiv.org/abs/2504.21551v1","title":"Euclidean interval objects in categories with finite products","summary":"Based on the intuitive notion of convexity, we formulate a universal property\ndefining interval objects in a category with finite products. Interval objects\nare structures corresponding to closed intervals of the real line, but their\ndefinition does not assume a pre-existing notion of real number. The universal\nproperty characterises such structures up to isomorphism, supports the\ndefinition of functions between intervals, and provides a means of verifying\nidentities between functions. In the category of sets, the universal property\ncharacterises closed intervals of real numbers with nonempty interior. In the\nthe category of topological spaces, we obtain intervals with the Euclidean\ntopology. We also prove that every elementary topos with natural numbers object\ncontains an interval object; furthermore, we characterise interval objects as\nintervals of real numbers in the Cauchy completion of the rational numbers\nwithin the Dedekind reals.","main_category":"math.CT","categories":"math.CT,math.GN","published":"2025-04-30T11:49:27Z"}
{"aid":"http://arxiv.org/abs/2504.21555v1","title":"Quantitative Matrix-Driven Diophantine approximation on $M_0$-sets","summary":"Let $E\\subset [0,1)^{d}$ be a set supporting a probability measure $\\mu$ with\nFourier decay $|\\widehat{\\mu}({\\bf{t}})|\\ll (\\log |{\\bf{t}}|)^{-s}$ for some\nconstant $s>d+1.$ Consider a sequence of expanding integral matrices\n$\\mathcal{A}=(A_n)_{n\\in\\N}$ such that the minimal singular values of\n$A_{n+1}A_{n}^{-1}$ are uniformly bounded below by $K>1$. We prove a\nquantitative Schmidt-type counting theorem under the following constraints: (1)\nthe points of interest are restricted to $E$; (2) the denominators of the\n``shifted'' rational approximations are drawn exclusively from $\\mathcal{A}$.\nOur result extends the work of Pollington, Velani, Zafeiropoulos, and Zorin\n(2022) to the matrix setting, advancing the study of Diophantine approximation\non fractals. Moreover, it strengthens the equidistribution property of the\nsequence $(A_n{\\bf x})_{n\\in\\N}$ for $\\mu$-almost every ${\\bf x}\\in E.$\nApplications include the normality of vectors and shrinking target problems on\nfractal sets.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T11:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.21587v1","title":"Long time dynamics of the Cauchy problem for the predator-prey model\n  with cross-diffusion","summary":"This paper is concerned with a predator-prey model in $N$-dimensional spaces\n($N=1, 2, 3$), given by \\begin{align*}\\left\\{\\begin{aligned} &\\frac{\\partial\nu}{\\partial t}=\\Delta u-\\chi\\nabla\\cdot(u\\nabla v),\\\\ &\\frac{\\partial\nv}{\\partial t}=\\Delta v+\\xi\\nabla\\cdot(v\\nabla u), \\end{aligned}\\right.\n\\end{align*} which describes random movement of both predator and prey species,\nas well as the spatial dynamics involving predators pursuing prey and prey\nattempting to evade predators. It is shown that any global strong solutions of\nthe corresponding Cauchy problem converge to zero in the sense of $L^p$-norm\nfor any $1<p\\le \\infty$, and also converge to the heat kernel with respect to\n$L^p$-norm for any $1\\le p\\le \\infty$. In particular, the decay rate thereof is\noptimal in the sense that it is consistent with that of the heat equation in\n$\\mathbb R^N$ ($N=2, 3$). Undoubtedly, the global existence of solutions\nappears to be among the most challenging topic in the analysis of this model.\n  Indeed even in the one-dimensional setting, only global weak solutions in a\nbounded domain have been successfully constructed by far. Nevertheless, to\nprovide a comprehensive understanding of the main results, we append the\nconclusion on the global existence and asymptotic behavior of strong solutions,\nalthough certain smallness conditions on the initial data are required.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T12:44:47Z"}
{"aid":"http://arxiv.org/abs/2504.21589v1","title":"DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for\n  Automated Subject Indexing","summary":"This paper presents our system developed for the SemEval-2025 Task 5:\nLLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical\nLibrary's Open-Access Catalog. Our system relies on prompting a selection of\nLLMs with varying examples of intellectually annotated records and asking the\nLLMs to similarly suggest keywords for new records. This few-shot prompting\ntechnique is combined with a series of post-processing steps that map the\ngenerated keywords to the target vocabulary, aggregate the resulting subject\nterms to an ensemble vote and, finally, rank them as to their relevance to the\nrecord. Our system is fourth in the quantitative ranking in the all-subjects\ntrack, but achieves the best result in the qualitative ranking conducted by\nsubject indexing experts.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.DL,I.2.7","published":"2025-04-30T12:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.21600v1","title":"Anisotropic Grand Lorentz Spaces","summary":"In this article, new anisotropic grand Lorentz spaces are defined and their\nproperties are studied. These spaces are a new structure that provides a\nunified parameter for the study of various functional spaces. The consideration\nof grand spaces is especially important for the study of boundary conditions of\nparameters and allows us to achieve new results in this area. The study of\nboundary parameters in classical spaces is not always possible. In recent\nyears, grand Lebesgue spaces and their generalizations have been widely studied\nin problems of functional spaces. These spaces are generalizations of classical\nLorentz and grand Lorentz spaces. The article defines grand anisotropic Lorentz\nspaces, gives basic estimates in these spaces, proves embedding theorems, and\nderives embedding theorems for parameters. The results obtained can play an\nimportant role not only in theoretical, but also in applied problems.","main_category":"math.FA","categories":"math.FA","published":"2025-04-30T12:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.21628v1","title":"Cycles of lengths 3 and n-1 in digraphs under a Bang-Jensen-Gutin-Li\n  type conditon","summary":"Bang-Jensen-Gutin-Li type conditions are the conditions for hamiltonicity of\ndigraphs which impose degree restrictions on nonadjacent vertices which have a\ncommon in-neighbor or a common out-neighbor. They can be viewed as an extension\nof Fan type conditions in undirected graphs, as well as generalization of\nlocally (in-, out-)semicomplete digraphs. Since their first appearance in 1996,\nvarious Bang-Jensen-Gutin-Li type conditions for hamitonicity have come forth.\nIn this paper we establish a condition of Bang-Jensen-Gutin-Li type which\nimplies not only a hamiltonian cycle but also a 3-cycle and an (n-1)-cycle,\nwith well-characterized exceptional graphs. We conjecture that this condition\nimplies the existence of cycle of every length.","main_category":"math.CO","categories":"math.CO,G.2.2","published":"2025-04-30T13:30:11Z"}
{"aid":"http://arxiv.org/abs/2504.21646v1","title":"Diffusion-based Adversarial Identity Manipulation for Facial Privacy\n  Protection","summary":"The success of face recognition (FR) systems has led to serious privacy\nconcerns due to potential unauthorized surveillance and user tracking on social\nnetworks. Existing methods for enhancing privacy fail to generate natural face\nimages that can protect facial privacy. In this paper, we propose\ndiffusion-based adversarial identity manipulation (DiffAIM) to generate natural\nand highly transferable adversarial faces against malicious FR systems. To be\nspecific, we manipulate facial identity within the low-dimensional latent space\nof a diffusion model. This involves iteratively injecting gradient-based\nadversarial identity guidance during the reverse diffusion process,\nprogressively steering the generation toward the desired adversarial faces. The\nguidance is optimized for identity convergence towards a target while promoting\nsemantic divergence from the source, facilitating effective impersonation while\nmaintaining visual naturalness. We further incorporate structure-preserving\nregularization to preserve facial structure consistency during manipulation.\nExtensive experiments on both face verification and identification tasks\ndemonstrate that compared with the state-of-the-art, DiffAIM achieves stronger\nblack-box attack transferability while maintaining superior visual quality. We\nalso demonstrate the effectiveness of the proposed approach for commercial FR\nAPIs, including Face++ and Aliyun.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T13:49:59Z"}
{"aid":"http://arxiv.org/abs/2504.21673v1","title":"Effect of Magnetic Anisotropy and Gradient-Induced Dzyaloshinskii-Moriya\n  Interaction on the Formation of Magnetic Skyrmions","summary":"Topological spin textures (e.g. skyrmions) can be stabilized by interfacial\nDzyaloshinskii-Moriya interaction (DMI) in the magnetic multilayer, which has\nbeen intensively studied. Recently, Bloch-type magnetic skyrmions stabilized by\ncomposition gradient-induced DMI (g-DMI) have been observed in 10-nm thick CoPt\nsingle layer. However, magnetic anisotropy in gradient-composition engineered\nCoPt (g-CoPt) films is highly sensitive to both the relative Co/Pt composition\nand the film thickness, leading to a complex interplay with g-DMI. The\nstability of skyrmions under the combined influence of magnetic anisotropy and\ng-DMI is crucial yet remains poorly understood. Here, we conduct a systematic\nstudy on the characteristics of magnetic skyrmions as a function of gradient\npolarity and effective gradient strength (defined as gradient/thickness) in\ng-CoPt single layers (thickness of 10-30 nm) using magnetic force microscopy\n(MFM), bulk magnetometry, and topological Hall effect measurements. Brillouin\nlight scattering confirms that both the sign and magnitude of g-DMI depend on\nthe polarity and amplitude of the composition gradient in g-CoPt films. MFM\nreveals that skyrmion size and density vary with g-CoPt film thickness,\ngradient polarity, and applied magnetic field. An increased skyrmion density is\nobserved in samples exhibiting higher magnetic anisotropy, in agreement with\nmicromagnetic simulations and energy barrier calculations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-30T14:13:08Z"}
{"aid":"http://arxiv.org/abs/2504.21715v1","title":"Entanglement-Enhanced Nanoscale Single-Spin Sensing","summary":"Detecting individual spins--including stable and metastable\nstates--represents a fundamental challenge in quantum sensing with broad\napplications across condensed matter physics, quantum chemistry, and\nsingle-molecule magnetic resonance imaging. While nitrogen-vacancy (NV) centers\nin diamond have emerged as powerful nanoscale sensors, their performance for\nsingle-spin detection remains constrained by substantial environmental noise\nand restricted sensing volume. Here, we propose and demonstrate an\nentanglement-enhanced sensing protocol that overcomes these limitations through\nthe strategic use of entangled NV pairs. Our approach achieves a 3.4-fold\nenhancement in sensitivity and a 1.6-fold reduction in spatial resolution\nrelative to single NV centers under ambient conditions. The protocol employs\ncarefully engineered entangled states that amplify target spin signals through\nquantum interference while suppressing environmental noise. Crucially, we\nextend these capabilities to resolve metastable single-spin dynamics, directly\nobserving stochastic transitions between different spin states by identifying\nstate-dependent coupling strengths. This dual functionality enables\nsimultaneous detection of static and dynamic spin species for studying complex\nquantum systems. The achieved performance establishes entanglement-enhanced\nsensing as a viable pathway toward atomic-scale characterization of quantum\nmaterials and interface.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T14:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.21734v1","title":"Thermoelectric Thomson coefficient of quark-gluon plasma in the presence\n  of a time-varying magnetic field","summary":"Heavy-ion collision experiments such as the Large Hadron Collider and the\nRelativistic Heavy Ion Collider offer a unique platform to study several key\nproperties of the quark-gluon plasma (QGP), a deconfined state of strongly\ninteracting matter. Quarks, being the electrically charged particles, can\ninduce an electric current in the medium in response to the temperature\ngradients. Hence, the QGP medium can behave like a thermoelectric medium. The\nthermoelectric coefficients, such as the Seebeck and Thomson coefficients, can\nhelp us to understand the intricate transport phenomenon of the medium. In\nperipheral collisions, the intense, transient, and time-dependent magnetic\nfield created due to spectator protons significantly influences the\nthermoelectric properties of the QGP medium, affecting the charge and heat\ntransport. This work uses the quasi-particle model to calculate the Thomson\ncoefficient in QGP. The Thomson effect, describing the continuous heating or\ncooling of the charge-carrying medium in the presence of temperature gradients,\nremains largely unexplored in QGP. The Seebeck effect, which relates\ntemperature gradients to induced electric fields, has been widely studied in\nthe literature. For the first time, we calculate the magneto-Thomson and\ntransverse Thomson coefficients. We have studied their dependence on\ntemperature, baryon chemical potential, center of mass energy, and\ntime-dependent magnetic field with different decay parameters. The transverse\nThomson effect originates due to the presence of the Nernst effect in the\npresence of a magnetic field. Our results provide new insights into the\nhigher-order thermoelectric transport properties of the QGP medium in the\ncontext of heavy-ion collisions.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-th,nucl-ex,nucl-th","published":"2025-04-30T15:24:53Z"}
{"aid":"http://arxiv.org/abs/2504.21755v1","title":"Test particle motion around a black hole dressed with a spherically\n  symmetric stationary fluid","summary":"We investigate the motion of a massive particle around a spherically\nsymmetric black hole surrounded by a stationary and radial inflow of perfect\nfluid. The background spacetime is modelled as a spherically symmetric solution\nto the Einstein field equations, where the effect of the fluid on the geometry\nis treated as a perturbation on the Schwarzschild background. The equation of\nstate for the fluid is assumed to follow the linear relationship $p = w \\rho$,\nwhere $p$ is the pressure, $\\rho$ is the energy density with $w$ being a\nconstant. The stress-energy tensor is treated as a phenomenological model to\ncapture deviations from the vacuum Einstein theory. We allow the parameter $w$\nof the equation of state to take both positive and negative values accepting a\nbroad range of scenarios including exotic ones. Specifically, we examine the\ncases $w =2/3$, $1/3$, $-3/4$ and $-4/3$. For $\\rho\\geq0$, the former two cases\nsatisfy all standard energy conditions while the case of $w=-3/4$ violates the\nstrong energy condition and the case of $w=-4/3$ violates all standard energy\nconditions. By solving the geodesic equations, we visualize the time-like\ngeodesics around the black hole, focusing on the apsis shift of the orbit. To\ngain further insight into the effects of accretion, we employ the method of\nosculating orbital elements. Additionally, we analyze the observable effects on\nspacetime by studying the redshift of the orbiting test particles as an example\nof possible observables. We show that the difference in the particle orbits due\nto the matter accretion may be probed by using the redshift observation of\nstars orbiting around the black hole.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-30T15:51:14Z"}
{"aid":"http://arxiv.org/abs/2504.21759v1","title":"Smart Environmental Monitoring of Marine Pollution using Edge AI","summary":"Oil spill incidents pose severe threats to marine ecosystems and coastal\nenvironments, necessitating rapid detection and monitoring capabilities to\nmitigate environmental damage. In this paper, we demonstrate how artificial\nintelligence, despite the inherent high computational and memory requirements,\ncan be efficiently integrated into marine pollution monitoring systems. More\nprecisely, we propose a drone-based smart monitoring system leveraging a\ncompressed deep learning U-Net architecture for oil spill detection and\nthickness estimation. Compared to the standard U-Net architecture, the number\nof convolution blocks and channels per block are modified. The new model is\nthen trained on synthetic radar data to accurately predict thick oil slick\nthickness up to 10 mm. Results show that our optimized Tiny U-Net achieves\nsuperior performance with an Intersection over Union (IoU) metric of\napproximately 79%, while simultaneously reducing the model size by a factor of\n$\\sim$269x compared to the state-of-the-art. This significant model compression\nenables efficient edge computing deployment on field-programmable gate array\n(FPGA) hardware integrated directly into the drone platform. Hardware\nimplementation demonstrates near real-time thickness estimation capabilities\nwith a run-time power consumption of approximately 2.2 watts. Our findings\nhighlight the increasing potential of smart monitoring technologies and\nefficient edge computing for operational characterization in marine\nenvironments.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-30T15:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.21778v1","title":"LoC-LIC: Low Complexity Learned Image Coding Using Hierarchical Feature\n  Transforms","summary":"Current learned image compression models typically exhibit high complexity,\nwhich demands significant computational resources. To overcome these\nchallenges, we propose an innovative approach that employs hierarchical feature\nextraction transforms to significantly reduce complexity while preserving bit\nrate reduction efficiency. Our novel architecture achieves this by using fewer\nchannels for high spatial resolution inputs/feature maps. On the other hand,\nfeature maps with a large number of channels have reduced spatial dimensions,\nthereby cutting down on computational load without sacrificing performance.\nThis strategy effectively reduces the forward pass complexity from \\(1256 \\,\n\\text{kMAC/Pixel}\\) to just \\(270 \\, \\text{kMAC/Pixel}\\). As a result, the\nreduced complexity model can open the way for learned image compression models\nto operate efficiently across various devices and pave the way for the\ndevelopment of new architectures in image compression technology.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-30T16:30:06Z"}
{"aid":"http://arxiv.org/abs/2504.21780v1","title":"MAGNET: an open-source library for mesh agglomeration by Graph Neural\n  Networks","summary":"We introduce MAGNET, an open-source Python library designed for mesh\nagglomeration in both two- and three-dimensions, based on employing Graph\nNeural Networks (GNN). MAGNET serves as a comprehensive solution for training a\nvariety of GNN models, integrating deep learning and other advanced algorithms\nsuch as METIS and k-means to facilitate mesh agglomeration and quality metric\ncomputation. The library's introduction is outlined through its code structure\nand primary features. The GNN framework adopts a graph bisection methodology\nthat capitalizes on connectivity and geometric mesh information via SAGE\nconvolutional layers, in line with the methodology proposed by Antonietti et\nal. (2024). Additionally, the proposed MAGNET library incorporates\nreinforcement learning to enhance the accuracy and robustness of the model for\npredicting coarse partitions within a multilevel framework. A detailed tutorial\nis provided to guide the user through the process of mesh agglomeration and the\ntraining of a GNN bisection model. We present several examples of mesh\nagglomeration conducted by MAGNET, demonstrating the library's applicability\nacross various scenarios. Furthermore, the performance of the newly introduced\nmodels is contrasted with that of METIS and k-means, illustrating that the\nproposed GNN models are competitive regarding partition quality and\ncomputational efficiency. Finally, we exhibit the versatility of MAGNET's\ninterface through its integration with Lymph, an open-source library\nimplementing discontinuous Galerkin methods on polytopal grids for the\nnumerical discretization of multiphysics differential problems.","main_category":"math.NA","categories":"math.NA,cs.MS,cs.NA","published":"2025-04-30T16:33:22Z"}
{"aid":"http://arxiv.org/abs/2504.21791v1","title":"Martingale problem of the two-dimensional stochastic heat equation at\n  criticality","summary":"We study the martingale formulation of the two-dimensional stochastic heat\nequation (SHE) at criticality. The main theorem proves an exact recursive-type\nequation that expresses the covariation measures of the SHE in terms of the\nsolutions via an integro-multiplication operator. As an application, the\nquadratic variations of the martingale parts in the mild form are proven\nexplicitly expressible in the solutions of the SHE and the two-dimensional\ntwo-body delta-Bose gas semigroups. The proofs are based on the standard\napproximations of the two-dimensional SHE at criticality, and now we analyze\nasymptotic expansions of the covariation measures of the approximate solutions\nin the limit. Also, new bounds for certain mixed moments of the fourth order of\nthe approximate solutions are among the main tools for a priori estimates.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T16:50:25Z"}
{"aid":"http://arxiv.org/abs/2505.00270v1","title":"Large Language Models as AI Agents for Digital Atoms and Molecules:\n  Catalyzing a New Era in Computational Biophysics","summary":"In computational biophysics, where molecular data is expanding rapidly and\nsystem complexity is increasing exponentially, large language models (LLMs) and\nagent-based systems are fundamentally reshaping the field. This perspective\narticle examines the recent advances at the intersection of LLMs, intelligent\nagents, and scientific computation, with a focus on biophysical computation.\nBuilding on these advancements, we introduce ADAM (Agent for Digital Atoms and\nMolecules), an innovative multi-agent LLM-based framework. ADAM employs\ncutting-edge AI architectures to reshape scientific workflows through a modular\ndesign. It adopts a hybrid neural-symbolic architecture that combines\nLLM-driven semantic tools with deterministic symbolic computations. Moreover,\nits ADAM Tool Protocol (ATP) enables asynchronous, database-centric tool\norchestration, fostering community-driven extensibility. Despite the\nsignificant progress made, ongoing challenges call for further efforts in\nestablishing benchmarking standards, optimizing foundational models and agents,\nand building an open collaborative ecosystem. ADAM is accessible at\nhttps://sidereus-ai.com.","main_category":"physics.comp-ph","categories":"physics.comp-ph,physics.bio-ph","published":"2025-05-01T03:33:57Z"}
{"aid":"http://arxiv.org/abs/2505.00294v1","title":"Gravitational radiations from periodic orbits around Einstein-Ã†ther\n  black holes","summary":"In this work, we investigate the gravitational wave emission from the\nperiodic orbital motion of a test particle around two specific types of black\nholes in Einstein-\\AE{}ther theory, a modified gravity that locally breaks\nLorentz symmetry while remaining consistent with theoretical and observational\nconstraints through a careful selection of its four coupling constants $c_i$.\nFocusing on the impact of the \\ae{}ther field, we examine the properties of\nperiodic orbits, which are characterized by a set of three topological integers\n$(z, w, v)$ that uniquely classify their trajectories. We then calculate the\ngravitational waveforms generated by these periodic orbits, identifying\npotential observational signatures. Our analysis reveals a direct connection\nbetween the zoom-whirl orbital behavior of the small compact object and the\ngravitational waveforms it emits: higher zoom numbers lead to increasingly\nintricate waveform substructures. Moreover, the presence of the \\ae{}ther field\nintroduces significant modifications to these waveforms, imprinting measurable\ndeviations that could be potentially tested or constrained by future\nspace-based gravitational wave detectors.","main_category":"gr-qc","categories":"gr-qc","published":"2025-05-01T04:34:03Z"}
{"aid":"http://arxiv.org/abs/2505.00322v1","title":"AI2-Active Safety: AI-enabled Interaction-aware Active Safety Analysis\n  with Vehicle Dynamics","summary":"This paper introduces an AI-enabled, interaction-aware active safety analysis\nframework that accounts for groupwise vehicle interactions. Specifically, the\nframework employs a bicycle model-augmented with road gradient\nconsiderations-to accurately capture vehicle dynamics. In parallel, a\nhypergraph-based AI model is developed to predict probabilistic trajectories of\nambient traffic. By integrating these two components, the framework derives\nvehicle intra-spacing over a 3D road surface as the solution of a stochastic\nordinary differential equation, yielding high-fidelity surrogate safety\nmeasures such as time-to-collision (TTC). To demonstrate its effectiveness, the\nframework is analyzed using stochastic numerical methods comprising 4th-order\nRunge-Kutta integration and AI inference, generating probability-weighted\nhigh-fidelity TTC (HF-TTC) distributions that reflect complex multi-agent\nmaneuvers and behavioral uncertainties. Evaluated with HF-TTC against\ntraditional constant-velocity TTC and non-interaction-aware approaches on\nhighway datasets, the proposed framework offers a systematic methodology for\nactive safety analysis with enhanced potential for improving safety perception\nin complex traffic environments.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-05-01T05:46:34Z"}
{"aid":"http://arxiv.org/abs/2505.00356v1","title":"Do global forecasting models require frequent retraining?","summary":"In an era of increasing computational capabilities and growing environmental\nconsciousness, organizations face a critical challenge in balancing the\naccuracy of forecasting models with computational efficiency and\nsustainability. Global forecasting models, lowering the computational time,\nhave gained significant attention over the years. However, the common practice\nof retraining these models with new observations raises important questions\nabout the costs of forecasting. Using ten different machine learning and deep\nlearning models, we analyzed various retraining scenarios, ranging from\ncontinuous updates to no retraining at all, across two large retail datasets.\nWe showed that less frequent retraining strategies maintain the forecast\naccuracy while reducing the computational costs, providing a more sustainable\napproach to large-scale forecasting. We also found that machine learning models\nare a marginally better choice to reduce the costs of forecasting when coupled\nwith less frequent model retraining strategies as the frequency of the data\nincreases. Our findings challenge the conventional belief that frequent\nretraining is essential for maintaining forecasting accuracy. Instead, periodic\nretraining offers a good balance between predictive performance and efficiency,\nboth in the case of point and probabilistic forecasting. These insights provide\nactionable guidelines for organizations seeking to optimize forecasting\npipelines while reducing costs and energy consumption.","main_category":"stat.AP","categories":"stat.AP,stat.ML,stat.OT","published":"2025-05-01T07:00:29Z"}
{"aid":"http://arxiv.org/abs/2505.00359v1","title":"TNStream: Applying Tightest Neighbors to Micro-Clusters to Define\n  Multi-Density Clusters in Streaming Data","summary":"In data stream clustering, systematic theory of stream clustering algorithms\nremains relatively scarce. Recently, density-based methods have gained\nattention. However, existing algorithms struggle to simultaneously handle\narbitrarily shaped, multi-density, high-dimensional data while maintaining\nstrong outlier resistance. Clustering quality significantly deteriorates when\ndata density varies complexly. This paper proposes a clustering algorithm based\non the novel concept of Tightest Neighbors and introduces a data stream\nclustering theory based on the Skeleton Set. Based on these theories, this\npaper develops a new method, TNStream, a fully online algorithm. The algorithm\nadaptively determines the clustering radius based on local similarity,\nsummarizing the evolution of multi-density data streams in micro-clusters. It\nthen applies a Tightest Neighbors-based clustering algorithm to form final\nclusters. To improve efficiency in high-dimensional cases, Locality-Sensitive\nHashing (LSH) is employed to structure micro-clusters, addressing the challenge\nof storing k-nearest neighbors. TNStream is evaluated on various synthetic and\nreal-world datasets using different clustering metrics. Experimental results\ndemonstrate its effectiveness in improving clustering quality for multi-density\ndata and validate the proposed data stream clustering theory.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE","published":"2025-05-01T07:15:20Z"}
{"aid":"http://arxiv.org/abs/2505.00387v1","title":"Fast Azimuthally Anisotropic 3D Radon Transform by Generalized Fourier\n  Slice Theorem","summary":"Expensive computation of the conventional sparse Radon transform limits its\nuse for effective transformation of 3D anisotropic seismic data cubes. We\nintroduce a fast algorithm for azimuthally anisotropic 3D Radon transform with\nsparsity constraints, allowing effective transformation of seismic volumes\ncorresponding to arbitrary anisotropic inhomogeneous media. In particular, a 3D\ndata (CMP) cube of time and offset coordinates is transformed to a 3D cube of\nintercept time, slowness, and azimuth. The recently proposed generalized\nFourier slice theorem is employed for very fast calculation of the 3D inverse\ntransformation and its adjoint, which are subsequently used for efficient\nimplementation of the sparse transform via a forward-backward splitting\nalgorithm. The new anisotropic transform improves the temporal resolution of\nthe resulting seismic data. Furthermore, the Radon transform coefficients\nallows constructing azimuthally dependent NMO velocity curve at any horizontal\nplane, which can be inverted for the medium anisotropic parameters. Numerical\nexamples using synthetic data sets are presented showing the effectiveness of\nthe proposed anisotropic method in improving seismic processing results\ncompared with conventional isotropic counterpart.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-05-01T08:23:35Z"}
{"aid":"http://arxiv.org/abs/2505.00388v1","title":"New kinds of block diagonal matching fields and toric degenerations of\n  Grassmannians","summary":"Block diagonal matching field has many previous works. In general, a coherent\nmatching field induces a monomial order to Pl\\\"{u}cker algebra, and block\ndiagonal matching fields are a kind of coherent matching fields. In the present\npaper, we introduce a new kind of block diagonal matching fields and study the\nproblem when they give a SAGBI basis. As a corollary, we provide a new family\nof toric degenerations of Grassmannians by using SAGBI bases.","main_category":"math.CO","categories":"math.CO,math.AC","published":"2025-05-01T08:23:48Z"}
{"aid":"http://arxiv.org/abs/2505.00390v1","title":"Neutron Star Radii from Laboratory Experiments","summary":"Our present knowledge of the nuclear equation of state is briefly reviewed in\nthis article intended for a wider readership. Particular emphasis is given to\nthe asymmetric-matter equation of state required for modeling neutron stars,\nneutron-star mergers, and r-process nucleosynthesis. Recent analyses based on\ncombining information obtained from nuclear theory, heavy-ion collisions and\nastrophysical observations confine the obtained radii of the canonical\n1.4-solar-mass neutron star to values between 12 km and 13 km. The remaining\nuncertainty is primarily related to missing information in the density interval\nbetween nuclear saturation density and about twice that value which, however,\nis accessible with laboratory experiments.","main_category":"nucl-th","categories":"nucl-th,astro-ph.SR,nucl-ex","published":"2025-05-01T08:28:06Z"}
{"aid":"http://arxiv.org/abs/2505.00414v1","title":"Ladders and Squares","summary":"In 1984, Ditor asked two questions: (1) For each $n\\in\\omega$ and infinite\ncardinal $\\kappa$, is there a join-semilattice of breadth $n+1$ and cardinality\n$\\kappa^{+n}$ whose principal ideals have cardinality $< \\kappa$? (2) For each\n$n \\in \\omega$, is there a lower-finite lattice of cardinality $\\aleph_{n}$\nwhose elements have at most $n+1$ lower covers? We show that both questions\nhave positive answers under the axiom of constructibility, and hence\nconsistently with $\\mathsf{ZFC}$. More specifically, we derive the positive\nanswers from assuming that $\\square_\\kappa$ holds for enough $\\kappa$'s.","main_category":"math.LO","categories":"math.LO,math.CO","published":"2025-05-01T09:24:41Z"}
{"aid":"http://arxiv.org/abs/2505.00467v1","title":"Red Teaming Large Language Models for Healthcare","summary":"We present the design process and findings of the pre-conference workshop at\nthe Machine Learning for Healthcare Conference (2024) entitled Red Teaming\nLarge Language Models for Healthcare, which took place on August 15, 2024.\nConference participants, comprising a mix of computational and clinical\nexpertise, attempted to discover vulnerabilities -- realistic clinical prompts\nfor which a large language model (LLM) outputs a response that could cause\nclinical harm. Red-teaming with clinicians enables the identification of LLM\nvulnerabilities that may not be recognised by LLM developers lacking clinical\nexpertise. We report the vulnerabilities found, categorise them, and present\nthe results of a replication study assessing the vulnerabilities across all\nLLMs provided.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T11:43:27Z"}
{"aid":"http://arxiv.org/abs/2505.00473v1","title":"Interpretable Spatial-Temporal Fusion Transformers: Multi-Output\n  Prediction for Parametric Dynamical Systems with Time-Varying Inputs","summary":"We explore the promising performance of a transformer model in predicting\noutputs of parametric dynamical systems with external time-varying input\nsignals. The outputs of such systems vary not only with physical parameters but\nalso with external time-varying input signals. Accurately catching the dynamics\nof such systems is challenging. We have adapted and extended an existing\ntransformer model for single output prediction to a multiple-output transformer\nthat is able to predict multiple output responses of these systems. The\nmultiple-output transformer generalizes the interpretability of the original\ntransformer. The generalized interpretable attention weight matrix explores not\nonly the temporal correlations in the sequence, but also the interactions\nbetween the multiple outputs, providing explanation for the spatial correlation\nin the output domain. This multiple-output transformer accurately predicts the\nsequence of multiple outputs, regardless of the nonlinearity of the system and\nthe dimensionality of the parameter space.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-05-01T11:55:42Z"}
{"aid":"http://arxiv.org/abs/2505.00476v1","title":"Simplified Fermionic Scattering State Preparation for the NISQ Era","summary":"With quantum computers steadily improving, large volume quantum scattering\nsimulations is getting very close. Yet, in the noisy intermediate scale quantum\n(NISQ) era, we are limited to shallow circuits on the order of a thousand\nlayers. Thus, accurate and efficient state preparation methods are needed. We\nintroduce a simplified fermionic scattering state preparation method that\nreduces circuit depth significantly by partially relaxing the fermionic\ncondition. Using the 1+1D transverse field Ising model as our test bed with\nexact diagonalization and time evolving block decimation with matrix product\nstates, we show that our simplified states retain nearly all of the behavior of\nthe true fermionic state while being prepared on just a handful of qubits. We\nalso show promising early results on IonQ Forte 1.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T12:03:58Z"}
{"aid":"http://arxiv.org/abs/2505.00487v1","title":"Analysis of the vulnerability of machine learning regression models to\n  adversarial attacks using data from 5G wireless networks","summary":"This article describes the process of creating a script and conducting an\nanalytical study of a dataset using the DeepMIMO emulator. An advertorial\nattack was carried out using the FGSM method to maximize the gradient. A\ncomparison is made of the effectiveness of binary classifiers in the task of\ndetecting distorted data. The dynamics of changes in the quality indicators of\nthe regression model were analyzed in conditions without adversarial attacks,\nduring an adversarial attack and when the distorted data was isolated. It is\nshown that an adversarial FGSM attack with gradient maximization leads to an\nincrease in the value of the MSE metric by 33% and a decrease in the R2\nindicator by 10% on average. The LightGBM binary classifier effectively\nidentifies data with adversarial anomalies with 98% accuracy. Regression\nmachine learning models are susceptible to adversarial attacks, but rapid\nanalysis of network traffic and data transmitted over the network makes it\npossible to identify malicious activity","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-05-01T12:36:05Z"}
{"aid":"http://arxiv.org/abs/2505.00533v1","title":"Test-time Correlation Alignment","summary":"Deep neural networks often experience performance drops due to distribution\nshifts between training and test data. Although domain adaptation offers a\nsolution, privacy concerns restrict access to training data in many real-world\nscenarios. This restriction has spurred interest in Test-Time Adaptation (TTA),\nwhich adapts models using only unlabeled test data. However, current TTA\nmethods still face practical challenges: (1) a primary focus on instance-wise\nalignment, overlooking CORrelation ALignment (CORAL) due to missing source\ncorrelations; (2) complex backpropagation operations for model updating,\nresulting in overhead computation and (3) domain forgetting.\n  To address these challenges, we provide a theoretical analysis to investigate\nthe feasibility of Test-time Correlation Alignment (TCA), demonstrating that\ncorrelation alignment between high-certainty instances and test instances can\nenhance test performances with a theoretical guarantee. Based on this, we\npropose two simple yet effective algorithms: LinearTCA and LinearTCA+.\nLinearTCA applies a simple linear transformation to achieve both instance and\ncorrelation alignment without additional model updates, while LinearTCA+ serves\nas a plug-and-play module that can easily boost existing TTA methods. Extensive\nexperiments validate our theoretical insights and show that TCA methods\nsignificantly outperforms baselines across various tasks, benchmarks and\nbackbones. Notably, LinearTCA improves adaptation accuracy by 5.88% on\nOfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6%\ncomputation time compared to the best baseline TTA method.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-01T13:59:13Z"}
{"aid":"http://arxiv.org/abs/2505.00542v1","title":"Scalable Quantum Computing with Optical Links","summary":"Quantum computers have great potential to solve problems which are\nintractable on classical computers. However, quantum processors have not yet\nreached the required scale to run applications which outperform traditional\ncomputers. Leading hardware platforms, such as superconducting qubit based\nprocessors, will soon become bottlenecked by the physical constraints of their\nlow temperature environments, and the expansion of quantum computers will\nnecessitate quantum links between multiple processor modules. Optical\nfrequencies offer the most promising path for these links due to their\nresilience to noise even at ambient temperature and the maturity of classical\noptical networks. However, required microwave-to-optics transducers cannot\noperate deterministically yet, which has widely been seen as a key challenge\nfor their integration into fault-tolerant quantum computers. In this work, we\nexamine implementations of optical links between cryogenic units that surpass\nthe performance of individual cryogenic modules even with the performance of\nexisting or near-term microwave-to-optics transducers. We show methods for\nthese transducers to provide on-demand entanglement between separated quantum\nprocessors with high fidelity and lay out key steps for adoption of the\ntechnology including scaling transducer numbers and integration with other\nhardware. Finally, we discuss a number of architectures comprised of these\nlinks which can drive the expansion of quantum data centers to utility scale.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-05-01T14:09:32Z"}
{"aid":"http://arxiv.org/abs/2505.00559v1","title":"Evolution variational inequalities with general costs","summary":"We extend the theory of gradient flows beyond metric spaces by studying\nevolution variational inequalities (EVIs) driven by general cost functions $c$,\nincluding Bregman and entropic transport divergences. We establish several\nproperties of the resulting flows, including stability and energy identities.\nUsing novel notions of convexity related to costs $c$, we prove that EVI flows\nare the limit of splitting schemes, providing assumptions for both implicit and\nexplicit iterations.","main_category":"math.FA","categories":"math.FA,math.MG","published":"2025-05-01T14:35:04Z"}
{"aid":"http://arxiv.org/abs/2505.00572v1","title":"A Bioinformatic Study of Genetics Involved in Determining Mild Traumatic\n  Brain Injury Severity and Recovery","summary":"Aim: This in silico study sought to identify specific biomarkers for mild\ntraumatic brain injury (mTBI) through the analysis of publicly available gene\nand miRNA databases, hypothesizing their influence on neuronal structure,\naxonal integrity, and regeneration. Methods: This study implemented a\nthree-step process: (1) Data searching for mTBI-related genes in Gene and\nMalaCard databases and literature review ; (2) Data analysis involved\nperforming functional annotation through GO and KEGG, identifying hub genes\nusing Cytoscape, mapping protein-protein interactions via DAVID and STRING, and\npredicting miRNA targets using miRSystem, miRWalk2.0, and mirDIP (3)\nRNA-sequencing analysis applied to the mTBI dataset GSE123336. Results: Eleven\ncandidate hub genes associated with mTBI outcome were identified: APOE, S100B,\nGFAP, BDNF, AQP4, COMT, MBP, UCHL1, DRD2, ASIC1, and CACNA1A. Enrichment\nanalysis linked these genes to neuron projection regeneration and synaptic\nplasticity. miRNAs linked to the mTBI candidate genes were hsa-miR-9-5p,\nhsa-miR-204-5p, hsa-miR-1908-5p, hsa-miR-16-5p, hsa-miR-10a-5p, has-miR-218-5p,\nhas-miR-34a-5p, and has-miR-199b-5p. The RNA sequencing revealed 2664\ndifferentially expressed miRNAs post-mTBI, with 17 showing significant changes\nat the time of injury and 48 hours post-injury. Two miRNAs were positively\ncorrelated with direct head hits. Conclusion: Our study indicates that specific\ngenes and miRNAs, particularly hsa-miR-10a-5p, may influence mTBI outcomes. Our\nresearch may guide future mTBI diagnostics, emphasizing the need to measure and\ntrack these specific genes and miRNAs in diverse cohorts.","main_category":"q-bio.GN","categories":"q-bio.GN,q-bio.NC","published":"2025-05-01T14:56:46Z"}
{"aid":"http://arxiv.org/abs/2505.00614v1","title":"Infinite sums of combinatorial games (Dadaist games)","summary":"We propose an interpretation of the infinite sum of combinatorial games. In\nsuch an interpretation, plays involve infinite runs, but without loops. The\nnotion of a run is quite natural, but different possibilities arises for the\nnotion of an alternating run.","main_category":"math.CO","categories":"math.CO,math.RA","published":"2025-05-01T15:47:02Z"}
{"aid":"http://arxiv.org/abs/2505.00625v1","title":"SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic\n  Regression for high-fidelity material property prediction","summary":"Recent advances in machine learning have demonstrated an enormous utility of\ndeep learning approaches, particularly Graph Neural Networks (GNNs) for\nmaterials science. These methods have emerged as powerful tools for\nhigh-throughput prediction of material properties, offering a compelling\nenhancement and alternative to traditional first-principles calculations. While\nthe community has predominantly focused on developing increasingly complex and\nuniversal models to enhance predictive accuracy, such approaches often lack\nphysical interpretability and insights into materials behavior. Here, we\nintroduce a novel computational paradigm, Self-Adaptable Graph Attention\nNetworks integrated with Symbolic Regression (SA-GAT-SR), that synergistically\ncombines the predictive capability of GNNs with the interpretative power of\nsymbolic regression. Our framework employs a self-adaptable encoding algorithm\nthat automatically identifies and adjust attention weights so as to screen\ncritical features from an expansive 180-dimensional feature space while\nmaintaining O(n) computational scaling. The integrated SR module subsequently\ndistills these features into compact analytical expressions that explicitly\nreveal quantum-mechanically meaningful relationships, achieving 23 times\nacceleration compared to conventional SR implementations that heavily rely on\nfirst principle calculations-derived features as input. This work suggests a\nnew framework in computational materials science, bridging the gap between\npredictive accuracy and physical interpretability, offering valuable physical\ninsights into material behavior.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,cs.LG","published":"2025-05-01T16:05:10Z"}
{"aid":"http://arxiv.org/abs/2505.00654v1","title":"Large Language Models Understanding: an Inherent Ambiguity Barrier","summary":"A lively ongoing debate is taking place, since the extraordinary emergence of\nLarge Language Models (LLMs) with regards to their capability to understand the\nworld and capture the meaning of the dialogues in which they are involved.\nArguments and counter-arguments have been proposed based upon thought\nexperiments, anecdotal conversations between LLMs and humans, statistical\nlinguistic analysis, philosophical considerations, and more. In this brief\npaper we present a counter-argument based upon a thought experiment and\nsemi-formal considerations leading to an inherent ambiguity barrier which\nprevents LLMs from having any understanding of what their amazingly fluent\ndialogues mean.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T16:55:44Z"}
{"aid":"http://arxiv.org/abs/2505.00661v1","title":"On the generalization of language models from in-context learning and\n  finetuning: a controlled study","summary":"Large language models exhibit exciting capabilities, yet can show\nsurprisingly narrow generalization from finetuning -- from failing to\ngeneralize to simple reversals of relations they are trained on, to missing\nlogical deductions that can be made from trained information. These failures to\ngeneralize from fine-tuning can hinder practical application of these models.\nHowever, language models' in-context learning shows different inductive biases,\nand can generalize better in some of these cases. Here, we explore these\ndifferences in generalization between in-context- and fine-tuning-based\nlearning. To do so, we constructed several novel datasets to evaluate and\nimprove models' ability to generalize from finetuning data. The datasets are\nconstructed to isolate the knowledge in the dataset from that in pretraining,\nto create clean tests of generalization. We expose pretrained large models to\ncontrolled subsets of the information in these datasets -- either in context,\nor through fine-tuning -- and evaluate their performance on test sets that\nrequire various types of generalization. We find overall that in data-matched\nsettings, in-context learning can generalize more flexibly than fine-tuning\n(though we also find some qualifications of prior findings, such as cases when\nfine-tuning can generalize to reversals embedded in a larger structure of\nknowledge). We build on these findings to propose a method to enable improved\ngeneralization from fine-tuning: adding in-context inferences to finetuning\ndata. We show that this method improves generalization across various splits of\nour datasets and other benchmarks. Our results have implications for\nunderstanding the inductive biases of different modes of learning in language\nmodels, and practically improving their performance.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-05-01T17:02:27Z"}
{"aid":"http://arxiv.org/abs/2505.00675v1","title":"Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future\n  Directions","summary":"Memory is a fundamental component of AI systems, underpinning large language\nmodels (LLMs) based agents. While prior surveys have focused on memory\napplications with LLMs, they often overlook the atomic operations that underlie\nmemory dynamics. In this survey, we first categorize memory representations\ninto parametric, contextual structured, and contextual unstructured and then\nintroduce six fundamental memory operations: Consolidation, Updating, Indexing,\nForgetting, Retrieval, and Compression. We systematically map these operations\nto the most relevant research topics across long-term, long-context, parametric\nmodification, and multi-source memory. By reframing memory systems through the\nlens of atomic operations and representation types, this survey provides a\nstructured and dynamic perspective on research, benchmark datasets, and tools\nrelated to memory in AI, clarifying the functional interplay in LLMs based\nagents while outlining promising directions for future research\\footnote{The\npaper list, datasets, methods and tools are available at\n\\href{https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI}{https://github.com/Elvin-Yiming-Du/Survey\\_Memory\\_in\\_AI}.}.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-01T17:31:33Z"}
