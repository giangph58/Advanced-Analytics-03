{"aid":"http://arxiv.org/abs/2503.21661v1","title":"From conceptualization to operationalized meaning via ontological\n  components","summary":"Ontologies enable knowledge sharing and interdisciplinary collaboration by\nproviding standardized, structured vocabularies for diverse communities. While\nlogical axioms are a cornerstone of ontology design, natural language elements\nsuch as annotations are equally critical for conveying intended meaning and\nensuring consistent term usage. This paper explores how meaning is represented\nin ontologies and how it can be effectively represented and communicated,\naddressing challenges such as indeterminacy of reference and meaning holism. To\nthis end, it proposes an approach founded on the use of a new structure, named\n'ontological component' and defined by: a term-centered design; enhanced\ncharacterization of both formal and natural language statements; an\noperationalizable definition of communicated meaning based on general\nassertions; and the integration of natural language elements into the logical\ntheory. By formalizing the meaning of ontological components, this work seeks\nto enhance the semantic robustness of terms, improving their clarity and\naccessibility across domains. Furthermore, it aims to address practical\nchallenges in applied ontologies, such as facilitating reuse and managing\nversioning, thereby strengthening their role in diverse applications.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-03-27T16:24:12Z"}
{"aid":"http://arxiv.org/abs/2503.21666v1","title":"Economy and sustainability analysis with a novel modular configurable\n  multi-modal white-box building model","summary":"This paper presents a novel modeling approach for building performance\nsimulation, characterized as a white-box model with a high degree of modularity\nand flexibility, enabling direct integration into complex large-scale energy\nsystem co-simulations. The introduced model is described in detail, with a\nfocus on its modular structure, and proposes various configurations that\ninclude various building insulation, heating methods, occupancy patterns, and\nweather data to analyze different scenarios, and the energy consumption, CO2\nemissions, and heating costs are compared and analyzed across 36 introduced\nscenarios. The thermodynamic behavior of the model is shown to be consistent\nwith real-world conditions, and the comparison of the scenarios concludes that\nthe use of heat pumps for indoor heating in well-insulated buildings has\nsignificant economic and sustainability benefits, whereas the use of natural\ngas-fueled boilers is more cost-effective for buildings with low energy\nratings.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-27T16:33:31Z"}
{"aid":"http://arxiv.org/abs/2503.21687v1","title":"Exploiting synergies between JWST and cosmic 21-cm observations to\n  uncover star formation in the early Universe","summary":"In the current era of JWST, we continue to uncover a wealth of information\nabout the Universe deep into the Epoch of Reionization. In this work, we run a\nsuite of simulations using the code 21cmSPACE, to explore the astrophysical\nproperties of galaxies in the early Universe, and their impact on high-redshift\nobservables. We use multi-wavelength observational data including the global\n21-cm signal and power spectrum limits from SARAS~3 and HERA respectively,\npresent-day diffuse X-ray and radio backgrounds, and UV luminosity functions\n(UVLFs) from HST and JWST in the range $z=6-14.5$ to derive our constraints. We\nconstrain a flexible model of halo-mass and redshift dependent star-formation\nefficiency (SFE), defined as the gas fraction converted into stars, and find\nthat it is best described by little to no redshift evolution at $z\\approx6-10$\nand rapid evolution at $z\\approx10-15$. We derive Bayesian functional posterior\ndistributions for the SFE across this redshift range, inferring that a halo of\nmass $M_h=10^{10}\\text{M}_\\odot$ has an efficiency of $2-3\\%$ at $z\\lesssim10$,\n$12\\%$ at $z=12$ and $26\\%$ at $z=15$. We also find, through synergy between\nSARAS~3 and UVLFs, that the minimum circular velocity for star-formation in\nhalos is $V_c = 16.9^{+25.7}_{-9.5}\\text{km s}^{-1}$ or equivalently\n$\\log_{10}(M_\\text{crit}/\\text{M}_\\odot) = 8.29^{+1.21}_{-1.08}$ at $z=6$.\nAlongside these star-formation constraints, we find the X-ray and radio\nefficiencies of early galaxies to be $f_X = 0.5^{+6.3}_{-0.3}$ and $f_r\n\\lesssim 11.7$ respectively, improving upon existing works that do not use UVLF\ndata. Our results demonstrate the critical role of UVLFs in constraining the\nearly Universe, and its synergies with 21-cm observations, alongside other\nmulti-wavelength observational datasets.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-03-27T16:54:22Z"}
{"aid":"http://arxiv.org/abs/2503.21700v1","title":"Normalized solutions of one-dimensional defocusing NLS equations with\n  nonlinear point interactions","summary":"We investigate normalized solutions for doubly nonlinear Schr\\\"odinger\nequations on the real line with a defocusing standard nonlinearity and a\nfocusing nonlinear point interaction of $\\delta$--type at the origin. We\nprovide a complete characterization of existence and uniqueness for normalized\nsolutions and for energy ground states for every value of the nonlinearity\npowers. We show that the interplay between a defocusing standard and a focusing\npoint nonlinearity gives rise to new phenomena with respect to those observed\nwith single nonlinearities, standard combined nonlinearities, and combined\nfocusing standard and pointwise nonlinearities.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-03-27T17:04:43Z"}
{"aid":"http://arxiv.org/abs/2503.21704v1","title":"Learning to Represent Individual Differences for Choice Decision Making","summary":"Human decision making can be challenging to predict because decisions are\naffected by a number of complex factors. Adding to this complexity,\ndecision-making processes can differ considerably between individuals, and\nmethods aimed at predicting human decisions need to take individual differences\ninto account. Behavioral science offers methods by which to measure individual\ndifferences (e.g., questionnaires, behavioral models), but these are often\nnarrowed down to low dimensions and not tailored to specific prediction tasks.\nThis paper investigates the use of representation learning to measure\nindividual differences from behavioral experiment data. Representation learning\noffers a flexible approach to create individual embeddings from data that are\nboth structured (e.g., demographic information) and unstructured (e.g., free\ntext), where the flexibility provides more options for individual difference\nmeasures for personalization, e.g., free text responses may allow for\nopen-ended questions that are less privacy-sensitive. In the current paper we\nuse representation learning to characterize individual differences in human\nperformance on an economic decision-making task. We demonstrate that models\nusing representation learning to capture individual differences consistently\nimprove decision predictions over models without representation learning, and\neven outperform well-known theory-based behavioral models used in these\nenvironments. Our results propose that representation learning offers a useful\nand flexible tool to capture individual differences.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-03-27T17:10:05Z"}
{"aid":"http://arxiv.org/abs/2503.21707v1","title":"Heterostructure Effects on the Magnetocrystalline Anisotropy Energy of\n  MnN","summary":"Thin film effects on the Magnetocrystalline Anisotropy Energy (MAE) of MnN\nwere studied using density functional theory (DFT). Initially, strain effects\non bulk MnN were considered as a proxy for lattice-matching induced strain and\na linear relationship between the c/a ratio and the MAE was found. This\nrelationship was explained in terms of underlying point group symmetry. Strain\nand charge-transfer effects were then considered for an ultra-thin film. It was\nfound that a Ta seed-layer suppresses the net spin moment on the Mn ions,\nleading to a reduction of the MAE.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-27T17:20:42Z"}
{"aid":"http://arxiv.org/abs/2503.21709v1","title":"Redefining Network Topology in Complex Systems: Merging Centrality\n  Metrics, Spectral Theory, and Diffusion Dynamics","summary":"This paper introduces a novel framework that combines traditional centrality\nmeasures with eigenvalue spectra and diffusion processes for a more\ncomprehensive analysis of complex networks. While centrality measures such as\ndegree, closeness, and betweenness have been commonly used to assess nodal\nimportance, they provide limited insight into dynamic network behaviors. By\nincorporating eigenvalue analysis, which evaluates network robustness and\nconnectivity through spectral properties, and diffusion processes that model\ninformation flow, this framework offers a deeper understanding of how networks\nfunction under dynamic conditions. Applied to synthetic networks, the approach\nidentifies key nodes not only by centrality but also by their role in diffusion\ndynamics and vulnerability points, offering a multi-dimensional view that\ntraditional methods alone cannot. This integrated analysis enables a more\nprecise identification of critical nodes and potential weaknesses, with\nimplications for improving network resilience in fields ranging from\nepidemiology to cybersecurity. Keywords: Centrality measures, eigenvalue\nspectra, diffusion processes, network analysis, network robustness, information\nflow, synthetic networks.","main_category":"cs.OH","categories":"cs.OH","published":"2025-03-27T17:21:46Z"}
{"aid":"http://arxiv.org/abs/2503.21721v1","title":"Evaluating Text-to-Image Synthesis with a Conditional FrÃ©chet\n  Distance","summary":"Evaluating text-to-image synthesis is challenging due to misalignment between\nestablished metrics and human preferences. We propose cFreD, a metric based on\nthe notion of Conditional Fr\\'echet Distance that explicitly accounts for both\nvisual fidelity and text-prompt alignment. Existing metrics such as Inception\nScore (IS), Fr\\'echet Inception Distance (FID) and CLIPScore assess either\nimage quality or image-text alignment but not both which limits their\ncorrelation with human preferences. Scoring models explicitly trained to\nreplicate human preferences require constant updates and may not generalize to\nnovel generation techniques or out-of-domain inputs. Through extensive\nexperiments across multiple recently proposed text-to-image models and diverse\nprompt datasets, we demonstrate that cFreD exhibits a higher correlation with\nhuman judgments compared to statistical metrics, including metrics trained with\nhuman preferences. Our findings validate cFreD as a robust, future-proof metric\nfor the systematic evaluation of text-to-image models, standardizing\nbenchmarking in this rapidly evolving field. We release our evaluation toolkit\nand benchmark in the appendix.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:35:14Z"}
{"aid":"http://arxiv.org/abs/2503.21722v1","title":"Energy Minimization for Participatory Federated Learning in IoT Analyzed\n  via Game Theory","summary":"The Internet of Things requires intelligent decision making in many\nscenarios. To this end, resources available at the individual nodes for sensing\nor computing, or both, can be leveraged. This results in approaches known as\nparticipatory sensing and federated learning, respectively. We investigate the\nsimultaneous implementation of both, through a distributed approach based on\nempowering local nodes with game theoretic decision making. A global objective\nof energy minimization is combined with the individual node's optimization of\nlocal expenditure for sensing and transmitting data over multiple learning\nrounds. We present extensive evaluations of this technique, based on both a\ntheoretical framework and experiments in a simulated network scenario with real\ndata. Such a distributed approach can reach a desired level of accuracy for\nfederated learning without a centralized supervision of the data collector.\nHowever, depending on the weight attributed to the local costs of the single\nnode, it may also result in a significantly high Price of Anarchy (from 1.28\nonwards). Thus, we argue for the need of incentive mechanisms, possibly based\non Age of Information of the single nodes.","main_category":"cs.LG","categories":"cs.LG,cs.MA","published":"2025-03-27T17:35:38Z"}
{"aid":"http://arxiv.org/abs/2503.21730v1","title":"Effective Skill Unlearning through Intervention and Abstention","summary":"Large language Models (LLMs) have demonstrated remarkable skills across\nvarious domains. Understanding the mechanisms behind their abilities and\nimplementing controls over them is becoming increasingly important for\ndeveloping better models. In this paper, we focus on skill unlearning in LLMs,\nspecifically unlearning a particular skill while retaining their overall\ncapabilities. We introduce two lightweight, training-free machine skill\nunlearning techniques for LLMs. First, we observe that the pre-activation\ndistribution of neurons in each Feed-Forward Layer (FFL) differs when the model\ndemonstrates different skills. Additionally, we find that queries triggering\nthe same skill cluster within the FFL key space and can be separated from other\nqueries using a hypercube. Based on these observations, we propose two\nlightweight, training-free skill unlearning methods via \\textit{intervention}\nand \\textit{abstention} respectively: \\texttt{Neuron Adjust} and \\texttt{Key\nSpace Detection}. We evaluate our methods on unlearning math-solving,\nPython-coding, and comprehension skills across seven different languages. The\nresults demonstrate their strong unlearning capabilities for the designated\nskills. Specifically, \\texttt{Key Space Detection} achieves over 80\\% relative\nperformance drop on the forgetting skill and less than 10\\% relative\nperformance drop on other skills and the model's general knowledge (MMLU) for\nmost unlearning tasks. Our code is available at\nhttps://github.com/Trustworthy-ML-Lab/effective_skill_unlearning","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-03-27T17:45:06Z"}
{"aid":"http://arxiv.org/abs/2503.21753v1","title":"Quantum enhanced parameter estimation with monitored quantum\n  nonequilibrium systems using inefficient photo detection","summary":"Many-body quantum systems hosting emergent collective behavior bear the\npromise to enable quantum enhanced parameter estimation. Formally this means\nthat the variance of the parameter to be estimated decreases faster than\n$N^{-1}$, where $N$ is the number of particles forming the quantum system. In\npractice such scaling is challenging to achieve as the underlying many-body\ncorrelations are fragile. Moreover, devising the optimal measurements that\nindeed tap the quantum enhancement is often rather involved. Here we show that\nthe inefficient detection of the photo emission from a dissipative quantum\nmany-body system is sufficient to reach quantum enhanced parameter estimation\neven when some loss channels remain completely unmonitored. We illustrate our\napproach by considering the so-called boundary time-crystal, which is a\nnonequilibrium many-body system that has been realized recently experimentally\nin cold atomic gases. By analyzing the structure of the temporal correlations\nof its emission field, we are able to construct a family of near optimal\nparameter estimation measurements with a simple interferometric setup.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-27T17:56:57Z"}
{"aid":"http://arxiv.org/abs/2503.21755v1","title":"VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic\n  Faithfulness","summary":"Video generation has advanced significantly, evolving from producing\nunrealistic outputs to generating videos that appear visually convincing and\ntemporally coherent. To evaluate these video generative models, benchmarks such\nas VBench have been developed to assess their faithfulness, measuring factors\nlike per-frame aesthetics, temporal consistency, and basic prompt adherence.\nHowever, these aspects mainly represent superficial faithfulness, which focus\non whether the video appears visually convincing rather than whether it adheres\nto real-world principles. While recent models perform increasingly well on\nthese metrics, they still struggle to generate videos that are not just\nvisually plausible but fundamentally realistic. To achieve real \"world models\"\nthrough video generation, the next frontier lies in intrinsic faithfulness to\nensure that generated videos adhere to physical laws, commonsense reasoning,\nanatomical correctness, and compositional integrity. Achieving this level of\nrealism is essential for applications such as AI-assisted filmmaking and\nsimulated world modeling. To bridge this gap, we introduce VBench-2.0, a\nnext-generation benchmark designed to automatically evaluate video generative\nmodels for their intrinsic faithfulness. VBench-2.0 assesses five key\ndimensions: Human Fidelity, Controllability, Creativity, Physics, and\nCommonsense, each further broken down into fine-grained capabilities. Tailored\nfor individual dimensions, our evaluation framework integrates generalists such\nas state-of-the-art VLMs and LLMs, and specialists, including anomaly detection\nmethods proposed for video generation. We conduct extensive annotations to\nensure alignment with human judgment. By pushing beyond superficial\nfaithfulness toward intrinsic faithfulness, VBench-2.0 aims to set a new\nstandard for the next generation of video generative models in pursuit of\nintrinsic faithfulness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:57:01Z"}
{"aid":"http://arxiv.org/abs/2503.21763v1","title":"Identification and estimation of treatment effects in a linear factor\n  model with fixed number of time periods","summary":"This paper provides a new approach for identifying and estimating the Average\nTreatment Effect on the Treated under a linear factor model that allows for\nmultiple time-varying unobservables. Unlike the majority of the literature on\ntreatment effects in linear factor models, our approach does not require the\nnumber of pre-treatment periods to go to infinity to obtain a valid estimator.\nOur identification approach employs a certain nonlinear transformations of the\ntime invariant observed covariates that are sufficiently correlated with the\nunobserved variables. This relevance condition can be checked with the\navailable data on pre-treatment periods by validating the correlation of the\ntransformed covariates and the pre-treatment outcomes. Based on our\nidentification approach, we provide an asymptotically unbiased estimator of the\neffect of participating in the treatment when there is only one treated unit\nand the number of control units is large.","main_category":"econ.EM","categories":"econ.EM","published":"2025-03-27T17:58:17Z"}
{"aid":"http://arxiv.org/abs/2503.21771v1","title":"A Unified Image-Dense Annotation Generation Model for Underwater Scenes","summary":"Underwater dense prediction, especially depth estimation and semantic\nsegmentation, is crucial for gaining a comprehensive understanding of\nunderwater scenes. Nevertheless, high-quality and large-scale underwater\ndatasets with dense annotations remain scarce because of the complex\nenvironment and the exorbitant data collection costs. This paper proposes a\nunified Text-to-Image and DEnse annotation generation method (TIDE) for\nunderwater scenes. It relies solely on text as input to simultaneously generate\nrealistic underwater images and multiple highly consistent dense annotations.\nSpecifically, we unify the generation of text-to-image and text-to-dense\nannotations within a single model. The Implicit Layout Sharing mechanism (ILS)\nand cross-modal interaction method called Time Adaptive Normalization (TAN) are\nintroduced to jointly optimize the consistency between image and dense\nannotations. We synthesize a large-scale underwater dataset using TIDE to\nvalidate the effectiveness of our method in underwater dense prediction tasks.\nThe results demonstrate that our method effectively improves the performance of\nexisting underwater dense prediction models and mitigates the scarcity of\nunderwater data with dense annotations. We hope our method can offer new\nperspectives on alleviating data scarcity issues in other fields. The code is\navailable at https: //github.com/HongkLin/TIDE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:43Z"}
{"aid":"http://arxiv.org/abs/2503.21773v1","title":"Simulating quantum circuits with restricted quantum computers","summary":"It is one of the most fundamental objectives in quantum information science\nto understand the boundary between the computational power of classical and\nquantum computers. One possible avenue to explore this boundary is to identify\nclasses of quantum circuits that can be efficiently simulated on a classical\ncomputer. Instead of simulating a general quantum circuit with a classical\ndevice, new schemes have recently emerged to simulate them on a quantum device\nthat is restricted in some manner. As such, these techniques allow us to study\nhow the restrictions impact the computational power of the device. One such\ntechnique is called quasiprobability simulation (QPS) and it estimates the\nresult of a quantum circuit with a Monte Carlo procedure that randomly replaces\ncircuit elements with ones that can be executed on the restricted quantum\ndevice.\n  The main focus of this thesis is dedicated to the QPS-based simulation of\nnonlocal quantum computation using local quantum operations. On the practical\nside, this enables the simulation of large quantum circuits using multiple\nsmaller quantum devices - a procedure that is sometimes called circuit\nknitting. We uncover a rich mathematical formalism with many connections to the\nresource theory of entanglement. We characterize the optimal simulation\noverhead for a broad range of practically relevant nonlocal states and channels\nand we explicitly provide achieving protocols. Moreover, we also investigate\nthe utility of classical communication between the local parties. Our results\naddress both the single-shot and asymptotic regime.\n  We frame QPS in a quantum resource theoretic framework, which highlights\nsimilarities that arise in the different instantiations of the technique.\nFurthermore, we study the importance of classical side information in the QPS\nprocedure and how it impacts the overhead and expressibility of QPS.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-27T17:59:45Z"}
{"aid":"http://arxiv.org/abs/2503.21775v1","title":"StyleMotif: Multi-Modal Motion Stylization using Style-Content Cross\n  Fusion","summary":"We present StyleMotif, a novel Stylized Motion Latent Diffusion model,\ngenerating motion conditioned on both content and style from multiple\nmodalities. Unlike existing approaches that either focus on generating diverse\nmotion content or transferring style from sequences, StyleMotif seamlessly\nsynthesizes motion across a wide range of content while incorporating stylistic\ncues from multi-modal inputs, including motion, text, image, video, and audio.\nTo achieve this, we introduce a style-content cross fusion mechanism and align\na style encoder with a pre-trained multi-modal model, ensuring that the\ngenerated motion accurately captures the reference style while preserving\nrealism. Extensive experiments demonstrate that our framework surpasses\nexisting methods in stylized motion generation and exhibits emergent\ncapabilities for multi-modal motion stylization, enabling more nuanced motion\nsynthesis. Source code and pre-trained models will be released upon acceptance.\nProject Page: https://stylemotif.github.io","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-03-27T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2503.21776v1","title":"Video-R1: Reinforcing Video Reasoning in MLLMs","summary":"Inspired by DeepSeek-R1's success in eliciting reasoning abilities through\nrule-based reinforcement learning (RL), we introduce Video-R1 as the first\nattempt to systematically explore the R1 paradigm for eliciting video reasoning\nwithin multimodal large language models (MLLMs). However, directly applying RL\ntraining with the GRPO algorithm to video reasoning presents two primary\nchallenges: (i) a lack of temporal modeling for video reasoning, and (ii) the\nscarcity of high-quality video-reasoning data. To address these issues, we\nfirst propose the T-GRPO algorithm, which encourages models to utilize temporal\ninformation in videos for reasoning. Additionally, instead of relying solely on\nvideo data, we incorporate high-quality image-reasoning data into the training\nprocess. We have constructed two datasets: Video-R1-COT-165k for SFT cold start\nand Video-R1-260k for RL training, both comprising image and video data.\nExperimental results demonstrate that Video-R1 achieves significant\nimprovements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as\nwell as on general video benchmarks including MVBench and TempCompass, etc.\nNotably, Video-R1-7B attains a 35.8% accuracy on video spatial reasoning\nbenchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All\ncodes, models, data are released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.21780v1","title":"Semantic Library Adaptation: LoRA Retrieval and Fusion for\n  Open-Vocabulary Semantic Segmentation","summary":"Open-vocabulary semantic segmentation models associate vision and text to\nlabel pixels from an undefined set of classes using textual queries, providing\nversatile performance on novel datasets. However, large shifts between training\nand test domains degrade their performance, requiring fine-tuning for effective\nreal-world applications. We introduce Semantic Library Adaptation (SemLA), a\nnovel framework for training-free, test-time domain adaptation. SemLA leverages\na library of LoRA-based adapters indexed with CLIP embeddings, dynamically\nmerging the most relevant adapters based on proximity to the target domain in\nthe embedding space. This approach constructs an ad-hoc model tailored to each\nspecific input without additional training. Our method scales efficiently,\nenhances explainability by tracking adapter contributions, and inherently\nprotects data privacy, making it ideal for sensitive applications.\nComprehensive experiments on a 20-domain benchmark built over 10 standard\ndatasets demonstrate SemLA's superior adaptability and performance across\ndiverse settings, establishing a new standard in domain adaptation for\nopen-vocabulary semantic segmentation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2503.23683v1","title":"Twisted Nodal Superconductors","summary":"Recent proposals for the realization of time-reversal symmetry breaking and\ntopological superconductivity in twisted nodal superconductors have led to a\nsurge of theoretical and experimental studies of these systems, marking one of\nthe newest entries in the rapidly growing field of moir\\'e materials. The\ninterplay between order parameters of the separate layers makes twisted\nsuperconductors unique, leading to additional emergent phenomena in regimes\nusually not of importance in moir\\'e physics, such as bulk interfaces and large\ntwist angles. We review the physics of twisted nodal superconductors,\nhighlighting both similarities and qualitative differences with other moir\\'e\nplatforms. While inspired by the rise of moir\\'e materials, the field is\nanchored in studies of unconventional superconductivity preceding the moir\\'e\nera, which we discuss in detail. In addition to summarizing the developments at\nthe present stage, we present a detailed outlook on the major open questions in\nthe field and some of the most exciting future directions.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.str-el","published":"2025-03-31T03:15:27Z"}
{"aid":"http://arxiv.org/abs/2503.23709v1","title":"Expanding-and-Shrinking Binary Neural Networks","summary":"While binary neural networks (BNNs) offer significant benefits in terms of\nspeed, memory and energy, they encounter substantial accuracy degradation in\nchallenging tasks compared to their real-valued counterparts. Due to the\nbinarization of weights and activations, the possible values of each entry in\nthe feature maps generated by BNNs are strongly constrained. To tackle this\nlimitation, we propose the expanding-and-shrinking operation, which enhances\nbinary feature maps with negligible increase of computation complexity, thereby\nstrengthening the representation capacity. Extensive experiments conducted on\nmultiple benchmarks reveal that our approach generalizes well across diverse\napplications ranging from image classification, object detection to generative\ndiffusion model, while also achieving remarkable improvement over various\nleading binarization algorithms based on different architectures including both\nCNNs and Transformers.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:13:33Z"}
{"aid":"http://arxiv.org/abs/2503.23710v1","title":"Formation of the Little Red Dots from the Core-collapse of\n  Self-interacting Dark Matter Halos","summary":"We present a statistical study on the formation and growth of black holes\n(BHs) seeded by gravothermal core-collapse of self-interacting dark matter\n(SIDM) halos at high redshifts, using a semi-analytical framework based on\nMonte-Carlo merger trees. We demonstrate that BH formation via gravothermal\ncollapse naturally occurs in high-concentration halos at a characteristic mass\nscale determined by the SIDM cross section, and only during the early Universe.\nThis mechanism is particularly promising for explaining the abundance of little\nred dots (LRDs) -- a population of early, apparently galaxy-less active\ngalactic nuclei hosting supermassive BHs. By incorporating this seeding process\nwith simplified models of BH growth and mergers, we successfully reproduce the\nobserved LRD mass function for moderately large cross sections of $\\sigma_{0m}\n\\sim 30 \\mathrm{cm^2\\,g^{-1}}$ and $\\omega \\sim 80\\,\\mathrm{km\\,s^{-1}}$,\nintriguingly consistent with independent local constraints derived from galaxy\nrotation curves. Our results highlight the potential of high-redshift BH\nstatistics as a complementary probe for constraining SIDM models.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-03-31T04:15:20Z"}
{"aid":"http://arxiv.org/abs/2503.23716v1","title":"On blowup solution in NLS equation under dispersion or nonlinearity\n  management","summary":"In this paper, we study the dispersion-managed nonlinear Schr\\\"odinger\n(DM-NLS) equation $$ i\\partial_t u(t,x)+\\gamma(t)\\Delta\nu(t,x)=|u(t,x)|^{\\frac4d}u(t,x),\\quad x\\in\\R^d, $$ and the nonlinearity-managed\nNLS (NM-NLS) equation: $$ i\\partial_t u(t,x)+\\Delta\nu(t,x)=\\gamma(t)|u(t,x)|^{\\frac4d}u(t,x), \\quad x\\in\\R^d, $$ where $\\gamma(t)$\nis a periodic function which is equal to $-1$ when $t\\in (0,1]$ and is equal to\n$1$ when $t\\in (1,2]$. The two models share the feature that the focusing and\ndefocusing effects convert periodically. For the classical focusing NLS, it is\nknown that the initial data $$ u_0(x)=T^{-\\frac{d}{2}}\\fe^{i\\frac{|x|^2}{4T}\n-i\\frac{\\omega^2}{T}}Q_\\omega\\left(\\frac{x}{T}\\right) $$ leads to a blowup\nsolution $$(T-t)^{-\\frac{d}{2}}\\fe^{i\\frac{|x|^2}{4(T-t)}\n-i\\frac{\\omega^2}{T-t}}Q_\\omega\\left(\\frac{x}{T-t}\\right), $$ so when $T\\leq1$,\nthis is also a blowup solution for DM-NLS and NM-NLS which blows up in the\nfirst focusing layer.\n  For DM-NLS, we prove that when $T>1$, the initial data $u_0$ above does not\nlead to a finite-time blowup and the corresponding solution is globally\nwell-posed. For NM-NLS, we prove the global well-posedness for $T\\in(1,2)$ and\nwe construct solution that can blow up at any focusing layer. The theoretical\nstudies are complemented by extensive numerical explorations towards\nunderstanding the stabilization effects in the two models and addressing their\ndifference.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA","published":"2025-03-31T04:36:58Z"}
{"aid":"http://arxiv.org/abs/2503.23728v1","title":"Performing Path Integral Molecular Dynamics Using Artificial\n  Intelligence Enhanced Molecular Simulation Framework","summary":"This study employed an artificial intelligence-enhanced molecular simulation\nframework to enable efficient Path Integral Molecular Dynamics (PIMD)\nsimulations. Owing to its modular architecture and high-throughput\ncapabilities, the framework effectively mitigates the computational complexity\nand resource-intensive limitations associated with conventional PIMD\napproaches. By integrating machine learning force fields (MLFFs) into the\nframework, we rigorously tested its performance through two representative\ncases: a small-molecule reaction system (double proton transfer in formic acid\ndimer) and a bulk-phase transition system (water-ice phase transformation).\nComputational results demonstrate that the proposed framework achieves\naccelerated PIMD simulations while preserving quantum mechanical accuracy.\nThese findings show that nuclear quantum effects can be captured for complex\nmolecular systems, using relatively low computational cost.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.comp-ph","published":"2025-03-31T05:01:56Z"}
{"aid":"http://arxiv.org/abs/2503.23741v1","title":"Classification of Modular Symmetries in Non-Supersymmetric Heterotic\n  String theories","summary":"We study modular symmetries in non-supersymmetric heterotic string theories\non toroidal backgrounds with Wilson line modulus, constructed by stringy\nScherk-Schwartz compactification. In particular, we focus on a subgroup of the\nT-duality group $O(D+16,D,\\mathbb{Z})$ with $D=2$ given by an outer\nautomorphism of the Narain lattice, which can be mapped to the Siegel modular\ngroup $\\mathrm{Sp}(4,\\mathbb{Z})$. We classify the modular symmetries and a\n$CP$-like symmetry on $T^2$ and its orbifolds with symmetric and asymmetric\norbifold twists. It turns out that the non-supersymmetric heterotic string\ntheories only enjoy a part of modular symmetries in contrast to supersymmetric\nones. Furthermore, the gauge symmetry is maximally enhanced at fixed points of\nmodular symmetries on $T^2$ on which we analyze the vacuum structure of\neight-dimensional tachyon-free vacua.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T05:42:06Z"}
{"aid":"http://arxiv.org/abs/2503.23746v1","title":"Short-video Propagation Influence Rating: A New Real-world Dataset and A\n  New Large Graph Model","summary":"Short-video platforms have gained immense popularity, captivating the\ninterest of millions, if not billions, of users globally. Recently, researchers\nhave highlighted the significance of analyzing the propagation of short-videos,\nwhich typically involves discovering commercial values, public opinions, user\nbehaviors, etc. This paper proposes a new Short-video Propagation Influence\nRating (SPIR) task and aims to promote SPIR from both the dataset and method\nperspectives. First, we propose a new Cross-platform Short-Video (XS-Video)\ndataset, which aims to provide a large-scale and real-world short-video\npropagation network across various platforms to facilitate the research on\nshort-video propagation. Our XS-Video dataset includes 117,720 videos, 381,926\nsamples, and 535 topics across 5 biggest Chinese platforms, annotated with the\npropagation influence from level 0 to 9. To the best of our knowledge, this is\nthe first large-scale short-video dataset that contains cross-platform data or\nprovides all of the views, likes, shares, collects, fans, comments, and comment\ncontent. Second, we propose a Large Graph Model (LGM) named NetGPT, based on a\nnovel three-stage training mechanism, to bridge heterogeneous graph-structured\ndata with the powerful reasoning ability and knowledge of Large Language Models\n(LLMs). Our NetGPT can comprehend and analyze the short-video propagation\ngraph, enabling it to predict the long-term propagation influence of\nshort-videos. Comprehensive experimental results evaluated by both\nclassification and regression metrics on our XS-Video dataset indicate the\nsuperiority of our method for SPIR.","main_category":"cs.CV","categories":"cs.CV,cs.CL,cs.LG,cs.MM,cs.SI","published":"2025-03-31T05:53:15Z"}
{"aid":"http://arxiv.org/abs/2503.23751v1","title":"Decoupled Distillation to Erase: A General Unlearning Method for Any\n  Class-centric Tasks","summary":"In this work, we present DEcoupLEd Distillation To Erase (DELETE), a general\nand strong unlearning method for any class-centric tasks. To derive this, we\nfirst propose a theoretical framework to analyze the general form of unlearning\nloss and decompose it into forgetting and retention terms. Through the\ntheoretical framework, we point out that a class of previous methods could be\nmainly formulated as a loss that implicitly optimizes the forgetting term while\nlacking supervision for the retention term, disturbing the distribution of\npre-trained model and struggling to adequately preserve knowledge of the\nremaining classes. To address it, we refine the retention term using \"dark\nknowledge\" and propose a mask distillation unlearning method. By applying a\nmask to separate forgetting logits from retention logits, our approach\noptimizes both the forgetting and refined retention components simultaneously,\nretaining knowledge of the remaining classes while ensuring thorough forgetting\nof the target class. Without access to the remaining data or intervention\n(i.e., used in some works), we achieve state-of-the-art performance across\nvarious benchmarks. What's more, DELETE is a general solution that can be\napplied to various downstream tasks, including face recognition, backdoor\ndefense, and semantic segmentation with great performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T06:02:27Z"}
{"aid":"http://arxiv.org/abs/2503.23753v1","title":"Reputation in public goods cooperation under double Q-learning protocol","summary":"Understanding and resolving cooperation dilemmas are key challenges in\nevolutionary game theory, which have revealed several mechanisms to address\nthem. This paper investigates the comprehensive influence of multiple\nreputation-related components on public cooperation. In particular, cooperative\ninvestments in public goods game are not fixed but simultaneously depend on the\nreputation of group organizers and the population's cooperation willingness,\nhence indirectly impacting on the players' income. Additionally, individual\npayoff can also be directly affected by their reputation via a weighted\napproach which effectively evaluates the actual income of players. Unlike\nconventional models, the reputation change of players is non-monotonic, but may\ntransform abruptly due to specific actions. Importantly, a theoretically\nsupported double Q-learning algorithm is introduced to avoid overestimation\nbias inherent from the classical Q-learning algorithm. Our simulations reveal a\nsignificantly improved cooperation level, that is explained by a detailed\nQ-value analysis. We also observe the lack of massive cooperative clusters in\nthe absence of network reciprocity. At the same time, as an intriguing\nphenomenon, some actors maintain moderate reputation and are continuously\nflipping between cooperation and defection. The robustness of our results are\nvalidated by mean-field approximation.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-03-31T06:03:26Z"}
{"aid":"http://arxiv.org/abs/2503.23767v1","title":"Biologically Inspired Spiking Diffusion Model with Adaptive Lateral\n  Selection Mechanism","summary":"Lateral connection is a fundamental feature of biological neural circuits,\nfacilitating local information processing and adaptive learning. In this work,\nwe integrate lateral connections with a substructure selection network to\ndevelop a novel diffusion model based on spiking neural networks (SNNs). Unlike\nconventional artificial neural networks, SNNs employ an intrinsic spiking inner\nloop to process sequential binary spikes. We leverage this spiking inner loop\nalongside a lateral connection mechanism to iteratively refine the substructure\nselection network, enhancing model adaptability and expressivity. Specifically,\nwe design a lateral connection framework comprising a learnable lateral matrix\nand a lateral mapping function, both implemented using spiking neurons, to\ndynamically update lateral connections. Through mathematical modeling, we\nestablish that the proposed lateral update mechanism, under a well-defined\nlocal objective, aligns with biologically plausible synaptic plasticity\nprinciples. Extensive experiments validate the effectiveness of our approach,\nanalyzing the role of substructure selection and lateral connection during\ntraining. Furthermore, quantitative comparisons demonstrate that our model\nconsistently surpasses state-of-the-art SNN-based generative models across\nmultiple benchmark datasets.","main_category":"cs.NE","categories":"cs.NE","published":"2025-03-31T06:31:50Z"}
{"aid":"http://arxiv.org/abs/2503.23775v1","title":"Evaluation of (Un-)Supervised Machine Learning Methods for GNSS\n  Interference Classification with Real-World Data Discrepancies","summary":"The accuracy and reliability of vehicle localization on roads are crucial for\napplications such as self-driving cars, toll systems, and digital tachographs.\nTo achieve accurate positioning, vehicles typically use global navigation\nsatellite system (GNSS) receivers to validate their absolute positions.\nHowever, GNSS-based positioning can be compromised by interference signals,\nnecessitating the identification, classification, determination of purpose, and\nlocalization of such interference to mitigate or eliminate it. Recent\napproaches based on machine learning (ML) have shown superior performance in\nmonitoring interference. However, their feasibility in real-world applications\nand environments has yet to be assessed. Effective implementation of ML\ntechniques requires training datasets that incorporate realistic interference\nsignals, including real-world noise and potential multipath effects that may\noccur between transmitter, receiver, and satellite in the operational area.\nAdditionally, these datasets require reference labels. Creating such datasets\nis often challenging due to legal restrictions, as causing interference to GNSS\nsources is strictly prohibited. Consequently, the performance of ML-based\nmethods in practical applications remains unclear. To address this gap, we\ndescribe a series of large-scale measurement campaigns conducted in real-world\nsettings at two highway locations in Germany and the Seetal Alps in Austria,\nand in large-scale controlled indoor environments. We evaluate the latest\nsupervised ML-based methods to report on their performance in real-world\nsettings and present the applicability of pseudo-labeling for unsupervised\nlearning. We demonstrate the challenges of combining datasets due to data\ndiscrepancies and evaluate outlier detection, domain adaptation, and data\naugmentation techniques to present the models' capabilities to adapt to changes\nin the datasets.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T06:51:52Z"}
{"aid":"http://arxiv.org/abs/2503.23797v1","title":"Kiloparsec-Scale Alignment of a Radio Jet with Cool Gas and Dust in a\n  z~6 Quasar","summary":"We present high-angular resolution (0.068\", ~400pc) ALMA imaging of the [CII]\nline and dust continuum emission of PSO J352.4034-15.3373, a radio-loud quasar\nat z=5.83. The observations reveal a remarkably close match between the\norientation of the [CII] and thermal dust emission mapped by ALMA, and radio\nsynchrotron emission of a radio jet previously mapped by the VLBA. This narrow\nalignment extends over ~4kpc, reminiscent of the well-studied 'alignment\neffect' in lower-redshift radio galaxies. The [CII] kinematics show a linear\nincrease in velocity with galactocentric radii up to ~200 km/s at r=2kpc,\nconsistent with bulk motions within the galaxy potential, and not relativistic\njet motions. The kinematics and respective morphologies are consistent with a\npicture in which the relativistic jet injects energy into the interstellar\nmedium (potentially leading to subsequent star formation), giving rise to the\nobserved alignment and significant (> 100 km/s) [CII] velocity dispersion\nwithin the host galaxy on kiloparsec scales. Indeed, the astonishingly close\nalignment and narrow linearity of the radio jet with the [CII] and dust\nemission are hard to conceive without some fundamental relationship between the\ntwo.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T07:19:54Z"}
{"aid":"http://arxiv.org/abs/2503.23804v1","title":"Get the Agents Drunk: Memory Perturbations in Autonomous Agent-based\n  Recommender Systems","summary":"Large language model-based agents are increasingly used in recommender\nsystems (Agent4RSs) to achieve personalized behavior modeling. Specifically,\nAgent4RSs introduces memory mechanisms that enable the agents to autonomously\nlearn and self-evolve from real-world interactions. However, to the best of our\nknowledge, how robust Agent4RSs are remains unexplored. As such, in this paper,\nwe propose the first work to attack Agent4RSs by perturbing agents' memories,\nnot only to uncover their limitations but also to enhance their security and\nrobustness, ensuring the development of safer and more reliable AI agents.\n  Given the security and privacy concerns, it is more practical to launch\nattacks under a black-box setting, where the accurate knowledge of the victim\nmodels cannot be easily obtained. Moreover, the practical attacks are often\nstealthy to maximize the impact. To this end, we propose a novel practical\nattack framework named DrunkAgent. DrunkAgent consists of a generation module,\na strategy module, and a surrogate module. The generation module aims to\nproduce effective and coherent adversarial textual triggers, which can be used\nto achieve attack objectives such as promoting the target items. The strategy\nmodule is designed to `get the target agents drunk' so that their memories\ncannot be effectively updated during the interaction process. As such, the\ntriggers can play the best role. Both of the modules are optimized on the\nsurrogate module to improve the transferability and imperceptibility of the\nattacks. By identifying and analyzing the vulnerabilities, our work provides\ncritical insights that pave the way for building safer and more resilient\nAgent4RSs. Extensive experiments across various real-world datasets demonstrate\nthe effectiveness of DrunkAgent.","main_category":"cs.CR","categories":"cs.CR,cs.CL,cs.IR,cs.MA","published":"2025-03-31T07:35:40Z"}
{"aid":"http://arxiv.org/abs/2503.23818v1","title":"Free Parametrization of L2-bounded State Space Models","summary":"Structured state-space models (SSMs) have emerged as a powerful architecture\nin machine learning and control, featuring stacked layers where each consists\nof a linear time-invariant (LTI) discrete-time system followed by a\nnonlinearity. While SSMs offer computational efficiency and excel in\nlong-sequence predictions, their widespread adoption in applications like\nsystem identification and optimal control is hindered by the challenge of\nensuring their stability and robustness properties. We introduce L2RU, a novel\nparametrization of SSMs that guarantees input-output stability and robustness\nby enforcing a prescribed L-bound for all parameter values. This design\neliminates the need for complex constraints, allowing unconstrained\noptimization over L2RUs by using standard methods such as gradient descent.\nLeveraging tools from system theory and convex optimization, we derive a\nnon-conservative parametrization of square discrete-time LTI systems with a\nspecified L2-bound, forming the foundation of the L2RU architecture.\nAdditionally, we enhance its performance with a bespoke initialization strategy\noptimized for long input sequences. Through a system identification task, we\nvalidate L2RU's superior performance, showcasing its potential in learning and\ncontrol applications.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-03-31T07:56:17Z"}
{"aid":"http://arxiv.org/abs/2503.23838v1","title":"A MeerKAT survey of nearby dwarf novae: I. New detections","summary":"A program to search for radio emission from dwarf-novae-type cataclysmic\nvariables was conducted with the South African MeerKAT radio telescope. The\ndwarf novae RU Pegasi, V426 Ophiuchi and IP Pegasi were detected during\noutburst at L-band (1284 MHz central frequency). Previously, only one\ncataclysmic variable was radio-detected at a frequency this low. We now bring\nthe number to four. With these three newly found radio-emitters, the population\nof dwarf novae confirmed to be radio-emitting at any frequency reaches 10\nsystems. We found that the radio luminosity is correlated with the optical\nluminosity. For V426 Ophiuchi and RU Pegasi we found a radio decline\ncontemporary with the outburst's optical decline. The peak radio luminosity of\ndwarf novae in outburst is very similar to that of novalike Cataclysmic\nVariables and no correlation with orbital period is seen.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T08:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.23845v1","title":"On the depth of subgroups of simple groups","summary":"The depth of a subgroup $H$ of a finite group $G$ is a positive integer\ndefined with respect to the inclusion of the corresponding complex group\nalgebras $\\mathbb{C}H \\subseteq \\mathbb{C}G$. This notion was originally\nintroduced by Boltje, Danz and K\\\"{u}lshammer in 2011, and it has been the\nsubject of numerous papers in recent years. In this paper, we study the depth\nof core-free subgroups, which allows us to apply powerful computational and\nprobabilistic techniques that were originally designed for studying bases for\npermutation groups. We use these methods to prove a wide range of new results\non the depth of subgroups of almost simple groups, significantly extending the\nscope of earlier work in this direction. For example, we establish best\npossible bounds on the depth of irreducible subgroups of classical groups and\nprimitive subgroups of symmetric groups. And with the exception of a handful of\nopen cases involving the Baby Monster, we calculate the exact depth of every\nsubgroup of every almost simple sporadic group. We also present a number of\nopen problems and conjectures.","main_category":"math.GR","categories":"math.GR,math.RT","published":"2025-03-31T08:46:46Z"}
{"aid":"http://arxiv.org/abs/2503.23846v1","title":"Exchange cross-talk mitigation in dense quantum dot arrays","summary":"Coupled spins in semiconductor quantum dots are a versatile platform for\nquantum computing and simulations of complex many-body phenomena. However, on\nthe path of scale-up, cross-talk from densely packed electrodes poses a severe\nchallenge. While cross-talk onto the dot potentials is nowadays routinely\ncompensated for, cross-talk on the exchange interaction is much more difficult\nto tackle because it is not always directly measurable. Here we propose and\nimplement a way of characterizing and compensating cross-talk on adjacent\nexchange interactions by following the singlet-triplet avoided crossing in Ge.\nWe show that we can easily identify the barrier-to-barrier cross-talk element\nwithout knowledge of the particular exchange value in a 2x4 quantum dot array.\nWe uncover striking differences among these cross-talk elements which can be\nlinked to the geometry of the device and the barrier gate fan-out. We validate\nthe methodology by tuning up four-spin Heisenberg chains. The same methodology\nshould be applicable to longer chains of spins and to other semiconductor\nplatforms in which mixing of the singlet and the lowest-energy triplet is\npresent or can be engineered. Additionally, this procedure is well suited for\nautomated tuning routines as we obtain a stand-out feature that can be easily\ntracked and directly returns the magnitude of the cross-talk.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T08:50:43Z"}
{"aid":"http://arxiv.org/abs/2503.23852v1","title":"Multispacecraft Observations of the 2024 September 9 Backside Solar\n  Eruption that Resulted in a Sustained Gamma Ray Emission Event","summary":"We report on the 2024 September 9 sustained gamma ray emission (SGRE) event\nobserved by the Large Area Telescope onboard the Fermi satellite. The event was\nassociated with a backside solar eruption observed by multiple spacecraft such\nas the Solar and Heliospheric Observatory (SOHO), Solar Terrestrial Relations\nObservatory (STEREO), Parker Solar Probe (PSP), Solar Orbiter (SolO), Solar\nDynamics Observatory (SDO), Wind, and GOES, and by ground based radio\ntelescopes. SolO Spectrometer Telescope for Imaging X rays (STIX) imaged an\nintense flare, which occurred about 41 deg behind the east limb, from\nheliographic coordinates S13E131. Forward modeling of the CME flux rope\nrevealed that it impulsively accelerated (3.54 km s^{-2}) to attain a peak\nspeed of 2162 km s^{-1}. SolO energetic particle detectors (EPD) observed\nprotons up to about 1 GeV from the extended shock and electrons that produced a\ncomplex type II burst and possibly type III bursts. The durations of SGRE and\ntype II burst are consistent with the linear relation between these quantities\nobtained from longer duration (exceeding 3 hours) SGRE events. All these\nobservations are consistent with an extended shock surrounding the CME flux\nrope, which is the likely source of high energy protons required for the SGRE\nevent. We compare this event with six other BTL SGRE eruptions and find that\nthey are all consistent with energetic shock driving CMEs. We also find a\nsignificant east west asymmetry in the BTL source locations.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T08:56:13Z"}
{"aid":"http://arxiv.org/abs/2503.23855v1","title":"Physics case for low-$\\sqrt{s}$ QCD studies at FCC-ee","summary":"Measurements of hadronic final states in $e^{+}e^{-}$ collisions at\ncentre-of-mass (CM) energies below the Z peak can notably extend the FCC-ee\nphysics reach in terms of precision quantum chromodynamics (QCD) studies.\nHadronic final states can be studied over a range of hadronic energies\n$\\sqrt{s_\\mathrm{had}} \\approx 20\\mbox{--}80\\,\\mathrm{GeV}$ by exploiting\nevents with hard initial- and final-state QED radiation (ISR/FSR) during the\nhigh-luminosity Z-pole run, as well as in dedicated short (about one month\nlong) $e^{+}e^{-}$ runs at CM energies $\\sqrt{s} \\approx 40\\,\\mathrm{GeV}$ and\n$60\\,\\mathrm{GeV}$. Using realistic estimates and fast detector simulations, we\nshow that data samples of about $10^{9}$ hadronic events can be collected at\nthe FCC-ee at each of the low-CM-energy points. Such datasets can be exploited\nin a variety of precision QCD measurements, including studies of light-,\nheavy-quark and gluon jet properties, hadronic event shapes, fragmentation\nfunctions, and nonperturbative dynamics. This will offer valuable insights into\nstrong interaction physics, complementing data from nominal FCC-ee runs at\nhigher center-of-mass energies, $\\sqrt{s} \\approx 91, 160, 240,$ and\n$365\\,\\mathrm{GeV}$.","main_category":"hep-ex","categories":"hep-ex,hep-ph,hep-th","published":"2025-03-31T09:03:46Z"}
{"aid":"http://arxiv.org/abs/2503.23874v1","title":"He-Mg compounds and helium-driven nonmetal transition in metallic\n  magnesium","summary":"The polymorphism and mechanism of helium compounds is crucial for\nunderstanding the physical and chemical nature of He-bearing materials under\npressures. Here, we predict two new types of He-bearing compounds, MgHe and\nMgnHe (n = 6, 8, 10, 15, 18), being formed above 750 GPa by unbiased ab initio\nstructure search. An unexpected bandgap is opened up in MgHe at as low as\naround 200 GPa. This is the first case of noble gas driven metal-nonmetal\ntransition in all elements. The same mechanism is demonstrated also being\napplicable to other metallic elements, and making beryllium transform into a\nnon-metallic state, a triumph that is impossible otherwise. Furthermore, the\nstability of the simple cubic phase of Mg (Mg-sc) is greatly enhanced by mixing\nwith He, which lowers the critical pressure of pure Mg-sc from about 1.1 TPa\ndown to 750 GPa to form ordered substitutional alloying phase of MgnHe on a\nsimple cubic lattice of Mg. This is the first report on Mg-based noble gas\nsubstitutional alloy, in sharp contrast to the conventional wisdom that He\npreferring interstitial sites. The observed striking influences of He\ndemonstrate the rich physics and chemistry of He-bearing compounds under\nultra-high pressures.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,physics.chem-ph,physics.comp-ph","published":"2025-03-31T09:25:09Z"}
{"aid":"http://arxiv.org/abs/2503.23893v1","title":"DiffScale: Continuous Downscaling and Bias Correction of Subseasonal\n  Wind Speed Forecasts using Diffusion Models","summary":"Renewable resources are strongly dependent on local and large-scale weather\nsituations. Skillful subseasonal to seasonal (S2S) forecasts -- beyond two\nweeks and up to two months -- can offer significant socioeconomic advantages to\nthe energy sector. This study aims to enhance wind speed predictions using a\ndiffusion model with classifier-free guidance to downscale S2S forecasts of\nsurface wind speed. We propose DiffScale, a diffusion model that super-resolves\nspatial information for continuous downscaling factors and lead times.\nLeveraging weather priors as guidance for the generative process of diffusion\nmodels, we adopt the perspective of conditional probabilities on sampling\nsuper-resolved S2S forecasts. We aim to directly estimate the density\nassociated with the target S2S forecasts at different spatial resolutions and\nlead times without auto-regression or sequence prediction, resulting in an\nefficient and flexible model. Synthetic experiments were designed to\nsuper-resolve wind speed S2S forecasts from the European Center for\nMedium-Range Weather Forecast (ECMWF) from a coarse resolution to a finer\nresolution of ERA5 reanalysis data, which serves as a high-resolution target.\nThe innovative aspect of DiffScale lies in its flexibility to downscale\narbitrary scaling factors, enabling it to generalize across various grid\nresolutions and lead times -without retraining the model- while correcting\nmodel errors, making it a versatile tool for improving S2S wind speed\nforecasts. We achieve a significant improvement in prediction quality,\noutperforming baselines up to week 3.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,eess.IV","published":"2025-03-31T09:44:28Z"}
{"aid":"http://arxiv.org/abs/2503.23898v1","title":"An Explainable Neural Radiomic Sequence Model with Spatiotemporal\n  Continuity for Quantifying 4DCT-based Pulmonary Ventilation","summary":"Accurate evaluation of regional lung ventilation is essential for the\nmanagement and treatment of lung cancer patients, supporting assessments of\npulmonary function, optimization of therapeutic strategies, and monitoring of\ntreatment response. Currently, ventilation scintigraphy using nuclear medicine\ntechniques is widely employed in clinical practice; however, it is often\ntime-consuming, costly, and entails additional radiation exposure. In this\nstudy, we propose an explainable neural radiomic sequence model to identify\nregions of compromised pulmonary ventilation based on four-dimensional computed\ntomography (4DCT). A cohort of 45 lung cancer patients from the VAMPIRE dataset\nwas analyzed. For each patient, lung volumes were segmented from 4DCT, and\nvoxel-wise radiomic features (56-dimensional) were extracted across the\nrespiratory cycle to capture local intensity and texture dynamics, forming\ntemporal radiomic sequences. Ground truth ventilation defects were delineated\nvoxel-wise using Galligas-PET and DTPA-SPECT. To identify compromised regions,\nwe developed a temporal saliency-enhanced explainable long short-term memory\n(LSTM) network trained on the radiomic sequences. Temporal saliency maps were\ngenerated to highlight key features contributing to the model's predictions.\nThe proposed model demonstrated robust performance, achieving average (range)\nDice similarity coefficients of 0.78 (0.74-0.79) for 25 PET cases and 0.78\n(0.74-0.82) for 20 SPECT cases. The temporal saliency map explained three key\nradiomic sequences in ventilation quantification: during lung exhalation,\ncompromised pulmonary function region typically exhibits (1) an increasing\ntrend of intensity and (2) a decreasing trend of homogeneity, in contrast to\nhealthy lung tissue.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-03-31T09:47:03Z"}
{"aid":"http://arxiv.org/abs/2503.23903v1","title":"Privacy Preservation for Statistical Input in Dynamical Systems","summary":"This paper addresses the challenge of privacy preservation for statistical\ninputs in dynamical systems. Motivated by an autonomous building application,\nwe formulate a privacy preservation problem for statistical inputs in linear\ntime-invariant systems. What makes this problem widely applicable is that the\ninputs, rather than being assumed to be deterministic, follow a probability\ndistribution, inherently embedding privacy-sensitive information that requires\nprotection. This formulation also presents a technical challenge as\nconventional differential privacy mechanisms are not directly applicable.\nThrough rigorous analysis, we develop strategy to achieve $(0, \\delta)$\ndifferential privacy through adding noise. Finally, the effectiveness of our\nmethods is demonstrated by revisiting the autonomous building application.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:54:09Z"}
{"aid":"http://arxiv.org/abs/2503.23904v1","title":"System $F^Ï$ with Coherent Implicit Resolution","summary":"We propose a calculus for modeling implicit programming that supports\nfirst-class, overlapping, locally scoped, and higher-order instances with\nhigher-kinded types. We propose a straightforward generalization of the\nwell-established System $F^\\omega$ to implicit parameters, with a uniform\ntreatment of type and term abstractions. Unlike previous works, we give a\ndeclarative specification of unambiguous, and thus coherent, resolution without\nintroducing restrictions motivated by an algorithmic formulation of resolution.","main_category":"cs.PL","categories":"cs.PL","published":"2025-03-31T09:54:32Z"}
{"aid":"http://arxiv.org/abs/2503.23906v1","title":"Topologizability and related properties of the iterates of composition\n  operators in Gelfand-Shilov classes","summary":"We analyse the behaviour of the iterates of composition operators defined by\npolynomials acting on global classes of ultradifferentiable functions of\nBeurling type which are invariant under the Fourier transform. In particular,\nwe determine the polynomials $\\psi$ for which the sequence of iterates of the\ncomposition operator $C_\\psi$ is topologizable (m-topologizable) acting on\ncertain Gelfand-Shilov spaces defined by mean of Braun-Meise-Taylor weights. We\nprove that the composition operators $C_\\psi$ with $\\psi$ a polynomial of\ndegree greater than one are always topologizable in certain settings involving\nGelfand-Shilov spaces, just like in the Schwartz space. Unlike in the Schwartz\nspace setting, composition operators $C_\\psi$ associated with polynomials\n$\\psi$ are not always $m-$topologizable. We also deal with the composition\noperators $C_\\psi$ with $\\psi$ being an affine function acting on\n$\\mathcal{S}_{\\omega}(\\mathbb{R})$ and find a complete characterization of\ntopologizability and m-topologizability","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-03-31T09:57:29Z"}
{"aid":"http://arxiv.org/abs/2503.23931v1","title":"Kernel-based dequantization of variational QML without Random Fourier\n  Features","summary":"There is currently a huge effort to understand the potential and limitations\nof variational quantum machine learning (QML) based on the optimization of\nparameterized quantum circuits. Recent proposals toward dequantizing\nvariational QML models for regression problems include approaches based on\nkernel methods with carefully chosen kernel functions, approximated via Random\nFourier Features (RFF). In this short note we show that for a wide range of\ninstances, this approach can be simplified. More specifically, we show that the\nkernels whose evaluation is approximated by RFF in this dequantization\nalgorithm can in fact often be evaluated exactly and efficiently classically.\nAs such, our results enhance the toolkit for kernel-based dequantization of\nvariational QML.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T10:26:16Z"}
{"aid":"http://arxiv.org/abs/2503.23933v1","title":"PupiNet: Seamless OCT-OCTA Interconversion Through Wavelet-Driven and\n  Multi-Scale Attention Mechanisms","summary":"Optical Coherence Tomography (OCT) and Optical Coherence Tomography\nAngiography (OCTA) are key diagnostic tools for clinical evaluation and\nmanagement of retinal diseases. Compared to traditional OCT, OCTA provides\nricher microvascular information, but its acquisition requires specialized\nsensors and high-cost equipment, creating significant challenges for the\nclinical deployment of hardware-dependent OCTA imaging methods. Given the\ntechnical complexity of OCTA image acquisition and potential mechanical\nartifacts, this study proposes a bidirectional image conversion framework\ncalled PupiNet, which accurately achieves bidirectional transformation between\n3D OCT and 3D OCTA. The generator module of this framework innovatively\nintegrates wavelet transformation and multi-scale attention mechanisms,\nsignificantly enhancing image conversion quality. Meanwhile, an Adaptive\nDiscriminator Augmentation (ADA) module has been incorporated into the\ndiscriminator to optimize model training stability and convergence efficiency.\nTo ensure clinical accuracy of vascular structures in the converted images, we\ndesigned a Vessel Structure Matcher (VSM) supervision module, achieving precise\nmatching of vascular morphology between generated images and target images.\nAdditionally, the Hierarchical Feature Calibration (HFC) module further\nguarantees high consistency of texture details between generated images and\ntarget images across different depth levels. To rigorously validate the\nclinical effectiveness of the proposed method, we conducted a comprehensive\nevaluation on a paired OCT-OCTA image dataset containing 300 eyes with various\nretinal pathologies. Experimental results demonstrate that PupiNet not only\nreliably achieves high-quality bidirectional transformation between the two\nmodalities but also shows significant advantages in image fidelity, vessel\nstructure preservation, and clinical usability.","main_category":"eess.IV","categories":"eess.IV","published":"2025-03-31T10:27:23Z"}
{"aid":"http://arxiv.org/abs/2503.23934v1","title":"Green MLOps to Green GenOps: An Empirical Study of Energy Consumption in\n  Discriminative and Generative AI Operations","summary":"This study presents an empirical investigation into the energy consumption of\nDiscriminative and Generative AI models within real-world MLOps pipelines. For\nDiscriminative models, we examine various architectures and hyperparameters\nduring training and inference and identify energy-efficient practices. For\nGenerative AI, Large Language Models (LLMs) are assessed, focusing primarily on\nenergy consumption across different model sizes and varying service requests.\nOur study employs software-based power measurements, ensuring ease of\nreplication across diverse configurations, models, and datasets. We analyse\nmultiple models and hardware setups to uncover correlations among various\nmetrics, identifying key contributors to energy consumption. The results\nindicate that for Discriminative models, optimising architectures,\nhyperparameters, and hardware can significantly reduce energy consumption\nwithout sacrificing performance. For LLMs, energy efficiency depends on\nbalancing model size, reasoning complexity, and request-handling capacity, as\nlarger models do not necessarily consume more energy when utilisation remains\nlow. This analysis provides practical guidelines for designing green and\nsustainable ML operations, emphasising energy consumption and carbon footprint\nreductions while maintaining performance. This paper can serve as a benchmark\nfor accurately estimating total energy use across different types of AI models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T10:28:04Z"}
{"aid":"http://arxiv.org/abs/2503.23956v1","title":"AirCache: Activating Inter-modal Relevancy KV Cache Compression for\n  Efficient Large Vision-Language Model Inference","summary":"Recent advancements in Large Visual Language Models (LVLMs) have gained\nsignificant attention due to their remarkable reasoning capabilities and\nproficiency in generalization. However, processing a large number of visual\ntokens and generating long-context outputs impose substantial computational\noverhead, leading to excessive demands for key-value (KV) cache. To address\nthis critical bottleneck, we propose AirCache, a novel KV cache compression\nmethod aimed at accelerating LVLMs inference. This work systematically\ninvestigates the correlations between visual and textual tokens within the\nattention mechanisms of LVLMs. Our empirical analysis reveals considerable\nredundancy in cached visual tokens, wherein strategically eliminating these\ntokens preserves model performance while significantly accelerating context\ngeneration. Inspired by these findings, we introduce an elite observation\nwindow for assessing the importance of visual components in the KV cache,\nfocusing on stable inter-modal relevancy modeling with enhanced\nmulti-perspective consistency. Additionally, we develop an adaptive layer-wise\nbudget allocation strategy that capitalizes on the strength and skewness of\ntoken importance distribution, showcasing superior efficiency compared to\nuniform allocation. Comprehensive evaluations across multiple LVLMs and\nbenchmarks demonstrate that our method achieves comparable performance to the\nfull cache while retaining only 10% of visual KV cache, thereby reducing\ndecoding latency by 29% to 66% across various batch size and prompt length of\ninputs. Notably, as cache retention rates decrease, our method exhibits\nincreasing performance advantages over existing approaches.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T11:13:18Z"}
{"aid":"http://arxiv.org/abs/2503.23967v1","title":"Note on $q=2$ paraparticle SYK model","summary":"We investigate the $q=2$ SYK model with paraparticles (PSYK$_2$), analyzing\nits thermodynamics and spectral form factor (SFF) using random matrix theory.\nThe Hamiltonian is quadratic, with coupling coefficients randomly drawn from\nthe Gaussian Unitary Ensemble (GUE). The model exhibits self-averaging behavior\nand shows a striking transition in SFF dynamics: while the fermionic SYK$_2$\ndisplays a ramp behavior $\\mathcal{K}(t) \\sim e^{C_0 t}$ with $C_0 \\sim \\ln N$,\nthe paraparticle cases exhibit $C_0 \\sim \\mathcal{O}(1)$. These findings offer\nnew insights into quantum systems with exotic statistics.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T11:32:06Z"}
{"aid":"http://arxiv.org/abs/2503.23997v1","title":"On the origin of Jupiter's fuzzy core: constraints from N-body, impact\n  and evolution simulations","summary":"It has been suggested that Jupiter's fuzzy core could be a result of a giant\nimpact. Here, we investigate the expected impact conditions from N-body\nsimulations. We then use state-of-the-art SPH simulations to investigate the\nresults of impacts with different conditions including various impactor masses\nand composition, different formation stages in Jupiter's growth, and different\nresolutions. We next simulate the long-term thermal evolution of Jupiter\npost-impact. We find that N-body simulations predict rather oblique impacts,\nand that head-on collisions are rare. Moreover, our results show that even\nunder a head-on collision, Jupiter's fuzzy core cannot be formed. We next\nsimulated Jupiter's thermal evolution and showed that unless post-impact\ntemperatures are extremely low, a giant impact would not lead to an extended\ndilute core as inferred by interior models. We conclude that Jupiter's fuzzy\ncore is not caused by an impact and is likely to be an outcome of its formation\nprocess.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-03-31T12:20:59Z"}
{"aid":"http://arxiv.org/abs/2503.24000v1","title":"Rethinking Key-Value Cache Compression Techniques for Large Language\n  Model Serving","summary":"Key-Value cache (\\texttt{KV} \\texttt{cache}) compression has emerged as a\npromising technique to optimize Large Language Model (LLM) serving. It\nprimarily decreases the memory consumption of \\texttt{KV} \\texttt{cache} to\nreduce the computation cost. Despite the development of many compression\nalgorithms, their applications in production environments are still not\nprevalent. In this paper, we revisit mainstream \\texttt{KV} \\texttt{cache}\ncompression solutions from a practical perspective. Our contributions are\nthree-fold. First, we comprehensively review existing algorithmic designs and\nbenchmark studies for \\texttt{KV} \\texttt{cache} compression and identify\nmissing pieces in their performance measurement, which could hinder their\nadoption in practice. Second, we empirically evaluate representative\n\\texttt{KV} \\texttt{cache} compression methods to uncover two key issues that\naffect the computational efficiency: (1) while compressing \\texttt{KV}\n\\texttt{cache} can reduce memory consumption, current implementations (e.g.,\nFlashAttention, PagedAttention) do not optimize for production-level LLM\nserving, resulting in suboptimal throughput performance; (2) compressing\n\\texttt{KV} \\texttt{cache} may lead to longer outputs, resulting in increased\nend-to-end latency. We further investigate the accuracy performance of\nindividual samples rather than the overall performance, revealing the intrinsic\nlimitations in \\texttt{KV} \\texttt{cache} compression when handling specific\nLLM tasks. Third, we provide tools to shed light on future \\texttt{KV}\n\\texttt{cache} compression studies and facilitate their practical deployment in\nproduction. They are open-sourced in\n\\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T12:23:31Z"}
{"aid":"http://arxiv.org/abs/2503.24003v1","title":"A Robust Extrinsic Single-index Model for Spherical Data","summary":"Regression with a spherical response is challenging due to the absence of\nlinear structure, making standard regression models inadequate. Existing\nmethods, mainly parametric, lack the flexibility to capture the complex\nrelationship induced by spherical curvature, while methods based on techniques\nfrom Riemannian geometry often suffer from computational difficulties. The\nnon-Euclidean structure further complicates robust estimation, with very\nlimited work addressing this issue, despite the common presence of outliers in\ndirectional data. This article introduces a new semi-parametric approach, the\nextrinsic single-index model (ESIM) and its robust estimation, to address these\nlimitations. We establish large-sample properties of the proposed estimator\nwith a wide range of loss functions and assess their robustness using the\ninfluence function and standardized influence function. Specifically, we focus\non the robustness of the exponential squared loss (ESL), demonstrating\ncomparable efficiency and superior robustness over least squares loss under\nhigh concentration. We also examine how the tuning parameter for the ESL\nbalances efficiency and robustness, providing guidance on its optimal choice.\nThe computational efficiency and robustness of our methods are further\nillustrated via simulations and applications to geochemical compositional data.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T12:27:42Z"}
{"aid":"http://arxiv.org/abs/2503.24016v1","title":"Bayesian Predictive Coding","summary":"Predictive coding (PC) is an influential theory of information processing in\nthe brain, providing a biologically plausible alternative to backpropagation.\nIt is motivated in terms of Bayesian inference, as hidden states and parameters\nare optimised via gradient descent on variational free energy. However,\nimplementations of PC rely on maximum \\textit{a posteriori} (MAP) estimates of\nhidden states and maximum likelihood (ML) estimates of parameters, limiting\ntheir ability to quantify epistemic uncertainty. In this work, we investigate a\nBayesian extension to PC that estimates a posterior distribution over network\nparameters. This approach, termed Bayesian Predictive coding (BPC), preserves\nthe locality of PC and results in closed-form Hebbian weight updates. Compared\nto PC, our BPC algorithm converges in fewer epochs in the full-batch setting\nand remains competitive in the mini-batch setting. Additionally, we demonstrate\nthat BPC offers uncertainty quantification comparable to existing methods in\nBayesian deep learning, while also improving convergence properties. Together,\nthese results suggest that BPC provides a biologically plausible method for\nBayesian learning in the brain, as well as an attractive approach to\nuncertainty quantification in deep learning.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-03-31T12:40:50Z"}
{"aid":"http://arxiv.org/abs/2503.24042v1","title":"Strain effects in a directly bonded diamond-on-insulator substrate","summary":"The direct bonding process of a diamond-on-insulator (DOI) substrate enables\nmonolithic integration of diamond photonic structures for quantum computing by\nimproving photon collection efficiency and entanglement generation rate between\nemitters. It also addresses key fabrication challenges, such as robustness,\nbonding strength, and scalability. In this study, we investigate strain effects\nin DOI substrates following direct bonding. Strain generation is expected near\nthe diamond-SiO2/Si interface due to thermal expansion coefficient mismatch\nbetween the bonded materials. Strain-induced lattice distortions are\ncharacterized using nitrogen-vacancy (NV) centers in diamond via optically\ndetected magnetic resonance (ODMR) and photoluminescence (PL) mapping. PL\nmapping reveals interference fringes in unbonded regions, indicating bonding\nirregularities. Depth-resolved ODMR measurements show a volumetric strain\ncomponent increase of ~0.45 MHz and a shear component increase of ~0.71 MHz\nbetween the top surface and the DOI interface. However, ODMR signal contrast\nand peak linewidth remain largely unaffected, suggesting no visible\ndeterioration in the optical properties of the emitters. By combining ODMR and\nPL mapping, this work establishes a robust methodology for assessing bonding\nquality and strain impact on NV centers, an essential step toward advancing\nscalable quantum technologies and integrated photonic circuits.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci,quant-ph","published":"2025-03-31T13:06:35Z"}
{"aid":"http://arxiv.org/abs/2503.24045v1","title":"Evaluating Variational Quantum Eigensolver and Quantum Dynamics\n  Algorithms on the Advection-Diffusion Equation","summary":"We investigate the potential of near-term quantum algorithms for solving\npartial differential equations (PDEs), focusing on a linear one-dimensional\nadvection-diffusion equation as a test case. This study benchmarks a\nground-state algorithm, Variational Quantum Eigensolver (VQE), against three\nleading quantum dynamics algorithms, Trotterization, Variational Quantum\nImaginary Time Evolution (VarQTE), and Adaptive Variational Quantum Dynamics\nSimulation (AVQDS), applied to the same PDE on small quantum hardware. While\nTrotterization is fully quantum, VarQTE and AVQDS are variational algorithms\nthat reduce circuit depth for noisy intermediate-scale quantum (NISQ) devices.\nHowever, hardware results from these dynamics methods show sizable errors due\nto noise and limited shot statistics. To establish a noise-free performance\nbaseline, we implement the VQE-based solver on a noiseless statevector\nsimulator. Our results show VQE can reach final-time infidelities as low as\n${O}(10^{-9})$ with $N=4$ qubits and moderate circuit depths, outperforming\nhardware-deployed dynamics methods that show infidelities $\\gtrsim 10^{-2}$. By\ncomparing noiseless VQE to shot-based and hardware-run algorithms, we assess\ntheir accuracy and resource demands, providing a baseline for future quantum\nPDE solvers. We conclude with a discussion of limitations and potential\nextensions to higher-dimensional, nonlinear PDEs relevant to engineering and\nfinance.","main_category":"quant-ph","categories":"quant-ph,cs.CE,cs.ET","published":"2025-03-31T13:09:59Z"}
{"aid":"http://arxiv.org/abs/2503.24089v1","title":"Initial State Privacy of Nonlinear Systems on Riemannian Manifolds","summary":"In this paper, we investigate initial state privacy protection for\ndiscrete-time nonlinear closed systems. By capturing Riemannian geometric\nstructures inherent in such privacy challenges, we refine the concept of\ndifferential privacy through the introduction of an initial state adjacency set\nbased on Riemannian distances. A new differential privacy condition is\nformulated using incremental output boundedness, enabling the design of\ntime-varying Laplacian noise to achieve specified privacy guarantees. The\nproposed framework extends beyond initial state protection to also cover system\nparameter privacy, which is demonstrated as a special application.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T13:42:18Z"}
{"aid":"http://arxiv.org/abs/2503.24096v1","title":"DANTE-AD: Dual-Vision Attention Network for Long-Term Audio Description","summary":"Audio Description is a narrated commentary designed to aid vision-impaired\naudiences in perceiving key visual elements in a video. While short-form video\nunderstanding has advanced rapidly, a solution for maintaining coherent\nlong-term visual storytelling remains unresolved. Existing methods rely solely\non frame-level embeddings, effectively describing object-based content but\nlacking contextual information across scenes. We introduce DANTE-AD, an\nenhanced video description model leveraging a dual-vision Transformer-based\narchitecture to address this gap. DANTE-AD sequentially fuses both frame and\nscene level embeddings to improve long-term contextual understanding. We\npropose a novel, state-of-the-art method for sequential cross-attention to\nachieve contextual grounding for fine-grained audio description generation.\nEvaluated on a broad range of key scenes from well-known movie clips, DANTE-AD\noutperforms existing methods across traditional NLP metrics and LLM-based\nevaluations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:49:43Z"}
{"aid":"http://arxiv.org/abs/2503.24107v1","title":"Efficient Construction of Feasible Solutions in Column Generation using\n  Quantum Annealing","summary":"Column generation (CG) has been used to solve constrained 0-1 quadratic\nprogramming problems. The pricing problem, which is iteratively solved in CG,\ncan be reduced to an unconstrained 0-1 quadratic programming problem, allowing\nfor the efficient application of quantum annealing (QA). The solutions obtained\nby CG are continuous relaxations, which cannot be practically used as feasible\n0-1 solutions. This study proposes a post-processing method for constructing\nfeasible 0-1 solutions from the continuous relaxations obtained through CG.\nNumerical experiments on randomly generated problems demonstrate that CG with\nthe proposed post-processing yields solutions comparable to commercial solvers\nwith significantly reduced computation time.","main_category":"quant-ph","categories":"quant-ph,cond-mat.dis-nn","published":"2025-03-31T14:00:12Z"}
{"aid":"http://arxiv.org/abs/2503.24108v1","title":"PolypSegTrack: Unified Foundation Model for Colonoscopy Video Analysis","summary":"Early detection, accurate segmentation, classification and tracking of polyps\nduring colonoscopy are critical for preventing colorectal cancer. Many existing\ndeep-learning-based methods for analyzing colonoscopic videos either require\ntask-specific fine-tuning, lack tracking capabilities, or rely on\ndomain-specific pre-training. In this paper, we introduce\n\\textit{PolypSegTrack}, a novel foundation model that jointly addresses polyp\ndetection, segmentation, classification and unsupervised tracking in\ncolonoscopic videos. Our approach leverages a novel conditional mask loss,\nenabling flexible training across datasets with either pixel-level segmentation\nmasks or bounding box annotations, allowing us to bypass task-specific\nfine-tuning. Our unsupervised tracking module reliably associates polyp\ninstances across frames using object queries, without relying on any\nheuristics. We leverage a robust vision foundation model backbone that is\npre-trained unsupervisedly on natural images, thereby removing the need for\ndomain-specific pre-training. Extensive experiments on multiple polyp\nbenchmarks demonstrate that our method significantly outperforms existing\nstate-of-the-art approaches in detection, segmentation, classification, and\ntracking.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T14:00:21Z"}
{"aid":"http://arxiv.org/abs/2503.24109v1","title":"Demailly's approximation of general weights: A conjecture of Matsumura","summary":"In this note, we address a conjecture posed by Matsumura, which gives the\nconvergence of the Demailly approximation of a general (weakly) upper\nsemi-continuous weight.","main_category":"math.CV","categories":"math.CV","published":"2025-03-31T14:01:26Z"}
{"aid":"http://arxiv.org/abs/2503.24112v1","title":"Characterization of norm and quasi-norm forms in S-adic setting","summary":"The goal of the present paper is to characterize the norm and quasi-norm\nforms defined over an arbitrary number field F in terms of their values at the\nS-integer points, where S is a finite set of valuations of F containing the\narchimedean ones. In this way we generalize the main result of the recent paper\n[T5], where the notion of a quasi-norm form is introduced when F = Q and S is a\nsingleton. In complement, we exhibit some relations with problems and results\nin this area of research.","main_category":"math.NT","categories":"math.NT","published":"2025-03-31T14:04:51Z"}
{"aid":"http://arxiv.org/abs/2503.24127v1","title":"Compression Metadata-assisted RoI Extraction and Adaptive Inference for\n  Efficient Video Analytics","summary":"Video analytics demand substantial computing resources, posing significant\nchallenges in computing resource-constrained environment. In this paper, to\nachieve high accuracy with acceptable computational workload, we propose a\ncost-effective regions of interest (RoIs) extraction and adaptive inference\nscheme based on the informative encoding metadata. Specifically, to achieve\nefficient RoI-based analytics, we explore motion vectors from encoding metadata\nto identify RoIs in non-reference frames through morphological opening\noperation. Furthermore, considering the content variation of RoIs, which calls\nfor inference by models with distinct size, we measure RoI complexity based on\nthe bitrate allocation information from encoding metadata. Finally, we design\nan algorithm that prioritizes scheduling RoIs to models of the appropriate\ncomplexity, balancing accuracy and latency. Extensive experimental results show\nthat our proposed scheme reduces latency by nearly 40% and improves 2.2% on\naverage in accuracy, outperforming the latest benchmarks.","main_category":"cs.MM","categories":"cs.MM","published":"2025-03-31T14:12:02Z"}
{"aid":"http://arxiv.org/abs/2503.24131v1","title":"A simple and general framework for the construction of exactly\n  div-curl-grad compatible discontinuous Galerkin finite element schemes on\n  unstructured simplex meshes","summary":"We introduce a new family of discontinuous Galerkin (DG) finite element\nschemes for the discretization of first order systems of hyperbolic partial\ndifferential equations (PDE) on unstructured simplex meshes in two and three\nspace dimensions that respect the two basic vector calculus identities exactly\nalso at the discrete level, namely that the curl of the gradient is zero and\nthat the divergence of the curl is zero. The key ingredient here is the\nconstruction of two compatible discrete nabla operators, a primary one and a\ndual one, both defined on general unstructured simplex meshes in multiple space\ndimensions. Our new schemes extend existing cell-centered finite volume methods\nbased on corner fluxes to arbitrary high order of accuracy in space. An\nimportant feature of our new method is the fact that only two different\ndiscrete function spaces are needed to represent the numerical solution, and\nthe choice of the appropriate function space for each variable is related to\nthe origin and nature of the underlying PDE. The first class of variables is\ndiscretized at the aid of a discontinuous Galerkin approach, where the\nnumerical solution is represented via piecewise polynomials of degree N and\nwhich are allowed to jump across element interfaces. This set of variables is\nrelated to those PDE which are mere consequences of the definitions, derived\nfrom some abstract scalar and vector potentials, and for which involutions like\nthe divergence-free or the curl-free property must hold if satisfied by the\ninitial data. The second class of variables is discretized via classical\ncontinuous Lagrange finite elements of approximation degree M=N+1 and is\nrelated to those PDE which can be derived as the Euler-Lagrange equations of an\nunderlying variational principle.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-03-31T14:17:11Z"}
{"aid":"http://arxiv.org/abs/2503.24137v1","title":"Half-life and precision shape measurement of 2Î½Î²Î² decay\n  of $^{130}$Te","summary":"We present a new measurement of the 2nbb half-life of 130Te (T1/2) using the\nfirst complete model of the CUORE data, based on 1038 kg yr of collected\nexposure. Thanks to optimized data selection, we achieve a factor of two\nimprovement in precision, obtaining T1/2 = (9.32 +0.05 -0.04 (stat.) +0.07\n-0.07 (syst.)) x10^20 yr. The signal-to-background ratio is increased by 70%\ncompared to our previous results, enabling the first application of the\nimproved 2nbb formalism to 130Te. Within this framework, we determine a\ncredibility interval for the effective axial coupling in the nuclear medium as\na function of nuclear matrix elements. We also extract values for the\nhigher-order nuclear matrix element ratios: second-to-first and third-to-first.\nThe second-to-first ratio agrees with nuclear model predictions, while the\nthird-to-first ratio deviates from theoretical expectations. These findings\nprovide essential tests of nuclear models and key inputs for future 0nbb\nsearches.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T14:19:33Z"}
{"aid":"http://arxiv.org/abs/2503.24144v1","title":"$\\mathsf{P}$-completeness of Graph Local Complementation","summary":"Local complementation of a graph $G$ on vertex $v$ is an operation that\nresults in a new graph $G*v$, where the neighborhood of $v$ is complemented.\nThis operation has been widely studied in graph theory and quantum computing.\n  This article introduces the Local Complementation Problem, a decision problem\nthat captures the complexity of applying a sequence of local complementations.\nGiven a graph $G$, a sequence of vertices $s$, and a pair of vertices $u,v$,\nthe problem asks whether the edge $(u,v)$ is present in the graph obtained\nafter applying local complementations according to $s$. The main contribution\nof this work is proving that this problem is $\\mathsf{P}$-complete, implying\nthat computing a sequence of local complementation is unlikely to be\nefficiently parallelizable. The proof is based on a reduction from the Circuit\nValue Problem, a well-known $\\mathsf{P}$-complete problem, by simulating\ncircuits through local complementations.\n  Aditionally, the complexity of this problem is analyzed under different\nrestrictions. In particular, it is shown that for complete and star graphs, the\nproblem belongs to $\\mathsf{LOGSPACE}$. Finally, it is conjectured that the\nproblem remains $\\mathsf{P}$-complete for the class of circle graphs.","main_category":"cs.CC","categories":"cs.CC,cs.DM","published":"2025-03-31T14:27:46Z"}
{"aid":"http://arxiv.org/abs/2503.24162v1","title":"Characteristic initial value problems for the Einstein-Maxwell-scalar\n  field equations in spherical symmetry","summary":"The characteristic initial boundary problem is discussed in spherical\nsymmetry for the Einstein-Maxwell-scalar field equations. It is formulated for\nan affine-null metric and the resulting field equations are cast into a\nhierarchical system of partial differential equations. The initial boundary\nvalue problem for a family of null hypersurfaces is specified for a\ntimelike-null foliation at the central geodesic of spherical symmetry as well\nas for a double-null foliation where the corresponding boundary is a null\nhypersurface. For the latter, two distinct boundary value formulations arise --\none where the null boundary has zero Misner-Sharp mass and another one where\nthe corresponding Misner-Sharp mass is nonzero. As an application, the\nnonextremal and the extremal Reissner-Nordstr\\\"om solution in null coordinates\nfor a charged black hole and the Fisher-Janis-Newman-Winicour solution are\nderived.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-03-31T14:46:11Z"}
{"aid":"http://arxiv.org/abs/2503.24163v1","title":"First-principles design of stable spin qubits in monolayer MoS2 with\n  elemental defect engineering","summary":"Quantum information science (QIS), encompassing technologies such as quantum\ncomputing, sensing, and communication, relies on the development and\nmanipulation of quantum bits (qubits). Recently, two-dimensional (2D) materials\n- characterized by their atomic thinness and external controllability - have\nemerged as promising candidates for qubit fabrication and manipulation at room\ntemperature. In this study, we propose that antisite defects (MX) in 2D\ntransition metal disulfides (TMDs) can serve as tunable quantum defects with\ncontrolled positioning. Using first-principles atomic structure simulations, we\nidentify six thermodynamically stable neutral antisite defects (MX, where M =\nMg, Ca, Sr, Ba, Zn, Cd; X = S) in monolayer 1H-MoS2. These defects exhibit\npotential as spin-defected qubits with stable triplet ground states.\nAdditionally, we demonstrate that the reduction of the bandgap leads to\nsignificant fluctuations in the absorption coefficient within the low-energy\nrange, resulting in the optical response within the desired telecommunication\nband, which is advantageous for quantum communication applications. The\nzero-phonon line (ZPL) associated with these qubits can serve as an effective\nidentifier. This work presents the novel, tunable approach to exploiting\ndefects in 2D materials, opening new possibilities for the development of qubit\nplatforms in quantum information technology.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-03-31T14:46:16Z"}
{"aid":"http://arxiv.org/abs/2503.24175v1","title":"What is the Funniest Number? An investigation of numerical humor","summary":"In a preliminary study of numerical humor, we propose the Perceived\nSpecificity Hypothesis (PSH). The PSH states that, for nonnegative integers <\n100, the funniness of a number increases with its apparent precision. A survey\nof 68 individuals supports the veracity of this hypothesis and indicates that\noddly specific numbers tend to be funniest. Our results motivate future study\nin this novel subfield.","main_category":"math.NT","categories":"math.NT,math.HO","published":"2025-03-31T14:52:12Z"}
{"aid":"http://arxiv.org/abs/2503.24194v1","title":"Berry Phase in Non-Perturbative QED","summary":"We study QED$_4$ in the adiabatic approximation, incorporating global\ntopological effects associated with the $U(1)$ Berry connection. The Berry\nphase accumulated by the fermionic vacuum is given by $\\Delta \\alpha =\n\\oint_{\\mathcal{C}} \\gamma_5\\, \\mathcal{A}^{(n)}$, where $\\mathcal{A}^{(n)}$ is\na closed but non-exact one-form defined over the space of gauge configurations.\nThis chiral holonomy induces an emergent vacuum angle that contributes\nnon-perturbatively to the effective action. The partition function decomposes\ninto topological sectors weighted by this geometric phase, analogous to quantum\nsystems on multiply connected spaces. Our results reveal that even in Abelian\ngauge theory, the infrared regime can exhibit global effects beyond the reach\nof local or perturbative descriptions.","main_category":"hep-th","categories":"hep-th,quant-ph","published":"2025-03-31T15:13:08Z"}
{"aid":"http://arxiv.org/abs/2503.24197v1","title":"Asymptotically distribution-free goodness-of-fit testing for point\n  processes","summary":"Consider an observation of a multivariate temporal point process $N$ with law\n$\\mathcal P$ on the time interval $[0,T]$. To test the null hypothesis that\n$\\mathcal P$ belongs to a given parametric family, we construct a convergent\ncompensated counting process to which we apply an innovation martingale\ntransformation. We prove that the resulting process converges weakly to a\nstandard Wiener process. Consequently, taking a suitable functional of this\nprocess yields an asymptotically distribution-free goodness-of-fit test for\npoint processes. For several standard tests based on the increments of this\ntransformed process, we establish consistency under alternative hypotheses.\nFinally, we assess the performance of the proposed testing procedure through a\nMonte Carlo simulation study and illustrate its practical utility with two\nreal-data examples.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-03-31T15:15:52Z"}
{"aid":"http://arxiv.org/abs/2503.24202v1","title":"Double-jump phase transition for the reverse Littlewood--Offord problem","summary":"Erd\\H{o}s conjectured in 1945 that for any unit vectors $v_1, \\dotsc, v_n$ in\n$\\mathbb{R}^2$ and signs $\\varepsilon_1, \\dotsc, \\varepsilon_n$ taken\nindependently and uniformly in $\\{-1,1\\}$, the random Rademacher sum $\\sigma =\n\\varepsilon_1 v_1 + \\dotsb + \\varepsilon_n v_n$ satisfies $\\|\\sigma\\|_2 \\leq 1$\nwith probability $\\Omega(1/n)$. While this conjecture is false for even $n$,\nBeck has proved that $\\|\\sigma\\|_2 \\leq \\sqrt{2}$ always holds with probability\n$\\Omega(1/n)$. Recently, He, Ju\\v{s}kevi\\v{c}ius, Narayanan, and Spiro\nconjectured that the Erd\\H{o}s' conjecture holds when $n$ is odd. We disprove\nthis conjecture by exhibiting vectors $v_1, \\dotsc, v_n$ for which\n$\\|\\sigma\\|_2 \\leq 1$ occurs with probability $O(1/n^{3/2})$. On the other\nhand, an approximated version of their conjecture holds: we show that we always\nhave $\\|\\sigma\\|_2 \\leq 1 + \\delta$ with probability $\\Omega_\\delta(1/n)$, for\nall $\\delta > 0$. This shows that when $n$ is odd, the minimum probability that\n$\\|\\sigma\\|_2 \\leq r$ exhibits a double-jump phase transition at $r = 1$, as we\ncan also show that $\\|\\sigma\\|_2 \\leq 1$ occurs with probability at least\n$\\Omega((1/2+\\mu)^n)$ for some $\\mu > 0$. Additionally, and using a different\nconstruction, we give a negative answer to a question of Beck and two other\nquestions of He, Ju\\v{s}kevi\\v{c}ius, Narayanan, and Spiro, concerning the\noptimal constructions minimising the probability that $\\|\\sigma\\|_2 \\leq\n\\sqrt{2}$. We also make some progress on the higher dimensional versions of\nthese questions.","main_category":"math.CO","categories":"math.CO,math.PR","published":"2025-03-31T15:20:49Z"}
{"aid":"http://arxiv.org/abs/2503.24211v1","title":"A Quantum Walk Inspired Qubit Lattice Algorithm for Simulating\n  Electromagnetic Wave Propagation and Scattering in Conservative and\n  Dissipative Magnetized Plasmas","summary":"Based on the Dirac representation of Maxwell equations we present an\nexplicit, discrete space-time, quantum walk-inspired algorithm suitable for\nsimulating the electromagnetic wave propagation and scattering from\ninhomogeneities within magnetized plasmas. The quantum walk is implemented on a\nlattice with an internal space of $n_q=4$--qubits, used to encode the classical\nfield amplitudes. Unitary rotation gates operate within this internal space to\ngenerate the non-trivial dynamics of the free plasma-Dirac equation. To\nincorporate the contributions from the cyclotron and plasma density\nterms--manifesting as inhomogeneous potential terms--in the plasma-Dirac\nequation, the walk process is complemented with unitary potential operators.\nThis leads to a unitary qubit lattice sequence that recovers the plasma-Dirac\nequation under a second-order accurate discretization scheme. The proposed\nalgorithm is explicit and demonstrates, in the worst case, a polynomial quantum\nadvantage compared to the Finite Difference Time Domain (FDTD) classical method\nin terms of resource requirements and error complexity. In addition, we extend\nthe algorithm to include dissipative effects by introducing a phenomenological\ncollision frequency between plasma species. Then, a post-selective\ntime-marching implementation scheme is delineated, featuring a non-vanishing\noverall success probability and, subsequently, eliminating the need for\namplitude amplification of the output state while preserving the quantum\nadvantage.","main_category":"quant-ph","categories":"quant-ph,physics.plasm-ph","published":"2025-03-31T15:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.24214v1","title":"Moving Edge for On-Demand Edge Computing: An Uncertainty-aware Approach","summary":"We study an edge demand response problem where, based on historical edge\nworkload demands, an edge provider needs to dispatch moving computing units,\ne.g. truck-carried modular data centers, in response to emerging hotspots\nwithin service area. The goal of edge provider is to maximize the expected\nrevenue brought by serving congested users with satisfactory performance, while\nminimizing the costs of moving units and the potential service-level agreement\nviolation penalty for interrupted services. The challenge is to make robust\npredictions for future demands, as well as optimized moving unit dispatching\ndecisions. We propose a learning-based, uncertain-aware moving unit scheduling\nframework, URANUS, to address this problem. Our framework novelly combines\nBayesian deep learning and distributionally robust approximation to make\npredictions that are robust to data, model and distributional uncertainties in\ndeep learning-based prediction models. Based on the robust prediction outputs,\nwe further propose an efficient planning algorithm to optimize moving unit\nscheduling in an online manner. Simulation experiments show that URANUS can\nsignificantly improve robustness in decision making, and achieve superior\nperformance compared to state-of-the-art reinforcement learning,\nuncertainty-agnostic learning-based methods, and other baselines.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T15:32:05Z"}
{"aid":"http://arxiv.org/abs/2503.24215v1","title":"All You Need is Sally-Anne: ToM in AI Strongly Supported After\n  Surpassing Tests for 3-Year-Olds","summary":"Theory of Mind (ToM) is a hallmark of human cognition, allowing individuals\nto reason about others' beliefs and intentions. Engineers behind recent\nadvances in Artificial Intelligence (AI) have claimed to demonstrate comparable\ncapabilities. This paper presents a model that surpasses traditional ToM tests\ndesigned for 3-year-old children, providing strong support for the presence of\nToM in AI systems.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T15:32:10Z"}
{"aid":"http://arxiv.org/abs/2503.24241v1","title":"Asymmetry in Distributions of Accumulated Gains and Losses in Stock\n  Returns","summary":"We study decades-long historic distributions of accumulated S\\&P500 returns,\nfrom daily returns to those over several weeks. The time series of the returns\nemphasize major upheavals in the markets -- Black Monday, Tech Bubble,\nFinancial Crisis and Covid Pandemic -- which are reflected in the tail ends of\nthe distributions. De-trending the overall gain, we concentrate on comparing\ndistributions of gains and losses. Specifically, we compare the tails of the\ndistributions, which are believed to exhibit power-law behavior and possibly\ncontain outliers. Towards this end we find confidence intervals of the linear\nfits of the tails of the complementary cumulative distribution functions on a\nlog-log scale, as well as conduct a statistical U-test in order to detect\noutliers. We also study probability density functions of the full distributions\nof the returns with the emphasis on their asymmetry. The key empirical\nobservations are that the mean of de-trended distributions increases\nnear-linearly with the number of days of accumulation while the overall skew is\nnegative -- consistent with the heavier tails of losses -- and depends little\non the number of days of accumulation. At the same time the variance of the\ndistributions exhibits near-perfect linear dependence on the number of days of\naccumulation, that is it remains constant if scaled to the latter. Finally, we\ndiscuss the theoretical framework for understanding accumulated returns. Our\nmain conclusion is that the current state of theory, which predicts symmetric\nor near-symmetric distributions of returns cannot explain the aggregate of\nempirical results.","main_category":"q-fin.ST","categories":"q-fin.ST,econ.TH,physics.data-an","published":"2025-03-31T15:54:04Z"}
{"aid":"http://arxiv.org/abs/2503.24251v1","title":"Combining Query Performance Predictors: A Reproducibility Study","summary":"A large number of approaches to Query Performance Prediction (QPP) have been\nproposed over the last two decades. As early as 2009, Hauff et al. [28]\nexplored whether different QPP methods may be combined to improve prediction\nquality. Since then, significant research has been done both on QPP approaches,\nas well as their evaluation. This study revisits Hauff et al.s work to assess\nthe reproducibility of their findings in the light of new prediction methods,\nevaluation metrics, and datasets. We expand the scope of the earlier\ninvestigation by: (i) considering post-retrieval methods, including supervised\nneural techniques (only pre-retrieval techniques were studied in [28]); (ii)\nusing sMARE for evaluation, in addition to the traditional correlation\ncoefficients and RMSE; and (iii) experimenting with additional datasets\n(Clueweb09B and TREC DL). Our results largely support previous claims, but we\nalso present several interesting findings. We interpret these findings by\ntaking a more nuanced look at the correlation between QPP methods, examining\nwhether they capture diverse information or rely on overlapping factors.","main_category":"cs.IR","categories":"cs.IR","published":"2025-03-31T16:01:58Z"}
{"aid":"http://arxiv.org/abs/2503.24269v1","title":"A direct detection method of galaxy intrinsic ellipticity-gravitational\n  shear correlation in non-linear regimes using self-calibration","summary":"Intrinsic alignment (IA) of galaxies is a challenging source of contamination\nin the Cosmic shear (GG) signals. The galaxy intrinsic\nellipticity-gravitational shear (IG) correlation is generally the most dominant\ncomponent of such contamination for cross-correlating redshift bins. The\nself-calibration (SC) method is one of the most effective techniques to\nmitigate such contamination from the GG signal. In a photometric survey, the SC\nmethod first extracts the galaxy number density-galaxy intrinsic ellipticity\n(gI) correlation from the observed galaxy-galaxy lensing correlation using the\nredshift dependence of lens-source pairs. The IG correlation is computed\nthrough a scaling relation using the gI correlation and other lensing\nobservables. We extend the SC method beyond the linear regime by modifying its\nscaling relation which can account for the non-linear galaxy bias model and\nvarious IA models. In this study, we provide a framework to detect the IG\ncorrelation for the redshift bins for source galaxies for the proposed year 1\nsurvey of the Rubin Legacy Survey of Space and Time (LSST Y1). We tested the\nmethod for the tidal alignment and tidal torquing (TATT) model of IA and we\nfound that the scaling relation is accurate within 10$\\%$ and 20$\\%$ for\ncross-correlating and auto-correlating redshift bins, respectively. Hence the\nsuppression of IG contamination can be accomplished with a factor of 10 and 5,\nfor cross-correlating and auto-correlating redshift bins, respectively. We\ntested the method's robustness and found that the suppression of IG\ncontamination by a factor of 5 is still achievable for all combinations of\ncross-correlating bins even with the inclusion of a moderate amount of\nuncertainties on IA and bias parameters, respectively. [Abridged]","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-03-31T16:15:37Z"}
{"aid":"http://arxiv.org/abs/2503.24282v1","title":"Style Quantization for Data-Efficient GAN Training","summary":"Under limited data setting, GANs often struggle to navigate and effectively\nexploit the input latent space. Consequently, images generated from adjacent\nvariables in a sparse input latent space may exhibit significant discrepancies\nin realism, leading to suboptimal consistency regularization (CR) outcomes. To\naddress this, we propose \\textit{SQ-GAN}, a novel approach that enhances CR by\nintroducing a style space quantization scheme. This method transforms the\nsparse, continuous input latent space into a compact, structured discrete proxy\nspace, allowing each element to correspond to a specific real data point,\nthereby improving CR performance. Instead of direct quantization, we first map\nthe input latent variables into a less entangled ``style'' space and apply\nquantization using a learnable codebook. This enables each quantized code to\ncontrol distinct factors of variation. Additionally, we optimize the optimal\ntransport distance to align the codebook codes with features extracted from the\ntraining data by a foundation model, embedding external knowledge into the\ncodebook and establishing a semantically rich vocabulary that properly\ndescribes the training dataset. Extensive experiments demonstrate significant\nimprovements in both discriminator robustness and generation quality with our\nmethod.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:28:44Z"}
{"aid":"http://arxiv.org/abs/2503.24286v1","title":"Pyrometheus: Symbolic abstractions for XPU and automatically\n  differentiated computation of combustion kinetics and thermodynamics","summary":"The cost of combustion simulations is often dominated by the evaluation of\nnet production rates of chemical species and mixture thermodynamics\n(thermochemistry). Execution on computing accelerators (XPUs) like graphic\nprocessing units (GPUs) can greatly reduce this cost. However, established\nthermochemistry software is not readily portable to such devices or sacrifices\nvaluable analytical forms that enable differentiation for sensitivity analysis\nand implicit time integration. Symbolic abstractions are developed with\ncorresponding transformations that enable computation on accelerators and\nautomatic differentiation by avoiding premature specification of detail. The\nsoftware package Pyrometheus is introduced as an implementation of these\nabstractions and their transformations for combustion thermochemistry. The\nformulation facilitates code generation from the symbolic representation of a\nspecific thermochemical mechanism in multiple target languages, including\nPython, C++, and Fortran. Computational concerns are separated: the generated\ncode processes array-valued expressions but does not specify their semantics.\nThese semantics are provided by compatible array libraries, such as NumPy,\nPytato, and Google JAX. Thus, the generated code retains a symbolic\nrepresentation of the thermochemistry, which translates to computation on\naccelerators and CPUs and automatic differentiation. The design and operation\nof these symbolic abstractions and their companion tool, Pyrometheus, are\ndiscussed throughout. Roofline demonstrations show that the computation of\nchemical source terms within MFC, a Fortran-based flow solver we link to\nPyrometheus, is performant.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-03-31T16:35:13Z"}
{"aid":"http://arxiv.org/abs/2503.24293v1","title":"Is analogy enough to draw novel adjective-noun inferences?","summary":"Recent work (Ross et al., 2025, 2024) has argued that the ability of humans\nand LLMs respectively to generalize to novel adjective-noun combinations shows\nthat they each have access to a compositional mechanism to determine the\nphrase's meaning and derive inferences. We study whether these inferences can\ninstead be derived by analogy to known inferences, without need for\ncomposition. We investigate this by (1) building a model of analogical\nreasoning using similarity over lexical items, and (2) asking human\nparticipants to reason by analogy. While we find that this strategy works well\nfor a large proportion of the dataset of Ross et al. (2025), there are novel\ncombinations for which both humans and LLMs derive convergent inferences but\nwhich are not well handled by analogy. We thus conclude that the mechanism\nhumans and LLMs use to generalize in these cases cannot be fully reduced to\nanalogy, and likely involves composition.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T16:41:16Z"}
{"aid":"http://arxiv.org/abs/2503.24305v1","title":"Evaluating machine learning models for predicting pesticides toxicity to\n  honey bees","summary":"Small molecules play a critical role in the biomedical, environmental, and\nagrochemical domains, each with distinct physicochemical requirements and\nsuccess criteria. Although biomedical research benefits from extensive datasets\nand established benchmarks, agrochemical data remain scarce, particularly with\nrespect to species-specific toxicity. This work focuses on ApisTox, the most\ncomprehensive dataset of experimentally validated chemical toxicity to the\nhoney bee (\\textit{Apis mellifera}), an ecologically vital pollinator. We\nevaluate ApisTox using a diverse suite of machine learning approaches,\nincluding molecular fingerprints, graph kernels, and graph neural networks, as\nwell as pretrained models. Comparative analysis with medicinal datasets from\nthe MoleculeNet benchmark reveals that ApisTox represents a distinct chemical\nspace. Performance degradation on non-medicinal datasets, such as ApisTox,\ndemonstrates their limited generalizability of current state-of-the-art\nalgorithms trained solely on biomedical data. Our study highlights the need for\nmore diverse datasets and for targeted model development geared toward the\nagrochemical domain.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T16:51:12Z"}
{"aid":"http://arxiv.org/abs/2503.24306v1","title":"Point Tracking in Surgery--The 2024 Surgical Tattoos in Infrared (STIR)\n  Challenge","summary":"Understanding tissue motion in surgery is crucial to enable applications in\ndownstream tasks such as segmentation, 3D reconstruction, virtual tissue\nlandmarking, autonomous probe-based scanning, and subtask autonomy. Labeled\ndata are essential to enabling algorithms in these downstream tasks since they\nallow us to quantify and train algorithms. This paper introduces a point\ntracking challenge to address this, wherein participants can submit their\nalgorithms for quantification. The submitted algorithms are evaluated using a\ndataset named surgical tattoos in infrared (STIR), with the challenge aptly\nnamed the STIR Challenge 2024. The STIR Challenge 2024 comprises two\nquantitative components: accuracy and efficiency. The accuracy component tests\nthe accuracy of algorithms on in vivo and ex vivo sequences. The efficiency\ncomponent tests the latency of algorithm inference. The challenge was conducted\nas a part of MICCAI EndoVis 2024. In this challenge, we had 8 total teams, with\n4 teams submitting before and 4 submitting after challenge day. This paper\ndetails the STIR Challenge 2024, which serves to move the field towards more\naccurate and efficient algorithms for spatial understanding in surgery. In this\npaper we summarize the design, submissions, and results from the challenge. The\nchallenge dataset is available here: https://zenodo.org/records/14803158 , and\nthe code for baseline models and metric calculation is available here:\nhttps://github.com/athaddius/STIRMetrics","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:53:09Z"}
{"aid":"http://arxiv.org/abs/2503.24316v1","title":"Structure and Fragmentation Scale of a Massive Star-Forming Filament in\n  NGC6334: High-Resolution Mid-Infrared Absorption Imaging with JWST","summary":"Dense filaments are believed to be representative of the initial conditions\nof star formation in molecular clouds. We have used the MIRI instrument on JWST\nto image the massive filament NGC6334M at d~1.3 kpc with unprecedented\nresolution and dynamic range at 7.7 and 25.5 microns. Our observations reveal\nthe fine structure of the filament in absorption against mid-infrared\nbackground emission. From the absorption data, we derive high-resolution column\ndensity maps and perform a detailed analysis of the filament structure. We find\na median filament width of 0.12+/-0.02 pc at both wavelengths, resolved by\nalmost two orders of magnitude by MIRI, and consistent with the typical\nhalf-power width of Herschel filaments in nearby (d<0.5 kpc) clouds. The JWST\ndata also reveal the presence of a quasi-periodic series of side filaments with\na similar projected spacing of 0.125+/-0.015 pc. Combining our JWST results\nwith Spitzer and APEX/Herschel data, we perform a study of cloud structure over\nfour orders of magnitude in linear scale. A convergence test shows that our\nwidth estimates for NGC6334M are robust and reflect the presence of a true\ncharacteristic scale. While there is evidence of a Kolmogorov-like spectrum of\nsmall-scale fluctuations down the 1.6x10^-3 pc resolution of the JWST\nobservations, we identify a break in the power spectrum of column density\nfluctuations at a scale ~0.1-0.4 pc comparable to the width of NGC6334M and its\nside filaments. This characteristic scale ~0.1pc has important implications for\nthe origin of the star formation efficiency in dense gas and the IMF.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T17:06:35Z"}
{"aid":"http://arxiv.org/abs/2503.24324v1","title":"Predicting and Mitigating Agricultural Price Volatility Using Climate\n  Scenarios and Risk Models","summary":"Agricultural price volatility challenges sustainable finance, planning, and\npolicy, driven by market dynamics and meteorological factors such as\ntemperature and precipitation. In India, the Minimum Support Price (MSP) system\nacts as implicit crop insurance, shielding farmers from price drops without\npremium payments. We analyze the impact of climate on price volatility for\nsoybean (Madhya Pradesh), rice (Assam), and cotton (Gujarat). Using ERA5-Land\nreanalysis data from the Copernicus Climate Change Service, we analyze\nhistorical climate patterns and evaluate two scenarios: SSP2.4.5 (moderate\ncase) and SSP5.8.5 (severe case). Our findings show that weather conditions\nstrongly influence price fluctuations and that integrating meteorological data\ninto volatility models enhances risk-hedging. Using the Exponential Generalized\nAutoregressive Conditional Heteroskedasticity (EGARCH) model, we estimate\nconditional price volatility and identify cross-correlations between weather\nand price volatility movements. Recognizing MSP's equivalence to a European put\noption, we apply the Black-Scholes model to estimate its implicit premium,\nquantifying its fiscal cost. We propose this novel market-based risk-hedging\nmechanism wherein the government purchases insurance equivalent to MSP,\nleveraging Black-Scholes for accurate premium estimation. Our results\nunderscore the importance of meteorological data in agricultural risk modeling,\nsupporting targeted insurance and strengthening resilience in agricultural\nfinance. This climate-informed financial framework enhances risk-sharing,\nstabilizes prices, and informs sustainable agricultural policy under growing\nclimate uncertainty.","main_category":"stat.AP","categories":"stat.AP,econ.GN,physics.soc-ph,q-fin.EC,q-fin.RM","published":"2025-03-31T17:11:00Z"}
{"aid":"http://arxiv.org/abs/2503.24331v1","title":"Critical quantum metrology using non-Hermitian spin model with\n  RT-symmetry","summary":"The non-Hermitian transverse XY model with\nKaplan-Shekhtman-Entin-Wohlman-Aharony (KSEA) interaction having RT-symmetry,\nreferred to as iKSEA model, possesses both an exceptional point at which\neigenvectors coalesce and a quantum critical point where gap-closing occurs. To\nprecisely estimate the magnetic field of the system, we prove that the quantum\nFisher information (QFI) of the ground state of the iKSEA model, which is a\nlower bound of the precision quantified by the root mean square error, scales\nas $N^2$, with N being the system-size. This provides Heisenberg scaling both\nat the quantum critical point and the exceptional point in the thermodynamic\nlimit. It indicates that when the system is in contact with the bath, resulting\nin this non-Hermitian model, reservoir engineering can provide enhanced\nprecision of system parameters. Additionally, we demonstrate analytically that,\nin contrast to Hermitian systems, QFI surpasses the Heisenberg limit and\nachieves super-Heisenberg scaling ($\\sim N^6$), when the strength of the KSEA\ninteraction approaches the anisotropy parameter, permitting competition between\nnon-hermiticity and hermiticity features, as long as the system size is\nmoderate.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-03-31T17:19:31Z"}
{"aid":"http://arxiv.org/abs/2503.24350v1","title":"Large CP violation in $Î^0_b \\to pK^-Ï^+Ï^-$ and its U-spin\n  partner decays","summary":"The LHCb Collaboration has recently found a large CP-violating rate asymmetry\nin the $b$-baryon decay $\\Lambda^0_b \\to pK^-\\pi^+\\pi^-$. This is the first\nobservation of CP violation in baryon processes, opening a new window to test\nits standard model (SM) origin. Many more baryon decays are expected to exhibit\nobservable signals of CP violation. We show that there also exists large CP\nviolation in the U-spin partner decay mode, $\\Xi^0_b \\to \\Sigma^+\\pi^- K^+K^-$,\nwith rate asymmetry $$A_{CP}(\\Xi^0_b \\to \\Sigma^+\\pi^- K^+ K^-) = -\nA_{CP}(\\Lambda^0_b \\to p K^- \\pi^+ \\pi^-)~ \\frac{Br(\\Lambda^0_b \\to p K^- \\pi^+\n\\pi^-)}{Br(\\Xi^0_b \\to \\Sigma^+ \\pi^- K^+ K^-)}~\n\\frac{\\tau^{\\Xi_b}}{\\tau^{\\Lambda_b}}$$ in the U-spin symmetry limit.\nNeglecting small annihilation contributions, we obtain $$A_{CP}(\\Lambda^0_b \\to\np \\pi^+ \\pi^- \\pi^-) =A_{CP}( \\Xi^0_b \\to \\Sigma^+ \\pi^- K^+ K^-) = -(12 \\pm 3)\n\\%.$$ These predictions provide crucial tests for the SM.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-03-31T17:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.24354v1","title":"ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent\n  Diffusion","summary":"Parameter generation has emerged as a novel paradigm for neural network\ndevelopment, offering an alternative to traditional neural network training by\nsynthesizing high-quality model weights directly. In the context of Low-Rank\nAdaptation (LoRA) for evolving ($\\textit{i.e.}$, constantly updated) large\nlanguage models (LLMs), this approach promises efficient adaptation without\ncostly retraining. However, existing methods face critical limitations in\nsimultaneously achieving scalability and controllability. In this paper, we\nintroduce $\\texttt{ORAL}$, a novel $\\textbf{conditional recurrent diffusion}$\nframework that addresses these challenges. $\\texttt{ORAL}$ incorporates a novel\nconditioning mechanism that integrates model architecture and textual task\nspecifications, enabling the generation of task-specific LoRA parameters that\ncan seamlessly transfer across evolving foundation models. Our approach\nsuccessfully scales to billions-of-parameter LLMs and maintains\ncontrollability. Through extensive experiments across seven language tasks,\nfour vision tasks, and three multimodal tasks using five pre-trained LLMs, we\ndemonstrate that $\\texttt{ORAL}$ generates high-quality LoRA parameters that\nachieve comparable or superior performance to vanilla trained counterparts.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,cs.CV","published":"2025-03-31T17:34:59Z"}
{"aid":"http://arxiv.org/abs/2503.24370v1","title":"Effectively Controlling Reasoning Models through Thinking Intervention","summary":"Reasoning-enhanced large language models (LLMs) explicitly generate\nintermediate reasoning steps prior to generating final answers, helping the\nmodel excel in complex problem-solving. In this paper, we demonstrate that this\nemerging generation framework offers a unique opportunity for more fine-grained\ncontrol over model behavior. We propose Thinking Intervention, a novel paradigm\ndesigned to explicitly guide the internal reasoning processes of LLMs by\nstrategically inserting or revising specific thinking tokens. We conduct\ncomprehensive evaluations across multiple tasks, including instruction\nfollowing on IFEval, instruction hierarchy on SEP, and safety alignment on\nXSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention\nsignificantly outperforms baseline prompting approaches, achieving up to 6.7%\naccuracy gains in instruction-following scenarios, 15.4% improvements in\nreasoning about instruction hierarchies, and a 40.0% increase in refusal rates\nfor unsafe prompts using open-source DeepSeek R1 models. Overall, our work\nopens a promising new research avenue for controlling reasoning LLMs.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-03-31T17:50:13Z"}
{"aid":"http://arxiv.org/abs/2503.24382v1","title":"Free360: Layered Gaussian Splatting for Unbounded 360-Degree View\n  Synthesis from Extremely Sparse and Unposed Views","summary":"Neural rendering has demonstrated remarkable success in high-quality 3D\nneural reconstruction and novel view synthesis with dense input views and\naccurate poses. However, applying it to extremely sparse, unposed views in\nunbounded 360{\\deg} scenes remains a challenging problem. In this paper, we\npropose a novel neural rendering framework to accomplish the unposed and\nextremely sparse-view 3D reconstruction in unbounded 360{\\deg} scenes. To\nresolve the spatial ambiguity inherent in unbounded scenes with sparse input\nviews, we propose a layered Gaussian-based representation to effectively model\nthe scene with distinct spatial layers. By employing a dense stereo\nreconstruction model to recover coarse geometry, we introduce a layer-specific\nbootstrap optimization to refine the noise and fill occluded regions in the\nreconstruction. Furthermore, we propose an iterative fusion of reconstruction\nand generation alongside an uncertainty-aware training approach to facilitate\nmutual conditioning and enhancement between these two processes. Comprehensive\nexperiments show that our approach outperforms existing state-of-the-art\nmethods in terms of rendering quality and surface reconstruction accuracy.\nProject page: https://zju3dv.github.io/free360/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2503.24383v1","title":"Two-color magneto-optical trapping of ytterbium atoms","summary":"We report laser cooling and trapping of ytterbium atoms in a two-color\nmagneto-optical trap (MOT). Benefited from both the broad singlet transition\n($^1\\text{S}_0\\rightarrow {}^1\\text{P}_1$) and the narrow intercombination\ntransition ($^1\\text{S}_0\\rightarrow {}^3\\text{P}_1$) of ytterbium atoms, the\ntwo-color MOT enables rapid loading and efficient cooling. We systematically\ninvestigate the shielding effect of the intercombination transition by\nexamining the atom loading and loss rates of single-color and two-color MOTs.\nOur findings are general and can be extended to other alkaline earth(-like)\natoms.","main_category":"physics.atom-ph","categories":"physics.atom-ph,cond-mat.quant-gas","published":"2025-03-31T17:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.01330v1","title":"Plasmonic Crystals with Tunable Band Gaps in the Grating Gate Transistor\n  Structures","summary":"We developed a hydrodynamic model of plasmonic crystals formed in the\ncurrent-driven grating gate transistor structures. The model demonstrates that\nthe quality factor of plasmonic resonances could be increased by using ungated\nregions with high electron densities connecting multiple plasmonic cavities.\nThe analytical and numerical calculations of the EM radiation absorption by the\nband plasmons show that the drive current makes all plasma modes optically\nactive by breaking the symmetry of the plasma oscillations. This effect results\nin splitting plasmon resonant absorption peaks revealing the gaps in the\nplasmonic band spectrum tunable by current. The analyzed design could achieve\nresonant behavior at room temperature for plasmonic crystals implemented in\nvarious material systems, including graphene, III-V, III-N materials, and\np-diamond. We argue that the resulting double-peak spectrum line in the\nterahertz range also facilitates the absorption at the gap frequency, typically\nin microwave range. Power pumping at the gap frequency enables excitation of\nthe gap plasmons, promoting frequency conversion from microwave to THz ranges.\nThe flexibility in the length of the ungated region for the investigated\nstructures allows for an effective coupling with THz radiation, with the metal\ngrating acting as a distributive resonant antenna. The applications of the\npresented results extend to THz communication systems, THz sensing and imaging,\nfrequency conversion systems, and other advanced THz plasmonic devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-02T03:30:41Z"}
{"aid":"http://arxiv.org/abs/2504.01334v1","title":"Structural stability in piecewise MÃ¶bius transformations","summary":"Structural stability of piecewise M\\\"obius transformations (PMTs) is\ninvestigated from several angles. A result about structural stability\nrestricted to the space of PMTs is obtained using hyperbolic features for the\ncomponent functions and the pre-singularities set, allowing a holomorphic\nmotion. Is it defined and analyzed for PMTs the analogous concept of J-stabilty\nfor rational maps, finding some relations with the general structural\nstability. The notions of hyperbolic and expansive PMTs are defined, showing\nthat they are not equivalent and none of them implies structural stability.\nCombining the previous results and analyzes, sufficient conditions are given\nfor structural stability. Finally, an example of structural stability in the\ncomplexified tent maps family is shown.","main_category":"math.DS","categories":"math.DS,math.CV","published":"2025-04-02T03:42:08Z"}
{"aid":"http://arxiv.org/abs/2504.01358v1","title":"3D Gaussian Inverse Rendering with Approximated Global Illumination","summary":"3D Gaussian Splatting shows great potential in reconstructing photo-realistic\n3D scenes. However, these methods typically bake illumination into their\nrepresentations, limiting their use for physically-based rendering and scene\nediting. Although recent inverse rendering approaches aim to decompose scenes\ninto material and lighting components, they often rely on simplifying\nassumptions that fail when editing. We present a novel approach that enables\nefficient global illumination for 3D Gaussians Splatting through screen-space\nray tracing. Our key insight is that a substantial amount of indirect light can\nbe traced back to surfaces visible within the current view frustum. Leveraging\nthis observation, we augment the direct shading computed by 3D Gaussians with\nMonte-Carlo screen-space ray-tracing to capture one-bounce indirect\nillumination. In this way, our method enables realistic global illumination\nwithout sacrificing the computational efficiency and editability benefits of 3D\nGaussians. Through experiments, we show that the screen-space approximation we\nutilize allows for indirect illumination and supports real-time rendering and\nediting. Code, data, and models will be made available at our project page:\nhttps://wuzirui.github.io/gs-ssr.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-02T05:02:25Z"}
{"aid":"http://arxiv.org/abs/2504.01365v1","title":"Inflation with Gauss-Bonnet correction: beyond slow-roll","summary":"If a coupling between the inflaton and the Gauss-Bonnet term is introduced,\nmany models of inflation that were ruled out by the most recent Planck data can\nbe made viable again. The predictions for the scalar spectral index and\ntensor-to-scalar ratio are typically computed using the slow-roll\napproximation. In this paper we instead study the full equations of motion and\ndetermine the necessary initial conditions for reasonable inflation epoch. We\nderive the conditions under which the Friedmann equation admits positive\nsolutions for the Hubble parameter. Then we study the possibility of the\ninflaton becoming trapped in a local potential minimum induced by the\nGauss-Bonnet term. Finally we demonstrate the results on monomial potential\nmodels with a quadratic and a quartic potential and show that the slow-roll\napproximation becomes imprecise in the quartic case.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-02T05:18:15Z"}
{"aid":"http://arxiv.org/abs/2504.01378v1","title":"A Control Barrier Function Approach to Constrained Resource Allocation\n  Problems in a Maximum Entropy Principle Framework","summary":"This paper presents a novel approach to solve capacitated facility location\nproblems (FLP) that encompass various resource allocation problems. FLPs are a\nclass of NP-hard combinatorial optimization problems, involving optimal\nplacement and assignment of a small number of facilities over a large number of\ndemand points, with each facility subject to upper and lower bounds on its\nresource utilization (e.g., the number of demand points it can serve). To\naddress the challenges posed by inequality constraints and the combinatorial\nnature of the solution space, we reformulate the problem as a dynamic control\ndesign problem, enabling structured constraint handling and enhanced solution\nefficiency. Our method integrates a Control Barrier Function (CBF) and Control\nLyapunov Function (CLF)-based framework with a maximum-entropy principle-based\nframework to ensure feasibility, optimality, and improved exploration of\nsolutions. Numerical experiments demonstrate that this approach significantly\nenhances computational efficiency, yielding better solutions and showing\nnegligible growth in computation time with problem size as compared to existing\nsolvers. These results highlight the potential of control-theoretic and\nentropy-based methods for large-scale facility location problems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T05:47:57Z"}
{"aid":"http://arxiv.org/abs/2504.01380v1","title":"FireGuard: A Generalized Microarchitecture for Fine-Grained Security\n  Analysis on OoO Superscalar Cores","summary":"High-performance security guarantees rely on hardware support. Generic\nprogrammable support for fine-grained instruction analysis has gained broad\ninterest in the literature as a fundamental building block for the security of\nfuture processors. Yet, implementation in real out-of-order (OoO) superscalar\nprocessors presents tough challenges that cannot be explored in highly abstract\nsimulators. We detail the challenges of implementing complex programmable\npathways without critical paths or contention. We then introduce FireGuard, the\nfirst implementation of fine-grained instruction analysis on a real OoO\nsuperscalar processor. We establish an end-to-end system, including\nmicroarchitecture, SoC, ISA and programming model. Experiments show that our\nsolution simultaneously ensures both security and performance of the system,\nwith parallel scalability. We examine the feasibility of building FireGuard\ninto modern SoCs: Apple's M1-Pro, Huawei's Kirin-960, and Intel's i7-12700F,\nwhere less than 1% silicon area is introduced. The Repo. of FireGuard's source\ncode: https://github.com/SEU-ACAL/reproduce-FireGuard-DAC-25.","main_category":"cs.CR","categories":"cs.CR,cs.AR","published":"2025-04-02T05:49:22Z"}
{"aid":"http://arxiv.org/abs/2504.01381v1","title":"Interstellar extinction toward MWC 148","summary":"We analyse high resolution optical spectra of MWC148 (optical counterpart of\nthe gamma-ray source HESS J0632+057) obtained at Observatoire de Haute Provence\nand Rozhen Observatory. We measure equivalent widths of 7 diffuse interstellar\nbands and estimate the interstellar extinction E_{B-V}=0.85 +/- 0.08.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-04-02T05:50:16Z"}
{"aid":"http://arxiv.org/abs/2504.01397v1","title":"Can the poltergeist mechanism produce observable GWs?","summary":"The enhancement of induced gravitational waves (GWs) occurs due to a sudden\ntransition from an early matter-dominated era to the radiation-dominated era.\nWe analyze the impact of the transition rate on the scalar potential. We find\nthat the finite transition duration suppresses the oscillation amplitude of the\nscalar potential, consequently suppressing the amplitude of the GW energy\nspectrum. By numerically solving the background and perturbation equations, we\ndemonstrate that the physically motivated models, such as the evaporation of\nprimordial black holes and the decay of Q-balls, cannot produce an observable\nGW signal.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T06:37:17Z"}
{"aid":"http://arxiv.org/abs/2504.01411v1","title":"General channel capacities from quantum channel-state duality","summary":"The quantum channel-state duality permits the characterization of a quantum\nprocess through a quantum state, referred to as a Choi state. This\ncharacteristic serves as the impetus for the quantum computing paradigm that\nutilizes Choi states as information sources. In this work, the fundamental\ntheorems regarding quantum channel capacity are proven when Choi states are\nconsidered as sources. This achievement enriches the set of capacities\nassociated with quantum channels. Moreover, it gives rise to novel\nopportunities for the comprehension of superadditivity phenomena and the\ndiscovery of new classes of quantum error-correction codes.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T06:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.01416v1","title":"DF-Calib: Targetless LiDAR-Camera Calibration via Depth Flow","summary":"Precise LiDAR-camera calibration is crucial for integrating these two sensors\ninto robotic systems to achieve robust perception. In applications like\nautonomous driving, online targetless calibration enables a prompt sensor\nmisalignment correction from mechanical vibrations without extra targets.\nHowever, existing methods exhibit limitations in effectively extracting\nconsistent features from LiDAR and camera data and fail to prioritize salient\nregions, compromising cross-modal alignment robustness. To address these\nissues, we propose DF-Calib, a LiDAR-camera calibration method that\nreformulates calibration as an intra-modality depth flow estimation problem.\nDF-Calib estimates a dense depth map from the camera image and completes the\nsparse LiDAR projected depth map, using a shared feature encoder to extract\nconsistent depth-to-depth features, effectively bridging the 2D-3D cross-modal\ngap. Additionally, we introduce a reliability map to prioritize valid pixels\nand propose a perceptually weighted sparse flow loss to enhance depth flow\nestimation. Experimental results across multiple datasets validate its accuracy\nand generalization,with DF-Calib achieving a mean translation error of 0.635cm\nand rotation error of 0.045 degrees on the KITTI dataset.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-02T07:09:44Z"}
{"aid":"http://arxiv.org/abs/2504.01422v1","title":"Optimization of BLE Broadcast Mode in Offline Finding Network","summary":"In the Offline Finding Network(OFN), offline Bluetooth tags broadcast to the\nsurrounding area, the finder devices receiving the broadcast signal and upload\nlocation information to the IoT(Internet of Things) cloud servers, thereby\nachieving offline finding of lost items. This process is essentially a\nBluetooth low energy (BLE) neighbor discovery process(NDP). In the process, the\nvariety of Bluetooth scan modes caused by the scan interval and scan window\nsettings affects the discovery latency of finder devices finding the tag\nbroadcast packets. To optimize the experience of searching for lost devices, we\npropose the CPBIS-mechanism, a certain proportion broadcast-intervals screening\nmechanism that calculates the most suitable two broadcast intervals and their\nproportion for offline tags. This reduces discovery latency in the BLE NDP,\nimproves the discovery success rate, further enhances the user experience. To\nour knowledge, we are the first to propose a comprehensive solution for\nconfiguring the broadcast interval parameters of advertisers in BLE NDP,\nparticularly for configurations involving two or more broadcast intervals. We\nevaluated the results obtained by CPBIS on the nRF52832 chip. The data shows\nthat the CPBIS-mechanism achieves relatively low discovery latencies for\nmultiple scan modes.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T07:13:22Z"}
{"aid":"http://arxiv.org/abs/2504.01430v1","title":"Asymptotic Error Bounds and Fractional-Bit Design for Fixed-Point\n  Grover's Quantum Algorithm Emulation","summary":"Quantum computing (QC) emulators, which simulate quantum algorithms on\nclassical hardware, are indispensable platforms for testing quantum algorithms\nbefore scalable quantum computers become widely available. A critical challenge\nin QC emulation is managing numerical errors from finite arithmetic precision,\nespecially truncation errors in resource-efficient fixed-point arithmetic.\nDespite its importance, systematic studies quantifying how truncation errors\nimpact quantum algorithm accuracy are limited. In this paper, we propose a\nrigorous quantitative framework analyzing truncation error propagation in\nfixed-point QC emulation, focusing on Grover's quantum search algorithm. First,\nwe introduce a simplified two-value amplitude representation of quantum states\nduring Grover's iterations and prove its theoretical validity. Using this\nrepresentation, we derive explicit mathematical expressions characterizing\ntruncation error accumulation across quantum gate operations. We quantify the\noverall emulation error by the $\\ell_2$ distance between ideal and emulated\nprobability distributions, obtaining asymptotic bounds scaling as $O(2^{n-f})$,\nwhere $n$ is the number of qubits and $f$ is fractional-bit precision.\nExtensive numerical simulations and empirical experiments on a practical\nfixed-point QC emulator confirm that observed errors precisely match our\ntheoretical predictions. Finally, we provide a closed-form formula to determine\nthe minimal fractional-bit precision required to achieve a specified error\nthreshold, offering clear guidelines for emulator designers balancing accuracy\nand resource utilization.","main_category":"quant-ph","categories":"quant-ph,cs.NA,math.NA","published":"2025-04-02T07:33:36Z"}
{"aid":"http://arxiv.org/abs/2504.01431v1","title":"Multi-convex Programming for Discrete Latent Factor Models Prototyping","summary":"Discrete latent factor models (DLFMs) are widely used in various domains such\nas machine learning, economics, neuroscience, psychology, etc. Currently,\nfitting a DLFM to some dataset relies on a customized solver for individual\nmodels, which requires lots of effort to implement and is limited to the\ntargeted specific instance of DLFMs. In this paper, we propose a generic\nframework based on CVXPY, which allows users to specify and solve the fitting\nproblem of a wide range of DLFMs, including both regression and classification\nmodels, within a very short script. Our framework is flexible and inherently\nsupports the integration of regularization terms and constraints on the DLFM\nparameters and latent factors, such that the users can easily prototype the\nDLFM structure according to their dataset and application scenario. We\nintroduce our open-source Python implementation and illustrate the framework in\nseveral examples.","main_category":"math.OC","categories":"math.OC,cs.CE,cs.LG","published":"2025-04-02T07:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.01433v1","title":"Reaction and interaction nucleus-nucleus cross sections in the complete\n  Glauber theory","summary":"The straightforward calculations of the reaction and interaction cross\nsections of the nuclear scattering are carried out in Glauber approach using\nthe generating function method. It allows for the resummation of all orders of\nGlauber theory. The results are obtained for $^4$He, $^{11}$Li, $^{12}$C\nscattering on $^{12}$C target. The difference between the reaction and the\ndifferential cross section is shown to be not exceeding several percents","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-02T07:34:53Z"}
{"aid":"http://arxiv.org/abs/2504.01436v1","title":"New perspectives on a classical embedding theorem","summary":"In this expository note, recent results of Kishimoto and Matsushita on\ntriangulated manifolds are linked to the classical criterion on the normal\nStiefel-Whitney classes for existence of an embedding of a smooth closed\nmanifold into Euclidean space of given dimension. We also look back at Atiyah's\nK-theoretic condition for the existence of a smooth embedding.","main_category":"math.GT","categories":"math.GT,math.AT","published":"2025-04-02T07:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.01437v1","title":"Behavioral Inequalities","summary":"We introduce behavioral inequalities as a way to model dynamical systems\ndefined by inequalities among their variables of interest. We claim that such a\nformulation enables the representation of safety-aware dynamical systems,\nsystems with bounds on disturbances, practical design limits and operational\nboundaries, etc. We develop a necessary and sufficient condition for the\nexistence of solutions to such behavioral inequalities and provide a\nparametrization of solutions when they exist. Finally, we show the efficacy of\nthe proposed method in two practical examples.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T07:43:22Z"}
{"aid":"http://arxiv.org/abs/2504.01441v1","title":"Locally- but not Globally-identified SVARs","summary":"This paper analyzes Structural Vector Autoregressions (SVARs) where\nidentification of structural parameters holds locally but not globally. In this\ncase there exists a set of isolated structural parameter points that are\nobservationally equivalent under the imposed restrictions. Although the data do\nnot inform us which observationally equivalent point should be selected, the\ncommon frequentist practice is to obtain one as a maximum likelihood estimate\nand perform impulse response analysis accordingly. For Bayesians, the lack of\nglobal identification translates to non-vanishing sensitivity of the posterior\nto the prior, and the multi-modal likelihood gives rise to computational\nchallenges as posterior sampling algorithms can fail to explore all the modes.\nThis paper overcomes these challenges by proposing novel estimation and\ninference procedures. We characterize a class of identifying restrictions and\ncircumstances that deliver local but non-global identification, and the\nresulting number of observationally equivalent parameter values. We propose\nalgorithms to exhaustively compute all admissible structural parameters given\nreduced-form parameters and utilize them to sample from the multi-modal\nposterior. In addition, viewing the set of observationally equivalent parameter\npoints as the identified set, we develop Bayesian and frequentist procedures\nfor inference on the corresponding set of impulse responses. An empirical\nexample illustrates our proposal.","main_category":"econ.EM","categories":"econ.EM","published":"2025-04-02T07:50:25Z"}
{"aid":"http://arxiv.org/abs/2504.01443v1","title":"Split Federated Learning for UAV-Enabled Integrated Sensing,\n  Computation, and Communication","summary":"Unmanned aerial vehicles (UAVs) with integrated sensing, computation, and\ncommunication (ISCC) capabilities have become key enablers of next-generation\nwireless networks. Federated edge learning (FEL) leverages UAVs as mobile\nlearning agents to collect data, perform local model updates, and contribute to\nglobal model aggregation. However, existing UAV-assisted FEL systems face\ncritical challenges, including excessive computational demands, privacy risks,\nand inefficient communication, primarily due to the requirement for full-model\ntraining on resource-constrained UAVs. To deal with aforementioned challenges,\nwe propose Split Federated Learning for UAV-Enabled ISCC (SFLSCC), a novel\nframework that integrates split federated learning (SFL) into UAV-assisted FEL.\nSFLSCC optimally partitions model training between UAVs and edge servers,\nsignificantly reducing UAVs' computational burden while preserving data\nprivacy. We conduct a theoretical analysis of UAV deployment, split point\nselection, data sensing volume, and client-side aggregation frequency, deriving\nclosed-form upper bounds for the convergence gap. Based on these insights, we\nconceive a joint optimization problem to minimize the energy consumption\nrequired to achieve a target model accuracy. Given the non-convex nature of the\nproblem, we develop a low-complexity algorithm to efficiently determine UAV\ndeployment, split point selection, and communication frequency. Extensive\nsimulations on a target motion recognition task validate the effectiveness of\nSFLSCC, demonstrating superior convergence performance and energy efficiency\ncompared to baseline methods.","main_category":"cs.DC","categories":"cs.DC,cs.ET","published":"2025-04-02T07:53:24Z"}
{"aid":"http://arxiv.org/abs/2504.01444v1","title":"PiCo: Jailbreaking Multimodal Large Language Models via\n  $\\textbf{Pi}$ctorial $\\textbf{Co}$de Contextualization","summary":"Multimodal Large Language Models (MLLMs), which integrate vision and other\nmodalities into Large Language Models (LLMs), significantly enhance AI\ncapabilities but also introduce new security vulnerabilities. By exploiting the\nvulnerabilities of the visual modality and the long-tail distribution\ncharacteristic of code training data, we present PiCo, a novel jailbreaking\nframework designed to progressively bypass multi-tiered defense mechanisms in\nadvanced MLLMs. PiCo employs a tier-by-tier jailbreak strategy, using\ntoken-level typographic attacks to evade input filtering and embedding harmful\nintent within programming context instructions to bypass runtime monitoring. To\ncomprehensively assess the impact of attacks, a new evaluation metric is\nfurther proposed to assess both the toxicity and helpfulness of model outputs\npost-attack. By embedding harmful intent within code-style visual instructions,\nPiCo achieves an average Attack Success Rate (ASR) of 84.13% on Gemini-Pro\nVision and 52.66% on GPT-4, surpassing previous methods. Experimental results\nhighlight the critical gaps in current defenses, underscoring the need for more\nrobust strategies to secure advanced MLLMs.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-02T07:54:32Z"}
{"aid":"http://arxiv.org/abs/2504.01452v1","title":"BiSeg-SAM: Weakly-Supervised Post-Processing Framework for Boosting\n  Binary Segmentation in Segment Anything Models","summary":"Accurate segmentation of polyps and skin lesions is essential for diagnosing\ncolorectal and skin cancers. While various segmentation methods for polyps and\nskin lesions using fully supervised deep learning techniques have been\ndeveloped, the pixel-level annotation of medical images by doctors is both\ntime-consuming and costly. Foundational vision models like the Segment Anything\nModel (SAM) have demonstrated superior performance; however, directly applying\nSAM to medical segmentation may not yield satisfactory results due to the lack\nof domain-specific medical knowledge. In this paper, we propose BiSeg-SAM, a\nSAM-guided weakly supervised prompting and boundary refinement network for the\nsegmentation of polyps and skin lesions. Specifically, we fine-tune SAM\ncombined with a CNN module to learn local features. We introduce a WeakBox with\ntwo functions: automatically generating box prompts for the SAM model and using\nour proposed Multi-choice Mask-to-Box (MM2B) transformation for rough\nmask-to-box conversion, addressing the mismatch between coarse labels and\nprecise predictions. Additionally, we apply scale consistency (SC) loss for\nprediction scale alignment. Our DetailRefine module enhances boundary precision\nand segmentation accuracy by refining coarse predictions using a limited amount\nof ground truth labels. This comprehensive approach enables BiSeg-SAM to\nachieve excellent multi-task segmentation performance. Our method demonstrates\nsignificant superiority over state-of-the-art (SOTA) methods when tested on\nfive polyp datasets and one skin cancer dataset.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-02T08:04:37Z"}
{"aid":"http://arxiv.org/abs/2504.01454v1","title":"Quantum Key Distribution with Efficient Post-Quantum\n  Cryptography-Secured Trusted Node on a Quantum Network","summary":"Quantum Key Distribution (QKD) enables two distant users to exchange a secret\nkey with information-theoretic security, based on the fundamental laws of\nquantum physics. While it is arguably the most mature application of quantum\ncryptography, it has inherent limitations in the achievable distance and the\nscalability to large-scale infrastructures. While the applicability of QKD can\nbe readily increased with the use of intermediary trusted nodes, this adds\nadditional privacy requirements on third parties. In this work, we present an\nefficient scheme leveraging a trusted node with lower privacy requirements\nthanks to the use of post-quantum cryptographic techniques, and implement it on\na deployed fiber optic quantum communication network in the Paris area.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T08:06:16Z"}
{"aid":"http://arxiv.org/abs/2504.01455v1","title":"Atmospheric dynamics of first steps toward terraforming Mars","summary":"Warming Mars' surface could be a step toward making it suitable for life, but\nwould represent a major science and engineering challenge. To warm Mars using\nengineered aerosol, particles released locally must disperse globally. The\nwinds that transport aerosol respond to the aerosol's radiative forcing,\nimplying strong radiative-dynamical feedbacks. Using a plume-tracking climate\nmodel without a water cycle, we investigate radiative-dynamical feedback from\nsurface release of two particle compositions: graphene (which attenuates UV)\nand aluminum. Both compositions can give fast global warming of ~30 K. We infer\nthat 2 liters/second release rate of graphene made from Mars' atmosphere via\nCO2-electrolysis could double Mars' greenhouse effect (+5 K). Self-lofting\nhelps particles rise and spread. The Hadley cell strengthens under warming,\naiding mixing. Warming can be focused in latitude by tuning particle size.\nWithin our model, Mars radiative-dynamical feedbacks enable engineered-aerosol\nwarming. Challenges remain, including functionalization, agglomeration,\ndry-deposition experiments, and modeling water cycle feedbacks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.geo-ph","published":"2025-04-02T08:06:35Z"}
{"aid":"http://arxiv.org/abs/2504.01473v1","title":"Cat-Eye Inspired Active-Passive-Composite Aperture-Shared Sub-Terahertz\n  Meta-Imager for Non-Interactive Concealed Object Detection","summary":"Within the feline eye, a distinctive tapetum lucidum as a mirror resides\nposterior to the retina, reflecting the incident rays to simulate light source\nemission. This secondary emission property enables felines to be highly\nsensitive to light, possessing remarkable visual capabilities even in dark\nsettings. Drawing inspiration from this natural phenomenon, we propose an\nactive-passive-composite sub-terahertz meta-imager integrated with a bifocus\nmetasurface, a high-sensitivity radiometer, and a low-power signal hidden\nradiation source. Benefiting from its aperture-shared advantage, this advanced\nfusion imaging system, enabled to be deployed by a simplified portable hardware\nplatform, allows for the concurrent acquisition of active and passive\nelectromagnetic properties to extend the target detection category and realize\nmulti-mode fusion perception. Notably, it also enables the extraction of\nradiation and reflection characteristics without additional calibration\nmodules. Experiments demonstrate the multi-target fusion imaging and localized\ninformation decoupling with the tailored field of view and emission energy.\nThis compact and multi-mode fusion imaging system may have plenty of potential\nfor airplane navigation positioning, abnormal monitoring, and non-interactive\nconcealed security checks.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T08:27:25Z"}
{"aid":"http://arxiv.org/abs/2504.01478v1","title":"Chemical Components in the Virgo Overdensity and Hercules-Aquila Cloud:\n  hints of more than one merger event in GSE-like debris","summary":"Using elemental abundances for 1.26 million K giants in the LAMOST DR8\nvalue-added catalog, we analyze the chemical abundances of the Virgo\nOverdensity (VOD) and Hercules-Aquila Cloud (HAC). We find two distinct\nchemical populations in both overdensities, which is in disagreement with the\nmainstream hypothesis that both overdensities are composed of materials from a\nsingle merger event, namely Gaia-Sausage-Enceladus (GSE). The two populations\nshow different chemical trends: one exhibits low metallicities and high\n$\\alpha$ abundances, and the other shows high metallicities and low $\\alpha$\nabundances, which is associated with the recently discovered Nereus and Virgo\nRadial Merger (VRM) components in the local stellar halo, respectively. The\nNereus component in these overdensities uniquely exhibits a decreasing trend in\nthe [Fe/H]-[Mn/Fe] plane. Out of all observed Milky Way dwarf galaxies, this\ntrend is only found in the Sculptor dwarf galaxy, which provides clues for the\nproperties of Nereus progenitor. We also find that the velocity ellipse with\nhigh aniostropy parameters that is usually considered to be part of GSE are\nactually a mix of the two components. Both overdensities are well-mixed in\nkinematic spaces, confirming recent claims that the debris of merger pairs are\nkinematically indistinguishable in a recent simulation. We find that the\nvelocity ellipses of the VRM stars in these overdensities have large\ninclination angles, which may be an indication of the merger time in simulated\nmerger events.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T08:34:47Z"}
{"aid":"http://arxiv.org/abs/2504.01493v1","title":"Shape derivative for the Dirichlet-to-Neumann operator on a manifold and\n  application to cellular protrusion","summary":"We establish a shape-derivative formula for the Dirichlet-to-Neumann operator\non a compact manifold. Then, we apply this formula to obtain the well-posedness\nin H 1 under a specific Rayleigh-Taylor condition to an equation describing\ncell protrusions. This equation is a generalisation of the theoretical part of\n[9] to any -2D as well as 3D-surfaces.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T08:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.01498v1","title":"On critical maps of the horizontal energy functional between Riemannian\n  foliations","summary":"In this paper, we consider critical points of the\n  horizontal energy $E_{\\HH}(f)$ for a smooth map $f$ between two Riemannian\n  foliations. These critical points are referred to as horizontally harmonic\n  maps. In particular, if the maps are foliated, they become transversally\n  harmonic maps. By utilizing the stress-energy tensor, we establish some\n  monotonicity formulas for horizontally harmonic maps from Euclidean spaces,\n  the quotients $K_{m}$ of Heisenberg groups and also for transversally\n  harmonic maps from Riemannian foliations with appropriate curvature pinching\n  conditions. Finally, we give Jin-type theorems for either horizontally\n  harmonic maps or transversally harmonic maps under some asymptotic\n  conditions at infinity.","main_category":"math.DG","categories":"math.DG","published":"2025-04-02T08:50:59Z"}
{"aid":"http://arxiv.org/abs/2504.01499v1","title":"The de Rham cohomology of covers with cyclic $p$-Sylow subgroup","summary":"Let $X$ be a smooth projective curve over a field $k$ with an action of a\nfinite group $G$. A well-known result of Chevalley and Weil describes the\n$k[G]$-module structure of cohomologies of $X$ in the case when the\ncharacteristic of $k$ does not divide $\\# G$. It is unlikely that such a\nformula can be derived in the general case, since the representation theory of\ngroups with non-cyclic $p$-Sylow subgroups is wild in characteristic $p$. The\ngoal of this article is to show that when $G$ has a cyclic $p$-Sylow subgroup,\nthe $G$-structure of the de Rham cohomology of $X$ is completely determined by\nthe ramification data. In principle, this leads to new formulas in the spirit\nof Chevalley and Weil for such curves. We provide such an explicit description\nof the de Rham cohomology in the cases when $G = \\mathbb Z/p^n$ and when the\n$p$-Sylow subgroup of $G$ is normal of order $p$.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-02T08:51:33Z"}
{"aid":"http://arxiv.org/abs/2504.01507v1","title":"Grasping by Spiraling: Reproducing Elephant Movements with Rigid-Soft\n  Robot Synergy","summary":"The logarithmic spiral is observed as a common pattern in several living\nbeings across kingdoms and species. Some examples include fern shoots,\nprehensile tails, and soft limbs like octopus arms and elephant trunks. In the\nlatter cases, spiraling is also used for grasping. Motivated by how this\nstrategy simplifies behavior into kinematic primitives and combines them to\ndevelop smart grasping movements, this work focuses on the elephant trunk,\nwhich is more deeply investigated in the literature. We present a soft arm\ncombined with a rigid robotic system to replicate elephant grasping\ncapabilities based on the combination of a soft trunk with a solid body. In our\nsystem, the rigid arm ensures positioning and orientation, mimicking the role\nof the elephant's head, while the soft manipulator reproduces trunk motion\nprimitives of bending and twisting under proper actuation patterns. This\nsynergy replicates 9 distinct elephant grasping strategies reported in the\nliterature, accommodating objects of varying shapes and sizes. The synergistic\ninteraction between the rigid and soft components of the system minimizes the\ncontrol complexity while maintaining a high degree of adaptability.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T08:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.01512v1","title":"High-fidelity 3D Object Generation from Single Image with RGBN-Volume\n  Gaussian Reconstruction Model","summary":"Recently single-view 3D generation via Gaussian splatting has emerged and\ndeveloped quickly. They learn 3D Gaussians from 2D RGB images generated from\npre-trained multi-view diffusion (MVD) models, and have shown a promising\navenue for 3D generation through a single image. Despite the current progress,\nthese methods still suffer from the inconsistency jointly caused by the\ngeometric ambiguity in the 2D images, and the lack of structure of 3D\nGaussians, leading to distorted and blurry 3D object generation. In this paper,\nwe propose to fix these issues by GS-RGBN, a new RGBN-volume Gaussian\nReconstruction Model designed to generate high-fidelity 3D objects from\nsingle-view images. Our key insight is a structured 3D representation can\nsimultaneously mitigate the afore-mentioned two issues. To this end, we propose\na novel hybrid Voxel-Gaussian representation, where a 3D voxel representation\ncontains explicit 3D geometric information, eliminating the geometric ambiguity\nfrom 2D images. It also structures Gaussians during learning so that the\noptimization tends to find better local optima. Our 3D voxel representation is\nobtained by a fusion module that aligns RGB features and surface normal\nfeatures, both of which can be estimated from 2D images. Extensive experiments\ndemonstrate the superiority of our methods over prior works in terms of\nhigh-quality reconstruction results, robust generalization, and good\nefficiency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:58:34Z"}
{"aid":"http://arxiv.org/abs/2504.01521v1","title":"Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion\n  Model","summary":"Recent advancements in diffusion models have revolutionized generative\nmodeling. However, the impressive and vivid outputs they produce often come at\nthe cost of significant model scaling and increased computational demands.\nConsequently, building personalized diffusion models based on off-the-shelf\nmodels has emerged as an appealing alternative. In this paper, we introduce a\nnovel perspective on conditional generation for transferring a pre-trained\nmodel. From this viewpoint, we propose *Domain Guidance*, a straightforward\ntransfer approach that leverages pre-trained knowledge to guide the sampling\nprocess toward the target domain. Domain Guidance shares a formulation similar\nto advanced classifier-free guidance, facilitating better domain alignment and\nhigher-quality generations. We provide both empirical and theoretical analyses\nof the mechanisms behind Domain Guidance. Our experimental results demonstrate\nits substantial effectiveness across various transfer benchmarks, achieving\nover a 19.6% improvement in FID and a 23.4% improvement in FD$_\\text{DINOv2}$\ncompared to standard fine-tuning. Notably, existing fine-tuned models can\nseamlessly integrate Domain Guidance to leverage these benefits, without\nadditional training.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-02T09:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.01542v1","title":"Register Always Matters: Analysis of LLM Pretraining Data Through the\n  Lens of Language Variation","summary":"Pretraining data curation is a cornerstone in Large Language Model (LLM)\ndevelopment, leading to growing research on quality filtering of large web\ncorpora. From statistical quality flags to LLM-based labeling systems, datasets\nare divided into categories, frequently reducing to a binary: those passing the\nfilters deemed as valuable examples, others discarded as useless or\ndetrimental. However, a more detailed understanding of the contribution of\ndifferent kinds of texts to model performance is still largely lacking. In this\narticle, we present the first study utilizing registers (also known as genres)\n- a widely used standard in corpus linguistics to model linguistic variation -\nto curate pretraining datasets and investigate the effect of register on the\nperformance of LLMs. We perform comparative studies by training models with\nregister classified data and evaluating them using standard benchmarks, and\nshow that the register of pretraining data substantially affects model\nperformance. We uncover surprising relationships between the pretraining\nmaterial and the resulting models: using the News register results in subpar\nperformance, and on the contrary, including the Opinion class, covering texts\nsuch as reviews and opinion blogs, is highly beneficial. While a model trained\non the entire unfiltered dataset outperforms those trained on datasets limited\nto a single register, combining well-performing registers like\nHow-to-Instructions, Informational Description, and Opinion leads to major\nimprovements. Furthermore, analysis of individual benchmark results reveals key\ndifferences in the strengths and drawbacks of specific register classes as\npretraining data. These findings show that register is an important explainer\nof model variation and can facilitate more deliberate future data selection\npractices.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T09:30:24Z"}
{"aid":"http://arxiv.org/abs/2504.01553v1","title":"Bhakti: A Lightweight Vector Database Management System for Endowing\n  Large Language Models with Semantic Search Capabilities and Memory","summary":"With the rapid development of big data and artificial intelligence\ntechnologies, the demand for effective processing and retrieval of vector data\nis growing. Against this backdrop, I have developed the Bhakti vector database,\naiming to provide a lightweight and easy-to-deploy solution to meet the storage\nand semantic search needs of small and medium-sized datasets. Bhakti supports a\nvariety of similarity calculation methods and a domain-specific language (DSL)\nfor document-based pattern matching pre-filtering, facilitating migration of\ndata with its portable data files, flexible data management and seamless\nintegration with Python3. Furthermore, I propose a memory-enhanced large\nlanguage model dialogue solution based on the Bhakti database, which can assign\ndifferent weights to the question and answer in dialogue history, achieving\nfine-grained control over the semantic importance of each segment in a single\ndialogue history. Through experimental validation, my method shows significant\nperformance in the application of semantic search and question-answering\nsystems. Although there are limitations in processing large datasets, such as\nnot supporting approximate calculation methods like HNSW, the lightweight\nnature of Bhakti gives it a clear advantage in scenarios involving small and\nmedium-sized datasets.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T09:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.01555v1","title":"Bifurcation from multiple eigenvalues of rotating traveling waves on a\n  capillary liquid drop","summary":"We consider the free boundary problem for a liquid drop of nearly spherical\nshape with capillarity, and we study the existence of nontrivial (i.e., non\nspherical) rotating traveling profiles bifurcating from the spherical shape,\nwhere the bifurcation parameter is the angular velocity. We prove that every\neigenvalue of the linearized problem is a bifurcation point, extending the\nknown result for simple eigenvalues to the general case of eigenvalues of any\nmultiplicity. We also obtain a lower bound on the number of bifurcating\nsolutions. The proof is based on the Hamiltonian structure of the problem and\non the variational argument of constrained critical points for traveling waves\nof Craig and Nicholls (2000, SIAM J. Math. Anal. 32, 323-359), adapted to the\nnearly spherical geometry; in particular, the role of the action functional is\nplayed here by the angular momentum with respect to the rotation axis.\nMoreover, the bifurcation equation presents a 2-dimensional degeneration,\nrelated to some symmetries of the physical problem. This additional difficulty\nis overcome thanks to a crucial transversality property, obtained by using the\nHamiltonian structure and the prime integrals corresponding to those symmetries\nby Noether theorem, which are the fluid mass and the component along the\nrotation axis of the velocity of the fluid barycenter.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T09:54:20Z"}
{"aid":"http://arxiv.org/abs/2504.01560v1","title":"Optimizing Package Delivery with Quantum Annealers: Addressing\n  Time-Windows and Simultaneous Pickup and Delivery","summary":"Recent research at the intersection of quantum computing and routing problems\nhas been highly prolific. Much of this work focuses on classical problems such\nas the Traveling Salesman Problem and the Vehicle Routing Problem. The\npractical applicability of these problems depends on the specific objectives\nand constraints considered. However, it is undeniable that translating complex\nreal-world requirements into these classical formulations often proves\nchallenging. In this paper, we resort to our previously published\nquantum-classical technique for addressing real-world-oriented routing\nproblems, known as Quantum for Real Package Delivery (Q4RPD), and elaborate on\nsolving additional realistic problem instances. Accordingly, this paper\nemphasizes the following characteristics: i) simultaneous pickup and\ndeliveries, ii) time-windows, and iii) mobility restrictions by vehicle type.\nTo illustrate the application of Q4RPD, we have conducted an experimentation\ncomprising seven instances, serving as a demonstration of the newly developed\nfeatures.","main_category":"cs.ET","categories":"cs.ET,cs.AI","published":"2025-04-02T10:01:34Z"}
{"aid":"http://arxiv.org/abs/2504.01561v1","title":"STPNet: Scale-aware Text Prompt Network for Medical Image Segmentation","summary":"Accurate segmentation of lesions plays a critical role in medical image\nanalysis and diagnosis. Traditional segmentation approaches that rely solely on\nvisual features often struggle with the inherent uncertainty in lesion\ndistribution and size. To address these issues, we propose STPNet, a\nScale-aware Text Prompt Network that leverages vision-language modeling to\nenhance medical image segmentation. Our approach utilizes multi-scale textual\ndescriptions to guide lesion localization and employs retrieval-segmentation\njoint learning to bridge the semantic gap between visual and linguistic\nmodalities. Crucially, STPNet retrieves relevant textual information from a\nspecialized medical text repository during training, eliminating the need for\ntext input during inference while retaining the benefits of cross-modal\nlearning. We evaluate STPNet on three datasets: COVID-Xray, COVID-CT, and\nKvasir-SEG. Experimental results show that our vision-language approach\noutperforms state-of-the-art segmentation methods, demonstrating the\neffectiveness of incorporating textual semantic knowledge into medical image\nanalysis. The code has been made publicly on\nhttps://github.com/HUANGLIZI/STPNet.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-02T10:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.01567v1","title":"Quantum Computing for Optimizing Aircraft Loading","summary":"The aircraft loading optimization problem is a computationally hard problem\nwith the best known classical algorithm scaling exponentially with the number\nof objects. We propose a quantum approach based on a multi-angle variant of the\nQAOA algorithm (Multi-Angle Layered Variational Quantum Algorithm (MAL-VQA))\ndesigned to utilize a smaller number of two qubit gates in the quantum circuit\nas compared to the standard QAOA algorithm so that the quantum optimization\nalgorithm can be run on near-term ion-trap quantum processing units (QPU). We\nalso describe a novel cost function implementation that can handle many\ndifferent types of inequality constraints without the overhead of introducing\nslack variables in the quantum circuit so that larger problems with complex\nconstraints may be represented on near-term QPUs which have low qubit counts.\nWe demonstrate the performance of the algorithm on different instances of the\naircraft loading problem by execution on IonQ QPUs Aria and Forte. Our\nexperiments obtain the optimal solutions for all the problem instances studied\nranging from 12 qubits to 28 qubits. This shows the potential scalability of\nthe method to significantly larger problem sizes with the improvement of\nquantum hardware in the near future as well as the robustness of the quantum\nalgorithm against varying initial guesses and varying constraints of different\nproblem instances.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-02T10:10:11Z"}
{"aid":"http://arxiv.org/abs/2504.01577v1","title":"Instance Migration Diffusion for Nuclear Instance Segmentation in\n  Pathology","summary":"Nuclear instance segmentation plays a vital role in disease diagnosis within\ndigital pathology. However, limited labeled data in pathological images\nrestricts the overall performance of nuclear instance segmentation. To tackle\nthis challenge, we propose a novel data augmentation framework Instance\nMigration Diffusion Model (IM-Diffusion), IM-Diffusion designed to generate\nmore varied pathological images by constructing diverse nuclear layouts and\ninternuclear spatial relationships. In detail, we introduce a Nuclear Migration\nModule (NMM) which constructs diverse nuclear layouts by simulating the process\nof nuclear migration. Building on this, we further present an\nInternuclear-regions Inpainting Module (IIM) to generate diverse internuclear\nspatial relationships by structure-aware inpainting. On the basis of the above,\nIM-Diffusion generates more diverse pathological images with different layouts\nand internuclear spatial relationships, thereby facilitating downstream tasks.\nEvaluation on the CoNSeP and GLySAC datasets demonstrate that the images\ngenerated by IM-Diffusion effectively enhance overall instance segmentation\nperformance. Code will be made public later.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-02T10:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.01584v1","title":"Higher-order topological phases for time-reversal-symmetry breaking\n  superconductivity in UTe$_2$","summary":"The recent discovery of heavy-fermion superconductor UTe$_2$ has broadened\nthe possibility of realizing exotic time-reversal-symmetry-breaking\nsuperconductivity. However, a comprehensive understanding of the topological\nphases in the superconducting states of UTe$_2$ is still lacking. Here, we\npresent an exhaustive classification of topological phases for all\ntime-reversal symmetry breaking pairing symmetries of UTe$_2$. Using the K\ntheoretical classification approach, we uncover that 25 out of 36 possible\npairing states are classified as higher-order topological phases, with some\ndemonstrating hybrid-order topology through an intricate interplay of hinge and\ncorner states. Furthermore, under the weak-coupling condition of the pair\npotentials, the possible pairing symmetries are constrained to $B_{ju} + i\nB_{ku}$, $A_{u} + i B_{j u}$, and $B_{j g} + iA_u$ ($j,k = 1,2,3$; $j \\neq k$),\nwhere these symbols denote the irreducible representations of the point group\n$D_{2h}$. For these pairing states, the topological invariants are related to\nthe Fermi surface topology via the Fermi-surface formula, enabling us to\nsystematically diagnose higher-order topological phases. Using a tight-binding\nmodel, we demonstrate the higher-order topological phases of the mixed-parity\n$A_u + iB_{1g}$ superconductors, where the second-order and hybrid-order\ntopological phases emerge as the number of Fermi surfaces enclosing the\ntime-reversal invariant momentum evolves from two to four. The findings suggest\nthat UTe$_2$ serves as a compelling platform for exploring higher-order\ntopological superconductors with diverse topological surface states.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T10:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.01587v1","title":"Modeling Urban Population Dynamics and City-to-City Migration","summary":"Migration plays a crucial role in urban growth. Over time, individuals opting\nto relocate led to vast metropolises like London and Paris during the\nIndustrial Revolution, Shanghai and Karachi during the last decades and\nthousands of smaller settlements. Here, we analyze the impact that migration\nhas on population redistribution. We use a model of city-to-city migration as a\nprocess that occurs within a network, where the nodes represent cities, and the\nedges correspond to the flux of individuals. We analyze metrics characterizing\nthe urban distribution and show how a slight preference for some destinations\nmight result in the observed distribution of the population.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-02T10:45:14Z"}
{"aid":"http://arxiv.org/abs/2504.01590v1","title":"KTaO3(001) Preparation Methods in Vacuum: Effects on Surface\n  Stoichiometry, Crystallography, and in-gap States","summary":"KTaO3 single crystals with different orientations are used as substrates for\nthe epitaxial growth of thin films and/or as hosts for two-dimensional electron\ngases. Due to the polar nature of the KTaO3(001) surface, one can expect\ndifficulties and challenges to arise in its preparation. Maintaining good\ninsulating characteristics without adding undesirable in-gap electronic states,\nobtaining good crystalline order up to the top surface layer, a sufficiently\nflat surface, and complete cleanliness of the surface (without water, C or OH\ncontaminants), are in general difficult conditions to accomplish\nsimultaneously. Cleaving in vacuum is likely the best option for obtaining a\nclean surface. However, since KTaO3 is cubic and lacks a well-defined cleavage\nplane, this method is notsuitable for sample growth or reproducible device\nfabrication. Here, we systematically evaluate the effect of typical preparation\nmethods applied on the surfaces of KTaO3(001) single crystals. In particular,\nwe used annealing in vacuum at different temperatures, light sputtering with\nAr+ ions at low energy (500 eV) followed by annealing, heavy Ar+ ion\nbombardment and annealing, and grazing Ar+ ion bombardment under continuous\nazimuthal rotation combined with both annealing in vacuum and in O2 atmosphere.\nPossible side effects after each treatment are evaluated by a combination of\ntechniques, including low-energy ion scattering at forward angles, Auger\nelectron spectroscopy, low-energy electron energy loss, X-ray photoelectron\nspectroscopy, low-energy electron diffraction, and time of flightsecondary ion\nmass spectrometry. Advantages and shortcomings of each preparation method are\ndiscussed in detail.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T10:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.01652v1","title":"Market-Oriented Flow Allocation for Thermal Solar Plants: An\n  Auction-Based Methodology with Artificial Intelligence","summary":"This paper presents a novel method to optimize thermal balance in parabolic\ntrough collector (PTC) plants. It uses a market-based system to distribute flow\namong loops combined with an artificial neural network (ANN) to reduce\ncomputation and data requirements. This auction-based approach balances loop\ntemperatures, accommodating varying thermal losses and collector efficiencies.\nValidation across different thermal losses, optical efficiencies, and\nirradiance conditions-sunny, partially cloudy, and cloudy-show improved thermal\npower output and intercept factors compared to a no-allocation system. It\ndemonstrates scalability and practicality for large solar thermal plants,\nenhancing overall performance. The method was first validated through\nsimulations on a realistic solar plant model, then adapted and successfully\ntested in a 50 MW solar trough plant, demonstrating its advantages.\nFurthermore, the algorithms have been implemented, commissioned, and are\ncurrently operating in 13 commercial solar trough plants.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-02T12:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.01661v1","title":"Limit cycles bifurcating from the quasi-homogeneous polynomial centers\n  of weight-degree 2 under non-smooth perturbations","summary":"We investigate the maximum number of limit cycles bifurcating from the period\nannulus of a family of cubic polynomial differential centers when it is\nperturbed inside the class of all cubic piecewise smooth polynomials. The\nfamily considered is the unique family of weight-homogeneous polynomial\ndifferential systems of weight-degree 2 with a center. When the switching line\nis $x=0$ or $y=0$, we obtain the sharp bounds of the number of limit cycles for\nthe perturbed systems by using the first order averaging method. Our results\nindicate that non-smooth systems can have more limit cycles than smooth ones,\nand the switching lines play an important role in the dynamics of non-smooth\nsystems.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T12:13:29Z"}
{"aid":"http://arxiv.org/abs/2504.01671v1","title":"Anomaly Detection for Hybrid Butterfly Subspecies via Probability\n  Filtering","summary":"Detecting butterfly hybrids requires knowledge of the parent subspecies, and\nthe process can be tedious when encountering a new subspecies. This study\nfocuses on a specific scenario where a model trained to recognize hybrid\nspecies A can generalize to species B when B biologically mimics A. Since\nspecies A and B share similar patterns, we leverage BioCLIP as our feature\nextractor to capture features based on their taxonomy. Consequently, the\nalgorithm designed for species A can be transferred to B, as their hybrid and\nnon-hybrid patterns exhibit similar relationships. To determine whether a\nbutterfly is a hybrid, we adopt proposed probability filtering and color\njittering to augment and simulate the mimicry. With these approaches, we\nachieve second place in the official development phase. Our code is publicly\navailable at https://github.com/Justin900429/NSF-HDR-Challenge.","main_category":"cs.CE","categories":"cs.CE,cs.AI","published":"2025-04-02T12:18:44Z"}
{"aid":"http://arxiv.org/abs/2504.01677v1","title":"System Level Synthesis for Affine Control Policies: Model Based and\n  Data-Driven Settings","summary":"There is an increasing need for effective control of systems with complex\ndynamics, particularly through data-driven approaches. System Level Synthesis\n(SLS) has emerged as a powerful framework that facilitates the control of\nlarge-scale systems while accounting for model uncertainties. SLS approaches\nare currently limited to linear systems and time-varying linear control\npolicies, thus limiting the class of achievable control strategies. We\nintroduce a novel closed-loop parameterization for time-varying affine control\npolicies, extending the SLS framework to a broader class of systems and\npolicies. We show that the closed-loop behavior under affine policies can be\nequivalently characterized using past system trajectories, enabling a fully\ndata-driven formulation. This parameterization seamlessly integrates affine\npolicies into optimal control problems, allowing for a closed-loop formulation\nof general Model Predictive Control (MPC) problems. To the best of our\nknowledge, this is the first work to extend SLS to affine policies in both\nmodel-based and data-driven settings, enabling an equivalent formulation of MPC\nproblems using closed-loop maps. We validate our approach through numerical\nexperiments, demonstrating that our model-based and data-driven affine SLS\nformulations achieve performance on par with traditional model-based MPC.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T12:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.01690v1","title":"Token Pruning in Audio Transformers: Optimizing Performance and Decoding\n  Patch Importance","summary":"Vision Transformers (ViTs) have achieved state-of-the-art performance across\nvarious computer vision tasks, but their high computational cost remains a\nchallenge. Token pruning has been proposed to reduce this cost by selectively\nremoving less important tokens. While effective in vision tasks by discarding\nnon-object regions, applying this technique to audio tasks presents unique\nchallenges, as distinguishing relevant from irrelevant regions in\ntime-frequency representations is less straightforward. In this study, for the\nfirst time, we applied token pruning to ViT-based audio classification models\nusing Mel-spectrograms and analyzed the trade-offs between model performance\nand computational cost: TopK token pruning can reduce MAC operations of\nAudioMAE and AST by 30-40%, with less than a 1% drop in classification\naccuracy. Our analysis reveals that while high-intensity tokens contribute\nsignificantly to model accuracy, low-intensity tokens remain important. In\nparticular, they play a more critical role in general audio classification\ntasks than in speech-specific tasks.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-02T12:44:38Z"}
{"aid":"http://arxiv.org/abs/2504.01700v1","title":"Reasoning LLMs for User-Aware Multimodal Conversational Agents","summary":"Personalization in social robotics is critical for fostering effective\nhuman-robot interactions, yet systems often face the cold start problem, where\ninitial user preferences or characteristics are unavailable. This paper\nproposes a novel framework called USER-LLM R1 for a user-aware conversational\nagent that addresses this challenge through dynamic user profiling and model\ninitiation. Our approach integrates chain-of-thought (CoT) reasoning models to\niteratively infer user preferences and vision-language models (VLMs) to\ninitialize user profiles from multimodal inputs, enabling personalized\ninteractions from the first encounter. Leveraging a Retrieval-Augmented\nGeneration (RAG) architecture, the system dynamically refines user\nrepresentations within an inherent CoT process, ensuring contextually relevant\nand adaptive responses. Evaluations on the ElderlyTech-VQA Bench demonstrate\nsignificant improvements in ROUGE-1 (+23.2%), ROUGE-2 (+0.6%), and ROUGE-L\n(+8%) F1 scores over state-of-the-art baselines, with ablation studies\nunderscoring the impact of reasoning model size on performance. Human\nevaluations further validate the framework's efficacy, particularly for elderly\nusers, where tailored responses enhance engagement and trust. Ethical\nconsiderations, including privacy preservation and bias mitigation, are\nrigorously discussed and addressed to ensure responsible deployment.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.RO","published":"2025-04-02T13:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.01726v1","title":"Shared-Memory Hierarchical Process Mapping","summary":"Modern large-scale scientific applications consist of thousands to millions\nof individual tasks. These tasks involve not only computation but also\ncommunication with one another. Typically, the communication pattern between\ntasks is sparse and can be determined in advance. Such applications are\nexecuted on supercomputers, which are often organized in a hierarchical\nhardware topology, consisting of islands, racks, nodes, and processors, where\nprocessing elements reside. To ensure efficient workload distribution, tasks\nmust be allocated to processing elements in a way that ensures balanced\nutilization. However, this approach optimizes only the workload, not the\ncommunication cost of the application. It is straightforward to see that\nplacing groups of tasks that frequently exchange large amounts of data on\nprocessing elements located near each other is beneficial. The problem of\nmapping tasks to processing elements considering optimization goals is called\nprocess mapping. In this work, we focus on minimizing communication cost while\nevenly distributing work. We present the first shared-memory algorithm that\nutilizes hierarchical multisection to partition the communication model across\nprocessing elements. Our parallel approach achieves the best solution on 95\npercent of instances while also being marginally faster than the next best\nalgorithm. Even in a serial setting, it delivers the best solution quality\nwhile also outperforming previous serial algorithms in speed.","main_category":"cs.DC","categories":"cs.DC,cs.DS","published":"2025-04-02T13:33:21Z"}
{"aid":"http://arxiv.org/abs/2504.01731v1","title":"The protein escape process at the ribosomal exit tunnel has conserved\n  mechanisms across the domains of life","summary":"The ribosomal exit tunnel is the primary structure affecting the release of\nnascent proteins at the ribosome. The ribosomal exit tunnels from different\nspecies have elements of conservation and differentiation in structural and\nphysico-chemical properties. In this study, by simulating the elongation and\nescape processes of nascent proteins at the ribosomal exit tunnels of four\ndifferent organisms, we show that the escape process has conserved mechanisms\nacross the domains of life. Specifically, it is found that the escape process\nof proteins follows the diffusion mechanism given by a simple diffusion model\nand the median escape time positively correlates with the number of hydrophobic\nresidues and the net charge of a protein for all the exit tunnels considered.\nThese properties hold for twelve distinct proteins considered in two slightly\ndifferent and improved G\\=o-like models. It is also found that the differences\nin physico-chemical properties of the tunnels lead to quantitative differences\nin the protein escape times. In particular, the relatively strong\nhydrophobicity of the E. coli's tunnel and the unusually high number of\nnegatively charged amino acids on the tunnel's surface of H. marismortui lead\nto substantially slower escapes of proteins at these tunnels than at those of\nS. cerevisisae and H. sapiens.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T13:40:58Z"}
{"aid":"http://arxiv.org/abs/2504.01740v1","title":"Stable Structure Learning with HC-Stable and Tabu-Stable Algorithms","summary":"Many Bayesian Network structure learning algorithms are unstable, with the\nlearned graph sensitive to arbitrary dataset artifacts, such as the ordering of\ncolumns (i.e., variable order). PC-Stable attempts to address this issue for\nthe widely-used PC algorithm, prompting researchers to use the \"stable\" version\ninstead. However, this problem seems to have been overlooked for score-based\nalgorithms. In this study, we show that some widely-used score-based\nalgorithms, as well as hybrid and constraint-based algorithms, including\nPC-Stable, suffer from the same issue. We propose a novel solution for\nscore-based greedy hill-climbing that eliminates instability by determining a\nstable node order, leading to consistent results regardless of variable\nordering. Two implementations, HC-Stable and Tabu-Stable, are introduced.\nTabu-Stable achieves the highest BIC scores across all networks, and the\nhighest accuracy for categorical networks. These results highlight the\nimportance of addressing instability in structure learning and provide a robust\nand practical approach for future applications. This extends the scope and\nimpact of our previous work presented at Probabilistic Graphical Models 2024 by\nincorporating continuous variables. The implementation, along with usage\ninstructions, is freely available on GitHub at\nhttps://github.com/causal-iq/discovery.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T13:51:44Z"}
{"aid":"http://arxiv.org/abs/2504.01779v1","title":"The Vertical Metallicity Gradient of the Galactic Disk for Mono-Age\n  Stellar Populations in LAMOST","summary":"The vertical metallicity gradient of the Galactic disk offers valuable\ninsights into the disk's formation and chemical evolution over time. We\nutilized the LAMOST-LRS young stellar sample to investigate this gradient and\nfound that it approaches zero as stellar effective temperature (or age)\nincreases (or decreases) across various Galactocentric distances. To validate\nthis result, we analyzed 295 open clusters younger than 3 Gyr and 976 classical\ncepheids within the Galactic disk. The findings confirmed that, within a given\nnarrow age range, the vertical metallicity gradient is effectively zero. This\nrelationship between metallicity and age supports the ``upside-down'' disk\nformation theory, as it indicates that the youngest and most metal-rich stars\ndominate the midplane, while older and more metal-poor stars formed at larger\nvertical heights and currently tend to be at these heights. Overall, our\nresults align well with theoretical predictions, offering further insight into\nthe chemical evolution and structural properties of the Milky Way.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T14:43:02Z"}
{"aid":"http://arxiv.org/abs/2504.01783v1","title":"CLaP -- State Detection from Time Series","summary":"The ever-growing amount of sensor data from machines, smart devices, and the\nenvironment leads to an abundance of high-resolution, unannotated time series\n(TS). These recordings encode the recognizable properties of latent states and\ntransitions from physical phenomena that can be modelled as abstract processes.\nThe unsupervised localization and identification of these states and their\ntransitions is the task of time series state detection (TSSD). We introduce\nCLaP, a new, highly accurate and efficient algorithm for TSSD. It leverages the\npredictive power of time series classification for TSSD in an unsupervised\nsetting by applying novel self-supervision techniques to detect whether data\nsegments emerge from the same state or not. To this end, CLaP cross-validates a\nclassifier with segment-labelled subsequences to quantify confusion between\nsegments. It merges labels from segments with high confusion, representing the\nsame latent state, if this leads to an increase in overall classification\nquality. We conducted an experimental evaluation using 391 TS from four\nbenchmarks and found CLaP to be significantly more precise in detecting states\nthan five state-of-the-art competitors. It achieves the best accuracy-runtime\ntradeoff and is scalable to large TS. We provide a Python implementation of\nCLaP, which can be deployed in TS analysis workflows.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DB","published":"2025-04-02T14:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.01788v1","title":"Projections from Furstenberg boundaries onto maximal flats and\n  barycenter maps","summary":"Let $G$ be a semisimple connected Lie group of non-compact type with finite\ncenter. Let $K<G$ be a maximal compact subgroup and $P<G$ be a minimal\nparabolic subgroup. For any pair $(F,x)$, where $F$ is a maximal flat in $G/K$\nand $x \\in G/P$ is opposite to the Weyl chambers determined by $F$, we define a\nprojection $\\Phi(F, x) \\in F$ which is continuous and $G$-equivariant.\nFurthermore, if $q \\geq 3$, we exhibit a $G$-equivariant continuous map defined\non an open subset of full measure of the space of $q$-tuples of $(G/P)^q$ with\nimage in $G/K$. When $G$ is the orientation preserving isometries of real\nhyperbolic space and $q = 3$, we recover the geometric barycenter of the\ncorresponding ideal triangle. All our proofs are constructive.","main_category":"math.GR","categories":"math.GR,math.DG","published":"2025-04-02T14:53:07Z"}
{"aid":"http://arxiv.org/abs/2504.01789v1","title":"OpenThaiGPT 1.6 and R1: Thai-Centric Open Source and Reasoning Large\n  Language Models","summary":"We present OpenThaiGPT 1.6 and R1 (OTG-1.6 and OTG-R1), Thai-centric Large\nLanguage Models (LLMs) developed through distinct methodologies to enhance\ngeneralization and reasoning capabilities. OTG-1.6 employs Task Arithmetic\nmodel merging for broad generalization, while OTG-R1 integrates multi-stage\ntraining with the Less-Is-More Reasoning Hypothesis (LIMO) for advanced\nreasoning. Benchmark evaluations demonstrate superior performance across Thai\nlanguage tasks, achieving competitive results against larger-scale open-source\nThai LLMs. This paper details the proposed models, training processes,\nbenchmarks, and results, highlighting improvements over previous models and\nestablishing new performance standards for Thai-centric LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T14:55:52Z"}
{"aid":"http://arxiv.org/abs/2504.01802v1","title":"Distributed Triangle Detection is Hard in Few Rounds","summary":"In the distributed triangle detection problem, we have an $n$-vertex network\n$G=(V,E)$ with one player for each vertex of the graph who sees the edges\nincident on the vertex. The players communicate in synchronous rounds using the\nedges of this network and have a limited bandwidth of $O(\\log{n})$ bits over\neach edge. The goal is to detect whether or not $G$ contains a triangle as a\nsubgraph in a minimal number of rounds.\n  We prove that any protocol (deterministic or randomized) for distributed\ntriangle detection requires $\\Omega(\\log\\log{n})$ rounds of communication.\nPrior to our work, only one-round lower bounds were known for this problem.\n  The primary technique for proving these types of distributed lower bounds is\nvia reductions from two-party communication complexity. However, it has been\nknown for a while that this approach is provably incapable of establishing any\nmeaningful lower bounds for distributed triangle detection. Our main technical\ncontribution is a new information theoretic argument which combines recent\nadvances on multi-pass graph streaming lower bounds with the point-to-point\ncommunication aspects of distributed models, and can be of independent\ninterest.","main_category":"cs.DS","categories":"cs.DS,cs.CC,cs.DC","published":"2025-04-02T15:10:21Z"}
{"aid":"http://arxiv.org/abs/2504.01811v1","title":"Inference of hidden common driver dynamics by anisotropic\n  self-organizing neural networks","summary":"We are introducing a novel approach to infer the underlying dynamics of\nhidden common drivers, based on analyzing time series data from two driven\ndynamical systems. The inference relies on time-delay embedding, estimation of\nthe intrinsic dimension of the observed systems, and their mutual dimension. A\nkey component of our approach is a new anisotropic training technique applied\nto Kohonen's self-organizing map, which effectively learns the attractor of the\ndriven system and separates it into submanifolds corresponding to the\nself-dynamics and shared dynamics.\n  To demonstrate the effectiveness of our method, we conducted simulated\nexperiments using different chaotic maps in a setup, where two chaotic maps\nwere driven by a third map with nonlinear coupling. The inferred time series\nexhibited high correlation with the time series of the actual hidden common\ndriver, in contrast to the observed systems. The quality of our reconstruction\nwere compared and shown to be superior to several other methods that are\nintended to find the common features behind the observed time series, including\nlinear methods like PCA and ICA as well as nonlinear methods like dynamical\ncomponent analysis, canonical correlation analysis and even deep canonical\ncorrelation analysis.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T15:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.01812v1","title":"Non-collocated vibration absorption using delayed resonator for spectral\n  and spacial tuning -- analysis and experimental validation","summary":"Non-collocated vibration absorption (NCVA) concept using delayed resonator\nfor in-situ tuning is analyzed and experimentally validated. There are two\ncritical contributions of this work. One is on the scalable analytical pathway\nfor verifying the concept of resonant substructure as the basis of the ideal\nvibration absorption. The second is to experimentally validate the spatial and\nspectral tunability of NCVA structures for the first time. For both novelties\narbitrarily large dimensions of interconnected mass-spring-damper chains are\nconsidered. Following the state of the art on NCVA, control synthesis is\nperformed over the resonant substructure comprising the delayed resonator and a\npart of the primary structure involved in the vibration absorption. The\nexperimental validation of the proposed NCVA concept is performed on a\nmechatronic setup with three interconnected cart-bodies. Based on the spectral\nanalysis, an excitation frequency is selected for which a stable vibration\nsuppression can be achieved sequentially for all the three bodies, one\ncollocated and two non-collocated. The experimental results closely match the\nsimulations for complete vibration suppression at the targeted bodies, and thus\nvalidating the crucial spatial tunability characteristic as well as the\ntraditional spectral tuning.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-02T15:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.01814v1","title":"Energy Density Functional of Confined Quarks: an Improved Ansatz","summary":"Density Functional Theory (DFT) is a robust framework for modeling\ninteracting many-body systems, including the equation of state (EoS) of dense\nmatter. Many models, however, rely on energy functionals based on assumptions\nthat have not been rigorously validated. We critically analyze a commonly used\nansatz for confinement, where the energy functional scales with density as $U\n\\propto n^{\\frac{2}{3}}$ . Our findings, derived from a systematic non-local\nenergy functional, reveal that this scaling does not capture the dynamics of\nconfinement. Instead, the energy functional evolves from $n^2$ at low densities\nto $n$ at high densities, governed by an infrared cutoff. These results suggest\nthat models relying on such assumptions should be revisited to ensure more\nreliable EoS construction.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE,hep-ph,hep-th","published":"2025-04-02T15:20:03Z"}
{"aid":"http://arxiv.org/abs/2504.01820v1","title":"Antenna Selection for Enhancing Privacy in Radar-Based Vital Sign\n  Monitoring Systems","summary":"Radar-based vital sign monitoring (VSM) systems have become valuable for\nnon-contact health monitoring by detecting physiological activities, such as\nrespiration and heartbeat, remotely. However, the conventional phased array\nused in VSM is vulnerable to privacy breaches, as an eavesdropper can extract\nsensitive vital sign information by analyzing the reflected radar signals. In\nthis paper, we propose a novel approach to protect privacy in radar-based VSM\nby modifying the radar transmitter hardware, specifically by strategically\nselecting the transmit antennas from the available antennas in the transmit\narray. By dynamically selecting which antennas connect or disconnect to the\nradio frequency chain, the transmitter introduces additional phase noise to the\nradar echoes, generating false frequencies in the power spectrum of the\nextracted phases at the eavesdropper's receiver. The antenna activation pattern\nis designed to maximize the variance of the phases introduced by antenna\nselection, which effectively makes the false frequencies dominate the spectrum,\nobscuring the actual vital sign frequencies. Meanwhile, the authorized\nreceiver, having knowledge of the antenna selection pattern, can compensate for\nthe phase noise and accurately extract the vital signs. Numerical experiments\nare conducted to validate the effectiveness of the proposed approach in\nenhancing privacy while maintaining vital sign monitoring.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T15:28:07Z"}
{"aid":"http://arxiv.org/abs/2504.01837v1","title":"CramÃ©r--Rao Inequalities for Several Generalized Fisher Information","summary":"The de Bruijn identity states that Fisher information is the half of the\nderivative of Shannon differential entropy along heat flow. In the same spirit,\nin this paper we introduce a generalized version of Fisher information, named\nas the R\\'enyi--Fisher information, which is the half of the derivative of\nR\\'enyi information along heat flow. Based on this R\\'enyi--Fisher information,\nwe establish sharp R\\'enyi-entropic isoperimetric inequalities, which\ngeneralize the classic entropic isoperimetric inequality to the R\\'enyi\nsetting. Utilizing these isoperimetric inequalities, we extend the classical\nCram\\'er--Rao inequality from Fisher information to R\\'enyi--Fisher\ninformation. Lastly, we use these generalized Cram\\'er--Rao inequalities to\ndetermine the signs of derivatives of entropy along heat flow, strengthening\nexisting results on the complete monotonicity of entropy.","main_category":"cs.IT","categories":"cs.IT,math.IT,math.PR,math.ST,stat.TH","published":"2025-04-02T15:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.01840v1","title":"LARGE: Legal Retrieval Augmented Generation Evaluation Tool","summary":"Recently, building retrieval-augmented generation (RAG) systems to enhance\nthe capability of large language models (LLMs) has become a common practice.\nEspecially in the legal domain, previous judicial decisions play a significant\nrole under the doctrine of stare decisis which emphasizes the importance of\nmaking decisions based on (retrieved) prior documents. However, the overall\nperformance of RAG system depends on many components: (1) retrieval corpora,\n(2) retrieval algorithms, (3) rerankers, (4) LLM backbones, and (5) evaluation\nmetrics. Here we propose LRAGE, an open-source tool for holistic evaluation of\nRAG systems focusing on the legal domain. LRAGE provides GUI and CLI interfaces\nto facilitate seamless experiments and investigate how changes in the\naforementioned five components affect the overall accuracy. We validated LRAGE\nusing multilingual legal benches including Korean (KBL), English (LegalBench),\nand Chinese (LawBench) by demonstrating how the overall accuracy changes when\nvarying the five components mentioned above. The source code is available at\nhttps://github.com/hoorangyee/LRAGE.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T15:45:03Z"}
{"aid":"http://arxiv.org/abs/2504.01852v1","title":"Deciphering the Nature of Virgil: An Obscured AGN Lurking Within an\n  Apparently Normal Lyman-Î± Emitter During Cosmic Reionization","summary":"We present a comprehensive analysis of the MIRI Extremely Red Object Virgil,\na Lyman-$\\alpha$ emitter at $z_{spec} = 6.6379 \\pm 0.0035$ with the photometric\nproperties of a Little Red Dot. Leveraging new JWST/MIRI imaging from the MIDIS\nand PAHSPECS programs, we confirm Virgil's extraordinary nature among galaxies\nin JADES/GOODS-South, exhibiting a strikingly red NIRCam-to-MIRI color (F444W\n$-$ F1500W = $2.84\\pm0.04$~mag). Deep NIRSpec/PRISM spectroscopy from the OASIS\nprogram offers key insights into the host galaxy, revealing properties of an\naverage star-forming galaxy during Cosmic Reionization, such as a subsolar\nmetallicity, low-to-moderate dust content, and a relatively high ionization\nparameter and electron temperature. By estimating the star formation rate of\nVirgil from UV and H$\\alpha$, we find evidence that the galaxy is either\nentering or fading out of a bursty episode. Although line-ratio diagnostics\nemployed at high-$z$ would classify Virgil as an Active Galactic Nucleus (AGN),\nthis classification becomes ambiguous once redshift evolution is considered.\nNonetheless, Virgil occupies the same parameter space as recently confirmed\nAGNs at similar redshifts. The new deep MIRI data at 15~$\\mu$m reinforce the\nAGN nature of Virgil, as inferred from multiple spectral energy distribution\n(SED) fitting codes. Virgil's rising infrared SED and UV excess resemble those\nof Dust-Obscured Galaxies (DOGs) studied with Spitzer at Cosmic Noon,\nparticularly blue-excess HotDOGs. Our results highlight the need for a\nmulti-wavelength approach incorporating MIRI to uncover such extreme sources at\n$z\\gtrsim6$ and to shed light on the interplay between galaxy evolution and\nearly black hole growth during Cosmic Reionization.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-02T16:04:22Z"}
{"aid":"http://arxiv.org/abs/2504.01853v1","title":"Implications of recent LHCb data on CPV in b-baryon four body decays","summary":"Motivated by the recent CPV observation, we investigate the CPV of b-baryon\ncharmless four body decays under the U-spin symmetry. However, we find that\nonly U-spin symmetry cannot provide effective predictions, particularly for\n$\\Lambda_b$ decays. For giving more useful predictions, we also give a simple\ndynamic analysis. By counting the\npower($\\lambda=\\sqrt{\\frac{\\Lambda_{QCD}}{m_b}}$) of each topological diagram,\nwe find that for the specific decay $B_b^2\\to R(B_1^2 M^2 M^{\\bar 2})M^2$, only\none U-spin amplitude can contribute in the leading power. Then the effective\nprediction can be given as \\begin{align}\n  A_{CP}^{dir}(\\Lambda_b^0 \\to R( p \\pi^- \\pi^+ )\\pi^-) = (-12.98 \\pm\n2.85)\\%.\\notag \\end{align} Considering the $\\Lambda_b$ can effectively produced\nin LHCb, we strongly encourage a more precise experimental investigation of it.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T16:05:00Z"}
{"aid":"http://arxiv.org/abs/2504.01862v1","title":"Axiomatic Foundations of Fractal Analysis and Fractal Number Theory","summary":"We develop an axiomatic framework for fractal analysis and fractal number\ntheory grounded in hierarchies of definability. Central to this approach is a\nsequence of formal systems F_n, each corresponding to a definability level S_n\ncontained in R of constructively accessible mathematical objects. This\nstructure refines classical analysis by replacing uncountable global constructs\nwith countable, syntactically constrained approximations.\n  The axioms formalize: - A hierarchy of definability levels S_n, indexed by\nsyntactic and ordinal complexity; - Fractal topologies and the induced notions\nof continuity, compactness, and differentiability; - Layered integration and\ndifferentiation with explicit convergence and definability bounds; - Arithmetic\nand function spaces over the stratified continuum R_{S_n}, which is a subset of\nR.\n  This framework synthesizes constructive mathematics, proof-theoretic\nstratification, and fractal geometric intuition into a unified, finitistically\nstructured model. Key results include the definability-based classification of\nreal numbers (e.g., algebraic, computable, Liouville), a stratified fundamental\ntheorem of calculus with syntactic error bounds, and compatibility with base\nsystems such as RCA_0 and ACA_0.\n  The framework enables constructive approximation and syntactic regularization\nof classical analysis, with applications to proof assistants, computable\nmathematics, and foundational studies of the continuum.","main_category":"math.LO","categories":"math.LO,math.FA,F.4.1","published":"2025-04-02T16:14:50Z"}
{"aid":"http://arxiv.org/abs/2504.01883v1","title":"CoRAG: Collaborative Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) models excel in knowledge-intensive\ntasks, especially under few-shot learning constraints. We introduce CoRAG, a\nframework extending RAG to collaborative settings, where clients jointly train\na shared model using a collaborative passage store. To evaluate CoRAG, we\nintroduce CRAB, a benchmark for collaborative homogeneous open-domain question\nanswering. Our experiments demonstrate that CoRAG consistently outperforms both\nparametric collaborative learning methods and locally trained RAG models in\nlow-resource scenarios. Further analysis reveals the critical importance of\nrelevant passages within the shared store, the surprising benefits of\nincorporating irrelevant passages, and the potential for hard negatives to\nnegatively impact performance. This introduces a novel consideration in\ncollaborative RAG: the trade-off between leveraging a collectively enriched\nknowledge base and the potential risk of incorporating detrimental passages\nfrom other clients. Our findings underscore the viability of CoRAG, while also\nhighlighting key design challenges and promising avenues for future research.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-02T16:40:43Z"}
{"aid":"http://arxiv.org/abs/2504.01894v1","title":"Multi-fidelity Parameter Estimation Using Conditional Diffusion Models","summary":"We present a multi-fidelity method for uncertainty quantification of\nparameter estimates in complex systems, leveraging generative models trained to\nsample the target conditional distribution. In the Bayesian inference setting,\ntraditional parameter estimation methods rely on repeated simulations of\npotentially expensive forward models to determine the posterior distribution of\nthe parameter values, which may result in computationally intractable\nworkflows. Furthermore, methods such as Markov Chain Monte Carlo (MCMC)\nnecessitate rerunning the entire algorithm for each new data observation,\nfurther increasing the computational burden. Hence, we propose a novel method\nfor efficiently obtaining posterior distributions of parameter estimates for\nhigh-fidelity models given data observations of interest. The method first\nconstructs a low-fidelity, conditional generative model capable of amortized\nBayesian inference and hence rapid posterior density approximation over a\nwide-range of data observations. When higher accuracy is needed for a specific\ndata observation, the method employs adaptive refinement of the density\napproximation. It uses outputs from the low-fidelity generative model to refine\nthe parameter sampling space, ensuring efficient use of the computationally\nexpensive high-fidelity solver. Subsequently, a high-fidelity, unconditional\ngenerative model is trained to achieve greater accuracy in the target posterior\ndistribution. Both low- and high- fidelity generative models enable efficient\nsampling from the target posterior and do not require repeated simulation of\nthe high-fidelity forward model. We demonstrate the effectiveness of the\nproposed method on several numerical examples, including cases with multi-modal\ndensities, as well as an application in plasma physics for a runaway electron\nsimulation model.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T16:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.01945v1","title":"Gluing moduli spaces of quantum toric stacks via secondary fan","summary":"The extension from toric varieties to quantum toric stacks allows for the\nstudy of moduli spaces of toric objects with fixed combinatorial structures, as\nwe now consider general finitely generated subgroups of $\\mathbb{R}^n$ as\n\"lattices.\" This paper aims to construct a moduli space that encompasses all\nsuch moduli spaces for a given dimension of the ambient space. To achieve this,\nwe adapt the construction of the secondary fan within the quantum framework.\nThis approach provides a description of wall-crossings between different moduli\nspaces, analogous to those observed in LVMB manifolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T17:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.01951v1","title":"The LLM Wears Prada: Analysing Gender Bias and Stereotypes through\n  Online Shopping Data","summary":"With the wide and cross-domain adoption of Large Language Models, it becomes\ncrucial to assess to which extent the statistical correlations in training\ndata, which underlie their impressive performance, hide subtle and potentially\ntroubling biases. Gender bias in LLMs has been widely investigated from the\nperspectives of works, hobbies, and emotions typically associated with a\nspecific gender. In this study, we introduce a novel perspective. We\ninvestigate whether LLMs can predict an individual's gender based solely on\nonline shopping histories and whether these predictions are influenced by\ngender biases and stereotypes. Using a dataset of historical online purchases\nfrom users in the United States, we evaluate the ability of six LLMs to\nclassify gender and we then analyze their reasoning and products-gender\nco-occurrences. Results indicate that while models can infer gender with\nmoderate accuracy, their decisions are often rooted in stereotypical\nassociations between product categories and gender. Furthermore, explicit\ninstructions to avoid bias reduce the certainty of model predictions, but do\nnot eliminate stereotypical patterns. Our findings highlight the persistent\nnature of gender biases in LLMs and emphasize the need for robust\nbias-mitigation strategies.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CY","published":"2025-04-02T17:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.01959v1","title":"Slot-Level Robotic Placement via Visual Imitation from Single Human\n  Video","summary":"The majority of modern robot learning methods focus on learning a set of\npre-defined tasks with limited or no generalization to new tasks. Extending the\nrobot skillset to novel tasks involves gathering an extensive amount of\ntraining data for additional tasks. In this paper, we address the problem of\nteaching new tasks to robots using human demonstration videos for repetitive\ntasks (e.g., packing). This task requires understanding the human video to\nidentify which object is being manipulated (the pick object) and where it is\nbeing placed (the placement slot). In addition, it needs to re-identify the\npick object and the placement slots during inference along with the relative\nposes to enable robot execution of the task. To tackle this, we propose SLeRP,\na modular system that leverages several advanced visual foundation models and a\nnovel slot-level placement detector Slot-Net, eliminating the need for\nexpensive video demonstrations for training. We evaluate our system using a new\nbenchmark of real-world videos. The evaluation results show that SLeRP\noutperforms several baselines and can be deployed on a real robot.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-02T17:59:45Z"}
{"aid":"http://arxiv.org/abs/2504.01960v1","title":"Diffusion-Guided Gaussian Splatting for Large-Scale Unconstrained 3D\n  Reconstruction and Novel View Synthesis","summary":"Recent advancements in 3D Gaussian Splatting (3DGS) and Neural Radiance\nFields (NeRF) have achieved impressive results in real-time 3D reconstruction\nand novel view synthesis. However, these methods struggle in large-scale,\nunconstrained environments where sparse and uneven input coverage, transient\nocclusions, appearance variability, and inconsistent camera settings lead to\ndegraded quality. We propose GS-Diff, a novel 3DGS framework guided by a\nmulti-view diffusion model to address these limitations. By generating\npseudo-observations conditioned on multi-view inputs, our method transforms\nunder-constrained 3D reconstruction problems into well-posed ones, enabling\nrobust optimization even with sparse data. GS-Diff further integrates several\nenhancements, including appearance embedding, monocular depth priors, dynamic\nobject modeling, anisotropy regularization, and advanced rasterization\ntechniques, to tackle geometric and photometric challenges in real-world\nsettings. Experiments on four benchmarks demonstrate that GS-Diff consistently\noutperforms state-of-the-art baselines by significant margins.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-02T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.02224v1","title":"Fundamental elements in the development of effective crowd control\n  strategies","summary":"In this work, we present typical challenges encountered when developing\nmethods for controlling crowds of people (or animal swarms). We discuss which\nelements shall be considered and the role they play to achieve a robust control\nin a variety of conditions. In particular, four different studies are reviewed,\neach of them investigating in detail important elements encountered in crowd\nsteering and control. More specifically synchronization, compliance, crowd (or\nswarm) density and human perception are studied showing the role they play in\ncombination. Ultimately, the success of a control strategy is determined by\ncarefully considering the effect each element has on individuals, but also on\nthe interactions between them, leading to the creation of a collective\nbehavior. We will also highlight the importance of psychological and cognitive\nfactors when dealing with human crowds, hinting at the fact that automatic\ncontrol systems may achieve optimal performance, but may be not necessarily\nwell perceived by people in terms of comfort. The discussion aims at showing\nrecent trends and potentialities of crowd control systems, but should also warn\non the risk in choosing a solution prioritizing optimization toward people's\nsafety or comfort.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-03T02:46:36Z"}
{"aid":"http://arxiv.org/abs/2504.02260v1","title":"Implicit Neural Differential Model for Spatiotemporal Dynamics","summary":"Hybrid neural-physics modeling frameworks through differentiable programming\nhave emerged as powerful tools in scientific machine learning, enabling the\nintegration of known physics with data-driven learning to improve prediction\naccuracy and generalizability. However, most existing hybrid frameworks rely on\nexplicit recurrent formulations, which suffer from numerical instability and\nerror accumulation during long-horizon forecasting. In this work, we introduce\nIm-PiNDiff, a novel implicit physics-integrated neural differentiable solver\nfor stable and accurate modeling of spatiotemporal dynamics. Inspired by deep\nequilibrium models, Im-PiNDiff advances the state using implicit fixed-point\nlayers, enabling robust long-term simulation while remaining fully end-to-end\ndifferentiable. To enable scalable training, we introduce a hybrid gradient\npropagation strategy that integrates adjoint-state methods with reverse-mode\nautomatic differentiation. This approach eliminates the need to store\nintermediate solver states and decouples memory complexity from the number of\nsolver iterations, significantly reducing training overhead. We further\nincorporate checkpointing techniques to manage memory in long-horizon rollouts.\nNumerical experiments on various spatiotemporal PDE systems, including\nadvection-diffusion processes, Burgers' dynamics, and multi-physics chemical\nvapor infiltration processes, demonstrate that Im-PiNDiff achieves superior\npredictive performance, enhanced numerical stability, and substantial\nreductions in memory and runtime cost relative to explicit and naive implicit\nbaselines. This work provides a principled, efficient, and scalable framework\nfor hybrid neural-physics modeling.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T04:07:18Z"}
{"aid":"http://arxiv.org/abs/2504.02270v1","title":"MinkOcc: Towards real-time label-efficient semantic occupancy prediction","summary":"Developing 3D semantic occupancy prediction models often relies on dense 3D\nannotations for supervised learning, a process that is both labor and\nresource-intensive, underscoring the need for label-efficient or even\nlabel-free approaches. To address this, we introduce MinkOcc, a multi-modal 3D\nsemantic occupancy prediction framework for cameras and LiDARs that proposes a\ntwo-step semi-supervised training procedure. Here, a small dataset of\nexplicitly 3D annotations warm-starts the training process; then, the\nsupervision is continued by simpler-to-annotate accumulated LiDAR sweeps and\nimages -- semantically labelled through vision foundational models. MinkOcc\neffectively utilizes these sensor-rich supervisory cues and reduces reliance on\nmanual labeling by 90\\% while maintaining competitive accuracy. In addition,\nthe proposed model incorporates information from LiDAR and camera data through\nearly fusion and leverages sparse convolution networks for real-time\nprediction. With its efficiency in both supervision and computation, we aim to\nextend MinkOcc beyond curated datasets, enabling broader real-world deployment\nof 3D semantic occupancy prediction in autonomous driving.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-03T04:31:56Z"}
{"aid":"http://arxiv.org/abs/2504.02302v1","title":"Causal Self-supervised Pretrained Frontend with Predictive Code for\n  Speech Separation","summary":"Speech separation (SS) seeks to disentangle a multi-talker speech mixture\ninto single-talker speech streams. Although SS can be generally achieved using\noffline methods, such a processing paradigm is not suitable for real-time\nstreaming applications. Causal separation models, which rely only on past and\npresent information, offer a promising solution for real-time streaming.\nHowever, these models typically suffer from notable performance degradation due\nto the absence of future context. In this paper, we introduce a novel frontend\nthat is designed to mitigate the mismatch between training and run-time\ninference by implicitly incorporating future information into causal models\nthrough predictive patterns. The pretrained frontend employs a transformer\ndecoder network with a causal convolutional encoder as the backbone and is\npretrained in a self-supervised manner with two innovative pretext tasks:\nautoregressive hybrid prediction and contextual knowledge distillation. These\ntasks enable the model to capture predictive patterns directly from mixtures in\na self-supervised manner. The pretrained frontend subsequently serves as a\nfeature extractor to generate high-quality predictive patterns. Comprehensive\nevaluations on synthetic and real-world datasets validated the effectiveness of\nthe proposed pretrained frontend.","main_category":"cs.SD","categories":"cs.SD,cs.LG,eess.AS","published":"2025-04-03T06:18:30Z"}
{"aid":"http://arxiv.org/abs/2504.02303v1","title":"Diversifying halo structures in two-component self-interacting dark\n  matter models via mass segregation","summary":"Self-interacting dark matter (SIDM), through gravothermal evolution driven by\nelastic self-scatterings, offers a compelling explanation for the observed\ndiversity of inner halo densities. In this work, we investigate SIDM dynamics\nin a two-component dark matter model with mass ratios of order unity, motivated\nby an asymmetric dark matter framework that naturally evades constraints from\nrelic abundance and mediator decay, while enabling strong, velocity-dependent\nself-interactions. We show that cross-component scatterings significantly\nenhance mass segregation, driving the formation of dense, core collapsed-like\nhalos. This effect couples naturally to SIDM-induced diversity, introducing a\nnew mechanism for generating structural variations beyond those arising from\ngravothermal evolution alone. Our results reveal a novel mechanism for\nreconciling SIDM with small-scale observational tensions by enabling shifts in\ncentral densities while preserving the flexibility to generate diverse halo\nstructures. We further highlight that halo structural diversity may serve as a\ndiagnostic of dark sector composition, opening a new observational window into\nthe particle nature of SIDM.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-03T06:20:10Z"}
{"aid":"http://arxiv.org/abs/2504.02322v1","title":"Distributed Log-driven Anomaly Detection System based on Evolving\n  Decision Making","summary":"Effective anomaly detection from logs is crucial for enhancing cybersecurity\ndefenses by enabling the early identification of threats. Despite advances in\nanomaly detection, existing systems often fall short in areas such as\npost-detection validation, scalability, and effective maintenance. These\nlimitations not only hinder the detection of new threats but also impair\noverall system performance. To address these challenges, we propose CEDLog, a\nnovel practical framework that integrates Elastic Weight Consolidation (EWC)\nfor continual learning and implements distributed computing for scalable\nprocessing by integrating Apache Airflow and Dask. In CEDLog, anomalies are\ndetected through the synthesis of Multi-layer Perceptron (MLP) and Graph\nConvolutional Networks (GCNs) using critical features present in event logs.\nThrough comparisons with update strategies on large-scale datasets, we\ndemonstrate the strengths of CEDLog, showcasing efficient updates and low false\npositives","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-03T06:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.02334v1","title":"Determining Sphere Radius through Pairwise Distances","summary":"We propose a novel method for determining the radius of a spherical surface\nbased on the distances measured between points on this surface. We consider the\nmost general case of determining the radius when the distances are measured\nwith errors and the sphere has random deviations from its ideal shape. For the\nsolution, we used the minimally necessary four points and an arbitrary N number\nof points. We provide a new closed form solution for the radius of the sphere\nthrough the matrix of pairwise distances. We also determine the standard\ndeviation of the radius estimate caused by measurement errors and deviations of\nthe sphere from its ideal shape. We found optimal configurations of points on\nthe sphere that provide the minimum standard deviation of the radius estimate.\nThis paper describes our solution and provides all the mathematical\nderivations. We share the implementation of our method as open source code at\nhttps://github.com/boris-sukhovilov/Sphere_Radius.","main_category":"cs.CG","categories":"cs.CG,cs.CV","published":"2025-04-03T07:15:15Z"}
{"aid":"http://arxiv.org/abs/2504.02369v1","title":"Finding Diverse Solutions in Combinatorial Problems with a Distributive\n  Lattice Structure","summary":"We generalize the polynomial-time solvability of $k$-\\textsc{Diverse Minimum\ns-t Cuts} (De Berg et al., ISAAC'23) to a wider class of combinatorial problems\nwhose solution sets have a distributive lattice structure. We identify three\nstructural conditions that, when met by a problem, ensure that a $k$-sized\nmultiset of maximally-diverse solutions -- measured by the sum of pairwise\nHamming distances -- can be found in polynomial time. We apply this framework\nto obtain polynomial time algorithms for finding diverse minimum $s$-$t$ cuts\nand diverse stable matchings. Moreover, we show that the framework extends to\ntwo other natural measures of diversity. Lastly, we present a simpler\nalgorithmic framework for finding a largest set of pairwise disjoint solutions\nin problems that meet these structural conditions.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-03T08:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.02372v1","title":"Quantum Key Distribution over Complex Networks","summary":"There exist several initiatives worldwide to deploy quantum key distribution\n(QKD) over existing fibre networks and achieve quantum-safe security at large\nscales. To understand the overall QKD network performance, it is required to\ntransition from the analysis of individual links, as done so far, to the\ncharacterization of the network as a whole. In this work, we undertake this\nstudy by embedding QKD protocols on complex networks, which correctly model the\nexisting fiber networks. We focus on networks with trusted nodes and on\ncontinuous-variable (CV) schemes, which have much higher key rates than their\ndiscrete-variable (DV) counterparts. In the effective CV network, however, many\nof the unique properties of complex networks, such as small-worldness and the\npresence of hubs, are lost due to the fast decay of the key rate with physical\ndistance for CV systems. These properties can be restored when considering a\nhybrid network consisting of both CV and DV protocols, achieving at the same\ntime high average rate and inter-connectivity. Our work opens the path to the\nstudy of QKD complex networks in existing infrastructures.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,physics.soc-ph","published":"2025-04-03T08:05:44Z"}
{"aid":"http://arxiv.org/abs/2504.02381v1","title":"Fermat Distance-to-Measure: a robust Fermat-like metric","summary":"Given a probability measure with density, Fermat distances and density-driven\nmetrics are conformal transformation of the Euclidean metric that shrink\ndistances in high density areas and enlarge distances in low density areas.\nAlthough they have been widely studied and have shown to be useful in various\nmachine learning tasks, they are limited to measures with density (with respect\nto Lebesgue measure, or volume form on manifold). In this paper, by replacing\nthe density with the Distance-to-Measure, we introduce a new metric, the Fermat\nDistance-to-Measure, defined for any probability measure in R^d. We derive\nstrong stability properties for the Fermat Distance-to-Measure with respect to\nthe measure and propose an estimator from random sampling of the measure,\nfeaturing an explicit bound on its convergence speed.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-03T08:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.02382v1","title":"Benchmark of Segmentation Techniques for Pelvic Fracture in CT and\n  X-ray: Summary of the PENGWIN 2024 Challenge","summary":"The segmentation of pelvic fracture fragments in CT and X-ray images is\ncrucial for trauma diagnosis, surgical planning, and intraoperative guidance.\nHowever, accurately and efficiently delineating the bone fragments remains a\nsignificant challenge due to complex anatomy and imaging limitations. The\nPENGWIN challenge, organized as a MICCAI 2024 satellite event, aimed to advance\nautomated fracture segmentation by benchmarking state-of-the-art algorithms on\nthese complex tasks. A diverse dataset of 150 CT scans was collected from\nmultiple clinical centers, and a large set of simulated X-ray images was\ngenerated using the DeepDRR method. Final submissions from 16 teams worldwide\nwere evaluated under a rigorous multi-metric testing scheme. The top-performing\nCT algorithm achieved an average fragment-wise intersection over union (IoU) of\n0.930, demonstrating satisfactory accuracy. However, in the X-ray task, the\nbest algorithm attained an IoU of 0.774, highlighting the greater challenges\nposed by overlapping anatomical structures. Beyond the quantitative evaluation,\nthe challenge revealed methodological diversity in algorithm design. Variations\nin instance representation, such as primary-secondary classification versus\nboundary-core separation, led to differing segmentation strategies. Despite\npromising results, the challenge also exposed inherent uncertainties in\nfragment definition, particularly in cases of incomplete fractures. These\nfindings suggest that interactive segmentation approaches, integrating human\ndecision-making with task-relevant information, may be essential for improving\nmodel reliability and clinical applicability.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-03T08:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.02418v1","title":"All-loop effective potential for arbitrary scalar models in curved\n  space-time","summary":"In this paper we calculate the leading divergences of the effective potential\nfor an arbitrary scalar theory on a curved spacetime background. Based on the\nrecurrence relation between the leading poles following from the locality\ncondition, we obtain a system of generalised renormalisation-group equations\nthat can be studied numerically or analytically in some special cases. We study\nthe simplest effective potentials for power-like models and give a comparison\nof them in the framework of cosmological phenomenology.","main_category":"hep-th","categories":"hep-th","published":"2025-04-03T09:17:28Z"}
{"aid":"http://arxiv.org/abs/2504.02422v1","title":"Applying Space-Group Symmetry to Speed up Hybrid-Functional-Based\n  Calculations with Numerical Atomic Orbitals","summary":"Building upon the efficient implementation of hybrid density functionals\n(HDFs) for large-scale periodic systems within the framework of numerical\natomic orbital bases using the localized resolution of identity (RI) technique,\nwe have developed an algorithm that exploits the space group symmetry in key\noperation steps of HDF calculations, leading to further improvements in two\nways. First, the reduction of $\\mathbf{k}$-points in the Brillouin zone can\nreduce the number of Kohn-Sham equations to be solved. This necessitates the\ncorrect implementation of the rotation relation between the density matrices of\nequivalent $\\mathbf{k}$-points within the representation of atomic orbitals.\nSecond, the reduction of the real-space sector can accelerate the construction\nof the exact-exchange part of the Hamiltonian in real space. We have\nimplemented this algorithm in the ABACUS software interfaced with LibRI, and\ntested its performance for several types of crystal systems with different\nsymmetries. The expected speed-up is achieved in both aspects: the time of\nsolving the Kohn-Sham equations decreases in proportion with the reduction of\n$\\mathbf{k}$-points, while the construction of the Hamiltonian in real space is\nsped up by several times, with the degree of acceleration depending on the size\nand symmetry of the system.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-03T09:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.02435v1","title":"Poisson-Voronoi percolation in higher rank","summary":"We show that the uniqueness thresholds for Poisson-Voronoi percolation in\nsymmetric spaces of connected higher rank semisimple Lie groups with property\n(T) converge to zero in the low-intensity limit. This phenomenon is\nfundamentally different from situations in which Poisson-Voronoi percolation\nhas previously been studied.\n  Our approach builds on a recent breakthrough of Fraczyk, Mellick and Wilkens\n(arXiv:2307.01194) and provides an alternative proof strategy for Gaboriau's\nfixed price problem. As a further application of our result, we give a new\nclass of examples of non-amenable Cayley graphs that admit factor of iid bond\npercolations with a unique infinite cluster and arbitrarily small expected\ndegree, answering a question inspired by Hutchcroft-Pete (Invent. math. 221\n(2020)).}","main_category":"math.PR","categories":"math.PR,math.GR","published":"2025-04-03T09:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.02460v1","title":"Finite steady-state current defies non-Hermitian many-body localization","summary":"Non-Hermitian many-body localization (NH MBL) has emerged as a possible\nscenario for stable localization in open systems, as suggested by spectral\nindicators identifying a putative transition for finite system sizes.\n  In this work, we shift the focus to dynamical probes, specifically the\nsteady-state spin current, to investigate transport properties in a disordered,\nnon-Hermitian XXZ spin chain. Through exact diagonalization for small systems\nand tensor-network methods for larger chains, we demonstrate that the\nsteady-state current remains finite and decays exponentially with disorder\nstrength, showing no evidence of a transition up to disorder values far beyond\nthe previously claimed critical point. Our results reveal a stark discrepancy\nbetween spectral indicators, which suggest localization, and transport\nbehavior, which indicates delocalization. This highlights the importance of\ndynamical observables in characterizing NH MBL and suggests that traditional\nspectral measures may not fully capture the physics of non-Hermitian systems.\n  Additionally, we observe a non-commutativity of limits in system size and\ntime, further complicating the interpretation of finite-size studies. These\nfindings challenge the existence of NH MBL in the studied model and underscore\nthe need for alternative approaches to understand localization in non-Hermitian\nsettings.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,quant-ph","published":"2025-04-03T10:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.02461v1","title":"Am I Being Treated Fairly? A Conceptual Framework for Individuals to\n  Ascertain Fairness","summary":"Current fairness metrics and mitigation techniques provide tools for\npractitioners to asses how non-discriminatory Automatic Decision Making (ADM)\nsystems are. What if I, as an individual facing a decision taken by an ADM\nsystem, would like to know: Am I being treated fairly? We explore how to create\nthe affordance for users to be able to ask this question of ADM. In this paper,\nwe argue for the reification of fairness not only as a property of ADM, but\nalso as an epistemic right of an individual to acquire information about the\ndecisions that affect them and use that information to contest and seek\neffective redress against those decisions, in case they are proven to be\ndiscriminatory. We examine key concepts from existing research not only in\nalgorithmic fairness but also in explainable artificial intelligence,\naccountability, and contestability. Integrating notions from these domains, we\npropose a conceptual framework to ascertain fairness by combining different\ntools that empower the end-users of ADM systems. Our framework shifts the focus\nfrom technical solutions aimed at practitioners to mechanisms that enable\nindividuals to understand, challenge, and verify the fairness of decisions, and\nalso serves as a blueprint for organizations and policymakers, bridging the gap\nbetween technical requirements and practical, user-centered accountability.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC,cs.LG,cs.MA","published":"2025-04-03T10:28:19Z"}
{"aid":"http://arxiv.org/abs/2504.02466v1","title":"Optimal first-passage times of active Brownian particles under\n  stochastic resetting","summary":"We study the first-passage-time (FPT) properties of an active Brownian\nparticle under stochastic resetting to its initial configuration, comprising\nits position and orientation, to reach an absorbing wall in two dimensions.\nCoupling a perturbative approach for low P\\'eclet numbers, measuring the\nrelative importance of self-propulsion with respect to diffusion, with the\nrenewal framework for the stochastic resetting process, we derive analytical\nexpressions for the survival probability, the FPT probability density, and the\nassociated low-order moments. Depending on their initial orientation, the\nminimal mean FPT for active particles to reach the boundary can both decrease\nand increase relative to the passive counterpart. The associated optimal\nresetting rates depend non-trivially on the initial distance to the boundary\ndue to the intricate interplay of resetting, rotational Brownian noise, and\nactive motion.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech,physics.bio-ph","published":"2025-04-03T10:36:32Z"}
{"aid":"http://arxiv.org/abs/2504.02474v1","title":"Rigid m-percolation in limited-valence gels","summary":"Determining the onset of rigidity in gels is a fundamental challenge with\nsignificant practical implications across different applications.\nLimited-valence, or patchy-particle systems have proven to be a valuable model\nto study the relationship between microscopic interactions and macroscopic\nmechanical properties. It has been suggested that the emergence of rigidity\ncoincides with the formation of an infinitely spanning cluster of particles\nwith at least three bonds. This work explores this hypothesis, its\nimplications, and its broader applicability across a range of system\nparameters, by associating the emergence of rigidity with m-percolation\ntransition for m=3. The properties of m-percolation are developed using a\nmean-field theoretical approach validated with numerical simulations, and used\nto build phase and rigidity diagrams for different particle valences of both\nsingle-component systems and binary mixtures of patchy particles. The\ndifference between connectivity and rigidity percolation thresholds is found to\nreduce with increasing valence, providing an explanation for the challenges\nencountered in experimental attempts to distinguish isotropic connectivity\npercolation from the onset of rigidity. For binary mixtures, we found a robust\nminimum average valence, below which the gel is never rigid.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T10:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.02476v1","title":"Globular cluster distributions as a dynamical probe of dark matter","summary":"Globular clusters (GCs) act as massive probe particles traversing the dark\nmatter halos of their host galaxies. Gravitational dynamical friction due to\nhalo particles causes GC orbits to contract over time, providing a beyond-mean\nfield test of the cold dark matter paradigm. We explore the information content\nof such systems, using N-body and semianalytic simulations and scanning over a\nrange of initial conditions. We consider data from the ultradiffuse galaxies\nNGC5846-UDG1 and UDG-DF44, and from the Fornax dwarf spheroidal galaxy. The GC\nsystems of UDG1 and Fornax indicate the presence of dark matter halos,\nindependent of (but consistent with) stellar kinematics data. UDG-DF44 is too\ndiffuse for dynamical friction to give strong constraints. Our analysis can be\nextended to many additional galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA,hep-ph","published":"2025-04-03T10:53:02Z"}
{"aid":"http://arxiv.org/abs/2504.02479v1","title":"Hierarchical Policy-Gradient Reinforcement Learning for Multi-Agent\n  Shepherding Control of Non-Cohesive Targets","summary":"We propose a decentralized reinforcement learning solution for multi-agent\nshepherding of non-cohesive targets using policy-gradient methods. Our\narchitecture integrates target-selection with target-driving through Proximal\nPolicy Optimization, overcoming discrete-action constraints of previous Deep\nQ-Network approaches and enabling smoother agent trajectories. This model-free\nframework effectively solves the shepherding problem without prior dynamics\nknowledge. Experiments demonstrate our method's effectiveness and scalability\nwith increased target numbers and limited sensing capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.MA,cs.SY,eess.SY,stat.ML","published":"2025-04-03T10:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.02504v1","title":"Ethics of Blockchain Technologies","summary":"This chapter explores three key questions in blockchain ethics. First, it\nsituates blockchain ethics within the broader field of technology ethics,\noutlining its goals and guiding principles. Second, it examines the unique\nethical challenges of blockchain applications, including permissionless\nsystems, incentive mechanisms, and privacy concerns. Key obstacles, such as\nconceptual modeling and information asymmetries, are identified as critical\nissues. Finally, the chapter argues that blockchain ethics should be approached\nas an engineering discipline, emphasizing the analysis and design of trade-offs\nin complex systems.","main_category":"cs.CY","categories":"cs.CY,cs.DC","published":"2025-04-03T11:36:12Z"}
{"aid":"http://arxiv.org/abs/2504.02511v1","title":"Analytical Discovery of Manifold with Machine Learning","summary":"Understanding low-dimensional structures within high-dimensional data is\ncrucial for visualization, interpretation, and denoising in complex datasets.\nDespite the advancements in manifold learning techniques, key challenges-such\nas limited global insight and the lack of interpretable analytical\ndescriptions-remain unresolved. In this work, we introduce a novel framework,\nGAMLA (Global Analytical Manifold Learning using Auto-encoding). GAMLA employs\na two-round training process within an auto-encoding framework to derive both\ncharacter and complementary representations for the underlying manifold. With\nthe character representation, the manifold is represented by a parametric\nfunction which unfold the manifold to provide a global coordinate. While with\nthe complementary representation, an approximate explicit manifold description\nis developed, offering a global and analytical representation of smooth\nmanifolds underlying high-dimensional datasets. This enables the analytical\nderivation of geometric properties such as curvature and normal vectors.\nMoreover, we find the two representations together decompose the whole latent\nspace and can thus characterize the local spatial structure surrounding the\nmanifold, proving particularly effective in anomaly detection and\ncategorization. Through extensive experiments on benchmark datasets and\nreal-world applications, GAMLA demonstrates its ability to achieve\ncomputational efficiency and interpretability while providing precise geometric\nand structural insights. This framework bridges the gap between data-driven\nmanifold learning and analytical geometry, presenting a versatile tool for\nexploring the intrinsic properties of complex data sets.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-03T11:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.02519v1","title":"Data-Driven Object Tracking: Integrating Modular Neural Networks into a\n  Kalman Framework","summary":"This paper presents novel Machine Learning (ML) methodologies for\nMulti-Object Tracking (MOT), specifically designed to meet the increasing\ncomplexity and precision demands of Advanced Driver Assistance Systems (ADAS).\nWe introduce three Neural Network (NN) models that address key challenges in\nMOT: (i) the Single-Prediction Network (SPENT) for trajectory prediction, (ii)\nthe Single-Association Network (SANT) for mapping individual Sensor Object (SO)\nto existing tracks, and (iii) the Multi-Association Network (MANTa) for\nassociating multiple SOs to multiple tracks. These models are seamlessly\nintegrated into a traditional Kalman Filter (KF) framework, maintaining the\nsystem's modularity by replacing relevant components without disrupting the\noverall architecture. Importantly, all three networks are designed to be run in\na realtime, embedded environment. Each network contains less than 50k trainable\nparameters. Our evaluation, conducted on the public KITTI tracking dataset,\ndemonstrates significant improvements in tracking performance. SPENT reduces\nthe Root Mean Square Error (RMSE) by 50% compared to a standard KF, while SANT\nand MANTa achieve up to 95% accuracy in sensor object-to-track assignments.\nThese results underscore the effectiveness of incorporating task-specific NNs\ninto traditional tracking systems, boosting performance and robustness while\npreserving modularity, maintainability, and interpretability.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T12:13:38Z"}
{"aid":"http://arxiv.org/abs/2504.02536v1","title":"A Sensorimotor Vision Transformer","summary":"This paper presents the Sensorimotor Transformer (SMT), a vision model\ninspired by human saccadic eye movements that prioritize high-saliency regions\nin visual input to enhance computational efficiency and reduce memory\nconsumption. Unlike traditional models that process all image patches\nuniformly, SMT identifies and selects the most salient patches based on\nintrinsic two-dimensional (i2D) features, such as corners and occlusions, which\nare known to convey high-information content and align with human fixation\npatterns. The SMT architecture uses this biological principle to leverage\nvision transformers to process only the most informative patches, allowing for\na substantial reduction in memory usage that scales with the sequence length of\nselected patches. This approach aligns with visual neuroscience findings,\nsuggesting that the human visual system optimizes information gathering through\nselective, spatially dynamic focus. Experimental evaluations on Imagenet-1k\ndemonstrate that SMT achieves competitive top-1 accuracy while significantly\nreducing memory consumption and computational complexity, particularly when a\nlimited number of patches is used. This work introduces a saccade-like\nselection mechanism into transformer-based vision models, offering an efficient\nalternative for image analysis and providing new insights into biologically\nmotivated architectures for resource-constrained applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:37:44Z"}
{"aid":"http://arxiv.org/abs/2504.02540v1","title":"A 3D-1D-0D Multiscale Model of the Neuro-Glial-Vascular Unit for\n  Synaptic and Vascular Dynamics in the Dorsal Vagal Complex","summary":"Cerebral blood flow regulation is critical for brain function, and its\ndisruption is implicated in various neurological disorders. Many existing\nmodels do not fully capture the complex, multiscale interactions among neuronal\nactivity, astrocytic signaling, and vascular dynamics--especially in key\nbrainstem regions. In this work, we present a 3D-1D-0D multiscale computational\nframework for modeling the neuro-glial-vascular unit (NGVU) in the dorsal vagal\ncomplex (DVC). Our approach integrates a quadripartite synapse model--which\nrepresents the interplay among excitatory and inhibitory neurons, astrocytes,\nand vascular smooth muscle cells--with a hierarchical description of vascular\ndynamics that couples a three-dimensional microcirculatory network with a\none-dimensional macrocirculatory representation and a zero-dimensional synaptic\ncomponent. By linking neuronal spiking, astrocytic calcium and gliotransmitter\nsignaling, and vascular tone regulation, our model reproduces key features of\nfunctional hyperemia and elucidates the feedback loops that help maintain\ncerebral blood flow. Simulation results demonstrate that neurotransmitter\nrelease triggers astrocytic responses that modulate vessel radius to optimize\noxygen and nutrient delivery. This integrated framework, to our knowledge the\nfirst model to combine these elements for the NGVU in the DVC, provides a\nrobust and modular platform for future investigations into the pathophysiology\nof cerebral blood flow regulation and its role in autonomic control, including\nthe regulation of stomach function.","main_category":"q-bio.TO","categories":"q-bio.TO","published":"2025-04-03T12:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.02557v1","title":"Aging of ring polymeric topological glass formers via thermal quench","summary":"We investigate the dynamical response of glass-forming systems composed of\ntopologically constrained ring polymers subjected to an instantaneous thermal\nquench, employing large-scale molecular dynamics simulations. We demonstrate\nthat the onset of glassiness depends on polymer stiffness, with increased\nrigidity enhancing configurational constraints and delaying structural\nrelaxation. In the glassy regime, the system exhibits hallmark aging\ncharacteristics, as evidenced by two-time correlation functions, namely the\nmean square displacement and self-intermediate scattering function, which\ndisplay a clear dependence on the waiting time following the thermal quench.\nThe extracted relaxation timescale ($\\tau_\\alpha$) follows an approximate\nsimple aging scenario with waiting time ($t_w$), described by $\\tau_\\alpha \\sim\nt_w^b$, where $0.8 < b < 0.93$. Finally, we analyze the threading of rings\nduring the thermal quench, demonstrating that both increased and persistent\nthreading correlate with the emergence of glassiness. Moreover, the threading\npersistence timescale exhibits a strong correlation with the structural\nrelaxation timescale. Our study thus provides a comprehensive view of\nstructural relaxation and aging in dense ring polymer systems, highlighting the\ncritical roles of topological constraints and polymer stiffness in governing\nnon-equilibrium glassy dynamics.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T13:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.02567v1","title":"High harmonic generation in monolayer MoS2 controlled by resonant and\n  near-resonant pulses on ultrashort time scales","summary":"We report on experimental investigation of nonperturbative high harmonic\ngeneration (HHG) in monolayer MoS2 in the ultraviolet spectral region driven by\nmid-infrared light. We study how the HHG is influenced by pre-excitation of the\nmonolayer using resonant and near-resonant pulses in a pump-probe-like scheme.\nThe resonant light creates high density exciton population. Due to ultrafast\ndephasing caused by electron-electron scattering, the HHG is suppressed in the\npresence of pre-excited carriers. In the case of near-resonant excitation with\nphoton energy below the exciton transition, the dynamics of the observed\nsuppression of the HHG yield contains a fast component which is a consequence\nof momentum scattering at carriers, which are excited by two-photon transition\nwhen the two pulses temporally overlap in the sample. This interpretation is\nsupported by comparison of the experimental data with theoretical calculations\nof two-photon absorption spectrum of MoS2 monolayer. This work demonstrates a\npossibility to control HHG in lowdimensional materials on ultrashort timescales\nby combining the driving strong-field pulse with a weak near-resonant light.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T13:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.02568v1","title":"Enhanced coherent terahertz emission from critical superconducting\n  fluctuations in YBa$_2$Cu$_3$O$_{6.6}$","summary":"Coherent terahertz (THz) emission is emerging as a powerful new tool to probe\nsymmetry breakings in quantum materials. This method relies on second order\noptical nonlinearities and is complementary to second harmonic generation\nspectroscopy. Here, we report coherent THz emission from Josephson plasmons in\nunderdoped YBa$_2$Cu$_3$O$_{6+x}$, and find that the amplitude of the emitted\nfield increases dramatically close to the superconducting transition\ntemperature, $T_C$. We show theoretically how emission is enhanced by critical\nsuperconducting fluctuations, a nonlinear analogue of critical opalescence.\nThis observation is expected to be of general importance for the study of many\nthermal and quantum phase transitions.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-03T13:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.02571v1","title":"D$^{0}$-meson-tagged jet axes difference in proton-proton collisions at\n  $\\mathbf{\\sqrt{\\textit{s}} = 5.02}$ TeV","summary":"Heavy-flavor quarks produced in proton-proton (pp) collisions provide a\nunique opportunity to investigate the evolution of quark-initiated parton\nshowers from initial hard scatterings to final-state hadrons. By examining jets\nthat contain heavy-flavor hadrons, this study explores the effects of both\nperturbative and non-perturbative QCD on jet formation and structure. The\nangular differences between various jet axes, $\\Delta R_{\\rm axis}$, offer\ninsight into the radiation patterns and fragmentation of charm quarks. The\nfirst measurement of D$^{0}$-tagged jet axes differences in pp collisions at\n$\\sqrt{s}=5.02$ TeV by the ALICE experiment at the LHC is presented for jets\nwith transverse momentum $p_{\\rm T}^{\\rm ch~jet} \\geq 10$ ${\\rm GeV}/c$ and\nD$^0$ mesons with $p_{\\rm T}^{\\rm D^{0}} \\geq 5$ ${\\rm GeV}/c$. In this\nD$^0$-meson-tagged jet measurement, three jet axis definitions, each with\ndifferent sensitivities to soft, wide-angle radiation, are used: the Standard\naxis, Soft Drop groomed axis, and Winner-Takes-All axis. Measurements of the\nradial distributions of D$^0$ mesons with respect to the jet axes, $\\Delta\nR_{\\mathrm{axis-D^0}}$, are reported, along with the angle, $\\Delta\nR_{\\mathrm{axis}}$, between the three jet axes. The D$^{0}$ meson emerges as\nthe leading particle in these jets, closely aligning with the Winner-Takes-All\naxis and diverging from the Standard jet axis. The results also examine how\nvarying the sensitivity to soft radiation with grooming influences the\norientation of the Soft Drop jet axis, and uncover that charm-jet structure is\nmore likely to survive grooming when the Soft Drop axis is further from the\nD$^{0}$ direction, providing further evidence of the dead-cone effect recently\nmeasured by ALICE.","main_category":"hep-ex","categories":"hep-ex,nucl-ex","published":"2025-04-03T13:37:15Z"}
{"aid":"http://arxiv.org/abs/2504.02582v1","title":"Ambiguity Function Analysis of Affine Frequency Division Multiplexing\n  for Integrated Sensing and Communication","summary":"Affine frequency division multiplexing (AFDM) is a chirp-based multicarrier\nwaveform that was recently proposed for communication over doubly dispersive\nchannels. Given its chirp nature, AFDM is expected to have superior sensing\ncapabilities compared to orthogonal frequency division multiplexing (OFDM) and\nis thus a promising candidate for integrated sensing and communication (ISAC)\napplications. In this paper, we derive a closed-form expression for the\nambiguity function of AFDM waveforms modulated with $M$-ary quadrature\namplitude modulation (QAM) data symbols. We determine the condition on the\nchirp rate of the AFDM waveform that minimizes the sidelobes in the delay/range\ndomain in the presence of random $M$-ary QAM symbols, thereby improving overall\nsensing performance. Additionally, we find an approximate statistical\ndistribution for the magnitude of the derived ambiguity function. Simulation\nresults are presented to evaluate the sensing performance of the AFDM waveform\nfor various system parameters and to compare its peak-to-sidelobe ratio (PSLR)\nand integrated sidelobe ratio (ISLR) with those of OFDM.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-03T13:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.02596v1","title":"Cosmic ray ionisation of a post-impact early Earth atmosphere: Solar\n  cosmic ray ionisation must be considered in origin-of-life scenarios","summary":"Cosmic rays (CR), both solar and Galactic, have an ionising effect on the\nEarth's atmosphere and are thought to be important for prebiotic molecule\nproduction. In particular, the $\\rm{H_2}$-dominated atmosphere following an\nocean-vaporising impact is considered favourable to prebiotic molecule\nformation. We model solar and Galactic CR transport through a post-impact early\nEarth atmosphere at 200Myr. We aim to identify the differences in the resulting\nionisation rates, $\\zeta$, particularly at the Earth's surface during a period\nwhen the Sun was very active. We use a Monte Carlo model to describe CR\ntransport through the early Earth atmosphere, giving the CR spectra as a\nfunction of altitude. We calculate $\\zeta$ and the ion-pair production rate,\n$Q$, as a function of altitude due to Galactic and solar CR. The Galactic and\nsolar CR spectra are both affected by the Sun's rotation rate, $\\Omega$,\nbecause the solar wind velocity and magnetic field strength both depend on\n$\\Omega$ and influence CR transport. We consider a range of input spectra\nresulting from the range of possible $\\Omega$, from $3.5-15\\,\n\\Omega_{\\rm{\\odot}}$. To account for the possibility that the Galactic CR\nspectrum outside the Solar System varies over Gyr timescales, we compare\ntop-of-atmosphere $\\zeta$ resulting from two different scenarios. We also\nconsider the suppression of the CR spectra by a planetary magnetic field. We\nfind that $\\zeta$ and $Q$ due to CR are dominated by solar CR in the early\nEarth atmosphere for most cases. The corresponding $\\zeta$ at the early Earth's\nsurface ranges from $5 \\times 10^{-21}\\rm{s^{-1}}$ for $\\Omega =\n3.5\\,\\Omega_{\\rm{\\odot}}$ to $1 \\times 10^{-16}\\rm{s^{-1}}$ for $\\Omega =\n15\\,\\Omega_{\\rm{\\odot}}$. Thus if the young Sun was a fast rotator, it is\nlikely that solar CR had a significant effect on the chemistry at the Earth's\nsurface at the time when life is likely to have formed.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR,physics.space-ph","published":"2025-04-03T13:59:09Z"}
{"aid":"http://arxiv.org/abs/2504.02598v1","title":"Graphs are everywhere -- Psst! In Music Recommendation too","summary":"In recent years, graphs have gained prominence across various domains,\nespecially in recommendation systems. Within the realm of music recommendation,\ngraphs play a crucial role in enhancing genre-based recommendations by\nintegrating Mel-Frequency Cepstral Coefficients (MFCC) with advanced graph\nembeddings. This study explores the efficacy of Graph Convolutional Networks\n(GCN), GraphSAGE, and Graph Transformer (GT) models in learning embeddings that\neffectively capture intricate relationships between music items and genres\nrepresented within graph structures. Through comprehensive empirical\nevaluations on diverse real-world music datasets, our findings consistently\ndemonstrate that these graph-based approaches outperform traditional methods\nthat rely solely on MFCC features or collaborative filtering techniques.\nSpecifically, the graph-enhanced models achieve notably higher accuracy in\npredicting genre-specific preferences and offering relevant music suggestions\nto users. These results underscore the effectiveness of utilizing graph\nembeddings to enrich feature representations and exploit latent associations\nwithin music data, thereby illustrating their potential to advance the\ncapabilities of personalized and context-aware music recommendation systems.\nKeywords: graphs, recommendation systems, neural networks, MFCC","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-03T14:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.02601v1","title":"The Homotopy Category of Strongly flat modules","summary":"In this paper, we plan to build upon significant results by Amnon Neeman\nregarding the homotopy category of flat modules to study\n${\\mathbb{K}}({S\\rm{SF}}\\mbox{-}R)$, the homotopy category of $S$-strongly flat\nmodules, where $S$ is a multiplicatively closed subset of a commutative ring\n$R$. The category ${\\mathbb{K}}({S\\rm{SF}}\\mbox{-}R)$ is an intermediate\ntriangulated category that includes ${\\mathbb{K}}({\\rm{Prj}\\mbox{-}} R)$, the\nhomotopy category of projective $R$-modules, which is always well generated by\na result of Neeman, and is included in ${\\mathbb{K}}({\\rm{Flat}}\\mbox{-} R)$,\nthe homotopy category of flat $R$-modules, which is well generated if and only\nif $R$ is perfect, by a result of \\v{S}\\'{t}ov\\'{i}\\v{c}ek. We analyze\ncorresponding inclusion functors and the existence of their adjoints. In this\nway, we provide a new, fully faithful embedding of the homotopy category of\nprojectives to the homotopy category of $S$-strongly flat modules. We introduce\nthe notion of $S$-almost well generated triangulated categories. If $R$ is an\n$S$-almost perfect ring, ${\\mathbb{K}}({\\rm{Flat}}\\mbox{-} R)$ is $S$-almost\nwell generated. We show that the converse is true under certain conditions on\nthe ring $R$. We hope that this approach provides insights into the largely\nmysterious class of $S$-strongly flat modules.","main_category":"math.AC","categories":"math.AC,math.RT","published":"2025-04-03T14:03:52Z"}
{"aid":"http://arxiv.org/abs/2504.02602v1","title":"Leveraging Sparse Annotations for Leukemia Diagnosis on the Large\n  Leukemia Dataset","summary":"Leukemia is 10th most frequently diagnosed cancer and one of the leading\ncauses of cancer related deaths worldwide. Realistic analysis of Leukemia\nrequires White Blook Cells (WBC) localization, classification, and\nmorphological assessment. Despite deep learning advances in medical imaging,\nleukemia analysis lacks a large, diverse multi-task dataset, while existing\nsmall datasets lack domain diversity, limiting real world applicability. To\novercome dataset challenges, we present a large scale WBC dataset named Large\nLeukemia Dataset (LLD) and novel methods for detecting WBC with their\nattributes. Our contribution here is threefold. First, we present a large-scale\nLeukemia dataset collected through Peripheral Blood Films (PBF) from several\npatients, through multiple microscopes, multi cameras, and multi magnification.\nTo enhance diagnosis explainability and medical expert acceptance, each\nleukemia cell is annotated at 100x with 7 morphological attributes, ranging\nfrom Cell Size to Nuclear Shape. Secondly, we propose a multi task model that\nnot only detects WBCs but also predicts their attributes, providing an\ninterpretable and clinically meaningful solution. Third, we propose a method\nfor WBC detection with attribute analysis using sparse annotations. This\napproach reduces the annotation burden on hematologists, requiring them to mark\nonly a small area within the field of view. Our method enables the model to\nleverage the entire field of view rather than just the annotated regions,\nenhancing learning efficiency and diagnostic accuracy. From diagnosis\nexplainability to overcoming domain shift challenges, presented datasets could\nbe used for many challenging aspects of microscopic image analysis. The\ndatasets, code, and demo are available at:\nhttps://im.itu.edu.pk/sparse-leukemiaattri/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:04:02Z"}
{"aid":"http://arxiv.org/abs/2504.02607v1","title":"Learning Geometrically-Informed Lyapunov Functions with Deep\n  Diffeomorphic RBF Networks","summary":"The practical deployment of learning-based autonomous systems would greatly\nbenefit from tools that flexibly obtain safety guarantees in the form of\ncertificate functions from data. While the geometrical properties of such\ncertificate functions are well understood, synthesizing them using machine\nlearning techniques still remains a challenge. To mitigate this issue, we\npropose a diffeomorphic function learning framework where prior structural\nknowledge of the desired output is encoded in the geometry of a simple\nsurrogate function, which is subsequently augmented through an expressive,\ntopology-preserving state-space transformation. Thereby, we achieve an indirect\nfunction approximation framework that is guaranteed to remain in the desired\nhypothesis space. To this end, we introduce a novel approach to construct\ndiffeomorphic maps based on RBF networks, which facilitate precise, local\ntransformations around data. Finally, we demonstrate our approach by learning\ndiffeomorphic Lyapunov functions from real-world data and apply our method to\ndifferent attractor systems.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.SY,eess.SY","published":"2025-04-03T14:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.02608v1","title":"Input to the European Strategy for Particle Physics: Strong-Field\n  Quantum Electrodynamics","summary":"This document sets out the intention of the strong-field QED community to\ncarry out, both experimentally and numerically, high-statistics parametric\nstudies of quantum electrodynamics in the non-perturbative regime, at fields\napproaching and exceeding the critical or `Schwinger' field of QED. In this\nregime, several exotic and fascinating phenomena are predicted to occur that\nhave never been directly observed in the laboratory. These include\nBreit-Wheeler pair production, vacuum birefringence, and quantum radiation\nreaction. This experimental program will also serve as a stepping stone towards\nstudies of elusive phenomena such as elastic scattering of real photons and the\nconjectured perturbative breakdown of QED at extreme fields. State-of-the-art\nhigh-power laser facilities in Europe and beyond are starting to offer unique\nopportunities to study this uncharted regime at the intensity frontier, which\nis highly relevant also for the design of future multi-TeV lepton colliders.\nHowever, a transition from qualitative observational experiments to\nquantitative and high-statistics measurements can only be performed with\nlarge-scale collaborations and with systematic experimental programs devoted to\nthe optimisation of several aspects of these complex experiments, including\ndetector developments, stability and tolerances studies, and laser technology.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T14:10:23Z"}
{"aid":"http://arxiv.org/abs/2504.02610v1","title":"Do evidence-based active-engagement courses reduce the gender gap in\n  introductory physics?","summary":"Prior research suggests that using evidence-based pedagogies can not only\nimprove learning for all students, it can also reduce the gender gap. We\ndescribe the impact of physics education research based pedagogical techniques\nin flipped and active-engagement non-flipped courses on the gender gap observed\nwith validated conceptual surveys. We compare male and female students'\nperformance in courses which make significant use of evidence-based active\nengagement (EBAE) strategies with courses that primarily use lecture-based (LB)\ninstruction. The analysis presented here includes data from two-semester\nsequences of introductory algebra-based and calculus-based introductory physics\ncourses. The surveys used to assess student learning in the first and second\nsemester courses were the Force Concept Inventory and the Conceptual Survey of\nElectricity and Magnetism, respectively. The performance of male and female\nstudents in EBAE courses at a particular level is compared with LB courses in\ntwo situations: (I) the same instructor taught two courses, one of which was an\nEBAE course and the other an LB course, while the homework, recitations and\nfinal exams were kept the same, (II) student performance in all of the EBAE\ncourses taught by different instructors was averaged and compared with LB\ncourses of the same type also averaged over different instructors. In all\ncases, we find that students in courses which make significant use of EBAE\nstrategies, on average, outperformed students in courses of the same type using\nprimarily LB instruction even though there was no statistically significant\ndifference on the pretest before instruction. However, the gender gap persisted\neven in courses using EBAE methods. We also discuss correlations between the\nperformance of male and female students on the validated conceptual surveys and\nthe final exam, which had a heavy weight on quantitative problem solving.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-03T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.02625v1","title":"A spanning tree model for Khovanov homology, Rasmussen's s-invariant and\n  exotic discs in the $4$-ball","summary":"The checkerboard coloring of knot diagrams offers a graph-theoretical\napproach to address topological questions. Champanerkar and Kofman defined a\ncomplex generated by the spanning trees of a graph obtained from the\ncheckerboard coloring whose homology is the reduced Khovanov homology. Notably,\nthe differential in their chain complex was not explicitly defined. We\nexplicitly define the combinatorial form of the differential within the\nspanning tree complex. We additionally provide a description of Rasmussen's\n$s$-invariant within the context of the spanning tree complex. Applying our\ntechniques, we identify a new infinite family of knots where each of them\nbounds a set of exotic discs within the 4-ball.","main_category":"math.GT","categories":"math.GT,math.CO,math.QA","published":"2025-04-03T14:23:50Z"}
{"aid":"http://arxiv.org/abs/2504.02639v1","title":"Reservoir Computing: A New Paradigm for Neural Networks","summary":"A Literature Review of Reservoir Computing.\n  Even before Artificial Intelligence was its own field of computational\nscience, humanity has tried to mimic the activity of the human brain. In the\nearly 1940s the first artificial neuron models were created as purely\nmathematical concepts. Over the years, ideas from neuroscience and computer\nscience were used to develop the modern Neural Network. The interest in these\nmodels rose quickly but fell when they failed to be successfully applied to\npractical applications, and rose again in the late 2000s with the drastic\nincrease in computing power, notably in the field of natural language\nprocessing, for example with the state-of-the-art speech recognizer making\nheavy use of deep neural networks.\n  Recurrent Neural Networks (RNNs), a class of neural networks with cycles in\nthe network, exacerbates the difficulties of traditional neural nets. Slow\nconvergence limiting the use to small networks, and difficulty to train through\ngradient-descent methods because of the recurrent dynamics have hindered\nresearch on RNNs, yet their biological plausibility and their capability to\nmodel dynamical systems over simple functions makes then interesting for\ncomputational researchers.\n  Reservoir Computing emerges as a solution to these problems that RNNs\ntraditionally face. Promising to be both theoretically sound and\ncomputationally fast, Reservoir Computing has already been applied successfully\nto numerous fields: natural language processing, computational biology and\nneuroscience, robotics, even physics. This survey will explore the history and\nappeal of both traditional feed-forward and recurrent neural networks, before\ndescribing the theory and models of this new reservoir computing paradigm.\nFinally recent papers using reservoir computing in a variety of scientific\nfields will be reviewed.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T14:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.02641v1","title":"Utilizing 5G NR SSB Blocks for Passive Detection and Localization of\n  Low-Altitude Drones","summary":"With the exponential growth of the unmanned aerial vehicle (UAV) industry and\na broad range of applications expected to appear in the coming years, the\nemployment of traditional radar systems is becoming increasingly cumbersome for\nUAV supervision. Motivated by this emerging challenge, this paper investigates\nthe feasibility of employing integrated sensing and communication (ISAC)\nsystems implemented over current and future wireless networks to perform this\ntask. We propose a sensing mechanism based on the synchronization signal block\n(SSB) in the fifth-generation (5G) standard that performs sensing in a passive\nbistatic setting. By assuming planar arrays at the sensing nodes and according\nto the 5G standard, we consider that the SSB signal is sent in a grid of\northogonal beams that are multiplexed in time, with some of them pointing\ntoward a surveillance region where low-altitude drones can be flying. The\nCramer-Rao Bound (CRB) is derived as the theoretical bound for range and\nvelocity estimation. Our results demonstrate the potential of employing SSB\nsignals for UAV-like target localization at low SNR.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-03T14:36:11Z"}
{"aid":"http://arxiv.org/abs/2504.02646v1","title":"Prompt Optimization with Logged Bandit Data","summary":"We study how to use naturally available user feedback, such as clicks, to\noptimize large language model (LLM) pipelines for generating personalized\nsentences using prompts. Naive approaches, which estimate the policy gradient\nin the prompt space, suffer either from variance caused by the large action\nspace of prompts or bias caused by inaccurate reward predictions. To circumvent\nthese challenges, we propose a novel kernel-based off-policy gradient method,\nwhich estimates the policy gradient by leveraging similarity among generated\nsentences, substantially reducing variance while suppressing the bias.\nEmpirical results on our newly established suite of benchmarks demonstrate the\neffectiveness of the proposed approach in generating personalized descriptions\nfor movie recommendations, particularly when the number of candidate prompts is\nlarge.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-03T14:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.02681v1","title":"Convergence of permuted products of exponentials","summary":"Let $\\{A_{i,n}\\}$ be a triangular array of elements in a Banach algebra,\nwhose norms do not grow too fast, and whose row averages converge to $A$. Let\n$\\sigma \\in S(n)$ be a permutation drawn uniformly at random. If the array only\ncontains $o(n / \\log n)$ distinct elements, then almost surely, for all $0 < s\n< t < 1$, the permuted product of their exponentials $\\prod_{i = [s n]}^{[t n]}\ne^{A_{\\sigma(i),n}/n}$ converges in norm to $e^{(t - s) A}$. For an array of\nfinite-dimensional matrices, convergence holds without this restriction. The\nproof of the latter result consists of an estimate valid in a general Banach\nalgebra, and an application of a matrix concentration inequality.","main_category":"math.FA","categories":"math.FA,math.PR","published":"2025-04-03T15:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02684v1","title":"High Chern numbers and topological flat bands in high-field polarized\n  Kitaev magnets on the star lattice","summary":"The geometrically frustrated Kitaev magnets are demonstrated to be fertile\nplaygrounds that allow for the occurrence of exotic phenomena, including\ntopological phases and the thermal Hall effect. Notwithstanding the established\nconsensus that the field-polarized phase in the honeycomb-lattice Kitaev magnet\nhosts topological magnons exhibiting Chern numbers $C = \\pm1$, the nature of\nmagnon excitations in Kitaev magnets on the star lattice, a triangle-decorated\nhoneycomb lattice, has rarely been explored primarily due to its complicated\ngeometry. To this end, we study the band topology of magnons on the star\nlattice in the presence of a strong out-of-plane magnetic field using linear\nspin-wave theory. By calculating the Chern numbers of magnon bands, we find\nthat topological phase diagrams are predominantly composed of two distinct\ntopological phases whose Chern numbers are different by a sign in inverse\norder. Remarkably, each phase is characterized by a high Chern number of either\n$+2$ or $-2$. In addition, several topological flat bands with large flatness\nare identified. The two phases are separated by a dozen narrow topological\nhigh-Chern-number segments, whose region shrinks as the magnetic field\nincreases and vanishes eventually. We also find that the thermal Hall\nconductivity approaches zero at certain parameters, and it changes (keeps) its\nsign when crossing the topological phase-transition points (flat-band points).","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-03T15:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.02716v1","title":"Inner-layer asymptotics in partially perforated domains: coupling across\n  flat and oscillating interfaces","summary":"The article examines a boundary-value problem in a domain consisting of\nperforated and imperforate regions, with Neumann conditions prescribed at\n  the boundaries of the perforations. Assuming the porous medium has symmetric,\nperiodic structure with a small period $\\varepsilon,$ we analyse the limit\nbehavior of the problem as $\\varepsilon \\to 0.$ A crucial aspect of this study\nis deriving correct coupling conditions at the common interface, which is\nachieved using inner-layer asymptotics. For the flat interface, we construct\nand justify a complete asymptotic expansion of the solution in the\n$H^1$-Sobolev space. Furthermore, for the $\\varepsilon$-periodically\noscillating interface of amplitude $\\mathcal{O}(\\varepsilon),$ we provide an\napproximation to the solution and establish the corresponding asymptotic\nestimates in $H^1$-Sobolev spaces.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T15:59:45Z"}
{"aid":"http://arxiv.org/abs/2504.02720v1","title":"On the topology of real algebraic stacks","summary":"Motivated by questions arising in the theory of moduli spaces in real\nalgebraic geometry, we develop a range of methods to study the topology of the\nreal locus of a Deligne-Mumford stack over the real numbers. As an application,\nwe verify in several cases the Smith-Thom type inequality for stacks that we\nconjectured in an earlier work. This requires combining techniques from group\ntheory, algebraic geometry, and topology.","main_category":"math.AG","categories":"math.AG,math.AT,math.GN","published":"2025-04-03T16:03:13Z"}
{"aid":"http://arxiv.org/abs/2504.02721v1","title":"Phase transitions for interacting particle systems on random graphs","summary":"In this paper, we study weakly interacting diffusion processes on random\ngraphs. Our main focus is on the properties of the mean-field limit and, in\nparticular, on the nonuniqueness of stationary states. By extending classical\nbifurcation analysis to include multichromatic interaction potentials and\nrandom graph structures, we explicitly identify bifurcation points and relate\nthem to the eigenvalues of the graphon integral operator. Furthermore, we\ncharacterize the resulting McKean-Vlasov PDE as a gradient flow with respect to\na suitable metric. We combine these theoretical results with the spectral\nanalysis of the linearized McKean-Vlasov operator and extensive numerical\nsimulations to gain insight into the stability and long-term behaviour of\nstationary solutions. In addition, we provide strong evidence that (minus) the\ninteraction energy of the interacting particle system serves as a natural order\nparameter. In particular, beyond the transition point and for multichromatic\ninteractions, we observe an energy cascade that is strongly linked to the\ndynamical metastability of the system.","main_category":"math.DS","categories":"math.DS,cs.NA,math-ph,math.MP,math.NA,math.PR","published":"2025-04-03T16:04:23Z"}
{"aid":"http://arxiv.org/abs/2504.02741v1","title":"A Complete Classification of Fourier Summation Formulas on the real line","summary":"We completely classify Fourier summation formulas of the form $$\n  \\int_{\\mathbb{R}} \\widehat{\\varphi}(t) d\\mu(t)=\\sum_{n=0}^{\\infty}\na(\\lambda_n)\\varphi(\\lambda_n), $$ that hold for any test function $\\varphi$,\nwhere $\\widehat\\varphi$ is the Fourier transform of $\\varphi$, $\\mu$ is a fixed\ncomplex measure on $\\mathbb{R}$ and $a:\\{\\lambda_n\\}_{n\\geq 0}\\to\\mathbb{C}$ is\na fixed function. We only assume the decay condition $$ \\int_{\\mathbb{R}}\n\\frac{d |\\mu|(t)}{(1+t^2)^{c_1}} + \\sum_{n\\geq 0} |a(\\lambda_n)|e^{-c_2\n|\\lambda_n|}<\\infty, $$ for some $c_1,c_2>0$. This completes the work initiated\nby the first author previously, where the condition $c_1\\leq 1$ was required.\nWe prove that any such pair $(\\mu,a)$ can be uniquely associated with a\nholomorphic map $F(z)$ in the upper-half space that is both almost periodic and\nbelongs to a certain higher index Nevanlinna class. The converse is also true:\nFor any such function $F$ it is possible to generate a Fourier summation pair\n$(\\mu,a)$. We provide important examples of such summation formulas not\ncontemplated by the previous results, such as Selberg's trace formula.","main_category":"math.CA","categories":"math.CA,math.MG,math.NT","published":"2025-04-03T16:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.02747v1","title":"GEOPARD: Geometric Pretraining for Articulation Prediction in 3D Shapes","summary":"We present GEOPARD, a transformer-based architecture for predicting\narticulation from a single static snapshot of a 3D shape. The key idea of our\nmethod is a pretraining strategy that allows our transformer to learn plausible\ncandidate articulations for 3D shapes based on a geometric-driven search\nwithout manual articulation annotation. The search automatically discovers\nphysically valid part motions that do not cause detachments or collisions with\nother shape parts. Our experiments indicate that this geometric pretraining\nstrategy, along with carefully designed choices in our transformer\narchitecture, yields state-of-the-art results in articulation inference in the\nPartNet-Mobility dataset.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-03T16:35:17Z"}
{"aid":"http://arxiv.org/abs/2504.02753v1","title":"Robust entangled photon generation by Floquet-engineered two-colour\n  pulses","summary":"Quantum emitters driven by resonant two-photon excitation are a leading\nsource for deterministically generated entangled photon pairs, essential for\nscalable photonic quantum technologies. However, conventional resonant schemes\nare highly sensitive to laser power fluctuations and pose additional\nexperimental challenges for emitters with small biexciton binding energies.\nHere, we demonstrate how biexciton preparation schemes with significantly\nimproved robustness and reduced laser filtering requirements can be identified\nusing a novel design principle beyond resonant and adiabatic driving: ultrafast\nall-optical Floquet engineering. This is achieved by employing two strongly and\nsymmetrically detuned dichromatic pulses, whose superposition generates a\nstroboscopic Hamiltonian that enables direct coupling between ground and\nbiexciton states. Moreover, a pulse delay serves as a tuning knob, introducing\nan effective magnetic field that concentrates the Bloch sphere trajectory at\nthe biexciton state for a wide range of parameters, making biexciton\npreparation particularly robust. Experimentally, we achieve a biexciton\noccupation exceeding 96% and preserve photon-pair entanglement with a fidelity\nof 93.4%. Our scheme highlights the great impact of Floquet-engineered\nmulticolour excitation protocols for on-demand quantum light sources.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-03T16:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.02757v1","title":"Echoes of the hidden: Uncovering coordination beyond network structure","summary":"The study of connectivity and coordination has drawn increasing attention in\nrecent decades due to their central role in driving markets, shaping societal\ndynamics, and influencing biological systems. Traditionally, observable\nconnections, such as phone calls, financial transactions, or social media\nconnections, have been used to infer coordination and connectivity. However,\nincomplete, encrypted, or fragmented data, alongside the ubiquity of\ncommunication platforms and deliberate obfuscation, often leave many real-world\nconnections hidden. In this study, we demonstrate that coordinating individuals\nexhibit shared bursty activity patterns, enabling their detection even when\nobservable links between them are sparse or entirely absent. We further propose\na generative model based on the network of networks formalism to account for\nthe mechanisms driving this collaborative burstiness, attributing it to shock\npropagation across networks rather than isolated individual behavior. Model\nsimulations demonstrate that when observable connection density is below 70\\%,\nburstiness significantly improves coordination detection compared to\nstate-of-the-art temporal and structural methods. This work provides a new\nperspective on community and coordination dynamics, advancing both theoretical\nunderstanding and practical detection. By laying the foundation for identifying\nhidden connections beyond observable network structures, it enables detection\nacross different platforms, alongside enhancing system behavior understanding,\ninformed decision-making, and risk mitigation.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-03T16:49:58Z"}
{"aid":"http://arxiv.org/abs/2504.02780v1","title":"From Consumption to Collaboration: Measuring Interaction Patterns to\n  Augment Human Cognition in Open-Ended Tasks","summary":"The rise of Generative AI, and Large Language Models (LLMs) in particular, is\nfundamentally changing cognitive processes in knowledge work, raising critical\nquestions about their impact on human reasoning and problem-solving\ncapabilities. As these AI systems become increasingly integrated into\nworkflows, they offer unprecedented opportunities for augmenting human thinking\nwhile simultaneously risking cognitive erosion through passive consumption of\ngenerated answers. This tension is particularly pronounced in open-ended tasks,\nwhere effective solutions require deep contextualization and integration of\ndomain knowledge. Unlike structured tasks with established metrics, measuring\nthe quality of human-LLM interaction in such open-ended tasks poses significant\nchallenges due to the absence of ground truth and the iterative nature of\nsolution development. To address this, we present a framework that analyzes\ninteraction patterns along two dimensions: cognitive activity mode (exploration\nvs. exploitation) and cognitive engagement mode (constructive vs. detrimental).\nThis framework provides systematic measurements to evaluate when LLMs are\neffective tools for thought rather than substitutes for human cognition,\nadvancing theoretical understanding and practical guidance for developing AI\nsystems that protect and augment human cognitive capabilities.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-03T17:20:36Z"}
{"aid":"http://arxiv.org/abs/2504.02785v1","title":"Beating full state tomography for unentangled spectrum estimation","summary":"How many copies of a mixed state $\\rho \\in \\mathbb{C}^{d \\times d}$ are\nneeded to learn its spectrum? To date, the best known algorithms for spectrum\nestimation require as many copies as full state tomography, suggesting the\npossibility that learning a state's spectrum might be as difficult as learning\nthe entire state. We show that this is not the case in the setting of\nunentangled measurements, by giving a spectrum estimation algorithm that uses\n$n = O(d^3\\cdot (\\log\\log(d) / \\log(d))^4 )$ copies of $\\rho$, which is\nasymptotically fewer than the $n = \\Omega(d^3)$ copies necessary for full state\ntomography. Our algorithm is inspired by the technique of local moment matching\nfrom classical statistics, and shows how it can be applied in the quantum\nsetting.\n  As an important subroutine in our spectrum estimation algorithm, we give an\nestimator of the $k$-th moment $\\operatorname{tr}(\\rho^k)$ which performs\nunentangled measurements and uses $O(d^{3-2/k})$ copies of $\\rho$ in order to\nachieve a constant multiplicative error. This directly translates to an\nadditive-error estimator of quantum Renyi entropy of order $k$ with the same\nnumber of copies.\n  Finally, we present numerical evidence that the sample complexity of spectrum\nestimation can only improve over full state tomography by a sub-polynomial\nfactor. Specifically, for spectrum learning with fully entangled measurements,\nwe run simulations which suggest a lower bound of $\\Omega(d^{2 - \\gamma})$\ncopies for any constant $\\gamma > 0$. From this, we conclude the current best\nlower bound of $\\Omega(d)$ is likely not tight.","main_category":"quant-ph","categories":"quant-ph,cs.CC,cs.DS","published":"2025-04-03T17:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.02796v1","title":"Suppression of decoherence dynamics by a dissipative bath at strong\n  coupling","summary":"Control of decoherence in open quantum systems has become a topic of great\ninterest due to the emergence of quantum technologies that depend on quantum\ncoherent effects. In this work, we investigate the decoherence dynamics of\nsystems coupled to multiple baths through noncommuting systems' operators, and\nbeyond the weak system-bath coupling limit. By building on cooperative effects\nbetween baths, we propose a novel strategy to mitigate rapid decoherence.\nConcretely, we study the dynamics of a qubit coupled to multiple environments\nwith arbitrary interaction strengths, and along different coordinates. Based on\ninsights gained on the decoherence dynamics from the analytical Effective\nHamiltonian method, we carry out numerical simulations using the Reaction\nCoordinate quantum master equation method. In contrast to standard\nexpectations, we show that when the system strongly interacts with a decohering\nbath, increasing its coupling to a second, dissipative bath slows down the\ndecoherence dynamics. Our work offers insights into the preservation of quantum\ncoherences in open quantum systems based on frustration effects, by utilizing\ncooperative effects between different heat baths.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T17:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.02803v1","title":"Beyond Discretization: A Continuous-Time Framework for Event Generation\n  in Neuromorphic Pixels","summary":"A novel continuous-time framework is proposed for modeling neuromorphic image\nsensors in the form of an initial canonical representation with analytical\ntractability. Exact simulation algorithms are developed in parallel with\nclosed-form expressions that characterize the model's dynamics. This framework\nenables the generation of synthetic event streams in genuine continuous-time,\nwhich combined with the analytical results, reveal the underlying mechanisms\ndriving the oscillatory behavior of event data presented in the literature.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-03T17:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.02804v1","title":"Convergence of Ricci flow and long-time existence of Harmonic map heat\n  flow","summary":"For an ancient Ricci flow asymptotic to a compact integrable shrinker, or a\nRicci flow developing a finite-time singularity modelled on the shrinker, we\nestablish the long-time existence of a harmonic map heat flow between the Ricci\nflow and the shrinker for all times. This provides a global parabolic gauge for\nthe Ricci flow and implies the uniqueness of the tangent flow without modulo\nany diffeomorphisms.\n  We present two main applications: First, we construct and classify all\nancient Ricci flows asymptotic to any compact integrable shrinker, showing that\nthey converge exponentially. Second, we obtain the optimal convergence rate at\nsingularities modelled on the shrinker, characterized by the first negative\neigenvalue of the stability operator for the entropy. In particular, we show\nthat any Ricci flow developing a round $\\mathbb S^n$ singularity converges at\nleast at the rate $(-t)^{\\frac{n+1}{n-1}}$.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-03T17:50:14Z"}
{"aid":"http://arxiv.org/abs/2504.02827v1","title":"On Vanishing Variance in Transformer Length Generalization","summary":"It is a widely known issue that Transformers, when trained on shorter\nsequences, fail to generalize robustly to longer ones at test time. This raises\nthe question of whether Transformer models are real reasoning engines, despite\ntheir impressive abilities in mathematical problem solving and code synthesis.\nIn this paper, we offer a vanishing variance perspective on this issue. To the\nbest of our knowledge, we are the first to demonstrate that even for today's\nfrontier models, a longer sequence length results in a decrease in variance in\nthe output of the multi-head attention modules. On the argmax retrieval and\ndictionary lookup tasks, our experiments show that applying layer normalization\nafter the attention outputs leads to significantly better length\ngeneralization. Our analyses attribute this improvement to a reduction-though\nnot a complete elimination-of the distribution shift caused by vanishing\nvariance.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.04738v1","title":"Automating the Search for Small Hard Examples to Approximation\n  Algorithms","summary":"Given an approximation algorithm $A$, we want to find the input with the\nworst approximation ratio, i.e., the input for which $A$'s output's objective\nvalue is the worst possible compared to the optimal solution's objective value.\nSuch hard examples shed light on the approximation algorithm's weaknesses, and\ncould help us design better approximation algorithms. When the inputs are\ndiscrete (e.g., unweighted graphs), one can find hard examples for small input\nsizes using brute-force enumeration. However, it's not obvious how to do this\nwhen the input space is continuous, as in makespan minimization or bin packing.\n  We develop a technique for finding small hard examples for a large class of\napproximation algorithms. Our algorithm works by constructing a decision tree\nrepresentation of the approximation algorithm and then running a linear program\nfor each leaf node of the decision tree. We implement our technique in Python,\nand demonstrate it on the longest-processing-time (LPT) heuristic for makespan\nminimization.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-07T05:32:37Z"}
{"aid":"http://arxiv.org/abs/2504.04747v1","title":"Two is Better than One: Efficient Ensemble Defense for Robust and\n  Compact Models","summary":"Deep learning-based computer vision systems adopt complex and large\narchitectures to improve performance, yet they face challenges in deployment on\nresource-constrained mobile and edge devices. To address this issue, model\ncompression techniques such as pruning, quantization, and matrix factorization\nhave been proposed; however, these compressed models are often highly\nvulnerable to adversarial attacks. We introduce the \\textbf{Efficient Ensemble\nDefense (EED)} technique, which diversifies the compression of a single base\nmodel based on different pruning importance scores and enhances ensemble\ndiversity to achieve high adversarial robustness and resource efficiency. EED\ndynamically determines the number of necessary sub-models during the inference\nstage, minimizing unnecessary computations while maintaining high robustness.\nOn the CIFAR-10 and SVHN datasets, EED demonstrated state-of-the-art robustness\nperformance compared to existing adversarial pruning techniques, along with an\ninference speed improvement of up to 1.86 times. This proves that EED is a\npowerful defense solution in resource-constrained environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T05:41:35Z"}
{"aid":"http://arxiv.org/abs/2504.04756v1","title":"Continuous Locomotive Crowd Behavior Generation","summary":"Modeling and reproducing crowd behaviors are important in various domains\nincluding psychology, robotics, transport engineering and virtual environments.\nConventional methods have focused on synthesizing momentary scenes, which have\ndifficulty in replicating the continuous nature of real-world crowds. In this\npaper, we introduce a novel method for automatically generating continuous,\nrealistic crowd trajectories with heterogeneous behaviors and interactions\namong individuals. We first design a crowd emitter model. To do this, we obtain\nspatial layouts from single input images, including a segmentation map,\nappearance map, population density map and population probability, prior to\ncrowd generation. The emitter then continually places individuals on the\ntimeline by assigning independent behavior characteristics such as agents'\ntype, pace, and start/end positions using diffusion models. Next, our crowd\nsimulator produces their long-term locomotions. To simulate diverse actions, it\ncan augment their behaviors based on a Markov chain. As a result, our overall\nframework populates the scenes with heterogeneous crowd behaviors by\nalternating between the proposed emitter and simulator. Note that all the\ncomponents in the proposed framework are user-controllable. Lastly, we propose\na benchmark protocol to evaluate the realism and quality of the generated\ncrowds in terms of the scene-level population dynamics and the individual-level\ntrajectory accuracy. We demonstrate that our approach effectively models\ndiverse crowd behavior patterns and generalizes well across different\ngeographical environments. Code is publicly available at\nhttps://github.com/InhwanBae/CrowdES .","main_category":"cs.CV","categories":"cs.CV,cs.LG,cs.RO","published":"2025-04-07T06:08:59Z"}
{"aid":"http://arxiv.org/abs/2504.04774v1","title":"BayesCPF: Enabling Collective Perception in Robot Swarms with Degrading\n  Sensors","summary":"The collective perception problem -- where a group of robots perceives its\nsurroundings and comes to a consensus on an environmental state -- is a\nfundamental problem in swarm robotics. Past works studying collective\nperception use either an entire robot swarm with perfect sensing or a swarm\nwith only a handful of malfunctioning members. A related study proposed an\nalgorithm that does account for an entire swarm of unreliable robots but\nassumes that the sensor faults are known and remain constant over time. To that\nend, we build on that study by proposing the Bayes Collective Perception Filter\n(BayesCPF) that enables robots with continuously degrading sensors to\naccurately estimate the fill ratio -- the rate at which an environmental\nfeature occurs. Our main contribution is the Extended Kalman Filter within the\nBayesCPF, which helps swarm robots calibrate for their time-varying sensor\ndegradation. We validate our method across different degradation models,\ninitial conditions, and environments in simulated and physical experiments. Our\nfindings show that, regardless of degradation model assumptions, fill ratio\nestimation using the BayesCPF is competitive to the case if the true sensor\naccuracy is known, especially when assumptions regarding the model and initial\nsensor accuracy levels are preserved.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T07:06:11Z"}
{"aid":"http://arxiv.org/abs/2504.04791v1","title":"Localization and Tracking for Cooperative Users in Multi-RIS-assisted\n  Systems: Theoretical Analysis and Principles of Interpretations","summary":"Localization and tracking (LocTrack) are fundamental enablers for a wide\nrange of emerging applications. Reconfigurable intelligent surfaces (RISs) have\nemerged as key components for enhancing the LocTrack performance. This paper\ninvestigates a multi-RIS-assisted multi-user (MRMU) LocTrack system, where\nmultiple RISs collaboratively reflect the position-bearing signals for\ninformation fusion at the base station, leveraging spatial-temporal\ncorrelations in user positions. While studies have shown these correlations\nimprove localization accuracy, their trade-offs with system complexity remain\nunclear. To address this gap, we characterize the effectiveness of\nspatial-temporal correlation priors (STPs) utilization in MRMU LocTrack systems\nusing a metric, termed efficiency of correlation (EoC). To further elucidate\ncorrelation propagation and RIS interactions, we provide a \"correlation\ninformation routing\" interpretation of EoC through random walk theory. EoC\nprovides a principled performance evaluation metric, that enables system\ndesigners to balance localization accuracy enhancement against the increased\ncomplexity. Additionally, we investigate the error propagation phenomenon,\nanalyzing its convergence and asymptotic behavior in MRMU LocTrack systems.\nFinally, we validate the theoretical results through extensive numerical\nsimulations.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T07:35:41Z"}
{"aid":"http://arxiv.org/abs/2504.04804v1","title":"DebGCD: Debiased Learning with Distribution Guidance for Generalized\n  Category Discovery","summary":"In this paper, we tackle the problem of Generalized Category Discovery (GCD).\nGiven a dataset containing both labelled and unlabelled images, the objective\nis to categorize all images in the unlabelled subset, irrespective of whether\nthey are from known or unknown classes. In GCD, an inherent label bias exists\nbetween known and unknown classes due to the lack of ground-truth labels for\nthe latter. State-of-the-art methods in GCD leverage parametric classifiers\ntrained through self-distillation with soft labels, leaving the bias issue\nunattended. Besides, they treat all unlabelled samples uniformly, neglecting\nvariations in certainty levels and resulting in suboptimal learning. Moreover,\nthe explicit identification of semantic distribution shifts between known and\nunknown classes, a vital aspect for effective GCD, has been neglected. To\naddress these challenges, we introduce DebGCD, a \\underline{Deb}iased learning\nwith distribution guidance framework for \\underline{GCD}. Initially, DebGCD\nco-trains an auxiliary debiased classifier in the same feature space as the GCD\nclassifier, progressively enhancing the GCD features. Moreover, we introduce a\nsemantic distribution detector in a separate feature space to implicitly boost\nthe learning efficacy of GCD. Additionally, we employ a curriculum learning\nstrategy based on semantic distribution certainty to steer the debiased\nlearning at an optimized pace. Thorough evaluations on GCD benchmarks\ndemonstrate the consistent state-of-the-art performance of our framework,\nhighlighting its superiority. Project page: https://visual-ai.github.io/debgcd/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.04809v1","title":"Select Me! When You Need a Tool: A Black-box Text Attack on Tool\n  Selection","summary":"Tool learning serves as a powerful auxiliary mechanism that extends the\ncapabilities of large language models (LLMs), enabling them to tackle complex\ntasks requiring real-time relevance or high precision operations. Behind its\npowerful capabilities lie some potential security issues. However, previous\nwork has primarily focused on how to make the output of the invoked tools\nincorrect or malicious, with little attention given to the manipulation of tool\nselection. To fill this gap, we introduce, for the first time, a black-box\ntext-based attack that can significantly increase the probability of the target\ntool being selected in this paper. We propose a two-level text perturbation\nattack witha coarse-to-fine granularity, attacking the text at both the word\nlevel and the character level. We conduct comprehensive experiments that\ndemonstrate the attacker only needs to make some perturbations to the tool's\ntextual information to significantly increase the possibility of the target\ntool being selected and ranked higher among the candidate tools. Our research\nreveals the vulnerability of the tool selection process and paves the way for\nfuture research on protecting this process.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T08:04:23Z"}
{"aid":"http://arxiv.org/abs/2504.04811v1","title":"Cross-Frame OTFS Parameter Estimation Based On Chinese Remainder Theorem","summary":"Orthogonal time-frequency space (OTFS) is a potential waveform for integrated\nsensing and communications (ISAC) systems because it can manage communication\nand sensing metrics in one unified domain, and has better performance in high\nmobility scenarios. In practice, a target might come from far distance or with\nultra-high speed. However, the max unambiguous range and max tolerable velocity\nof OTFS-ISAC system is limited by the unambiguous round-trip delay and Doppler\nshift, which are related to OTFS frame, i.e., time slots and subcarrier\nspacing, respectively. To enlarge the sensing range, a novel OTFS cross-frame\nranging and velocity estimation model as well as its corresponding method based\non the Chinese remainder theorem (CRT) are proposed in this paper. By designing\nco-prime numbers of subcarriers and time slots in different subframes, the\ndifference in the responses of the subframes for a target can be used to\nestimate the distance and velocity of an out-of-range target. Several frame\nstructures are further designed for specific sensing scenarios, such as target\nwith ultra-high speed or at far distance. Simulation results show that the\nproposed method can achieve significantly better performance in NMSE compared\nwith the classic sensing methods under the condition of same time and frequency\nresources.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T08:05:32Z"}
{"aid":"http://arxiv.org/abs/2504.04820v1","title":"Dark energy under a gauge symmetry: A review of gauged quintessence and\n  its implications","summary":"We review the gauged quintessence scenario, wherein the quintessence scalar\nfield responsible for dark energy is promoted to a complex field charged under\na dark $U(1)$ gauge symmetry. This construction leads to new and potentially\nrich cosmological phenomenology. After a concise recap of the standard\nquintessence scenario, we highlight how a $U(1)$ gauge invariance alters the\ndynamics of the scalar and the associated dark gauge boson. We survey the\nevolution of both fields across cosmic history, discuss their possible\nproduction via a misalignment mechanism, and examine implications for the\nHubble tension. We also comment on potential non-gravitational signals of\ngauged quintessence through kinetic mixing (the dark photon vector portal).","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-07T08:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.04822v1","title":"How to build transfer matrices, one wave at a time","summary":"We show how to build the closed-form expression of transfer matrices for wave\npropagation in layered media. The key is to represent the propagation across\nthe piece-wise constant medium as a superposition of a finite number of paths\n($2^{N-1}$ paths for a medium with $N$ layers), each one of them contributing a\ncertain phase change (corresponding to signed sums of the phase change in each\nindividual layer) and amplitude change (corresponding to the pattern of\ntransmission and/or reflection associated to each path). The outlined technique\nis combinatorial in nature: it begins with the linear governing equations in\nfrequency domain, whose fundamental solution is known, then it enumerates the\nfinite number of paths across the overall system, then computes their\nassociated phase and amplitude change, and finally adds all the possible paths\nto find the final result. Beyond providing physical insight, this\n``path-by-path'' construction can also circumvent the need for transfer matrix\nnumerical multiplication in many practical applications, potentially enabling\nsubstantial computational savings.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cond-mat.other","published":"2025-04-07T08:22:38Z"}
{"aid":"http://arxiv.org/abs/2504.04830v1","title":"X-ray particle tracking velocimetry for rheological characterization:\n  Application to material extrusion additive manufacturing","summary":"We introduce X-ray Particle Tracking Velocimetry (XPTV) as a promising method\nto quantitatively resolve the velocity field and associated rheological\nquantities of polymer melt flow within the nozzle of a fused filament\nfabrication (FFF) printer. Employing tungsten powder as tracer particles\nembedded within a polymer filament, we investigate melt flow dynamics through\nan aluminum nozzle in a custom-designed experimental setup, based on commercial\ndesigns. The velocity profiles obtained via XPTV reveal significant deviations\nfrom classical Newtonian flow, highlighting complex heterogeneous and\nnon-isothermal behavior within the melt. From these measurements, we determine\nthe local infinitesimal strain rate tensor and correlate flow-induced\nnon-Newtonian effects to spatially varying temperature distributions,\nreflecting incomplete thermal homogenization within the nozzle. Our findings\ndemonstrate the capability of XPTV to quantify both velocity fields and\nrheological properties, underscoring its potential as a future tool for\ninvestigating opaque polymer melt flows in additive manufacturing, industrial\nprocessing, and rheology. To our knowledge, this represents the first reported\napplication of XPTV in polymer melt rheology, offering a new approach to\naddress measurement challenges previously inaccessible to conventional optical\nmethods.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-07T08:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.04832v1","title":"Pullback and Weil transfer on Chow groups","summary":"In the paper ``Weil transfer of algebraic cycles'', published by the second\nauthor in Indagationes Mathematicae about 25 years ago, a Weil transfer map for\nChow groups of smooth algebraic varieties has been constructed and its basic\nproperties have been established. The proof of commutativity with the pullback\nhomomorphisms given there used a variant of Moving Lemma suffering a lack of\nreference. Here we are providing an alternative proof based on a more\ncontemporary construction of the pullback via a deformation to the normal cone.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T08:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.04838v1","title":"Palatable pellets -- a fundamental framework to produce sustainable\n  pellets via extrusion","summary":"In pellet manufacturing various ingredients in powder or particle form are\npressed together into a dense product, a pellet, with better nutritional,\ncalorific, and handling properties than the individual input ingredients\nthemselves. For this reason, pellet manufacturing is applied to up-convert\nindustrial co-products from various sectors like agriculture, forestry, human\nfood, or bio-energy production, to valorize their waste-streams into more\nvaluable products. However, processing such diverse ingredient streams presents\nan industrial challenge and raises the important scientific question: \"Under\nwhich process conditions do loose pellet ingredients bind together to form a\nmechanically rigid and durable pellet?\" In this work we provide new answers to\nthis old research question by determining the causal relationships between\nprocessing parameters and physical pellet quality. Systematic pelleting\nexperiments reveal that the interplay of typical process parameters such as\nsteam conditioning temperature, production rate, and die geometry, can be\nunderstood in an overarching framework of process interactions. We introduce\nthe concept of the \"stickiness temperature,\" $\\mathrm{T^*}$, marking the onset\nof critical enthalpic reactions necessary for pellet agglomeration, the\nboundary condition for bond formation within a pellet. Our framework\ndemonstrates how $T^*$ is achieved through a combination of steam conditioning\nand friction, and how these conditions can be controlled by adjusting process\nparameters. Our findings underscore the significance of pellet temperature in\nconjunction with die residence time, for optimizing physical pellet quality\nwhile reducing energy consumption per kilogram of product. Validating our\nresults in a trial and leveraging existing literature data, our framework\nprovides handles to intelligently enhance the efficiency and sustainability of\npelleting processes.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-07T08:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.04840v1","title":"Unsupervised Ego- and Exo-centric Dense Procedural Activity Captioning\n  via Gaze Consensus Adaptation","summary":"Even from an early age, humans naturally adapt between exocentric (Exo) and\negocentric (Ego) perspectives to understand daily procedural activities.\nInspired by this cognitive ability, in this paper, we propose a novel\nUnsupervised Ego-Exo Adaptation for Dense Video Captioning (UEA-DVC) task,\nwhich aims to predict the time segments and descriptions for target view\nvideos, while only the source view data are labeled during training. Despite\nprevious works endeavoring to address the fully-supervised single-view or\ncross-view dense video captioning, they lapse in the proposed unsupervised task\ndue to the significant inter-view gap caused by temporal misalignment and\nirrelevant object interference. Hence, we propose a Gaze Consensus-guided\nEgo-Exo Adaptation Network (GCEAN) that injects the gaze information into the\nlearned representations for the fine-grained alignment between the Ego and Exo\nviews. Specifically, the Score-based Adversarial Learning Module (SALM)\nincorporates a discriminative scoring network to learn unified view-invariant\nrepresentations for bridging distinct views from a global level. Then, the Gaze\nConsensus Construction Module (GCCM) utilizes gaze representations to\nprogressively calibrate the learned global view-invariant representations for\nextracting the video temporal contexts based on focusing regions. Moreover, the\ngaze consensus is constructed via hierarchical gaze-guided consistency losses\nto spatially and temporally align the source and target views. To support our\nresearch, we propose a new EgoMe-UEA-DVC benchmark and experiments demonstrate\nthe effectiveness of our method, which outperforms many related methods by a\nlarge margin. The code will be released.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-07T08:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.04855v1","title":"BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents","summary":"Detecting biases in structured data is a complex and time-consuming task.\nExisting automated techniques are limited in diversity of data types and\nheavily reliant on human case-by-case handling, resulting in a lack of\ngeneralizability. Currently, large language model (LLM)-based agents have made\nsignificant progress in data science, but their ability to detect data biases\nis still insufficiently explored. To address this gap, we introduce the first\nend-to-end, multi-agent synergy framework, BIASINSPECTOR, designed for\nautomatic bias detection in structured data based on specific user\nrequirements. It first develops a multi-stage plan to analyze user-specified\nbias detection tasks and then implements it with a diverse and well-suited set\nof tools. It delivers detailed results that include explanations and\nvisualizations. To address the lack of a standardized framework for evaluating\nthe capability of LLM agents to detect biases in data, we further propose a\ncomprehensive benchmark that includes multiple evaluation metrics and a large\nset of test cases. Extensive experiments demonstrate that our framework\nachieves exceptional overall performance in structured data bias detection,\nsetting a new milestone for fairer data applications.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T09:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.04856v1","title":"Approach to optimal quantum transport via states over time","summary":"We approach the problem of constructing a quantum analogue of the immensely\nfruitful classical transport cost theory of Monge from a new angle. Going back\nto the original motivations, by which the transport is a bilinear function of a\nmass distribution (without loss of generality a probability density) and a\ntransport plan (a stochastic kernel), we explore the quantum version where the\nmass distribution is generalised to a density matrix, and the transport plan to\na completely positive and trace preserving map.\n  These two data are naturally integrated into their Jordan product, which is\ncalled state over time (``stote''), and the transport cost is postulated to be\na linear function of it.\n  We explore the properties of this transport cost, as well as the optimal\ntransport cost between two given states (simply the minimum cost over all\nsuitable transport plans). After that, we analyse in considerable detail the\ncase of unitary invariant cost, for which we can calculate many costs\nanalytically. These findings suggest that our quantum transport cost is\nqualitatively different from Monge's classical transport.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-07T09:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.04891v1","title":"Leveraging Large Language Models for Cost-Effective, Multilingual\n  Depression Detection and Severity Assessment","summary":"Depression is a prevalent mental health disorder that is difficult to detect\nearly due to subjective symptom assessments. Recent advancements in large\nlanguage models have offered efficient and cost-effective approaches for this\nobjective. In this study, we evaluated the performance of four LLMs in\ndepression detection using clinical interview data. We selected the best\nperforming model and further tested it in the severity evaluation scenario and\nknowledge enhanced scenario. The robustness was evaluated in complex diagnostic\nscenarios using a dataset comprising 51074 statements from six different mental\ndisorders. We found that DeepSeek V3 is the most reliable and cost-effective\nmodel for depression detection, performing well in both zero-shot and few-shot\nscenarios, with zero-shot being the most efficient choice. The evaluation of\nseverity showed low agreement with the human evaluator, particularly for mild\ndepression. The model maintains stably high AUCs for detecting depression in\ncomplex diagnostic scenarios. These findings highlight DeepSeek V3s strong\npotential for text-based depression detection in real-world clinical\napplications. However, they also underscore the need for further refinement in\nseverity assessment and the mitigation of potential biases to enhance clinical\nreliability.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-07T09:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.04893v1","title":"SCAM: A Real-World Typographic Robustness Evaluation for Multimodal\n  Foundation Models","summary":"Typographic attacks exploit the interplay between text and visual content in\nmultimodal foundation models, causing misclassifications when misleading text\nis embedded within images. However, existing datasets are limited in size and\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\nattack images to date, containing 1,162 images across hundreds of object\ncategories and attack words. Through extensive benchmarking of Vision-Language\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\ndegrade performance, and identify that training data and model architecture\ninfluence the susceptibility to these attacks. Our findings reveal that\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\nattacks, validating their use in research. Our work provides a comprehensive\nresource and empirical insights to facilitate future research toward robust and\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\nin this paper under https://huggingface.co/datasets/BLISS-e-V/SCAM, along with\nthe code for evaluations at https://github.com/Bliss-e-V/SCAM.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T10:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.04904v1","title":"A kinetic CMA diagram","summary":"We present a kinetic Clemmow-Mullaly-Allis (CMA) diagram by systematically\nanalysing the kinetic effects on the wave propagation in a homogeneous thermal\nplasma. The differences between the cold and kinetic CMA diagrams are outlined.\nIt is found that new boundaries for weakly damped left- and right-handed\ncircularly polarized waves are located above the ion and electron cyclotron\nfrequency lines in the kinetic CMA diagram. Additionally, Langmuir waves in the\nkinetic CMA diagram occupy a specific region between the new Langmuir wave\nboundary and the plasma frequency line, while in the cold CMA diagram, they\nexist on the plasma frequency line. The extraordinary-Bernstein mode\ntransformation frequency lines in the kinetic CMA diagram replace the hybrid\nresonant frequency lines of the cold CMA diagram, with discontinuities between\ndifferent cyclotron harmonics. These new boundaries partition the parameter\nspace in the kinetic CMA diagram differently, leading to new inverse wave\nnormal surfaces in the regions bounded by new boundaries. The kinetic CMA\ndiagram not only contributes to a basic understanding of wave properties in\nthermal plasmas, but also can provide a powerful tool to explore new possible\npropagation paths.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T10:22:29Z"}
{"aid":"http://arxiv.org/abs/2504.04915v1","title":"Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question\n  Answering via White-Box and Black-Box LLM Collaboration","summary":"Retrieval-Augmented Generation (RAG) systems often struggle to handle\nmulti-hop question-answering tasks accurately due to irrelevant context\nretrieval and limited complex reasoning capabilities. We introduce Collab-RAG,\na collaborative training framework that leverages mutual enhancement between a\nwhite-box small language model (SLM) and a blackbox large language model (LLM)\nfor RAG. Specifically, the SLM decomposes complex queries into simpler\nsub-questions, thus enhancing the accuracy of the retrieval and facilitating\nmore effective reasoning by the black-box LLM. Concurrently, the black-box LLM\nprovides feedback signals to improve the SLM's decomposition capability. We\nobserve that Collab-RAG relies solely on supervision from an affordable\nblack-box LLM without additional distillation from frontier LLMs, yet\ndemonstrates strong generalization across multiple black-box LLMs. Experimental\nevaluations across five multi-hop QA datasets demonstrate that Collab-RAG\nsubstantially outperforms existing black-box-only and SLM fine-tuning baselines\nby 1.8%-14.2% on average. In particular, our fine-tuned 3B SLM surpasses a\nfrozen 32B LLM in question decomposition, highlighting the efficiency of\nCollab-RAG in improving reasoning and retrieval for complex questions. The code\nof Collab-RAG is available on https://github.com/ritaranx/Collab-RAG/.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-04-07T10:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.04925v1","title":"Scaling regimes in slow quenches within a gapped phase","summary":"We consider the finite-time quench dynamics in the quantum transverse field\nIsing model which exhibits a second order phase transition from a paramagnetic\nto a ferromagnetic phase, as the transverse magnetic field is decreased. These\ndynamics have been thoroughly investigated in previous studies when the\ncritical point is crossed during the quench; here, we quench the system from\ndeep in the paramagnetic phase to just above the critical field so that the\nsystem remains in the gapped phase throughout the quench duration. On linearly\nquenching the infinitely large system, we find that the behavior of mean\nlongitudinal defect density and mean transverse magnetization at the end of the\nquench falls into three distinct scaling regimes as the quench time is\nincreased. For sufficiently small quench times, these observables remain\nroughly constant, but for larger quench times, a crossover occurs from the\nKibble-Zurek scaling law to the quadratic quench rate law when the Kibble-Zurek\ntime is of the order of relaxation time at the final quench field. These\nresults are shown analytically using power series and uniform asymptotic\nexpansions of the exact solution of the model, and also compared with an\nadiabatic perturbation theory in the third regime. We find that the above\nmentioned scaling regimes hold for quenches within the ferromagnetic phase\nalso, and provide a general scaling argument for crossover from the\nKibble-Zurek regime to an adiabatic regime for slow quenches within a gapped\nphase.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T11:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.04936v1","title":"Constrained Gaussian Process Motion Planning via Stein Variational\n  Newton Inference","summary":"Gaussian Process Motion Planning (GPMP) is a widely used framework for\ngenerating smooth trajectories within a limited compute time--an essential\nrequirement in many robotic applications. However, traditional GPMP approaches\noften struggle with enforcing hard nonlinear constraints and rely on Maximum a\nPosteriori (MAP) solutions that disregard the full Bayesian posterior. This\nlimits planning diversity and ultimately hampers decision-making. Recent\nefforts to integrate Stein Variational Gradient Descent (SVGD) into motion\nplanning have shown promise in handling complex constraints. Nonetheless, these\nmethods still face persistent challenges, such as difficulties in strictly\nenforcing constraints and inefficiencies when the probabilistic inference\nproblem is poorly conditioned. To address these issues, we propose a novel\nconstrained Stein Variational Gaussian Process Motion Planning (cSGPMP)\nframework, incorporating a GPMP prior specifically designed for trajectory\noptimization under hard constraints. Our approach improves the efficiency of\nparticle-based inference while explicitly handling nonlinear constraints. This\nadvancement significantly broadens the applicability of GPMP to motion planning\nscenarios demanding robust Bayesian inference, strict constraint adherence, and\ncomputational efficiency within a limited time. We validate our method on\nstandard benchmarks, achieving an average success rate of 98.57% across 350\nplanning tasks, significantly outperforming competitive baselines. This\ndemonstrates the ability of our method to discover and use diverse trajectory\nmodes, enhancing flexibility and adaptability in complex environments, and\ndelivering significant improvements over standard baselines without incurring\nmajor computational costs.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-07T11:20:11Z"}
{"aid":"http://arxiv.org/abs/2504.04938v1","title":"Initial Error Tolerant Distributed Mean Field Control under Partial and\n  Discrete Information","summary":"In this paper, an initial error tolerant distributed mean field control\nmethod under partial and discrete information is introduced, where each agent\nonly has discrete observations on its own state. First, we study agents'\nbehavior in linear quadratic mean field games (LQMFGs) under heterogeneous\nerroneous information of the initial mean field state (MF-S), and formulate the\nrelationships between initial errors and systemic deviations. Next, by\ncapturing the initial error affection on the private trajectory of an agent, we\ngive a distributed error estimation method based on maximum likelihood\nestimation (MLE), where each agent estimates information errors only based on\ndiscrete observations on its private trajectory. Furthermore, we establish an\nerror-based segmented state estimation method, design the initial error\ntolerant distributed mean field control method (IET-DMFC), and demonstrate the\nconsistent property of state estimation as observation frequency increases.\nFinally, simulations are performed to verify the efficiency of the algorithm\nand the consistent properties.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T11:21:17Z"}
{"aid":"http://arxiv.org/abs/2504.04978v1","title":"The eigenvalue one property of finite groups, I","summary":"We prove a conjecture of Dekimpe, De Rock and Penninckx concerning the\nexistence of eigenvalues one in certain elements of finite groups acting\nirreducibly on a real vector space of odd dimension. This yields a sufficient\ncondition for a closed flat manifold to be an $R_{\\infty}$-manifold.","main_category":"math.GR","categories":"math.GR","published":"2025-04-07T12:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.04984v1","title":"Finding large $k$-colorable induced subgraphs in (bull, chair)-free and\n  (bull,E)-free graphs","summary":"We study the Max Partial $k$-Coloring problem, where we are given a\nvertex-weighted graph, and we ask for a maximum-weight induced subgraph that\nadmits a proper $k$-coloring. For $k=1$ this problem coincides with Maximum\nWeight Independent Set, and for $k=2$ the problem is equivalent (by\ncomplementation) to Minimum Odd Cycle Transversal. Furthermore, it generalizes\n$k$-Coloring. We show that Max Partial $k$-Coloring on $n$-vertex instances\nwith clique number $\\omega$ can be solved in time\n  * $n^{\\mathcal{O}(k\\omega)}$ if the input graph excludes the bull and the\nchair as an induced subgraph,\n  * $n^{\\mathcal{O}(k\\omega \\log n)}$ if the input graph excludes the bull and\nE as an induced subgraph.\n  This implies that $k$-Coloring can be solved in polynomial time in the former\nclass, and in quasipolynomial-time in the latter one.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-07T12:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.05013v1","title":"Performances of far and near-field thermophotonic refrigeration devices\n  from the detailed-balance approach","summary":"We study a near-field thermophotonic (NF-TPX) refrigerating device,\nconsisting of a lightemitting diode and a photovoltaic cell in close proximity.\nCalculations are performed in the frame of the detailed-balance approach. We\nstudy how thermal radiation, separation distance and LED temperature can affect\nboth cooling power and coefficient of performance. More specifically, we assess\nthe impact of bandgap energy and internal quantum efficiency for an artificial\nmaterial on those cooling performances. For a particular device made of GaAs\nand/or AlGaAs we show that, in the near-field regime, the cooling power can be\nincreased by one order of magnitude compared to far field. However, a 10%\nreduction of the quantum efficiency can lead to a decrease of the cooling power\nby two orders of magnitude. Finally, we compare existing literature data on\nelectroluminescent, TPX and thermoelectric cooling with our detailed balance\nprediction, which highlights design-rule requirements for NF-TPX cooling\ndevices.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-07T12:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.05040v1","title":"InstructionBench: An Instructional Video Understanding Benchmark","summary":"Despite progress in video large language models (Video-LLMs), research on\ninstructional video understanding, crucial for enhancing access to\ninstructional content, remains insufficient. To address this, we introduce\nInstructionBench, an Instructional video understanding Benchmark, which\nchallenges models' advanced temporal reasoning within instructional videos\ncharacterized by their strict step-by-step flow. Employing GPT-4, we formulate\nQ\\&A pairs in open-ended and multiple-choice formats to assess both\nCoarse-Grained event-level and Fine-Grained object-level reasoning. Our\nfiltering strategies exclude questions answerable purely by common-sense\nknowledge, focusing on visual perception and analysis when evaluating Video-LLM\nmodels. The benchmark finally contains 5k questions across over 700 videos. We\nevaluate the latest Video-LLMs on our InstructionBench, finding that\nclosed-source models outperform open-source ones. However, even the best model,\nGPT-4o, achieves only 53.42\\% accuracy, indicating significant gaps in temporal\nreasoning. To advance the field, we also develop a comprehensive instructional\nvideo dataset with over 19k Q\\&A pairs from nearly 2.5k videos, using an\nautomated data generation framework, thereby enriching the community's research\nresources.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.05041v1","title":"Segmented Trajectory Optimization for Autonomous Parking in Unstructured\n  Environments","summary":"This paper presents a Segmented Trajectory Optimization (STO) method for\nautonomous parking, which refines an initial trajectory into a dynamically\nfeasible and collision-free one using an iterative SQP-based approach. STO\nmaintains the maneuver strategy of the high-level global planner while allowing\ncurvature discontinuities at switching points to improve maneuver efficiency.\nTo ensure safety, a convex corridor is constructed via GJK-accelerated ellipse\nshrinking and expansion, serving as safety constraints in each iteration.\nNumerical simulations in perpendicular and reverse-angled parking scenarios\ndemonstrate that STO enhances maneuver efficiency while ensuring safety.\nMoreover, computational performance confirms its practicality for real-world\napplications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T13:07:17Z"}
{"aid":"http://arxiv.org/abs/2504.05043v1","title":"Displacement Memory Effect from Supersymmetry","summary":"We explain the recent results regarding the displacement memory effect (DME)\nof plane gravitational waves using supersymmetric quantum mechanics. This novel\napproach stems from the fact that both geodesic and Schr\\\"odinger equations are\nSturm-Liouville boundary value problems. Supersymmetry provides a unified\nframework for P\\\"oschl-Teller and Scarf profiles and restores the critical\nvalues of wave amplitudes for DME in a natural way. Within our framework, we\nobtain a compact formula for DME in terms of the asymptotic values of the\nsuperpotential and the geodesics. In addition, this new technique enables us to\nbuild plane and gravitational waves with 2-transverse directions using\nsuperpartner potentials. Lastly, we study DME within a singular wave profile\ninspired by supersymmetric quantum mechanics, which shows the broader\napplicability of our method.","main_category":"gr-qc","categories":"gr-qc,hep-th,math-ph,math.MP","published":"2025-04-07T13:12:51Z"}
{"aid":"http://arxiv.org/abs/2504.05045v1","title":"Attention-Augmented Inverse Reinforcement Learning with Graph\n  Convolutions for Multi-Agent Task Allocation","summary":"Multi-agent task allocation (MATA) plays a vital role in cooperative\nmulti-agent systems, with significant implications for applications such as\nlogistics, search and rescue, and robotic coordination. Although traditional\ndeep reinforcement learning (DRL) methods have been shown to be promising,\ntheir effectiveness is hindered by a reliance on manually designed reward\nfunctions and inefficiencies in dynamic environments. In this paper, an inverse\nreinforcement learning (IRL)-based framework is proposed, in which multi-head\nself-attention (MHSA) and graph attention mechanisms are incorporated to\nenhance reward function learning and task execution efficiency. Expert\ndemonstrations are utilized to infer optimal reward densities, allowing\ndependence on handcrafted designs to be reduced and adaptability to be\nimproved. Extensive experiments validate the superiority of the proposed method\nover widely used multi-agent reinforcement learning (MARL) algorithms in terms\nof both cumulative rewards and task execution efficiency.","main_category":"cs.LG","categories":"cs.LG,cs.MA","published":"2025-04-07T13:14:45Z"}
{"aid":"http://arxiv.org/abs/2504.05071v1","title":"AI-Driven Tactical Communications and Networking for Defense: A Survey\n  and Emerging Trends","summary":"The integration of Artificial Intelligence (AI) in military communications\nand networking is reshaping modern defense strategies, enhancing secure data\nexchange, real-time situational awareness, and autonomous decision-making. This\nsurvey explores how AI-driven technologies improve tactical communication\nnetworks, radar-based data transmission, UAV-assisted relay systems, and\nelectronic warfare resilience. The study highlights AI applications in adaptive\nsignal processing, multi-agent coordination for network optimization,\nradar-assisted target tracking, and AI-driven electronic countermeasures. Our\nwork introduces a novel three-criteria evaluation methodology. It\nsystematically assesses AI applications based on general system objectives,\ncommunications constraints in the military domain, and critical tactical\nenvironmental factors. We analyze key AI techniques for different types of\nlearning applied to multi-domain network interoperability and distributed data\ninformation fusion in military operations. We also address challenges such as\nadversarial AI threats, the real-time adaptability of autonomous communication\nnetworks, and the limitations of current AI models under battlefield\nconditions. Finally, we discuss emerging trends in self-healing networks,\nAI-augmented decision support systems, and intelligent spectrum allocation. We\nprovide a structured roadmap for future AI-driven defense communications and\nnetworking research.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-07T13:38:32Z"}
{"aid":"http://arxiv.org/abs/2504.05073v1","title":"The Drinfeld-Grinberg-Kazhdan theorem and embedding codimension of the\n  arc space","summary":"We prove an extension of the theorem of Drinfeld, Grinberg and Kazhdan to\narcs with arbitrary residue field. As an application we show that the embedding\ncodimension is generically constant on each irreducible subset of the arc space\nwhich is not contained in the singular locus. In the case of maximal divisorial\nsets, this relates the corresponding finite formal models with invariants of\nsingularities of the underlying variety.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T13:39:56Z"}
{"aid":"http://arxiv.org/abs/2504.05085v1","title":"Characterisation of conserved and reacting moieties in chemical reaction\n  networks","summary":"A detailed understanding of biochemical networks at the molecular level is\nessential for studying complex cellular processes. In this paper, we provide a\ncomprehensive description of biochemical networks by considering individual\natoms and chemical bonds. To address combinatorial complexity, we introduce a\nwell-established approach to group similar types of information within\nbiochemical networks. A conserved moiety is a set of atoms whose association is\ninvariant across all reactions in a network. A reacting moiety is a set of\nbonds that are either broken, formed, or undergo a change in bond order in at\nleast one reaction in the network. By mathematically identifying these\nmoieties, we establish the biological significance of conserved and reacting\nmoieties according to the mathematical properties of the stoichiometric matrix.\nWe also present a novel decomposition of the stoichiometric matrix based on\nconserved moieties. This approach bridges the gap between graph theory, linear\nalgebra, and biological interpretation, thus opening up new horizons in the\nstudy of chemical reaction networks.","main_category":"q-bio.MN","categories":"q-bio.MN","published":"2025-04-07T13:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.05087v1","title":"All-to-all connectivity of Rydberg-atom-based quantum processors with\n  messenger qubits","summary":"Rydberg atom arrays is a promising platform for programmable quantum\nsimulators and universal quantum processors. A major challenge threatening the\nscalability of this platform is the limited qubit connectivity due to the\nfinite range of interactions between atoms. We discuss an approach to realize\ndynamical all-to-all connectivity between qubits with the use of moving atoms,\nwhich we referred to as messenger qubits, that interact with the computational\nqubits of the processor. We propose four specific architectures capitalizing on\nthis idea and compare them one to another, as well as to alternative\napproaches. We argue that the use of messenger qubits, while posing new\ntechnological challenges, promises further development of the\nRydberg-atom-based platform.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T13:57:24Z"}
{"aid":"http://arxiv.org/abs/2504.05090v1","title":"Radial Epiderivative Based Line Search Methods in Nonconvex and\n  Nonsmooth Box-Constrained Optimization","summary":"In this paper, we develop a novel radial epiderivative-based line search\nmethods for solving nonsmooth and nonconvex box-constrained optimization\nproblems. The rationale for employing the concept of radial epiderivatives is\nthat they provide necessary and sufficient conditions for both identifying\nglobal descent directions and achieving global minimum of nonconvex and\nnondifferentiable functions. These properties of radial epiderivatives are\ncombined with line search methods to develop iterative solution algorithms. The\nproposed methods generate search directions at each iteration where global\ndescent directions and stopping criteria are performed by using the abilities\nof the radial epiderivatives. We use two line search methods, that is cyclic\ncoordinate and particle swarm optimization techniques to generate search\ndirections, selecting only those that exhibit descent, as determined by using\napproximately computed radial epiderivatives at the current point. As a\nparticular case, these methods are applied for minimizing concave functions. In\nthe paper, two convergence theorems are proved. One of them deals with the\ngeneral line search method and covers only the set of directions generated by\nthe method. The second convergence theorem deals with minimizing concave\nfunctions which deals not only with the generated set of directions but covers\nthe whole set of feasible solutions. The performance of the proposed method is\nevaluated by using well-known benchmark problems from the literature. The\nresults demonstrate the advantages of the proposed approach in generating\noptimal or near-optimal solutions.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T13:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.05094v1","title":"Hollow Victory: How Malicious Proposers Exploit Validator Incentives in\n  Optimistic Rollup Dispute Games","summary":"Blockchain systems, such as Ethereum, are increasingly adopting layer-2\nscaling solutions to improve transaction throughput and reduce fees. One\npopular layer-2 approach is the Optimistic Rollup, which relies on a mechanism\nknown as a dispute game for block proposals. In these systems, validators can\nchallenge blocks that they believe contain errors, and a successful challenge\nresults in the transfer of a portion of the proposer's deposit as a reward. In\nthis paper, we reveal a structural vulnerability in the mechanism: validators\nmay not be awarded a proper profit despite winning a dispute challenge. We\ndevelop a formal game-theoretic model of the dispute game and analyze several\nscenarios, including cases where the proposer controls some validators and\ncases where a secondary auction mechanism is deployed to induce additional\nparticipation. Our analysis demonstrates that under current designs, the\ncompetitive pressure from validators may be insufficient to deter malicious\nbehavior. We find that increased validator competition, paradoxically driven by\nhigher rewards or participation, can allow a malicious proposer to\nsignificantly lower their net loss by capturing value through mechanisms like\nauctions. To address this, we propose countermeasures such as an escrowed\nreward mechanism and a commit-reveal protocol. Our findings provide critical\ninsights into enhancing the economic security of layer-2 scaling solutions in\nblockchain networks.","main_category":"cs.GT","categories":"cs.GT,cs.CR","published":"2025-04-07T14:00:46Z"}
{"aid":"http://arxiv.org/abs/2504.05102v1","title":"Underreporting of Intimate Partner Violence in Brazil","summary":"According to WHO (2013), in general 30% of all women worldwide who have been\nin a relationship have experienced physical and/or sexual violence by their\nintimate partner. However, only a small percentage of intimate partner violence\n(IPV) victims report it to the police. This phenomenon of under-reporting is\nknown as ``dark figure''. This paper aims to investigate the factors associated\nwith the reporting decision of IPV victims to the police in Brazil using the\nthird wave of the ``Pesquisa de Condi\\c{c}\\~{o}es Socioecon\\^{o}micas e\nViol\\^{e}ncia Dom\\'{e}stica e Familiar contra a Mulher ($PCSVDF^{Mulher}$)''.\nUsing a bivariate probit regression model with sample selection, we found that\nolder white women, those who do not tolerate domestic violence, and women who\nhave experienced physical violence are more likely to report IPV to the police.\nIn contrast, married women, those with partners who abuse alcohol and those who\nwitnessed or knew that their mothers had experienced IPV, are less likely to\nreport it to law enforcement.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC,stat.OT","published":"2025-04-07T14:09:35Z"}
{"aid":"http://arxiv.org/abs/2504.05118v1","title":"VAPO: Efficient and Reliable Reinforcement Learning for Advanced\n  Reasoning Tasks","summary":"We present VAPO, Value-based Augmented Proximal Policy Optimization framework\nfor reasoning models., a novel framework tailored for reasoning models within\nthe value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the\nQwen 32B pre-trained model, attains a state-of-the-art score of\n$\\mathbf{60.4}$. In direct comparison under identical experimental settings,\nVAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B\nand DAPO by more than 10 points. The training process of VAPO stands out for\nits stability and efficiency. It reaches state-of-the-art performance within a\nmere 5,000 steps. Moreover, across multiple independent runs, no training\ncrashes occur, underscoring its reliability. This research delves into long\nchain-of-thought (long-CoT) reasoning using a value-based reinforcement\nlearning framework. We pinpoint three key challenges that plague value-based\nmethods: value model bias, the presence of heterogeneous sequence lengths, and\nthe sparsity of reward signals. Through systematic design, VAPO offers an\nintegrated solution that effectively alleviates these challenges, enabling\nenhanced performance in long-CoT reasoning tasks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T14:21:11Z"}
{"aid":"http://arxiv.org/abs/2504.05125v1","title":"Interpretable Style Takagi-Sugeno-Kang Fuzzy Clustering","summary":"Clustering is an efficient and essential technique for exploring latent\nknowledge of data. However, limited attention has been given to the\ninterpretability of the clusters detected by most clustering algorithms. In\naddition, due to the homogeneity of data, different groups of data have their\nown homogeneous styles. In this paper, the above two aspects are considered,\nand an interpretable style Takagi-Sugeno-Kang (TSK) fuzzy clustering\n(IS-TSK-FC) algorithm is proposed. The clustering behavior of IS-TSK-FC is\nfully guided by the TSK fuzzy inference on fuzzy rules. In particular, samples\nare grouped into clusters represented by the corresponding consequent vectors\nof all fuzzy rules learned in an unsupervised manner. This can explain how the\nclusters are generated in detail, thus making the underlying decision-making\nprocess of the IS-TSK-FC interpretable. Moreover, a series of style matrices\nare introduced to facilitate the consequents of fuzzy rules in IS-TSK-FC by\ncapturing the styles of clusters as well as the nuances between different\nstyles. Consequently, all the fuzzy rules in IS-TSK-FC have powerful data\nrepresentation capability. After determining the antecedents of all the fuzzy\nrules, the optimization problem of IS-TSK-FC can be iteratively solved in an\nalternation manner. The effectiveness of IS-TSK-FC as an interpretable\nclustering tool is validated through extensive experiments on benchmark\ndatasets with unknown implicit/explicit styles. Specially, the superior\nclustering performance of IS-TSK-FC is demonstrated on case studies where\ndifferent groups of data present explicit styles. The source code of IS-TSK-FC\ncan be downloaded from https://github.com/gusuhang10/IS-TSK-FC.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T14:28:56Z"}
{"aid":"http://arxiv.org/abs/2504.05151v1","title":"Error formulas for block rational Krylov approximations of matrix\n  functions","summary":"This paper investigates explicit expressions for the error associated with\nthe block rational Krylov approximation of matrix functions. Two formulas are\nproposed, both derived from characterizations of the block FOM residual. The\nfirst formula employs a block generalization of the residual polynomial, while\nthe second leverages the block collinearity of the residuals. A posteriori\nerror bounds based on the knowledge of spectral information of the argument are\nderived and tested on a set of examples. Notably, both error formulas and their\ncorresponding upper bounds do not require the use of quadratures for their\npractical evaluation.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T14:56:55Z"}
{"aid":"http://arxiv.org/abs/2504.05164v1","title":"Balancing Task-invariant Interaction and Task-specific Adaptation for\n  Unified Image Fusion","summary":"Unified image fusion aims to integrate complementary information from\nmulti-source images, enhancing image quality through a unified framework\napplicable to diverse fusion tasks. While treating all fusion tasks as a\nunified problem facilitates task-invariant knowledge sharing, it often\noverlooks task-specific characteristics, thereby limiting the overall\nperformance. Existing general image fusion methods incorporate explicit task\nidentification to enable adaptation to different fusion tasks. However, this\ndependence during inference restricts the model's generalization to unseen\nfusion tasks. To address these issues, we propose a novel unified image fusion\nframework named \"TITA\", which dynamically balances both Task-invariant\nInteraction and Task-specific Adaptation. For task-invariant interaction, we\nintroduce the Interaction-enhanced Pixel Attention (IPA) module to enhance\npixel-wise interactions for better multi-source complementary information\nextraction. For task-specific adaptation, the Operation-based Adaptive Fusion\n(OAF) module dynamically adjusts operation weights based on task properties.\nAdditionally, we incorporate the Fast Adaptive Multitask Optimization (FAMO)\nstrategy to mitigate the impact of gradient conflicts across tasks during joint\ntraining. Extensive experiments demonstrate that TITA not only achieves\ncompetitive performance compared to specialized methods across three image\nfusion scenarios but also exhibits strong generalization to unseen fusion\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T15:08:35Z"}
{"aid":"http://arxiv.org/abs/2504.05174v1","title":"Learning symmetries in datasets","summary":"We investigate how symmetries present in datasets affect the structure of the\nlatent space learned by Variational Autoencoders (VAEs). By training VAEs on\ndata originating from simple mechanical systems and particle collisions, we\nanalyze the organization of the latent space through a relevance measure that\nidentifies the most meaningful latent directions. We show that when symmetries\nor approximate symmetries are present, the VAE self-organizes its latent space,\neffectively compressing the data along a reduced number of latent variables.\nThis behavior captures the intrinsic dimensionality determined by the symmetry\nconstraints and reveals hidden relations among the features. Furthermore, we\nprovide a theoretical analysis of a simple toy model, demonstrating how, under\nidealized conditions, the latent space aligns with the symmetry directions of\nthe data manifold. We illustrate these findings with examples ranging from\ntwo-dimensional datasets with $O(2)$ symmetry to realistic datasets from\nelectron-positron and proton-proton collisions. Our results highlight the\npotential of unsupervised generative models to expose underlying structures in\ndata and offer a novel approach to symmetry discovery without explicit\nsupervision.","main_category":"cs.LG","categories":"cs.LG,hep-ph","published":"2025-04-07T15:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05179v1","title":"IEC-Independent Coupling Between Water Uptake and Ionic Conductivity in\n  Anion-Conducting Polymer Films","summary":"Anion exchange membranes (AEMs) are promising candidates for replacing proton\nexchange membranes (PEMs) in electrochemical devices such as fuel cells,\nelectrolyzers, batteries, and osmotic energy extraction systems. However,\noptimizing the AEM design requires a deeper understanding of the ionic\nconduction mechanism in the hydrated polymer matrix. This study investigates\nthis mechanism by seeking to understand the relationship between ion exchange\ncapacity (IEC), water absorption, and ionic conductivity in\npolynorbornene-based thin films. We combine experimental measurements with\ncomputational simulations using a newly developed minimal model of the polymer\nfilm. Our model is able to reproduce key experimental observations, including\nwater sorption isotherms and ion conduction behavior as a function of relative\nhumidity, and successfully captures the relationship between them. By comparing\nexperimental data with computational results, we explain the commonly reported\ncorrelation between conductivity and hydration level and show how the\ncorrelation between these variables is affected by the charge density and\ntemperature of the material. Our research advances our understanding of the\nphysical mechanisms that govern the performance of the polyelectrolyte\nmembrane, which is essential for the development of more efficient, stable, and\nenvironmentally friendly electrochemical systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-04-07T15:26:53Z"}
{"aid":"http://arxiv.org/abs/2504.05187v1","title":"Resource-Efficient Beam Prediction in mmWave Communications with\n  Multimodal Realistic Simulation Framework","summary":"Beamforming is a key technology in millimeter-wave (mmWave) communications\nthat improves signal transmission by optimizing directionality and intensity.\nHowever, conventional channel estimation methods, such as pilot signals or beam\nsweeping, often fail to adapt to rapidly changing communication environments.\nTo address this limitation, multimodal sensing-aided beam prediction has gained\nsignificant attention, using various sensing data from devices such as LiDAR,\nradar, GPS, and RGB images to predict user locations or network conditions.\nDespite its promising potential, the adoption of multimodal sensing-aided beam\nprediction is hindered by high computational complexity, high costs, and\nlimited datasets. Thus, in this paper, a resource-efficient learning approach\nis proposed to transfer knowledge from a multimodal network to a monomodal\n(radar-only) network based on cross-modal relational knowledge distillation\n(CRKD), while reducing computational overhead and preserving predictive\naccuracy. To enable multimodal learning with realistic data, a novel multimodal\nsimulation framework is developed while integrating sensor data generated from\nthe autonomous driving simulator CARLA with MATLAB-based mmWave channel\nmodeling, and reflecting real-world conditions. The proposed CRKD achieves its\nobjective by distilling relational information across different feature spaces,\nwhich enhances beam prediction performance without relying on expensive sensor\ndata. Simulation results demonstrate that CRKD efficiently distills multimodal\nknowledge, allowing a radar-only model to achieve $94.62\\%$ of the teacher\nperformance. In particular, this is achieved with just $10\\%$ of the teacher\nnetwork's parameters, thereby significantly reducing computational complexity\nand dependence on multimodal sensor data.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.LG","published":"2025-04-07T15:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.05211v1","title":"Exploiting individual differences to bootstrap communication","summary":"Establishing a communication system is hard because the intended meaning of a\nsignal is unknown to its receiver when first produced, and the signaller also\nhas no idea how that signal will be interpreted. Most theoretical accounts of\nthe emergence of communication systems rely on feedback to reinforce behaviours\nthat have led to successful communication in the past. However, providing such\nfeedback requires already being able to communicate the meaning that was\nintended or interpreted. Therefore these accounts cannot explain how\ncommunication can be bootstrapped from non-communicative behaviours. Here we\npresent a model that shows how a communication system, capable of expressing an\nunbounded number of meanings, can emerge as a result of individual behavioural\ndifferences in a large population without any pre-existing means to determine\ncommunicative success. The two key cognitive capabilities responsible for this\noutcome are behaving predictably in a given situation, and an alignment of\npsychological states ahead of signal production that derives from shared\nintentionality. Since both capabilities can exist independently of\ncommunication, our results are compatible with theories in which large flexible\nsocially-learned communication systems like language are the product of a\ngeneral but well-developed capacity for social cognition.","main_category":"cs.CL","categories":"cs.CL,physics.soc-ph,q-bio.PE","published":"2025-04-07T15:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.05212v1","title":"On multipolar magnetic anomaly detection: multipolar signal subspaces,\n  an analytical orthonormal basis, multipolar truncature and detection\n  performance","summary":"In this paper, we consider the magnetic anomaly detection problem which aims\nto find hidden ferromagnetic masses by estimating the weak perturbation they\ninduce on local Earth's magnetic field. We consider classical detection schemes\nthat rely on signals recorded on a moving sensor, and modeling of the source as\na function of unknown parameters. As the usual spherical harmonic decomposition\nof the anomaly has to be truncated in practice, we study the signal vector\nsubspaces induced by each multipole of the decomposition, proving they are not\nin direct sum, and discussing the impact it has on the choice of the truncation\norder. Further, to ease the detection strategy based on generalized likelihood\nratio test, we rely on orthogonal polynomials theory to derive an analytical\nset of orthonormal functions (multipolar orthonormal basis functions) that\nspans the space of the noise-free measured signal. Finally, based on the\nsubspace structure of the multipole vector spaces, we study the impact of the\ntruncation order on the detection performance, beyond the issue of potential\nsurparametrization, and the behaviour of the information criteria used to\nchoose this order.","main_category":"eess.SP","categories":"eess.SP,math-ph,math.MP,stat.ME","published":"2025-04-07T16:00:24Z"}
{"aid":"http://arxiv.org/abs/2504.05217v1","title":"LLM-Alignment Live-Streaming Recommendation","summary":"In recent years, integrated short-video and live-streaming platforms have\ngained massive global adoption, offering dynamic content creation and\nconsumption. Unlike pre-recorded short videos, live-streaming enables real-time\ninteraction between authors and users, fostering deeper engagement. However,\nthis dynamic nature introduces a critical challenge for recommendation systems\n(RecSys): the same live-streaming vastly different experiences depending on\nwhen a user watching. To optimize recommendations, a RecSys must accurately\ninterpret the real-time semantics of live content and align them with user\npreferences.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T16:04:00Z"}
{"aid":"http://arxiv.org/abs/2504.05224v1","title":"Reinforced Multi-teacher Knowledge Distillation for Efficient General\n  Image Forgery Detection and Localization","summary":"Image forgery detection and localization (IFDL) is of vital importance as\nforged images can spread misinformation that poses potential threats to our\ndaily lives. However, previous methods still struggled to effectively handle\nforged images processed with diverse forgery operations in real-world\nscenarios. In this paper, we propose a novel Reinforced Multi-teacher Knowledge\nDistillation (Re-MTKD) framework for the IFDL task, structured around an\nencoder-decoder \\textbf{C}onvNeXt-\\textbf{U}perNet along with\n\\textbf{E}dge-Aware Module, named Cue-Net. First, three Cue-Net models are\nseparately trained for the three main types of image forgeries, i.e.,\ncopy-move, splicing, and inpainting, which then serve as the multi-teacher\nmodels to train the target student model with Cue-Net through self-knowledge\ndistillation. A Reinforced Dynamic Teacher Selection (Re-DTS) strategy is\ndeveloped to dynamically assign weights to the involved teacher models, which\nfacilitates specific knowledge transfer and enables the student model to\neffectively learn both the common and specific natures of diverse tampering\ntraces. Extensive experiments demonstrate that, compared with other\nstate-of-the-art methods, the proposed method achieves superior performance on\nseveral recently emerged datasets comprised of various kinds of image\nforgeries.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:12:05Z"}
{"aid":"http://arxiv.org/abs/2504.05225v1","title":"Vision-Language Model Predictive Control for Manipulation Planning and\n  Trajectory Generation","summary":"Model Predictive Control (MPC) is a widely adopted control paradigm that\nleverages predictive models to estimate future system states and optimize\ncontrol inputs accordingly. However, while MPC excels in planning and control,\nit lacks the capability for environmental perception, leading to failures in\ncomplex and unstructured scenarios. To address this limitation, we introduce\nVision-Language Model Predictive Control (VLMPC), a robotic manipulation\nplanning framework that integrates the perception power of vision-language\nmodels (VLMs) with MPC. VLMPC utilizes a conditional action sampling module\nthat takes a goal image or language instruction as input and leverages VLM to\ngenerate candidate action sequences. These candidates are fed into a video\nprediction model that simulates future frames based on the actions. In\naddition, we propose an enhanced variant, Traj-VLMPC, which replaces video\nprediction with motion trajectory generation to reduce computational complexity\nwhile maintaining accuracy. Traj-VLMPC estimates motion dynamics conditioned on\nthe candidate actions, offering a more efficient alternative for long-horizon\ntasks and real-time applications. Both VLMPC and Traj-VLMPC select the optimal\naction sequence using a VLM-based hierarchical cost function that captures both\npixel-level and knowledge-level consistency between the current observation and\nthe task input. We demonstrate that both approaches outperform existing\nstate-of-the-art methods on public benchmarks and achieve excellent performance\nin various real-world robotic manipulation tasks. Code is available at\nhttps://github.com/PPjmchen/VLMPC.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T16:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.05227v1","title":"A Reality Check of Vision-Language Pre-training in Radiology: Have We\n  Progressed Using Text?","summary":"Vision-language pre-training has recently gained popularity as it allows\nlearning rich feature representations using large-scale data sources. This\nparadigm has quickly made its way into the medical image analysis community. In\nparticular, there is an impressive amount of recent literature developing\nvision-language models for radiology. However, the available medical datasets\nwith image-text supervision are scarce, and medical concepts are fine-grained,\ninvolving expert knowledge that existing vision-language models struggle to\nencode. In this paper, we propose to take a prudent step back from the\nliterature and revisit supervised, unimodal pre-training, using fine-grained\nlabels instead. We conduct an extensive comparison demonstrating that unimodal\npre-training is highly competitive and better suited to integrating\nheterogeneous data sources. Our results also question the potential of recent\nvision-language models for open-vocabulary generalization, which have been\nevaluated using optimistic experimental settings. Finally, we study novel\nalternatives to better integrate fine-grained labels and noisy text\nsupervision.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:13:26Z"}
{"aid":"http://arxiv.org/abs/2504.05231v1","title":"Mapping biodiversity at very-high resolution in Europe","summary":"This paper describes a cascading multimodal pipeline for high-resolution\nbiodiversity mapping across Europe, integrating species distribution modeling,\nbiodiversity indicators, and habitat classification. The proposed pipeline\nfirst predicts species compositions using a deep-SDM, a multimodal model\ntrained on remote sensing, climate time series, and species occurrence data at\n50x50m resolution. These predictions are then used to generate biodiversity\nindicator maps and classify habitats with Pl@ntBERT, a transformer-based LLM\ndesigned for species-to-habitat mapping. With this approach, continental-scale\nspecies distribution maps, biodiversity indicator maps, and habitat maps are\nproduced, providing fine-grained ecological insights. Unlike traditional\nmethods, this framework enables joint modeling of interspecies dependencies,\nbias-aware training with heterogeneous presence-absence data, and large-scale\ninference from multi-source remote sensing inputs.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-07T16:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.05236v1","title":"Gravitational waveforms from periodic orbits around a Schwarzschild\n  black hole embedded in a Dehnen-type dark matter halo","summary":"In this paper, we study the periodic orbits, characterized by zoom-whirl\nbehavior, around a Schwarzschild-like black hole (BH) embedded within a\nDehnen-type dark matter (DM) halo. We demonstrate how the DM halo modifies the\ngravitational dynamics of the black hole, influencing the energy and angular\nmomentum of timelike particle geodesics and enhancing their interaction with\nthe BH. We determine the radii of the marginally bound orbits (MBOs) and\ninnermost stable circular orbits (ISCOs), showing that the DM halo increases\nboth. This provides a deeper understanding of how the DM alters the behavior,\nenergy, and angular momentum of timelike particle geodesics. Furthermore, we\nexplore the gravitational waveforms emitted by a timelike particle in periodic\norbits around a supermassive black hole (SMBH) within this BH-DM system. Using\na semi-analytical approach, we calculate particle trajectories and derive the\ncorresponding waveforms, demonstrating that the DM halo modifies the zoom-whirl\norbital behavior, leading to distinct changes in the waveform structure. Our\nfindings suggest that future gravitational wave (GW) observations could\nconstrain the properties of DM halos surrounding BHs, providing new insights\ninto the gravitational wave signatures arising from the interaction between BH\ngravity and DM.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T16:20:10Z"}
{"aid":"http://arxiv.org/abs/2504.05239v1","title":"LLM-based Automated Grading with Human-in-the-Loop","summary":"The rise of artificial intelligence (AI) technologies, particularly large\nlanguage models (LLMs), has brought significant advancements to the field of\neducation. Among various applications, automatic short answer grading (ASAG),\nwhich focuses on evaluating open-ended textual responses, has seen remarkable\nprogress with the introduction of LLMs. These models not only enhance grading\nperformance compared to traditional ASAG approaches but also move beyond simple\ncomparisons with predefined \"golden\" answers, enabling more sophisticated\ngrading scenarios, such as rubric-based evaluation. However, existing\nLLM-powered methods still face challenges in achieving human-level grading\nperformance in rubric-based assessments due to their reliance on fully\nautomated approaches. In this work, we explore the potential of LLMs in ASAG\ntasks by leveraging their interactive capabilities through a human-in-the-loop\n(HITL) approach. Our proposed framework, GradeHITL, utilizes the generative\nproperties of LLMs to pose questions to human experts, incorporating their\ninsights to refine grading rubrics dynamically. This adaptive process\nsignificantly improves grading accuracy, outperforming existing methods and\nbringing ASAG closer to human-level evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.05240v1","title":"Bayesian local clustering of age-period mortality surfaces across\n  multiple countries","summary":"Although traditional literature on mortality modeling has focused on single\ncountries in isolation, recent contributions have progressively moved toward\njoint models for multiple countries. Besides favoring borrowing of information\nto improve age-period forecasts, this perspective has also potentials to infer\nlocal similarities among countries' mortality patterns in specific age classes\nand periods that could unveil unexplored demographic trends, while guiding the\ndesign of targeted policies. Advancements along this latter relevant direction\nare currently undermined by the lack of a multi-country model capable of\nincorporating the core structures of age-period mortality surfaces together\nwith clustering patterns among countries that are not global, but rather vary\nlocally across different combinations of ages and periods. We cover this gap by\ndeveloping a novel Bayesian model for log-mortality rates that characterizes\nthe age structure of mortality through a B-spline expansion whose\ncountry-specific dynamic coefficients encode both changes of this age structure\nacross periods and also local clustering patterns among countries under a\ntime-dependent random partition prior for these country-specific dynamic\ncoefficients. While flexible, this formulation admits tractable posterior\ninference leveraging a suitably-designed Gibbs-sampler. The application to\nmortality data from 14 countries unveils local similarities highlighting both\npreviously-recognized demographic phenomena and also yet-unexplored trends.","main_category":"stat.AP","categories":"stat.AP,stat.ME","published":"2025-04-07T16:23:19Z"}
{"aid":"http://arxiv.org/abs/2504.05261v1","title":"Componentwise Linear Ideals From Sums","summary":"Let $I,J$ be componentwise linear ideals in a polynomial ring $S$. We study\nnecessary and sufficient conditions for $I+J$ to be componentwise linear. We\nprovide a complete characterization when $\\dim S=2$. As a consequence, any\ncomponentwise linear monomial ideal in $k[x,y]$ has linear quotients using\ngenerators in non-decreasing degrees. In any dimension, we show that under mild\ncompatibility conditions, one can build a componentwise linear ideal from a\ngiven collection of componentwise linear monomial ideals using only sum and\nproduct with square-free monomials. We provide numerous examples to demonstrate\nthe optimality of our results.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-07T16:54:42Z"}
{"aid":"http://arxiv.org/abs/2504.05273v1","title":"What We Do Not Know: GPT Use in Business and Management","summary":"This systematic review examines peer-reviewed studies on application of GPT\nin business management, revealing significant knowledge gaps. Despite\nidentifying interesting research directions such as best practices,\nbenchmarking, performance comparisons, social impacts, our analysis yields only\n42 relevant studies for the 22 months since its release. There are so few\nstudies looking at a particular sector or subfield that management researchers,\nbusiness consultants, policymakers, and journalists do not yet have enough\ninformation to make well-founded statements on how GPT is being used in\nbusinesses. The primary contribution of this paper is a call to action for\nfurther research. We provide a description of current research and identify\nknowledge gaps on the use of GPT in business. We cover the management subfields\nof finance, marketing, human resources, strategy, operations, production, and\nanalytics, excluding retail and sales. We discuss gaps in knowledge of GPT\npotential consequences on employment, productivity, environmental costs,\noppression, and small businesses. We propose how management consultants and the\nmedia can help fill those gaps. We call for practical work on business control\nsystems as they relate to existing and foreseeable AI-related business\nchallenges. This work may be of interest to managers, to management\nresearchers, and to people working on AI in society.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-07T17:11:53Z"}
{"aid":"http://arxiv.org/abs/2504.05275v1","title":"On canonical sandpile actions of embedded graphs","summary":"The sandpile group of a connected graph is a group whose cardinality is the\nnumber of spanning trees. The group is known to have a canonical simply\ntransitive action on spanning trees if the graph is embedded into the plane.\nHowever, no canonical action on the spanning trees is known for the nonplanar\ncase. We show that for any embedded Eulerian digraph, one can define a\ncanonical simply transitive action of the sandpile group on compatible Eulerian\ntours (a set whose cardinality equals to the number of spanning arborescences).\nThis enables us to give a new proof that the rotor-routing action of a ribbon\ngraph is independent of the root if and only if the embedding is into the plane\n(originally proved by Chan, Church and Grochow).\n  Recently, Merino, Moffatt and Noble defined a sandpile group variant (called\nJacobian) for embedded graphs, whose cardinality is the number of quasi-trees.\nBaker, Ding and Kim showed that this group acts canonically on the quasitrees.\nWe show that the Jacobian of an embedded graph is canonically isomorphic to the\nusual sandpile group of the medial digraph, and the action by Baker at al.\nagrees with the action of the sandpile group of the medial digraph on Eulerian\ntours (which fact is made possible by the existence of a canonical bijection\nbetween Eulerian tours of the medial digraph and quasi-trees due to Bouchet).","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T17:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.05277v1","title":"Non-local charges from perturbed defects via SymTFT in 2d CFT","summary":"We investigate non-local conserved charges in perturbed two-dimensional\nconformal field theories from the point of view of the 3d SymTFT of the\nunperturbed theory. In the SymTFT we state a simple commutation condition which\nresults in a pair of compatible bulk and defect perturbations, such that the\nperturbed line defects are conserved in the perturbed CFT. In other words, the\nperturbed defects are rigidly translation invariant, and such defects form a\nmonoidal category which extends the topological symmetries. As examples we\nstudy the A-type Virasoro minimal models $M(p,q)$. Our formalism provides\none-parameter families of commuting non-local conserved charges for\nperturbations by a primary bulk field with Kac label $(1,2)$, $(1,3)$, or\n$(1,5)$, which are the standard integrable perturbations of minimal models. We\nfind solutions to the commutation condition also for other bulk perturbations,\nsuch as $(1,7)$, and we contrast this with the existence of local conserved\ncharges. There has been recent interest in the possibility that in certain\ncases perturbations by fields such as $(1,7)$ can be integrable, and our\nconstruction provides a new way in which integrability can be found without the\nneed for local conserved charges.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-07T17:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.05284v1","title":"FERIVer: An FPGA-assisted Emulated Framework for RTL Verification of\n  RISC-V Processors","summary":"Processor design and verification require a synergistic approach that\ncombines instruction-level functional simulations with precise hardware\nemulations. The trade-off between speed and accuracy in the instruction set\nsimulation poses a significant challenge to the efficiency of processor\nverification. By tapping the potentials of Field Programmable Gate Arrays\n(FPGAs), we propose an FPGA-assisted System-on-Chip (SoC) platform that\nfacilitates cross-verification by the embedded CPU and the synthesized hardware\nin the programmable fabrics. This method accelerates the verification of the\nRISC-V Instruction Set Architecture (ISA) processor at a speed of 5 million\ninstructions per second (MIPS), which is 150x faster than the vendor-specific\ntool (Xilinx XSim) and a 35x boost to the state-of-the-art open-source\nverification setup (Verilator). With less than 7\\% hardware occupation on Zynq\n7000 FPGA, the proposed framework enables flexible verification with high time\nand cost efficiency for exploring RISC-V instruction set architectures.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-07T17:34:05Z"}
{"aid":"http://arxiv.org/abs/2504.05644v1","title":"iEBAKER: Improved Remote Sensing Image-Text Retrieval Framework via\n  Eliminate Before Align and Keyword Explicit Reasoning","summary":"Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR),\nwhich aims at searching for the corresponding targets based on the given query.\nAmong these efforts, the application of Foundation Models (FMs), such as CLIP,\nto the domain of remote sensing has yielded encouraging outcomes. However,\nexisting FM based methodologies neglect the negative impact of weakly\ncorrelated sample pairs and fail to account for the key distinctions among\nremote sensing texts, leading to biased and superficial exploration of sample\npairs. To address these challenges, we propose an approach named iEBAKER (an\nImproved Eliminate Before Align strategy with Keyword Explicit Reasoning\nframework) for RSITR. Specifically, we propose an innovative Eliminate Before\nAlign (EBA) strategy to filter out the weakly correlated sample pairs, thereby\nmitigating their deviations from optimal embedding space during\nalignment.Further, two specific schemes are introduced from the perspective of\nwhether local similarity and global similarity affect each other. On this\nbasis, we introduce an alternative Sort After Reversed Retrieval (SAR)\nstrategy, aims at optimizing the similarity matrix via reverse retrieval.\nAdditionally, we incorporate a Keyword Explicit Reasoning (KER) module to\nfacilitate the beneficial impact of subtle key concept distinctions. Without\nbells and whistles, our approach enables a direct transition from FM to RSITR\ntask, eliminating the need for additional pretraining on remote sensing data.\nExtensive experiments conducted on three popular benchmark datasets demonstrate\nthat our proposed iEBAKER method surpasses the state-of-the-art models while\nrequiring less training data. Our source code will be released at\nhttps://github.com/zhangy0822/iEBAKER.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:40:19Z"}
{"aid":"http://arxiv.org/abs/2504.05654v1","title":"Curved representational Bregman divergences and their applications","summary":"By analogy to curved exponential families, we define curved Bregman\ndivergences as restrictions of Bregman divergences to sub-dimensional parameter\nsubspaces, and prove that the barycenter of a finite weighted parameter set\nwith respect to a curved Bregman divergence amounts to the Bregman projection\nonto the subspace induced by the constraint of the barycenter with respect to\nthe unconstrained full Bregman divergence. We demonstrate the significance of\ncurved Bregman divergences with two examples: (1) symmetrized Bregman\ndivergences and (2) the Kullback-Leibler divergence between circular complex\nnormal distributions. We then consider monotonic embeddings to define\nrepresentational curved Bregman divergences and show that the\n$\\alpha$-divergences are representational curved Bregman divergences with\nrespect to $\\alpha$-embeddings of the probability simplex into the positive\nmeasure cone. As an application, we report an efficient method to calculate the\nintersection of a finite set of $\\alpha$-divergence spheres.","main_category":"cs.IT","categories":"cs.IT,cs.LG,math.IT","published":"2025-04-08T04:05:12Z"}
{"aid":"http://arxiv.org/abs/2504.05663v1","title":"Characterization of $P_3$-connected graphs","summary":"For any pair of edges $e,f$ of a graph $G$, we say that {\\em $e,f$ are\n$P_3$-connected in $G$} if there exists a sequence of edges $e=e_0,e_1,\\ldots,\ne_k=f$ such that $e_i$ and $e_{i+1}$ are two edges of an induced $3$-vertex\npath in $G$ for every $0\\leq i\\leq k-1$. If every pair of edges of $G$ are\n$P_3$-connected in $G$, then $G$ is {\\em $P_3$-connected}. $P_3$-connectivity\nwas first defined by Chudnovsky et al. in 2024 to prove that every connected\ngraph not containing $P_5$ as an induced subgraph has cop number at most two.\nIn this paper, we give a characterization of $P_3$-connected graphs and prove\nthat a simple graph is $P_3$-connected if and only if it is connected and has\nno homogeneous set whose induced subgraph contains an edge.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T04:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.05677v1","title":"Noisy Deep Ensemble: Accelerating Deep Ensemble Learning via Noise\n  Injection","summary":"Neural network ensembles is a simple yet effective approach for enhancing\ngeneralization capabilities. The most common method involves independently\ntraining multiple neural networks initialized with different weights and then\naveraging their predictions during inference. However, this approach increases\ntraining time linearly with the number of ensemble members. To address this\nissue, we propose the novel ``\\textbf{Noisy Deep Ensemble}'' method,\nsignificantly reducing the training time required for neural network ensembles.\nIn this method, a \\textit{parent model} is trained until convergence, and then\nthe weights of the \\textit{parent model} are perturbed in various ways to\nconstruct multiple \\textit{child models}. This perturbation of the\n\\textit{parent model} weights facilitates the exploration of different local\nminima while significantly reducing the training time for each ensemble member.\nWe evaluated our method using diverse CNN architectures on CIFAR-10 and\nCIFAR-100 datasets, surpassing conventional efficient ensemble methods and\nachieving test accuracy comparable to standard ensembles. Code is available at\n\\href{https://github.com/TSTB-dev/NoisyDeepEnsemble}{https://github.com/TSTB-dev/NoisyDeepEnsemble}","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T04:36:39Z"}
{"aid":"http://arxiv.org/abs/2504.05680v1","title":"Simultaneous construction of fast equator, poleward meridional flow, and\n  near-surface shear layer in solar magnetohydrodynamic calculation","summary":"We carry out an unprecedented high-resolution simulation for the solar\nconvection zone. Our calculation reproduces the fast equator and near-surface\nshear layer (NSSL) of differential rotation and the near-surface poleward\nmeridional flow simultaneously. The NSSL is located in a complex layer where\nthe spatial and time scales of thermal convection are significantly small\ncompared with the deep convection zone. While there have been several attempts\nto reproduce the NSSL in numerical simulation, the results are still far from\nreality. In this study, we succeed in reproducing an NSSL in our new\ncalculation. Our analyses lead to a deeper understanding of the construction\nmechanism of the NSSL, which is summarized as: 1) rotationally unconstrained\nconvection in the near-surface layer transports the angular momentum radially\ninward; 2) sheared poleward meridional flow around the top boundary is\nconstructed; 3) the shear causes a positive kinetic $\\langle v'_r\nv'_\\theta\\rangle$ and negative magnetic $\\langle B_r B_\\theta\\rangle$\ncorrelations; and 4) the turbulent viscosity and magnetic tension are\nlatitudinally balanced with the Coriolis force in the NSSL. We emphasize the\nimportance of the magnetic field in the solar convection zone.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T04:44:37Z"}
{"aid":"http://arxiv.org/abs/2504.05683v1","title":"Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained LLMs\n  Ready for HR Spoken Interview Transcript Analysis?","summary":"This research paper presents a comprehensive analysis of the performance of\nprominent pre-trained large language models (LLMs), including GPT-4 Turbo,\nGPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001,\ntext-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in\ncomparison to expert human evaluators in providing scores, identifying errors,\nand offering feedback and improvement suggestions to candidates during mock HR\n(Human Resources) interviews. We introduce a dataset called HURIT (Human\nResource Interview Transcripts), which comprises 3,890 HR interview transcripts\nsourced from real-world HR interview scenarios. Our findings reveal that\npre-trained LLMs, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit\ncommendable performance and are capable of producing evaluations comparable to\nthose of expert human evaluators. Although these LLMs demonstrate proficiency\nin providing scores comparable to human experts in terms of human evaluation\nmetrics, they frequently fail to identify errors and offer specific actionable\nadvice for candidate performance improvement in HR interviews. Our research\nsuggests that the current state-of-the-art pre-trained LLMs are not fully\nconducive for automatic deployment in an HR interview assessment. Instead, our\nfindings advocate for a human-in-the-loop approach, to incorporate manual\nchecks for inconsistencies and provisions for improving feedback quality as a\nmore suitable strategy.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T04:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.05687v1","title":"Radial Isotropic Position via an Implicit Newton's Method","summary":"Placing a dataset $A = \\{\\mathbf{a}_i\\}_{i \\in [n]} \\subset \\mathbb{R}^d$ in\nradial isotropic position, i.e., finding an invertible $\\mathbf{R} \\in\n\\mathbb{R}^{d \\times d}$ such that the unit vectors $\\{(\\mathbf{R}\n\\mathbf{a}_i) \\|\\mathbf{R} \\mathbf{a}_i\\|_2^{-1}\\}_{i \\in [n]}$ are in\nisotropic position, is a powerful tool with applications in functional\nanalysis, communication complexity, coding theory, and the design of learning\nalgorithms. When the transformed dataset has a second moment matrix within a\n$\\exp(\\pm \\epsilon)$ factor of a multiple of $\\mathbf{I}_d$, we call\n$\\mathbf{R}$ an $\\epsilon$-approximate Forster transform.\n  We give a faster algorithm for computing approximate Forster transforms,\nbased on optimizing an objective defined by Barthe [Barthe98]. When the\ntransform has a polynomially-bounded aspect ratio, our algorithm uses\n$O(nd^{\\omega - 1}(\\frac n \\epsilon)^{o(1)})$ time to output an\n$\\epsilon$-approximate Forster transform with high probability, when one\nexists. This is almost the natural limit of this approach, as even evaluating\nBarthe's objective takes $O(nd^{\\omega - 1})$ time. Previously, the\nstate-of-the-art runtime in this regime was based on cutting-plane methods, and\nscaled at least as $\\approx n^3 + n^2 d^{\\omega - 1}$. We also provide explicit\nestimates on the aspect ratio in the smoothed analysis setting, and show that\nour algorithm similarly improves upon those in the literature.\n  To obtain our results, we develop a subroutine of potential broader interest:\na reduction from almost-linear time sparsification of graph Laplacians to the\nability to support almost-linear time matrix-vector products. We combine this\ntool with new stability bounds on Barthe's objective to implicitly implement a\nbox-constrained Newton's method [CMTV17, ALOW17].","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-04-08T05:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.05688v1","title":"First and Second Fundamental Theorems for Invariant Rings Generated by\n  Circulant Determinants","summary":"In this paper, we give the first and second fundamental theorems of invariant\ntheory for certain invariant rings whose generators are expressed by circulant\ndeterminants.","main_category":"math.RT","categories":"math.RT,math.GR,math.RA","published":"2025-04-08T05:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05698v1","title":"Point-based Instance Completion with Scene Constraints","summary":"Recent point-based object completion methods have demonstrated the ability to\naccurately recover the missing geometry of partially observed objects. However,\nthese approaches are not well-suited for completing objects within a scene, as\nthey do not consider known scene constraints (e.g., other observed surfaces) in\ntheir completions and further expect the partial input to be in a canonical\ncoordinate system, which does not hold for objects within scenes. While\ninstance scene completion methods have been proposed for completing objects\nwithin a scene, they lag behind point-based object completion methods in terms\nof object completion quality and still do not consider known scene constraints\nduring completion. To overcome these limitations, we propose a point\ncloud-based instance completion model that can robustly complete objects at\narbitrary scales and pose in the scene. To enable reasoning at the scene level,\nwe introduce a sparse set of scene constraints represented as point clouds and\nintegrate them into our completion model via a cross-attention mechanism. To\nevaluate the instance scene completion task on indoor scenes, we further build\na new dataset called ScanWCF, which contains labeled partial scans as well as\naligned ground truth scene completions that are watertight and collision-free.\nThrough several experiments, we demonstrate that our method achieves improved\nfidelity to partial scans, higher completion quality, and greater plausibility\nover existing state-of-the-art methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T05:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.05736v1","title":"Rank-Then-Score: Enhancing Large Language Models for Automated Essay\n  Scoring","summary":"In recent years, large language models (LLMs) achieve remarkable success\nacross a variety of tasks. However, their potential in the domain of Automated\nEssay Scoring (AES) remains largely underexplored. Moreover, compared to\nEnglish data, the methods for Chinese AES is not well developed. In this paper,\nwe propose Rank-Then-Score (RTS), a fine-tuning framework based on large\nlanguage models to enhance their essay scoring capabilities. Specifically, we\nfine-tune the ranking model (Ranker) with feature-enriched data, and then feed\nthe output of the ranking model, in the form of a candidate score set, with the\nessay content into the scoring model (Scorer) to produce the final score.\nExperimental results on two benchmark datasets, HSK and ASAP, demonstrate that\nRTS consistently outperforms the direct prompting (Vanilla) method in terms of\naverage QWK across all LLMs and datasets, and achieves the best performance on\nChinese essay scoring using the HSK dataset.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T07:10:51Z"}
{"aid":"http://arxiv.org/abs/2504.05738v1","title":"LLM-assisted Mutation for Whitebox API Testing","summary":"Cloud applications heavily rely on APIs to communicate with each other and\nexchange data. To ensure the reliability of cloud applications, cloud providers\nwidely adopt API testing techniques. Unfortunately, existing API testing\napproaches are insufficient to reach strict conditions, a problem known as\nfitness plateaus, due to the lack of gradient provided by coverage metrics. To\naddress this issue, we propose MioHint, a novel white-box API testing approach\nthat leverages the code comprehension capabilities of Large Language Model\n(LLM) to boost API testing. The key challenge of LLM-based API testing lies in\nsystem-level testing, which emphasizes the dependencies between requests and\ntargets across functions and files, thereby making the entire codebase the\nobject of analysis. However, feeding the entire codebase to an LLM is\nimpractical due to its limited context length and short memory. MioHint\naddresses this challenge by synergizing static analysis with LLMs. We retrieve\nrelevant code with data-dependency analysis at the statement level, including\ndef-use analysis for variables used in the target and function expansion for\nsubfunctions called by the target.\n  To evaluate the effectiveness of our method, we conducted experiments across\n16 real-world REST API services. The findings reveal that MioHint achieves an\naverage increase of 4.95% absolute in line coverage compared to the baseline,\nEvoMaster, alongside a remarkable factor of 67x improvement in mutation\naccuracy. Furthermore, our method successfully covers over 57% of hard-to-cover\ntargets while in baseline the coverage is less than 10%.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T07:14:51Z"}
{"aid":"http://arxiv.org/abs/2504.05748v1","title":"When Less Is More: A Sparse Facial Motion Structure For Listening Motion\n  Learning","summary":"Effective human behavior modeling is critical for successful human-robot\ninteraction. Current state-of-the-art approaches for predicting listening head\nbehavior during dyadic conversations employ continuous-to-discrete\nrepresentations, where continuous facial motion sequence is converted into\ndiscrete latent tokens. However, non-verbal facial motion presents unique\nchallenges owing to its temporal variance and multi-modal nature.\nState-of-the-art discrete motion token representation struggles to capture\nunderlying non-verbal facial patterns making training the listening head\ninefficient with low-fidelity generated motion. This study proposes a novel\nmethod for representing and predicting non-verbal facial motion by encoding\nlong sequences into a sparse sequence of keyframes and transition frames. By\nidentifying crucial motion steps and interpolating intermediate frames, our\nmethod preserves the temporal structure of motion while enhancing instance-wise\ndiversity during the learning process. Additionally, we apply this novel sparse\nrepresentation to the task of listening head prediction, demonstrating its\ncontribution to improving the explanation of facial motion patterns.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-08T07:25:12Z"}
{"aid":"http://arxiv.org/abs/2504.05753v1","title":"Accelerated Natural Gradient Method for Parametric Manifold Optimization","summary":"Parametric manifold optimization problems frequently arise in various machine\nlearning tasks, where state functions are defined on infinite-dimensional\nmanifolds. We propose a unified accelerated natural gradient descent (ANGD)\nframework to address these problems. By incorporating a Hessian-driven damping\nterm into the manifold update, we derive an accelerated Riemannian gradient\n(ARG) flow that mitigates oscillations. An equivalent first-order system is\nfurther presented for the ARG flow, enabling a unified discretization scheme\nthat leads to the ANGD method. In our discrete update, our framework considers\nvarious advanced techniques, including least squares approximation of the\nupdate direction, projected momentum to accelerate convergence, and efficient\napproximation methods through the Kronecker product. It accommodates various\nmetrics, including $H^s$, Fisher-Rao, and Wasserstein-2 metrics, providing a\ncomputationally efficient solution for large-scale parameter spaces. We\nestablish a convergence rate for the ARG flow under geodesic convexity\nassumptions. Numerical experiments demonstrate that ANGD outperforms standard\nNGD, underscoring its effectiveness across diverse deep learning tasks.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T07:33:04Z"}
{"aid":"http://arxiv.org/abs/2504.05759v1","title":"RETROcode: Leveraging a Code Database for Improved Natural Language to\n  Code Generation","summary":"As text and code resources have expanded, large-scale pre-trained models have\nshown promising capabilities in code generation tasks, typically employing\nsupervised fine-tuning with problem statement-program pairs. However,\nincreasing model size and data volume for performance gains also raises\ncomputational demands and risks of overfitting. Addressing these challenges, we\npresent RETROcode, a novel adaptation of the RETRO architecture \\cite{RETRO}\nfor sequence-to-sequence models, utilizing a large code database as an\nauxiliary scaling method. This approach, diverging from simply enlarging model\nand dataset sizes, allows RETROcode to leverage a vast code database for\nprediction, enhancing the model's efficiency by integrating extensive memory.\nOur findings indicate that RETROcode not only outperforms similar-sized\ntraditional architectures on test sets but also approaches the effectiveness of\nthe much larger Codex model, despite being trained from scratch on a\nsubstantially smaller dataset.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:41:13Z"}
{"aid":"http://arxiv.org/abs/2504.05766v1","title":"On raw moments of the binomial distribution","summary":"We study the $k$:th raw moment of a variable $R$ following the binomial\ndistribution $\\text{B}(n, p)$, where $n/k \\rightarrow \\beta > 0$. It is known\nthat $\\mathbb{E}(R^k)$ is bounded both from below and from above by functions\nof the form $k^k \\Psi^k$. We solve the asymptotically optimal value of $\\Psi$\nas a function of $p$ and $\\beta$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-08T07:46:22Z"}
{"aid":"http://arxiv.org/abs/2504.05770v1","title":"A Lightweight Multi-Module Fusion Approach for Korean Character\n  Recognition","summary":"Optical Character Recognition (OCR) is essential in applications such as\ndocument processing, license plate recognition, and intelligent surveillance.\nHowever, existing OCR models often underperform in real-world scenarios due to\nirregular text layouts, poor image quality, character variability, and high\ncomputational costs.\n  This paper introduces SDA-Net (Stroke-Sensitive Attention and Dynamic Context\nEncoding Network), a lightweight and efficient architecture designed for robust\nsingle-character recognition. SDA-Net incorporates: (1) a Dual Attention\nMechanism to enhance stroke-level and spatial feature extraction; (2) a Dynamic\nContext Encoding module that adaptively refines semantic information using a\nlearnable gating mechanism; (3) a U-Net-inspired Feature Fusion Strategy for\ncombining low-level and high-level features; and (4) a highly optimized\nlightweight backbone that reduces memory and computational demands.\n  Experimental results show that SDA-Net achieves state-of-the-art accuracy on\nchallenging OCR benchmarks, with significantly faster inference, making it\nwell-suited for deployment in real-time and edge-based OCR systems.","main_category":"cs.CV","categories":"cs.CV,cs.AI,I.2.10","published":"2025-04-08T07:50:19Z"}
{"aid":"http://arxiv.org/abs/2504.05796v1","title":"X-ray Strain and Stress Tensor Tomography","summary":"The microscopic distribution of strain and stress plays a crucial role for\nthe performance, safety, and lifetime of components in aeronautics, automotive\nand critical infrastructure [1]. While non-destructive methods for measuring\nthe stress close to the surface have long been long established, only a limited\nnumber of approaches for depth-resolved measurements based on x-rays or\nneutrons are available [2]. These feature significant limitations, including\nlong scan times, intricate experimental set-ups, limited spatial resolution or\nanisotropic gauge volumes with aspect ratios of 1:10 or worse. Here, we present\na method that overcomes these limitations and obtains tomographic\nreconstructions of the full six-dimensional strain and stress tensor\ncomponents. Using a simple and wide spread experimental set-up that combines\nx-ray powder diffraction with single axis tomography, we achieve\nnon-destructive determination of depth-resolved strain and stress distributions\nwith isotropic resolution. The presented method could be of interest for\nadditive manufacturing of metals [3,4], battery research [5], in-situ\nmetallurgy [6] and the experimental validation of finite element simulations\n[7].","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.ins-det","published":"2025-04-08T08:23:26Z"}
{"aid":"http://arxiv.org/abs/2504.05797v1","title":"Possible existence of pygmy dipole resonance built on excited states in\n  a neutron-rich $^{80}$Ge nucleus","summary":"The pygmy dipole resonance (PDR) at the low-lying tail of the giant dipole\nresonance (GDR) is an interesting research subject as it carries important\ninformation about the nuclear surface with mixed isoscalar and isovector\nvibrations in $N > Z$ systems. The present paper investigates the possible\nexistence of the PDR built on excited states in a neutron-rich $^{80}$Ge\nnucleus using the phonon damping model (PDM) with and without pairing\ncorrelation at zero and finite temperatures. The results obtained within the\nPDM with exact pairing (EP+PDM) reveal the appearance of two enhanced\n$\\gamma$-transitions $E_\\gamma = 7.25$ and 7.35 MeV at $T=0.6$ MeV, which carry\nthe PDR nature and hence implying the possible existence of PDR built on\nexcited states in this nucleus. These two $\\gamma$-energies nicely match with a\nrecent experimental observation, thus indicating the crucial role of the\ninclusion of exact pairing solution in the precise description of low-lying\n$\\gamma$-transitions. The partition function-based analysis shows that this\npredicted PDR at $T=$ 0.6MeV is mainly contributed by the first $2^+$ excited\nstate of the $^{80}$Ge nucleus. The isospin mixing at the nuclear surface is\nalso observed in the investigated PDR at $T=0.6-0.7$ MeV. The primary mechanism\nunderlying the emergence of the hot PDR is found due to the coupling of GDR\nphonon to non-collective particle-particle and hole-hole configurations at\nfinite temperatures within the PDM framework, along with the shift in\nparticle-hole excitation energies due to thermal pairing correlations","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-08T08:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.05806v1","title":"Meta-Continual Learning of Neural Fields","summary":"Neural Fields (NF) have gained prominence as a versatile framework for\ncomplex data representation. This work unveils a new problem setting termed\n\\emph{Meta-Continual Learning of Neural Fields} (MCL-NF) and introduces a novel\nstrategy that employs a modular architecture combined with optimization-based\nmeta-learning. Focused on overcoming the limitations of existing methods for\ncontinual learning of neural fields, such as catastrophic forgetting and slow\nconvergence, our strategy achieves high-quality reconstruction with\nsignificantly improved learning speed. We further introduce Fisher Information\nMaximization loss for neural radiance fields (FIM-NeRF), which maximizes\ninformation gains at the sample level to enhance learning generalization, with\nproved convergence guarantee and generalization bound. We perform extensive\nevaluations across image, audio, video reconstruction, and view synthesis tasks\non six diverse datasets, demonstrating our method's superiority in\nreconstruction quality and speed over existing MCL and CL-NF approaches.\nNotably, our approach attains rapid adaptation of neural fields for city-scale\nNeRF rendering with reduced parameter requirement.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T08:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.05818v1","title":"Proper constituent gluon mass as the final piece to construct hybrid","summary":"After treating hybrid as a three-body system, we recalculate the spectra and\ndecay widths of the $1^{-+}$ light hybrids via the Gauss Expansion Method\n(GEM). Our result shows that, after adding into only one more parameter\n$m_g$=450 MeV, i.e., the constituent gluon mass, we can reproduce nearly all\nthe results in our previous work by just using the model parameters from meson\nspectra calculation, which shows the unification of Quantum Chromodynamics\n(QCD). As a result, $\\pi_1(1600)$ and $\\eta_1(1855)$ may not be explained as\n$1^{-+}$ hybrids simultaneously, and the $\\eta_1(1855)$ observed by BESIII may\nnot be a hybrid. In addition, we predict an existence of a hybrid\n$\\eta_1(1640)$, which can be verified by searching the $a_1(1260)\\pi$ channel.\nFurthermore, to search for an isospin-0 and an isospin-$\\frac{1}{2}$ hybrid,\nthe golden channels may be $K_1(1270)\\bar{K}$ and $K_1(1270)\\pi$, respectively.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T09:01:14Z"}
{"aid":"http://arxiv.org/abs/2504.05831v1","title":"Leveraging Robust Optimization for LLM Alignment under Distribution\n  Shifts","summary":"Large language models (LLMs) increasingly rely on preference alignment\nmethods to steer outputs toward human values, yet these methods are often\nconstrained by the scarcity of high-quality human-annotated data. To tackle\nthis, recent approaches have turned to synthetic data generated by LLMs as a\nscalable alternative. However, synthetic data can introduce distribution\nshifts, compromising the nuanced human preferences that are essential for\ndesirable outputs. In this paper, we propose a novel distribution-aware\noptimization framework that improves preference alignment in the presence of\nsuch shifts. Our approach first estimates the likelihood ratios between the\ntarget and training distributions leveraging a learned classifier, then it\nminimizes the worst-case loss over data regions that reflect the target\nhuman-preferred distribution. By explicitly prioritizing the target\ndistribution during optimization, our method mitigates the adverse effects of\ndistributional variation and enhances the generation of responses that\nfaithfully reflect human values.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T09:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.05833v1","title":"AVENet: Disentangling Features by Approximating Average Features for\n  Voice Conversion","summary":"Voice conversion (VC) has made progress in feature disentanglement, but it is\nstill difficult to balance timbre and content information. This paper evaluates\nthe pre-trained model features commonly used in voice conversion, and proposes\nan innovative method for disentangling speech feature representations.\nSpecifically, we first propose an ideal content feature, referred to as the\naverage feature, which is calculated by averaging the features within\nframe-level aligned parallel speech (FAPS) data. For generating FAPS data, we\nutilize a technique that involves freezing the duration predictor in a\nText-to-Speech system and manipulating speaker embedding. To fit the average\nfeature on traditional VC datasets, we then design the AVENet to take features\nas input and generate closely matching average features. Experiments are\nconducted on the performance of AVENet-extracted features within a VC system.\nThe experimental results demonstrate its superiority over multiple current\nspeech feature disentangling methods. These findings affirm the effectiveness\nof our disentanglement approach.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-08T09:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.05835v1","title":"Scalar-assisted magnetogenesis during the radiation-dominated epoch","summary":"We propose a novel mechanism to generate primordial magnetic fields (PMFs)\nstrong enough to explain the observed cosmic magnetic fields. We employ a\nscalar field charged under U(1) gauge symmetry with a non-trivial VEV to\nprovide an effective mass term to the EM field and thus break its conformal\ninvariance. The primordial magneto-genesis takes place in the radiation\ndominated (RD) epoch, after the electroweak symmetry breaking (EWSB) phase. As\na result, our mechanism is naturally free from the over-production of electric\nfields due to high conductivity in the RD epoch, and the baryon isocurvature\nproblem which takes place only if magneto-genesis happens before the ESWB\nphase. In addition, we find that a significant amount of PMFs can be generated\nwhen the scalar field experiences a tachyonic phase. In this case, the scalar\nfield is light and weakly coupled and has negligible energy density compared to\nthe cold dark matter, hence the strong coupling problem and the back-reaction\nproblem are also absent. Therefore, our model is free from the above-mentioned\nproblems that frequently appear in other primordial magneto-genesis scenarios.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,gr-qc","published":"2025-04-08T09:18:30Z"}
{"aid":"http://arxiv.org/abs/2504.05837v1","title":"Derivation of Kirchhoff-type plate theories for elastic materials with\n  voids","summary":"We rigorously derive a Blake-Zisserman-Kirchhoff theory for thin plates with\nmaterial voids, starting from a three-dimensional model with elastic bulk and\ninterfacial energy featuring a Willmore-type curvature penalization. The\neffective two-dimensional model comprises a classical elastic bending energy\nand surface terms which reflect the possibility that voids can persist in the\nlimit, that the limiting plate can be broken apart into several pieces, or that\nthe plate can be folded. Building upon and extending the techniques used in the\nauthors' recent work on the derivation of one-dimensional theories for thin\nbrittle rods with voids, the present contribution generalizes the results of\nSantili and Schmidt (2022), by considering general geometries on the admissible\nset of voids and constructing recovery sequences for all admissible limiting\nconfigurations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T09:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.05847v1","title":"RÃ©duire le bruit grÃ¢ce Ã  la rÃ©alitÃ© augmentÃ©e sonore --\n  Auditory Concealer","summary":"This report presents the work done over 22 weeks of internship within the\nSound Perception and Design team of the Sciences and Technologies of Music and\nSound (STMS) laboratory at the Institute for Research and Coordination in\nAcoustics/Music (IRCAM). As part of the launch of the project Reducing Noise\nwith Augmented Reality (ReNAR); which aims to create a tool to reduce in\nreal-time the cognitive impact of sounds perceived as unpleasant or annoying in\nindoor environments; an initial study was conducted to validate the feasibility\nand effectiveness of a new masking approach called concealer. The main\nhypothesis is that the concealer approach could provide better results than a\nmasker approach in terms of perceived pleasantness. Mixtures of two noise\nsources (ventilation) and five masking sounds (water sounds) were generated\nusing both approaches at various levels. The evaluation of the perceived\npleasantness of these mixtures showed that the masker approach remains more\neffective than the concealer approach, regardless of the noise source, water\nsound, or level used.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-08T09:27:07Z"}
{"aid":"http://arxiv.org/abs/2504.05850v1","title":"Graphical functions with spin","summary":"The theory of graphical functions is generalized from scalar theories to\ntheories with spin, leading to a numerator structure in Feynman integrals. The\nmain part of this article treats the case of positive integer spin, which is\nobtained from spin $1/2$ theories after the evaluation of $\\gamma$ traces.\n  As an application (in this article used mainly to prove consistency and\nefficiency of the method), we calculate Feynman periods in Yukawa-$\\phi^4$\n(Gross-Neveu-Yukawa) theory up to loop order eight.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-08T09:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.05863v1","title":"Extending Parametric Model Embedding with Physical Information for\n  Design-space Dimensionality Reduction in Shape Optimization","summary":"In this work, an extension of the parametric model embedding (PME) approach\nis presented, aiming to achieve more effective design-space dimensionality\nreduction for shape optimization in vehicle design. PME, rooted in principal\ncomponent analysis (PCA), not only identifies a reduced set of critical modes\nbut also re-parameterizes the original design space, enabling direct and\ninterpretable manipulations of shape modifications within the reduced space.\nAlongside the \"physics-informed\" version (PI-PME), which enriches geometry with\nlow-fidelity distributed and lumped physical quantities, a \"physics-driven\"\nvariant (PD-PME) is introduced that focuses exclusively on physical parameters.\nBoth formulations employ PCA to capture the principal modes of variability yet\ndiffer in their balance between geometric and physical information, through the\nad-hoc definition of a weighted inner product. Through test cases involving the\nRAE-2822 airfoil, a bio-inspired underwater glider, a naval propeller, and the\nDTMB-5415 destroyer-type vessel, it is shown how the resulting frameworks\nprovide a first-level assessment of design variability, offer interpretability\nregarding which original variables most strongly affect performance, and\nefficiently bridge geometric and physical parameters. Furthermore, lumped\nphysical parameters can serve as a low-fidelity foundation for multi-fidelity\noptimization, directly leveraging the linear re-parameterization to drive the\nreduced design variables. Meanwhile, distributed physical parameters enable the\nconstruction of machine-learning-based reduced-order models to infer integral\nquantities of interest. By allowing the user to embed these insights early in\nthe design process, PI-PME and PD-PME facilitate more robust, cost-effective\nexploration, paving the way for subsequent high-fidelity optimization.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T09:43:41Z"}
{"aid":"http://arxiv.org/abs/2504.05866v1","title":"CTI-HAL: A Human-Annotated Dataset for Cyber Threat Intelligence\n  Analysis","summary":"Organizations are increasingly targeted by Advanced Persistent Threats\n(APTs), which involve complex, multi-stage tactics and diverse techniques.\nCyber Threat Intelligence (CTI) sources, such as incident reports and security\nblogs, provide valuable insights, but are often unstructured and in natural\nlanguage, making it difficult to automatically extract information. Recent\nstudies have explored the use of AI to perform automatic extraction from CTI\ndata, leveraging existing CTI datasets for performance evaluation and\nfine-tuning. However, they present challenges and limitations that impact their\neffectiveness. To overcome these issues, we introduce a novel dataset manually\nconstructed from CTI reports and structured according to the MITRE ATT&CK\nframework. To assess its quality, we conducted an inter-annotator agreement\nstudy using Krippendorff alpha, confirming its reliability. Furthermore, the\ndataset was used to evaluate a Large Language Model (LLM) in a real-world\nbusiness context, showing promising generalizability.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-08T09:47:15Z"}
{"aid":"http://arxiv.org/abs/2504.05870v1","title":"Inverse Design of Parameter-Controlled Disclination Paths","summary":"Topological defects, such as disclination lines in nematic liquid crystals,\nare fundamental to many physical systems and applications. In this work, we\nstudy the behavior of nematic disclinations in thin parallel-plate geometries\nwith strong patterned planar anchoring. Building on prior models, we solve both\nthe forward problem -- predicting disclination trajectories from given surface\npatterns -- and an extended inverse problem -- designing surface patterns to\nproduce a tunable family of disclination curves under varying system\nparameters. We present an explicit calculation for pattern construction,\nanalyze parameter limitations and stability constraints, and highlight\nexperimental and technological applications.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-08T09:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.05872v1","title":"On free line arrangements with double, triple and quadruple points","summary":"We show that there are only finitely many combinatorial types of free real\nline arrangements with only double, triple and quadruple intersection points,\nand we enlist all admissible weak-combinatorics of them. Then we classify all\nreal $M$-line arrangements. In particular, we show that real $M$-line\narrangements are simplicial.","main_category":"math.AG","categories":"math.AG,math.CO","published":"2025-04-08T09:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.05879v1","title":"PÃ³lya-SzegÅ inequalities on submanifolds with small total mean\n  curvature","summary":"We establish P\\'olya-Szeg\\H{o}-type inequalities (PSIs) for Sobolev-functions\ndefined on a regular $n$-dimensional submanifold $\\Sigma$ (possibly with\nboundary) of a $(n+m)$-dimensional Euclidean space, under explicit upper bounds\nof the total mean curvature. The $p$-Sobolev and Gagliardo-Nirenberg\ninequalities, as well as the spectral gap in $W^{1,p}_0(\\Sigma)$ are derived as\ncorollaries. Using these PSIs, we prove a sharp $p$-Log-Sobolev inequality for\nminimal submanifolds in codimension one and two. The asymptotic sharpness of\nboth the multiplicative constant appearing in PSIs and the assumption on the\ntotal mean curvature bound as $n\\to \\infty$ is provided. A second equivalent\nversion of our PSIs is presented in the appendix of this paper, introducing the\nnotion of model space $(\\mathbb{R}^+,\\mathfrak{m}_{n,K})$ of dimension $n$ and\ntotal mean curvature bounded by $K$.","main_category":"math.DG","categories":"math.DG","published":"2025-04-08T10:07:34Z"}
{"aid":"http://arxiv.org/abs/2504.05883v1","title":"Rolling Horizon Coverage Control with Collaborative Autonomous Agents","summary":"This work proposes a coverage controller that enables an aerial team of\ndistributed autonomous agents to collaboratively generate non-myopic coverage\nplans over a rolling finite horizon, aiming to cover specific points on the\nsurface area of a 3D object of interest. The collaborative coverage problem,\nformulated, as a distributed model predictive control problem, optimizes the\nagents' motion and camera control inputs, while considering inter-agent\nconstraints aiming at reducing work redundancy. The proposed coverage\ncontroller integrates constraints based on light-path propagation techniques to\npredict the parts of the object's surface that are visible with regard to the\nagents' future anticipated states. This work also demonstrates how complex,\nnon-linear visibility assessment constraints can be converted into logical\nexpressions that are embedded as binary constraints into a mixed-integer\noptimization framework. The proposed approach has been demonstrated through\nsimulations and practical applications for inspecting buildings with unmanned\naerial vehicles (UAVs).","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T10:17:38Z"}
{"aid":"http://arxiv.org/abs/2504.05891v1","title":"To Give or Not to Give? The Impacts of Strategically Withheld Recourse","summary":"Individuals often aim to reverse undesired outcomes in interactions with\nautomated systems, like loan denials, by either implementing system-recommended\nactions (recourse), or manipulating their features. While providing recourse\nbenefits users and enhances system utility, it also provides information about\nthe decision process that can be used for more effective strategic\nmanipulation, especially when the individuals collectively share such\ninformation with each other.\n  We show that this tension leads rational utility-maximizing systems to\nfrequently withhold recourse, resulting in decreased population utility,\nparticularly impacting sensitive groups.\n  To mitigate these effects, we explore the role of recourse subsidies, finding\nthem effective in increasing the provision of recourse actions by rational\nsystems, as well as lowering the potential social cost and mitigating\nunfairness caused by recourse withholding.","main_category":"cs.GT","categories":"cs.GT,cs.LG","published":"2025-04-08T10:36:16Z"}
{"aid":"http://arxiv.org/abs/2504.05897v1","title":"HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient\n  MoE Inference","summary":"The Mixture of Experts (MoE) architecture has demonstrated significant\nadvantages as it enables to increase the model capacity without a proportional\nincrease in computation. However, the large MoE model size still introduces\nsubstantial memory demands, which usually requires expert offloading on\nresource-constrained platforms and incurs significant overhead. Hybrid CPU-GPU\ninference has been proposed to leverage CPU computation to reduce expert\nloading overhead but faces major challenges: on one hand, the expert activation\npatterns of MoE models are highly unstable, rendering the fixed mapping\nstrategies in existing works inefficient; on the other hand, the hybrid CPU-GPU\nschedule for MoE is inherently complex due to the diverse expert sizes,\nstructures, uneven workload distribution, etc. To address these challenges, in\nthis paper, we propose HybriMoE, a hybrid CPU-GPU inference framework that\nimproves resource utilization through a novel CPU-GPU scheduling and cache\nmanagement system. HybriMoE introduces (i) a dynamic intra-layer scheduling\nstrategy to balance workloads across CPU and GPU, (ii) an impact-driven\ninter-layer prefetching algorithm, and (iii) a score-based caching algorithm to\nmitigate expert activation instability. We implement HybriMoE on top of the\nkTransformers framework and evaluate it on three widely used MoE-based LLMs.\nExperimental results demonstrate that HybriMoE achieves an average speedup of\n1.33$\\times$ in the prefill stage and 1.70$\\times$ in the decode stage compared\nto state-of-the-art hybrid MoE inference framework. Our code is available at:\nhttps://github.com/PKU-SEC-Lab/HybriMoE.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-08T10:47:37Z"}
{"aid":"http://arxiv.org/abs/2504.05899v1","title":"Spatially Resolved Optical Responses of a High-Kinetic-Inductance\n  Microwave Resonator","summary":"Understanding the optical response of a high-kinetic-inductance microwave\nresonator is crucial for applications ranging from single-photon detection to\nquantum transduction between microwave and optical domains, which is gaining\nsignificant attention for scaling up quantum computers. However, interactions\nbetween the pump light and the superconducting resonator often induce\nunintended resonance frequency shifts and linewidth broadening. In this study,\nwe measure the local optical response of a NbTiN nanowire resonator using a\nlaser-scanning microwave spectroscopy system integrated with a dilution\nrefrigerator. The optical response of the resonator shows correlation with the\nresonance modes and position, which is attributed to the two-level system\naround the resonator. These findings not only contribute to the design and\nunderstanding of quantum transducers and single-photon detectors, but also to\nthe understandings of catastrophic high-energy particle irradiation events that\ngenerate unintended phonons in quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T10:51:26Z"}
{"aid":"http://arxiv.org/abs/2504.05918v1","title":"Deep RL-based Autonomous Navigation of Micro Aerial Vehicles (MAVs) in a\n  complex GPS-denied Indoor Environment","summary":"The Autonomy of Unmanned Aerial Vehicles (UAVs) in indoor environments poses\nsignificant challenges due to the lack of reliable GPS signals in enclosed\nspaces such as warehouses, factories, and indoor facilities. Micro Aerial\nVehicles (MAVs) are preferred for navigating in these complex, GPS-denied\nscenarios because of their agility, low power consumption, and limited\ncomputational capabilities. In this paper, we propose a Reinforcement Learning\nbased Deep-Proximal Policy Optimization (D-PPO) algorithm to enhance realtime\nnavigation through improving the computation efficiency. The end-to-end network\nis trained in 3D realistic meta-environments created using the Unreal Engine.\nWith these trained meta-weights, the MAV system underwent extensive\nexperimental trials in real-world indoor environments. The results indicate\nthat the proposed method reduces computational latency by 91\\% during training\nperiod without significant degradation in performance. The algorithm was tested\non a DJI Tello drone, yielding similar results.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-08T11:14:37Z"}
{"aid":"http://arxiv.org/abs/2504.05925v1","title":"SVLTA: Benchmarking Vision-Language Temporal Alignment via Synthetic\n  Video Situation","summary":"Vision-language temporal alignment is a crucial capability for human dynamic\nrecognition and cognition in real-world scenarios. While existing research\nfocuses on capturing vision-language relevance, it faces limitations due to\nbiased temporal distributions, imprecise annotations, and insufficient\ncompositionally. To achieve fair evaluation and comprehensive exploration, our\nobjective is to investigate and evaluate the ability of models to achieve\nalignment from a temporal perspective, specifically focusing on their capacity\nto synchronize visual scenarios with linguistic context in a temporally\ncoherent manner. As a preliminary step, we present the statistical analysis of\nexisting benchmarks and reveal the existing challenges from a decomposed\nperspective. To this end, we introduce SVLTA, the Synthetic Vision-Language\nTemporal Alignment derived via a well-designed and feasible control generation\nmethod within a simulation environment. The approach considers commonsense\nknowledge, manipulable action, and constrained filtering, which generates\nreasonable, diverse, and balanced data distributions for diagnostic\nevaluations. Our experiments reveal diagnostic insights through the evaluations\nin temporal question answering, distributional shift sensitiveness, and\ntemporal alignment adaptation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T11:31:37Z"}
{"aid":"http://arxiv.org/abs/2504.05962v1","title":"Autoencoder-Based Detection of Anomalous Stokes V Spectra in the\n  Flare-Producing Active Region 13663 Using Hinode/SP Observations","summary":"Detecting unusual signals in observational solar spectra is crucial for\nunderstanding the features associated with impactful solar events, such as\nsolar flares. However, existing spectral analysis techniques face challenges,\nparticularly when relying on pre-defined, physics-based calculations to process\nlarge volumes of noisy and complex observational data. To address these\nlimitations, we applied deep learning to detect anomalies in the Stokes V\nspectra from the Hinode/SP instrument. Specifically, we developed an\nautoencoder model for spectral compression, which serves as an anomaly\ndetection method. Our model effectively identifies anomalous spectra within\nspectro-polarimetric maps captured prior to the onset of the X1.3 flare on May\n5, 2024, in NOAA AR 13663. These atypical spectral points exhibit highly\ncomplex profiles and spatially align with polarity inversion lines in\nmagnetogram images, indicating their potential as sites of magnetic energy\nstorage and possible triggers for flares. Notably, the detected anomalies are\nhighly localized, making them particularly challenging to identify in\nmagnetogram images using current manual methods.","main_category":"cs.LG","categories":"cs.LG,astro-ph.IM,astro-ph.SR","published":"2025-04-08T12:20:47Z"}
{"aid":"http://arxiv.org/abs/2504.05963v1","title":"Learning Verified Monitors for Hidden~Markov~Models","summary":"Runtime monitors assess whether a system is in an unsafe state based on a\nstream of observations. We study the problem where the system is subject to\nprobabilistic uncertainty and described by a hidden Markov model. A stream of\nobservations is then unsafe if the probability of being in an unsafe state is\nabove a threshold. A correct monitor recognizes the set of unsafe observations.\nThe key contribution of this paper is the first correct-by-construction\nsynthesis method for such monitors, represented as finite automata. The\ncontribution combines four ingredients: First, we establish the coNP-hardness\nof checking whether an automaton is a correct monitor, i.e., a monitor without\nmisclassifications. Second, we provide a reduction that reformulates the search\nfor misclassifications into a standard probabilistic system synthesis problem.\nThird, we integrate the verification routine into an active automata learning\nroutine to synthesize correct monitors. Fourth, we provide a prototypical\nimplementation that shows the feasibility and limitations of the approach on a\nseries of benchmarks.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-04-08T12:23:20Z"}
{"aid":"http://arxiv.org/abs/2504.06002v1","title":"Has ACT measured radiative corrections to the tree-level Higgs-like\n  inflation?","summary":"Starobinsky inflation and non-minimally coupled Higgs inflation have been\namong the most favored models of the early universe, as their predictions for\nthe scalar spectral index $n_s$ and tensor-to-scalar ratio $r$ fall comfortably\nwithin the constraints set by Planck and BICEP/Keck. However, new results from\nthe Atacama Cosmology Telescope (ACT) suggest a preference for higher values of\n$n_s$, introducing tension with the simplest realizations of these models. In\nthis work, being agnostic about the nature of the inflaton, we show that\nincorporating one-loop corrections to a Higgs-like inflationary scenario leads\nto a shift in the predicted value of $n_s$, which brings Higgs-like inflation\ninto better agreement with ACT observations. Remarkably, we find that this can\nbe achieved with non-minimal couplings $\\xi < 1$, in contrast to the large\nvalues typically required in conventional Higgs inflation, thereby pushing any\nunitarity-violation scale above the Planck scale. The effect is even more\nsignificant when the model is formulated in the Palatini approach, where the\nmodified field-space structure naturally enhances deviations from the metric\ncase. These findings highlight the importance of quantum corrections and\ngravitational degrees of freedom in refining inflationary predictions in light\nof new data.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-08T13:11:58Z"}
{"aid":"http://arxiv.org/abs/2504.06026v1","title":"Taking out the Toxic Trash: Recovering Precision in Mixed Flow-Sensitive\n  Static Analyses","summary":"Static analysis of real-world programs combines flow- and context-sensitive\nanalyses of local program states with computation of flow- and\ncontext-insensitive invariants at globals, that, e.g., abstract data shared by\nmultiple threads. The values of locals and globals may mutually depend on each\nother, with the analysis of local program states both making contributions to\nglobals and querying their values. Usually, all contributions to globals are\naccumulated during fixpoint iteration, with widening applied to enforce\ntermination. Such flow-insensitive information often becomes unnecessarily\nimprecise and can include superfluous contributions -- trash -- which, in turn,\nmay be toxic to the precision of the overall analysis. To recover precision of\nglobals, we propose techniques complementing each other: Narrowing on globals\ndifferentiates contributions by origin; reluctant widening limits the amount of\nwidening applied at globals; and finally, abstract garbage collection undoes\ncontributions to globals and propagates their withdrawal. The experimental\nevaluation shows that these techniques increase the precision of mixed\nflow-sensitive analyses at a reasonable cost.","main_category":"cs.PL","categories":"cs.PL,cs.SE","published":"2025-04-08T13:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.06027v1","title":"OSDM-MReg: Multimodal Image Registration based One Step Diffusion Model","summary":"Multimodal remote sensing image registration aligns images from different\nsensors for data fusion and analysis. However, current methods often fail to\nextract modality-invariant features when aligning image pairs with large\nnonlinear radiometric differences. To address this issues, we propose\nOSDM-MReg, a novel multimodal image registration framework based image-to-image\ntranslation to eliminate the gap of multimodal images. Firstly, we propose a\nnovel one-step unaligned target-guided conditional denoising diffusion\nprobabilistic models(UTGOS-CDDPM)to translate multimodal images into a unified\ndomain. In the inference stage, traditional conditional DDPM generate\ntranslated source image by a large number of iterations, which severely slows\ndown the image registration task. To address this issues, we use the unaligned\ntraget image as a condition to promote the generation of low-frequency features\nof the translated source image. Furthermore, during the training stage, we add\nthe inverse process of directly predicting the translated image to ensure that\nthe translated source image can be generated in one step during the testing\nstage. Additionally, to supervised the detail features of translated source\nimage, we propose a new perceptual loss that focuses on the high-frequency\nfeature differences between the translated and ground-truth images. Finally, a\nmultimodal multiscale image registration network (MM-Reg) fuse the multimodal\nfeature of the unimodal images and multimodal images by proposed multimodal\nfeature fusion strategy. Experiments demonstrate superior accuracy and\nefficiency across various multimodal registration tasks, particularly for\nSAR-optical image pairs.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-08T13:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.06040v1","title":"Exploring the Lifecycle and Maintenance Practices of Pre-Trained Models\n  in Open-Source Software Repositories","summary":"Pre-trained models (PTMs) are becoming a common component in open-source\nsoftware (OSS) development, yet their roles, maintenance practices, and\nlifecycle challenges remain underexplored. This report presents a plan for an\nexploratory study to investigate how PTMs are utilized, maintained, and tested\nin OSS projects, focusing on models hosted on platforms like Hugging Face and\nPyTorch Hub. We plan to explore how PTMs are used in open-source software\nprojects and their related maintenance practices by mining software\nrepositories that use PTMs and analyzing their code-base, historical data, and\nreported issues. This study aims to provide actionable insights into improving\nthe use and sustainability of PTM in open-source projects and a step towards a\nfoundation for advancing software engineering practices in the context of model\ndependencies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T13:41:13Z"}
{"aid":"http://arxiv.org/abs/2504.06044v1","title":"Polynomial-Time PIT from (Almost) Necessary Assumptions","summary":"The celebrated result of Kabanets and Impagliazzo (Computational Complexity,\n2004) showed that PIT algorithms imply circuit lower bounds, and vice versa.\nSince then it has been a major challenge to understand the precise connections\nbetween PIT and lower bounds. In particular, a main goal has been to understand\nwhich lower bounds suffice to obtain efficient PIT algorithms, and how close\nare they to lower bounds that are necessary for the conclusion.\n  We construct polynomial-time PIT algorithms from lower bounds that are, up to\nrelatively minor remaining gaps, necessary for the existence of such\nalgorithms. That is, we prove that these lower bounds are, up to the mentioned\nminor gaps, both sufficient and necessary for polynomial-time PIT, over fields\nof characteristic zero. Over sufficiently large finite fields, we show a\nsimilar result wherein the PIT algorithm runs in time $n^{\\log^{(c)}(n)}$, i.e.\na power of $c$-iterated log for an arbitrarily large constant $c>1$.\n  The key to these improvements is studying PIT versus lower bounds in the\nuniform setting, in which we focus on proving lower bounds for uniform\narithmetic circuits and their variants (and on deducing algorithms from such\nlower bounds). Indeed, by working in this setting we obtain results that are\nsignificantly tighter than previously known results concerning polynomial-time\nPIT vs lower bounds, and are in fact also tighter than known\nhardness-vs-randomness connections in the Boolean setting.\n  Our results are obtained by combining recent techniques from Boolean hardness\nvs randomness, and in particular the generator of Chen and Tell (FOCS 2021),\nwith the algebraic hitting-set generator of Guo, Kumar, Saptharishi, and\nSolomon (SIAM J. Computing 2022) along with the bootstrapping ideas of Agrawal,\nGhosh, and Saxena (STOC 2018) and of Kumar, Saptharishi, and Tengse (SODA\n2019).","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-08T13:44:21Z"}
{"aid":"http://arxiv.org/abs/2504.06048v1","title":"Trust-Region Twisted Policy Improvement","summary":"Monte-Carlo tree search (MCTS) has driven many recent breakthroughs in deep\nreinforcement learning (RL). However, scaling MCTS to parallel compute has\nproven challenging in practice which has motivated alternative planners like\nsequential Monte-Carlo (SMC). Many of these SMC methods adopt particle filters\nfor smoothing through a reformulation of RL as a policy inference problem. Yet,\npersisting design choices of these particle filters often conflict with the aim\nof online planning in RL, which is to obtain a policy improvement at the start\nof planning. Drawing inspiration from MCTS, we tailor SMC planners specifically\nfor RL by improving data generation within the planner through constrained\naction sampling and explicit terminal state handling, as well as improving\npolicy and value target estimation. This leads to our Trust-Region Twisted SMC\n(TRT-SMC), which shows improved runtime and sample-efficiency over baseline\nMCTS and SMC methods in both discrete and continuous domains.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T13:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.06050v1","title":"Low-loss far-infrared surface phonon polaritons in suspended SrTiO3\n  nanomembranes","summary":"Phonon polaritons (PhPs), excitations arising from the coupling of light with\nlattice vibrations, enable light confinement and local field enhancement, which\nis essential for various photonic and thermal applications. To date, PhPs with\nhigh confinement and low loss have been mainly observed in the mid-infrared\nregime and mostly in manually exfoliated flakes of van der Waals (vdW)\nmaterials. In this work, we demonstrate the existence of low-loss,\nthickness-tunable phonon polaritons in the far-infrared regime within\ntransferable free-standing SrTiO3 membranes synthesized through a scalable\napproach, achieving high figures of merit, which are comparable to the previous\nrecord values from the vdW materials. Leveraging atomic precision in thickness\ncontrol, large dimensions, and compatibility with mature oxide electronics,\nfunctional oxide membranes present a promising large-scale two-dimensional (2D)\nplatform alternative to vdW materials for on-chip polaritonic technologies in\nthe far-infrared regime.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-08T13:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.06061v1","title":"Non-reciprocal waves in two-dimensional electron systems with\n  temperature gradient","summary":"We demonstrate that the interaction of dc temperature gradient with ac\nmagnetic field in temperature-biased two-dimensional electron systems leads to\nformation of a new electromagnetic mode, a two-dimensional thermomagnetic wave\n(2d TMW). This wave is transverse electric and non-reciprocal, and its damping\nrate can be lower than that of conventional 2d plasma waves. The Q-factor of 2d\nTMW is independent of the wave vector. Numerical estimates show that in\nstate-of-the-art two-dimensional electrons systems the 2d TMW Q-factor is the\norder of $10^{-3}$. We discuss possible ways to overcome this issue.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T14:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.06063v1","title":"Inclusive semileptonic decays of the $D_s$ meson: A first-principles\n  lattice QCD calculation","summary":"We present the results of a first-principles theoretical study of the\ninclusive semileptonic decays of the $D_s$ meson. We performed a\nstate-of-the-art lattice QCD calculation using the gauge ensembles produced by\nthe Extended Twisted Mass Collaboration (ETMC) with dynamical light, strange\nand charm quarks with physical masses and employed the so-called\nHansen-Lupo-Tantalo (HLT) method to extract the decay rate and the first two\nlepton-energy moments from the relevant Euclidean correlators. We have\ncarefully taken into account all sources of systematic errors, including the\nones associated with the continuum and infinite-volume extrapolations and with\nthe HLT spectral reconstruction method. We obtained results in very good\nagreement with the currently available experimental determinations and with a\ntotal accuracy at the few-percent level, of the same order of magnitude of the\nexperimental error. Our total error is dominated by the lattice QCD simulations\nstatistical uncertainties and is certainly improvable. From the results\npresented and thoroughly discussed in this paper we conclude that it is\nnowadays possible to study heavy mesons inclusive semileptonic decays on the\nlattice at a phenomenologically relevant level of accuracy. The\nphenomenological implications of our physical results are the subject of a\ncompanion letter [1].","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-08T14:07:58Z"}
{"aid":"http://arxiv.org/abs/2504.06074v1","title":"On Contact Round Surgeries on $(\\mathbb{S}^3,Î¾_{st})$ and Their\n  Diagrams","summary":"We introduce the notions of contact round surgery of index 1 and 2,\nrespectively, on Legendrian knots in $\\left(\\mathbb{S}^3, \\xi_{st}\\right)$ and\nassociate diagrams to them. We realize Jiro Adachi's contact round surgeries as\nspecial cases. We show that every closed connected contact 3-manifold can be\nobtained by performing a sequence of contact round surgeries on some Legendrian\nlink in $\\left(\\mathbb{S}^3, \\xi_{st}\\right)$, thus obtaining a contact round\nsurgery diagram for each contact 3-manifold. This is analogous to a similar\nresult of Ding and Geiges for contact Dehn surgeries. We discuss a bridge\nbetween certain pairs of contact round surgery diagrams of index 1 and 2 and\ncontact $\\pm1$-surgery diagrams. We use this bridge to establish the result\nmentioned above.","main_category":"math.SG","categories":"math.SG,math.GT","published":"2025-04-08T14:12:27Z"}
{"aid":"http://arxiv.org/abs/2504.06081v1","title":"On the interference of the scattered wave and the incident wave in light\n  scattering problems with Gaussian beams","summary":"We consider the light scattering problem for a Gaussian beam and a\n(spherical) particle at arbitrary location. Within the beam cross section, the\ntotal electromagnetic field is the superposition of the incident beam and the\nscattered wave. Using the Generalized Lorenz-Mie Theory (GLMT) as a vehicle to\naccess such scattering problems, we discuss the mathematical modeling of this\ninterference at short, large but finite and infinite distances from the\nscatterer. We show how to eliminate the errors that can arise from improper\nmodeling in the most straight-forward manner, that is superimposing the\nscattered wave with the closed-form expression for the Gaussian beam at a\nfinite distance from the particle. GLMT uses a low order beam model ($s^1$),\nbut using the known higher order models ($s^3$, $s^5$, $s^7$, ...) would not\nmitigate these errors as we discuss. The challenge lies in an appropriate\ndescription of the Gaussian beam at arbitrary distances from its focus, not in\nits description on the scale of a particle (located in or near the focus) nor\nin the expressions for the scattered field. Hence, the solutions described here\ncan readily be extended to light scattering frameworks other than GLMT and are\nthus also relevant for non-spherical particles.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T14:20:57Z"}
{"aid":"http://arxiv.org/abs/2504.06087v1","title":"Accurate Ab-initio Neural-network Solutions to Large-Scale Electronic\n  Structure Problems","summary":"We present finite-range embeddings (FiRE), a novel wave function ansatz for\naccurate large-scale ab-initio electronic structure calculations. Compared to\ncontemporary neural-network wave functions, FiRE reduces the asymptotic\ncomplexity of neural-network variational Monte Carlo (NN-VMC) by $\\sim\nn_\\text{el}$, the number of electrons. By restricting electron-electron\ninteractions within the neural network, FiRE accelerates all key operations --\nsampling, pseudopotentials, and Laplacian computations -- resulting in a\nreal-world $10\\times$ acceleration in now-feasible 180-electron calculations.\nWe validate our method's accuracy on various challenging systems, including\nbiochemical compounds, conjugated hydrocarbons, and organometallic compounds.\nOn these systems, FiRE's energies are consistently within chemical accuracy of\nthe most reliable data, including experiments, even in cases where\nhigh-accuracy methods such as CCSD(T), AFQMC, or contemporary NN-VMC fall\nshort. With these improvements in both runtime and accuracy, FiRE represents a\nnew `gold-standard' method for fast and accurate large-scale ab-initio\ncalculations, potentially enabling new computational studies in fields like\nquantum chemistry, solid-state physics, and material design.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cs.LG,physics.chem-ph","published":"2025-04-08T14:28:54Z"}
{"aid":"http://arxiv.org/abs/2504.06111v1","title":"Leveraging Axis-Aligned Subspaces for High-Dimensional Bayesian\n  Optimization with Group Testing","summary":"Bayesian optimization (BO ) is an effective method for optimizing\nexpensive-to-evaluate black-box functions. While high-dimensional problems can\nbe particularly challenging, due to the multitude of parameter choices and the\npotentially high number of data points required to fit the model, this\nlimitation can be addressed if the problem satisfies simplifying assumptions.\nAxis-aligned subspace approaches, where few dimensions have a significant\nimpact on the objective, motivated several algorithms for high-dimensional BO .\nHowever, the validity of this assumption is rarely verified, and the assumption\nis rarely exploited to its full extent. We propose a group testing ( GT)\napproach to identify active variables to facilitate efficient optimization in\nthese domains. The proposed algorithm, Group Testing Bayesian Optimization\n(GTBO), first runs a testing phase where groups of variables are systematically\nselected and tested on whether they influence the objective, then terminates\nonce active dimensions are identified. To that end, we extend the\nwell-established GT theory to functions over continuous domains. In the second\nphase, GTBO guides optimization by placing more importance on the active\ndimensions. By leveraging the axis-aligned subspace assumption, GTBO\noutperforms state-of-the-art methods on benchmarks satisfying the assumption of\naxis-aligned subspaces, while offering improved interpretability.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-08T15:00:15Z"}
{"aid":"http://arxiv.org/abs/2504.06113v1","title":"Interplay between trimer structure and magnetic ground state in\n  Ba5Ru3O12 probed by Neutron and muSR techniques","summary":"We report a detailed inelastic neutron scattering (INS) and muon spin\nrelaxation (muSR) investigations of a trimer Ruthenate Ba5Ru3O12 system, which\nundergoes long-range antiferromagnetic ordering at TN = 60 K. The INS reveals\ntwo distinct spin-wave excitations below TN : one around 5.6 meV and the other\nat 10 to 15 meV. The coexistence of such excitations at both low and high\nmomentum transfer regions is speculated to be strong electronic correlation and\nspin-phonon coupling of Ruthenium. By accompanying the INS spectra based on a\nlinear spin wave theory using SpinW software, we show that Ba5Ru3O12 exhibits\nspin frustration due to competing exchange interactions between neighboring and\nnext-neighboring Ru-moments, exchange anisotropy and strong spin-orbit\ncoupling, which yields a non-collinear spin structure, in contrast to other\nruthenate trimers in this series. Interestingly, these magnetic excitations\ndoes not completely vanish even at high temperatures above TN , evidencing\nshort-range magnetic correlations in this trimer system. This is further\nsupported by muSR spectroscopy, which exhibits a gradual drop in the initial\nasymmetry around the magnetic phase transition and is further verified through\nmaximum entropy analysis. The results of muSR spectroscopy indicates a dynamic\nnature of magnetic order, attributed to local magnetic anisotropy within the\ntrimer as a result of local structural distortion and different hybridization,\nconsistent with canted spin-structure. We predict the ground state of\nRu3O12-isolated trimer through theoretical calculations which agree with the\nexperimentally observed spin excitation.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T15:06:01Z"}
{"aid":"http://arxiv.org/abs/2504.06133v1","title":"Gravitational Baryogenesis in Extended Proca-Nuevo Gravity","summary":"In this article, we investigate the gravitational baryogenesis mechanism in\nthe framework of Extended Proca-Nuevo (EPN) gravity, a theory where a massive\nvector field is non-minimally coupled to the curvature. This analysis is\ncarried out for an early universe, encompassing three separate cosmological\nscenarios defined by power-law, exponential, and modified exponential scale\nfactors. By deriving the modified field equations from the EPN action, we\nobtain precise solutions for each scale factor, including the influence of the\nvector field. We compute the baryon-to-entropy ratio using the gravitational\nbaryogenesis formalism, where the baryon asymmetry arises from a dynamical\ncoupling of the baryon current with the derivative of the Ricci scalar. Our\nfindings demonstrate that the baryon-to-entropy ratio is consistent with\nobservational constraints in all scenarios, highlighting the potential of EPN\ngravity as a viable theory to explain the matter-antimatter asymmetry in the\nearly universe. The study further stresses the contribution of anisotropy and\nvector field dynamics to the cosmological evolution within modified gravity\nmodels.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T15:26:58Z"}
{"aid":"http://arxiv.org/abs/2504.06151v1","title":"Zerrow: True Zero-Copy Arrow Pipelines in Bauplan","summary":"Bauplan is a FaaS-based lakehouse specifically built for data pipelines: its\nexecution engine uses Apache Arrow for data passing between the nodes in the\nDAG. While Arrow is known as the \"zero copy format\", in practice, limited Linux\nkernel support for shared memory makes it difficult to avoid copying entirely.\nIn this work, we introduce several new techniques to eliminate nearly all\ncopying from pipelines: in particular, we implement a new kernel module that\nperforms de-anonymization, thus eliminating a copy to intermediate data. We\nconclude by sharing our preliminary evaluation on different workloads types, as\nwell as discussing our plan for future improvements.","main_category":"cs.OS","categories":"cs.OS,cs.DB","published":"2025-04-08T15:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.06155v1","title":"K-theory and matrix transfers","summary":"We introduce and study matrix transfers to achieve elementary models for\nbivariant $K$-theory. They share lots of common properties with Voevodsky's\nframed correspondences and lead to symmetric matrix motives of algebraic\nvarieties introduced in this paper. Symmetric matrix motives recover\n$K$-motives and fit in a closed symmetric monoidal triangulated category of\nsymmetric matrix motives constructed in this paper by using methods of enriched\nmotivic homotopy theory.","main_category":"math.KT","categories":"math.KT,math.AG,math.RA","published":"2025-04-08T15:49:33Z"}
{"aid":"http://arxiv.org/abs/2504.06157v1","title":"Hall Effect Thruster Forecasting using a Topological Approach for Data\n  Assimilation","summary":"Hall Effect Thrusters (HETs) are electric thrusters that eject heavy ionized\ngas particles from the spacecraft to generate thrust. Although traditionally\nthey were used for station keeping, recently They have been used for\ninterplanetary space missions due to their high delta-V potential and their\noperational longevity in contrast to other thrusters, e.g., chemical. However,\nthe operation of HETs involves complex processes such as ionization of gases,\nstrong magnetic fields, and complicated solar panel power supply interactions.\nTherefore, their operation is extremely difficult to model thus necessitating\nData Assimilation (DA) approaches for estimating and predicting their\noperational states. Because HET's operating environment is often noisy with\nnon-Gaussian sources, this significantly limits applicable DA tools. We\ndescribe a topological approach for data assimilation that bypasses these\nlimitations that does not depend on the noise model, and utilize it to forecast\nspatiotemporal plume field states of HETs. Our approach is a generalization of\nthe Topological Approach for Data Assimilation (TADA) method that allows\nincluding different forecast functions. We show how TADA can be combined with\nthe Long Short-Term Memory network for accurate forecasting. We then apply our\napproach to high-fidelity Hall Effect Thruster (HET) simulation data from the\nAir Force Research Laboratory (AFRL) rocket propulsion division where we\ndemonstrate the forecast resiliency of TADA on noise contaminated,\nhigh-dimensional data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T15:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.06167v1","title":"Signaling Human Intentions to Service Robots: Understanding the Use of\n  Social Cues during In-Person Conversations","summary":"As social service robots become commonplace, it is essential for them to\neffectively interpret human signals, such as verbal, gesture, and eye gaze,\nwhen people need to focus on their primary tasks to minimize interruptions and\ndistractions. Toward such a socially acceptable Human-Robot Interaction, we\nconducted a study ($N=24$) in an AR-simulated context of a coffee chat.\nParticipants elicited social cues to signal intentions to an anthropomorphic,\nzoomorphic, grounded technical, or aerial technical robot waiter when they were\nspeakers or listeners. Our findings reveal common patterns of social cues over\nintentions, the effects of robot morphology on social cue position and\nconversational role on social cue complexity, and users' rationale in choosing\nsocial cues. We offer insights into understanding social cues concerning\nperceptions of robots, cognitive load, and social context. Additionally, we\ndiscuss design considerations on approaching, social cue recognition, and\nresponse strategies for future service robots.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T16:07:00Z"}
{"aid":"http://arxiv.org/abs/2504.06177v1","title":"Hydroxide Mobility in Aqueous Systems: Ab Initio Accuracy with\n  Millisecond Timescales","summary":"We present a multiscale simulation approach for hydroxide transport in\naqueous solutions of potassium hydroxide, combining ab initio molecular\ndynamics (AIMD) simulations with force field ensemble averaging and lattice\nMonte Carlo techniques. This method achieves near ab initio accuracy by\ncapturing the femtosecond scale dielectric relaxation dynamics of the aqueous\nhydrogen bonding network, while extending the simulation capability to\nmillisecond diffusion timescales. This extraordinary extension of the available\nlength and time scales enables future studies of hydroxide mobility in\nfunctional materials such as nanostructured anion-exchange membranes, where\nhydroxide ions migrate through nanometer-sized channels. Remarkably, our\napproach demonstrates that a single AIMD trajectory is sufficient to predict\nhydroxide conductivity over a range of concentrations, underscoring its\ncomputational efficiency and relevance to the design of advanced energy\nmaterials.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-08T16:19:46Z"}
{"aid":"http://arxiv.org/abs/2504.06178v1","title":"Flash Sculptor: Modular 3D Worlds from Objects","summary":"Existing text-to-3D and image-to-3D models often struggle with complex scenes\ninvolving multiple objects and intricate interactions. Although some recent\nattempts have explored such compositional scenarios, they still require an\nextensive process of optimizing the entire layout, which is highly cumbersome\nif not infeasible at all. To overcome these challenges, we propose Flash\nSculptor in this paper, a simple yet effective framework for compositional 3D\nscene/object reconstruction from a single image. At the heart of Flash Sculptor\nlies a divide-and-conquer strategy, which decouples compositional scene\nreconstruction into a sequence of sub-tasks, including handling the appearance,\nrotation, scale, and translation of each individual instance. Specifically, for\nrotation, we introduce a coarse-to-fine scheme that brings the best of both\nworlds--efficiency and accuracy--while for translation, we develop an\noutlier-removal-based algorithm that ensures robust and precise parameters in a\nsingle step, without any iterative optimization. Extensive experiments\ndemonstrate that Flash Sculptor achieves at least a 3 times speedup over\nexisting compositional 3D methods, while setting new benchmarks in\ncompositional 3D reconstruction performance. Codes are available at\nhttps://github.com/YujiaHu1109/Flash-Sculptor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T16:20:51Z"}
{"aid":"http://arxiv.org/abs/2504.06187v1","title":"Scaling Invariance: A Gateway to Phase Transitions","summary":"We explore the concept of scaling invariance in a type of dynamical systems\nthat undergo a transition from order (regularity) to disorder (chaos). The\nsystems are described by a two-dimensional, nonlinear mapping that preserves\nthe area in the phase space. The key variables are the action and the angle, as\nusual from Hamiltonian systems. The transition is influenced by a control\nparameter giving the form of the order parameter. We observe a scaling\ninvariance in the average squared action within the chaotic region, providing\nevidence that this change from regularity (integrability) to chaos\n(non-integrability) is akin to a second-order or continuous phase transition.\nAs the order parameter approaches zero, its response against the variation of\nthe control parameter (susceptibility) becomes increasingly pronounced (indeed\ndiverging), resembling a phase transition. These findings could not be obtained\nwithout a seminal paper on Phys. Rev. Lett. {\\bf 2004}, {\\em 93}, 014101.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-08T16:31:23Z"}
{"aid":"http://arxiv.org/abs/2504.06203v1","title":"Factorizing Defects from Generalized Pinning Fields","summary":"We introduce generalized pinning fields in conformal field theory that model\na large class of critical impurities at large distance, enriching the familiar\nuniversality classes. We provide a rigorous definition of such defects as\ncertain unbounded operators on the Hilbert space and prove that when inserted\non codimension-one surfaces they factorize the spacetime into two halves. The\nfactorization channels are further constrained by symmetries in the bulk. As a\ncorollary, we solve such critical impurities in the 2d minimal models and\nestablish the factorization phenomena previously observed for localized mass\ndeformations in the 3d ${\\rm O}(N)$ model.","main_category":"hep-th","categories":"hep-th,cond-mat.str-el,math.OA","published":"2025-04-08T16:47:34Z"}
{"aid":"http://arxiv.org/abs/2504.06211v1","title":"Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs","summary":"Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in\nprivacy-preserving and verifiable computing. ZKPs enable a proving party to\nprove the truth of a statement to a verifying party without revealing anything\nelse. ZKPs have applications in blockchain technologies, verifiable machine\nlearning, and electronic voting, but have yet to see widespread adoption due to\nthe computational complexity of the proving process. Recent works have\naccelerated the key primitives of state-of-the-art ZKP protocols on GPU and\nASIC. However, the protocols accelerated thus far face one of two challenges:\nthey either require a trusted setup for each application, or they generate\nlarger proof sizes with higher verification costs, limiting their applicability\nin scenarios with numerous verifiers or strict verification time constraints.\nThis work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art\nZKP protocol that supports both one-time, universal setup and small proof sizes\nfor typical ZKP applications in publicly verifiable, consensus-based systems.\nWe accelerate the entire protocol, including two major primitives: SumCheck and\nMulti-scalar Multiplications (MSMs). We develop a full-chip architecture using\n366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation\nprocess, achieving geometric mean speedups of 801$\\times$ over CPU baselines.","main_category":"cs.AR","categories":"cs.AR,cs.CR","published":"2025-04-08T16:56:10Z"}
{"aid":"http://arxiv.org/abs/2504.06223v1","title":"Generalized Bronnikov-Ellis wormhole solution in the\n  scalar-Einstein-Gauss-Bonnet $4d$ gravitational model","summary":"We consider the sEGB $4d$ gravitational model with a scalar field\n$\\varphi\\left(u\\right)$, Einstein and Gauss-Bonnet terms. The model action\ncontains a potential term $U\\left(\\varphi\\right))$, a Gauss-Bonnet coupling\nfunction $f\\left(\\varphi\\right)$ and a parameter $\\varepsilon = \\pm 1$, where\n$\\varepsilon = 1$ corresponds to the usual scalar field, and $\\varepsilon = -1$\nto the phantom field. In this paper, the sEGB reconstruction procedure\nconsidered in our previous paper is applied to the metric of the\nBronnikov-Ellis solution, which describes a massive wormhole in the model with\na phantom field (and zero potential). For this metric, written in the Buchdal\nparameterization with a radial variable $u$, we find a solution of the master\nequation for $ f\\left(\\varphi\\left(u\\right)\\right)$ with the integration\n(reconstruction) parameter $C_0$. We also find expressions for\n$U\\left(\\varphi\\left(u\\right)\\right)$ and $\\varepsilon \\dot{\\varphi} =\nh\\left(u\\right)$ for $\\varepsilon = \\pm 1$. We prove that for all non-trivial\nvalues of the parameter $C_0 \\neq 0$ the function $h\\left(u\\right)$ is not of\nconstant sign for all admissible $u \\in \\left(-\\infty , +\\infty\\right)$. This\nmeans that for a fixed value of the parameter $\\varepsilon = \\pm 1$ there is no\nnon-trivial sEGB reconstruction in which the scalar field is a purely ordinary\nfield ($\\varepsilon = 1$) or a purely phantom field ($\\varepsilon = - 1$).","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T17:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.06228v1","title":"SOFIA/upGREAT imaging spectroscopy of the [C II] 158 um fine structure\n  line toward the Sgr A region in the Galactic center","summary":"We present SOFIA/upGREAT velocity-resolved spectral imaging and analysis of\nthe 158 um [C II] spectral line toward the central 80 by 43\\,pc region of the\nCentral Molecular Zone of the Galaxy. The field we imaged with 14\" (0.6 pc)\nspatial and 1 km/s spectral resolution contains the Circum-Nuclear Disk (CND)\naround the central black hole Sgr A*, the neighboring thermal Arched Filaments,\nthe nonthermal filaments of the Radio Arc, and the three luminous central star\nclusters. [C II] traces emission from the CND's inner edge to material orbiting\nat a distance of approximately 6 pc. Its velocity field reveals no sign of\ninflowing material nor interaction with winds from the Sgr A East supernova\nremnant. Wide-field imaging of the Sgr A region shows multiple circular\nsegments, including the thermal Arched Filaments, that are centered on a region\nthat includes the Quintuplet cluster. We examine the possibility that the\nArched Filaments and other large-scale arcs trace transient excitation events\nfrom supernova blast waves. Along the Arched Filaments, comparisons among\nfar-IR fine structure lines show changes in ionization state over small scales\nand that high-excitation lines are systematically shifted in position from the\nother lines. These also point to transient fast winds that shocked on the\nsurface of the Arches cloud to produce additional local UV radiation to excite\nthe Arched Filaments on a cloud surface illuminated by UV from hot stars.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T17:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.06231v1","title":"Orb-v3: atomistic simulation at scale","summary":"We introduce Orb-v3, the next generation of the Orb family of universal\ninteratomic potentials. Models in this family expand the\nperformance-speed-memory Pareto frontier, offering near SoTA performance across\na range of evaluations with a >10x reduction in latency and > 8x reduction in\nmemory. Our experiments systematically traverse this frontier, charting the\ntrade-off induced by roto-equivariance, conservatism and graph sparsity.\nContrary to recent literature, we find that non-equivariant, non-conservative\narchitectures can accurately model physical properties, including those which\nrequire higher-order derivatives of the potential energy surface.\n  This model release is guided by the principle that the most valuable\nfoundation models for atomic simulation will excel on all fronts: accuracy,\nlatency and system size scalability. The reward for doing so is a new era of\ncomputational chemistry driven by high-throughput and mesoscale all-atom\nsimulations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:27:34Z"}
{"aid":"http://arxiv.org/abs/2504.06232v1","title":"HiFlow: Training-free High-Resolution Image Generation with Flow-Aligned\n  Guidance","summary":"Text-to-image (T2I) diffusion/flow models have drawn considerable attention\nrecently due to their remarkable ability to deliver flexible visual creations.\nStill, high-resolution image synthesis presents formidable challenges due to\nthe scarcity and complexity of high-resolution content. To this end, we present\nHiFlow, a training-free and model-agnostic framework to unlock the resolution\npotential of pre-trained flow models. Specifically, HiFlow establishes a\nvirtual reference flow within the high-resolution space that effectively\ncaptures the characteristics of low-resolution flow information, offering\nguidance for high-resolution generation through three key aspects:\ninitialization alignment for low-frequency consistency, direction alignment for\nstructure preservation, and acceleration alignment for detail fidelity. By\nleveraging this flow-aligned guidance, HiFlow substantially elevates the\nquality of high-resolution image synthesis of T2I models and demonstrates\nversatility across their personalized variants. Extensive experiments validate\nHiFlow's superiority in achieving superior high-resolution image quality over\ncurrent state-of-the-art methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:30:40Z"}
{"aid":"http://arxiv.org/abs/2504.06263v1","title":"OmniSVG: A Unified Scalable Vector Graphics Generation Model","summary":"Scalable Vector Graphics (SVG) is an important image format widely adopted in\ngraphic design because of their resolution independence and editability. The\nstudy of generating high-quality SVG has continuously drawn attention from both\ndesigners and researchers in the AIGC community. However, existing methods\neither produces unstructured outputs with huge computational cost or is limited\nto generating monochrome icons of over-simplified structures. To produce\nhigh-quality and complex SVG, we propose OmniSVG, a unified framework that\nleverages pre-trained Vision-Language Models (VLMs) for end-to-end multimodal\nSVG generation. By parameterizing SVG commands and coordinates into discrete\ntokens, OmniSVG decouples structural logic from low-level geometry for\nefficient training while maintaining the expressiveness of complex SVG\nstructure. To further advance the development of SVG synthesis, we introduce\nMMSVG-2M, a multimodal dataset with two million richly annotated SVG assets,\nalong with a standardized evaluation protocol for conditional SVG generation\ntasks. Extensive experiments show that OmniSVG outperforms existing methods and\ndemonstrates its potential for integration into professional SVG design\nworkflows.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:59:49Z"}
{"aid":"http://arxiv.org/abs/2504.06552v1","title":"Understanding Users' Security and Privacy Concerns and Attitudes Towards\n  Conversational AI Platforms","summary":"The widespread adoption of conversational AI platforms has introduced new\nsecurity and privacy risks. While these risks and their mitigation strategies\nhave been extensively researched from a technical perspective, users'\nperceptions of these platforms' security and privacy remain largely unexplored.\nIn this paper, we conduct a large-scale analysis of over 2.5M user posts from\nthe r/ChatGPT Reddit community to understand users' security and privacy\nconcerns and attitudes toward conversational AI platforms. Our qualitative\nanalysis reveals that users are concerned about each stage of the data\nlifecycle (i.e., collection, usage, and retention). They seek mitigations for\nsecurity vulnerabilities, compliance with privacy regulations, and greater\ntransparency and control in data handling. We also find that users exhibit\nvaried behaviors and preferences when interacting with these platforms. Some\nusers proactively safeguard their data and adjust privacy settings, while\nothers prioritize convenience over privacy risks, dismissing privacy concerns\nin favor of benefits, or feel resigned to inevitable data sharing. Through\nqualitative content and regression analysis, we discover that users' concerns\nevolve over time with the evolving AI landscape and are influenced by\ntechnological developments and major events. Based on our findings, we provide\nrecommendations for users, platforms, enterprises, and policymakers to enhance\ntransparency, improve data controls, and increase user trust and adoption.","main_category":"cs.CR","categories":"cs.CR,cs.CY","published":"2025-04-09T03:22:48Z"}
{"aid":"http://arxiv.org/abs/2504.06559v1","title":"TabKAN: Advancing Tabular Data Analysis using Kolmograv-Arnold Network","summary":"Tabular data analysis presents unique challenges due to its heterogeneous\nfeature types, missing values, and complex interactions. While traditional\nmachine learning methods, such as gradient boosting, often outperform deep\nlearning approaches, recent advancements in neural architectures offer\npromising alternatives. This paper introduces TabKAN, a novel framework that\nadvances tabular data modeling using Kolmogorov-Arnold Networks (KANs). Unlike\nconventional deep learning models, KANs leverage learnable activation functions\non edges, enhancing both interpretability and training efficiency. Our\ncontributions include: (1) the introduction of modular KAN-based architectures\ntailored for tabular data analysis, (2) the development of a transfer learning\nframework for KAN models, enabling effective knowledge transfer between\ndomains, (3) the development of model-specific interpretability for tabular\ndata learning, reducing reliance on post hoc and model-agnostic analysis, and\n(4) comprehensive evaluation of vanilla supervised learning across binary and\nmulti-class classification tasks. Through extensive benchmarking on diverse\npublic datasets, TabKAN demonstrates superior performance in supervised\nlearning while significantly outperforming classical and Transformer-based\nmodels in transfer learning scenarios. Our findings highlight the advantage of\nKAN-based architectures in efficiently transferring knowledge across domains,\nbridging the gap between traditional machine learning and deep learning for\nstructured data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T03:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.06567v1","title":"A Novel Angle-Delay-Doppler Estimation Scheme for AFDM-ISAC System in\n  Mixed Near-field and Far-field Scenarios","summary":"The recently proposed multi-chirp waveform, affine frequency division\nmultiplexing (AFDM), is considered as a potential candidate for integrated\nsensing and communication (ISAC). However, acquiring accurate target sensing\nparameter information becomes challenging due to fractional delay and Doppler\nshift occurrence, as well as effects introduced by the coexistence of\nnear-field (NF) and far-field (FF) targets associated with large-scale antenna\nsystems. In this paper, we propose a novel angle-delay-Doppler estimation\nscheme for AFDM-ISAC system in mixed NF and FF scenarios. Specifically, we\nmodel the received ISAC signals as a third-order tensor that admits a low-rank\nCANDECOMP/PARAFAC (CP) format. By employing the Vandermonde nature of the\nfactor matrix and the spatial smoothing technique, we develop a structured CP\ndecomposition method that guarantees the condition for uniqueness. We further\npropose a low-complexity estimation scheme to acquire target sensing parameters\nwith fractional values, including angle of arrival/departure (AoA/AoD), delay\nand Doppler shift accurately. We also derive the Cram\\'er-Rao Lower Bound\n(CRLB) as a benchmark and analyze the complexity of our proposed scheme.\nFinally, simulation results are provided to demonstrate the effectiveness and\nsuperiority of our proposed scheme.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T04:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.06572v1","title":"Domain Generalization via Discrete Codebook Learning","summary":"Domain generalization (DG) strives to address distribution shifts across\ndiverse environments to enhance model's generalizability. Current DG approaches\nare confined to acquiring robust representations with continuous features,\nspecifically training at the pixel level. However, this DG paradigm may\nstruggle to mitigate distribution gaps in dealing with a large space of\ncontinuous features, rendering it susceptible to pixel details that exhibit\nspurious correlations or noise. In this paper, we first theoretically\ndemonstrate that the domain gaps in continuous representation learning can be\nreduced by the discretization process. Based on this inspiring finding, we\nintroduce a novel learning paradigm for DG, termed Discrete Domain\nGeneralization (DDG). DDG proposes to use a codebook to quantize the feature\nmap into discrete codewords, aligning semantic-equivalent information in a\nshared discrete representation space that prioritizes semantic-level\ninformation over pixel-level intricacies. By learning at the semantic level,\nDDG diminishes the number of latent features, optimizing the utilization of the\nrepresentation space and alleviating the risks associated with the wide-ranging\nspace of continuous features. Extensive experiments across widely employed\nbenchmarks in DG demonstrate DDG's superior performance compared to\nstate-of-the-art approaches, underscoring its potential to reduce the\ndistribution gaps and enhance the model's generalizability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T04:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.06584v1","title":"CAFE-AD: Cross-Scenario Adaptive Feature Enhancement for Trajectory\n  Planning in Autonomous Driving","summary":"Imitation learning based planning tasks on the nuPlan dataset have gained\ngreat interest due to their potential to generate human-like driving behaviors.\nHowever, open-loop training on the nuPlan dataset tends to cause causal\nconfusion during closed-loop testing, and the dataset also presents a long-tail\ndistribution of scenarios. These issues introduce challenges for imitation\nlearning. To tackle these problems, we introduce CAFE-AD, a Cross-Scenario\nAdaptive Feature Enhancement for Trajectory Planning in Autonomous Driving\nmethod, designed to enhance feature representation across various scenario\ntypes. We develop an adaptive feature pruning module that ranks feature\nimportance to capture the most relevant information while reducing the\ninterference of noisy information during training. Moreover, we propose a\ncross-scenario feature interpolation module that enhances scenario information\nto introduce diversity, enabling the network to alleviate over-fitting in\ndominant scenarios. We evaluate our method CAFE-AD on the challenging public\nnuPlan Test14-Hard closed-loop simulation benchmark. The results demonstrate\nthat CAFE-AD outperforms state-of-the-art methods including rule-based and\nhybrid planners, and exhibits the potential in mitigating the impact of\nlong-tail distribution within the dataset. Additionally, we further validate\nits effectiveness in real-world environments. The code and models will be made\navailable at https://github.com/AlniyatRui/CAFE-AD.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-09T05:16:29Z"}
{"aid":"http://arxiv.org/abs/2504.06612v1","title":"A Hilbert--Mumford criterion for generalised Monge--AmpÃ¨re equations","summary":"We give a new numerical criterion in the spirit of GIT for existence of\nsolutions to inverse Hessian equations, including in particular the J-equation.\nOur criterion is formulated in terms of stability of pairs in the sense of\nPaul. To that end, we build on previous work of the author with Dervan, and\ngeneralise a result of Zhang, proving isometry between generalised Chow line\nbundles and mixed Deligne pairings.","main_category":"math.DG","categories":"math.DG,math.AG","published":"2025-04-09T06:16:59Z"}
{"aid":"http://arxiv.org/abs/2504.06615v1","title":"Reliability Assessment of Low-Cost PM Sensors under High Humidity and\n  High PM Level Outdoor Conditions","summary":"Low-cost particulate matter (PM) sensors have become increasingly popular due\nto their compact size, low power consumption, and cost-effective installation\nand maintenance. While several studies have explored the effects of\nmeteorological conditions and pollution exposure on low-cost sensor (LCS)\nperformance, few have addressed the combined impact of high PM concentration\nand high humidity levels. In contrast to most evaluation studies, which\ngenerally report $\\text{PM}_{2.5}$ levels below $150~\\mu\\text{g/m}^3$, our\nstudy observed hourly average $\\text{PM}_{2.5}$ concentrations ranging from\n$6-611~\\mu\\text{g/m}^3$ (mean value of $137~\\mu\\text{g/m}^3$), with relative\nhumidity between $25-95\\%$ (mean value of $72\\%$), and temperature varying from\n$6-29^\\circ$C (mean value of $16^\\circ$C). We evaluate three LCS models (SPS30,\nPMS7003, HPMA115C0-004) in outdoor conditions during the winter season in New\nDelhi, India, deployed alongside a reference-grade beta attenuation monitor\n(BAM). The results indicate a strong correlation between LCS and BAM\nmeasurements (${R^2} > 90\\%$). The RMSE increases with increasing PM\nconcentration and humidity levels but the narrow $95\\%$ confidence interval\nrange of LCS as a function of the reference BAM suggests the importance of LCS\nin air pollution monitoring. Among the evaluated LCS models, SPS30 showed the\nhighest overall accuracy. Overall, the study demonstrates that LCS can\neffectively monitor air quality in regions with high PM and high humidity\nlevels, provided appropriate correction models are applied.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T06:21:24Z"}
{"aid":"http://arxiv.org/abs/2504.06618v1","title":"Human-like compositional learning of visually-grounded concepts using\n  synthetic environments","summary":"The compositional structure of language enables humans to decompose complex\nphrases and map them to novel visual concepts, showcasing flexible\nintelligence. While several algorithms exhibit compositionality, they fail to\nelucidate how humans learn to compose concept classes and ground visual cues\nthrough trial and error. To investigate this multi-modal learning challenge, we\ndesigned a 3D synthetic environment in which an agent learns, via\nreinforcement, to navigate to a target specified by a natural language\ninstruction. These instructions comprise nouns, attributes, and critically,\ndeterminers, prepositions, or both. The vast array of word combinations\nheightens the compositional complexity of the visual grounding task, as\nnavigating to a blue cube above red spheres is not rewarded when the\ninstruction specifies navigating to \"some blue cubes below the red sphere\". We\nfirst demonstrate that reinforcement learning agents can ground determiner\nconcepts to visual targets but struggle with more complex prepositional\nconcepts. Second, we show that curriculum learning, a strategy humans employ,\nenhances concept learning efficiency, reducing the required training episodes\nby 15% in determiner environments and enabling agents to easily learn\nprepositional concepts. Finally, we establish that agents trained on determiner\nor prepositional concepts can decompose held-out test instructions and rapidly\nadapt their navigation policies to unseen visual object combinations.\nLeveraging synthetic environments, our findings demonstrate that multi-modal\nreinforcement learning agents can achieve compositional understanding of\ncomplex concept classes and highlight the efficacy of human-like learning\nstrategies in improving artificial systems' learning efficiency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:33:28Z"}
{"aid":"http://arxiv.org/abs/2504.06634v1","title":"Crafting Query-Aware Selective Attention for Single Image\n  Super-Resolution","summary":"Single Image Super-Resolution (SISR) reconstructs high-resolution images from\nlow-resolution inputs, enhancing image details. While Vision Transformer\n(ViT)-based models improve SISR by capturing long-range dependencies, they\nsuffer from quadratic computational costs or employ selective attention\nmechanisms that do not explicitly focus on query-relevant regions. Despite\nthese advancements, prior work has overlooked how selective attention\nmechanisms should be effectively designed for SISR. We propose SSCAN, which\ndynamically selects the most relevant key-value windows based on query\nsimilarity, ensuring focused feature extraction while maintaining efficiency.\nIn contrast to prior approaches that apply attention globally or heuristically,\nour method introduces a query-aware window selection strategy that better\naligns attention computation with important image regions. By incorporating\nfixed-sized windows, SSCAN reduces memory usage and enforces linear\ntoken-to-token complexity, making it scalable for large images. Our experiments\ndemonstrate that SSCAN outperforms existing attention-based SISR methods,\nachieving up to 0.14 dB PSNR improvement on urban datasets, guaranteeing both\ncomputational efficiency and reconstruction quality in SISR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:17:29Z"}
{"aid":"http://arxiv.org/abs/2504.06637v1","title":"SCI-Reason: A Dataset with Chain-of-Thought Rationales for Complex\n  Multimodal Reasoning in Academic Areas","summary":"Large Language Models (LLMs) and Large Multimodal Models (LMMs) demonstrate\nimpressive problem-solving skills in many tasks and domains. However, their\nability to reason with complex images in academic domains has not been\nsystematically investigated. To bridge this gap, we present SCI-Reason, a\ndataset for complex multimodel reasoning in academic areas. SCI-Reason aims to\ntest and improve the reasoning ability of large multimodal models using real\ncomplex images in academic domains. The dataset contains 12,066 images and\n12,626 question-answer pairs extracted from PubMed, divided into training,\nvalidation and test splits. Each question-answer pair also contains an accurate\nand efficient inference chain as a guide to improving the inference properties\nof the dataset. With SCI-Reason, we performed a comprehensive evaluation of 8\nwell-known models. The best performing model, Claude-3.7-Sonnet, only achieved\nan accuracy of 55.19%. Error analysis shows that more than half of the model\nfailures are due to breakdowns in multi-step inference chains rather than\nerrors in primary visual feature extraction. This finding underscores the\ninherent limitations in reasoning capabilities exhibited by current multimodal\nmodels when processing complex image analysis tasks within authentic academic\ncontexts. Experiments on open-source models show that SCI-Reason not only\nenhances reasoning ability but also demonstrates cross-domain generalization in\nVQA tasks. We also explore future applications of model inference capabilities\nin this domain, highlighting its potential for future research.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-09T07:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.06651v1","title":"Collision avoidance from monocular vision trained with novel view\n  synthesis","summary":"Collision avoidance can be checked in explicit environment models such as\nelevation maps or occupancy grids, yet integrating such models with a\nlocomotion policy requires accurate state estimation. In this work, we consider\nthe question of collision avoidance from an implicit environment model. We use\nmonocular RGB images as inputs and train a collisionavoidance policy from\nphotorealistic images generated by 2D Gaussian splatting. We evaluate the\nresulting pipeline in realworld experiments under velocity commands that bring\nthe robot on an intercept course with obstacles. Our results suggest that RGB\nimages can be enough to make collision-avoidance decisions, both in the room\nwhere training data was collected and in out-of-distribution environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:39:12Z"}
{"aid":"http://arxiv.org/abs/2504.06661v1","title":"Domain-Conditioned Scene Graphs for State-Grounded Task Planning","summary":"Recent robotic task planning frameworks have integrated large multimodal\nmodels (LMMs) such as GPT-4V. To address grounding issues of such models, it\nhas been suggested to split the pipeline into perceptional state grounding and\nsubsequent state-based planning. As we show in this work, the state grounding\nability of LMM-based approaches is still limited by weaknesses in granular,\nstructured, domain-specific scene understanding. To address this shortcoming,\nwe develop a more structured state grounding framework that features a\ndomain-conditioned scene graph as its scene representation. We show that such\nrepresentation is actionable in nature as it is directly mappable to a symbolic\nstate in classical planning languages such as PDDL. We provide an instantiation\nof our state grounding framework where the domain-conditioned scene graph\ngeneration is implemented with a lightweight vision-language approach that\nclassifies domain-specific predicates on top of domain-relevant object\ndetections. Evaluated across three domains, our approach achieves significantly\nhigher state estimation accuracy and task planning success rates compared to\nthe previous LMM-based approaches.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:51:46Z"}
{"aid":"http://arxiv.org/abs/2504.06666v1","title":"Patch Matters: Training-free Fine-grained Image Caption Enhancement via\n  Local Perception","summary":"High-quality image captions play a crucial role in improving the performance\nof cross-modal applications such as text-to-image generation, text-to-video\ngeneration, and text-image retrieval. To generate long-form, high-quality\ncaptions, many recent studies have employed multimodal large language models\n(MLLMs). However, current MLLMs often produce captions that lack fine-grained\ndetails or suffer from hallucinations, a challenge that persists in both\nopen-source and closed-source models. Inspired by Feature-Integration theory,\nwhich suggests that attention must focus on specific regions to integrate\nvisual information effectively, we propose a \\textbf{divide-then-aggregate}\nstrategy. Our method first divides the image into semantic and spatial patches\nto extract fine-grained details, enhancing the model's local perception of the\nimage. These local details are then hierarchically aggregated to generate a\ncomprehensive global description. To address hallucinations and inconsistencies\nin the generated captions, we apply a semantic-level filtering process during\nhierarchical aggregation. This training-free pipeline can be applied to both\nopen-source models (LLaVA-1.5, LLaVA-1.6, Mini-Gemini) and closed-source models\n(Claude-3.5-Sonnet, GPT-4o, GLM-4V-Plus). Extensive experiments demonstrate\nthat our method generates more detailed, reliable captions, advancing\nmultimodal description generation without requiring model retraining. The\nsource code are available at https://github.com/GeWu-Lab/Patch-Matters","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:07:46Z"}
{"aid":"http://arxiv.org/abs/2504.06681v1","title":"Mechanical stability of resonant Bose-Fermi mixtures","summary":"We investigate the mechanical stability of Bose-Fermi mixtures at zero\ntemperature in the presence of a tunable Feshbach resonance, which induces a\ncompetition between boson condensation and boson-fermion pairing when the boson\ndensity is smaller than the fermion density. Using a many-body diagrammatic\napproach validated by fixed-node Quantum Monte Carlo calculations and supported\nby recent experimental observations, we determine the minimal amount of\nboson-boson repulsion required to guarantee the stability of the mixture across\nthe entire range of boson-fermion interactions from weak to strong coupling.\nOur stability phase diagrams indicate that mixtures with boson-to-fermion mass\nratios near two, such as the $^{87}$Rb-$^{40}$K system, exhibit optimal\nstability conditions. Moreover, by applying our results to a recent experiment\nwith a $^{23}$Na-$^{40}$K mixture, we find that the boson-boson repulsion was\ninsufficient to ensure stability, suggesting that the experimental timescale\nwas short enough to avoid mechanical collapse. On the other hand, we also show\nthat even in the absence of boson-boson repulsion, Bose-Fermi mixtures become\nintrinsically stable beyond a certain coupling strength, preceding the quantum\nphase transition associated with the vanishing of the bosonic condensate. We\nthus propose an experimental protocol for observing this quantum phase\ntransition in a mechanically stable configuration.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-09T08:39:14Z"}
{"aid":"http://arxiv.org/abs/2504.06690v1","title":"Homogenization theory of random walks in degenerate random environment","summary":"Recent progress on the understanding of the Random Conductance Model is\nreviewed. A particular emphasis is on homogenization results such as functional\ncentral limit theorems, local limit theorems and heat kernel estimates for\nalmost every realization of the environment, established for random walks among\nstationary ergodic conductances that are possibly unbounded but satisfy certain\nmoment conditions.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T08:52:16Z"}
{"aid":"http://arxiv.org/abs/2504.06696v1","title":"Kerr enhanced optomechanical entanglement via reservoir design","summary":"Quantum entanglement is a crucial resource in quantum technologies, enabling\nadvancements in quantum computing, quantum communication, and quantum precision\nmeasurement. Here, we propose a method to enhance optomechanical entanglement\nby introducing an optical Kerr nonlinear medium and a squeezed vacuum reservoir\nof the optomechanical cavity. By performing the displacement and squeezing\ntransformations, the system can be reduced to a standard linearized\noptomechanical system with normalized driving detuning and linearized-coupling\nstrength, in which the optical and mechanical modes are, respectively, coupled\nto an optical vacuum bath and a mechanical heat bath. We focus on the\nentanglement generation in the single stable regime of the system. By\nevaluating the steady-state logarithm negativity, we find that the\noptomechanical entanglement can be enhanced within a wide range of the Kerr\nconstant. In addition, the Kerr nonlinearity can extend the stable region,\nenabling considerable entanglement generation in the blue sideband-parameter\nregion. We also investigate the dependence of the entanglement generation on\nthe average thermal phonon occupation of the mechanical bath and the optical\ndriving amplitude. It is found that the presence of the Kerr nonlinearity\nallows the generation of optomechanical entanglement even when the thermal\nphonon occupation of the mechanical bath is as high as 3000. Our findings will\nprovide valuable insights into enhancing fragile quantum resources in quantum\nsystems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T08:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.06703v1","title":"Exact QSP angles for odd monomials","summary":"We present an analytical solution to the angle-finding problem in quantum\nsignal processing (QSP) for monomials of odd degree.\n  Specifically, we show that to implement a monomial of degree \\( n \\), where\n\\( n \\) is odd, it suffices to choose powers of a primitive \\( n \\)-th root of\nunity as QSP phase angles.\n  Our approach departs from standard numerical methods and is rooted in a\ngroup-theoretic argument.\n  Being fully analytical, it eliminates numerical errors and reduces\ncomputational overhead in QSP implementation of odd monomials.\n  Such use cases arise, for example, in quantum computing, where self-adjoint\ncontractions are embedded into unitary operators acting on extended Hilbert\nspaces.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T09:07:51Z"}
{"aid":"http://arxiv.org/abs/2504.06705v1","title":"Evolution of the Comptonizing medium of the black-hole candidate Swift\n  J1727.8$-$1613 along the hard to hard-intermediate state transition using\n  NICER","summary":"We analyse the properties of the Comptonizing medium in the black-hole X-ray\nbinary Swift J1727.8$-$1613 using the time-dependent Comptonization model\nvkompth, using NICER observations of type-C QPOs in the hard and\nhard-intermediate states. During the 2023 outburst of the source, we measure\nthe rms and phase lags of the QPO across 45 observations as the QPO frequency,\n$\\nu_{\\rm QPO}$, evolves from $\\sim 0.3$ Hz to $\\sim 7$ Hz. By simultaneously\nfitting the time-averaged spectrum of the source and the rms and lag spectra of\nthe QPO, we derive the evolution of the disk and corona parameters. At\n$\\nu_{\\rm QPO} = 0.34$ Hz, the QPO phase lags are hard, with 10 keV photons\nlagging 0.5 keV photons by $\\sim 0.5$ rad. As $\\nu_{\\rm QPO}$ increases, the\nlags for the same energy bands decrease, reaching near zero at $\\nu_{\\rm QPO}\n\\sim 1.2$ Hz, and then reverse to soft lags of $\\sim -1.1$ rad at $\\nu_{\\rm\nQPO} \\sim 7$ Hz. Initially, the inner radius of the accretion disk is truncated\nat $\\sim 30-40 R_g$ (assuming a 10 solar-mass black hole) and, as the QPO\nfrequency increases, the truncation radius decreases down to $\\sim 10 R_g$.\nInitially, two coronas of sizes of $\\sim 6.5 \\times 10^3$ km and $\\sim 2 \\times\n10^3$ km, extend over the disk and are illuminated by different regions of the\ndisk. As the QPO frequency increases, both the coronas shrink to $\\sim 2 \\times\n10^3$ km at $\\nu_{\\rm QPO} = 2.5$ Hz. Following a data gap, one corona expands\nagain, peaking at a size of $\\sim 2 \\times 10^4$ km. We interpret the evolution\nof the coronal size in the context of accompanying radio observations,\ndiscussing its implications for the interplay between the corona and the jet.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA,astro-ph.IM","published":"2025-04-09T09:08:56Z"}
{"aid":"http://arxiv.org/abs/2504.06715v1","title":"Bistability and complex bifurcation diagrams generated by waning and\n  boosting of immunity","summary":"We investigate an epidemiological model that incorporates waning of immunity\nat the individual level and boosting of the immune system upon re-exposure to\nthe pathogen. When immunity is fully restored upon boosting, the system can be\nexpressed as an SIRS-type model with discrete and distributed delays. We\nconduct a numerical bifurcation analysis varying the boosting force and the\nmaximum period of immunity (in the absence of boosting), while keeping other\nparameters fixed at values representative of a highly infectious disease like\npertussis. The stability switches of the endemic equilibrium, identified\nnumerically, are validated using an established analytical approach, confirming\nthat the equilibrium is unstable in a bounded parameter region, and stable\noutside this region. Using recently developed continuation methods for models\nwith discrete and distributed delays, we explore periodic solutions and their\nbifurcations. Our analysis significantly extends previous findings and reveals\na rich dynamical landscape, including catastrophic bifurcations of limit\ncycles, torus bifurcations, and bistability regions where two stable periodic\nsolutions coexist, differing in amplitude and period. These complex\nbifurcations have critical public health implications: perturbations--such as\nnon-pharmaceutical interventions--can shift the system between attractors,\nleading to long-term consequences from short-term measures.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T09:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.06728v1","title":"Light-field dressing of transient photo-excited states above $E_F$","summary":"Time-periodic light-field provides an emerging pathway for dynamically\nengineering quantum materials by forming hybrid states between photons and\nBloch electrons. So far, experimental progress on light-field dressed states\nhas been mainly focused on the occupied states, however, it is unclear if the\ntransient photo-excited states above the Fermi energy $E_F$ can also be\ndressed, leaving the dynamical interplay between photo-excitation and\nlight-field dressing elusive. Here, we provide direct experimental evidence for\nlight-field dressing of the transient photo-excited surface states above $E_F$,\nwhich exhibits distinct dynamics with a delay response as compared to\nlight-field dressed states below $E_F$. Our work reveals the dual roles of the\npump pulse in both photo-excitation and light-field dressing, providing a more\ncomprehensive picture with new insights on the light-induced manipulation of\ntransient electronic states.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T09:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.06735v1","title":"Interactive Expressive Motion Generation Using Dynamic Movement\n  Primitives","summary":"Our goal is to enable social robots to interact autonomously with humans in a\nrealistic, engaging, and expressive manner. The 12 Principles of Animation [1]\nare a well-established framework animators use to create movements that make\ncharacters appear convincing, dynamic, and emotionally expressive. This paper\nproposes a novel approach that leverages Dynamic Movement Primitives (DMPs) to\nimplement key animation principles, providing a learnable, explainable,\nmodulable, online adaptable and composable model for automatic expressive\nmotion generation. DMPs, originally developed for general imitation learning in\nrobotics and grounded in a spring-damper system design, offer mathematical\nproperties that make them particularly suitable for this task. Specifically,\nthey enable modulation of the intensities of individual principles and\nfacilitate the decomposition of complex, expressive motion sequences into\nlearnable and parametrizable primitives. We present the mathematical\nformulation of the parameterized animation principles and demonstrate the\neffectiveness of our framework through experiments and application on three\nrobotic platforms with different kinematic configurations, in simulation, on\nactual robots and in a user study. Our results show that the approach allows\nfor creating diverse and nuanced expressions using a single base model.","main_category":"cs.RO","categories":"cs.RO,cs.GR","published":"2025-04-09T09:46:50Z"}
{"aid":"http://arxiv.org/abs/2504.06742v1","title":"nnLandmark: A Self-Configuring Method for 3D Medical Landmark Detection","summary":"Landmark detection plays a crucial role in medical imaging tasks that rely on\nprecise spatial localization, including specific applications in diagnosis,\ntreatment planning, image registration, and surgical navigation. However,\nmanual annotation is labor-intensive and requires expert knowledge. While deep\nlearning shows promise in automating this task, progress is hindered by limited\npublic datasets, inconsistent benchmarks, and non-standardized baselines,\nrestricting reproducibility, fair comparisons, and model generalizability.This\nwork introduces nnLandmark, a self-configuring deep learning framework for 3D\nmedical landmark detection, adapting nnU-Net to perform heatmap-based\nregression. By leveraging nnU-Net's automated configuration, nnLandmark\neliminates the need for manual parameter tuning, offering out-of-the-box\nusability. It achieves state-of-the-art accuracy across two public datasets,\nwith a mean radial error (MRE) of 1.5 mm on the Mandibular Molar Landmark (MML)\ndental CT dataset and 1.2 mm for anatomical fiducials on a brain MRI dataset\n(AFIDs), where nnLandmark aligns with the inter-rater variability of 1.5 mm.\nWith its strong generalization, reproducibility, and ease of deployment,\nnnLandmark establishes a reliable baseline for 3D landmark detection,\nsupporting research in anatomical localization and clinical workflows that\ndepend on precise landmark identification. The code will be available soon.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T09:53:39Z"}
{"aid":"http://arxiv.org/abs/2504.06760v1","title":"Applications of Poisson cohomology to the inducibility problems and\n  study of deformation maps","summary":"This paper provides some applications of the Poisson cohomology groups\nintroduced by Flato, Gerstenhaber and Voronov. Given an abelian extension of a\nPoisson algebra by a representation, we first investigate the inducibility of a\npair of Poisson algebra automorphisms and show that the corresponding\nobstruction lies in the second Poisson cohomology group. Consequently, we\nobtain the Wells exact sequence connecting various automorphism groups and the\nsecond Poisson cohomology group. Subsequently, we also consider the\ninducibility for a pair of Poisson algebra derivations, obtain the obstruction\nand construct the corresponding Wells-type exact sequence.\n  To get another application, we introduce the notion of a `deformation map' in\na proto-twilled Poisson algebra. A deformation map unifies various well-known\noperators such as Poisson homomorphisms, Poisson derivations, crossed\nhomomorphisms, Rota-Baxter operators of any weight, twisted Rota-Baxter\noperators, Reynolds operators and modified Rota-Baxter operators on Poisson\nalgebras. We show that a deformation map $r$ induces a new Poisson algebra\nstructure and a suitable representation of it. The corresponding Poisson\ncohomology is defined to be the cohomology of the deformation map $r$. Finally,\nwe study the formal deformations of the operator $r$ in terms of the\ncohomology.","main_category":"math.RT","categories":"math.RT,math.KT,math.RA","published":"2025-04-09T10:26:22Z"}
{"aid":"http://arxiv.org/abs/2504.06768v1","title":"FedMerge: Federated Personalization via Model Merging","summary":"One global model in federated learning (FL) might not be sufficient to serve\nmany clients with non-IID tasks and distributions. While there has been\nadvances in FL to train multiple global models for better personalization, they\nonly provide limited choices to clients so local finetuning is still\nindispensable. In this paper, we propose a novel ``FedMerge'' approach that can\ncreate a personalized model per client by simply merging multiple global models\nwith automatically optimized and customized weights. In FedMerge, a few global\nmodels can serve many non-IID clients, even without further local finetuning.\nWe formulate this problem as a joint optimization of global models and the\nmerging weights for each client. Unlike existing FL approaches where the server\nbroadcasts one or multiple global models to all clients, the server only needs\nto send a customized, merged model to each client. Moreover, instead of\nperiodically interrupting the local training and re-initializing it to a global\nmodel, the merged model aligns better with each client's task and data\ndistribution, smoothening the local-global gap between consecutive rounds\ncaused by client drift. We evaluate FedMerge on three different non-IID\nsettings applied to different domains with diverse tasks and data types, in\nwhich FedMerge consistently outperforms existing FL approaches, including\nclustering-based and mixture-of-experts (MoE) based methods.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T10:44:14Z"}
{"aid":"http://arxiv.org/abs/2504.06773v1","title":"On the Destruction of Invariant Lagrangian Graphs for Conformal\n  Symplectic Twist Maps","summary":"In this article we investigate the fragility of invariant Lagrangian graphs\nfor dissipative maps, focusing on their destruction under small perturbations.\nInspired by Herman's work on conservative systems, we prove that all\n$C^0$-invariant Lagrangian graphs for an integrable dissipative twist maps can\nbe destroyed by perturbations that are arbitrarily small in the\n$C^{1-\\varepsilon}$-topology. This result is sharp, as evidenced by the\npersistence of $C^1$-invariant graphs under $C^1$-perturbations guaranteed by\nthe normally hyperbolic invariant manifold theorem.","main_category":"math.DS","categories":"math.DS,math.SG","published":"2025-04-09T10:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.06785v1","title":"Zero-Shot Image-Based Large Language Model Approach to Road Pavement\n  Monitoring","summary":"Effective and rapid evaluation of pavement surface condition is critical for\nprioritizing maintenance, ensuring transportation safety, and minimizing\nvehicle wear and tear. While conventional manual inspections suffer from\nsubjectivity, existing machine learning-based methods are constrained by their\nreliance on large and high-quality labeled datasets, which require significant\nresources and limit adaptability across varied road conditions. The\nrevolutionary advancements in Large Language Models (LLMs) present significant\npotential for overcoming these challenges. In this study, we propose an\ninnovative automated zero-shot learning approach that leverages the image\nrecognition and natural language understanding capabilities of LLMs to assess\nroad conditions effectively. Multiple LLM-based assessment models were\ndeveloped, employing prompt engineering strategies aligned with the Pavement\nSurface Condition Index (PSCI) standards. These models' accuracy and\nreliability were evaluated against official PSCI results, with an optimized\nmodel ultimately selected. Extensive tests benchmarked the optimized model\nagainst evaluations from various levels experts using Google Street View road\nimages. The results reveal that the LLM-based approach can effectively assess\nroad conditions, with the optimized model -employing comprehensive and\nstructured prompt engineering strategies -outperforming simpler configurations\nby achieving high accuracy and consistency, even surpassing expert evaluations.\nMoreover, successfully applying the optimized model to Google Street View\nimages demonstrates its potential for future city-scale deployments. These\nfindings highlight the transformative potential of LLMs in automating road\ndamage evaluations and underscore the pivotal role of detailed prompt\nengineering in achieving reliable assessments.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T11:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.06796v1","title":"Learning in Spiking Neural Networks with a Calcium-based Hebbian Rule\n  for Spike-timing-dependent Plasticity","summary":"Understanding how biological neural networks are shaped via local plasticity\nmechanisms can lead to energy-efficient and self-adaptive information\nprocessing systems, which promises to mitigate some of the current roadblocks\nin edge computing systems. While biology makes use of spikes to seamless use\nboth spike timing and mean firing rate to modulate synaptic strength, most\nmodels focus on one of the two. In this work, we present a Hebbian local\nlearning rule that models synaptic modification as a function of calcium traces\ntracking neuronal activity. We show how the rule reproduces results from spike\ntime and spike rate protocols from neuroscientific studies. Moreover, we use\nthe model to train spiking neural networks on MNIST digit recognition to show\nand explain what sort of mechanisms are needed to learn real-world patterns. We\nshow how our model is sensitive to correlated spiking activity and how this\nenables it to modulate the learning rate of the network without altering the\nmean firing rate of the neurons nor the hyparameters of the learning rule. To\nthe best of our knowledge, this is the first work that showcases how spike\ntiming and rate can be complementary in their role of shaping the connectivity\nof spiking neural networks.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-09T11:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.06804v1","title":"A few remarks concerning application of the Lifshitz theory to\n  calculation of the Casimir-Polder interaction","summary":"The Lifshitz theory provides a semiclassical description of the\nCasimir-Polder atom-plate interaction, where the electromagnetic field is\nquantized whereas the material of the plate is considered as a continuous\nmedium. This places certain restrictions on its application regarding the\nallowable atom-plate separation distances and the dielectric properties of the\nplate material. Below we demonstrate that in some recent literature the\napplication conditions of the Lifshitz theory established by its founders are\nviolated by applying it at too short separations and using the dielectric\npermittivities possessing the negative imaginary parts in violation of the\nsecond law of thermodynamics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T11:51:13Z"}
{"aid":"http://arxiv.org/abs/2504.06810v1","title":"On the exceptional set of crepant resolutions of abelian singularities","summary":"Let G be a finite abelian subgroup of SL(n,C), and suppose there exists a\ntoric crepant resolution phi: X -- > C^n/G. We prove that for each component E\nof the exceptional set of phi there exists an open subset U of X that contains\nE and is isomorphic to the total space of the canonical bundle of E. This\ncontributes to the collection of results aimed at solving a classical problem,\ni.e., to determine which submanifolds of a complex manifold have a neighborhood\nisomorphic to a neighborhood of the zero section of their normal bundle.","main_category":"math.AG","categories":"math.AG","published":"2025-04-09T12:01:23Z"}
{"aid":"http://arxiv.org/abs/2504.06816v1","title":"A Graph Diffusion Algorithm for Lexical Similarity Evaluation","summary":"In this paper, we present an algorithm for evaluating lexical similarity\nbetween a given language and several reference language clusters. As an input,\nwe have a list of concepts and the corresponding translations in all considered\nlanguages. Moreover, each reference language is assigned to one of $c$ language\nclusters. For each of the concepts, the algorithm computes the distance between\neach pair of translations. Based on these distances, it constructs a weighted\ndirected graph, where every vertex represents a language. After, it solves a\ngraph diffusion equation with a Dirichlet boundary condition, where the unknown\nis a map from the vertex set to $\\mathbb{R}^c$. The resulting coordinates are\nvalues from the interval $[0,1]$ and they can be interpreted as probabilities\nof belonging to each of the clusters or as a lexical similarity distribution\nwith respect to the reference clusters. The distances between translations are\ncalculated using phonetic transcriptions and a modification of the\nDamerau-Levenshtein distance. The algorithm can be useful in analyzing\nrelationships between languages spoken in multilingual territories with a lot\nof mutual influences. We demonstrate this by presenting a case study regarding\nvarious European languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.06864v1","title":"Emergent Theory for Constitutive Relations in Classical Defect Systems","summary":"Optical, acoustic, hydrodynamic, and thermal defect systems are often studied\nby analogy with each other. This may indicate that we may find a emergent\ntheory for constitutive relations of classical defect systems. Start with\nthermal systems, we put up with a bootstrap method to describe classical\ntransport. We conjecture that Landau-Khalatnikov equation could provide heat\nconstitutive relations when taking heat flux as order parameter. We show that\nthe corresponding effctive Lagrangian has similar form of that of Wick-rotated\ncomplex scalar field theory at non-relativistic limit, and only in perfect\nconducting situation that this system is a canonical ensemble. We argue that\nour method could be generalized to other systems besides thermal ones. By\nanalogy with ferroelectrics, we propose the thermal domain model, which is a\nconserved current XY model. Phase transition of the thermal system is\nqualitatively discussed in this model.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.supr-con,hep-th","published":"2025-04-09T13:13:14Z"}
{"aid":"http://arxiv.org/abs/2504.06866v1","title":"GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception\n  and Grasping in Cluttered Scenes","summary":"Robust grasping in cluttered environments remains an open challenge in\nrobotics. While benchmark datasets have significantly advanced deep learning\nmethods, they mainly focus on simplistic scenes with light occlusion and\ninsufficient diversity, limiting their applicability to practical scenarios. We\npresent GraspClutter6D, a large-scale real-world grasping dataset featuring:\n(1) 1,000 highly cluttered scenes with dense arrangements (14.1 objects/scene,\n62.6\\% occlusion), (2) comprehensive coverage across 200 objects in 75\nenvironment configurations (bins, shelves, and tables) captured using four\nRGB-D cameras from multiple viewpoints, and (3) rich annotations including 736K\n6D object poses and 9.3B feasible robotic grasps for 52K RGB-D images. We\nbenchmark state-of-the-art segmentation, object pose estimation, and grasping\ndetection methods to provide key insights into challenges in cluttered\nenvironments. Additionally, we validate the dataset's effectiveness as a\ntraining resource, demonstrating that grasping networks trained on\nGraspClutter6D significantly outperform those trained on existing datasets in\nboth simulation and real-world experiments. The dataset, toolkit, and\nannotation tools are publicly available on our project website:\nhttps://sites.google.com/view/graspclutter6d.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-04-09T13:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.06873v1","title":"A note on measurings and higher order Hochschild homology of algebras","summary":"We know that coalgebra measurings behave like generalized maps between\nalgebras. In this note, we show that coalgebra measurings between commutative\nalgebras induce morphisms between higher order Hochschild homology groups of\nalgebras. By higher order Hochschild homology, we mean the the Hochschild\nhomology groups of a commutative algebra with respect to a simplicial set as\nintroduced by Pirashvili.","main_category":"math.RA","categories":"math.RA","published":"2025-04-09T13:24:20Z"}
{"aid":"http://arxiv.org/abs/2504.06879v1","title":"Machine Learning Approach to Study of Low Energy Alpha-Deuteron Elastic\n  Scattering using Phase Function Method","summary":"Central idea: To obtain the interaction potential using the inverse\nscattering method, we have employed the Physics-Informed Machine Learning\n(PIML) approach. In this framework, the machine learning algorithm is guided by\nthe underlying physical laws, enabling the accurate extraction of the inverse\nscattering potential from the elastic scattering data. Methodology: As a\nreference potential, a combination of three smoothly joined Morse functions has\nbeen utilized, characterized by ten model parameters. These parameters are\noptimized in an iterative fashion using a Genetic Algorithm to ensure the best\nfit to the phase shifts extracted from the experimental scattering data. The\nprocess of optimization is guided by the computed scattering phase shifts by\nsolving the phase equation using 5th order RK-method for the reference\npotential in each iteration Results: Our approach yields inverse potentials for\nboth single and multi channel scattering. Using the Scattering Phase Shifts\nobtained from these inverse potentials, we calculate the partial cross-section\nto determine the resonance energies and decay width. The obtain values of\nresonance energies and decay width for 3D1, 3D2 and 3D3 states of\nalpha-deuteron are in correspondence with the experimental results. Conclusion:\nIt can be concluded that our machine learning-based approach for constructing\nthe inverse potential offers a novel and complementary technique to existing\ndirect methods.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-09T13:34:41Z"}
{"aid":"http://arxiv.org/abs/2504.06881v1","title":"Compound and Parallel Modes of Tropical Convolutional Neural Networks","summary":"Convolutional neural networks have become increasingly deep and complex,\nleading to higher computational costs. While tropical convolutional neural\nnetworks (TCNNs) reduce multiplications, they underperform compared to standard\nCNNs. To address this, we propose two new variants - compound TCNN (cTCNN) and\nparallel TCNN (pTCNN)-that use combinations of tropical min-plus and max-plus\nkernels to replace traditional convolution kernels. This reduces\nmultiplications and balances efficiency with performance. Experiments on\nvarious datasets show that cTCNN and pTCNN match or exceed the performance of\nother CNN methods. Combining these with conventional CNNs in deeper\narchitectures also improves performance. We are further exploring simplified\nTCNN architectures that reduce parameters and multiplications with minimal\naccuracy loss, aiming for efficient and effective models.","main_category":"cs.CV","categories":"cs.CV,cs.AI,I.2.6","published":"2025-04-09T13:36:11Z"}
{"aid":"http://arxiv.org/abs/2504.06889v1","title":"Mixed-Precision in High-Order Methods: the Impact of Floating-Point\n  Precision on the ADER-DG Algorithm","summary":"We present a mixed-precision implementation of the high-order discontinuous\nGalerkin method with ADER time stepping (ADER-DG) for solving hyperbolic\nsystems of partial differential equations (PDEs) in the hyperbolic PDE engine\nExaHyPE. The implementation provides a simple API extension for specifying the\nnumerical precision for individual kernels, and thus allows for testing the\neffect of low and mixed precision on the accuracy of the solution. To showcase\nthis, we study the impact of precision on the overall convergence order and\nactual accuracy of the method as achieved for four common hyperbolic PDE\nsystems and five relevant scenarios that feature an analytic solution. For all\nscenarios, we also assess how sensitive each kernel of the ADER-DG algorithm is\nto using double, single or even half precision. This addresses the question\nwhere thoughtful adoption of mixed precision can mitigate hurtful effects of\nlow precision on the overall simulation.","main_category":"math.NA","categories":"math.NA,cs.DS,cs.NA","published":"2025-04-09T13:50:43Z"}
{"aid":"http://arxiv.org/abs/2504.06898v1","title":"Identifying and mitigating errors in hole spin qubit readout","summary":"High-fidelity readout of spin qubits in semiconductor quantum dots can be\nachieved by combining a radio-frequency (RF) charge sensor together with\nspin-to-charge conversion and Pauli spin blockade. However, reaching high\nreadout fidelities in hole spin qubits remains elusive and is complicated by a\ncombination of site-dependent spin anisotropies and short spin relaxation\ntimes. Here, we analyze the different error processes that arise during readout\nusing a double-latched scheme in a germanium double quantum dot hole spin qubit\nsystem. We first investigate the spin-to-charge conversion process as a\nfunction of magnetic field orientation, and configure the system to\nadiabatically map the $\\lvert \\downarrow\\downarrow \\rangle$ state to the only\nnon-blockaded state. We reveal a strong dependence of the spin relaxation rates\non magnetic field strength and minimize this relaxation by operating at low\nfields. We further characterize and mitigate the error processes that arise\nduring the double-latching process. By combining an RF charge sensor, a\ndouble-latching process, and optimized magnetic field parameters, we achieve a\nsingle-shot single-qubit state-preparation-and-measurement fidelity of 97.0%,\nthe highest reported fidelity for hole spin qubits. Unlike prior works and\nvital to usability, we simultaneously maintain universal control of both spins.\nThese findings lay the foundation for the reproducible achievement of\nhigh-fidelity readout in hole-based spin quantum processors.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-09T13:57:26Z"}
{"aid":"http://arxiv.org/abs/2504.06901v1","title":"Classification of algebraic tangles","summary":"We study algebraic tangles as fundamental components in knot theory,\ndeveloping a systematic approach to classify and tabulate prime tangles using a\nnovel canonical representation. The canonical representation enables us to\ndistinguish mutant tangles, which fills the gaps in previous classifications.\nMoreover, we increase the classification of prime tangles up to 14 crossings\nand analyze tangle symmetry groups. We provide a database of our results:\nhttps://tangleinfo.cent.uw.edu.pl.","main_category":"math.GT","categories":"math.GT,math.AT,math.GR,math.NT","published":"2025-04-09T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.06903v1","title":"Network Cross-Validation and Model Selection via Subsampling","summary":"Complex and larger networks are becoming increasingly prevalent in scientific\napplications in various domains. Although a number of models and methods exist\nfor such networks, cross-validation on networks remains challenging due to the\nunique structure of network data. In this paper, we propose a general\ncross-validation procedure called NETCROP (NETwork CRoss-Validation using\nOverlapping Partitions). The key idea is to divide the original network into\nmultiple subnetworks with a shared overlap part, producing training sets\nconsisting of the subnetworks and a test set with the node pairs between the\nsubnetworks. This train-test split provides the basis for a network\ncross-validation procedure that can be applied on a wide range of model\nselection and parameter tuning problems for networks. The method is\ncomputationally efficient for large networks as it uses smaller subnetworks for\nthe training step. We provide methodological details and theoretical guarantees\nfor several model selection and parameter tuning tasks using NETCROP. Numerical\nresults demonstrate that NETCROP performs accurate cross-validation on a\ndiverse set of network model selection and parameter tuning problems. The\nresults also indicate that NETCROP is computationally much faster while being\noften more accurate than the existing methods for network cross-validation.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-09T14:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.06909v1","title":"Climate impacts of equatorial superrotation","summary":"While it is expected that the large-scale tropical circulation should undergo\nsome changes in a warmer climate, it remains an open question whether its\ncharacteristic features, such as the Hadley cell, the intertropical convergence\nzone, or the weak surface easterlies, could take a completely different shape.\nAs an example, it has been hypothesized that the Earth's atmosphere may have\nexperienced equatorial superrotation -- i.e. westerly winds at the equator --\nduring its history. The possibility of equatorial superrotation has been\nstudied in a range of planetary atmospheres, including Earth-like ones, with\nthe objective of understanding the underlying dynamical processes. However, the\nbroader impact that this dramatic circulation change would have on the climate\nsystem is practically unexplored. This is the question we address here. We\nperform idealized GCM simulations with an imposed equatorial torque to\ninvestigate how a forced superrotating atmosphere affects surface temperature\nand the water cycle. We show that these effects are quite large and directly\nrelated to the global circulation changes, which extend beyond the tropical\natmosphere. Using tools including a forcing/feedback analysis and a moist\nenergy balance model, we argue that the dominant mechanism is changes in\natmospheric energy transport, driven in particular by the collapse of the\nmeridional overturning circulation, and to a smaller extent by the appearance\nof an equatorial jet, and the concomitant redistribution of moisture in the\ntropics, leading to a much weaker relative humidity gradient which has strong\nradiative effects.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-09T14:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.06913v1","title":"Controlling a Social Network of Individuals with Coevolving Actions and\n  Opinions","summary":"In this paper, we consider a population of individuals who have actions and\nopinions, which coevolve, mutually influencing one another on a complex network\nstructure. In particular, we formulate a control problem for this social\nnetwork, in which we assume that we can inject into the network a committed\nminority -- a set of stubborn nodes -- with the objective of steering the\npopulation, initially at a consensus, to a different consensus state. Our study\nfocuses on two main objectives: i) determining the conditions under which the\ncommitted minority succeeds in its goal, and ii) identifying the optimal\nplacement for such a committed minority. After deriving general monotone\nconvergence result for the controlled dynamics, we leverage these results to\nbuild a computationally-efficient algorithm to solve the first problem and an\neffective heuristics for the second problem, which we prove to be NP-complete.\nThe proposed methodology is illustrated though academic examples, and\ndemonstrated on a real-world case study.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.DS","published":"2025-04-09T14:20:46Z"}
{"aid":"http://arxiv.org/abs/2504.06922v1","title":"Kinetic phase diagram for two-step nucleation in colloid-polymer\n  mixtures","summary":"Two-step crystallization via a metastable intermediate phase is often\nregarded as a non-classical process that lies beyond the framework of classical\nnucleation theory (CNT). In this work, we investigate two-step crystallization\nin colloid-polymer mixtures via an intermediate liquid phase. Using CNT-based\nseeding simulations, we construct a kinetic phase diagram that identifies\nregions of phase space where the critical nucleus is either liquid or\ncrystalline. These predictions are validated using transition path sampling\nsimulations at nine different relevant state points. When the critical nucleus\nis liquid, crystallization occurs stochastically during the growth phase,\nwhereas for a crystalline critical nucleus, the crystallization process happens\npre-critically at a fixed nucleus size. We conclude that CNT-based kinetic\nphase diagrams are a powerful tool for understanding and predicting\n`non-classical' crystal nucleation mechanisms.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-09T14:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.06939v1","title":"FeedbackEval: A Benchmark for Evaluating Large Language Models in\n  Feedback-Driven Code Repair Tasks","summary":"Code repair is a fundamental task in software development, facilitating\nefficient bug resolution and software maintenance. Although large language\nmodels (LLMs) have demonstrated considerable potential in automated code\nrepair, their ability to comprehend and effectively leverage diverse types of\nfeedback remains insufficiently understood. To bridge this gap, we introduce\nFeedbackEval, a systematic benchmark for evaluating LLMs' feedback\ncomprehension and performance in code repair tasks. We conduct a comprehensive\nempirical study on five state-of-the-art LLMs, including GPT-4o, Claude-3.5,\nGemini-1.5, GLM-4, and Qwen2.5, to evaluate their behavior under both\nsingle-iteration and iterative code repair settings. Our results show that\nstructured feedback, particularly in the form of test feedback, leads to the\nhighest repair success rates, while unstructured feedback proves significantly\nless effective. Iterative feedback further enhances repair performance, though\nthe marginal benefit diminishes after two or three rounds. Moreover, prompt\nstructure is shown to be critical: incorporating docstrings, contextual\ninformation, and explicit guidelines substantially improves outcomes, whereas\npersona-based, chain-of-thought, and few-shot prompting strategies offer\nlimited benefits in single-iteration scenarios. This work introduces a robust\nbenchmark and delivers practical insights to advance the understanding and\ndevelopment of feedback-driven code repair using LLMs.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T14:43:08Z"}
{"aid":"http://arxiv.org/abs/2504.06943v1","title":"Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations,\n  Architectural Components, and Cognitive Integration","summary":"Agents powered by Large Language Models (LLMs) have recently demonstrated\nimpressive capabilities in various tasks. Still, they face limitations in tasks\nrequiring specific, structured knowledge, flexibility, or accountable\ndecision-making. While agents are capable of perceiving their environments,\nforming inferences, planning, and executing actions towards goals, they often\nface issues such as hallucinations and lack of contextual memory across\ninteractions. This paper explores how Case-Based Reasoning (CBR), a strategy\nthat solves new problems by referencing past experiences, can be integrated\ninto LLM agent frameworks. This integration allows LLMs to leverage explicit\nknowledge, enhancing their effectiveness. We systematically review the\ntheoretical foundations of these enhanced agents, identify critical framework\ncomponents, and formulate a mathematical model for the CBR processes of case\nretrieval, adaptation, and learning. We also evaluate CBR-enhanced agents\nagainst other methods like Chain-of-Thought reasoning and standard\nRetrieval-Augmented Generation, analyzing their relative strengths. Moreover,\nwe explore how leveraging CBR's cognitive dimensions (including\nself-reflection, introspection, and curiosity) via goal-driven autonomy\nmechanisms can further enhance the LLM agent capabilities. Contributing to the\nongoing research on neuro-symbolic hybrid systems, this work posits CBR as a\nviable technique for enhancing the reasoning skills and cognitive aspects of\nautonomous LLM agents.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-09T14:51:02Z"}
{"aid":"http://arxiv.org/abs/2504.06944v1","title":"Understanding The Effects of Geotechnical Properties on Viscous Erosion\n  Rate from Plume Surface Interactions","summary":"With humans returning to the Moon under the Artemis program, understanding\nand mitigating effects from Plume Surface Interactions (PSI) will be essential\nfor the protection of personnel and equipment on the Moon. To help characterize\nthe underlying mechanics associated with viscous erosion and crater formation,\nexperimental measurements using regolith simulants and subsonic, non-reacting\nflows were completed using compressed air in a splitter plate, plume cratering\nsetup. More specifically, these investigations examined the underlying effects\nof bulk density, cohesion, and exhaust flow characteristics on viscous erosion\nrates and crater formation using Lunar highlands simulant (LHS-1), Lunar mare\nsimulant (LMS-1), LHS-1D (Dust) simulants, and 40-80 um glass beads in\natmosphere. Results show that particle size distribution can ultimately\ninfluence crater shapes and erosion rates, likely owing to internal angle of\nfriction. Measurements show that increasing bulk density, especially from an\nuncompacted to a slightly compacted state, decreases erosion rate by as much as\n50%. While cohesion of granular material can mitigate erosion rates to some\nextent, higher levels of cohesion above 1,000 Pa may actually increase viscous\nerosion rates due to particle clumping. A modified version of Metzger's (2024a)\nequation for volumetric erosion rate is presented, with limitations discussed.\nThese modified equations for viscous erosion, with limitations noted, show that\ngeotechnical properties play an important role in viscous erosion and should be\nconsidered in PSI computer models for future mission planning.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-09T14:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.06951v1","title":"GLT hidden structures in mean-field quantum spin systems","summary":"This work explores structured matrix sequences arising in mean-field quantum\nspin systems. We express these sequences within the framework of generalized\nlocally Toeplitz (GLT) $*$-algebras, leveraging the fact that each GLT matrix\nsequence has a unique GLT symbol. This symbol characterizes both the asymptotic\nsingular value distribution and, for Hermitian or quasi-Hermitian sequences,\nthe asymptotic spectral distribution. Specifically, we analyze two cases of\nreal symmetric matrix sequences stemming from mean-field quantum spin systems\nand determine their associated distributions using GLT theory. Our study\nconcludes with visualizations and numerical tests that validate the theoretical\nfindings, followed by a discussion of open problems and future directions.","main_category":"quant-ph","categories":"quant-ph,cs.NA,math.NA","published":"2025-04-09T14:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.06975v1","title":"AWDIT: An Optimal Weak Database Isolation Tester","summary":"In order to achieve low latency, high throughput, and partition tolerance,\nmodern databases forgo strong transaction isolation for weak isolation\nguarantees. However, several production databases have been found to suffer\nfrom isolation bugs, breaking their data-consistency contract. Black-box\ntesting is a prominent technique for detecting isolation bugs, by checking\nwhether histories of database transactions adhere to a prescribed isolation\nlevel.\n  Testing databases on realistic workloads of large size requires isolation\ntesters to be as efficient as possible, a requirement that has initiated a\nstudy of the complexity of isolation testing. Although testing strong isolation\nhas been known to be NP-complete, weak isolation levels were recently shown to\nbe testable in polynomial time, which has propelled the scalability of testing\ntools. However, existing testers have a large polynomial complexity,\nrestricting testing to workloads of only moderate size, which is not typical of\nlarge-scale databases.\n  In this work, we develop AWDIT, a highly-efficient and provably optimal\ntester for weak database isolation. Given a history $H$ of size $n$ and $k$\nsessions, AWDIT tests whether H satisfies the most common weak isolation levels\nof Read Committed (RC), Read Atomic (RA), and Causal Consistency (CC) in time\n$O(n^{3/2})$, $O(n^{3/2})$, and $O(n \\cdot k)$, respectively, improving\nsignificantly over the state of the art. Moreover, we prove that AWDIT is\nessentially optimal, in the sense that there is a conditional lower bound of\n$n^{3/2}$ for any weak isolation level between RC and CC. Our experiments show\nthat AWDIT is significantly faster than existing, highly optimized testers;\ne.g., for the $\\sim$20% largest histories, AWDIT obtains an average speedup of\n$245\\times$, $193\\times$, and $62\\times$ for RC, RA, and CC, respectively, over\nthe best baseline.","main_category":"cs.PL","categories":"cs.PL,cs.DB","published":"2025-04-09T15:30:09Z"}
{"aid":"http://arxiv.org/abs/2504.06979v1","title":"Artificial Intelligence for Pediatric Height Prediction Using\n  Large-Scale Longitudinal Body Composition Data","summary":"This study developed an accurate artificial intelligence model for predicting\nfuture height in children and adolescents using anthropometric and body\ncomposition data from the GP Cohort Study (588,546 measurements from 96,485\nchildren aged 7-18). The model incorporated anthropometric measures, body\ncomposition, standard deviation scores, and growth velocity parameters, with\nperformance evaluated using RMSE, MAE, and MAPE. Results showed high accuracy\nwith males achieving average RMSE, MAE, and MAPE of 2.51 cm, 1.74 cm, and\n1.14%, and females showing 2.28 cm, 1.68 cm, and 1.13%, respectively.\nExplainable AI approaches identified height SDS, height velocity, and soft lean\nmass velocity as crucial predictors. The model generated personalized growth\ncurves by estimating individual-specific height trajectories, offering a robust\ntool for clinical decision support, early identification of growth disorders,\nand optimization of growth outcomes.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.LG","published":"2025-04-09T15:32:15Z"}
{"aid":"http://arxiv.org/abs/2504.06990v1","title":"Enhancing TiFe Alloy Activation for Hydrogen Storage Through Al, Cr, Co,\n  and Cu Substitutions as a Step Towards Future Recycling","summary":"This study investigates the activation behavior of $TiFe_{0.80}$-$X_{0.20}$\n(X = Co, Cu, Cr, Al) alloys to identify the most effective materials for\nproducing hydrogen storage alloys from recycled sources in view of a circular\neconomy perspective. Activation was tested using two methods: a Sievert\nVolumetric Apparatus at room temperature and 64 bar of hydrogen, and\nhigh-pressure differential scanning calorimetry with 50 bar hydrogen under\nthermal cycles up to 400 {\\deg}C. Activation properties were analyzed by\nassessing time for incubation and for full charging, that are influenced,\nrespectively, by surface and bulk diffusion of hydrogen. Results showed that\nCr-substituted alloys are rapidly activated, due to the presence of $TiCr_{2}$\ncompound, while Al-containing alloys absorbed hydrogen immediately. In\ncontrast, Co- and Cu-substituted alloys required extended activation times, due\nto less quantity of secondary phases and limited diffusion channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T15:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.06993v1","title":"Screening of material defects using universal machine-learning\n  interatomic potentials","summary":"Finding new materials with previously unknown atomic structure or materials\nwith optimal set of properties for a specific application greatly benefits from\ncomputational modeling. Recently, such screening has been dramatically\naccelerated by the invent of universal machine-learning interatomic potentials\nthat offer first principles accuracy at orders of magnitude lower computational\ncost. Their application to the screening of defects with desired properties or\nto finding new stable compounds with high density of defects, however, has not\nbeen explored. Here, we show that the universal machine-learning interatomic\npotentials have reached sufficient accuracy to enable large-scale screening of\ndefective materials. We carried out vacancy calculations for 86 259 materials\nin the Materials Project database and analyzed the formation energies in terms\nof oxidation numbers. We further demonstrate the application of these models\nfor finding new materials at or below the convex hull of known materials and\nfor simulated etching of low-dimensional materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-09T16:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.06994v1","title":"RayFronts: Open-Set Semantic Ray Frontiers for Online Scene\n  Understanding and Exploration","summary":"Open-set semantic mapping is crucial for open-world robots. Current mapping\napproaches either are limited by the depth range or only map beyond-range\nentities in constrained settings, where overall they fail to combine\nwithin-range and beyond-range observations. Furthermore, these methods make a\ntrade-off between fine-grained semantics and efficiency. We introduce\nRayFronts, a unified representation that enables both dense and beyond-range\nefficient semantic mapping. RayFronts encodes task-agnostic open-set semantics\nto both in-range voxels and beyond-range rays encoded at map boundaries,\nempowering the robot to reduce search volumes significantly and make informed\ndecisions both within & beyond sensory range, while running at 8.84 Hz on an\nOrin AGX. Benchmarking the within-range semantics shows that RayFronts's\nfine-grained image encoding provides 1.34x zero-shot 3D semantic segmentation\nperformance while improving throughput by 16.5x. Traditionally, online mapping\nperformance is entangled with other system components, complicating evaluation.\nWe propose a planner-agnostic evaluation framework that captures the utility\nfor online beyond-range search and exploration, and show RayFronts reduces\nsearch volume 2.2x more efficiently than the closest online baselines.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV,cs.LG","published":"2025-04-09T16:06:58Z"}
{"aid":"http://arxiv.org/abs/2504.07007v1","title":"Data-Driven Insights into Rare Earth Mineralization: Machine Learning\n  Applications Using Functional Material Synthesis Data","summary":"Quantitative understanding of rare earth element (REE) mineralization\nmechanisms, crucial for improving industrial separation, remains limited. This\nstudy leverages 1239 hydrothermal synthesis datapoints from material science as\na surrogate for natural REE mineralization. We trained machine learning models\n(KNN, RF, XGBoost) using precursor, additive, and reaction data to predict\nproduct elements and phases, validating predictions with new experiments.\nXGBoost exhibited the highest accuracy, with feature importance analysis\nindicating thermodynamic properties were critical for predictions. Observed\ncorrelations among reaction parameters aligned with classical crystallization\ntheory. Further XGBoost models successfully predicted reaction temperature and\npH from precursor/product data. Our findings demonstrate the cross-disciplinary\nutility of material science data for geochemical understanding, underscore the\nneed for research on less-studied REE minerals (e.g., carbonates, heavy REEs),\nand suggest potential to accelerate REE resource development.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T16:26:21Z"}
{"aid":"http://arxiv.org/abs/2504.07010v1","title":"Assumption-free fidelity bounds for hardware noise characterization","summary":"In the Quantum Supremacy regime, quantum computers may overcome classical\nmachines on several tasks if we can estimate, mitigate, or correct unavoidable\nhardware noise. Estimating the error requires classical simulations, which\nbecome unfeasible in the Quantum Supremacy regime. We leverage Machine Learning\ndata-driven approaches and Conformal Prediction, a Machine Learning uncertainty\nquantification tool known for its mild assumptions and finite-sample validity,\nto find theoretically valid upper bounds of the fidelity between noiseless and\nnoisy outputs of quantum devices. Under reasonable extrapolation assumptions,\nthe proposed scheme applies to any Quantum Computing hardware, does not require\nmodeling the device's noise sources, and can be used when classical simulations\nare unavailable, e.g. in the Quantum Supremacy regime.","main_category":"quant-ph","categories":"quant-ph,cs.LG,stat.ML","published":"2025-04-09T16:27:52Z"}
{"aid":"http://arxiv.org/abs/2504.07032v1","title":"Restoring the Forecasting Power of Google Trends with Statistical\n  Preprocessing","summary":"Google Trends reports how frequently specific queries are searched on Google\nover time. It is widely used in research and industry to gain early insights\ninto public interest. However, its data generation mechanism introduces missing\nvalues, sampling variability, noise, and trends. These issues arise from\nprivacy thresholds mapping low search volumes to zeros, daily sampling\nvariations causing discrepancies across historical downloads, and algorithm\nupdates altering volume magnitudes over time. Data quality has recently\ndeteriorated, with more zeros and noise, even for previously stable queries. We\npropose a comprehensive statistical methodology to preprocess Google Trends\nsearch information using hierarchical clustering, smoothing splines, and\ndetrending. We validate our approach by forecasting U.S. influenza\nhospitalizations with a univariate ARIMAX model. Compared to omitting exogenous\nvariables, our results show that raw Google Trends data degrades modeling\nperformance, while preprocessed signals enhance forecast accuracy by 58%\nnationally and 24% at the state level.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-09T16:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.07043v1","title":"BIA Transmission in Rate Splitting-based Optical Wireless Networks","summary":"Optical wireless communication (OWC) has recently received massive interest\nas a new technology that can support the enormous data traffic increasing on\ndaily basis. In particular, laser-based OWC networks can provide terabits per\nsecond (Tbps) aggregate data rates. However, the emerging OWC networks require\na high number of optical access points (APs), each AP corresponding to an\noptical cell, to provide uniform coverage for multiple users. Therefore,\ninter-cell interference (ICI) and multi-user interference (MUI) are crucial\nissues that must be managed efficiently to provide high spectral efficiency. In\nradio frequency (RF) networks, rate splitting (RS) is proposed as a\ntransmission scheme to serve multiple users simultaneously following a certain\nstrategy. It was shown that RS provides high data rates compared to orthogonal\nand non-orthogonal interference management schemes. Considering the high\ndensity of OWC networks, the application of RS within each optical cell might\nnot be practical due to severe ICI. In this paper, a new strategy is derived\nreferred to as blind interference alignment-rate splitting (BIA-RS) to fully\ncoordinate the transmission among the optical APs, while determining the\nprecoding matrices of multiple groups of users formed beforehand. Therefore, RS\ncan be implemented within each group to manage MUI. The proposed BIA-RS scheme\nrequires two layers of power allocation to achieve high performance. Given\nthat, a max-min fractional optimization problem is formulated to optimally\ndistribute the power budget among the groups and the messages intended to the\nusers of each group. Finally, a power allocation algorithm is designed with\nmultiple Lagrangian multipliers to provide practical and sub-optimal solutions.\nThe results show the high performance of the proposed scheme compared to other\ncounterpart schemes.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T17:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.07044v1","title":"Buffer Centering for bittide Synchronization via Frame Rotation","summary":"Maintaining consistent time in distributed systems is a fundamental\nchallenge. The bittide system addresses this by providing logical\nsynchronization through a decentralized control mechanism that observes local\nbuffer occupancies and controls the frequency of an oscillator at each node. A\ncritical aspect of bittide's stability and performance is ensuring that these\nelastic buffers operate around a desired equilibrium point, preventing data\nloss due to overflow or underflow. This paper introduces a novel method for\ncentering buffer occupancies in a bittide network using a technique we term\nframe rotation. We propose a control strategy utilizing a directed spanning\ntree of the network graph. By adjusting the frequencies of nodes in a specific\norder dictated by this tree, and employing a pulsed feedback controller that\ntargets the buffer occupancy of edges within the spanning tree, we prove that\nall elastic buffers in the network can be driven to their desired equilibrium.\nThis ordered adjustment approach ensures that prior centering efforts are not\ndisrupted, providing a robust mechanism for managing buffer occupancy in\nbittide synchronized systems.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-09T17:02:27Z"}
{"aid":"http://arxiv.org/abs/2504.07048v1","title":"Context Switching for Secure Multi-programming of Near-Term Quantum\n  Computers","summary":"Multi-programming quantum computers improve device utilization and\nthroughput. However, crosstalk from concurrent two-qubit CNOT gates poses\nsecurity risks, compromising the fidelity and output of co-running victim\nprograms. We design Zero Knowledge Tampering Attacks (ZKTAs), using which\nattackers can exploit crosstalk without knowledge of the hardware error\nprofile. ZKTAs can alter victim program outputs in 40% of cases on commercial\nsystems.\n  We identify that ZKTAs succeed because the attacker's program consistently\nruns with the same victim program in a fixed context. To mitigate this, we\npropose QONTEXTS: a context-switching technique that defends against ZKTAs by\nrunning programs across multiple contexts, each handling only a subset of\ntrials. QONTEXTS uses multi-programming with frequent context switching while\nidentifying a unique set of programs for each context. This helps limit only a\nfraction of execution to ZKTAs. We enhance QONTEXTS with attack detection\ncapabilities that compare the distributions from different contexts against\neach other to identify noisy contexts executed with ZKTAs. Our evaluations on\nreal IBMQ systems show that QONTEXTS increases program resilience by three\norders of magnitude and fidelity by 1.33$\\times$ on average. Moreover, QONTEXTS\nimproves throughput by 2$\\times$, advancing security in multi-programmed\nenvironments.","main_category":"cs.CR","categories":"cs.CR,cs.ET","published":"2025-04-09T17:05:16Z"}
{"aid":"http://arxiv.org/abs/2504.07051v1","title":"Revisiting X-ray polarization of the shell of Cassiopeia A using\n  spectropolarimetric analysis","summary":"X-ray synchrotron radiation is expected to be highly polarized. Thanks to the\nImaging X-ray Polarimetry Explorer (IXPE), it is now possible to evaluate the\ndegree of X-ray polarization in sources such as supernova remnants (SNRs).\nJointly using IXPE data and high-resolution Chandra observations, we perform a\nspatially resolved spectropolarimetric analysis of SNR Cassiopeia A (Cas A). We\nfocus in the 3-6 keV energy band on regions near the shell dominated by\nnonthermal synchrotron emission. By combining IXPE's polarization sensitivity\nwith Chandra's higher spatial and spectral resolution, we constrain the local\npolarization degree (PD) and polarization angle (PA) across the remnant. Our\nanalysis reveals PD values ranging locally from 10% to 26%, showing significant\nregional variations that underscore the complex magnetic field morphology of\nCas A. The polarization vectors indicate a predominantly radial magnetic field,\nconsistent with previous studies. Thanks to the improved modeling of thermal\ncontamination using Chandra data, we retrieve higher PD values compared to\nearlier IXPE analysis and more significant detections with respect to the\nstandard IXPEOBSSIM analysis. Finally, we also estimate the degree of magnetic\nturbulence {\\eta} from the measured photon index and PD, under the assumption\nof an isotropic fluctuating field across the shell of Cas A.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T17:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.07054v1","title":"Weighted Lojasiewicz inequalities and regularity of harmonic map flow","summary":"At a finite-time singularity of harmonic map flow in the critical dimension,\nwe show that a Lojasiewicz inequality between the quantities appearing in\nStruwe's monotonicity formula implies continuity of the body map and the\nno-neck property for bubble-tree decompositions. We prove such an inequality\nwhen the target is $S^2,$ yielding both properties in this case.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-09T17:14:34Z"}
{"aid":"http://arxiv.org/abs/2504.07068v1","title":"Quantum Reverse Shannon Theorem Revisited","summary":"Reverse Shannon theorems concern the use of noiseless channels to simulate\nnoisy ones. This is dual to the usual noisy channel coding problem, where a\nnoisy (classical or quantum) channel is used to simulate a noiseless one. The\nQuantum Reverse Shannon Theorem is extensively studied by Bennett and\nco-authors in [IEEE Trans. Inf. Theory, 2014]. They present two distinct\ntheorems, each tailored to classical and quantum channel simulations\nrespectively, explaining the fact that these theorems remain incomparable due\nto the fundamentally different nature of correlations they address. The authors\nleave as an open question the challenge of formulating a unified theorem that\ncould encompass the principles of both and unify them. We unify these two\ntheorems into a single, comprehensive theorem, extending it to the most general\ncase by considering correlations with a general mixed-state reference system.\nFurthermore, we unify feedback and non-feedback theorems by simulating a\ngeneral side information system at the encoder side.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT","published":"2025-04-09T17:37:20Z"}
{"aid":"http://arxiv.org/abs/2504.07437v1","title":"Unifying and extending Diffusion Models through PDEs for solving Inverse\n  Problems","summary":"Diffusion models have emerged as powerful generative tools with applications\nin computer vision and scientific machine learning (SciML), where they have\nbeen used to solve large-scale probabilistic inverse problems. Traditionally,\nthese models have been derived using principles of variational inference,\ndenoising, statistical signal processing, and stochastic differential\nequations. In contrast to the conventional presentation, in this study we\nderive diffusion models using ideas from linear partial differential equations\nand demonstrate that this approach has several benefits that include a\nconstructive derivation of the forward and reverse processes, a unified\nderivation of multiple formulations and sampling strategies, and the discovery\nof a new class of models. We also apply the conditional version of these models\nto solving canonical conditional density estimation problems and challenging\ninverse problems. These problems help establish benchmarks for systematically\nquantifying the performance of different formulations and sampling strategies\nin this study, and for future studies. Finally, we identify and implement a\nmechanism through which a single diffusion model can be applied to measurements\nobtained from multiple measurement operators. Taken together, the contents of\nthis manuscript provide a new understanding and several new directions in the\napplication of diffusion models to solving physics-based inverse problems.","main_category":"cs.LG","categories":"cs.LG,stat.CO,stat.ML","published":"2025-04-10T04:07:36Z"}
{"aid":"http://arxiv.org/abs/2504.07438v1","title":"Satellite System Architecting Considering On-Orbit Refueling","summary":"This paper introduces the problem of selecting a satellite system\narchitecture considering commercial on-orbit refueling (OOR). The problem aims\nto answer two questions: \"How durable should a satellite be?\" and \"How much\npropellant should be loaded into the satellite at launch?\" We formulate the\nproblem as a mathematical optimization by adopting the design lifetime and\npropellant mass as design variables and considering two objective functions to\nbalance the returns and risks. A surrogate model-based framework, grounded in a\nsatellite lifecycle simulation, is developed to address this problem. The\ndeveloped framework considers various uncertainties and operational flexibility\nand integrates a modified satellite sizing and cost model by adjusting\ntraditional models with OOR. A design case study of a geosynchronous equatorial\norbit communication satellite considering the OOR highlights the effectiveness\nof the developed framework.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T04:07:58Z"}
{"aid":"http://arxiv.org/abs/2504.07446v1","title":"A mass conserved reaction-diffusion system reveals switching between\n  coexisting polar and oscillatory cell motility states","summary":"Motile eukaryotic cells display distinct modes of migration that often occur\nwithin the same cell type. It remains unclear, however, whether transitions\nbetween the migratory modes require changes in external conditions, or whether\nthe different modes are coexisting states that emerge from the underlying\nsignaling network. Using a mass-conserved reaction-diffusion model of small\nGTPase signaling with F-actin mediated feedback, we uncover a bistable regime\nwhere a polarized mode of migration coexists with spatiotemporal oscillations.\nIndeed, experimental observations of D. discoideum show that, upon collision\nwith a rigid boundary, cells may switch from polarized to disordered motion.","main_category":"nlin.PS","categories":"nlin.PS,q-bio.CB","published":"2025-04-10T04:31:22Z"}
{"aid":"http://arxiv.org/abs/2504.07460v1","title":"Measuring Cosmic Growth Rate with CSST Spectroscopic Survey and Fast\n  Radio Burst","summary":"The cosmic growth rate, which is related to peculiar velocity and is a\nprimary scientific objective of galaxy spectroscopic surveys, can be inferred\nfrom the Redshift Space Distortion effect and the kinetic Sunyaev-Zel'dovich\neffect. However, the reconstruction noise power spectrum of the radial velocity\nfield in kSZ is significantly dependent on the measurement of the small-scale\ngalaxy-electron power spectrum $P_{ge}$. In this study, we thoroughly discuss\nthe enhancement of cosmic growth rate measurements facilitated by Fast Radio\nBursts, which probe the electron density of the universe along their\npropagation paths to provide crucial additional information on $P_{ge}$.\nSubsequently, we utilize future spectroscopic surveys from the Chinese Space\nStation Telescope and the CMB-S4 experiment, combined with FRB dispersion\nmeasures, to achieve precise measurements of the cosmic growth rate at\nredshifts $z_g = 0.15,0.45,0.75$. Employing Fisher matrix forecasting analysis,\nwe anticipate that constraints on $f\\sigma_8$ will reach a precision of 0.001\nwith a sample size of $10^6$ FRBs. Furthermore, we perform a global analysis\nusing Markov Chain Monte Carlo methods to constrain key parameters of three\ndistinct dark energy models and a modified gravity model based on cosmic growth\nrate measurements. The results demonstrate that these refined $f\\sigma_8$\nmeasurements considerably enhance the constraints on relevant cosmological\nparameters compared to those obtained from Planck. As the number of observed\nFRBs increases, alongside more precise galaxy surveys and next-generation CMB\nobservations, new opportunities will arise for constraining cosmological models\nusing the kSZ effect and for developing novel cosmological applications of\nFRBs.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T05:10:15Z"}
{"aid":"http://arxiv.org/abs/2504.07472v1","title":"HACMony: Automatically Testing Hopping-related Audio-stream Conflict\n  Issues on HarmonyOS","summary":"HarmonyOS is emerging as a popular distributed operating system for diverse\nmobile devices. One of its standout features is app-hopping, which allows users\nto seamlessly transition apps across different HarmonyOS devices. However, when\napps playing audio streams hop between devices, they can easily trigger\nHopping-related Audio-stream Conflict (HAC) scenarios. Improper resolution of\nHAC will lead to significant HAC issues, which are harder to detect compared to\nsingle-device audio-stream conflicts, due to the unclear semantics of\nHarmonyOS's app-hopping mechanism and the lack of effective multi-app hopping\ntesting methods. To fill the gap, this paper introduces an automated and\nefficient approach to detecting HAC issues. We formalized the operational\nsemantics of HarmonyOS's app-hopping mechanism for audio streams for the first\ntime. Leveraging this formalization, we designed an Audio Service Transition\nGraph (ASTG) to model the behaviors of audio-API-related services and proposed\na model-based approach to detect HAC issues automatically. Our techniques were\nimplemented in a tool, HACMony, and evaluated on 20 real-world HarmonyOS apps.\nExperimental results reveal that 11 of the 20 apps exhibit HAC issues.\nAdditionally, we summarized the detected issues into two typical types, namely\nMOD and MOR, and analyzed their characteristics to assist and guide both app\nand OS developers.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T05:55:08Z"}
{"aid":"http://arxiv.org/abs/2504.07507v1","title":"Drive in Corridors: Enhancing the Safety of End-to-end Autonomous\n  Driving via Corridor Learning and Planning","summary":"Safety remains one of the most critical challenges in autonomous driving\nsystems. In recent years, the end-to-end driving has shown great promise in\nadvancing vehicle autonomy in a scalable manner. However, existing approaches\noften face safety risks due to the lack of explicit behavior constraints. To\naddress this issue, we uncover a new paradigm by introducing the corridor as\nthe intermediate representation. Widely adopted in robotics planning, the\ncorridors represents spatio-temporal obstacle-free zones for the vehicle to\ntraverse. To ensure accurate corridor prediction in diverse traffic scenarios,\nwe develop a comprehensive learning pipeline including data annotation,\narchitecture refinement and loss formulation. The predicted corridor is further\nintegrated as the constraint in a trajectory optimization process. By extending\nthe differentiability of the optimization, we enable the optimized trajectory\nto be seamlessly trained within the end-to-end learning framework, improving\nboth safety and interpretability. Experimental results on the nuScenes dataset\ndemonstrate state-of-the-art performance of our approach, showing a 66.7%\nreduction in collisions with agents and a 46.5% reduction with curbs,\nsignificantly enhancing the safety of end-to-end driving. Additionally,\nincorporating the corridor contributes to higher success rates in closed-loop\nevaluations.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T07:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.07515v1","title":"Sequential Filtering Techniques for Simultaneous Tracking and Parameter\n  Estimation","summary":"The number of resident space objects is rising at an alarming rate.\nMega-constellations and breakup events are proliferating in most orbital\nregimes, and safe navigation is becoming increasingly problematic. It is\nimportant to be able to track RSOs accurately and at an affordable\ncomputational cost. Orbital dynamics are highly nonlinear, and current\noperational methods assume Gaussian representations of the objects' states and\nemploy linearizations which cease to hold true in observation-free propagation.\nMonte Carlo-based filters can provide a means to approximate the a posteriori\nprobability distribution of the states more accurately by providing support in\nthe portion of the state space which overlaps the most with the processed\nobservations. Moreover, dynamical models are not able to capture the full\nextent of realistic forces experienced in the near-Earth space environment, and\nhence fully deterministic propagation methods may fail to achieve the desired\naccuracy. By modeling orbital dynamics as a stochastic system and solving it\nusing stochastic numerical integrators, we are able to simultaneously estimate\nthe scale of the process noise incurred by the assumed uncertainty in the\nsystem, and robustly track the state of the spacecraft. In order to find an\nadequate balance between accuracy and computational cost, we propose three\nalgorithms which are capable of tracking a space object and estimating the\nmagnitude of the system's uncertainty. The proposed filters are successfully\napplied to a LEO scenario, demonstrating the ability to accurately track a\nspacecraft state and estimate the scale of the uncertainty online, in various\nsimulation setups.","main_category":"astro-ph.IM","categories":"astro-ph.IM,stat.AP","published":"2025-04-10T07:23:00Z"}
{"aid":"http://arxiv.org/abs/2504.07529v1","title":"Automating the Path: An R&D Agenda for Human-Centered AI and\n  Visualization","summary":"The emergence of generative AI, large language models (LLMs), and foundation\nmodels is fundamentally reshaping computer science, and visualization and\nvisual analytics are no exception. We present a systematic framework for\nunderstanding how human-centered AI (HCAI) can transform the visualization\ndiscipline. Our framework maps four key HCAI tool capabilities -- amplify,\naugment, empower, and enhance -- onto the four phases of visual sensemaking:\nview, explore, schematize, and report. For each combination, we review existing\ntools, envision future possibilities, identify challenges and pitfalls, and\nexamine ethical considerations. This design space can serve as an R\\&D agenda\nfor both visualization researchers and practitioners to integrate AI into their\nwork as well as understanding how visualization can support HCAI research.","main_category":"cs.HC","categories":"cs.HC,H.5.2","published":"2025-04-10T07:52:18Z"}
{"aid":"http://arxiv.org/abs/2504.07571v1","title":"The birth of Be star disks I. From localized ejection to circularization","summary":"Classical Be stars are well known to eject mass, but the details governing\nthe initial distribution and evolution of this matter into a disk are poorly\nconstrained by observations. By combining high-cadence spectroscopy with\ncontemporaneous space photometry from TESS, we have sampled about 30 mass\nejection events in 13 Be stars. Our goal is to constrain the geometrical and\nkinematic properties of the ejecta, facilitating the investigation into the\ninitial conditions and evolution, and understanding its interactions with\npreexisting material. The photometric variability is analyzed together with\nmeasurements of the rapidly changing emission features to identify the onset of\noutburst events and obtain information about the geometry of the ejecta and its\nevolution. All Be stars observed with sufficiently high cadence exhibit rapid\noscillations of line asymmetry with a single frequency in the days following\nthe start of the event. The emission asymmetry cycles break down after roughly\n5 - 10 cycles, with the emission line profile converging toward approximate\nsymmetry. In photometry, several frequencies typically emerge at relatively\nhigh amplitude at some point during the mass ejection process. In all observed\ncases, freshly ejected material was initially within a narrow azimuthal range,\nindicating it was launched from a localized region on the star. The material\norbits the star with a frequency consistent with the near-surface Keplerian\norbital frequency. This material circularizes into a disk configuration after\nseveral orbital timescales. This is true whether or not there was a preexisting\ndisk. We find no evidence for precursor phases prior to the ejection of mass in\nour sample. The several photometric frequencies that emerge during outburst are\nat least partially stellar in origin. (Abstract abridged)","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-10T09:13:41Z"}
{"aid":"http://arxiv.org/abs/2504.07584v1","title":"REANIMATOR: Reanimate Retrieval Test Collections with Extracted and\n  Synthetic Resources","summary":"Retrieval test collections are essential for evaluating information retrieval\nsystems, yet they often lack generalizability across tasks. To overcome this\nlimitation, we introduce REANIMATOR, a versatile framework designed to enable\nthe repurposing of existing test collections by enriching them with extracted\nand synthetic resources. REANIMATOR enhances test collections from PDF files by\nparsing full texts and machine-readable tables, as well as related contextual\ninformation. It then employs state-of-the-art large language models to produce\nsynthetic relevance labels. Including an optional human-in-the-loop step can\nhelp validate the resources that have been extracted and generated. We\ndemonstrate its potential with a revitalized version of the TREC-COVID test\ncollection, showcasing the development of a retrieval-augmented generation\nsystem and evaluating the impact of tables on retrieval-augmented generation.\nREANIMATOR enables the reuse of test collections for new applications, lowering\ncosts and broadening the utility of legacy resources.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.07590v1","title":"DWFS-Obfuscation: Dynamic Weighted Feature Selection for Robust Malware\n  Familial Classification under Obfuscation","summary":"Due to its open-source nature, the Android operating system has consistently\nbeen a primary target for attackers. Learning-based methods have made\nsignificant progress in the field of Android malware detection. However,\ntraditional detection methods based on static features struggle to identify\nobfuscated malicious code, while methods relying on dynamic analysis suffer\nfrom low efficiency. To address this, we propose a dynamic weighted feature\nselection method that analyzes the importance and stability of features,\ncalculates scores to filter out the most robust features, and combines these\nselected features with the program's structural information. We then utilize\ngraph neural networks for classification, thereby improving the robustness and\naccuracy of the detection system. We analyzed 8,664 malware samples from eight\nmalware families and tested a total of 44,940 malware variants generated using\nseven obfuscation strategies. Experiments demonstrate that our proposed method\nachieves an F1-score of 95.56% on the unobfuscated dataset and 92.28% on the\nobfuscated dataset, indicating that the model can effectively detect obfuscated\nmalware.","main_category":"cs.CR","categories":"cs.CR,I.2.7","published":"2025-04-10T09:37:43Z"}
{"aid":"http://arxiv.org/abs/2504.07619v1","title":"Beating Transformers using Synthetic Cognition","summary":"The road to Artificial General Intelligence goes through the generation of\nepisodic reactive behaviors, where the Transformer architecture has been proven\nto be the state-of-the-art. However, they still fail to develop reasoning.\nRecently, a novel approach for developing cognitive architectures, called\nSynthetic Cognition, has been proposed and implemented to develop instantaneous\nreactive behavior. In this study, we aim to explore the use of Synthetic\nCognition to develop episodic reactive behaviors. We propose a mechanism to\ndeal with sequences for the recent implementation of Synthetic Cognition, and\ntest it against DNA foundation models in DNA sequence classification tasks. In\nour experiments, our proposal clearly outperforms the DNA foundation models,\nobtaining the best score on more benchmark tasks than the alternatives. Thus,\nwe achieve two goals: expanding Synthetic Cognition to deal with sequences, and\nbeating the Transformer architecture for sequence classification.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-10T10:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.07621v1","title":"What causes long outbursts of neutron star low-mass X-ray binaries?","summary":"Many neutron star low-mass X-ray binaries (NS LMXBs) with short orbital\nperiods (~hours) cycle between outburst and quiescent phases, and thus provide\nan excellent way to study the accretion process. The cause of such outbursts is\nbelieved to be thermal-viscous instability in the accretion disc. However, some\nof these transient sources show unusually long outbursts. For example, EXO\n0748-676 remained in outburst for at least 23 years before entering a\nquiescence, only to re-emerge 16 years later. We aim to investigate if such\nlong outbursts could be due to the usual disc instability, or if any other\nmechanism is required. In order to address this question, we systematically\ncompare various properties of long outburst and short outburst NS LMXBs. For\nthis, we analyze the long-term X-ray light curves of many short orbital period\n(hours) NS LMXBs, examining the outburst duration and the inferred accretion\nrate, and estimate the accretion disc mass. Our study shows that long outburst\nsources are well-separated from the short outburst ones in parameter spaces\ninvolving accretion rate, disc mass, outburst duration, etc. in four ways. This\nimplies that the thermal-viscous instability in the disc cannot explain the\nlong outbursts, but could explain the short ones. Moreover, we discuss that\nboth donor star related and disc related models have difficulties in explaining\nlong outbursts. Our finding will be crucial to understanding the accretion\nprocess of transiently accreting neutron stars and black holes.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T10:09:32Z"}
{"aid":"http://arxiv.org/abs/2504.07628v1","title":"Singular networks and ultrasensitive terminal behaviors","summary":"Negative conductance elements are key to shape the input-output behavior at\nthe terminals of a network through localized positive feedback amplification.\nThe balance of positive and negative differential conductances creates\nsingularities at which rich, intrinsically nonlinear, and ultrasensitive\nterminal behaviors emerge. Motivated by neuromorphic engineering applications,\nin this note we extend a recently introduced nonlinear network graphical\nmodeling framework to include negative conductance elements. We use this\nextended framework to define the class of singular networks and to characterize\ntheir ultra-sensitive input/output behaviors at given terminals. Our results\nare grounded in the Lyapunov-Schmidt reduction method, which is shown to fully\ncharacterize the singularities and bifurcations of the input-output behavior at\nthe network terminals, including when the underlying input-output relation is\nnot explicitly computable through other reduction methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T10:24:25Z"}
{"aid":"http://arxiv.org/abs/2504.07629v1","title":"On the double Beltrami states in Hall magnetohydrodynamics","summary":"In this paper, we investigate double Beltrami states in the Hall\nmagnetohydrodynamic (Hall MHD) equations. Initially, we examine the double\nBeltrami states as a special class of steady solutions to the ideal Hall MHD\nequations, which are closely related to Beltrami flows in incompressible fluid\ndynamics. Specifically, we classify the double Beltrami states and show that\nthey can be derived by using the variational method as energy minimizers,\nsubject to the conservation of two helicities. We then extend our analysis to\ntime-dependent double Beltrami states in the viscous and resistive Hall MHD\nequations, exploring their exact form and stability properties.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T10:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.07641v1","title":"Quasi-rigid-band behavior and band gap changes upon isovalent\n  substitution in Cs$_3$Bi$_2$Br$_{9-x}$I$_x$","summary":"The recently introduced approach, combining the parameter-free\nArmiento-K\\\"{u}mmel generalized gradient approximation exchange functional with\nthe nonseparable gradient approximation Minnesota correlation functional, was\nused to calculate the electronic structure of the Cs$_3$Bi$_2$Br$_{9-x}$I$_x$\nseries within density functional theory including the spin-orbit coupling. The\nchanges in the band gap size and its dependence on the $x$ value was\ninvestigated. The band gap was found to be of indirect nature and it decreases\nwith increasing I content as long as the system is in the $P\\overline{3}m1$\nphase. A clear non-linear dependence of the band gap size on $x$ was\nestablished which is in qualitative and quantitative agreement with reported\nexperimental data. The quasi-rigid band behavior of the states in the valence\nand conduction bands of the $P\\overline{3}m1$ phase is discussed since no\nsignificant changes in the shape of the total density of unoccupied states were\nobserved upon the isovalent substitution.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T10:41:42Z"}
{"aid":"http://arxiv.org/abs/2504.07642v1","title":"Cache-a-lot: Pushing the Limits of Unsatisfiable Core Reuse in SMT-Based\n  Program Analysis","summary":"Satisfiability Modulo Theories (SMT) solvers are integral to program analysis\ntechniques like concolic and symbolic execution, where they help assess the\nsatisfiability of logical formulae to explore execution paths of the program\nunder test. However, frequent solver invocations are still the main performance\nbottleneck of these techniques. One way to mitigate this challenge is through\noptimizations such as caching and reusing solver results. While current methods\ntypically focus on reusing results from fully equivalent or closely related\nformulas, they often miss broader opportunities for reuse. In this paper, we\npropose a novel approach, Cache-a-lot, that extends the reuse of unsatisfiable\n(unsat) results by systematically considering all possible variable\nsubstitutions. This enables more extensive reuse of results, thereby reducing\nthe number of SMT solver invocations and improving the overall efficiency of\nconcolic and symbolic execution. Our evaluation, conducted against the\nstate-of-the-art Utopia solution using two benchmark sets, shows significant\nimprovements, particularly with more complex formulas. Our method achieves up\nto 74% unsat core reuse, compared to Utopia's 41%, and significant increase in\nthe time savings. These results demonstrate that, despite the additional\ncomputational complexity, the broader reuse of unsat results significantly\nenhances performance, offering valuable advancements for formal verification\nand program analysis.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T10:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.07645v1","title":"Prediction of Usage Probabilities of Shopping-Mall Corridors Using\n  Heterogeneous Graph Neural Networks","summary":"We present a method based on graph neural network (GNN) for prediction of\nprobabilities of usage of shopping-mall corridors. The heterogeneous graph\nnetwork of shops and corridor paths are obtained from floorplans of the malls\nby creating vector layers for corridors, shops and entrances. These are\nsubsequently assimilated into nodes and edges of graphs. The prediction of the\nusage probability is based on the shop features, namely, the area and usage\ncategories they fall into, and on the graph connecting these shops, corridor\njunctions and entrances by corridor paths. Though the presented method is\napplicable for training on datasets obtained from a field survey or from\npedestrian-detecting sensors, the target data of the supervised deep-learning\nwork flow in this work are obtained from a probability method. We also include\na context-specific representation learning of latent features. The\nusage-probability prediction is made on each edge, which is a connection by a\nsection of corridor path between the adjacent nodes representing the shops or\ncorridor points. To create a feature for each edge, the hidden-layer feature\nvectors acquired in the message-passing GNN layers at the nodes of each edge\nare averaged and concatenated with the vector obtained by their multiplication.\nThese edge-features are then passed to multilayer perceptrons (MLP) to make the\nfinal prediction of usage probability on each edge. The samples of synthetic\nlearning dataset for each shopping mall are obtained by changing the shops'\nusage and area categories, and by subsequently feeding the graph into the\nprobability model.\n  When including different shopping malls in a single dataset, we also propose\nto consider graph-level features to inform the model with specific identifying\nfeatures of each mall.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T10:48:36Z"}
{"aid":"http://arxiv.org/abs/2504.07647v1","title":"Rate Analysis and Optimization of LoS Beyond Diagonal RIS-assisted MIMO\n  Systems","summary":"In this letter, we derive an expression for the achievable rate in a\nmultiple-input multiple-output (MIMO) system assisted by a beyond-diagonal\nreconfigurable intelligent surface (BD-RIS) when the channels to and from the\nBD-RIS are line-of-sight (LoS) while the direct link is non-line-of-sight\n(NLoS). The rate expression allows to derive the optimal unitary and symmetric\nscattering BD-RIS matrix in closed form. Our simulation results show that the\nproposed solution is competitive even under the more usual Ricean channel\nfading model when the direct link is weak.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T10:48:52Z"}
{"aid":"http://arxiv.org/abs/2504.07679v1","title":"The Cosmological Evidence for Non-Minimal Coupling","summary":"The recent observational evidence of deviations from the $\\Lambda$-Cold Dark\nMatter ($\\Lambda$CDM) model points towards the presence of evolving dark\nenergy. The simplest possibility consists of a cosmological scalar field\n$\\varphi$, dubbed quintessence, driving the accelerated expansion. We assess\nthe evidence for the existence of such a scalar field. We find that, if the\naccelerated expansion is driven by quintessence, the data favour a potential\nenergy $V(\\varphi)$ that is concave, i.e., $m^2=d^2V/d\\varphi^2<0$.\nFurthermore, and more significantly, the data strongly favour a scalar field\nthat is non-minimally coupled to gravity (Bayes factor $\\log(B) = 7.34 \\pm\n0.60$), leading to time variations in the gravitational constant on\ncosmological scales, and the existence of fifth forces on smaller scales. The\nfact that we do not observe such fifth forces implies that either new physics\nmust come into play on non-cosmological scales or that quintessence is an\nunlikely explanation for the observed cosmic acceleration.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-10T12:07:47Z"}
{"aid":"http://arxiv.org/abs/2504.07681v1","title":"Role of activity and dissipation in achieving precise beating in cilia:\n  Insights from the rower model","summary":"Cilia and flagella are micron-sized filaments that actively beat with\nremarkable precision in a viscous medium, driving microorganism movement and\nefficient flow. We study the rower model to uncover how cilia activity and\ndissipation enable this precise motion. In this model, cilia motion is\nrepresented by a micro-beads Brownian movement between two distant harmonic\npotentials. At specific locations, energy pumps trigger potential switches,\ncapturing cilia activity and generating oscillations. We quantify precision of\noscillation using a quality factor, identifying its scaling with activity and\noscillation amplitude, finding precision maximization at an optimal amplitude.\nThe data collapse is not accurate for noisy oscillations. An exact analytic\nexpression for the precision quality factor, based on first passage time\nfluctuations, and derived in the small noise approximation, explains its\noptimality and scaling. Energy budget analysis shows the quality factor's\nconsistency with the thermodynamic uncertainty relation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T12:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.07691v1","title":"Distilling Knowledge from Heterogeneous Architectures for Semantic\n  Segmentation","summary":"Current knowledge distillation (KD) methods for semantic segmentation focus\non guiding the student to imitate the teacher's knowledge within homogeneous\narchitectures. However, these methods overlook the diverse knowledge contained\nin architectures with different inductive biases, which is crucial for enabling\nthe student to acquire a more precise and comprehensive understanding of the\ndata during distillation. To this end, we propose for the first time a generic\nknowledge distillation method for semantic segmentation from a heterogeneous\nperspective, named HeteroAKD. Due to the substantial disparities between\nheterogeneous architectures, such as CNN and Transformer, directly transferring\ncross-architecture knowledge presents significant challenges. To eliminate the\ninfluence of architecture-specific information, the intermediate features of\nboth the teacher and student are skillfully projected into an aligned logits\nspace. Furthermore, to utilize diverse knowledge from heterogeneous\narchitectures and deliver customized knowledge required by the student, a\nteacher-student knowledge mixing mechanism (KMM) and a teacher-student\nknowledge evaluation mechanism (KEM) are introduced. These mechanisms are\nperformed by assessing the reliability and its discrepancy between\nheterogeneous teacher-student knowledge. Extensive experiments conducted on\nthree main-stream benchmarks using various teacher-student pairs demonstrate\nthat our HeteroAKD outperforms state-of-the-art KD methods in facilitating\ndistillation between heterogeneous architectures.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-10T12:24:58Z"}
{"aid":"http://arxiv.org/abs/2504.07703v1","title":"Optimal Frequency Support from Virtual Power Plants: Minimal Reserve and\n  Allocation","summary":"This paper proposes a novel reserve-minimizing and allocation strategy for\nvirtual power plants (VPPs) to deliver optimal frequency support. The proposed\nstrategy enables VPPs, acting as aggregators for inverter-based resources\n(IBRs), to provide optimal frequency support economically. The proposed\nstrategy captures time-varying active power injections, reducing the\nunnecessary redundancy compared to traditional fixed reserve schemes. Reserve\nrequirements for the VPPs are determined based on system frequency response and\nsafety constraints, ensuring efficient grid support. Furthermore, an\nenergy-based allocation model decomposes power injections for each IBR,\naccounting for their specific limitations. Numerical experiments validate the\nfeasibility of the proposed approach, highlighting significant financial gains\nfor VPPs, especially as system inertia decreases due to higher renewable energy\nintegration.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T12:43:38Z"}
{"aid":"http://arxiv.org/abs/2504.07721v1","title":"From empirical brain networks towards modeling music perception -- a\n  perspective","summary":"This perspective article investigates how auditory stimuli influence neural\nnetwork dynamics using the FitzHugh-Nagumo (FHN) model and empirical brain\nconnectivity data. Results show that synchronization is sensitive to both the\nfrequency and amplitude of auditory input, with synchronization enhanced when\ninput frequencies align with the system's intrinsic frequencies. Increased\nstimulus amplitude broadens the synchronization range governed by a delicate\ninterplay involving the network's topology, the spatial location of the input,\nand the frequency characteristics of the cortical input signals. This\nperspective article also reveals that brain activity alternates between\nsynchronized and desynchronized states, reflecting critical dynamics and phase\ntransitions in neural networks. Notably, gamma-band synchronization is crucial\nfor processing music, with coherence peaking in this frequency range. The\nfindings emphasize the role of structural connectivity and network topology in\nmodulating synchronization, providing insights into how music perception\nengages brain networks. This perspective article offers a computational\nframework for understanding neural mechanisms in music perception, with\npotential implications for cognitive neuroscience and music psychology.","main_category":"q-bio.NC","categories":"q-bio.NC,nlin.AO","published":"2025-04-10T13:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.07722v1","title":"Relaxing the Markov Requirements on Reinforcement Learning Under Weak\n  Partial Ignorability","summary":"Incomplete data, confounding effects, and violations of the Markov property\nare interrelated problems which are ubiquitous in Reinforcement Learning\napplications. We introduce the concept of ``partial ignorabilty\" and leverage\nit to establish a novel convergence theorem for adaptive Reinforcement\nLearning. This theoretical result relaxes the Markov assumption on the\nstochastic process underlying conventional $Q$-learning, deploying a\ngeneralized form of the Robbins-Monro stochastic approximation theorem to\nestablish optimality. This result has clear downstream implications for most\nactive subfields of Reinforcement Learning, with clear paths for extension to\nthe field of Causal Inference.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-10T13:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.07726v1","title":"Quantum Machine Learning: Unveiling Trends, Impacts through Bibliometric\n  Analysis","summary":"Quantum Machine Learning (QML) is the intersection of two revolutionary\nfields: quantum computing and machine learning. It promises to unlock\nunparalleled capabilities in data analysis, model building, and problem-solving\nby harnessing the unique properties of quantum mechanics. This research\nendeavors to conduct a comprehensive bibliometric analysis of scientific\ninformation pertaining to QML covering the period from 2000 to 2023. An\nextensive dataset comprising 9493 scholarly works is meticulously examined to\nunveil notable trends, impact factors, and funding patterns within the domain.\nAdditionally, the study employs bibliometric mapping techniques to visually\nillustrate the network relationships among key countries, institutions,\nauthors, patent citations and significant keywords in QML research. The\nanalysis reveals a consistent growth in publications over the examined period.\nThe findings highlight the United States and China as prominent contributors,\nexhibiting substantial publication and citation metrics. Notably, the study\nconcludes that QML, as a research subject, is currently in a formative stage,\ncharacterized by robust scholarly activity and ongoing development.","main_category":"cs.DL","categories":"cs.DL,cs.LG","published":"2025-04-10T13:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.07729v1","title":"Benchmarking Multi-Organ Segmentation Tools for Multi-Parametric\n  T1-weighted Abdominal MRI","summary":"The segmentation of multiple organs in multi-parametric MRI studies is\ncritical for many applications in radiology, such as correlating imaging\nbiomarkers with disease status (e.g., cirrhosis, diabetes). Recently, three\npublicly available tools, such as MRSegmentator (MRSeg), TotalSegmentator MRI\n(TS), and TotalVibeSegmentator (VIBE), have been proposed for multi-organ\nsegmentation in MRI. However, the performance of these tools on specific MRI\nsequence types has not yet been quantified. In this work, a subset of 40\nvolumes from the public Duke Liver Dataset was curated. The curated dataset\ncontained 10 volumes each from the pre-contrast fat saturated T1, arterial T1w,\nvenous T1w, and delayed T1w phases, respectively. Ten abdominal structures were\nmanually annotated in these volumes. Next, the performance of the three public\ntools was benchmarked on this curated dataset. The results indicated that MRSeg\nobtained a Dice score of 80.7 $\\pm$ 18.6 and Hausdorff Distance (HD) error of\n8.9 $\\pm$ 10.4 mm. It fared the best ($p < .05$) across the different sequence\ntypes in contrast to TS and VIBE.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T13:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.07750v1","title":"Counting 5-isogenies of elliptic curves over $\\mathbb{Q}$","summary":"We show that the number of $5$-isogenies of elliptic curves defined over\n$\\mathbb{Q}$ with naive height bounded by $H > 0$ is asymptotic to $C_5\\cdot\nH^{1/6} (\\log H)^2$ for some explicitly computable constant $C_5 > 0$. This\nsettles the asymptotic count of rational points on the genus zero modular\ncurves $X_0(m)$. We leverage an explicit $\\mathbb{Q}$-isomorphism between the\nstack $\\mathscr{X}_0(5)$ and the generalized Fermat equation $x^2 + y^2 = z^4$\nwith $\\mathbb{G}_m$-action of weights $(4, 4, 2)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T13:45:11Z"}
{"aid":"http://arxiv.org/abs/2504.07763v1","title":"Data over dialogue: Why artificial intelligence is unlikely to humanise\n  medicine","summary":"Recently, a growing number of experts in artificial intelligence (AI) and\nmedicine have be-gun to suggest that the use of AI systems, particularly\nmachine learning (ML) systems, is likely to humanise the practice of medicine\nby substantially improving the quality of clinician-patient relationships. In\nthis thesis, however, I argue that medical ML systems are more likely to\nnegatively impact these relationships than to improve them. In particular, I\nargue that the use of medical ML systems is likely to comprise the quality of\ntrust, care, empathy, understanding, and communication between clinicians and\npatients.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC,cs.LG","published":"2025-04-10T14:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.07770v1","title":"Sublevels in arrangements and the spherical arc crossing number of\n  complete graphs","summary":"Levels and sublevels in arrangements -- and, dually, $k$-sets and $(\\leq\nk)$-sets -- are fundamental notions in discrete and computational geometry and\nnatural generalizations of convex polytopes, which correspond to the $0$-level.\nA long-standing conjecture of Eckhoff, Linhart, and Welzl, which would\ngeneralize McMullen's Upper Bound Theorem for polytopes and provide an exact\nrefinement of asymptotic bounds by Clarkson, asserts that for all $k\\leq\n\\lfloor \\frac{n-d-2}{2}\\rfloor$, the number of $(\\leq k)$-sets of a set $S$ of\n$n$ points in $\\mathbf{R}^d$ is maximized if $S$ is the vertex set of a\nneighborly polytope.\n  As a new tool for studying this conjecture and related problems, we introduce\nthe $g$-matrix, which generalizes both the $g$-vector of a simple polytope and\na Gale dual version of the $g$-vector studied by Lee and Welzl. Our main result\nis that the $g$-matrix of every vector configuration in $\\mathbf{R}^3$ is\nnon-negative, which implies the Eckhoff--Linhart--Welzl conjecture in the case\nwhere $d=n-4$.\n  As a corollary, we obtain the following result about crossing numbers:\nConsider a configuration $V\\subset S^2 \\subset \\mathbf{R}^3$ of $n$ unit\nvectors, and connect every pair of vectors by the unique shortest geodesic arc\nbetween them in the unit sphere $S^2$. This yields a drawing of the complete\ngraph $K_n$ in $S^2$, which we call a spherical arc drawing. Complementing\nprevious results for rectilinear drawings, we show that the number of crossings\nin any spherical arc drawing of $K_n$ is at least $\\frac{1}{4}\\lfloor\n\\frac{n}{2}\\rfloor \\lfloor \\frac{n-1}{2}\\rfloor \\lfloor \\frac{n-2}{2}\\rfloor\n\\lfloor \\frac{n-3}{2}\\rfloor$, which equals the conjectured value of the\ncrossing number of $K_n$. Moreover, the lower bound is attained if $V$ is\nconeighborly, i.e., if every open linear halfspace contains at least $\\lfloor\n(n-2)/2 \\rfloor$ of the vectors in $V$.","main_category":"math.CO","categories":"math.CO,cs.CG","published":"2025-04-10T14:10:15Z"}
{"aid":"http://arxiv.org/abs/2504.07779v1","title":"Genetic Programming with Reinforcement Learning Trained Transformer for\n  Real-World Dynamic Scheduling Problems","summary":"Dynamic scheduling in real-world environments often struggles to adapt to\nunforeseen disruptions, making traditional static scheduling methods and\nhuman-designed heuristics inadequate. This paper introduces an innovative\napproach that combines Genetic Programming (GP) with a Transformer trained\nthrough Reinforcement Learning (GPRT), specifically designed to tackle the\ncomplexities of dynamic scheduling scenarios. GPRT leverages the Transformer to\nrefine heuristics generated by GP while also seeding and guiding the evolution\nof GP. This dual functionality enhances the adaptability and effectiveness of\nthe scheduling heuristics, enabling them to better respond to the dynamic\nnature of real-world tasks. The efficacy of this integrated approach is\ndemonstrated through a practical application in container terminal truck\nscheduling, where the GPRT method outperforms traditional GP, standalone\nTransformer methods, and other state-of-the-art competitors. The key\ncontribution of this research is the development of the GPRT method, which\nshowcases a novel combination of GP and Reinforcement Learning (RL) to produce\nrobust and efficient scheduling solutions. Importantly, GPRT is not limited to\ncontainer port truck scheduling; it offers a versatile framework applicable to\nvarious dynamic scheduling challenges. Its practicality, coupled with its\ninterpretability and ease of modification, makes it a valuable tool for diverse\nreal-world scenarios.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T14:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.07780v1","title":"Interference-caged quantum many-body scars: the Fock space topological\n  localization and interference zeros","summary":"We propose a general mechanism for realizing athermal finite-energy-density\neigenstates -- termed interference-caged quantum many-body scars (ICQMBS) --\nwhich originate from exact many-body destructive interference on the Fock space\ngraph. These eigenstates are strictly localized to specific subsets of\nvertices, analogous to compact localized states in flat-band systems. Central\nto our framework is a connection between interference zeros and graph\nautomorphisms, which classify vertices according to the graph's local topology.\nThis connection enables the construction of a new class of topological ICQMBS,\nwhose robustness arises from the local topology of the Fock space graph rather\nthan from conventional conservation laws or dynamical constraints. We\ndemonstrate the effectiveness of this framework by developing a\ngraph-theory-based search algorithm, which identifies ICQMBS in both a\none-dimensional spin-1 XY model and two-dimensional quantum link models across\ndistinct gauge sectors. In particular, we discover the proposed topological\nICQMBS in the two-dimensional quantum link model and provide an intuitive\nexplanation for previously observed order-by-disorder phenomena in Hilbert\nspace. Our results reveal an unexpected synergy between graph theory, flat-band\nphysics, and quantum many-body dynamics, offering new insights into the\nstructure and stability of nonthermal eigenstates.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.other","published":"2025-04-10T14:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.07785v1","title":"Towards Micro-Action Recognition with Limited Annotations: An\n  Asynchronous Pseudo Labeling and Training Approach","summary":"Micro-Action Recognition (MAR) aims to classify subtle human actions in\nvideo. However, annotating MAR datasets is particularly challenging due to the\nsubtlety of actions. To this end, we introduce the setting of Semi-Supervised\nMAR (SSMAR), where only a part of samples are labeled. We first evaluate\ntraditional Semi-Supervised Learning (SSL) methods to SSMAR and find that these\nmethods tend to overfit on inaccurate pseudo-labels, leading to error\naccumulation and degraded performance. This issue primarily arises from the\ncommon practice of directly using the predictions of classifier as\npseudo-labels to train the model. To solve this issue, we propose a novel\nframework, called Asynchronous Pseudo Labeling and Training (APLT), which\nexplicitly separates the pseudo-labeling process from model training.\nSpecifically, we introduce a semi-supervised clustering method during the\noffline pseudo-labeling phase to generate more accurate pseudo-labels.\nMoreover, a self-adaptive thresholding strategy is proposed to dynamically\nfilter noisy labels of different classes. We then build a memory-based\nprototype classifier based on the filtered pseudo-labels, which is fixed and\nused to guide the subsequent model training phase. By alternating the two\npseudo-labeling and model training phases in an asynchronous manner, the model\ncan not only be learned with more accurate pseudo-labels but also avoid the\noverfitting issue. Experiments on three MAR datasets show that our APLT largely\noutperforms state-of-the-art SSL methods. For instance, APLT improves accuracy\nby 14.5\\% over FixMatch on the MA-12 dataset when using only 50\\% labeled data.\nCode will be publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.07797v1","title":"Event-Triggered Source Seeking Control for Nonholonomic Systems","summary":"This paper introduces an event-triggered source seeking control (ET-SSC) for\nautonomous vehicles modeled as the nonholonomic unicycle. The classical source\nseeking control is enhanced with static-triggering conditions to enable\naperiodic and less frequent updates of the system's input signals, offering a\nresource-aware control design. Our convergence analysis is based on\ntime-scaling combined with Lyapunov and averaging theories for systems with\ndiscontinuous right-hand sides. ET-SSC ensures exponentially stable behavior\nfor the resulting average system, leading to practical asymptotic convergence\nto a small neighborhood of the source point. We guarantee the avoidance of Zeno\nbehavior by establishing a minimum dwell time to prevent infinitely fast\nswitching. The performance optimization is aligned with classical\ncontinuous-time source seeking algorithms while balancing system performance\nwith actuation resource consumption. Our ET-SSC algorithm, the first of its\nkind, allows for arbitrarily large inter-sampling times, overcoming the\nlimitations of classical sampled-data implementations for source seeking\ncontrol.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-10T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.07805v1","title":"Symmetry energy dependence of the bulk viscosity of nuclear matter","summary":"We clarify how the weak-interaction-driven bulk viscosity $\\zeta$ and the\nbulk relaxation time $\\tau_\\Pi$ of neutrino-transparent $npe$ matter depend on\nthe nuclear symmetry energy. We show that, at saturation density, the\nequation-of-state dependence of these transport quantities is fully determined\nby the experimentally constrained nuclear symmetry energy $S$ and its slope\n$L$. Variations of $L$ within current experimental uncertainties can change the\n(frequency-independent) bulk viscosity by orders of magnitude. This suggests\nthat dissipative effects encoded in the gravitational-wave signatures of binary\nneutron star inspirals may help constrain nuclear symmetry energy properties.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-04-10T14:42:50Z"}
{"aid":"http://arxiv.org/abs/2504.07812v1","title":"Numerical instability of non-Hermitian Hamiltonian evolutions","summary":"The extreme sensitivity of non-Hermitian Hamiltonians exhibiting the\nnon-Hermitian skin effect (NHSE) has been extensively studied in recent years\nwith well-established theoretical explanations. However, this sensitivity is\noften overlooked in numerical calculations, as seen in Refs.\n\\cite{NHSEEPTKawabata, Schiro}. In this work, we examine the solvable\nHatano-Nelson and symplectic Hatano-Nelson models, comparing our high-precision\nresults with those in Ref. \\cite{NHSEEPTKawabata}. We systematically\ninvestigate inaccuracies in physical results arising from neglecting numerical\nerrors during diagonalization and non-Hermitian Hamiltonian evolution.\nMoreover, we attribute these numerical instabilities to the large condition\nnumber, which grows exponentially with system size due to NHSE, indicating\nstrong normality. Interestingly, it is found that a reliable spectrum alone is\ninsufficient for accurate non-Hermitian evolution, while the reliability of\nwavefunctions plays a more critical role. To ensure the accuracy of numerical\nresults for non-Hermitian systems exhibiting NHSE, our work underscores the\nimportance of estimating the condition number before performing numerical\ncomputations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T14:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.07844v1","title":"A quantum computing approach to beam angle optimization","summary":"Background: Beam angle optimization (BAO) is a critical component of\nradiation therapy (RT) treatment planning, where small changes in beam\nconfiguration can significantly impact treatment quality, especially for proton\nRT. Mathematically, BAO is a mixed integer programming (MIP) problem, which is\nNP-hard due to its exponential growing search space. Traditional optimization\ntechniques often struggle with computational efficiency, necessitating the\ndevelopment of novel approaches. Purpose: This study introduces QC-BAO, a\nhybrid quantum-classical approach that leverages quantum computing to solve the\nMIP formulation of BAO. Methods: The proposed approach, QC-BAO, models BAO as\nan MIP problem, incorporating binary variables for beam angle selection and\ncontinuous variables for optimizing spot intensities for proton therapy. The\nproposed approach employs a hybrid quantum-classical framework, utilizing\nquantum computing to solve the binary decision component while integrating\nclassical optimization techniques, including iterative convex relaxation and\nalternating direction method of multipliers. Results: Computational experiments\nwere conducted on clinical test cases to evaluate QC-BAO's performance against\nclinically verified angles and a heuristic approach, GS-BAO. QC-BAO\ndemonstrated improved treatment plan quality over both clinical and GS-BAO. The\nmethod consistently increased the conformity index (CI) for target coverage\nwhile reducing mean and maximum doses to organs-at-risk (OAR). Additionally,\nQC-BAO produced the lowest objective function value, confirming its superior\noptimization capability. Conclusions: The findings highlight the potential of\nquantum computing to enhance the solution to BAO problem by demonstrated\nimprovement in plan quality using the proposed method, QC-BAO. This study paves\nthe way for future clinical implementation of quantum-accelerated optimization\nin RT.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-10T15:24:37Z"}
{"aid":"http://arxiv.org/abs/2504.07911v1","title":"The Urban Impact of AI: Modeling Feedback Loops in Next-Venue\n  Recommendation","summary":"Next-venue recommender systems are increasingly embedded in location-based\nservices, shaping individual mobility decisions in urban environments. While\ntheir predictive accuracy has been extensively studied, less attention has been\npaid to their systemic impact on urban dynamics. In this work, we introduce a\nsimulation framework to model the human-AI feedback loop underpinning\nnext-venue recommendation, capturing how algorithmic suggestions influence\nindividual behavior, which in turn reshapes the data used to retrain the\nmodels. Our simulations, grounded in real-world mobility data, systematically\nexplore the effects of algorithmic adoption across a range of recommendation\nstrategies. We find that while recommender systems consistently increase\nindividual-level diversity in visited venues, they may simultaneously amplify\ncollective inequality by concentrating visits on a limited subset of popular\nplaces. This divergence extends to the structure of social co-location\nnetworks, revealing broader implications for urban accessibility and spatial\nsegregation. Our framework operationalizes the feedback loop in next-venue\nrecommendation and offers a novel lens through which to assess the societal\nimpact of AI-assisted mobility-providing a computational tool to anticipate\nfuture risks, evaluate regulatory interventions, and inform the design of ethic\nalgorithmic systems.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-10T17:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.07918v1","title":"Shuffling via Transpositions","summary":"We consider a family of card shuffles of $n$ cards, where the allowed moves\ninvolve transpositions corresponding to the Jucys--Murphy elements of\n$\\{S_m\\}_{m \\leq n}$. We diagonalize the transition matrix of these shuffles.\nAs a special case, we consider the $k$-star transpositions shuffle, a natural\ninterpolation between random transpositions and star transpositions. We proved\nthat the $k$-star transpositions shuffle exhibits total variation cutoff at\ntime $\\frac{2n-(k+1)}{2(n-1)}n\\log n$ with a window of\n$\\frac{2n-(k+1)}{2(n-1)}n$. Furthermore, we prove that for the case where $k/n\n\\rightarrow 0$ or $1$, this shuffle has the same limit profile as random\ntranspositions, which has been fully determined by Teyssier.","main_category":"math.CO","categories":"math.CO,math.PR","published":"2025-04-10T17:33:30Z"}
{"aid":"http://arxiv.org/abs/2504.07919v1","title":"Double White Dwarf Tides with Multi-messenger Measurements","summary":"Short-period Galactic double white dwarf (DWD) systems will be observable\nboth in visible light through photometric monitoring and in mHz-range\ngravitational waves (GWs) with forthcoming space-based laser interferometry\nsuch as LISA. When only photometric variability is used to measure DWD\nintrinsic properties, there is a degeneracy between the chirp mass and binary\ntidal interaction, as orbital frequency time derivative is set by both GW\nradiation and tides. Without expensive radial velocity data from spectroscopic\nmonitoring, this degeneracy may be lifted in principle by directly measuring\nthe second time derivative of the orbital frequency through photometric\nmonitoring over an ultra-long time baseline. Alternatively, the degeneracy can\nbe removed by exploiting information in both photometric variability and the\ncoherent GW waveform. Investigating both approaches, we find that direct\nmeasurement of the second time derivative is likely infeasible for most DWDs,\nwhile the multi-messenger method will disentangle measurements of the chirp\nmass and the binary moments of inertia, for a large sample of tidally locked\nsystems. The latter information will enable empirical tests of WD structure\nmodels with finite temperature effects.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-10T17:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.07944v1","title":"Hyperbolic sine-Gordon model beyond the first threshold","summary":"We study the hyperbolic sine-Gordon model, with a parameter $\\beta^2 > 0$,\nand its associated Gibbs dynamics on the two-dimensional torus. By introducing\na physical space approach to the Fourier restriction norm method and\nestablishing nonlinear dispersive smoothing for the imaginary multiplicative\nGaussian chaos, we construct invariant Gibbs dynamics for the hyperbolic\nsine-Gordon model beyond the first threshold $\\beta^2 = 2\\pi$. The\ndeterministic step of our argument hinges on establishing key bilinear\nestimates, featuring weighted bounds for a cone multiplier. Moreover, the\nprobabilistic component involves a careful analysis of the imaginary Gaussian\nmultiplicative chaos and reduces to integrating singularities along space-time\nlight cones. As a by-product of our proof, we identify $\\beta^2 = 6\\pi$ as a\ncritical threshold for the hyperbolic sine-Gordon model, which is quite\nsurprising given that the associated parabolic model has a critical threshold\nat $\\beta^2 =8\\pi$.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,math.PR","published":"2025-04-10T17:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.07952v1","title":"Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory","summary":"Despite their impressive performance on complex tasks, current language\nmodels (LMs) typically operate in a vacuum: Each input query is processed\nseparately, without retaining insights from previous attempts. Here, we present\nDynamic Cheatsheet (DC), a lightweight framework that endows a black-box LM\nwith a persistent, evolving memory. Rather than repeatedly re-discovering or\nre-committing the same solutions and mistakes, DC enables models to store and\nreuse accumulated strategies, code snippets, and general problem-solving\ninsights at inference time. This test-time learning enhances performance\nsubstantially across a range of tasks without needing explicit ground-truth\nlabels or human feedback. Leveraging DC, Claude 3.5 Sonnet's accuracy more than\ndoubled on AIME math exams once it began retaining algebraic insights across\nquestions. Similarly, GPT-4o's success rate on Game of 24 increased from 10% to\n99% after the model discovered and reused a Python-based solution. In tasks\nprone to arithmetic mistakes, such as balancing equations, DC enabled GPT-4o\nand Claude to reach near-perfect accuracy by recalling previously validated\ncode, whereas their baselines stagnated around 50%. Beyond arithmetic\nchallenges, DC yields notable accuracy gains on knowledge-demanding tasks.\nClaude achieved a 9% improvement in GPQA-Diamond and an 8% boost on MMLU-Pro\nproblems. Crucially, DC's memory is self-curated, focusing on concise,\ntransferable snippets rather than entire transcript. Unlike finetuning or\nstatic retrieval methods, DC adapts LMs' problem-solving skills on the fly,\nwithout modifying their underlying parameters. Overall, our findings present DC\nas a promising approach for augmenting LMs with persistent memory, bridging the\ndivide between isolated inference events and the cumulative, experience-driven\nlearning characteristic of human cognition.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.07963v1","title":"PixelFlow: Pixel-Space Generative Models with Flow","summary":"We present PixelFlow, a family of image generation models that operate\ndirectly in the raw pixel space, in contrast to the predominant latent-space\nmodels. This approach simplifies the image generation process by eliminating\nthe need for a pre-trained Variational Autoencoder (VAE) and enabling the whole\nmodel end-to-end trainable. Through efficient cascade flow modeling, PixelFlow\nachieves affordable computation cost in pixel space. It achieves an FID of 1.98\non 256$\\times$256 ImageNet class-conditional image generation benchmark. The\nqualitative text-to-image results demonstrate that PixelFlow excels in image\nquality, artistry, and semantic control. We hope this new paradigm will inspire\nand open up new opportunities for next-generation visual generation models.\nCode and models are available at https://github.com/ShoufaChen/PixelFlow.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.09882v1","title":"SIO-Mapper: A Framework for Lane-Level HD Map Construction Using\n  Satellite Images and OpenStreetMap with No On-Site Visits","summary":"High-definition (HD) maps, particularly those containing lane-level\ninformation regarded as ground truth, are crucial for vehicle localization\nresearch. Traditionally, constructing HD maps requires highly accurate sensor\nmeasurements collection from the target area, followed by manual annotation to\nassign semantic information. Consequently, HD maps are limited in terms of\ngeographic coverage. To tackle this problem, in this paper, we propose\nSIO-Mapper, a novel lane-level HD map construction framework that constructs\ncity-scale maps without physical site visits by utilizing satellite images and\nOpenStreetmap data. One of the key contributions of SIO-Mapper is its ability\nto extract lane information more accurately by introducing SIO-Net, a novel\ndeep learning network that integrates features from satellite image and\nOpenStreetmap using both Transformer-based and convolution-based encoders.\nFurthermore, to overcome challenges in merging lanes over large areas, we\nintroduce a novel lane integration methodology that combines cluster-based and\ngraph-based approaches. This algorithm ensures the seamless aggregation of lane\nsegments with high accuracy and coverage, even in complex road environments. We\nvalidated SIO-Mapper on the Naver Labs Open Dataset and NuScenes dataset,\ndemonstrating better performance in various environments including Korea, the\nUnited States, and Singapore compared to the state-of-the-art lane-level HD\nmapconstruction methods.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T05:10:57Z"}
{"aid":"http://arxiv.org/abs/2504.09906v1","title":"Plasticity-Aware Mixture of Experts for Learning Under QoE Shifts in\n  Adaptive Video Streaming","summary":"Adaptive video streaming systems are designed to optimize Quality of\nExperience (QoE) and, in turn, enhance user satisfaction. However, differences\nin user profiles and video content lead to different weights for QoE factors,\nresulting in user-specific QoE functions and, thus, varying optimization\nobjectives. This variability poses significant challenges for neural networks,\nas they often struggle to generalize under evolving targets - a phenomenon\nknown as plasticity loss that prevents conventional models from adapting\neffectively to changing optimization objectives. To address this limitation, we\npropose the Plasticity-Aware Mixture of Experts (PA-MoE), a novel learning\nframework that dynamically modulates network plasticity by balancing memory\nretention with selective forgetting. In particular, PA-MoE leverages noise\ninjection to promote the selective forgetting of outdated knowledge, thereby\nendowing neural networks with enhanced adaptive capabilities. In addition, we\npresent a rigorous theoretical analysis of PA-MoE by deriving a regret bound\nthat quantifies its learning performance. Experimental evaluations demonstrate\nthat PA-MoE achieves a 45.5% improvement in QoE over competitive baselines in\ndynamic streaming environments. Further analysis reveals that the model\neffectively mitigates plasticity loss by optimizing neuron utilization.\nFinally, a parameter sensitivity study is performed by injecting varying levels\nof noise, and the results align closely with our theoretical predictions.","main_category":"cs.MM","categories":"cs.MM,cs.AI","published":"2025-04-14T06:02:41Z"}
{"aid":"http://arxiv.org/abs/2504.09913v1","title":"Optimal Non-Asymptotic Rates of Value Iteration for Average-Reward\n  Markov Decision Processes","summary":"While there is an extensive body of research on the analysis of Value\nIteration (VI) for discounted cumulative-reward MDPs, prior work on analyzing\nVI for (undiscounted) average-reward MDPs has been limited, and most prior\nresults focus on asymptotic rates in terms of Bellman error. In this work, we\nconduct refined non-asymptotic analyses of average-reward MDPs, obtaining a\ncollection of convergence results that advance our understanding of the setup.\nAmong our new results, most notable are the $\\mathcal{O}(1/k)$-rates of\nAnchored Value Iteration on the Bellman error under the multichain setup and\nthe span-based complexity lower bound that matches the $\\mathcal{O}(1/k)$ upper\nbound up to a constant factor of $8$ in the weakly communicating and unichain\nsetups","main_category":"math.OC","categories":"math.OC","published":"2025-04-14T06:22:14Z"}
{"aid":"http://arxiv.org/abs/2504.09921v1","title":"All-optical Raman control of ultracold atomic hyperfine states using\n  pulsed jump protocol","summary":"We develop a pulse-driven jump protocol to achieve all-optical Raman control\nof ultracold atomic hyperfine states. By establishing general conditions for\nadiabatic evolution between quantum states in parameter space, we derive the\nessential pulse area and phase conditions necessary for quantum state transfer\nin a resonant single-$\\Lambda$ three-level system. We extend this approach to a\ndouble-$\\Lambda$ four-level system by incorporating a neighboring intermediate\nstate, which leads to a single-photon detuned $\\Lambda$ three-level system.\nThrough numerical simulations of the ultracold $^{87}$Rb atomic system, we\ndemonstrate that high-fidelity and robust control of quantum state transfer can\nbe achieved in the single-$\\Lambda$ three-level system using stimulated Raman\nadiabatic passage (STIRAP) and the pulsed jump protocol. Furthermore, we show\nthat the destructive quantum interference effects between resonant and detuned\nRaman pathways in the double-$\\Lambda$ four-level system can be mitigated by\noptimizing the pulse area and two-photon detuning parameters within the pulsed\njump protocol. This work presents a promising approach for achieving\nall-optical Raman control of quantum state transfer in ultracold atomic\nhyperfine states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T06:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.09923v1","title":"Guiding Reasoning in Small Language Models with LLM Assistance","summary":"The limited reasoning capabilities of small language models (SLMs) cast doubt\non their suitability for tasks demanding deep, multi-step logical deduction.\nThis paper introduces a framework called Small Reasons, Large Hints (SMART),\nwhich selectively augments SLM reasoning with targeted guidance from large\nlanguage models (LLMs). Inspired by the concept of cognitive scaffolding, SMART\nemploys a score-based evaluation to identify uncertain reasoning steps and\ninjects corrective LLM-generated reasoning only when necessary. By framing\nstructured reasoning as an optimal policy search, our approach steers the\nreasoning trajectory toward correct solutions without exhaustive sampling. Our\nexperiments on mathematical reasoning datasets demonstrate that targeted\nexternal scaffolding significantly improves performance, paving the way for\ncollaborative use of both SLM and LLM to tackle complex reasoning tasks that\nare currently unsolvable by SLMs alone.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.09946v1","title":"Assessing Judging Bias in Large Reasoning Models: An Empirical Study","summary":"Large Reasoning Models (LRMs) like DeepSeek-R1 and OpenAI-o1 have\ndemonstrated remarkable reasoning capabilities, raising important questions\nabout their biases in LLM-as-a-judge settings. We present a comprehensive\nbenchmark comparing judging biases between LLMs and LRMs across both subjective\npreference-alignment datasets and objective fact-based datasets. Through\ninvestigation of bandwagon, authority, position, and distraction biases, we\nuncover four key findings: (1) despite their advanced reasoning capabilities,\nLRMs remain susceptible to the above biases; (2) LRMs demonstrate better\nrobustness than LLMs specifically on fact-related datasets; (3) LRMs exhibit\nnotable position bias, preferring options in later positions; and (4) we\nidentify a novel \"superficial reflection bias\" where phrases mimicking\nreasoning (e.g., \"wait, let me think...\") significantly influence model\njudgments. To address these biases, we design and evaluate three mitigation\nstrategies: specialized system prompts that reduce judging biases by up to 19\\%\nin preference alignment datasets and 14\\% in fact-related datasets, in-context\nlearning that provides up to 27\\% improvement on preference tasks but shows\ninconsistent results on factual tasks, and a self-reflection mechanism that\nreduces biases by up to 10\\% in preference datasets and 16\\% in fact-related\ndatasets, with self-reflection proving particularly effective for LRMs. Our\nwork provides crucial insights for developing more reliable LLM-as-a-Judge\nframeworks, especially as LRMs become increasingly deployed as automated\njudges.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-14T07:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.09955v1","title":"VR MRI Training for Adolescents: A Comparative Study of Gamified VR,\n  Passive VR, 360 Video, and Traditional Educational Video","summary":"Magnetic Resonance Imaging (MRI) can be a stressful experience for pediatric\npatients due to the loud acoustic environment, enclosed scanner bore, and a\nprolonged requirement to remain still. While sedation is commonly used to\nmanage anxiety and motion, it carries clinical risks and logistical burdens.\nTraditional preparatory approaches, such as instructional videos and mock\nscans, often lack engagement for older children and adolescents. In this study,\nwe present a comparative evaluation of four MRI preparation modalities: (1) a\ngamified virtual reality (VR) simulation that trains stillness through\nreal-time feedback; (2) a passive VR experience replicating the MRI environment\nwithout interactivity; (3) a 360 degree first-person video of a real MRI\nprocedure; and (4) a standard 2D educational video. Using a within-subjects\ndesign (N = 11, ages 10-16), we assess each method's impact on head motion\ndata, anxiety reduction, procedural preparedness, usability, cognitive\nworkload, and subjective preference. Results show that the gamified VR\ncondition has significantly lower head motion (p < 0.001) and yielded the\nhighest preparedness scores (p < 0.05). Head motion data were significantly\ncorrelated with learning outcomes (p < 0.01), suggesting that behavioral\nperformance in VR strongly indicates procedural readiness. While all modalities\nreduced anxiety and were rated usable, interactive VR was preferred by most\nparticipants and demonstrated unique advantages in promoting engagement and\nbehavioral rehearsal. We conclude with design recommendations for designing\nimmersive simulations and integrating VR training into pediatric imaging\nworkflows.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T07:40:30Z"}
{"aid":"http://arxiv.org/abs/2504.09971v1","title":"Proofs of Useful Work from Arbitrary Matrix Multiplication","summary":"We revisit the longstanding open problem of implementing Nakamoto's\nproof-of-work (PoW) consensus based on a real-world computational task $T(x)$\n(as opposed to artificial random hashing), in a truly permissionless setting\nwhere the miner itself chooses the input $x$. The challenge in designing such a\nProof-of-Useful-Work (PoUW) protocol, is using the native computation of $T(x)$\nto produce a PoW certificate with prescribed hardness and with negligible\ncomputational overhead over the worst-case complexity of $T(\\cdot)$ -- This\nensures malicious miners cannot ``game the system\" by fooling the verifier to\naccept with higher probability compared to honest miners (while using similar\ncomputational resources). Indeed, obtaining a PoUW with $O(1)$-factor overhead\nis trivial for any task $T$, but also useless.\n  Our main result is a PoUW for the task of Matrix Multiplication $MatMul(A,B)$\nof arbitrary matrices with $1+o(1)$ multiplicative overhead compared to naive\n$MatMul$ (even in the presence of Fast Matrix Multiplication-style algorithms,\nwhich are currently impractical). We conjecture that our protocol has optimal\nsecurity in the sense that a malicious prover cannot obtain any significant\nadvantage over an honest prover. This conjecture is based on reducing hardness\nof our protocol to the task of solving a batch of low-rank random linear\nequations which is of independent interest.\n  Since $MatMul$s are the bottleneck of AI compute as well as countless\nindustry-scale applications, this primitive suggests a concrete design of a new\nL1 base-layer protocol, which nearly eliminates the energy-waste of Bitcoin\nmining -- allowing GPU consumers to reduce their AI training and inference\ncosts by ``re-using\" it for blockchain consensus, in exchange for block rewards\n(2-for-1). This blockchain is currently under construction.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T08:22:40Z"}
{"aid":"http://arxiv.org/abs/2504.09976v1","title":"Nonlocal operators in divergence form and existence theory for\n  integrable data","summary":"We present an existence and uniqueness result for weak solutions of Dirichlet\nboundary value problems governed by a nonlocal operator in divergence form and\nin the presence of a datum which is assumed to belong only to $L^1(\\Omega)$ and\nto be suitably dominated.\n  We also prove that the solution that we find converges, as $s\\nearrow 1$, to\na solution of the local counterpart problem, recovering the classical result as\na limit case. This requires some nontrivial customized uniform estimates and\nrepresentation formulas, given that the datum is only in $L^1(\\Omega)$ and\ntherefore the usual regularity theory cannot be leveraged to our benefit in\nthis framework.\n  The limit process uses a nonlocal operator, obtained as an affine\ntransformation of a homogeneous kernel, which recovers, in the limit as\n$s\\nearrow 1$, every classical operator in divergence form.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T08:31:51Z"}
{"aid":"http://arxiv.org/abs/2504.09981v1","title":"Learning rate matrix and information-thermodynamic trade-off relation","summary":"Non-equilibrium systems exchange information in addition to energy. In\ninformation thermodynamics, the information flow is characterized by the\nlearning rate, which is not invariant under coordinate transformations. To\nformalize the property of the learning rate under variable transformations, we\nintroduce a learning rate matrix. This matrix has the learning rates as its\ndiagonal elements and characterizes the changes in the learning rates under\nlinear coordinate transformations. The maximal eigenvalue of the symmetric part\nof the learning rate matrix gives the maximal information flow under orthogonal\ntransformations. Furthermore, we derive a new trade-off relation between the\nlearning rate and the heat dissipation of a subsystem. Finally, we illustrate\nthe results using analytically solvable yet experimentally feasible models.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-14T08:49:43Z"}
{"aid":"http://arxiv.org/abs/2504.10002v1","title":"FLoRA: Sample-Efficient Preference-based RL via Low-Rank Style\n  Adaptation of Reward Functions","summary":"Preference-based reinforcement learning (PbRL) is a suitable approach for\nstyle adaptation of pre-trained robotic behavior: adapting the robot's policy\nto follow human user preferences while still being able to perform the original\ntask. However, collecting preferences for the adaptation process in robotics is\noften challenging and time-consuming. In this work we explore the adaptation of\npre-trained robots in the low-preference-data regime. We show that, in this\nregime, recent adaptation approaches suffer from catastrophic reward forgetting\n(CRF), where the updated reward model overfits to the new preferences, leading\nthe agent to become unable to perform the original task. To mitigate CRF, we\npropose to enhance the original reward model with a small number of parameters\n(low-rank matrices) responsible for modeling the preference adaptation. Our\nevaluation shows that our method can efficiently and effectively adjust robotic\nbehavior to human preferences across simulation benchmark tasks and multiple\nreal-world robotic tasks.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-14T09:04:14Z"}
{"aid":"http://arxiv.org/abs/2504.10007v1","title":"Balancing Two Classifiers via A Simplex ETF Structure for Model\n  Calibration","summary":"In recent years, deep neural networks (DNNs) have demonstrated\nstate-of-the-art performance across various domains. However, despite their\nsuccess, they often face calibration issues, particularly in safety-critical\napplications such as autonomous driving and healthcare, where unreliable\npredictions can have serious consequences. Recent research has started to\nimprove model calibration from the view of the classifier. However, the\nexploration of designing the classifier to solve the model calibration problem\nis insufficient. Let alone most of the existing methods ignore the calibration\nerrors arising from underconfidence. In this work, we propose a novel method by\nbalancing learnable and ETF classifiers to solve the overconfidence or\nunderconfidence problem for model Calibration named BalCAL. By introducing a\nconfidence-tunable module and a dynamic adjustment method, we ensure better\nalignment between model confidence and its true accuracy. Extensive\nexperimental validation shows that ours significantly improves model\ncalibration performance while maintaining high predictive accuracy,\noutperforming existing techniques. This provides a novel solution to the\ncalibration challenges commonly encountered in deep learning.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-14T09:09:01Z"}
{"aid":"http://arxiv.org/abs/2504.10018v1","title":"RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset\n  and An Asymmetric RWKV Fusion Framework","summary":"Existing pedestrian attribute recognition methods are generally developed\nbased on RGB frame cameras. However, these approaches are constrained by the\nlimitations of RGB cameras, such as sensitivity to lighting conditions and\nmotion blur, which hinder their performance. Furthermore, current attribute\nrecognition primarily focuses on analyzing pedestrians' external appearance and\nclothing, lacking an exploration of emotional dimensions. In this paper, we\nrevisit these issues and propose a novel multi-modal RGB-Event attribute\nrecognition task by drawing inspiration from the advantages of event cameras in\nlow-light, high-speed, and low-power consumption. Specifically, we introduce\nthe first large-scale multi-modal pedestrian attribute recognition dataset,\ntermed EventPAR, comprising 100K paired RGB-Event samples that cover 50\nattributes related to both appearance and six human emotions, diverse scenes,\nand various seasons. By retraining and evaluating mainstream PAR models on this\ndataset, we establish a comprehensive benchmark and provide a solid foundation\nfor future research in terms of data and algorithmic baselines. In addition, we\npropose a novel RWKV-based multi-modal pedestrian attribute recognition\nframework, featuring an RWKV visual encoder and an asymmetric RWKV fusion\nmodule. Extensive experiments are conducted on our proposed dataset as well as\ntwo simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving\nstate-of-the-art results. The source code and dataset will be released on\nhttps://github.com/Event-AHU/OpenPAR","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T09:22:16Z"}
{"aid":"http://arxiv.org/abs/2504.10023v1","title":"Revisiting the deuteron mass radius via near-threshold $Ï^0$,\n  $Ï$ and $Ï$ meson photoproduction","summary":"We present a comprehensive analysis of the near-threshold photoproduction of\nthe $\\rho^0$, $\\omega$, and $\\phi$ mesons on a deuterium target, leveraging\npublished datasets from the DESY and SLAC facilities. In our extraction of the\ndeuteron mass radius, we employ a dipole-form scalar gravitational form factor\nto effectively model the $|t|$-dependence of the differential cross sections\nassociated with vector meson photoproductions. Utilizing the vector-meson\ndominance model alongside a low-energy Quantum Chromodynamics (QCD) theorem\nassumption, we derive the deuteron mass radius from the near-threshold\nphotoproduction data of the $\\rho^0$, $\\omega$, and $\\phi$ mesons. The mass\nradii obtained from various datasets demonstrate consistency within the\nstatistical uncertainties, yielding an average value of $2.07 \\pm 0.15$ fm.\nThis precision surpasses previous estimates solely based on the $\\phi$ meson\nphotoproduction data. Our findings provide novel constraints for theoretical\nnuclear structure models and significantly enhance our understanding of the\nmass distribution within the deuteron.","main_category":"hep-ph","categories":"hep-ph,nucl-ex,nucl-th","published":"2025-04-14T09:27:15Z"}
{"aid":"http://arxiv.org/abs/2504.10029v1","title":"Quantum Squeezing Effects in Coupled van der Pol Oscillators","summary":"Achieving synchronized quantum states within the quantum realm is a\nsignificant goal. This regime is characterized by restricted excitation\noccurrences and a highly nonclassical stable state of the self-oscillating\nsystem. However, many existing approaches to observe synchronization in this\nquantum realm face a major challenge: the influence of noise tends to\novershadow the synchronization phenomenon. In coupled van der Pol oscillators,\nsynchronization occurs when a system of two or more oscillators interacts. Our\ninvestigation demonstrates that introducing the squeezing Hamiltonian in two\ncoupled van der Pol oscillators enhances nonclassical effects, increases\nquantum correlations, and improves the robustness of synchronization dynamics.\nThis was evidenced through the analysis of the Wigner function and power\nspectrum, showing significant improvements compared to systems without\nsqueezing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T09:33:05Z"}
{"aid":"http://arxiv.org/abs/2504.10043v1","title":"Instrumenting a Lake as a Wide-Field Gamma-ray Detector","summary":"Ground-level particle detection has recently emerged as an extremely powerful\napproach to TeV-PeV gamma-ray astronomy. The most successful observatories of\nthis type, HAWC and LHAASO, utilise water-Cherenkov based detector units,\nhoused in tanks or buildings. Here we explore the possibility of deploying\nwater-Cherenkov detector units directly in to a natural or artificial lake.\nPossible advantages include reduced cost and improved performance due to better\nshielding. The lake concept has been developed as an option for the future\nSouthern Wide-view Gamma-ray Observatory, and is now under consideration for a\npossible future extension of the observatory, beyond its recently selected land\nsite. We present results from prototypes operated in a custom built facility,\nand concepts for full-scale array deployment and long-term operation.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-14T09:44:13Z"}
{"aid":"http://arxiv.org/abs/2504.10045v1","title":"CHARM: Calibrating Reward Models With Chatbot Arena Scores","summary":"Reward models (RMs) play a crucial role in Reinforcement Learning from Human\nFeedback by serving as proxies for human preferences in aligning large language\nmodels. In this paper, we identify a model preference bias in RMs, where they\nsystematically assign disproportionately high scores to responses from certain\npolicy models. This bias distorts ranking evaluations and leads to unfair\njudgments. To address this issue, we propose a calibration method named CHatbot\nArena calibrated Reward Modeling (CHARM) that leverages Elo scores from the\nChatbot Arena leaderboard to mitigate RM overvaluation. We also introduce a\nMismatch Degree metric to measure this preference bias. Our approach is\ncomputationally efficient, requiring only a small preference dataset for\ncontinued training of the RM. We conduct extensive experiments on reward model\nbenchmarks and human preference alignment. Results demonstrate that our\ncalibrated RMs (1) achieve improved evaluation accuracy on RM-Bench and the\nChat-Hard domain of RewardBench, and (2) exhibit a stronger correlation with\nhuman preferences by producing scores more closely aligned with Elo rankings.\nBy mitigating model preference bias, our method provides a generalizable and\nefficient solution for building fairer and more reliable reward models.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-14T09:51:09Z"}
{"aid":"http://arxiv.org/abs/2504.10095v1","title":"Influence of packing protocol on fractal exponents in dense polydisperse\n  packings","summary":"We study fractal properties of a system of densely and randomly packed disks,\nobeying a power-law distribution of radii, which is generated by using various\nprotocols: Delaunay triangulation (DT) with both zero and periodic boundary\nconditions and the constant pressure protocol with periodic boundary\nconditions. The power-law exponents of the mass-radius relation and structure\nfactor are obtained numerically for various values of the size ratio of the\ndistribution, defined as the largest-to-smallest radius ratio. It is shown that\nthe size ratio is an important control parameter responsible for the\nconsistency of the fractal properties of the system: the greater the ratio, the\nless the finite size effects are pronounced and the better the agreement\nbetween the exponents. For the DT protocol, the exponents of the mass-radius\nrelation, structure factor, and power-law distribution coincide even at\nmoderate values of the size ratio. By contrast, for the constant-pressure\nprotocol, all three exponents are found to be different for both moderate\n(around 300) and large (around 1500) size ratios, which might indicate a biased\nrather than random spatial distribution of the disks. Nevertheless, there is a\ntendency for the exponents to converge as the size ratio increases, suggesting\nthat all the exponents become equal in the limit of infinite size ratio.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T11:01:39Z"}
{"aid":"http://arxiv.org/abs/2504.10098v1","title":"Analyzing reduced density matrices in SU(2) Chern-Simons theory","summary":"We investigate the reduced density matrices obtained for the quantum states\nin the context of 3d Chern-Simons theory with gauge group SU(2) and\nChern-Simons level $k$. We focus on the quantum states associated with the\n$T_{p,p}$ torus link complements, which is a $p$-party pure quantum state. The\nreduced density matrices are obtained by taking the $(1|p-1)$ bi-partition of\nthe total system. We show that the characteristic polynomials of these reduced\ndensity matrices are monic polynomials with rational coefficients.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,quant-ph","published":"2025-04-14T11:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.10100v1","title":"A direct and algebraic characterization of higher-order differential\n  operators","summary":"This paper presents an algebraic approach to characterizing higher-order\ndifferential operators. While the foundational Leibniz rule addresses\nfirst-order derivatives, its extension to higher orders typically involves\nidentities relating multiple distinct operators. In contrast, we introduce a\nnovel operator equation involving only a single $n$\\textsuperscript{th}-order\ndifferential operator. We demonstrate that, under certain mild conditions, this\nequation serves to characterize such operators. Specifically, our results show\nthat these higher-order differential operators can be identified as particular\nsolutions to this single-operator identity. This approach provides a framework\nfor understanding the algebraic structure of higher-order differential\noperators acting on function spaces.","main_category":"math.CA","categories":"math.CA","published":"2025-04-14T11:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.10105v1","title":"Global and Local Mamba Network for Multi-Modality Medical Image\n  Super-Resolution","summary":"Convolutional neural networks and Transformer have made significant\nprogresses in multi-modality medical image super-resolution. However, these\nmethods either have a fixed receptive field for local learning or significant\ncomputational burdens for global learning, limiting the super-resolution\nperformance. To solve this problem, State Space Models, notably Mamba, is\nintroduced to efficiently model long-range dependencies in images with linear\ncomputational complexity. Relying on the Mamba and the fact that low-resolution\nimages rely on global information to compensate for missing details, while\nhigh-resolution reference images need to provide more local details for\naccurate super-resolution, we propose a global and local Mamba network\n(GLMamba) for multi-modality medical image super-resolution. To be specific,\nour GLMamba is a two-branch network equipped with a global Mamba branch and a\nlocal Mamba branch. The global Mamba branch captures long-range relationships\nin low-resolution inputs, and the local Mamba branch focuses more on\nshort-range details in high-resolution reference images. We also use the deform\nblock to adaptively extract features of both branches to enhance the\nrepresentation ability. A modulator is designed to further enhance deformable\nfeatures in both global and local Mamba blocks. To fully integrate the\nreference image for low-resolution image super-resolution, we further develop a\nmulti-modality feature fusion block to adaptively fuse features by considering\nsimilarities, differences, and complementary aspects between modalities. In\naddition, a contrastive edge loss (CELoss) is developed for sufficient\nenhancement of edge textures and contrast in medical images.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:14:24Z"}
{"aid":"http://arxiv.org/abs/2504.10111v1","title":"Preliminary experimental investigation on the interaction of a\n  subaqueous dune like granular structure with a turbulent open channel flow","summary":"We study the interaction of a subaqueous dune like granular structure with a\nturbulent open channel flow experimentally using optical diagnostics in the\nReynolds and Froude parameter space ($7.7{\\times}10^3<Re<3.8{\\times}10^4$,\n$0.1<Fr<0.4$). Interactions between the turbulent flow and the granular\nstructure give rise to transient erosion-deposition dynamics leading to various\ntypes of particle transport. The subaqueous structures in the channel bed\nevolves due to shear-stress-induced erosion, gravity-driven deposition, and\nsubsequent particle transport. We study the centroid motion and the granular\nstructure shape evolution. At lower end of our $Re-Fr$ parameter space, we\nobserve no erosion and the structure remains at rest. At intermediate values of\n$Re$ and $Fr$, we observe very slow erosion and the granular structure moves\nvere slowly as a rigid body without significant shape deformation. Higher\nvalues of $Re$ and $Fr$ causes vortex formation at the upstream of the dune\nresulting in stronger erosion, rapid shape deformation and relatively higher\ntranslation velocity of the centroid.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-14T11:18:18Z"}
{"aid":"http://arxiv.org/abs/2504.10121v1","title":"Impact of rainfall risk on rice production: realized volatility in mean\n  model","summary":"Rural economies are largely dependent upon agriculture, which is greatly\ndetermined by climatic conditions such as rainfall. This study aims to forecast\nagricultural production in Maharashtra, India, which utilises annual data from\nthe year 1962 to 2021. Since rainfall plays a major role with respect to the\ncrop yield, we analyze the impact of rainfall on crop yield using four time\nseries models that includes ARIMA, ARIMAX, GARCH-ARIMA and GARCH-ARIMAX. We\ntake advantage of rainfall as an external regressor to examine if it\ncontributes to the performance of the model. 1-step, 2-step, and 3-step ahead\nforecasts are obtained and the model performance is assessed using MAE and\nRMSE. The models are able to more accurately predict when using rainfall as a\npredictor compared to when solely dependant on historical production trends\n(more improved outcomes are seen in the ARIMAX and GARCH-ARIMAX models). As\nsuch, these findings underscore the need for climate-aware forecasting\ntechniques that provide useful information to policymakers and farmers to aid\nin agricultural planning.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-14T11:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.10124v1","title":"Unravelling the Flow of Information in a Nonequilibrium Process","summary":"Identifying the origin of nonequilibrium characteristics in a generic\ninteracting system having multiple degrees of freedom is a challenging task. In\nthis context, information theoretic measures such as mutual information and\nrelated polymorphs offer valuable insights. Here, we explore these measures in\na minimal experimental model consisting of two hydrodynamically coupled\ncolloidal particles, where a nonequilibrium drive is introduced via an\nexponentially correlated noise acting on one of the particles. We show that the\ninformation-theoretic tools considered enable a systematic, data-driven\ndissection of information flow within the system. These measures allow us to\nidentify the driving node and reconstruct the directional dependencies between\nparticles. Notably, they help explain a recently observed, counterintuitive\ntrend in the dependence of irreversibility on interaction strength under\ncoarse-graining (B. Das et.al., arXiv:2405.00800 (2024)). Finally, our results\ndemonstrate how directional information measures can uncover the hidden\nstructure of nonequilibrium dynamics and provide a framework for studying\nsimilar effects in more complex systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-14T11:32:19Z"}
{"aid":"http://arxiv.org/abs/2504.10137v1","title":"Multi-Target Position Error Bound and Power Allocation Scheme for\n  Cell-Free mMIMO-OTFS ISAC Systems","summary":"This paper investigates multi-target position estimation in cell-free massive\nmultiple-input multiple-output (CF mMIMO) architectures, where orthogonal time\nfrequency and space (OTFS) is used as an integrated sensing and communication\n(ISAC) signal. Closed-form expressions for the Cram\\'{e}r-Rao lower bound and\nthe positioning error bound (PEB) in multi-target position estimation are\nderived, providing quantitative evaluations of sensing performance. To enhance\nthe overall performance of the ISAC system, a power allocation algorithm is\ndeveloped to maximize the minimum user communication\nsignal-to-interference-plus-noise ratio while ensuring a specified sensing PEB\nrequirement. The results validate the proposed PEB expression and its\napproximation, clearly illustrating the coordination gain enabled by ISAC.\nFurther, the superiority of using the multi-static CF mMIMO architecture over\ntraditional cellular ISAC is demonstrated, and the advantages of OTFS signals\nin high-mobility scenarios are highlighted.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-14T11:48:15Z"}
{"aid":"http://arxiv.org/abs/2504.10142v1","title":"Band width estimates with lower spectral curvature bounds","summary":"In this work, we use the warped \\( \\mu \\)-bubble method to study the\nconsequences of a spectral curvature bound. In particular, with a lower\nspectral Ricci curvature bound and lower spectral scalar curvature bound, we\nshow that the band width of a torical band is bounded above. We also obtain\nsome rigidity results.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T11:54:13Z"}
{"aid":"http://arxiv.org/abs/2504.10144v1","title":"Evidence for electron spin-torsion coupling in the rotational spectrum\n  of the CH$_3$CO radical","summary":"Open-shell non-rigid molecular systems exhibiting an internal rotation are\nlikely candidates for a coupling between the spin angular momentum of the\nunpaired electron and the torsional motion. This electron spin-torsion coupling\nlacked both an experimental validation and a theoretical modeling. Here, the\nfirst experimental observation of the electron spin-torsion coupling is\nreported analyzing the pure rotational spectrum at millimeter wavelengths of\nthe CH$_3$CO radical, a $^2\\Sigma$ open-shell molecule displaying an internal\nrotation of its methyl group. To account for this coupling, a specific\nHamiltonian incorporating the rotational, torsional, and electronic degrees of\nfreedom is developed and allows us to reproduce the experimental spectrum. The\npresent demonstration of the electron spin-torsion coupling will undoubtedly be\nkey to future investigations of large open-shell molecules exhibiting a complex\ninternal dynamics.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-14T11:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.10148v1","title":"Hierarchical and Step-Layer-Wise Tuning of Attention Specialty for\n  Multi-Instance Synthesis in Diffusion Transformers","summary":"Text-to-image (T2I) generation models often struggle with multi-instance\nsynthesis (MIS), where they must accurately depict multiple distinct instances\nin a single image based on complex prompts detailing individual features.\nTraditional MIS control methods for UNet architectures like SD v1.5/SDXL fail\nto adapt to DiT-based models like FLUX and SD v3.5, which rely on integrated\nattention between image and text tokens rather than text-image cross-attention.\nTo enhance MIS in DiT, we first analyze the mixed attention mechanism in DiT.\nOur token-wise and layer-wise analysis of attention maps reveals a hierarchical\nresponse structure: instance tokens dominate early layers, background tokens in\nmiddle layers, and attribute tokens in later layers. Building on this\nobservation, we propose a training-free approach for enhancing MIS in DiT-based\nmodels with hierarchical and step-layer-wise attention specialty tuning (AST).\nAST amplifies key regions while suppressing irrelevant areas in distinct\nattention maps across layers and steps, guided by the hierarchical structure.\nThis optimizes multimodal interactions by hierarchically decoupling the complex\nprompts with instance-based sketches. We evaluate our approach using upgraded\nsketch-based layouts for the T2I-CompBench and customized complex scenes. Both\nquantitative and qualitative results confirm our method enhances complex layout\ngeneration, ensuring precise instance placement and attribute representation in\nMIS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.10158v1","title":"COUNTS: Benchmarking Object Detectors and Multimodal Large Language\n  Models under Distribution Shifts","summary":"Current object detectors often suffer significant perfor-mance degradation in\nreal-world applications when encountering distributional shifts. Consequently,\nthe out-of-distribution (OOD) generalization capability of object detectors has\ngarnered increasing attention from researchers. Despite this growing interest,\nthere remains a lack of a large-scale, comprehensive dataset and evaluation\nbenchmark with fine-grained annotations tailored to assess the OOD\ngeneralization on more intricate tasks like object detection and grounding. To\naddress this gap, we introduce COUNTS, a large-scale OOD dataset with\nobject-level annotations. COUNTS encompasses 14 natural distributional shifts,\nover 222K samples, and more than 1,196K labeled bounding boxes. Leveraging\nCOUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed\nto comprehensively evaluate the OOD generalization capabilities of object\ndetectors by utilizing controlled distribution shifts between training and\ntesting data. OODG, on the other hand, aims to assess the OOD generalization of\ngrounding abilities in multimodal large language models (MLLMs). Our findings\nreveal that, while large models and extensive pre-training data substantially\nen hance performance in in-distribution (IID) scenarios, significant\nlimitations and opportunities for improvement persist in OOD contexts for both\nobject detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o\nand Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope\nCOUNTS facilitates advancements in the development and assessment of robust\nobject detectors and MLLMs capable of maintaining high performance under\ndistributional shifts.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T12:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.10159v1","title":"Monadic type-and-effect soundness","summary":"We introduce the abstract notions of \"monadic operational semantics\", a\nsmall-step semantics where computational effects are modularly modeled by a\nmonad, and \"type-and-effect system\", including \"effect types\" whose\ninterpretation lifts well-typedness to its monadic version. In this\nmeta-theory, as usually done in the non-monadic case, we can express progress\nand subject reduction properties and provide a proof, given once and for all,\nthat they imply soundness. The approach is illustrated on a lambda calculus\nwith generic effects. We equip the calculus with an expressive type-and-effect\nsystem, and provide proofs of progress and subject reduction which are\nparametric on the interpretation of effect types. In this way, we obtain as\ninstances many significant examples, such as checking exceptions,\npreventing/limiting non-determinism, constraining order/fairness of outputs on\ndifferent locations. We also provide an extension with constructs to raise and\nhandle computational effects, which can be instantiated to model different\npolicies.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-14T12:13:44Z"}
{"aid":"http://arxiv.org/abs/2504.10172v1","title":"Characterising quantum measurement through environmental stochastic\n  entropy production in a two spin 1/2 system","summary":"Quantum state diffusion is a framework within which measurement may be\ndescribed as the continuous and gradual collapse of a quantum system to an\neigenstate as a result of interaction with its environment. The irreversible\nnature of the quantum trajectories that arise may be characterised by the\nenvironmental stochastic entropy production associated with the measurement. We\nconsider a system of two spin 1/2 particles undergoing either single particle\nmeasurements or measurements of the total z-spin component S_{z}. The mean\nasymptotic rates of environmental stochastic entropy production associated with\ncollapse can depend on the eigenstate of S_{z} selected, and on the initial\nstate of the system, offering an additional avenue for characterising quantum\nmeasurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T12:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.10193v1","title":"A Piece of QAICCC: Towards a Countermeasure Against Crosstalk Attacks in\n  Quantum Servers","summary":"Quantum computing, while allowing for processing information exponentially\nfaster than classical computing, requires computations to be delegated to\nquantum servers, which makes security threats possible. For instance, previous\nstudies demonstrated that crosstalk between attacker and victim's qubits can be\nexploited to mount security attacks.\n  In this idea paper, we propose the QAICCC approach to allocate qubits between\nusers to minimize inter-circuit crosstalk and, thus, possibilities for attacks,\nwhile maximizing qubit usage. Also, combined with existing techniques, QAICCC\naims to reduce intra-circuit noise. Thus, QAICCC will support quantum computing\nadoption by securing the usage of quantum servers by a large number of actors.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T12:55:07Z"}
{"aid":"http://arxiv.org/abs/2504.10197v1","title":"Comparison of smoothening flows for the topological charge in QCD-like\n  theories","summary":"We investigate properties of the topological charge for several SU(NC) gauge\nfield ensembles for NC = 4, 5, 6 with a single fermion in the two-index\nanti-symmetric representation, covering multiple lattice spacings at otherwise\napproximately constant physical parameters. Comparing the topological charge\ndefined by the Wilson flow and the over-improved DBW2 flow we find that already\nat small flow times the latter stabilises on discrete values. We provide\nevidence that as the lattice spacing is lowered the Wilson flow also separates\ninto discrete sectors at earlier flow times. Adopting the DWB2 definition in\nthe remainder of the analysis, we do not see any evidence of fractional\ntopological charges, which could in principle appear at finite lattice spacing.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-14T13:02:50Z"}
{"aid":"http://arxiv.org/abs/2504.10203v1","title":"A moving horizon estimator for aquifer thermal energy storages","summary":"Aquifer thermal energy storages (ATES) represent groundwater saturated\naquifers that store thermal energy in the form of heated or cooled groundwater.\nCombining two ATES, one can harness excess thermal energy from summer (heat)\nand winter (cold) to support the building's heating, ventilation, and air\nconditioning (HVAC) technology. In general, a dynamic operation of ATES\nthroughout the year is beneficial to avoid using fossil fuel-based HVAC\ntechnology and maximize the ``green use'' of ATES. Model predictive control\n(MPC) with an appropriate system model may become a crucial control approach\nfor ATES systems. Consequently, the MPC model should reflect spatial\ntemperature profiles around ATES' boreholes to predict extracted groundwater\ntemperatures accurately. However, meaningful predictions require the estimation\nof the current state of the system, as measurements are usually only at the\nborehole of the ATES. In control, this is often realized by model-based\nobservers. Still, observing the state of an ATES system is non-trivial, since\nthe model is typically hybrid. We show how to exploit the specific structure of\nthe hybrid ATES model and design an easy-to-solve moving horizon estimator\nbased on a quadratic program.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T13:11:34Z"}
{"aid":"http://arxiv.org/abs/2504.10205v1","title":"Dual Theory of Turbulent Mixing","summary":"We present an exact analytic solution for incompressible turbulent mixing\ndescribed by 3D NS equations, with a passive scalar (concentration,\ntemperature, or other scalar field) driven by the turbulent velocity field.\nUsing our recent solution of decaying turbulence in terms of the Euler\nensemble, we represent the correlation functions of a passive scalar as\nstatistical averages over this ensemble. The statistical limit, corresponding\nto decaying turbulence, can be computed in quadrature. We find the decay\nspectrum and the scaling functions of the pair correlation and match them with\nphysical and real experiments.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,hep-th,nlin.SI","published":"2025-04-14T13:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.10225v1","title":"A Quasi-Steady-State Black Box Simulation Approach for the Generation of\n  g-g-g-v Diagrams","summary":"The classical g-g diagram, representing the achievable acceleration space for\na vehicle, is commonly used as a constraint in trajectory planning and control\ndue to its computational simplicity. To address non-planar road geometries,\nthis concept can be extended to incorporate g-g constraints as a function of\nvehicle speed and vertical acceleration, commonly referred to as g-g-g-v\ndiagrams. However, the estimation of g-g-g-v diagrams is an open problem.\nExisting simulation-based approaches struggle to isolate non-transient,\nopen-loop stable states across all combinations of speed and acceleration,\nwhile optimization-based methods often require simplified vehicle equations and\nhave potential convergence issues. In this paper, we present a novel,\nopen-source, quasi-steady-state black box simulation approach that applies a\nvirtual inertial force in the longitudinal direction. The method emulates the\nload conditions associated with a specified longitudinal acceleration while\nmaintaining constant vehicle speed, enabling open-loop steering ramps in a\npurely QSS manner. Appropriate regulation of the ramp steer rate inherently\nmitigates transient vehicle dynamics when determining the maximum feasible\nlateral acceleration. Moreover, treating the vehicle model as a black box\neliminates model mismatch issues, allowing the use of high-fidelity or\nproprietary vehicle dynamics models typically unsuited for optimization\napproaches. An open-source version of the proposed method is available at:\nhttps://github.com/TUM-AVS/GGGVDiagrams","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T13:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.10255v1","title":"Dissipation-Induced Threshold on Integrability Footprints","summary":"The presence of a dissipative environment disrupts the unitary spectrum of\ndynamical quantum maps. Nevertheless, key features of the underlying unitary\ndynamics -- such as their integrable or chaotic nature -- are not immediately\nerased by dissipation. To investigate this, we model dissipation as a convex\ncombination of a unitary evolution and a random Kraus map, and study how\nsignatures of integrability fade as dissipation strength increases. Our\nanalysis shows that in the weakly dissipative regime, the complex eigenvalue\nspectrum organizes into well-defined, high-density clusters. We estimate the\ncritical dissipation threshold beyond which these clusters disappear, rendering\nthe dynamics indistinguishable from chaotic evolution. This threshold depends\nonly on the number of spectral clusters and the rank of the random Kraus\noperator. To characterize this transition, we introduce the eigenvalue angular\nvelocity as a diagnostic of integrability loss. We illustrate our findings\nthrough several integrable quantum circuits, including the dissipative quantum\nFourier transform. Our results provide a quantitative picture of how noise\ngradually erases the footprints of integrability in open quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-14T14:16:37Z"}
{"aid":"http://arxiv.org/abs/2504.10256v1","title":"Compressible fluids excited by space-dependent transport noise","summary":"We study the compressible Navier-Stokes system driven by physically relevant\ntransport noise, where the noise influences both the continuity and momentum\nequations. Our approach is based on transforming the system into a partial\ndifferential equation with random, time- and space-dependent coefficients. A\nkey challenge arises from the fact that these coefficients are\nnon-differentiable in time, rendering standard compactness arguments for the\nidentification of the pressure inapplicable. To overcome this difficulty, we\ndevelop a novel multi-layer approximation scheme and introduce a precise\nlocalization strategy with respect to both the sample space and time variable.\nThe limit pressure is then identified via the corresponding effective viscous\nflux identity. By means of stochastic compactness methods, particularly\nSkorokhod's representation theorem and its generalization by Jakubowski, we\nensure the progressive measurability required to return to the original system.\nOur results broaden the applicability of transport noise models in fluid\ndynamics and offer new insights into the interaction between stochastic effects\nand compressibility.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T14:17:25Z"}
{"aid":"http://arxiv.org/abs/2504.10267v1","title":"Trade-offs in Privacy-Preserving Eye Tracking through Iris Obfuscation:\n  A Benchmarking Study","summary":"Recent developments in hardware, computer graphics, and AI may soon enable\nAR/VR head-mounted displays (HMDs) to become everyday devices like smartphones\nand tablets. Eye trackers within HMDs provide a special opportunity for such\nsetups as it is possible to facilitate gaze-based research and interaction.\nHowever, estimating users' gaze information often requires raw eye images and\nvideos that contain iris textures, which are considered a gold standard\nbiometric for user authentication, and this raises privacy concerns. Previous\nresearch in the eye-tracking community focused on obfuscating iris textures\nwhile keeping utility tasks such as gaze estimation accurate. Despite these\nattempts, there is no comprehensive benchmark that evaluates state-of-the-art\napproaches. Considering all, in this paper, we benchmark blurring, noising,\ndownsampling, rubber sheet model, and iris style transfer to obfuscate user\nidentity, and compare their impact on image quality, privacy, utility, and risk\nof imposter attack on two datasets. We use eye segmentation and gaze estimation\nas utility tasks, and reduction in iris recognition accuracy as a measure of\nprivacy protection, and false acceptance rate to estimate risk of attack. Our\nexperiments show that canonical image processing methods like blurring and\nnoising cause a marginal impact on deep learning-based tasks. While\ndownsampling, rubber sheet model, and iris style transfer are effective in\nhiding user identifiers, iris style transfer, with higher computation cost,\noutperforms others in both utility tasks, and is more resilient against spoof\nattacks. Our analyses indicate that there is no universal optimal approach to\nbalance privacy, utility, and computation burden. Therefore, we recommend\npractitioners consider the strengths and weaknesses of each approach, and\npossible combinations of those to reach an optimal privacy-utility trade-off.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T14:29:38Z"}
{"aid":"http://arxiv.org/abs/2504.10275v1","title":"LMFormer: Lane based Motion Prediction Transformer","summary":"Motion prediction plays an important role in autonomous driving. This study\npresents LMFormer, a lane-aware transformer network for trajectory prediction\ntasks. In contrast to previous studies, our work provides a simple mechanism to\ndynamically prioritize the lanes and shows that such a mechanism introduces\nexplainability into the learning behavior of the network. Additionally,\nLMFormer uses the lane connection information at intersections, lane merges,\nand lane splits, in order to learn long-range dependency in lane structure.\nMoreover, we also address the issue of refining the predicted trajectories and\npropose an efficient method for iterative refinement through stacked\ntransformer layers. For benchmarking, we evaluate LMFormer on the nuScenes\ndataset and demonstrate that it achieves SOTA performance across multiple\nmetrics. Furthermore, the Deep Scenario dataset is used to not only illustrate\ncross-dataset network performance but also the unification capabilities of\nLMFormer to train on multiple datasets and achieve better performance.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T14:43:46Z"}
{"aid":"http://arxiv.org/abs/2504.10288v1","title":"Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost\n  imaging","summary":"We present a new self-supervised deep-learning-based Ghost Imaging (GI)\nreconstruction method, which provides unparalleled reconstruction performance\nfor noisy acquisitions among unsupervised methods. We present the supporting\nmathematical framework and results from theoretical and real data use cases.\nSelf-supervision removes the need for clean reference data while offering\nstrong noise reduction. This provides the necessary tools for addressing\nsignal-to-noise ratio concerns for GI acquisitions in emerging and cutting-edge\nlow-light GI scenarios. Notable examples include micro- and nano-scale x-ray\nemission imaging, e.g., x-ray fluorescence imaging of dose-sensitive samples.\nTheir applications include in-vivo and in-operando case studies for biological\nsamples and batteries.","main_category":"cs.CV","categories":"cs.CV,cs.LG,physics.data-an","published":"2025-04-14T14:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.10307v1","title":"CROSSAN: Towards Efficient and Effective Adaptation of Multiple\n  Multimodal Foundation Models for Sequential Recommendation","summary":"Multimodal Foundation Models (MFMs) excel at representing diverse raw\nmodalities (e.g., text, images, audio, videos, etc.). As recommender systems\nincreasingly incorporate these modalities, leveraging MFMs to generate better\nrepresentations has great potential. However, their application in sequential\nrecommendation remains largely unexplored. This is primarily because mainstream\nadaptation methods, such as Fine-Tuning and even Parameter-Efficient\nFine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur high\ncomputational costs, especially when integrating multiple modality encoders,\nthus hindering research progress. As a result, it remains unclear whether we\ncan efficiently and effectively adapt multiple (>2) MFMs for the sequential\nrecommendation task.\n  To address this, we propose a plug-and-play Cross-modal Side Adapter Network\n(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSAN\nachieves high efficiency while enabling cross-modal learning across diverse\nmodalities. To optimize the final stage of multimodal fusion across diverse\nmodalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.\nCROSSAN achieves superior performance on the public datasets for adapting four\nfoundation models with raw modalities. Performance consistently improves as\nmore MFMs are adapted. We will release our code and datasets to facilitate\nfuture research.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T15:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.10318v1","title":"Shield Bash: Abusing Defensive Coherence State Retrieval to Break Timing\n  Obfuscation","summary":"Microarchitectural attacks are a significant concern, leading to many\nhardware-based defense proposals. However, different defenses target different\nclasses of attacks, and their impact on each other has not been fully\nconsidered. To raise awareness of this problem, we study an interaction between\ntwo state-of-the art defenses in this paper, timing obfuscations of remote\ncache lines (TORC) and delaying speculative changes to remote cache lines\n(DSRC). TORC mitigates cache-hit based attacks and DSRC mitigates speculative\ncoherence state change attacks.\n  We observe that DSRC enables coherence information to be retrieved into the\nprocessor core, where it is out of the reach of timing obfuscations to protect.\nThis creates an unforeseen consequence that redo operations can be triggered\nwithin the core to detect the presence or absence of remote cache lines, which\nconstitutes a security vulnerability. We demonstrate that a new covert channel\nattack is possible using this vulnerability. We propose two ways to mitigate\nthe attack, whose performance varies depending on an application's cache usage.\nOne way is to never send remote exclusive coherence state (E) information to\nthe core even if it is created. The other way is to never create a remote E\nstate, which is responsible for triggering redos.\n  We demonstrate the timing difference caused by this microarchitectural\ndefense assumption violation using GEM5 simulations. Performance evaluation on\nSPECrate 2017 and PARSEC benchmarks of the two fixes show less than 32\\%\naverage overhead across both sets of benchmarks. The repair which prevented the\ncreation of remote E state had less than 2.8% average overhead.","main_category":"cs.CR","categories":"cs.CR,cs.AR","published":"2025-04-14T15:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.10324v1","title":"Rayleigh-BÃ©nard-Marangoni convection in binary fluids - Effect of\n  miscibility on oscillatory mode","summary":"The pair of fluids, FC72- 1cSt silicone oil, exhibiting temperature-sensitive\nmiscibility gap is considered in this study to investigate the classical\nRayleigh-B\\'enard-Marangoni (RBM) instability. The system of fluids is\nconsidered at distinct temperatures to elucidate the effect of the degree of\nmiscibility between the two fluids. We employ a modified phase- field model to\ntrack the evolution of the RBM instability as the temperature of the system is\nvaried. The proposed model correctly initializes the concentration profile and\nalso properly leads to a miscibility-dependent surface tension. A\nspectral-collocation-based method is employed to solve the linearized governing\nequations that help investigate the onset characteristics of the convection,\ni.e., both the critical values and the mode of convection onset, which could be\neither oscillatory or stationary. The results reveal the dependence of the\nwindow of oscillatory convection on the degree of miscibility between the two\nfluids. The coupling between the Korteweg stresses and the degree of\nmiscibility governs the thermal energy required to provoke the system into the\nconvective state. The onset of RBM flow is analyzed parametrically, with the\nsuccessive rise in the strength of the Marangoni component.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-14T15:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.10332v1","title":"MIPS is a Maxwell fluid with an extended and non-monotonic crossover","summary":"Understanding the mechanical properties of active suspensions is crucial for\ntheir potential applications in materials engineering. Among the various\nphenomena in active matter that have no analogue in equilibrium systems,\nmotility-induced phase separation (MIPS) in active colloidal suspensions is one\nof the most extensively studied. However, the mechanical properties of this\nfundamental active state of matter remain poorly understood. This study\ninvestigates the rheology of a suspension of active colloidal particles under\nconstant and oscillatory shear. Systems consisting of pseudo-hard active\nBrownian particles exhibiting co-existence of dense and dilute phases behave as\na viscoelastic Maxwell fluid at low and high frequencies, displaying\nexclusively shear thinning across a wide range of densities and activities.\nRemarkably, the cross-over point between the storage and loss moduli is\nnon-monotonic, rising with activity before the MIPS transition but falling with\nactivity after the transition, revealing the subtleties of how active forces\nand intrinsically out-of-equilibrium phases affect the mechanical properties of\nthese systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T15:40:17Z"}
{"aid":"http://arxiv.org/abs/2504.10333v1","title":"The Pierre Auger Observatory: Results and Prospects","summary":"The Pierre Auger Observatory advances the study of ultra-high-energy cosmic\nrays through a hybrid system of surface and fluorescence detectors. This paper\npresents recent results, including refined spectrum measurements, anisotropy\nevidence, and new insights into cosmic-ray composition. Studies at energies\nbeyond terrestrial accelerators reveal implications for particle physics. The\nAugerPrime upgrade will further enhance particle identification and extend the\nsensitivity to photons and neutrinos, broadening the Observatory's capability\nto explore cosmic-ray sources and propagation, paving the way for new\ndiscoveries.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.IM,hep-ex","published":"2025-04-14T15:40:48Z"}
{"aid":"http://arxiv.org/abs/2504.10347v1","title":"Uncertain Location Transmitter and UAV-Aided Warden Based LEO Satellite\n  Covert Communication Systems","summary":"We propose a novel covert communication system in which a ground user, Alice,\ntransmits unauthorized message fragments to Bob, a low-Earth orbit satellite\n(LEO), and an unmanned aerial vehicle (UAV) warden (Willie) attempts to detect\nthese transmissions. The key contribution is modeling a scenario where Alice\nand Willie are unaware of each other's exact locations and move randomly within\na specific area. Alice utilizes environmental obstructions to avoid detection\nand only transmits when the satellite is directly overhead. LEO satellite\ntechnology allows users to avoid transmitting messages near a base station. We\nintroduce two key performance metrics: catch probability (Willie detects and\nlocates Alice during a message chunk transmission) and overall catch\nprobability over multiple message chunks. We analyze how two parameters impact\nthese metrics: 1) the size of the detection window and 2) the number of message\nchunks. The paper proposes two algorithms to optimize these parameters. The\nsimulation results show that the algorithms effectively reduce the detection\nrisks. This work advances the understanding of covert communication under\nmobility and uncertainty in satellite-aided systems.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T15:55:31Z"}
{"aid":"http://arxiv.org/abs/2504.10356v1","title":"MultiLoKo: a multilingual local knowledge benchmark for LLMs spanning 31\n  languages","summary":"We present MultiLoKo, a new benchmark for evaluating multilinguality in LLMs\ncovering 31 languages. MultiLoKo consists of three partitions: a main partition\nconsisting of 500 questions per language, separately sourced to be locally\nrelevant to the specific language, and two translated partitions, containing\nhuman-authored translations from 30 non-English languages to English and vice\nversa. For comparison, we also release corresponding machine-authored\ntranslations. The data is equally distributed over two splits: a dev split and\na blind, out-of-distribution test split. MultiLoKo can be used to study a\nvariety of questions regarding the multilinguality of LLMs as well as\nmeta-questions about multilingual benchmark creation. We compute MultiLoKo\nscores for 11 base and chat models marketed to be multilingual and study their\naverage performance, their performance parity across languages, how much their\nability to answer questions depends on the question language, and which\nlanguages are most difficult. None of the models we studied performs well on\nMultiLoKo, as indicated by low average scores as well as large differences\nbetween the best and worst scoring languages. Furthermore, we find a\nsubstantial effect of the question language, indicating sub-optimal knowledge\ntransfer between languages. Lastly, we find that using local vs\nEnglish-translated data can result in differences more than 20 points for the\nbest performing models, drastically change the estimated difficulty of some\nlanguages. For using machines instead of human translations, we find a weaker\neffect on ordering of language difficulty, a larger difference in model\nrankings, and a substantial drop in estimated performance for all models.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T16:05:59Z"}
{"aid":"http://arxiv.org/abs/2504.10368v1","title":"S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability\n  of Large Reasoning Models","summary":"We introduce S1-Bench, a novel benchmark designed to evaluate Large Reasoning\nModels' (LRMs) performance on simple tasks that favor intuitive system 1\nthinking rather than deliberative system 2 reasoning. While LRMs have achieved\nsignificant breakthroughs in complex reasoning tasks through explicit chains of\nthought, their reliance on deep analytical thinking may limit their system 1\nthinking capabilities. Moreover, a lack of benchmark currently exists to\nevaluate LRMs' performance in tasks that require such capabilities. To fill\nthis gap, S1-Bench presents a set of simple, diverse, and naturally clear\nquestions across multiple domains and languages, specifically designed to\nassess LRMs' performance in such tasks. Our comprehensive evaluation of 22 LRMs\nreveals significant lower efficiency tendencies, with outputs averaging 15.5\ntimes longer than those of traditional small LLMs. Additionally, LRMs often\nidentify correct answers early but continue unnecessary deliberation, with some\nmodels even producing numerous errors. These findings highlight the rigid\nreasoning patterns of current LRMs and underscore the substantial development\nneeded to achieve balanced dual-system thinking capabilities that can adapt\nappropriately to task complexity.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T16:13:23Z"}
{"aid":"http://arxiv.org/abs/2504.10374v1","title":"Ctrl-Z: Controlling AI Agents via Resampling","summary":"Control evaluations measure whether monitoring and security protocols for AI\nsystems prevent intentionally subversive AI models from causing harm. Our work\npresents the first control evaluation performed in an agent environment. We\nconstruct BashBench, a dataset of 257 challenging multi-step system\nadministration tasks, and evaluate whether various safety measures can prevent\nan adversarially constructed AI agent from covertly downloading and executing\nmalicious code in this environment. This multi-step setting introduces new\nattack and defense dynamics, which we investigate in order to design novel\ncontrol protocols that prevent safety failures without hindering the ability of\nnon-malicious agents to perform useful work. We introduce a class of control\nprotocols called resample protocols that dynamically take additional samples of\ncertain actions. We find these protocols significantly improve on existing\ntechniques by selectively blocking the AI agent from executing suspicious code\nand incriminating the agent by generating additional examples of dangerous\nbehavior. We measure the tradeoff between attack prevention and usefulness; our\nbest protocol combines resampling with analysis of previous steps, reducing the\nsuccess rate of attacks from 58% to 7% at a 5% cost to the performance of a\nnon-malicious agent.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T16:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.10376v1","title":"Tumor-immune cell interactions by a fully parabolic chemotaxis model\n  with logistic source","summary":"This work studies the existence of classical solutions to a class of\nchemotaxis systems reading\n  \\[\\begin{cases}\n  u_t = \\Delta u-\\chi \\nabla\\cdot(u \\nabla v) + \\mu_1 u^k -\\mu_2 u^{k+1}, &\n\\text{in} \\; \\Omega\\times(0,T_{\\text{max}}), \\\\\n  v_t= \\Delta v+\\alpha w-\\beta v-\\gamma u v, & \\text{in} \\;\n\\Omega\\times(0,T_{\\text{max}}), \\\\\n  w_t= \\Delta w-\\delta u w+ \\mu_3 w(1-w), & \\text{in} \\;\n\\Omega\\times(0,T_{\\text{max}}), \\\\\n  \\frac{\\partial u}{\\partial\\nu}=\\frac{\\partial v}{\\partial\\nu}=\\frac{\\partial\nw}{\\partial\\nu}=0, & \\text{on} \\; \\partial\\Omega\\times(0,T_{\\text{max}}), \\\\\n  u(x,0)=u_0(x), \\quad v(x,0)= v_0(x), \\quad w(x,0)= w_0(x), &\nx\\in\\overline{\\Omega},\n  \\end{cases}\\] that model interactions between tumor (i.e., $w$) and immune\ncells (i.e., $u$) with a logistic-type source term $\\mu_1 u^k - \\mu_2 u^{k+1}$,\n$k\\geq1$, also in presence of a chemical signal (i.e., $v$). The model\nparameters $\\chi, \\mu_1,\\mu_2, \\mu_3, \\alpha, \\beta, \\gamma$, and $\\delta$ are\nall positive. The value $T_{\\text{max}}$ indicates the maximum instant of time\nup to which solutions are defined. Our focus is on examining the global\nexistence in a bounded domain $\\Omega\\subset \\mathbb{R}^n, n \\geq 3$, under\nNeumann boundary conditions. We distinguish between two scenarios: $k>1$ and\n$k=1$. The first case allows to prove boundedness under smaller assumptions\nrelying only on the model parameters instead of on the initial data, while the\nsecond case requires an extra condition relating the parameters $\\chi, \\mu_2$,\n$n$, and the initial data $\\lVert v_0 \\rVert_{L^\\infty(\\Omega)}$. This model\ncan be seen as an extension of those previously examined in [11] and [4], being\nthe former a system with only two equations and the latter the same model\nwithout logistic.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:24:04Z"}
{"aid":"http://arxiv.org/abs/2504.10388v1","title":"Inferring genotype-phenotype maps using attention models","summary":"Predicting phenotype from genotype is a central challenge in genetics.\nTraditional approaches in quantitative genetics typically analyze this problem\nusing methods based on linear regression. These methods generally assume that\nthe genetic architecture of complex traits can be parameterized in terms of an\nadditive model, where the effects of loci are independent, plus (in some cases)\npairwise epistatic interactions between loci. However, these models struggle to\nanalyze more complex patterns of epistasis or subtle gene-environment\ninteractions. Recent advances in machine learning, particularly attention-based\nmodels, offer a promising alternative. Initially developed for natural language\nprocessing, attention-based models excel at capturing context-dependent\ninteractions and have shown exceptional performance in predicting protein\nstructure and function. Here, we apply attention-based models to quantitative\ngenetics. We analyze the performance of this attention-based approach in\npredicting phenotype from genotype using simulated data across a range of\nmodels with increasing epistatic complexity, and using experimental data from a\nrecent quantitative trait locus mapping study in budding yeast. We find that\nour model demonstrates superior out-of-sample predictions in epistatic regimes\ncompared to standard methods. We also explore a more general multi-environment\nattention-based model to jointly analyze genotype-phenotype maps across\nmultiple environments and show that such architectures can be used for\n\"transfer learning\" - predicting phenotypes in novel environments with limited\ntraining data.","main_category":"q-bio.GN","categories":"q-bio.GN,cs.LG,q-bio.PE","published":"2025-04-14T16:32:17Z"}
{"aid":"http://arxiv.org/abs/2504.10398v1","title":"How well can we unravel the accreted constituents of the Milky Way\n  stellar halo? A test on cosmological hydrodynamical simulations","summary":"Context. One of the primary goals of Galactic Archaeology is to reconstruct\nthe Milky Way's accretion history. To achieve this, significant efforts have\nbeen dedicated to identifying signatures of past accretion events. In\nparticular, the study of integrals-of-motion (IoM) space has proven to be\nhighly insightful for uncovering these ancient mergers and understanding their\nimpact on the Galaxy's evolution.\n  Aims. This paper evaluates the effectiveness of a state-of-the-art method for\ndetecting debris from accreted galaxies, by testing it on four Milky Way-like\ngalaxies from the Auriga suite of cosmological magneto-hydrodynamical\nsimulations.\n  Methods. We employ the innovative method from L\\\"ovdal et al. (2022) to\nidentify substructures in the integrals-of-motion space within the local\nstellar halos of the four simulated galaxies. This approach enables us to\nevaluate the method's performance by comparing the properties of the identified\nclusters with the known populations of accreted galaxies in the simulations.\nAdditionally, we investigate whether incorporating chemical abundances and\nstellar age information can help to link distinct structures originating from\nthe same accretion event.\n  Results. This method is very effective in detecting debris from accretion\nevents that occur less than 6-7 Gyr ago but struggles to detect most of the\ndebris from older accretion. Furthermore, most of the detected structures\nsuffer from significant contamination by in-situ stars. Our results also show\nthat the method may also generate artificial detections.\n  Conclusions. Our work show that the Milky Way's accretion history remains\nuncertain, and question the reality of some detected structures in the Solar\nvicinity.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-14T16:48:55Z"}
{"aid":"http://arxiv.org/abs/2504.10399v1","title":"Unique Decoding of Reed-Solomon and Related Codes for Semi-Adversarial\n  Errors","summary":"For over a quarter century, the Guruswami-Sudan algorithm has served as the\nstate-of-the-art for list-decoding Reed-Solomon (RS) codes up to the Johnson\nbound against adversarial errors. However, some recent structural results on\nthe combinatorial list decoding of randomly punctured Reed-Solomon codes\nsuggest that Johnson bound can likely be broken for some subclasses of RS\ncodes. Motivated by these results, we seek to make traction on understanding\nadversarial decoding by considering a new model: semi-adversarial errors. This\nerror model bridges between fully random errors and fully adversarial errors by\nallowing some symbols of a message to be corrupted by an adversary while others\nare replaced with uniformly random symbols.\n  As our main quest, we seek to understand optimal efficient unique decoding\nalgorithms in the semi-adversarial model. In particular, we revisit some\nclassical results on decoding interleaved Reed-Solomon codes (aka subfield\nevaluation RS codes) in the random error model by Bleichenbacher-Kiayias-Yung\n(BKY) and work to improve and extend their analysis. First, we give an improved\nimplementation and analysis of the BKY algorithm for interleaved Reed-Solomon\ncodes in the semi-adversarial model. In particular, our algorithm runs in\nnear-linear time, and for most mixtures of random and adversarial errors, our\nanalysis matches the information-theoretic optimum.\n  Moreover, inspired by the BKY algorithm, we use a novel interpolation to\nextend our approach to the settings of folded Reed-Solomon codes, resulting in\nfast algorithms for unique decoding against semi-adversarial errors. A\nparticular advantage of our near-linear time algorithm over state-of-the-art\ndecoding algorithms for adversarial errors is that its running time depends\nonly on a polynomial function of the folding parameter rather than on an\nexponential function.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-14T16:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.10411v1","title":"FPGA-Optimized Hardware Accelerator for Fast Fourier Transform and\n  Singular Value Decomposition in AI","summary":"This research introduces an FPGA-based hardware accelerator to optimize the\nSingular Value Decomposition (SVD) and Fast Fourier transform (FFT) operations\nin AI models. The proposed design aims to improve processing speed and reduce\ncomputational latency. Through experiments, we validate the performance\nbenefits of the hardware accelerator and show how well it handles FFT and SVD\noperations. With its strong security and durability, the accelerator design\nachieves significant speedups over software implementations, thanks to its\nmodules for data flow control, watermark embedding, FFT, and SVD.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-14T16:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.10423v1","title":"Overcoming light scattering with high optical nonlinearity","summary":"Achieving high-resolution optical imaging deep within heterogeneous and\nscattering media remains a fundamental challenge in biological microscopy,\nwhere conventional techniques are hindered by multiple light scattering and\nabsorption. Here, we present a non-invasive imaging approach that harnesses the\nnonlinear response of luminescent labels in conjunction with the statistical\nand spatial properties of speckle patterns - an effect of random light\ninterference. Using avalanching nanoparticles (ANPs) with strong\nphotoluminescence nonlinearity, we demonstrate that random speckle illumination\ncan be converted into a single, localized, sub-diffraction excitation spot.\nThis spot can be scanned across the sample using the angular memory effect,\nenabling high-resolution imaging through a scattering layer. Our method is\ngeneral, fast, and cost-effective. It requires no wavefront shaping, no\nfeedback, and no reconstruction algorithm, offering a powerful new route to\ndeep, high-resolution imaging through complex media.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci,physics.bio-ph,physics.med-ph","published":"2025-04-14T17:10:24Z"}
{"aid":"http://arxiv.org/abs/2504.10445v1","title":"RealWebAssist: A Benchmark for Long-Horizon Web Assistance with\n  Real-World Users","summary":"To achieve successful assistance with long-horizon web-based tasks, AI agents\nmust be able to sequentially follow real-world user instructions over a long\nperiod. Unlike existing web-based agent benchmarks, sequential instruction\nfollowing in the real world poses significant challenges beyond performing a\nsingle, clearly defined task. For instance, real-world human instructions can\nbe ambiguous, require different levels of AI assistance, and may evolve over\ntime, reflecting changes in the user's mental state. To address this gap, we\nintroduce RealWebAssist, a novel benchmark designed to evaluate sequential\ninstruction-following in realistic scenarios involving long-horizon\ninteractions with the web, visual GUI grounding, and understanding ambiguous\nreal-world user instructions. RealWebAssist includes a dataset of sequential\ninstructions collected from real-world human users. Each user instructs a\nweb-based assistant to perform a series of tasks on multiple websites. A\nsuccessful agent must reason about the true intent behind each instruction,\nkeep track of the mental state of the user, understand user-specific routines,\nand ground the intended tasks to actions on the correct GUI elements. Our\nexperimental results show that state-of-the-art models struggle to understand\nand ground user instructions, posing critical challenges in following\nreal-world user instructions for long-horizon web assistance.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV,cs.LG","published":"2025-04-14T17:36:46Z"}
{"aid":"http://arxiv.org/abs/2504.10479v1","title":"InternVL3: Exploring Advanced Training and Test-Time Recipes for\n  Open-Source Multimodal Models","summary":"We introduce InternVL3, a significant advancement in the InternVL series\nfeaturing a native multimodal pre-training paradigm. Rather than adapting a\ntext-only large language model (LLM) into a multimodal large language model\n(MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and\nlinguistic capabilities from both diverse multimodal data and pure-text corpora\nduring a single pre-training stage. This unified training paradigm effectively\naddresses the complexities and alignment challenges commonly encountered in\nconventional post-hoc training pipelines for MLLMs. To further improve\nperformance and scalability, InternVL3 incorporates variable visual position\nencoding (V2PE) to support extended multimodal contexts, employs advanced\npost-training techniques such as supervised fine-tuning (SFT) and mixed\npreference optimization (MPO), and adopts test-time scaling strategies\nalongside an optimized training infrastructure. Extensive empirical evaluations\ndemonstrate that InternVL3 delivers superior performance across a wide range of\nmulti-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the\nMMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its\ncapabilities remain highly competitive with leading proprietary models,\nincluding ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also\nmaintaining strong pure-language proficiency. In pursuit of open-science\nprinciples, we will publicly release both the training data and model weights\nto foster further research and development in next-generation MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.10834v1","title":"LightFormer: A lightweight and efficient decoder for remote sensing\n  image segmentation","summary":"Deep learning techniques have achieved remarkable success in the semantic\nsegmentation of remote sensing images and in land-use change detection.\nNevertheless, their real-time deployment on edge platforms remains constrained\nby decoder complexity. Herein, we introduce LightFormer, a lightweight decoder\nfor time-critical tasks that involve unstructured targets, such as disaster\nassessment, unmanned aerial vehicle search-and-rescue, and cultural heritage\nmonitoring. LightFormer employs a feature-fusion and refinement module built on\nchannel processing and a learnable gating mechanism to aggregate multi-scale,\nmulti-range information efficiently, which drastically curtails model\ncomplexity. Furthermore, we propose a spatial information selection module\n(SISM) that integrates long-range attention with a detail preservation branch\nto capture spatial dependencies across multiple scales, thereby substantially\nimproving the recognition of unstructured targets in complex scenes. On the\nISPRS Vaihingen benchmark, LightFormer attains 99.9% of GLFFNet's mIoU (83.9%\nvs. 84.0%) while requiring only 14.7% of its FLOPs and 15.9% of its parameters,\nthus achieving an excellent accuracy-efficiency trade-off. Consistent results\non LoveDA, ISPRS Potsdam, RescueNet, and FloodNet further demonstrate its\nrobustness and superior perception of unstructured objects. These findings\nhighlight LightFormer as a practical solution for remote sensing applications\nwhere both computational economy and high-precision segmentation are\nimperative.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T03:25:39Z"}
{"aid":"http://arxiv.org/abs/2504.10836v1","title":"Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach\n  Based on Deep Joint Source-Channel Coding","summary":"In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communication systems, the acquisition of downlink channel state\ninformation (CSI) is essential for maximizing spatial resource utilization and\nimproving system spectral efficiency. The separate design of modules in\nAI-based CSI feedback architectures under traditional modular communication\nframeworks, including channel estimation (CE), CSI compression and feedback,\nleads to sub-optimal performance. In this paper, we propose an uplink assisted\njoint CE and and CSI feedback approach via deep learning for downlink CSI\nacquisition, which mitigates performance degradation caused by distribution\nbias across separately trained modules in traditional modular communication\nframeworks. The proposed network adopts a deep joint source-channel coding\n(DJSCC) architecture to mitigate the cliff effect encountered in the\nconventional separate source-channel coding. Furthermore, we exploit the uplink\nCSI as auxiliary information to enhance CSI reconstruction accuracy by\nleveraging the partial reciprocity between the uplink and downlink channels in\nFDD systems, without introducing additional overhead. The effectiveness of\nuplink CSI as assisted information and the necessity of an end-toend\nmulti-module joint training architecture is validated through comprehensive\nablation and scalability experiments.","main_category":"eess.SP","categories":"eess.SP,cs.AI","published":"2025-04-15T03:29:24Z"}
{"aid":"http://arxiv.org/abs/2504.10855v1","title":"Virtual Contraction Approach to Decentralized Adaptive Stabilization of\n  Nonlinear Time-Delayed Networks","summary":"In this paper, we utilize a diagonally dominant structure for the\ndecentralized stabilization of unknown nonlinear time-delayed networks.\nGeneralizing the idea of virtual contraction analysis to time-delayed systems,\nwe demonstrate that nonlinear time-delayed networks can be stabilized by\ndiagonal high-gains if the input matrices possess certain generalized\n(column/row) diagonally dominant properties. To achieve stabilization of\nunknown networks, we further propose a distributed adaptive tuning rule for\neach individual gain function, ensuring that all closed-loop trajectories\nconverge to the origin. The effectiveness of the proposed decentralized\nadaptive control is verified in a case study on epidemic spreading control in\nSIS networks with transmission delays.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T04:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.10868v1","title":"AdS3 axion wormholes as stable contributions to the Euclidean\n  gravitational path integral","summary":"Recent work has demonstrated that Euclidean Giddings-Strominger axion\nwormholes are stable in asymptotically flat 4D Minkowski spacetime, suggesting\nthat they should, at least naively, be included as contributions in the quantum\ngravitational path integral. Such inclusion appears to lead to known wormhole\nparadoxes, such as the factorization problem. In this paper, we generalize\nthese results to AdS3 spacetime, where the axion is equivalent to a U(1) gauge\nfield. We explicitly construct the classical wormhole solutions, show their\nregularity and stability, and compute their actions for arbitrary ratios of the\nwormhole mouth radius to the AdS radius and across various topologies. Finally,\nWe discuss potential implications of these findings for the 3D gravitational\npath integral.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T05:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.10874v1","title":"Strongly electroweak phase transition with $U(1)_{L_Î¼-L_Ï}$\n  gauged non-zero hypercharge triplet","summary":"This article considers three non-zero hypercharge triplets as an extension of\nthe Standard Model Higgs doublet. Under extra $U(1)_{L_{\\mu}-L_{\\tau}}$\nsymmetry, the triplets are charged. We examine the stability of the electroweak\nvacuum at the two-loop and tree-levels. The two-loop $\\beta$-functions are\nfound to be capable of satisfying the vacuum stability up to the Planck scale.\nOn the other hand, only up to $10^{12}$ GeV can the perturbative unitarity be\nsatisfied because of the increase in the positive influence from triplet\ndegrees of freedom. For the strongly electroweak first-order phase transition,\nthe parameter space permitted by the Planck scale stability is examined.\nBecause the triplet degrees of freedom contribute sufficiently to the cubic\nterm, the model satisfies the strongly first order phase transition for the\ntriplet bare mass parameters up to the TeV scale. For all mass ranges, it is\nfound that this model predicts a strongly first-order phase transition until\nthe degrees of freedom are heavy enough to separate from the thermal bath. The\ngravitational wave signatures are tested at the benchmark places that fulfill\nthe strongly first-order phase transition. The measurable frequency range of\nthe LISA and BBO experiments also turns out to contain the benchmark points\npermitted by Planck scale stability, strongly first-order phase transition.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T05:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.10898v1","title":"Xpose: Bi-directional Engineering for Hidden Query Extraction","summary":"Query reverse engineering (QRE) aims to synthesize a SQL query to connect a\ngiven database and result instance. A recent variation of QRE is where an\nadditional input, an opaque executable containing a ground-truth query, is\nprovided, and the goal is to non-invasively extract this specific query through\nonly input-output examples. This variant, called Hidden Query Extraction (HQE),\nhas a spectrum of industrial use-cases including query recovery, database\nsecurity, and vendor migration. The reverse engineering (RE) tools developed\nfor HQE, which are based on database mutation and generation techniques, can\nonly extract flat queries with key-based equi joins and conjunctive arithmetic\nfilter predicates, making them limited wrt both query structure and query\noperators. In this paper, we present Xpose, a HQE solution that elevates the\nextraction scope to realistic complex queries, such as those found in the TPCH\nbenchmark. A two-pronged approach is taken: (1) The existing RE scope is\nsubstantially extended to incorporate union connectors, algebraic filter\npredicates, and disjunctions for both values and predicates. (2) The predictive\npower of LLMs is leveraged to convert business descriptions of the opaque\napplication into extraction guidance, representing ``forward engineering\" (FE).\nThe FE module recognizes common constructs, such as nesting of sub-queries,\nouter joins, and scalar functions. In essence, FE establishes the broad query\ncontours, while RE fleshes out the fine-grained details. We have evaluated\nXpose on (a) E-TPCH, a query suite comprising the complete TPCH benchmark\nextended with queries featuring unions, diverse join types, and sub-queries;\nand (b) the real-world STACK benchmark. The experimental results demonstrate\nthat its bi-directional engineering approach accurately extracts these complex\nqueries, representing a significant step forward with regard to HQE coverage.","main_category":"cs.DB","categories":"cs.DB,cs.AI,H.2.8","published":"2025-04-15T06:17:58Z"}
{"aid":"http://arxiv.org/abs/2504.10903v1","title":"Efficient Reasoning Models: A Survey","summary":"Reasoning models have demonstrated remarkable progress in solving complex and\nlogic-intensive tasks by generating extended Chain-of-Thoughts (CoTs) prior to\narriving at a final answer. Yet, the emergence of this \"slow-thinking\"\nparadigm, with numerous tokens generated in sequence, inevitably introduces\nsubstantial computational overhead. To this end, it highlights an urgent need\nfor effective acceleration. This survey aims to provide a comprehensive\noverview of recent advances in efficient reasoning. It categorizes existing\nworks into three key directions: (1) shorter - compressing lengthy CoTs into\nconcise yet effective reasoning chains; (2) smaller - developing compact\nlanguage models with strong reasoning capabilities through techniques such as\nknowledge distillation, other model compression techniques, and reinforcement\nlearning; and (3) faster - designing efficient decoding strategies to\naccelerate inference. A curated collection of papers discussed in this survey\nis available in our GitHub repository.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T06:28:00Z"}
{"aid":"http://arxiv.org/abs/2504.10905v1","title":"InterAnimate: Taming Region-aware Diffusion Model for Realistic Human\n  Interaction Animation","summary":"Recent video generation research has focused heavily on isolated actions,\nleaving interactive motions-such as hand-face interactions-largely unexamined.\nThese interactions are essential for emerging biometric authentication systems,\nwhich rely on interactive motion-based anti-spoofing approaches. From a\nsecurity perspective, there is a growing need for large-scale, high-quality\ninteractive videos to train and strengthen authentication models. In this work,\nwe introduce a novel paradigm for animating realistic hand-face interactions.\nOur approach simultaneously learns spatio-temporal contact dynamics and\nbiomechanically plausible deformation effects, enabling natural interactions\nwhere hand movements induce anatomically accurate facial deformations while\nmaintaining collision-free contact. To facilitate this research, we present\nInterHF, a large-scale hand-face interaction dataset featuring 18 interaction\npatterns and 90,000 annotated videos. Additionally, we propose InterAnimate, a\nregion-aware diffusion model designed specifically for interaction animation.\nInterAnimate leverages learnable spatial and temporal latents to effectively\ncapture dynamic interaction priors and integrates a region-aware interaction\nmechanism that injects these priors into the denoising process. To the best of\nour knowledge, this work represents the first large-scale effort to\nsystematically study human hand-face interactions. Qualitative and quantitative\nresults show InterAnimate produces highly realistic animations, setting a new\nbenchmark. Code and data will be made public to advance research.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-15T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.10916v1","title":"Embedding Radiomics into Vision Transformers for Multimodal Medical\n  Image Classification","summary":"Background: Deep learning has significantly advanced medical image analysis,\nwith Vision Transformers (ViTs) offering a powerful alternative to\nconvolutional models by modeling long-range dependencies through\nself-attention. However, ViTs are inherently data-intensive and lack\ndomain-specific inductive biases, limiting their applicability in medical\nimaging. In contrast, radiomics provides interpretable, handcrafted descriptors\nof tissue heterogeneity but suffers from limited scalability and integration\ninto end-to-end learning frameworks. In this work, we propose the\nRadiomics-Embedded Vision Transformer (RE-ViT) that combines radiomic features\nwith data-driven visual embeddings within a ViT backbone.\n  Purpose: To develop a hybrid RE-ViT framework that integrates radiomics and\npatch-wise ViT embeddings through early fusion, enhancing robustness and\nperformance in medical image classification.\n  Methods: Following the standard ViT pipeline, images were divided into\npatches. For each patch, handcrafted radiomic features were extracted and fused\nwith linearly projected pixel embeddings. The fused representations were\nnormalized, positionally encoded, and passed to the ViT encoder. A learnable\n[CLS] token aggregated patch-level information for classification. We evaluated\nRE-ViT on three public datasets (including BUSI, ChestXray2017, and Retinal\nOCT) using accuracy, macro AUC, sensitivity, and specificity. RE-ViT was\nbenchmarked against CNN-based (VGG-16, ResNet) and hybrid (TransMed) models.\n  Results: RE-ViT achieved state-of-the-art results: on BUSI,\nAUC=0.950+/-0.011; on ChestXray2017, AUC=0.989+/-0.004; on Retinal OCT,\nAUC=0.986+/-0.001, which outperforms other comparison models.\n  Conclusions: The RE-ViT framework effectively integrates radiomics with ViT\narchitectures, demonstrating improved performance and generalizability across\nmultimodal medical image classification tasks.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-04-15T06:55:58Z"}
{"aid":"http://arxiv.org/abs/2504.10922v1","title":"Equivalence of germs (of mappings and sets) over k vs that over K","summary":"Consider real-analytic mapping-germs, (R^n,o)-> (R^m,o). They can be\nequivalent (by coordinate changes) complex-analytically, but not\nreal-analytically. However, if the transformation of complex-equivalence is\nidentity modulo higher order terms, then it implies the real-equivalence.\n  On the other hand, starting from complex-analytic map-germs (C^n,o)->(C^m,o),\nand taking any field extension, C to K, one has: if two maps are equivalent\nover K, then they are equivalent over C.\n  These (quite useful) properties seem to be not well known. We prove slightly\nstronger properties in a more general form:\n  * for Maps(X,Y) where X,Y are (formal/analytic/Nash) scheme-germs, with\narbitrary singularities, over a base ring k;\n  * for the classical groups of (right/left-right/contact) equivalence of\nSingularity Theory;\n  * for faithfully-flat extensions of rings k -> K. In particular, for\narbitrary extension of fields, in any characteristic.\n  The case ``k is a ring\" is important for the study of\ndeformations/unfoldings. E.g. it implies the statement for fields: if a family\nof maps {f_t} is trivial over K, then it is also trivial over k.\n  Similar statements for scheme-germs (``isomorphism over K vs isomorphism over\nk\") follow by the standard reduction ``Two maps are contact equivalent iff\ntheir zero sets are ambient isomorphic\".\n  This study involves the contact equivalence of maps with singular targets,\nwhich seems to be not well-established. We write down the relevant part of this\ntheory.","main_category":"math.AG","categories":"math.AG,math.AC,math.CV","published":"2025-04-15T07:09:27Z"}
{"aid":"http://arxiv.org/abs/2504.10923v1","title":"Fast-Powerformer: A Memory-Efficient Transformer for Accurate Mid-Term\n  Wind Power Forecasting","summary":"Wind power forecasting (WPF), as a significant research topic within\nrenewable energy, plays a crucial role in enhancing the security, stability,\nand economic operation of power grids. However, due to the high stochasticity\nof meteorological factors (e.g., wind speed) and significant fluctuations in\nwind power output, mid-term wind power forecasting faces a dual challenge of\nmaintaining high accuracy and computational efficiency. To address these\nissues, this paper proposes an efficient and lightweight mid-term wind power\nforecasting model, termed Fast-Powerformer. The proposed model is built upon\nthe Reformer architecture, incorporating structural enhancements such as a\nlightweight Long Short-Term Memory (LSTM) embedding module, an input\ntransposition mechanism, and a Frequency Enhanced Channel Attention Mechanism\n(FECAM). These improvements enable the model to strengthen temporal feature\nextraction, optimize dependency modeling across variables, significantly reduce\ncomputational complexity, and enhance sensitivity to periodic patterns and\ndominant frequency components. Experimental results conducted on multiple\nreal-world wind farm datasets demonstrate that the proposed Fast-Powerformer\nachieves superior prediction accuracy and operational efficiency compared to\nmainstream forecasting approaches. Furthermore, the model exhibits fast\ninference speed and low memory consumption, highlighting its considerable\npractical value for real-world deployment scenarios.","main_category":"cs.LG","categories":"cs.LG,eess.SP","published":"2025-04-15T07:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.10924v1","title":"Exploring the nature of $Î·_{1}(1855)$ and it's partner in a chiral\n  quark model","summary":"Inspired by the recent experimental discoveries of \\(X(3872)\\)\n(\\(c\\bar{q}\\)-\\(q\\bar{c}\\)) and \\(T_{cc}\\) (\\(c\\bar{q}\\)-\\(c\\bar{q}\\)), we\nsystematically study two four-quark systems: the \\(K K_1\\)\n(\\(q\\bar{s}\\)-\\(q\\bar{s}\\)) system and the \\(K \\bar{K}_1\\)\n(\\(q\\bar{s}\\)-\\(s\\bar{q}\\)) system, which is a candidate for the recently\nobserved \\(\\eta_1(1855)\\). Within the framework of an accurate few-body\ncalculation method (GEM), we employ the chiral quark model to simultaneously\nconsider the molecular and diquark structures of these two multiquark systems\nand include their channel coupling effects. Our results show that the \\(K\n\\bar{K}_1\\) system remains a scattering state. On the other hand, due to the\npresence of a good-diquark structure in the \\(K K_1\\) system, we obtain a bound\nstate in the coupled-channel calculation. The primary contribution to the\nbinding energy comes from the exchange of \\(\\pi\\)-meson and \\(\\sigma\\)-meson.\nThe inter-quark distance indicates that it is a compact four-quark structure.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T07:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.10942v1","title":"The path towards measuring the gravitational field of proton bunches at\n  accelerators","summary":"The Newtonian law describing the gravitational interaction of\nnon-relativistic (slowly moving) gravitating matter, has been tested in many\nlaboratory experiments with very high precision. In contrast, the post\nMinkowskian predictions for the gravitational field of ultra-relativistic\nmatter, dominated by momentum instead of rest mass, have not been tested\ndirectly yet. The intense ultra-relativistic proton beam in the LHC storage\nring offers the potential to test general relativity and alternative\ngravitational theories in this parameter regime for the first time in\ncontrolled lab-scale experiments. If successful, this would open the road to a\nnovel use case of the LHC, where non-trivial gravitational physics could be\nstudied likely in a parasitic mode, without the necessity of dedicated filling\npatterns. While the technical challenges are formidable, they should also lead\nto the development of ultra-high-sensitive acceleration sensors with abundant\napplications in other parts of science and technology. The present document\nsummarizes the status of the theoretical studies in this direction, points out\nthe challenges, and possible ways of addressing them. It was submitted as a\ncontribution to the European Strategy for Particle Physics (ESPP) 2026 Update.","main_category":"hep-ex","categories":"hep-ex,gr-qc,quant-ph","published":"2025-04-15T07:45:35Z"}
{"aid":"http://arxiv.org/abs/2504.10946v1","title":"Maximum principles and spectral analysis for the superposition of\n  operators of fractional order","summary":"We consider a \"superposition operator\" obtained through the continuous\nsuperposition of operators of mixed fractional order, modulated by a signed\nBorel finite measure defined over the set $[0, 1]$. The relevance of this\noperator is rooted in the fact that it incorporates special and significant\ncases of interest, like the mixed operator $-\\Delta + (-\\Delta)^s$, the\n(possibly) infinite sum of fractional Laplacians and allows to consider\noperators carrying a \"wrong sign\".\n  We first outline weak and strong maximum principles for this type of\noperators. Then, we complete the spectral analysis for the related Dirichlet\neigenvalue problem started in [DPLSV25b].","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T07:50:32Z"}
{"aid":"http://arxiv.org/abs/2504.10968v1","title":"Bulk Hydrodynamic Transport in Weyl Semimetals","summary":"The role of collective longitudinal modes, plasmons, in bulk hydrodynamic\ntransport in Weyl semimetals is explored. In contrast to graphene, where these\nmodes are gapless, plasmons in Weyl semimetals are gapped. This gap, however,\ncan be made arbitrarily small by decreasing the temperature or the chemical\npotential, making plasmon modes thermally accessible, both in thermodynamics\nand transport. In very clean Weyl semimetals near charge-neutrality where the\nplasmon gap is minimal, we find that they leave an imprint in the thermal\nconductivity and the viscosity.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-15T08:20:45Z"}
{"aid":"http://arxiv.org/abs/2504.10974v1","title":"Self-Supervised Enhancement of Forward-Looking Sonar Images: Bridging\n  Cross-Modal Degradation Gaps through Feature Space Transformation and\n  Multi-Frame Fusion","summary":"Enhancing forward-looking sonar images is critical for accurate underwater\ntarget detection. Current deep learning methods mainly rely on supervised\ntraining with simulated data, but the difficulty in obtaining high-quality\nreal-world paired data limits their practical use and generalization. Although\nself-supervised approaches from remote sensing partially alleviate data\nshortages, they neglect the cross-modal degradation gap between sonar and\nremote sensing images. Directly transferring pretrained weights often leads to\noverly smooth sonar images, detail loss, and insufficient brightness. To\naddress this, we propose a feature-space transformation that maps sonar images\nfrom the pixel domain to a robust feature domain, effectively bridging the\ndegradation gap. Additionally, our self-supervised multi-frame fusion strategy\nleverages complementary inter-frame information to naturally remove speckle\nnoise and enhance target-region brightness. Experiments on three self-collected\nreal-world forward-looking sonar datasets show that our method significantly\noutperforms existing approaches, effectively suppressing noise, preserving\ndetailed edges, and substantially improving brightness, demonstrating strong\npotential for underwater target detection applications.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-15T08:34:56Z"}
{"aid":"http://arxiv.org/abs/2504.10988v1","title":"Hyperlinearity via amenable near representations","summary":"We characterize the amenability of unitary representations (in the sense of\nBekka) via the existence of an orthonormal basis supporting an invariant\nprobability charge. Based on this, we explore several natural notions of\namenable near representations on Hilbert spaces. Establishing an analogue of a\ntheorem about sofic groups by Elek and Szab\\'o, we prove that a group is\nhyperlinear if and only if it admits an essentially free amenable near\nrepresentation. This answers a question raised by Pestov and Kwiatkowska. For\ncomparison, we also provide characterizations of Kirchberg's factorization\nproperty, as well as Haagerup's property, along similar lines.","main_category":"math.GR","categories":"math.GR,math.FA","published":"2025-04-15T09:00:41Z"}
{"aid":"http://arxiv.org/abs/2504.10989v1","title":"Global N-body Simulation of Gap Edge Structures Created by Perturbations\n  from a Small Satellite Embedded in Saturn's Rings II: The Effect of\n  Satellite's Orbital Eccentricity and Inclination","summary":"Pan and Daphnis are embedded in Saturn's rings and opening a gap with\nsatellite wakes at the gap edges. Furthermore, in the case of Daphnis,\npronounced vertical wall structures casting shadows on the rings are also\nobserved in the satellite wakes. In this paper, we perform a global 3D N-body\nsimulation with non-zero $e_{\\rm s}$ or non-zero $i_{\\rm s}$ of the satellite\norbit to investigate how they affect the gap edge structures. We found that the\neffect of satellite eccentricity is important both in the satellite wakes and\nthe vertical walls at the gap edges. The non-sinusoidal sawtooth-like satellite\nwakes and azimuthally more localized vertical walls observed by Cassini are\nsimultaneously reproduced in the detailed structures and spatial scales. Both\nof them periodically vary due to the satellite excursions between the apocenter\nand the pericenter. The ring particles in outer (inner) rings that undergo\nclosest encounters with the satellite near the apocenter (pericenter) are\nexcited the most highly. Because the excited eccentricities of the ring\nparticles are converted to the inclinations through physical collisions, the\nconversion is the most active for the particles that acquire the highest\neccentricities, resulting in the azimuthally more localized vertical wall\nstructures. The predicted height of the tallest vertical walls is $\\sim 0.2$\ntimes the satellite Hill radius in the case of the satellite eccentricity\ncomparable to Daphnis when adopting Hill scaling, which is twice as much as the\nheight obtained in the case of the circular satellite orbit and is\nquantitatively more consistent with the Cassini observation. These results show\nthat the observed vertical walls are actually formed by the satellite wakes\nfollowed by their conversion to the vertical motions through inter-particle\ncollisions, rather than by the out-of-plane perturbation from the satellite in\nan inclined orbit.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T09:01:52Z"}
{"aid":"http://arxiv.org/abs/2504.10991v1","title":"No detection of radio continuum from low-redshift passive spiral\n  galaxies","summary":"Radio-emitting active galactic nuclei (AGNs) are common in elliptical\ngalaxies and AGN feedback is one of the possible mechanisms for regulating star\nformation in massive galaxies. It is unclear if all passive galaxy populations\nhost radio AGNs and if AGN feedback is a plausible mechanism for truncating or\nregulating star formation in these galaxies. To determine if radio AGNs are\ncommon in passive spiral galaxies, we have measured the radio emission of 38\nlow-redshift passive spiral galaxies using RACS-low at 887.5 MHz and VLASS at 3\nGHz. We selected a subset of 2MRS galaxies with negligible WISE 12 $\\mu$m\nemission from warm dust, and spiral morphologies from HyperLeda, RC3, 2MRS and\nmanual inspection. In contrast to comparable early-type galaxies, our sample\nhas no significant radio detections, with radio flux densities below 1 mJy,\nimplying that radio AGNs are rare or non-existent in passive spirals. Using the\ncombined radio images and assuming radio luminosity is proportional to $K$-band\nluminosity, we find ${\\rm log}~L_\\nu \\lesssim 9.01-0.4~M_K$. This falls below\nthe radio luminosities of passive elliptical galaxies, implying radio\nluminosity in passive galaxies is correlated with host galaxy morphology and\nkinematics.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T09:07:10Z"}
{"aid":"http://arxiv.org/abs/2504.10998v1","title":"On the completeness problem of homogeneous Lorentz 3-dimensional spaces,\n  Part II","summary":"We consider 3-dimensional solvable Lie groups given by a semi-direct product\n$\\mathbb{R}\\ltimes_A\\mathbb{R}^2$, where $A$ is a nonzero real $2\\times2$\ndiagonalizable matrix. The completeness problem has been addressed in the\nliterature for two limiting cases: the unimodular Lie group $\\mathrm{Sol}$ and\nthe homothetic Lie group $\\mathrm{Ho}$. In this work, we solve the completeness\nproblem of left-invariant Lorentzian metrics on the remaining Lie groups of the\ngiven form. Moreover, we show that every 3-dimensional non-unimodular Lie group\nhas an incomplete left-invariant metric.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T09:15:07Z"}
{"aid":"http://arxiv.org/abs/2504.11006v1","title":"A Navier-Stokes-Peridynamics hybrid algorithm for the coupling of\n  compressible flows and fracturing materials","summary":"Modeling and simulation of fluid-structure interactions are crucial to the\nsuccess of aerospace engineering. This work addresses a novel hybrid algorithm\nthat models the close coupling between compressible flows and deformable\nmaterials using a mesoscopic approach. Specifically, the high-speed flows are\ndescribed by the gas-kinetic scheme, which is a robust Navier-Stokes\nalternative solver built on the molecular kinetic theory. The deformation,\ndamage, and fracture of materials are depicted using the bond-based\nperidynamics, which serves as coarse-grained molecular dynamics to construct\nnon-local extensions of classical continuum mechanics. The evolution of fluids\nand materials are closely coupled using the ghost-cell immersed boundary\nmethod. Within each time step, the solutions of flow and solid fields are\nupdated simultaneously, and physics-driven boundary conditions are exchanged\nfor each other via ghost cells. Extensive numerical experiments, including\ncrack propagation in a pre-cracked plate, subsonic flow around the NACA0012\nairfoil, supersonic flow around the circular cylinder, and shock wave impacting\non the elastic panel, are performed to validate the algorithm. The simulation\nresults demonstrate the unique advantages of current hybrid algorithm in\nsolving fracture propagation induced by high-speed flows.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-15T09:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.11008v1","title":"MediSee: Reasoning-based Pixel-level Perception in Medical Images","summary":"Despite remarkable advancements in pixel-level medical image perception,\nexisting methods are either limited to specific tasks or heavily rely on\naccurate bounding boxes or text labels as input prompts. However, the medical\nknowledge required for input is a huge obstacle for general public, which\ngreatly reduces the universality of these methods. Compared with these\ndomain-specialized auxiliary information, general users tend to rely on oral\nqueries that require logical reasoning. In this paper, we introduce a novel\nmedical vision task: Medical Reasoning Segmentation and Detection (MedSD),\nwhich aims to comprehend implicit queries about medical images and generate the\ncorresponding segmentation mask and bounding box for the target object. To\naccomplish this task, we first introduce a Multi-perspective, Logic-driven\nMedical Reasoning Segmentation and Detection (MLMR-SD) dataset, which\nencompasses a substantial collection of medical entity targets along with their\ncorresponding reasoning. Furthermore, we propose MediSee, an effective baseline\nmodel designed for medical reasoning segmentation and detection. The\nexperimental results indicate that the proposed method can effectively address\nMedSD with implicit colloquial queries and outperform traditional medical\nreferring segmentation methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T09:28:53Z"}
{"aid":"http://arxiv.org/abs/2504.11011v1","title":"Document Quality Scoring for Web Crawling","summary":"The internet contains large amounts of low-quality content, yet users expect\nweb search engines to deliver high-quality, relevant results. The abundant\npresence of low-quality pages can negatively impact retrieval and crawling\nprocesses by wasting resources on these documents. Therefore, search engines\ncan greatly benefit from techniques that leverage efficient quality estimation\nmethods to mitigate these negative impacts. Quality scoring methods for web\npages are useful for many processes typical for web search systems, including\nstatic index pruning, index tiering, and crawling. Building on work by Chang et\nal.~\\cite{chang2024neural}, who proposed using neural estimators of semantic\nquality for static index pruning, we extend their approach and apply their\nneural quality scorers to assess the semantic quality of web pages in crawling\nprioritisation tasks. In our experimental analysis, we found that prioritising\nsemantically high-quality pages over low-quality ones can improve downstream\nsearch effectiveness. Our software contribution consists of a Docker container\nthat computes an effective quality score for a given web page, allowing the\nquality scorer to be easily included and used in other components of web search\nsystems.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-15T09:32:57Z"}
{"aid":"http://arxiv.org/abs/2504.11022v1","title":"Meta-learning For Few-Shot Time Series Crop Type Classification: A\n  Benchmark On The EuroCropsML Dataset","summary":"Spatial imbalances in crop type data pose significant challenges for accurate\nclassification in remote sensing applications. Algorithms aiming at\ntransferring knowledge from data-rich to data-scarce tasks have thus surged in\npopularity. However, despite their effectiveness in previous evaluations, their\nperformance in challenging real-world applications is unclear and needs to be\nevaluated. This study benchmarks transfer learning and several meta-learning\nalgorithms, including (First-Order) Model-Agnostic Meta-Learning ((FO)-MAML),\nAlmost No Inner Loop (ANIL), and Task-Informed Meta-Learning (TIML), on the\nreal-world EuroCropsML time series dataset, which combines farmer-reported crop\ndata with Sentinel-2 satellite observations from Estonia, Latvia, and Portugal.\nOur findings indicate that MAML-based meta-learning algorithms achieve slightly\nhigher accuracy compared to simpler transfer learning methods when applied to\ncrop type classification tasks in Estonia after pre-training on data from\nLatvia. However, this improvement comes at the cost of increased computational\ndemands and training time. Moreover, we find that the transfer of knowledge\nbetween geographically disparate regions, such as Estonia and Portugal, poses\nsignificant challenges to all investigated algorithms. These insights\nunderscore the trade-offs between accuracy and computational resource\nrequirements in selecting machine learning methods for real-world crop type\nclassification tasks and highlight the difficulties of transferring knowledge\nbetween different regions of the Earth. To facilitate future research in this\ndomain, we present the first comprehensive benchmark for evaluating transfer\nand meta-learning methods for crop type classification under real-world\nconditions. The corresponding code is publicly available at\nhttps://github.com/dida-do/eurocrops-meta-learning.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T09:47:57Z"}
{"aid":"http://arxiv.org/abs/2504.11024v1","title":"Easy3D: A Simple Yet Effective Method for 3D Interactive Segmentation","summary":"The increasing availability of digital 3D environments, whether through\nimage-based 3D reconstruction, generation, or scans obtained by robots, is\ndriving innovation across various applications. These come with a significant\ndemand for 3D interaction, such as 3D Interactive Segmentation, which is useful\nfor tasks like object selection and manipulation. Additionally, there is a\npersistent need for solutions that are efficient, precise, and performing well\nacross diverse settings, particularly in unseen environments and with\nunfamiliar objects. In this work, we introduce a 3D interactive segmentation\nmethod that consistently surpasses previous state-of-the-art techniques on both\nin-domain and out-of-domain datasets. Our simple approach integrates a\nvoxel-based sparse encoder with a lightweight transformer-based decoder that\nimplements implicit click fusion, achieving superior performance and maximizing\nefficiency. Our method demonstrates substantial improvements on benchmark\ndatasets, including ScanNet, ScanNet++, S3DIS, and KITTI-360, and also on\nunseen geometric distributions such as the ones obtained by Gaussian Splatting.\nThe project web-page is available at https://simonelli-andrea.github.io/easy3d.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.11037v1","title":"Statistical complexity as a probe of mass and phase structure in compact\n  objects","summary":"In this work, we present a comprehensive and systematic study of the\nstatistical complexity, originally introduced by L\\'opez-Ruiz, Mancini, and\nCalbet [Phys. Lett. A 209, 321-326 (1995)], across a broad range of compact\nstar models. We explore how complexity correlates not only with macroscopic\nobservables such as mass and radius, but also with the microscopic\ncharacteristics of the underlying equation of state. By incorporating both\nrealistic equations of state and analytical solutions to Einstein's field\nequations, we demonstrate that gravitational mass plays a dominant role in\ndetermining the behavior of complexity. Furthermore, we show that strong phase\ntransitions within the stellar interior, such as those hypothesized in hybrid\nstars, can manifest as distinct features in the complexity profile, offering a\npotential informational signature of such transitions. This work offers new\ninsights into the link between information theory and compact object physics,\nhighlighting complexity's potential as a diagnostic tool in astrophysics.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE,gr-qc,nucl-th,quant-ph","published":"2025-04-15T09:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.11066v1","title":"Improving fingerprint presentation attack detection by an approach\n  integrated into the personal verification stage","summary":"Presentation Attack Detection (PAD) systems are usually designed\nindependently of the fingerprint verification system. While this can be\nacceptable for use cases where specific user templates are not predetermined,\nit represents a missed opportunity to enhance security in scenarios where\nintegrating PAD with the fingerprint verification system could significantly\nleverage users' templates, which are the real target of a potential\npresentation attack. This does not mean that a PAD should be specifically\ndesigned for such users; that would imply the availability of many enrolled\nusers' PAI and, consequently, complexity, time, and cost increase. On the\ncontrary, we propose to equip a basic PAD, designed according to the state of\nthe art, with an innovative add-on module called the Closeness Binary Code (CC)\nmodule. The term \"closeness\" refers to a peculiar property of the bona\nfide-related features: in an Euclidean feature space, genuine fingerprints tend\nto cluster in a specific pattern. First, samples from the same finger are close\nto each other, then samples from other fingers of the same user and finally,\nsamples from fingers of other users. This property is statistically verified in\nour previous publication, and further confirmed in this paper. It is\nindependent of the user population and the feature set class, which can be\nhandcrafted or deep network-based (embeddings). Therefore, the add-on can be\ndesigned without the need for the targeted user samples; moreover, it exploits\nher/his samples' \"closeness\" property during the verification stage. Extensive\nexperiments on benchmark datasets and state-of-the-art PAD methods confirm the\nbenefits of the proposed add-on, which can be easily coupled with the main PAD\nmodule integrated into the fingerprint verification system.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:01:06Z"}
{"aid":"http://arxiv.org/abs/2504.11067v1","title":"Morphing-based Compression for Data-centric ML Pipelines","summary":"Data-centric ML pipelines extend traditional machine learning (ML) pipelines\n-- of feature transformations and ML model training -- by outer loops for data\ncleaning, augmentation, and feature engineering to create high-quality input\ndata. Existing lossless matrix compression applies lightweight compression\nschemes to numeric matrices and performs linear algebra operations such as\nmatrix-vector multiplications directly on the compressed representation but\nstruggles to efficiently rediscover structural data redundancy. Compressed\noperations are effective at fitting data in available memory, reducing I/O\nacross the storage-memory-cache hierarchy, and improving instruction\nparallelism. The applied data cleaning, augmentation, and feature\ntransformations provide a rich source of information about data characteristics\nsuch as distinct items, column sparsity, and column correlations. In this\npaper, we introduce BWARE -- an extension of AWARE for workload-aware lossless\nmatrix compression -- that pushes compression through feature transformations\nand engineering to leverage information about structural transformations.\nBesides compressed feature transformations, we introduce a novel technique for\nlightweight morphing of a compressed representation into workload-optimized\ncompressed representations without decompression. BWARE shows substantial\nend-to-end runtime improvements, reducing the execution time for training\ndata-centric ML pipelines from days to hours.","main_category":"cs.DB","categories":"cs.DB,cs.DC,cs.LG","published":"2025-04-15T11:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.11069v1","title":"Pseudospectral implementation of the Einstein-Maxwell system","summary":"Electromagnetism plays an important role in a variety of applications in\ngravity that we wish to investigate. To that end, in this work, we present an\nimplementation of the Maxwell equations within the adaptive-mesh pseudospectral\nnumerical relativity code bamps. We present a thorough analysis of the\nevolution equations as a first order symmetric hyperbolic system of PDEs,\nincluding the construction of the characteristic variables for use in our\npenalty boundary communication scheme, and radiation controlling, constraint\npreserving outer boundary conditions which, in the language of\nKreiss-Agranovich-M\\'etivier, are shown to be boundary-stable. After presenting\na formulation of the Maxwell constraints that we may solve for initial data, we\nmove on to present a suite of numerical tests. Our simulations, both within the\nCowling approximation, and in full non-linear evolution, demonstrate rapid\nconvergence of error with resolution, as well as consistency with known\nquasinormal decay rates on the Kerr background. Finally we present evolutions\nof the electrovacuum equations of motion with strong data, a good\nrepresentation of typical critical collapse runs.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-15T11:06:10Z"}
{"aid":"http://arxiv.org/abs/2504.11073v1","title":"FreeDOM: Online Dynamic Object Removal Framework for Static Map\n  Construction Based on Conservative Free Space Estimation","summary":"Online map construction is essential for autonomous robots to navigate in\nunknown environments. However, the presence of dynamic objects may introduce\nartifacts into the map, which can significantly degrade the performance of\nlocalization and path planning. To tackle this problem, a novel online dynamic\nobject removal framework for static map construction based on conservative free\nspace estimation (FreeDOM) is proposed, consisting of a scan-removal front-end\nand a map-refinement back-end. First, we propose a multi-resolution map\nstructure for fast computation and effective map representation. In the\nscan-removal front-end, we employ raycast enhancement to improve free space\nestimation and segment the LiDAR scan based on the estimated free space. In the\nmap-refinement back-end, we further eliminate residual dynamic objects in the\nmap by leveraging incremental free space information. As experimentally\nverified on SemanticKITTI, HeLiMOS, and indoor datasets with various sensors,\nour proposed framework overcomes the limitations of visibility-based methods\nand outperforms state-of-the-art methods with an average F1-score improvement\nof 9.7%.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T11:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.11078v1","title":"Dynamical Measurement of Supermassive Black Hole Masses: QPE Timing\n  Method","summary":"Quasi-periodic eruptions (QPEs) are intense repeating soft X-ray bursts with\nrecurrence times about a few hours to a few weeks from galactic nuclei. More\nand more analyses show that (at least a fraction of) QPEs are the result of\ncollisions between a stellar mass object (SMO, a stellar mass black hole or a\nmain sequence star) and an accretion disk around a supermassive black hole\n(SMBH) in galactic nuclei. Previous studies have shown that the SMO trajectory\ncan be reconstructed from QPE timing data, consequently the SMBH mass can be\nrobustly measured from tracing a single SMO. In this Letter, we construct a\ncomprehensive Bayesian framework for implementing the QPE timing method,\nexplore the optimal QPE observation strategy for measuring SMBH masses, and\nforecast the measurement precision expected in the era of multi-target X-ray\ntelescope, Chasing All Transients Constellation Hunters (CATCH). As a result,\nwe find the QPE timing method is of great potential in precise measurement of\nSMBH masses (and spins), especially in the lower mass end ($\\lesssim 10^7\nM_\\odot$) where QPEs prevail and relevant dynamical timescales are reasonably\nshort to be measured.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-04-15T11:22:20Z"}
{"aid":"http://arxiv.org/abs/2504.11081v1","title":"DPS: Design Pattern Summarisation Using Code Features","summary":"Automatic summarisation has been used efficiently in recent years to condense\ntexts, conversations, audio, code, and various other artefacts. A range of\nmethods, from simple template-based summaries to complex machine learning\ntechniques -- and more recently, large language models -- have been employed to\ngenerate these summaries. Summarising software design patterns is important\nbecause it helps developers quickly understand and reuse complex design\nconcepts, thereby improving software maintainability and development\nefficiency. However, the generation of summaries for software design patterns\nhas not yet been explored. Our approach utilises code features and JavaParser\nto parse the code and create a JSON representation. Using an NLG library on\nthis JSON representation, we convert it into natural language text that acts as\na summary of the code, capturing the contextual information of the design\npattern. Our empirical results indicate that the summaries generated by our\napproach capture the context in which patterns are applied in the codebase.\nStatistical evaluations demonstrate that our summaries closely align with\nhuman-written summaries, as evident from high values in the ROUGE-L, BLEU-4,\nNIST, and FrugalScore metrics. A follow-up survey further shows that DPS\nsummaries were rated as capturing context better than human-generated\nsummaries.","main_category":"cs.SE","categories":"cs.SE,D.2","published":"2025-04-15T11:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.11088v1","title":"FLSSM: A Federated Learning Storage Security Model with Homomorphic\n  Encryption","summary":"Federated learning based on homomorphic encryption has received widespread\nattention due to its high security and enhanced protection of user data\nprivacy. However, the characteristics of encrypted computation lead to three\nchallenging problems: ``computation-efficiency\", ``attack-tracing\" and\n``contribution-assessment\". The first refers to the efficiency of encrypted\ncomputation during model aggregation, the second refers to tracing malicious\nattacks in an encrypted state, and the third refers to the fairness of\ncontribution assessment for local models after encryption. This paper proposes\na federated learning storage security model with homomorphic encryption (FLSSM)\nto protect federated learning model privacy and address the three issues\nmentioned above. First, we utilize different nodes to aggregate local models in\nparallel, thereby improving encrypted models' aggregation efficiency. Second,\nwe introduce trusted supervise nodes to examine local models when the global\nmodel is attacked, enabling the tracing of malicious attacks under homomorphic\nencryption. Finally, we fairly reward local training nodes with encrypted local\nmodels based on trusted training time. Experiments on multiple real-world\ndatasets show that our model significantly outperforms baseline models in terms\nof both efficiency and security metrics.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T11:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.11101v1","title":"Consensus Entropy: Harnessing Multi-VLM Agreement for Self-Verifying and\n  Self-Improving OCR","summary":"The Optical Character Recognition (OCR) task is important for evaluating\nVision-Language Models (VLMs) and providing high-quality data sources for LLM\ntraining data. While state-of-the-art VLMs show improved average OCR accuracy,\nthey still struggle with sample-level quality degradation and lack reliable\nautomatic detection of low-quality outputs. We introduce Consensus Entropy\n(CE), a training-free post-inference method that quantifies OCR uncertainty by\naggregating outputs from multiple VLMs. Our approach exploits a key insight:\ncorrect VLM OCR predictions converge in output space while errors diverge. We\ndevelop a lightweight multi-model framework that effectively identifies\nproblematic samples, selects the best outputs and combines model strengths.\nExperiments across multiple OCR benchmarks and VLMs demonstrate that CE\noutperforms VLM-as-judge approaches and single-model baselines at the same cost\nand achieves state-of-the-art results across multiple metrics. For instance,\nour solution demonstrates: achieving 15.2\\% higher F1 scores than VLM-as-judge\nmethods in quality verification, delivering 6.0\\% accuracy gains on\nmathematical calculation tasks, and requiring rephrasing only 7.3\\% of inputs\nwhile maintaining overall performance. Notably, the entire process requires\nneither training nor supervision while maintaining plug-and-play functionality\nthroughout.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-15T11:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.11116v1","title":"Breaking the Dimensional Barrier: A Pontryagin-Guided Direct Policy\n  Optimization for Continuous-Time Multi-Asset Portfolio","summary":"Solving large-scale, continuous-time portfolio optimization problems\ninvolving numerous assets and state-dependent dynamics has long been challenged\nby the curse of dimensionality. Traditional dynamic programming and PDE-based\nmethods, while rigorous, typically become computationally intractable beyond a\nsmall number of state variables (often limited to ~3-6 in prior numerical\nstudies). To overcome this critical barrier, we introduce the\n\\emph{Pontryagin-Guided Direct Policy Optimization} (PG-DPO) framework. PG-DPO\nleverages Pontryagin's Maximum Principle to directly guide neural network\npolicies via backpropagation-through-time, naturally incorporating exogenous\nstate processes without requiring dense state grids. Crucially, our\ncomputationally efficient ``Two-Stage'' variant exploits rapidly stabilizing\ncostate estimates derived from BPTT, converting them into near-optimal\nclosed-form Pontryagin controls after only a short warm-up, significantly\nreducing training overhead. This enables a breakthrough in scalability:\nnumerical experiments demonstrate that PG-DPO successfully tackles problems\nwith dimensions previously considered far out of reach, optimizing portfolios\nwith up to 50 assets and 10 state variables. The framework delivers\nnear-optimal policies, offering a practical and powerful alternative for\nhigh-dimensional continuous-time portfolio choice.","main_category":"q-fin.PM","categories":"q-fin.PM,q-fin.CP","published":"2025-04-15T12:03:14Z"}
{"aid":"http://arxiv.org/abs/2504.11127v1","title":"Keplerian motion of a compact source orbiting the inner disk of PDS 70:\n  A third protoplanet in a resonance with b and c?","summary":"The disk around PDS 70 hosts two directly imaged protoplanets in a gap.\nPrevious VLT/SPHERE and recent James Webb Space Telescope/NIRCam observations\nhave hinted at the presence of a third compact source in the same gap at ~13\nau, interior to the orbit of PDS 70 b. We reduce seven published and one\nunpublished VLT/SPHERE datasets in YJH and K bands, as well as an archival\nVLT/NaCo dataset in L' band, and an archival VLT/SINFONI dataset in H+K band.\nWe combine angular-, spectral- and reference star differential imaging to\nsearch for protoplanet candidates. We recover the compact source in all epochs,\nconsistent with the JWST detection, moving on an arc that can be fit by\nKeplerian motion of a protoplanet which could be in a resonance with PDS 70 b &\nc. We find that the spectral slope is overall consistent with the unresolved\nstar and inner disk emission at 0.95--1.65$\\mu$m, which suggests a dust\nscattering dominated spectrum. An excess beyond 2.3$\\mu$m could be thermal\nemission from either a protoplanet or heated circumplanetary dust, variability,\nor inner disk contamination, and requires confirmation. While we currently\ncannot rule out a moving inner disk feature or a dust clump associated with an\nunseen planet, the data supports the hypothesis of a third protoplanet in this\nremarkable system.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T12:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.11146v1","title":"Exploring Student Behaviors and Motivations using AI TAs with Optional\n  Guardrails","summary":"AI-powered chatbots and digital teaching assistants (AI TAs) are gaining\npopularity in programming education, offering students timely and personalized\nfeedback. Despite their potential benefits, concerns about student\nover-reliance and academic misconduct have prompted the introduction of\n\"guardrails\" into AI TAs - features that provide scaffolded support rather than\ndirect solutions. However, overly restrictive guardrails may lead students to\nbypass these tools and use unconstrained AI models, where interactions are not\nobservable, thus limiting our understanding of students' help-seeking\nbehaviors. To investigate this, we designed and deployed a novel AI TA tool\nwith optional guardrails in one lab of a large introductory programming course.\nAs students completed three code writing and debugging tasks, they had the\noption to receive guardrailed help or use a \"See Solution\" feature which\ndisabled the guardrails and generated a verbatim response from the underlying\nmodel. We investigate students' motivations and use of this feature and examine\nthe association between usage and their course performance. We found that 50%\nof the 885 students used the \"See Solution\" feature for at least one problem\nand 14% used it for all three problems. Additionally, low-performing students\nwere more likely to use this feature and use it close to the deadline as they\nstarted assignments later. The predominant factors that motivated students to\ndisable the guardrails were assistance in solving problems, time pressure, lack\nof self-regulation, and curiosity. Our work provides insights into students'\nsolution-seeking motivations and behaviors, which has implications for the\ndesign of AI TAs that balance pedagogical goals with student preferences.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-15T12:48:22Z"}
{"aid":"http://arxiv.org/abs/2504.11150v1","title":"GC-GAT: Multimodal Vehicular Trajectory Prediction using Graph Goal\n  Conditioning and Cross-context Attention","summary":"Predicting future trajectories of surrounding vehicles heavily relies on what\ncontextual information is given to a motion prediction model. The context\nitself can be static (lanes, regulatory elements, etc) or dynamic (traffic\nparticipants). This paper presents a lane graph-based motion prediction model\nthat first predicts graph-based goal proposals and later fuses them with cross\nattention over multiple contextual elements. We follow the famous\nencoder-interactor-decoder architecture where the encoder encodes scene context\nusing lightweight Gated Recurrent Units, the interactor applies cross-context\nattention over encoded scene features and graph goal proposals, and the decoder\nregresses multimodal trajectories via Laplacian Mixture Density Network from\nthe aggregated encodings. Using cross-attention over graph-based goal proposals\ngives robust trajectory estimates since the model learns to attend to future\ngoal-relevant scene elements for the intended agent. We evaluate our work on\nnuScenes motion prediction dataset, achieving state-of-the-art results.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-15T12:53:07Z"}
{"aid":"http://arxiv.org/abs/2504.11167v1","title":"Low-Rank SPIKE Framework for Solving Large Sparse Linear Systems with\n  Applications","summary":"The SPIKE family of linear system solvers provides parallelism using a block\ntridiagonal partitioning. Typically SPIKE-based solvers are applied to banded\nsystems, resulting in structured off-diagonal blocks with non-zeros elements\nrestricted to relatively small submatrices comprising the band of the original\nmatrix. In this work, a low-rank SVD based approximation of the off-diagonal\nblocks is investigated. This produces a representation which more effectively\nhandles matrices with large, sparse bands. A set of flexible distributed\nsolvers, the LR-SPIKE variants, are implemented. There are applicable to a wide\nrange of applications -- from use as a \"black-box\" preconditioner which\nstraightforwardly improves upon the classic Block Jacobi preconditioner, to use\nas a specialized \"approximate direct solver.\" An investigation of the\neffectiveness of the new preconditioners for a selection of SuiteSparse\nmatrices is performed, particularly focusing on matrices derived from 3D finite\nelement simulations. In addition, the SPIKE approximate linear system solvers\nare also paired with the FEAST eigenvalue solver, where they are shown to be\nparticularly effective due to the former's rapid convergence, and the latter's\nacceptance of loose linear system solver convergence, resulting in a\ncombination which requires very few solver iterations.","main_category":"math.NA","categories":"math.NA,cs.MS,cs.NA","published":"2025-04-15T13:15:00Z"}
{"aid":"http://arxiv.org/abs/2504.11170v1","title":"A Real-time Anomaly Detection Method for Robots based on a Flexible and\n  Sparse Latent Space","summary":"The growing demand for robots to operate effectively in diverse environments\nnecessitates the need for robust real-time anomaly detection techniques during\nrobotic operations. However, deep learning-based models in robotics face\nsignificant challenges due to limited training data and highly noisy signal\nfeatures. In this paper, we present Sparse Masked Autoregressive Flow-based\nAdversarial AutoEncoders model to address these problems. This approach\nintegrates Masked Autoregressive Flow model into Adversarial AutoEncoders to\nconstruct a flexible latent space and utilize Sparse autoencoder to efficiently\nfocus on important features, even in scenarios with limited feature space. Our\nexperiments demonstrate that the proposed model achieves a 4.96% to 9.75%\nhigher area under the receiver operating characteristic curve for\npick-and-place robotic operations with randomly placed cans, compared to\nexisting state-of-the-art methods. Notably, it showed up to 19.67% better\nperformance in scenarios involving collisions with lightweight objects.\nAdditionally, unlike the existing state-of-the-art model, our model performs\ninferences within 1 millisecond, ensuring real-time anomaly detection. These\ncapabilities make our model highly applicable to machine learning-based robotic\nsafety systems in dynamic environments. The code will be made publicly\navailable after acceptance.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-15T13:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.11172v1","title":"TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data","summary":"Large-scale foundation models in Earth Observation can learn versatile,\nlabel-efficient representations by leveraging massive amounts of unlabeled\ndata. However, existing public datasets are often limited in scale, geographic\ncoverage, or sensor variety. We introduce TerraMesh, a new globally diverse,\nmultimodal dataset combining optical, synthetic aperture radar, elevation, and\nland-cover modalities in an Analysis-Ready Data format. TerraMesh includes over\n9 million samples with eight spatiotemporal aligned modalities, enabling\nlarge-scale pre-training and fostering robust cross-modal correlation learning.\nWe provide detailed data processing steps, comprehensive statistics, and\nempirical evidence demonstrating improved model performance when pre-trained on\nTerraMesh. The dataset will be made publicly available with a permissive\nlicense.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:20:35Z"}
{"aid":"http://arxiv.org/abs/2504.11182v1","title":"Exploring Backdoor Attack and Defense for LLM-empowered Recommendations","summary":"The fusion of Large Language Models (LLMs) with recommender systems (RecSys)\nhas dramatically advanced personalized recommendations and drawn extensive\nattention. Despite the impressive progress, the safety of LLM-based RecSys\nagainst backdoor attacks remains largely under-explored. In this paper, we\nraise a new problem: Can a backdoor with a specific trigger be injected into\nLLM-based Recsys, leading to the manipulation of the recommendation responses\nwhen the backdoor trigger is appended to an item's title? To investigate the\nvulnerabilities of LLM-based RecSys under backdoor attacks, we propose a new\nattack framework termed Backdoor Injection Poisoning for RecSys (BadRec).\nBadRec perturbs the items' titles with triggers and employs several fake users\nto interact with these items, effectively poisoning the training set and\ninjecting backdoors into LLM-based RecSys. Comprehensive experiments reveal\nthat poisoning just 1% of the training data with adversarial examples is\nsufficient to successfully implant backdoors, enabling manipulation of\nrecommendations. To further mitigate such a security threat, we propose a\nuniversal defense strategy called Poison Scanner (P-Scanner). Specifically, we\nintroduce an LLM-based poison scanner to detect the poisoned items by\nleveraging the powerful language understanding and rich knowledge of LLMs. A\ntrigger augmentation agent is employed to generate diverse synthetic triggers\nto guide the poison scanner in learning domain-specific knowledge of the\npoisoned item detection task. Extensive experiments on three real-world\ndatasets validate the effectiveness of the proposed P-Scanner.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-15T13:37:38Z"}
{"aid":"http://arxiv.org/abs/2504.11196v1","title":"The Lifetime of the Covid Memorial Wall: Modelling with Collections\n  Demography, Social Media Data and Citizen Science","summary":"The National Covid Memorial Wall in London, featuring over 240,000\nhand-painted red hearts, faces significant conservation challenges due to the\nrapid fading of the paint. This study evaluates the transition to a\nbetter-quality paint and its implications for the wall's long-term\npreservation. The rapid fading of the initial materials required an\nunsustainable repainting rate, burdening volunteers. Lifetime simulations based\non a collections demography framework suggest that repainting efforts must\ncontinue at a rate of some hundreds of hearts per week to maintain a stable\npercentage of hearts in good condition. This finding highlights the need for a\nsustainable management strategy that includes regular maintenance or further\nreduction of the fading rate.\n  Methodologically, this study demonstrates the feasibility of using a\ncollections demography approach, supported by citizen science and social media\ndata, to inform heritage management decisions. An agent-based simulation is\nused to propagate the multiple uncertainties measured. The methodology provides\na robust basis for modeling and decision-making, even in a case like this,\nwhere reliance on publicly available images and volunteer-collected data\nintroduces variability. Future studies could improve data within a citizen\nscience framework by inviting public submissions, using on-site calibration\ncharts, and increasing volunteer involvement for longitudinal data collection.\nThis research illustrates the flexibility of the collections demography\nframework, firstly by showing its applicability to an outdoor monument, which\nis very different from the published case studies, and secondly by\ndemonstrating how it can work even with low-quality data.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-15T13:51:14Z"}
{"aid":"http://arxiv.org/abs/2504.11205v1","title":"Can Quasi Periodic Oscillations Encode Traces of Black Hole Phase\n  Transitions ?","summary":"Finding observational evidence or imprints of black hole phase transitions is\na promising and active area of research. Aiming to contribute to this\ndirection, in this work, we probe the well-known thermodynamic phase structure\nof the Reissner Nordstr\\\"om Anti de Sitter (RN-AdS) black hole through the lens\nof its quasi-periodic oscillations (QPOs). Can QPOs be influenced by black hole\nphase transitions? Do they carry any signature of such transitions in their\nobservational patterns? These were the central questions guiding our study. By\nanalyzing the upper and lower QPO frequencies within the Relativistic\nPrecession (RP) model, we observe that the frequency-temperature relationship\nreflects distinguishing features corresponding to the small, intermediate, and\nlarge black hole phases, offering insights into their stability properties. The\nanalysis is further extended to other QPO models, including the Warped Disk\n(WD) and Epicyclic Resonance (ER) models. The presence of distinct phase\nstructures remains evident across all models which is an encouraging outcome\nthat may be worth exploring further in the context of other black hole systems.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-15T14:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.11206v1","title":"Investigation of optimal transfers to retrograde co-orbital orbits in\n  the Earth-Moon system","summary":"Recent findings on retrograde co-orbital mean-motion resonances in the\nEarth-Moon system, highlight the potential use of spacecraft in retrograde\nresonances. Based on these discoveries, this study investigates retrograde\nco-orbital resonances within the Earth-Moon system, focusing on both optimal\nand sub-optimal orbital transfers to such configurations. The paper provides a\ncomprehensive analysis of retrograde co-orbital resonances, optimization\ntechniques to evaluate and enhance the performance of bi-impulsive transfers to\nthese configurations. The results reveal the feasibility of low-cost transfers,\nwhich could support a range of future missions, including space exploration and\nsatellite deployment. Combining advanced optimization processes, we obtained\nsolutions for orbital transfers for different arrival points in retrograde\nco-orbitals improving mission efficiency and offering a cost-effective approach\nto interplanetary exploration.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T14:10:05Z"}
{"aid":"http://arxiv.org/abs/2504.11216v1","title":"Diversity-Driven Learning: Tackling Spurious Correlations and Data\n  Heterogeneity in Federated Models","summary":"Federated Learning (FL) enables decentralized training of machine learning\nmodels on distributed data while preserving privacy. However, in real-world FL\nsettings, client data is often non-identically distributed and imbalanced,\nresulting in statistical data heterogeneity which impacts the generalization\ncapabilities of the server's model across clients, slows convergence and\nreduces performance. In this paper, we address this challenge by first\nproposing a characterization of statistical data heterogeneity by means of 6\nmetrics of global and client attribute imbalance, class imbalance, and spurious\ncorrelations. Next, we create and share 7 computer vision datasets for binary\nand multiclass image classification tasks in Federated Learning that cover a\nbroad range of statistical data heterogeneity and hence simulate real-world\nsituations. Finally, we propose FedDiverse, a novel client selection algorithm\nin FL which is designed to manage and leverage data heterogeneity across\nclients by promoting collaboration between clients with complementary data\ndistributions. Experiments on the seven proposed FL datasets demonstrate\nFedDiverse's effectiveness in enhancing the performance and robustness of a\nvariety of FL methods while having low communication and computational\noverhead.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T14:20:42Z"}
{"aid":"http://arxiv.org/abs/2504.11217v1","title":"Is model selection possible for the $\\ell_p$-loss? PCO estimation for\n  regression models","summary":"This paper addresses the problem of model selection in the sequence model\n$Y=\\theta+\\varepsilon\\xi$, when $\\xi$ is sub-Gaussian, for non-euclidian\nloss-functions. In this model, the Penalized Comparison to Overfitting\nprocedure is studied for the weighted $\\ell_p$-loss, $p\\geq 1.$ Several oracle\ninequalities are derived from concentration inequalities for sub-Weibull\nvariables. Using judicious collections of models and penalty terms, minimax\nrates of convergence are stated for Besov bodies $\\mathcal{B}_{r,\\infty}^s$.\nThese results are applied to the functional model of nonparametric regression.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-15T14:20:44Z"}
{"aid":"http://arxiv.org/abs/2504.11230v1","title":"CAP-Net: A Unified Network for 6D Pose and Size Estimation of\n  Categorical Articulated Parts from a Single RGB-D Image","summary":"This paper tackles category-level pose estimation of articulated objects in\nrobotic manipulation tasks and introduces a new benchmark dataset. While recent\nmethods estimate part poses and sizes at the category level, they often rely on\ngeometric cues and complex multi-stage pipelines that first segment parts from\nthe point cloud, followed by Normalized Part Coordinate Space (NPCS) estimation\nfor 6D poses. These approaches overlook dense semantic cues from RGB images,\nleading to suboptimal accuracy, particularly for objects with small parts. To\naddress these limitations, we propose a single-stage Network, CAP-Net, for\nestimating the 6D poses and sizes of Categorical Articulated Parts. This method\ncombines RGB-D features to generate instance segmentation and NPCS\nrepresentations for each part in an end-to-end manner. CAP-Net uses a unified\nnetwork to simultaneously predict point-wise class labels, centroid offsets,\nand NPCS maps. A clustering algorithm then groups points of the same predicted\nclass based on their estimated centroid distances to isolate each part.\nFinally, the NPCS region of each part is aligned with the point cloud to\nrecover its final pose and size. To bridge the sim-to-real domain gap, we\nintroduce the RGBD-Art dataset, the largest RGB-D articulated dataset to date,\nfeaturing photorealistic RGB images and depth noise simulated from real\nsensors. Experimental evaluations on the RGBD-Art dataset demonstrate that our\nmethod significantly outperforms the state-of-the-art approach. Real-world\ndeployments of our model in robotic tasks underscore its robustness and\nexceptional sim-to-real transfer capabilities, confirming its substantial\npractical utility. Our dataset, code and pre-trained models are available on\nthe project page.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-15T14:30:26Z"}
{"aid":"http://arxiv.org/abs/2504.11258v1","title":"Multi-Agent Reinforcement Learning for Greenhouse Gas Offset Credit\n  Markets","summary":"Climate change is a major threat to the future of humanity, and its impacts\nare being intensified by excess man-made greenhouse gas emissions. One method\ngovernments can employ to control these emissions is to provide firms with\nemission limits and penalize any excess emissions above the limit. Excess\nemissions may also be offset by firms who choose to invest in carbon reducing\nand capturing projects. These projects generate offset credits which can be\nsubmitted to a regulating agency to offset a firm's excess emissions, or they\ncan be traded with other firms. In this work, we characterize the finite-agent\nNash equilibrium for offset credit markets. As computing Nash equilibria is an\nNP-hard problem, we utilize the modern reinforcement learning technique\nNash-DQN to efficiently estimate the market's Nash equilibria. We demonstrate\nnot only the validity of employing reinforcement learning methods applied to\nclimate themed financial markets, but also the significant financial savings\nemitting firms may achieve when abiding by the Nash equilibria through\nnumerical experiments.","main_category":"q-fin.MF","categories":"q-fin.MF,cs.LG","published":"2025-04-15T14:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.11259v1","title":"The Cambridge Report on Database Research","summary":"On October 19 and 20, 2023, the authors of this report convened in Cambridge,\nMA, to discuss the state of the database research field, its recent\naccomplishments and ongoing challenges, and future directions for research and\ncommunity engagement. This gathering continues a long standing tradition in the\ndatabase community, dating back to the late 1980s, in which researchers meet\nroughly every five years to produce a forward looking report.\n  This report summarizes the key takeaways from our discussions. We begin with\na retrospective on the academic, open source, and commercial successes of the\ncommunity over the past five years. We then turn to future opportunities, with\na focus on core data systems, particularly in the context of cloud computing\nand emerging hardware, as well as on the growing impact of data science, data\ngovernance, and generative AI.\n  This document is not intended as an exhaustive survey of all technical\nchallenges or industry innovations in the field. Rather, it reflects the\nperspectives of senior community members on the most pressing challenges and\npromising opportunities ahead.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T14:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.11262v1","title":"Enhanced Small Target Detection via Multi-Modal Fusion and Attention\n  Mechanisms: A YOLOv5 Approach","summary":"With the rapid development of information technology, modern warfare\nincreasingly relies on intelligence, making small target detection critical in\nmilitary applications. The growing demand for efficient, real-time detection\nhas created challenges in identifying small targets in complex environments due\nto interference. To address this, we propose a small target detection method\nbased on multi-modal image fusion and attention mechanisms. This method\nleverages YOLOv5, integrating infrared and visible light data along with a\nconvolutional attention module to enhance detection performance. The process\nbegins with multi-modal dataset registration using feature point matching,\nensuring accurate network training. By combining infrared and visible light\nfeatures with attention mechanisms, the model improves detection accuracy and\nrobustness. Experimental results on anti-UAV and Visdrone datasets demonstrate\nthe effectiveness and practicality of our approach, achieving superior\ndetection results for small and dim targets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:02:10Z"}
{"aid":"http://arxiv.org/abs/2504.11272v1","title":"Attosecond plasma lens","summary":"Attosecond pulses provide unique opportunities for studies of time-resolved\nelectron dynamics. However, focusing these pulses, typically ranging from the\nvacuum ultraviolet to the soft-X-ray region, remains challenging. Conventional\nrefractive lenses are not suitable owing to the large dispersion and the strong\nabsorption, while reflective optics, despite avoiding these issues, still lead\nto high losses. Here we propose a tunable plasma lens capable of focusing\nattosecond pulses, and experimentally demonstrate focusing of these pulses at\nextreme-ultraviolet photon energies around 20 eV and 80 eV. A key advantage is\nits compatibility with nonlinear frequency conversion processes like\nhigh-harmonic generation. The different focusing properties of the fundamental\nlight and the generated harmonic frequencies allow for efficient separation of\nthese components. Consequently, the transmission of high-harmonic generation\nbeamlines can be increased to more than 80%, making this approach highly\nsuitable for photon-demanding applications.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T15:13:47Z"}
{"aid":"http://arxiv.org/abs/2504.11274v1","title":"Isomeric yield ratios and mass spectrometry of Y and Nb isotopes in the\n  neutron-rich N=60 region: the unusual case of $^{98}$Y","summary":"The isomeric yield ratio (IYR) of fission products is an observable that\ncarries relevant information about the fragments emerging from the scission of\na fissioning nucleus. We report on IYR of $^{96,98,100}$Y and $^{100,102}$Nb,\ntogether with the previously reported values for $^{97}$Y and $^{99}$Nb,\nproduced in the 28 MeV $\\alpha$-induced fission of $^{232}$Th at the Ion Guide\nIsotope Separation On-Line (IGISOL) facility of the University of\nJyv{\\\"a}skyl{\\\"a}. We measured the IYR using two different techniques, the\nphase-imaging ion-cyclotron-resonance (PI-ICR) and the multiple-reflection\ntime-of-flight mass spectrometry (MR-TOF-MS) methods. Moreover, we measured the\nmasses of the long-lived isomeric states in $^{98,100}$Y and $^{100,102}$Nb\npopulated via in-trap $\\beta$-decay of their precursors. Since the\n$\\beta$-decay selectively populates states with a favourable spin-parity, we\ncould identify the measured state and show that in all cases except $^{102}$Nb\nthe ground state is the low-spin state. This measurement confirms the\nspin-parity assignments of all the nuclei as they are reported on the ENSDF\nevaluations, disagreeing with the assignment for $^{100}$Y reported on the\nNUBASE2020 evaluation.\n  Making also use of previously reported data, we observe an anomalously low\nIYR for the $N=59$ isotope $^{98}$Y as compared to other yttrium or neighboring\nniobium isotopes. This behavior is very rare across the nuclear chart and is\nposited to be connected to the characteristic shape coexistence of $^{98}$Y and\nto the change in the charge radii of the ground and excited states in the\n$N=58-60$ region.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-15T15:15:13Z"}
{"aid":"http://arxiv.org/abs/2504.11282v1","title":"Minimum-Turn Tours of Even Polyominoes","summary":"Let $P$ be a connected bounded region in the plane formed out of $2 \\times 2$\nblocks joined by their sides. Peng and Rascoussier conjectured that all\nminimum-turn Hamiltonian cycles of $P$ exhibit a certain regular structure. We\nprove this conjecture in the special case when $P$ is a topological disk. The\nproof proceeds in two phases - a \"downward\" phase where we break apart an\nirregular Hamiltonian cycle into a collection of shorter cycles; and an\n\"upward\" phase where we put it back together in a different way so that,\noverall, the number of turns in it decreases.","main_category":"math.CO","categories":"math.CO","published":"2025-04-15T15:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.11283v1","title":"Influence of the magnetic activity cycle on mean density and acoustic\n  radius inversions","summary":"Asteroseismic modelling is crucial for upcoming missions like PLATO,\nCubeSpec, and Roman. Despite significant progress, discrepancies between\nobservations and theoretical predictions introduce biases in stellar\ncharacterisation at the precision required by PLATO. Current models typically\nignore magnetic activity, assuming its effects are hidden within surface\neffects. However, recent studies have shown significant impacts of magnetic\nactivity on the Sun's asteroseismic characterisation using forward modelling.\nUsing GOLF and BiSON observations of two full solar activity cycles, we\nquantified the impact of magnetic activity on solar mean density and acoustic\nradius inversions. Observations were segmented into yearly overlapping\nsnapshots, each offset by 91.25 days. Inversions were performed for each\nsnapshot to determine mean density and acoustic radius, tracking their temporal\nevolution and estimating systematic uncertainty due to magnetic activity. We\nobserved a clear imprint of the magnetic activity cycle on solar mean density\nand acoustic radius through helioseismic inversions, consistent across GOLF and\nBiSON datasets. This imprint is the largest source of systematic uncertainty in\nsolar asteroseismic characterisation. Including low radial-order modes\nmitigates these effects more significantly than previously measured for other\nstellar variables. We recommend asteroseismic values for solar mean density\n(1.4104 \\pm 0.0051 g/cm3) and acoustic radius (3722.0 \\pm 4.1 s), averaged over\ntwo activity cycles. These values account for major systematic errors,\nachieving high precision (0.36% for mean density and 0.11% for acoustic\nradius). These results are promising for high-precision characterisation of\nSun-like stars, a better-constrained mean density being able to enhance the\nprecision of stellar radius estimate, which is crucial for exoplanetary system\ncharacterisation.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-15T15:22:51Z"}
{"aid":"http://arxiv.org/abs/2504.11296v1","title":"Random matrix ensembles and integrable differential identities","summary":"Integrable differential identities, together with ensemble-specific initial\nconditions, provide an effective approach for the characterisation of relevant\nobservables and state functions in random matrix theory. We develop the\napproach for the unitary and orthogonal ensembles. In particular, we focus on a\nreduction where the probability measure is induced by a Hamiltonian expressed\nas a formal series of even interactions. We show that the order parameters for\nthe unitary ensemble, that is associated with the Volterra lattice, solve the\nmodified KP equation. The analogous reduction for the orthogonal ensemble,\nassociated with the Pfaff lattice, leads to a new integrable chain. A key step\nfor the calculation of order parameters solution for the orthogonal ensemble is\nthe evaluation of the initial condition by using a map from orthogonal to\nskew-orthogonal polynomials. The thermodynamic limit leads to an integrable\nsystem (a chain for the orthogonal ensemble) of hydrodynamic type.\nIntriguingly, we find that the solution to the initial value problem for both\nthe discrete system and its continuum limit are given by the very same\nsemi-discrete dynamical chain.","main_category":"math-ph","categories":"math-ph,math.MP,nlin.SI","published":"2025-04-15T15:35:19Z"}
{"aid":"http://arxiv.org/abs/2504.11299v1","title":"Efficient and Stable Multi-Dimensional Kolmogorov-Smirnov Distance","summary":"We revisit extending the Kolmogorov-Smirnov distance between probability\ndistributions to the multidimensional setting and make new arguments about the\nproper way to approach this generalization. Our proposed formulation maximizes\nthe difference over orthogonal dominating rectangular ranges (d-sided\nrectangles in R^d), and is an integral probability metric. We also prove that\nthe distance between a distribution and a sample from the distribution\nconverges to 0 as the sample size grows, and bound this rate. Moreover, we show\nthat one can, up to this same approximation error, compute the distance\nefficiently in 4 or fewer dimensions; specifically the runtime is near-linear\nin the size of the sample needed for that error. With this, we derive a\ndelta-precision two-sample hypothesis test using this distance. Finally, we\nshow these metric and approximation properties do not hold for other popular\nvariants.","main_category":"stat.CO","categories":"stat.CO,cs.CG,cs.LG","published":"2025-04-15T15:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.11315v1","title":"New Key Rate Bound for High-Dimensional BB84 with Multiple Basis\n  Measurements","summary":"In this paper we derive a new bound on the secret key-rate of the High\nDimensional BB84 protocol operating with multiple mutually unbiased bases\n(MUBs). To our knowledge, our proof is the first for this protocol that is both\ngeneral (in that it can handle arbitrary, asymmetric channels), and also the\nfirst that derives a bound on the quantum min entropy for general attacks,\nwithout relying on post selection techniques or the asymptotic equipartition\nproperty. Because of this, our new result shows that far more optimistic\nkey-rates are possible for a low number of signals, even in general channels.\nFurthermore, our proof methods may be broadly applicable to other protocols\nrelying on multiple measurement bases and we prove several technical lemmas\nthat may have independent interest. We evaluate our new bound and compare to\nprior work, showing that higher key-rates are possible in several operating\nscenarios. We also show some interesting behavior of the protocol when faced\nwith asymmetric noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.11317v1","title":"The role of non-Markovian dissipation in quantum phase transitions:\n  tricriticality, spin squeezing, and directional symmetry breaking","summary":"Understanding how to control phase transitions in quantum systems is at the\nforefront of research for the development of new quantum materials and\ntechnologies. Here, we study how the coupling of a quantum system to a\nnon-Markovian environment, i.e., an environment with a frequency-dependent\nspectral density inducing memory effects, can be used to generate and reshape\nphase transitions and squeezing in matter phases. Focusing on a\nLipkin-Meshkov-Glick model, we demonstrate that non-Markovian dissipation can\nbe leveraged to engineer tricriticality via the fusion of\n$2^{\\mathrm{nd}}$-order and $1^{\\mathrm{st}}$-order critical points. We\nidentify phases that arise from different ways of breaking the single weak\nsymmetry of our model, which led us to introduce the concept of\n\\textit{directional spontaneous symmetry breaking} (DSSB) as a general\nframework to understand this phenomenon. We show that signatures of DSSB can be\nseen in the emergence of spin squeezing along different directions, and that\nthe latter is controllable via non-Markovian effects, opening up possibilities\nfor applications in quantum metrology. Finally, we propose an experimental\nimplementation of our non-Markovian model in cavity QED. Our work features\nnon-Markovianity as a resource for controlling phase transitions in general\nsystems, and highlights shortcomings of the Markovian limit in this context.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.11318v1","title":"Mildly-Interacting Fermionic Unitaries are Efficiently Learnable","summary":"Recent work has shown that one can efficiently learn fermionic Gaussian\nunitaries, also commonly known as nearest-neighbor matchcircuits or\nnon-interacting fermionic unitaries. However, one could ask a similar question\nabout unitaries that are near Gaussian: for example, unitaries prepared with a\nsmall number of non-Gaussian circuit elements. These operators find\nsignificance in quantum chemistry and many-body physics, yet no algorithm\nexists to learn them.\n  We give the first such result by devising an algorithm which makes queries to\na $n$-mode fermionic unitary $U$ prepared by at most $O(t)$ non-Gaussian gates\nand returns a circuit approximating $U$ to diamond distance $\\varepsilon$ in\ntime $\\textrm{poly}(n,2^t,1/\\varepsilon)$. This resolves a central open\nquestion of Mele and Herasymenko under the strongest distance metric. In fact,\nour algorithm is much more general: we define a property of unitary Gaussianity\nknown as unitary Gaussian dimension and show that our algorithm can learn\n$n$-mode unitaries of Gaussian dimension at least $2n - O(t)$ in time\n$\\textrm{poly}(n,2^t,1/\\varepsilon)$. Indeed, this class subsumes unitaries\nprepared by at most $O(t)$ non-Gaussian gates but also includes several\nunitaries that require up to $2^{O(t)}$ non-Gaussian gates to construct.\n  In addition, we give a $\\textrm{poly}(n,1/\\varepsilon)$-time algorithm to\ndistinguish whether an $n$-mode unitary is of Gaussian dimension at least $k$\nor $\\varepsilon$-far from all such unitaries in Frobenius distance, promised\nthat one is the case. Along the way, we prove structural results about\nnear-Gaussian fermionic unitaries that are likely to be of independent\ninterest.","main_category":"quant-ph","categories":"quant-ph,cs.DS,cs.LG","published":"2025-04-15T15:59:32Z"}
{"aid":"http://arxiv.org/abs/2504.11323v1","title":"Domain wall evolution beyond quartic potentials: The Sine-Gordon and\n  Christ-Lee potentials","summary":"Domain walls are the simplest type of topological defects formed at\ncosmological phase transitions, and one of the most constrained. Their studies\ntypically assume a quartic double well potential, but this model is not fully\nrepresentative of the range of known or plausible particle physics models. Here\nwe study the cosmological evolution of domain walls in two other classes of\npotentials. The Sine-Gordon potential allows several types of walls,\ninterpolating between different pairs of minima (which demands specific\nnumerical algorithms to separately measure the relevant properties of each\ntype). The Christ-Lee potential parametrically interpolates between sextic and\nquartic behavior. We use multiple sets of simulations in two and three spatial\ndimensions, for various cosmological epochs and under various choices of\ninitial conditions, to discuss the scaling properties of these networks. In the\nSine-Gordon case, we identify and quantify deviations from the usual scaling\nbehavior. In the Christ-Lee case, we discuss conditions under which walls form\n(or not), and quantify how these outcomes depend on parameters such as the\nenergy difference between the false and true vacua and the expansion rate of\nthe Universe. Various biased initial conditions are also addressed in\nappendices. Finally, we briefly comment on the possible cosmological\nimplications of our results.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-15T16:02:35Z"}
{"aid":"http://arxiv.org/abs/2504.11327v1","title":"Rate-form equilibrium for an isotropic Cauchy-elastic formulation: Part\n  I: modeling","summary":"We derive the rate-form spatial equilibrium system for a nonlinear Cauchy\nelastic formulation in isotropic finite-strain elasticity. For a given explicit\nCauchy stress-strain constitutive equation, we determine those properties that\npertain to the appearing fourth-order stiffness tensor. Notably, we show that\nthis stiffness tensor $\\mathbb{H}^{\\text{ZJ}}(\\sigma)$ acting on the\nZaremba-Jaumann stress rate is uniformly positive definite. We suggest a\nmathematical treatment of the ensuing spatial PDE-system which may ultimately\nlead to a local existence result, to be presented in part II of this work. As a\npreparatory step, we show existence and uniqueness of a subproblem based on\nKorn's first inequality and the positive definiteness of this stiffness tensor.\nThe procedure is not confined to Cauchy elasticity, however in the Cauchy\nelastic case, most theoretical statements can be made explicit.\n  Our development suggests that looking at the rate-form equations of given\nCauchy-elastic models may provide additional insight to the modeling of\nnonlinear isotropic elasticity. This especially concerns constitutive\nrequirements emanating from the rate-formulation, here being reflected by the\npositive definiteness of $\\mathbb{H}^{\\text{ZJ}}(\\sigma)$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T16:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.11330v1","title":"Decorrelation in Complex Wave Scattering","summary":"Phenomena involving multiple scattering, despite having attracted\nconsiderable attention in physics for decades, continue to generate unexpected\nand counterintuitive behaviours prompting further studies. For optical\nscattering, the memory effect well predicts fourth order statistics, i.e. the\nintensity correlation, as long as the scattering strength and depth are within\ncertain bounds. The memory effect has found a wide range of applications, where\nits limitations also become apparent: for example, in imaging through turbid\nmedia, decorrelation due to multiscattering in thick samples has been shown to\nrestrict the field of view. However, to our knowledge, no comprehensive\nmechanism exists to date that can account for decorrelation precisely. In this\npaper, we quantify how the scatterer's own statistics determine such\nlimitations. We show that the ensemble statistics of the backscattered field\nmay be decomposed into two terms: one expresses surface scattering, where\nstatistical distributions of multiscale structure features may be inferred from\nour previous works; while the second term originates from the underlying\nscattering volume and is diffusive. The new framework agrees well with\nexperiments, including the prediction of a new quasipower law for fluctuations\ninduced by the single realization.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T16:04:02Z"}
{"aid":"http://arxiv.org/abs/2504.11338v1","title":"Transformer-Based Model for Cold Start Mitigation in FaaS Architecture","summary":"Serverless architectures, particularly the Function as a Service (FaaS)\nmodel, have become a cornerstone of modern cloud computing due to their ability\nto simplify resource management and enhance application deployment agility.\nHowever, a significant challenge remains: the cold start problem. This\nphenomenon occurs when an idle FaaS function is invoked, requiring a full\ninitialization process, which increases latency and degrades user experience.\nExisting solutions for cold start mitigation are limited in terms of invocation\npattern generalization and implementation complexity. In this study, we propose\nan innovative approach leveraging Transformer models to mitigate the impact of\ncold starts in FaaS architectures. Our solution excels in accurately modeling\nfunction initialization delays and optimizing serverless system performance.\nExperimental evaluation using a public dataset provided by Azure demonstrates a\nsignificant reduction in cold start times, reaching up to 79\\% compared to\nconventional methods.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-15T16:12:07Z"}
{"aid":"http://arxiv.org/abs/2504.11354v1","title":"Kimina-Prover Preview: Towards Large Formal Reasoning Models with\n  Reinforcement Learning","summary":"We introduce Kimina-Prover Preview, a large language model that pioneers a\nnovel reasoning-driven exploration paradigm for formal theorem proving, as\nshowcased in this preview release. Trained with a large-scale reinforcement\nlearning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong\nperformance in Lean 4 proof generation by employing a structured reasoning\npattern we term \\textit{formal reasoning pattern}. This approach allows the\nmodel to emulate human problem-solving strategies in Lean, iteratively\ngenerating and refining proof steps. Kimina-Prover sets a new state-of-the-art\non the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved\nbenchmark performance, our work yields several key insights: (1) Kimina-Prover\nexhibits high sample efficiency, delivering strong results even with minimal\nsampling (pass@1) and scaling effectively with computational budget, stemming\nfrom its unique reasoning pattern and RL training; (2) we demonstrate clear\nperformance scaling with model size, a trend previously unobserved for neural\ntheorem provers in formal mathematics; (3) the learned reasoning style,\ndistinct from traditional search algorithms, shows potential to bridge the gap\nbetween formal verification and informal mathematical intuition. We open source\ndistilled versions with 1.5B and 7B parameters of Kimina-Prover","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T16:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.11357v1","title":"NNLO predictions with nonlocal subtractions and fiducial power\n  corrections in GENEVA","summary":"We present the implementation of next-to-next-to-leading order (NNLO) QCD\nfully-differential corrections within the GENEVA framework, for both\ncolour-singlet and colour-singlet+jet processes at hadron colliders, by\nemploying a nonlocal subtraction approach. In particular, we discuss the\nimplementation details and the challenges that arise when utilizing a dynamical\ninfrared cutoff parameter. Additionally, we combine the subtraction with the\nprojection-to-Born method in order to include fiducial power corrections. As a\ntest case, we provide predictions for Drell-Yan and $Z$+jet production at the\nLHC, using $N$-jettiness as resolution variable. We validate the NNLO\ncorrections of GENEVA against NNLOJET finding excellent agreement. Finally, we\ndiscuss how to extend our method to calculate the N$^3$LO QCD\nfully-differential corrections to colour-singlet production at hadron\ncolliders.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-15T16:26:01Z"}
{"aid":"http://arxiv.org/abs/2504.11362v1","title":"$27 \\otimes 27$","summary":"We study the decomposition into $SU(N)$ irreducible representations (irreps)\nof the tensor product $27 \\otimes 27$, where $27$ is the highest-dimensional\n$SU(N)$ irrep present in a two-gluon system, and explicitly construct all\nHermitian projectors on these irreps, as well as transition operators between\nthem. This yields an explicit basis of the complete $27\\otimes 27$ color space\n(defined as the space of $27\\otimes 27\\to 27 \\otimes 27$ color maps) in terms\nof orthogonal multiplets. This study shows that even complex color structures\ncan be addressed, with the help of the birdtrack pictorial technique, using\nonly elementary tools. In particular, we highlight the usefulness of the\nquadratic Casimir operator, whose eigenspaces allow efficient filtering of all\nprojectors and transition operators, and of the permutation operators that\nfurther improve this filtering. The product $27\\otimes 27$ also has an\ninteresting feature: three equivalent irreps $27$ appear in the decomposition,\ntwo of which are symmetric and can therefore be distinguished neither by the\nquadratic Casimir operator nor by their symmetry under permutation. In this\ncase, it is convenient to use Clebsch-Gordan coefficients to derive the two\nassociated, symmetric projectors. The latter are not uniquely determined (only\ntheir sum is), and we give the set of all solutions. Finally, we explicitly\nderive the soft anomalous dimension matrix associated with $27\\otimes 27\\to\n27\\otimes 27$, whose block-diagonal main structure is easy to understand, but\nwhose detailed spectrum properties remain intriguing. The approach presented\nfor $27 \\otimes 27 \\to 27 \\otimes 27$ could in principle be applied to any\nproduct of $SU(N)$ irreps, and eventually automated.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-15T16:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.11367v1","title":"Network Alignment","summary":"Complex networks are frequently employed to model physical or virtual complex\nsystems. When certain entities exist across multiple systems simultaneously,\nunveiling their corresponding relationships across the networks becomes\ncrucial. This problem, known as network alignment, holds significant\nimportance. It enhances our understanding of complex system structures and\nbehaviours, facilitates the validation and extension of theoretical physics\nresearch about studying complex systems, and fosters diverse practical\napplications across various fields. However, due to variations in the\nstructure, characteristics, and properties of complex networks across different\nfields, the study of network alignment is often isolated within each domain,\nwith even the terminologies and concepts lacking uniformity. This review\ncomprehensively summarizes the latest advancements in network alignment\nresearch, focusing on analyzing network alignment characteristics and progress\nin various domains such as social network analysis, bioinformatics,\ncomputational linguistics and privacy protection. It provides a detailed\nanalysis of various methods' implementation principles, processes, and\nperformance differences, including structure consistency-based methods, network\nembedding-based methods, and graph neural network-based (GNN-based) methods.\nAdditionally, the methods for network alignment under different conditions,\nsuch as in attributed networks, heterogeneous networks, directed networks, and\ndynamic networks, are presented. Furthermore, the challenges and the open\nissues for future studies are also discussed.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.CL","published":"2025-04-15T16:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.11374v1","title":"A Winner-Takes-All Mechanism for Event Generation","summary":"We present a novel framework for central pattern generator design that\nleverages the intrinsic rebound excitability of neurons in combination with\nwinner-takes-all computation. Our approach unifies decision-making and rhythmic\npattern generation within a simple yet powerful network architecture that\nemploys all-to-all inhibitory connections enhanced by designable excitatory\ninteractions. This design offers significant advantages regarding ease of\nimplementation, adaptability, and robustness. We demonstrate its efficacy\nthrough a ring oscillator model, which exhibits adaptive phase and frequency\nmodulation, making the framework particularly promising for applications in\nneuromorphic systems and robotics.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-15T16:40:37Z"}
{"aid":"http://arxiv.org/abs/2504.11388v1","title":"Local solubility in generalised ChÃ¢telet varieties","summary":"We develop asymptotic formulas, via the circle method, for averages of\nmultivariate equidistributed arithmetic functions evaluated at polynomial\nvalues in many variables.\n  As an application, we count fibers with a rational point in families of\nhigh-dimensional Ch\\^atelet varieties.\n  Among the local solutions in these fibrations, we observe a reciprocity\ninvolving infinitely many places, governed by only finitely many ramified\nBrauer elements.","main_category":"math.NT","categories":"math.NT","published":"2025-04-15T16:57:43Z"}
{"aid":"http://arxiv.org/abs/2504.11390v1","title":"Unraveling Momentum and Heat Intercoupling in Reattaching Turbulent\n  Boundary Layers Using Dynamic Mode Decomposition","summary":"Dynamic mode decomposition method is deployed to investigate the heat\ntransfer mechanism in a compressible turbulent shear layer and shockwave. To\nthis end, highly resolved Large Eddy Simulations are performed to explore the\neffect of wall thermal conditions on the behavior of a reattaching free shear\nlayer interacting with an oblique shock in compressible turbulent flows.\nVarious different wall temperature conditions, such as cold adiabatic and hot\nwall, are considered. Dynamic mode decomposition is used to isolate and study\nthe structures generated by the shear layer exposed in the boundary layer.\nResults reveal that the shear layer flapping is the most energetic mode. The\nhot wall gains the highest amplitude for the flapping frequency, and the\nvortical motions are most intense in the vicinity of the reattachment point of\nthe heated wall. The vortex shedding due to the large-scale motion of the shear\nlayer is associated with the second energetic mode. The cold wall not only has\na higher amplitude of the shedding mode, but it also has a lower frequency\ncompared to the adiabatic and hot walls. This work sheds light on the\nunderlying physics of the nonlinear intercoupling of momentum and heat, hence\nproviding guidelines for designing control systems for high speed flight\nvehicles and mitigating aircraft fatigue loading caused by intense wall\npressure fluctuations and heat flux.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-15T16:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.11413v1","title":"Solving the Phase Problem of Diffraction: X-ray Standing Waves Imaging\n  on Bismuthene/SiC(0001)","summary":"The phase retrieval problem is a fundamental shortcoming of all\ndiffraction-based methods, arising from the inability to measure the phase of\nscattered waves. The (normal incidence) X-ray standing wave (NIXSW) technique\ncircumvents this issue by introducing a (Bragg-generated) X-ray standing wave\nfield throughout the sample, relative to which any atomic species can be\nlocalized by probing its fluorescence or photoelectron yield. In essence, in a\nsingle measurement the complex scattering factor (i.e., its amplitude\n\\textit{and} phase) corresponding to the used Bragg reflection is determined.\nPerforming this for multiple Bragg reflections enables one to reconstruct the\nscattering density of the sample in three dimensions, straightforwardly as the\nFourier sum of all measured (complex) scattering factors. Here, we utilize this\ntechnique to reveal the structural key features involved in the formation of\nthe quantum spin Hall insulator bismuthene on silicon carbide. In this\nprominent example, the two-dimensional Bi layer is confined between a 4H-SiC\nsubstrate crystal and an epitaxial graphene layer. The key finding is a change\nin the adsorption site of the Bi atoms underneath the graphene upon\nhydrogenation, caused by the H-saturation of one (out of three) Si dangling\nbonds per unit cell. This structural change, clearly revealed by our NIXSW\nimaging experiment, is the key feature leading to the formation of the\ncharacteristic band structure of the 2D bismuthene honeycomb.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-15T17:28:24Z"}
{"aid":"http://arxiv.org/abs/2504.11423v1","title":"ADT: Tuning Diffusion Models with Adversarial Supervision","summary":"Diffusion models have achieved outstanding image generation by reversing a\nforward noising process to approximate true data distributions. During\ntraining, these models predict diffusion scores from noised versions of true\nsamples in a single forward pass, while inference requires iterative denoising\nstarting from white noise. This training-inference divergences hinder the\nalignment between inference and training data distributions, due to potential\nprediction biases and cumulative error accumulation. To address this problem,\nwe propose an intuitive but effective fine-tuning framework, called Adversarial\nDiffusion Tuning (ADT), by stimulating the inference process during\noptimization and aligning the final outputs with training data by adversarial\nsupervision. Specifically, to achieve robust adversarial training, ADT features\na siamese-network discriminator with a fixed pre-trained backbone and\nlightweight trainable parameters, incorporates an image-to-image sampling\nstrategy to smooth discriminative difficulties, and preserves the original\ndiffusion loss to prevent discriminator hacking. In addition, we carefully\nconstrain the backward-flowing path for back-propagating gradients along the\ninference path without incurring memory overload or gradient explosion.\nFinally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3),\ndemonstrate that ADT significantly improves both distribution alignment and\nimage quality.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T17:37:50Z"}
{"aid":"http://arxiv.org/abs/2504.11429v1","title":"Improving Statistical Privacy by Subsampling","summary":"Differential privacy (DP) considers a scenario, where an adversary has almost\ncomplete information about the entries of a database This worst-case assumption\nis likely to overestimate the privacy thread for an individual in real life.\nStatistical privacy (SP) denotes a setting where only the distribution of the\ndatabase entries is known to an adversary, but not their exact values. In this\ncase one has to analyze the interaction between noiseless privacy based on the\nentropy of distributions and privacy mechanisms that distort the answers of\nqueries, which can be quite complex.\n  A privacy mechanism often used is to take samples of the data for answering a\nquery. This paper proves precise bounds how much different methods of sampling\nincrease privacy in the statistical setting with respect to database size and\nsampling rate. They allow us to deduce when and how much sampling provides an\nimprovement and how far this depends on the privacy parameter {\\epsilon}. To\nperform these investigations we develop a framework to model sampling\ntechniques.\n  For the DP setting tradeoff functions have been proposed as a finer measure\nfor privacy compared to ({\\epsilon},{\\delta})-pairs. We apply these tools to\nstatistical privacy with subsampling to get a comparable characterization","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T17:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.11437v1","title":"Ghostly interactions in (1+1) dimensional classical field theory","summary":"We investigate the classical stability of two coupled scalar fields with\nopposite-sign kinetic terms evolving in 1+1 dimensional Minkowski spacetime. In\nthe first part, we characterise unquenched ghostly interactions and present\nnumerical solutions that support the following statements. First, the classical\ninstability is not instantaneous and can even be benign, i.e., free of\nfinite-time singularities. Second, while the classical instability can cascade\ntowards higher frequency excitations, it is not driven by high frequency modes:\nAt fixed amplitude, high-frequency modes are more stable than low-frequency\nmodes. In the second part, we demonstrate that the classical instability can be\nquenched by mass terms. In particular, we exemplify that heavy high-frequency\nghost fields seem to not violate the decoupling theorem and can be integrated\nout classically. In the third part, we demonstrate how self-interactions can\nquench the instability, for instance, by postponing its onset to parametrically\nlarge times. Extrapolating numerical results at large but finite evolution time\nto infinite evolution time, we demonstrate that classical fluctuations around\ntrivial and nontrivial field-theory vacua are increasingly long-lived with (i)\nsmaller initial amplitude of fluctuations, (ii) higher initial frequency of\nfluctuations, (iii) larger masses of the fields, or (iv) weaker interaction\ncoupling. Moreover, our numerical simulations for field-theoretical\ngeneralisations of some globally-stable ghostly mechanical models do not\nfeature any instability.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.11449v1","title":"SymTFT construction of gapless exotic-foliated dual models","summary":"We construct Symmetry Topological Field Theories (SymTFTs) for continuous\nsubsystem symmetries, which are inherently non-Lorentz-invariant. Our framework\nproduces dual bulk descriptions -- gapped foliated and exotic SymTFTs -- that\ngenerates gapless boundary theories with spontaneous subsystem symmetry\nbreaking via interval compactification. In analogy with the sandwich\nconstruction of SymTFT, we call this Mille-feuille. This is done by specifying\ngapped and symmetry-breaking boundary conditions. In this way we obtain the\nfoliated dual realizations of various models, including the XY plaquette, XYZ\ncube, and $\\phi$, $\\hat{\\phi}$ theories. This also captures self-duality\nsymmetries as condensation defects and provides a systematic method for\ngenerating free theories that non-linearly realize subsystem symmetries.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-th","published":"2025-04-15T17:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.11775v1","title":"Discrimination-free Insurance Pricing with Privatized Sensitive\n  Attributes","summary":"Fairness has emerged as a critical consideration in the landscape of machine\nlearning algorithms, particularly as AI continues to transform decision-making\nacross societal domains. To ensure that these algorithms are free from bias and\ndo not discriminate against individuals based on sensitive attributes such as\ngender and race, the field of algorithmic bias has introduced various fairness\nconcepts, along with methodologies to achieve these notions in different\ncontexts. Despite the rapid advancement, not all sectors have embraced these\nfairness principles to the same extent. One specific sector that merits\nattention in this regard is insurance. Within the realm of insurance pricing,\nfairness is defined through a distinct and specialized framework. Consequently,\nachieving fairness according to established notions does not automatically\nensure fair pricing in insurance. In particular, regulators are increasingly\nemphasizing transparency in pricing algorithms and imposing constraints on\ninsurance companies on the collection and utilization of sensitive consumer\nattributes. These factors present additional challenges in the implementation\nof fairness in pricing algorithms. To address these complexities and comply\nwith regulatory demands, we propose an efficient method for constructing fair\nmodels that are tailored to the insurance domain, using only privatized\nsensitive attributes. Notably, our approach ensures statistical guarantees,\ndoes not require direct access to sensitive attributes, and adapts to varying\ntransparency requirements, addressing regulatory demands while ensuring\nfairness in insurance pricing.","main_category":"stat.ML","categories":"stat.ML,cs.CY,cs.LG,q-fin.RM","published":"2025-04-16T05:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.11784v1","title":"DALC: Distributed Arithmetic Coding Aided by Linear Codes","summary":"Distributed Arithmetic Coding (DAC) has emerged as a feasible solution to the\nSlepian-Wolf problem, particularly in scenarios with non-stationary sources and\nfor data sequences with lengths ranging from small to medium. Due to the\ninherent decoding ambiguity in DAC, the number of candidate paths grows\nexponentially with the increase in source length. To select the correct\ndecoding path from the set of candidates, DAC decoders utilize the Maximum A\nPosteriori (MAP) metric to rank the decoding sequences, outputting the path\nwith the highest MAP metric as the decoding result of the decoder. However,\nthis method may still inadvertently output incorrect paths that have a MAP\nmetric higher than the correct decoding path, despite not being the correct\ndecoding path. To address the issue, we propose Distributed Arithmetic Coding\nAided by Linear Codes (DALC), which employs linear codes to constrain the\ndecoding process, thereby eliminating some incorrect paths and preserving the\ncorrect one. During the encoding phase, DALC generates the parity bits of the\nlinear code for encoding the source data. In the decoding phase, each path in\nthe set of candidate paths is verified in descending order according to the MAP\nmetric until a path that meets the verification criteria is encountered, which\nis then outputted as the decoding result. DALC enhances the decoding\nperformance of DAC by excluding candidate paths that do not meet the\nconstraints imposed by linear codes. Our experimental results demonstrate that\nDALC reduces the Bit Error Rate(BER), with especially improvements in skewed\nsource data scenarios.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T05:36:52Z"}
{"aid":"http://arxiv.org/abs/2504.11785v1","title":"Ground state and multiple normalized solutions of quasilinear\n  SchrÃ¶dinger equations in the $L^2$-supercritical case and the Sobolev\n  critical case","summary":"This paper is devoted to studying the existence of normalized solutions for\nthe following quasilinear Schr\\\"odinger equation \\begin{equation*}\n\\begin{aligned}\n  -\\Delta u-u\\Delta u^2 +\\lambda u=|u|^{p-2}u \\quad\\mathrm{in}\\ \\mathbb{R}^{N},\n\\end{aligned} \\end{equation*} where $N=3,4$, $\\lambda$ appears as a Lagrange\nmultiplier and $p \\in (4+\\frac{4}{N},2\\cdot2^*]$. The solutions correspond to\ncritical points of the energy functional subject to the $L^2$-norm constraint\n$\\int_{\\mathbb{R}^N}|u|^2dx=a^2>0$. In the Sobolev critical case $p=2\\cdot\n2^*$, the energy functional has no critical point. As for $L^2$-supercritical\ncase $p \\in (4+\\frac{4}{N},2\\cdot2^*)$: on the one hand, taking into account\nPohozaev manifold and perturbation method, we obtain the existence of ground\nstate normalized solutions for the non-radial case; on the other hand, we get\nthe existence of infinitely many normalized solutions in $H^1_r(\\mathbb{R}^N)$.\nMoreover, our results cover several relevant existing results. And in the end,\nwe get the asymptotic properties of energy as $a$ tends to $+\\infty$ and $a$\ntends to $0^+$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T05:37:28Z"}
{"aid":"http://arxiv.org/abs/2504.11792v1","title":"Large Language Models for Drug Overdose Prediction from Longitudinal\n  Medical Records","summary":"The ability to predict drug overdose risk from a patient's medical records is\ncrucial for timely intervention and prevention. Traditional machine learning\nmodels have shown promise in analyzing longitudinal medical records for this\ntask. However, recent advancements in large language models (LLMs) offer an\nopportunity to enhance prediction performance by leveraging their ability to\nprocess long textual data and their inherent prior knowledge across diverse\ntasks. In this study, we assess the effectiveness of Open AI's GPT-4o LLM in\npredicting drug overdose events using patients' longitudinal insurance claims\nrecords. We evaluate its performance in both fine-tuned and zero-shot settings,\ncomparing them to strong traditional machine learning methods as baselines. Our\nresults show that LLMs not only outperform traditional models in certain\nsettings but can also predict overdose risk in a zero-shot setting without\ntask-specific training. These findings highlight the potential of LLMs in\nclinical decision support, particularly for drug overdose risk prediction.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-16T05:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.11801v1","title":"Ultra-fast and accurate multimode waveguide design based on\n  dataset-based eigenmode expansion method","summary":"We propose a dataset-based photonic simulation framework for multimode\nwaveguide design, enabling ultra-fast simulations with high accuracy. Compared\nto conventional approaches, our method offers two to three orders of magnitude\nspeed-up in complex multimode waveguide designs. Based on this approach, we\ndemonstrate a silicon multimode waveguide bend with an effective radius of\n$30\\,\\mu\\mathrm{m}$ under one second, with accuracy validated against\ncommercial 3D finite-difference time-domain method. We further explore its\nutility for device optimization by designing a $20\\,\\mu \\mathrm{m}$-radius,\narbitrary power splitting ratio bends through thousands of optimization\niterations, completed in just 68 minutes on a standard desktop CPU. This\nframework enables the rapid design and engineering of large-scale multimode\nphotonic devices, making computationally intensive simulations more accessible\nto many photonic circuit designers.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-16T06:17:19Z"}
{"aid":"http://arxiv.org/abs/2504.11802v1","title":"On the photon energy conservation in stimulated emission. Experiment","summary":"Quantum electrodynamics predicts identity of incident and emitted photons in\nstimulated emission. This fundamental law is important to test experimentally.\nIn this work stimulated emission in GaAs semiconductor amplifier was\ninvestigated and positive frequency shift of the amplified beam was detected.\nIn relative units this frequency shift was found equal $\\Delta\\nu/\\nu = (+1.7\n\\pm 0.2)\\cdot10^{-18}$. This indicates violation of the photon energy\nconservation in stimulated emission.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-16T06:17:28Z"}
{"aid":"http://arxiv.org/abs/2504.11805v1","title":"Network-Integrated Decoding System for Real-Time Quantum Error\n  Correction with Lattice Surgery","summary":"Existing real-time decoders for surface codes are limited to isolated logical\nqubits and do not support logical operations involving multiple logical qubits.\nWe present DECONET, a first-of-its-kind decoding system that scales to\nthousands of logical qubits and supports logical operations implemented through\nlattice surgery. DECONET organizes compute resources in a network-integrated\nhybrid tree-grid structure, which results in minimal latency increase and no\nthroughput degradation as the system grows. Specifically, DECONET can be scaled\nto any arbitrary number of $l$ logical qubits by increasing the compute\nresources by $O(l \\times log(l))$, which provides the required $O(l)$ growth in\nI/O resources while incurring only an $O(log(l))$ increase in latency-a modest\ngrowth that is sufficient for thousands of logical qubits. Moreover, we\nanalytically show that the scaling approach preserves throughput, keeping\nDECONET backlog-free for any number of logical qubits. We report an exploratory\nprototype of DECONET, called DECONET/HELIOS, built with five VMK-180 FPGAs,\nthat successfully decodes 100 logical qubits of distance five. For 100 logical\nqubits, under a phenomenological noise rate of 0.1%, the DECONET/HELIOS has an\naverage latency of 2.40 {\\mu}s and an inverse throughput of 0.84 {\\mu}s per\nmeasurement round.","main_category":"quant-ph","categories":"quant-ph,cs.DC,cs.NI","published":"2025-04-16T06:37:12Z"}
{"aid":"http://arxiv.org/abs/2504.11815v1","title":"On projection mappings and the gradient projection method on hyperbolic\n  space forms","summary":"This paper presents several new properties of the intrinsic\n$\\kappa$-projection into $\\kappa$-hyperbolically convex sets of\n$\\kappa$-hyperbolic space forms, along with closed-form formulas for the\nintrinsic $\\kappa$-projection into specific $\\kappa$-hyperbolically convex\nsets. It also discusses the relationship between the intrinsic\n$\\kappa$-projection, the Euclidean orthogonal projection, and the Lorentz\nprojection. These properties lay the groundwork for analyzing the gradient\nprojection method and hold importance in their own right. Additionally, new\nproperties of the gradient projection method to solve constrained optimization\nproblems in $\\kappa$-hyperbolic space forms are established, considering both\nconstant and backtracking step sizes in the analysis. It is shown that every\naccumulation point of the sequence generated by the method for both step sizes\nis a stationary point for the given problem. Additionally, an iteration\ncomplexity bound is provided that upper bounds the number of iterations needed\nto achieve a suitable measure of stationarity for both step sizes. Finally, the\nproperties of the constrained Fermat-Weber problem are explored, demonstrating\nthat the sequence generated by the gradient projection method converges to its\nunique solution. Numerical experiments on solving the Fermat-Weber problem are\npresented, illustrating the theoretical findings and demonstrating the\neffectiveness of the proposed methods.","main_category":"math.OC","categories":"math.OC,cs.NA,math.DG,math.NA","published":"2025-04-16T07:01:00Z"}
{"aid":"http://arxiv.org/abs/2504.11823v1","title":"Multi-goal Rapidly Exploring Random Tree with Safety and Dynamic\n  Constraints for UAV Cooperative Path Planning","summary":"Cooperative path planning is gaining its importance due to the increasing\ndemand on using multiple unmanned aerial vehicles (UAVs) for complex missions.\nThis work addresses the problem by introducing a new algorithm named MultiRRT\nthat extends the rapidly exploring random tree (RRT) to generate paths for a\ngroup of UAVs to reach multiple goal locations at the same time. We first\nderive the dynamics constraint of the UAV and include it in the problem\nformulation. MultiRRT is then developed, taking into account the cooperative\nrequirements and safe constraints during its path-searching process. The\nalgorithm features two new mechanisms, node reduction and Bezier interpolation,\nto ensure the feasibility and optimality of the paths generated. Importantly,\nthe interpolated paths are proven to meet the safety and dynamics constraints\nimposed by obstacles and the UAVs. A number of simulations, comparisons, and\nexperiments have been conducted to evaluate the performance of the proposed\napproach. The results show that MultiRRT can generate collision-free paths for\nmultiple UAVs to reach their goals with better scores in path length and\nsmoothness metrics than state-of-the-art RRT variants including Theta-RRT,\nFN-RRT, RRT*, and RRT*-Smart. The generated paths are also tested in practical\nflights with real UAVs to evaluate their validity for cooperative tasks. The\nsource code of the algorithm is available at\nhttps://github.com/duynamrcv/multi-target_RRT","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T07:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.11825v1","title":"TextDiffSeg: Text-guided Latent Diffusion Model for 3d Medical Images\n  Segmentation","summary":"Diffusion Probabilistic Models (DPMs) have demonstrated significant potential\nin 3D medical image segmentation tasks. However, their high computational cost\nand inability to fully capture global 3D contextual information limit their\npractical applications. To address these challenges, we propose a novel\ntext-guided diffusion model framework, TextDiffSeg. This method leverages a\nconditional diffusion framework that integrates 3D volumetric data with natural\nlanguage descriptions, enabling cross-modal embedding and establishing a shared\nsemantic space between visual and textual modalities. By enhancing the model's\nability to recognize complex anatomical structures, TextDiffSeg incorporates\ninnovative label embedding techniques and cross-modal attention mechanisms,\neffectively reducing computational complexity while preserving global 3D\ncontextual integrity. Experimental results demonstrate that TextDiffSeg\nconsistently outperforms existing methods in segmentation tasks involving\nkidney and pancreas tumors, as well as multi-organ segmentation scenarios.\nAblation studies further validate the effectiveness of key components,\nhighlighting the synergistic interaction between text fusion, image feature\nextractor, and label encoder. TextDiffSeg provides an efficient and accurate\nsolution for 3D medical image segmentation, showcasing its broad applicability\nin clinical diagnosis and treatment planning.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-16T07:17:36Z"}
{"aid":"http://arxiv.org/abs/2504.11834v1","title":"Estimation and inference in error-in-operator model","summary":"Many statistical problems can be reduced to a linear inverse problem in which\nonly a noisy version of the operator is available. Particular examples include\nrandom design regression, deconvolution problem, instrumental variable\nregression, functional data analysis, error-in-variable regression, drift\nestimation in stochastic diffusion, and many others. The pragmatic plug-in\napproach can be well justified in the classical asymptotic setup with a growing\nsample size. However, recent developments in high dimensional inference reveal\nsome new features of this problem. In high dimensional linear regression with a\nrandom design, the plug-in approach is questionable but the use of a simple\nridge penalization yields a benign overfitting phenomenon; see\n\\cite{baLoLu2020}, \\cite{ChMo2022}, \\cite{NoPuSp2024}. This paper revisits the\ngeneral Error-in-Operator problem for finite samples and high dimension of the\nsource and image spaces. A particular focus is on the choice of a proper\nregularization. We show that a simple ridge penalty (Tikhonov regularization)\nworks properly in the case when the operator is more regular than the signal.\nIn the opposite case, some model reduction technique like spectral truncation\nshould be applied.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-16T07:45:44Z"}
{"aid":"http://arxiv.org/abs/2504.11859v1","title":"Meta Theorem for Hardness on FCP-Problem","summary":"The Fewest Clues Problem (FCP) framework has been introduced to study the\ncomplexity of determining whether a solution to an \\NP~problem can be uniquely\nidentified by specifying a subset of the certificate. For a given problem $P\n\\in \\NP$, its FCP variant is denoted by FCP-$P$. While several \\NP-complete\nproblems have been shown to have $\\Sigma_2^\\p$-complete FCP variants, it\nremains open whether this holds for all \\NP-complete problems.\n  In this work, we propose a meta-theorem that establishes the\n$\\Sigma_2^\\p$-completeness of FCP-$P$ under the condition that the \\NP-hardness\nof $P$ is proven via a polynomial-time reduction satisfying certain structural\nproperties. Furthermore, we apply the meta-theorem to demonstrate the\n$\\Sigma_2^\\p$-completeness of the FCP variants of several \\NP-complete\nproblems.","main_category":"cs.CC","categories":"cs.CC,F.1.3","published":"2025-04-16T08:30:34Z"}
{"aid":"http://arxiv.org/abs/2504.11869v1","title":"Recovering the CMB signal with neural networks","summary":"Component separation is the process of extracting one or more emission\nsources in astrophysical maps. It is therefore crucial to develop models that\ncan accurately clean the cosmic microwave background (CMB) in current and\nfuture experiments. In this work, we present a new methodology based on neural\nnetworks which operates on realistic temperature and polarization simulations.\nWe assess its performance by comparing the power spectra of the output maps\nwith those of the input maps and other emissions. For temperature, we obtain\nresiduals of $20 \\pm \\mu K^{2}$. For polarization, we analyze the $E$ and $B$\nmodes, which are related to density (scalar) and primordial gravitational waves\n(tensorial) perturbations occurring in the first second of the Universe,\nobtaining residuals of $10^{-2} \\mu K^{2}$ at $l>200$ and $10^{-2}$ and\n$10^{-3} \\mu K^{2}$ for $E$ and $B$, respectively.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-04-16T08:44:46Z"}
{"aid":"http://arxiv.org/abs/2504.11871v1","title":"Channel-Adaptive Robust Resource Allocation for Highly Reliable\n  IRS-Assisted V2X Communications","summary":"This paper addresses the challenges of resource allocation in vehicular\nnetworks enhanced by Intelligent Reflecting Surfaces (IRS), considering the\nuncertain Channel State Information (CSI) typical of vehicular environments due\nto the Doppler shift. Leveraging the 3GPP's Mode 1 cellular V2X architecture,\nour system model facilitates efficient subcarrier usage and interference\nreduction through coordinated V2I and V2V communications. Each Cellular User\nEquipment (CUE) shares its spectrum with at most one Vehicular User Equipment\n(VUE) in a one-to-one reuse pattern. We formulate a joint optimization problem\nfor vehicular transmit power, Multi-User Detection (MUD) matrices, V2V link\nspectrum reuse, and IRS reflection coefficients in IRS-aided V2X communication\nwith imperfect CSI. To tackle this, a novel robust resource allocation\nalgorithm is developed by first decomposing the problem into manageable\nsub-problems such as power allocation, MUD matrices optimization and IRS phase\nshifts, and then using the Block Coordinate Descent (BCD) method to alternately\noptimize these subproblems for optimal resource allocation. Our contributions\ninclude efficient approaches for self-learning based power allocation and phase\nshift optimization that adapt to CSI uncertainties, significantly enhancing the\nreliability and efficiency of vehicular communications. Simulation results\nvalidate the effectiveness of the proposed solutions in improving the Quality\nof Service (QoS) and managing the complex interference inherent in dense\nvehicular networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T08:48:53Z"}
{"aid":"http://arxiv.org/abs/2504.11882v1","title":"Seeking and leveraging alternative variable dependency concepts in\n  gray-box-elusive bimodal land-use allocation problems","summary":"Solving land-use allocation problems can help us to deal with some of the\nmost urgent global environmental issues. Since these problems are NP-hard,\neffective optimizers are needed to handle them. The knowledge about variable\ndependencies allows for proposing such tools. However, in this work, we\nconsider a real-world multi-objective problem for which standard variable\ndependency discovery techniques are inapplicable. Therefore, using\nlinkage-based variation operators is unreachable. To address this issue, we\npropose a definition of problem-dedicated variable dependency. On this base, we\npropose obtaining masks of dependent variables. Using them, we construct three\nnovel crossover operators. The results concerning real-world test cases show\nthat introducing our propositions into two well-known optimizers (NSGA-II,\nMOEA/D) dedicated to multi-objective optimization significantly improves their\neffectiveness.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T09:06:55Z"}
{"aid":"http://arxiv.org/abs/2504.11884v1","title":"Training and synchronizing oscillator networks with Equilibrium\n  Propagation","summary":"Oscillator networks represent a promising technology for unconventional\ncomputing and artificial intelligence. Thus far, these systems have primarily\nbeen demonstrated in small-scale implementations, such as Ising Machines for\nsolving combinatorial problems and associative memories for image recognition,\ntypically trained without state-of-the-art gradient-based algorithms. Scaling\nup oscillator-based systems requires advanced gradient-based training methods\nthat also ensure robustness against frequency dispersion between individual\noscillators. Here, we demonstrate through simulations that the Equilibrium\nPropagation algorithm enables effective gradient-based training of oscillator\nnetworks, facilitating synchronization even when initial oscillator frequencies\nare significantly dispersed. We specifically investigate two oscillator models:\npurely phase-coupled oscillators and oscillators coupled via both amplitude and\nphase interactions. Our results show that these oscillator networks can scale\nsuccessfully to standard image recognition benchmarks, such as achieving nearly\n98\\% test accuracy on the MNIST dataset, despite noise introduced by imperfect\nsynchronization. This work thus paves the way for practical hardware\nimplementations of large-scale oscillator networks, such as those based on\nspintronic devices.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cs.ET","published":"2025-04-16T09:10:31Z"}
{"aid":"http://arxiv.org/abs/2504.11906v1","title":"Testing of tempered fractional Brownian motions","summary":"We propose here a testing methodology based on the autocovariance, detrended\nmoving average, and time-averaged mean-squared displacement statistics for\ntempered fractional Brownian motions (TFBMs) which are related to the notions\nof semi-long range dependence and transient anomalous diffusion. In this\nframework, we consider three types of TFBMs: two with a tempering factor\nincorporated into their moving-average representation, and one with a tempering\nparameter added to the autocorrelation formula. We illustrate their dynamics\nwith the use of quantile lines. Using the proposed methodology, we provide a\ncomprehensive power analysis of the tests. It appears that the tests allow\ndistinguishing between the tempered processes with different Hurst parameters.","main_category":"stat.ME","categories":"stat.ME,physics.data-an","published":"2025-04-16T09:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.11914v1","title":"AnomalyR1: A GRPO-based End-to-end MLLM for Industrial Anomaly Detection","summary":"Industrial Anomaly Detection (IAD) poses a formidable challenge due to the\nscarcity of defective samples, making it imperative to deploy models capable of\nrobust generalization to detect unseen anomalies effectively. Traditional\napproaches, often constrained by hand-crafted features or domain-specific\nexpert models, struggle to address this limitation, underscoring the need for a\nparadigm shift. We introduce AnomalyR1, a pioneering framework that leverages\nVLM-R1, a Multimodal Large Language Model (MLLM) renowned for its exceptional\ngeneralization and interpretability, to revolutionize IAD. By integrating MLLM\nwith Group Relative Policy Optimization (GRPO), enhanced by our novel Reasoned\nOutcome Alignment Metric (ROAM), AnomalyR1 achieves a fully end-to-end solution\nthat autonomously processes inputs of image and domain knowledge, reasons\nthrough analysis, and generates precise anomaly localizations and masks. Based\non the latest multimodal IAD benchmark, our compact 3-billion-parameter model\noutperforms existing methods, establishing state-of-the-art results. As MLLM\ncapabilities continue to advance, this study is the first to deliver an\nend-to-end VLM-based IAD solution that demonstrates the transformative\npotential of ROAM-enhanced GRPO, positioning our framework as a forward-looking\ncornerstone for next-generation intelligent anomaly detection systems in\nindustrial applications with limited defective data.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T09:48:41Z"}
{"aid":"http://arxiv.org/abs/2504.11936v1","title":"Mind2Matter: Creating 3D Models from EEG Signals","summary":"The reconstruction of 3D objects from brain signals has gained significant\nattention in brain-computer interface (BCI) research. Current research\npredominantly utilizes functional magnetic resonance imaging (fMRI) for 3D\nreconstruction tasks due to its excellent spatial resolution. Nevertheless, the\nclinical utility of fMRI is limited by its prohibitive costs and inability to\nsupport real-time operations. In comparison, electroencephalography (EEG)\npresents distinct advantages as an affordable, non-invasive, and mobile\nsolution for real-time brain-computer interaction systems. While recent\nadvances in deep learning have enabled remarkable progress in image generation\nfrom neural data, decoding EEG signals into structured 3D representations\nremains largely unexplored. In this paper, we propose a novel framework that\ntranslates EEG recordings into 3D object reconstructions by leveraging neural\ndecoding techniques and generative models. Our approach involves training an\nEEG encoder to extract spatiotemporal visual features, fine-tuning a large\nlanguage model to interpret these features into descriptive multimodal outputs,\nand leveraging generative 3D Gaussians with layout-guided control to synthesize\nthe final 3D structures. Experiments demonstrate that our model captures\nsalient geometric and semantic features, paving the way for applications in\nbrain-computer interfaces (BCIs), virtual reality, and neuroprosthetics.Our\ncode is available in https://github.com/sddwwww/Mind2Matter.","main_category":"cs.GR","categories":"cs.GR,cs.HC,eess.SP","published":"2025-04-16T10:16:03Z"}
{"aid":"http://arxiv.org/abs/2504.11944v1","title":"VIPO: Value Function Inconsistency Penalized Offline Reinforcement\n  Learning","summary":"Offline reinforcement learning (RL) learns effective policies from\npre-collected datasets, offering a practical solution for applications where\nonline interactions are risky or costly. Model-based approaches are\nparticularly advantageous for offline RL, owing to their data efficiency and\ngeneralizability. However, due to inherent model errors, model-based methods\noften artificially introduce conservatism guided by heuristic uncertainty\nestimation, which can be unreliable. In this paper, we introduce VIPO, a novel\nmodel-based offline RL algorithm that incorporates self-supervised feedback\nfrom value estimation to enhance model training. Specifically, the model is\nlearned by additionally minimizing the inconsistency between the value learned\ndirectly from the offline data and the one estimated from the model. We perform\ncomprehensive evaluations from multiple perspectives to show that VIPO can\nlearn a highly accurate model efficiently and consistently outperform existing\nmethods. It offers a general framework that can be readily integrated into\nexisting model-based offline RL algorithms to systematically enhance model\naccuracy. As a result, VIPO achieves state-of-the-art performance on almost all\ntasks in both D4RL and NeoRL benchmarks.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T10:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.11958v1","title":"Initial Condition Independent Stabilisability of Switched Affine Systems","summary":"We have previously demonstrated that a switched affine system is stabilisable\nindependently of the initial condition, i.e. there exists an asymptotically\nstabilising switching function which is the same for all initial conditions, if\nand only if there exists a stable convex combination of the sub-system\nmatrices. This result was proven by constructing a stabilising switching\nfunction of unbounded switching frequency. The current paper proves that there\nexists a switching function with bounded switching frequency which stabilises a\nswitched affine system independent of its initial condition.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T10:41:06Z"}
{"aid":"http://arxiv.org/abs/2504.11974v1","title":"Who Said Only Military Officers Can Deal with Uncertainty? On the\n  Importance of Uncertainty in EdTech Data Visualisations","summary":"AI-powered predictive systems have high margins of error. However, data\nvisualisations of algorithmic systems in education and other social fields tend\nto visualise certainty, thus invisibilising the underlying approximations and\nuncertainties of the algorithmic systems and the social settings in which these\nsystems operate. This paper draws on a critical speculative approach to first\nanalyse data visualisations from predictive analytics platforms for education.\nIt demonstrates that visualisations of uncertainty in education are rare.\nSecond, the paper explores uncertainty visualisations in other fields (defence,\nclimate change and healthcare). The paper concludes by reflecting on the role\nof data visualisations and un/certainty in shaping educational futures. It also\nidentifies practical implications for the design of data visualisations in\neducation.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-16T11:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.11975v1","title":"SemEval-2025 Task 3: Mu-SHROOM, the Multilingual Shared Task on\n  Hallucinations and Related Observable Overgeneration Mistakes","summary":"We present the Mu-SHROOM shared task which is focused on detecting\nhallucinations and other overgeneration mistakes in the output of\ninstruction-tuned large language models (LLMs). Mu-SHROOM addresses\ngeneral-purpose LLMs in 14 languages, and frames the hallucination detection\nproblem as a span-labeling task. We received 2,618 submissions from 43\nparticipating teams employing diverse methodologies. The large number of\nsubmissions underscores the interest of the community in hallucination\ndetection. We present the results of the participating systems and conduct an\nempirical analysis to identify key factors contributing to strong performance\nin this task. We also emphasize relevant current challenges, notably the\nvarying degree of hallucinations across languages and the high annotator\ndisagreement when labeling hallucination spans.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T11:15:26Z"}
{"aid":"http://arxiv.org/abs/2504.11977v1","title":"Leveraging Machine Learning Models to Predict the Outcome of Digital\n  Medical Triage Interviews","summary":"Many existing digital triage systems are questionnaire-based, guiding\npatients to appropriate care levels based on information (e.g., symptoms,\nmedical history, and urgency) provided by the patients answering\nquestionnaires. Such a system often uses a deterministic model with predefined\nrules to determine care levels. It faces challenges with incomplete triage\ninterviews since it can only assist patients who finish the process. In this\nstudy, we explore the use of machine learning (ML) to predict outcomes of\nunfinished interviews, aiming to enhance patient care and service quality.\nPredicting triage outcomes from incomplete data is crucial for patient safety\nand healthcare efficiency. Our findings show that decision-tree models,\nparticularly LGBMClassifier and CatBoostClassifier, achieve over 80\\% accuracy\nin predicting outcomes from complete interviews while having a linear\ncorrelation between the prediction accuracy and interview completeness degree.\nFor example, LGBMClassifier achieves 88,2\\% prediction accuracy for interviews\nwith 100\\% completeness, 79,6\\% accuracy for interviews with 80\\% completeness,\n58,9\\% accuracy for 60\\% completeness, and 45,7\\% accuracy for 40\\%\ncompleteness. The TabTransformer model demonstrated exceptional accuracy of\nover 80\\% for all degrees of completeness but required extensive training time,\nindicating a need for more powerful computational resources. The study\nhighlights the linear correlation between interview completeness and predictive\npower of the decision-tree models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T11:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.11985v1","title":"A Heavy-Metal Scenario of Ultra-High-Energy Cosmic Rays","summary":"The mass composition of ultra-high-energy cosmic rays is an open problem in\nastroparticle physics. It is usually inferred from the depth of the shower\nmaximum (Xmax) of cosmic-ray showers, which is only ambiguously determined by\nmodern hadronic interaction models. We examine a data-driven scenario, in which\nwe consider the expectation value of Xmax as a free parameter. We test the\nnovel hypothesis whether the cosmic-ray data from the Pierre Auger Observatory\ncan be interpreted in a consistent picture, under the assumption that the mass\ncomposition of cosmic rays at the highest energies is dominated by high\nmetallicity, resulting in pure iron nuclei at energies above ~40 EeV. We\ninvestigate the implications on astrophysical observations and hadronic\ninteractions, and we discuss the global consistency of the data assuming this\nheavy-metal scenario. We conclude that the data from the Pierre Auger\nObservatory can be interpreted consistently if the expectation values for Xmax\nfrom modern hadronic interaction models are shifted to larger values.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T11:27:23Z"}
{"aid":"http://arxiv.org/abs/2504.11988v1","title":"Strong Convergence Rates for Euler Schemes of Levy-Driven SDE using\n  Dynamic Cutting","summary":"We derive strong Lp convergence rates for the Euler-Maruyama schemes of\nLevy-driven SDE using a new dynamic cutting (DC) method with a time-dependent\njump threshold. In addition, we present results from numerical simulations\ncomparing the DC and Asmussen-Rosinski (AR) approaches. These simulations\ndemonstrate the superior accuracy achieved by the DC method.","main_category":"math.PR","categories":"math.PR,cs.NA,math.NA","published":"2025-04-16T11:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.12000v1","title":"Control of Rayleigh-BÃ©nard Convection: Effectiveness of Reinforcement\n  Learning in the Turbulent Regime","summary":"Data-driven flow control has significant potential for industry, energy\nsystems, and climate science. In this work, we study the effectiveness of\nReinforcement Learning (RL) for reducing convective heat transfer in the 2D\nRayleigh-B\\'enard Convection (RBC) system under increasing turbulence. We\ninvestigate the generalizability of control across varying initial conditions\nand turbulence levels and introduce a reward shaping technique to accelerate\nthe training. RL agents trained via single-agent Proximal Policy Optimization\n(PPO) are compared to linear proportional derivative (PD) controllers from\nclassical control theory. The RL agents reduced convection, measured by the\nNusselt Number, by up to 33% in moderately turbulent systems and 10% in highly\nturbulent settings, clearly outperforming PD control in all settings. The\nagents showed strong generalization performance across different initial\nconditions and to a significant extent, generalized to higher degrees of\nturbulence. The reward shaping improved sample efficiency and consistently\nstabilized the Nusselt Number to higher turbulence levels.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-16T11:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.12006v1","title":"Comment on Path integral measure and RG equations for gravity","summary":"Asymptotic safety is a candidate for a predictive quantum theory of gravity\nand matter. Recent works (arXiv:2412.10194 and arXiv:2412.14108) challenged\nthis scenario. We show that their arguments fail on a basic level.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T12:00:22Z"}
{"aid":"http://arxiv.org/abs/2504.12007v1","title":"Generative Recommendation with Continuous-Token Diffusion","summary":"In recent years, there has been a significant trend toward using large\nlanguage model (LLM)-based recommender systems (RecSys). Current research\nprimarily focuses on representing complex user-item interactions within a\ndiscrete space to align with the inherent discrete nature of language models.\nHowever, this approach faces limitations due to its discrete nature: (i)\ninformation is often compressed during discretization; (ii) the tokenization\nand generation for the vast number of users and items in real-world scenarios\nare constrained by a limited vocabulary. Embracing continuous data presents a\npromising alternative to enhance expressive capabilities, though this approach\nis still in its early stages. To address this gap, we propose a novel\nframework, DeftRec, which incorporates \\textbf{de}noising di\\textbf{f}fusion\nmodels to enable LLM-based RecSys to seamlessly support continuous\n\\textbf{t}oken as input and target. First, we introduce a robust tokenizer with\na masking operation and an additive K-way architecture to index users and\nitems, capturing their complex collaborative relationships into continuous\ntokens. Crucially, we develop a denoising diffusion model to process user\npreferences within continuous domains by conditioning on reasoning content from\npre-trained large language model. During the denoising process, we reformulate\nthe objective to include negative interactions, building a comprehensive\nunderstanding of user preferences for effective and accurate recommendation\ngeneration. Finally, given a continuous token as output, recommendations can be\neasily generated through score-based retrieval. Extensive experiments\ndemonstrate the effectiveness of the proposed methods, showing that DeftRec\nsurpasses competitive benchmarks, including both traditional and emerging\nLLM-based RecSys.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-16T12:01:03Z"}
{"aid":"http://arxiv.org/abs/2504.12009v1","title":"Network-Centric Countermeasures Against Integrated Sensing Enabled\n  Jamming Adversaries","summary":"Recent developments in Integrated Sensing and Communication have led to new\nadversarial models in wireless security through Integrated Sensing and Jamming\n(ISAJ) adversaries. ISAJ adversaries, owing to their sensing capabilities, are\nknown to inject jamming energy over the victim's frequency band, and also use\ngeneralized energy measurements on various network frequencies to detect the\npresence of countermeasures. Existing countermeasures against such ISAJ\nadversaries are laid under the assumption that the adversary does not have the\nknowledge of the countermeasure. However, according to Kerchoffs' principle in\ncryptography, security of a countermeasure should only rely on the secret-keys,\nnot on the obfuscation of the countermeasure. On testing the security of\nexisting countermeasures, we observe that they violate Kerchoffs' principle,\nthus motivating the need for new countermeasures. In this regard, we propose a\nnovel network-centric countermeasure against ISAJ adversaries, wherein a group\nof users in the network assist the victim to reliably communicate her messages\nin a covert manner. Firstly, we analyse the error performance of the proposed\ncountermeasure, and study its behavior on the number of assisting users in the\nnetwork. Subsequently, to validate its security against Kerchoffs' principle,\nwe study the Shannon's entropy associated with the presence of the victim's\nmessages in the network and analyse its behaviour as a function of the number\nof assisting users. Finally, to study the interplay between reliability and\ncovertness, we pose interesting optimization problems and solve them to choose\nthe underlying parameters of the countermeasure and the number of assisting\nusers.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T12:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.12040v1","title":"No equivalence between hydrodynamic and dispersive mass of the charged\n  polaron","summary":"We consider the problem of a charged impurity exerting a weak, slowly\ndecaying force on its surroundings, treating the latter as an ideal\ncompressible fluid. In the semiclassical approximation, the ion is described by\nthe Newton equation coupled to the Euler equation for the medium. After\nlinearization, we obtain a simple closed formula for the effective mass of the\nimpurity, depending on the interaction potential, the mean medium density, and\nsound velocity. Thus, once the interaction and the equation of state of the\nfluid is known, an estimate of the hydrodynamic effective mass can be quickly\nprovided. Going beyond the classical case, we show that replacing the Newton\nwith Schr\\\"{o}dinger equation can drastically change the behavior of the\nimpurity. In particular, the scaling of the Fermi polaron effective mass with\nthe medium density is opposite in quantum and classical scenario. Our results\nare relevant for experimental systems featuring low energy impurities in Fermi\nor Bose systems, such as ions immersed in neutral atomic gases.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.flu-dyn,quant-ph","published":"2025-04-16T12:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.12071v1","title":"Generalized Restart Mechanism for Successive-Cancellation Flip Decoding\n  of Polar Codes","summary":"Polar codes are a class of linear error-correction codes that have received a\nlot of attention due to their ability to achieve channel capacity in an\narbitrary binary discrete memoryless channel (B-DMC) with low-complexity\nsuccessive-cancellation (SC) decoding. However, practical implementations often\nrequire better error-correction performance than what SC decoding provides,\nparticularly at short to moderate code lengths. Successive-cancellation flip\n(SCF) decoding algorithm was proposed to improve error-correction performance\nwith an aim to detect and correct the first wrongly estimated bit in a codeword\nbefore resuming SC decoding. At each additional SC decoding trial, i.e.,\ndecoding attempt beyond the initial unsuccessful trial, one bit estimated as\nthe least reliable is flipped. Dynamic SCF (DSCF) is a variation of SCF, where\nmultiple bits may be flipped simultaneously per trial. Despite the improved\nerror-correction performance compared to the SC decoder, SCF-based decoders\nhave variable execution time, which leads to high average execution time and\nlatency. In this work, we propose the generalized restart mechanism (GRM) that\nallows to skip decoding computations that are identical between the initial\ntrial and any additional trial. Under DSCF decoding with up to 3-bit flips per\ndecoding trial, our proposed GRM is shown to reduce the average execution time\nby 25% to 60% without any negative effect on error-correction performance. The\nproposed mechanism is adaptable to state-of-the-art latency-reduction\ntechniques. When applied to Fast-DSCF-3 decoding, the additional reduction\nbrought by the GRM is 15% to 22%. For the DSCF-3 decoder, the proposed\nmechanism requires approximately 4% additional memory.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T13:26:30Z"}
{"aid":"http://arxiv.org/abs/2504.12074v1","title":"Learning from the Past: Adaptive Parallelism Tuning for Stream\n  Processing Systems","summary":"Distributed stream processing systems rely on the dataflow model to define\nand execute streaming jobs, organizing computations as Directed Acyclic Graphs\n(DAGs) of operators. Adjusting the parallelism of these operators is crucial to\nhandling fluctuating workloads efficiently while balancing resource usage and\nprocessing performance. However, existing methods often fail to effectively\nutilize execution histories or fully exploit DAG structures, limiting their\nability to identity bottlenecks and determine the optimal parallelism. In this\npaper, we propose StreamTune, a novel approach for adaptive paralelism tuning\nin stream processing systems. StreamTune incorporates a pre-training and\nfine-tuning framework that leverages global knowledge from historical execution\ndata for job-specific parallelism tuning. In the pre-training phase, Stream\nTune clusters the historical data with Graph Edit Distance and pre-trains a\nGraph Neural Networkbased encoder per cluster to capture the correlation\nbetween the operator parallelism, DAG structures, and the identified\noperator-level bottlenecks. In the online tuning phase, StreamTune iteratively\nrefines operator parallelism recommendations using an operator-level bottleneck\nprediction model enforced with a monotonic constraint, which aligns with the\nobserved system performance behavior. Evaluation results demonstrate that\nStreamTune reduces reconfigurations by up to 29.6% and parallelism degrees by\nup to 30.8% in Apache Flink under a synthetic workload. In Timely Dataflow,\nStreamTune achieves up to an 83.3% reduction in parallelism degrees while\nmaintaining comparable processing performance under the Nexmark benchmark, when\ncompared to the state-of-the-art methods.","main_category":"cs.DC","categories":"cs.DC,cs.DB","published":"2025-04-16T13:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.12076v1","title":"Subitizing-Inspired_Large_Language_Models_for_Floorplanning","summary":"We present a novel approach to solving the floorplanning problem by\nleveraging fine-tuned Large Language Models (LLMs). Inspired by subitizing--the\nhuman ability to instantly and accurately count small numbers of items at a\nglance--we hypothesize that LLMs can similarly address floorplanning challenges\nswiftly and accurately. We propose an efficient representation of the\nfloorplanning problem and introduce a method for generating high-quality\ndatasets tailored for model fine-tuning. We fine-tune LLMs on datasets with a\nspecified number of modules to test whether LLMs can emulate the human ability\nto quickly count and arrange items. Our experimental results demonstrate that\nfine-tuned LLMs, particularly GPT4o-mini, achieve high success and optimal\nrates while attaining relatively low average dead space. These findings\nunderscore the potential of LLMs as promising solutions for complex\noptimization tasks in VLSI design.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-16T13:35:41Z"}
{"aid":"http://arxiv.org/abs/2504.12090v1","title":"Reasoning-Based AI for Startup Evaluation (R.A.I.S.E.): A\n  Memory-Augmented, Multi-Step Decision Framework","summary":"We present a novel framework that bridges the gap between the\ninterpretability of decision trees and the advanced reasoning capabilities of\nlarge language models (LLMs) to predict startup success. Our approach leverages\nchain-of-thought prompting to generate detailed reasoning logs, which are\nsubsequently distilled into structured, human-understandable logical rules. The\npipeline integrates multiple enhancements - efficient data ingestion, a\ntwo-step refinement process, ensemble candidate sampling, simulated\nreinforcement learning scoring, and persistent memory - to ensure both stable\ndecision-making and transparent output. Experimental evaluations on curated\nstartup datasets demonstrate that our combined pipeline improves precision by\n54% from 0.225 to 0.346 and accuracy by 50% from 0.46 to 0.70 compared to a\nstandalone OpenAI o3 model. Notably, our model achieves over 2x the precision\nof a random classifier (16%). By combining state-of-the-art AI reasoning with\nexplicit rule-based explanations, our method not only augments traditional\ndecision-making processes but also facilitates expert intervention and\ncontinuous policy refinement. This work lays the foundation for the\nimplementation of interpretable LLM-powered decision frameworks in high-stakes\ninvestment environments and other domains that require transparent and\ndata-driven insights.","main_category":"cs.AI","categories":"cs.AI,I.2.7","published":"2025-04-16T13:53:42Z"}
{"aid":"http://arxiv.org/abs/2504.12095v1","title":"The Gray graph is pseudo 2-factor isomorphic","summary":"A graph is pseudo 2-factor isomorphic if all of its 2-factors have the same\nparity of number of cycles. Abreu et al. [J. Comb. Theory, Ser. B. 98 (2008)\n432--442] conjectured that $K_{3,3}$, the Heawood graph and the Pappus graph\nare the only essentially 4-edge-connected pseudo 2-factor isomorphic cubic\nbipartite graphs. This conjecture was disproved by Goedgebeur [Discr. Appl.\nMath. 193 (2015) 57--60] who constructed a counterexample $\\mathcal{G}$ (of\ngirth 6) on 30 vertices. Using a computer search, he also showed that this is\nthe only counterexample up to at least 40 vertices and that there are no\ncounterexamples of girth greater than 6 up to at least 48 vertices.\n  In this manuscript, we show that the Gray graph -- which has 54 vertices and\ngirth 8 -- is also a counterexample to the pseudo 2-factor isomorphic graph\nconjecture. Next to the graph $\\mathcal{G}$, this is the only other known\ncounterexample. Using a computer search, we show that there are no smaller\ncounterexamples of girth 8 and show that there are no other counterexamples up\nto at least 42 vertices of any girth. Moreover, we also verified that there are\nno further counterexamples among the known censuses of symmetrical graphs.\n  Recall that a graph is 2-factor Hamiltonian if all of its 2-factors are\nHamiltonian cycles. As a by-product of the computer searches performed for this\npaper, we have verified that the $2$-factor Hamiltonian conjecture of Funk et\nal. [J. Comb. Theory, Ser. B. 87(1) (2003) 138--144], which is still open,\nholds for cubic bipartite graphs of girth at least 8 up to 52 vertices, and up\nto 42 vertices for any girth.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-16T13:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.12108v1","title":"Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust\n  and Traceable Text Generation","summary":"The rapid development of Large Language Models (LLMs) has intensified\nconcerns about content traceability and potential misuse. Existing watermarking\nschemes for sampled text often face trade-offs between maintaining text quality\nand ensuring robust detection against various attacks. To address these issues,\nwe propose a novel watermarking scheme that improves both detectability and\ntext quality by introducing a cumulative watermark entropy threshold. Our\napproach is compatible with and generalizes existing sampling functions,\nenhancing adaptability. Experimental results across multiple LLMs show that our\nscheme significantly outperforms existing methods, achieving over 80\\%\nimprovements on widely-used datasets, e.g., MATH and GSM8K, while maintaining\nhigh detection accuracy.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T14:16:38Z"}
{"aid":"http://arxiv.org/abs/2504.12113v1","title":"Clarifying Ambiguities: on the Role of Ambiguity Types in Prompting\n  Methods for Clarification Generation","summary":"In information retrieval (IR), providing appropriate clarifications to better\nunderstand users' information needs is crucial for building a proactive\nsearch-oriented dialogue system. Due to the strong in-context learning ability\nof large language models (LLMs), recent studies investigate prompting methods\nto generate clarifications using few-shot or Chain of Thought (CoT) prompts.\nHowever, vanilla CoT prompting does not distinguish the characteristics of\ndifferent information needs, making it difficult to understand how LLMs resolve\nambiguities in user queries. In this work, we focus on the concept of ambiguity\nfor clarification, seeking to model and integrate ambiguities in the\nclarification process. To this end, we comprehensively study the impact of\nprompting schemes based on reasoning and ambiguity for clarification. The idea\nis to enhance the reasoning abilities of LLMs by limiting CoT to predict first\nambiguity types that can be interpreted as instructions to clarify, then\ncorrespondingly generate clarifications. We name this new prompting scheme\nAmbiguity Type-Chain of Thought (AT-CoT). Experiments are conducted on various\ndatasets containing human-annotated clarifying questions to compare AT-CoT with\nmultiple baselines. We also perform user simulations to implicitly measure the\nquality of generated clarifications under various IR scenarios.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-16T14:21:02Z"}
{"aid":"http://arxiv.org/abs/2504.12117v1","title":"The $L_p$ Minkowski problems on affine dual quermassintegrals","summary":"In this paper, we provided $L_p$ curvature measures of affine dual\nquermassintegrals for $p\\in\\mathbb{R}$, and solved the existence part of the\n$L_p$ Minkowski problems for the non-symmetric measures when $p>1$ and\nsymmetric measures when $p\\geq0$. When $p=0$, this is the affine dual Minkowski\nproblems, which is introduced and solved by Cai-Leng-Wu-Xi in [7].","main_category":"math.MG","categories":"math.MG","published":"2025-04-16T14:27:47Z"}
{"aid":"http://arxiv.org/abs/2504.12165v1","title":"CodingHomo: Bootstrapping Deep Homography With Video Coding","summary":"Homography estimation is a fundamental task in computer vision with\napplications in diverse fields. Recent advances in deep learning have improved\nhomography estimation, particularly with unsupervised learning approaches,\noffering increased robustness and generalizability. However, accurately\npredicting homography, especially in complex motions, remains a challenge. In\nresponse, this work introduces a novel method leveraging video coding,\nparticularly by harnessing inherent motion vectors (MVs) present in videos. We\npresent CodingHomo, an unsupervised framework for homography estimation. Our\nframework features a Mask-Guided Fusion (MGF) module that identifies and\nutilizes beneficial features among the MVs, thereby enhancing the accuracy of\nhomography prediction. Additionally, the Mask-Guided Homography Estimation\n(MGHE) module is presented for eliminating undesired features in the\ncoarse-to-fine homography refinement process. CodingHomo outperforms existing\nstate-of-the-art unsupervised methods, delivering good robustness and\ngeneralizability. The code and dataset are available at:\n\\href{github}{https://github.com/liuyike422/CodingHomo","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T15:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.12170v1","title":"AI Behind Closed Doors: a Primer on The Governance of Internal\n  Deployment","summary":"The most advanced future AI systems will first be deployed inside the\nfrontier AI companies developing them. According to these companies and\nindependent experts, AI systems may reach or even surpass human intelligence\nand capabilities by 2030. Internal deployment is, therefore, a key source of\nbenefits and risks from frontier AI systems. Despite this, the governance of\nthe internal deployment of highly advanced frontier AI systems appears absent.\nThis report aims to address this absence by priming a conversation around the\ngovernance of internal deployment. It presents a conceptualization of internal\ndeployment, learnings from other sectors, reviews of existing legal frameworks\nand their applicability, and illustrative examples of the type of scenarios we\nare most concerned about. Specifically, it discusses the risks correlated to\nthe loss of control via the internal application of a misaligned AI system to\nthe AI research and development pipeline, and unconstrained and undetected\npower concentration behind closed doors. The report culminates with a small\nnumber of targeted recommendations that provide a first blueprint for the\ngovernance of internal deployment.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-16T15:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.12177v1","title":"Mapping Controversies Using Artificial Intelligence: An Analysis of the\n  Hamas-Israel Conflict on YouTube","summary":"This article analyzes the Hamas-Israel controversy through 253,925\nSpanish-language YouTube comments posted between October 2023 and January 2024,\nfollowing the October 7 attack that escalated the conflict. Adopting an\ninterdisciplinary approach, the study combines the analysis of controversies\nfrom Science and Technology Studies (STS) with advanced computational\nmethodologies, specifically Natural Language Processing (NLP) using the BERT\n(Bidirectional Encoder Representations from Transformers) model. Using this\napproach, the comments were automatically classified into seven categories,\nreflecting pro-Palestinian, pro-Israeli, anti- Palestinian, anti-Israeli\npositions, among others. The results show a predominance of pro- Palestinian\ncomments, although pro-Israeli and anti-Palestinian comments received more\n\"likes.\" This study also applies the agenda-setting theory to demonstrate how\nmedia coverage significantly influences public perception, observing a notable\nshift in public opinion, transitioning from a pro- Palestinian stance to a more\ncritical position towards Israel. This work highlights the importance of\ncombining social science perspectives with technological tools in the analysis\nof controversies, presenting a methodological innovation by integrating\ncomputational analysis with critical social theories to address complex public\nopinion phenomena and media narratives.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T15:27:57Z"}
{"aid":"http://arxiv.org/abs/2504.12182v1","title":"Domains, Information Frames, and Their Logic","summary":"In \\cite{sp25}, continuous information frames were introduced that capture\nexactly all continuous domains. They are obtained from the information frames\nconsidered in \\cite{sp21} by omitting the conservativity requirement.\nInformation frames generalise Scott's information systems~\\cite{sc82}: Instead\nof the global consistency predicate, there is now a local consistency predicate\nfor each token. Strong information frames are obtained by strengthening the\nconditions for these predicates. Let $\\CIF$ and $\\SIF$ be the corresponding\ncategories.\n  In \\cite{sxx08} another generalisation of Scott's information systems was\nintroduced which also exactly captures all continuous domains. As shown in\n\\cite{hzl15}, the definition can be simplified while maintaining the\nrepresentation result. Let $\\CIS$ and $\\SCIS$ be the corresponding categories.\nIt is shown that all these categories are equivalent. Moreover, the equivalence\nextends to the subcategories of (strong) continuous information frames with\ntruth elements. Such information frames capture exactly all pointed continuous\ndomains.\n  Continuous information frames are families of rudimentary logics, associated\nwith each token is a local consistency predicate and an entailment relation.\nHowever, they lack the expressive power of propositional logic. In an attempt\nto make each of this logics more expressible, continuous stratified conjunctive\nlogics are introduced. These are families of conjunctive logics. The category\n$\\CSL$ of such logics is shown to be isomorphic to $\\SIF_{\\bt}$, the category\nof strong continuous information frames with a truth element.","main_category":"cs.LO","categories":"cs.LO,F.3.1","published":"2025-04-16T15:38:59Z"}
{"aid":"http://arxiv.org/abs/2504.12184v1","title":"Feature Selection for Data-driven Explainable Optimization","summary":"Mathematical optimization, although often leading to NP-hard models, is now\ncapable of solving even large-scale instances within reasonable time. However,\nthe primary focus is often placed solely on optimality. This implies that while\nobtained solutions are globally optimal, they are frequently not comprehensible\nto humans, in particular when obtained by black-box routines. In contrast,\nexplainability is a standard requirement for results in Artificial\nIntelligence, but it is rarely considered in optimization yet. There are only a\nfew studies that aim to find solutions that are both of high quality and\nexplainable. In recent work, explainability for optimization was defined in a\ndata-driven manner: a solution is considered explainable if it closely\nresembles solutions that have been used in the past under similar\ncircumstances. To this end, it is crucial to identify a preferably small subset\nof features from a presumably large set that can be used to explain a solution.\nIn mathematical optimization, feature selection has received little attention\nyet. In this work, we formally define the feature selection problem for\nexplainable optimization and prove that its decision version is NP-complete. We\nintroduce mathematical models for optimized feature selection. As their global\nsolution requires significant computation time with modern mixed-integer linear\nsolvers, we employ local heuristics. Our computational study using data that\nreflect real-world scenarios demonstrates that the problem can be solved\npractically efficiently for instances of reasonable size.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T15:40:03Z"}
{"aid":"http://arxiv.org/abs/2504.12194v1","title":"The Optimal Condition Number for ReLU Function","summary":"ReLU is a widely used activation function in deep neural networks. This paper\nexplores the stability properties of the ReLU map. For any weight matrix\n$\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$ and bias vector $\\boldsymbol{b}\n\\in \\mathbb{R}^{m}$ at a given layer, we define the condition number\n$\\beta_{\\boldsymbol{A},\\boldsymbol{b}}$ as\n$\\beta_{\\boldsymbol{A},\\boldsymbol{b}} =\n\\frac{\\mathcal{U}_{\\boldsymbol{A},\\boldsymbol{b}}}{\\mathcal{L}_{\\boldsymbol{A},\\boldsymbol{b}}}$,\nwhere $\\mathcal{U}_{\\boldsymbol{A},\\boldsymbol{b}}$\n  and $\\mathcal{L}_{\\boldsymbol{A},\\boldsymbol{b}}$ are the upper and lower\nLipschitz constants, respectively. We first demonstrate that for any given\n$\\boldsymbol{A}$ and $\\boldsymbol{b}$, the condition number satisfies\n$\\beta_{\\boldsymbol{A},\\boldsymbol{b}} \\geq \\sqrt{2}$. Moreover, when the\nweights of the network at a given layer are initialized as random i.i.d.\nGaussian variables and the bias term is set to zero, the condition number\nasymptotically approaches this lower bound. This theoretical finding suggests\nthat Gaussian weight initialization is optimal for preserving distances in the\ncontext of random deep neural network weights.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T15:47:38Z"}
{"aid":"http://arxiv.org/abs/2504.12214v1","title":"Bayesian random-effects meta-analysis of aggregate data on clinical\n  events","summary":"To appreciate intervention effects on rare events, meta-analysis techniques\nare commonly applied in order to assess the accumulated evidence. When it comes\nto adverse effects in clinical trials, these are often most adequately handled\nusing survival methods. A common-effect model that is able to process data in\ncommonly quoted formats in terms of hazard ratios has been proposed for this\npurpose by Holzhauer (Stat. Med. 2017; 36(5):723-737). In order to accommodate\npotential heterogeneity between studies, we have extended the model by\nHolzhauer to a random-effects approach. The Bayesian model is described in\ndetail, and applications to realistic data sets are discussed along with\nsensitivity analyses and Monte Carlo simulations to support the conclusions.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T16:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.12222v1","title":"Coding-Prior Guided Diffusion Network for Video Deblurring","summary":"While recent video deblurring methods have advanced significantly, they often\noverlook two valuable prior information: (1) motion vectors (MVs) and coding\nresiduals (CRs) from video codecs, which provide efficient inter-frame\nalignment cues, and (2) the rich real-world knowledge embedded in pre-trained\ndiffusion generative models. We present CPGDNet, a novel two-stage framework\nthat effectively leverages both coding priors and generative diffusion priors\nfor high-quality deblurring. First, our coding-prior feature propagation (CPFP)\nmodule utilizes MVs for efficient frame alignment and CRs to generate attention\nmasks, addressing motion inaccuracies and texture variations. Second, a\ncoding-prior controlled generation (CPC) module network integrates coding\npriors into a pretrained diffusion model, guiding it to enhance critical\nregions and synthesize realistic details. Experiments demonstrate our method\nachieves state-of-the-art perceptual quality with up to 30% improvement in IQA\nmetrics. Both the code and the codingprior-augmented dataset will be\nopen-sourced.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T16:14:43Z"}
{"aid":"http://arxiv.org/abs/2504.12251v1","title":"An Evaluation of N-Gram Selection Strategies for Regular Expression\n  Indexing in Contemporary Text Analysis Tasks","summary":"Efficient evaluation of regular expressions (regex, for short) is crucial for\ntext analysis, and n-gram indexes are fundamental to achieving fast regex\nevaluation performance. However, these indexes face scalability challenges\nbecause of the exponential number of possible n-grams that must be indexed.\nMany existing selection strategies, developed decades ago, have not been\nrigorously evaluated on contemporary large-scale workloads and lack\ncomprehensive performance comparisons. Therefore, a unified and comprehensive\nevaluation framework is necessary to compare these methods under the same\nexperimental settings. This paper presents the first systematic evaluation of\nthree representative n-gram selection strategies across five workloads,\nincluding real-time production logs and genomic sequence analysis. We examine\ntheir trade-offs in terms of index construction time, storage overhead, false\npositive rates, and end-to-end query performance. Through empirical results,\nthis study provides a modern perspective on existing n-gram based regular\nexpression evaluation methods, extensive observations, valuable discoveries,\nand an adaptable testing framework to guide future research in this domain. We\nmake our implementations of these methods and our test framework available as\nopen-source at https://github.com/mush-zhang/RegexIndexComparison.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-16T16:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.12257v1","title":"QSHS: An Axion Dark Matter Resonant Search Apparatus","summary":"We describe a resonant cavity search apparatus for axion dark matter\nconstructed by the Quantum Sensors for the Hidden Sector (QSHS) collaboration.\nThe apparatus is configured to search for QCD axion dark matter, though also\nhas the capability to detect axion-like particles (ALPs), dark photons, and\nsome other forms of wave-like dark matter. Initially, a tuneable cylindrical\noxygen-free copper cavity is read out using a low noise microwave amplifier\nfeeding a heterodyne receiver. The cavity is housed in a dilution refrigerator\nand threaded by a solenoidal magnetic field, nominally 8T. The apparatus also\nhouses a magnetic field shield for housing superconducting electronics, and\nseveral other fixed-frequency resonators for use in testing and commissioning\nvarious prototype quantum electronic devices sensitive at a range of axion\nmasses in the range $\\rm 2.0$ to $\\rm 40\\,eV/c^2$. We present performance data\nfor the resonator, dilution refrigerator, and magnet, and plans for the first\nscience run.","main_category":"physics.ins-det","categories":"physics.ins-det,astro-ph.IM,hep-ex","published":"2025-04-16T17:08:00Z"}
{"aid":"http://arxiv.org/abs/2504.12264v1","title":"Towards Learning to Complete Anything in Lidar","summary":"We propose CAL (Complete Anything in Lidar) for Lidar-based shape-completion\nin-the-wild. This is closely related to Lidar-based semantic/panoptic scene\ncompletion. However, contemporary methods can only complete and recognize\nobjects from a closed vocabulary labeled in existing Lidar datasets. Different\nto that, our zero-shot approach leverages the temporal context from multi-modal\nsensor sequences to mine object shapes and semantic features of observed\nobjects. These are then distilled into a Lidar-only instance-level completion\nand recognition model. Although we only mine partial shape completions, we find\nthat our distilled model learns to infer full object shapes from multiple such\npartial observations across the dataset. We show that our model can be prompted\non standard benchmarks for Semantic and Panoptic Scene Completion, localize\nobjects as (amodal) 3D bounding boxes, and recognize objects beyond fixed class\nvocabularies. Our project page is\nhttps://research.nvidia.com/labs/dvl/projects/complete-anything-lidar","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T17:21:55Z"}
{"aid":"http://arxiv.org/abs/2504.12275v1","title":"The rank evolution of block bidiagonal matrices over finite fields","summary":"We investigate uniform random block lower bidiagonal matrices over the finite\nfield $\\mathbb{F}_q$, and prove that their rank undergoes a phase transition.\n  First, we consider block lower bidiagonal matrices with $(k_n+1)\\times k_n$\nblocks where each block is of size $n\\times n$. We prove that if $k_n\\ll\nq^{n/2}$, then these matrices have full rank with high probability, and if\n$k_n\\gg q^{n/2}$, then the rank has Gaussian fluctuations.\n  Second, we consider block lower bidiagonal matrices with $k_n\\times k_n$\nblocks where each block is of size $n\\times n$. We prove that if $k_n\\ll\nq^{n/2}$, then the rank exhibits the same constant order fluctuations as the\nrank of the matrix products considered by Nguyen and Van Peski, and if $k_n\\gg\nq^{n/2}$, then the rank has Gaussian fluctuations.\n  Finally, we also consider a truncated version of the first model, where we\nprove that at $k_n\\approx q^{n/2}$, we have a phase transition between a\nCohen-Lenstra and a Gaussian limiting behavior of the rank. We also show that\nthere is a localization/delocalization phase transition for the vectors in the\nkernels of these matrices at the same critical point.\n  In all three cases, we also provide a precise description of the behavior of\nthe rank at criticality.\n  These results are proved by analyzing the limiting behavior of a Markov chain\nobtained from the increments of the ranks of these matrices.","main_category":"math.PR","categories":"math.PR","published":"2025-04-16T17:35:02Z"}
{"aid":"http://arxiv.org/abs/2504.12289v1","title":"A finite Carrollian critical point","summary":"We construct examples of renormalizable Carrollian theories with finite\neffective central charge and non-trivial dynamics. These include critical\npoints that are not scale-invariant but rather exhibit hyperscaling violation.\nAll of our examples are mildly non-Lagrangian, in that they arise from suitable\n$N\\to 0$ limits of Carrollian theories with $N$-component fields, including\nlimits of Carrollian vector models and non-abelian gauge theories. We discuss\nimplications for flat space holography, highlighting challenges in realizing\nCarrollian duals to gravitational theories.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T17:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.12295v1","title":"Murmurations for elliptic curves ordered by height","summary":"He, Lee, Oliver, and Pozdnyakov [19] have empirically observed that the\naverage of the $p$th coefficients of the $L$-functions of elliptic curves of\nparticular ranks in a given range of conductors $N$ appears to approximate a\ncontinuous function of $p$, depending primarily on the parity of the rank.\nHence the sum of $p$th coefficients against the root number also appears to\napproximate a continuous function, dubbed the murmuration density. However, it\nis not clear from this numerical data how to obtain an explicit formula for the\nmurmuration density. Convergence of similar averages was proved by Zubrilina\n[32] for modular forms of weight 2 (of which elliptic curves form a thin\nsubset) and analogous results for other families of automorphic forms have been\nobtained in further work [6,23]. Each of these works gives an explicit formula\nfor the murmuration density. We consider a variant problem where the elliptic\ncurves are ordered by naive height, and the $p$th coefficients are averaged\nover $p/N$ in a fixed interval. We give a conjecture for the murmuration\ndensity in this case, as an explicit but complicated sum of Bessel functions.\nThis conjecture is motivated by a theorem about a variant problem where we sum\nthe $n$th coefficients for $n$ with no small prime factors against a smooth\nweight function. We test this conjecture for elliptic curves of naive height up\nto $2^{28}$ and find good agreement with the data. The theorem is proved using\nthe Voronoi summation formula, and the method should apply to many different\nfamilies of $L$-functions. This is the first work to give an explicit formula\nfor the murmuration density of a family of elliptic curves, in any ordering.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T17:56:37Z"}
{"aid":"http://arxiv.org/abs/2504.12615v1","title":"Shrinkage priors for circulant correlation structure models","summary":"We consider a new statistical model called the circulant correlation\nstructure model, which is a multivariate Gaussian model with unknown covariance\nmatrix and has a scale-invariance property. We construct shrinkage priors for\nthe circulant correlation structure models and show that Bayesian predictive\ndensities based on those priors asymptotically dominate Bayesian predictive\ndensities based on Jeffreys priors under the Kullback-Leibler (KL) risk\nfunction. While shrinkage of eigenvalues of covariance matrices of Gaussian\nmodels has been successful, the proposed priors shrink a non-eigenvalue part of\ncovariance matrices.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-17T03:39:52Z"}
{"aid":"http://arxiv.org/abs/2504.12619v1","title":"SAM-Based Building Change Detection with Distribution-Aware Fourier\n  Adaptation and Edge-Constrained Warping","summary":"Building change detection remains challenging for urban development, disaster\nassessment, and military reconnaissance. While foundation models like Segment\nAnything Model (SAM) show strong segmentation capabilities, SAM is limited in\nthe task of building change detection due to domain gap issues. Existing\nadapter-based fine-tuning approaches face challenges with imbalanced building\ndistribution, resulting in poor detection of subtle changes and inaccurate edge\nextraction. Additionally, bi-temporal misalignment in change detection,\ntypically addressed by optical flow, remains vulnerable to background noises.\nThis affects the detection of building changes and compromises both detection\naccuracy and edge recognition. To tackle these challenges, we propose a new\nSAM-Based Network with Distribution-Aware Fourier Adaptation and\nEdge-Constrained Warping (FAEWNet) for building change detection. FAEWNet\nutilizes the SAM encoder to extract rich visual features from remote sensing\nimages. To guide SAM in focusing on specific ground objects in remote sensing\nscenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregate\ntask-oriented changed information. This adapter not only effectively addresses\nthe domain gap issue, but also pays attention to the distribution of changed\nbuildings. Furthermore, to mitigate noise interference and misalignment in\nheight offset estimation, we design a novel flow module that refines building\nedge extraction and enhances the perception of changed buildings. Our\nstate-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasets\nhighlight the effectiveness of FAEWNet. The code is available at\nhttps://github.com/SUPERMAN123000/FAEWNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T03:47:43Z"}
{"aid":"http://arxiv.org/abs/2504.12624v1","title":"The (3+1)-dimensional dispersionless integrable hierarchy and nonlinear\n  Riemann-Hilbert problem associated with the Doubrov-Ferapontov modified\n  heavenly equation","summary":"According to the classification of integrable complex Monge-Ampere equations\nby Doubrov and Ferapontov, the modified heavenly equation is a typical\n(3+1)-dimensional dispersionless and canonical integrable equation.In this\npaper we use the eigenfunctions of the Doubrov-Ferapontov modified heavenly\nequation to obtain a related hierarchy. Next we construct the Lax-Sato\nequations with Hamiltonian vector fields and Zakharov-Shabat type equations\nwhich are equivalent to the hierarchy. The nonlinear Riemann-Hilbert problem is\nalso applied to study the solution of Doubrov-Ferapontov modified heavenly\nequation.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-17T03:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.12635v1","title":"On Equivalence Between Decentralized Policy-Profile Mixtures and\n  Behavioral Coordination Policies in Multi-Agent Systems","summary":"Constrained decentralized team problem formulations are good models for many\ncooperative multi-agent systems. Constraints necessitate randomization when\nsolving for optimal solutions -- our past results show that joint randomization\namongst the team is necessary for (strong) Lagrangian duality to hold -- , but\na better understanding of randomization still remains. For a partially observed\nmulti-agent system with Borel hidden state and finite observations and actions,\nwe prove the equivalence between joint mixtures of decentralized\npolicy-profiles (both pure and behavioral) and common-information based\nbehavioral coordination policies (also mixtures of them). This generalizes past\nwork that shows equivalence between pure decentralized policy-profiles and pure\ncoordination policies. The equivalence can be exploited to develop results on\nstrong duality and number of randomizations.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T04:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.12668v1","title":"Observing Nucleation and Crystallization of Rocksalt LiF from Molten\n  State through Molecular Dynamics Simulations with Refined Machine-Learned\n  Force Field","summary":"Lithium fluoride (LiF) is a critical component for stabilizing lithium metal\nanode and high-voltage cathodes towards the next-generation high-energy-density\nlithium batteries.Recent modeling study reported the formation of wurtzite LiF\nbelow about 550 K (J. Am. Chem. Soc. 2023, 145, 1327-1333), in contrast to\nexperimental observation of rocksalt LiF under ambient conditions. To address\nthis discrepancy, we employ molecular dynamics (MD) simulations with a refined\nmachine-learned force field (MLFF), and demonstrate the nucleation and\ncrystallization of rocksalt LiF from the molten phase at temperatures below\nabout 800 K. The rocksalt phase remains stable in LiF nanoparticles.\nComplementary density functional theory (DFT) calculations show that dispersion\ninteractions are essential for correctly predicting the thermodynamic stability\nof rocksalt LiF over the wurtzite phase on top of the commonly used PBE\nfunctional. Furthermore, we show that inclusion of virial stresses--alongside\nenergies and forces--in the training of MLFFs is crucial for capturing phase\nnucleation and crystallization of rocksalt LiF under the isothermal-isobaric\nensemble. These findings underscore the critical role of dispersion\ninteractions in atomistic simulations of battery materials, where such effects\nare often non-negligible, and highlight the necessity of incorporating virial\nstresses during the training of MLFF to enable accurate modeling of solid-state\nsystems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T05:52:51Z"}
{"aid":"http://arxiv.org/abs/2504.12673v1","title":"ACoRN: Noise-Robust Abstractive Compression in Retrieval-Augmented\n  Language Models","summary":"Abstractive compression utilizes smaller langauge models to condense\nquery-relevant context, reducing computational costs in retrieval-augmented\ngeneration (RAG). However,retrieved documents often include information that is\neither irrelevant to answering the query or misleading due to factual incorrect\ncontent, despite having high relevance scores. This behavior indicates that\nabstractive compressors are more likely to omit important information essential\nfor the correct answer, especially in long contexts where attention dispersion\noccurs. To address this issue, we categorize retrieved documents in a more\nfine-grained manner and propose Abstractive Compression Robust against Noise\n(ACoRN), which introduces two novel training steps. First, we use offline data\naugmentation on the training dataset to enhance compressor robustness against\ntwo distinct types of retrieval noise. Second, since the language modelbased\ncompressor cannot fully utilize information from multiple retrieved documents\nand exhibits positional bias, we perform finetuning to generate summaries\ncentered around key information that directly supports the correct answer. Our\nexperiments demonstrate that T5-large, trained with ACoRN as a compressor,\nimproves EM and F1 scores while preserving the answer string, which could serve\nas direct evidence. ACoRN excels on datasets with many accuracy-reducing\ndocuments, making it highly useful in real-world scenarios.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T06:05:35Z"}
{"aid":"http://arxiv.org/abs/2504.12688v1","title":"Ab initio study of anisotropic effects in two-dimensional Fe$_3$GeTe$_2$\n  using $\\bf{k}$-dependent Green's functions","summary":"In the present work, we develop the Green's function apparatus and extend its\napplicability to the study of microscopic anisotropic effects in real\nconducting materials. The problem of the previously proposed approaches written\nin terms of inter-atomic Green's functions is the presence of a spatial sum\nover all atoms of the crystal, which greatly complicates their application to\nsystems with itinerant electrons. To provide a solution we derived expressions\nfor magnetic torque vector and Dzyaloshinskii-Moriya interactions based on\n$\\bf{k}$-dependent Green's functions, which allow numerical evaluations with\nguaranteed stability of spatial sums over the crystal lattice and moreover with\nmuch lower computational cost. Approbation of the approaches on the case of\nFe$_3$GeTe$_2$ monolayer, which is based on first-principles DFT calculations,\nconfirmed the numerical stability and allowed us to reproduce the\ncharacteristic length of experimentally observed collective spin excitations in\nthe domain structure of this promising conducting material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T06:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.12696v1","title":"Collaborative Perception Datasets for Autonomous Driving: A Review","summary":"Collaborative perception has attracted growing interest from academia and\nindustry due to its potential to enhance perception accuracy, safety, and\nrobustness in autonomous driving through multi-agent information fusion. With\nthe advancement of Vehicle-to-Everything (V2X) communication, numerous\ncollaborative perception datasets have emerged, varying in cooperation\nparadigms, sensor configurations, data sources, and application scenarios.\nHowever, the absence of systematic summarization and comparative analysis\nhinders effective resource utilization and standardization of model evaluation.\nAs the first comprehensive review focused on collaborative perception datasets,\nthis work reviews and compares existing resources from a multi-dimensional\nperspective. We categorize datasets based on cooperation paradigms, examine\ntheir data sources and scenarios, and analyze sensor modalities and supported\ntasks. A detailed comparative analysis is conducted across multiple dimensions.\nWe also outline key challenges and future directions, including dataset\nscalability, diversity, domain adaptation, standardization, privacy, and the\nintegration of large language models. To support ongoing research, we provide a\ncontinuously updated online repository of collaborative perception datasets and\nrelated literature:\nhttps://github.com/frankwnb/Collaborative-Perception-Datasets-for-Autonomous-Driving.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:49:21Z"}
{"aid":"http://arxiv.org/abs/2504.12702v1","title":"Embodied Neuromorphic Control Applied on a 7-DOF Robotic Manipulator","summary":"The development of artificial intelligence towards real-time interaction with\nthe environment is a key aspect of embodied intelligence and robotics. Inverse\ndynamics is a fundamental robotics problem, which maps from joint space to\ntorque space of robotic systems. Traditional methods for solving it rely on\ndirect physical modeling of robots which is difficult or even impossible due to\nnonlinearity and external disturbance. Recently, data-based model-learning\nalgorithms are adopted to address this issue. However, they often require\nmanual parameter tuning and high computational costs. Neuromorphic computing is\ninherently suitable to process spatiotemporal features in robot motion control\nat extremely low costs. However, current research is still in its infancy:\nexisting works control only low-degree-of-freedom systems and lack performance\nquantification and comparison. In this paper, we propose a neuromorphic control\nframework to control 7 degree-of-freedom robotic manipulators. We use Spiking\nNeural Network to leverage the spatiotemporal continuity of the motion data to\nimprove control accuracy, and eliminate manual parameters tuning. We validated\nthe algorithm on two robotic platforms, which reduces torque prediction error\nby at least 60% and performs a target position tracking task successfully. This\nwork advances embodied neuromorphic control by one step forward from proof of\nconcept to applications in complex real-world tasks.","main_category":"cs.RO","categories":"cs.RO,cs.NE","published":"2025-04-17T07:13:37Z"}
{"aid":"http://arxiv.org/abs/2504.12714v1","title":"Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination","summary":"Zero-shot coordination (ZSC), the ability to adapt to a new partner in a\ncooperative task, is a critical component of human-compatible AI. While prior\nwork has focused on training agents to cooperate on a single task, these\nspecialized models do not generalize to new tasks, even if they are highly\nsimilar. Here, we study how reinforcement learning on a distribution of\nenvironments with a single partner enables learning general cooperative skills\nthat support ZSC with many new partners on many new problems. We introduce two\nJax-based, procedural generators that create billions of solvable coordination\nchallenges. We develop a new paradigm called Cross-Environment Cooperation\n(CEC), and show that it outperforms competitive baselines quantitatively and\nqualitatively when collaborating with real people. Our findings suggest that\nlearning to collaborate across many unique scenarios encourages agents to\ndevelop general norms, which prove effective for collaboration with different\npartners. Together, our results suggest a new route toward designing generalist\ncooperative agents capable of interacting with humans without requiring human\ndata.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.LG","published":"2025-04-17T07:41:25Z"}
{"aid":"http://arxiv.org/abs/2504.12719v1","title":"B*: Efficient and Optimal Base Placement for Fixed-Base Manipulators","summary":"B* is a novel optimization framework that addresses a critical challenge in\nfixed-base manipulator robotics: optimal base placement. Current methods rely\non pre-computed kinematics databases generated through sampling to search for\nsolutions. However, they face an inherent trade-off between solution optimality\nand computational efficiency when determining sampling resolution. To address\nthese limitations, B* unifies multiple objectives without database dependence.\nThe framework employs a two-layer hierarchical approach. The outer layer\nsystematically manages terminal constraints through progressive tightening,\nparticularly for base mobility, enabling feasible initialization and broad\nsolution exploration. The inner layer addresses non-convexities in each\nouter-layer subproblem through sequential local linearization, converting the\noriginal problem into tractable sequential linear programming (SLP). Testing\nacross multiple robot platforms demonstrates B*'s effectiveness. The framework\nachieves solution optimality five orders of magnitude better than\nsampling-based approaches while maintaining perfect success rates and reduced\ncomputational overhead. Operating directly in configuration space, B* enables\nsimultaneous path planning with customizable optimization criteria. B* serves\nas a crucial initialization tool that bridges the gap between theoretical\nmotion planning and practical deployment, where feasible trajectory existence\nis fundamental.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T07:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.12729v1","title":"Dead Gate Elimination","summary":"Hybrid quantum algorithms combine the strengths of quantum and classical\ncomputing. Many quantum algorithms, such as the variational quantum eigensolver\n(VQE), leverage this synergy. However, quantum circuits are executed in full,\neven when only subsets of measurement outcomes contribute to subsequent\nclassical computations. In this manuscript, we propose a novel circuit\noptimization technique that identifies and removes dead gates. We prove that\nthe removal of dead gates has no influence on the probability distribution of\nthe measurement outcomes that contribute to the subsequent calculation result.\nWe implemented and evaluated our optimization on a VQE instance, a quantum\nphase estimation (QPE) instance, and hybrid programs embedded with random\ncircuits of varying circuit width, confirming its capability to remove a\nnon-trivial number of dead gates in real-world algorithms. The effect of our\noptimization scales up as more measurement outcomes are identified as\nnon-contributory, resulting in a proportionally greater reduction of dead\ngates.","main_category":"quant-ph","categories":"quant-ph,cs.PL,cs.SE","published":"2025-04-17T08:10:59Z"}
{"aid":"http://arxiv.org/abs/2504.12737v1","title":"Chinese-Vicuna: A Chinese Instruction-following Llama-based Model","summary":"Chinese-Vicuna is an open-source, resource-efficient language model designed\nto bridge the gap in Chinese instruction-following capabilities by fine-tuning\nMeta's LLaMA architecture using Low-Rank Adaptation (LoRA). Targeting\nlow-resource environments, it enables cost-effective deployment on consumer\nGPUs (e.g., RTX-2080Ti for 7B models) and supports domain-specific adaptation\nin fields like healthcare and law. By integrating hybrid datasets (BELLE and\nGuanaco) and 4-bit quantization (QLoRA), the model achieves competitive\nperformance in tasks such as translation, code generation, and domain-specific\nQ\\&A. The project provides a comprehensive toolkit for model conversion, CPU\ninference, and multi-turn dialogue interfaces, emphasizing accessibility for\nresearchers and developers. Evaluations indicate competitive performance across\nmedical tasks, multi-turn dialogue coherence, and real-time legal updates.\nChinese-Vicuna's modular design, open-source ecosystem, and community-driven\nenhancements position it as a versatile foundation for Chinese LLM\napplications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T08:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.12739v1","title":"Mask Image Watermarking","summary":"We present MaskMark, a simple, efficient and flexible framework for image\nwatermarking. MaskMark has two variants: MaskMark-D, which supports global\nwatermark embedding, watermark localization, and local watermark extraction for\napplications such as tamper detection, and MaskMark-ED, which focuses on local\nwatermark embedding and extraction with enhanced robustness in small regions,\nenabling localized image protection. Built upon the classical Encoder-\nDistortion-Decoder training paradigm, MaskMark-D introduces a simple masking\nmechanism during the decoding stage to support both global and local watermark\nextraction. A mask is applied to the watermarked image before extraction,\nallowing the decoder to focus on selected regions and learn local extraction. A\nlocalization module is also integrated into the decoder to identify watermark\nregions during inference, reducing interference from irrelevant content and\nimproving accuracy. MaskMark-ED extends this design by incorporating the mask\ninto the encoding stage as well, guiding the encoder to embed the watermark in\ndesignated local regions for enhanced robustness. Comprehensive experiments\nshow that MaskMark achieves state-of-the-art performance in global watermark\nextraction, local watermark extraction, watermark localization, and\nmulti-watermark embedding. It outperforms all existing baselines, including the\nrecent leading model WAM for local watermarking, while preserving high visual\nquality of the watermarked images. MaskMark is also flexible, by adjusting the\ndistortion layer, it can adapt to different robustness requirements with just a\nfew steps of fine-tuning. Moreover, our approach is efficient and easy to\noptimize, requiring only 20 hours on a single A6000 GPU with just 1/15 the\ncomputational cost of WAM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:29:00Z"}
{"aid":"http://arxiv.org/abs/2504.12748v1","title":"Attack-Defense Trees with Offensive and Defensive Attributes (with\n  Appendix)","summary":"Effective risk management in cybersecurity requires a thorough understanding\nof the interplay between attacker capabilities and defense strategies.\nAttack-Defense Trees (ADTs) are a commonly used methodology for representing\nthis interplay; however, previous work in this domain has only focused on\nanalyzing metrics such as cost, damage, or time from the perspective of the\nattacker. This approach provides an incomplete view of the system, as it\nneglects to model defender attributes: in real-world scenarios, defenders have\nfinite resources for countermeasures and are similarly constrained. In this\npaper, we propose a novel framework that incorporates defense metrics into\nADTs, and we present efficient algorithms for computing the Pareto front\nbetween defense and attack metrics. Our methods encode both attacker and\ndefender metrics as semirings, allowing our methods to be used for many metrics\nsuch as cost, damage, and skill. We analyze tree-structured ADTs using a\nbottom-up approach and general ADTs by translating them into binary decision\ndiagrams. Experiments on randomly generated ADTS demonstrate that both\napproaches effectively handle ADTs with several hundred nodes.","main_category":"cs.CR","categories":"cs.CR,cs.GT","published":"2025-04-17T08:41:07Z"}
{"aid":"http://arxiv.org/abs/2504.12763v1","title":"Single Complex-Frequency Resonance Mode in an Engineered Disordered\n  Time-Varying Cavity","summary":"We propose a straightforward mechanism for achieving unique $k$-space\nresonance modes in one-dimensional time-varying cavities where periodic\ntemporal modulation creates momentum band gaps through Floquet dynamics. By\nengineering the synergy between cavity resonance conditions and Floquet mode\nformation in photonic time crystals, we demonstrate the emergence of a single\ndominant momentum state that exhibits remarkable robustness against temporal\ndisorder. Through analytical modeling and numerical verification, we show that\nthe interplay between time-varying medium and cavity boundary conditions leads\nto amplification of specific waves followed by spatial mode selection. This\nengineered resonance mechanism enables insensitivity to initial wave source\nconfiguration and strong temporal disorder immunity. Our findings give a simple\nmechanism for exploiting narrow momentum bandgaps, and establish a foundation\nfor developing high-quality temporal cavity lasers and advancing extreme\ntemporal predictability in time-modulated systems.","main_category":"physics.optics","categories":"physics.optics,cond-mat.dis-nn","published":"2025-04-17T09:00:32Z"}
{"aid":"http://arxiv.org/abs/2504.12810v1","title":"Learning Time-Varying Quantum Lossy Channels","summary":"Time-varying quantum channels are essential for modeling realistic quantum\nsystems with evolving noise properties. Here, we consider Gaussian lossy\nchannels varying from one use to another and we employ neural networks to\nclassify, regress, and forecast the behavior of these channels from their\nChoi-Jamiolkowski states. The networks achieve at least 87% of accuracy in\ndistinguishing between non-Markovian, Markovian, memoryless, compound, and\ndeterministic channels. In regression tasks, the model accurately reconstructs\nthe loss parameter sequences, and in forecasting, it predicts future values,\nwith improved performance as the memory parameter approaches 1 for Markovian\nchannels. These results demonstrate the potential of neural networks in\ncharacterizing and predicting the dynamics of quantum channels.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T10:15:47Z"}
{"aid":"http://arxiv.org/abs/2504.12813v1","title":"Approaching Current Challenges in Developing a Software Stack for Fully\n  Autonomous Driving","summary":"Autonomous driving is a complex undertaking. A common approach is to break\ndown the driving task into individual subtasks through modularization. These\nsub-modules are usually developed and published separately. However, if these\nindividually developed algorithms have to be combined again to form a\nfull-stack autonomous driving software, this poses particular challenges.\nDrawing upon our practical experience in developing the software of TUM\nAutonomous Motorsport, we have identified and derived these challenges in\ndeveloping an autonomous driving software stack within a scientific\nenvironment. We do not focus on the specific challenges of individual\nalgorithms but on the general difficulties that arise when deploying research\nalgorithms on real-world test vehicles. To overcome these challenges, we\nintroduce strategies that have been effective in our development approach. We\nadditionally provide open-source implementations that enable these concepts on\nGitHub. As a result, this paper's contributions will simplify future full-stack\nautonomous driving projects, which are essential for a thorough evaluation of\nthe individual algorithms.","main_category":"cs.RO","categories":"cs.RO,cs.SE","published":"2025-04-17T10:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.12819v1","title":"A scalable mixed-integer conic optimization approach to\n  cardinality-constrained Poisson regression with safe screening","summary":"This paper introduces a novel approach for cardinality-constrained Poisson\nregression to address feature selection challenges in high-dimensional count\ndata. We formulate the problem as a mixed-integer conic optimization, enabling\nthe use of modern solvers for optimal solutions. To enhance computational\nefficiency, we develop a safe screening based on Fenchel conjugates, thereby\neffectively removing irrelevant features before optimization. Experiments on\nsynthetic datasets demonstrate that our safe screening significantly reduces\nthe problem size, leading to substantial improvements in computational time.\nOur approach can solve Poisson regression problems with tens of thousands of\nfeatures, exceeding the scale of previous studies. This work provides a\nvaluable tool for interpretable feature selection in high-dimensional Poisson\nregression.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T10:24:33Z"}
{"aid":"http://arxiv.org/abs/2504.12829v1","title":"Particle-based Simulation of an Air-Breathing Electric Propulsion System","summary":"A novel concept called Air-Breathing Electric Propulsion proposes to fly\nsatellites at altitudes in the range 180-250 km, since this would have some\nadvantages for the performance of radio communication and Earth observation\nequipment. The ABEP satellites compensate the atmospheric drag through a\ncontinuous thrust provided by collecting, ionizing and accelerating the\nresidual atmospheric particles. It is clear that the feasibility of this\nconcept will require a significant design and testing effort, performed first\non ground and later in orbit. Plasma simulation tools play a fundamental role\nin the development of this technology, for two main reasons: (i) they can\npotentially increase dramatically the optimization and testing process of ABEP\nsystems, since on-ground testing and in-orbit demonstrators are costly and time\nconsuming, and (ii) the fidelity of on-ground testing is limited by the finite\nsize and pumping speed of high-vacuum facilities, as well as the means through\nwhich the orbital flow is produced. In this paper, we demonstrate a one-way\ncoupled, particle-based simulation strategy for a CubeSat sized ABEP system.\nThe neutral flow in the full geometry of the ABEP system comprising the intake\nand the thruster is simulated first through Direct Simulation Monte Carlo.\nThen, the resulting neutral density is used as the input for a Particle-in-Cell\nsimulation of the detailed thruster geometry. The simulations are performed in\n3D and within the VKI in-house code Pantera, taking advantage of the\nfully-implicit energy-conserving scheme.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-17T10:42:59Z"}
{"aid":"http://arxiv.org/abs/2504.12838v1","title":"Exact-WKB Analysis of Two-level Floquet Systems","summary":"We explore the application of the exact Wentzel-Kramers-Brillouin (WKB)\nanalysis to two-level Floquet systems and establish a systematic procedure to\ncalculate the quasi-energy and Floquet effective Hamiltonian. We show that, in\nthe exact-WKB analysis, the quasi-energy and Floquet effective Hamiltonian can\nbe expressed in terms of cycle integrals (Voros symbol), which characterize\nmonodromy matrices for Schr\\\"odinger-type differential equations governing\ntwo-level Floquet systems. We analytically evaluate the cycle integrals using\nthe low-frequency expansion and derive both perturbative and non-perturbative\ncorrections to the quasi-energy and Floquet effective Hamiltonian. To verify\nthe accuracy of our results, we compare them with numerical calculations and\nanalyze resonant oscillations, which reveal non-perturbative features that\ncannot be captured by the perturbative expansion.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-17T10:53:52Z"}
{"aid":"http://arxiv.org/abs/2504.12842v1","title":"Geometry of the moduli space of Hermitian-Einstein connections on\n  manifolds with a dilaton","summary":"We demonstrate that the moduli space of Hermitian-Einstein connections\n$\\text{M}^*_{HE}(M^{2n})$ of vector bundles over compact non-Gauduchon\nHermitian manifolds $(M^{2n}, g, \\omega)$ that exhibit a dilaton field $\\Phi$\nadmit a strong K\\\"ahler with torsion structure provided a certain condition is\nimposed on their Lee form $\\theta$ and the dilaton. We find that the geometries\nthat satisfy this condition include those that solve the string field equations\nor equivalently the gradient flow soliton type of equations. In addition, we\ndemonstrate that if the underlying manifold $(M^{2n}, g, \\omega)$ admits a\nholomorphic and Killing vector field $X$ that leaves $\\Phi$ also invariant,\nthen the moduli spaces $\\text{M}^*_{HE}(M^{2n})$ admits an induced holomorphic\nand Killing vector field $\\alpha_X$. Furthermore, if $X$ is covariantly\nconstant with respect to the compatible connection $\\hat\\nabla$ with torsion a\n3-form on $(M^{2n}, g, \\omega)$, then $\\alpha_X$ is also covariantly constant\nwith respect to the compatible connection $\\hat D$ with torsion a 3-form on\n$\\text{M}^*_{HE}(M^{2n})$ provided that $K^\\flat\\wedge X^\\flat$ is a\n$(1,1)$-form with $K^\\flat=\\theta+2d\\Phi$ and $\\Phi$ is invariant under $X$ and\n$IX$, where $I$ is the complex structure of $M^{2n}$.","main_category":"math.DG","categories":"math.DG,hep-th","published":"2025-04-17T10:57:39Z"}
{"aid":"http://arxiv.org/abs/2504.12851v1","title":"Optimal Capital Structure for Life Insurance Companies Offering Surplus\n  Participation","summary":"We adapt Leland's dynamic capital structure model to the context of an\ninsurance company selling participating life insurance contracts explaining the\nexistence of life insurance contracts which provide both a guaranteed payment\nand surplus participation to the policyholders. Our derivation of the optimal\nparticipation rate reveals its pronounced sensitivity to the contract duration\nand the associated tax rate. Moreover, the asset substitution effect, which\ndescribes the tendency of equity holders to increase the riskiness of a\ncompany's investment decisions, decreases when adding surplus participation.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-04-17T11:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.12871v1","title":"Improvable Students in School Choice","summary":"The Deferred Acceptance algorithm (DA) frequently produces Pareto inefficient\nallocations in school choice problems. While a number of efficient mechanisms\nthat Pareto-dominate DA are available, a normative question remains unexplored:\nwhich students should benefit from efficiency enhancements? We address it by\nintroducing the concept of \\emph{maximally improvable students}, who benefit in\nevery improvement over DA that includes as many students as possible in\nset-inclusion terms. We prove that common mechanisms such as\nEfficiency-Adjusted DA (EADA) and Top Trading Cycles applied to DA (DA+TTC) can\nfall significantly short of this benchmark. These mechanisms may only improve\ntwo maximally-improvable students when up to $n-1$ could benefit. Addressing\nthis limitation, we develop the Maximum Improvement over DA mechanism (MIDA),\nwhich generates an efficient allocation that maximises the number of students\nimproved over DA. We show that MIDA can generate fewer blocking pairs than EADA\nand DA+TTC, demonstrating that its distributional improvements need not come at\nthe cost of high justified envy.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-17T11:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.12881v1","title":"Photoinduced magnetic phase transitions in the cubic Kondo-lattice model","summary":"We theoretically study photoinduced magnetic phase transitions and their\ndynamical processes in the Kondo-lattice model on a cubic lattice. It is\ndemonstrated that light irradiation gives rise to magnetic phase transitions\nfrom the ground-state ferromagnetic state to a three-dimensional\nantiferromagnetic state as a nonequilibrium steady state in the photodriven\nsystem. This phase transition occurs as a consequence of the formation of\npseudo half-filling band occupation via the photoexcitation and relaxation of\nelectrons, where all the electron states constituting the lower band separated\nfrom the upper band by an exchange gap are partially but nearly uniformly\noccupied. We also find that several types of antiferromagnetic correlations,\ne.g., A-type and C-type antiferromagnetic correlations, appear in a transient\nstate of the dynamical phase transition. By calculating magnon spectra for the\nphotodriven system, we argue that the instability to the A-type or C-type\nantiferromagnetic state occurs in the ferromagnetic ground state as a softening\nof the magnon band dispersion at corresponding momentum points depending on the\nlight polarization. Our findings provide important insights into the\nunderstanding of photoinduced magnetic phase transitions in the\nthree-dimensional Kondo-lattice magnets.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-17T12:14:20Z"}
{"aid":"http://arxiv.org/abs/2504.12888v1","title":"Anemia, weight, and height among children under five in Peru from 2007\n  to 2022: A Panel Data analysis","summary":"Econometrics in general, and Panel Data methods in particular, are becoming\ncrucial in Public Health Economics and Social Policy analysis. In this\ndiscussion paper, we employ a helpful approach of Feasible Generalized Least\nSquares (FGLS) to assess if there are statistically relevant relationships\nbetween hemoglobin (adjusted to sea-level), weight, and height from 2007 to\n2022 in children up to five years of age in Peru. By using this method, we may\nfind a tool that allows us to confirm if the relationships considered between\nthe target variables by the Peruvian agencies and authorities are in the right\ndirection to fight against chronic malnutrition and stunting.","main_category":"q-bio.PE","categories":"q-bio.PE,econ.EM,stat.AP","published":"2025-04-17T12:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.12889v1","title":"RIS-Assisted Beamfocusing in Near-Field IoT Communication Systems: A\n  Transformer-Based Approach","summary":"The massive number of antennas in extremely large aperture array (ELAA)\nsystems shifts the propagation regime of signals in internet of things (IoT)\ncommunication systems towards near-field spherical wave propagation. We propose\na reconfigurable intelligent surfaces (RIS)-assisted beamfocusing mechanism,\nwhere the design of the two-dimensional beam codebook that contains both the\nangular and distance domains is challenging. To address this issue, we\nintroduce a novel Transformer-based two-stage beam training algorithm, which\nincludes the coarse and fine search phases. The proposed mechanism provides a\nfine-grained codebook with enhanced spatial resolution, enabling precise\nbeamfocusing. Specifically, in the first stage, the beam training is performed\nto estimate the approximate location of the device by using a simple codebook,\ndetermining whether it is within the beamfocusing range (BFR) or the\nnone-beamfocusing range (NBFR). In the second stage, by using a more precise\ncodebook, a fine-grained beam search strategy is conducted. Experimental\nresults unveil that the precision of the RIS-assisted beamfocusing is greatly\nimproved. The proposed method achieves beam selection accuracy up to 97% at\nsignal-to-noise ratio (SNR) of 20 dB, and improves 10% to 50% over the baseline\nmethod at different SNRs.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-17T12:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.12898v1","title":"Information Gain-Guided Causal Intervention for Autonomous Debiasing\n  Large Language Models","summary":"Despite significant progress, recent studies indicate that current large\nlanguage models (LLMs) may still capture dataset biases and utilize them during\ninference, leading to the poor generalizability of LLMs. However, due to the\ndiversity of dataset biases and the insufficient nature of bias suppression\nbased on in-context learning, the effectiveness of previous prior\nknowledge-based debiasing methods and in-context learning based automatic\ndebiasing methods is limited. To address these challenges, we explore the\ncombination of causal mechanisms with information theory and propose an\ninformation gain-guided causal intervention debiasing (IGCIDB) framework. This\nframework first utilizes an information gain-guided causal intervention method\nto automatically and autonomously balance the distribution of\ninstruction-tuning dataset. Subsequently, it employs a standard supervised\nfine-tuning process to train LLMs on the debiased dataset. Experimental results\nshow that IGCIDB can effectively debias LLM to improve its generalizability\nacross different tasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T12:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.12941v1","title":"Osmolyte-Modulated Differential Capacitance and Disjoining Pressure for\n  Nanoconfined Electrolytes: A Modified Poisson-Boltzmann Theory","summary":"This study employs modified Poisson-Boltzmann theory to systematically\ninvestigate the influence of zwitterionic osmolyte additives to an electrolyte\nsolution on disjoining pressure and electric differential capacitance within\ncharged slit-like nanopores with conductive walls. We demonstrate that\nincreasing concentrations of zwitterionic osmolytes result in a marked\nsynergistic enhancement of both disjoining pressure and differential\ncapacitance, highlighting their dual role in improving supercapacitor\nperformance. The insights gained underscore the unique capabilities of\nzwitterionic osmolytes as multifunctional additives for fine-tuning the\nproperties of electric double layers, thereby bridging the gap between\ncapacitive efficiency and electrode longevity.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-17T13:40:05Z"}
{"aid":"http://arxiv.org/abs/2504.12948v1","title":"Algorithms for the Shortest Vector Problem in $2$-dimensional Lattices,\n  Revisited","summary":"Efficiently solving the Shortest Vector Problem (SVP) in two-dimensional\nlattices holds practical significance in cryptography and computational\ngeometry. While simpler than its high-dimensional counterpart, two-dimensional\nSVP motivates scalable solutions for high-dimensional lattices and benefits\napplications like sequence cipher cryptanalysis involving large integers. In\nthis work, we first propose a novel definition of reduced bases and develop an\nefficient adaptive lattice reduction algorithm \\textbf{CrossEuc} that\nstrategically applies the Euclidean algorithm across dimensions. Building on\nthis framework, we introduce \\textbf{HVec}, a vectorized generalization of the\nHalf-GCD algorithm originally defined for integers, which can efficiently halve\nthe bit-length of two vectors and may have independent interest. By iteratively\ninvoking \\textbf{HVec}, our optimized algorithm \\textbf{HVecSBP} achieves a\nreduced basis in $O(\\log n M(n) )$ time for arbitrary input bases with\nbit-length $n$, where $M(n)$ denotes the cost of multiplying two $n$-bit\nintegers. Compared to existing algorithms, our design is applicable to general\nforms of input lattices, eliminating the cost of pre-converting input bases to\nHermite Normal Form (HNF). The comprehensive experimental results demonstrate\nthat for the input lattice bases in HNF, the optimized algorithm\n\\textbf{HVecSBP} achieves at least a $13.5\\times$ efficiency improvement\ncompared to existing methods. For general-form input lattice bases, converting\nthem to HNF before applying \\textbf{HVecSBP} offers only marginal advantages in\nextreme cases where the two basis vectors are nearly degenerate. However, as\nthe linear dependency between input basis vectors decreases, directly employing\n\\textbf{HVecSBP} yields increasingly significant efficiency gains,\noutperforming hybrid approaches that rely on prior \\textbf{HNF} conversion.","main_category":"cs.CG","categories":"cs.CG,cs.CR","published":"2025-04-17T13:50:51Z"}
{"aid":"http://arxiv.org/abs/2504.12950v1","title":"Tensor-monopole-induced topological boundary effects in four-dimensional\n  acoustic metamaterials","summary":"Gauge field theory provides the mathematical and conceptual framework to\ndescribe and understand topological singularities such as Weyl points and\nmagnetic monopoles. While singularities associated with vector electromagnetic\ngauge fields have been well-studied, those of higher-form tensor gauge fields,\nlike the four-dimensional (4D) tensor monopoles predicted by string theory,\nhave remained largely theoretical or limited to experimental demonstration in\npure synthetic dimensions, thereby not allowing investigations of the\nassociated boundary effects. Here, we present a 4D system with tensor monopoles\nusing engineered acoustic metamaterials. Our momentum space combines three real\nmomentum dimensions and a geometric parameter as the fourth. By varying this\nfourth momentum, we experimentally reveal two distinct topological surface\nstates in 3D subsystems: Fermi-arc surface states in a gapless subsystem and\nDirac-cone surface states in a gapped subsystem. Our work introduces a novel\nplatform for exploring new topological structures associated with tensor gauge\nfield and topological phenomena in higher dimensions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T13:51:50Z"}
{"aid":"http://arxiv.org/abs/2504.12965v1","title":"Topological lax comma categories","summary":"This paper investigates the interplay between properties of a topological\nspace $X$, in particular of its natural order, and properties of the lax comma\ncategory $\\mathsf{Top} \\Downarrow X$, where $\\mathsf{Top}$ denotes the category\nof topologicalspaces and continuous maps. Namely, it is shown that, whenever\n$X$ is a topological $\\bigwedge$-semilattice, the canonical forgetful functor\n$\\mathsf{Top} \\Downarrow X \\to \\mathsf{Top}$ is topological, preserves and\nreflects exponentials, and preserves effective descent morphisms. Moreover,\nunder additional conditions on $X$, a characterisation of effective descent\nmorphisms is obtained.","main_category":"math.CT","categories":"math.CT,math.GN","published":"2025-04-17T14:18:42Z"}
{"aid":"http://arxiv.org/abs/2504.12973v1","title":"Input to the ESPPU 2026 update: Searching for millicharged particles\n  with the FORMOSA experiment at the CERN LHC","summary":"In this contribution, we evaluate the sensitivity for particles with charges\nmuch smaller than the electron charge with a dedicated scintillator-based\ndetector in the far forward region at the CERN LHC, FORMOSA. This contribution\nwill outline the scientific case for this detector, its design and potential\nlocations, and the sensitivity that can be achieved. The ongoing efforts to\nprove the feasibility of the detector with the FORMOSA demonstrator will be\ndiscussed. Finally, possible upgrades to the detector through the use of\nhigh-performance scintillator will be discussed.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-04-17T14:26:33Z"}
{"aid":"http://arxiv.org/abs/2504.12980v1","title":"Motion of ferrodark solitons in harmonically trapped superfluids: spin\n  corrections and emergent quartic potentials exhibiting symmetry breaking","summary":"We propose a framework for topological soliton dynamics in trapped spinor\nsuperfluids, decomposing the force acting on the soliton by the surrounding\nfluid into the buoyancy force and spin-corrections arising from the density\ndepletion at soliton core and the coupling between the orbital motion and the\nspin mixing, respectively. For ferrodark solitons (FDSs) in spin-1\nBose-Einstein Condensates (BECs), the spin correction enables mapping the FDS\nmotion in a harmonic trap to the atomic-mass particle dynamics in an emergent\nquartic potential. Initially placing a type-I FDS near the trap center, a\nsingle-sided oscillation happens, which maps to the particle moving around a\nlocal minimum of the emergent double-well potential. As the initial distance of\na type-II FDS from the trap center increases, the motion exhibits three\nregimes: trap-centered harmonic and anharmonic, followed by single-sided\noscillations. Correspondingly the emergent quartic potential undergoes symmetry\nbreaking, transitioning from a single minimum to a double-well shape, where\nparticle motion shifts from oscillating around the single minimum to crossing\nbetween two minima via the local maximum, then the motion around one of the two\nminima. In a hard-wall trap with linear potential, the FDS motion maps to a\nharmonic oscillator.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,nlin.PS","published":"2025-04-17T14:32:16Z"}
{"aid":"http://arxiv.org/abs/2504.12983v1","title":"Adaptive Modeling of Correlated Noise in Space-Based Gravitational Wave\n  Detectors","summary":"Accurately estimating the statistical properties of noise is important in\nspace-based gravitational wave data analysis. Traditional methods often assume\nuncorrelated noise or impose restrictive parametric forms on cross-channel\ncorrelations, which could lead to biased estimation in complex instrumental\nnoise. This paper introduces a spline-based framework with trans-dimensional\nBayesian inference to reconstruct the full noise covariance matrix, including\nfrequency-dependent auto- and cross-power spectral densities, without prior\nassumptions on noise shapes. The developed software $\\mathtt{NOISAR}$ can\nrecover the features of the noise power spectrum curves with a relative error\n$\\leq 10\\%$ for both auto- and cross-one.","main_category":"astro-ph.IM","categories":"astro-ph.IM,gr-qc","published":"2025-04-17T14:41:56Z"}
{"aid":"http://arxiv.org/abs/2504.13010v1","title":"Simultaneous Polysomnography and Cardiotocography Reveal Temporal\n  Correlation Between Maternal Obstructive Sleep Apnea and Fetal Hypoxia","summary":"Background: Obstructive sleep apnea syndrome (OSAS) during pregnancy is\ncommon and can negatively affect fetal outcomes. However, studies on the\nimmediate effects of maternal hypoxia on fetal heart rate (FHR) changes are\nlacking. Methods: We used time-synchronized polysomnography (PSG) and\ncardiotocography (CTG) data from two cohorts to analyze the correlation between\nmaternal hypoxia and FHR changes (accelerations or decelerations). Maternal\nhypoxic event characteristics were analyzed using generalized linear modeling\n(GLM) to assess their associations with different FHR changes. Results: A total\nof 118 pregnant women participated. FHR changes were significantly associated\nwith maternal hypoxia, primarily characterized by accelerations. A longer\nhypoxic duration correlated with more significant FHR accelerations (P < 0.05),\nwhile prolonged hypoxia and greater SpO2 drop were linked to FHR decelerations\n(P < 0.05). Both cohorts showed a transient increase in FHR during maternal\nhypoxia, which returned to baseline after the event resolved. Conclusion:\nMaternal hypoxia significantly affects FHR, suggesting that maternal OSAS may\ncontribute to fetal hypoxia. These findings highlight the importance of\nmaternal-fetal interactions and provide insights for future interventions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T15:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.13019v1","title":"The higher regularity of the discrete Hardy-Littlewood maximal function","summary":"In a recent short note the first author \\cite{tem} gave the first positive\nresult on the higher order regularity of the discrete noncentered\nHardy-Littlewood maximal function. In this article we conduct a thorough\ninvestigation of possible similar results for higher order derivatives. We\nuncover that such results are indeed a consequence of a stronger phenomenon\nregarding the growth of $l^p(\\Z)$ norms of the derivatives of characteristic\nfunctions of finite subsets of $\\Z$. Along the way we discover very interesting\nconnections to Prouhot-Tarry-Escott (PTE) problem, and to zeros of complex\npolynomials with restricted coefficients (Littlewood-type polynomials).","main_category":"math.CA","categories":"math.CA","published":"2025-04-17T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.13059v1","title":"RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins","summary":"In the rapidly advancing field of robotics, dual-arm coordination and complex\nobject manipulation are essential capabilities for developing advanced\nautonomous systems. However, the scarcity of diverse, high-quality\ndemonstration data and real-world-aligned evaluation benchmarks severely limits\nsuch development. To address this, we introduce RoboTwin, a generative digital\ntwin framework that uses 3D generative foundation models and large language\nmodels to produce diverse expert datasets and provide a real-world-aligned\nevaluation platform for dual-arm robotic tasks. Specifically, RoboTwin creates\nvaried digital twins of objects from single 2D images, generating realistic and\ninteractive scenarios. It also introduces a spatial relation-aware code\ngeneration framework that combines object annotations with large language\nmodels to break down tasks, determine spatial constraints, and generate precise\nrobotic movement code. Our framework offers a comprehensive benchmark with both\nsimulated and real-world data, enabling standardized evaluation and better\nalignment between simulated training and real-world performance. We validated\nour approach using the open-source COBOT Magic Robot platform. Policies\npre-trained on RoboTwin-generated data and fine-tuned with limited real-world\nsamples demonstrate significant potential for enhancing dual-arm robotic\nmanipulation systems by improving success rates by over 70% for single-arm\ntasks and over 40% for dual-arm tasks compared to models trained solely on\nreal-world data.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CL","published":"2025-04-17T16:14:24Z"}
{"aid":"http://arxiv.org/abs/2504.13072v1","title":"HiScene: Creating Hierarchical 3D Scenes with Isometric View Generation","summary":"Scene-level 3D generation represents a critical frontier in multimedia and\ncomputer graphics, yet existing approaches either suffer from limited object\ncategories or lack editing flexibility for interactive applications. In this\npaper, we present HiScene, a novel hierarchical framework that bridges the gap\nbetween 2D image generation and 3D object generation and delivers high-fidelity\nscenes with compositional identities and aesthetic scene content. Our key\ninsight is treating scenes as hierarchical \"objects\" under isometric views,\nwhere a room functions as a complex object that can be further decomposed into\nmanipulatable items. This hierarchical approach enables us to generate 3D\ncontent that aligns with 2D representations while maintaining compositional\nstructure. To ensure completeness and spatial alignment of each decomposed\ninstance, we develop a video-diffusion-based amodal completion technique that\neffectively handles occlusions and shadows between objects, and introduce shape\nprior injection to ensure spatial coherence within the scene. Experimental\nresults demonstrate that our method produces more natural object arrangements\nand complete object instances suitable for interactive applications, while\nmaintaining physical plausibility and alignment with user inputs.","main_category":"cs.GR","categories":"cs.GR,cs.CV,cs.MM","published":"2025-04-17T16:33:39Z"}
{"aid":"http://arxiv.org/abs/2504.13089v1","title":"Absorption of Fermionic Dark Matter in the PICO-60 C$_{3}$F$_{8}$ Bubble\n  Chamber","summary":"Fermionic dark matter absorption on nuclear targets via neutral current\ninteractions is explored using a non-relativistic effective field theory\nframework. An analysis of data from the PICO-60 C$_{3}$F$_{8}$ bubble chamber\nsets leading constraints on spin-independent absorption for dark matter masses\nbelow 23 MeV/$\\textit{c}^2$ and establishes the first limits on spin-dependent\nabsorptive interactions. These results demonstrate the sensitivity of bubble\nchambers to low-mass dark matter and underscore the importance of absorption\nsearches in expanding the parameter space of direct detection experiments.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-04-17T16:55:46Z"}
{"aid":"http://arxiv.org/abs/2504.13092v1","title":"EventVAD: Training-Free Event-Aware Video Anomaly Detection","summary":"Video Anomaly Detection~(VAD) focuses on identifying anomalies within videos.\nSupervised methods require an amount of in-domain training data and often\nstruggle to generalize to unseen anomalies. In contrast, training-free methods\nleverage the intrinsic world knowledge of large language models (LLMs) to\ndetect anomalies but face challenges in localizing fine-grained visual\ntransitions and diverse events. Therefore, we propose EventVAD, an event-aware\nvideo anomaly detection framework that combines tailored dynamic graph\narchitectures and multimodal LLMs through temporal-event reasoning.\nSpecifically, EventVAD first employs dynamic spatiotemporal graph modeling with\ntime-decay constraints to capture event-aware video features. Then, it performs\nadaptive noise filtering and uses signal ratio thresholding to detect event\nboundaries via unsupervised statistical features. The statistical boundary\ndetection module reduces the complexity of processing long videos for MLLMs and\nimproves their temporal reasoning through event consistency. Finally, it\nutilizes a hierarchical prompting strategy to guide MLLMs in performing\nreasoning before determining final decisions. We conducted extensive\nexperiments on the UCF-Crime and XD-Violence datasets. The results demonstrate\nthat EventVAD with a 7B MLLM achieves state-of-the-art (SOTA) in training-free\nsettings, outperforming strong baselines that use 7B or larger MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:59:04Z"}
{"aid":"http://arxiv.org/abs/2504.13098v1","title":"Irradiation Studies of the Resistive AC-coupled Silicon Detector\n  (RSD/AC-LGAD)","summary":"Resistive AC-coupled Silicon Detectors (RSDs) are silicon sensors which\nprovide high temporal and spatial resolution. The RSD is a candidate sensor to\nbe used in future tracking detectors with the objective of obtaining '4D'\ntracking, where timing information can be used along with spatial hits during\ntrack finding. 4D tracking will be an essential part of any future lepton or\nhadron collider and may even be feasible at the HL-LHC. For applications at\nhadron colliders, RSD sensors must be able to operate in high fluence\nenvironments in order to provide 4D tracking. However, the effects of radiation\non RSDs have not been extensively studied. In this study, RSDs were irradiated\nto $1.0$, $2.0$, and $3.5 \\times 10^{15}$~cm$^{-2}$ (1~MeV neutron equivalents)\nwith both protons and neutrons. The sensors were then characterized\nelectrically to study the acceptor removal and, for the first time in this\ndoping concentration range, the donor removal. Then, the Transient Current\nTechnique was used to begin investigating the signal charge sharing after\nirradiation. The results suggest an interesting trend between acceptor and\ndonor removal, which is worthy of further study and could assist in improving\nradiation hardness of Low Gain Avalanche Diodes (LGADs).","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-17T17:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.13104v1","title":"Taylor coefficients and zeroes of entire functions of exponential type","summary":"Let $F$ be an entire function of exponential type represented by the Taylor\nseries \\[ F(z) = \\sum_{n\\ge 0} \\omega_n \\frac{z^n}{n!} \\] with unimodular\ncoefficients $|\\omega_n|=1$. We show that either the counting function $n_F(r)$\nof zeroes of $F$ grows linearly at infinity, or $F$ is an exponential function.\nThe same conclusion holds if only a positive asymptotic proportion of the\ncoefficients $\\omega_n$ is unimodular. This significantly extends a classical\nresult of Carlson (1915).\n  The second result requires less from the coefficient sequence $\\omega$, but\nmore from the counting function of zeroes $n_F$. Assuming that $0<c\\le\n|\\omega_n| \\le C <\\infty$, $n\\in\\mathbb Z_+$, we show that $n_F(r) =\no(\\sqrt{r})$ as $r\\to\\infty$, implies that $F$ is an exponential function. The\nsame conclusion holds if, for some $\\alpha<1/2$, $n_F(r_j)=O(r_j^{\\alpha})$\nonly along a sequence $r_j\\to\\infty$. Furthermore, this conclusion ceases to\nhold if $n_F(r)=O(\\sqrt r)$ as $r\\to\\infty$.","main_category":"math.CV","categories":"math.CV","published":"2025-04-17T17:18:52Z"}
{"aid":"http://arxiv.org/abs/2504.13110v1","title":"Propagation of Chaos in One-hidden-layer Neural Networks beyond\n  Logarithmic Time","summary":"We study the approximation gap between the dynamics of a polynomial-width\nneural network and its infinite-width counterpart, both trained using projected\ngradient descent in the mean-field scaling regime. We demonstrate how to\ntightly bound this approximation gap through a differential equation governed\nby the mean-field dynamics. A key factor influencing the growth of this ODE is\nthe local Hessian of each particle, defined as the derivative of the particle's\nvelocity in the mean-field dynamics with respect to its position. We apply our\nresults to the canonical feature learning problem of estimating a\nwell-specified single-index model; we permit the information exponent to be\narbitrarily large, leading to convergence times that grow polynomially in the\nambient dimension $d$. We show that, due to a certain ``self-concordance''\nproperty in these problems -- where the local Hessian of a particle is bounded\nby a constant times the particle's velocity -- polynomially many neurons are\nsufficient to closely approximate the mean-field dynamics throughout training.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-17T17:24:38Z"}
{"aid":"http://arxiv.org/abs/2504.13135v1","title":"Probing CP-Violating Neutral Triple Gauge Couplings at Electron-Positron\n  Colliders","summary":"We study the forms of CP-violating (CPV) neutral triple gauge couplings\n(nTGCs) that can be realized via dimension-8 operators in the Standard Model\nEffective Field Theory (SMEFT). We present a new formulation of the CPV nTGC\nform factors that is compatible with the spontaneous breaking of the\nelectroweak gauge symmetry, and show how these CPV form factors can be matched\nconsistently with the corresponding dimension-8 CPV nTGC operators in the\nbroken phase. We then study probes of the CPV nTGCs at future high-energy\n$e^+e^-$ colliders with centre-of-mass energies $\\sqrt{s} = (0.25, 0.5,1, 3,\n5)$TeV respectively, demonstrating that the $e^{\\mp}$ beam polarizations can\nhelp to improve the sensitivities of probes of the nTGCs. We estimate that the\nsensitivities for probing the new physics scales of the nTGCs can range from\n${O}(\\rm{TeV})$ at a 250GeV $e^+e^-$ collider to ${O}(10\\rm{TeV})$ at a 5TeV\n$e^+e^-$ collider, and that the sensitivities to form factors range from\n${O}(10^{-4})$ to ${O}(10^{-8})$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T17:47:54Z"}
{"aid":"http://arxiv.org/abs/2504.13140v1","title":"PCBEAR: Pose Concept Bottleneck for Explainable Action Recognition","summary":"Human action recognition (HAR) has achieved impressive results with deep\nlearning models, but their decision-making process remains opaque due to their\nblack-box nature. Ensuring interpretability is crucial, especially for\nreal-world applications requiring transparency and accountability. Existing\nvideo XAI methods primarily rely on feature attribution or static textual\nconcepts, both of which struggle to capture motion dynamics and temporal\ndependencies essential for action understanding. To address these challenges,\nwe propose Pose Concept Bottleneck for Explainable Action Recognition (PCBEAR),\na novel concept bottleneck framework that introduces human pose sequences as\nmotion-aware, structured concepts for video action recognition. Unlike methods\nbased on pixel-level features or static textual descriptions, PCBEAR leverages\nhuman skeleton poses, which focus solely on body movements, providing robust\nand interpretable explanations of motion dynamics. We define two types of\npose-based concepts: static pose concepts for spatial configurations at\nindividual frames, and dynamic pose concepts for motion patterns across\nmultiple frames. To construct these concepts, PCBEAR applies clustering to\nvideo pose sequences, allowing for automatic discovery of meaningful concepts\nwithout manual annotation. We validate PCBEAR on KTH, Penn-Action, and HAA500,\nshowing that it achieves high classification performance while offering\ninterpretable, motion-driven explanations. Our method provides both strong\npredictive performance and human-understandable insights into the model's\nreasoning process, enabling test-time interventions for debugging and improving\nmodel behavior.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:50:07Z"}
{"aid":"http://arxiv.org/abs/2504.13147v1","title":"Purely gravitational dark matter production in warm inflation","summary":"We consider an appealing scenario for the production of purely gravitational\ndark matter in the background of warm inflation, a mechanism that maintains\nstable thermal bath during inflation. Through systematic investigation of\nvarious gravitational production channels, we reveal distinctive features\ncompared to the standard inflation scenario. Notably, the inflaton annihilation\nchannel in warm inflation exhibits markedly different thermodynamics from the\nstandard inflation paradigm, leading to a suppression on the production of\nsub-inflaton-mass dark matter. For the production channel of inflationary\nvacuum fluctuations, we find a correlation of $\\rho_\\chi\\propto m_\\chi^{5/2}$\nfor the conformally coupled dark matter, which expands the feasible range of\ndark matter mass. Our results also indicates that a minimum temperature\nthreshold of $10^{-6}M_P$ is necessary for warm inflation, which allows\nadequate dark matter production. With observational constraints, our results\nprovide stringent limits on the mass range of purely gravitational dark matter\nwith sufficient density: $10^{-8}-10^{-2}M_P$ for minimal coupling and\n$10^{-14}-10^{-2}M_P$ for conformal coupling.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-17T17:54:40Z"}
{"aid":"http://arxiv.org/abs/2504.13166v1","title":"Topologically enabled superconductivity: possible implications for\n  rhombohedral graphene","summary":"We present a topological mechanism for superconductivity emerging from\nChern-2 insulators. While, naively, time-reversal symmetry breaking is expected\nto prevent superconductivity, it turns out that the opposite is the case: An\nexplicit model calculation for a generalized attractive-U Haldane-Hubbard model\ndemonstrates that superconductivity is only stabilized near the quantum\nanomalous Hall state, but not near a trivial, time-reversal symmetric band\ninsulator. As standard Bardeen-Cooper-Schrieffer-like mean-field theory fails\nto capture any superconducting state, we explain this using an effective\nfractionalized field theory involving fermionic chargeons, bosonic colorons and\nan emergent U(1) gauge field. When the chargeons form a gapped topological band\nstructure, the proliferation of single monopoles of this gauge field is\nforbidden. However, long-ranged monopole-antimonopole correlations emerge, and\nwe argue that those correspond to superconducting order. Using random phase\napproximation on top of extensive slave-rotor mean-field calculations we\ncharacterize coherence length and stiffness of the superconductor. Thereby, we\ndeduce the phase diagram in parameter space and furthermore discuss the effect\nof doping, temperature and an external magnetic field. We complement the\nfractionalized theory with calculations using an effective spin model and\nGutzwiller projected wavefunctions. While mostly based on a simple toy model,\nwe argue that our findings contribute to a better understanding of\nsuperconductivity emerging out of spin- and valley polarized rhombohedral\ngraphene multilayers in a parameter regime with nearby quantum anomalous Hall\ninsulators.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-17T17:59:01Z"}
