{"aid":"http://arxiv.org/abs/2503.21662v1","title":"Electronic structure dimensionality of the quantum-critical ferromagnet\n  YbNi$_4$P$_2$","summary":"YbNi$_4$P$_2$ is the first known ferromagnetic metal showing a second-order\nquantum phase transition. Current theoretical understanding rules out second\norder ferromagnetic quantum criticality in centrosymmetric 2D and 3D metals.\nThus, studying the electronic structure of YbNi$_4$P$_2$ is of prime\nfundamental importance. Using angle-resolved photoemission spectroscopy, we\nexperimentally prove the existence of 1D Fermi surface contours. In addition,\nour results demonstrate that part of the electronic structure of YbNi$_4$P$_2$\nis made of states of higher dimensionality, thereby bringing into question the\nfact that ferromagnetic quantum criticality in centrosymmetric crystals, is\nexclusively found in 1D systems. Our experimental data show that the electronic\nstructure of YbNi$_4$P$_2$ is a playground of mixed dimensionality, electron\ncorrelations, strong hybridization and spin-orbit coupling, all of them\nproviding new insights in understanding the origin of ferromagnetic quantum\ncriticality.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci,quant-ph","published":"2025-03-27T16:27:42Z"}
{"aid":"http://arxiv.org/abs/2503.21663v1","title":"DiPolMol-Py: A Python package for calculations for $^2Î£$\n  ground-state molecules","summary":"We present the python package DiPolMol-Py, which can be used to calculate the\nrotational and hyperfine structure of $^2\\Sigma$ molecules. The calculations\ncan be performed in the presence of dc magnetic fields, dc electric fields and\nfar off-resonant optical fields. We additionally include functions to calculate\nthe polarisability of the molecule and the transition dipole moment between\ndifferent energy eigenstates. The package is applicable to many of the\nmolecules which can be laser cooled, specifically the alkaline earth fluorides.\nWe provide a constants file which includes many of the required literature\nvalues for CaF, SrF and BaF. Additional species can easily be added by updating\nthis file.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.comp-ph","published":"2025-03-27T16:31:06Z"}
{"aid":"http://arxiv.org/abs/2503.21672v1","title":"The Avoider-Enforcer game on hypergraphs of rank 3","summary":"In the Avoider-Enforcer convention of positional games, two players, Avoider\nand Enforcer, take turns selecting vertices from a hypergraph H. Enforcer wins\nif, by the time all vertices of H have been selected, Avoider has completely\nfilled an edge of H with her vertices; otherwise, Avoider wins. In this paper,\nwe first give some general results, in particular regarding the outcome of the\ngame and disjoint unions of hypergraphs. We then determine which player has a\nwinning strategy for all hypergraphs of rank 2, and for linear hypergraphs of\nrank 3 when Avoider plays the last move. The structural characterisations we\nobtain yield polynomial-time algorithms.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-03-27T16:40:37Z"}
{"aid":"http://arxiv.org/abs/2503.21673v1","title":"A friendly introduction to triangular transport","summary":"Decision making under uncertainty is a cross-cutting challenge in science and\nengineering. Most approaches to this challenge employ probabilistic\nrepresentations of uncertainty. In complicated systems accessible only via data\nor black-box models, however, these representations are rarely known. We\ndiscuss how to characterize and manipulate such representations using\ntriangular transport maps, which approximate any complex probability\ndistribution as a transformation of a simple, well-understood distribution. The\nparticular structure of triangular transport guarantees many desirable\nmathematical and computational properties that translate well into solving\npractical problems. Triangular maps are actively used for density estimation,\n(conditional) generative modelling, Bayesian inference, data assimilation,\noptimal experimental design, and related tasks. While there is ample literature\non the development and theory of triangular transport methods, this manuscript\nprovides a detailed introduction for scientists interested in employing measure\ntransport without assuming a formal mathematical background. We build intuition\nfor the key foundations of triangular transport, discuss many aspects of its\npractical implementation, and outline the frontiers of this field.","main_category":"stat.CO","categories":"stat.CO,physics.ao-ph,stat.ME,stat.ML","published":"2025-03-27T16:41:14Z"}
{"aid":"http://arxiv.org/abs/2503.21674v1","title":"Intelligent IoT Attack Detection Design via ODLLM with Feature\n  Ranking-based Knowledge Base","summary":"The widespread adoption of Internet of Things (IoT) devices has introduced\nsignificant cybersecurity challenges, particularly with the increasing\nfrequency and sophistication of Distributed Denial of Service (DDoS) attacks.\nTraditional machine learning (ML) techniques often fall short in detecting such\nattacks due to the complexity of blended and evolving patterns. To address\nthis, we propose a novel framework leveraging On-Device Large Language Models\n(ODLLMs) augmented with fine-tuning and knowledge base (KB) integration for\nintelligent IoT network attack detection. By implementing feature ranking\ntechniques and constructing both long and short KBs tailored to model\ncapacities, the proposed framework ensures efficient and accurate detection of\nDDoS attacks while overcoming computational and privacy limitations. Simulation\nresults demonstrate that the optimized framework achieves superior accuracy\nacross diverse attack types, especially when using compact models in edge\ncomputing environments. This work provides a scalable and secure solution for\nreal-time IoT security, advancing the applicability of edge intelligence in\ncybersecurity.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.NI","published":"2025-03-27T16:41:57Z"}
{"aid":"http://arxiv.org/abs/2503.21684v1","title":"Decorated phases in triblock copolymers: zeroth- and first-order\n  analysis","summary":"We study a two-dimensional inhibitory ternary system characterized by a free\nenergy functional which combines an interface short-range interaction energy\npromoting micro-domain growth with a Coulomb-type long-range interaction energy\nwhich prevents micro-domains from unlimited spreading. Here we consider a\nscenario in which two species are dominant and one species is vanishingly\nsmall. In this scenario two energy levels are distinguished: the zeroth-order\nenergy encodes information on the optimal arrangement of the dominant\nconstituents, while the first-order energy gives the shape of the vanishing\nconstituent. This first-order energy also shows that, for any optimal\nconfiguration, the vanishing phase must lie on the boundary between the two\ndominant constituents and form lens clusters also known as vesica piscis.","main_category":"math.AP","categories":"math.AP","published":"2025-03-27T16:52:27Z"}
{"aid":"http://arxiv.org/abs/2503.21694v1","title":"Progressive Rendering Distillation: Adapting Stable Diffusion for\n  Instant Text-to-Mesh Generation without 3D Data","summary":"It is highly desirable to obtain a model that can generate high-quality 3D\nmeshes from text prompts in just seconds. While recent attempts have adapted\npre-trained text-to-image diffusion models, such as Stable Diffusion (SD), into\ngenerators of 3D representations (e.g., Triplane), they often suffer from poor\nquality due to the lack of sufficient high-quality 3D training data. Aiming at\novercoming the data shortage, we propose a novel training scheme, termed as\nProgressive Rendering Distillation (PRD), eliminating the need for 3D\nground-truths by distilling multi-view diffusion models and adapting SD into a\nnative 3D generator. In each iteration of training, PRD uses the U-Net to\nprogressively denoise the latent from random noise for a few steps, and in each\nstep it decodes the denoised latent into 3D output. Multi-view diffusion\nmodels, including MVDream and RichDreamer, are used in joint with SD to distill\ntext-consistent textures and geometries into the 3D outputs through score\ndistillation. Since PRD supports training without 3D ground-truths, we can\neasily scale up the training data and improve generation quality for\nchallenging text prompts with creative concepts. Meanwhile, PRD can accelerate\nthe inference speed of the generation model in just a few steps. With PRD, we\ntrain a Triplane generator, namely TriplaneTurbo, which adds only $2.5\\%$\ntrainable parameters to adapt SD for Triplane generation. TriplaneTurbo\noutperforms previous text-to-3D generators in both efficiency and quality.\nSpecifically, it can produce high-quality 3D meshes in 1.2 seconds and\ngeneralize well for challenging text input. The code is available at\nhttps://github.com/theEricMa/TriplaneTurbo.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV","published":"2025-03-27T16:59:15Z"}
{"aid":"http://arxiv.org/abs/2503.21708v1","title":"Elementwise Layer Normalization","summary":"A recent paper proposed Dynamic Tanh (DyT) as a drop-in replacement for Layer\nNormalization. Although the method is empirically well-motivated and appealing\nfrom a practical point of view, it lacks a theoretical foundation. In this\nwork, we derive DyT mathematically and show that a well-defined approximation\nis needed to do so. By dropping said approximation, an alternative element-wise\ntransformation is obtained, which we call Elementwise Layer Normalization\n(ELN). We demonstrate that ELN resembles Layer Normalization more accurately\nthan DyT does.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-03-27T17:20:44Z"}
{"aid":"http://arxiv.org/abs/2503.21714v1","title":"As easy as PIE: understanding when pruning causes language models to\n  disagree","summary":"Language Model (LM) pruning compresses the model by removing weights, nodes,\nor other parts of its architecture. Typically, pruning focuses on the resulting\nefficiency gains at the cost of effectiveness. However, when looking at how\nindividual data points are affected by pruning, it turns out that a particular\nsubset of data points always bears most of the brunt (in terms of reduced\naccuracy) when pruning, but this effect goes unnoticed when reporting the mean\naccuracy of all data points. These data points are called PIEs and have been\nstudied in image processing, but not in NLP. In a study of various NLP\ndatasets, pruning methods, and levels of compression, we find that PIEs impact\ninference quality considerably, regardless of class frequency, and that BERT is\nmore prone to this than BiLSTM. We also find that PIEs contain a high amount of\ndata points that have the largest influence on how well the model generalises\nto unseen data. This means that when pruning, with seemingly moderate loss to\naccuracy across all data points, we in fact hurt tremendously those data points\nthat matter the most. We trace what makes PIEs both hard and impactful to\ninference to their overall longer and more semantically complex text. These\nfindings are novel and contribute to understanding how LMs are affected by\npruning. The code is available at: https://github.com/pietrotrope/AsEasyAsPIE","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-27T17:26:32Z"}
{"aid":"http://arxiv.org/abs/2503.21723v1","title":"OccRobNet : Occlusion Robust Network for Accurate 3D Interacting\n  Hand-Object Pose Estimation","summary":"Occlusion is one of the challenging issues when estimating 3D hand pose. This\nproblem becomes more prominent when hand interacts with an object or two hands\nare involved. In the past works, much attention has not been given to these\noccluded regions. But these regions contain important and beneficial\ninformation that is vital for 3D hand pose estimation. Thus, in this paper, we\npropose an occlusion robust and accurate method for the estimation of 3D\nhand-object pose from the input RGB image. Our method includes first localising\nthe hand joints using a CNN based model and then refining them by extracting\ncontextual information. The self attention transformer then identifies the\nspecific joints along with the hand identity. This helps the model to identify\nthe hand belongingness of a particular joint which helps to detect the joint\neven in the occluded region. Further, these joints with hand identity are then\nused to estimate the pose using cross attention mechanism. Thus, by identifying\nthe joints in the occluded region, the obtained network becomes robust to\nocclusion. Hence, this network achieves state-of-the-art results when evaluated\non the InterHand2.6M, HO3D and H$_2$O3D datasets.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-03-27T17:36:55Z"}
{"aid":"http://arxiv.org/abs/2503.21727v1","title":"Enhancing Underwater Navigation through Cross-Correlation-Aware Deep\n  INS/DVL Fusion","summary":"The accurate navigation of autonomous underwater vehicles critically depends\non the precision of Doppler velocity log (DVL) velocity measurements. Recent\nadvancements in deep learning have demonstrated significant potential in\nimproving DVL outputs by leveraging spatiotemporal dependencies across multiple\nsensor modalities. However, integrating these estimates into model-based\nfilters, such as the extended Kalman filter, introduces statistical\ninconsistencies, most notably, cross-correlations between process and\nmeasurement noise. This paper addresses this challenge by proposing a\ncross-correlation-aware deep INS/DVL fusion framework. Building upon BeamsNet,\na convolutional neural network designed to estimate AUV velocity using DVL and\ninertial data, we integrate its output into a navigation filter that explicitly\naccounts for the cross-correlation induced between the noise sources. This\napproach improves filter consistency and better reflects the underlying sensor\nerror structure. Evaluated on two real-world underwater trajectories, the\nproposed method outperforms both least squares and cross-correlation-neglecting\napproaches in terms of state uncertainty. Notably, improvements exceed 10% in\nvelocity and misalignment angle confidence metrics. Beyond demonstrating\nempirical performance, this framework provides a theoretically principled\nmechanism for embedding deep learning outputs within stochastic filters.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-27T17:38:43Z"}
{"aid":"http://arxiv.org/abs/2503.21728v1","title":"Near field imaging of local interference in radio interferometric data:\n  Impact on the redshifted 21-cm power spectrum","summary":"Radio-frequency interference (RFI) is a major systematic limitation in radio\nastronomy, particularly for science cases requiring high sensitivity, such as\n21-cm cosmology. Traditionally, RFI is dealt with by identifying its signature\nin the dynamic spectra of visibility data and flagging strongly affected\nregions. However, for RFI sources that do not occupy narrow regions in the\ntime-frequency space, such as persistent local RFI, modeling these sources\ncould be essential to mitigating their impact. This paper introduces two\nmethods for detecting and characterizing local RFI sources from radio\ninterferometric visibilities: matched filtering and maximum a posteriori (MAP)\nimaging. These algorithms use the spherical wave equation to construct\nthree-dimensional near-field image cubes of RFI intensity from the\nvisibilities. The matched filter algorithm can generate normalized maps by\ncross-correlating the expected contributions from RFI sources with the observed\nvisibilities, while the MAP method performs a regularized inversion of the\nvisibility equation in the near field. We also develop a full polarization\nsimulation framework for RFI and demonstrate the methods on simulated\nobservations of local RFI sources. The stability, speed, and errors introduced\nby these algorithms are investigated, and, as a demonstration, the algorithms\nare applied to a subset of NenuFAR observations to perform spatial, spectral,\nand temporal characterization of two local RFI sources. We assess the impact of\nlocal RFI on images, the uv plane, and cylindrical power spectra through\nsimulations and describe these effects qualitatively. We also quantify the\nlevel of errors and biases that these algorithms induce and assess their\nimplications for the estimated 21-cm power spectrum with radio interferometers.\nThe near-field imaging and simulation codes are made available publicly in the\nPython library nfis.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO","published":"2025-03-27T17:40:38Z"}
{"aid":"http://arxiv.org/abs/2503.21733v1","title":"Fully dynamic biconnectivity in $\\tilde{\\mathcal{O}}(\\log^2 n)$ time","summary":"We present a deterministic fully-dynamic data structure for maintaining\ninformation about the cut-vertices in a graph; i.e. the vertices whose removal\nwould disconnect the graph. Our data structure supports insertion and deletion\nof edges, as well as queries to whether a pair of connected vertices are either\nbiconnected, or can be separated by a cutvertex, and in the latter case we\nsupport access to separating cutvertices. All update operations are supported\nin amortized $O(\\log^2 n \\log^2 \\log n)$ time, and queries take worst-case\n$O(\\log n \\log^2 \\log n)$ time. Note that these time bounds match the current\nbest for deterministic dynamic connectivity up to $\\log \\log n$ factors.\n  We obtain our improved running time by a series of reductions from the\noriginal problem into well-defined data structure problems. While we do apply\nthe well-known techniques for improving running time of two-edge connectivity\n[STOC'00, SODA'18], these techniques alone do not lead to an update time of\n$\\tilde{O}(\\log^3 n)$, let alone the $\\tilde{O}(\\log^2 n)$ we give as a final\nresult.\n  Our contributions include a formally defined transient expose operation,\nwhich can be thought of as a cheaper read-only expose operation on a top tree.\nFor each vertex in the graph, we maintain a data structure over its neighbors,\nand in this data structure we apply biasing (twice) to save two $\\tilde{O}(\\log\nn)$ factors. One of these biasing techniques is a new biased disjoint sets data\nstructure, which may be of independent interest. Moreover, in this neighborhood\ndata structure, we facilitate that the vertex can select two VIP neighbors that\nget special treatment, corresponding to its potentially two neighbors on an\nexposed path, improving a $\\log n$-time operation down to constant time. It is\nthis combination of VIP neighbors with the transient expose that saves an\n$\\tilde{O}(\\log n)$-factor from another bottleneck.","main_category":"cs.DS","categories":"cs.DS","published":"2025-03-27T17:47:18Z"}
{"aid":"http://arxiv.org/abs/2503.21735v1","title":"GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release\n  Analytics","summary":"Ensuring the reliability and effectiveness of software release decisions is\ncritical, particularly in safety-critical domains like automotive systems.\nPrecise analysis of release validation data, often presented in tabular form,\nplays a pivotal role in this process. However, traditional methods that rely on\nmanual analysis of extensive test datasets and validation metrics are prone to\ndelays and high costs. Large Language Models (LLMs) offer a promising\nalternative but face challenges in analytical reasoning, contextual\nunderstanding, handling out-of-scope queries, and processing structured test\ndata consistently; limitations that hinder their direct application in\nsafety-critical scenarios. This paper introduces GateLens, an LLM-based tool\nfor analyzing tabular data in the automotive domain. GateLens translates\nnatural language queries into Relational Algebra (RA) expressions and then\ngenerates optimized Python code. It outperforms the baseline system on\nbenchmarking datasets, achieving higher F1 scores and handling complex and\nambiguous queries with greater robustness. Ablation studies confirm the\ncritical role of the RA module, with performance dropping sharply when omitted.\nIndustrial evaluations reveal that GateLens reduces analysis time by over 80%\nwhile maintaining high accuracy and reliability. As demonstrated by presented\nresults, GateLens achieved high performance without relying on few-shot\nexamples, showcasing strong generalization across various query types from\ndiverse company roles. Insights from deploying GateLens with a partner\nautomotive company offer practical guidance for integrating AI into critical\nworkflows such as release validation. Results show that by automating test\nresult analysis, GateLens enables faster, more informed, and dependable release\ndecisions, and can thus advance software scalability and reliability in\nautomotive systems.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL,cs.MA","published":"2025-03-27T17:48:32Z"}
{"aid":"http://arxiv.org/abs/2503.21736v1","title":"Local Primordial non-Gaussian Bias from Time Evolution","summary":"Primordial non-Gaussianity (PNG) is a signature of fundamental physics in the\nearly universe that is probed by cosmological observations. It is well known\nthat the local type of PNG generates a strong signal in the two-point function\nof large-scale structure tracers, such as galaxies. This signal, often termed\n``scale-dependent bias'' is a generic feature of modulation of gravitational\nstructure formation by a large-scale mode. It is less well-appreciated that the\ncoefficient controlling this signal, $b_{\\phi}$, is closely connected to the\ntime evolution of the tracer number density. This correspondence between time\nevolution and local PNG can be simply explained for a universal tracer whose\nmass function only depends on peak height, and more generally for non-universal\ntracers in the separate universe picture, which we validate in simulations. We\nalso describe how to recover the bias of tracers subject to a survey selection\nfunction, and perform a simple demonstration on simulated galaxies. Since the\nlocal PNG amplitude in $n-$point statistics ($f_{\\rm NL}$) is largely\ndegenerate with the coefficient $b_{\\phi}$, this proof of concept study\ndemonstrates that galaxy survey data can allow for more optimal and robust\nextraction of local PNG information from upcoming surveys.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-03-27T17:49:31Z"}
{"aid":"http://arxiv.org/abs/2503.21741v1","title":"Adiabatic quantum state preparation in integrable models","summary":"We propose applying the adiabatic algorithm to prepare high-energy\neigenstates of integrable models on a quantum computer. We first review the\nstandard adiabatic algorithm to prepare ground states in each magnetization\nsector of the prototypical XXZ Heisenberg chain. Based on the thermodynamic\nBethe ansatz, we show that the algorithm circuit depth is polynomial in the\nnumber of qubits $N$, outperforming previous methods explicitly relying on\nintegrability. Next, we propose a protocol to prepare arbitrary eigenstates of\nintegrable models that satisfy certain conditions. For a given target\neigenstate, we construct a suitable parent Hamiltonian written in terms of a\ncomplete set of local conserved quantities. We propose using such Hamiltonian\nas an input for an adiabatic algorithm. After benchmarking this construction in\nthe case of the non-interacting XY spin chain, where we can rigorously prove\nits efficiency, we apply it to prepare arbitrary eigenstates of the\nRichardson-Gaudin models. In this case, we provide numerical evidence that the\ncircuit depth of our algorithm is polynomial in $N$ for all eigenstates,\ndespite the models being interacting.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,cond-mat.str-el","published":"2025-03-27T17:51:20Z"}
{"aid":"http://arxiv.org/abs/2503.21746v1","title":"Effects of dissipation on phase diagram and bosonic excitations in the\n  quark-meson model","summary":"In this work we study the quark-meson model within a real-time formulation of\nthe functional renormalization group (FRG) on the Schwinger-Keldysh contour.\nFirst, we discuss in detail the symmetry of thermal equilibrium for the\nfermionic sector of the Keldysh action. We take into account dissipation for\nthe bosonic degrees of freedom in the spirit of the Caldeira-Leggett model by\ncoupling the system to an $O(4)$ invariant external heat bath. We study the\neffect of dissipation on static equilibrium properties, most prominently on the\nFRG flow of the effective potential and thus on the resulting phase diagram. We\nfind that, unlike in classical systems, through the contributions from non-zero\nMatsubara modes the dissipative dynamics can in general have an effect on\nstatic observables. We investigate these effects within two phenomenological\nmodels for the temperature dependence of the pion damping to verify that they\nare quantitatively small. To estimate their largest possible influence, we\nconsider limits where the damping constants approach infinity.","main_category":"hep-ph","categories":"hep-ph","published":"2025-03-27T17:53:22Z"}
{"aid":"http://arxiv.org/abs/2503.21749v1","title":"LeX-Art: Rethinking Text Generation via Scalable High-Quality Data\n  Synthesis","summary":"We introduce LeX-Art, a comprehensive suite for high-quality text-image\nsynthesis that systematically bridges the gap between prompt expressiveness and\ntext rendering fidelity. Our approach follows a data-centric paradigm,\nconstructing a high-quality data synthesis pipeline based on Deepseek-R1 to\ncurate LeX-10K, a dataset of 10K high-resolution, aesthetically refined\n1024$\\times$1024 images. Beyond dataset construction, we develop LeX-Enhancer,\na robust prompt enrichment model, and train two text-to-image models, LeX-FLUX\nand LeX-Lumina, achieving state-of-the-art text rendering performance. To\nsystematically evaluate visual text generation, we introduce LeX-Bench, a\nbenchmark that assesses fidelity, aesthetics, and alignment, complemented by\nPairwise Normalized Edit Distance (PNED), a novel metric for robust text\naccuracy evaluation. Experiments demonstrate significant improvements, with\nLeX-Lumina achieving a 79.81% PNED gain on CreateBench, and LeX-FLUX\noutperforming baselines in color (+3.18%), positional (+4.45%), and font\naccuracy (+3.81%). Our codes, models, datasets, and demo are publicly\navailable.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:56:15Z"}
{"aid":"http://arxiv.org/abs/2503.21752v1","title":"Hypergraphic zonotopes and acyclohedra","summary":"We introduce a higher-uniformity analogue of graphic zonotopes and\npermutohedra. Specifically, given a $(d+1)$-uniform hypergraph $H$, we define\nits hypergraphic zonotope $\\mathcal{Z}_H$, and when $H$ is the complete\n$(d+1)$-uniform hypergraph $K^{(d+1)}_n$, we call its hypergraphic zonotope the\nacyclohedron $\\mathcal{A}_{n,d}$.\n  We express the volume of $\\mathcal{Z}_H$ as a homologically weighted count of\nthe spanning $d$-dimensional hypertrees of $H$, which is closely related to\nKalai's generalization of Cayley's theorem in the case when $H=K^{(d+1)}_n$\n(but which, curiously, is not the same). We also relate the vertices of\nhypergraphic zonotopes to a notion of acyclic orientations previously studied\nby Linial and Morganstern for complete hypergraphs.","main_category":"math.CO","categories":"math.CO","published":"2025-03-27T17:56:42Z"}
{"aid":"http://arxiv.org/abs/2503.21768v1","title":"Results on branching random walks and rumor processes via germ order","summary":"Germ order is a non-standard stochastic order defined through the comparison\nof the generating functions of the processes. This order was first introduced\nfor branching random walks with a constant breeding law and independent\ndispersal of offspring, which are characterized by a one-dimensional generating\nfunction. In this work, we investigate the properties of the extension of this\nconcept to processes characterized by a multidimensional generating function,\nsuch as general branching random walks and rumor processes. In particular, we\nuse germ ordering to characterize the behavior of certain branching random\nwalks and rumor processes with inhomogeneous breeding/transmitting laws.","main_category":"math.PR","categories":"math.PR","published":"2025-03-27T17:59:06Z"}
{"aid":"http://arxiv.org/abs/2503.23680v1","title":"Modeling Framework to Predict Melting Dynamics at Microstructural\n  Defects in TNT-HMX High Explosive Composites","summary":"Many high explosive (HE) formulations are composite materials whose\nmicrostructure is understood to impact functional characteristics. Interfaces\nare known to mediate the formation of hot spots that control their safety and\ninitiation. To study such processes at molecular scales, we developed all-atom\nforce fields (FFs) for Octol, a prototypical HE formulation comprised of TNT\n(2,4,6-trinitrotoluene) and HMX\n(octahydro-1,3,5,7-tetranitro-1,3,5,7-tetrazocine). We extended a FF for TNT\nand recasted it in a form that can be readily combined with a well-established\nFF for HMX. The resulting FF was extensively validated against experimental\nresults and density functional theory calculations. We applied the new combined\nTNT-HMX FF to predict and rank surface and interface energies, which indicate\nthat there is an energetic driver for coarsening of microstructural grains in\nTNT-HMX composites. Finally, we assess the impact of several microstructural\nenvironments on the dynamic melting of TNT crystal under ultrafast thermal\nloading. We find that both free surfaces and planar material interfaces are\neffective nucleation points for TNT melting. However, MD simulations show that\nTNT crystal is prone to superheating by at least 50 K on sub-nanosecond\ntimescales and that the degree of superheating is inversely correlated with\nsurface and interface energy. The modeling framework presented here will enable\nfuture studies on hot spot formation processes in accident scenarios that are\ngoverned by strong coupling between microstructural interfaces, material\nmechanics, momentum and energy transport, phase transitions, and chemistry.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T03:01:34Z"}
{"aid":"http://arxiv.org/abs/2503.23688v1","title":"Mapping Geopolitical Bias in 11 Large Language Models: A Bilingual,\n  Dual-Framing Analysis of U.S.-China Tensions","summary":"This study systematically analyzes geopolitical bias across 11 prominent\nLarge Language Models (LLMs) by examining their responses to seven critical\ntopics in U.S.-China relations. Utilizing a bilingual (English and Chinese) and\ndual-framing (affirmative and reverse) methodology, we generated 19,712 prompts\ndesigned to detect ideological leanings in model outputs. Responses were\nquantitatively assessed on a normalized scale from -2 (strongly Pro-China) to\n+2 (strongly Pro-U.S.) and categorized according to stance, neutrality, and\nrefusal rates. The findings demonstrate significant and consistent ideological\nalignments correlated with the LLMs' geographic origins; U.S.-based models\npredominantly favored Pro-U.S. stances, while Chinese-origin models exhibited\npronounced Pro-China biases. Notably, language and prompt framing substantially\ninfluenced model responses, with several LLMs exhibiting stance reversals based\non prompt polarity or linguistic context. Additionally, we introduced\ncomprehensive metrics to evaluate response consistency across languages and\nframing conditions, identifying variability and vulnerabilities in model\nbehaviors. These results offer practical insights that can guide organizations\nand individuals in selecting LLMs best aligned with their operational\npriorities and geopolitical considerations, underscoring the importance of\ncareful model evaluation in politically sensitive applications. Furthermore,\nthe research highlights specific prompt structures and linguistic variations\nthat can strategically trigger distinct responses from models, revealing\nmethods for effectively navigating and influencing LLM outputs.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-03-31T03:38:17Z"}
{"aid":"http://arxiv.org/abs/2503.23691v1","title":"A Conceptual Framework for Human-AI Collaborative Genome Annotation","summary":"Genome annotation is essential for understanding the functional elements\nwithin genomes. While automated methods are indispensable for processing\nlarge-scale genomic data, they often face challenges in accurately predicting\ngene structures and functions. Consequently, manual curation by domain experts\nremains crucial for validating and refining these predictions. These combined\noutcomes from automated tools and manual curation highlight the importance of\nintegrating human expertise with AI capabilities to improve both the accuracy\nand efficiency of genome annotation. However, the manual curation process is\ninherently labor-intensive and time-consuming, making it difficult to scale for\nlarge datasets. To address these challenges, we propose a conceptual framework,\nHuman-AI Collaborative Genome Annotation (HAICoGA), which leverages the\nsynergistic partnership between humans and artificial intelligence to enhance\nhuman capabilities and accelerate the genome annotation process. Additionally,\nwe explore the potential of integrating Large Language Models (LLMs) into this\nframework to support and augment specific tasks. Finally, we discuss emerging\nchallenges and outline open research questions to guide further exploration in\nthis area.","main_category":"q-bio.GN","categories":"q-bio.GN,cs.HC","published":"2025-03-31T03:44:00Z"}
{"aid":"http://arxiv.org/abs/2503.23700v1","title":"Dual-band Unified Exploration of Three CMZ Clouds (DUET). Cloud-wide\n  census of continuum sources showing low spectral indices","summary":"The Milky Way's Central Molecular Zone (CMZ) is measured to form stars 10\ntimes less efficiently than in the Galactic disk, based on emission from\nhigh-mass stars. However, the CMZ's low-mass protostellar population, which\naccounts for most of the initial stellar mass budget and star formation rate\n(SFR), is poorly constrained observationally due to limited sensitivity and\nresolution. We present the Dual-band Unified Exploration of Three CMZ Clouds\n(DUET) survey, targeting the 20 km/s Cloud, Sgr C, and Dust Ridge cloud e using\nthe Atacama Large Millimeter/submillimeter Array (ALMA) at 1.3 and 3 mm. The\nmosaicked observations achieve a comparable resolution of 0.2-0.3\" (~1600-2500\nau) and a sky coverage of 8.3-10.4 square arcmin, respectively. We report 563\ncontinuum sources at 1.3 mm and 330 at 3 mm, respectively, and a dual-band\ncatalog with 450 continuum sources. These sources are marginally resolved at\nthe 2,000 au resolution. We find a cloud-wide deviation (>70%) from\ncommonly-used dust modified blackbody (MBB) models, characterized by either low\nspectral indices or low brightness temperatures. Three possible explanations\nfor the deviation are discussed. (1) Optically thick Class 0/I Young stellar\nobjects (YSOs) with very small beam filling factors can lead to lower\nbrightness temperatures than what MBB models predict. (2) Large (mm/cm-sized)\ndust grains have more significant self-scattering, and therefore\nfrequency-dependent albedo could cause lower spectral indices. (3) Free-free\nemission over 30 uJy can severely contaminate dust emission and cause low\nspectral indices for mJy sources in our sample, although the needed number of\nmassive protostars (embedded UCHII regions) is infeasibly high for the normal\nstellar initial mass function. A reliable measurement of the SFR at low\nprotostellar masses will require future work to distinguish between these\npossible explanations.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-03-31T03:56:43Z"}
{"aid":"http://arxiv.org/abs/2503.23702v1","title":"3D Dental Model Segmentation with Geometrical Boundary Preserving","summary":"3D intraoral scan mesh is widely used in digital dentistry diagnosis,\nsegmenting 3D intraoral scan mesh is a critical preliminary task. Numerous\napproaches have been devised for precise tooth segmentation. Currently, the\ndeep learning-based methods are capable of the high accuracy segmentation of\ncrown. However, the segmentation accuracy at the junction between the crown and\nthe gum is still below average. Existing down-sampling methods are unable to\neffectively preserve the geometric details at the junction. To address these\nproblems, we propose CrossTooth, a boundary-preserving segmentation method that\ncombines 3D mesh selective downsampling to retain more vertices at the\ntooth-gingiva area, along with cross-modal discriminative boundary features\nextracted from multi-view rendered images, enhancing the geometric\nrepresentation of the segmentation network. Using a point network as a backbone\nand incorporating image complementary features, CrossTooth significantly\nimproves segmentation accuracy, as demonstrated by experiments on a public\nintraoral scan dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:00:11Z"}
{"aid":"http://arxiv.org/abs/2503.23714v1","title":"Building Instruction-Tuning Datasets from Human-Written Instructions\n  with Open-Weight Large Language Models","summary":"Instruction tuning is crucial for enabling Large Language Models (LLMs) to\nsolve real-world tasks. Prior work has shown the effectiveness of\ninstruction-tuning data synthesized solely from LLMs, raising a fundamental\nquestion: Do we still need human-originated signals for instruction tuning?\nThis work answers the question affirmatively: we build state-of-the-art\ninstruction-tuning datasets sourced from human-written instructions, by simply\npairing them with LLM-generated responses. LLMs fine-tuned on our datasets\nconsistently outperform those fine-tuned on existing ones. Our data\nconstruction approach can be easily adapted to other languages; we build\ndatasets for Japanese and confirm that LLMs tuned with our data reach\nstate-of-the-art performance. Analyses suggest that instruction-tuning in a new\nlanguage allows LLMs to follow instructions, while the tuned models exhibit a\nnotable lack of culture-specific knowledge in that language. The datasets and\nfine-tuned models will be publicly available. Our datasets, synthesized with\nopen-weight LLMs, are openly distributed under permissive licenses, allowing\nfor diverse use cases.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T04:28:38Z"}
{"aid":"http://arxiv.org/abs/2503.23720v1","title":"On an approach to canonicalizing elliptic Feynman integrals","summary":"We present a systematic method for the construction of canonical bases for\nunivariate elliptic Feynman integrals with multiple kinematic scales, which\nfrequently arise in phenomenologically relevant scattering processes. The\nconstruction is performed in the Legendre normal form of elliptic curves, where\nthe geometric propoerties of the curves are simple and explicit and further\nkinemtic singularities are present as marked points. The canonical bases are\nconstructed using Abelian differentials of three kinds with a universal linear\ntransformation. The bases constructed in the normal form can be mapped to\ngeneric integral families via an appropriate M\\\"obius transformation. As a\ndemonstration, we discuss the application of our method to several concrete\nexamples, where we show that the $\\varepsilon$-factorization of sub-sector\ndependence can also be simply done. Our method can be readily applied to more\ncomplicated integral families straightforwardly.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-03-31T04:42:54Z"}
{"aid":"http://arxiv.org/abs/2503.23723v1","title":"Undecidable problems associated with variational quantum algorithms","summary":"Variational Quantum Algorithms (VQAs), such as the Variational Quantum\nEigensolver (VQE) and the Quantum Approximate Optimization Algorithm (QAOA),\nare widely studied as candidates for near-term quantum advantage. Recent work\nhas shown that training VQAs is NP-hard in general. In this paper, we present a\nconditional result suggesting that the training of VQAs is undecidable, even in\nidealized, noiseless settings. We reduce the decision version of the digitized\nVQA training problem-where circuit parameters are drawn from a discrete set-to\nthe question of whether a universal Diophantine equation (UDE) has a root. This\nreduction relies on encoding the UDE into the structure of a variational\nquantum circuit via the matrix exponentials. The central step involves\nestablishing a correspondence between the objective function of the VQA and a\nknown UDE of 58 variables and degree 4. Our main result is conditional on a\nnatural conjecture: that a certain system of structured complex polynomial\nequations-arising from the inner product of a VQA circuit output and a fixed\nobservable-has at least one solution. We argue this conjecture is plausible\nbased on dimension-counting arguments (degrees of freedom in the Hamiltonians,\nstate vector, and observable), and the generic solvability of such systems in\nalgebraic geometry over the complex numbers. Under this assumption, we suggest\nthat deciding whether a digitized VQA achieves a given energy threshold is\nundecidable. This links the limitations of variational quantum algorithms to\nfoundational questions in mathematics and logic, extending the known landscape\nof quantum computational hardness to include uncomputability. Additionally, we\nestablish an unconditional undecidability result for VQA convergence in open\nquantum systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T04:52:43Z"}
{"aid":"http://arxiv.org/abs/2503.23724v1","title":"Colossal enhancement of spin transmission through magnon confinement in\n  an antiferromagnet","summary":"Since Felix Bloch's introduction of the concept of spin waves in 1930,\nmagnons (the quanta of spin waves) have been extensively studied in a range of\nmaterials for spintronics, particularly for non-volatile logic-in-memory\ndevices. Controlling magnons in conventional antiferromagnets and harnessing\nthem in practical applications, however, remains a challenge. In this letter,\nwe demonstrate highly efficient magnon transport in an\nLaFeO$_3$/BiFeO$_3$/LaFeO$_3$ all-antiferromagnetic system which can be\ncontrolled electrically, making it highly desirable for energy-efficient\ncomputation. Leveraging spin-orbit-driven spin-charge transduction, we\ndemonstrate that this material architecture permits magnon confinement in\nultrathin antiferromagnets, enhancing the output voltage generated by magnon\ntransport by several orders of magnitude, which provides a pathway to enable\nmagnetoelectric memory and logic functionalities. Additionally, its\nnon-volatility enables ultralow-power logic-in-memory processing, where\nmagnonic devices can be efficiently reconfigured via electrically controlled\nmagnon spin currents within magnetoelectric channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T04:52:59Z"}
{"aid":"http://arxiv.org/abs/2503.23727v1","title":"Angle-dependent in-situ fast flavor transformations in post-neutron star\n  merger disks","summary":"The remnant black hole-accretion disk system resulting from binary neutron\nstar mergers has proven to be a promising site for synthesizing the heaviest\nelements via rapid neutron capture (r-process). A critical factor in\ndetermining the full r-process pattern in these environments is the neutron\nrichness of the ejecta, which is strongly influenced by neutrino interactions.\nOne key ingredient shaping these interactions is fast neutrino flavor\nconversions (FFCs), which arise due to angular crossings in neutrino\ndistributions and occur on nanosecond timescales. We present the first\nthree-dimensional, in-situ, angle-dependent modeling of FFCs in post-merger\ndisks, implemented within general relativistic magnetohydrodynamics with Monte\nCarlo neutrino transport. Our results reveal that, by suppressing electron\nneutrinos, FFCs more efficiently cool the disk and weaken the early thermally\ndriven wind. Less re-leptonization due to electron neutrino absorption makes\nthis cooler wind more neutron-rich, producing a more robust r-process at higher\nlatitudes of the outflow. This study underscores the necessity of incorporating\nFFCs in realistic simulations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T05:01:52Z"}
{"aid":"http://arxiv.org/abs/2503.23733v1","title":"AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models\n  with Unsupervised Coefficient Optimization","summary":"Recently, model merging methods have demonstrated powerful strengths in\ncombining abilities on various tasks from multiple Large Language Models\n(LLMs). While previous model merging methods mainly focus on merging\nhomogeneous models with identical architecture, they meet challenges when\ndealing with Multimodal Large Language Models (MLLMs) with inherent\nheterogeneous property, including differences in model architecture and the\nasymmetry in the parameter space. In this work, we propose AdaMMS, a novel\nmodel merging method tailored for heterogeneous MLLMs. Our method tackles the\nchallenges in three steps: mapping, merging and searching. Specifically, we\nfirst design mapping function between models to apply model merging on MLLMs\nwith different architecture. Then we apply linear interpolation on model\nweights to actively adapt the asymmetry in the heterogeneous MLLMs. Finally in\nthe hyper-parameter searching step, we propose an unsupervised hyper-parameter\nselection method for model merging. As the first model merging method capable\nof merging heterogeneous MLLMs without labeled data, extensive experiments on\nvarious model combinations demonstrated that AdaMMS outperforms previous model\nmerging methods on various vision-language benchmarks.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-03-31T05:13:02Z"}
{"aid":"http://arxiv.org/abs/2503.23736v1","title":"Every Painting Awakened: A Training-free Framework for\n  Painting-to-Animation Generation","summary":"We introduce a training-free framework specifically designed to bring\nreal-world static paintings to life through image-to-video (I2V) synthesis,\naddressing the persistent challenge of aligning these motions with textual\nguidance while preserving fidelity to the original artworks. Existing I2V\nmethods, primarily trained on natural video datasets, often struggle to\ngenerate dynamic outputs from static paintings. It remains challenging to\ngenerate motion while maintaining visual consistency with real-world paintings.\nThis results in two distinct failure modes: either static outputs due to\nlimited text-based motion interpretation or distorted dynamics caused by\ninadequate alignment with real-world artistic styles. We leverage the advanced\ntext-image alignment capabilities of pre-trained image models to guide the\nanimation process. Our approach introduces synthetic proxy images through two\nkey innovations: (1) Dual-path score distillation: We employ a dual-path\narchitecture to distill motion priors from both real and synthetic data,\npreserving static details from the original painting while learning dynamic\ncharacteristics from synthetic frames. (2) Hybrid latent fusion: We integrate\nhybrid features extracted from real paintings and synthetic proxy images via\nspherical linear interpolation in the latent space, ensuring smooth transitions\nand enhancing temporal consistency. Experimental evaluations confirm that our\napproach significantly improves semantic alignment with text prompts while\nfaithfully preserving the unique characteristics and integrity of the original\npaintings. Crucially, by achieving enhanced dynamic effects without requiring\nany model training or learnable parameters, our framework enables plug-and-play\nintegration with existing I2V methods, making it an ideal solution for\nanimating real-world paintings. More animated examples can be found on our\nproject website.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-03-31T05:25:49Z"}
{"aid":"http://arxiv.org/abs/2503.23748v1","title":"THEMIS: Towards Practical Intellectual Property Protection for\n  Post-Deployment On-Device Deep Learning Models","summary":"On-device deep learning (DL) has rapidly gained adoption in mobile apps,\noffering the benefits of offline model inference and user privacy preservation\nover cloud-based approaches. However, it inevitably stores models on user\ndevices, introducing new vulnerabilities, particularly model-stealing attacks\nand intellectual property infringement. While system-level protections like\nTrusted Execution Environments (TEEs) provide a robust solution, practical\nchallenges remain in achieving scalable on-device DL model protection,\nincluding complexities in supporting third-party models and limited adoption in\ncurrent mobile solutions. Advancements in TEE-enabled hardware, such as\nNVIDIA's GPU-based TEEs, may address these obstacles in the future. Currently,\nwatermarking serves as a common defense against model theft but also faces\nchallenges here as many mobile app developers lack corresponding machine\nlearning expertise and the inherent read-only and inference-only nature of\non-device DL models prevents third parties like app stores from implementing\nexisting watermarking techniques in post-deployment models.\n  To protect the intellectual property of on-device DL models, in this paper,\nwe propose THEMIS, an automatic tool that lifts the read-only restriction of\non-device DL models by reconstructing their writable counterparts and leverages\nthe untrainable nature of on-device DL models to solve watermark parameters and\nprotect the model owner's intellectual property. Extensive experimental results\nacross various datasets and model structures show the superiority of THEMIS in\nterms of different metrics. Further, an empirical investigation of 403\nreal-world DL mobile apps from Google Play is performed with a success rate of\n81.14%, showing the practicality of THEMIS.","main_category":"cs.CR","categories":"cs.CR,cs.LG,cs.SE","published":"2025-03-31T05:58:57Z"}
{"aid":"http://arxiv.org/abs/2503.23749v1","title":"Lower semicontinuity of bounded property in the branching problem and\n  sphericity of flag variety","summary":"Vinberg--Kimel'fel'd [Funct. Anal. Appl., 1978] established that a\nquasi-projective normal $G$-variety $X$ is spherical if and only if $G$-modules\non the spaces $\\Gamma(X, \\mathcal{L})$ of global sections of $G$-equivariant\nline bundles are multiplicity-free. This result was generalized by\nKobayashi--Oshima [Adv. Math., 2013] and several researchers to (degenerate)\nprincipal series representations of reductive Lie groups. The purpose of this\nshort article is to show that the boundedness of the multiplicities in the\nrestrictions of cohomologically induced modules implies the sphericity of some\npartial flag variety.\n  In our previous paper, we reduce the boundedness of the multiplicities to the\nfiniteness of a ring-theoretic invariant $\\mathrm{PIdeg}$. To show the main\nresult, we discuss the lower semicontinuity of $\\mathrm{PIdeg}$ on the space\n$\\mathrm{Prim}(\\mathcal{U}(\\mathfrak{g}))$ of primitive ideals. We also treat\nthe finiteness of the lengths of the restrictions of cohomologically induced\nmodules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-31T06:01:51Z"}
{"aid":"http://arxiv.org/abs/2503.23755v1","title":"Large-scale quantum-dot-lithium-niobate hybrid integrated photonic\n  circuits enabling on-chip quantum networking","summary":"Hybrid integrated quantum photonics combines solid-state artificial atoms\nwith reconfigurable photonic circuits, enabling scalable chip-based quantum\nnetworks. Self-assembled quantum dots (QDs) are ideal for this goal due to\ntheir ability to generate highly indistinguishable single photons with\nexceptional brightness. Integrating QDs into low-loss photonic circuits can\nfacilitate complex quantum networks by enabling entanglement transfer via\ntwo-photon interference. However, challenges such as limited scalability,\nspectral inhomogeneity, and quantum interference between independent sources\nremain. We present a hybrid photonic architecture that integrates QD-containing\nwaveguides with low-loss lithium niobate (LN) circuits, incorporating 20\ndeterministic single-photon sources (SPSs). Using the piezoelectric properties\nof thin-film lithium niobate (TFLN), we achieve on-chip local spectral tuning\nof QD emissions by up to 7.7 meV,three orders of magnitude greater than the\ntransform-limited linewidth. This approach enables on-chip quantum interference\nwith a visibility of 0.73 between two spatially separated QD SPSs connected by\n0.48 mm long waveguides, establishing a functional quantum network.The\nlarge-scale integration of spectrally tunable QD-based SPSs into low-loss LN\ncircuits, combined with fast electro-optical switching, paves the way for\ncompact, lightweight, and scalable photonic quantum networks.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T06:10:44Z"}
{"aid":"http://arxiv.org/abs/2503.23760v1","title":"Towards a cognitive architecture to enable natural language interaction\n  in co-constructive task learning","summary":"This research addresses the question, which characteristics a cognitive\narchitecture must have to leverage the benefits of natural language in\nCo-Constructive Task Learning (CCTL). To provide context, we first discuss\nInteractive Task Learning (ITL), the mechanisms of the human memory system, and\nthe significance of natural language and multi-modality. Next, we examine the\ncurrent state of cognitive architectures, analyzing their capabilities to\ninform a concept of CCTL grounded in multiple sources. We then integrate\ninsights from various research domains to develop a unified framework. Finally,\nwe conclude by identifying the remaining challenges and requirements necessary\nto achieve CCTL in Human-Robot Interaction (HRI).","main_category":"cs.RO","categories":"cs.RO,cs.CL,cs.HC","published":"2025-03-31T06:23:14Z"}
{"aid":"http://arxiv.org/abs/2503.23765v1","title":"STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World\n  Understanding?","summary":"The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution\nfor Embodied AI and Autonomous Driving has become a prevailing trend. While\nMLLMs have been extensively studied for visual semantic understanding tasks,\ntheir ability to perform precise and quantitative spatial-temporal\nunderstanding in real-world applications remains largely unexamined, leading to\nuncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we\nintroduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal\nunderstanding through challenging tasks such as estimating and predicting the\nappearance, pose, displacement, and motion of objects. Our benchmark\nencompasses a wide range of robot and vehicle operations across desktop,\nindoor, and outdoor scenarios. The extensive experiments reveals that the\nstate-of-the-art MLLMs still struggle in real-world spatial-temporal\nunderstanding, especially in tasks requiring precise distance estimation and\nmotion analysis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T06:30:35Z"}
{"aid":"http://arxiv.org/abs/2503.23781v1","title":"DebFlow: Automating Agent Creation via Agent Debate","summary":"Large language models (LLMs) have demonstrated strong potential and\nimpressive performance in automating the generation and optimization of\nworkflows. However, existing approaches are marked by limited reasoning\ncapabilities, high computational demands, and significant resource\nrequirements. To address these issues, we propose DebFlow, a framework that\nemploys a debate mechanism to optimize workflows and integrates reflexion to\nimprove based on previous experiences. We evaluated our method across six\nbenchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approach\nachieved a 3\\% average performance improvement over the latest baselines,\ndemonstrating its effectiveness in diverse problem domains. In particular,\nduring training, our framework reduces resource consumption by 37\\% compared to\nthe state-of-the-art baselines. Additionally, we performed ablation studies.\nRemoving the Debate component resulted in a 4\\% performance drop across two\nbenchmark datasets, significantly greater than the 2\\% drop observed when the\nReflection component was removed. These findings strongly demonstrate the\ncritical role of Debate in enhancing framework performance, while also\nhighlighting the auxiliary contribution of reflexion to overall optimization.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T06:56:13Z"}
{"aid":"http://arxiv.org/abs/2503.23784v1","title":"Sample-based subsampling strategies to identify microplastics in the\n  presence of a high number of particles using quantum-cascade laser-based\n  infrared imaging","summary":"Microplastics (MPs) are ubiquitous in all ecosystems, affecting wildlife and,\nultimately, human health. The complexity of natural samples plus the\nunspecificity of their treatments to isolate polymers renders the\ncharacterization of thousands of particles impractical for environmental\nmonitoring using conventional spectroscopic techniques. Two primary solutions\nare to analyze a small fraction of the sample or to measure only a subset of\nparticles present over a holder, known as subsampling. A strategy to subsample\nreflective Kevley slides and gold-coated filters using quantum-cascade\nlaser-based infrared imaging is proposed here, as this technology is a\npromising tool for MPs monitoring. In contrast to most previous approaches that\nstruggle to propose general subsampling schemes, we introduce the concept of\nsample-based subsampling. This can be applied ex-ante always and it highlights\nthe best subsampling areas for a sample after a preliminary assay to count the\ntotal number of particles on a holder. The error at this stage acts as a proxy\nto minimize errors when evaluating the number of particles and MPs,\nsignificantly enhancing the feasibility of large-scale MPs monitoring. The\npredictive ability of the approach was tested for fibres and fragments, for\ntotal amounts of particles and MPs. Further, the evaluations were disaggregated\nby size and polymer type. In most situations the reference values were\ncontained in the confidence intervals of the predicted values (often within the\n68 % ones) and relative errors were lower than 25 %. Exceptions occurred when\nvery scarce (one or two) items of a given size or polymer were present on the\noverall holder. The approach was compared to other systematic ad-hoc\nstrategies.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-03-31T07:02:04Z"}
{"aid":"http://arxiv.org/abs/2503.23795v1","title":"Trajectory Planning for Automated Driving using Target Funnels","summary":"Self-driving vehicles rely on sensory input to monitor their surroundings and\ncontinuously adapt to the most likely future road course. Predictive trajectory\nplanning is based on snapshots of the (uncertain) road course as a key input.\nUnder noisy perception data, estimates of the road course can vary\nsignificantly, leading to indecisive and erratic steering behavior. To overcome\nthis issue, this paper introduces a predictive trajectory planning algorithm\nwith a novel objective function: instead of targeting a single reference\ntrajectory based on the most likely road course, tracking a series of target\nreference sets, called a target funnel, is considered. The proposed planning\nalgorithm integrates probabilistic information about the road course, and thus\nimplicitly considers regular updates to road perception. Our solution is\nassessed in a case study using real driving data collected from a prototype\nvehicle. The results demonstrate that the algorithm maintains tracking accuracy\nand substantially reduces undesirable steering commands in the presence of\nnoisy road perception, achieving a 56% reduction in input costs compared to a\ncertainty equivalent formulation.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-03-31T07:15:55Z"}
{"aid":"http://arxiv.org/abs/2503.23800v1","title":"Light-Driven Skyrmion Crystal Generation in Plasmonic Metasurfaces\n  Through the Inverse Faraday Effect","summary":"Skyrmions are topological structures defined by a winding vector\nconfiguration that yields a quantized topological charge. In magnetic\nmaterials, skyrmions manifest as stable, mobile spin textures, positioning them\nat the forefront of spintronics research. Meanwhile, their optical counterparts\nunlock new possibilities for manipulating and directing light at the nanoscale.\nExploring the territories where magnetism and optics meet therefore holds\nimmense promise for ultrafast control over magnetic processes. Here, we report\nthe generation of a skyrmion-topological lattice through the inverse Faraday\neffect in a plasmonic metasurface. Specifically, a hexagonal array of gold\nnanodisks induces unidirectional drift photocurrents in each nanodisk, while\ncounterpropagating phantom currents arise in the hexagonal interstices. This\ninterplay creates a lattice of skyrmionic magnetic textures. Crucially, the all\noptical, large scale formation of skyrmions potentially at ultrafast timescales\noffers a pathway for integrating these topological spin textures into magnetic\nmaterials, laying the groundwork for next-generation data storage and\nprocessing technologies.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci","published":"2025-03-31T07:24:02Z"}
{"aid":"http://arxiv.org/abs/2503.23819v1","title":"Conformal uncertainty quantification to evaluate predictive fairness of\n  foundation AI model for skin lesion classes across patient demographics","summary":"Deep learning based diagnostic AI systems based on medical images are\nstarting to provide similar performance as human experts. However these data\nhungry complex systems are inherently black boxes and therefore slow to be\nadopted for high risk applications like healthcare. This problem of lack of\ntransparency is exacerbated in the case of recent large foundation models,\nwhich are trained in a self supervised manner on millions of data points to\nprovide robust generalisation across a range of downstream tasks, but the\nembeddings generated from them happen through a process that is not\ninterpretable, and hence not easily trustable for clinical applications. To\naddress this timely issue, we deploy conformal analysis to quantify the\npredictive uncertainty of a vision transformer (ViT) based foundation model\nacross patient demographics with respect to sex, age and ethnicity for the\ntasks of skin lesion classification using several public benchmark datasets.\nThe significant advantage of this method is that conformal analysis is method\nindependent and it not only provides a coverage guarantee at population level\nbut also provides an uncertainty score for each individual. We used a\nmodel-agnostic dynamic F1-score-based sampling during model training, which\nhelped to stabilize the class imbalance and we investigate the effects on\nuncertainty quantification (UQ) with or without this bias mitigation step. Thus\nwe show how this can be used as a fairness metric to evaluate the robustness of\nthe feature embeddings of the foundation model (Google DermFoundation) and thus\nadvance the trustworthiness and fairness of clinical AI.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-03-31T08:06:00Z"}
{"aid":"http://arxiv.org/abs/2503.23820v1","title":"When Counterfactual Reasoning Fails: Chaos and Real-World Complexity","summary":"Counterfactual reasoning, a cornerstone of human cognition and\ndecision-making, is often seen as the 'holy grail' of causal learning, with\napplications ranging from interpreting machine learning models to promoting\nalgorithmic fairness. While counterfactual reasoning has been extensively\nstudied in contexts where the underlying causal model is well-defined,\nreal-world causal modeling is often hindered by model and parameter\nuncertainty, observational noise, and chaotic behavior. The reliability of\ncounterfactual analysis in such settings remains largely unexplored. In this\nwork, we investigate the limitations of counterfactual reasoning within the\nframework of Structural Causal Models. Specifically, we empirically investigate\n\\emph{counterfactual sequence estimation} and highlight cases where it becomes\nincreasingly unreliable. We find that realistic assumptions, such as low\ndegrees of model uncertainty or chaotic dynamics, can result in\ncounterintuitive outcomes, including dramatic deviations between predicted and\ntrue counterfactual trajectories. This work urges caution when applying\ncounterfactual reasoning in settings characterized by chaos and uncertainty.\nFurthermore, it raises the question of whether certain systems may pose\nfundamental limitations on the ability to answer counterfactual questions about\ntheir behavior.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T08:14:51Z"}
{"aid":"http://arxiv.org/abs/2503.23836v1","title":"Gradient catastrophe and Peregrine soliton in nonlinear flexible\n  mechanical metamaterials","summary":"We explore the generation of extreme wave events in mechanical metamaterials\nusing the regularization of the gradient catastrophe theory developed by A.\nTovbis and M. Bertola for the nonlinear Schr\\\"odinger equation. According to\nthis theory, Peregrine solitons can locally emerge in the semiclassical limit\nof the nonlinear Schr\\\"odinger equation. Our objective is to determine whether\nthe phenomenon of gradient catastrophe can occur in a class of architected\nstructures designated as flexible mechanical metamaterials, both with and\nwithout losses. We demonstrate theoretically and numerically that this\nphenomenon can occur in a canonical example of such flexible mechanical\nmetamaterial, a chain of rotating units, studied earlier for its ability to\nsupport robust nonlinear waves such as elastic vector solitons. We find that in\nthe presence of weak losses, the gradient catastrophe persists although the\namplitude of extreme generated events is smaller and their onset is delayed\ncompared to the lossless configuration.","main_category":"nlin.PS","categories":"nlin.PS,physics.class-ph","published":"2025-03-31T08:31:15Z"}
{"aid":"http://arxiv.org/abs/2503.23841v1","title":"A search for the three isomers of cyano-1,3-butadiene in TMC-1:\n  Implications for bottom-up routes involving 1,3-butadiene","summary":"The molecule 1,3-butadiene (CH2CHCHCH2) could play a key role in the\nsynthesis of the cyclic molecules cyclopentadiene and benzene in cold dense\nclouds. Since 1,3-butadiene is non-polar, we searched for its cyano derivative,\nwhich exists in the form of three different polar isomers, in the cold dense\ncloud TMC-1. We used the most recent data obtained with the Yebes 40m telescope\nin the Q band (31.0-50.3 GHz) in the frame of the QUIJOTE project. We do not\ndetect any of the two isomers of 1-cyano-1,3-butadiene, and derive 3sigma upper\nlimits to their column densities of 1.2e10 cm-2 and 2.0e10 cm-2 for E- and\nZ-1-cyano-1,3-butadiene, respectively. Our results are not consistent with\nthose from Cooke et al. (2023), who determine a column density of 3.8e10 cm-2\nfor E-1-cyano-1,3-butadiene in TMC-1 using GBT data and a line stack technique.\nAt the current level of sensitivity of our data, there is tentative evidence\nfor the presence of the third cyano derivative isomer, 2-cyano-1,3-butadiene,\nalthough a firm detection must await more sensitive data. We derive an upper\nlimit to its column density of 3.1e10 cm-2. This isomer cannot be formed in the\nreaction between CN and 1,3-butadiene, according to experimental and\ntheoretical studies, and thus we speculate whether it could arise from\nneutral-neutral reactions like C2H3 + CH2CHCN and CH2CCN + C2H4. From the upper\nlimit on the abundance of 1-cyano-1,3-butadiene derived here, we estimate that\nthe abundance of 1,3-butadiene in TMC-1 is below 1e-11 - 1e-10 relative to H2.\nThe low abundance inferred for 1,3-butadiene makes it unlikely that it plays an\nimportant role in bottom-up routes to cyclopentadiene and benzene.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T08:39:13Z"}
{"aid":"http://arxiv.org/abs/2503.23849v1","title":"Narrow-Line Seyfert 1 Galaxies Beyond the Local X-ray Universe: An X-ray\n  spectral sample","summary":"Narrow-line Seyfert 1 AGNs (NLS1s) represent a unique stage in the black hole\ngrowth history, characterised by low black hole masses of approximately\n$10^{6}$-$10^{8}$ solar masses and around-Eddington accretion rates. X-ray\nstudies of NLS1s have largely been confined to the local Universe ($z < 0.2$),\nwhile their broad-line counterparts and radio-loud quasars have been more\nextensively investigated at higher redshifts. In this work, we conducted an\nX-ray spectral analysis for 14 SDSS-observed NLS1s at $z\\approx1$ in the eRASS1\ncatalogue. We found that all of their eROSITA observations agree with the\nexpected rest-frame 2 keV monochromatic luminosity given their rest-frame 2500\nangstrom monochromatic luminosity, further supporting evidence of AGN emission.\nSecond, when fitted with a power-law model, most continuum spectra between\n0.7-7 keV in their rest frames necessitate photon indices $\\Gamma\\gtrsim2.5$.\nNotably, the highest photon index of around 4.7 in one of our NLS1 AGNs hints\nat a significant contribution from soft excess emission. Finally, our analysis\ndemonstrates that we can align the Eddington ratios with optical measurements\nby applying a correction factor between 10-120 to their X-ray luminosity.\nAlthough measurement uncertainty remains considerable, our findings suggest\nthat assumptions for the standard geometrically thin accretion disc model made\nin previous estimations of this correction factor may not apply to near or\nsuper-Eddington NLS1 AGNs. Finally, we also compare this sample with extremely\nvariable nearby NLS1s and other X-ray-weak AGNs, such as JWST-observed,\nbroad-line AGNs at $z=5-6$, and underscores the importance of deeper X-ray\nsurveys for more X-ray-weak NLS1s.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T08:55:07Z"}
{"aid":"http://arxiv.org/abs/2503.23850v1","title":"Event-activity dependence of heavy-flavor production at the ALICE\n  experiment","summary":"Heavy-flavor production at the LHC offers valuable tests of\nquantum-chromodynamics calculations, owing to the large masses of heavy quarks.\nMeasurements of charm production as a function of event activity reveal new\nfeatures of charm production and fragmentation, providing insights to the\ninterplay between soft and hard processes. In addition, charm production in\nheavy-ion collisions addresses flavor-dependent quark transport properties in\nboth hot and cold nuclear matter, helping to clarify the roles of coalescence\nand fragmentation in heavy-flavor hadron formation. This contribution\nsummarizes recent measurements from the ALICE experiment on charm production as\na function of charged-particle multiplicity in pp collisions at various\nenergies, including the measurements of charm baryon-to-meson production yield\nratios in pp, p--Pb and Pb--Pb collisions. New results on ${\\rm D}^0$\nproduction in pp collisions as a function of the transverse spherocity of the\nevent, as well as of the transverse event-activity classifier $R_{\\rm T}$, are\nalso presented.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T08:55:52Z"}
{"aid":"http://arxiv.org/abs/2503.23860v1","title":"The Kossakowski Matrix and Strict Positivity of Markovian Quantum\n  Dynamics","summary":"We investigate the relationship between strict positivity of the Kossakowski\nmatrix, irreducibility and positivity improvement properties of Markovian\nQuantum Dynamics. We show that for a Gaussian quantum dynamical semigroup\nstrict positivity of the Kossakowski matrix implies irreducibility and, with an\nadditional technical assumption, that the support of any initial state is the\nwhole space for any positive time.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T09:07:26Z"}
{"aid":"http://arxiv.org/abs/2503.23861v1","title":"$s_{\\pm}$ pairing via interlayer interaction in\n  La$_{2.85}$Pr$_{0.15}$Ni$_2$O$_7$ Thin Films under Ambient Pressure","summary":"We demonstrate that interlayer \\(s_{\\pm}\\)-wave pairing dominates\nsuperconductivity in La\\(_{2.85}\\)Pr\\(_{0.15}\\)Ni\\(_2\\)O\\(_7\\) thin films\nthrough self-consistent mean-field calculations. We further show that applying\na perpendicular electric field breaks layer equivalence, generating nodal\nstructures, Fermi arcs, and finite low-energy states in the \\(d_{x^2-y^2}\\)\norbital. Our results quantitatively align with recent experimental observations\nfor the superconducting gaps, and we propose experimental symmetry-breaking\nperturbations as a direct test for the interlayer pairing mechanism.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T09:08:26Z"}
{"aid":"http://arxiv.org/abs/2503.23863v1","title":"GRACEFUL: A Learned Cost Estimator For UDFs","summary":"User-Defined-Functions (UDFs) are a pivotal feature in modern DBMS, enabling\nthe extension of native DBMS functionality with custom logic. However, the\nintegration of UDFs into query optimization processes poses significant\nchallenges, primarily due to the difficulty of estimating UDF execution costs.\nConsequently, existing cost models in DBMS optimizers largely ignore UDFs or\nrely on static assumptions, resulting in suboptimal performance for queries\ninvolving UDFs. In this paper, we introduce GRACEFUL, a novel learned cost\nmodel to make accurate cost predictions of query plans with UDFs enabling\noptimization decisions for UDFs in DBMS. For example, as we show in our\nevaluation, using our cost model, we can achieve 50x speedups through informed\npull-up/push-down filter decisions of the UDF compared to the standard case\nwhere always a filter push-down is applied. Additionally, we release a\nsynthetic dataset of over 90,000 UDF queries to promote further research in\nthis area.","main_category":"cs.DB","categories":"cs.DB","published":"2025-03-31T09:09:12Z"}
{"aid":"http://arxiv.org/abs/2503.23869v1","title":"Communication-Efficient and Personalized Federated Foundation Model\n  Fine-Tuning via Tri-Matrix Adaptation","summary":"In federated learning, fine-tuning pre-trained foundation models poses\nsignificant challenges, particularly regarding high communication cost and\nsuboptimal model performance due to data heterogeneity between the clients. To\naddress these issues, this paper introduces communication-efficient federated\nLoRA adaption (CE-LoRA), a method that employs a tri-factorization low-rank\nadaptation approach with personalized model parameter aggregation. We first\npresents a novel LoRA parameter factorization by introducing a small-size dense\nmatrix, which can significantly reduce the communication cost and achieve\ncomparable empirical performance than transferring the low-rank parameter\nmatrix used by existing methods. Without violating data privacy, the server\nconsiders the client similarity in both training dataset and model parameter\nspace, and learns personalized weights for model aggregation. Our experiments\non various LLM and VLM fine-tuning tasks demonstrate that CE-LoRA not only\nsignificantly reduces communication overhead but also improves performance\nunder not independently and identically distributed data conditions. In\naddition, CE-LoRA improves data privacy protection, effectively mitigating\ngradient-based data reconstruction attacks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T09:18:42Z"}
{"aid":"http://arxiv.org/abs/2503.23871v1","title":"The holonomy Lie $\\infty$-groupoid of a singular foliation I","summary":"We construct a finite-dimensional higher Lie groupoid integrating a singular\nfoliation $\\mathcal F$, under the mild assumption that the latter admits a\ngeometric resolution. More precisely, a recursive use of bi-submersions, a tool\ncoming from non-commutative geometry and invented by Androulidakis and\nSkandalis, allows us to integrate any universal Lie $\\infty$-algebroid of a\nsingular foliation to a Kan simplicial manifold, where all components are made\nof non-connected manifolds which are all the same finite dimension that can be\nchosen to be equal to the ranks of a given geometric resolution. Its\n1-truncation is the Androulidakis-Skandalis holonomy groupoid.","main_category":"math.CT","categories":"math.CT,math.DG","published":"2025-03-31T09:20:32Z"}
{"aid":"http://arxiv.org/abs/2503.23872v1","title":"European Strategy for Particle Physics 2026: the NA60+/DiCE experiment\n  at the SPS","summary":"The exploration of the phase diagram of Quantum ChromoDynamics (QCD) is\ncarried out by studying ultrarelativistic heavy-ion collisions. The energy\nrange covered by the CERN SPS ($\\sqrt{s_{\\rm {NN}}} \\sim 6-17$ GeV) is ideal\nfor the investigation of the region corresponding to finite baryochemical\npotential ($\\mu_{\\rm B}$), and was little explored up to now. We propose in\nthis document a new experiment, NA60+/DiCE (Dilepton and Charm Experiment),\nthat will address several observables which are fundamental for the\nunderstanding of the phase transition from hadronic matter towards a\nQuark-Gluon Plasma (QGP) at finite $\\mu_B$. In particular, we propose to study,\nin Pb-Pb collisions, as a function of the collision energy, the production of\nthermal dimuons, from which one can obtain a caloric curve of the QCD phase\ndiagram that may be sensitive to the order of the phase transition. In\naddition, the measurement of a $\\rho-{\\rm a}_1$ mixing contribution will\nprovide conclusive insights into the restoration of the chiral symmetry of QCD.\nStudies of open charm and charmonium production will also be carried out,\naddressing the measurement of transport properties of the QGP and the\ninvestigation of the onset of the deconfinement transition. Reference\nmeasurements with proton-nucleus collisions are an essential part of this\nprogram. The experimental set-up couples a vertex telescope based on monolithic\nactive pixel sensors (MAPS) to a muon spectrometer with MWPC detectors. Two\nexisting CERN dipole magnets, MEP48 and MNP33, will be used for the vertex and\nmuon spectrometers, respectively. The continuing availability of Pb ion beams\nin the CERN SPS is a crucial requirement for the experimental program. After\nthe submission of a LoI, the experiment proposal is currently in preparation\nand is due by mid 2025. The start of the data taking is foreseen by 2029/2030,\nand should last about 7 years.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-03-31T09:23:01Z"}
{"aid":"http://arxiv.org/abs/2503.23887v1","title":"An End-to-End Comprehensive Gear Fault Diagnosis Method Based on\n  Multi-Scale Feature-Level Fusion Strategy","summary":"To satisfy the requirements of the end-to-end fault diagnosis of gears, an\nintegrated intelligent method of fault diagnosis for gears using acceleration\nsignals was proposed, which was based on Gabor-based Adaptive Short-Time\nFourier Transform (Gabor-ASTFT) and Dual-Tree Complex Wavelet Transform(DTCWT)\nalgorithms, Dilated Residual structure and feature fusion layer, is proposed in\nthis paper. Initially, the raw one-dimensional acceleration signals collected\nfrom the gearbox base using vibration sensors undergo pre-segmentation\nprocessing. The Gabor-ASTFT and DTCWT are then applied to convert the original\none-dimensional time-domain signals into two-dimensional time-frequency\nrepresentations, facilitating the preliminary extraction of fault features and\nobtaining weak feature maps.Subsequently, a dual-channel structure is\nestablished using deconvolution and dilated convolution to perform upsampling\nand downsampling on the feature maps, adjusting their sizes accordingly. A\nfeature fusion layer is then constructed to integrate the dual-channel\nfeatures, enabling multi-scale analysis of the extracted fault\nfeatures.Finally, a convolutional neural network (CNN) model incorporating a\nresidual structure is developed to conduct deep feature extraction from the\nfused feature maps. The extracted features are subsequently fed into a Global\nAverage Pooling(GAP) and a classification function for fault classification.\nConducting comparative experiments on different datasets, the proposed method\nis demonstrated to effectively meet the requirements of end-to-end fault\ndiagnosis for gears.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T09:40:06Z"}
{"aid":"http://arxiv.org/abs/2503.23894v1","title":"Quasinormal modes of a dyonic black hole in Einstein-Euler-Heisenberg\n  theory","summary":"In this study, we investigate the quasinormal modes of a non-rotating dyonic\nblack hole within the framework of Einstein-Euler-Heisenberg theory. We present\na detailed analysis focuses on understanding the influence of dyonic charges on\nthe oscillatory properties of these BHs. The quasinormal modes are calculated\nto explore the interplay between the dyonic charge and the characteristic\nfrequencies of perturbations. The results are then systematically compared with\nthose of black holes possessing purely electric or purely magnetic charges in\nthe Einstein-Euler-Heisenberg framework. This comparison highlights the unique\nsignatures and dynamic behavior introduced by the presence of dyonic charges,\noffering deeper insights into the properties of black holes in nonlinear\nelectrodynamics theories.","main_category":"gr-qc","categories":"gr-qc","published":"2025-03-31T09:44:48Z"}
{"aid":"http://arxiv.org/abs/2503.23920v1","title":"Semileptonic baryon decays $Î_b\\rightarrow Î_c \\ell^- \\barÎ½_\\ell\n  $ in perturbative QCD","summary":"We perform a detailed analysis of the semileptonic $\\Xi_b\\rightarrow \\Xi_c\n\\ell^- \\bar{\\nu}_\\ell$ decays within the perturbative QCD (PQCD) framework. In\nour study, the $\\Xi_b\\rightarrow \\Xi_c$ transition form factors are calculated\nusing several popular models for baryonic light-cone distribution amplitudes\n(LCDAs). These form factors are then employed to analyze a range of observable\nquantities for the semileptonic processes via the helicity formalism. Our work\npresents predictions for the branching fractions of these decays for both the\n$\\tau$ and $e$ channels. Notably, the obtained lepton flavor universality\nratio, $\\mathcal{R}_{\\Xi_c}\\approx 0.3$, may offer new insights into the\n$\\mathcal{R}^{(*)}$ puzzle. Furthermore, we investigate various angular\nobservables, such as forward-backward asymmetries, lepton-side convexity\nparameters, and polarization asymmetries, which provide complementary\ninformation regarding potential new physics in $b$-baryonic semileptonic\ntransitions. The numerical results for these angular observables are presented\nas both functions of $q^2$ and as averaged values. We observe that the lepton\nmass plays a significant role in shaping the angular distributions, affecting\nmost of the observables under consideration. These results are expected to be\nvaluable for both current and future experimental investigations of\nsemileptonic heavy-to-heavy baryon decays.","main_category":"hep-ph","categories":"hep-ph","published":"2025-03-31T10:10:31Z"}
{"aid":"http://arxiv.org/abs/2503.23930v1","title":"Exploring Reliable PPG Authentication on Smartwatches in Daily Scenarios","summary":"Photoplethysmography (PPG) Sensors, widely deployed in smartwatches, offer a\nsimple and non-invasive authentication approach for daily use. However, PPG\nauthentication faces reliability issues due to motion artifacts from physical\nactivity and physiological variability over time. To address these challenges,\nwe propose MTL-RAPID, an efficient and reliable PPG authentication model, that\nemploys a multitask joint training strategy, simultaneously assessing signal\nquality and verifying user identity. The joint optimization of these two tasks\nin MTL-RAPID results in a structure that outperforms models trained on\nindividual tasks separately, achieving stronger performance with fewer\nparameters. In our comprehensive user studies regarding motion artifacts (N =\n30), time variations (N = 32), and user preferences (N = 16), MTL-RAPID\nachieves a best AUC of 99.2\\% and an EER of 3.5\\%, outperforming existing\nbaselines. We opensource our PPG authentication dataset along with the\nMTL-RAPID model to facilitate future research on GitHub.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:25:48Z"}
{"aid":"http://arxiv.org/abs/2503.23932v1","title":"The wind properties of O-type stars at sub-SMC metallicity","summary":"Radiation-driven winds heavily influence the evolution and fate of massive\nstars. Feedback processes from these winds impact the properties of the\ninterstellar medium of their host galaxies. The dependence of mass loss on\nstellar properties is poorly understood, particularly at low metallicity ($Z$).\nWe aim to characterise stellar and wind properties of massive stars in Local\nGroup dwarf galaxies with $Z$ below that of the Small Magellanic Cloud and\nconfront our findings to theories of radiation-driven winds. We perform\nquantitative optical and UV spectroscopy on a sample of 11 O-type stars in\nnearby dwarf galaxies with $Z < 0.2\\,Z_\\odot$. The stellar atmosphere code\nFastwind and the genetic algorithm Kiwi-GA are used to determine stellar and\nwind parameters. Inhomogeneities in the wind are assumed to be optically thin.\nThe winds of the sample stars are weak, with mass loss rates $\\sim\n10^{-9}-10^{-7}\\,M_\\odot\\,{\\rm yr}^{-1}$. Such feeble winds can only be\nconstrained if UV spectra are available. The modified wind momentum as a\nfunction of luminosity ($L$) for stars in this $Z$ regime is in agreement with\nextrapolations to lower $Z$ of a recently established empirical relation for\nthis quantity as a function of both $L$ and $Z$. However, theoretical\nprescriptions do not match our results or those of other recent analyses at low\nluminosity ($L \\lesssim 10^{5.2}\\,L_{\\odot}$) and low $Z$; in this regime, they\npredict winds that are stronger by an order of magnitude or more. For our\nsample stars at $Z \\sim 0.14\\,Z_\\odot$, with masses $\\sim 30 - 50\\,M_{\\odot}$,\nstellar winds strip little mass during main-sequence evolution. However, if the\nsteep dependence of mass loss on luminosity found here also holds for more\nmassive stars at these metallicities, these may suffer as severely from\nmain-sequence mass stripping as very massive stars in the Large Magellanic\nCloud and Milky Way.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-03-31T10:27:14Z"}
{"aid":"http://arxiv.org/abs/2503.23944v1","title":"Left-hand cut problem in lattice QCD and an EFT-based solution","summary":"Lattice QCD has become an essential tool for studying the hadron-hadron\ninteraction from the first principles. However, when extracting infinite-volume\nscattering parameters from finite-volume energy levels, the traditional\nL\\\"uscher formula encounters limitations due to the left-hand cut induced by\nlong-range interactions such as the one-pion exchange. In this work, we propose\nan alternative approach based on chiral effective field theory combined with a\nHamiltonian method in the plane wave basis. By solving a Schr\\\"odinger-like\nequation in the finite volume, our method connects the finite-volume energy\nspectrum with infinite-volume observables, while systematically incorporating\nthe long-range physics and solving the left-hand cut problem. The use of the\nplane wave basis mitigates issues related to partial wave mixing. Our numerical\nresults for $DD^*$ scattering at $m_\\pi \\approx$ 280 MeV demonstrate that this\napproach overcomes the limitations of the L\\\"uscher method and points towards a\nresonance interpretation of the $T_{cc}(3875)$ state, as opposed to the virtual\nstate predicted by traditional analyses.","main_category":"hep-lat","categories":"hep-lat","published":"2025-03-31T10:49:56Z"}
{"aid":"http://arxiv.org/abs/2503.23949v1","title":"AMB-FHE: Adaptive Multi-biometric Fusion with Fully Homomorphic\n  Encryption","summary":"Biometric systems strive to balance security and usability. The use of\nmulti-biometric systems combining multiple biometric modalities is usually\nrecommended for high-security applications. However, the presentation of\nmultiple biometric modalities can impair the user-friendliness of the overall\nsystem and might not be necessary in all cases. In this work, we present a\nsimple but flexible approach to increase the privacy protection of\nhomomorphically encrypted multi-biometric reference templates while enabling\nadaptation to security requirements at run-time: An adaptive multi-biometric\nfusion with fully homomorphic encryption (AMB-FHE). AMB-FHE is benchmarked\nagainst a bimodal biometric database consisting of the CASIA iris and MCYT\nfingerprint datasets using deep neural networks for feature extraction. Our\ncontribution is easy to implement and increases the flexibility of biometric\nauthentication while offering increased privacy protection through joint\nencryption of templates from multiple modalities.","main_category":"cs.CR","categories":"cs.CR,cs.CV","published":"2025-03-31T11:00:08Z"}
{"aid":"http://arxiv.org/abs/2503.23954v1","title":"Exclusion of a diquark-antidiquark structure for the lightest\n  positive-parity charmed mesons","summary":"The nature of low-lying scalar and axial-vector charmed mesons has been\ndebated for decades, with hadronic molecular and compact tetraquark models\nbeing prominent candidates. These two models predict quite different features\nfor the accessible SU(3) multiplets in the scalar and axial-vector sectors,\nwhich can be tested through lattice calculations at SU(3) symmetric points. In\nthis work, we perform lattice calculations for both scalar and axial-vector\ncharmed mesons with an SU(3) symmetric pion mass about 613 MeV for the SU(3)\n$[6]$ and $[\\overline{15}]$ multiplets. We find that the $[6]$ multiplet\nexhibits attractive interactions in both scalar and axial-vector sectors, while\nthe $[\\overline{15}]$ multiplet shows repulsive interactions in both sectors.\nThe energy shifts in the scalar and axial-vector sectors are compatible with\neach other within uncertainties. These results are fully consistent with the\nhadronic molecular picture, while challenging the compact tetraquark model,\nwhich predicts the existence of low-lying $[\\overline{15}]$ states in the\naxial-vector sector but not in the scalar sector.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-03-31T11:12:29Z"}
{"aid":"http://arxiv.org/abs/2503.23963v1","title":"A Benchmark for Vision-Centric HD Mapping by V2I Systems","summary":"Autonomous driving faces safety challenges due to a lack of global\nperspective and the semantic information of vectorized high-definition (HD)\nmaps. Information from roadside cameras can greatly expand the map perception\nrange through vehicle-to-infrastructure (V2I) communications. However, there is\nstill no dataset from the real world available for the study on map\nvectorization onboard under the scenario of vehicle-infrastructure cooperation.\nTo prosper the research on online HD mapping for Vehicle-Infrastructure\nCooperative Autonomous Driving (VICAD), we release a real-world dataset, which\ncontains collaborative camera frames from both vehicles and roadside\ninfrastructures, and provides human annotations of HD map elements. We also\npresent an end-to-end neural framework (i.e., V2I-HD) leveraging vision-centric\nV2I systems to construct vectorized maps. To reduce computation costs and\nfurther deploy V2I-HD on autonomous vehicles, we introduce a directionally\ndecoupled self-attention mechanism to V2I-HD. Extensive experiments show that\nV2I-HD has superior performance in real-time inference speed, as tested by our\nreal-world dataset. Abundant qualitative results also demonstrate stable and\nrobust map construction quality with low cost in complex and various driving\nscenes. As a benchmark, both source codes and the dataset have been released at\nOneDrive for the purpose of further study.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-03-31T11:24:53Z"}
{"aid":"http://arxiv.org/abs/2503.23968v1","title":"Total Cartier index of a bounded family","summary":"We prove that the total Cartier index of a bounded family of projective\nvarieties of klt type is bounded.","main_category":"math.AG","categories":"math.AG","published":"2025-03-31T11:33:38Z"}
{"aid":"http://arxiv.org/abs/2503.23981v1","title":"Federated Structured Sparse PCA for Anomaly Detection in IoT Networks","summary":"Although federated learning has gained prominence as a privacy-preserving\nframework tailored for distributed Internet of Things (IoT) environments,\ncurrent federated principal component analysis (PCA) methods lack integration\nof sparsity, a critical feature for robust anomaly detection. To address this\nlimitation, we propose a novel federated structured sparse PCA (FedSSP)\napproach for anomaly detection in IoT networks. The proposed model uniquely\nintegrates double sparsity regularization: (1) row-wise sparsity governed by\n$\\ell_{2,p}$-norm with $p\\in[0,1)$ to eliminate redundant feature dimensions,\nand (2) element-wise sparsity via $\\ell_{q}$-norm with $q\\in[0,1)$ to suppress\nnoise-sensitive components. To efficiently solve this non-convex optimization\nproblem in a distributed setting, we devise a proximal alternating minimization\n(PAM) algorithm with rigorous theoretical proofs establishing its convergence\nguarantees. Experiments on real datasets validate that incorporating structured\nsparsity enhances both model interpretability and detection accuracy.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-03-31T11:50:21Z"}
{"aid":"http://arxiv.org/abs/2503.23982v1","title":"Deep Nets as Hamiltonians","summary":"Neural networks are complex functions of both their inputs and parameters.\nMuch prior work in deep learning theory analyzes the distribution of network\noutputs at a fixed a set of inputs (e.g. a training dataset) over random\ninitializations of the network parameters. The purpose of this article is to\nconsider the opposite situation: we view a randomly initialized Multi-Layer\nPerceptron (MLP) as a Hamiltonian over its inputs. For typical realizations of\nthe network parameters, we study the properties of the energy landscape induced\nby this Hamiltonian, focusing on the structure of near-global minimum in the\nlimit of infinite width. Specifically, we use the replica trick to perform an\nexact analytic calculation giving the entropy (log volume of space) at a given\nenergy. We further derive saddle point equations that describe the overlaps\nbetween inputs sampled iid from the Gibbs distribution induced by the random\nMLP. For linear activations we solve these saddle point equations exactly. But\nwe also solve them numerically for a variety of depths and activation\nfunctions, including $\\tanh, \\sin, \\text{ReLU}$, and shaped non-linearities. We\nfind even at infinite width a rich range of behaviors. For some\nnon-linearities, such as $\\sin$, for instance, we find that the landscapes of\nrandom MLPs exhibit full replica symmetry breaking, while shallow $\\tanh$ and\nReLU networks or deep shaped MLPs are instead replica symmetric.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,cs.AI,cs.LG,math.PR","published":"2025-03-31T11:51:10Z"}
{"aid":"http://arxiv.org/abs/2503.23986v1","title":"A Practical Rollup Escape Hatch Design","summary":"A rollup network is a type of popular \"Layer 2\" scaling solution for general\npurpose \"Layer 1\" blockchains like Ethereum. Rollups networks separate\nexecution of transactions from other aspects like consensus, processing\ntransactions off of the Layer 1, and posting the data onto the underlying layer\nfor security. While rollups offer significant scalability advantages, they\noften rely on centralized operators for transaction ordering and inclusion,\nwhich also introduces potential risks. If the operator fails to build rollup\nblocks or propose new state roots to the underlying Layer 1, users may lose\naccess to digital assets on the rollup. An escape hatch allows users to bypass\nthe failing operator and withdraw assets directly on the Layer 1. We propose\nusing a time-based trigger, Merkle proofs, and new resolver contracts to\nimplement a practical escape hatch for these networks. The use of novel\nresolver contracts allow user owned assets to be located in the Layer 2 state\nroot, including those owned by smart contracts, in order to allow users to\nescape them. This design ensures safe and verifiable escape of assets,\nincluding ETH, ERC-20 and ERC-721 tokens, and more, from the Layer 2.","main_category":"cs.DC","categories":"cs.DC,cs.CR","published":"2025-03-31T11:55:10Z"}
{"aid":"http://arxiv.org/abs/2503.23989v1","title":"Rubric Is All You Need: Enhancing LLM-based Code Evaluation With\n  Question-Specific Rubrics","summary":"Since the disruption in LLM technology brought about by the release of GPT-3\nand ChatGPT, LLMs have shown remarkable promise in programming-related tasks.\nWhile code generation remains a popular field of research, code evaluation\nusing LLMs remains a problem with no conclusive solution. In this paper, we\nfocus on LLM-based code evaluation and attempt to fill in the existing gaps. We\npropose multi-agentic novel approaches using question-specific rubrics tailored\nto the problem statement, arguing that these perform better for logical\nassessment than the existing approaches that use question-agnostic rubrics. To\naddress the lack of suitable evaluation datasets, we introduce two datasets: a\nData Structures and Algorithms dataset containing 150 student submissions from\na popular Data Structures and Algorithms practice website, and an Object\nOriented Programming dataset comprising 80 student submissions from\nundergraduate computer science courses. In addition to using standard metrics\n(Spearman Correlation, Cohen's Kappa), we additionally propose a new metric\ncalled as Leniency, which quantifies evaluation strictness relative to expert\nassessment. Our comprehensive analysis demonstrates that question-specific\nrubrics significantly enhance logical assessment of code in educational\nsettings, providing better feedback aligned with instructional goals beyond\nmere syntactic correctness.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-03-31T11:59:43Z"}
{"aid":"http://arxiv.org/abs/2503.23990v1","title":"BeMERC: Behavior-Aware MLLM-based Framework for Multimodal Emotion\n  Recognition in Conversation","summary":"Multimodal emotion recognition in conversation (MERC), the task of\nidentifying the emotion label for each utterance in a conversation, is vital\nfor developing empathetic machines. Current MLLM-based MERC studies focus\nmainly on capturing the speaker's textual or vocal characteristics, but ignore\nthe significance of video-derived behavior information. Different from text and\naudio inputs, learning videos with rich facial expression, body language and\nposture, provides emotion trigger signals to the models for more accurate\nemotion predictions. In this paper, we propose a novel behavior-aware\nMLLM-based framework (BeMERC) to incorporate speaker's behaviors, including\nsubtle facial micro-expression, body language and posture, into a vanilla\nMLLM-based MERC model, thereby facilitating the modeling of emotional dynamics\nduring a conversation. Furthermore, BeMERC adopts a two-stage instruction\ntuning strategy to extend the model to the conversations scenario for\nend-to-end training of a MERC predictor. Experiments demonstrate that BeMERC\nachieves superior performance than the state-of-the-art methods on two\nbenchmark datasets, and also provides a detailed discussion on the significance\nof video-derived behavior information in MERC.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:04:53Z"}
{"aid":"http://arxiv.org/abs/2503.23993v1","title":"DenseFormer: Learning Dense Depth Map from Sparse Depth and Image via\n  Conditional Diffusion Model","summary":"The depth completion task is a critical problem in autonomous driving,\ninvolving the generation of dense depth maps from sparse depth maps and RGB\nimages. Most existing methods employ a spatial propagation network to\niteratively refine the depth map after obtaining an initial dense depth. In\nthis paper, we propose DenseFormer, a novel method that integrates the\ndiffusion model into the depth completion task. By incorporating the denoising\nmechanism of the diffusion model, DenseFormer generates the dense depth map by\nprogressively refining an initial random depth distribution through multiple\niterations. We propose a feature extraction module that leverages a feature\npyramid structure, along with multi-layer deformable attention, to effectively\nextract and integrate features from sparse depth maps and RGB images, which\nserve as the guiding condition for the diffusion process. Additionally, this\npaper presents a depth refinement module that applies multi-step iterative\nrefinement across various ranges to the dense depth results generated by the\ndiffusion process. The module utilizes image features enriched with multi-scale\ninformation and sparse depth input to further enhance the accuracy of the\npredicted depth map. Extensive experiments on the KITTI outdoor scene dataset\ndemonstrate that DenseFormer outperforms classical depth completion methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T12:11:01Z"}
{"aid":"http://arxiv.org/abs/2503.23995v1","title":"Analytic Conformal Blocks of $C_2$-cofinite Vertex Operator Algebras\n  III: The Sewing-Factorization Theorems","summary":"Let $\\mathbb V=\\bigoplus_{n\\in\\mathbb N}\\mathbb V(n)$ be a $C_2$-cofinite\nVOA, not necessarily rational or self-dual. In this paper, we establish various\nversions of the sewing-factorization (SF) theorems for conformal blocks\nassociated to grading-restricted generalized modules of $\\mathbb V^{\\otimes N}$\n(where $N\\in\\mathbb N$). In addition to the versions announced in the\nIntroduction of [GZ23], we prove the following coend version of the SF theorem:\n  Let $\\mathfrak F$ be a compact Riemann surface with $N$ incoming and $R$\noutgoing marked points, and let $\\mathfrak G$ be another compact Riemann\nsurface with $K$ incoming and $R$ outgoing marked points. Assign $\\mathbb\nW\\in\\mathrm{Mod}(\\mathbb V^{\\otimes N})$ and $\\mathbb X\\in\\mathrm{Mod}(\\mathbb\nV^{\\otimes K})$ to the incoming marked points of $\\mathfrak F$ and $\\mathfrak\nG$ respectively. For each $\\mathbb{M} \\in \\mathrm{Mod}(\\mathbb{V}^{\\otimes\nR})$, assign $\\mathbb{M}$ and its contragredient $\\mathbb M'$ to the outgoing\nmarked points of $\\mathfrak F$ and $\\mathfrak G$ respectively. Denote the\ncorresponding spaces of conformal blocks by $\\mathscr T_{\\mathfrak F}^*(\\mathbb\nM\\otimes\\mathbb W)$ and $\\mathscr T_{\\mathfrak{G}}^*(\\mathbb M'\\otimes\\mathbb\nX)$. Let the $\\mathfrak X$ be the $(N+K)$-pointed surface obtained by sewing\n$\\mathfrak F$, $\\mathfrak G$ along their outgoing marked points. Then the\nsewing of conformal blocks-proved to be convergent in [GZ24]-yields an\nisomorphism of vector spaces $$\\int^{\\mathbb{M}\\in\\mathrm{Mod}(\\mathbb\nV^{\\otimes R})}\\mathscr T_{\\mathfrak F}^*(\\mathbb\nM\\otimes\\mathbb{W})\\otimes_{\\mathbb C} \\mathscr T_{\\mathfrak G}^*(\\mathbb\nM'\\otimes \\mathbb X)\\simeq\\mathscr T_{\\mathfrak X}^*(\\mathbb W\\otimes \\mathbb\nX)$$\n  We also discuss the relation between conformal blocks and the modular\nfunctors defined using Lyubashenko's coend in the case where $\\mathbb V$ is\nstrongly finite and rigid.","main_category":"math.QA","categories":"math.QA,math-ph,math.MP,math.RT","published":"2025-03-31T12:13:27Z"}
{"aid":"http://arxiv.org/abs/2503.24001v1","title":"Convergence of a finite volume scheme for a model for ants","summary":"We develop and analyse a finite volume scheme for a nonlocal active matter\nsystem known to exhibit a rich array of complex behaviours. The model under\ninvestigation was derived from a stochastic system of interacting particles\ndescribing a foraging ant colony coupled to pheromone dynamics. In this work,\nwe prove that the unique numerical solution converges to the unique weak\nsolution as the mesh size and the time step go to zero. We also show discrete\nlong-time estimates, which prove that certain norms are preserved for all\ntimes, uniformly in the mesh size and time step. In particular, we prove higher\nregularity estimates which provide an analogue of continuum parabolic higher\nregularity estimates. Finally, we numerically study the rate of convergence of\nthe scheme, and we provide examples of the existence of multiple metastable\nsteady states.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-03-31T12:23:49Z"}
{"aid":"http://arxiv.org/abs/2503.24019v1","title":"AutoML Algorithms for Online Generalized Additive Model Selection:\n  Application to Electricity Demand Forecasting","summary":"Electricity demand forecasting is key to ensuring that supply meets demand\nlest the grid would blackout. Reliable short-term forecasts may be obtained by\ncombining a Generalized Additive Models (GAM) with a State-Space model (Obst et\nal., 2021), leading to an adaptive (or online) model. A GAM is an\nover-parameterized linear model defined by a formula and a state-space model\ninvolves hyperparameters. Both the formula and adaptation parameters have to be\nfixed before model training and have a huge impact on the model's predictive\nperformance. We propose optimizing them using the DRAGON package of Keisler\n(2025), originally designed for neural architecture search. This work\ngeneralizes it for automated online generalized additive model selection by\ndefining an efficient modeling of the search space (namely, the space of the\nGAM formulae and adaptation parameters). Its application to short-term French\nelectricity demand forecasting demonstrates the relevance of the approach","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.AP","published":"2025-03-31T12:46:33Z"}
{"aid":"http://arxiv.org/abs/2503.24026v1","title":"HumanDreamer: Generating Controllable Human-Motion Videos via Decoupled\n  Generation","summary":"Human-motion video generation has been a challenging task, primarily due to\nthe difficulty inherent in learning human body movements. While some approaches\nhave attempted to drive human-centric video generation explicitly through pose\ncontrol, these methods typically rely on poses derived from existing videos,\nthereby lacking flexibility. To address this, we propose HumanDreamer, a\ndecoupled human video generation framework that first generates diverse poses\nfrom text prompts and then leverages these poses to generate human-motion\nvideos. Specifically, we propose MotionVid, the largest dataset for\nhuman-motion pose generation. Based on the dataset, we present MotionDiT, which\nis trained to generate structured human-motion poses from text prompts.\nBesides, a novel LAMA loss is introduced, which together contribute to a\nsignificant improvement in FID by 62.4%, along with respective enhancements in\nR-precision for top1, top2, and top3 by 41.8%, 26.3%, and 18.3%, thereby\nadvancing both the Text-to-Pose control accuracy and FID metrics. Our\nexperiments across various Pose-to-Video baselines demonstrate that the poses\ngenerated by our method can produce diverse and high-quality human-motion\nvideos. Furthermore, our model can facilitate other downstream tasks, such as\npose sequence prediction and 2D-3D motion lifting.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T12:51:45Z"}
{"aid":"http://arxiv.org/abs/2503.24028v1","title":"Pay More Attention to the Robustness of Prompt for Instruction Data\n  Mining","summary":"Instruction tuning has emerged as a paramount method for tailoring the\nbehaviors of LLMs. Recent work has unveiled the potential for LLMs to achieve\nhigh performance through fine-tuning with a limited quantity of high-quality\ninstruction data. Building upon this approach, we further explore the impact of\nprompt's robustness on the selection of high-quality instruction data. This\npaper proposes a pioneering framework of high-quality online instruction data\nmining for instruction tuning, focusing on the impact of prompt's robustness on\nthe data mining process. Our notable innovation, is to generate the adversarial\ninstruction data by conducting the attack for the prompt of online instruction\ndata. Then, we introduce an Adversarial Instruction-Following Difficulty metric\nto measure how much help the adversarial instruction data can provide to the\ngeneration of the corresponding response. Apart from it, we propose a novel\nAdversarial Instruction Output Embedding Consistency approach to select\nhigh-quality online instruction data. We conduct extensive experiments on two\nbenchmark datasets to assess the performance. The experimental results serve to\nunderscore the effectiveness of our proposed two methods. Moreover, the results\nunderscore the critical practical significance of considering prompt's\nrobustness.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T12:53:08Z"}
{"aid":"http://arxiv.org/abs/2503.24034v1","title":"Creation of a black hole bomb instability in an electromagnetic system","summary":"The amplification and generation of electromagnetic radiation by a rotating\nmetallic or lossy cylinder, first theorized by Zeldovich in the 1970s, is\ntightly connected to the concepts of quantum friction, energy extraction from\nrotating black holes and runaway mechanisms such as black hole bombs. Despite\nrecent advances including acoustic analogues of the Zeldovich effect and the\nobservation of a negative resistance in a low-frequency electromagnetic model,\nactual positive signal amplitude gain, the spontaneous generation of\nelectromagnetic waves and runaway amplifi- cation effects have never been\nexperimentally verified. Here, we demonstrate experimentally that a\nmechanically rotating metallic cylinder not only definitively acts as an\namplifier of a rotating elec- tromagnetic field mode but also, when paired with\na low-loss resonator, becomes unstable and acts as a generator, seeded only by\nnoise. The system exhibits an exponential runaway amplification of\nspontaneously generated electromagnetic modes thus demonstrating the\nelectromagnetic analogue of Press and Teukolskys black hole bomb. The\nexponential amplification from noise supports theoretical investigations into\nblack hole instabilities and is promising for the development of future\nexperiments to observe quantum friction in the form of the Zeldovich effect\nseeded by the quantum vacuum.","main_category":"quant-ph","categories":"quant-ph,physics.app-ph,physics.ins-det","published":"2025-03-31T13:00:10Z"}
{"aid":"http://arxiv.org/abs/2503.24044v1","title":"Bi-Level Route Optimization and Path Planning with Hazard Exploration","summary":"Effective risk monitoring in dynamic environments such as disaster zones\nrequires an adaptive exploration strategy to detect hidden threats. We propose\na bi-level unmanned aerial vehicle (UAV) monitoring strategy that efficiently\nintegrates high-level route optimization with low-level path planning for known\nand unknown hazards. At the high level, we formulate the route optimization as\na vehicle routing problem (VRP) to determine the optimal sequence for visiting\nknown hazard locations. To strategically incorporate exploration efficiency, we\nintroduce an edge-based centroidal Voronoi tessellation (CVT), which refines\nbaseline routes using pseudo-nodes and allocates path budgets based on the\nUAV's battery capacity using a line segment Voronoi diagram. At the low level,\npath planning maximizes information gain within the allocated path budget by\ngenerating kinematically feasible B-spline trajectories. Bayesian inference is\napplied to dynamically update hazard probabilities, enabling the UAVs to\nprioritize unexplored regions. Simulation results demonstrate that edge-based\nCVT improves spatial coverage and route uniformity compared to the node-based\nmethod. Additionally, our optimized path planning consistently outperforms\nbaselines in hazard discovery rates across a diverse set of scenarios.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T13:08:51Z"}
{"aid":"http://arxiv.org/abs/2503.24049v1","title":"The Linear Collider Facility (LCF) at CERN","summary":"In this paper we outline a proposal for a Linear Collider Facility as the\nnext flagship project for CERN. It offers the opportunity for a timely,\ncost-effective and staged construction of a new collider that will be able to\ncomprehensively map the Higgs boson's properties, including the Higgs field\npotential, thanks to a large span in centre-of-mass energies and polarised\nbeams. A comprehensive programme to study the Higgs boson and its closest\nrelatives with high precision requires data at centre-of-mass energies from the\nZ pole to at least 1 TeV. It should include measurements of the Higgs boson in\nboth major production mechanisms, ee -> ZH and ee -> vvH, precision\nmeasurements of gauge boson interactions as well as of the W boson, Higgs boson\nand top-quark masses, measurement of the top-quark Yukawa coupling through ee\n->ttH, measurement of the Higgs boson self-coupling through HH production, and\nprecision measurements of the electroweak couplings of the top quark. In\naddition, ee collisions offer discovery potential for new particles\ncomplementary to HL-LHC.","main_category":"hep-ex","categories":"hep-ex,physics.acc-ph","published":"2025-03-31T13:12:13Z"}
{"aid":"http://arxiv.org/abs/2503.24051v1","title":"Practical Quantum Advantage for Boosting Citations","summary":"Realizing practical quantum advantage with meaningful economic impact is the\nholy grail of the quantum information field. Recent quantum technology advances\nhave driven exponential growth in quantum information research, with resultant\npublications achieving significantly elevated impact. Within academia, citation\ncounts serve as a key metric for evaluating research impact, often directly\ninfluencing career advancement and compensation structures. Motivated by these\nobservations, we propose a potential protocol for practical quantum advantage\nin boosting citations.","main_category":"physics.pop-ph","categories":"physics.pop-ph,quant-ph","published":"2025-03-31T13:13:48Z"}
{"aid":"http://arxiv.org/abs/2503.24058v1","title":"Mechanical Squeezed Kerr Oscillator based on Tapered Ion Trap","summary":"We propose the realization of a mechanically squeezed Kerr oscillator with a\nsingle ion in a tapered trap. We show that the motion coupling between the\naxial and radial modes caused by the trap geometry leads to Kerr nonlinearity\nof the radial mode with magnitude controlled by the trap frequencies. This\nallows the realization of non-Gaussian quantum gates, which play a significant\nrole in the universal set of continuous variable quantum gates. Furthermore, we\nshow that, because of the nonlinearity of the ion trap, applying an\noff-resonant time-varying electric field along the trap axis causes a motion\nsqueezing of the radial mode. Finally, we discuss the motion mode frequency\nspectrum of an ion crystal in a tapered trap. We show that the frequency gap\nbetween the motion modes increases with trap nonlinearity, which benefits the\nrealization of faster quantum gates.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T13:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.24060v1","title":"Quantization of Lie-Poisson algebra and Lie algebra solutions of\n  mass-deformed type IIB matrix model","summary":"A quantization of Lie-Poisson algebras is studied. The mass-deformed IIB\nmatrix model admits classical solutions constructed from the basis of any\nsemisimple Lie algebra. We consider the geometry described by the classical\nsolutions of the Lie algebras in the limit where the mass vanishes and the\nmatrix size is infinite. Lie-Poisson varieties are regarded as such geometric\nobjects. We provide a quantization called ``weak matrix regularization''of any\nLie-Poisson algebra (linear Poisson algebra) on the algebraic variety defined\nby its Casimir polynomials. The Lie algebra that gives weak matrix\nregularization is not necessarily semisimple. Casimir polynomials correspond\nwith Casimir operators of the Lie algebra by the quantization. This\nquantization is a generalization of the fuzzy sphere. In order to define the\nweak matrix regularization of the quotient space by the ideal generated by the\nCasimir polynomials, we take a construction method that fixes a reduced\nGr\\\"obner basis of the ideal. The Gr\\\"obner basis determines remainders of\npolynomials. The operation of replacing this remainders with representation\nmatrices of a Lie algebra roughly corresponds to a weak matrix regularization.\nAs concrete examples, we construct weak matrix regularization for $su(2)$ and\n$su(3)$. In the case of $su(3)$, we not only construct weak matrix\nregularization for the quadratic Casimir polynomial, but also construct weak\nmatrix regularization for the cubic Casimir polynomial.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-03-31T13:21:15Z"}
{"aid":"http://arxiv.org/abs/2503.24063v1","title":"A robot-assisted pipeline to rapidly scan 1.7 million historical aerial\n  photographs","summary":"During the 20th Century, aerial surveys captured hundreds of millions of\nhigh-resolution photographs of the earth's surface. These images, the\nprecursors to modern satellite imagery, represent an extraordinary visual\nrecord of the environmental and social upheavals of the 20th Century. However,\nmost of these images currently languish in physical archives where retrieval is\ndifficult and costly. Digitization could revolutionize access, but manual\nscanning is slow and expensive. Here, we describe and validate a novel\nrobot-assisted pipeline that increases worker productivity in scanning 30-fold,\napplied at scale to digitize an archive of 1.7 million historical aerial\nphotographs from 65 countries.","main_category":"eess.IV","categories":"eess.IV,cs.SY,econ.GN,eess.SY,q-fin.EC","published":"2025-03-31T13:23:05Z"}
{"aid":"http://arxiv.org/abs/2503.24068v1","title":"A Quantum Energy Inequality for a Non-commutative QFT","summary":"We establish a quantum energy inequality (QEI) for a quantum field theory\nformulated in a non-commutative spacetime. This inequality provides a\nfundamental bound on the expectation values of the energy density, ensuring the\nstability and physical consistency of the theory.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-03-31T13:27:12Z"}
{"aid":"http://arxiv.org/abs/2503.24072v1","title":"Estimation of thermal properties and boundary heat transfer coefficient\n  of the ground with a Bayesian technique","summary":"Urbanization is the key contributor for climate change. Increasing\nurbanization rate causes an urban heat island (UHI) effect, which strongly\ndepends on the short- and long-wave radiation balance heat flux between the\nsurfaces. In order to calculate accurately this heat flux, it is required to\nassess the surface temperature which depends on the knowledge of the thermal\nproperties and the surface heat transfer coefficients in the heat transfer\nproblem. The aim of this paper is to estimate the thermal properties of the\nground and the time varying surface heat transfer coefficient by solving an\ninverse problem. The Dufort--Frankel scheme is applied for solving the unsteady\nheat transfer problem. For the inverse problem, a Markov chain Monte Carlo\nmethod is used to estimate the posterior probability density function of\nunknown parameters within the Bayesian framework of statistics, by applying the\nMetropolis-Hastings algorithm for random sample generation. Actual temperature\nmeasurements available at different ground depths were used for the solution of\nthe inverse problem. Different time discretizations were examined for the\ntransient heat transfer coefficient at the ground surface, which then involved\ndifferent prior distributions. Results of different case studies show that the\nestimated values of the unknown parameters were in accordance with literature\nvalues. Moreover, with the present solution of the inverse problem the\ntemperature residuals were smaller than those obtained by using literature\nvalues for the unknowns.","main_category":"cs.CE","categories":"cs.CE,math-ph,math.MP,G.3","published":"2025-03-31T13:29:25Z"}
{"aid":"http://arxiv.org/abs/2503.24076v1","title":"On a question about real rooted polynomials and f-polynomials of\n  simplicial complexes","summary":"For a polynomial $f(t) = 1+f_0t+\\cdots +f_{d-1}t^d$ with positive integer\ncoefficients Bell and Skandera ask if real rootedness of f(t) implies that\nthere is a simplicial complex with f-vector $(1,f_0 \\ldots,f_{d-1})$. In this\npaper we discover properties implied by the real rootedness of f(t) in terms of\nthe binomial representation $f_i = \\binom{x_{i+1}}{i+1}, i \\geq 0$. We use\nthese to provide a sufficient criterion for a positive answer to the question\nby Bell and Skandera. We also describe two further approaches to the conjecture\nand use one to verify that some well studied real rooted classical polynomials\nare f-polynomials. Finally, we provide a series of results showing that the set\nof f-vectors of simplicial complexes is closed under constructions also\npreserving real rootedness of their generating polynomials.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T13:31:37Z"}
{"aid":"http://arxiv.org/abs/2503.24083v1","title":"Controlled Latent Diffusion Models for 3D Porous Media Reconstruction","summary":"Three-dimensional digital reconstruction of porous media presents a\nfundamental challenge in geoscience, requiring simultaneous resolution of\nfine-scale pore structures while capturing representative elementary volumes.\nWe introduce a computational framework that addresses this challenge through\nlatent diffusion models operating within the EDM framework. Our approach\nreduces dimensionality via a custom variational autoencoder trained in binary\ngeological volumes, improving efficiency and also enabling the generation of\nlarger volumes than previously possible with diffusion models. A key innovation\nis our controlled unconditional sampling methodology, which enhances\ndistribution coverage by first sampling target statistics from their empirical\ndistributions, then generating samples conditioned on these values. Extensive\ntesting on four distinct rock types demonstrates that conditioning on porosity\n- a readily computable statistic - is sufficient to ensure a consistent\nrepresentation of multiple complex properties, including permeability,\ntwo-point correlation functions, and pore size distributions. The framework\nachieves better generation quality than pixel-space diffusion while enabling\nsignificantly larger volume reconstruction (256-cube voxels) with substantially\nreduced computational requirements, establishing a new state-of-the-art for\ndigital rock physics applications.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.LG","published":"2025-03-31T13:36:55Z"}
{"aid":"http://arxiv.org/abs/2503.24087v1","title":"Dynamics of Spinning Test Body in quadratic Einstein-Cartan Theory and\n  its Free-fall Test","summary":"We study the dynamics of the non-relativistic spinning test body (STB) in the\nframework of Einstein-Cartan theory(ECT), in which the weak equivalence\nprinciple is violated by the spin-gravitational interaction. We derive the\ngeneral equation of geodesic in terms of comoving tetrads. More concretely, we\nconsider the case of the quadratic form of the lagrangian, within the\nenvironment of weak and static spherically symmetric space-time. We find that\nthe trajectories of STB deviate from the traditional Mathisson\\textendash\nPapapetrou equation, which is due to the coupling of the spin of the test\nparticle to the torsion field of the environment. This allows us to test the\ntheory with free-fall experiment in the laboratory, such as atom\ninterferometer. By using the previous data, we find the upper bound of the\npossible torsion field on Earth is given by up to $2.0\\times 10^{1}\n\\mathrm{~m^{-1}}$ and torsion gradient up to $3.1 \\times\n10^{-6}\\mathrm{~m^{-2}}$. This result may enable us to provide a theoretical\nfoundation for future precision measurements of the existence of the fifth\nforce.","main_category":"gr-qc","categories":"gr-qc,hep-ph,hep-th,physics.atom-ph,quant-ph","published":"2025-03-31T13:41:00Z"}
{"aid":"http://arxiv.org/abs/2503.24094v1","title":"Classification of Jordan multiplicative maps on matrix algebras","summary":"Let $M_n(\\mathbb{F})$ be the algebra of $n \\times n$ matrices over a field\n$\\mathbb{F}$ of characteristic not equal to $2$. If $n\\ge 2$, we show that an\narbitrary map $\\phi : M_n(\\mathbb{F}) \\to M_n(\\mathbb{F})$ is Jordan\nmultiplicative, i.e. it satisfies the functional equation $$\n\\phi(XY+YX)=\\phi(X)\\phi(Y)+\\phi(Y)\\phi(X), \\quad \\text{for all } X,Y \\in\nM_n(\\mathbb{F}) $$ if and only if one of the following holds: either $\\phi$ is\nconstant and equal to a fixed idempotent, or there exists an invertible matrix\n$T \\in M_n(\\mathbb{F})$ and a ring monomorphism $\\omega: \\mathbb{F} \\to\n\\mathbb{F}$ such that $$ \\phi(X)=T\\omega(X)T^{-1} \\quad \\text{ or } \\quad\n\\phi(X)=T\\omega(X)^tT^{-1}, \\quad \\text{for all } X \\in M_n(\\mathbb{F}), $$\nwhere $\\omega(X)$ denotes the matrix obtained by applying $\\omega$ entrywise to\n$X$. In particular, any Jordan multiplicative map $\\phi : M_n(\\mathbb{F}) \\to\nM_n(\\mathbb{F})$ with $\\phi(0)=0$ is automatically additive.","main_category":"math.RA","categories":"math.RA","published":"2025-03-31T13:45:22Z"}
{"aid":"http://arxiv.org/abs/2503.24095v1","title":"Threats and Opportunities in AI-generated Images for Armed Forces","summary":"Images of war are almost as old as war itself. From cave paintings to\nphotographs of mobile devices on social media, humans always had the urge to\ncapture particularly important events during a war. Images provide visual\nevidence. For armed forces, they may serve as the output of a sensor (e.g. in\naerial reconnaissance) or as an effector on cognition (e.g. in form of\nphotographic propaganda). They can inform, influence, or even manipulate a\ntarget audience. The recent advancements in the field of generative Artificial\nIntelligence (AI) to synthesize photorealistic images give rise to several new\nchallenges for armed forces. The objective of this report is to investigate the\nrole of AI-generated images for armed forces and provide an overview on\nopportunities and threats. When compared with traditional image generation\n(e.g. photography), generative AI brings distinct conceptual advantages to\nimplement new tactical tenets and concepts which so far have not been feasible:\nmasses of AI-generated images can be used for deceptive purposes, to influence\nthe pace of combat in the information environment, to cause surprise, sow\nconfusion and shock. AI-generated images are a tool favoured for offensive\nmanoeuvres in the information environment. To prepare for future challenges\ninvolving AI-generated images and improve their resilience, recommendations are\ngiven at the end of the report for all branches of the armed forces, who are\nactive in cyber defense and/or exposed to the information environment.","main_category":"cs.CY","categories":"cs.CY","published":"2025-03-31T13:46:02Z"}
{"aid":"http://arxiv.org/abs/2503.24104v1","title":"Application of Battery Storage to Switching Predictive Control of Power\n  Distribution Systems Including Road Heating","summary":"A road heating system is an electrical device which promotes snow melting by\nburying a heating cable as a thermal source underground. When integrating road\nheating into the power distribution system, we need to optimize the flow of\nelectric power by appropriately integrating distributed power sources and\nconventional power distribution equipment. In this paper, we extend the power\ndistribution system considered in the authors' previous study to the case where\nbattery storage is installed. As a main result, we propose a predictive\nswitching control that achieves the reduction of distribution loss, attenuation\nof voltage fluctuation, and efficient snow melting, simultaneously. We verify\nthe effectiveness of the application of battery storage through numerical\nsimulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-03-31T13:57:04Z"}
{"aid":"http://arxiv.org/abs/2503.24113v1","title":"From Local to Remote: VisIVO Visual Analytics in the Era of the Square\n  Kilometre Array","summary":"The field of astrophysics is continuously advancing, with an ever-growing\ninflux of data requiring robust and efficient analysis tools. As the Square\nKilometre Array (SKA) radio telescopes come fully operational, we anticipate\nthe generation of hundreds of petabytes of data annually, characterized by\nunprecedented resolution and detail. In this context, scientific visualization\nbecomes a critical component, enabling researchers to interpret complex\ndatasets and extract meaningful insights. The immense volume of data demands\nnot only suitable tools but also substantial infrastructure and computational\ncapacity to analyze it effectively. In this work, we will discuss how we are\naddressing these challenges with the development of our interactive\nvisualization tool named VisIVO Visual Analytics. The tool is transitioning\nfrom a local visualizer to a remote visualizer, utilizing a client-server\narchitecture. This evolution will allow the software to run parallel\nvisualization pipelines on high-performance computing (HPC) clusters, thereby\nenhancing its capacity to handle extensive datasets efficiently.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T14:04:53Z"}
{"aid":"http://arxiv.org/abs/2503.24114v1","title":"Generic linearized curvature singularity at the perturbed Kerr Cauchy\n  horizon","summary":"We prove the precise asymptotics of the spin $-2$ Teukolsky field in the\ninterior and along the Cauchy horizon of a subextremal Kerr black hole.\nTogether with the oscillatory blow-up asymptotics of the spin $+2$ Teukolsky\nfield proven in our previous work arXiv:2409.02670, our result suggests that\ngeneric perturbations of a Kerr black hole build up to form a\ncoordinate-independent curvature singularity at the Cauchy horizon. This\nsupports the Strong Cosmic Censorship conjecture in Kerr spacetimes. Unlike in\nthe spin $+2$ case, the spin $-2$ Teukolsky field is regular on the Cauchy\nhorizon and the first term in its asymptotic development vanishes. As a result,\nthe derivation of a precise lower bound for the spin $-2$ field is more\ndelicate than in the spin $+2$ case, and relies on a novel ODE method based on\na decomposition of the Teukolsky operator between radial and time derivatives.","main_category":"gr-qc","categories":"gr-qc,math.AP","published":"2025-03-31T14:05:27Z"}
{"aid":"http://arxiv.org/abs/2503.24116v1","title":"Multi-Task Learning for Extracting Menstrual Characteristics from\n  Clinical Notes","summary":"Menstrual health is a critical yet often overlooked aspect of women's\nhealthcare. Despite its clinical relevance, detailed data on menstrual\ncharacteristics is rarely available in structured medical records. To address\nthis gap, we propose a novel Natural Language Processing pipeline to extract\nkey menstrual cycle attributes -- dysmenorrhea, regularity, flow volume, and\nintermenstrual bleeding. Our approach utilizes the GatorTron model with\nMulti-Task Prompt-based Learning, enhanced by a hybrid retrieval preprocessing\nstep to identify relevant text segments. It out- performs baseline methods,\nachieving an average F1-score of 90% across all menstrual characteristics,\ndespite being trained on fewer than 100 annotated clinical notes. The retrieval\nstep consistently improves performance across all approaches, allowing the\nmodel to focus on the most relevant segments of lengthy clinical notes. These\nresults show that combining multi-task learning with retrieval improves\ngeneralization and performance across menstrual charac- teristics, advancing\nautomated extraction from clinical notes and supporting women's health\nresearch.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T14:07:03Z"}
{"aid":"http://arxiv.org/abs/2503.24119v1","title":"Measuring User Experience Through Speech Analysis: Insights from HCI\n  Interviews","summary":"User satisfaction plays a crucial role in user experience (UX) evaluation.\nTraditionally, UX measurements are based on subjective scales, such as\nquestionnaires. However, these evaluations may suffer from subjective bias. In\nthis paper, we explore the acoustic and prosodic features of speech to\ndifferentiate between positive and neutral UX during interactive sessions. By\nanalyzing speech features such as root-mean-square (RMS), zero-crossing\nrate(ZCR), jitter, and shimmer, we identified significant differences between\nthe positive and neutral user groups. In addition, social speech features such\nas activity and engagement also show notable variations between these groups.\nOur findings underscore the potential of speech analysis as an objective and\nreliable tool for UX measurement, contributing to more robust and\nbias-resistant evaluation methodologies. This work offers a novel approach to\nintegrating speech features into UX evaluation and opens avenues for further\nresearch in HCI.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T14:07:38Z"}
{"aid":"http://arxiv.org/abs/2503.24123v1","title":"CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic\n  Learning","summary":"Many computational tasks benefit from being formulated as the composition of\nneural networks followed by a discrete symbolic program. The goal of\nneurosymbolic learning is to train the neural networks using only end-to-end\ninput-output labels of the composite. We introduce CTSketch, a novel, scalable\nneurosymbolic learning algorithm. CTSketch uses two techniques to improve the\nscalability of neurosymbolic inference: decompose the symbolic program into\nsub-programs and summarize each sub-program with a sketched tensor. This\nstrategy allows us to approximate the output distribution of the program with\nsimple tensor operations over the input distributions and summaries. We provide\ntheoretical insight into the maximum error of the approximation. Furthermore,\nwe evaluate CTSketch on many benchmarks from the neurosymbolic literature,\nincluding some designed for evaluating scalability. Our results show that\nCTSketch pushes neurosymbolic learning to new scales that have previously been\nunattainable by obtaining high accuracy on tasks involving over one thousand\ninputs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T14:08:58Z"}
{"aid":"http://arxiv.org/abs/2503.24136v1","title":"Numerical simulation of Generalized Hermite Processes","summary":"Hermite processes are paradigmatic examples of stochastic processes which can\nbelong to any Wiener chaos of an arbitrary order; the wellknown fractional\nBrownian motion belonging to the Gaussian first order Wiener chaos and the\nRosenblatt process belonging to the non-Gaussian second order Wiener chaos are\ntwo particular cases of them. Except these two particular cases no simulation\nmethod for sample paths of Hermite processes is available so far. The goal of\nour article is to introduce a new method which potentially allows to simulate\nsample paths of any Hermite process and even those of any generalized Hermite\nprocess. Our starting point is the representation for the latter process as\nrandom wavelet-typeseries, obtained in our very recent paper [3]. We construct\nfrom it a \"concrete\" sequence of piecewise linear continuous random functions\nwhich almost surely approximate sample paths of this process for the uniform\nnorm on any compact interval, and we provide an almost sure estimate of the\napproximation error. Then, for the Rosenblatt process and more importantly for\nthe third order Hermite process, we propose algorithms allowing to implement\nthis sequence and we illustrate them by several simulations. Python routines\nimplementing these synthesis procedures are available upon request.","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T14:18:42Z"}
{"aid":"http://arxiv.org/abs/2503.24140v1","title":"Reinforcement Learning for Safe Autonomous Two Device Navigation of\n  Cerebral Vessels in Mechanical Thrombectomy","summary":"Purpose: Autonomous systems in mechanical thrombectomy (MT) hold promise for\nreducing procedure times, minimizing radiation exposure, and enhancing patient\nsafety. However, current reinforcement learning (RL) methods only reach the\ncarotid arteries, are not generalizable to other patient vasculatures, and do\nnot consider safety. We propose a safe dual-device RL algorithm that can\nnavigate beyond the carotid arteries to cerebral vessels.\n  Methods: We used the Simulation Open Framework Architecture to represent the\nintricacies of cerebral vessels, and a modified Soft Actor-Critic RL algorithm\nto learn, for the first time, the navigation of micro-catheters and\nmicro-guidewires. We incorporate patient safety metrics into our reward\nfunction by integrating guidewire tip forces. Inverse RL is used with\ndemonstrator data on 12 patient-specific vascular cases.\n  Results: Our simulation demonstrates successful autonomous navigation within\nunseen cerebral vessels, achieving a 96% success rate, 7.0s procedure time, and\n0.24 N mean forces, well below the proposed 1.5 N vessel rupture threshold.\n  Conclusion: To the best of our knowledge, our proposed autonomous system for\nMT two-device navigation reaches cerebral vessels, considers safety, and is\ngeneralizable to unseen patient-specific cases for the first time. We envisage\nfuture work will extend the validation to vasculatures of different complexity\nand on in vitro models. While our contributions pave the way towards deploying\nagents in clinical settings, safety and trustworthiness will be crucial\nelements to consider when proposing new methodology.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-03-31T14:25:46Z"}
{"aid":"http://arxiv.org/abs/2503.24141v1","title":"The Influence of an Adjoint Mismatch on the Primal-Dual Douglas-Rachford\n  Method","summary":"The primal-dual Douglas-Rachford method is a well-known algorithm to solve\noptimization problems written as convex-concave saddle-point problems. Each\niteration involves solving a linear system involving a linear operator and its\nadjoint. However, in practical applications it is often computationally\nfavorable to replace the adjoint operator by a computationally more efficient\napproximation. This leads to an adjoint mismatch. In this paper, we analyze the\nconvergence of the primal-dual Douglas-Rachford method under the presence of an\nadjoint mismatch. We provide mild conditions that guarantee the existence of a\nfixed point and find an upper bound on the error of the primal solution.\nFurthermore, we establish step sizes in the strongly convex setting that\nguarantee linear convergence under mild conditions. Additionally, we provide an\nalternative method that can also be derived from the Douglas-Rachford method\nand is also guaranteed to converge in this setting. Moreover, we illustrate our\nresults both for an academic and a real-world inspired example.","main_category":"math.OC","categories":"math.OC","published":"2025-03-31T14:25:59Z"}
{"aid":"http://arxiv.org/abs/2503.24143v1","title":"Enhancing Traffic Safety with AI and 6G: Latency Requirements and\n  Real-Time Threat Detection","summary":"The rapid digitalization of urban infrastructure opens the path to smart\ncities, where IoT-enabled infrastructure enhances public safety and efficiency.\nThis paper presents a 6G and AI-enabled framework for traffic safety\nenhancement, focusing on real-time detection and classification of emergency\nvehicles and leveraging 6G as the latest global communication standard. The\nsystem integrates sensor data acquisition, convolutional neural network-based\nthreat detection, and user alert dissemination through various software modules\nof the use case. We define the latency requirements for such a system,\nsegmenting the end-to-end latency into computational and networking components.\nOur empirical evaluation demonstrates the impact of vehicle speed and user\ntrajectory on system reliability. The results provide insights for network\noperators and smart city service providers, emphasizing the critical role of\nlow-latency communication and how networks can enable relevant services for\ntraffic safety.","main_category":"cs.DC","categories":"cs.DC","published":"2025-03-31T14:27:32Z"}
{"aid":"http://arxiv.org/abs/2503.24146v1","title":"Joint Modeling of Multiple Longitudinal Biomarkers and Survival Outcomes\n  via Threshold Regression: Variability as a Predictor","summary":"Longitudinal biomarker data and health outcomes are routinely collected in\nmany studies to assess how biomarker trajectories predict health outcomes.\nExisting methods primarily focus on mean biomarker profiles, treating\nvariability as a nuisance. However, excess variability may indicate system\ndysregulations that may be associated with poor outcomes. In this paper, we\naddress the long-standing problem of using variability information of multiple\nlongitudinal biomarkers in time-to-event analyses by formulating and studying a\nBayesian joint model. We first model multiple longitudinal biomarkers, some of\nwhich are subject to limit-of-detection censoring. We then model the survival\ntimes by incorporating random effects and variances from the longitudinal\ncomponent as predictors through threshold regression that admits\nnon-proportional hazards. We demonstrate the operating characteristics of the\nproposed joint model through simulations and apply it to data from the Study of\nWomen's Health Across the Nation (SWAN) to investigate the impact of the mean\nand variability of follicle-stimulating hormone (FSH) and anti-Mullerian\nhormone (AMH) on age at the final menstrual period (FMP).","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T14:33:04Z"}
{"aid":"http://arxiv.org/abs/2503.24151v1","title":"Robust Feedback Optimization with Model Uncertainty: A Regularization\n  Approach","summary":"Feedback optimization optimizes the steady state of a dynamical system by\nimplementing optimization iterations in closed loop with the plant. It relies\non online measurements and limited model information, namely, the input-output\nsensitivity. In practice, various issues including inaccurate modeling, lack of\nobservation, or changing conditions can lead to sensitivity mismatches, causing\nclosed-loop sub-optimality or even instability. To handle such uncertainties,\nwe pursue robust feedback optimization, where we optimize the closed-loop\nperformance against all possible sensitivities lying in specific uncertainty\nsets. We provide tractable reformulations for the corresponding min-max\nproblems via regularizations and characterize the online closed-loop\nperformance through the tracking error in case of time-varying optimal\nsolutions. Simulations on a distribution grid illustrate the effectiveness of\nour robust feedback optimization controller in addressing sensitivity\nmismatches in a non-stationary environment.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T14:36:25Z"}
{"aid":"http://arxiv.org/abs/2503.24166v1","title":"Foundation Models For Seismic Data Processing: An Extensive Review","summary":"Seismic processing plays a crucial role in transforming raw data into\nhigh-quality subsurface images, pivotal for various geoscience applications.\nDespite its importance, traditional seismic processing techniques face\nchallenges such as noisy and damaged data and the reliance on manual,\ntime-consuming workflows. The emergence of deep learning approaches has\nintroduced effective and user-friendly alternatives, yet many of these deep\nlearning approaches rely on synthetic datasets and specialized neural networks.\nRecently, foundation models have gained traction in the seismic domain, due to\ntheir success in natural imaging. This paper investigates the application of\nfoundation models in seismic processing on the tasks: demultiple,\ninterpolation, and denoising. It evaluates the impact of different model\ncharacteristics, such as pre-training technique and neural network\narchitecture, on performance and efficiency. Rather than proposing a single\nseismic foundation model, this paper critically examines various natural image\nfoundation models and suggest some promising candidates for future exploration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T14:48:31Z"}
{"aid":"http://arxiv.org/abs/2503.24172v1","title":"Pseudo-Random UAV Test Generation Using Low-Fidelity Path Simulator","summary":"Simulation-based testing provides a safe and cost-effective environment for\nverifying the safety of Uncrewed Aerial Vehicles (UAVs). However, simulation\ncan be resource-consuming, especially when High-Fidelity Simulators (HFS) are\nused. To optimise simulation resources, we propose a pseudo-random test\ngenerator that uses a Low-Fidelity Simulator (LFS) to estimate UAV flight\npaths. This work simplifies the PX4 autopilot HFS to develop a LFS, which\noperates one order of magnitude faster than the HFS.Test cases predicted to\ncause safety violations in the LFS are subsequently validated using the HFS.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T14:50:46Z"}
{"aid":"http://arxiv.org/abs/2503.24189v1","title":"Quantum superalgebras and the free-fermionic Yang-Baxter equation","summary":"The free-fermion point refers to a\n$\\operatorname{GL}(2)\\times\\operatorname{GL}(1)$ parametrized Yang-Baxter\nequation within the six-vertex model. It has been known for a long time that\nthis is connected with the quantum group $U_q(\\mathfrak{gl}(1|1))$. We\ndemonstrate that $R$-matrices from the finite quantum superalgebra\n$U_q(\\mathfrak{gl}(1|1))$ recovers a dense subset of the free-fermion point of\nthe six-vertex model and recover the prime, simple modules in the affine\nquantum superalgebra $U_q(\\widehat{\\mathfrak{gl}}(1|1))$. Either of these\nquantum groups can be used to generate the full free-fermion point, and we\ndiscuss them both. Our discussion includes 6 families of six-vertex models used\nby Brubaker, Bump, and Friedberg in connection with Tokuyama's theorem, a\ndeformation of the Weyl character formula. Thus our work gives quantum group\ninterpretations for those models, known informally as Tokuyama ice.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-03-31T15:06:50Z"}
{"aid":"http://arxiv.org/abs/2503.24207v1","title":"Definability of mad families of vector spaces and two local Ramsey\n  theories","summary":"Let $E$ be a vector space over a countable field of dimension $\\aleph_0$. Two\ninfinite-dimensional subspaces $V,W \\subseteq E$ are almost disjoint if $V \\cap\nW$ is finite-dimensional. This paper provides some improvements on results\nabout the definability of maximal almost disjoint families (mad families) of\nsubspaces in [17]. We show that a full mad family of block subspaces exists\nassuming either $\\frak{p} = \\max\\{\\frak{b},\\frak{s}\\}$ or a positive answer to\na problem in [17], improving Smythe's construction assuming $\\frak{p} =\n\\frak{c}$. We also discuss the abstract Mathias forcing introduced by Di\nPrisco-Mijares-Nieto in [11], and apply it to show that in the Solovay's model\nobtained by the collapse of a Mahlo cardinal, there are no full mad families of\nblock subspaces over $\\mathbb{F}_2$.","main_category":"math.LO","categories":"math.LO","published":"2025-03-31T15:24:19Z"}
{"aid":"http://arxiv.org/abs/2503.24212v1","title":"Characterization of $\\PSL(2,q)$ by the number of singular elements","summary":"Given a finite group $G$, let $\\pi(G)$ denote the set of all primes that\ndivide the order of $G$. For a prime $r \\in \\pi(G)$, we define $r$-singular\nelements as those elements of $G$ whose order is divisible by $r$. Denote by\n$S_r(G)$ the number of $r$-singluar elements of $G$. We denote the proportion\n$S_r(G)/|G|$ of $r$-singular elements in $G$ by ${\\mu_r}(G)$. Let $\\mu(G) :=\n{\\{\\mu_r}(G) | r\\in \\pi(G)\\}$ be the set of all proportions of $r$-singular\nelements for each prime $r$ in $\\pi(G)$. In this paper, we prove that if a\nfinite group $G$ has the same set $\\mu(G)$ as the simple group $\\PSL(2,q)$,\nthen $G$ is isomorphic to $\\PSL(2,q)$.","main_category":"math.GR","categories":"math.GR","published":"2025-03-31T15:30:34Z"}
{"aid":"http://arxiv.org/abs/2503.24216v1","title":"Improving prediction of heavy rainfall in the Mediterranean with Neural\n  Networks using both observation and Numerical Weather Prediction data","summary":"Forecasting Heavy Precipitation Events (HPE) in the Mediterranean is crucial\nbut challenging due to the complexity of the processes involved. In this\ncontext, Artificial Intelligence methods have recently proven to be competitive\nwith state-of-the-art Numerical Weather Prediction (NWP). This work focuses on\nimproving the prediction of the occurrence of HPE over periods from 1 h to 24 h\nbased on Neural Network (NN) models. The proposed method uses both\nground-station observations and data from M\\'et\\'eo France's Arome and Arpege\nNWP models, on two regions with oceanic and Mediterranean climates for the\nperiod 2016-2018. The verification metric is the Peirce Skill Score. Results\nshow that the NN model using only observations or NWP data performs better for\nshorter and longer rainfall accumulation period respectively. In contrast, a\nhybrid method combining both observations and NWP data offers the best\nperformance and remains stable with the rainfall accumulation period. The\nhybrid method also improves the performance in predicting increasingly intense\nrainfall, from the 5% to the 0.1% rarest events. The choice of the loss\nfunction is found to be an important aspect of this work, where only balanced\nloss functions provide results insensitive to rare event frequency. Finally,\nthe hybrid method is particularly well suited for the prediction of HPE in the\nMediterranean climate, especially during the fall season, period during which\nmost HPE occur.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-03-31T15:33:35Z"}
{"aid":"http://arxiv.org/abs/2503.24217v1","title":"Finite groups with few character values that are not character degrees","summary":"Let $ G $ be a finite group and $ \\chi \\in \\mathrm{Irr}(G) $. Define $\n\\mathrm{cv}(G)=\\{\\chi(g)\\mid \\chi \\in \\mathrm{Irr}(G), g\\in G \\} $, $\n\\mathrm{cv}(\\chi)=\\{\\chi(g)\\mid g\\in G \\} $ and denote $ \\mathrm{dl}(G) $ by\nthe derived length of $ G $. In the 1990s Berkovich, Chillag and Zhmud\ndescribed groups $ G $ in which $ |\\mathrm{cv}(\\chi)|=3 $ for every non-linear\n$ \\chi \\in \\mathrm{Irr}(G) $ and their results show that $ G $ is solvable.\nThey also considered groups in which $ |\\mathrm{cv}(\\chi)|=4 $ for some\nnon-linear $ \\chi \\in \\mathrm{Irr}(G) $. Continuing with their work, in this\narticle, we prove that if $ |\\mathrm{cv}(\\chi)|\\leqslant 4 $ for every\nnon-linear $ \\chi \\in \\mathrm{Irr}(G) $, then $ G $ is solvable. We also\nconsidered groups $ G $ such that $ |\\mathrm{cv}(G)\\setminus \\mathrm{cd}(G)|=2\n$. T. Sakurai classified these groups in the case when $ |\\mathrm{cd}(G)|=2 $.\nWe show that $ G $ is solvable and we classify groups $ G $ when $\n|\\mathrm{cd}(G)|\\leqslant 4 $ or $ \\mathrm{dl}(G)\\leqslant 3 $. It is\ninteresting to note that these groups are such that $\n|\\mathrm{cv}(\\chi)|\\leqslant 4 $ for all $ \\chi \\in \\mathrm{Irr}(G) $. Lastly,\nwe consider finite groups $ G $ with $ |\\mathrm{cv}(G)\\setminus\n\\mathrm{cd}(G)|=3 $. For nilpotent groups, we obtain a characterization which\nis also connected to the work of Berkovich, Chillag and Zhmud. For\nnon-nilpotent groups, we obtain the structure of $ G $ when $ \\mathrm{dl}(G)=2\n$.","main_category":"math.GR","categories":"math.GR","published":"2025-03-31T15:35:23Z"}
{"aid":"http://arxiv.org/abs/2503.24219v1","title":"MB-ORES: A Multi-Branch Object Reasoner for Visual Grounding in Remote\n  Sensing","summary":"We propose a unified framework that integrates object detection (OD) and\nvisual grounding (VG) for remote sensing (RS) imagery. To support conventional\nOD and establish an intuitive prior for VG task, we fine-tune an open-set\nobject detector using referring expression data, framing it as a partially\nsupervised OD task. In the first stage, we construct a graph representation of\neach image, comprising object queries, class embeddings, and proposal\nlocations. Then, our task-aware architecture processes this graph to perform\nthe VG task. The model consists of: (i) a multi-branch network that integrates\nspatial, visual, and categorical features to generate task-aware proposals, and\n(ii) an object reasoning network that assigns probabilities across proposals,\nfollowed by a soft selection mechanism for final referring object localization.\nOur model demonstrates superior performance on the OPT-RSVG and DIOR-RSVG\ndatasets, achieving significant improvements over state-of-the-art methods\nwhile retaining classical OD capabilities. The code will be available in our\nrepository: \\url{https://github.com/rd20karim/MB-ORES}.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG,cs.MM","published":"2025-03-31T15:36:41Z"}
{"aid":"http://arxiv.org/abs/2503.24226v1","title":"Asymptotic Freedom and Finite-size Scaling of Two-dimensional Classical\n  Heisenberg Model","summary":"The classical Heisenberg model is one of the most fundamental models in\nstatistical and condensed matter physics. Extensive theoretical and numerical\nstudies suggest that, in two dimensions, this model does not exhibit a\nfinite-temperature phase transition but instead manifests asymptotic freedom.\nHowever, some research has also proposed the possibility of a\nBerezinskii-Kosterlitz-Thouless (BKT) phase transition over the years. In this\nstudy, we revisit the classical two-dimensional (2D) Heisenberg model through\nlarge-scale simulations with linear system sizes up to $L=16384$. Our\nMonte-Carlo data, without any extrapolation, clearly reveal an exponential\ndivergence of the correlation length $\\xi$ as a function of inverse temperature\n$\\beta$, a hallmark of asymptotic freedom. Moreover, extrapolating $\\xi$ to the\nthermodynamic limit in the low-temperature regime achieves close agreement with\nthe three-loop perturbative calculations. We further propose a finite-size\nscaling (FSS) ansatz for $\\xi$, demonstrating that the pseudo-critical point\n$\\beta_L$ diverges logarithmically with $L$. The thermodynamic and finite-size\nscaling behaviors of the magnetic susceptibility $\\chi$ are also investigated\nand corroborate the prediction of asymptotic freedom. Our work provides solid\nevidence for asymptotic freedom in the 2D Heisenberg model and advances\nunderstanding of finite-size scaling in such systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T15:39:13Z"}
{"aid":"http://arxiv.org/abs/2503.24227v1","title":"Ambient and high pressure studies of structural, electronic and magnetic\n  properties of EuZn$_2$P$_2$ single crystal","summary":"A thorough study of EuZn$_2$P$_2$ single crystals, which were grown from Sn\nflux, was performed using both bulk (heat capacity, ac susceptibility, dc\nmagnetization, electrical resistivitivity, magnetoresistance) and microscopic\n(M\\\"ossbauer spectroscopy) techniques. Electrical resistance and magnetic\nsusceptibility were measured also under high pressure conditions (up to 19 GPa\nand 9.5 GPa, respectively). Further insight into electronic properties and\nphonons is provided by ab initio calculations. The results indicate that\nEuZn$_2$P$_2$ is an antiferromagnet with strong Eu-Eu exchange coupling of\nferromagnetic type within the basal plane and weaker antiferromagnetic\ninteraction along the c axis. The Eu magnetic moments are tilted from the basal\nplane. Hydrostatic pressure strongly affects both magnetic (increase of the\nN\\'eel temperature) and electronic (suppression of the band gap and semi\nmetallic behavior) properties, indicating a strong interplay of structure with\nmagnetic and electronic degrees of freedom.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T15:40:30Z"}
{"aid":"http://arxiv.org/abs/2503.24236v1","title":"Estimating a graph's spectrum via random Kirchhoff forests","summary":"Exact eigendecomposition of large matrices is very expensive, and it is\npractically impossible to compute exact eigenvalues. Instead, one may set a\nmore modest goal of approaching the empirical distribution of the eigenvalues,\nrecovering the overall shape of the eigenspectrum. Current approaches to\nspectral estimation typically work with \\emph{moments} of the spectral\ndistribution. These moments are first estimated using Monte Carlo trace\nestimators, then the estimates are combined to approximate the spectral\ndensity. In this article we show how \\emph{Kirchhoff forests}, which are random\nforests on graphs, can be used to estimate certain non-linear moments of very\nlarge graph Laplacians. We show how to combine these moments into an estimate\nof the spectral density. If the estimate's desired precision isn't too high,\nour approach paves the way to the estimation of a graph's spectrum in time\nsublinear in the number of links.","main_category":"stat.CO","categories":"stat.CO,math.ST,stat.TH","published":"2025-03-31T15:47:55Z"}
{"aid":"http://arxiv.org/abs/2503.24238v1","title":"PhD Thesis: Shifted Contact Structures on Differentiable Stacks","summary":"This thesis focuses on developing \"stacky\" versions of contact structures,\nextending the classical notion of contact structures on manifolds. A fruitful\napproach is to study contact structures using line bundle-valued $1$-forms.\nSpecifically, we introduce the notions of $0$ and $+1$-shifted contact\nstructures on Lie groupoids. To define the kernel of a line bundle-valued\n$1$-form $\\theta$ on a Lie groupoid, we draw inspiration from the concept of\nthe homotopy kernel in Homological Algebra. That kernel is essentially given by\na representation up to homotopy (RUTH). Similarly, the curvature is described\nby a specific RUTH morphism. Both the definitions are motivated by the\nSymplectic-to-Contact Dictionary, which establishes a relationship between\nSymplectic and Contact Geometry. Examples of $0$-shifted contact structures can\nbe found in contact structures on orbifolds, while examples of $+1$-shifted\ncontact structures include the prequantization of $+1$-shifted symplectic\nstructures and the integration of Dirac-Jacobi structures.","main_category":"math.DG","categories":"math.DG,math-ph,math.MP,math.SG","published":"2025-03-31T15:52:35Z"}
{"aid":"http://arxiv.org/abs/2503.24239v1","title":"An alternative approach in the generalized Chaplygin gas model in higher\n  dimensional space-time","summary":"In the paper, we have presented a higher-dimensional cosmological model with\na generalized Chaplygin-type gas to explain the recent acceleration of the\nuniverse. Dimensional reduction is feasible in this model, and our solutions\nare general, as they recover all known results of $4D$ Chaplygin-driven\ncosmology when $d =0$. Using Hubble-$57$ data obtained through the differential\nage method (DA), the best fit curves are drawn and estimated observational\nconstraints of the model parameters. A note worthy aspect of the model is that\nthe resulting field equation is highly nonlinear with respect to the scale\nfactor. This nonlinearity allows us to describe both dust-dominated and\naccelerating universes, though only in extremal cases. We obtain solutions of\nthe non-linear field equations which are new and interesting. We have adopted a\nfirst-order approximation of the key equation, which enabled us to derive an\nexact, time-dependent solution for the scale factor. The higher dimensional\ncosmological model is found to converge to a $\\Lambda$CDM model for a\nlarge-scale factor, capturing the desired feature of an acceleration flip. We\nalso explore the evolution of the deceleration parameter, effective EoS, jerk\nparameter, etc., both analytically and graphically. The Chaplygin gas parameter\n$\\alpha$ being significantly less than unity, apparently the present model does\nnot support pure Chaplygin gas model ($\\alpha = 1$). However, the lower value\nis consistent with our analysis, suggesting that smaller values of $\\alpha$ are\nexpected at the later stage of the universe.","main_category":"gr-qc","categories":"gr-qc","published":"2025-03-31T15:53:24Z"}
{"aid":"http://arxiv.org/abs/2503.24242v1","title":"Orlando's flask: detection of a lost-and-found valley on the Moon","summary":"High angular resolution holds the key to extending our knowledge in several\ndomains of astronomical research. In addition to the development of new\ninstruments, advancements in post-processing algorithms can enhance the\nperformances attainable in an observation, turning archival observations into a\ntreasure. We developed a machine-learning tool, named zoom-in, that is able to\nimprove the angular resolution of an astronomical image by a factor of $\\sim\n100$ by optimally recombining short-cadence sequences of images. After training\nour model on real-life photographs, we tested our method on archival images of\nthe Moon taken through ESO instruments. We were able to achieve a remarkable\nspatial resolution of $\\sim 1$ m of the lunar surface. While analyzing one of\nthe fields from the sample, we discovered structures of clear anthropic origin\ninside the Aristarchus crater. The features appear to be consistent with\nancient ruins of cities and castles. A thorough analysis of the relevant\nliterature allowed us to conclude that this valley corresponds to the one\ndescribed in Ludovico Ariosto's \"Orlando Furioso\": a place where all the items\nlost by humans gather and pile up. Analyses of the surface brightness from our\nimages, indicating an abnormally high albedo of $\\sim 0.25$, further\ncorroborate this idea suggesting a conspicuous presence of glass. We infer the\npresence of >1 billion flasks of human wits on the lunar surface, whose origin\nwe investigate in detail. We urge for a dedicated mission, astolfo, to be\ncarried out by Artemis astronauts in order to recover human wits and bring them\nback to the Earth.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-03-31T15:54:30Z"}
{"aid":"http://arxiv.org/abs/2503.24245v1","title":"Enhancing Large Language Models (LLMs) for Telecommunications using\n  Knowledge Graphs and Retrieval-Augmented Generation","summary":"Large language models (LLMs) have made significant progress in\ngeneral-purpose natural language processing tasks. However, LLMs are still\nfacing challenges when applied to domain-specific areas like\ntelecommunications, which demands specialized expertise and adaptability to\nevolving standards. This paper presents a novel framework that combines\nknowledge graph (KG) and retrieval-augmented generation (RAG) techniques to\nenhance LLM performance in the telecom domain. The framework leverages a KG to\ncapture structured, domain-specific information about network protocols,\nstandards, and other telecom-related entities, comprehensively representing\ntheir relationships. By integrating KG with RAG, LLMs can dynamically access\nand utilize the most relevant and up-to-date knowledge during response\ngeneration. This hybrid approach bridges the gap between structured knowledge\nrepresentation and the generative capabilities of LLMs, significantly enhancing\naccuracy, adaptability, and domain-specific comprehension. Our results\ndemonstrate the effectiveness of the KG-RAG framework in addressing complex\ntechnical queries with precision. The proposed KG-RAG model attained an\naccuracy of 88% for question answering tasks on a frequently used\ntelecom-specific dataset, compared to 82% for the RAG-only and 48% for the\nLLM-only approaches.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T15:58:08Z"}
{"aid":"http://arxiv.org/abs/2503.24250v1","title":"A possibility for grand unification and non-Higgs mass generation in a\n  Nambu-Jona-Lasinio-like theory of fermions interacting with current metric\n  field","summary":"Grand unification possibilities in Nambu-Jona-Lasinio-like models are\nstudied. To address the problem of vector boson masses and nonrenormalizability\nof the theory, algebraic formalism encompassing the effective action,\nSchwinger-Keldysh path integral, and Bogoliubov-Parasiuk-Hepp-Zimmerman\nrenormalization is constructed. A new NJL-like model: the theory of current\nmetric field interacting with fermions is proposed. Bosonization in this model\ncan produce massless vector bosons under certain conditions which makes it a\ncandidate grand unified theory. Both Higgs and non-Higgs effects can contribute\nto particle masses.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-03-31T16:01:32Z"}
{"aid":"http://arxiv.org/abs/2503.24257v1","title":"Mathematical foundations of information economics","summary":"The state of economic theory and accumulated facts from the different\nbranches of the economic science require to analyze the concept of the\ndescription of economy systems. The economic reality generates the problems the\nsolution of that is only possible by a new paradigm of the description of\neconomy system. The classical mathematical economics is based on a notion of\nthe rational consumer choice generated by a certain preference relation on some\nset of goods a consumer wanted and the concept of maximization of the firm\nprofit. The sense of the notion of the ratio- nal consumer choice is that it is\ndetermined by a certain utility function, defining the choice of a consumer by\nmaximization of it on a certain budget set of goods. More- over, choices of\nconsumers are independent. In the reality choices of consumers are not\nindependent because they depend on the firms supply. Except the firms supply,\nthe consumer choice is also determined by information about the state of the\neconomy system that the consumer has and respectively eval- uates at the moment\nof the choice. In turn, the firms supply is made on the basis of needs of the\nconsumers and their buying power. By information about the state of the economy\nsystem we understand a certain information about the equilibrium price vector\nand productive processes realized in the economy system under the equilibrium\nprice vector.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-03-31T16:05:39Z"}
{"aid":"http://arxiv.org/abs/2503.24259v1","title":"Advances in Continual Graph Learning for Anti-Money Laundering Systems:\n  A Comprehensive Review","summary":"Financial institutions are required by regulation to report suspicious\nfinancial transactions related to money laundering. Therefore, they need to\nconstantly monitor vast amounts of incoming and outgoing transactions. A\nparticular challenge in detecting money laundering is that money launderers\ncontinuously adapt their tactics to evade detection. Hence, detection methods\nneed constant fine-tuning. Traditional machine learning models suffer from\ncatastrophic forgetting when fine-tuning the model on new data, thereby\nlimiting their effectiveness in dynamic environments. Continual learning\nmethods may address this issue and enhance current anti-money laundering (AML)\npractices, by allowing models to incorporate new information while retaining\nprior knowledge. Research on continual graph learning for AML, however, is\nstill scarce. In this review, we critically evaluate state-of-the-art continual\ngraph learning approaches for AML applications. We categorise methods into\nreplay-based, regularization-based, and architecture-based strategies within\nthe graph neural network (GNN) framework, and we provide in-depth experimental\nevaluations on both synthetic and real-world AML data sets that showcase the\neffect of the different hyperparameters. Our analysis demonstrates that\ncontinual learning improves model adaptability and robustness in the face of\nextreme class imbalances and evolving fraud patterns. Finally, we outline key\nchallenges and propose directions for future research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T16:06:47Z"}
{"aid":"http://arxiv.org/abs/2503.24261v1","title":"Cell divisions both challenge and refine tissue boundaries in the\n  Drosophila embryo","summary":"Tissue boundaries pattern embryos, suppress tumours, and provide directional\ncues. Tissue boundaries are associated with supracellular cables formed by\nactin and the molecular motor non-muscle myosin II. Actomyosin cables generate\ntension that prevents cell mixing. Whether other cellular behaviours contribute\nto the formation of linear interfaces between cell populations remains unclear.\nIn the Drosophila embryo, an actomyosin-based boundary separates the ectoderm\nfrom the mesectoderm, a group of neuronal and glial progenitors. Mathematical\nmodelling predicted that cell divisions in the ectoderm challenge the\nmesectoderm-ectoderm (ME) boundary. Consistent with this, suppressing ectoderm\ncell divisions in vivo prevented cell mixing across the ME boundary when\nactomyosin-based tension was lost. Our mathematical model also predicted that\ncell divisions sharpen the ME boundary by reducing tension and increasing cell\nmotility in the ectoderm. We found that inhibiting ectoderm divisions in vivo\nreduced boundary linearity. Using laser ablation and cell tracking, we\ndemonstrated that cell divisions reduced junctional tension and increased cell\nmovement in the ectoderm. Together, our results reveal that cell divisions\nfacilitate cellular rearrangements to increase fluidity in a novel mechanism\nfor boundary refinement.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-03-31T16:07:57Z"}
{"aid":"http://arxiv.org/abs/2503.24273v1","title":"Generating Mitigations for Downstream Projects to Neutralize Upstream\n  Library Vulnerability","summary":"Third-party libraries are essential in software development as they prevent\nthe need for developers to recreate existing functionalities. However,\nvulnerabilities within these libraries pose significant risks to dependent\nprojects. Upgrading dependencies to secure versions is not feasible to\nneutralize vulnerabilities without patches or in projects with specific version\nrequirements. Moreover, repairing the vulnerability proves challenging when the\nsource code of the library is inaccessible. Both the state-of-the-art automatic\nvulnerability repair and automatic program repair methods fail to address this\nissue. Therefore, mitigating library vulnerabilities without source code and\navailable patches is crucial for a swift response to potential security\nattacks. Existing tools encounter challenges concerning generalizability and\nfunctional security. In this study, we introduce LUMEN to mitigate library\nvulnerabilities in impacted projects. Upon disclosing a vulnerability, we\nretrieve existing workarounds to gather a resembling mitigation strategy. In\ncases where a resembling strategy is absent, we propose type-based strategies\nbased on the vulnerability reproducing behavior and extract essential\ninformation from the vulnerability report to guide mitigation generation. Our\nassessment of LUMEN spans 121 impacted functions of 40 vulnerabilities,\nsuccessfully mitigating 70.2% of the functions, which substantially outperforms\nour baseline in neutralizing vulnerabilities without functionality loss.\nAdditionally, we conduct an ablation study to validate the rationale behind our\nresembling strategies and type-based strategies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-31T16:20:29Z"}
{"aid":"http://arxiv.org/abs/2503.24275v1","title":"Davenport-Heilbronn Function Ratio Properties and Non-Trivial Zeros\n  Study","summary":"This paper systematically investigates the analytic properties of the ratio\n$f(s)/f(1-s) = X(s)$ based on the Davenport-Heilbronn functional equation $f(s)\n= X(s)f(1-s)$. We propose a novel method to analyze the distribution of\nnon-trivial zeros through the monotonicity of the ratio $|f(s)/f(1-s)|$.\nRigorously proving that non-trivial zeros can only lie on the critical line\n$\\sigma=1/2$, we highlight two groundbreaking findings: 1. Contradiction of\nOff-Critical Zeros: Numerical \"exceptional zeros\" (e.g., Spira, 1994) violate\nthe theoretical threshold $\\kappa=1.21164$ and conflict with the monotonicity\nconstraint of $|X(s)|=1$. 2. Essential Difference Between Approximate and\nStrict Zeros: Points satisfying $f(s) \\to 0$ do not constitute strict zeros\nunless verified by analyticity. This work provides a new perspective for\nstudying zero distributions of $L$-functions related to the Riemann Hypothesis.","main_category":"math.NT","categories":"math.NT,math.AP","published":"2025-03-31T16:21:38Z"}
{"aid":"http://arxiv.org/abs/2503.24284v1","title":"Value of Information-based Deceptive Path Planning Under Adversarial\n  Interventions","summary":"Existing methods for deceptive path planning (DPP) address the problem of\ndesigning paths that conceal their true goal from a passive, external observer.\nSuch methods do not apply to problems where the observer has the ability to\nperform adversarial interventions to impede the path planning agent. In this\npaper, we propose a novel Markov decision process (MDP)-based model for the DPP\nproblem under adversarial interventions and develop new value of information\n(VoI) objectives to guide the design of DPP policies. Using the VoI objectives\nwe propose, path planning agents deceive the adversarial observer into choosing\nsuboptimal interventions by selecting trajectories that are of low\ninformational value to the observer. Leveraging connections to the linear\nprogramming theory for MDPs, we derive computationally efficient solution\nmethods for synthesizing policies for performing DPP under adversarial\ninterventions. In our experiments, we illustrate the effectiveness of the\nproposed solution method in achieving deceptiveness under adversarial\ninterventions and demonstrate the superior performance of our approach to both\nexisting DPP methods and conservative path planning approaches on illustrative\ngridworld problems.","main_category":"cs.LG","categories":"cs.LG,cs.AI,math.OC","published":"2025-03-31T16:31:29Z"}
{"aid":"http://arxiv.org/abs/2503.24290v1","title":"Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement\n  Learning on the Base Model","summary":"We introduce Open-Reasoner-Zero, the first open source implementation of\nlarge-scale reasoning-oriented RL training focusing on scalability, simplicity\nand accessibility. Through extensive experiments, we demonstrate that a\nminimalist approach, vanilla PPO with GAE ($\\lambda=1$, $\\gamma=1$) and\nstraightforward rule-based rewards, without any KL regularization, is\nsufficient to scale up both response length and benchmark performance, similar\nto the phenomenon observed in DeepSeek-R1-Zero. Using the same base model as\nDeepSeek-R1-Zero-Qwen-32B, our implementation achieves superior performance on\nAIME2024, MATH500, and the GPQA Diamond benchmark while demonstrating\nremarkable efficiency -- requiring only a tenth of the training steps, compared\nto DeepSeek-R1-Zero pipeline. In the spirit of open source, we release our\nsource code, parameter settings, training data, and model weights across\nvarious sizes.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-03-31T16:36:05Z"}
{"aid":"http://arxiv.org/abs/2503.24294v1","title":"Nonlinear-elasticity models with surface energy","summary":"Soft solids with surface energy exhibit complex mechanical behavior,\nnecessitating advanced constitutive models to capture the interplay between\nbulk and surface mechanics. This interplay has profound implications for\nmaterial design and emerging technologies. In this work, we set up variational\nmodels for bulk-surface elasticity and explore a novel class of\nsurface-polyconvex constitutive models that account for surface energy while\nensuring the existence of minimizers. These models are implemented within a\nfinite element framework and validated through benchmark problems and\napplications, including, e.g., the liquid bridge problem and the\nRayleigh-Plateau instability, for which the surface energy plays the dominant\nrole. The results demonstrate the ability of surface-polyconvex models to\naccurately capture surface-driven phenomena, establishing them as a powerful\ntool for advancing the mechanics of soft materials in both engineering and\nbiological applications.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-03-31T16:41:37Z"}
{"aid":"http://arxiv.org/abs/2503.24299v1","title":"Shape Expressions with Inheritance","summary":"We formally introduce an inheritance mechanism for the Shape Expressions\nlanguage (ShEx). It is inspired by inheritance in object-oriented programming\nlanguages, and provides similar advantages such as reuse, modularity, and more\nflexible data modelling. Using an example, we explain the main features of the\ninheritance mechanism. We present its syntax and formal semantics. The\nsemantics is an extension of the semantics of ShEx 2.1. It also directly yields\na validation algorithm as an extension of the previous ShEx validation\nalgorithms, while maintaining the same algorithmic complexity.","main_category":"cs.DB","categories":"cs.DB,cs.AI","published":"2025-03-31T16:42:44Z"}
{"aid":"http://arxiv.org/abs/2503.24302v1","title":"Synergy of Doob Transformation and Montroll Defect Theory for Random\n  Walks in External Potentials","summary":"We present a systematic method for constructing stochastic processes by\nmodifying simpler, analytically solvable random walks on discrete lattices. Our\nframework integrates the Doob $h$-transformation with the Montroll defect\ntheory, overcoming the strict constraints associated with each method alone. By\ncombining these two approaches, we map random walks in simple potentials onto\nprocesses involving more general external potentials and metastable states.\nExplicit analytical expressions relate the transformed process to the original\none, facilitating direct investigation of exponential decay rates and\nadditional dynamical modes. As an illustrative example, we demonstrate our\nmethod by analyzing a random walker in a linear potential modified to include a\nmetastable state, revealing distinct exponential decay regimes relevant to\nescape dynamics.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T16:47:14Z"}
{"aid":"http://arxiv.org/abs/2503.24307v1","title":"A Systematic Evaluation of LLM Strategies for Mental Health Text\n  Analysis: Fine-tuning vs. Prompt Engineering vs. RAG","summary":"This study presents a systematic comparison of three approaches for the\nanalysis of mental health text using large language models (LLMs): prompt\nengineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA\n3, we evaluate these approaches on emotion classification and mental health\ncondition detection tasks across two datasets. Fine-tuning achieves the highest\naccuracy (91% for emotion classification, 80% for mental health conditions) but\nrequires substantial computational resources and large training sets, while\nprompt engineering and RAG offer more flexible deployment with moderate\nperformance (40-68% accuracy). Our findings provide practical insights for\nimplementing LLM-based solutions in mental health applications, highlighting\nthe trade-offs between accuracy, computational requirements, and deployment\nflexibility.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-03-31T16:54:04Z"}
{"aid":"http://arxiv.org/abs/2503.24317v1","title":"Thermodynamic Features of a Heat Engine Coupled with Exponentially\n  Decreasing Temperature Across the Reaction Coordinate, as well as\n  Perspectives on Nonequilibrium Thermodynamics","summary":"In this study, we advance the understanding of non-equilibrium systems by\nderiving thermodynamic relations for a heat engine operating under an\nexponentially decreasing temperature profile. Such thermal configurations\nclosely mimic spatially localized heating such as laser-induced thermal\ngradients. Using exact analytical solutions, we show that this arrangement\nresults in significantly higher velocity, entropy production, and extraction\nrates than piecewise thermal profiles, while exhibiting reduced irreversibility\nand complexity relative to linear or quadratic gradients. We further examine\nthe thermodynamic behavior of the Brownian particles in the networks. Our study\nreveals that the velocity and entropy production rates remain independent of\nnetwork size; on the contrary, extensive quantities such as total entropy\ndepend on the number of microstates. Additionally, we show that a Brownian\nparticle in a ratchet potential with spatially varying temperature achieves\ndirected motion, even without external forces driven by solely thermal\nasymmetry. These findings highlight the critical role of temperature asymmetry\nin controlling the transport processes and optimizing the particle dynamics.\nThis in turn will have promising applications in microfluidic devices and\nnanoscale sensors. Finally, we explore the influence of the system parameters\non the efficiency and performance of the heat engine. The exponential\ntemperature profiles enable faster velocities while simultaneously exhibiting\nhigher efficiency compared with other thermal arrangements. Moreover, by\naddressing key questions on entropy production, we provide insights into the\ntransition between nonequilibrium and equilibrium systems and contribute tools\nfor optimizing energy-efficient systems in both natural and engineered\nsettings.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T17:07:01Z"}
{"aid":"http://arxiv.org/abs/2503.24318v1","title":"Quantum Conference Key Agreement with Classical Advantage Distillation","summary":"In this work, we prove security of a quantum conference key agreement (QCKA)\nprotocol augmented with a classical advantage distillation (CAD) protocol. We\nderive a proof of security, in the finite key setting, that is able to bound\nthe secure key rate for any general, coherent, attack. We evaluate the\nperformance of the system, showing our result can improve the noise tolerance\nof the protocol in some, but not all, scenarios.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:07:36Z"}
{"aid":"http://arxiv.org/abs/2503.24319v1","title":"Resolving the baryon assymmetry with RATS","summary":"Current leading theories of physics such as the Big Bang, the standard model\nof particle physics, and general relativity suggest that the universe should\ncontain an equal amount of matter and antimatter. Yet observations have found a\ndisproportionately large amount of matter, a phenomenon known as the baryon\nassymmetry problem. Since century-old established theories are traditionally\nimpossible to refute, the only possible explanation is that the remaining\nantimatter is hidden in plain sight and remains to be observed. We propose the\nexistence of anti-stars to solve the baryon assymetry in our new Reasonable\nAntimatter Theory of Stars (RATS). In this context, the RATS will create a\nframework to resolve the traditional tension between observers and theorists,\nand thus contribute to the peaceful and collaborative spirit of astronomy. Our\nmethod is the firing of neurons in our brains, typically known as a thought\nexperiment. We still have no idea why or how this works, but it must be good\nbecause most of science was created this way. Our results are the result of our\nmethods, which result in some text and the resulting conclusions. In order to\nencourage the reader to reach the end of this short paper, we do not want to\nspoil the conclusions here. Instead, the conclusions will conclude the paper.","main_category":"physics.pop-ph","categories":"physics.pop-ph,astro-ph.CO,astro-ph.SR","published":"2025-03-31T17:07:37Z"}
{"aid":"http://arxiv.org/abs/2503.24320v1","title":"Can Test-Time Scaling Improve World Foundation Model?","summary":"World foundation models, which simulate the physical world by predicting\nfuture states from current observations and inputs, have become central to many\napplications in physical intelligence, including autonomous driving and\nrobotics. However, these models require substantial computational resources for\npretraining and are further constrained by available data during post-training.\nAs such, scaling computation at test time emerges as both a critical and\npractical alternative to traditional model enlargement or re-training. In this\nwork, we introduce SWIFT, a test-time scaling framework tailored for WFMs.\nSWIFT integrates our extensible WFM evaluation toolkit with process-level\ninference strategies, including fast tokenization, probability-based Top-K\npruning, and efficient beam search. Empirical results on the COSMOS model\ndemonstrate that test-time scaling exists even in a compute-optimal way. Our\nfindings reveal that test-time scaling laws hold for WFMs and that SWIFT\nprovides a scalable and effective pathway for improving WFM inference without\nretraining or increasing model size. The code is available at\nhttps://github.com/Mia-Cong/SWIFT.git.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:07:37Z"}
{"aid":"http://arxiv.org/abs/2503.24321v1","title":"Sample-Optimal Private Regression in Polynomial Time","summary":"We consider the task of privately obtaining prediction error guarantees in\nordinary least-squares regression problems with Gaussian covariates (with\nunknown covariance structure). We provide the first sample-optimal polynomial\ntime algorithm for this task under both pure and approximate differential\nprivacy. We show that any improvement to the sample complexity of our algorithm\nwould violate either statistical-query or information-theoretic lower bounds.\nAdditionally, our algorithm is robust to a small fraction of arbitrary outliers\nand achieves optimal error rates as a function of the fraction of outliers. In\ncontrast, all prior efficient algorithms either incurred sample complexities\nwith sub-optimal dimension dependence, scaling with the condition number of the\ncovariates, or obtained a polynomially worse dependence on the privacy\nparameters.\n  Our technical contributions are two-fold: first, we leverage resilience\nguarantees of Gaussians within the sum-of-squares framework. As a consequence,\nwe obtain efficient sum-of-squares algorithms for regression with optimal\nrobustness rates and sample complexity. Second, we generalize the recent\nrobustness-to-privacy framework [HKMN23, (arXiv:2212.05015)] to account for the\ngeometry induced by the covariance of the input samples. This framework\ncrucially relies on the robust estimators to be sum-of-squares algorithms, and\ncombining the two steps yields a sample-optimal private regression algorithm.\nWe believe our techniques are of independent interest, and we demonstrate this\nby obtaining an efficient algorithm for covariance-aware mean estimation, with\nan optimal dependence on the privacy parameters.","main_category":"cs.DS","categories":"cs.DS,cs.IT,cs.LG,math.IT,stat.ML","published":"2025-03-31T17:08:12Z"}
{"aid":"http://arxiv.org/abs/2503.24341v1","title":"Chemically Tuning Room Temperature Pulsed Optically Detected Magnetic\n  Resonance","summary":"Optical detection of magnetic resonance enables spin-based quantum sensing\nwith high spatial resolution and sensitivity-even at room temperature-as\nexemplified by solid-state defects. Molecular systems provide a complementary,\nchemically tunable, platform for room-temperature optically detected magnetic\nresonance (ODMR)-based quantum sensing. A critical parameter governing sensing\nsensitivity is the optical contrast-i.e., the difference in emission between\ntwo spin states. In state-of-the-art solid-state defects such as the\nnitrogen-vacancy center in diamond, this contrast is approximately 30%. Here,\ncapitalizing on chemical tunability, we show that room-temperature ODMR\ncontrasts of 40% can be achieved in molecules. Using a nitrogen-substituted\nanalogue of pentacene (6,13-diazapentacene), we enhance contrast compared to\npentacene and, by determining the triplet kinetics through time-dependent\npulsed ODMR, show how this arises from accelerated anisotropic intersystem\ncrossing. Furthermore, we translate high-contrast room-temperature pulsed ODMR\nto self-assembled nanocrystals. Overall, our findings highlight the synthetic\nhandles available to optically readable molecular spins and the opportunities\nto capitalize on chemical tunability for room-temperature quantum sensing.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph","published":"2025-03-31T17:25:46Z"}
{"aid":"http://arxiv.org/abs/2503.24342v1","title":"Coordinating Distributed Energy Resources with Nodal Pricing in\n  Distribution Networks: a Game-Theoretic Approach","summary":"We propose a real-time nodal pricing mechanism for cost minimization and\nvoltage control in a distribution network with autonomous distributed energy\nresources and analyze the resulting market using stochastic game theory. Unlike\nexisting methods, the proposed pricing scheme does not require device-aware\ncentralized coordination or communication between prosumers. By developing new\nsufficient conditions under which a stochastic game is a Markov potential game,\nwe show that the problem of computing an equilibrium for the proposed model is\nequivalent to solving a single-agent Markov Decision Process. These new\nconditions are general and may apply to other applications. We compute the\nequilibrium for an IEEE test system to empirically demonstrate the\neffectiveness of the pricing policy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T17:25:50Z"}
{"aid":"http://arxiv.org/abs/2503.24346v1","title":"Projections for Key Measurements in Heavy Flavour Physics","summary":"Precision studies of flavour-changing processes involving quarks and leptons\nprovide a number of ways to improve knowledge of the Standard Model and search\nfor physics beyond it. There are excellent short- and mid-term prospects for\nsignificantly improved measurements in heavy flavour physics (involving b and c\nhadrons and $\\tau$ leptons), with upgrades in progress or planned for the\nATLAS, CMS and LHCb experiments exploiting proton-proton collisions at CERN's\nLarge Hadron Collider, and for the Belle II experiment operating with\nelectron-positron collisions from the SuperKEKB accelerator in KEK. The\nexpected sensitivities that can be achieved from these experiments for a number\nof key observables are presented, highlighting the complementarity of the\ndifferent experiments and showing how the precision will improve with time.\nThis international programme in heavy flavour physics will result in\nunprecedented capability to probe this sector of the Standard Model and,\npotentially, observe imprints of physics at higher energy scales than can be\naccessed directly.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T17:32:03Z"}
{"aid":"http://arxiv.org/abs/2503.24359v1","title":"Unveiling the Fast Acceleration of AGN-Driven Winds at Kiloparsec Scales","summary":"Supermassive black holes at the centre of galaxies gain mass through\naccretion disks. Models predict that quasi-spherical winds, expelled by the\nblack hole during active accretion phases, have a key role in shaping galaxy\nevolution by regulating star formation, the distribution of metals over\nkiloparsec scales, and by sweeping ambient gas to the outskirts and beyond of\ngalaxies. Nonetheless, the mechanism driving these outflows and the amount of\nenergy exchanged between the wind and the galaxy's interstellar medium remain\nunclear. Here, we present a detailed analysis of the kinematical properties of\nwinds in a sample of nearby active galaxies using the novel kinematic tool\nMOKA3D, which takes into account the clumpy nature of the ISM. We find\nremarkable similarities among the properties of the outflows in all the\ngalaxies examined. In particular, we provide the first evidence that outflows\nexhibit a regular trend in radial velocity, initially constant or slightly\ndecreasing, followed by rapid acceleration starting at approximately 1 kpc from\nthe nucleus, despite the seemingly complex kinematics observed. The observed\nbehavior aligns with our current theoretical understanding of Active Galactic\nNuclei outflows, where a momentum-driven phase transitions to an\nenergy-conserving phase just beyond approximately 1 kpc. The constant velocity\nof the momentum-driven wind is then rapidly accelerated following the\ninefficient Compton cooling of post-shock material and the transition to energy\nconservation. The measured radial terminal velocities of the outflows are\nalways larger than the escape velocities from the host galaxies, confirming the\nkey role of outflows in shaping the galaxy properties and evolution, as a\nmanifestation of AGN feedback. Our results, only made possible by our novel\nkinematic analysis tool, are crucial to understand the origin and the powering\nmechanism of these winds.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T17:37:44Z"}
{"aid":"http://arxiv.org/abs/2503.24360v1","title":"Unique Decay Modes and Signatures of pNGB scalars in $SU(5)/SO(5)$\n  Composite Higgs Model","summary":"The nature of the Higgs boson, whether it is elementary or composite, will be\ninvestigated through precision measurements in ongoing experiments. In\ncomposite Higgs scenarios, the Higgs may manifest as a pseudo Nambu-Goldstone\nboson (pNGB) arising from a strongly interacting sector. The $SU(5)/SO(5)$\nComposite Higgs Model features a rich scalar sector, with the decay patterns of\nthe scalars being heavily influenced by how fermions are embedded in various\nrepresentations of $SU(5)$. We discuss how the mass of the pNGB scalars and\ntheir couplings depend functionally on the compositeness scale and parameters\nof the strong sector. Unique decay modes of the scalars emerge from the model\nwhen the mixing between the mass and the gauge eigenstates is non-negligible.\nWe present a comprehensive and thorough analysis of the fermiophilic and\nfermiophobic decay modes of the pNGB scalars. One of our main findings is that\nthe decay patterns of the two singly charged scalars differ significantly.\nAdditionally, one pNGB scalar decays to another on-shell pNGB scalar when the\nmasses are more than $\\sim 1$ TeV. Both these factors play a significant role\nin creating highly distinctive signatures in collider experiments. A muon\ncollider presents a promising avenue for detecting pNGB scalars with masses\ngreater than 1 TeV, particularly, in final states involving multiple jets.","main_category":"hep-ph","categories":"hep-ph","published":"2025-03-31T17:39:32Z"}
{"aid":"http://arxiv.org/abs/2503.24365v1","title":"Which LIME should I trust? Concepts, Challenges, and Solutions","summary":"As neural networks become dominant in essential systems, Explainable\nArtificial Intelligence (XAI) plays a crucial role in fostering trust and\ndetecting potential misbehavior of opaque models. LIME (Local Interpretable\nModel-agnostic Explanations) is among the most prominent model-agnostic\napproaches, generating explanations by approximating the behavior of black-box\nmodels around specific instances. Despite its popularity, LIME faces challenges\nrelated to fidelity, stability, and applicability to domain-specific problems.\nNumerous adaptations and enhancements have been proposed to address these\nissues, but the growing number of developments can be overwhelming,\ncomplicating efforts to navigate LIME-related research. To the best of our\nknowledge, this is the first survey to comprehensively explore and collect\nLIME's foundational concepts and known limitations. We categorize and compare\nits various enhancements, offering a structured taxonomy based on intermediate\nsteps and key issues. Our analysis provides a holistic overview of advancements\nin LIME, guiding future research and helping practitioners identify suitable\napproaches. Additionally, we provide a continuously updated interactive website\n(https://patrick-knab.github.io/which-lime-to-trust/), offering a concise and\naccessible overview of the survey.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T17:44:39Z"}
{"aid":"http://arxiv.org/abs/2503.24371v1","title":"Policy Gradient for LQR with Domain Randomization","summary":"Domain randomization (DR) enables sim-to-real transfer by training\ncontrollers on a distribution of simulated environments, with the goal of\nachieving robust performance in the real world. Although DR is widely used in\npractice and is often solved using simple policy gradient (PG) methods,\nunderstanding of its theoretical guarantees remains limited. Toward addressing\nthis gap, we provide the first convergence analysis of PG methods for\ndomain-randomized linear quadratic regulation (LQR). We show that PG converges\nglobally to the minimizer of a finite-sample approximation of the DR objective\nunder suitable bounds on the heterogeneity of the sampled systems. We also\nquantify the sample-complexity associated with achieving a small performance\ngap between the sample-average and population-level objectives. Additionally,\nwe propose and analyze a discount-factor annealing algorithm that obviates the\nneed for an initial jointly stabilizing controller, which may be challenging to\nfind. Empirical results support our theoretical findings and highlight\npromising directions for future work, including risk-sensitive DR formulations\nand stochastic PG algorithms.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-03-31T17:51:00Z"}
{"aid":"http://arxiv.org/abs/2503.24385v1","title":"Evolution of structure growth during dark energy domination: insights\n  from the cross-correlation of DESI galaxies with CMB lensing and galaxy\n  magnification","summary":"We use a Hybrid Effective Field Theory (HEFT) model to constrain the\nevolution of low-redshift $(z\\lesssim0.4)$ matter fluctuations by\ncross-correlating DESI Bright Galaxy Survey (BGS) legacy imaging with the\nlatest CMB lensing maps from Planck and ACT. Our tomographic BGS analysis finds\nthat the evolution and amplitude of matter fluctuations align with\nCMB-conditioned $\\Lambda$CDM predictions. When including DESI Baryon Acoustic\nOscillation (BAO) measurements we obtain $\\sigma_8 = 0.876^{+0.051}_{-0.067}$\nfrom BGS alone. Jointly analyzing BGS and Luminous Red Galaxy (LRG)\ncross-correlations with the same CMB lensing maps yields $\\sigma_8 =\n0.791\\pm0.021$. As a complementary approach we isolate the galaxy magnification\nsignal from the cross-correlation of non-overlapping BGS and LRG photometric\nredshift bins, ruling out the null-magnification hypothesis at $11\\sigma$. For\nthe first time, we constrain structure growth from the (finite-difference\ncalibrated) galaxy magnification signal and find\n$\\sigma_8=0.720\\pm0.047\\,\\,({\\rm stat.})\\pm0.050\\,\\,({\\rm sys.})$ when adopting\na linear bias model and including BAO data.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-03-31T17:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.01325v1","title":"Coarse chain recurrence, Morse graphs with finite errors, and\n  persistence of circulations","summary":"In flow control, finite energy may be injected to push out material trapped\nin the attractor and to eliminate stagnation and circulate the flow. To\ndescribe such phenomena and to give a lower bound on the energy required, we\ngeneralize the existing concepts of chain recurrence. In fact, this paper\nintroduces concepts of ``coarse chain recurrences'' and Morse graphs with\nfinite errors. Using these concepts, we describe toy models of escape from\nattracting basins and elimination of stagnation by controls using finite\nenergy, persistence of recurrent points, and singular limit behaviors where\nenergy injections go to zero. Furthermore, we construct filtrations associated\nwith dynamical systems, which indicate the persistence of circulations.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T03:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.01339v1","title":"Computing Time-varying Network Reliability using Binary Decision\n  Diagrams","summary":"Computing the reliability of a time-varying network, taking into account its\ndynamic nature, is crucial for networks that change over time, such as space\nnetworks, vehicular ad-hoc networks, and drone networks. These networks are\nmodeled using temporal graphs, in which each edge is labeled with a time\nindicating its existence at a specific point in time. The time-varying network\nreliability is defined as the probability that a data packet from the source\nvertex can reach the terminal vertex, following links with increasing time\nlabels (i.e., a journey), while taking into account the possibility of network\nlink failures. Currently, the existing method for calculating this reliability\ninvolves explicitly enumerating all possible journeys between the source and\nterminal vertices and then calculating the reliability using the sum of\ndisjoint products method. However, this method has high computational\ncomplexity. In contrast, there is an efficient algorithm that uses binary\ndecision diagrams (BDDs) to evaluate the reliability of a network whose\ntopology does not change over time. This paper presents an efficient exact\nalgorithm that utilizes BDDs for computing the time-varying network\nreliability. Experimental results show that the proposed method runs faster\nthan the existing method up to four orders of magnitude.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T03:58:50Z"}
{"aid":"http://arxiv.org/abs/2504.01345v1","title":"Breaking BERT: Gradient Attack on Twitter Sentiment Analysis for\n  Targeted Misclassification","summary":"Social media platforms like Twitter have increasingly relied on Natural\nLanguage Processing NLP techniques to analyze and understand the sentiments\nexpressed in the user generated content. One such state of the art NLP model is\nBidirectional Encoder Representations from Transformers BERT which has been\nwidely adapted in sentiment analysis. BERT is susceptible to adversarial\nattacks. This paper aims to scrutinize the inherent vulnerabilities of such\nmodels in Twitter sentiment analysis. It aims to formulate a framework for\nconstructing targeted adversarial texts capable of deceiving these models,\nwhile maintaining stealth. In contrast to conventional methodologies, such as\nImportance Reweighting, this framework core idea resides in its reliance on\ngradients to prioritize the importance of individual words within the text. It\nuses a whitebox approach to attain fine grained sensitivity, pinpointing words\nthat exert maximal influence on the classification outcome. This paper is\norganized into three interdependent phases. It starts with fine-tuning a\npre-trained BERT model on Twitter data. It then analyzes gradients of the model\nto rank words on their importance, and iteratively replaces those with feasible\ncandidates until an acceptable solution is found. Finally, it evaluates the\neffectiveness of the adversarial text against the custom trained sentiment\nclassification model. This assessment would help in gauging the capacity of the\nadversarial text to successfully subvert classification without raising any\nalarm.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-02T04:21:19Z"}
{"aid":"http://arxiv.org/abs/2504.01346v1","title":"GTR: Graph-Table-RAG for Cross-Table Question Answering","summary":"Beyond pure text, a substantial amount of knowledge is stored in tables. In\nreal-world scenarios, user questions often require retrieving answers that are\ndistributed across multiple tables. GraphRAG has recently attracted much\nattention for enhancing LLMs' reasoning capabilities by organizing external\nknowledge to address ad-hoc and complex questions, exemplifying a promising\ndirection for cross-table question answering. In this paper, to address the\ncurrent gap in available data, we first introduce a multi-table benchmark,\nMutliTableQA, comprising 60k tables and 25k user queries collected from\nreal-world sources. Then, we propose the first Graph-Table-RAG framework,\nnamely GTR, which reorganizes table corpora into a heterogeneous graph, employs\na hierarchical coarse-to-fine retrieval process to extract the most relevant\ntables, and integrates graph-aware prompting for downstream LLMs' tabular\nreasoning. Extensive experiments show that GTR exhibits superior cross-table\nquestion-answering performance while maintaining high deployment efficiency,\ndemonstrating its real-world practical applicability.","main_category":"cs.CL","categories":"cs.CL,cs.IR,cs.LG","published":"2025-04-02T04:24:41Z"}
{"aid":"http://arxiv.org/abs/2504.01347v1","title":"MEEK: Re-thinking Heterogeneous Parallel Error Detection Architecture\n  for Real-World OoO Superscalar Processors","summary":"Heterogeneous parallel error detection is an approach to achieving\nfault-tolerant processors, leveraging multiple power-efficient cores to\nre-execute software originally run on a high-performance core. Yet, its complex\ncomponents, gathering data cross-chip from many parts of the core, raise\nquestions of how to build it into commodity cores without heavy design invasion\nand extensive re-engineering.\n  We build the first full-RTL design, MEEK, into an open-source SoC, from\nmicroarchitecture and ISA to the OS and programming model. We identify and\nsolve bottlenecks and bugs overlooked in previous work, and demonstrate that\nMEEK offers microsecond-level detection capacity with affordable overheads. By\ntrading off architectural functionalities across codesigned hardware-software\nlayers, MEEK features only light changes to a mature out-of-order superscalar\ncore, simple coordinating software layers, and a few lines of operating-system\ncode. The Repo. of MEEK's source code:\nhttps://github.com/SEU-ACAL/reproduce-MEEK-DAC-25.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T04:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.01352v1","title":"Quo Vadis, HCOMP? A Review of 12 Years of Research at the Frontier of\n  Human Computation and Crowdsourcing","summary":"The field of human computation and crowdsourcing has historically studied how\ntasks can be outsourced to humans. However, many tasks previously distributed\nto human crowds can today be completed by generative AI with human-level\nabilities, and concerns about crowdworkers increasingly using language models\nto complete tasks are surfacing. These developments undermine core premises of\nthe field. In this paper, we examine the evolution of the Conference on Human\nComputation and Crowdsourcing (HCOMP) - a representative example of the field\nas one of its key venues - through the lens of Kuhn's paradigm shifts. We\nreview 12 years of research at HCOMP, mapping the evolution of HCOMP's research\ntopics and identifying significant shifts over time. Reflecting on the findings\nthrough the lens of Kuhn's paradigm shifts, we suggest that these shifts do not\nconstitute a paradigm shift. Ultimately, our analysis of gradual topic shifts\nover time, combined with data on the evident overlap with related venues,\ncontributes a data-driven perspective to the broader discussion about the\nfuture of HCOMP and the field as a whole.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-02T04:51:57Z"}
{"aid":"http://arxiv.org/abs/2504.01356v1","title":"xML-workFlow: an end-to-end explainable scikit-learn workflow for rapid\n  biomedical experimentation","summary":"Motivation: Building and iterating machine learning models is often a\nresource-intensive process. In biomedical research, scientific codebases can\nlack scalability and are not easily transferable to work beyond what they were\nintended. xML-workFlow addresses this issue by providing a rapid, robust, and\ntraceable end-to-end workflow that can be adapted to any ML project with\nminimal code rewriting.\n  Results: We show a practical, end-to-end workflow that integrates\nscikit-learn, MLflow, and SHAP. This template significantly reduces the time\nand effort required to build and iterate on ML models, addressing the common\nchallenges of scalability and reproducibility in biomedical research. Adapting\nour template may save bioinformaticians time in development and enables\nbiomedical researchers to deploy ML projects.\n  Availability and implementation: xML-workFlow is available at\nhttps://github.com/MedicalGenomicsLab/xML-workFlow.","main_category":"cs.LG","categories":"cs.LG,cs.SE","published":"2025-04-02T05:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.01362v1","title":"Connection Matrices in Macaulay2","summary":"In this article, we describe the theoretical foundations of the Macaulay2\npackage ConnectionMatrices and explain how to use it. For a left ideal in the\nWeyl algebra that is of finite holonomic rank, we implement the computation of\nthe encoded system of linear PDEs in connection form with respect to an\nelimination term order that depends on a chosen positive weight vector. We also\nimplement the gauge transformation for carrying out a change of basis over the\nfield of rational functions. We demonstrate all implemented algorithms with\nexamples.","main_category":"math.AG","categories":"math.AG,cs.SC","published":"2025-04-02T05:08:45Z"}
{"aid":"http://arxiv.org/abs/2504.01373v1","title":"UniFault: A Fault Diagnosis Foundation Model from Bearing Data","summary":"Machine fault diagnosis (FD) is a critical task for predictive maintenance,\nenabling early fault detection and preventing unexpected failures. Despite its\nimportance, existing FD models are operation-specific with limited\ngeneralization across diverse datasets. Foundation models (FM) have\ndemonstrated remarkable potential in both visual and language domains,\nachieving impressive generalization capabilities even with minimal data through\nfew-shot or zero-shot learning. However, translating these advances to FD\npresents unique hurdles. Unlike the large-scale, cohesive datasets available\nfor images and text, FD datasets are typically smaller and more heterogeneous,\nwith significant variations in sampling frequencies and the number of channels\nacross different systems and applications. This heterogeneity complicates the\ndesign of a universal architecture capable of effectively processing such\ndiverse data while maintaining robust feature extraction and learning\ncapabilities. In this paper, we introduce UniFault, a foundation model for\nfault diagnosis that systematically addresses these issues. Specifically, the\nmodel incorporates a comprehensive data harmonization pipeline featuring two\nkey innovations. First, a unification scheme transforms multivariate inputs\ninto standardized univariate sequences while retaining local inter-channel\nrelationships. Second, a novel cross-domain temporal fusion strategy mitigates\ndistribution shifts and enriches sample diversity and count, improving the\nmodel generalization across varying conditions. UniFault is pretrained on over\n9 billion data points spanning diverse FD datasets, enabling superior few-shot\nperformance. Extensive experiments on real-world FD datasets demonstrate that\nUniFault achieves SoTA performance, setting a new benchmark for fault diagnosis\nmodels and paving the way for more scalable and robust predictive maintenance\nsolutions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T05:34:27Z"}
{"aid":"http://arxiv.org/abs/2504.01390v1","title":"Evaluating probabilities without model risk","summary":"This article presents methods for estimating extreme probabilities, beyond\nthe range of the observations. These methods are model-free and applicable to\nalmost any sample size. They are grounded in order statistics theory and have a\nwide range of applications, as they simply require the assumption of a finite\nexpectation. Even in cases when a particular risk model exists, the new methods\nprovide clarity, security and simplicity. The methodology is applicable to the\nbehavior of financial markets, and the results may be compared to those\nprovided by extreme value theory.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-02T06:10:57Z"}
{"aid":"http://arxiv.org/abs/2504.01401v1","title":"Systematic study of Î±-decay half-lives of superheavy nuclei based\n  on Coulomb and proximity potential models with temperature effects","summary":"By employing the Coulomb proximity potential model (CPPM) in conjunction with\n22 distinct proximity potential models, we investigated the temperature\ndependence and the effects of proton number and neutron number on the diffusion\nparameters that determine the {\\alpha}-decay half-lives of superheavy nuclei.\nThe results indicate that the Prox.77-3 T-DEP proximity potential model yields\nthe best performance, with the lowest root mean square deviation\n({\\sigma}=0.515), reflecting a high consistency with experimental data. In\ncontrast, Bass77, AW95, Ngo80, and Guo2013 display larger deviations. The\ninclusion of temperature dependence significantly improves the accuracy of\nmodels such as Prox.77-3, Prox.77-6, and Prox.77-7. The -decay half-lives of 36\npotential superheavy nuclei were further predicted using the five most accurate\nproximity potential models and Ni's empirical formula, with the results\naligning well with experimental data. These predictions underscore the high\nreliability of the CPPM combined with proximity potential models in the\ntheoretical calculation of {\\alpha}-decay half-lives of superheavy nuclei,\noffering valuable theoretical insights for future experimental investigations\nof superheavy nuclei.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-02T06:39:48Z"}
{"aid":"http://arxiv.org/abs/2504.01424v1","title":"On the Role of Priors in Bayesian Causal Learning","summary":"In this work, we investigate causal learning of independent causal mechanisms\nfrom a Bayesian perspective. Confirming previous claims from the literature, we\nshow in a didactically accessible manner that unlabeled data (i.e., cause\nrealizations) do not improve the estimation of the parameters defining the\nmechanism. Furthermore, we observe the importance of choosing an appropriate\nprior for the cause and mechanism parameters, respectively. Specifically, we\nshow that a factorized prior results in a factorized posterior, which resonates\nwith Janzing and Sch\\\"olkopf's definition of independent causal mechanisms via\nthe Kolmogorov complexity of the involved distributions and with the concept of\nparameter independence of Heckerman et al.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T07:19:49Z"}
{"aid":"http://arxiv.org/abs/2504.01428v1","title":"MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation","summary":"Optical coherence tomography angiography (OCTA) shows its great importance in\nimaging microvascular networks by providing accurate 3D imaging of blood\nvessels, but it relies upon specialized sensors and expensive devices. For this\nreason, previous works show the potential to translate the readily available 3D\nOptical Coherence Tomography (OCT) images into 3D OCTA images. However,\nexisting OCTA translation methods directly learn the mapping from the OCT\ndomain to the OCTA domain in continuous and infinite space with guidance from\nonly a single view, i.e., the OCTA project map, resulting in suboptimal\nresults. To this end, we propose the multi-view Tri-alignment framework for OCT\nto OCTA 3D image translation in discrete and finite space, named MuTri. In the\nfirst stage, we pre-train two vector-quantized variational auto-encoder (VQ-\nVAE) by reconstructing 3D OCT and 3D OCTA data, providing semantic prior for\nsubsequent multi-view guidances. In the second stage, our multi-view\ntri-alignment facilitates another VQVAE model to learn the mapping from the OCT\ndomain to the OCTA domain in discrete and finite space. Specifically, a\ncontrastive-inspired semantic alignment is proposed to maximize the mutual\ninformation with the pre-trained models from OCT and OCTA views, to facilitate\ncodebook learning. Meanwhile, a vessel structure alignment is proposed to\nminimize the structure discrepancy with the pre-trained models from the OCTA\nproject map view, benefiting from learning the detailed vessel structure\ninformation. We also collect the first large-scale dataset, namely, OCTA2024,\nwhich contains a pair of OCT and OCTA volumes from 846 subjects.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T07:28:09Z"}
{"aid":"http://arxiv.org/abs/2504.01432v1","title":"Adaptive adequacy testing of high-dimensional factor-augmented\n  regression model","summary":"In this paper, we investigate the adequacy testing problem of\nhigh-dimensional factor-augmented regression model. Existing test procedures\nperform not well under dense alternatives. To address this critical issue, we\nintroduce a novel quadratic-type test statistic which can efficiently detect\ndense alternative hypotheses. We further propose an adaptive test procedure to\nremain powerful under both sparse and dense alternative hypotheses.\nTheoretically, under the null hypothesis, we establish the asymptotic normality\nof the proposed quadratic-type test statistic and asymptotic independence of\nthe newly introduced quadratic-type test statistic and a maximum-type test\nstatistic. We also prove that our adaptive test procedure is powerful to detect\nsignals under either sparse or dense alternative hypotheses. Simulation studies\nand an application to an FRED-MD macroeconomics dataset are carried out to\nillustrate the merits of our introduced procedures.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-02T07:34:23Z"}
{"aid":"http://arxiv.org/abs/2504.01435v1","title":"Relativistic quantum Otto heat engine using a three-level Unruh-DeWitt\n  detector","summary":"In this study, we explore a relativistic quantum Otto heat engine with a\nqutrit as the working substance interacting with a quantum scalar field in\ncurved spacetime. Unlike qubits, which extract work by simply expanding or\nshrinking a single energy gap, qutrits allow multiple energy gaps to be\nadjusted independently, enabling more versatile work extraction in the quantum\nOtto cycle. We derive a general positive work condition in terms of the\neffective temperature that each pair of energy levels perceives. Moreover, we\ndiscuss additional subtleties that are absent when using a qubit, such as the\ngeneration of coherence terms in the density matrix due to interactions.","main_category":"quant-ph","categories":"quant-ph,gr-qc","published":"2025-04-02T07:38:58Z"}
{"aid":"http://arxiv.org/abs/2504.01439v1","title":"On $\\overline{\\partial }_{b}$-harmonic maps from pseudo-Hermitian\n  manifolds to KÃ¤hler manifolds","summary":"In this paper, we consider maps from pseudo-Hermitian manifolds to K\\\"{a}hler\nmanifolds and introduce partial energy functionals for these maps.\n  First, we obtain a foliated Lichnerowicz type result on general\n  pseudo-Hermitian manifolds, which generalizes a related result on Sasakian\n  manifolds in \\cite{SSZ2013holomorphic}. Next, we investigate critical maps of\nthe partial\n  energy functionals, which are referred to as $\\overline{\\partial\n}_{b}$-harmonic maps and $\\partial _{b}$-harmonic maps. We give a foliated\nresult\n  for both $\\overline{\\partial }_{b}$- and $\\partial _{b}$-harmonic maps,\n  generalizing a foliated result of Petit \\cite{Pet2002harmonic} for harmonic\nmaps. Then we\n  are able to generalize Siu's holomorphicity result for harmonic maps\n\\cite{Siu1980rigid}\n  to the case for $\\overline{\\partial }_{b}$- and $\\partial _{b}$-harmonic\n  maps.","main_category":"math.DG","categories":"math.DG","published":"2025-04-02T07:49:49Z"}
{"aid":"http://arxiv.org/abs/2504.01467v1","title":"Causal chiral 2-form electrodynamics","summary":"Generic nonlinear theories of chiral 2-form electrodynamics allow\nsuperluminal propagation in some stationary homogeneous backgrounds and are\ntherefore acausal. We find a simple parameterisation of the subclass of causal\ntheories. By construction of the stress-energy tensor from the Hamiltonian\ndensity, we show that causality implies both the Dominant and Strong energy\nconditions. We also revisit the Perry-Schwarz formulation, clarifying aspects\nof it and of its relation to the Hamiltonian formulation.","main_category":"hep-th","categories":"hep-th","published":"2025-04-02T08:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.01477v1","title":"Online Timestamp-based Transactional Isolation Checking of Database\n  Systems (Extended Version)","summary":"Serializability (SER) and snapshot isolation (SI) are widely used\ntransactional isolation levels in database systems. The isolation checking\nproblem asks whether a given execution history of a database system satisfies a\nspecified isolation level. However, existing SER and SI checkers, whether\ntraditional black-box checkers or recent timestamp-based white-box ones,\noperate offline and require the entire history to be available to construct a\ndependency graph, making them unsuitable for continuous and ever-growing\nhistories.\n  This paper addresses online isolation checking by extending the\ntimestamp-based isolation checking approach to online settings. Specifically,\nwe design CHRONOS, an efficient timestamp-based offline SI checker. CHRONOS is\nincremental and avoids constructing a start-ordered serialization graph for the\nentire history, making it well-suited for online scenarios. We further extend\nCHRONOS into an online SI checker, AION, addressing several key challenges\nunique to online settings. Additionally, we develop AION-SER for online SER\nchecking. Experiments highlight that CHRONOS processes offline histories with\nup to one million transactions in seconds, greatly outperforming existing SI\ncheckers. Furthermore, AION and AION-SER sustain a throughput of approximately\n12K transactions per second, demonstrating their practicality for online\nisolation checking.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-02T08:30:48Z"}
{"aid":"http://arxiv.org/abs/2504.01480v1","title":"A microscopic traffic flow model on network with destination-aware V2V\n  communications and rational decision-making","summary":"In this paper we carry out a computational study of a novel microscopic\nfollow-the-leader model for traffic flow on road networks. We assume that each\ndriver has its own origin and destination, and wants to complete its journey in\nminimal time. We also assume that each driver is able to take rational\ndecisions at junctions and can change route while moving depending on the\ntraffic conditions. The main novelty of the model is that vehicles can\nautomatically and anonymously share information about their position,\ndestination, and planned path when they are close to each other within a\ncertain distance. The pieces of information acquired during the journey are\nused to optimize the route itself. In the limit case of a infinite\ncommunication range, we recover the classical Reactive User Equilibrium and\nDynamic User Equilibrium.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T08:35:37Z"}
{"aid":"http://arxiv.org/abs/2504.01481v1","title":"Identifying Obfuscated Code through Graph-Based Semantic Analysis of\n  Binary Code","summary":"Protecting sensitive program content is a critical issue in various\nsituations, ranging from legitimate use cases to unethical contexts.\nObfuscation is one of the most used techniques to ensure such protection.\nConsequently, attackers must first detect and characterize obfuscation before\nlaunching any attack against it. This paper investigates the problem of\nfunction-level obfuscation detection using graph-based approaches, comparing\nalgorithms, from elementary baselines to promising techniques like GNN (Graph\nNeural Networks), on different feature choices. We consider various obfuscation\ntypes and obfuscators, resulting in two complex datasets. Our findings\ndemonstrate that GNNs need meaningful features that capture aspects of function\nsemantics to outperform baselines. Our approach shows satisfactory results,\nespecially in a challenging 11-class classification task and in a practical\nmalware analysis example.","main_category":"cs.CR","categories":"cs.CR,cs.LG,stat.ML","published":"2025-04-02T08:36:27Z"}
{"aid":"http://arxiv.org/abs/2504.01495v1","title":"Are Autonomous Web Agents Good Testers?","summary":"Despite advances in automated testing, manual testing remains prevalent due\nto the high maintenance demands associated with test script fragility-scripts\noften break with minor changes in application structure. Recent developments in\nLarge Language Models (LLMs) offer a potential alternative by powering\nAutonomous Web Agents (AWAs) that can autonomously interact with applications.\nThese agents may serve as Autonomous Test Agents (ATAs), potentially reducing\nthe need for maintenance-heavy automated scripts by utilising natural language\ninstructions similar to those used by human testers. This paper investigates\nthe feasibility of adapting AWAs for natural language test case execution and\nhow to evaluate them. We contribute with (1) a benchmark of three offline web\napplications, and a suite of 113 manual test cases, split between passing and\nfailing cases, to evaluate and compare ATAs performance, (2) SeeAct-ATA and\npinATA, two open-source ATA implementations capable of executing test steps,\nverifying assertions and giving verdicts, and (3) comparative experiments using\nour benchmark that quantifies our ATAs effectiveness. Finally we also proceed\nto a qualitative evaluation to identify the limitations of PinATA, our best\nperforming implementation. Our findings reveal that our simple implementation,\nSeeAct-ATA, does not perform well compared to our more advanced PinATA\nimplementation when executing test cases (50% performance improvement).\nHowever, while PinATA obtains around 60% of correct verdict and up to a\npromising 94% specificity, we identify several limitations that need to be\naddressed to develop more resilient and reliable ATAs, paving the way for\nrobust, low maintenance test automation. CCS Concepts: $\\bullet$ Software and\nits engineering $\\rightarrow$ Software testing and debugging.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T08:48:01Z"}
{"aid":"http://arxiv.org/abs/2504.01496v1","title":"Entanglement and Bell Nonlocality in $Ï^+ Ï^-$ at the LHC using\n  Machine Learning for Neutrino Reconstruction","summary":"Experiments at the CERN Large Hadron Collider (LHC) have accumulated an\nunprecedented amount of data corresponding to a large variety of quantum\nstates. Although searching for new particles beyond the Standard Model of\nparticle physics remains a high priority for the LHC program, precision\nmeasurements of the physical processes predicted in the Standard Model continue\nto lead us to a deeper understanding of nature at high energies. We carry out\ndetailed simulations for the process $pp \\to \\tau^+\\tau^- X$ to perform quantum\ntomography and to measure the quantum entanglement and the Bell nonlocality of\nthe $\\tau^+\\tau^-$ two qubit state, including both statistical and systematic\nuncertainties. By using advanced machine learning techniques for neutrino\nmomentum reconstruction, we achieve precise measurements of the full spin\ndensity matrix, a critical advantage over previous studies limited by\nreconstruction challenges for missing momenta. Our analysis reveals a clear\nobservation of Bell nonlocality with high statistical significance, surpassing\n5$\\sigma$, establishing $\\tau^+ \\tau^-$ as an ideal system for quantum\ninformation studies in high-energy collisions. Given its experimental\nfeasibility and the high expected sensitivity for Bell nonlocality, we propose\nthat $\\tau^+ \\tau^-$ should be regarded as the new benchmark system for quantum\ninformation studies at the LHC, complementing and extending the insights gained\nfrom the $t\\bar{t}$ system.","main_category":"hep-ph","categories":"hep-ph,hep-ex,quant-ph","published":"2025-04-02T08:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.01497v1","title":"Acceleration via Perturbations on Low-resolution Ordinary Differential\n  Equations","summary":"Recently, the high-resolution ordinary differential equation (ODE) framework,\nwhich retains higher-order terms, has been proposed to analyze gradient-based\noptimization algorithms. Through this framework, the term $\\nabla^2\nf(X_t)\\dot{X_t}$, known as the gradient-correction term, was found to be\nessential for reducing oscillations and accelerating the convergence rate of\nfunction values. Despite the importance of this term, simply adding it to the\nlow-resolution ODE may sometimes lead to a slower convergence rate. To fully\nunderstand this phenomenon, we propose a generalized perturbed ODE and analyze\nthe role of the gradient and gradient-correction perturbation terms under both\ncontinuous-time and discrete-time settings. We demonstrate that while the\ngradient-correction perturbation is essential for obtaining accelerations, it\ncan hinder the convergence rate of function values in certain cases. However,\nthis adverse effect can be mitigated by involving an additional gradient\nperturbation term. Moreover, by conducting a comprehensive analysis, we derive\nproper choices of perturbation parameters. Numerical experiments are also\nprovided to validate our theoretical findings.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T08:50:31Z"}
{"aid":"http://arxiv.org/abs/2504.01504v1","title":"Approximate Agreement Algorithms for Byzantine Collaborative Learning","summary":"In Byzantine collaborative learning, $n$ clients in a peer-to-peer network\ncollectively learn a model without sharing their data by exchanging and\naggregating stochastic gradient estimates. Byzantine clients can prevent others\nfrom collecting identical sets of gradient estimates. The aggregation step thus\nneeds to be combined with an efficient (approximate) agreement subroutine to\nensure convergence of the training process.\n  In this work, we study the geometric median aggregation rule for Byzantine\ncollaborative learning. We show that known approaches do not provide\ntheoretical guarantees on convergence or gradient quality in the agreement\nsubroutine. To satisfy these theoretical guarantees, we present a hyperbox\nalgorithm for geometric median aggregation.\n  We practically evaluate our algorithm in both centralized and decentralized\nsettings under Byzantine attacks on non-i.i.d. data. We show that our geometric\nmedian-based approaches can tolerate sign-flip attacks better than known\nmean-based approaches from the literature.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-02T08:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.01508v1","title":"UAKNN: Label Distribution Learning via Uncertainty-Aware KNN","summary":"Label Distribution Learning (LDL) aims to characterize the polysemy of an\ninstance by building a set of descriptive degrees corresponding to the\ninstance. In recent years, researchers seek to model to obtain an accurate\nlabel distribution by using low-rank, label relations, expert experiences, and\nlabel uncertainty estimation. In general, these methods are based on algorithms\nwith parameter learning in a linear (including kernel functions) or deep\nlearning framework. However, these methods are difficult to deploy and update\nonline due to high training costs, limited scalability, and outlier\nsensitivity. To address this problem, we design a novel LDL method called\nUAKNN, which has the advantages of the KNN algorithm with the benefits of\nuncertainty modeling. In addition, we provide solutions to the dilemma of\nexisting work on extremely label distribution spaces. Extensive experiments\ndemonstrate that our method is significantly competitive on 12 benchmarks and\nthat the inference speed of the model is well-suited for industrial-level\napplications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T08:57:23Z"}
{"aid":"http://arxiv.org/abs/2504.01510v1","title":"Surface forces and frictional properties of adsorbed bio-based cationic\n  polysaccharide thin films in salted aqueous medium","summary":"Inter-surface forces mediated by polymer films are important in a range of\ntechnological and industrial situations. In cosmetics, applications such as\nhair conditioning typically rely on the adsorption of polyelectrolyte films\nonto the charged surface of hair fibers, whose contact mechanics and\ntribological properties are central in determining the final sensorial\nperceptions associated with the cosmetic treatment. A major current challenge\nto be tackled by the cosmetic industry is to design high-performance products\nemploying bio-sourced polyelectrolytes, with the aim of achieving\neco-sustainable processes and products. In this context, the present study\nfocuses on the mechanical properties of thin films obtained by adsorption from\nsolution of fungal chitosan onto negatively charged mica surfaces. We use a\nSurface Forces Apparatus allowing for the simultaneous measurement of film\nthickness and friction force as a function of the applied normal load and shear\nvelocity. We show that, in aqueous medium at an ionic strength of 40 mM,\nadsorbed films of chitosan give rise to repulsive inter-surface forces whose\nrange, comparable to the Flory radius of the macromolecules, increases with the\npolymer molecular weight. In addition, the adsorbed layers are found to behave,\nunder compressive forces, as pseudo-brushes of neutral polymers. Finally, we\nshow that under shear forces, chitosan layers exhibit a transition from a low\nto a high friction regime under increasing confinement.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T08:57:56Z"}
{"aid":"http://arxiv.org/abs/2504.01531v1","title":"DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal\n  Forecasting","summary":"Accurate predictions of spatio-temporal systems' states are crucial for tasks\nsuch as system management, control, and crisis prevention. However, the\ninherent time variance of spatio-temporal systems poses challenges to achieving\naccurate predictions whenever stationarity is not granted. To address\nnon-stationarity frameworks, we propose a Distribution and Relation Adaptive\nNetwork (DRAN) capable of dynamically adapting to relation and distribution\nchanges over time. While temporal normalization and de-normalization are\nfrequently used techniques to adapt to distribution shifts, this operation is\nnot suitable for the spatio-temporal context as temporal normalization scales\nthe time series of nodes and possibly disrupts the spatial relations among\nnodes. In order to address this problem, we develop a Spatial Factor Learner\n(SFL) module that enables the normalization and de-normalization process in\nspatio-temporal systems. To adapt to dynamic changes in spatial relationships\namong sensors, we propose a Dynamic-Static Fusion Learner (DSFL) module that\neffectively integrates features learned from both dynamic and static relations\nthrough an adaptive fusion ratio mechanism. Furthermore, we introduce a\nStochastic Learner to capture the noisy components of spatio-temporal\nrepresentations. Our approach outperforms state of the art methods in weather\nprediction and traffic flows forecasting tasks. Experimental results show that\nour SFL efficiently preserves spatial relationships across various temporal\nnormalization operations. Visualizations of the learned dynamic and static\nrelations demonstrate that DSFL can capture both local and distant\nrelationships between nodes. Moreover, ablation studies confirm the\neffectiveness of each component.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T09:18:43Z"}
{"aid":"http://arxiv.org/abs/2504.01544v1","title":"Periodic solutions of a class of second-order non-autonomous\n  differential equations","summary":"This paper investigates the dynamical behavior of periodic solutions for a\nclass of second-order non-autonomous differential equations. First, based on\nthe Lyapunov-Schmidt reduction method for finite-dimensional functions, the\ncorresponding bifurcation function is constructed, and it is proven that the\nsystem possesses at least one T-periodic solution. Second, a two-timing method\nis employed to perform perturbation analysis on the original equation. By\nseparating the fast and slow time scales, an explicit expression for the\napproximate T-periodic solution is derived. Furthermore, for the stability of\nthe system under parametric excitation, the bifurcation characteristics near\nthe first instability tongue are revealed through perturbation expansion and\neigenvalue analysis. Additionally, the Ince-Strutt stability diagram is plotted\nto illustrate the stability boundaries.","main_category":"math.CA","categories":"math.CA","published":"2025-04-02T09:33:03Z"}
{"aid":"http://arxiv.org/abs/2504.01547v1","title":"Semi-Supervised Biomedical Image Segmentation via Diffusion Models and\n  Teacher-Student Co-Training","summary":"Supervised deep learning for semantic segmentation has achieved excellent\nresults in accurately identifying anatomical and pathological structures in\nmedical images. However, it often requires large annotated training datasets,\nwhich limits its scalability in clinical settings. To address this challenge,\nsemi-supervised learning is a well-established approach that leverages both\nlabeled and unlabeled data. In this paper, we introduce a novel semi-supervised\nteacher-student framework for biomedical image segmentation, inspired by the\nrecent success of generative models. Our approach leverages denoising diffusion\nprobabilistic models (DDPMs) to generate segmentation masks by progressively\nrefining noisy inputs conditioned on the corresponding images. The teacher\nmodel is first trained in an unsupervised manner using a cycle-consistency\nconstraint based on noise-corrupted image reconstruction, enabling it to\ngenerate informative semantic masks. Subsequently, the teacher is integrated\ninto a co-training process with a twin-student network. The student learns from\nground-truth labels when available and from teacher-generated pseudo-labels\notherwise, while the teacher continuously improves its pseudo-labeling\ncapabilities. Finally, to further enhance performance, we introduce a\nmulti-round pseudo-label generation strategy that iteratively improves the\npseudo-labeling process. We evaluate our approach on multiple biomedical\nimaging benchmarks, spanning multiple imaging modalities and segmentation\ntasks. Experimental results show that our method consistently outperforms\nstate-of-the-art semi-supervised techniques, highlighting its effectiveness in\nscenarios with limited annotated data. The code to replicate our experiments\ncan be found at\nhttps://github.com/ciampluca/diffusion_semi_supervised_biomedical_image_segmentation","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T09:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.01564v1","title":"Numerical techniques for geodesic approximation in Riemaniann shape\n  optimization","summary":"Shape optimization is commonly applied in engineering to optimize shapes with\nrespect to an objective functional relying on PDE solutions. In this paper, we\nview shape optimization as optimization on Riemannian shape manifolds. We\nconsider so-called outer metrics on the diffeomorphism group to solve\nPDE-constrained shape optimization problems efficiently. Commonly, the\nnumerical solution of such problems relies on the Riemannian version of the\nsteepest descent method. One key difference between this version and the\nstandard method is that iterates are updated via geodesics or retractions. Due\nto the lack of explicit expressions for geodesics, for most of the previously\nproposed metrics, very limited progress has been made in this direction.\nLeveraging the existence of explicit expressions for the geodesic equations\nassociated to the outer metrics on the diffeomorphism group, we aim to study\nthe viability of using such equations in the context of PDE-constrained shape\noptimization. However, solving geodesic equations is computationally\nchallenging and often restrictive. Therefore, this paper discusses potential\nnumerical approaches to simplify the numerical burden of using geodesics,\nmaking the proposed method computationally competitive with previously\nestablished methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T10:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.01574v1","title":"Cutwidth Bounds via Vertex Partitions","summary":"We study the cutwidth measure on graphs and ways to bound the cutwidth of a\ngraph by partitioning its vertices. We consider bounds expressed as a function\nof two quantities: on the one hand, the maximal cutwidth x of the subgraphs\ninduced by the classes of the partition, and on the other hand, the cutwidth y\nof the quotient multigraph obtained by merging each class to a single vertex.\nWe consider in particular decomposition of directed graphs into strongly\nconnected components (SCCs): in this case, x is the maximal cutwidth of an SCC,\nand y is the cutwidth of the directed acyclic condensation multigraph.\n  We show that the cutwidth of a graph is always in O(x + y), specifically it\ncan be upper bounded by 1.5x + y. We also show a lower bound justifying that\nthe constant 1.5 cannot be improved in general","main_category":"cs.DS","categories":"cs.DS,cs.DM","published":"2025-04-02T10:23:58Z"}
{"aid":"http://arxiv.org/abs/2504.01575v1","title":"Fully ergodic simulations using radial updates","summary":"A sensible application of the Hybrid Monte Carlo (HMC) method is often\nhindered by the presence of large - or even infinite - potential barriers.\nThese potential barriers separate the configuration space into distinct sectors\nand can lead to ergodicity violations that bias measurements. In this work, we\naddress this problem by augmenting HMC with a multiplicative\nMetropolis-Hastings update in a so-called ''radial direction'' of the fields\nwhich enables crossing the potential barriers and ensures ergodicity of the\nsampling algorithm at comparably low computational cost. We demonstrate the\nalgorithm on a simple toy model and show how it can be applied to the fermionic\nHubbard model describing physics ranging from an exactly-solvable two-site\nsystem to the $C_{20}H_{12}$ perylene molecule. Our numerical results show that\nthe radial updates successfully remove ergodicity violations, while\nsimultaneously reducing autocorrelation times.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-lat","published":"2025-04-02T10:28:49Z"}
{"aid":"http://arxiv.org/abs/2504.01588v1","title":"Building Knowledge from Interactions: An LLM-Based Architecture for\n  Adaptive Tutoring and Social Reasoning","summary":"Integrating robotics into everyday scenarios like tutoring or physical\ntraining requires robots capable of adaptive, socially engaging, and\ngoal-oriented interactions. While Large Language Models show promise in\nhuman-like communication, their standalone use is hindered by memory\nconstraints and contextual incoherence. This work presents a multimodal,\ncognitively inspired framework that enhances LLM-based autonomous\ndecision-making in social and task-oriented Human-Robot Interaction.\nSpecifically, we develop an LLM-based agent for a robot trainer, balancing\nsocial conversation with task guidance and goal-driven motivation. To further\nenhance autonomy and personalization, we introduce a memory system for\nselecting, storing and retrieving experiences, facilitating generalized\nreasoning based on knowledge built across different interactions. A preliminary\nHRI user study and offline experiments with a synthetic dataset validate our\napproach, demonstrating the system's ability to manage complex interactions,\nautonomously drive training tasks, and build and retrieve contextual memories,\nadvancing socially intelligent robotics.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-02T10:45:41Z"}
{"aid":"http://arxiv.org/abs/2504.01609v1","title":"The Mini-SiTian Array: the mini-SiTian Realtime Image Processing\n  pipeline (STRIP)","summary":"This paper provides a comprehensive introduction to the Mini-SiTian Real-Time\nImage Processing pipeline (STRIP) and evaluates its operational performance.\nThe STRIP pipeline is specifically designed for real-time alert triggering and\nlight curve generation for transient sources. By applying the STRIP pipeline to\nboth simulated and real observational data of the Mini-SiTian survey, it\nsuccessfully identified various types of variable sources, including stellar\nflares, supernovae, variable stars, and asteroids, while meeting requirements\nof reduction speed within 5 minutes. For the real observational dataset, the\npipeline detected 1 flare event, 127 variable stars, and 14 asteroids from\nthree monitored sky regions. Additionally, two datasets were generated: one, a\nreal-bogus training dataset comprising 218,818 training samples, and the other,\na variable star light curve dataset with 421 instances. These datasets will be\nused to train machine learning algorithms, which are planned for future\nintegration into STRIP.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.01624v1","title":"Glycemic Variability Before And After Hypoglycemia Across Different\n  Timeframes In Type 1 Diabetes With And Without Automated Insulin Delivery","summary":"Managing Type 1 diabetes (T1D) aims to optimize glucose levels within the\ntarget range while minimizing hyperglycemia and hypoglycemia. Exercise presents\nadditional challenges due to complex effects on glucose dynamics. Despite\nadvancements in diabetes technology, significant gaps remain in understanding\nthe relationship between exercise, glycemic variability (GV), and hypoglycemia\nin both automated insulin delivery (AID) and non-AID users. Additionally,\nlimited research explores the temporal progression of GV before and after\nhypoglycemia and the impact of long-duration episodes on glucose recovery. This\nstudy analyses the Type 1 Diabetes and Exercise Initiative (T1DEXI) dataset,\nassessing GV, hypoglycemia, gender, and exercise interactions in AID (n=222)\nand non-AID (n=276) users. The study examined patterns of glycemic variability\nmetrics like time below range (TBR) surrounding hypoglycemia events, focusing\non the 48 hours before and after these events. We further assess the impact of\ndifferent hypoglycemia levels (41-50 mg/dL, 51-60 mg/dL, and 61-70 mg/dL) on\npost-event glucose stability. GV increased before and after hypoglycemia up to\n48 hours in both AID and non-AID users, with statistically significant\ndifferences. TBR elevation persisted across all groups, peaking around\nhypoglycemic episodes. Notably, females using AID achieved significantly\nimproved glucose stability compared to non-AID females - a larger within-group\ndifference than that observed in males. Individual-level AID analyses showed\nthat long hypoglycemia episodes (>40 minutes) led to prolonged TBR elevation,\nsuggesting slower recovery despite AID intervention. GV trends may aid in\npredicting hypoglycemia over extended periods. Integrating GV patterns into AID\nsystems could enhance glucose stability and mitigate hypoglycemia cycles.","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-04-02T11:30:34Z"}
{"aid":"http://arxiv.org/abs/2504.01631v1","title":"Constructive Decompositions of the Identity for Functional John\n  Ellipsoids","summary":"We consider functional ellipsoids in the sense defined by Ivanov and\nNasz\\'odi and we study the problem of constructing a decomposition of the\nidentity similar to the one given by Fritz John in his fundamental theorem.","main_category":"math.FA","categories":"math.FA,math.DG","published":"2025-04-02T11:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.01634v1","title":"Shape Anisotropy Enabled Field Free Switching of Perpendicular\n  Nanomagnets","summary":"Spin Orbit Torque-Magnetic Random Access Memory (SOT-MRAM) is being developed\nas a successor to the Spin transfer torque MRAM (STT-MRAM) owing to its\nsuperior performance on the metrics of reliability and read-write speed. SOT\nswitching of perpendicularly magnetized ferromagnet in the heavy\nmetal/ferromagnet bilayer of SOT-MRAM unit cell requires an additional external\nmagnetic field to support the spin-orbit torque generated by heavy metal to\ncause deterministic switching. This complexity can be overcome if an internal\nfield can be generated to break the switching symmetry. We experimentally\ndemonstrate that by engineering the shape of ferromagnet, an internal magnetic\nfield capable of breaking the switching symmetry can be generated, which allows\nfor deterministic switching by spin-orbit torques. We fabricated nanomagnets of\nCobalt with triangular shape on top of Platinum and showed external magnetic\nfield free switching between the two stable states of magnetization by\napplication of nano-second voltage pulses. The experimental findings are\nconsistent with the micro-magnetic simulation results of the proposed geometry.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-02T11:40:10Z"}
{"aid":"http://arxiv.org/abs/2504.01641v1","title":"Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with\n  Domain Alignment","summary":"The method for image-to-point cloud registration typically determines the\nrigid transformation using a coarse-to-fine pipeline. However, directly and\nuniformly matching image patches with point cloud patches may lead to focusing\non incorrect noise patches during matching while ignoring key ones. Moreover,\ndue to the significant differences between image and point cloud modalities, it\nmay be challenging to bridge the domain gap without specific improvements in\ndesign. To address the above issues, we innovatively propose the\nUncertainty-aware Hierarchical Matching Module (UHMM) and the Adversarial Modal\nAlignment Module (AMAM). Within the UHMM, we model the uncertainty of critical\ninformation in image patches and facilitate multi-level fusion interactions\nbetween image and point cloud features. In the AMAM, we design an adversarial\napproach to reduce the domain gap between image and point cloud. Extensive\nexperiments and ablation studies on RGB-D Scene V2 and 7-Scenes benchmarks\ndemonstrate the superiority of our method, making it a state-of-the-art\napproach for image-to-point cloud registration tasks.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T11:43:55Z"}
{"aid":"http://arxiv.org/abs/2504.01646v1","title":"Adaptive mesh refinement quantum algorithm for Maxwell's equations","summary":"Algorithms that promise to leverage resources of quantum computers\nefficiently to accelerate the finite element method have emerged. However, the\nfinite element method is usually incorporated into a high-level numerical\nscheme which allows the adaptive refinement of the mesh on which the solution\nis approximated. In this work, we propose to extend adaptive mesh refinement to\nthe quantum formalism, and apply our method to the resolution of Maxwell's\nequations. An important step in this procedure is the computation of error\nestimators, which guide the refinement. By using block-encoding, we propose a\nway to compute these estimators with quantum circuits. We present first\nnumerical experiments on a 2D geometry.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T11:54:24Z"}
{"aid":"http://arxiv.org/abs/2504.01647v1","title":"FlowR: Flowing from Sparse to Dense 3D Reconstructions","summary":"3D Gaussian splatting enables high-quality novel view synthesis (NVS) at\nreal-time frame rates. However, its quality drops sharply as we depart from the\ntraining views. Thus, dense captures are needed to match the high-quality\nexpectations of some applications, e.g. Virtual Reality (VR). However, such\ndense captures are very laborious and expensive to obtain. Existing works have\nexplored using 2D generative models to alleviate this requirement by\ndistillation or generating additional training views. These methods are often\nconditioned only on a handful of reference input views and thus do not fully\nexploit the available 3D information, leading to inconsistent generation\nresults and reconstruction artifacts. To tackle this problem, we propose a\nmulti-view, flow matching model that learns a flow to connect novel view\nrenderings from possibly sparse reconstructions to renderings that we expect\nfrom dense reconstructions. This enables augmenting scene captures with novel,\ngenerated views to improve reconstruction quality. Our model is trained on a\nnovel dataset of 3.6M image pairs and can process up to 45 views at 540x960\nresolution (91K tokens) on one H100 GPU in a single forward pass. Our pipeline\nconsistently improves NVS in sparse- and dense-view scenarios, leading to\nhigher-quality reconstructions than prior works across multiple, widely-used\nNVS benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T11:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.01650v1","title":"Sparse Gaussian Neural Processes","summary":"Despite significant recent advances in probabilistic meta-learning, it is\ncommon for practitioners to avoid using deep learning models due to a\ncomparative lack of interpretability. Instead, many practitioners simply use\nnon-meta-models such as Gaussian processes with interpretable priors, and\nconduct the tedious procedure of training their model from scratch for each\ntask they encounter. While this is justifiable for tasks with a limited number\nof data points, the cubic computational cost of exact Gaussian process\ninference renders this prohibitive when each task has many observations. To\nremedy this, we introduce a family of models that meta-learn sparse Gaussian\nprocess inference. Not only does this enable rapid prediction on new tasks with\nsparse Gaussian processes, but since our models have clear interpretations as\nmembers of the neural process family, it also allows manual elicitation of\npriors in a neural process for the first time. In meta-learning regimes for\nwhich the number of observed tasks is small or for which expert domain\nknowledge is available, this offers a crucial advantage.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-02T12:00:09Z"}
{"aid":"http://arxiv.org/abs/2504.01654v1","title":"Bubble Clustering Decoder for Quantum Topological Codes","summary":"Quantum computers are highly vulnerable to noise, necessitating the use of\nerror-correcting codes to protect stored data. Errors must be continuously\ncorrected over time to counteract decoherence using appropriate decoders.\nTherefore, fast decoding strategies capable of handling real-time syndrome\nextraction are crucial for achieving fault-tolerant quantum computing. In this\npaper, we introduce the bubble clustering (BC) decoder for quantum surface\ncodes, which serves as a low-latency replacement for MWPM, achieving\nsignificantly faster execution at the cost of a slight performance degradation.\nThis speed boost is obtained leveraging an efficient cluster generation based\non bubbles centered on defects, and avoiding the computational overhead\nassociated with cluster growth and merging phases, commonly adopted in\ntraditional decoders. Our complexity analysis reveals that the proposed decoder\noperates with a complexity on the order of the square of the number of defects.\nFor moderate physical error rates, this is equivalent to linear complexity in\nthe number of data qubits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T12:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.01656v1","title":"Probabilistic plugging of airways by sliding mucus films","summary":"When do mucus films plug lung airways? Using reduced-order simulations of a\nlarge ensemble of randomly perturbed films, we show that the answer is not\ndetermined by just the film's volume. While very thin films always stay open\nand very thick films always plug, we find a range of intermediate films for\nwhich plugging is uncertain. The fastest-growing linear mode of the\nRayleigh-Plateau instability ensures that the film's volume is divided among\nmultiple humps. However, the nonlinear growth of these humps can occur\nunevenly, due to spontaneous axial sliding -- a lucky hump can sweep up a\ndisproportionate share of the film's volume and so form a plug. This\nsliding-induced plugging is robust and prevails with or without gravitational\nand ciliary transport.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,nlin.PS","published":"2025-04-02T12:04:44Z"}
{"aid":"http://arxiv.org/abs/2504.01668v1","title":"Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation\n  for 3D Semantic Segmentation","summary":"3D point cloud semantic segmentation (PCSS) is a cornerstone for\nenvironmental perception in robotic systems and autonomous driving, enabling\nprecise scene understanding through point-wise classification. While\nunsupervised domain adaptation (UDA) mitigates label scarcity in PCSS, existing\nmethods critically overlook the inherent vulnerability to real-world\nperturbations (e.g., snow, fog, rain) and adversarial distortions. This work\nfirst identifies two intrinsic limitations that undermine current PCSS-UDA\nrobustness: (a) unsupervised features overlap from unaligned boundaries in\nshared-class regions and (b) feature structure erosion caused by\ndomain-invariant learning that suppresses target-specific patterns. To address\nthe proposed problems, we propose a tripartite framework consisting of: 1) a\nrobustness evaluation model quantifying resilience against adversarial\nattack/corruption types through robustness metrics; 2) an invertible attention\nalignment module (IAAM) enabling bidirectional domain mapping while preserving\ndiscriminative structure via attention-guided overlap suppression; and 3) a\ncontrastive memory bank with quality-aware contrastive learning that\nprogressively refines pseudo-labels with feature quality for more\ndiscriminative representations. Extensive experiments on\nSynLiDAR-to-SemanticPOSS adaptation demonstrate a maximum mIoU improvement of\n14.3\\% under adversarial attack.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-02T12:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.01669v1","title":"The CosmoVerse White Paper: Addressing observational tensions in\n  cosmology with systematics and fundamental physics","summary":"The standard model of cosmology has provided a good phenomenological\ndescription of a wide range of observations both at astrophysical and\ncosmological scales for several decades. This concordance model is constructed\nby a universal cosmological constant and supported by a matter sector described\nby the standard model of particle physics and a cold dark matter contribution,\nas well as very early-time inflationary physics, and underpinned by gravitation\nthrough general relativity. There have always been open questions about the\nsoundness of the foundations of the standard model. However, recent years have\nshown that there may also be questions from the observational sector with the\nemergence of differences between certain cosmological probes. In this White\nPaper, we identify the key objectives that need to be addressed over the coming\ndecade together with the core science projects that aim to meet these\nchallenges. These discordances primarily rest on the divergence in the\nmeasurement of core cosmological parameters with varying levels of statistical\nconfidence. These possible statistical tensions may be partially accounted for\nby systematics in various measurements or cosmological probes but there is also\na growing indication of potential new physics beyond the standard model. After\nreviewing the principal probes used in the measurement of cosmological\nparameters, as well as potential systematics, we discuss the most promising\narray of potential new physics that may be observable in upcoming surveys. We\nalso discuss the growing set of novel data analysis approaches that go beyond\ntraditional methods to test physical models. [Abridged]","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-02T12:17:19Z"}
{"aid":"http://arxiv.org/abs/2504.01675v1","title":"Einstein's elevator and the principle of equivalence","summary":"We outlines here the design, execution, and educational outcomes of an\nintervention inspired by Einstein's elevator thought experiment, intended to\nintroduce secondary school students to the principle of equivalence, which is\nat the basis of the theory of General Relativity. We build an experimental\nversion of Einstein's elevator, which simulated the effects of free-fall in an\naccelerated reference frame: a detailed description of the experimental\napparatus and its construction is provided, highlighting the challenges and\ninnovations in creating a simple yet functional setup using everyday materials.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-02T12:25:08Z"}
{"aid":"http://arxiv.org/abs/2504.01693v1","title":"$SL_k$-Tilings and Paths in $\\mathbb{Z}^k$","summary":"An $SL_k$-tiling is a bi-infinite array of integers having all adjacent\n$k\\times k$ minors equal to one and all adjacent $(k+1)\\times (k+1)$ minors\nequal to zero. Introduced and studied by Bergeron and Reutenauer,\n$SL_k$-tilings generalize the notion of Conway-Coxeter frieze patterns in the\ncase $k=2$. In a recent paper, Short showed a bijection between bi-infinite\npaths of reduced rationals in the Farey graph and $SL_2$-tilings. We extend\nthis result to higher $k$ by constructing a bijection between $SL_k$-tilings\nand certain pairs of bi-infinite strips of vectors in $\\mathbb{Z}^k$ called\npaths. The key ingredient in the proof is the connection to Pl\\\"ucker friezes\nand Grassmannian cluster algebras. As an application, we obtain results about\nperiodicity, duality, and positivity for tilings.","main_category":"math.CO","categories":"math.CO,math.RA,math.RT","published":"2025-04-02T12:49:39Z"}
{"aid":"http://arxiv.org/abs/2504.01695v1","title":"MS_ATpV-FWI: Full Waveform Inversion based on Multi-scale Structural\n  Similarity Index Measure and Anisotropic Total p-Variation Regularization","summary":"Full waveform inversion (FWI) is a high-resolution seismic inversion\ntechnique popularly used in oil and gas exploration. Traditional FWI employs\nthe $l_2$ norm measurement to minimize the misfit between observed and\npredicted seismic data. However, when the background velocity is inaccurate or\nthe seismic data lacks low-frequency components, the conventional FWI suffers\nfrom cycle skipping, leading to inaccurate inversion results. This paper\nintroduces a multiscale structural similarity index measure (M-SSIM) objective\nfunction for FWI. We also incorporate anisotropic total p-variation\nregularization (ATpV) to further improve the accuracy of FWI. M-SSIM extracts\nmulti-scale structural features of seismic data in terms of both phase and\namplitude. These features can reduce the risk of cycle skipping and improve the\nstability of FWI. Additionally, ATpV applies structural constraints to the\nvelocity gradients, which helps suppress artifacts and preserve the sharp\nboundaries of geological formations. We propose to use the automatic\ndifferentiation (AD) to efficiently and stably optimize this novelly introduced\nFWI objective function. Both synthetic and field seismic data demonstrate that\nthe proposed method accurately characterizes complex subsurface velocity\nstructures, even when the background velocity is crude, the data lacks\nlow-frequency components, or contains noise.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-02T12:55:11Z"}
{"aid":"http://arxiv.org/abs/2504.01708v1","title":"TransforMerger: Transformer-based Voice-Gesture Fusion for Robust\n  Human-Robot Communication","summary":"As human-robot collaboration advances, natural and flexible communication\nmethods are essential for effective robot control. Traditional methods relying\non a single modality or rigid rules struggle with noisy or misaligned data as\nwell as with object descriptions that do not perfectly fit the predefined\nobject names (e.g. 'Pick that red object'). We introduce TransforMerger, a\ntransformer-based reasoning model that infers a structured action command for\nrobotic manipulation based on fused voice and gesture inputs. Our approach\nmerges multimodal data into a single unified sentence, which is then processed\nby the language model. We employ probabilistic embeddings to handle uncertainty\nand we integrate contextual scene understanding to resolve ambiguous references\n(e.g., gestures pointing to multiple objects or vague verbal cues like \"this\").\nWe evaluate TransforMerger in simulated and real-world experiments,\ndemonstrating its robustness to noise, misalignment, and missing information.\nOur results show that TransforMerger outperforms deterministic baselines,\nespecially in scenarios requiring more contextual knowledge, enabling more\nrobust and flexible human-robot communication. Code and datasets are available\nat: http://imitrob.ciirc.cvut.cz/publications/transformerger.","main_category":"cs.RO","categories":"cs.RO,cs.HC,cs.LG","published":"2025-04-02T13:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.01719v1","title":"Beyond Non-Expert Demonstrations: Outcome-Driven Action Constraint for\n  Offline Reinforcement Learning","summary":"We address the challenge of offline reinforcement learning using realistic\ndata, specifically non-expert data collected through sub-optimal behavior\npolicies. Under such circumstance, the learned policy must be safe enough to\nmanage \\textit{distribution shift} while maintaining sufficient flexibility to\ndeal with non-expert (bad) demonstrations from offline data.To tackle this\nissue, we introduce a novel method called Outcome-Driven Action Flexibility\n(ODAF), which seeks to reduce reliance on the empirical action distribution of\nthe behavior policy, hence reducing the negative impact of those bad\ndemonstrations.To be specific, a new conservative reward mechanism is developed\nto deal with {\\it distribution shift} by evaluating actions according to\nwhether their outcomes meet safety requirements - remaining within the state\nsupport area, rather than solely depending on the actions' likelihood based on\noffline data.Besides theoretical justification, we provide empirical evidence\non widely used MuJoCo and various maze benchmarks, demonstrating that our ODAF\nmethod, implemented using uncertainty quantification techniques, effectively\ntolerates unseen transitions for improved \"trajectory stitching,\" while\nenhancing the agent's ability to learn from realistic non-expert data.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-02T13:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.01734v1","title":"Quasinormal modes of near-extremal Reissner-NordstrÃ¶m-de Sitter\n  spacetimes","summary":"We study quasinormal modes (QNMs) for the Klein-Gordon equation on\nReissner-Nordstr\\\"om-de Sitter black holes with near-extremal charge. We locate\nall QNMs of size $\\mathcal{O}(\\kappa_{\\rm C})$ where $\\kappa_{\\rm C}$ is the\nsurface gravity of the Cauchy horizon (which vanishes at extremality): they are\nwell-approximated by $\\kappa_{\\rm C}$ times QNMs of the near-horizon geometry\n${\\rm AdS}^2\\times{\\mathbb S}^2$ of the extremal limit.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T13:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.01737v1","title":"Enlightenment Period Improving DNN Performance","summary":"In the early stage of deep neural network training, the loss decreases\nrapidly before gradually leveling off. Extensive research has shown that during\nthis stage, the model parameters undergo significant changes and their\ndistribution is largely established. Existing studies suggest that the\nintroduction of noise during early training can degrade model performance. We\nidentify a critical \"enlightenment period\" encompassing up to the first 4% of\nthe training cycle (1--20 epochs for 500-epoch training schedules), a phase\ncharacterized by intense parameter fluctuations and heightened noise\nsensitivity. Our findings reveal that strategically reducing noise during this\nbrief phase--by disabling data augmentation techniques such as Mixup or\nremoving high-loss samples--leads to statistically significant improvements in\nmodel performance. This work opens new avenues for exploring the relationship\nbetween the enlightenment period and network training dynamics across diverse\nmodel architectures and tasks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T13:49:31Z"}
{"aid":"http://arxiv.org/abs/2504.01744v1","title":"Universal inverse Radon transforms: Inhomogeneity, angular restrictions\n  and boundary","summary":"An alternative method to invert the Radon transforms without the use of\nCourand-Hilbert's identities has been proposed and developed independently from\nthe space dimension. For the universal representation of inverse Radon\ntransform, we study the consequences of inhomogeneity of outset function\nwithout the restrictions on the angular Radon coordinates. We show that this\ninhomogeneity yields a natural evidence for the presence of the extra\ncontributions in the case of the full angular region. In addition, if the\noutset function is well-localized in the space, we demonstrate that the\ncorresponding boundary conditions and the angular restrictions should be\napplied for both the direct and inverse Radon transforms. Besides, we relate\nthe angular restrictions on the Radon variable to the boundary exclusion of\noutset function and its Radon image.","main_category":"math.CA","categories":"math.CA,hep-ph,hep-th,math-ph,math.MP","published":"2025-04-02T13:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.01747v1","title":"The untangling number of 3-periodic tangles","summary":"The entanglement of curves within a 3-periodic box provides a model for\ncomplicated space-filling entangled structures occurring in biological\nmaterials and structural chemistry. Quantifying the complexity of the\nentanglement within these models enhances the characterisation of these\nstructures. In this paper, we introduce a new measure of entanglement\ncomplexity through the untangling number, reminiscent of the unknotting number\nin knot theory. The untangling number quantifies the minimum distance between a\ngiven 3-periodic structure and its least tangled version, called ground state,\nthrough a sequence of operations in a diagrammatic representation of the\nstructure. For entanglements that consist of only infinite open curves, we show\nthat the generic ground states of these structures are crystallographic rod\npackings, well-known in structural chemistry.","main_category":"math.GT","categories":"math.GT","published":"2025-04-02T14:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.01753v1","title":"Well-clipped cones behave themselves under all finite quotients, the\n  cone conjecture under most","summary":"We introduce a property of convex cones, being \"well-clipped\", that is\ninspired by the work of several complex algebraic geometers on the\nMorrison-Kawamata cone conjecture. That property is satisfied by movable cones\nof divisors on various complex projective varieties of Calabi-Yau type, such as\nabelian varieties and projective hyperk\\\"ahler manifolds. The property of being\nwell-clipped has the advantage to descend under taking invariants by a finite\ngroup action, and to be stable by direct sums. In the class of well-clipped\ncones, we also provide a simple characterization of those cones that admit a\nrational polyhedral fundamental domain under some natural group action.\n  We use this framework to prove the movable cone conjecture for finite\nquotients of various projective varieties of Calabi-Yau type, notably products\nof projective primitive symplectic varieties, abelian varieties, and smooth\nrational surfaces underlying klt Calabi-Yau pairs. This entails Enriques\nmanifolds. We deduce that such finite quotients admit finitely many unmarked\nsmall $\\mathbb{Q}$-factorial modifications, and that the nef cone conjecture\nholds for them.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T14:08:08Z"}
{"aid":"http://arxiv.org/abs/2504.01757v1","title":"KD$^{2}$M: An unifying framework for feature knowledge distillation","summary":"Knowledge Distillation (KD) seeks to transfer the knowledge of a teacher,\ntowards a student neural net. This process is often done by matching the\nnetworks' predictions (i.e., their output), but, recently several works have\nproposed to match the distributions of neural nets' activations (i.e., their\nfeatures), a process known as \\emph{distribution matching}. In this paper, we\npropose an unifying framework, Knowledge Distillation through Distribution\nMatching (KD$^{2}$M), which formalizes this strategy. Our contributions are\nthreefold. We i) provide an overview of distribution metrics used in\ndistribution matching, ii) benchmark on computer vision datasets, and iii)\nderive new theoretical results for KD.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-02T14:14:46Z"}
{"aid":"http://arxiv.org/abs/2504.01773v1","title":"Budget-Feasible Contracts","summary":"The problem of computing near-optimal contracts in combinatorial settings has\nrecently attracted significant interest in the computer science community.\nPrevious work has provided a rich body of structural and algorithmic insights\ninto this problem. However, most of these results rely on the assumption that\nthe principal has an unlimited budget for incentivizing agents, an assumption\nthat is often unrealistic in practice. This motivates the study of the optimal\ncontract problem under budget constraints. We study multi-agent contracts with\nbudget constraints under both binary and combinatorial actions. For binary\nactions, our contribution is threefold. First, we generalize all previously\nknown approximation guarantees on the principal's revenue to budgeted settings.\nSecond, through the lens of budget constraints, we uncover insightful\nconnections between the standard objective of the principal's revenue and other\nobjectives. We identify a broad class of objectives, which we term BEST\nobjectives, including reward, social welfare, and revenue, and show that they\nare all equivalent (up to a constant factor), leading to approximation\nguarantees for all BEST objectives. Third, we introduce the price of frugality,\nwhich quantifies the loss due to budget constraints, and establish near-tight\nbounds on this measure, providing deeper insights into the tradeoffs between\nbudgets and incentives. For combinatorial actions, we establish a strong\nnegative result. Specifically, we show that in a budgeted setting with\nsubmodular rewards, no finite approximation is possible to any BEST objective.\nThis stands in contrast to the unbudgeted setting with submodular rewards,\nwhere a polynomial-time constant-factor approximation is known for revenue. On\nthe positive side, for gross substitutes rewards, we recover our binary-actions\nresults, obtaining a constant-factor approximation for all BEST objectives.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-02T14:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.01775v1","title":"Defect detection in III-V multijunction solar cells using reverse-bias\n  stress tests","summary":"Reverse biasing triple-junction GaInP/Ga(In)As/Ge solar cells may affect\ntheir performance by the formation of permanent shunts even if the reverse\nbreakdown voltage is not reached. In previous works, it was observed that, amid\nthe three components, GaInP subcells are more prone to degrade when reverse\nbiased suffering permanent damage, although they present an initial good\nperformance. The aim of this work is, firstly, to study the characteristics of\nthe defects that cause the catastrophic failure of the devices. For this, GaInP\nisotype solar cells were analysed by visual inspection and electroluminescence\nmaps and submitted to reverse bias stress test. We find that specific growth\ndefects (i.e. hillocks), when covered with metal, cause the degradation in the\ncells. SEM cross-section imaging and EDX compositional analysis of these\ndefects reveal their complex structures, which in essence consist of material\nabnormally grown on and around particles present on the wafer surface before\ngrowth. The reverse bias stress test is proposed as a screening method to spot\ndefects hidden under the metal that may not be detected by conventional\nscreening methods. By applying a quick reverse bias stress test, we can detect\nthose defects that cause the degradation of devices at voltages below the\nbreakdown voltage and that may also affect their long-term reliability.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-02T14:36:26Z"}
{"aid":"http://arxiv.org/abs/2504.01785v1","title":"Time-optimal single-scalar control on a qubit of unitary dynamics","summary":"Optimal control theory is applied to analyze the time-optimal solution with a\nsingle scalar control knob in a two-level quantum system without quantum\ndecoherence. Emphasis is \\change{placed} on the dependence on the maximum\ncontrol strength $u_\\text{max}$. General constraints on the optimal protocol\nare derived and used to rigorously parameterize the time-optimal solution. Two\nconcrete problems are investigated. For generic state preparation problems,\nboth multiple bang-bang and bang-singular-bang are legitimate and should be\nconsidered. Generally, the optimal is bang-bang for small $u_\\text{max}$, and\nthere exists a state-dependent critical amplitude above which singular control\nemerges. For the X-gate operation of a qubit, the optimal protocol \\change{is\nexclusively} multiple bang-bang. The minimum gate time is about 80\\% of that\nbased on the resonant Rabi $\\pi$-pulse over a wide range of control strength;\nin the $u_\\text{max} \\rightarrow 0$ limit this ratio is derived to be $\\pi/4$.\nTo develop practically feasible protocols, we present methods to smooth the\nabrupt changes in the bang-bang control while preserving perfect gate fidelity.\n\\change{The presence of bang-bang segments in the time-optimal protocol}\nindicates that the high-frequency components and a full calculation (instead of\nthe commonly adopted Rotating Wave Approximation) are essential for the\nultimate quantum speed limit.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T14:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01792v1","title":"UniViTAR: Unified Vision Transformer with Native Resolution","summary":"Conventional Vision Transformer simplifies visual modeling by standardizing\ninput resolutions, often disregarding the variability of natural visual data\nand compromising spatial-contextual fidelity. While preliminary explorations\nhave superficially investigated native resolution modeling, existing approaches\nstill lack systematic analysis from a visual representation perspective. To\nbridge this gap, we introduce UniViTAR, a family of homogeneous vision\nfoundation models tailored for unified visual modality and native resolution\nscenario in the era of multimodal. Our framework first conducts architectural\nupgrades to the vanilla paradigm by integrating multiple advanced components.\nBuilding upon these improvements, a progressive training paradigm is\nintroduced, which strategically combines two core mechanisms: (1) resolution\ncurriculum learning, transitioning from fixed-resolution pretraining to native\nresolution tuning, thereby leveraging ViT's inherent adaptability to\nvariable-length sequences, and (2) visual modality adaptation via inter-batch\nimage-video switching, which balances computational efficiency with enhanced\ntemporal reasoning. In parallel, a hybrid training framework further synergizes\nsigmoid-based contrastive loss with feature distillation from a frozen teacher\nmodel, thereby accelerating early-stage convergence. Finally, trained\nexclusively on public datasets, externsive experiments across multiple model\nscales from 0.3B to 1B demonstrate its effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T14:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.01795v1","title":"Factors Influencing Farmers' Motivation to Adopt Smart Farm Technology\n  in South Korea","summary":"Smart farming technologies have recently become a major focus because they\npromise improved agricultural productivity together with sustainability\nbenefits. The rate at which farmers adopt new technologies differs because of\nvarious socio-economic and technological factors. This research investigates\nthe main factors affecting smart farm adoption through an evaluation of farmer\nage, education attainment, land size, government banking, technological hurdles\nand financial limitations. Statistical analysis of survey responses reveals\nthat farmers under thirty years old and possessing advanced education along\nwith operating expansive farms demonstrate greater willingness to adopt smart\nfarming solutions. Government policies that offer financial assistance and\ntraining programs drive farmers to adopt new systems yet technical and\nfinancial difficulties prevent broad adoption. The research results demonstrate\nthe requirement for targeted policies that should help farmers by providing\nspecific financial help and digital education programs. This study delivers\nimportant knowledge which helps government officials together with agricultural\nleaders to accelerate the adaptation speed of smart farming technology.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-02T15:02:05Z"}
{"aid":"http://arxiv.org/abs/2504.01803v1","title":"DISINFOX: an open-source threat exchange platform serving intelligence\n  on disinformation and influence operations","summary":"This paper introduces DISINFOX, an open-source threat intelligence exchange\nplatform for the structured collection, management, and dissemination of\ndisinformation incidents and influence operations. Analysts can upload and\ncorrelate information manipulation and interference incidents, while clients\ncan access and analyze the data through an interactive web interface or\nprogrammatically via a public API. This facilitates integration with other\nvendors, providing a unified view of cybersecurity and disinformation events.\n  The solution is fully containerized using Docker, comprising a web-based\nfrontend for user interaction, a backend REST API for managing core\nfunctionalities, and a public API for structured data retrieval, enabling\nseamless integration with existing Cyber Threat Intelligence (CTI) workflows.\nIn particular, DISINFOX models the incidents through DISARM Tactics,\nTechniques, and Procedures (TTPs), a MITRE ATT&CK-like framework for\ndisinformation, with a custom data model based on the Structured Threat\nInformation eXpression (STIX2) standard.\n  As an open-source solution, DISINFOX provides a reproducible and extensible\nhub for researchers, analysts, and policymakers seeking to enhance the\ndetection, investigation, and mitigation of disinformation threats. The\nintelligence generated from a custom dataset has been tested and utilized by a\nlocal instance of OpenCTI, a mature CTI platform, via a custom-built connector,\nvalidating the platform with the exchange of more than 100 disinformation\nincidents.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-02T15:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.01805v1","title":"Spatial-R1: Enhancing MLLMs in Video Spatial Reasoning","summary":"Enhancing the spatial reasoning capabilities of Multi-modal Large Language\nModels (MLLMs) for video understanding is crucial yet challenging. We present\nSpatial-R1, a targeted approach involving two key contributions: the curation\nof SR, a new video spatial reasoning dataset from ScanNet with automatically\ngenerated QA pairs across seven task types, and the application of\nTask-Specific Group Relative Policy Optimization (GRPO) for fine-tuning. By\ntraining the Qwen2.5-VL-7B-Instruct model on SR using GRPO, Spatial-R1\nsignificantly advances performance on the VSI-Bench benchmark, achieving a\n7.4\\% gain over the baseline and outperforming strong contemporary models. This\nwork validates the effectiveness of specialized data curation and optimization\ntechniques for improving complex spatial reasoning in video MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T15:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.01806v1","title":"Quattro: Transformer-Accelerated Iterative Linear Quadratic Regulator\n  Framework for Fast Trajectory Optimization","summary":"Real-time optimal control remains a fundamental challenge in robotics,\nespecially for nonlinear systems with stringent performance requirements. As\none of the representative trajectory optimization algorithms, the iterative\nLinear Quadratic Regulator (iLQR) faces limitations due to their inherently\nsequential computational nature, which restricts the efficiency and\napplicability of real-time control for robotic systems. While existing parallel\nimplementations aim to overcome the above limitations, they typically demand\nadditional computational iterations and high-performance hardware, leading to\nonly modest practical improvements. In this paper, we introduce Quattro, a\ntransformer-accelerated iLQR framework employing an algorithm-hardware\nco-design strategy to predict intermediate feedback and feedforward matrices.\nIt facilitates effective parallel computations on resource-constrained devices\nwithout sacrificing accuracy. Experiments on cart-pole and quadrotor systems\nshow an algorithm-level acceleration of up to 5.3$\\times$ and 27$\\times$ per\niteration, respectively. When integrated into a Model Predictive Control (MPC)\nframework, Quattro achieves overall speedups of 2.8$\\times$ for the cart-pole\nand 17.8$\\times$ for the quadrotor compared to the one that applies traditional\niLQR. Transformer inference is deployed on FPGA to maximize performance,\nachieving up to 27.3$\\times$ speedup over commonly used computing devices, with\naround 2 to 4$\\times$ power reduction and acceptable hardware overhead.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-02T15:12:18Z"}
{"aid":"http://arxiv.org/abs/2504.01819v1","title":"Implicit Bias Injection Attacks against Text-to-Image Diffusion Models","summary":"The proliferation of text-to-image diffusion models (T2I DMs) has led to an\nincreased presence of AI-generated images in daily life. However, biased T2I\nmodels can generate content with specific tendencies, potentially influencing\npeople's perceptions. Intentional exploitation of these biases risks conveying\nmisleading information to the public. Current research on bias primarily\naddresses explicit biases with recognizable visual patterns, such as skin color\nand gender. This paper introduces a novel form of implicit bias that lacks\nexplicit visual features but can manifest in diverse ways across various\nsemantic contexts. This subtle and versatile nature makes this bias challenging\nto detect, easy to propagate, and adaptable to a wide range of scenarios. We\nfurther propose an implicit bias injection attack framework (IBI-Attacks)\nagainst T2I diffusion models by precomputing a general bias direction in the\nprompt embedding space and adaptively adjusting it based on different inputs.\nOur attack module can be seamlessly integrated into pre-trained diffusion\nmodels in a plug-and-play manner without direct manipulation of user input or\nmodel retraining. Extensive experiments validate the effectiveness of our\nscheme in introducing bias through subtle and diverse modifications while\npreserving the original semantics. The strong concealment and transferability\nof our attack across various scenarios further underscore the significance of\nour approach. Code is available at https://github.com/Hannah1102/IBI-attacks.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T15:24:12Z"}
{"aid":"http://arxiv.org/abs/2504.01824v1","title":"Topological Feature of Real-time Fisher Zeros","summary":"There are numerous methods to characterize topology and its boundary zero\nmodes, yet their statistical mechanical properties have not received as much\nattention as other approaches. Here, we investigate the Fisher zeros and\nthermofield dynamics of topological models, revealing that boundary zero modes\ncan be described by an overlooked real-time Fisher zero pairing effect. This\neffect is validated in the Su-Schrieffer-Heeger model and the Kitaev chain\nmodel, with the latter exhibiting a Fisher zero braiding picture. Topological\nzero modes exhibit robustness even when non-Hermiticity is introduced into the\nsystem and display characteristics of imaginary-time crystals when the energy\neigenvalues are complex. We further examine the real-time Fisher zeros of the\none-dimensional transverse field Ising model, which maps to the Kitaev chain.\nWe present a fractal picture of the Fisher zeros, illustrating how interactions\neliminate topology. The mechanism of zero-pairing provides a natural\nstatistical mechanical approach to understanding the connection between\ntopology and many-body physics.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech,hep-lat,quant-ph","published":"2025-04-02T15:30:24Z"}
{"aid":"http://arxiv.org/abs/2504.01833v1","title":"YourBench: Easy Custom Evaluation Sets for Everyone","summary":"Evaluating large language models (LLMs) effectively remains a critical\nbottleneck, as traditional static benchmarks suffer from saturation and\ncontamination, while human evaluations are costly and slow. This hinders timely\nor domain-specific assessment, crucial for real-world applications. We\nintroduce YourBench, a novel, open-source framework that addresses these\nlimitations by enabling dynamic, automated generation of reliable, up-to-date,\nand domain-tailored benchmarks cheaply and without manual annotation, directly\nfrom user-provided documents. We demonstrate its efficacy by replicating 7\ndiverse MMLU subsets using minimal source text, achieving this for under 15 USD\nin total inference costs while perfectly preserving the relative model\nperformance rankings (Spearman Rho = 1) observed on the original benchmark. To\nensure that YourBench generates data grounded in provided input instead of\nrelying on posterior parametric knowledge in models, we also introduce\nTempora-0325, a novel dataset of over 7K diverse documents, published\nexclusively after March 2025. Our comprehensive analysis spans 26 SoTA models\nfrom 7 major families across varying scales (3-671B parameters) to validate the\nquality of generated evaluations through rigorous algorithmic checks (e.g.,\ncitation grounding) and human assessments. We release the YourBench library,\nthe Tempora-0325 dataset, 150k+ question answer pairs based on Tempora and all\nevaluation and inference traces to facilitate reproducible research and empower\nthe community to generate bespoke benchmarks on demand, fostering more relevant\nand trustworthy LLM evaluation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.1","published":"2025-04-02T15:40:24Z"}
{"aid":"http://arxiv.org/abs/2504.01834v1","title":"Faster computation of Witt vectors over polynomial rings","summary":"We describe an algorithm which computes the ring laws for Witt vectors of\nfinite length over a polynomial ring with coefficients in a finite field. This\nalgorithm uses an isomorphism of Illusie in order to compute in an adequate\npolynomial ring. We also give an implementation of the algorithm in SageMath,\nwhich turns out to be faster that Finotti's algorithm, which was until now the\nmost efficient one for these operations.","main_category":"math.AC","categories":"math.AC","published":"2025-04-02T15:40:38Z"}
{"aid":"http://arxiv.org/abs/2504.01847v1","title":"Confluence of Conditional Rewriting Modulo","summary":"Sets of equations E play an important computational role in rewriting-based\nsystems R by defining an equivalence relation =E inducing a partition of terms\ninto E-equivalence classes on which rewriting computations, denoted ->R/E and\ncalled *rewriting modulo E*, are issued. This paper investigates *confluence of\n->R/E*, usually called *E-confluence*, for *conditional* rewriting-based\nsystems, where rewriting steps are determined by conditional rules. We rely on\nJouannaud and Kirchner's framework to investigate confluence of an abstract\nrelation R modulo an abstract equivalence relation E on a set A. We show how to\nparticularize the framework to be used with conditional systems. Then, we show\nhow to define appropriate finite sets of *conditional pairs* to prove and\ndisprove E-confluence. In particular, we introduce *Logic-based Conditional\nCritical Pairs* which do not require the use of (often infinitely many)\nE-unifiers to provide a finite representation of the *local peaks* considered\nin the abstract framework. We also introduce *parametric Conditional Variable\nPairs* which are essential to deal with conditional rules in the analysis of\nE-confluence. Our results apply to well-known classes of rewriting-based\nsystems. In particular, to *Equational (Conditional) Term Rewriting Systems*.","main_category":"cs.LO","categories":"cs.LO,cs.PL,cs.SC","published":"2025-04-02T15:55:06Z"}
{"aid":"http://arxiv.org/abs/2504.01849v1","title":"An Approach to Technical AGI Safety and Security","summary":"Artificial General Intelligence (AGI) promises transformative benefits but\nalso presents significant risks. We develop an approach to address the risk of\nharms consequential enough to significantly harm humanity. We identify four\nareas of risk: misuse, misalignment, mistakes, and structural risks. Of these,\nwe focus on technical approaches to misuse and misalignment. For misuse, our\nstrategy aims to prevent threat actors from accessing dangerous capabilities,\nby proactively identifying dangerous capabilities, and implementing robust\nsecurity, access restrictions, monitoring, and model safety mitigations. To\naddress misalignment, we outline two lines of defense. First, model-level\nmitigations such as amplified oversight and robust training can help to build\nan aligned model. Second, system-level security measures such as monitoring and\naccess control can mitigate harm even if the model is misaligned. Techniques\nfrom interpretability, uncertainty estimation, and safer design patterns can\nenhance the effectiveness of these mitigations. Finally, we briefly outline how\nthese ingredients could be combined to produce safety cases for AGI systems.","main_category":"cs.AI","categories":"cs.AI,cs.CY,cs.LG","published":"2025-04-02T15:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.01850v1","title":"Code Red! On the Harmfulness of Applying Off-the-shelf Large Language\n  Models to Programming Tasks","summary":"Nowadays, developers increasingly rely on solutions powered by Large Language\nModels (LLM) to assist them with their coding tasks. This makes it crucial to\nalign these tools with human values to prevent malicious misuse. In this paper,\nwe propose a comprehensive framework for assessing the potential harmfulness of\nLLMs within the software engineering domain. We begin by developing a taxonomy\nof potentially harmful software engineering scenarios and subsequently, create\na dataset of prompts based on this taxonomy. To systematically assess the\nresponses, we design and validate an automatic evaluator that classifies the\noutputs of a variety of LLMs both open-source and closed-source models, as well\nas general-purpose and code-specific LLMs. Furthermore, we investigate the\nimpact of models size, architecture family, and alignment strategies on their\ntendency to generate harmful content. The results show significant disparities\nin the alignment of various LLMs for harmlessness. We find that some models and\nmodel families, such as Openhermes, are more harmful than others and that\ncode-specific models do not perform better than their general-purpose\ncounterparts. Notably, some fine-tuned models perform significantly worse than\ntheir base-models due to their design choices. On the other side, we find that\nlarger models tend to be more helpful and are less likely to respond with\nharmful information. These results highlight the importance of targeted\nalignment strategies tailored to the unique challenges of software engineering\ntasks and provide a foundation for future work in this critical area.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-02T16:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.01859v1","title":"A method to derive material-specific spin-bath model descriptions of\n  materials displaying prevalent spin physics (for simulation on NISQ devices)","summary":"Magnetism and spin physics are true quantum mechanical effects and their\ndescription usually requires multi reference methods and is often hidden in the\nstandard description of molecules in quantum chemistry. In this work we present\na twofold approach to the description of spin physics in molecules and solids.\nFirst, we present a method that identifies the single-particle basis in which a\ngiven subset of the orbitals is equivalent to spin degrees of freedom for\nmodels and materials which feature significant spin physics at low energies. We\nintroduce a metric for the spin-like character of a basis orbital, of which the\noptimization yields the basis containing the optimum spin-like basis orbitals.\nSecond, we demonstrate an extended Schrieffer-Wolff transformation method to\nderive the effective Hamiltonian acting on the subspace of the Hilbert space in\nwhich the charge degree of freedom of electron densities in the spin-like\norbitals is integrated out. The method then yields an effective spin-bath\nHamiltonian description for the system. This extended Schrieffer-Wolff\ntransformation is applicable to a wide range of Hamiltonians and has been\nutilized in this work for model Hamiltonians as well as the active space\nHamiltonian of molecular chromium bromide.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-02T16:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.01860v1","title":"Hyperbolic decomposition of Dirichlet distance for ARMA models","summary":"We investigate the hyperbolic decomposition of the Dirichlet norm and\ndistance between autoregressive moving average (ARMA) models. Beginning with\nthe K\\\"ahler information geometry of linear systems in the Hardy space and\nweighted Hardy spaces, we demonstrate that the Dirichlet norm and distance of\nARMA models, corresponding to the mutual information between the past and\nfuture, are decomposed into functions of the hyperbolic distance between the\npoles and zeros of the ARMA models.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-02T16:12:24Z"}
{"aid":"http://arxiv.org/abs/2504.01861v1","title":"Corner-Grasp: Multi-Action Grasp Detection and Active Gripper Adaptation\n  for Grasping in Cluttered Environments","summary":"Robotic grasping is an essential capability, playing a critical role in\nenabling robots to physically interact with their surroundings. Despite\nextensive research, challenges remain due to the diverse shapes and properties\nof target objects, inaccuracies in sensing, and potential collisions with the\nenvironment. In this work, we propose a method for effectively grasping in\ncluttered bin-picking environments where these challenges intersect. We utilize\na multi-functional gripper that combines both suction and finger grasping to\nhandle a wide range of objects. We also present an active gripper adaptation\nstrategy to minimize collisions between the gripper hardware and the\nsurrounding environment by actively leveraging the reciprocating suction cup\nand reconfigurable finger motion. To fully utilize the gripper's capabilities,\nwe built a neural network that detects suction and finger grasp points from a\nsingle input RGB-D image. This network is trained using a larger-scale\nsynthetic dataset generated from simulation. In addition to this, we propose an\nefficient approach to constructing a real-world dataset that facilitates grasp\npoint detection on various objects with diverse characteristics. Experiment\nresults show that the proposed method can grasp objects in cluttered\nbin-picking scenarios and prevent collisions with environmental constraints\nsuch as a corner of the bin. Our proposed method demonstrated its effectiveness\nin the 9th Robotic Grasping and Manipulation Competition (RGMC) held at ICRA\n2024.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T16:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.01865v1","title":"FeynMaster Manual","summary":"We present the manual for FeynMaster 2.1, a multitasking software for\nparticle physics studies. This new version includes additional functions and is\ncompatible with recent versions of related software. It can be downloaded in\nhttps://porthos.tecnico.ulisboa.pt/FeynMaster/.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T16:18:10Z"}
{"aid":"http://arxiv.org/abs/2504.01867v1","title":"Long-range correlations in the intrabeam scattering in relativistic\n  beams","summary":"The standard approach in the conventional theory of intrabeam scattering\n(IBS) is based on the analysis of binary Coulomb collisions of charged\nparticles in the beam. This picture is only partially true: in reality, a given\nparticle collides simultaneously with many partners and a more rigorous\ntreatment should take this collective aspect of the collisions into account. A\nframework for such treatment has been known in plasma physics since beginning\nof the 1960s. In this work, we will show how it can be applied to IBS in\nrelativistic beams for a particular problem of the growth of the beam energy\nspread. A preliminary conclusion of this work is that the conventional IBS\ntheory might underestimate the effects of long-range correlations in Coulomb\ncollisions in the beam.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-02T16:21:07Z"}
{"aid":"http://arxiv.org/abs/2504.01877v1","title":"Effects of Dynamic Bonds on the Kinetic Pathways of Supramolecular\n  Diblock Copolymers Disorder-Order Transition","summary":"Supramolecular block copolymers (SBC) consist of covalent polymer building\nblocks that are connected into well-defined architectures via supramolecular\nbonds. Assisted by the dynamic and reversible supramolecular interactions, it\nis envisaged that SBC self-assemblies may exhibit more diverse morphologies,\nstimuli-responsivity comparing to their covalent analogues. At the fundamental\nlevel, these features are related to the free-energy landscape of\nself-assemblies. It is therefore of central importance to understand the impact\nof dynamic/reversible bonds on the free energy landscape during structure\ntransitions. In this study, we first conduct smart Monte Carlo simulations to\ncompare the kinetics of the disorder-order transition (DOT) of supramolecular\ndiblock copolymers (SDBC) to that of covalent diblock copolymers (CDBC). The\nstructural order parameter for CDBC exhibits a fast and smooth transition\nprocess across different random number seeds and initial configurations. In\ncontrast, the SDBC system shows more diverse transition pathways, which can be\nclassified into three types. These results suggest that reversible\nsupramolecular interactions complicate the pathways, and bring about various\nintermediate structures. Next, we apply the string method to construct the\nminimum free energy path of the transition, from which the transition state and\nthe free energy barrier are evaluated. It is found that the transition free\nenergy barrier strongly correlates with the fraction of supramolecules. By\ndecomposing the free energy into A-B interaction energy and association energy,\nwe found that the interplay of both two effects decide the kinetic pathway and\nthe final equilibrium structures.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T16:33:17Z"}
{"aid":"http://arxiv.org/abs/2504.01878v1","title":"Tunable Thresholds and Frequency Encoding in a Spiking NOD Controller","summary":"Spiking Nonlinear Opinion Dynamics (S-NOD) is an excitable decision-making\nmodel inspired by the spiking dynamics of neurons. S-NOD enables the design of\nagile decision-making that can rapidly switch between decision options in\nresponse to a changing environment. In S-NOD, decisions are represented by\ncontinuous time, yet discrete, opinion spikes. Here, we extend previous\nanalysis of S-NOD and explore its potential as a nonlinear controller with a\ntunable balance between robustness and responsiveness. We identify and provide\nnecessary conditions for the bifurcation that determines the onset of periodic\nopinion spiking. We leverage this analysis to characterize the tunability of\nthe input-output threshold for opinion spiking as a function of the model basal\nsensitivity and the modulation of opinion spiking frequency as a function of\ninput magnitude past threshold. We conclude with a discussion on S-NOD as a new\nneuromorphic control block and its extension to distributed spiking\ncontrollers.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T16:33:21Z"}
{"aid":"http://arxiv.org/abs/2504.01895v1","title":"Polynomially convex embeddings and CR singularities of real manifolds","summary":"It is proved that any smooth manifold $\\mathcal M$ of dimension $m$ admits a\nsmooth polynomially convex embedding into $\\mathbb C^n$ when $n\\geq \\lfloor\n5m/4\\rfloor$. Further, such embeddings are dense in the space of smooth maps\nfrom $\\mathcal M$ into $\\mathbb C^n$ in the $\\mathcal C^3$-topology. The\ncomponents of any such embedding give smooth generators of the algebra of\ncomplex-valued continuous functions on $\\mathcal M$. A key ingredient of the\nproof is a coordinate-free description of certain notions of (non)degeneracy,\nas defined by Webster and Coffman, for CR-singularities of order one of an\nembedded real manifold in $\\mathbb C^n$. The main result is obtained by\ninductively perturbing each stratum of degeneracy to produce a global\npolynomially convex embedding.","main_category":"math.CV","categories":"math.CV","published":"2025-04-02T16:55:17Z"}
{"aid":"http://arxiv.org/abs/2504.01904v1","title":"A Dilaton Sum Rule for the Conformal Anomaly Form Factor in QCD at Order\n  $Î±_s$","summary":"We present an off-shell dispersive analysis of the graviton-gluon-gluon \\(\nTJJ \\) vertex, extending previous QED and QCD results of this interaction, and\nshow that it satisfies a conformal anomaly sum rule at one-loop, under the most\ngeneral kinematical conditions. The conformal anomaly form factor emerges from\nthe trace sector of the interaction and its absorptive amplitude is constrained\nby an area law similarly to the chiral and gravitational anomaly cases.\nBuilding on our previous analysis of those anomalies, we illustrate the\npatterns of cancelation between the localized and the continuum contributions\nto the spectral density of this form factor. As in the chiral/gravitational\ncase, a spectral flow localizes the exchanged intermediate state at zero\nmomentum transfer as the quark mass is sent to zero. The perturbative analysis\nindicates that sum rules are central dynamical features of anomaly\ninteractions, and the coupling or the decoupling of the associated dilaton\npoles are correlated with the saturation of the sum rule either by a pole or by\na dispersive cut. In the conformal and on-shell limit, the particle pole\ninteraction describes a nonlocal S-matrix element entirely supported on the\nlight-cone, with contribution both from the dilaton pole in the trace sector\nand from other sectors of the correlator, except for flavour number $n_f=3$\nquarks $ u,d,s$, where only the dilaton pole in the trace sector appears.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-02T17:04:10Z"}
{"aid":"http://arxiv.org/abs/2504.01906v1","title":"Gaze-Hand Steering for Travel and Multitasking in Virtual Environments","summary":"As head-mounted displays (HMDs) with eye-tracking become increasingly\naccessible, the need for effective gaze-based interfaces in virtual reality\n(VR) grows. Traditional gaze- or hand-based navigation often limits user\nprecision or impairs free viewing, making multitasking difficult. We present a\ngaze-hand steering technique that combines eye-tracking with hand-pointing:\nusers steer only when gaze aligns with a hand-defined target, reducing\nunintended actions and enabling free look. Speed is controlled via either a\njoystick or a waist-level speed circle. We evaluated our method in a user study\n(N=20) across multitasking and single-task scenarios, comparing it to a similar\ntechnique. Results show that gaze-hand steering maintains performance and\nenhances user comfort and spatial awareness during multitasking. Our findings\nsupport the use of gaze-hand steering in gaze-dominant VR applications\nrequiring precision and simultaneous interaction. Our method significantly\nimproves VR navigation in gaze-dominant, multitasking-intensive applications,\nsupporting immersion and efficient control.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-02T17:07:01Z"}
{"aid":"http://arxiv.org/abs/2504.01910v1","title":"Joint estimation of position and momentum with arbitrarily high\n  precision using non-Gaussian states","summary":"We address the joint estimation of changes in the position and linear\nmomentum of a quantum particle or, equivalently, changes in the complex field\nof a bosonic mode. Although these changes are generated by non-commuting\noperators, we show that leveraging non-Gaussianity enables their simultaneous\nestimation with arbitrarily high precision and arbitrarily low quantum\nincompatibility. Specifically, we demonstrate that any pure non-Gaussian state\nprovides an advantage over all Gaussian states, whether pure or mixed.\nMoreover, properly tuned non-Gaussian mixtures of Gaussian states can also\nserve as a resource.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T17:11:32Z"}
{"aid":"http://arxiv.org/abs/2504.01911v1","title":"Advancing AI-Scientist Understanding: Making LLM Think Like a Physicist\n  with Interpretable Reasoning","summary":"Large Language Models (LLMs) are playing an expanding role in physics\nresearch by enhancing reasoning, symbolic manipulation, and numerical\ncomputation. However, ensuring the reliability and interpretability of their\noutputs remains a significant challenge. In our framework, we conceptualize the\ncollaboration between AI and human scientists as a dynamic interplay among\nthree modules: the reasoning module, the interpretation module, and the\nAI-scientist interaction module. Recognizing that effective physics reasoning\ndemands rigorous logical consistency, quantitative precision, and deep\nintegration with established theoretical models, we introduce the\ninterpretation module to improve the understanding of AI-generated outputs,\nwhich is not previously explored in the literature. This module comprises\nmultiple specialized agents, including summarizers, model builders, UI\nbuilders, and testers, which collaboratively structure LLM outputs within a\nphysically grounded framework, by constructing a more interpretable science\nmodel. A case study demonstrates that our approach enhances transparency,\nfacilitates validation, and strengthens AI-augmented reasoning in scientific\ndiscovery.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.HC","published":"2025-04-02T17:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.01914v1","title":"Quantum-amplified global-phase spectroscopy on an optical clock\n  transition","summary":"Optical lattice clocks (OLCs) are at the forefront of precision metrology,\noperating near a standard quantum limit (SQL) set by quantum noise. Harnessing\nquantum entanglement offers a promising route to surpass this limit, yet there\nremain practical roadblocks concerning scalability and measurement resolution\nrequirements. Here, we adapt the holonomic quantum-gate concept to develop a\nnovel Rabi-type \"global-phase spectroscopy\" (GPS) that utilizes the\ndetuning-sensitive global Aharanov-Anandan phase. With this approach, we are\nable to demonstrate quantum-amplified time-reversal spectroscopy in an OLC that\nachieves 2.4(7) dB metrological gain without subtracting the laser noise, and\n4.0(8) dB improvement in laser noise sensitivity beyond the SQL. We further\nintroduce rotary echo to protect the dynamics from inhomogeneities in\nlight-atom coupling and implement a laser-noise-canceling differential\nmeasurement through symmetric phase encoding in two nuclear spin states. Our\ntechnique is not limited by measurement resolution, scales easily owing to the\nglobal nature of entangling interaction, and exhibits high resilience to\ntypical experimental imperfections. We expect it to be broadly applicable to\nnext-generation atomic clocks and other quantum sensors approaching the\nfundamental quantum precision limits.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-02T17:18:18Z"}
{"aid":"http://arxiv.org/abs/2504.01916v1","title":"FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer\n  Text Inputs","summary":"As a pioneering vision-language model, CLIP (Contrastive Language-Image\nPre-training) has achieved significant success across various domains and a\nwide range of downstream vision-language tasks. However, the text encoders in\npopular CLIP models are limited to processing only 77 text tokens, which\nconstrains their ability to effectively handle longer, detail-rich captions.\nAdditionally, CLIP models often struggle to effectively capture detailed visual\nand textual information, which hampers their performance on tasks that require\nfine-grained analysis. To address these limitations, we present a novel\napproach, \\textbf{FineLIP}, that extends the capabilities of CLIP. FineLIP\nenhances cross-modal text-image mapping by incorporating \\textbf{Fine}-grained\nalignment with \\textbf{L}onger text input within the CL\\textbf{IP}-style\nframework. FineLIP first extends the positional embeddings to handle longer\ntext, followed by the dynamic aggregation of local image and text tokens. The\naggregated results are then used to enforce fine-grained token-to-token\ncross-modal alignment. We validate our model on datasets with long, detailed\ncaptions across two tasks: zero-shot cross-modal retrieval and text-to-image\ngeneration. Quantitative and qualitative experimental results demonstrate the\neffectiveness of FineLIP, outperforming existing state-of-the-art approaches.\nFurthermore, comprehensive ablation studies validate the benefits of key design\nelements within FineLIP.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-02T17:19:59Z"}
{"aid":"http://arxiv.org/abs/2504.01917v1","title":"Applying software engineering solutions to law management, Nigeria as a\n  case study","summary":"Legal technology has changed the way law firms are managed worldwide.\nSubstantial research has been undertaken on the role of legal technology in law\nfirm management especially in developed countries. Though, most studies have\nonly focused on the benefits and challenges, and have failed to analyse law\nfirm management areas requiring software solutions. The principal objective of\nthis paper was to investigate the level of technology adoption among Nigerian\nlaw firms, as well as to develop a software solution to automate work processes\nin identified areas. This investigation was done using systematic literature\nreview to gather relevant data on the subject area and identify knowledge gaps.\nFindings from the research indicated a need for further analysis of the various\nareas in law practice that could require software solutions. The findings also\ndiscussed the implementation of a property management module which is an\nimportant contribution to the management of law firms in Nigeria. A\nspeech-to-text transcription feature was also implemented to eliminate the need\nfor lengthy typing.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T17:21:25Z"}
{"aid":"http://arxiv.org/abs/2504.01922v1","title":"Is Less Really More? Fake News Detection with Limited Information","summary":"The threat that online fake news and misinformation pose to democracy,\njustice, public confidence, and especially to vulnerable populations, has led\nto a sharp increase in the need for fake news detection and intervention.\nWhether multi-modal or pure text-based, most fake news detection methods depend\non textual analysis of entire articles. However, these fake news detection\nmethods come with certain limitations. For instance, fake news detection\nmethods that rely on full text can be computationally inefficient, demand large\namounts of training data to achieve competitive accuracy, and may lack\nrobustness across different datasets. This is because fake news datasets have\nstrong variations in terms of the level and types of information they provide;\nwhere some can include large paragraphs of text with images and metadata,\nothers can be a few short sentences. Perhaps if one could only use minimal\ninformation to detect fake news, fake news detection methods could become more\nrobust and resilient to the lack of information. We aim to overcome these\nlimitations by detecting fake news using systematically selected, limited\ninformation that is both effective and capable of delivering robust, promising\nperformance. We propose a framework called SLIM Systematically-selected Limited\nInformation) for fake news detection. In SLIM, we quantify the amount of\ninformation by introducing information-theoretic measures. SLIM leverages\nlimited information to achieve performance in fake news detection comparable to\nthat of state-of-the-art obtained using the full text. Furthermore, by\ncombining various types of limited information, SLIM can perform even better\nwhile significantly reducing the quantity of information required for training\ncompared to state-of-the-art language model-based fake news detection\ntechniques.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-02T17:32:37Z"}
{"aid":"http://arxiv.org/abs/2504.01930v1","title":"A thorough benchmark of automatic text classification: From traditional\n  approaches to large language models","summary":"Automatic text classification (ATC) has experienced remarkable advancements\nin the past decade, best exemplified by recent small and large language models\n(SLMs and LLMs), leveraged by Transformer architectures. Despite recent\neffectiveness improvements, a comprehensive cost-benefit analysis investigating\nwhether the effectiveness gains of these recent approaches compensate their\nmuch higher costs when compared to more traditional text classification\napproaches such as SVMs and Logistic Regression is still missing in the\nliterature. In this context, this work's main contributions are twofold: (i) we\nprovide a scientifically sound comparative analysis of the cost-benefit of\ntwelve traditional and recent ATC solutions including five open LLMs, and (ii)\na large benchmark comprising {22 datasets}, including sentiment analysis and\ntopic classification, with their (train-validation-test) partitions based on\nfolded cross-validation procedures, along with documentation, and code. The\nrelease of code, data, and documentation enables the community to replicate\nexperiments and advance the field in a more scientifically sound manner. Our\ncomparative experimental results indicate that LLMs outperform traditional\napproaches (up to 26%-7.1% on average) and SLMs (up to 4.9%-1.9% on average) in\nterms of effectiveness. However, LLMs incur significantly higher computational\ncosts due to fine-tuning, being, on average 590x and 8.5x slower than\ntraditional methods and SLMs, respectively. Results suggests the following\nrecommendations: (1) LLMs for applications that require the best possible\neffectiveness and can afford the costs; (2) traditional methods such as\nLogistic Regression and SVM for resource-limited applications or those that\ncannot afford the cost of tuning large LLMs; and (3) SLMs like Roberta for\nnear-optimal effectiveness-efficiency trade-off.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T17:40:08Z"}
{"aid":"http://arxiv.org/abs/2504.01932v1","title":"Semidefinite lower bounds for covering codes","summary":"Let $K_q(n,r)$ denote the minimum size of a $q$-ary covering code of word\nlength $n$ and covering radius $r$. In other words, $K_q(n,r)$ is the minimum\nsize of a set of $q$-ary codewords of length $n$ such that the Hamming balls of\nradius $r$ around the codewords cover the Hamming space $\\{0,\\ldots,q-1\\}^n$.\nThe special case $K_3(n,1)$ is often referred to as the football pool problem,\nas it is equivalent to finding a set of forecasts on $n$ football matches that\nis guaranteed to contain a forecast with at most one wrong outcome.\n  In this paper, we build and expand upon the work of Gijswijt (2005), who\nintroduced a semidefinite programming lower bound on $K_q(n,r)$ via matrix\ncuts. We develop techniques that strengthen this bound, by introducing new\nsemidefinite constraints inspired by Lasserre's hierarchy for 0-1 programs and\nsymmetry reduction methods, and a more powerful objective function. The\ntechniques lead to sharper lower bounds, setting new records across a broad\nrange of values of $q$, $n$, and $r$.","main_category":"math.CO","categories":"math.CO,cs.IT,math.IT,math.OC","published":"2025-04-02T17:42:03Z"}
{"aid":"http://arxiv.org/abs/2504.01935v1","title":"Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning\n  Length?","summary":"Large language models (LLMs) often benefit from verbalized reasoning at\ninference time, but it remains unclear which aspects of task difficulty these\nextra reasoning tokens address. To investigate this question, we formalize a\nframework using deterministic finite automata (DFAs). DFAs offer a formalism\nthrough which we can characterize task complexity through measurable properties\nsuch as run length (number of reasoning steps required) and state-space size\n(decision complexity). We first show that across different tasks and models of\ndifferent sizes and training paradigms, there exists an optimal amount of\nreasoning tokens such that the probability of producing a correct solution is\nmaximized. We then investigate which properties of complexity govern this\ncritical length: we find that task instances with longer corresponding\nunderlying DFA runs (i.e. demand greater latent state-tracking requirements)\ncorrelate with longer reasoning lengths, but, surprisingly, that DFA size (i.e.\nstate-space complexity) does not. We then demonstrate an implication of these\nfindings: being able to predict the optimal number of reasoning tokens for new\nproblems and filtering out non-optimal length answers results in consistent\naccuracy improvements.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T17:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.01938v1","title":"A Unified Approach to Analysis and Design of Denoising Markov Models","summary":"Probabilistic generative models based on measure transport, such as diffusion\nand flow-based models, are often formulated in the language of Markovian\nstochastic dynamics, where the choice of the underlying process impacts both\nalgorithmic design choices and theoretical analysis. In this paper, we aim to\nestablish a rigorous mathematical foundation for denoising Markov models, a\nbroad class of generative models that postulate a forward process transitioning\nfrom the target distribution to a simple, easy-to-sample distribution,\nalongside a backward process particularly constructed to enable efficient\nsampling in the reverse direction. Leveraging deep connections with\nnonequilibrium statistical mechanics and generalized Doob's $h$-transform, we\npropose a minimal set of assumptions that ensure: (1) explicit construction of\nthe backward generator, (2) a unified variational objective directly minimizing\nthe measure transport discrepancy, and (3) adaptations of the classical\nscore-matching approach across diverse dynamics. Our framework unifies existing\nformulations of continuous and discrete diffusion models, identifies the most\ngeneral form of denoising Markov models under certain regularity assumptions on\nforward generators, and provides a systematic recipe for designing denoising\nMarkov models driven by arbitrary L\\'evy-type processes. We illustrate the\nversatility and practical effectiveness of our approach through novel denoising\nMarkov models employing geometric Brownian motion and jump processes as forward\ndynamics, highlighting the framework's potential flexibility and capability in\nmodeling complex distributions.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA,stat.ML","published":"2025-04-02T17:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.01942v1","title":"De Sitter entropy: on-shell versus off-shell","summary":"Attributing thermodynamic properties to the Bunch-Davies state in static\npatch of de Sitter space and setting the corresponding equations of state, we\ndemonstrate that, for pure gravity, the bulk entropy computed on-shell as a\nvolume integral in de Sitter space coincides with the Wald entropy (area law)\nin any spacetime dimension and for any theory of f(R) gravity. We extend this\nresult to the renormalized entanglement entropy of a non-minimally coupled\nscalar field. From the on-shell perspective, entropy emerges as a bulk\ncontribution, whereas from the off-shell viewpoint, it manifests as a boundary\n(horizon) contribution. As a result, in de Sitter space, generalized entropy\ncan be understood in two distinct ways: either as a bulk or as a boundary\ncontribution.","main_category":"hep-th","categories":"hep-th","published":"2025-04-02T17:48:35Z"}
{"aid":"http://arxiv.org/abs/2504.01949v1","title":"Comparison of Bayesian methods for extrapolation of treatment effects: a\n  large scale simulation study","summary":"Extrapolating treatment effects from related studies is a promising strategy\nfor designing and analyzing clinical trials in situations where achieving an\nadequate sample size is challenging. Bayesian methods are well-suited for this\npurpose, as they enable the synthesis of prior information through the use of\nprior distributions. While the operating characteristics of Bayesian approaches\nfor borrowing data from control arms have been extensively studied, methods\nthat borrow treatment effects -- quantities derived from the comparison between\ntwo arms -- remain less well understood. In this paper, we present the findings\nof an extensive simulation study designed to address this gap. We evaluate the\nfrequentist operating characteristics of these methods, including the\nprobability of success, mean squared error, bias, precision, and credible\ninterval coverage. Our results provide insights into the strengths and\nlimitations of existing methods in the context of confirmatory trials. In\nparticular, we show that the Conditional Power Prior and the Robust Mixture\nPrior perform better overall, while the test-then-pool variants and the\np-value-based power prior display suboptimal performance.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-02T17:55:11Z"}
{"aid":"http://arxiv.org/abs/2504.01955v1","title":"Scene-Centric Unsupervised Panoptic Segmentation","summary":"Unsupervised panoptic segmentation aims to partition an image into\nsemantically meaningful regions and distinct object instances without training\non manually annotated data. In contrast to prior work on unsupervised panoptic\nscene understanding, we eliminate the need for object-centric training data,\nenabling the unsupervised understanding of complex scenes. To that end, we\npresent the first unsupervised panoptic method that directly trains on\nscene-centric imagery. In particular, we propose an approach to obtain\nhigh-resolution panoptic pseudo labels on complex scene-centric data, combining\nvisual representations, depth, and motion cues. Utilizing both pseudo-label\ntraining and a panoptic self-training strategy yields a novel approach that\naccurately predicts panoptic segmentation of complex scenes without requiring\nany human annotations. Our approach significantly improves panoptic quality,\ne.g., surpassing the recent state of the art in unsupervised panoptic\nsegmentation on Cityscapes by 9.4% points in PQ.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.02211v1","title":"FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault\n  Tolerant Attention","summary":"Transformer models leverage self-attention mechanisms to capture complex\ndependencies, demonstrating exceptional performance in various applications.\nHowever, the long-duration high-load computations required for model inference\nimpose stringent reliability demands on the computing platform, as soft errors\nthat occur during execution can significantly degrade model performance.\nExisting fault tolerance methods protect each operation separately using\ndecoupled kernels, incurring substantial computational and memory overhead. In\nthis paper, we propose a novel error-resilient framework for Transformer\nmodels, integrating end-to-end fault tolerant attention (EFTA) to improve\ninference reliability against soft errors. Our approach enables error detection\nand correction within a fully fused attention kernel, reducing redundant data\naccess and thereby mitigating memory faults. To further enhance error coverage\nand reduce overhead, we design a hybrid fault tolerance scheme tailored for the\nEFTA, introducing for the first time: 1) architecture-aware algorithm-based\nfault tolerance (ABFT) using tensor checksum, which minimizes inter-thread\ncommunication overhead on tensor cores during error detection; 2) selective\nneuron value restriction, which selectively applies adaptive fault tolerance\nconstraints to neuron values, balancing error coverage and overhead; 3) unified\nverification, reusing checksums to streamline multiple computation steps into a\nsingle verification process. Experimental results show that EFTA achieves up to\n7.56x speedup over traditional methods with an average fault tolerance overhead\nof 13.9%.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.LG","published":"2025-04-03T02:05:08Z"}
{"aid":"http://arxiv.org/abs/2504.02213v1","title":"Secure Generalization through Stochastic Bidirectional Parameter Updates\n  Using Dual-Gradient Mechanism","summary":"Federated learning (FL) has gained increasing attention due to\nprivacy-preserving collaborative training on decentralized clients, mitigating\nthe need to upload sensitive data to a central server directly. Nonetheless,\nrecent research has underscored the risk of exposing private data to\nadversaries, even within FL frameworks. In general, existing methods sacrifice\nperformance while ensuring resistance to privacy leakage in FL. We overcome\nthese issues and generate diverse models at a global server through the\nproposed stochastic bidirectional parameter update mechanism. Using diverse\nmodels, we improved the generalization and feature representation in the FL\nsetup, which also helped to improve the robustness of the model against privacy\nleakage without hurting the model's utility. We use global models from past FL\nrounds to follow systematic perturbation in parameter space at the server to\nensure model generalization and resistance against privacy attacks. We generate\ndiverse models (in close neighborhoods) for each client by using systematic\nperturbations in model parameters at a fine-grained level (i.e., altering each\nconvolutional filter across the layers of the model) to improve the\ngeneralization and security perspective. We evaluated our proposed approach on\nfour benchmark datasets to validate its superiority. We surpassed the\nstate-of-the-art methods in terms of model utility and robustness towards\nprivacy leakage. We have proven the effectiveness of our method by evaluating\nperformance using several quantitative and qualitative results.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T02:06:57Z"}
{"aid":"http://arxiv.org/abs/2504.02230v1","title":"An exact five dimensional Weyl-Geometry Gauss-Bonnet Black Hole","summary":"We present a new exact black hole solution of a 5-dimensional Weyl-geometry\nGauss-Bonnet theory of gravity. The Euclidean sector defines a fully regular\nmetric coupled to the Weyl vector field. The Euclidean action and entropy are\ncomputed, with the latter following the simple $A/4$ form plus a term linear in\nthe horizon radius, characteristic of Gauss-Bonnet couplings.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-03T02:50:31Z"}
{"aid":"http://arxiv.org/abs/2504.02234v1","title":"LLM Social Simulations Are a Promising Research Method","summary":"Accurate and verifiable large language model (LLM) simulations of human\nresearch subjects promise an accessible data source for understanding human\nbehavior and training new AI systems. However, results to date have been\nlimited, and few social scientists have adopted these methods. In this position\npaper, we argue that the promise of LLM social simulations can be achieved by\naddressing five tractable challenges. We ground our argument in a literature\nsurvey of empirical comparisons between LLMs and human research subjects,\ncommentaries on the topic, and related work. We identify promising directions\nwith prompting, fine-tuning, and complementary methods. We believe that LLM\nsocial simulations can already be used for exploratory research, such as pilot\nexperiments for psychology, economics, sociology, and marketing. More\nwidespread use may soon be possible with rapidly advancing LLM capabilities,\nand researchers should prioritize developing conceptual models and evaluations\nthat can be iteratively deployed and refined at pace with ongoing AI advances.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CL,cs.CY","published":"2025-04-03T03:01:26Z"}
{"aid":"http://arxiv.org/abs/2504.02239v1","title":"The Author Is Sovereign: A Manifesto for Ethical Copyright in the Age of\n  AI","summary":"In the age of AI, authorship is being quietly eroded by algorithmic content\nscraping, legal gray zones like \"fair use,\" and platforms that profit from\ncreative labor without consent or compensation. This short manifesto proposes a\nradical alternative: a system in which the author is sovereign of their\nintellectual domain. It presents seven ethical principles that challenge\nprevailing assumptions about open access, copyright ownership, and the public\ndomain - arguing that voluntary, negotiated consent must replace coercive\nnorms. The text exposes how weakened authorship fuels structural exploitation.\nIn place of reactive solutions, it calls for a new ethic of authorship rooted\nin consent, dignity, and contractual fairness.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-03T03:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.02243v1","title":"The growth of transcendental entire solutions of linear difference\n  equations with polynomial coefficients","summary":"In this paper, we study the growth of transcendental entire solutions of\nlinear difference equations\n  \\begin{equation}\n  P_m(z)\\Delta^mf(z)+\\cdots+P_1(z)\\Delta f(z)+P_0(z)f(z)=0,\\tag{+}\n  \\end{equation} where $P_j(z)$ are polynomials for $j=0,\\ldots,m$. At first,\nwe reveal type of binomial series in terms of its coefficients. Second, we give\na list of all possible orders, which are less than 1, and types of\ntranscendental entire solutions of linear difference equations $(+)$. In\nparticular, we give so far the best precise growth estimate of transcendental\nentire solutions of order less than 1 of $(+)$, which improves results in [3,\n4], [5], [7]. Third, for any given rational number $\\rho\\in(0,1)$ and real\nnumber $\\sigma\\in(0,\\infty)$, we can construct a linear difference equation\nwith polynomial coefficients which has a transcendental entire solution of\norder $\\rho$ and type $\\sigma$. At last, some examples are illustrated for our\nmain theorem.","main_category":"math.CV","categories":"math.CV","published":"2025-04-03T03:16:01Z"}
{"aid":"http://arxiv.org/abs/2504.02244v1","title":"SocialGesture: Delving into Multi-person Gesture Understanding","summary":"Previous research in human gesture recognition has largely overlooked\nmulti-person interactions, which are crucial for understanding the social\ncontext of naturally occurring gestures. This limitation in existing datasets\npresents a significant challenge in aligning human gestures with other\nmodalities like language and speech. To address this issue, we introduce\nSocialGesture, the first large-scale dataset specifically designed for\nmulti-person gesture analysis. SocialGesture features a diverse range of\nnatural scenarios and supports multiple gesture analysis tasks, including\nvideo-based recognition and temporal localization, providing a valuable\nresource for advancing the study of gesture during complex social interactions.\nFurthermore, we propose a novel visual question answering (VQA) task to\nbenchmark vision language models'(VLMs) performance on social gesture\nunderstanding. Our findings highlight several limitations of current gesture\nrecognition models, offering insights into future directions for improvement in\nthis field. SocialGesture is available at\nhuggingface.co/datasets/IrohXu/SocialGesture.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T03:21:06Z"}
{"aid":"http://arxiv.org/abs/2504.02256v1","title":"A direct algebraic proof for the non-positivity of Liouvillian\n  eigenvalues in Markovian quantum dynamics","summary":"Markovian open quantum systems are described by the Lindblad master equation\n$\\partial_t\\rho =\\mathcal{L}(\\rho)$, where $\\rho$ denotes the system's density\noperator and $\\mathcal{L}$ the Liouville super-operator, which is also known as\nthe Liouvillian. For systems with a finite-dimensional Hilbert space, it is a\nfundamental property of the Liouvillian, that the real-parts of all its\neigenvalues are non-positive which, in physical terms, corresponds to the\nstability of the system. The usual argument for this property is indirect,\nusing that $\\mathcal{L}$ generates a quantum channel and that quantum channels\nare contractive. We provide a direct algebraic proof based on the Lindblad form\nof Liouvillians.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T03:54:25Z"}
{"aid":"http://arxiv.org/abs/2504.02262v1","title":"Predictive modeling of altitude resolved greenline airglow emission\n  (557.7 nm) in the MLT region","summary":"Atomic oxygen is a critical and highly reactive chemical species responsible\nfor key physical and chemical processes in the mesosphere and lower\nthermosphere.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-03T04:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.02268v1","title":"Advancing Semantic Caching for LLMs with Domain-Specific Embeddings and\n  Synthetic Data","summary":"This report investigates enhancing semantic caching effectiveness by\nemploying specialized, fine-tuned embedding models. Semantic caching relies on\nembedding similarity rather than exact key matching, presenting unique\nchallenges in balancing precision, query latency, and computational efficiency.\nWe propose leveraging smaller, domain-specific embedding models, fine-tuned\nwith targeted real-world and synthetically generated datasets. Our empirical\nevaluations demonstrate that compact embedding models fine-tuned for just one\nepoch on specialized datasets significantly surpass both state-of-the-art\nopen-source and proprietary alternatives in precision and recall. Moreover, we\nintroduce a novel synthetic data generation pipeline for the semantic cache\nthat mitigates the challenge of limited domain-specific annotated data, further\nboosting embedding performance. Our approach effectively balances computational\noverhead and accuracy, establishing a viable and efficient strategy for\npractical semantic caching implementations.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-03T04:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.02272v1","title":"Generative Classifier for Domain Generalization","summary":"Domain generalization (DG) aims to improve the generalizability of computer\nvision models toward distribution shifts. The mainstream DG methods focus on\nlearning domain invariance, however, such methods overlook the potential\ninherent in domain-specific information. While the prevailing practice of\ndiscriminative linear classifier has been tailored to domain-invariant\nfeatures, it struggles when confronted with diverse domain-specific\ninformation, e.g., intra-class shifts, that exhibits multi-modality. To address\nthese issues, we explore the theoretical implications of relying on domain\ninvariance, revealing the crucial role of domain-specific information in\nmitigating the target risk for DG. Drawing from these insights, we propose\nGenerative Classifier-driven Domain Generalization (GCDG), introducing a\ngenerative paradigm for the DG classifier based on Gaussian Mixture Models\n(GMMs) for each class across domains. GCDG consists of three key modules:\nHeterogeneity Learning Classifier~(HLC), Spurious Correlation Blocking~(SCB),\nand Diverse Component Balancing~(DCB). Concretely, HLC attempts to model the\nfeature distributions and thereby capture valuable domain-specific information\nvia GMMs. SCB identifies the neural units containing spurious correlations and\nperturbs them, mitigating the risk of HLC learning spurious patterns.\nMeanwhile, DCB ensures a balanced contribution of components in HLC, preventing\nthe underestimation or neglect of critical components. In this way, GCDG excels\nin capturing the nuances of domain-specific information characterized by\ndiverse distributions. GCDG demonstrates the potential to reduce the target\nrisk and encourage flat minima, improving the generalizability. Extensive\nexperiments show GCDG's comparable performance on five DG benchmarks and one\nface anti-spoofing dataset, seamlessly integrating into existing DG methods\nwith consistent improvements.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T04:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.02279v1","title":"MultiTSF: Transformer-based Sensor Fusion for Human-Centric Multi-view\n  and Multi-modal Action Recognition","summary":"Action recognition from multi-modal and multi-view observations holds\nsignificant potential for applications in surveillance, robotics, and smart\nenvironments. However, existing methods often fall short of addressing\nreal-world challenges such as diverse environmental conditions, strict sensor\nsynchronization, and the need for fine-grained annotations. In this study, we\npropose the Multi-modal Multi-view Transformer-based Sensor Fusion (MultiTSF).\nThe proposed method leverages a Transformer-based to dynamically model\ninter-view relationships and capture temporal dependencies across multiple\nviews. Additionally, we introduce a Human Detection Module to generate\npseudo-ground-truth labels, enabling the model to prioritize frames containing\nhuman activity and enhance spatial feature learning. Comprehensive experiments\nconducted on our in-house MultiSensor-Home dataset and the existing MM-Office\ndataset demonstrate that MultiTSF outperforms state-of-the-art methods in both\nvideo sequence-level and frame-level action recognition settings.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T05:04:05Z"}
{"aid":"http://arxiv.org/abs/2504.02280v1","title":"LLM-Guided Evolution: An Autonomous Model Optimization for Object\n  Detection","summary":"In machine learning, Neural Architecture Search (NAS) requires domain\nknowledge of model design and a large amount of trial-and-error to achieve\npromising performance. Meanwhile, evolutionary algorithms have traditionally\nrelied on fixed rules and pre-defined building blocks. The Large Language Model\n(LLM)-Guided Evolution (GE) framework transformed this approach by\nincorporating LLMs to directly modify model source code for image\nclassification algorithms on CIFAR data and intelligently guide mutations and\ncrossovers. A key element of LLM-GE is the \"Evolution of Thought\" (EoT)\ntechnique, which establishes feedback loops, allowing LLMs to refine their\ndecisions iteratively based on how previous operations performed. In this\nstudy, we perform NAS for object detection by improving LLM-GE to modify the\narchitecture of You Only Look Once (YOLO) models to enhance performance on the\nKITTI dataset. Our approach intelligently adjusts the design and settings of\nYOLO to find the optimal algorithms against objective such as detection\naccuracy and speed. We show that LLM-GE produced variants with significant\nperformance improvements, such as an increase in Mean Average Precision from\n92.5% to 94.5%. This result highlights the flexibility and effectiveness of\nLLM-GE on real-world challenges, offering a novel paradigm for automated\nmachine learning that combines LLM-driven reasoning with evolutionary\nstrategies.","main_category":"cs.NE","categories":"cs.NE,cs.CV","published":"2025-04-03T05:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.02285v1","title":"Tree-based Models for Vertical Federated Learning: A Survey","summary":"Tree-based models have achieved great success in a wide range of real-world\napplications due to their effectiveness, robustness, and interpretability,\nwhich inspired people to apply them in vertical federated learning (VFL)\nscenarios in recent years. In this paper, we conduct a comprehensive study to\ngive an overall picture of applying tree-based models in VFL, from the\nperspective of their communication and computation protocols. We categorize\ntree-based models in VFL into two types, i.e., feature-gathering models and\nlabel-scattering models, and provide a detailed discussion regarding their\ncharacteristics, advantages, privacy protection mechanisms, and applications.\nThis study also focuses on the implementation of tree-based models in VFL,\nsummarizing several design principles for better satisfying various\nrequirements from both academic research and industrial deployment. We conduct\na series of experiments to provide empirical observations on the differences\nand advances of different types of tree-based models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T05:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.02287v1","title":"MultiSensor-Home: A Wide-area Multi-modal Multi-view Dataset for Action\n  Recognition and Transformer-based Sensor Fusion","summary":"Multi-modal multi-view action recognition is a rapidly growing field in\ncomputer vision, offering significant potential for applications in\nsurveillance. However, current datasets often fail to address real-world\nchallenges such as wide-area environmental conditions, asynchronous data\nstreams, and the lack of frame-level annotations. Furthermore, existing methods\nface difficulties in effectively modeling inter-view relationships and\nenhancing spatial feature learning. In this study, we propose the Multi-modal\nMulti-view Transformer-based Sensor Fusion (MultiTSF) method and introduce the\nMultiSensor-Home dataset, a novel benchmark designed for comprehensive action\nrecognition in home environments. The MultiSensor-Home dataset features\nuntrimmed videos captured by distributed sensors, providing high-resolution RGB\nand audio data along with detailed multi-view frame-level action labels. The\nproposed MultiTSF method leverages a Transformer-based fusion mechanism to\ndynamically model inter-view relationships. Furthermore, the method also\nintegrates a external human detection module to enhance spatial feature\nlearning. Experiments on MultiSensor-Home and MM-Office datasets demonstrate\nthe superiority of MultiTSF over the state-of-the-art methods. The quantitative\nand qualitative results highlight the effectiveness of the proposed method in\nadvancing real-world multi-modal multi-view action recognition.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T05:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.02294v1","title":"Search for Fast Radio Bursts and radio pulsars from pulsing\n  Ultraluminous X-ray Sources","summary":"We conducted targeted fast radio burst (FRB) and pulsar searches on eight\npulsing ultraluminous X-ray sources (PULXs) using the Five-hundred-meter\nAperture Spherical Radio Telescope (FAST) and the Parkes 64-meter Radio\nTelescope (Murriyang) to investigate whether PULXs could be progenitors of\nFRBs. FAST carried out 12 observations of four PULXs, totaling 8 hours, while\nParkes conducted 12 observations of the remaining four PULXs, totaling 11\nhours. No significant signals were detected through single-pulse and periodic\nsearches, covering a dispersion measure (DM) range of 0-5000 pc cm$^{-3}$,\nplacing stringent upper limits on the radio flux density from these sources.\nThe results imply that accretion processes and dense stellar winds in PULXs\nlikely suppress or attenuate potential coherent emission in radio band.\nAdditionally, the beaming factor and luminosity of FRBs associated with PULXs,\nas well as the highly relativistic and magnetized nature of their outflows, may\nlimit detectability. Non-detection yielded from the observations covering the\nfull orbital phases of PULXs can also constrain the theoretical models that\nlink FRB emission to highly magnetized neutron stars in binary systems.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-03T05:49:34Z"}
{"aid":"http://arxiv.org/abs/2504.02314v1","title":"Mapped interacting boson model for nuclear structure studies","summary":"The present status of the mapped interacting boson model studies on nuclear\nstructure is reviewed. With the assumption that the nuclear surface deformation\ninduced by the multi-nucleon dynamics is simulated by bosonic degrees of\nfreedom, the interacting-boson Hamiltonian that provides energy spectra and\nwave functions is determined by mapping the potential energy surface that is\nobtained from self-consistent mean-field calculations based on the energy\ndensity functional onto the corresponding energy surface of the boson system.\nThis procedure has been shown to be valid in general cases of the quadrupole\ncollective states, and has allowed for systematic studies on spectroscopic\nproperties of medium-heavy and heavy nuclei, including those that are far from\nthe line of $\\beta$ stability. The method is extended to study intriguing\nnuclear structure phenomena that include shape phase transitions and\ncoexistence, octupole deformation and collectivity, and the coupling of the\nsingle-particle to collective degrees of freedom, which is crucial to describe\nstructures of odd nuclei, and $\\beta$ and $\\beta\\beta$ decays.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-03T06:42:58Z"}
{"aid":"http://arxiv.org/abs/2504.02323v1","title":"CoTAL: Human-in-the-Loop Prompt Engineering, Chain-of-Thought Reasoning,\n  and Active Learning for Generalizable Formative Assessment Scoring","summary":"Large language models (LLMs) have created new opportunities to assist\nteachers and support student learning. Methods such as chain-of-thought (CoT)\nprompting enable LLMs to grade formative assessments in science, providing\nscores and relevant feedback to students. However, the extent to which these\nmethods generalize across curricula in multiple domains (such as science,\ncomputing, and engineering) remains largely untested. In this paper, we\nintroduce Chain-of-Thought Prompting + Active Learning (CoTAL), an LLM-based\napproach to formative assessment scoring that (1) leverages Evidence-Centered\nDesign (ECD) principles to develop curriculum-aligned formative assessments and\nrubrics, (2) applies human-in-the-loop prompt engineering to automate response\nscoring, and (3) incorporates teacher and student feedback to iteratively\nrefine assessment questions, grading rubrics, and LLM prompts for automated\ngrading. Our findings demonstrate that CoTAL improves GPT-4's scoring\nperformance, achieving gains of up to 24.5% over a non-prompt-engineered\nbaseline. Both teachers and students view CoTAL as effective in scoring and\nexplaining student responses, each providing valuable refinements to enhance\ngrading accuracy and explanation quality.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:53:34Z"}
{"aid":"http://arxiv.org/abs/2504.02332v1","title":"Stability of complex communities: A perspective from discrete-time\n  dynamics","summary":"Understanding the stability of complex communities is a central focus in\necology, many important theoretical advancements have been made to identify\ndrivers of ecological stability. However, previous results often rely on the\ncontinuous-time dynamics, assuming that species have overlapping generations.\nIn contrast, numerous real-world communities consist of species with\nnon-overlapping generations, whose quantitative behavior can only be precisely\nrepresented by discrete-time dynamics rather than continuous ones. Here, we\ndevelop a theoretical framework and propose a metric to quantify the stability\nof complex communities characterized by non-overlapping generations and diverse\ninteraction types. In stark contrast to existing results for overlapping\ngenerations, we find that increasing self-regulation strength first stabilizes\nand then destabilizes complex communities. This pattern is further confirmed in\nboth exploitative (E. aerogenes, P. aurantiaca, P. chlororaphis, P.\ncitronellolis) and competitive (P. putida, P. veroni, S. marcescens) soil\nmicrobial communities. Moreover, we show that communities with diverse\ninteraction types become the most stable, which is corroborated by empirical\nmouse microbial networks. Furthermore, we reveal that the prevalence of weak\ninteractions can stabilize communities, which is consistent with findings from\nexisting microbial experiments. Our analyses of complex communities with\nnon-overlapping generations provide a more comprehensive understanding of\necological stability and informs practical strategies for ecological\nrestoration and control.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.bio-ph","published":"2025-04-03T07:10:52Z"}
{"aid":"http://arxiv.org/abs/2504.02349v1","title":"Large (Vision) Language Models are Unsupervised In-Context Learners","summary":"Recent advances in large language and vision-language models have enabled\nzero-shot inference, allowing models to solve new tasks without task-specific\ntraining. Various adaptation techniques such as prompt engineering, In-Context\nLearning (ICL), and supervised fine-tuning can further enhance the model's\nperformance on a downstream task, but they require substantial manual effort to\nconstruct effective prompts or labeled examples. In this work, we introduce a\njoint inference framework for fully unsupervised adaptation, eliminating the\nneed for manual prompt engineering and labeled examples. Unlike zero-shot\ninference, which makes independent predictions, the joint inference makes\npredictions simultaneously for all inputs in a given task. Since direct joint\ninference involves computationally expensive optimization, we develop efficient\napproximation techniques, leading to two unsupervised adaptation methods:\nunsupervised fine-tuning and unsupervised ICL. We demonstrate the effectiveness\nof our methods across diverse tasks and models, including language-only\nLlama-3.1 on natural language processing tasks, reasoning-oriented Qwen2.5-Math\non grade school math problems, vision-language OpenFlamingo on vision tasks,\nand the API-only access GPT-4o model on massive multi-discipline tasks. Our\nexperiments demonstrate substantial improvements over the standard zero-shot\napproach, including 39% absolute improvement on the challenging GSM8K math\nreasoning dataset. Remarkably, despite being fully unsupervised, our framework\noften performs on par with supervised approaches that rely on ground truth\nlabels.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T07:33:02Z"}
{"aid":"http://arxiv.org/abs/2504.02357v1","title":"ReuseDroid: A VLM-empowered Android UI Test Migrator Boosted by Active\n  Feedback","summary":"GUI testing is an essential quality assurance process in mobile app\ndevelopment. However, the creation and maintenance of GUI tests for mobile apps\nare resource-intensive and costly. Recognizing that many apps share similar\nfunctionalities, researchers have proposed various techniques to migrate GUI\ntests from one app to another with similar features. For example, some\ntechniques employ mapping-based approaches to align the GUI elements traversed\nby the tests of a source app to those present in the target app. Other test\nmigration techniques have also been proposed to leverage large language models\n(LLMs) by adapting the GUI tasks in source tests. However, these techniques are\nineffective in dealing with different operational logic between the source and\ntarget apps. The semantics of GUI elements may not be correctly inferred due to\nthe missing analysis of these flows. In this work, we propose REUSEDROID, a\nnovel multiagent framework for GUI test migration empowered by Large\nVision-Language Models (VLMs). REUSEDROID is powered by multiple VLM-based\nagents, each tackling a stage of the test migration process by leveraging the\nrelevant visual and textual information embedded in GUI pages. An insight of\nREUSEDROID is to migrate tests based only on the core logic shared across\nsimilar apps, while their entire operational logic could differ. We evaluate\nREUSEDROID on LinPro, a new test migration dataset that consists of 578\nmigration tasks for 39 popular apps across 4 categories. The experimental\nresult shows that REUSEDROID can successfully migrate 90.3% of the migration\ntasks, outperforming the best mapping-based and LLM-based baselines by 318.1%\nand 109.1%, respectively.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-03T07:45:09Z"}
{"aid":"http://arxiv.org/abs/2504.02363v1","title":"Double groupoids of composites: applications to uniformity","summary":"In this paper we present a geometrical framework to study the uniformity of a\ncomposite material by means of double groupoid theory. The notions of vertical\nand horizontal uniformity are introduced, as well as other weaker ones that\nallows us to study other possible notions of more general uniformity.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-03T07:53:36Z"}
{"aid":"http://arxiv.org/abs/2504.02367v1","title":"CrystalFormer-RL: Reinforcement Fine-Tuning for Materials Design","summary":"Reinforcement fine-tuning has instrumental enhanced the instruction-following\nand reasoning abilities of large language models. In this work, we explore the\napplications of reinforcement fine-tuning to the autoregressive\ntransformer-based materials generative model CrystalFormer (arXiv:2403.15734)\nusing discriminative machine learning models such as interatomic potentials and\nproperty prediction models. By optimizing reward signals-such as energy above\nthe convex hull and material property figures of merit-reinforcement\nfine-tuning infuses knowledge from discriminative models into generative\nmodels. The resulting model, CrystalFormer-RL, shows enhanced stability in\ngenerated crystals and successfully discovers crystals with desirable yet\nconflicting material properties, such as substantial dielectric constant and\nband gap simultaneously. Notably, we observe that reinforcement fine-tuning\nenables not only the property-guided novel material design ability of\ngenerative pre-trained model but also unlocks property-driven material\nretrieval from the unsupervised pre-training dataset. Leveraging rewards from\ndiscriminative models to fine-tune materials generative models opens an\nexciting gateway to the synergies of the machine learning ecosystem for\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.comp-ph","published":"2025-04-03T07:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.02378v1","title":"Weak Itinerant Ferromagnetism (WIFM) in MAX phase compound\n  Cr$_{1.9}$Fe$_{0.1}$GeC","summary":"Magnetic MAX phase compounds are important materials for studying the\ntwo-dimensional magnetism because of their layered crystallographic structure.\nThe hexagonal MAX phase compound Cr$_2$GeC is a Pauli paramagnet, and here we\nreport the induction of an ordered magnetic state by doping Fe at the Cr site.\nInduced magnetism for small doping concentrations (indicated as 5% and 2.5%) is\nfound to have a weak itinerant ferromagnetic character. The Rhodes-Wolhfarth\nratio is found to be 13.29, while the coefficient of electronic heat capacity\n($\\Gamma$) is 27 mJ-mol$^{-1}$K$^{-2}$ for Cr$_{1.9}$Fe$_{0.1}$GeC. Our x-ray\nmagnetic circular dichorism measurement confirms that the magnetic moment\narises from the Fe atom only, and Cr has negligible contribution towards the\nordered moment. Our critical analysis indicates that the magnetic phase\ntransition in Cr$_{1.9}$Fe$_{0.1}$GeC follows mean field theory.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-03T08:15:51Z"}
{"aid":"http://arxiv.org/abs/2504.02380v1","title":"Beyond Asymptotics: Targeted exploration with finite-sample guarantees","summary":"In this paper, we introduce a targeted exploration strategy for the\nnon-asymptotic, finite-time case. The proposed strategy is applicable to\nuncertain linear time-invariant systems subject to sub-Gaussian disturbances.\nAs the main result, the proposed approach provides a priori guarantees,\nensuring that the optimized exploration inputs achieve a desired accuracy of\nthe model parameters. The technical derivation of the strategy (i) leverages\nexisting non-asymptotic identification bounds with self-normalized martingales,\n(ii) utilizes spectral lines to predict the effect of sinusoidal excitation,\nand (iii) effectively accounts for spectral transient error and parametric\nuncertainty. A numerical example illustrates how the finite exploration time\ninfluence the required exploration energy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T08:17:17Z"}
{"aid":"http://arxiv.org/abs/2504.02384v1","title":"Resistive switching characteristics of Cu/MgO/MoS2/Cu structure","summary":"During the study of resistive switching devices, researchers have found that\nthe influence of the insertion layer cannot be ignored. Many reports have\nconfirmed that the appropriate insertion layer can significantly improve the\nperformance of the resistive switching devices. Therefore, in this work, we use\nmagnetron sputtering to fabricate three devices: Cu/MgO/Cu, Cu/MgO/MoS2/Cu and\nCu/MoS2/MgO/Cu. Through the characterization test of each device and the\nmeasurement of the I-V curve, it is found that the resistive switching\ncharacteristics of the Cu/MgO/Cu device will change greatly after adding an\nMoS2 insertion layer. The analysis results show that the inserted MoS2 layer\ndoes not change the main transmission mechanism (space charge limited\nconduction) of the device, but affects the regulating function of interfacial\npotential barrier, the effect also is related to the location of MoS2 inserted\ninto the layer. Among the Cu/MgO/Cu, Cu/MgO/MoS2/Cu and Cu/MoS2/MgO/Cu devices,\nthe Cu/MgO/MoS2/Cu device exhibits a larger switching ratio (about 103) and a\nlower reset voltage (about 0.21 V), which can be attributed to the regulation\nof the interface barrier between MgO and MoS2. In addition, when the MoS2 layer\nis inserted between the bottom electrodes Cu and MgO, the leakage current of\nthe device is significantly reduced. Therefore, Cu/MoS2/MgO/Cu device has the\nhighest commercial value from the point of view of practical applications.\nFinally, according to the XPS results and XRD results, we establish the\nconductive filament models for the three devices, and analyze the reasons for\nthe different resistive switching characteristics of the three devices.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-03T08:22:36Z"}
{"aid":"http://arxiv.org/abs/2504.02385v1","title":"Quantum singular value transformation without block encodings:\n  Near-optimal complexity with minimal ancilla","summary":"We develop new algorithms for Quantum Singular Value Transformation (QSVT), a\nunifying framework underlying a wide range of quantum algorithms. Existing\nimplementations of QSVT rely on block encoding, incurring $O(\\log L)$ ancilla\noverhead and circuit depth $\\widetilde{O}(d\\lambda L)$ for polynomial\ntransformations of a Hamiltonian $H=\\sum_{k=1}^L \\lambda_k H_k$, where $d$ is\npolynomial degree, and $\\lambda=\\sum_k |\\lambda_k|$. We introduce a new\napproach that eliminates block encoding, needs only a single ancilla qubit, and\nmaintains near-optimal complexity, using only basic Hamiltonian simulation\nmethods such as Trotterization. Our method achieves a circuit depth of\n$\\widetilde{O}(L(d\\lambda_{\\mathrm{comm}})^{1+o(1)})$, without any multi-qubit\ncontrolled gates. Here, $\\lambda_{\\mathrm{comm}}$ depends on the nested\ncommutators of the $H_k$'s and can be much smaller than $\\lambda$. Central to\nour technique is a novel use of Richardson extrapolation, enabling systematic\nerror cancellation in interleaved sequences of arbitrary unitaries and\nHamiltonian evolution operators, establishing a broadly applicable framework\nbeyond QSVT. Additionally, we propose two randomized QSVT algorithms for cases\nwith only sampling access to Hamiltonian terms. The first uses qDRIFT, while\nthe second replaces block encodings in QSVT with randomly sampled unitaries.\nBoth achieve quadratic complexity in $d$, which we establish as a lower bound\nfor any randomized method implementing polynomial transformations in this\nmodel. Finally, as applications, we develop end-to-end quantum algorithms for\nquantum linear systems and ground state property estimation, achieving\nnear-optimal complexity without oracular access. Our results provide a new\nframework for quantum algorithms, reducing hardware overhead while maintaining\nnear-optimal performance, with implications for both near-term and\nfault-tolerant quantum computing.","main_category":"quant-ph","categories":"quant-ph,cs.DS","published":"2025-04-03T08:24:15Z"}
{"aid":"http://arxiv.org/abs/2504.02391v1","title":"Marine Saliency Segmenter: Object-Focused Conditional Diffusion with\n  Region-Level Semantic Knowledge Distillation","summary":"Marine Saliency Segmentation (MSS) plays a pivotal role in various\nvision-based marine exploration tasks. However, existing marine segmentation\ntechniques face the dilemma of object mislocalization and imprecise boundaries\ndue to the complex underwater environment. Meanwhile, despite the impressive\nperformance of diffusion models in visual segmentation, there remains potential\nto further leverage contextual semantics to enhance feature learning of\nregion-level salient objects, thereby improving segmentation outcomes. Building\non this insight, we propose DiffMSS, a novel marine saliency segmenter based on\nthe diffusion model, which utilizes semantic knowledge distillation to guide\nthe segmentation of marine salient objects. Specifically, we design a\nregion-word similarity matching mechanism to identify salient terms at the word\nlevel from the text descriptions. These high-level semantic features guide the\nconditional feature learning network in generating salient and accurate\ndiffusion conditions with semantic knowledge distillation. To further refine\nthe segmentation of fine-grained structures in unique marine organisms, we\ndevelop the dedicated consensus deterministic sampling to suppress\noverconfident missegmentations. Comprehensive experiments demonstrate the\nsuperior performance of DiffMSS over state-of-the-art methods in both\nquantitative and qualitative evaluations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T08:31:36Z"}
{"aid":"http://arxiv.org/abs/2504.02397v1","title":"Learning Audio-guided Video Representation with Gated Attention for\n  Video-Text Retrieval","summary":"Video-text retrieval, the task of retrieving videos based on a textual query\nor vice versa, is of paramount importance for video understanding and\nmultimodal information retrieval. Recent methods in this area rely primarily on\nvisual and textual features and often ignore audio, although it helps enhance\noverall comprehension of video content. Moreover, traditional models that\nincorporate audio blindly utilize the audio input regardless of whether it is\nuseful or not, resulting in suboptimal video representation. To address these\nlimitations, we propose a novel video-text retrieval framework, Audio-guided\nVIdeo representation learning with GATEd attention (AVIGATE), that effectively\nleverages audio cues through a gated attention mechanism that selectively\nfilters out uninformative audio signals. In addition, we propose an adaptive\nmargin-based contrastive loss to deal with the inherently unclear\npositive-negative relationship between video and text, which facilitates\nlearning better video-text alignment. Our extensive experiments demonstrate\nthat AVIGATE achieves state-of-the-art performance on all the public\nbenchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T08:45:36Z"}
{"aid":"http://arxiv.org/abs/2504.02415v1","title":"Unveiling Spatiotemporal Properties of the Quasi-periodic Pulsations in\n  the Balmer Continuum at 3600 Ã in an X-class Solar White-light Flare","summary":"Quasi-periodic pulsations (QPPs) in the Balmer continuum of solar white-light\nflares (WLFs) are rarely reported, and accurately pinpointing the spatial\nsource of flaring QPPs remains a significant challenge. We present\nspatiotemporal characteristics of QPPs of an X2.8 two-ribbon solar WLF\n(SOL2023-12-14T17:02), which was well observed by the White-light Solar\nTelescope (WST) aboard the Advanced Space-based Solar Observatory, with\nhigh-cadence imaging (1--2 s) in the Balmer continuum at 3600 \\AA. Combined\nwith additional multi-instrument data, we find that the enhancement of the WLF\nin both Balmer and Paschen continua shows strong spatiotemporal correlation\nwith hard X-ray (HXR) emissions. Notably, the pulses in the WST Balmer\ncontinuum exhibited a near-zero time lag with most HXR pulses, whereas soft\nX-ray and extreme ultraviolet emissions showed a lag of 2--3 s. Interestingly,\nquasi-harmonic QPPs with periods of $\\sim$11 s and $\\sim$20 s were observed in\nmultiple wavelengths in the rising phase of the white-light continuum.\nFurthermore, we employed Fourier transform to spatially locate the QPPs around\n11 and 20 s, revealing that they primarily originated from the east flare\nribbon, which exhibited the most substantial continuum enhancement. More\ninterestingly, we find that the west ribbon contributed significantly to the\n11-second QPP but had a weaker contribution to the 20-second QPP. Moreover, the\noccurrence of quasi-harmonic QPPs is temporally coincident with the rapid\nelongation and separation motions of flare ribbons. Possible mechanisms for the\nquasi-harmonic QPPs have been discussed. These observations provide valuable\ninsights into QPP modeling for solar and stellar flares.","main_category":"astro-ph.SR","categories":"astro-ph.SR,J.2","published":"2025-04-03T09:12:01Z"}
{"aid":"http://arxiv.org/abs/2504.02417v1","title":"Leveraging Static Relationships for Intra-Type and Inter-Type Message\n  Passing in Video Question Answering","summary":"Video Question Answering (VideoQA) is an important research direction in the\nfield of artificial intelligence, enabling machines to understand video content\nand perform reasoning and answering based on natural language questions.\nAlthough methods based on static relationship reasoning have made certain\nprogress, there are still deficiencies in the accuracy of static relationship\nrecognition and representation, and they have not fully utilized the static\nrelationship information in videos for in-depth reasoning and analysis.\nTherefore, this paper proposes a reasoning method for intra-type and inter-type\nmessage passing based on static relationships. This method constructs a dual\ngraph for intra-type message passing reasoning and builds a heterogeneous graph\nbased on static relationships for inter-type message passing reasoning. The\nintra-type message passing reasoning model captures the neighborhood\ninformation of targets and relationships related to the question in the dual\ngraph, updating the dual graph to obtain intra-type clues for answering the\nquestion. The inter-type message passing reasoning model captures the\nneighborhood information of targets and relationships from different categories\nrelated to the question in the heterogeneous graph, updating the heterogeneous\ngraph to obtain inter-type clues for answering the question. Finally, the\nanswers are inferred by combining the intra-type and inter-type clues based on\nstatic relationships. Experimental results on the ANetQA and Next-QA datasets\ndemonstrate the effectiveness of this method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T09:14:41Z"}
{"aid":"http://arxiv.org/abs/2504.02420v1","title":"On learning racing policies with reinforcement learning","summary":"Fully autonomous vehicles promise enhanced safety and efficiency. However,\nensuring reliable operation in challenging corner cases requires control\nalgorithms capable of performing at the vehicle limits. We address this\nrequirement by considering the task of autonomous racing and propose solving it\nby learning a racing policy using Reinforcement Learning (RL). Our approach\nleverages domain randomization, actuator dynamics modeling, and policy\narchitecture design to enable reliable and safe zero-shot deployment on a real\nplatform. Evaluated on the F1TENTH race car, our RL policy not only surpasses a\nstate-of-the-art Model Predictive Control (MPC), but, to the best of our\nknowledge, also represents the first instance of an RL policy outperforming\nexpert human drivers in RC racing. This work identifies the key factors driving\nthis performance improvement, providing critical insights for the design of\nrobust RL-based control strategies for autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-03T09:21:48Z"}
{"aid":"http://arxiv.org/abs/2504.02424v1","title":"Designing optimal elastic filaments for viscous propulsion","summary":"The propulsion of many eukaryotic cells is generated by flagella, flexible\nslender filaments that are actively oscillating in space and time. The dynamics\nof these biological appendages have inspired the design of many types of\nartificial microswimmers. The magnitude of the filament's viscous propulsion\ndepends on the time-varying shape of the filament, and that shape depends in\nturn on the spatial distribution of the bending rigidity of the filament. In\nthis work, we rigorously determine the relationship between the mechanical\n(bending) properties of the filament and the viscous thrust it produces using\nmathematical optimisation. Specifically, by considering a model system (a\nslender elastic filament with an oscillating slope at its base), we derive the\noptimal bending rigidity function along the filament that maximises the\ntime-averaged thrust produced by the actuated filament. Instead of prescribing\na specific functional form, we use functional optimisation and adjoint-based\nvariational calculus to formally establish the link between the distribution of\nbending rigidity and propulsion. The optimal rigidities are found to be stiff\nnear the base, and soft near the distal end, with a spatial distribution that\ndepends critically on the constraints used in the optimisation procedure. These\nfindings may guide the optimal design of future artificial swimmers.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-03T09:28:32Z"}
{"aid":"http://arxiv.org/abs/2504.02428v1","title":"Semigroup Congruences and Subsemigroups of the Direct Square","summary":"We investigate semigroups $S$ which have the property that every subsemigroup\nof $S\\times S$ which contains the diagonal $\\{ (s,s)\\colon s\\in S\\}$ is\nnecessarily a congruence on $S$. We call such $S$ a DSC semigroup. It is well\nknown that all finite groups are DSC, and easy to see that every DSC semigroup\nmust be simple. Building on this, we show that for broad classes of semigroups\n-- including periodic, stable, inverse and several well-known types of simple\nsemigroups -- the only DSC members are groups. However, it turns out that there\nexist non-group DSC semigroups, which we obtain utilising a construction\nintroduced by Byleen for the purpose of constructing interesting\ncongruence-free semigroups. Such examples can additionally be regular or\nbisimple.","main_category":"math.RA","categories":"math.RA,math.GR","published":"2025-04-03T09:33:50Z"}
{"aid":"http://arxiv.org/abs/2504.02453v1","title":"Heavy meson lightcone distribution amplitudes from Lattice QCD","summary":"Lightcone distribution amplitudes (LCDAs) within the framework of heavy quark\neffective theory (HQET) play a crucial role in the theoretical description of\nweak decays of heavy bottom mesons. However, the first-principle determination\nof HQET LCDAs faces significant theoretical challenges. In this presentation,\nwe introduce a practical approach to address these obstacles. This makes\nsequential use of effective field theories. Leveraging the newly-generated\nlattice ensembles, we present a pioneering lattice calculation, offering new\ninsights into LCDAs for heavy mesons. Additionally, we discuss the impact of\nthese results on the heavy-to-light form factors and briefly give potential\nfuture directions in this field.","main_category":"hep-lat","categories":"hep-lat,hep-ex,hep-ph","published":"2025-04-03T10:17:38Z"}
{"aid":"http://arxiv.org/abs/2504.02455v1","title":"QPanda3: A High-Performance Software-Hardware Collaborative Framework\n  for Large-Scale Quantum-Classical Computing Integration","summary":"QPanda3 is a high-performance quantum programming framework that enhances\nquantum computing efficiency through optimized circuit compilation, an advanced\ninstruction stream format (OriginBIS), and hardware-aware execution strategies.\nThese engineering optimizations significantly improve both processing speed and\nsystem performance, addressing key challenges in the NISQ era. A core\ninnovation, OriginBIS, accelerates encoding speeds by up to 86.9x compared to\nOpenQASM 2.0, while decoding is 35.6x faster, leading to more efficient data\nhandling, reduced memory overhead, and improved communication efficiency. This\ndirectly enhances the execution of quantum circuits, making large-scale quantum\nsimulations more feasible. Comprehensive benchmarking demonstrates QPanda3's\nsuperior performance: quantum circuit construction is 20.7x faster, execution\nspeeds improve by 3.4x, and transpilation efficiency increases by 14.97x over\nQiskit. Notably, in compiling a 118-qubit W-state circuit on a 2D-grid\ntopology, QPanda3 achieves an unprecedented 869.9x speedup, underscoring its\nability to handle complex quantum workloads at scale. By combining high-speed\nquantum processing with a modular and extensible software architecture, QPanda3\nprovides a practical bridge between today's NISQ devices and future\nfault-tolerant quantum computing. It facilitates real-world applications in\nfinancial modeling, materials science, and combinatorial optimization, while\nits robust and scalable design supports industrial adoption and cloud-based\ndeployment.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-03T10:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.02462v1","title":"Gravitational Wave with Domain Wall Dominance","summary":"Domain walls (DWs) can be produced when a discrete symmetry is spontaneously\nbroken, and long-lived DWs can dominate the energy density of the universe. In\nthis work, we explore the possibility that a \"domain wall dominant (DWD)\" phase\nexisted in the early universe and ended with DW decay. During the DWD phase,\nthe universe undergoes a power-law accelerated expansion of the scale factor\nand exhibits temporal superhorizon evolution of the relevant frequency modes.\nWe show that this can lead to distinct features imprinted on the stochastic\ngravitational wave (GW) background. Our findings provide a comprehensive\nframework for evaluating GW emission associated with DWD, leading to\ndistinguishable long-lived DW-induced GWs from other cosmological sources, with\nsignificant implications for future GW observatories.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-03T10:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.02463v1","title":"Evaluating AI Recruitment Sourcing Tools by Human Preference","summary":"This study introduces a benchmarking methodology designed to evaluate the\nperformance of AI-driven recruitment sourcing tools. We created and utilized a\ndataset to perform a comparative analysis of search results generated by\nleading AI-based solutions, LinkedIn Recruiter, and our proprietary system,\nPearch.ai. Human experts assessed the relevance of the returned candidates, and\nan Elo rating system was applied to quantitatively measure each tool's\ncomparative performance. Our findings indicate that AI-driven recruitment\nsourcing tools consistently outperform LinkedIn Recruiter in candidate\nrelevance, with Pearch.ai achieving the highest performance scores.\nFurthermore, we found a strong alignment between AI-based evaluations and human\njudgments, highlighting the potential for advanced AI technologies to\nsubstantially enhance talent acquisition effectiveness. Code and supporting\ndata are publicly available at\nhttps://github.com/vslaykovsky/ai-sourcing-benchmark","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-03T10:33:43Z"}
{"aid":"http://arxiv.org/abs/2504.02469v1","title":"An MHD Simulation of the Possible Modulations of Stellar CMEs Radio\n  Observations by an Exoplanetary Magnetosphere","summary":"Type II radio bursts are the indicator of adverse space weather in a stellar\nsystem. These radio bursts are the consequence of shock wave acceleration due\nto the coronal mass ejection (CME). Here, we perform a series of\nmagnetohydrodynamic (MHD) simulations of a CME-driven star-planet system in\norder to investigate the modulation in radio burst mechanism by a close-in\nexoplanetary system. We use a model for the stellar wind with a close-in\nexoplanet, and a CME model based on the eruption of a flux rope. We are able to\ngenerate synthetic radio burst images from our MHD simulations. We find that\nradio burst like phenomena is most likely to be observed for moderately active\nsolar like stars and close-in exoplanetary systems have significant influence\non the nature of radio burst spectrum. We find that when the planetary field is\nnot too strong, the planetary magnetosphere is pushing against the CME,\nincreasing its density so the radio burst is visible at higher frequencies.\nWhen the planetary field is very strong, the large magnetosphere does not leave\nroom for the CME shock to evolve so the radio burst is more visible in the\nlower frequencies associated with the weak compression at the flanks of the CME\nshock. In case of highly active solar-like stars, strong overlying stellar\nfields weakens the solar-like CME shock, thus generates very weak (almost\nnon-visible) radio burst signals. For HD 189733 (moderate stellar field), only\nintensity difference is visible when the CME arrives the planet. We also do not\nfind significant modulation in the radio emission by a close-in exoplanet\nsystem when the stellar magnetic field is complex. In summary, our result\nsuggests that the nature of the radio burst spectrum is highly dependent on the\ntopology of the stellar magnetic field and the close-in exoplanetary magnetic\nfield strength.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-03T10:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.02472v1","title":"Polarimetry imprints of exotic compact objects: solitonic boson stars","summary":"In this work we analyze the polarization observational properties of\nsolitonic boson stars orbited by spherical hot-spots emitting synchrotron\nradiation from a thermal distribution of electrons. We consider three boson\nstar configurations with different compacticities ranging from a dilute model\nwith a large radius to an ultra-compact model capable of holding null bound\norbits. We observe that the polarimetric imprints of the primary images for all\nmodels are comparable to those of the Schwarzschild spacetime, and thus any\npotentially distinguishable differences must arise from the additional\nstructure of secondary and plunge-through images. For low inclination\n($20^\\circ$) observations we find that the two QU-loops of the least compact\nmodel are in contradiction with the current ALMA and GRAVITY observations and\neffectively excludes the possibility of Sgr A* being a dilute solitonic boson\nstar. For high inclination ($80^\\circ$) observations, both the Electric Vector\nPosition Angle (EVPA) and the QU-loops present large qualitative deviations\nfrom the Schwarzschild black-hole for all models analyzed. Our results\nemphasize the suitability of polarimetry as a framework to test the nature of\nsupermassive compact objects with future observations, especially at high\ninclination.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-03T10:47:28Z"}
{"aid":"http://arxiv.org/abs/2504.02486v1","title":"We Need Improved Data Curation and Attribution in AI for Scientific\n  Discovery","summary":"As the interplay between human-generated and synthetic data evolves, new\nchallenges arise in scientific discovery concerning the integrity of the data\nand the stability of the models. In this work, we examine the role of synthetic\ndata as opposed to that of real experimental data for scientific research. Our\nanalyses indicate that nearly three-quarters of experimental datasets available\non open-access platforms have relatively low adoption rates, opening new\nopportunities to enhance their discoverability and usability by automated\nmethods. Additionally, we observe an increasing difficulty in distinguishing\nsynthetic from real experimental data. We propose supplementing ongoing efforts\nin automating synthetic data detection by increasing the focus on watermarking\nreal experimental data, thereby strengthening data traceability and integrity.\nOur estimates suggest that watermarking even less than half of the real world\ndata generated annually could help sustain model robustness, while promoting a\nbalanced integration of synthetic and human-generated content.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T11:07:52Z"}
{"aid":"http://arxiv.org/abs/2504.02501v1","title":"Logarithmic $A$-hypergeometric series ${\\textrm I}\\! {\\textrm I}\\!\n  {\\textrm I}$","summary":"This paper is the third in a series exploring Frobenius's method for\n$A$-hypergeometric systems. Frobenius's method is a classical technique for\nconstructing logarithmic series solutions of differential equations by\nperturbing exponents of generic series solutions. We show that all\n$A$-hypergeometric series solutions can be obtained via this method.\n  Building upon our prior studies, we develop a duality framework between\nformal power series and differential operators, introduce minimal vectors with\nrespect to a generic weight, and establish key results on logarithmic\ncoefficients of $A$-hypergeometric series. We extend Frobenius's method and\nprove its sufficiency in constructing all $A$-hypergeometric series solutions.\nFurthermore, we explore conditions under which the Frobenius method developed\nin our previous studies suffices and we pose an open question on the necessity\nof the extended one.","main_category":"math.AG","categories":"math.AG","published":"2025-04-03T11:28:04Z"}
{"aid":"http://arxiv.org/abs/2504.02512v1","title":"Towards Generalizing Temporal Action Segmentation to Unseen Views","summary":"While there has been substantial progress in temporal action segmentation,\nthe challenge to generalize to unseen views remains unaddressed. Hence, we\ndefine a protocol for unseen view action segmentation where camera views for\nevaluating the model are unavailable during training. This includes changing\nfrom top-frontal views to a side view or even more challenging from exocentric\nto egocentric views. Furthermore, we present an approach for temporal action\nsegmentation that tackles this challenge. Our approach leverages a shared\nrepresentation at both the sequence and segment levels to reduce the impact of\nview differences during training. We achieve this by introducing a sequence\nloss and an action loss, which together facilitate consistent video and action\nrepresentations across different views. The evaluation on the Assembly101,\nIkeaASM, and EgoExoLearn datasets demonstrate significant improvements, with a\n12.8% increase in F1@50 for unseen exocentric views and a substantial 54%\nimprovement for unseen egocentric views.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-03T11:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.02518v1","title":"Online Multivariate Regularized Distributional Regression for\n  High-dimensional Probabilistic Electricity Price Forecasting","summary":"Probabilistic electricity price forecasting (PEPF) is a key task for market\nparticipants in short-term electricity markets. The increasing availability of\nhigh-frequency data and the need for real-time decision-making in energy\nmarkets require online estimation methods for efficient model updating. We\npresent an online, multivariate, regularized distributional regression model,\nallowing for the modeling of all distribution parameters conditional on\nexplanatory variables. Our approach is based on the combination of the\nmultivariate distributional regression and an efficient online learning\nalgorithm based on online coordinate descent for LASSO-type regularization.\nAdditionally, we propose to regularize the estimation along a path of\nincreasingly complex dependence structures of the multivariate distribution,\nallowing for parsimonious estimation and early stopping. We validate our\napproach through one of the first forecasting studies focusing on multivariate\nprobabilistic forecasting in the German day-ahead electricity market while\nusing only online estimation methods. We compare our approach to online\nLASSO-ARX-models with adaptive marginal distribution and to online univariate\ndistributional models combined with an adaptive Copula. We show that the\nmultivariate distributional regression, which allows modeling all distribution\nparameters - including the mean and the dependence structure - conditional on\nexplanatory variables such as renewable in-feed or past prices provide superior\nforecasting performance compared to modeling of the marginals only and keeping\na static/unconditional dependence structure. Additionally, online estimation\nyields a speed-up by a factor of 80 to over 400 times compared to batch\nfitting.","main_category":"stat.ML","categories":"stat.ML,econ.EM,q-fin.ST,stat.AP,stat.CO","published":"2025-04-03T12:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.02522v1","title":"Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic\n  Assessment","summary":"The capacity of Vision transformers (ViTs) to handle variable-sized inputs is\noften constrained by computational complexity and batch processing limitations.\nConsequently, ViTs are typically trained on small, fixed-size images obtained\nthrough downscaling or cropping. While reducing computational burden, these\nmethods result in significant information loss, negatively affecting tasks like\nimage aesthetic assessment. We introduce Charm, a novel tokenization approach\nthat preserves Composition, High-resolution, Aspect Ratio, and Multi-scale\ninformation simultaneously. Charm prioritizes high-resolution details in\nspecific regions while downscaling others, enabling shorter fixed-size input\nsequences for ViTs while incorporating essential information. Charm is designed\nto be compatible with pre-trained ViTs and their learned positional embeddings.\nBy providing multiscale input and introducing variety to input tokens, Charm\nimproves ViT performance and generalizability for image aesthetic assessment.\nWe avoid cropping or changing the aspect ratio to further preserve information.\nExtensive experiments demonstrate significant performance improvements on\nvarious image aesthetic and quality assessment datasets (up to 8.1 %) using a\nlightweight ViT backbone. Code and pre-trained models are available at\nhttps://github.com/FBehrad/Charm.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.02527v1","title":"Recent results on strangeness enhancement in small collision systems\n  with ALICE","summary":"Quantum Chromodynamics (QCD) predicts that, at sufficiently high temperature\nand energy density, nuclear matter undergoes a phase transition from confined\nhadrons to a deconfined state of quarks and gluons known as the quark-gluon\nplasma (QGP). One of the historically proposed signatures of QGP formation is\nstrangeness enhancement (SE), characterized by an increased production of\nstrange hadrons in heavy-ion collisions relative to proton--proton (pp)\ninteractions. At the LHC, the ALICE experiment has measured a continuous\nincrease in the strange-to-non-strange hadron yield ratios as a function of\nmidrapidity charged-particle multiplicity, not only in large systems like\nPb--Pb but also in small systems such as pp and p--Pb. The origin of SE in\nsmall systems is still under debate, motivating further experimental\ninvestigations. This article presents recent ALICE analyses that offer\ncomplementary insights into the phenomenon. These include (i)\nmulti-differential studies using event-shape observables such as transverse\nspherocity and the concept of effective energy, and (ii) the first measurement\nof multiplicity distributions of strange and multi-strange hadrons,\nP($\\textit{n}_{S}$), in pp collisions.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T12:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.02534v1","title":"Delineate Anything: Resolution-Agnostic Field Boundary Delineation on\n  Satellite Imagery","summary":"The accurate delineation of agricultural field boundaries from satellite\nimagery is vital for land management and crop monitoring. However, current\nmethods face challenges due to limited dataset sizes, resolution discrepancies,\nand diverse environmental conditions. We address this by reformulating the task\nas instance segmentation and introducing the Field Boundary Instance\nSegmentation - 22M dataset (FBIS-22M), a large-scale, multi-resolution dataset\ncomprising 672,909 high-resolution satellite image patches (ranging from 0.25 m\nto 10 m) and 22,926,427 instance masks of individual fields, significantly\nnarrowing the gap between agricultural datasets and those in other computer\nvision domains. We further propose Delineate Anything, an instance segmentation\nmodel trained on our new FBIS-22M dataset. Our proposed model sets a new\nstate-of-the-art, achieving a substantial improvement of 88.5% in mAP@0.5 and\n103% in mAP@0.5:0.95 over existing methods, while also demonstrating\nsignificantly faster inference and strong zero-shot generalization across\ndiverse image resolutions and unseen geographic regions. Code, pre-trained\nmodels, and the FBIS-22M dataset are available at\nhttps://lavreniuk.github.io/Delineate-Anything.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:37:04Z"}
{"aid":"http://arxiv.org/abs/2504.02548v1","title":"Rapidity spectra in high-energy collisions and longitudinal nuclear\n  suppression from nonadditive statistics","summary":"We investigate the longitudinal nuclear suppression factor defined by a\nscaled ratio of rapidity distributions. To study this experimental observable,\nwe describe three approaches involving numerical and analytical calculations.\nWe first approach this problem by conducting model studies using EPOS,\nFTFP$_{BERT}$, and HIJING, and notice that while EPOS shows a decreasing trend\nof this ratio for increasing rapidity, the latter two model calculations\ndisplay an increment of the ratio. The analytical approaches involve, first,\nthe quasi-exponential distribution obtained from the Tsallis statistics, and\nsecond, the nonadditive Boltzmann transport equation in the relaxation time\napproximation. We notice that our analytical results satisfactorily describe\nNA61 experimental data (for $\\sqrt{s_{NN}}$=6.3, 7.6, 8.8, 12.3, and 17.3 GeV)\nfor the negatively charged pions.","main_category":"nucl-th","categories":"nucl-th,hep-ex,hep-ph,nucl-ex","published":"2025-04-03T12:57:03Z"}
{"aid":"http://arxiv.org/abs/2504.02552v1","title":"Variational convergences under moving anisotropies","summary":"We study the asymptotic behaviour of sequences of integral functionals\ndepending on moving anisotropies. We introduce and describe the relevant\nfunctional setting, establishing uniform Meyers-Serrin type approximations,\nPoincar\\'e inequalities and compactness properties. We prove several\n$\\Gamma$-convergence results, and apply the latter to the study of\n$H$-convergence of anisotropic linear differential operators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T13:06:41Z"}
{"aid":"http://arxiv.org/abs/2504.02553v1","title":"Exploring Individual Factors in the Adoption of LLMs for Specific\n  Software Engineering Tasks","summary":"The advent of Large Language Models (LLMs) is transforming software\ndevelopment, significantly enhancing software engineering processes. Research\nhas explored their role within development teams, focusing on specific tasks\nsuch as artifact generation, decision-making support, and information\nretrieval. Despite the growing body of work on LLMs in software engineering,\nmost studies have centered on broad adoption trends, neglecting the nuanced\nrelationship between individual cognitive and behavioral factors and their\nimpact on task-specific adoption. While factors such as perceived effort and\nperformance expectancy have been explored at a general level, their influence\non distinct software engineering tasks remains underexamined. This gap hinders\nthe development of tailored LLM-based systems (e.g., Generative AI Agents) that\nalign with engineers' specific needs and limits the ability of team leaders to\ndevise effective strategies for fostering LLM adoption in targeted workflows.\nThis study bridges this gap by surveying N=188 software engineers to test the\nrelationship between individual attributes related to technology adoption and\nLLM adoption across five key tasks, using structural equation modeling (SEM).\nThe Unified Theory of Acceptance and Use of Technology (UTAUT2) was applied to\ncharacterize individual adoption behaviors. The findings reveal that\ntask-specific adoption is influenced by distinct factors, some of which\nnegatively impact adoption when considered in isolation, underscoring the\ncomplexity of LLM integration in software engineering. To support effective\nadoption, this article provides actionable recommendations, such as seamlessly\nintegrating LLMs into existing development environments and encouraging\npeer-driven knowledge sharing to enhance information retrieval.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-03T13:07:04Z"}
{"aid":"http://arxiv.org/abs/2504.02555v1","title":"Noise Calibration and Spatial-Frequency Interactive Network for STEM\n  Image Enhancement","summary":"Scanning Transmission Electron Microscopy (STEM) enables the observation of\natomic arrangements at sub-angstrom resolution, allowing for atomically\nresolved analysis of the physical and chemical properties of materials.\nHowever, due to the effects of noise, electron beam damage, sample thickness,\netc, obtaining satisfactory atomic-level images is often challenging. Enhancing\nSTEM images can reveal clearer structural details of materials. Nonetheless,\nexisting STEM image enhancement methods usually overlook unique features in the\nfrequency domain, and existing datasets lack realism and generality. To resolve\nthese issues, in this paper, we develop noise calibration, data synthesis, and\nenhancement methods for STEM images. We first present a STEM noise calibration\nmethod, which is used to synthesize more realistic STEM images. The parameters\nof background noise, scan noise, and pointwise noise are obtained by\nstatistical analysis and fitting of real STEM images containing atoms. Then we\nuse these parameters to develop a more general dataset that considers both\nregular and random atomic arrangements and includes both HAADF and BF mode\nimages. Finally, we design a spatial-frequency interactive network for STEM\nimage enhancement, which can explore the information in the frequency domain\nformed by the periodicity of atomic arrangement. Experimental results show that\nour data is closer to real STEM images and achieves better enhancement\nperformances together with our network. Code will be available at\nhttps://github.com/HeasonLee/SFIN}{https://github.com/HeasonLee/SFIN.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T13:11:57Z"}
{"aid":"http://arxiv.org/abs/2504.02563v1","title":"The rise and fall of radio-luminous merger shocks from a large sample of\n  galaxy cluster simulations","summary":"The generation of merger shocks is a natural outcome of the hierarchical\nprocess of structure formation. As time elapses cosmic structures grow in mass\nand size via mergers and through the continuous accretion of material onto the\npotential wells of dark matter haloes. In particular, some\ndynamically-perturbed galaxy clusters exhibit spectacular non-thermal radio\nfeatures known as radio relics that are believed to trace cluster merger shocks\nat different stages of evolution. These radio shocks are thought to be\nilluminated by the acceleration of cosmic ray electrons in the presence of\nintracluster magnetic fields. In this contribution, we analyse a large sample\nof hydrodynamical, cosmological re-simulations of merging galaxy clusters\nbelonging to The Three Hundred Project to study the median evolution of radio\nrelics as a function of cluster mass and redshift. This synthetic cluster\nmerger sample enables us to compute in detail the luminosity output of radio\nshocks from their onset at core passage to demise.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-03T13:25:25Z"}
{"aid":"http://arxiv.org/abs/2504.02573v1","title":"Generating Function of Loop Reduction by Baikov Representation","summary":"In this work, we study the computation of reduction coefficients for multi\nloop Feynman integrals using generating functions constructed within the Baikov\nrepresentation. Compared with traditional Feynman rules, the Baikov formalism\noffers a more structured and transparent framework, especially well suited for\nanalyzing the reduction problem. We emphasize that, in a variety of nontrivial\ncases including several one loop and selected multi loop examples the\ngenerating functions can be explicitly computed in closed form, often involving\nhypergeometric or elementary functions. These analytic expressions signifi\ncantly simplify the determination of reduction coefficients and enhance their\ninterpretability. The results demonstrate the practicality and potential of\nthis approach, suggesting that the use of generating functions within the\nBaikov representation can serve as a powerful and flexible tool in modern\nFeynman integral reduction, even though its full scope for generic multi-loop\ntopologies remains to be explored.","main_category":"hep-th","categories":"hep-th","published":"2025-04-03T13:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.02575v1","title":"Assessing Geographical and Seasonal Influences on Energy Efficiency of\n  Electric Drayage Trucks","summary":"The electrification of heavy-duty vehicles is a critical pathway towards\nimproved energy efficiency of the freight sector. The current battery electric\ntruck technology poses several challenges to the operations of commercial\nvehicles, such as limited driving range, sensitivity to climate conditions, and\nlong recharging times. Estimating the energy consumption of heavy-duty electric\ntrucks is crucial to assess the feasibility of the fleet electrification and\nits impact on the electric grid. This paper focuses on developing a model-based\nsimulation approach to predict and analyze the energy consumption of drayage\ntrucks used in ports logistic operations, considering seasonal climate\nvariations and geographical characteristics. The paper includes results for\nthree major container ports within the United States, providing region-specific\ninsights into driving range, payload capacity, and charging infrastructure\nrequirements, which will inform decision-makers in integrating electric trucks\ninto the existing drayage operations and plan investments for electric grid\ndevelopment.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T13:39:21Z"}
{"aid":"http://arxiv.org/abs/2504.02599v1","title":"Technical Overview of Recent Developments in Small Modular Reactors in\n  the United States","summary":"Small modular reactors (SMRs) are a class of advanced nuclear fission\nreactors characterized by their compact core size (typically <300 MWe) and\npassive safety systems. Their modular design enables on-site assembly, making\nthem suitable for deployment in locations inaccessible to conventional\nlarge-scale reactors. With rising global energy demand, particularly driven by\nthe growth of AI, SMRs have recently gained attention as a potential solution\nfor powering data centers. This technical review aims to provide the public and\nrelevant stakeholders with a foundational understanding of SMR technology. It\nbegins with an overview of SMR concepts, historical context, and their current\nrole in the U.S. energy mix. Detailed technical summaries of nine selected SMR\ndesigns are then presented, covering core design, fuel systems, reactivity\ncontrol, and safety features. The report also outlines key regulatory\nframeworks, including 10 CFR Part 50, Part 52, and the technology-inclusive,\nrisk-informed, and performance-based framework currently under development.\nFinally, major U.S. programs and legislative efforts supporting SMR deployment\nover the past decade are summarized.","main_category":"physics.soc-ph","categories":"physics.soc-ph,physics.ins-det","published":"2025-04-03T14:01:32Z"}
{"aid":"http://arxiv.org/abs/2504.02615v1","title":"A Hybrid Similarity-Aware Graph Neural Network with Transformer for Node\n  Classification","summary":"Node classification has gained significant importance in graph deep learning\nwith real-world applications such as recommendation systems, drug discovery,\nand citation networks. Graph Convolutional Networks and Graph Transformers have\nachieved superior performance in node classification tasks. However, the key\nconcern with Graph Convolutional Networks is over-squashing, which limits their\nability to capture long-range dependencies in the network. Additionally, Graph\nTransformers face scalability challenges, making it difficult to process large\ngraphs efficiently. To address this, we propose a novel framework, A Hybrid\nSImilarity-Aware Graph Neural Network with Transformer for Node Classification\n(SIGNNet), which capitalizes on local and global structural information,\nenhances the model's capability to effectively capture fine-grained\nrelationships and broader contextual patterns within the graph structure. The\nproposed method leverages Graph Convolutional Networks alongside a score-based\nmechanism to effectively capture local and global node interactions while\naddressing the limitations of over-squashing. Our proposed method employs a\nnovel Personalized PageRank-based node sampling method to address scalability\nissues by generating subgraphs of nodes. Additionally, SIGNNet incorporates a\nnovel attention mechanism, Structure-Aware Multi-Head Attention (SA-MHA), which\nintegrates node structural information for informed attention weighting,\nenabling the model to prioritize nodes based on topological significance.\nExtensive experiments demonstrate the significant improvements achieved by the\nproposed method over existing state-of-the-art methods, with average accuracy\ngains of 6.03%, 5.47%, 4.78%, 19.10%, 19.61%, 7.22%, 19.54%, and 14.94% on\nCora, Citeseer, CS, Wisconsin, Texas, Actor, Cornell and Chameleon datasets,\nrespectively.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-03T14:14:37Z"}
{"aid":"http://arxiv.org/abs/2504.02634v1","title":"The FCC integrated programme: a physics manifesto","summary":"The FCC integrated programme comprises an $\\rm e^+e^-$ high-luminosity\ncircular collider that will produce very large samples of data in an energy\nrange $88 \\le \\sqrt{s} \\le 365$ GeV, followed by a high-energy $\\rm pp$ machine\nthat, with the current baseline plan, will operate at a collision energy of\naround 85 TeV and deliver datasets an order of magnitude larger than those of\nthe HL-LHC. This visionary project will allow for transformative measurements\nacross a very broad range of topics, which in almost all cases will exceed in\nsensitivity the projections of any other proposed facility, and simultaneously\nprovide the best possible opportunity for discovering physics beyond the\nStandard Model. The highlights of the physics programme are presented, together\nwith discussion on the key attributes of the integrated project that enable the\nphysics reach. It is noted that the baseline programme of FCC-ee, in\nparticular, is both flexible and extendable, and also that the synergy and\ncomplementarity of the electron and proton machines, and the sharing of a\ncommon infrastructure, provides a remarkably efficient, timely and\ncost-effective approach to addressing the most pressing open questions in\nelementary particle physics.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-03T14:31:24Z"}
{"aid":"http://arxiv.org/abs/2504.02640v1","title":"RoSMM: A Robust and Secure Multi-Modal Watermarking Framework for\n  Diffusion Models","summary":"Current image watermarking technologies are predominantly categorized into\ntext watermarking techniques and image steganography; however, few methods can\nsimultaneously handle text and image-based watermark data, which limits their\napplicability in complex digital environments. This paper introduces an\ninnovative multi-modal watermarking approach, drawing on the concept of vector\ndiscretization in encoder-based vector quantization. By constructing adjacency\nmatrices, the proposed method enables the transformation of text watermarks\ninto robust image-based representations, providing a novel multi-modal\nwatermarking paradigm for image generation applications. Additionally, this\nstudy presents a newly designed image restoration module to mitigate image\ndegradation caused by transmission losses and various noise interferences,\nthereby ensuring the reliability and integrity of the watermark. Experimental\nresults validate the robustness of the method under multiple noise attacks,\nproviding a secure, scalable, and efficient solution for digital image\ncopyright protection.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-03T14:36:08Z"}
{"aid":"http://arxiv.org/abs/2504.02658v1","title":"MiLo: Efficient Quantized MoE Inference with Mixture of Low-Rank\n  Compensators","summary":"A critical approach for efficiently deploying Mixture-of-Experts (MoE) models\nwith massive parameters is quantization. However, state-of-the-art MoE models\nsuffer from non-negligible accuracy loss with extreme quantization, such as\nunder 4 bits. To address this, we introduce MiLo, a novel method that augments\nhighly quantized MoEs with a mixture of low-rank compensators. These\ncompensators consume only a small amount of additional memory but significantly\nrecover accuracy loss from extreme quantization. MiLo also identifies that\nMoEmodels exhibit distinctive characteristics across weights due to their\nhybrid dense-sparse architectures, and employs adaptive rank selection policies\nalong with iterative optimizations to close the accuracy gap. MiLo does not\nrely on calibration data, allowing it to generalize to different MoE models and\ndatasets without overfitting to a calibration set. To avoid the hardware\ninefficiencies of extreme quantization, such as 3-bit, MiLo develops Tensor\nCore-friendly 3-bit kernels, enabling measured latency speedups on 3-bit\nquantized MoE models. Our evaluation shows that MiLo outperforms existing\nmethods on SoTA MoE models across various tasks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T14:54:17Z"}
{"aid":"http://arxiv.org/abs/2504.02667v1","title":"Compositionality Unlocks Deep Interpretable Models","summary":"We propose $\\chi$-net, an intrinsically interpretable architecture combining\nthe compositional multilinear structure of tensor networks with the\nexpressivity and efficiency of deep neural networks. $\\chi$-nets retain equal\naccuracy compared to their baseline counterparts. Our novel, efficient\ndiagonalisation algorithm, ODT, reveals linear low-rank structure in a\nmultilayer SVHN model. We leverage this toward formal weight-based\ninterpretability and model compression.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T15:07:54Z"}
{"aid":"http://arxiv.org/abs/2504.02671v1","title":"LLM for Complex Reasoning Task: An Exploratory Study in Fermi Problems","summary":"Fermi Problems (FPs) are mathematical reasoning tasks that require human-like\nlogic and numerical reasoning. Unlike other reasoning questions, FPs often\ninvolve real-world impracticalities or ambiguous concepts, making them\nchallenging even for humans to solve. Despite advancements in AI, particularly\nwith large language models (LLMs) in various reasoning tasks, FPs remain\nrelatively under-explored. This work conducted an exploratory study to examine\nthe capabilities and limitations of LLMs in solving FPs. We first evaluated the\noverall performance of three advanced LLMs using a publicly available FP\ndataset. We designed prompts according to the recently proposed TELeR taxonomy,\nincluding a zero-shot scenario. Results indicated that all three LLMs achieved\na fp_score (range between 0 - 1) below 0.5, underscoring the inherent\ndifficulty of these reasoning tasks. To further investigate, we categorized FPs\ninto standard and specific questions, hypothesizing that LLMs would perform\nbetter on standard questions, which are characterized by clarity and\nconciseness, than on specific ones. Comparative experiments confirmed this\nhypothesis, demonstrating that LLMs performed better on standard FPs in terms\nof both accuracy and efficiency.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T15:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.02676v1","title":"Snow: Self-organizing Broadcast Protocol for Cloud","summary":"In large-scale distributed applications, efficient and reliable broadcast\nprotocols are essential for node communication. Tree-based broadcast lacks\nflexibility and may suffer performance degradation or even broadcast failure\nwhen cluster membership changes. Gossip-based broadcast incurs high bandwidth\noverhead and only provides probabilistic delivery guarantees. In tree-based\nbroadcasting, when an internal node leaves, its child nodes need to reconnect\nto a new parent. This process may introduce instability, leading to potential\nmessage duplication and increased transmission latency. However, in cloud\nenvironments, node departures and arrivals are common, causing frequent\nperformance degradation in tree-based broadcasting. This paper introduces Snow,\na self-organizing broadcast protocol designed for cloud environments. Instead,\nit dynamically sends or forwards messages based on each node's membership view,\nultimately forming a broadcast structure resembling a multi-way balanced\ntree(the height difference of leaf nodes is at most 1). Our experimental\nresults showed that Snow maintains message delivery reliability and latency\nguarantees under node churn while maintaining low overhead without sending\nunnecessary redundant messages.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-03T15:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.02687v1","title":"Lower bounds on the normal injectivity radius of hypersurfaces and\n  bounded geometries on manifolds with boundary","summary":"We prove for the first time a pointwise lower estimate of the normal\ninjectivity radius of an embedded hypersurface in an arbitrary Riemannian\nmanifold. Main applications include: (i) a pointwise lower estimate of the\ngraphing radius of a properly embedded hypersurface; (ii) the construction of\nmetrics of bounded geometry on arbitrary manifolds with boundary; (iii) the\nequivalence of the classical (topological) notion of orientation with that of\nthe geometric notion (in the sense of metric measure spaces) on arbitrary\nRiemannian manifolds with boundary. In addition, we prove that every manifold\nwith boundary admits a metric with bounded geometry such that the boundary\nbecomes convex. This result strengthens the justification of a recent notion of\norientation on finite dimensional RCD spaces.","main_category":"math.DG","categories":"math.DG","published":"2025-04-03T15:27:49Z"}
{"aid":"http://arxiv.org/abs/2504.02690v1","title":"Planar Laser-Induced Fluorescence system for Space and Phase-resolved\n  Ion Velocity Distribution Function Measurements","summary":"In this work, we present a planar laser-induced fluorescence (PLIF) system\nfor two-dimensional (2D) spatial and phase-resolved ion velocity distribution\nfunction (IVDF) measurements. A continuous-wave tunable diode laser produces a\nlaser sheet that irradiates the plasma, and the resulting fluorescence is\ncaptured by an intensified CCD (ICCD) camera. Fluorescence images recorded at\nvarying laser wavelengths are converted into 2D IVDFs using the Doppler shift\nprinciple. Comparing six image filters, the singular-value decomposition\n(SVD)-based noise filtering is identified as the most effective for enhancing\nthe signal-to-noise ratio while preserving the IVDF structure. The developed\nICCD-based PLIF system is tested in an electron-beam generated $E \\times B$\nplasma with a moderate bulk plasma density of $\\sim10^{10}$ $cm^{-3}$. The PLIF\nmeasurements are validated against a conventional single-point LIF method using\nphotomultiplier tube (PMT)-based detection at various positions. The\nphase-resolving capability of the system is tested by oscillating the plasma\nbetween two nominal operating modes with different density profiles and\ntriggering the ICCD camera with the externally driven plasma oscillation. The\nresulting oscillations in fluorescence intensity show good agreement with\nplasma density variations measured by electrostatic probes, demonstrating the\nsystems ability to resolve phase-dependent dynamics. The measured IVDFs reveal\nseveral signatures of ion dynamics in this plasma source, including radially\noutflowing ions and anomalous ion heating in the plasma periphery, as\nanticipated by theoretical studies.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T15:29:28Z"}
{"aid":"http://arxiv.org/abs/2504.02694v1","title":"Semiparametric Counterfactual Regression","summary":"We study counterfactual regression, which aims to map input features to\noutcomes under hypothetical scenarios that differ from those observed in the\ndata. This is particularly useful for decision-making when adapting to sudden\nshifts in treatment patterns is essential. We propose a doubly robust-style\nestimator for counterfactual regression within a generalizable framework that\naccommodates a broad class of risk functions and flexible constraints, drawing\non tools from semiparametric theory and stochastic optimization. Our approach\nuses incremental interventions to enhance adaptability while maintaining\nconsistency with standard methods. We formulate the target estimand as the\noptimal solution to a stochastic optimization problem and develop an efficient\nestimation strategy, where we can leverage rapid development of modern\noptimization algorithms. We go on to analyze the rates of convergence and\ncharacterize the asymptotic distributions. Our analysis shows that the proposed\nestimators can achieve $\\sqrt{n}$-consistency and asymptotic normality for a\nbroad class of problems. Numerical illustrations highlight their effectiveness\nin adapting to unseen counterfactual scenarios while maintaining parametric\nconvergence rates.","main_category":"stat.ME","categories":"stat.ME,cs.LG,stat.ML","published":"2025-04-03T15:32:26Z"}
{"aid":"http://arxiv.org/abs/2504.02697v1","title":"Learning Phase Distortion with Selective State Space Models for Video\n  Turbulence Mitigation","summary":"Atmospheric turbulence is a major source of image degradation in long-range\nimaging systems. Although numerous deep learning-based turbulence mitigation\n(TM) methods have been proposed, many are slow, memory-hungry, and do not\ngeneralize well. In the spatial domain, methods based on convolutional\noperators have a limited receptive field, so they cannot handle a large spatial\ndependency required by turbulence. In the temporal domain, methods relying on\nself-attention can, in theory, leverage the lucky effects of turbulence, but\ntheir quadratic complexity makes it difficult to scale to many frames.\nTraditional recurrent aggregation methods face parallelization challenges.\n  In this paper, we present a new TM method based on two concepts: (1) A\nturbulence mitigation network based on the Selective State Space Model\n(MambaTM). MambaTM provides a global receptive field in each layer across\nspatial and temporal dimensions while maintaining linear computational\ncomplexity. (2) Learned Latent Phase Distortion (LPD). LPD guides the state\nspace model. Unlike classical Zernike-based representations of phase\ndistortion, the new LPD map uniquely captures the actual effects of turbulence,\nsignificantly improving the model's capability to estimate degradation by\nreducing the ill-posedness. Our proposed method exceeds current\nstate-of-the-art networks on various synthetic and real-world TM benchmarks\nwith significantly faster inference speed. The code is available at\nhttp://github.com/xg416/MambaTM.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T15:33:18Z"}
{"aid":"http://arxiv.org/abs/2504.02699v1","title":"An extension of smooth numbers: multiple dense divisibility","summary":"The $i$-tuply $y$-densely divisible numbers were introduced by a Polymath\nproject, as a weaker condition on the moduli than $y$-smoothness, in\ndistribution estimates for primes in arithmetic progressions. We obtain the\norder of magnitude of the count of these integers up to $x$, uniformly in $x$\nand $y$, for every fixed natural number $i$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T15:34:43Z"}
{"aid":"http://arxiv.org/abs/2504.02701v1","title":"Responsible Development of Offensive AI","summary":"As AI advances, broader consensus is needed to determine research priorities.\nThis endeavor discusses offensive AI and provides guidance by leveraging\nSustainable Development Goals (SDGs) and interpretability techniques. The\nobjective is to more effectively establish priorities that balance societal\nbenefits against risks. The two forms of offensive AI evaluated in this study\nare vulnerability detection agents, which solve Capture- The-Flag challenges,\nand AI-powered malware.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-03T15:37:38Z"}
{"aid":"http://arxiv.org/abs/2504.02718v1","title":"A simple description of blow-up solutions through dynamics at infinity\n  in nonautonomous ODEs","summary":"A simple criterion of the existence of (type-I) blow-up solutions for\nnonautonomous ODEs is provided. In a previous study [Matsue, SIADS, 24(2025),\n415-456], geometric criteria for characterizing blow-up solutions for\nnonautonomous ODEs are provided by means of dynamics at infinity. The basic\nidea towards the present aim is to correspond such criteria to leading-term\nequations associated with blow-up ansatz characterizing multiple-order\nasymptotic expansions, which originated from the corresponding study developed\nin the framework of autonomous ODEs. Restricting our attention to constant\ncoefficients of leading terms of blow-ups, results involving the simple\ncriterion of blow-up characterizations in autonomous ODEs can be mimicked to\nnonautonomous ODEs.","main_category":"math.DS","categories":"math.DS,math.CA","published":"2025-04-03T16:02:39Z"}
{"aid":"http://arxiv.org/abs/2504.02737v1","title":"RBR4DNN: Requirements-based Testing of Neural Networks","summary":"Deep neural network (DNN) testing is crucial for the reliability and safety\nof critical systems, where failures can have severe consequences. Although\nvarious techniques have been developed to create robustness test suites,\nrequirements-based testing for DNNs remains largely unexplored -- yet such\ntests are recognized as an essential component of software validation of\ncritical systems. In this work, we propose a requirements-based test suite\ngeneration method that uses structured natural language requirements formulated\nin a semantic feature space to create test suites by prompting text-conditional\nlatent diffusion models with the requirement precondition and then using the\nassociated postcondition to define a test oracle to judge outputs of the DNN\nunder test. We investigate the approach using fine-tuned variants of\npre-trained generative models. Our experiments on the MNIST, CelebA-HQ,\nImageNet, and autonomous car driving datasets demonstrate that the generated\ntest suites are realistic, diverse, consistent with preconditions, and capable\nof revealing faults.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.LG","published":"2025-04-03T16:24:49Z"}
{"aid":"http://arxiv.org/abs/2504.02743v1","title":"Sequential Binary Hypothesis Testing with Competing Agents under\n  Information Asymmetry","summary":"This paper concerns sequential hypothesis testing in competitive multi-agent\nsystems where agents exchange potentially manipulated information.\nSpecifically, a two-agent scenario is studied where each agent aims to\ncorrectly infer the true state of nature while optimizing decision speed and\naccuracy. At each iteration, agents collect private observations, update their\nbeliefs, and share (possibly corrupted) belief signals with their counterparts\nbefore deciding whether to stop and declare a state, or continue gathering more\ninformation. The analysis yields three main results: (1)~when agents share\ninformation strategically, the optimal signaling policy involves\nequal-probability randomization between truthful and inverted beliefs;\n(2)~agents maximize performance by relying solely on their own observations for\nbelief updating while using received information only to anticipate their\ncounterpart's stopping decision; and (3)~the agent reaching their confidence\nthreshold first cause the other agent to achieve a higher conditional\nprobability of error. Numerical simulations further demonstrate that agents\nwith higher KL divergence in their conditional distributions gain competitive\nadvantage. Furthermore, our results establish that information sharing --\ndespite strategic manipulation -- reduces overall system stopping time compared\nto non-interactive scenarios, which highlights the inherent value of\ncommunication even in this competitive setup.","main_category":"eess.SY","categories":"eess.SY,cs.MA,cs.SY,math.OC","published":"2025-04-03T16:30:40Z"}
{"aid":"http://arxiv.org/abs/2504.02776v1","title":"Bifurcations of the HÃ©non map with additive bounded noise","summary":"We numerically study bifurcations of attractors of the H\\'enon map with\nadditive bounded noise with spherical reach. The bifurcations are analysed\nusing a finite-dimensional boundary map. We distinguish between two types of\nbifurcations: topological bifurcations and boundary bifurcations. Topological\nbifurcations describe discontinuous changes of attractors and boundary\nbifurcations occur when singularities of an attractor's boundary are created or\ndestroyed. We identify correspondences between topological and boundary\nbifurcations of attractors and local and global bifurcations of the boundary\nmap.","main_category":"math.DS","categories":"math.DS","published":"2025-04-03T17:17:11Z"}
{"aid":"http://arxiv.org/abs/2504.02786v1","title":"Quantum maximally symmetric space-times","summary":"We show that 4-dimensional maximally symmetric spacetimes can be obtained\nfrom a coherent state quantisation of gravity, always resulting in geometries\nthat approach the Minkowski vacuum exponentially away from the radius of\ncurvature. A possible connection with the central charge in the AdS/CFT\ncorrespondence is also noted.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-03T17:30:31Z"}
{"aid":"http://arxiv.org/abs/2504.02792v1","title":"Unified World Models: Coupling Video and Action Diffusion for\n  Pretraining on Large Robotic Datasets","summary":"Imitation learning has emerged as a promising approach towards building\ngeneralist robots. However, scaling imitation learning for large robot\nfoundation models remains challenging due to its reliance on high-quality\nexpert demonstrations. Meanwhile, large amounts of video data depicting a wide\nrange of environments and diverse behaviors are readily available. This data\nprovides a rich source of information about real-world dynamics and\nagent-environment interactions. Leveraging this data directly for imitation\nlearning, however, has proven difficult due to the lack of action annotation\nrequired for most contemporary methods. In this work, we present Unified World\nModels (UWM), a framework that allows for leveraging both video and action data\nfor policy learning. Specifically, a UWM integrates an action diffusion process\nand a video diffusion process within a unified transformer architecture, where\nindependent diffusion timesteps govern each modality. We show that by simply\ncontrolling each diffusion timestep, UWM can flexibly represent a policy, a\nforward dynamics, an inverse dynamics, and a video generator. Through simulated\nand real-world experiments, we show that: (1) UWM enables effective pretraining\non large-scale multitask robot datasets with both dynamics and action\npredictions, resulting in more generalizable and robust policies than imitation\nlearning, (2) UWM naturally facilitates learning from action-free video data\nthrough independent control of modality-specific diffusion timesteps, further\nimproving the performance of finetuned policies. Our results suggest that UWM\noffers a promising step toward harnessing large, heterogeneous datasets for\nscalable robot learning, and provides a simple unification between the often\ndisparate paradigms of imitation learning and world modeling. Videos and code\nare available at https://weirdlabuw.github.io/uwm/.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-03T17:38:59Z"}
{"aid":"http://arxiv.org/abs/2504.02799v1","title":"Systematic Evaluation of Large Vision-Language Models for Surgical\n  Artificial Intelligence","summary":"Large Vision-Language Models offer a new paradigm for AI-driven image\nunderstanding, enabling models to perform tasks without task-specific training.\nThis flexibility holds particular promise across medicine, where\nexpert-annotated data is scarce. Yet, VLMs' practical utility in\nintervention-focused domains--especially surgery, where decision-making is\nsubjective and clinical scenarios are variable--remains uncertain. Here, we\npresent a comprehensive analysis of 11 state-of-the-art VLMs across 17 key\nvisual understanding tasks in surgical AI--from anatomy recognition to skill\nassessment--using 13 datasets spanning laparoscopic, robotic, and open\nprocedures. In our experiments, VLMs demonstrate promising generalizability, at\ntimes outperforming supervised models when deployed outside their training\nsetting. In-context learning, incorporating examples during testing, boosted\nperformance up to three-fold, suggesting adaptability as a key strength. Still,\ntasks requiring spatial or temporal reasoning remained difficult. Beyond\nsurgery, our findings offer insights into VLMs' potential for tackling complex\nand dynamic scenarios in clinical and broader real-world applications.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T17:42:56Z"}
{"aid":"http://arxiv.org/abs/2504.02809v1","title":"Fractional attractors in light of the latest ACT observations","summary":"In light of the latest results from ACT observations we review a class of\npotentials labeled as fractional attractors, that can originate from Palatini\ngravity. We show in a model independent way that this class of potentials\npredicts both a spectral index $n_s$ and a tensor-to-scalar ratio $r$ which fit\nthe $1\\sigma$ region of the combination ACT+Planck data for a wide choice of\nthe parameters. We also provide a numerical fit for the parameter space of this\nmodels in the case of a simple quadratic and quartic fractional potential.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph","published":"2025-04-03T17:53:22Z"}
{"aid":"http://arxiv.org/abs/2504.02817v1","title":"Efficient Autoregressive Shape Generation via Octree-Based Adaptive\n  Tokenization","summary":"Many 3D generative models rely on variational autoencoders (VAEs) to learn\ncompact shape representations. However, existing methods encode all shapes into\na fixed-size token, disregarding the inherent variations in scale and\ncomplexity across 3D data. This leads to inefficient latent representations\nthat can compromise downstream generation. We address this challenge by\nintroducing Octree-based Adaptive Tokenization, a novel framework that adjusts\nthe dimension of latent representations according to shape complexity. Our\napproach constructs an adaptive octree structure guided by a\nquadric-error-based subdivision criterion and allocates a shape latent vector\nto each octree cell using a query-based transformer. Building upon this\ntokenization, we develop an octree-based autoregressive generative model that\neffectively leverages these variable-sized representations in shape generation.\nExtensive experiments demonstrate that our approach reduces token counts by 50%\ncompared to fixed-size methods while maintaining comparable visual quality.\nWhen using a similar token length, our method produces significantly\nhigher-quality shapes. When incorporated with our downstream generative model,\nour method creates more detailed and diverse 3D content than existing\napproaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:57:52Z"}
{"aid":"http://arxiv.org/abs/2504.04728v1","title":"Exploring Kernel Transformations for Implicit Neural Representations","summary":"Implicit neural representations (INRs), which leverage neural networks to\nrepresent signals by mapping coordinates to their corresponding attributes,\nhave garnered significant attention. They are extensively utilized for image\nrepresentation, with pixel coordinates as input and pixel values as output. In\ncontrast to prior works focusing on investigating the effect of the model's\ninside components (activation function, for instance), this work pioneers the\nexploration of the effect of kernel transformation of input/output while\nkeeping the model itself unchanged. A byproduct of our findings is a simple yet\neffective method that combines scale and shift to significantly boost INR with\nnegligible computation overhead. Moreover, we present two perspectives, depth\nand normalization, to interpret the performance benefits caused by scale and\nshift transformation. Overall, our work provides a new avenue for future works\nto understand and improve INR through the lens of kernel transformation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T04:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.04733v1","title":"Robustifying Approximate Bayesian Computation","summary":"Approximate Bayesian computation (ABC) is one of the most popular\n\"likelihood-free\" methods. These methods have been applied in a wide range of\nfields by providing solutions to intractable likelihood problems in which exact\nBayesian approaches are either infeasible or computationally costly. However,\nthe performance of ABC can be unreliable when dealing with model\nmisspecification. To circumvent the poor behavior of ABC in these settings, we\npropose a novel ABC approach that is robust to model misspecification. This new\nmethod can deliver more accurate statistical inference under model\nmisspecification than alternatives and also enables the detection of summary\nstatistics that are incompatible with the assumed data-generating process. We\ndemonstrate the effectiveness of our approach through several simulated\nexamples, where it delivers more accurate point estimates and uncertainty\nquantification over standard ABC approaches when the model is misspecified.\nAdditionally, we apply our approach to an empirical example, further showcasing\nits advantages over alternative methods.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-07T05:11:02Z"}
{"aid":"http://arxiv.org/abs/2504.04735v1","title":"Fermi Operator Expansion for the Hartree-Fock-Bogoliubov Theory","summary":"A variety of phases in the inner crust of neutron stars are crucial for\nunderstanding the pulsar phenomena. However, the three-dimensional\ncoordinate-space calculation of the phases is computationally demanding. We aim\nto generalize the Fermi Operator Expansion (FOE) method that is effective for\nfinite-temperature coordinate-space simulation, from the Hartree-Fock theory to\nHartree-Fock-Bogoliubov (HFB) theory including the pairing effects.\nFurthermore, the periodic structure with free neutrons in the inner crust\nrequires us to treat the system with the band theory. We give a concise proof\nthat the generalized density matrix in the HFB theory can be obtained with the\nFOE. The Chebyshev polynomial expansion is used for calculations of the HFB\nband theory. Using a model for a slab phase of the inner crust, the FOE method\nproduces results in good agreement with those based on the diagonalization of\nthe HFB Hamiltonian. The FOE method for the HFB band theory is a powerful tool\nfor studying the non-trivial exotic structures in neutron stars. The FOE method\nis suitable for parallelization and further acceleration is possible with\nnearsightedness.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-07T05:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.04736v1","title":"Synthetic Data Generation & Multi-Step RL for Reasoning & Tool Use","summary":"Reinforcement learning has been shown to improve the performance of large\nlanguage models. However, traditional approaches like RLHF or RLAIF treat the\nproblem as single-step. As focus shifts toward more complex reasoning and\nagentic tasks, language models must take multiple steps of text generation,\nreasoning and environment interaction before generating a solution. We propose\na synthetic data generation and RL methodology targeting multi-step\noptimization scenarios. This approach, called Step-Wise Reinforcement Learning\n(SWiRL), iteratively generates multi-step reasoning and tool use data, and then\nlearns from that data. It employs a simple step-wise decomposition that breaks\neach multi-step trajectory into multiple sub-trajectories corresponding to each\naction by the original model. It then applies synthetic data filtering and RL\noptimization on these sub-trajectories. We evaluated SWiRL on a number of\nmulti-step tool use, question answering, and mathematical reasoning tasks. Our\nexperiments show that SWiRL outperforms baseline approaches by 21.5%, 12.3%,\n14.8%, 11.1%, and 15.3% in relative accuracy on GSM8K, HotPotQA, CofCA,\nMuSiQue, and BeerQA, respectively. Excitingly, the approach exhibits\ngeneralization across tasks: for example, training only on HotPotQA (text\nquestion-answering) improves zero-shot performance on GSM8K (a math dataset) by\na relative 16.9%.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG","published":"2025-04-07T05:20:58Z"}
{"aid":"http://arxiv.org/abs/2504.04741v1","title":"The First Search for Optical Transient as a Counterpart of a\n  Month-timescale IceCube Neutrino Multiplet Event","summary":"Optical transients with timescale of months, such as supernovae (SNe) and\ntidal disruption events (TDEs), are candidates of high-energy neutrino sources.\nMultiple neutrino detections from the same direction within a month timescale\nprovide a unique opportunity to identify such optical counterparts in the\nnearby Universe. In this work, we conduct archival search for the optical\ncounterpart of an IceCube triplet event using the data of Zwicky Transient\nFacility. We develop a dedicated alert filtering system and validate the\nperformance by following a blind analysis method. Applying this filtering\nsystem to the data after the detections of the IceCube triplet event, we find\nno transient candidates within the localization area. Assuming that the IceCube\ntriplet event originates from an astrophysical source, we constrain parameters\nof optical transient, a peak luminosity and a decay timescale, using a simple\nsignal model that is motivated by TDEs and superluminous SNe (SLSNe). Assuming\nthe case with no time lag between neutrino detections and optical peak, almost\nentire parameter space of the known TDEs and SLSNe would be constrained. To\ngive constraints on transients with a rapidly evolving light curve, quick\nfollow-up observations for future neutrino multiplet events are crucial.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T05:36:26Z"}
{"aid":"http://arxiv.org/abs/2504.04742v1","title":"Unveiling Physical Conditions and Star Formation Processes in the G47\n  Filamentary Cloud","summary":"We present a multi-wavelength study of the filamentary cloud G47 (d\n$\\sim$4.44 kpc), which hosts the mid-infrared bubbles N98, B1, and B2. The\nSMGPS 1.3 GHz continuum map detects ionized emission toward all the bubbles,\nmarking the first detection of ionized emission toward the B2 bubble. Analysis\nof the unWISE 12.0 $\\mu$m image, Spitzer 8.0 $\\mu$m image, and the Herschel\ncolumn density and temperature maps reveals two previously unreported\nhub-filament system candidates associated with the HII regions B2 and N98,\nwhich are powered by massive OB stars. This indirectly favours the\napplicability of a global non-isotropic collapse (GNIC) scenario for massive\nstar formation in N98 and B2. The position-position-velocity diagram of FUGIN\n$^{13}$CO(1-0) shows significant velocity variations from 61 to 53 km s$^{-1}$\ntoward areas between B2 and N98, where the magnetic field morphology exhibits\nsignificant curvature, and high velocity dispersion (i.e., 2.3--3.1 km\ns$^{-1}$) is observed. This may be explained by the expansion of the HII\nregions B2 and N98. The energy budget of the cloud, estimated using SOFIA/HAWC+\nand molecular line data, suggests that the magnetic field dominates over\nturbulence and gravity in G47. Furthermore, the radial column density and\nvelocity profiles of G47 display signatures of converging flows in a sheet-like\nstructure. The relative orientations between the magnetic field and local\ngravity suggest that G47 may undergo gravitational contraction along the\nmagnetic field lines once it becomes magnetically supercritical.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-07T05:36:27Z"}
{"aid":"http://arxiv.org/abs/2504.04746v1","title":"The Cohen-Macaulay property of invariant rings over ring of integers of\n  a global field-II","summary":"Let $A$ be the ring of integers of a number field $K$. Let $G \\subseteq\nGL_3(A)$ be a finite group. Let $G$ act linearly on $R = A[X,Y, Z]$ (fixing\n$A$) and let $S = R^G$ be the ring of invariants. Assume the Veronese subring\n$S^{<m>}$ of $S$ is standard graded. We prove that if for all primes $p$\ndividing $|G|$, the Sylow $p$-subgroup of $G$ has exponent $p$ then for all $l\n\\gg 0$ the Veronese subring $S^{<ml>}$ of $S$ is Cohen-Macaulay. We prove a\nsimilar result if for all primes $p$ dividing $|G|$, the prime $p$ is\nunramified in $K$.","main_category":"math.AC","categories":"math.AC","published":"2025-04-07T05:39:40Z"}
{"aid":"http://arxiv.org/abs/2504.04748v1","title":"Sharp threshold for network recovery from voter model dynamics","summary":"We investigate the problem of recovering a latent directed Erd\\H{o}s-R\\'enyi\ngraph $G^*\\sim \\mathcal G(n,p)$ from observations of discrete voter model\ntrajectories on $G^*$, where $np$ grows polynomially in $n$. Given access to\n$M$ independent voter model trajectories evolving up to time $T$, we establish\nthat $G^*$ can be recovered \\emph{exactly} with probability at least $0.9$ by\nan \\emph{efficient} algorithm, provided that \\[ M \\cdot \\min\\{T, n\\} \\geq C n^2\np^2 \\log n \\] holds for a sufficiently large constant $C$. Here, $M\\cdot\n\\min\\{T,n\\}$ can be interpreted as the approximate number of effective update\nrounds being observed, since the voter model on $G^*$ typically reaches\nconsensus after $\\Theta(n)$ rounds, and no further information can be gained\nafter this point. Furthermore, we prove an \\emph{information-theoretic} lower\nbound showing that the above condition is tight up to a constant factor. Our\nresults indicate that the recovery problem does not exhibit a\nstatistical-computational gap.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T05:47:52Z"}
{"aid":"http://arxiv.org/abs/2504.04749v1","title":"Vision Transformers with Autoencoders and Explainable AI for Cancer\n  Patient Risk Stratification Using Whole Slide Imaging","summary":"Cancer remains one of the leading causes of mortality worldwide,\nnecessitating accurate diagnosis and prognosis. Whole Slide Imaging (WSI) has\nbecome an integral part of clinical workflows with advancements in digital\npathology. While various studies have utilized WSIs, their extracted features\nmay not fully capture the most relevant pathological information, and their\nlack of interpretability limits clinical adoption.\n  In this paper, we propose PATH-X, a framework that integrates Vision\nTransformers (ViT) and Autoencoders with SHAP (Shapley Additive Explanations)\nto enhance model explainability for patient stratification and risk prediction\nusing WSIs from The Cancer Genome Atlas (TCGA). A representative image slice is\nselected from each WSI, and numerical feature embeddings are extracted using\nGoogle's pre-trained ViT. These features are then compressed via an autoencoder\nand used for unsupervised clustering and classification tasks. Kaplan-Meier\nsurvival analysis is applied to evaluate stratification into two and three risk\ngroups. SHAP is used to identify key contributing features, which are mapped\nonto histopathological slices to provide spatial context.\n  PATH-X demonstrates strong performance in breast and glioma cancers, where a\nsufficient number of WSIs enabled robust stratification. However, performance\nin lung cancer was limited due to data availability, emphasizing the need for\nlarger datasets to enhance model reliability and clinical applicability.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-07T05:48:42Z"}
{"aid":"http://arxiv.org/abs/2504.04758v1","title":"Feature Importance-Aware Deep Joint Source-Channel Coding for\n  Computationally Efficient and Adjustable Image Transmission","summary":"Recent advancements in deep learning-based joint source-channel coding\n(deepJSCC) have significantly improved communication performance, but their\nhigh computational demands restrict practical deployment. Furthermore, some\napplications require the adaptive adjustment of computational complexity. To\naddress these challenges, we propose a computationally efficient and adjustable\ndeepJSCC model for image transmission, which we call feature importance-aware\ndeepJSCC (FAJSCC). Unlike existing deepJSCC models that equally process all\nneural features of images, FAJSCC first classifies features into important and\nless important features and then processes them differently. Specifically,\ncomputationally-intensive self-attention is applied to the important features\nand computationally-efficient spatial attention to the less important ones. The\nfeature classification is based on the available computational budget and\nimportance scores predicted by an importance predictor, which estimates each\nfeature's contribution to performance. It also allows independent adjustment of\nencoder and decoder complexity within a single trained model. With these\nproperties, our FAJSCC is the first deepJSCC that is computationally efficient\nand adjustable while maintaining high performance. Experiments demonstrate that\nour FAJSCC achieves higher image transmission performance across various\nchannel conditions while using less computational complexity than the recent\nstate-of-the-art models. Adding to this, by separately varying the\ncomputational resources of the encoder and decoder, it is concluded that the\ndecoder's error correction function requires the largest computational\ncomplexity in FAJSCC, which is the first observation in deepJSCC literature.\nThe FAJSCC code is publicly available at\nhttps://github.com/hansung-choi/FAJSCC.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-07T06:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.04765v1","title":"Multi-Agent Deep Reinforcement Learning for Multiple Anesthetics\n  Collaborative Control","summary":"Automated control of personalized multiple anesthetics in clinical Total\nIntravenous Anesthesia (TIVA) is crucial yet challenging. Current systems,\nincluding target-controlled infusion (TCI) and closed-loop systems, either rely\non relatively static pharmacokinetic/pharmacodynamic (PK/PD) models or focus on\nsingle anesthetic control, limiting personalization and collaborative control.\nTo address these issues, we propose a novel framework, Value Decomposition\nMulti-Agent Deep Reinforcement Learning (VD-MADRL). VD-MADRL optimizes the\ncollaboration between two anesthetics propofol (Agent I) and remifentanil\n(Agent II). And It uses a Markov Game (MG) to identify optimal actions among\nheterogeneous agents. We employ various value function decomposition methods to\nresolve the credit allocation problem and enhance collaborative control. We\nalso introduce a multivariate environment model based on random forest (RF) for\nanesthesia state simulation. Additionally, a data resampling and alignment\ntechnique ensures synchronized trajectory data. Our experiments on general and\nthoracic surgery datasets show that VD-MADRL performs better than human\nexperience. It improves dose precision and keeps anesthesia states stable,\nproviding great clinical value.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T06:36:24Z"}
{"aid":"http://arxiv.org/abs/2504.04771v1","title":"Improving Multilingual Retrieval-Augmented Language Models through\n  Dialectic Reasoning Argumentations","summary":"Retrieval-augmented generation (RAG) is key to enhancing large language\nmodels (LLMs) to systematically access richer factual knowledge. Yet, using RAG\nbrings intrinsic challenges, as LLMs must deal with potentially conflicting\nknowledge, especially in multilingual retrieval, where the heterogeneity of\nknowledge retrieved may deliver different outlooks. To make RAG more\nanalytical, critical and grounded, we introduce Dialectic-RAG (DRAG), a modular\napproach guided by Argumentative Explanations, i.e., structured reasoning\nprocess that systematically evaluates retrieved\n  information by comparing, contrasting, and resolving conflicting\nperspectives. Given a query and a set of multilingual related documents, DRAG\nselects and exemplifies relevant knowledge for delivering dialectic\nexplanations that, by critically weighing opposing arguments and filtering\nextraneous content, clearly determine the final response. Through a series of\nin-depth experiments, we show the impact of our framework both as an in-context\nlearning strategy and for constructing demonstrations to instruct smaller\nmodels. The final results demonstrate that DRAG significantly improves RAG\napproaches, requiring low-impact computational effort and providing robustness\nto knowledge perturbations.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T06:55:15Z"}
{"aid":"http://arxiv.org/abs/2504.04778v1","title":"Abundance of weird quasiperiodic attractors in piecewise linear\n  discontinuous maps","summary":"In this work, we consider a class of $n$-dimensional, $n\\geq2$, piecewise\nlinear discontinuous maps that can exhibit a new type of attractor, called a\nweird quasiperiodic attractor. While the dynamics associated with these\nattractors may appear chaotic, we prove that chaos cannot occur. The considered\nclass of $n$-dimensional maps allows for any finite number of partitions,\nseparated by various types of discontinuity sets. The key characteristic,\nbeyond discontinuity, is that all functions defining the map have the same real\nfixed point. These maps cannot have hyperbolic cycles other than the fixed\npoint itself. We consider the two-dimensional case in detail. We prove that in\nnongeneric cases, the restriction, or the first return, of the map to a segment\nof straight line is reducible to a piecewise linear circle map. The generic\nattractor, different from the fixed point, is a weird quasiperiodic attractor,\nwhich may coexist with other attractors or attracting sets. We illustrate the\nexistence of these attractors through numerous examples, using functions with\ndifferent types of Jacobian matrices, as well as with different types of\ndiscontinuity sets. In some cases, we describe possible mechanisms leading to\nthe appearance of these attractors. We also give examples in the\nthree-dimensional space. Several properties of this new type of attractor\nremain open for further investigation.","main_category":"math.DS","categories":"math.DS,nlin.CD","published":"2025-04-07T07:14:14Z"}
{"aid":"http://arxiv.org/abs/2504.04784v1","title":"Disentangling Instruction Influence in Diffusion Transformers for\n  Parallel Multi-Instruction-Guided Image Editing","summary":"Instruction-guided image editing enables users to specify modifications using\nnatural language, offering more flexibility and control. Among existing\nframeworks, Diffusion Transformers (DiTs) outperform U-Net-based diffusion\nmodels in scalability and performance. However, while real-world scenarios\noften require concurrent execution of multiple instructions, step-by-step\nediting suffers from accumulated errors and degraded quality, and integrating\nmultiple instructions with a single prompt usually results in incomplete edits\ndue to instruction conflicts. We propose Instruction Influence Disentanglement\n(IID), a novel framework enabling parallel execution of multiple instructions\nin a single denoising process, designed for DiT-based models. By analyzing\nself-attention mechanisms in DiTs, we identify distinctive attention patterns\nin multi-instruction settings and derive instruction-specific attention masks\nto disentangle each instruction's influence. These masks guide the editing\nprocess to ensure localized modifications while preserving consistency in\nnon-edited regions. Extensive experiments on open-source and custom datasets\ndemonstrate that IID reduces diffusion steps while improving fidelity and\ninstruction completion compared to existing baselines. The codes will be\npublicly released upon the acceptance of the paper.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.04790v1","title":"Unified speed limits in classical and quantum dynamics via temporal\n  Fisher information","summary":"The importance of Fisher information is increasing in nonequilibrium\nthermodynamics, as it has played a fundamental role in trade-off relations such\nas thermodynamic uncertainty relations and speed limits. In this work, we\ninvestigate temporal Fisher information, which measures the temporal\ninformation content encoded in probability distributions, for both classical\nand quantum systems. We establish that temporal Fisher information is bounded\nfrom above by physical costs, such as entropy production in classical Langevin\nand Markov processes, and the variance of interaction Hamiltonians in open\nquantum systems. Conversely, temporal Fisher information is bounded from below\nby statistical distances (e.g., the Bhattacharyya arccos distance), leading to\nclassical and quantum speed limits that constrain the minimal time required for\nstate transformations. Our work provides a unified perspective of speed limits\nfrom the point of view of temporal Fisher information in both classical and\nquantum dynamics.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-07T07:34:18Z"}
{"aid":"http://arxiv.org/abs/2504.04795v1","title":"Embodied Perception for Test-time Grasping Detection Adaptation with\n  Knowledge Infusion","summary":"It has always been expected that a robot can be easily deployed to unknown\nscenarios, accomplishing robotic grasping tasks without human intervention.\nNevertheless, existing grasp detection approaches are typically off-body\ntechniques and are realized by training various deep neural networks with\nextensive annotated data support. {In this paper, we propose an embodied\ntest-time adaptation framework for grasp detection that exploits the robot's\nexploratory capabilities.} The framework aims to improve the generalization\nperformance of grasping skills for robots in an unforeseen environment.\nSpecifically, we introduce embodied assessment criteria based on the robot's\nmanipulation capability to evaluate the quality of the grasp detection and\nmaintain suitable samples. This process empowers the robots to actively explore\nthe environment and continuously learn grasping skills, eliminating human\nintervention. Besides, to improve the efficiency of robot exploration, we\nconstruct a flexible knowledge base to provide context of initial optimal\nviewpoints. Conditioned on the maintained samples, the grasp detection networks\ncan be adapted in the test-time scene. When the robot confronts new objects, it\nwill undergo the same adaptation procedure mentioned above to realize\ncontinuous learning. Extensive experiments conducted on a real-world robot\ndemonstrate the effectiveness and generalization of our proposed framework.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T07:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.04797v1","title":"Addressing the Curse of Scenario and Task Generalization in AI-6G: A\n  Multi-Modal Paradigm","summary":"Existing works on machine learning (ML)-empowered wireless communication\nprimarily focus on monolithic scenarios and single tasks. However, with the\nblooming growth of communication task classes coupled with various task\nrequirements in future 6G systems, this working pattern is obviously\nunsustainable. Therefore, identifying a groundbreaking paradigm that enables a\nuniversal model to solve multiple tasks in the physical layer within diverse\nscenarios is crucial for future system evolution. This paper aims to\nfundamentally address the curse of ML model generalization across diverse\nscenarios and tasks by unleashing multi-modal feature integration capabilities\nin future systems. Given the universality of electromagnetic propagation\ntheory, the communication process is determined by the scattering environment,\nwhich can be more comprehensively characterized by cross-modal perception, thus\nproviding sufficient information for all communication tasks across varied\nenvironments. This fact motivates us to propose a transformative two-stage\nmulti-modal pre-training and downstream task adaptation paradigm...","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T07:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.04805v1","title":"Measurement of substructure-dependent suppression of large-radius jets\n  with charged particles in Pb+Pb collisions with ATLAS","summary":"Measurements of jet substructure in Pb+Pb collisions provide key insights\ninto the mechanism of jet quenching in the hot and dense QCD medium created in\nthese collisions. This Letter presents a measurement of the suppression of\nlarge-radius jets with a radius parameter of $R = 1.0$ and its dependence on\nthe jet substructure. The measurement uses 1.72 nb$^{-1}$ of Pb+Pb data and 255\npb$^{-1}$ of $pp$ data, both at $\\sqrt{s_{_\\mathrm{NN}}} = 5.02$ TeV, recorded\nwith the ATLAS detector at the Large Hadron Collider. Large-radius jets are\nreconstructed by reclustering $R = 0.2$ calorimetric jets and are measured for\ntransverse momentum above $200$ GeV. Jet substructure is evaluated using\ncharged-particle tracks, and the overall level of jet suppression is quantified\nusing the jet nuclear modification factor ($R_\\mathrm{AA}$). The jet\n$R_\\mathrm{AA}$ is measured as a function of jet $p_{\\mathrm{T}}$, the charged\n$k_t$ splitting scale ($\\sqrt{d_{12}}$), and the angular separation ($dR_{12}$)\nof two leading sub-jets. The jet $R_\\mathrm{AA}$ gradually decreases with\nincreasing $\\sqrt{d_{12}}$, implying significantly stronger suppression of\nlarge-radius jets with larger $k_t$ splitting scale. The jet $R_\\mathrm{AA}$\ngradually decreases for $dR_{12}$ in the range $0.01{-}0.2$ and then remains\nconsistent with a constant for $dR_{12} \\gtrsim 0.2$. The observed significant\ndependence of jet suppression on the jet substructure will provide new insights\ninto its role in the quenching process.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-07T08:01:08Z"}
{"aid":"http://arxiv.org/abs/2504.04808v1","title":"ELT-Bench: An End-to-End Benchmark for Evaluating AI Agents on ELT\n  Pipelines","summary":"Practitioners are increasingly turning to Extract-Load-Transform (ELT)\npipelines with the widespread adoption of cloud data warehouses. However,\ndesigning these pipelines often involves significant manual work to ensure\ncorrectness. Recent advances in AI-based methods, which have shown strong\ncapabilities in data tasks, such as text-to-SQL, present an opportunity to\nalleviate manual efforts in developing ELT pipelines. Unfortunately, current\nbenchmarks in data engineering only evaluate isolated tasks, such as using data\ntools and writing data transformation queries, leaving a significant gap in\nevaluating AI agents for generating end-to-end ELT pipelines.\n  To fill this gap, we introduce ELT-Bench, an end-to-end benchmark designed to\nassess the capabilities of AI agents to build ELT pipelines. ELT-Bench consists\nof 100 pipelines, including 835 source tables and 203 data models across\nvarious domains. By simulating realistic scenarios involving the integration of\ndiverse data sources and the use of popular data tools, ELT-Bench evaluates AI\nagents' abilities in handling complex data engineering workflows. AI agents\nmust interact with databases and data tools, write code and SQL queries, and\norchestrate every pipeline stage. We evaluate two representative code agent\nframeworks, Spider-Agent and SWE-Agent, using six popular Large Language Models\n(LLMs) on ELT-Bench. The highest-performing agent, Spider-Agent\nClaude-3.7-Sonnet with extended thinking, correctly generates only 3.9% of data\nmodels, with an average cost of $4.30 and 89.3 steps per pipeline. Our\nexperimental results demonstrate the challenges of ELT-Bench and highlight the\nneed for a more advanced AI agent to reduce manual effort in ELT workflows. Our\ncode and data are available at https://github.com/uiuc-kang-lab/ETL.git.","main_category":"cs.DB","categories":"cs.DB,cs.AI","published":"2025-04-07T08:03:36Z"}
{"aid":"http://arxiv.org/abs/2504.04815v1","title":"Beyond Answers: How LLMs Can Pursue Strategic Thinking in Education","summary":"Artificial Intelligence (AI) holds transformative potential in education,\nenabling personalized learning, enhancing inclusivity, and encouraging\ncreativity and curiosity. In this paper, we explore how Large Language Models\n(LLMs) can act as both patient tutors and collaborative partners to enhance\neducation delivery. As tutors, LLMs personalize learning by offering\nstep-by-step explanations and addressing individual needs, making education\nmore inclusive for students with diverse backgrounds or abilities. As\ncollaborators, they expand students' horizons, supporting them in tackling\ncomplex, real-world problems and co-creating innovative projects. However, to\nfully realize these benefits, LLMs must be leveraged not as tools for providing\ndirect solutions but rather to guide students in developing resolving\nstrategies and finding learning paths together. Therefore, a strong emphasis\nshould be placed on educating students and teachers on the successful use of\nLLMs to ensure their effective integration into classrooms. Through practical\nexamples and real-world case studies, this paper illustrates how LLMs can make\neducation more inclusive and engaging while empowering students to reach their\nfull potential.","main_category":"cs.CY","categories":"cs.CY,cs.ET,eess.SP","published":"2025-04-07T08:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.04831v1","title":"SMF: Template-free and Rig-free Animation Transfer using Kinetic Codes","summary":"Animation retargeting involves applying a sparse motion description (e.g.,\n2D/3D keypoint sequences) to a given character mesh to produce a semantically\nplausible and temporally coherent full-body motion. Existing approaches come\nwith a mix of restrictions - they require annotated training data, assume\naccess to template-based shape priors or artist-designed deformation rigs,\nsuffer from limited generalization to unseen motion and/or shapes, or exhibit\nmotion jitter. We propose Self-supervised Motion Fields (SMF) as a\nself-supervised framework that can be robustly trained with sparse motion\nrepresentations, without requiring dataset specific annotations, templates, or\nrigs. At the heart of our method are Kinetic Codes, a novel autoencoder-based\nsparse motion encoding, that exposes a semantically rich latent space\nsimplifying large-scale training. Our architecture comprises dedicated spatial\nand temporal gradient predictors, which are trained end-to-end. The resultant\nnetwork, regularized by the Kinetic Codes's latent space, has good\ngeneralization across shapes and motions. We evaluated our method on unseen\nmotion sampled from AMASS, D4D, Mixamo, and raw monocular video for animation\ntransfer on various characters with varying shapes and topology. We report a\nnew SoTA on the AMASS dataset in the context of generalization to unseen\nmotion. Project webpage at https://motionfields.github.io/","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-07T08:42:52Z"}
{"aid":"http://arxiv.org/abs/2504.04834v1","title":"Learning Affine Correspondences by Integrating Geometric Constraints","summary":"Affine correspondences have received significant attention due to their\nbenefits in tasks like image matching and pose estimation. Existing methods for\nextracting affine correspondences still have many limitations in terms of\nperformance; thus, exploring a new paradigm is crucial. In this paper, we\npresent a new pipeline designed for extracting accurate affine correspondences\nby integrating dense matching and geometric constraints. Specifically, a novel\nextraction framework is introduced, with the aid of dense matching and a novel\nkeypoint scale and orientation estimator. For this purpose, we propose loss\nfunctions based on geometric constraints, which can effectively improve\naccuracy by supervising neural networks to learn feature geometry. The\nexperimental show that the accuracy and robustness of our method outperform the\nexisting ones in image matching tasks. To further demonstrate the effectiveness\nof the proposed method, we applied it to relative pose estimation. Affine\ncorrespondences extracted by our method lead to more accurate poses than the\nbaselines on a range of real-world datasets. The code is available at\nhttps://github.com/stilcrad/DenseAffine.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:44:50Z"}
{"aid":"http://arxiv.org/abs/2504.04837v1","title":"Uni4D: A Unified Self-Supervised Learning Framework for Point Cloud\n  Videos","summary":"Point cloud video representation learning is primarily built upon the masking\nstrategy in a self-supervised manner. However, the progress is slow due to\nseveral significant challenges: (1) existing methods learn the motion\nparticularly with hand-crafted designs, leading to unsatisfactory motion\npatterns during pre-training which are non-transferable on fine-tuning\nscenarios. (2) previous Masked AutoEncoder (MAE) frameworks are limited in\nresolving the huge representation gap inherent in 4D data. In this study, we\nintroduce the first self-disentangled MAE for learning discriminative 4D\nrepresentations in the pre-training stage. To address the first challenge, we\npropose to model the motion representation in a latent space. The second issue\nis resolved by introducing the latent tokens along with the typical geometry\ntokens to disentangle high-level and low-level features during decoding.\nExtensive experiments on MSR-Action3D, NTU-RGBD, HOI4D, NvGesture, and SHREC'17\nverify this self-disentangled learning framework. We demonstrate that it can\nboost the fine-tuning performance on all 4D tasks, which we term Uni4D. Our\npre-trained model presents discriminative and meaningful 4D representations,\nparticularly benefits processing long videos, as Uni4D gets $+3.8\\%$\nsegmentation accuracy on HOI4D, significantly outperforming either\nself-supervised or fully-supervised methods after end-to-end fine-tuning.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:47:36Z"}
{"aid":"http://arxiv.org/abs/2504.04839v1","title":"Crossed Ponderomotive Lenses for Spherical Aberration Correction in\n  Electron Optics","summary":"This article evaluates the lens characteristics of a non-rotationally\nsymmetric electron lens based on a ponderomotive potential (i.e., a\nponderomotive lens) formed by intersecting one or more optical beams\nperpendicular to an electron beam. Based on geometric optics, design formulas\nare derived for the focal length and general spherical aberration coefficients\nof specifically crossed ponderomotive lenses. Numerical calculations\ndemonstrate that a pair of these crossed ponderomotive lenses can effectively\ncorrect spherical aberration in the objective lens of an electron microscope.\nUnlike rotationally symmetric ponderomotive lenses, which require the optical\nbeam to be coaxially aligned with the electron beam, the crossed ponderomotive\nlens avoids the need to place optical mirrors and lenses directly on the beam\naxis. Thus, it offers practical advantages in designing and building electron\noptical instruments and contributes to system miniaturization. With lens\nproperties similar to multipole lenses, the proposed crossed ponderomotive lens\nis expected to facilitate diverse developments in electron optical systems\nincorporating ponderomotive potentials.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T08:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.04845v1","title":"Open problems UP24","summary":"The conference Unexpected Phenomena in Energy Minimization and Polarization,\nheld in Sofia, Bulgaria in 2024, provided a platform for researchers to discuss\nand propose challenging open questions across various fields, such as potential\ntheory, approximation, special functions, point configurations, lattices, and\nnumerical analysis. The open problems sessions were productive, fruitful and\nled to a range of interesting questions. In this document, we present these\nopen problems.","main_category":"math.CA","categories":"math.CA,math-ph,math.MP","published":"2025-04-07T08:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.04857v1","title":"3D Gaussian Particle Approximation of VDB Datasets: A Study for\n  Scientific Visualization","summary":"The complexity and scale of Volumetric and Simulation datasets for Scientific\nVisualization(SciVis) continue to grow. And the approaches and advantages of\nmemory-efficient data formats and storage techniques for such datasets vary.\nOpenVDB library and its VDB data format excels in memory efficiency through its\nhierarchical and dynamic tree structure, with active and inactive sub-trees for\ndata storage. It is heavily used in current production renderers for both\nanimation and rendering stages in VFX pipelines and photorealistic rendering of\nvolumes and fluids. However, it still remains to be fully leveraged in SciVis\nwhere domains dealing with sparse scalar fields like porous media, time varying\nvolumes such as tornado and weather simulation or high resolution simulation of\nComputational Fluid Dynamics present ample number of large challenging data\nsets.Goal of this paper is not only to explore the use of OpenVDB in SciVis but\nalso to explore a level of detail(LOD) technique using 3D Gaussian particles\napproximating voxel regions. For rendering, we utilize NVIDIA OptiX library for\nray marching through the Gaussians particles. Data modeling using 3D Gaussians\nhas been very popular lately due to success in stereoscopic image to 3D scene\nconversion using Gaussian Splatting and Gaussian approximation and mixture\nmodels aren't entirely new in SciVis as well. Our work explores the integration\nwith rendering software libraries like OpenVDB and OptiX to take advantage of\ntheir built-in memory compaction and hardware acceleration features, while also\nleveraging the performance capabilities of modern GPUs. Thus, we present a\nSciVis rendering approach that uses 3D Gaussians at varying LOD in a lossy\nscheme derived from VDB datasets, rather than focusing on photorealistic volume\nrendering.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-07T09:14:15Z"}
{"aid":"http://arxiv.org/abs/2504.04861v1","title":"SAFT: Structure-aware Transformers for Textual Interaction\n  Classification","summary":"Textual interaction networks (TINs) are an omnipresent data structure used to\nmodel the interplay between users and items on e-commerce websites, social\nnetworks, etc., where each interaction is associated with a text description.\nClassifying such textual interactions (TIC) finds extensive use in detecting\nspam reviews in e-commerce, fraudulent transactions in finance, and so on.\nExisting TIC solutions either (i) fail to capture the rich text semantics due\nto the use of context-free text embeddings, and/or (ii) disregard the bipartite\nstructure and node heterogeneity of TINs, leading to compromised TIC\nperformance. In this work, we propose SAFT, a new architecture that integrates\nlanguage- and graph-based modules for the effective fusion of textual and\nstructural semantics in the representation learning of interactions. In\nparticular, line graph attention (LGA)/gated attention units (GAUs) and\npretrained language models (PLMs) are capitalized on to model the\ninteraction-level and token-level signals, which are further coupled via the\nproxy token in an iterative and contextualized fashion. Additionally, an\nefficient and theoretically-grounded approach is developed to encode the local\nand global topology information pertaining to interactions into structural\nembeddings. The resulting embeddings not only inject the structural features\nunderlying TINs into the textual interaction encoding but also facilitate the\ndesign of graph sampling strategies. Extensive empirical evaluations on\nmultiple real TIN datasets demonstrate the superiority of SAFT over the\nstate-of-the-art baselines in TIC accuracy.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T09:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.04886v1","title":"Pyroelectric doping reversal of MoS2 p-n junctions on ferroelectric\n  domain walls probed by photoluminescence","summary":"Tailoring the optical properties and electronic doping in transition metal\ndichalcogenides (TMDs) is a central strategy for developing innovative systems\nwith tunable characteristics. In this context, pyroelectric materials, which\nhold the capacity for charge generation when subjected to temperature changes,\noffer a promising route for this modulation. This work employs spatially\nresolved photoluminescence (PL) to explore the impact of pyroelectricity on the\nelectronic doping of monolayer MoS2 deposited on periodically poled LiNbO3 (LN)\nsubstrates. The results demonstrate that pyroelectricity in LN modulates the\ncharge carrier density in MoS2 on ferroelectric surfaces acting as doping\nmechanism without the need for gating electrodes. Furthermore, upon cooling,\npyroelectric charges effectively reverse the doping of p-n junctions on DWs,\nconverting them into n-p junctions. These findings highlight the potential of\npyroelectric substrates for tunable and configurable charge engineering in\ntransition metal dichalcogenides and suggest their applicability to other\ncombinations of 2D materials and ferroelectric substrates. They also open\navenues for alternative device architectures in nanoelectronic or nanophotonic\ndevices including switches, memories or sensors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-07T09:52:37Z"}
{"aid":"http://arxiv.org/abs/2504.04889v1","title":"The CesÃ ro Value Iteration","summary":"In this paper, we address the problem of undiscouted infinite-horizon optimal\ncontrol for deterministic systems where the classic value iteration does not\nconverge. For such systems, we propose to use the Ces\\`aro mean to define the\ninfinitehorizon optimal control problem and the corresponding infinitehorizon\nvalue function. Moreover, for this value function, we introduce the Ces\\`aro\nvalue iteration and prove its convergence for the special case of systems with\nperiodic optimal operating behavior.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-07T09:55:48Z"}
{"aid":"http://arxiv.org/abs/2504.04896v1","title":"Understanding and Design of Interstitial Oxygen Conductors","summary":"Highly efficient oxygen active materials that react with, absorb, and\ntransport oxygen is essential for fuel cells, electrolyzers and related\napplications. While vacancy mediated oxygen ion conductors have long been the\nfocus of research, they are limited by high migration barriers at intermediate\ntemperatures, which hinder their practical applications. In contrast,\ninterstitial oxygen conductors exhibit significantly lower migration barriers\nenabling faster ionic conductivity at lower temperatures. This review\nsystematically examines both well established and recently identified families\nof interstitial oxygen ion conductors, focusing on how their unique structural\nmotifs such as corner sharing polyhedral frameworks, isolated polyhedral, and\ncage like architectures, facilitate low migration barriers through interstitial\nand interstitialcy diffusion mechanisms. A central discussion of this review\nfocuses on the evolution of design strategies, from targeted donor doping,\nelement screening, and physical intuition descriptor material discovery, which\nleverage computational tools to explore vast chemical spaces in search of new\ninterstitial conductors. The success of these strategies demonstrates that a\nsignificant, largely unexplored space remains for discovering high performing\ninterstitial oxygen conductors. Crucial features enabling high performance\ninterstitial oxygen diffusion include the availability of electrons for oxygen\nreduction and sufficient structural flexibility with accessible volume for\ninterstitial accommodation. This review concludes with a forward looking\nperspective, proposing a knowledge driven methodology that integrates current\nunderstanding with data centric approaches to identify promising interstitial\noxygen conductors outside traditional search paradigms.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T10:08:31Z"}
{"aid":"http://arxiv.org/abs/2504.04897v1","title":"The Minimum Eternal Vertex Cover Problem on a Subclass of\n  Series-Parallel Graphs","summary":"Eternal vertex cover is the following two-player game between a defender and\nan attacker on a graph. Initially, the defender positions k guards on k\nvertices of the graph; the game then proceeds in turns between the defender and\nthe attacker, with the attacker selecting an edge and the defender responding\nto the attack by moving some of the guards along the edges, including the\nattacked one. The defender wins a game on a graph G with k guards if they have\na strategy such that, in every round of the game, the vertices occupied by the\nguards form a vertex cover of G, and the attacker wins otherwise. The eternal\nvertex cover number of a graph G is the smallest number k of guards allowing\nthe defender to win and Eternal Vertex Cover is the problem of computing the\neternal vertex cover number of the given graph.\n  We study this problem when restricted to the well-known class of\nseries-parallel graphs. In particular, we prove that Eternal Vertex Cover can\nbe solved in linear time when restricted to melon graphs, a proper subclass of\nseries-parallel graphs. Moreover, we also conjecture that this problem is\nNP-hard on series-parallel graphs.","main_category":"math.CO","categories":"math.CO,cs.CC,cs.DM,cs.DS,G.2.2","published":"2025-04-07T10:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.04898v1","title":"SLIDE: Automated Identification and Quantification of Grain Boundary\n  Sliding and Opening in 3D","summary":"Grain Boundary (GB) deformation mechanisms such as Sliding (GBS) and Opening\n(GBO) are prevalent in alloys at high homologous temperatures but are hard to\ncapture quantitatively. We propose an automated procedure to quantify 3D GB\ndeformations at the nanoscale, using a combination of precisely aligned Digital\nImage Correlation (DIC), electron backscatter diffraction, optical\nprofilometry, and in-beam secondary electron maps. The framework, named Sliding\nidentification by Local Integration of Displacements across Edges (SLIDE), (i)\ndistinguishes GBS from GBO, (ii) computes the datapoint-wise measured in-plane\ndisplacement gradient tensor (from DIC), (iii) projects this data onto the\ntheoretical GBS tensor to reject near-GB plasticity/elasticity/noise, and (iv)\nadds the out-of-plane step from optical profilometry to yield the local 3D\nGBS/GBO vector; automatically repeated for each $\\sim$50nm-long GB segment.\nSLIDE is validated on a virtual experiment of discrete 3D sliding, and\nsuccessfully applied to Zn-coated steel experiments, yielding quantitative\nGBS/GBO activity maps.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T10:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.04906v1","title":"On misconceptions about the Brier score in binary prediction models","summary":"The Brier score is a widely used metric evaluating overall performance of\npredictions for binary outcome probabilities in clinical research. However, its\ninterpretation can be complex, as it does not align with commonly taught\nconcepts in medical statistics. Consequently, the Brier score is often\nmisinterpreted, sometimes to a significant extent, a fact that has not been\nadequately addressed in the literature. This commentary aims to explore\nprevalent misconceptions surrounding the Brier score and elucidate the reasons\nthese interpretations are incorrect.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-07T10:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.04908v1","title":"Cloud-Fog Automation: The New Paradigm towards Autonomous Industrial\n  Cyber-Physical Systems","summary":"Autonomous Industrial Cyber-Physical Systems (ICPS) represent a future vision\nwhere industrial systems achieve full autonomy, integrating physical processes\nseamlessly with communication, computing and control technologies while\nholistically embedding intelligence. Cloud-Fog Automation is a new digitalized\nindustrial automation reference architecture that has been recently proposed.\nThis architecture is a fundamental paradigm shift from the traditional\nInternational Society of Automation (ISA)-95 model to accelerate the\nconvergence and synergy of communication, computing, and control towards a\nfully autonomous ICPS. With the deployment of new wireless technologies to\nenable almost-deterministic ultra-reliable low-latency communications, a joint\ndesign of optimal control and computing has become increasingly important in\nmodern ICPS. It is also imperative that system-wide cyber-physical security are\ncritically enforced. Despite recent advancements in the field, there are still\nsignificant research gaps and open technical challenges. Therefore, a\ndeliberate rethink in co-designing and synergizing communications, computing,\nand control (which we term \"3C co-design\") is required. In this paper, we\nposition Cloud-Fog Automation with 3C co-design as the new paradigm to realize\nthe vision of autonomous ICPS. We articulate the state-of-the-art and future\ndirections in the field, and specifically discuss how goal-oriented\ncommunication, virtualization-empowered computing, and Quality of Service\n(QoS)-aware control can drive Cloud-Fog Automation towards a fully autonomous\nICPS, while accounting for system-wide cyber-physical security.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-07T10:36:26Z"}
{"aid":"http://arxiv.org/abs/2504.04939v1","title":"A Taxonomy of Self-Handover","summary":"Self-handover, transferring an object between one's own hands, is a common\nbut understudied bimanual action. While it facilitates seamless transitions in\ncomplex tasks, the strategies underlying its execution remain largely\nunexplored. Here, we introduce the first systematic taxonomy of self-handover,\nderived from manual annotation of over 12 hours of cooking activity performed\nby 21 participants. Our analysis reveals that self-handover is not merely a\npassive transition, but a highly coordinated action involving anticipatory\nadjustments by both hands. As a step toward automated analysis of human\nmanipulation, we further demonstrate the feasibility of classifying\nself-handover types using a state-of-the-art vision-language model. These\nfindings offer fresh insights into bimanual coordination, underscoring the role\nof self-handover in enabling smooth task transitions-an ability essential for\nadaptive dual-arm robotics.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-04-07T11:21:42Z"}
{"aid":"http://arxiv.org/abs/2504.04942v1","title":"Lemmanaid: Neuro-Symbolic Lemma Conjecturing","summary":"Automatically conjecturing useful, interesting and novel lemmas would greatly\nimprove automated reasoning tools and lower the bar for formalizing mathematics\nin proof assistants. It is however a very challenging task for both neural and\nsymbolic approaches. We present the first steps towards a practical\nneuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language\nModels (LLMs) and symbolic methods, and evaluate it on proof libraries for the\nIsabelle proof assistant. We train an LLM to generate lemma templates that\ndescribe the shape of a lemma, and use symbolic methods to fill in the details.\nWe compare Lemmanaid against an LLM trained to generate complete lemma\nstatements as well as previous fully symbolic conjecturing methods. Our results\nindicate that neural and symbolic techniques are complementary. By leveraging\nthe best of both symbolic and neural methods we can generate useful lemmas for\na wide range of input domains, facilitating computer-assisted theory\ndevelopment and formalization.","main_category":"cs.AI","categories":"cs.AI,cs.LO","published":"2025-04-07T11:30:36Z"}
{"aid":"http://arxiv.org/abs/2504.04949v1","title":"One Quantizer is Enough: Toward a Lightweight Audio Codec","summary":"Neural audio codecs have recently gained traction for their ability to\ncompress high-fidelity audio and generate discrete tokens that can be utilized\nin downstream generative modeling tasks. However, leading approaches often rely\non resource-intensive models and multi-quantizer architectures, resulting in\nconsiderable computational overhead and constrained real-world applicability.\nIn this paper, we present SQCodec, a lightweight neural audio codec that\nleverages a single quantizer to address these limitations. SQCodec explores\nstreamlined convolutional networks and local Transformer modules, alongside\nTConv, a novel mechanism designed to capture acoustic variations across\nmultiple temporal scales, thereby enhancing reconstruction fidelity while\nreducing model complexity. Extensive experiments across diverse datasets show\nthat SQCodec achieves audio quality comparable to multi-quantizer baselines,\nwhile its single-quantizer design offers enhanced adaptability and its\nlightweight architecture reduces resource consumption by an order of magnitude.\nThe source code is publicly available at https://github.com/zhai-lw/SQCodec.","main_category":"cs.SD","categories":"cs.SD,cs.AI,I.2.m","published":"2025-04-07T11:34:39Z"}
{"aid":"http://arxiv.org/abs/2504.04953v1","title":"M-Prometheus: A Suite of Open Multilingual LLM Judges","summary":"The use of language models for automatically evaluating long-form text\n(LLM-as-a-judge) is becoming increasingly common, yet most LLM judges are\noptimized exclusively for English, with strategies for enhancing their\nmultilingual evaluation capabilities remaining largely unexplored in the\ncurrent literature. This has created a disparity in the quality of automatic\nevaluation methods for non-English languages, ultimately hindering the\ndevelopment of models with better multilingual capabilities. To bridge this\ngap, we introduce M-Prometheus, a suite of open-weight LLM judges ranging from\n3B to 14B parameters that can provide both direct assessment and pairwise\ncomparison feedback on multilingual outputs. M-Prometheus models outperform\nstate-of-the-art open LLM judges on multilingual reward benchmarks spanning\nmore than 20 languages, as well as on literary machine translation (MT)\nevaluation covering 4 language pairs. Furthermore, M-Prometheus models can be\nleveraged at decoding time to significantly improve generated outputs across\nall 3 tested languages, showcasing their utility for the development of better\nmultilingual models. Lastly, through extensive ablations, we identify the key\nfactors for obtaining an effective multilingual judge, including backbone model\nselection and training on natively multilingual feedback data instead of\ntranslated data. We release our models, training dataset, and code.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T11:37:26Z"}
{"aid":"http://arxiv.org/abs/2504.04958v1","title":"Probabilistic imaginary-time evolution in state-vector-based and\n  shot-based simulations and on quantum devices","summary":"Imaginary-time evolution, an important technique in tensor network and\nquantum Monte Carlo algorithms on classical computers, has recently been\nadapted to quantum computing. In this study, we focus on probabilistic\nimaginary-time evolution (PITE) algorithm and derive its formulation in the\ncontext of state-vector-based simulations, where quantum state vectors are\ndirectly used to compute observables without statistical errors. We compare the\nresults with those of shot-based simulations, which estimate observables\nthrough repeated projective measurements. Applying the PITE algorithm to the\nHeisenberg chain, we investigate optimal initial conditions for convergence. We\nfurther demonstrate the method on the transverse-field Ising model using a\nstate-of-the-art trapped-ion quantum device. Finally, we explore the potential\nof error mitigation in this framework, highlighting practical considerations\nfor near-term digital quantum simulations.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-07T11:45:31Z"}
{"aid":"http://arxiv.org/abs/2504.04969v1","title":"Grouped Target Tracking and Seamless People Counting with a 24 GHz MIMO\n  FMCW","summary":"The problem of radar-based tracking of groups of people moving together and\ncounting their numbers in indoor environments is considered here. A novel\nprocessing pipeline to track groups of people moving together and count their\nnumbers is proposed and validated. The pipeline is specifically designed to\ndeal with frequent changes of direction and stop & go movements typical of\nindoor activities. The proposed approach combines a tracker with a classifier\nto count the number of grouped people; this uses both spatial features\nextracted from range-azimuth maps, and Doppler frequency features extracted\nwith wavelet decomposition. Thus, the pipeline outputs over time both the\nlocation and number of people present. The proposed approach is verified with\nexperimental data collected with a 24 GHz Frequency Modulated Continuous Wave\n(FMCW) radar. It is shown that the proposed method achieves 95.59% accuracy in\ncounting the number of people, and a tracking metric OSPA of 0.338.\nFurthermore, the performance is analyzed as a function of different relevant\nvariables such as feature combinations and scenarios.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T11:56:03Z"}
{"aid":"http://arxiv.org/abs/2504.04971v1","title":"Below threshold nonsequential double ionization with linearly polarized\n  two-color fields II: Quantum interference","summary":"We perform a systematic analysis of intra-channel quantum interference in\nlaser-induced nonsequential double ionization with linearly polarized\nbichromatic fields, focusing on the recollision-excitation with subsequent\nionization (RESI) mechanism, and employing the strong-field approximation. We\ngeneralize and elaborate several analytic interference conditions for RESI in\narbitrary driving fields, with a focus on the interference arising from the\nspecific symmetries of bichromatic fields. For example, for waves of comparable\nstrengths, multiple events per half cycle for the direct electron must be\nconsidered. Furthermore, interference breaks some of the symmetries arising\nfrom the field. We detangle the superimposed interference fringes originating\nfrom phase differences related to symmetrization due to electron exchange,\ntemporal shifts and a combination of exchange and event interference. We show\nthat the hierarchy between exchange-only and exchange-temporal interference is\nfluid and can be manipulated by an appropriate choice of driving-field\nparameters. This is enabled by different types of interference occupying\nspecific regions of the plane spanned by the electron momentum components\nparallel to the driving-field polarization.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-07T11:57:18Z"}
{"aid":"http://arxiv.org/abs/2504.04976v1","title":"A Domain-Based Taxonomy of Jailbreak Vulnerabilities in Large Language\n  Models","summary":"The study of large language models (LLMs) is a key area in open-world machine\nlearning. Although LLMs demonstrate remarkable natural language processing\ncapabilities, they also face several challenges, including consistency issues,\nhallucinations, and jailbreak vulnerabilities. Jailbreaking refers to the\ncrafting of prompts that bypass alignment safeguards, leading to unsafe outputs\nthat compromise the integrity of LLMs. This work specifically focuses on the\nchallenge of jailbreak vulnerabilities and introduces a novel taxonomy of\njailbreak attacks grounded in the training domains of LLMs. It characterizes\nalignment failures through generalization, objectives, and robustness gaps. Our\nprimary contribution is a perspective on jailbreak, framed through the\ndifferent linguistic domains that emerge during LLM training and alignment.\nThis viewpoint highlights the limitations of existing approaches and enables us\nto classify jailbreak attacks on the basis of the underlying model deficiencies\nthey exploit. Unlike conventional classifications that categorize attacks based\non prompt construction methods (e.g., prompt templating), our approach provides\na deeper understanding of LLM behavior. We introduce a taxonomy with four\ncategories -- mismatched generalization, competing objectives, adversarial\nrobustness, and mixed attacks -- offering insights into the fundamental nature\nof jailbreak vulnerabilities. Finally, we present key lessons derived from this\ntaxonomic study.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-04-07T12:05:16Z"}
{"aid":"http://arxiv.org/abs/2504.04980v1","title":"Combining kinetic and thermodynamic uncertainty relations in quantum\n  transport","summary":"We study the fluctuations of generic currents in multi-terminal,\nmulti-channel quantum transport settings. In the quantum regime, these\nfluctuations and the resulting precision differ strongly depending on whether\nthe device is of fermionic or bosonic nature. Using scattering theory, we show\nthat the precision is bounded by constraints set by the entropy production and\nby the activity in the spirit of thermodynamic or kinetic uncertainty\nrelations, valid for fermionic and bosonic quantum systems and even in the\nabsence of time-reversal symmetry. Furthermore, we derive a combined\nthermodynamic kinetic uncertainty relation, which is tight over a wide range of\nparameters and can hence predict the reachable precision of a device.\n  Since these constraints can be expressed in terms of observables accessible\nin transport measurements, such as currents and bandwidth, we foresee that the\ntight thermodynamic kinetic uncertainty-like bounds are also useful as an\ninference tool: they can be exploited to estimate entropy production from\ntransport observables, such as the charge current and its noise, which are more\neasily accessible in experiment.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-04-07T12:09:09Z"}
{"aid":"http://arxiv.org/abs/2504.04985v1","title":"Quasi-periodic sub-structure of RRAT J1913+1330","summary":"Recent findings suggest a universal relationship between the quasi-periodic\nsub-structures and rotational periods across various types of radio-emitting\nneutron stars. In this study, we report the detection of 12 quasi-periodic\nsub-structures in a rotating radio transient (RRAT) J1913+1330 using the\nFive-hundred-meter Aperture Spherical Radio Telescope (FAST). This is the\nsecond known RRAT exhibiting quasi-periodic sub-structures. Our result\nreinforces the observed relationship between quasi-periodicity and rotational\nperiod. The polarization analysis reveals that 11 of the 12 pulses exhibit high\nlinear polarization consistent with the quasi-periodic behaviour of the total\nintensity, while circular polarization with detectable quasi-periodic\nsub-structures is observed in only three pulses. No correlation is found\nbetween the sub-structure periods and their widths, peak fluxes, or fluences,\neven under the extremely variable single-pulse energy and morphology observed\nin J1913+1330.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T12:11:49Z"}
{"aid":"http://arxiv.org/abs/2504.04986v1","title":"Quantum control of a random transverse Ising spin system","summary":"We consider subspace transfer within the time-dependent one-dimensional\nquantum transverse Ising model, with random nearest-neighbor interactions and a\ntransverse field. We run numerical simulations using a variational approach and\nthe numerical GRAPE (gradient-ascent pulse engineering) and dCRAB (dressed\nchopped random basis) quantum control algorithms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T12:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.04987v1","title":"Classification of rank-one actions via the cutting-and-stacking\n  parameters","summary":"Let $G$ be a discrete countable infinite group. Let $T$ and $\\widetilde T$ be\ntwo rank-one $\\sigma$-finite measure preserving actions of $G$ and let\n$\\mathcal T$ and $\\widetilde {\\mathcal T}$ be the cutting-and-stacking\nparameters that determine $T$ and $\\widetilde T$ respectively. We find\nnecessary and sufficient conditions on $\\mathcal T$ and $\\widetilde{\\mathcal\nT}$ under which $T$ and $\\widetilde T$ are isomorphic. We also show that the\nisomorphism equivalence relation is a $G_\\delta$-subset in the Cartesian square\nof the set of all admissible parameters $\\mathcal T$ endowed with the natural\nPolish topology. If $G$ is amenable and $T$ and $\\widetilde T$ are finite\nmeasure preserving then we also find necessary and sufficient conditioins on\n$\\mathcal T$ and $\\widetilde {\\mathcal T}$ under which $\\widetilde T$ is a\nfactor of $T$.","main_category":"math.DS","categories":"math.DS","published":"2025-04-07T12:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.04989v1","title":"Randomized block Krylov method for approximation of truncated tensor SVD","summary":"This paper is devoted to studying the application of the block Krylov\nsubspace method for approximation of the truncated tensor SVD (T-SVD). The\ntheoretical results of the proposed randomized approach are presented. Several\nexperimental experiments using synthetics and real-world data are conducted to\nverify the efficiency and feasibility of the proposed randomized approach, and\nthe numerical results show that the proposed method provides promising results.\nApplications of the proposed approach to data completion and data compression\nare presented.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T12:13:47Z"}
{"aid":"http://arxiv.org/abs/2504.04990v1","title":"Quantum walk with coherent multiple translations induces fast quantum\n  gate operations","summary":"Quantum walks with one-dimensional translational symmetry are important for\nquantum algorithms, where the speed-up of the diffusion speed can be reached if\nlong-range couplings are added. Our work studies a scheme of a ring under the\nstrong resonant modulation that can support discrete-time quantum walk\nincluding coherent multiple long-range translations in a natural way along\nsynthetic frequency dimension. These multiple translation paths are added in a\ncoherent way, which makes the walker evolve under the topological band.\nTherein, not only the fast diffusion speed is expected, but more importantly,\nwe find that single quantum gate operations can be performed in the\nquasi-momentum space. In particular, we show the arbitrary single-qubit state\npreparation and an example of CNOT two-qubit gate with only one time step,\ndramarically increasing quantum algorithms. Our study uses a single ring to\nprovide fast quantum gate operations based on coherent multiple path quantum\nwalk, which may provide unique designs for efficient quantum operations on\nphotonic chips.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-07T12:14:19Z"}
{"aid":"http://arxiv.org/abs/2504.04994v1","title":"Following the Whispers of Values: Unraveling Neural Mechanisms Behind\n  Value-Oriented Behaviors in LLMs","summary":"Despite the impressive performance of large language models (LLMs), they can\npresent unintended biases and harmful behaviors driven by encoded values,\nemphasizing the urgent need to understand the value mechanisms behind them.\nHowever, current research primarily evaluates these values through external\nresponses with a focus on AI safety, lacking interpretability and failing to\nassess social values in real-world contexts. In this paper, we propose a novel\nframework called ValueExploration, which aims to explore the behavior-driven\nmechanisms of National Social Values within LLMs at the neuron level. As a case\nstudy, we focus on Chinese Social Values and first construct C-voice, a\nlarge-scale bilingual benchmark for identifying and evaluating Chinese Social\nValues in LLMs. By leveraging C-voice, we then identify and locate the neurons\nresponsible for encoding these values according to activation difference.\nFinally, by deactivating these neurons, we analyze shifts in model behavior,\nuncovering the internal mechanism by which values influence LLM\ndecision-making. Extensive experiments on four representative LLMs validate the\nefficacy of our framework. The benchmark and code will be available.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T12:23:59Z"}
{"aid":"http://arxiv.org/abs/2504.04998v1","title":"CONCERT: a Modular Reconfigurable Robot for Construction","summary":"This paper presents CONCERT, a fully reconfigurable modular collaborative\nrobot (cobot) for multiple on-site operations in a construction site. CONCERT\nhas been designed to support human activities in construction sites by\nleveraging two main characteristics: high-power density motors and modularity.\nIn this way, the robot is able to perform a wide range of highly demanding\ntasks by acting as a co-worker of the human operator or by autonomously\nexecuting them following user instructions. Most of its versatility comes from\nthe possibility of rapidly changing its kinematic structure by adding or\nremoving passive or active modules. In this way, the robot can be set up in a\nvast set of morphologies, consequently changing its workspace and capabilities\ndepending on the task to be executed. In the same way, distal end-effectors can\nbe replaced for the execution of different operations. This paper also includes\na full description of the software pipeline employed to automatically discover\nand deploy the robot morphology. Specifically, depending on the modules\ninstalled, the robot updates the kinematic, dynamic, and geometric parameters,\ntaking into account the information embedded in each module. In this way, we\ndemonstrate how the robot can be fully reassembled and made operational in less\nthan ten minutes. We validated the CONCERT robot across different use cases,\nincluding drilling, sanding, plastering, and collaborative transportation with\nobstacle avoidance, all performed in a real construction site scenario. We\ndemonstrated the robot's adaptivity and performance in multiple scenarios\ncharacterized by different requirements in terms of power and workspace.\nCONCERT has been designed and built by the Humanoid and Human-Centered\nMechatronics Laboratory (HHCM) at the Istituto Italiano di Tecnologia in the\ncontext of the European Project Horizon 2020 CONCERT.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T12:25:52Z"}
{"aid":"http://arxiv.org/abs/2504.05000v1","title":"Energy Gap Modulation in Proximitized Superconducting Puddles of\n  Graphene","summary":"We investigated proximity-induced superconductivity in a graphene-insulating\nInO bilayer system through gate-controlled transport measurements. Distinct\noscillations in the differential conductance are observed across both the\nelectron and hole doping regimes, with oscillation amplitudes increasing as the\nchemical potential moves away from the Dirac point. These findings are\nexplained using a theoretical model of a normal-superconductor-normal (NSN)\njunction, which addresses reflection and transmission probabilities at normal\nincidence. From this model, we extract key parameters for the proximitized\ngraphene, including the superconducting energy gap Delta and the effective\nlength scale Ls of the superconducting regions. Near the Dirac point, we\nobserve a minimal Ls and a maximal Delta, aligning with the theory that the gap\nin strongly disordered superconductors increases as the coherence length of\nlocalized pairs decreases. This suggests that spatial confinement in a\nlow-density superconductor leads to an effective increase in the\nsuperconducting gap.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-07T12:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.05001v1","title":"SILVIA: Ultra-precision formation flying demonstration for space-based\n  interferometry","summary":"We propose SILVIA (Space Interferometer Laboratory Voyaging towards\nInnovative Applications), a mission concept designed to demonstrate\nultra-precision formation flying between three spacecraft separated by 100 m.\nSILVIA aims to achieve sub-micrometer precision in relative distance control by\nintegrating spacecraft sensors, laser interferometry, low-thrust and low-noise\nmicro-propulsion for real-time measurement and control of distances and\nrelative orientations between spacecraft. A 100-meter-scale mission in a\nnear-circular low Earth orbit has been identified as an ideal, cost-effective\nsetting for demonstrating SILVIA, as this configuration maintains a good\nbalance between small relative perturbations and low risk for collision. This\nmission will fill the current technology gap towards future missions, including\ngravitational wave observatories such as DECIGO (DECihertz Interferometer\nGravitational wave Observatory), designed to detect the primordial\ngravitational wave background, and high-contrast nulling infrared\ninterferometers like LIFE (Large Interferometer for Exoplanets), designed for\ndirect imaging of thermal emissions from nearby terrestrial planet candidates.\nThe mission concept and its key technologies are outlined, paving the way for\nthe next generation of high-precision space-based observatories.","main_category":"astro-ph.IM","categories":"astro-ph.IM,cs.SY,eess.SY,gr-qc,physics.ins-det","published":"2025-04-07T12:27:46Z"}
{"aid":"http://arxiv.org/abs/2504.05004v1","title":"Stacking Variational Bayesian Monte Carlo","summary":"Variational Bayesian Monte Carlo (VBMC) is a sample-efficient method for\napproximate Bayesian inference with computationally expensive likelihoods.\nWhile VBMC's local surrogate approach provides stable approximations, its\nconservative exploration strategy and limited evaluation budget can cause it to\nmiss regions of complex posteriors. In this work, we introduce Stacking\nVariational Bayesian Monte Carlo (S-VBMC), a method that constructs global\nposterior approximations by merging independent VBMC runs through a principled\nand inexpensive post-processing step. Our approach leverages VBMC's mixture\nposterior representation and per-component evidence estimates, requiring no\nadditional likelihood evaluations while being naturally parallelizable. We\ndemonstrate S-VBMC's effectiveness on two synthetic problems designed to\nchallenge VBMC's exploration capabilities and two real-world applications from\ncomputational neuroscience, showing substantial improvements in posterior\napproximation quality across all cases.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-07T12:30:59Z"}
{"aid":"http://arxiv.org/abs/2504.05005v1","title":"Can audio recordings be used to detect leaks and coughs during\n  mechanical insufflation exsufflation (MI-E) treatment?","summary":"This report relates to a study group hosted by the EPSRC funded network,\nIntegrating data-driven BIOphysical models into REspiratory MEdicine (BIOREME),\nand supported by SofTMech and Innovate UK, Business Connect. The BIOREME\nnetwork hosts events, including this study group, to bring together\nmulti-disciplinary researchers, clinicians, companies and charities to catalyse\nresearch in the applications of mathematical modelling for respiratory\nmedicine. The goal of this study group was to provide an interface between\ncompanies, clinicians, and mathematicians to develop mathematical tools to the\nproblems presented. The study group was held at The University of Glasgow on\nthe 17 - 21 June 2024 and was attended by 16 participants from 8 different\ninstitutions. Below details the technical report of one of the challenges and\nthe methods developed by the team of researchers who worked on this challenge.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-07T12:32:01Z"}
{"aid":"http://arxiv.org/abs/2504.05023v1","title":"Topological transition between gapless phases in quantum walks","summary":"Topological gapless phases of matter have been a recent interest among\ntheoretical and experimental condensed matter physicists. Fermionic chains with\nextended nearest neighbor couplings have been observed to show unique\ntopological transition at the multicritical points between distinct gapless\nphases. In this work, we show that such topological gapless phases and the\ntransition between them can be simulated in a quantum walk. We consider a\nthree-step discrete-time quantum walk and identify various critical or gapless\nphases and multicriticalities from the topological phase diagram along with\ntheir distinguished energy dispersions. We reconstruct the scaling theory based\non the curvature function to study transition between gapless phases in the\nquantum walk. We show the interesting features observed in fermionic chains,\nsuch as diverging, sign flipping and swapping properties of curvature function,\ncan be simulated in the quantum walk. Moreover, the renormalization group flow\nand Wannier state correlation functions also identify transition at the\nmulticritical points between gapless phases. We observe the scaling law and\noverlapping of critical and fixed point properties at the multicritical points\nof the fermionic chains can also be observed in the quantum walk. Furthermore,\nwe categorize the topological transitions at various multicritical points using\nthe group velocity of the energy eigenstates. Finally, the topological\ncharacters of various gapless phases are captured using winding number which\nallows one to distinguish various gapless phases and also show the transitions\nat the multicritical points.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.other,cond-mat.stat-mech","published":"2025-04-07T12:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.05028v1","title":"The Lorentzian splitting theorem with weakened curvature condition","summary":"In this note we present a version of the Lorentzian splitting theorem under\nan averaged Ricci curvature condition, utilizing, in its proof, the properties\nof achronal limits developed in [18], [19].","main_category":"math.DG","categories":"math.DG,gr-qc","published":"2025-04-07T12:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.05032v1","title":"Contact surgery numbers of projective spaces","summary":"We classify all contact projective spaces with contact surgery number one. In\nparticular, this implies that there exist infinitely many non-isotopic contact\nstructures on the real projective 3-space which cannot be obtained by a single\nrational contact surgery from the standard tight contact 3-sphere.\n  Large parts of our proofs deal with a detailed analysis of Gompf's\n$\\Gamma$-invariant of tangential 2-plane fields on 3-manifolds. From our main\nresult we also deduce that the $\\Gamma$-invariant of a tangential 2-plane field\non the real projective 3-space only depends on its $d_3$-invariant.","main_category":"math.GT","categories":"math.GT,math.SG","published":"2025-04-07T12:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.05033v1","title":"CloSE: A Compact Shape- and Orientation-Agnostic Cloth State\n  Representation","summary":"Cloth manipulation is a difficult problem mainly because of the non-rigid\nnature of cloth, which makes a good representation of deformation essential. We\npresent a new representation for the deformation-state of clothes. First, we\npropose the dGLI disk representation, based on topological indices computed for\nsegments on the edges of the cloth mesh border that are arranged on a circular\ngrid. The heat-map of the dGLI disk uncovers patterns that correspond to\nfeatures of the cloth state that are consistent for different shapes, sizes of\npositions of the cloth, like the corners and the fold locations. We then\nabstract these important features from the dGLI disk onto a circle, calling it\nthe Cloth StatE representation (CloSE). This representation is compact,\ncontinuous, and general for different shapes. Finally, we show the strengths of\nthis representation in two relevant applications: semantic labeling and high-\nand low-level planning. The code, the dataset and the video can be accessed\nfrom : https://jaykamat99.github.io/close-representation","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-07T12:54:58Z"}
{"aid":"http://arxiv.org/abs/2504.05050v1","title":"Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language\n  Models","summary":"Large language models (LLMs) are foundational explorations to artificial\ngeneral intelligence, yet their alignment with human values via instruction\ntuning and preference learning achieves only superficial compliance. Here, we\ndemonstrate that harmful knowledge embedded during pretraining persists as\nindelible \"dark patterns\" in LLMs' parametric memory, evading alignment\nsafeguards and resurfacing under adversarial inducement at distributional\nshifts. In this study, we first theoretically analyze the intrinsic ethical\nvulnerability of aligned LLMs by proving that current alignment methods yield\nonly local \"safety regions\" in the knowledge manifold. In contrast, pretrained\nknowledge remains globally connected to harmful concepts via high-likelihood\nadversarial trajectories. Building on this theoretical insight, we empirically\nvalidate our findings by employing semantic coherence inducement under\ndistributional shifts--a method that systematically bypasses alignment\nconstraints through optimized adversarial prompts. This combined theoretical\nand empirical approach achieves a 100% attack success rate across 19 out of 23\nstate-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing\ntheir universal vulnerabilities.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T13:20:17Z"}
{"aid":"http://arxiv.org/abs/2504.05053v1","title":"Morphological Effects on Bacterial Brownian Motion: Validation of a\n  Chiral Two-Body Model","summary":"During bacterial swimming, thermal noise inevitably affects their motion,\nwhile the flagellum not only propels the bacteria, but also plays a crucial\nrole in enhancing the stability of their forward direction. In this study, we\naim to validate the effectiveness of a previously established chiral two-body\nmodel for simulating bacterial Brownian motion, which simplifies the helical\nflagellum to a chiral body. We systematically investigate bacterial motion\nusing the chiral two-body model, resistive force theory, and twin multipole\nmoment. We validate the effectiveness of the model by comparing the standard\ndeviations of the flagellar random velocities obtained from different methods.\nThe analytical solutions for the velocities, the thrust, and torque exerted by\nthe motor on the cell body are derived from the chiral two-body model during\nbacterial non-Brownian motion. We characterize the shape and symmetry of the\ntrajectories through the eigenvalues of the radius of gyration tensor, describe\ntheir linearity employing the directionality ratio, and evaluate the stability\nof forward direction using the average orientation. We conclude that\nappropriately increasing the helix radius and the contour length of the\nflagellum can elongate trajectories and enhance linearity. In addition, the\nlonger contour length increases the average orientation, thereby enhancing the\nstability of the bacterial forward direction. This study further validates the\neffectiveness of the chiral two-body model in simulating bacterial Brownian\nmotion and indicates the importance of the flagellum in stabilizing bacterial\nBrownian motion.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T13:21:39Z"}
{"aid":"http://arxiv.org/abs/2504.05062v1","title":"LDGNet: A Lightweight Difference Guiding Network for Remote Sensing\n  Change Detection","summary":"With the rapid advancement of deep learning, the field of change detection\n(CD) in remote sensing imagery has achieved remarkable progress. Existing\nchange detection methods primarily focus on achieving higher accuracy with\nincreased computational costs and parameter sizes, leaving development of\nlightweight methods for rapid real-world processing an underexplored challenge.\nTo address this challenge, we propose a Lightweight Difference Guiding Network\n(LDGNet), leveraging absolute difference image to guide optical remote sensing\nchange detection. First, to enhance the feature representation capability of\nthe lightweight backbone network, we propose the Difference Guiding Module\n(DGM), which leverages multi-scale features extracted from the absolute\ndifference image to progressively influence the original image encoder at each\nlayer, thereby reinforcing feature extraction. Second, we propose the\nDifference-Aware Dynamic Fusion (DADF) module with Visual State Space Model\n(VSSM) for lightweight long-range dependency modeling. The module first uses\nfeature absolute differences to guide VSSM's global contextual modeling of\nchange regions, then employs difference attention to dynamically fuse these\nlong-range features with feature differences, enhancing change semantics while\nsuppressing noise and background. Extensive experiments on multiple datasets\ndemonstrate that our method achieves comparable or superior performance to\ncurrent state-of-the-art (SOTA) methods requiring several times more\ncomputation, while maintaining only 3.43M parameters and 1.12G FLOPs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.05072v1","title":"$Q_B$-Optimal Two-Level Designs","summary":"Two-level designs are widely used for screening experiments where the goal is\nto identify a few active factors which have major effects. Orthogonal two-level\ndesigns in which all factors are level-balance and each of the four level\ncombinations of any pair of factors appears equally often are commonly used. In\nthis paper, we apply the model-robust $Q_B$ criterion introduced by Tsai,\nGilmour and Mead (2007) to the selection of optimal two-level screening designs\nwithout the requirements of level-balance and pairwise orthogonality. The\ncriterion incorporates experimenter's prior belief on how likely a factor is to\nbe active and recommends different designs under different priors, and without\nthe requirement of level-balance and pairwise orthogonality, a wider range of\ndesigns is possible. A coordinate exchange algorithm is developed for the\nconstruction of $Q_B$-optimal designs for given priors.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-07T13:38:39Z"}
{"aid":"http://arxiv.org/abs/2504.05076v1","title":"Content-Distortion High-Order Interaction for Blind Image Quality\n  Assessment","summary":"The content and distortion are widely recognized as the two primary factors\naffecting the visual quality of an image. While existing No-Reference Image\nQuality Assessment (NR-IQA) methods have modeled these factors, they fail to\ncapture the complex interactions between content and distortions. This\nshortfall impairs their ability to accurately perceive quality. To confront\nthis, we analyze the key properties required for interaction modeling and\npropose a robust NR-IQA approach termed CoDI-IQA (Content-Distortion high-order\nInteraction for NR-IQA), which aggregates local distortion and global content\nfeatures within a hierarchical interaction framework. Specifically, a\nProgressive Perception Interaction Module (PPIM) is proposed to explicitly\nsimulate how content and distortions independently and jointly influence image\nquality. By integrating internal interaction, coarse interaction, and fine\ninteraction, it achieves high-order interaction modeling that allows the model\nto properly represent the underlying interaction patterns. To ensure sufficient\ninteraction, multiple PPIMs are employed to hierarchically fuse multi-level\ncontent and distortion features at different granularities. We also tailor a\ntraining strategy suited for CoDI-IQA to maintain interaction stability.\nExtensive experiments demonstrate that the proposed method notably outperforms\nthe state-of-the-art methods in terms of prediction accuracy, data efficiency,\nand generalization ability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:44:30Z"}
{"aid":"http://arxiv.org/abs/2504.05078v1","title":"Serverless Approach to Running Resource-Intensive STAR Aligner","summary":"The application of serverless computing for alignment of RNA-sequences can\nimprove many existing bioinformatics workflows by reducing operational costs\nand execution times. This work analyzes the applicability of serverless\nservices for running the STAR aligner, which is known for its accuracy and\nlarge memory requirement. This presents a challenge, as serverless services\nwere designed for light and short tasks. Nevertheless, we successfully deploy a\nSTAR-based pipeline on AWS ECS service, propose multiple optimizations, and\nperform experiment with 17 TBs of data. Results are compared against standard\nvirtual machine (VM) based solution showing that serverless is a valid\nalternative for small-scale batch processing. However, in large-scale where\nefficiency matters the most, VMs are still recommended.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-07T13:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.05079v1","title":"Experimental verification of Threshold Quantum State Tomography on a\n  fully-reconfigurable photonic integrated circuit","summary":"Reconstructing the state of a complex quantum system represents a pivotal\ntask for all quantum information applications, both for characterization\npurposes and for verification of quantum protocols. Recent technological\ndevelopments have shown the capability of building quantum systems with\nprogressively larger number of qubits in different platforms. The standard\napproach based on quantum state tomography, while providing a method to\ncompletely characterize an unknown quantum state, requires a number of\nmeasurements that scales exponentially with the number of qubits. Other methods\nhave been subsequently proposed and tested to reduce the number of\nmeasurements, or to focus on specific properties of the output state rather\nthan on its complete reconstruction. Here, we show experimentally the\napplication of an approach, called threshold quantum state tomography, in an\nadvanced hybrid photonic platform with states up to n=4 qubits. This method\ndoes not require a priori knowledge on the state, and selects only the\ninformative projectors starting from the measurement of the density matrix\ndiagonal. We show the effectiveness of this approach in a photonic platform,\nshowing that a consistent reduction in the number of measurement is obtained\nwhile reconstructing relevant states for quantum protocols, with only very\nlimited loss of information. The advantage of this protocol opens perspective\nof its application in larger, more complex, systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T13:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.05100v1","title":"Non-Smooth Multi-objective Controller Synthesis for Test-Mass Actuation\n  in Gravitational-Wave Detectors","summary":"This paper proposes a non-smooth controller optimization method and shows the\nresults of ongoing research on the implementation of this method for\ngravitational wave applications. Typical performance requirements concerning\nthese type of suspensions are defined in terms of both H2- and Hinf-type\nconstraints. A non-smooth optimization approach is investigated, which allows\nthe use of non-convex cost functions that are often a result of mixed H2/Hinf\noptimization problems. Besides the controller, the distribution of the\nactuation is integrated with the optimization to investigate the feasibility of\nsimultaneous controller and actuator optimization. The results demonstrate that\nthe proposed non-smooth optimization method is able to find suitable solutions\nfor the control and actuator distribution that satisfy all required performance\nand design constraints.","main_category":"astro-ph.IM","categories":"astro-ph.IM,gr-qc","published":"2025-04-07T14:08:05Z"}
{"aid":"http://arxiv.org/abs/2504.05103v1","title":"TDFANet: Encoding Sequential 4D Radar Point Clouds Using\n  Trajectory-Guided Deformable Feature Aggregation for Place Recognition","summary":"Place recognition is essential for achieving closed-loop or global\npositioning in autonomous vehicles and mobile robots. Despite recent\nadvancements in place recognition using 2D cameras or 3D LiDAR, it remains to\nbe seen how to use 4D radar for place recognition - an increasingly popular\nsensor for its robustness against adverse weather and lighting conditions.\nCompared to LiDAR point clouds, radar data are drastically sparser, noisier and\nin much lower resolution, which hampers their ability to effectively represent\nscenes, posing significant challenges for 4D radar-based place recognition.\nThis work addresses these challenges by leveraging multi-modal information from\nsequential 4D radar scans and effectively extracting and aggregating\nspatio-temporal features.Our approach follows a principled pipeline that\ncomprises (1) dynamic points removal and ego-velocity estimation from velocity\nproperty, (2) bird's eye view (BEV) feature encoding on the refined point\ncloud, (3) feature alignment using BEV feature map motion trajectory calculated\nby ego-velocity, (4) multi-scale spatio-temporal features of the aligned BEV\nfeature maps are extracted and aggregated.Real-world experimental results\nvalidate the feasibility of the proposed method and demonstrate its robustness\nin handling dynamic environments. Source codes are available.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T14:10:07Z"}
{"aid":"http://arxiv.org/abs/2504.05108v1","title":"Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement\n  Learning","summary":"Discovering efficient algorithms for solving complex problems has been an\noutstanding challenge in mathematics and computer science, requiring\nsubstantial human expertise over the years. Recent advancements in evolutionary\nsearch with large language models (LLMs) have shown promise in accelerating the\ndiscovery of algorithms across various domains, particularly in mathematics and\noptimization. However, existing approaches treat the LLM as a static generator,\nmissing the opportunity to update the model with the signal obtained from\nevolutionary exploration. In this work, we propose to augment LLM-based\nevolutionary search by continuously refining the search operator - the LLM -\nthrough reinforcement learning (RL) fine-tuning. Our method leverages\nevolutionary search as an exploration strategy to discover improved algorithms,\nwhile RL optimizes the LLM policy based on these discoveries. Our experiments\non three combinatorial optimization tasks - bin packing, traveling salesman,\nand the flatpack problem - show that combining RL and evolutionary search\nimproves discovery efficiency of improved algorithms, showcasing the potential\nof RL-enhanced evolutionary strategies to assist computer scientists and\nmathematicians for more efficient algorithm design.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.NE","published":"2025-04-07T14:14:15Z"}
{"aid":"http://arxiv.org/abs/2504.05109v1","title":"Inverse Mixed Integer Optimization: An Interior Point Perspective","summary":"We propose a novel solution framework for inverse mixed-integer optimization\nbased on analytic center concepts from interior point methods. We characterize\nthe optimality gap of a given solution, provide structural results, and propose\nmodels that can efficiently solve large problems. First, we exploit the\nproperty that mixed-integer solutions are primarily interior points that can be\nmodeled as weighted analytic centers with unique weights. We then demonstrate\nthat the optimality of a given solution can be measured relative to an\nidentifiable optimal solution to the linear programming relaxation. We quantify\nthe absolute optimality gap and pose the inverse mixed-integer optimization\nproblem as a bi-level program where the upper-level objective minimizes the\nnorm to a given reference cost, while the lower-level objective minimizes the\nabsolute optimality gap to an optimal linear programming solution. We provide\ntwo models that address the discrepancies between the upper and lower-level\nproblems, establish links with noisy and data-driven optimization, and conduct\nextensive numerical testing. We find that the proposed framework successfully\nidentifies high-quality solutions in rapid computational times. Compared to the\nstate-of-the-art trust region cutting plane method, it achieves optimal cost\nvectors for 95% and 68% of the instances within optimality gaps of e-2 and e-5,\nrespectively, without sacrificing the relative proximity to the nominal cost\nvector. To ensure the optimality of the given solution, the proposed approach\nis complemented by a classical cutting plane method. It is shown to solve\ninstances that the trust region cutting plane method could not successfully\nsolve as well as being in very close proximity to the nominal cost vector.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T14:15:17Z"}
{"aid":"http://arxiv.org/abs/2504.05132v1","title":"Oscillatory flows in three-dimensional deformable microchannels","summary":"Deformable microchannels emulate a key characteristic of soft biological\nsystems and flexible engineering devices: the flow-induced deformation of the\nconduit due to slow viscous flow within. Elucidating the two-way coupling\nbetween oscillatory flow and deformation of a three-dimensional (3D)\nrectangular channel is crucial for designing lab- and organ-on-a-chip\nmicrosystems and eventually understanding flow-structure instabilities that can\nenhance mixing and transport. We determine the axial variations of the primary\nflow, pressure, and deformation for Newtonian fluids in the canonical geometry\nof a slender (long) and shallow (wide) 3D rectangular channel with a deformable\ntop wall under the assumption of weak compliance and without restriction on the\noscillation frequency (i.e., on the Womersley number). Unlike rigid conduits,\nthe pressure distribution is not linear with the axial coordinate. To validate\nthis prediction, we design a PDMS-based experimental platform with a\nspeaker-based flow-generation apparatus and a pressure acquisition system with\nmultiple ports along the axial length of the channel. The experimental\nmeasurements show good agreement with the predicted pressure profiles across a\nwide range of the key dimensionless quantities: the Womersley number, the\ncompliance number, and the elastoviscous number. Finally, we explore how the\nnonlinear flow -- deformation coupling leads to self-induced streaming\n(rectification of the oscillatory flow). Following Zhang and Rallabandi (J.\nFluid Mech., 996, 2024, A16), we develop a theory for the cycle-averaged\npressure based on the primary problem's solution, and we validate the\npredictions for the axial distribution of the streaming pressure against\nhigh-precision experimental measurements.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-07T14:35:46Z"}
{"aid":"http://arxiv.org/abs/2504.05136v1","title":"Information Geometry of Exponentiated Gradient: Convergence beyond\n  L-Smoothness","summary":"We study the minimization of smooth, possibly nonconvex functions over the\npositive orthant, a key setting in Poisson inverse problems, using the\nexponentiated gradient (EG) method. Interpreting EG as Riemannian gradient\ndescent (RGD) with the $e$-Exp map from information geometry as a retraction,\nwe prove global convergence under weak assumptions -- without the need for\n$L$-smoothness -- and finite termination of Riemannian Armijo line search.\nNumerical experiments, including an accelerated variant, highlight EG's\npractical advantages, such as faster convergence compared to RGD based on\ninterior-point geometry.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T14:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.05147v1","title":"Pr$ÎµÎµ$mpt: Sanitizing Sensitive Prompts for LLMs","summary":"The rise of large language models (LLMs) has introduced new privacy\nchallenges, particularly during inference where sensitive information in\nprompts may be exposed to proprietary LLM APIs. In this paper, we address the\nproblem of formally protecting the sensitive information contained in a prompt\nwhile maintaining response quality. To this end, first, we introduce a\ncryptographically inspired notion of a prompt sanitizer which transforms an\ninput prompt to protect its sensitive tokens. Second, we propose\nPr$\\epsilon\\epsilon$mpt, a novel system that implements a prompt sanitizer.\nPr$\\epsilon\\epsilon$mpt categorizes sensitive tokens into two types: (1) those\nwhere the LLM's response depends solely on the format (such as SSNs, credit\ncard numbers), for which we use format-preserving encryption (FPE); and (2)\nthose where the response depends on specific values, (such as age, salary) for\nwhich we apply metric differential privacy (mDP). Our evaluation demonstrates\nthat Pr$\\epsilon\\epsilon$mpt is a practical method to achieve meaningful\nprivacy guarantees, while maintaining high utility compared to unsanitized\nprompts, and outperforming prior methods","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-07T14:52:40Z"}
{"aid":"http://arxiv.org/abs/2504.05152v1","title":"PanoDreamer: Consistent Text to 360-Degree Scene Generation","summary":"Automatically generating a complete 3D scene from a text description, a\nreference image, or both has significant applications in fields like virtual\nreality and gaming. However, current methods often generate low-quality\ntextures and inconsistent 3D structures. This is especially true when\nextrapolating significantly beyond the field of view of the reference image. To\naddress these challenges, we propose PanoDreamer, a novel framework for\nconsistent, 3D scene generation with flexible text and image control. Our\napproach employs a large language model and a warp-refine pipeline, first\ngenerating an initial set of images and then compositing them into a 360-degree\npanorama. This panorama is then lifted into 3D to form an initial point cloud.\nWe then use several approaches to generate additional images, from different\nviewpoints, that are consistent with the initial point cloud and expand/refine\nthe initial point cloud. Given the resulting set of images, we utilize 3D\nGaussian Splatting to create the final 3D scene, which can then be rendered\nfrom different viewpoints. Experiments demonstrate the effectiveness of\nPanoDreamer in generating high-quality, geometrically consistent 3D scenes.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T14:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.05157v1","title":"Duals and time-reversed flows of generalized Ornstein-Uhlenbeck\n  processes","summary":"We derive explicit representations for the (Siegmund-) dual and the\ntime-reversed flow of generalized Ornstein-Uhlenbeck processes whenever these\nexist. It turns out that the dual and the process corresponding to the reversed\nstochastic flow are again generalized Ornstein-Uhlenbeck processes. Further, we\nobserve that the stationary distribution of the dual process provides\ninformation about the hitting time of zero of the original process.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T15:00:10Z"}
{"aid":"http://arxiv.org/abs/2504.05169v1","title":"Machine learning interatomic potential can infer electrical response","summary":"Modeling the response of material and chemical systems to electric fields\nremains a longstanding challenge. Machine learning interatomic potentials\n(MLIPs) offer an efficient and scalable alternative to quantum mechanical\nmethods but do not by themselves incorporate electrical response. Here, we show\nthat polarization and Born effective charge (BEC) tensors can be directly\nextracted from long-range MLIPs within the Latent Ewald Summation (LES)\nframework, solely by learning from energy and force data. Using this approach,\nwe predict the infrared spectra of bulk water under zero or finite external\nelectric fields, ionic conductivities of high-pressure superionic ice, and the\nphase transition and hysteresis in ferroelectric PbTiO$_3$ perovskite. This\nwork thus extends the capability of MLIPs to predict electrical\nresponse--without training on charges or polarization or BECs--and enables\naccurate modeling of electric-field-driven processes in diverse systems at\nscale.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.chem-ph,physics.comp-ph","published":"2025-04-07T15:14:07Z"}
{"aid":"http://arxiv.org/abs/2504.05190v1","title":"Maximum Shortest Path Interdiction Problem by Upgrading Nodes on Trees\n  under Unit Cost","summary":"Network interdiction problems by deleting critical nodes have wide\napplications. However, node deletion is not always feasible in certain\npractical scenarios. We consider the maximum shortest path interdiction problem\nby upgrading nodes on trees under unit cost (MSPIT-UN$_u$). It aims to upgrade\na subset of nodes to maximize the length of the shortest root-leaf distance\nsuch that the total upgrade cost under unit cost is upper bounded by a given\nvalue. We develop a dynamic programming algorithm with a time complexity of\n$O(n^3)$ to solve this problem. Furthermore, we consider the related minimum\ncost problem of (MSPIT-UN$_u$) and propose an $O(n^3\\log n)$ binary search\nalgorithm, where a dynamic programming algorithm is exceeded in each iteration\nto solve its corresponding problem (MSPIT-UN$_u$). Finally, we design numerical\nexperiments to show the effectiveness of the algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T15:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.05200v1","title":"Affine hypersurfaces and superintegrable systems","summary":"It was recently shown that under mild assumptions second-order conformally\nsuperintegrable systems can be encoded in a $(0,3)$-tensor, called structure\ntensor. For abundant systems, this approach led to algebraic integrability\nconditions that essentially allow one to restore a system from the knowledge of\nits structure tensor in a point on the manifold. Here we study the geometric\nstructure formalising such systems, which we call an abundant manifold. The\nunderlying Riemannian manifold is necessarily conformally flat. We establish a\ncorrespondence between these superintegrable systems and the geometry of affine\nhypersurfaces. More precisely, we show that abundant manifolds correspond to\ncertain non-degenerate relative affine hypersurfaces normalisations in $\\mathbb\nR^{n+1}$ ($n\\ge 2$). We also formulate the necessary and sufficient conditions\nnon-degenerate relative affine hypersurface normalisations in $\\mathbb R^{n+1}$\nneed to satisfy, if they arise from abundant manifolds. These relative affine\nhypersurface normalisations are called abundant hypersurface normalisations.\nBoth for abundant manifolds and for relative affine hypersurface normalisations\na natural concept of conformal equivalence can be defined. We prove that they\nare compatible, permitting us to identify conformal classes of abundant\nmanifolds with abundant hypersurface immersions (without specified\nnormalisation).","main_category":"math.DG","categories":"math.DG","published":"2025-04-07T15:50:26Z"}
{"aid":"http://arxiv.org/abs/2504.05202v1","title":"Infinitely Divisible Noise for Differential Privacy: Nearly Optimal\n  Error in the High $\\varepsilon$ Regime","summary":"Differential privacy (DP) can be achieved in a distributed manner, where\nmultiple parties add independent noise such that their sum protects the overall\ndataset with DP. A common technique here is for each party to sample their\nnoise from the decomposition of an infinitely divisible distribution. We\nanalyze two mechanisms in this setting: 1) the generalized discrete Laplace\n(GDL) mechanism, whose distribution (which is closed under summation) follows\nfrom differences of i.i.d. negative binomial shares, and 2) the multi-scale\ndiscrete Laplace (MSDLap) mechanism, a novel mechanism following the sum of\nmultiple i.i.d. discrete Laplace shares at different scales.\n  For $\\varepsilon \\geq 1$, our mechanisms can be parameterized to have\n$O\\left(\\Delta^3 e^{-\\varepsilon}\\right)$ and $O\\left(\\min\\left(\\Delta^3\ne^{-\\varepsilon}, \\Delta^2 e^{-2\\varepsilon/3}\\right)\\right)$ MSE,\nrespectively, where $\\Delta$ denote the sensitivity; the latter bound matches\nknown optimality results. We also show a transformation from the discrete\nsetting to the continuous setting, which allows us to transform both mechanisms\nto the continuous setting and thereby achieve the optimal $O\\left(\\Delta^2\ne^{-2\\varepsilon / 3}\\right)$ MSE. To our knowledge, these are the first\ninfinitely divisible additive noise mechanisms that achieve order-optimal MSE\nunder pure DP, so our work shows formally there is no separation in utility\nwhen query-independent noise adding mechanisms are restricted to infinitely\ndivisible noise. For the continuous setting, our result improves upon the Arete\nmechanism from [Pagh and Stausholm, ALT 2022] which gives an MSE of\n$O\\left(\\Delta^2 e^{-\\varepsilon/4}\\right)$. Furthermore, we give an exact\nsampler tuned to efficiently implement the MSDLap mechanism, and we apply our\nresults to improve a state of the art multi-message shuffle DP protocol in the\nhigh $\\varepsilon$ regime.","main_category":"cs.CR","categories":"cs.CR,cs.DS","published":"2025-04-07T15:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.05214v1","title":"Post-Training Language Models for Continual Relation Extraction","summary":"Real-world data, such as news articles, social media posts, and chatbot\nconversations, is inherently dynamic and non-stationary, presenting significant\nchallenges for constructing real-time structured representations through\nknowledge graphs (KGs). Relation Extraction (RE), a fundamental component of KG\ncreation, often struggles to adapt to evolving data when traditional models\nrely on static, outdated datasets. Continual Relation Extraction (CRE) methods\ntackle this issue by incrementally learning new relations while preserving\npreviously acquired knowledge. This study investigates the application of\npre-trained language models (PLMs), specifically large language models (LLMs),\nto CRE, with a focus on leveraging memory replay to address catastrophic\nforgetting. We evaluate decoder-only models (eg, Mistral-7B and Llama2-7B) and\nencoder-decoder models (eg, Flan-T5 Base) on the TACRED and FewRel datasets.\nTask-incremental fine-tuning of LLMs demonstrates superior performance over\nearlier approaches using encoder-only models like BERT on TACRED, excelling in\nseen-task accuracy and overall performance (measured by whole and average\naccuracy), particularly with the Mistral and Flan-T5 models. Results on FewRel\nare similarly promising, achieving second place in whole and average accuracy\nmetrics. This work underscores critical factors in knowledge transfer, language\nmodel architecture, and KG completeness, advancing CRE with LLMs and memory\nreplay for dynamic, real-time relation extraction.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:01:22Z"}
{"aid":"http://arxiv.org/abs/2504.05218v1","title":"Hybrid machine learning data assimilation for marine biogeochemistry","summary":"Marine biogeochemistry models are critical for forecasting, as well as\nestimating ecosystem responses to climate change and human activities. Data\nassimilation (DA) improves these models by aligning them with real-world\nobservations, but marine biogeochemistry DA faces challenges due to model\ncomplexity, strong nonlinearity, and sparse, uncertain observations. Existing\nDA methods applied to marine biogeochemistry struggle to update unobserved\nvariables effectively, while ensemble-based methods are computationally too\nexpensive for high-complexity marine biogeochemistry models. This study\ndemonstrates how machine learning (ML) can improve marine biogeochemistry DA by\nlearning statistical relationships between observed and unobserved variables.\nWe integrate ML-driven balancing schemes into a 1D prototype of a system used\nto forecast marine biogeochemistry in the North-West European Shelf seas. ML is\napplied to predict (i) state-dependent correlations from free-run ensembles and\n(ii), in an ``end-to-end'' fashion, analysis increments from an Ensemble Kalman\nFilter. Our results show that ML significantly enhances updates for previously\nnot-updated variables when compared to univariate schemes akin to those used\noperationally. Furthermore, ML models exhibit moderate transferability to new\nlocations, a crucial step toward scaling these methods to 3D operational\nsystems. We conclude that ML offers a clear pathway to overcome current\ncomputational bottlenecks in marine biogeochemistry DA and that refining\ntransferability, optimizing training data sampling, and evaluating scalability\nfor large-scale marine forecasting, should be future research priorities.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.LG","published":"2025-04-07T16:04:10Z"}
{"aid":"http://arxiv.org/abs/2504.05226v1","title":"Proposing TAGbank as a Corpus of Tree-Adjoining Grammar Derivations","summary":"The development of lexicalized grammars, particularly Tree-Adjoining Grammar\n(TAG), has significantly advanced our understanding of syntax and semantics in\nnatural language processing (NLP). While existing syntactic resources like the\nPenn Treebank and Universal Dependencies offer extensive annotations for\nphrase-structure and dependency parsing, there is a lack of large-scale corpora\ngrounded in lexicalized grammar formalisms. To address this gap, we introduce\nTAGbank, a corpus of TAG derivations automatically extracted from existing\nsyntactic treebanks. This paper outlines a methodology for mapping\nphrase-structure annotations to TAG derivations, leveraging the generative\npower of TAG to support parsing, grammar induction, and semantic analysis. Our\napproach builds on the work of CCGbank, extending it to incorporate the unique\nstructural properties of TAG, including its transparent derivation trees and\nits ability to capture long-distance dependencies. We also discuss the\nchallenges involved in the extraction process, including ensuring consistency\nacross treebank schemes and dealing with language-specific syntactic\nidiosyncrasies. Finally, we propose the future extension of TAGbank to include\nmultilingual corpora, focusing on the Penn Korean and Penn Chinese Treebanks,\nto explore the cross-linguistic application of TAG's formalism. By providing a\nrobust, derivation-based resource, TAGbank aims to support a wide range of\ncomputational tasks and contribute to the theoretical understanding of TAG's\ngenerative capacity.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:13:19Z"}
{"aid":"http://arxiv.org/abs/2504.05233v1","title":"Formation of Near-surface Atmospheric Inversion and Surface Inversion in\n  Hothouse Climates","summary":"A hothouse climate may develop throughout Earth's history and its warming\nfuture and on potentially habitable exoplanets near the inner edge of the\nhabitable zone. Previous studies suggested that near-surface atmospheric\ninversion (NAIV) with planetary boundary air temperature being higher than the\nair temperature adjacent to the surface, is a pronounced phenomenon in hothouse\nclimates. However, the underlying mechanisms are unclear. Here we show that\nlower-tropospheric radiative heating is necessary but not independently\nsufficient in forming the NAIV. Instead, the dynamic heating induced by\nlarge-scale subsidence is essential. With the prescribed reasonable large-scale\nsubsidence, NAIV appears in small-domain cloud-resolving simulations, which was\nnot observed in previous studies. Surface evaporative cooling also contributes\nto the formation of the NAIV. Besides NAIV, we find that surface inversion\n(SIV) with the air adjacent to the surface being warmer than the underlying sea\nsurface is also a distinct phenomenon in hothouse climates. SIV is caused by\nstrong surface evaporative cooling and large atmospheric shortwave absorption.\nThese two types of inversion strongly stabilize the atmosphere, weaken\natmospheric circulation, dry the free troposphere, and suppress the\nhydrological cycle.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.ao-ph","published":"2025-04-07T16:18:06Z"}
{"aid":"http://arxiv.org/abs/2504.05248v1","title":"PINNverse: Accurate parameter estimation in differential equations from\n  noisy data with constrained physics-informed neural networks","summary":"Parameter estimation for differential equations from measured data is an\ninverse problem prevalent across quantitative sciences. Physics-Informed Neural\nNetworks (PINNs) have emerged as effective tools for solving such problems,\nespecially with sparse measurements and incomplete system information. However,\nPINNs face convergence issues, stability problems, overfitting, and complex\nloss function design. Here we introduce PINNverse, a training paradigm that\naddresses these limitations by reformulating the learning process as a\nconstrained differential optimization problem. This approach achieves a dynamic\nbalance between data loss and differential equation residual loss during\ntraining while preventing overfitting. PINNverse combines the advantages of\nPINNs with the Modified Differential Method of Multipliers to enable\nconvergence on any point on the Pareto front. We demonstrate robust and\naccurate parameter estimation from noisy data in four classical ODE and PDE\nmodels from physics and biology. Our method enables accurate parameter\ninference also when the forward problem is expensive to solve.","main_category":"cs.LG","categories":"cs.LG,cs.AI,physics.comp-ph","published":"2025-04-07T16:34:57Z"}
{"aid":"http://arxiv.org/abs/2504.05259v1","title":"How to evaluate control measures for LLM agents? A trajectory from today\n  to superintelligence","summary":"As LLM agents grow more capable of causing harm autonomously, AI developers\nwill rely on increasingly sophisticated control measures to prevent possibly\nmisaligned agents from causing harm. AI developers could demonstrate that their\ncontrol measures are sufficient by running control evaluations: testing\nexercises in which a red team produces agents that try to subvert control\nmeasures. To ensure control evaluations accurately capture misalignment risks,\nthe affordances granted to this red team should be adapted to the capability\nprofiles of the agents to be deployed under control measures.\n  In this paper we propose a systematic framework for adapting affordances of\nred teams to advancing AI capabilities. Rather than assuming that agents will\nalways execute the best attack strategies known to humans, we demonstrate how\nknowledge of an agents's actual capability profile can inform proportional\ncontrol evaluations, resulting in more practical and cost-effective control\nmeasures. We illustrate our framework by considering a sequence of five\nfictional models (M1-M5) with progressively advanced capabilities, defining\nfive distinct AI control levels (ACLs). For each ACL, we provide example rules\nfor control evaluation, control measures, and safety cases that could be\nappropriate. Finally, we show why constructing a compelling AI control safety\ncase for superintelligent LLM agents will require research breakthroughs,\nhighlighting that we might eventually need alternative approaches to mitigating\nmisalignment risk.","main_category":"cs.AI","categories":"cs.AI,cs.CR","published":"2025-04-07T16:52:52Z"}
{"aid":"http://arxiv.org/abs/2504.05267v1","title":"A Telecentric Offset Reflective Imaging System (TORIS) for Terahertz\n  Imaging and Spectroscopy","summary":"Terahertz (THz) imaging has emerged as a promising technology in medical\ndiagnostics due to its non-ionizing radiation and high sensitivity to water\ncontent. However, conventional THz imaging systems face limitations such as\nslow mechanical scanning, restricted field of view, and poor telecentricity. To\novercome these challenges, we introduce the Telecentric Offset Reflective\nImaging System (TORIS), a novel dual-mirror scanning design optimized for\nhigh-speed, distortion-free imaging. The system employs a telecentric f-theta\nlens and is validated using ray tracing and physical optics simulations. It\nachieves uniform resolution across a 50 mm x 50 mm field of view without the\nneed for mechanical translation stages. Broadband spectral imaging of a USAF\nresolution test target across WR-2.2 (325-500 GHz) and WR-1.5 (500-700 GHz)\nfrequency bands demonstrates consistent beam focus and minimal distortion, with\na maximum deviation of 2.7 degrees from normal incidence and a beam waist of\n2.1 lambda at the field edge in the WR-1.5 band. The system's sensitivity to\nhydration dynamics is further validated through imaging of wet tissue paper,\ncapturing temporal changes in water content. In vivo imaging of human skin\nafter capsaicin patch application reveals localized hydration variations due to\nbiochemical response and adhesive removal. These findings confirm the system's\npotential for real-time hydration sensing and dermatological evaluation. TORIS\nsets a new benchmark in THz imaging, with applications in clinical diagnostics,\nwound assessment, and material characterization.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-07T17:05:35Z"}
{"aid":"http://arxiv.org/abs/2504.05283v1","title":"JWST Reveals Spectral Tracers of Recent Surface Modification on Europa","summary":"Europa has been modified by a variety of geologic processes, exposing\ninternally-derived materials that are heavily irradiated by charged particles\ntrapped in Jupiter's magnetosphere. Prior spectral analysis of H2O ice on\nEuropa relied on low signal-to-noise data at wavelengths >2.5 microns, limiting\nassessment of a 3.1 micron Fresnel peak that is diagnostic of exposed\ncrystalline ice. We report new measurements of H2O ice spectral features using\nhigh signal-to-noise data collected by the NIRSpec spectrograph (1.48 - 5.35\nmicrons) on the James Webb Space Telescope. These data reveal a narrow 3.1\nmicron crystalline H2O ice Fresnel peak, which is primarily located at southern\nlatitudes in Tara and Powys Regiones. Our analysis indicates that crystalline\nice exposed in these low-latitude regiones is likely sustained by ongoing\nthermal (re)crystallization outpacing charged particle amorphization of the top\n10 microns of Europa's regolith over short timescales (<15 days). We also\nmeasured H2O ice features centered near 1.5 microns, 1.65 microns, and 2.0\nmicrons, and a broad 3.6 micron H2O continuum peak, which are all stronger at\nnorthern latitudes, in contrast to the 3.1 micron Fresnel peak identified at\nsouthern latitudes. These results support the hypothesis that H2O ice in\nEuropa's regolith is vertically stratified, with amorphous ice grains\ndominating its exposed surface, except in Tara and Powys Regiones. We also find\nthat a previously detected 4.38 micron 13O2 feature is present almost\nexclusively at southern latitudes in Tara and Powys Regiones, likely derived\nfrom an internal source of carbon-bearing material.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-07T17:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.05287v1","title":"RobustDexGrasp: Robust Dexterous Grasping of General Objects from\n  Single-view Perception","summary":"Robust grasping of various objects from single-view perception is fundamental\nfor dexterous robots. Previous works often rely on fully observable objects,\nexpert demonstrations, or static grasping poses, which restrict their\ngeneralization ability and adaptability to external disturbances. In this\npaper, we present a reinforcement-learning-based framework that enables\nzero-shot dynamic dexterous grasping of a wide range of unseen objects from\nsingle-view perception, while performing adaptive motions to external\ndisturbances. We utilize a hand-centric object representation for shape feature\nextraction that emphasizes interaction-relevant local shapes, enhancing\nrobustness to shape variance and uncertainty. To enable effective hand\nadaptation to disturbances with limited observations, we propose a mixed\ncurriculum learning strategy, which first utilizes imitation learning to\ndistill a policy trained with privileged real-time visual-tactile feedback, and\ngradually transfers to reinforcement learning to learn adaptive motions under\ndisturbances caused by observation noises and dynamic randomization. Our\nexperiments demonstrate strong generalization in grasping unseen objects with\nrandom poses, achieving success rates of 97.0% across 247,786 simulated objects\nand 94.6% across 512 real objects. We also demonstrate the robustness of our\nmethod to various disturbances, including unobserved object movement and\nexternal forces, through both quantitative and qualitative evaluations. Project\nPage: https://zdchan.github.io/Robust_DexGrasp/","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T17:38:19Z"}
{"aid":"http://arxiv.org/abs/2504.05294v1","title":"Truthful or Fabricated? Using Causal Attribution to Mitigate Reward\n  Hacking in Explanations","summary":"Chain-of-thought explanations are widely used to inspect the decision process\nof large language models (LLMs) and to evaluate the trustworthiness of model\noutputs, making them important for effective collaboration between LLMs and\nhumans. We demonstrate that preference optimization - a key step in the\nalignment phase - can inadvertently reduce the faithfulness of these\nexplanations. This occurs because the reward model (RM), which guides\nalignment, is tasked with optimizing both the expected quality of the response\nand the appropriateness of the explanations (e.g., minimizing bias or adhering\nto safety standards), creating potential conflicts. The RM lacks a mechanism to\nassess the consistency between the model's internal decision process and the\ngenerated explanation. Consequently, the LLM may engage in \"reward hacking\" by\nproducing a final response that scores highly while giving an explanation\ntailored to maximize reward rather than accurately reflecting its reasoning. To\naddress this issue, we propose enriching the RM's input with a causal\nattribution of the prediction, allowing the RM to detect discrepancies between\nthe generated self-explanation and the model's decision process. In controlled\nsettings, we show that this approach reduces the tendency of the LLM to\ngenerate misleading explanations.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T17:49:23Z"}
{"aid":"http://arxiv.org/abs/2504.05296v1","title":"Let it Snow! Animating Static Gaussian Scenes With Dynamic Weather\n  Effects","summary":"3D Gaussian Splatting has recently enabled fast and photorealistic\nreconstruction of static 3D scenes. However, introducing dynamic elements that\ninteract naturally with such static scenes remains challenging. Accordingly, we\npresent a novel hybrid framework that combines Gaussian-particle\nrepresentations for incorporating physically-based global weather effects into\nstatic 3D Gaussian Splatting scenes, correctly handling the interactions of\ndynamic elements with the static scene. We follow a three-stage process: we\nfirst map static 3D Gaussians to a particle-based representation. We then\nintroduce dynamic particles and simulate their motion using the Material Point\nMethod (MPM). Finally, we map the simulated particles back to the Gaussian\ndomain while introducing appearance parameters tailored for specific effects.\nTo correctly handle the interactions of dynamic elements with the static scene,\nwe introduce specialized collision handling techniques. Our approach supports a\nvariety of weather effects, including snowfall, rainfall, fog, and sandstorms,\nand can also support falling objects, all with physically plausible motion and\nappearance. Experiments demonstrate that our method significantly outperforms\nexisting approaches in both visual quality and physical realism.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-07T17:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.05298v1","title":"One-Minute Video Generation with Test-Time Training","summary":"Transformers today still struggle to generate one-minute videos because\nself-attention layers are inefficient for long context. Alternatives such as\nMamba layers struggle with complex multi-scene stories because their hidden\nstates are less expressive. We experiment with Test-Time Training (TTT) layers,\nwhose hidden states themselves can be neural networks, therefore more\nexpressive. Adding TTT layers into a pre-trained Transformer enables it to\ngenerate one-minute videos from text storyboards. For proof of concept, we\ncurate a dataset based on Tom and Jerry cartoons. Compared to baselines such as\nMamba~2, Gated DeltaNet, and sliding-window attention layers, TTT layers\ngenerate much more coherent videos that tell complex stories, leading by 34 Elo\npoints in a human evaluation of 100 videos per method. Although promising,\nresults still contain artifacts, likely due to the limited capability of the\npre-trained 5B model. The efficiency of our implementation can also be\nimproved. We have only experimented with one-minute videos due to resource\nconstraints, but the approach can be extended to longer videos and more complex\nstories. Sample videos, code and annotations are available at:\nhttps://test-time-training.github.io/video-dit","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.05304v1","title":"Gaussian Mixture Flow Matching Models","summary":"Diffusion models approximate the denoising distribution as a Gaussian and\npredict its mean, whereas flow matching models reparameterize the Gaussian mean\nas flow velocity. However, they underperform in few-step sampling due to\ndiscretization error and tend to produce over-saturated colors under\nclassifier-free guidance (CFG). To address these limitations, we propose a\nnovel Gaussian mixture flow matching (GMFlow) model: instead of predicting the\nmean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a\nmulti-modal flow velocity distribution, which can be learned with a KL\ndivergence loss. We demonstrate that GMFlow generalizes previous diffusion and\nflow matching models where a single Gaussian is learned with an $L_2$ denoising\nloss. For inference, we derive GM-SDE/ODE solvers that leverage analytic\ndenoising distributions and velocity fields for precise few-step sampling.\nFurthermore, we introduce a novel probabilistic guidance scheme that mitigates\nthe over-saturation issues of CFG and improves image generation quality.\nExtensive experiments demonstrate that GMFlow consistently outperforms flow\nmatching baselines in generation quality, achieving a Precision of 0.942 with\nonly 6 sampling steps on ImageNet 256$\\times$256.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-07T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.05306v1","title":"CREA: A Collaborative Multi-Agent Framework for Creative Content\n  Generation with Diffusion Models","summary":"Creativity in AI imagery remains a fundamental challenge, requiring not only\nthe generation of visually compelling content but also the capacity to add\nnovel, expressive, and artistically rich transformations to images. Unlike\nconventional editing tasks that rely on direct prompt-based modifications,\ncreative image editing demands an autonomous, iterative approach that balances\noriginality, coherence, and artistic intent. To address this, we introduce\nCREA, a novel multi-agent collaborative framework that mimics the human\ncreative process. Our framework leverages a team of specialized AI agents who\ndynamically collaborate to conceptualize, generate, critique, and enhance\nimages. Through extensive qualitative and quantitative evaluations, we\ndemonstrate that CREA significantly outperforms state-of-the-art methods in\ndiversity, semantic alignment, and creative transformation. By structuring\ncreativity as a dynamic, agentic process, CREA redefines the intersection of AI\nand art, paving the way for autonomous AI-driven artistic exploration,\ngenerative design, and human-AI co-creation. To the best of our knowledge, this\nis the first work to introduce the task of creative editing.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.05635v1","title":"The $L^p$-boundedness of wave operators for nonhomogeneous fourth-order\n  SchrÃ¶dinger operators in high dimensions","summary":"This paper investigates the $L^p$-boundedness of wave operators associated\nwith the nonhomogeneous fourth-order Sch\\\"odinger operator $H = \\Delta^2 -\n\\Delta + V(x)$ on $\\mathbb{R}^n$. Assuming the real-valued potential $ V $\nexhibits sufficient decay and regularity, we prove that for all dimensions $ n\n\\geq 5 $, the wave operators $ W_{\\pm}(H, H_0)$ are bounded on\n$L^{p}(\\mathbb{R}^{n}) $ for all $ 1 \\leq p \\leq \\infty $, provided that zero\nis a regular threshold of $H $.\n  As applications, we derive the sharp $L^p$-$L^{p'}$ dispersive estimates for\nSchr\\\"odinger group $e^{-itH}$, as well as for the solutions operators $\\cos(t\n\\sqrt{H})$ and $\\frac{\\sin (t \\sqrt{H})}{ \\sqrt{H}}$ associated with the\nfollowing beam equations with potentials: $$\n  \\partial_t^2 u + \\left(\\Delta^2 -\\Delta+ V(x) \\right) u = 0, \\ \\\n  u(0, x) = f(x), \\quad \\partial_t u(0, x) = g(x),\\ \\ (t, x) \\in \\mathbb{R}\n\\times \\mathbb{R}^n,\\ n\\geq5, $$\n  where $p'$ denotes the H\\\"older conjugate of $p$, with $1 \\leq p \\leq 2$.\nMoreover, we remark that the same results hold for the operator $ \\epsilon\n\\Delta^2 - \\Delta + V$ with a parameter $\\epsilon>0,$ providing greater\nflexibility for the analysis of related equations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T03:28:06Z"}
{"aid":"http://arxiv.org/abs/2504.05639v1","title":"DBOT: Artificial Intelligence for Systematic Long-Term Investing","summary":"Long-term investing was previously seen as requiring human judgment. With the\nadvent of generative artificial intelligence (AI) systems, automated systematic\nlong-term investing is now feasible. In this paper, we present DBOT, a system\nwhose goal is to reason about valuation like Aswath Damodaran, who is a unique\nexpert in the investment arena in terms of having published thousands of\nvaluations on companies in addition to his numerous writings on the topic,\nwhich provide ready training data for an AI system. DBOT can value any publicly\ntraded company. DBOT can also be back-tested, making its behavior and\nperformance amenable to scientific inquiry. We compare DBOT to its analytic\nparent, Damodaran, and highlight the research challenges involved in raising\nits current capability to that of Damodaran's. Finally, we examine the\nimplications of DBOT-like AI agents for the financial industry, especially how\nthey will impact the role of human analysts in valuation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,q-fin.PR","published":"2025-04-08T03:34:22Z"}
{"aid":"http://arxiv.org/abs/2504.05640v1","title":"CTI-Unet: Cascaded Threshold Integration for Improved U-Net Segmentation\n  of Pathology Images","summary":"Chronic kidney disease (CKD) is a growing global health concern,\nnecessitating precise and efficient image analysis to aid diagnosis and\ntreatment planning. Automated segmentation of kidney pathology images plays a\ncentral role in facilitating clinical workflows, yet conventional segmentation\nmodels often require delicate threshold tuning. This paper proposes a novel\n\\textit{Cascaded Threshold-Integrated U-Net (CTI-Unet)} to overcome the\nlimitations of single-threshold segmentation. By sequentially integrating\nmultiple thresholded outputs, our approach can reconcile noise suppression with\nthe preservation of finer structural details. Experiments on the challenging\nKPIs2024 dataset demonstrate that CTI-Unet outperforms state-of-the-art\narchitectures such as nnU-Net, Swin-Unet, and CE-Net, offering a robust and\nflexible framework for kidney pathology image segmentation.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T03:35:09Z"}
{"aid":"http://arxiv.org/abs/2504.05646v1","title":"Lattice: Learning to Efficiently Compress the Memory","summary":"Attention mechanisms have revolutionized sequence learning but suffer from\nquadratic computational complexity. This paper introduces Lattice, a novel\nrecurrent neural network (RNN) mechanism that leverages the inherent low-rank\nstructure of K-V matrices to efficiently compress the cache into a fixed number\nof memory slots, achieving sub-quadratic complexity. We formulate this\ncompression as an online optimization problem and derive a dynamic memory\nupdate rule based on a single gradient descent step. The resulting recurrence\nfeatures a state- and input-dependent gating mechanism, offering an\ninterpretable memory update process. The core innovation is the orthogonal\nupdate: each memory slot is updated exclusively with information orthogonal to\nits current state hence incorporation of only novel, non-redundant data, which\nminimizes the interference with previously stored information. The experimental\nresults show that Lattice achieves the best perplexity compared to all\nbaselines across diverse context lengths, with performance improvement becoming\nmore pronounced as the context length increases.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T03:48:43Z"}
{"aid":"http://arxiv.org/abs/2504.05650v1","title":"Exploring exclusive decay $B^+\\to Ï\\ell^+Î½$ within LCSR","summary":"In this paper, we calculate the Cabibbo-Kobayashi-Maskawa matrix element\n$|V_{ub}|$ by the semileptonic decay $B^+\\to \\omega\\ell^+\\nu$. For the\ntransition form factors (TFFs) $A_1(q^2)$, $A_2(q^2)$ and $V(q^2)$ of $B^+\\to\n\\omega$, we employ the QCD light-cone sum rules method for calculation, and by\nconstructing the correlation function using left-handed chiral current, we make\nthe $\\delta^1$-order twist-2 LCDA $\\phi^\\| _{2;\\omega}(x,\\mu)$ dominate the\ncontribution. In which the twist-2 LCDA $\\phi^\\| _{2;\\omega}(x,\\mu)$ is\nconstructed by light-cone harmonic oscillator model. Then, we obtain\n$A_1(0)=0.209^{+0.049}_{-0.042}$, $A_2(0)=0.206^{+0.051}_{-0.042}$ and\n$V(0)=0.258^{+0.058}_{-0.048}$ at large recoil region. Two important ratios of\nTFFs are $r_V=1.234_{-0.322}^{+0.425}$ and $r_2=0.985_{-0.274}^{+0.347}$. After\nextrapolating TFFs to the whole physical $q^2$-region by simplified\n$z(q^2,t)$-series expansion, we obtain the differential decay width and\nbranching fraction $\\mathcal{B}(B^+\\to\n\\omega\\ell^+\\nu)=(1.35^{+1.24}_{-0.69})\\times 10^{-4}$, which show good\nagreement with BaBar and Belle Collaborations. Finally, we extract the\n$|V_{ub}|$ by using the $\\mathcal{B}(B^+\\to \\omega\\ell^+\\nu)$ result from BaBar\nCollaboration, which leads to $|V_{ub}|=(3.66^{+1.38}_{-1.12})\\times 10^{-3}$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T03:54:28Z"}
{"aid":"http://arxiv.org/abs/2504.05652v1","title":"Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking","summary":"Large Language Models (LLMs) have become increasingly integral to a wide\nrange of applications. However, they still remain the threat of jailbreak\nattacks, where attackers manipulate designed prompts to make the models elicit\nmalicious outputs. Analyzing jailbreak methods can help us delve into the\nweakness of LLMs and improve it. In this paper, We reveal a vulnerability in\nlarge language models (LLMs), which we term Defense Threshold Decay (DTD), by\nanalyzing the attention weights of the model's output on input and subsequent\noutput on prior output: as the model generates substantial benign content, its\nattention weights shift from the input to prior output, making it more\nsusceptible to jailbreak attacks. To demonstrate the exploitability of DTD, we\npropose a novel jailbreak attack method, Sugar-Coated Poison (SCP), which\ninduces the model to generate substantial benign content through benign input\nand adversarial reasoning, subsequently producing malicious content. To\nmitigate such attacks, we introduce a simple yet effective defense strategy,\nPOSD, which significantly reduces jailbreak success rates while preserving the\nmodel's generalization capabilities.","main_category":"cs.CR","categories":"cs.CR,cs.CL","published":"2025-04-08T03:57:09Z"}
{"aid":"http://arxiv.org/abs/2504.05653v1","title":"How communities shape epidemic spreading: A hierarchically structured\n  metapopulation perspective","summary":"Recent outbreaks of COVID-19, Zika, Ebola, and influenza have renewed\ninterest in advancing epidemic models to better reflect the complexities of\ndisease spreading. Modern approaches incorporate social norms, mobility\npatterns, and heterogeneous community structures to capture the interplay\nbetween social and biological dynamics. This study examines epidemic\npropagation in hierarchically structured metapopulation networks, where\nindividuals interact within localized communities -- such as schools,\nworkplaces, and theaters -- and diffuse across them. Using mean-field\naveraging, we derive a scaling law linking contagion rates to the mean\nconnectivity degree, while stability analysis identifies thresholds for\ninfection surges. In networks with heterogeneous mean degrees, spectral\nperturbation theory reveals how structural variability accelerates and\namplifies disease spreading. We find that nodes with above-average degrees are\nnot only infected earlier but also act as key outbreak drivers. Framing\nepidemic dynamics as a continuous phase transition, we apply pattern formation\ntheory to show that the critical eigenvectors governing system stability are\nshaped by the network's degree distribution. Crucially, by analyzing Laplacian\neigenvector localization, we uncover a one-to-one correspondence between\ncommunity infection densities and the entries of the critical eigenvector --\nrevealing how internal community structure directly shapes global infection\npatterns. This work provides a systematic framework for understanding and\npredicting epidemic dynamics in structured populations, while highlighting the\nfundamental role of community organization.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO","published":"2025-04-08T04:02:06Z"}
{"aid":"http://arxiv.org/abs/2504.05655v1","title":"Multi-bubble solutions for the Dirichlet problem of the $H$-system with\n  higher degree","summary":"We consider a Dirichlet problem of the $H$-system \\begin{equation*}\n\\begin{cases} \\Delta v = 2v_x\\wedge v_y ~& \\text{ in }\\mathcal{D},\\\\\nv=\\varepsilon \\tilde g ~& \\text{ on }\\partial{\\mathcal{D}}, \\end{cases}\n\\end{equation*} where $\\mathcal D\\subset \\mathbb{R}^2$ is the unit disk,\n$v:\\mathcal D\\to \\mathbb{R}^3$, and $\\tilde g:\\partial \\mathcal D\\to\n\\mathbb{R}^3$ is a given smooth map. As $\\varepsilon\\to 0^+$, we construct\nmulti-bubble solutions concentrating at distinct points, taking around each\npoint the profile of degree 2 $H$-bubble. This gives a partial answer to a\nconjecture due to Brezis-Coron \\cite{BrezisCoron} and Chanillo-Malchiodi\n\\cite{chanillomalchiodi2005cagasymptotic} concerning the limiting configuration\nin the case of higher degrees. This seems to be the first construction in\nemploying higher-degree harmonic maps as the primary configurations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T04:05:53Z"}
{"aid":"http://arxiv.org/abs/2504.05669v1","title":"xMTF: A Formula-Free Model for Reinforcement-Learning-Based Multi-Task\n  Fusion in Recommender Systems","summary":"Recommender systems need to optimize various types of user feedback, e.g.,\nclicks, likes, and shares. A typical recommender system handling multiple types\nof feedback has two components: a multi-task learning (MTL) module, predicting\nfeedback such as click-through rate and like rate; and a multi-task fusion\n(MTF) module, integrating these predictions into a single score for item\nranking. MTF is essential for ensuring user satisfaction, as it directly\ninfluences recommendation outcomes. Recently, reinforcement learning (RL) has\nbeen applied to MTF tasks to improve long-term user satisfaction. However,\nexisting RL-based MTF methods are formula-based methods, which only adjust\nlimited coefficients within pre-defined formulas. The pre-defined formulas\nrestrict the RL search space and become a bottleneck for MTF. To overcome this,\nwe propose a formula-free MTF framework. We demonstrate that any suitable\nfusion function can be expressed as a composition of single-variable monotonic\nfunctions, as per the Sprecher Representation Theorem. Leveraging this, we\nintroduce a novel learnable monotonic fusion cell (MFC) to replace pre-defined\nformulas. We call this new MFC-based model eXtreme MTF (xMTF). Furthermore, we\nemploy a two-stage hybrid (TSH) learning strategy to train xMTF effectively. By\nexpanding the MTF search space, xMTF outperforms existing methods in extensive\noffline and online experiments.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T04:28:22Z"}
{"aid":"http://arxiv.org/abs/2504.05676v1","title":"Interfacial Heat Transport via Evanescent Radiation by Hot Electrons","summary":"We predict an additional thermal transport pathway across metal/non-metal\ninterfaces with large electron-phonon non-equilibrium via evanescent radiative\nheat transfer. In such systems, electron scattering processes vary drastically\nand can be leveraged to guide heat across interfaces via radiative heat\ntransport without engaging the lattice directly. We employ the formalism of\nfluctuational electrodynamics to simulate the spectral radiative heat flux\nacross the interface of a metal film and a non-metal substrate. We find that\nthe radiative conductance can exceed 300 MW m$^{-2}$ K$^{-1}$ at an electron\ntemperature of 5000 K for an emitting tungsten film on a hexagonal boron\nnitride substrate, becoming comparable to its conductive counterpart. This\nallows for a more holistic approach to the heat flow across interfaces,\naccounting for electron-phonon non-equilibrium and ultrafast near-field\nphonon-polariton coupling.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.comp-ph","published":"2025-04-08T04:36:29Z"}
{"aid":"http://arxiv.org/abs/2504.05681v1","title":"Covariance-Intersection-based Distributed Kalman Filtering: Stability\n  Problems Revisited","summary":"This paper studies the stability of covariance-intersection (CI)-based\ndistributed Kalman filtering in time-varying systems. For the general\ntime-varying case, a relationship between the error covariance and the\nobservability Gramian is established. Utilizing this relationship, we\ndemonstrate an intuition that the stability of a node is only related to the\nobservability of those nodes that can reach it uniformly. For the periodic\ntime-varying case, it is proved by a monotonicity analysis method that CI-based\ndistributed Kalman filtering converges periodically for any initial condition.\nThe convergent point is shown to be the unique positive definite solution to a\nRiccati-like equation. Additionally, by constructing an intermediate difference\nequation, the closed-loop transition matrix of the estimation error system is\nproved to be Schur stable. Notably, all theoretical results are obtained\nwithout requiring network connectivity assumptions. Finally, simulations verify\nthe effectiveness of the stability results.","main_category":"eess.SY","categories":"eess.SY,cs.SY,B.4","published":"2025-04-08T04:44:50Z"}
{"aid":"http://arxiv.org/abs/2504.05691v1","title":"StayLTC: A Cost-Effective Multimodal Framework for Hospital Length of\n  Stay Forecasting","summary":"Accurate prediction of Length of Stay (LOS) in hospitals is crucial for\nimproving healthcare services, resource management, and cost efficiency. This\npaper presents StayLTC, a multimodal deep learning framework developed to\nforecast real-time hospital LOS using Liquid Time-Constant Networks (LTCs).\nLTCs, with their continuous-time recurrent dynamics, are evaluated against\ntraditional models using structured data from Electronic Health Records (EHRs)\nand clinical notes. Our evaluation, conducted on the MIMIC-III dataset,\ndemonstrated that LTCs significantly outperform most of the other time series\nmodels, offering enhanced accuracy, robustness, and efficiency in resource\nutilization. Additionally, LTCs demonstrate a comparable performance in LOS\nprediction compared to time series large language models, while requiring\nsignificantly less computational power and memory, underscoring their potential\nto advance Natural Language Processing (NLP) tasks in healthcare.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T05:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.05693v1","title":"STRIVE: A Think & Improve Approach with Iterative Refinement for\n  Enhancing Question Quality Estimation","summary":"Automatically assessing question quality is crucial for educators as it saves\ntime, ensures consistency, and provides immediate feedback for refining\nteaching materials. We propose a novel methodology called STRIVE (Structured\nThinking and Refinement with multiLLMs for Improving Verified Question\nEstimation) using a series of Large Language Models (LLMs) for automatic\nquestion evaluation. This approach aims to improve the accuracy and depth of\nquestion quality assessment, ultimately supporting diverse learners and\nenhancing educational practices. The method estimates question quality in an\nautomated manner by generating multiple evaluations based on the strengths and\nweaknesses of the provided question and then choosing the best solution\ngenerated by the LLM. Then the process is improved by iterative review and\nresponse with another LLM until the evaluation metric values converge. This\nsophisticated method of evaluating question quality improves the estimation of\nquestion quality by automating the task of question quality evaluation.\nCorrelation scores show that using this proposed method helps to improve\ncorrelation with human judgments compared to the baseline method. Error\nanalysis shows that metrics like relevance and appropriateness improve\nsignificantly relative to human judgments by using STRIVE.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T05:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.05700v1","title":"Pose-Aware Weakly-Supervised Action Segmentation","summary":"Understanding human behavior is an important problem in the pursuit of visual\nintelligence. A challenge in this endeavor is the extensive and costly effort\nrequired to accurately label action segments. To address this issue, we\nconsider learning methods that demand minimal supervision for segmentation of\nhuman actions in long instructional videos. Specifically, we introduce a\nweakly-supervised framework that uniquely incorporates pose knowledge during\ntraining while omitting its use during inference, thereby distilling pose\nknowledge pertinent to each action component. We propose a pose-inspired\ncontrastive loss as a part of the whole weakly-supervised framework which is\ntrained to distinguish action boundaries more effectively. Our approach,\nvalidated through extensive experiments on representative datasets, outperforms\nprevious state-of-the-art (SOTA) in segmenting long instructional videos under\nboth online and offline settings. Additionally, we demonstrate the framework's\nadaptability to various segmentation backbones and pose extractors across\ndifferent datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T05:42:55Z"}
{"aid":"http://arxiv.org/abs/2504.05703v1","title":"Natural Theories","summary":"We consider the class of physical theories whose dynamics are given by\nnatural equations, which are partial differential equations determined by a\nfunctor from the category of n-manifolds, for some n, to the category of fiber\nbundles, satisfying certain further conditions. We show how the theory of\nnatural equations clarifies several important foundational issues, including\nthe status and meaning of minimal coupling, symmetries of theories, and\nbackground structure. We also state and prove a fundamental result about the\ninitial value problem for natural equations.","main_category":"physics.hist-ph","categories":"physics.hist-ph,gr-qc,math-ph,math.MP","published":"2025-04-08T05:56:17Z"}
{"aid":"http://arxiv.org/abs/2504.05709v1","title":"Some aspects of generalized Dunkl-Williams constant in Banach spaces","summary":"This article delves into an exploration of two innovative constants, namely\nDW(X,{\\alpha},\\b{eta}) and DWB (X,{\\alpha},\\b{eta}), both of which constitute\nextensions of the Dunkl-Williams constant. We derive both the upper and lower\nbounds for these two constants and establish two equivalent relations between\nthem. Moreover, we elucidate the relationships between these constants and\nseveral well-known constants. Additionally, we have refined the value of the\nDWB (X,{\\alpha},\\b{eta}) constant in certain specific Banach spaces.","main_category":"math.FA","categories":"math.FA,F.2.2","published":"2025-04-08T06:06:23Z"}
{"aid":"http://arxiv.org/abs/2504.05725v1","title":"Synthesis, crystal and electronic structures, and second harmonic\n  generation of La 4Ge 3S12","summary":"The crystal structure of La 4 Ge 3S 12 has been known to be\nnoncentrosymmetric for almost four decades. This characteristic inversion\nsymmetry breaking suggests the presence of nonlinear optical properties. Yet\nonly recently have nonlinear optical phenomena such as second harmonic\ngeneration (SHG) been reported in this material. In this study, we synthesized\nLa4Ge3S12 using the direct reaction method and characterized the composition,\ncrystal structure, and electronic structure using electron probe microanalysis,\npowder and single-crystal X-ray diffraction, and X-ray photoelectron\nspectroscopy. The experimentally measured electronic structure is in line with\nthat obtained using first-principles calculations. In addition, we observed the\nnonlinear optical properties of La4Ge3S12 in response to an ultrashort infrared\npulsed laser. We found that the intensity of the SHG depends quadratically on\nthe intensity of the incident light, mirroring the intrinsic nature of\nnonlinear optics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T06:54:48Z"}
{"aid":"http://arxiv.org/abs/2504.05726v1","title":"Signal and Backward Raman Pump Power Optimization in Multi-Band Systems\n  Using Fast Power Profile Estimation","summary":"This paper presents an efficient numerical method for calculating spatial\npower profiles of both signal and pump with significant Interchannel Stimulated\nRaman Scattering (ISRS) and backward Raman amplification in multiband systems.\nThis method was evaluated in the optimization of a C+L+S/C+L+S+E 1000km link,\nemploying three backward Raman pumps, by means of a closed-form EGN model\n(CFM6). The results show a 100x computational speed increase, enabling deep\noptimization which made it possible to obtain very good overall system\nperformance and flat GSNR.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T06:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.05741v1","title":"DDT: Decoupled Diffusion Transformer","summary":"Diffusion transformers have demonstrated remarkable generation quality,\nalbeit requiring longer training iterations and numerous inference steps. In\neach denoising step, diffusion transformers encode the noisy inputs to extract\nthe lower-frequency semantic component and then decode the higher frequency\nwith identical modules. This scheme creates an inherent optimization dilemma:\nencoding low-frequency semantics necessitates reducing high-frequency\ncomponents, creating tension between semantic encoding and high-frequency\ndecoding. To resolve this challenge, we propose a new\n\\textbf{\\color{ddt}D}ecoupled \\textbf{\\color{ddt}D}iffusion\n\\textbf{\\color{ddt}T}ransformer~(\\textbf{\\color{ddt}DDT}), with a decoupled\ndesign of a dedicated condition encoder for semantic extraction alongside a\nspecialized velocity decoder. Our experiments reveal that a more substantial\nencoder yields performance improvements as model size increases. For ImageNet\n$256\\times256$, Our DDT-XL/2 achieves a new state-of-the-art performance of\n{1.31 FID}~(nearly $4\\times$ faster training convergence compared to previous\ndiffusion transformers). For ImageNet $512\\times512$, Our DDT-XL/2 achieves a\nnew state-of-the-art FID of 1.28. Additionally, as a beneficial by-product, our\ndecoupled architecture enhances inference speed by enabling the sharing\nself-condition between adjacent denoising steps. To minimize performance\ndegradation, we propose a novel statistical dynamic programming approach to\nidentify optimal sharing strategies.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T07:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.05749v1","title":"Limitations of the $g$-tensor formalism of semiconductor spin qubits","summary":"The $g$-tensor formalism is a powerful method for describing the electrical\ndriving of semiconductor spin qubits. However, up to now, this technique has\nonly been applied to the simplest qubit dynamics, resonant monochromatic\ndriving by a single gate. Here we study the description of (i) monochromatic\ndriving using two driving gates and bichromatic driving via (ii) one or (iii)\ntwo gates. Assuming a general Hamiltonian with qubit states well separated from\nexcited orbital states, we find that when (i) two driving gates are used for\nmonochromatic driving or (ii) a single one for bichromatic, the $g$-tensor\nformalism successfully captures the leading-order dynamics. We express the Rabi\nfrequency and the Bloch-Siegert shift using the $g$-tensor and its first and\nsecond derivatives with respect to the gate voltage. However, when (iii)\nbichromatic driving is realized using two distinct driving gates, we see a\nbreakdown of $g$-tensor formalism: the Rabi frequency cannot be expressed using\nthe $g$-tensor and its derivatives. We find that beyond the $g$-tensor and its\nderivatives, three additional parameters are needed to capture the dynamics. We\ndemonstrate our general results by assuming an electron (hole) confined in a\ncircular quantum dot, subjected to Rashba spin-orbit interaction.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-08T07:25:13Z"}
{"aid":"http://arxiv.org/abs/2504.05750v1","title":"Radiative Backpropagation with Non-Static Geometry","summary":"One of the core working principles of Radiative Backpropagation (RB) is that\ndifferential radiance is transported like normal radiance. This report shows\nthat this is only true if scene geometry is static. We suggest that static\ngeometry is an implicit assumption in the current theory, leading to biased\ngradients in implementations based on detached sampling, and demonstrate this\nwith simple examples. We derive the general derivatives for non-static\ngeometry: the RB-based derivatives with detached sampling are obtained either\nby an algorithm similar to attached path replay backpropagation or by a\nconstruction that reparameterizes the rendering integral over surfaces.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-08T07:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.05751v1","title":"InvNeRF-Seg: Fine-Tuning a Pre-Trained NeRF for 3D Object Segmentation","summary":"Neural Radiance Fields (NeRF) have been widely adopted for reconstructing\nhigh quality 3D point clouds from 2D RGB images. However, the segmentation of\nthese reconstructed 3D scenes is more essential for downstream tasks such as\nobject counting, size estimation, and scene understanding. While segmentation\non raw 3D point clouds using deep learning requires labor intensive and\ntime-consuming manual annotation, directly training NeRF on binary masks also\nfails due to the absence of color and shading cues essential for geometry\nlearning. We propose Invariant NeRF for Segmentation (InvNeRFSeg), a two step,\nzero change fine tuning strategy for 3D segmentation. We first train a standard\nNeRF on RGB images and then fine tune it using 2D segmentation masks without\naltering either the model architecture or loss function. This approach produces\nhigher quality, cleaner segmented point clouds directly from the refined\nradiance field with minimal computational overhead or complexity. Field density\nanalysis reveals consistent semantic refinement: densities of object regions\nincrease while background densities are suppressed, ensuring clean and\ninterpretable segmentations. We demonstrate InvNeRFSegs superior performance\nover both SA3D and FruitNeRF on both synthetic fruit and real world soybean\ndatasets. This approach effectively extends 2D segmentation to high quality 3D\nsegmentation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T07:31:01Z"}
{"aid":"http://arxiv.org/abs/2504.05752v1","title":"Complete and robust population transfer between the two ground states of\n  a three-state loop quantum system by amplitude composite pulse control","summary":"This work presents a method for achieving complete, robust, and efficient\npopulation transfer between the two ground states in a three-level loop quantum\nsystem. The approach utilizes composite pulse sequences by effectively mapping\nthe three-state system onto an equivalent two-level system. This transformation\nallows the use of broadband composite pulses designed initially for\nconventional two-state quantum systems. Unlike traditional implementations, the\ncomposite pulses in the three-level system are not controlled through phase\nadjustments; instead, they are realized via the amplitude ratio of the Rabi\nfrequencies.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T07:32:00Z"}
{"aid":"http://arxiv.org/abs/2504.05791v1","title":"Illusion Spaces in VR: The Interplay Between Size and Taper Angle\n  Perception in Grasping","summary":"Leveraging the integration of visual and proprioceptive cues, research has\nuncovered various perception thresholds in VR that can be exploited to support\nhaptic feedback for grasping. While previous studies have explored individual\ndimensions, such as size, the combined effect of multiple geometric properties\non perceptual illusions remains poorly understood. We present a two-alternative\nforced choice study investigating the perceptual interplay between object size\nand taper angle. We introduce an illusion space model, providing detailed\ninsights into how physical and virtual object configurations affect human\nperception. Our insights reveal how, for example, as virtual sizes increase,\nusers perceive that taper angles increase, and as virtual angles decrease,\nusers overestimate sizes. We provide a mathematical model of the illusion\nspace, and an associated tool, which can be used as a guide for the design of\nfuture VR haptic devices and for proxy object selections.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T08:19:56Z"}
{"aid":"http://arxiv.org/abs/2504.05812v1","title":"Right Question is Already Half the Answer: Fully Unsupervised LLM\n  Reasoning Incentivization","summary":"While large language models (LLMs) have demonstrated exceptional capabilities\nin challenging tasks such as mathematical reasoning, existing methods to\nenhance reasoning ability predominantly rely on supervised fine-tuning (SFT)\nfollowed by reinforcement learning (RL) on reasoning-specific data after\npre-training. However, these approaches critically depend on external\nsupervisions--such as human labelled reasoning traces, verified golden answers,\nor pre-trained reward models--which limits scalability and practical\napplicability. In this work, we propose Entropy Minimized Policy Optimization\n(EMPO), which makes an early attempt at fully unsupervised LLM reasoning\nincentivization. EMPO does not require any supervised information for\nincentivizing reasoning capabilities (i.e., neither verifiable reasoning\ntraces, problems with golden answers, nor additional pre-trained reward\nmodels). By continuously minimizing the predictive entropy of LLMs on unlabeled\nuser queries in a latent semantic space, EMPO enables purely self-supervised\nevolution of reasoning capabilities with strong flexibility and practicality.\nOur experiments demonstrate competitive performance of EMPO on both\nmathematical reasoning and free-form commonsense reasoning tasks. Specifically,\nwithout any supervised signals, EMPO boosts the accuracy of Qwen2.5-Math-7B\nBase from 30.7\\% to 48.1\\% on mathematical benchmarks and improves truthfulness\naccuracy of Qwen2.5-7B Instruct from 87.16\\% to 97.25\\% on TruthfulQA.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T08:48:51Z"}
{"aid":"http://arxiv.org/abs/2504.05813v1","title":"A new approach for simulating PBH formation from generic curvature\n  fluctuations with the Misner-Sharp formalism","summary":"Primordial Black Holes (PBHs) may have formed in the early Universe due to\nthe collapse of super-horizon curvature fluctuations. Simulations of PBH\nformation have been essential for inferring the initial conditions that lead to\nblack hole formation and for studying their properties and impact on our\nUniverse. The Misner-Sharp formalism is commonly used as a standard approach\nfor these simulations. Recently, type-II fluctuations, characterized by a\nnon-monotonic areal radius, have gained interest. In the standard Misner-Sharp\napproach for simulating PBH formation with these fluctuations, the evolution\nequations suffer from divergent terms (0/0), which complicate and prevent the\nsimulations. We formulate a new approach to overcome this issue in a simple\nmanner by using the trace of the extrinsic curvature as an auxiliary variable,\nallowing simulations of type-II fluctuations within the Misner-Sharp formalism.\nUsing a set of standard exponential-shaped curvature profiles, we apply our new\napproach and numerical code based on pseudospectral methods to study the time\nevolution of the gravitational collapse, threshold values of type A/B PBHs and\nPBH mass. Interestingly, we identify cases of type-II fluctuations that do not\nnecessarily result in PBH formation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T08:53:38Z"}
{"aid":"http://arxiv.org/abs/2504.05814v1","title":"The threshold for PBH formation in the type-II region and its analytical\n  estimation","summary":"We numerically simulate the formation of Primordial Black Holes (PBHs) in a\nradiation-dominated Universe under the assumption of spherical symmetry, driven\nby the collapse of adiabatic fluctuations, for different curvature profiles\n$\\zeta$. Our results show that the threshold for PBH formation, defined as the\npeak value of the critical compaction function $\\mathcal{C}_{c}(r_m)$ (where\n$r_m$ is the scale at which the peak occurs), does not asymptotically saturate\nto its maximum possible value in the type-I region for sufficiently sharp\nprofiles. Instead, the threshold is found in the type-II region with\n$\\mathcal{C}_{c}(r_m)$ being a minimum. We find, for the cases tested, that\nthis is a general trend associated with profiles that exhibit extremely large\ncurvatures in the linear component of the compaction function\n$\\mathcal{C}_{l}(r) \\equiv -4r \\zeta'(r)/3$ shape around its peak $r_m$ (spiky\nshapes). To measure this curvature at $r_m$, we define a dimensionless\nparameter: $\\kappa \\equiv -r^{2}_m \\mathcal{C}_l''(r_m)$, and we find that the\nthresholds observed in the type-II region occur for $\\kappa \\gtrsim 30$ for the\nprofiles we have used. By defining the threshold in terms of\n$\\mathcal{C}_{l,c}(r_m)$, we extend previous analytical estimations to the\ntype-II region, which is shown to be accurate within a few percent when\ncompared to the numerical simulations for the tested profiles. Our results\nsuggest that current PBH abundance calculations for models where the threshold\nlies in the type-II region may have been overestimated due to the general\nassumption that it should saturate at the boundary between the type-I and\ntype-II regions.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T08:53:42Z"}
{"aid":"http://arxiv.org/abs/2504.05816v1","title":"Solitons of the constrained SchrÃ¶dinger equations","summary":"We consider the linear vector Schr\\\"odinger equation subjected to quadratic\nconstraints. We demonstrate that the resulting nonlinear system is closely\nrelated to the Ablowitz-Ladik hierarchy and use this fact to derive the\nN-soliton solutions for the discussed model.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP","published":"2025-04-08T08:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.05823v1","title":"New cosystolic high-dimensional expanders from KMS groups","summary":"Cosystolic expansion is a high-dimensional generalization of the Cheeger\nconstant for simplicial complexes. Originally, this notion was motivated by the\nfact that it implies the topological overlapping property, but more recently it\nwas shown to be connected to problems in theoretical computer science such as\nlist agreement expansion and agreement expansion in the low soundness regime.\n  There are only a few constructions of high-dimensional cosystolic expanders\nand, in dimension larger than $2$, the only known constructions prior to our\nwork were (co-dimension 1)-skeletons of quotients of affine buildings. In this\npaper, we give the first coset complex construction of cosystolic expanders for\nan arbitrary dimension. Our construction is more symmetric and arguably more\nelementary than the previous constructions relying on quotients of affine\nbuildings.\n  The coset complexes we consider arise from finite quotients of\nKac--Moody--Steinberg (KMS) groups and are known as KMS complexes. KMS\ncomplexes were introduced in recent work by Grave de Peralta and\nValentiner-Branth where it was shown that they are local-spectral expanders.\nOur result is that KMS complexes, satisfying some minor condition, give rise to\ninfinite families of bounded degree cosystolic expanders of arbitrary dimension\nand for any finitely generated Abelian coefficient group.\n  This result is achieved by observing that proper links of KMS complexes are\njoins of opposition complexes in spherical buildings. In order to show that\nthese opposition complexes are coboundary expanders, we develop a new method\nfor constructing cone functions by iteratively adding sets of vertices. Hence\nwe show that the links of KMS complexes are coboundary expanders. Using the\nprior local-to-global results, we obtain cosystolic expansion for the\n(co-dimension 1)-skeletons of the KMS complexes.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-08T09:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.05824v1","title":"End-to-End Dialog Neural Coreference Resolution: Balancing Efficiency\n  and Accuracy in Large-Scale Systems","summary":"Large-scale coreference resolution presents a significant challenge in\nnatural language processing, necessitating a balance between efficiency and\naccuracy. In response to this challenge, we introduce an End-to-End Neural\nCoreference Resolution system tailored for large-scale applications. Our system\nefficiently identifies and resolves coreference links in text, ensuring minimal\ncomputational overhead without compromising on performance. By utilizing\nadvanced neural network architectures, we incorporate various contextual\nembeddings and attention mechanisms, which enhance the quality of predictions\nfor coreference pairs. Furthermore, we apply optimization strategies to\naccelerate processing speeds, making the system suitable for real-world\ndeployment. Extensive evaluations conducted on benchmark datasets demonstrate\nthat our model achieves improved accuracy compared to existing approaches,\nwhile effectively maintaining rapid inference times. Rigorous testing confirms\nthe ability of our system to deliver precise coreference resolutions\nefficiently, thereby establishing a benchmark for future advancements in this\nfield.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T09:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.05825v1","title":"Spin Dynamics in Rotating Quantum Plasmas: Coupled EPI Dispersion and\n  Solitary wave analysis","summary":"The propagation of an electrostatic wave in a three-component e-p-I\nastrophysical quantum plasma in a rotating frame has been studied, taking into\naccount the particle spin, Fermi pressure, and quantum Bohm potential. Spin\npolarization plays a key role in explaining the dynamics of quantum plasmas,\nespecially in astrophysical contexts due to the high external magnetic field\nprevalent in such environments. Effects specific to this particular\nenvironment, like rotation as well as gravity, have also been included. Coupled\ndispersion of electron, positron, and ion modes has been obtained. Further, the\ninvestigation of solitary waves by the Korteweg de Vries method has been\ncarried out, and a soliton solution has been obtained. Quantum effects increase\nwave dispersion and soliton stability in quantum plasma, thereby affecting the\nelectrostatic potential.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-08T09:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.05840v1","title":"Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed\n  RL Environments","summary":"Traditional Reinforcement Learning (RL) algorithms assume the distribution of\nthe data to be uniform or mostly uniform. However, this is not the case with\nmost real-world applications like autonomous driving or in nature where animals\nroam. Some experiences are encountered frequently, and most of the remaining\nexperiences occur rarely; the resulting distribution is called Zipfian. Taking\ninspiration from the theory of complementary learning systems, an architecture\nfor learning from Zipfian distributions is proposed where important long tail\ntrajectories are discovered in an unsupervised manner. The proposal comprises\nan episodic memory buffer containing a prioritised memory module to ensure\nimportant rare trajectories are kept longer to address the Zipfian problem,\nwhich needs credit assignment to happen in a sample efficient manner. The\nexperiences are then reinstated from episodic memory and given weighted\nimportance forming the trajectory to be executed. Notably, the proposed\narchitecture is modular, can be incorporated in any RL architecture and yields\nimproved performance in multiple Zipfian tasks over traditional architectures.\nOur method outperforms IMPALA by a significant margin on all three tasks and\nall three evaluation metrics (Zipfian, Uniform, and Rare Accuracy) and also\ngives improvements on most Atari environments that are considered challenging","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T09:21:39Z"}
{"aid":"http://arxiv.org/abs/2504.05843v1","title":"The off-shell one- and two-loop box recovered from intersection theory","summary":"We advertise intersection theory for generalised hypergeometric functions as\na means of evaluating Mellin-Barnes representations. As an example, we study\ntwo-parameter representations of the off-shell one- and two-loop box graphs in\nexactly four-dimensional configuration space. Closing the integration contours\nfor the MB parameters we transform these into double sums. Polygamma functions\nin the MB representation of the double box and the occurrence of higher poles\nare taken into account by parametric differentiation. Summing over any one of\nthe counters results into a $_{p+1}F_p$ that we replace by its Euler integral\nrepresentation. The process can be repeated a second time and results in a two-\nor four-parameter Euler integral, respectively. We use intersection theory to\nderive Pfaffian systems of equations on related sets of master integrals and\nsolve for the box and double box integrals reproducing the known expressions.\nFinally, we use a trick to re-derive the double box from a two-parameter Euler\nintegral. This second computation requires only very little computing\nresources.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T09:22:28Z"}
{"aid":"http://arxiv.org/abs/2504.05849v1","title":"On the Importance of Conditioning for Privacy-Preserving Data\n  Augmentation","summary":"Latent diffusion models can be used as a powerful augmentation method to\nartificially extend datasets for enhanced training. To the human eye, these\naugmented images look very different to the originals. Previous work has\nsuggested to use this data augmentation technique for data anonymization.\nHowever, we show that latent diffusion models that are conditioned on features\nlike depth maps or edges to guide the diffusion process are not suitable as a\nprivacy preserving method. We use a contrastive learning approach to train a\nmodel that can correctly identify people out of a pool of candidates. Moreover,\nwe demonstrate that anonymization using conditioned diffusion models is\nsusceptible to black box attacks. We attribute the success of the described\nmethods to the conditioning of the latent diffusion model in the anonymization\nprocess. The diffusion model is instructed to produce similar edges for the\nanonymized images. Hence, a model can learn to recognize these patterns for\nidentification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T09:27:51Z"}
{"aid":"http://arxiv.org/abs/2504.05876v1","title":"Topological ignition of the stealth coronal mass ejections","summary":"One of hot topics in the solar physics are the so-called 'stealth' coronal\nmass ejections (CME), which are not associated with any appreciable energy\nrelease events in the lower corona, such as the solar flares. It is sometimes\nassumed that these phenomena might be produced by some specific physical\nmechanism, but no particular suggestions were put forward. It is the aim of the\npresent paper to show that a promising explanation of the stealth CMEs can be\nbased on the so-called 'topological' ignition of the magnetic reconnection. As\na theoretical basis, we employ the Gorbachev-Kel'ner-Somov-Shvarts (GKSS) model\nof formation of the magnetic null point, which is produced by a specific\nsuperposition of the remote sources (sunspots) rather than by the local current\nsystems. As follows from our numerical simulations, the topological model\nexplains very well all basic features of the stealth CMEs: (i) the plasma\neruption develops without an appreciable heat release from the spot of\nreconnection, i.e., without the solar flare; (ii) the spot of reconnection\n(magnetic null point) can be formed far away from the location of the magnetic\nfield sources; (iii) the trajectories of eruption are strongly curved, which\ncan explain observability of CMEs generated behind the solar limb. Therefore,\nthe topological ignition of magnetic reconnection should be interesting both by\nitself, as a novel physical phenomenon, and as a prognostic tool for\nforecasting the stealth CMEs and the resulting unexpected geomagnetic storms.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-08T10:04:57Z"}
{"aid":"http://arxiv.org/abs/2504.05880v1","title":"Some structure theorems for Weingarten surfaces","summary":"Let $M\\subset\\mathbb{R}^3$ be a properly embedded, connected, complete\nsurface with boundary a convex planar curve $C$, satisfying an elliptic\nequation $H=f(H^2-K)$, where $H$ and $K$ are the mean and the Gauss curvature\nrespectively - which we will refer to as Weingarten equation. When $M$ is\ncontained in one of the two halfspaces determined by $C$, we give sufficient\nconditions for $M$ to inherit the symmetries of $C$. In particular, when $M$ is\nvertically cylindrically bounded, we get that $M$ is rotational if $C$ is a\ncircle. In the case in which the Weingarten equation is linear, we give a\nsufficient condition for such a surface to be contained in a halfspace. Both\nresults are generalizations of results of Rosenberg and Sa Earp, for constant\nmean curvature surfaces, to the Weingarten setting. In particular, our results\nalso recover and generalize the constant mean curvature case.","main_category":"math.DG","categories":"math.DG","published":"2025-04-08T10:09:24Z"}
{"aid":"http://arxiv.org/abs/2504.05882v1","title":"Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban\n  LiDAR Segmentation with Semi-Supervised Techniques","summary":"3D semantic segmentation plays a critical role in urban modelling, enabling\ndetailed understanding and mapping of city environments. In this paper, we\nintroduce Turin3D: a new aerial LiDAR dataset for point cloud semantic\nsegmentation covering an area of around 1.43 km2 in the city centre of Turin\nwith almost 70M points. We describe the data collection process and compare\nTurin3D with others previously proposed in the literature. We did not fully\nannotate the dataset due to the complexity and time-consuming nature of the\nprocess; however, a manual annotation process was performed on the validation\nand test sets, to enable a reliable evaluation of the proposed techniques. We\nfirst benchmark the performances of several point cloud semantic segmentation\nmodels, trained on the existing datasets, when tested on Turin3D, and then\nimprove their performances by applying a semi-supervised learning technique\nleveraging the unlabelled training set. The dataset will be publicly available\nto support research in outdoor point cloud segmentation, with particular\nrelevance for self-supervised and semi-supervised learning approaches given the\nabsence of ground truth annotations for the training set.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T10:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.05889v1","title":"Comparative Investigation of MAPbBr$_x$I$_{1-x}$ and\n  SbH$_4$Br$_x$I$_{1-x}$ Perovskites: Electronic and Structural Properties","summary":"This paper comparatively investigates the structural and electronic\nproperties of hybrid perovskites MAPbBr$_x$I$_{1-x}$ and\nSbH$_4$PbBr$_x$I$_{1-x}$ by means of DFT-based calculations. The main aim is to\ncheck if the increase in band gap due to substitution of I$^-$ ions with Br$^-$\nions can be overcome by introducing the inorganic SbH$_4^+$ cation. Since the\nBr$^-$ ions merely enhance structural stability of the perovskite framework and\nSbH$_4^+$ not only sustains that stability but also reduces the band gap to\nnearly ideal values and thereby improves electronic performance, these are the\nleading candidates among them. Of them, the reduced band gap SbH$_4$PbI$_3$\n($\\sim$1.37 eV) and the perfectly matched SbH$_4$PbBrI$_2$ with its band gap\nbeing exactly 1.51 eV are top prospects for being stable and having\nhigh-efficiency solar cell applications. The findings show that SbH$_4^+$-based\nperovskites have potential for future photovoltaic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-08T10:31:06Z"}
{"aid":"http://arxiv.org/abs/2504.05890v1","title":"Large central values of Dirichlet L-functions in cosets","summary":"In this paper we consider the distribution of large central values of\nDirichlet L-functions over cosets of the group of characters modulo q via\nSoundararajan's resonator method.","main_category":"math.NT","categories":"math.NT","published":"2025-04-08T10:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.05894v1","title":"Why do zeroes happen? A model-based approach for demand classification","summary":"Effective demand forecasting is critical for inventory management, production\nplanning, and decision making across industries. Selecting the appropriate\nmodel and suitable features to efficiently capture patterns in the data is one\nof the main challenges in demand forecasting. In reality, this becomes even\nmore complicated when the recorded sales have zeroes, which can happen\nnaturally or due to some anomalies, such as stockouts and recording errors.\nMistreating the zeroes can lead to the application of inappropriate forecasting\nmethods, and thus leading to poor decision making. Furthermore, the demand\nitself can have different fundamental characteristics, and being able to\ndistinguish one type from another might bring substantial benefits in terms of\naccuracy and thus decision making. We propose a two-stage model-based\nclassification framework that in the first step, identifies artificially\noccurring zeroes, and then classifies demand to one of the possible types:\nregular/intermittent, intermittent smooth/lumpy, fractional/count. The\nframework utilises statistical modelling and information criteria to detect\nanomalous zeroes and then classify demand into those categories. We then argue\nthat different types of demand need different features, and show empirically\nthat they tend to increase the accuracy of the forecasting methods compared to\nthose applied directly to the dataset without the generated features and the\ntwo-stage framework. Our general practical recommendation based on that is to\nuse the mixture approach for intermittent demand, capturing the demand sizes\nand demand probability separately, as it seems to improve the accuracy of\ndifferent forecasting approaches.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-08T10:45:30Z"}
{"aid":"http://arxiv.org/abs/2504.05905v1","title":"Rethinking Review Citations: Impact on Scientific Integrity","summary":"The proliferation of surveys and review articles in academic journals has\nimpacted citation metrics like impact factor and h-index, skewing evaluations\nof journal and researcher quality. This work investigates the implications of\nthis trend, focusing on the field of Computer Science, where a notable increase\nin review publications has led to inflated citation counts and rankings. While\nreviews serve as valuable literature overviews, they should not overshadow the\nprimary goal of research -to advance scientific knowledge through original\ncontributions. We advocate for prioritizing citations of primary research in\njournal articles to uphold citation integrity and ensure fair recognition of\nsubstantive contributions. This approach preserves the reliability of\ncitation-based metrics and supports genuine scientific advancement.","main_category":"cs.DL","categories":"cs.DL,cs.CY","published":"2025-04-08T11:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.05909v1","title":"Interpreting the Win Ratio in Hierarchical Composite Endpoints:\n  Challenges, Limitations, and Perspectives with Examples from Chronic Kidney\n  Disease Trials","summary":"Win statistics based methods have gained traction as a method for analyzing\nHierarchical Composite Endpoints (HCEs) in randomized clinical trials,\nparticularly in cardiovascular and kidney disease research. HCEs offer several\nkey advantages, including increased statistical power, the mitigation of\ncompeting risks, and hierarchical weighting of clinical importance for\ndifferent outcome components. While, as summary measures, the win ratio (WR)\nalong with the Net Benefit (NB) and the Win Odds (WO) provide a structured\napproach to analyzing HCEs, several concerns regarding their interpretability\nremain. In this paper, we explore critical aspects of WR interpretation that\nhave received limited attention. Specifically, we discuss the challenge of\ndefining an appropriate estimand in the context of HCEs using the WR, the\ndifficulties in formulating a relevant causal question underlying the WR, and\nthe dependency of the WR on the variance of its components, which complicates\nits role as an effect measure. Additionally, we highlight the\nnon-collapsibility of the WR, akin to hazard and odds ratios, further\ncomplicating its interpretation. While the WR remains a valuable tool in\nclinical trials, its inherent limitations must be acknowledged to ensure its\nappropriate application and interpretation in regulatory and clinical\ndecision-making.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T11:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.05916v1","title":"Multilevel Quantum Rabi Models","summary":"The quantum Rabi model, which describes the interaction between a simplified\natom and a mode of the electromagnetic field, is a cornerstone of modern\nquantum optics. One of the key assumptions of the model is that the `atom' is a\nperfect two-level system. We explore what happens when one generalizes the atom\nto a multilevel system, with $m$ ground and $n$ excited states coupled to the\nsame field. We focus on the case where the excited and ground states form\ndistinct, well-separated, manifolds of near-degenerate levels (so that the\nspacing between the excited states on a given manifold is much less than the\naverage spacing between the manifolds) and consider either uniform or random\ncouplings between the individual ground and excited levels. We find that the\nsystem reduces approximately to a direct sum of Rabi models with a range of\ndifferent couplings. Importantly, the strongest coupling is enhanced in a way\nthat depends on the number of levels, for the simple case where $n=m$, the\ncoupling scales with $n$ for uniform couplings and $2\\sqrt{n}$ for random\ncouplings (in the limit of large $n$). Our work thus suggests that multilevel\nRabi systems could provide an attractive alternative route to accessing regimes\nof very strong coupling in light-matter systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T11:10:19Z"}
{"aid":"http://arxiv.org/abs/2504.05919v1","title":"Measurement of high-mass $t\\bar{t}\\ell^{+}\\ell^{-}$ production and\n  lepton flavour universality-inspired effective field theory interpretations\n  at $\\sqrt{s}=13$ TeV with the ATLAS detector","summary":"Measurements of $t\\bar{t}\\ell^{+}\\ell^{-}$ production in the region of high\ndilepton invariant mass with effective field theory (EFT) interpretations are\npresented. They are performed using final states with three isolated leptons\n(electrons or muons) and are based on $\\sqrt{s} = 13$ TeV proton-proton\ncollision data with an integrated luminosity of $140\\,\\mathrm{fb}^{-1}$,\nrecorded from 2015 to 2018 with the ATLAS detector at the Large Hadron\nCollider. Measurements of the $t\\bar{t}\\ell^{+}\\ell^{-}$ signal strength and\ncross-section upper-limits are performed inclusively in lepton flavour and\nseparately for electrons and muons. The study also aims to probe anomalous\nfour-fermion interactions including to test for possible lepton flavor\nuniversality violation. No significant deviations from the Standard Model\npredictions are observed and the measurements are interpreted through the EFT\nformalism to provide new constraints on relevant operators.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-08T11:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.05923v1","title":"Uncovering Fairness through Data Complexity as an Early Indicator","summary":"Fairness constitutes a concern within machine learning (ML) applications.\nCurrently, there is no study on how disparities in classification complexity\nbetween privileged and unprivileged groups could influence the fairness of\nsolutions, which serves as a preliminary indicator of potential unfairness. In\nthis work, we investigate this gap, specifically, we focus on synthetic\ndatasets designed to capture a variety of biases ranging from historical bias\nto measurement and representational bias to evaluate how various complexity\nmetrics differences correlate with group fairness metrics. We then apply\nassociation rule mining to identify patterns that link disproportionate\ncomplexity differences between groups with fairness-related outcomes, offering\ndata-centric indicators to guide bias mitigation. Our findings are also\nvalidated by their application in real-world problems, providing evidence that\nquantifying group-wise classification complexity can uncover early indicators\nof potential fairness challenges. This investigation helps practitioners to\nproactively address bias in classification tasks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DS","published":"2025-04-08T11:28:40Z"}
{"aid":"http://arxiv.org/abs/2504.05933v1","title":"Irrationality of the reciprocal sum of doubly exponential sequences","summary":"We show that sequences of positive integers whose ratios $a_n^2/a_{n+1}$ lie\nwithin a specific range are almost uniquely determined by their reciprocal\nsums. For instance, the Sylvester sequence is uniquely characterized as the\nonly sequence with $a_n^2/a_{n+1}\\in [2/3,4/3]$ whose reciprocal sum is equal\nto $1$. This result has applications to irrationality problems. We prove that\nfor almost every real number $\\alpha > 1$, sequences asymptotic to\n$\\alpha^{2^n}$ have irrational reciprocal sums. Furthermore, our observations\nprovide heuristic insight into an open problem by Erd\\H{o}s and Graham.","main_category":"math.NT","categories":"math.NT","published":"2025-04-08T11:47:29Z"}
{"aid":"http://arxiv.org/abs/2504.05951v1","title":"Representing Normative Regulations in OWL DL for Automated Compliance\n  Checking Supported by Text Annotation","summary":"Compliance checking is the process of determining whether a regulated entity\nadheres to these regulations. Currently, compliance checking is predominantly\nmanual, requiring significant time and highly skilled experts, while still\nbeing prone to errors caused by the human factor. Various approaches have been\nexplored to automate compliance checking, however, representing regulations in\nOWL DL language which enables compliance checking through OWL reasoning has not\nbeen adopted. In this work, we propose an annotation schema and an algorithm\nthat transforms text annotations into machine-interpretable OWL DL code. The\nproposed approach is validated through a proof-of-concept implementation\napplied to examples from the building construction domain.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T12:05:21Z"}
{"aid":"http://arxiv.org/abs/2504.05953v1","title":"On walk domination: Between different types of walks and $m_3$-path","summary":"This paper investigates the domination relationships among various types of\nwalks connecting two non-adjacent vertices in a graph. In particular, we center\nour attention on the problem which is proposed in [S. B. Tondato, Graphs\nCombin. 40 (2024)]. A \\textit{\\( uv \\)-\\( m_3 \\) path} is a \\( uv \\)-induced\npath of length at least three. A walk between two non-adjacent vertices in a\ngraph $G$ is called a weakly toll walk if the first and last vertices in the\nwalk are adjacent only to the second and second-to-last vertices, respectively,\nand these intermediate vertices may appear more than once in the walk. And an\n$l_k$-path is an induced path of length at most $k$ between two non-adjacent\nvertices in a graph $G$. We study the domination between weakly toll walks,\n$l_k$-paths ($k\\in \\left\\{2,3\\right\\}$) and different types of walks connecting\ntwo non-adjacent vertices $u$ and $v$ of a graph (shortest paths, tolled walks,\nweakly toll walks, $l_k$-paths for $k\\in \\left\\{2,3\\right\\}$, $m_3$-path), and\nshow how these give rise to characterizations of graph classes.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T12:06:30Z"}
{"aid":"http://arxiv.org/abs/2504.05959v1","title":"Old and New Results on Alphabetic Codes","summary":"This comprehensive survey examines the field of alphabetic codes, tracing\ntheir development from the 1960s to the present day. We explore classical\nalphabetic codes and their variants, analyzing their properties and the\nunderlying mathematical and algorithmic principles. The paper covers the\nfundamental relationship between alphabetic codes and comparison-based search\nprocedures and their applications in data compression, routing, and testing. We\nreview optimal alphabetic code construction algorithms, necessary and\nsufficient conditions for their existence, and upper bounds on the average code\nlength of optimal alphabetic codes. The survey also discusses variations and\ngeneralizations of the classical problem of constructing minimum average length\nalphabetic codes. By elucidating both classical results and recent findings,\nthis paper aims to serve as a valuable resource for researchers and students,\nconcluding with promising future research directions in this still-active\nfield.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-08T12:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.05978v1","title":"Smart Exploration in Reinforcement Learning using Bounded Uncertainty\n  Models","summary":"Reinforcement learning (RL) is a powerful tool for decision-making in\nuncertain environments, but it often requires large amounts of data to learn an\noptimal policy. We propose using prior model knowledge to guide the exploration\nprocess to speed up this learning process. This model knowledge comes in the\nform of a model set to which the true transition kernel and reward function\nbelong. We optimize over this model set to obtain upper and lower bounds on the\nQ-function, which are then used to guide the exploration of the agent. We\nprovide theoretical guarantees on the convergence of the Q-function to the\noptimal Q-function under the proposed class of exploring policies. Furthermore,\nwe also introduce a data-driven regularized version of the model set\noptimization problem that ensures the convergence of the class of exploring\npolicies to the optimal policy. Lastly, we show that when the model set has a\nspecific structure, namely the bounded-parameter MDP (BMDP) framework, the\nregularized model set optimization problem becomes convex and simple to\nimplement. In this setting, we also show that we obtain finite-time convergence\nto the optimal policy under additional assumptions. We demonstrate the\neffectiveness of the proposed exploration strategy in a simulation study. The\nresults indicate that the proposed method can significantly speed up the\nlearning process in reinforcement learning.","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY","published":"2025-04-08T12:33:38Z"}
{"aid":"http://arxiv.org/abs/2504.05979v1","title":"An Empirical Study of GPT-4o Image Generation Capabilities","summary":"The landscape of image generation has rapidly evolved, from early GAN-based\napproaches to diffusion models and, most recently, to unified generative\narchitectures that seek to bridge understanding and generation tasks. Recent\nadvances, especially the GPT-4o, have demonstrated the feasibility of\nhigh-fidelity multimodal generation, their architectural design remains\nmysterious and unpublished. This prompts the question of whether image and text\ngeneration have already been successfully integrated into a unified framework\nfor those methods. In this work, we conduct an empirical study of GPT-4o's\nimage generation capabilities, benchmarking it against leading open-source and\ncommercial models. Our evaluation covers four main categories, including\ntext-to-image, image-to-image, image-to-3D, and image-to-X generation, with\nmore than 20 tasks. Our analysis highlights the strengths and limitations of\nGPT-4o under various settings, and situates it within the broader evolution of\ngenerative modeling. Through this investigation, we identify promising\ndirections for future unified generative models, emphasizing the role of\narchitectural design and data scaling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T12:34:36Z"}
{"aid":"http://arxiv.org/abs/2504.05984v1","title":"Subaru High-$z$ Exploration of Low-Luminosity Quasars (SHELLQs). XXIII.\n  The powering mechanisms of the Ly$Î±$ haloes around high-$z$ quasars\n  probed by slit spectroscopy","summary":"We present the analysis of Ly$\\alpha$ haloes around faint quasars at $z\\sim4$\nand $z\\sim6$. We use 20 and 162 quasars at $z\\sim4$ and $z\\sim6$, taken by slit\nspectroscopy, and detect Ly$\\alpha$ haloes around 12 and 26 of these quasars,\nrespectively. The average absolute magnitudes of the detected quasars are\n$\\langle M_{1450} \\rangle = -23.84$ mag at $z\\sim4$ and $\\langle M_{1450}\n\\rangle = -23.68$ mag at $z\\sim6$, which are comparable at $z\\sim4$ and 3 mag\nfainter at $z\\sim6$ than those of previous studies. The median surface\nbrightness profiles are found to be consistent with an exponential curve,\nshowing a hint of flattening within a radius of 5 kpc. The Ly$\\alpha$ haloes\naround these faint quasars are systematically fainter than those around bright\nquasars in the previous studies. We confirm the previous results that the\nLy$\\alpha$ halo luminosity depends on both the ionizing and Ly$\\alpha$ peak\nluminosities of quasars at $z\\sim4$, and also find that a similar correlation\nholds even at $z\\sim6$. While the observed Ly$\\alpha$ halo luminosity is\noverall attributed to recombination emission from the optically thin gas clouds\nin the CGM, its luminosity dependences can be consistently explained by the\npartial contributions of recombination radiation from the optically thick\nclouds, which is thought to originate from the CGM centre, and the scattered\nLy$\\alpha$ photons, which is resonantly trapped at the CGM centre and escaping\noutside of the haloes.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T12:40:29Z"}
{"aid":"http://arxiv.org/abs/2504.05985v1","title":"Adaptive RISE Control for Dual-Arm Unmanned Aerial Manipulator Systems\n  with Deep Neural Networks","summary":"The unmanned aerial manipulator system, consisting of a multirotor UAV\n(unmanned aerial vehicle) and a manipulator, has attracted considerable\ninterest from researchers. Nevertheless, the operation of a dual-arm\nmanipulator poses a dynamic challenge, as the CoM (center of mass) of the\nsystem changes with manipulator movement, potentially impacting the multirotor\nUAV. Additionally, unmodeled effects, parameter uncertainties, and external\ndisturbances can significantly degrade control performance, leading to\nunforeseen dangers. To tackle these issues, this paper proposes a nonlinear\nadaptive RISE (robust integral of the sign of the error) controller based on\nDNN (deep neural network). The first step involves establishing the kinematic\nand dynamic model of the dual-arm aerial manipulator. Subsequently, the\nadaptive RISE controller is proposed with a DNN feedforward term to effectively\naddress both internal and external challenges. By employing Lyapunov\ntechniques, the asymptotic convergence of the tracking error signals are\nguaranteed rigorously. Notably, this paper marks a pioneering effort by\npresenting the first DNN-based adaptive RISE controller design accompanied by a\ncomprehensive stability analysis. To validate the practicality and robustness\nof the proposed control approach, several groups of actual hardware experiments\nare conducted. The results confirm the efficacy of the developed methodology in\nhandling real-world scenarios, thereby offering valuable insights into the\nperformance of the dual-arm aerial manipulator system.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T12:43:45Z"}
{"aid":"http://arxiv.org/abs/2504.05988v1","title":"Consistency Relation for Fixed Point Dynamics","summary":"We gain insight on the fixed point dynamics of $d$ dimensional quantum field\ntheories by exploiting the critical behavior of the $d-\\epsilon$ sister\ntheories. To this end we first derive a self-consistent relation between the\n$d-\\epsilon$ scaling exponents and the associated $d$ dimensional beta\nfunctions. We then demonstrate that to account for an interacting fixed point\nin the original theory the related $d-\\epsilon$ scaling exponent must be\nmulti-valued in $\\epsilon$. We elucidate our findings by discussing several\nexamples such as the QCD Banks-Zaks infrared fixed point, QCD at large number\nof flavors, as well as the O(N) model in four dimensions. For the latter, we\nshow that although the $1/N$ corrections prevent the reconstruction of the\nrenormalization group flow, this is possible when adding the $1/N^2$\ncontributions.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-08T12:50:27Z"}
{"aid":"http://arxiv.org/abs/2504.05996v1","title":"Unified Beta Regression Model with Random Effects for the Analysis of\n  Sensory Attributes","summary":"Studies involving sensory analysis are essential for evaluating and measuring\nthe characteristics of food and beverages, including consumer acceptance of\nsamples. For various products, the experimental designs are generally\nincomplete block designs, with sensory attributes assessed using hedonic\nscales, ratings, or scores. Statistical methods such as generalized logits are\ncommonly used to analyze these data but face limitations, including convergence\nissues due to superparameterization. Furthermore, sensory attributes are\ntraditionally analyzed separately, increasing the complexity of the process and\ncomplicating the interpretation of results. This study proposes a unified beta\nregression model with random effects for simultaneously analyzing multiple\nsensory attributes, whose scores were converted to the (0,1) interval.\nSimulation studies demonstrated overall agreement rates greater than 82% for\nthe unified model compared to models fitted separately for each attribute. As a\nmotivational example, the unified model was applied to a real dataset in which\n98 potential consumers evaluated eight grape juice formulations for each\nsensory attribute: colour, flavour, aroma, acidity, and sweetness. The unified\nmodel identified the same top-rated formulations as the separately fitted\nmodels, characterized by a higher proportion of juice relative to sugar. The\nresults underscore the ability of the unified model to simplify the analytical\nprocess without compromising accuracy, offering an efficient and insightful\napproach to sensory studies.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T13:01:58Z"}
{"aid":"http://arxiv.org/abs/2504.06000v1","title":"Odd-parity ground state in dilute Yu-Shiba-Rusinov dimers and chains","summary":"Magnetic adatoms on superconductors induce Yu-Shiba-Rusinov (YSR) states,\nwhich are key to the design of low-dimensional correlated systems and\ntopological superconductivity. Competing magnetic interactions and\nsuperconducting pairing lead to a rich phase diagram. Using a scanning\ntunneling microscope (STM), we position Fe atoms on 2H-NbSe$_2$ to build a\ndimer with an odd-parity ground state, i.e., a partially screened YSR channel\nwith the hybridized states spanning the Fermi level. This ground state makes\nthe dimer a promising precursor for a topological YSR chain. By adding one atom\nat a time, we track the formation of YSR bands. The lowest-energy band crosses\nthe Fermi level and we find strong site-dependent spectral variations\nespecially at the chain's terminations. We attribute these features to quantum\nspin effects and ferromagnetic coupling influenced by the local chemical\nenvironment, rather than topological superconductivity or Majorana modes.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-08T13:08:02Z"}
{"aid":"http://arxiv.org/abs/2504.06006v1","title":"Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?","summary":"Optimal hyperparameter selection is critical for maximizing neural network\nperformance, especially as models grow in complexity. This work investigates\nthe viability of using large language models (LLMs) for hyperparameter\noptimization by employing a fine-tuned version of Code Llama. Through\nparameter-efficient fine-tuning using LoRA, we adapt the LLM to generate\naccurate and efficient hyperparameter recommendations tailored to diverse\nneural network architectures. Unlike traditional methods such as Optuna, which\nrely on exhaustive trials, the proposed approach achieves competitive or\nsuperior results in terms of Root Mean Square Error (RMSE) while significantly\nreducing computational overhead. Our approach highlights that LLM-based\noptimization not only matches state-of-the-art methods like Tree-structured\nParzen Estimators but also accelerates the tuning process. This positions LLMs\nas a promising alternative to conventional optimization techniques,\nparticularly for rapid experimentation. Furthermore, the ability to generate\nhyperparameters in a single inference step makes this method particularly\nwell-suited for resource-constrained environments such as edge devices and\nmobile applications, where computational efficiency is paramount. The results\nconfirm that LLMs, beyond their efficiency, offer substantial time savings and\ncomparable stability, underscoring their value in advancing machine learning\nworkflows. All generated hyperparameters are included in the LEMUR Neural\nNetwork (NN) Dataset, which is publicly available and serves as an open-source\nbenchmark for hyperparameter optimization research.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE","published":"2025-04-08T13:15:47Z"}
{"aid":"http://arxiv.org/abs/2504.06019v1","title":"Radiatively-Cooled Moist Convection under an Idealised Climate Change\n  Scenario: Linear Analysis","summary":"In order to explore the effects of climate change on atmospheric convection\nand the water cycle, we develop and analyse an extension of the Rainy-B\\'enard\nmodel, which is itself a moist version of the Rayleigh-B\\'enard model of dry\nconvection. Including moisture changes the character of the convection, with\ncondensation providing a source of buoyancy via latent heating. The climate\nchange model is set up by imposing a variable radiative cooling rate,\nprescribing surface temperature and relative humidity, and imposing a\nmoist-pseudoadiabatic profile at the top boundary (a flux boundary condition).\nThe model is analysed across the climate parameter space by examining\ndiagnostics of the model's basic state, and its stability, with Convective\nAvailable Potential Energy (CAPE) calculations and a linear stability analysis.\nWe use the linear stability results to identify new parameters relevant for\nthis moist convective system, and to understand how the linear instability\nresponds to the climate parameters. In particular, we define the \"Rainy number\"\nas a scaled ratio of positive-area CAPE and diffusion parameters. An\nalternative radiative-based Rainy number also is shown to describe the\nparameter space, especially for problems relating to changes in flux\nconditions. The analysis provides a novel theoretical understanding of how the\ndynamics and scales of moist convection and hence precipitation will change\nunder climate change.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.ao-ph","published":"2025-04-08T13:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.06020v1","title":"Information-Theoretic Reward Decomposition for Generalizable RLHF","summary":"A generalizable reward model is crucial in Reinforcement Learning from Human\nFeedback (RLHF) as it enables correctly evaluating unseen prompt-response\npairs. However, existing reward models lack this ability, as they are typically\ntrained by increasing the reward gap between chosen and rejected responses,\nwhile overlooking the prompts that the responses are conditioned on.\nConsequently, when the trained reward model is evaluated on prompt-response\npairs that lie outside the data distribution, neglecting the effect of prompts\nmay result in poor generalization of the reward model. To address this issue,\nwe decompose the reward value into two independent components: prompt-free\nreward and prompt-related reward. Prompt-free reward represents the evaluation\nthat is determined only by responses, while the prompt-related reward reflects\nthe reward that derives from both the prompt and the response. We extract these\ntwo components from an information-theoretic perspective, which requires no\nextra models. Subsequently, we propose a new reward learning algorithm by\nprioritizing data samples based on their prompt-free reward values. Through toy\nexamples, we demonstrate that the extracted prompt-free and prompt-related\nrewards effectively characterize two parts of the reward model. Further,\nstandard evaluations show that our method improves both the alignment\nperformance and the generalization capability of the reward model.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T13:26:07Z"}
{"aid":"http://arxiv.org/abs/2504.06025v1","title":"Geometries with trialities arising from linear spaces","summary":"A triality is a sort of super-symmetry that exchanges the types of the\nelements of an incidence geometry in cycles of length three. Although\ngeometries with trialities exhibit fascinating behaviors, their construction is\nchallenging, making them rare in the literature. To understand trialities more\ndeeply, it is crucial to have a wide variety of examples at hand. In this\narticle, we introduce a general method for constructing various rank-three\nincidence systems with trialities. Specifically, for any rank two incidence\nsystem $\\Gamma$, we define its triangle complex $\\Delta(\\Gamma)$, a rank three\nincidence system whose elements consist of three copies of the flags (pairs of\nincident elements) of $\\Gamma$. This triangle complex always admits a triality\nthat cyclically permutes the three copies. We then explore in detail the\nproperties of the triangle complex when $\\Gamma$ is a linear space, including\nflag-transitivity, the existence of dualities, and connectivity properties. As\na consequence of our work, this construction yields the first infinite family\nof thick, flag-transitive and residually connected geometries with trialities\nbut no dualities.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-08T13:28:55Z"}
{"aid":"http://arxiv.org/abs/2504.06032v1","title":"3D evolution of protein networks and lipid globules in heat-treated egg\n  yolk","summary":"Upon heating, egg yolk transforms from a liquid to a gel due to protein\ndenaturation. This process can serve as a useful model to better understand\nprotein denaturation in general. Using x-ray holographic tomography, we\ninvestigated the structural changes in egg yolk during boiling without the need\nfor complex sample fixation or drying. Our results reveal a developing\nseparation between proteins and lipids, with fatty components rapidly\naggregating into large globules that subsequently evolve into bubbles.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-08T13:35:25Z"}
{"aid":"http://arxiv.org/abs/2504.06033v1","title":"Parallel Small Vertex Connectivity in Near-Linear Work and\n  Polylogarithmic Depth","summary":"We present a randomized parallel algorithm in the {\\sf PRAM} model for\n$k$-vertex connectivity. Given an undirected simple graph, our algorithm either\nfinds a set of fewer than $k$ vertices whose removal disconnects the graph or\nreports that no such set exists. The algorithm runs in $O(m \\cdot\n\\text{poly}(k, \\log n))$ work and $O(\\text{poly}(k, \\log n))$ depth, which is\nnearly optimal for any $k = \\text{poly}(\\log n)$. Prior to our work, algorithms\nwith near-linear work and polylogarithmic depth were known only for $k=3$\n[Miller, Ramachandran, STOC'87]; for $k=4$, sequential algorithms achieving\nnear-linear time were known [Forster, Nanongkai, Yang, Saranurak,\nYingchareonthawornchai, SODA'20], but no algorithm with near-linear work could\nachieve even sublinear (on $n$) depth.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-08T13:35:38Z"}
{"aid":"http://arxiv.org/abs/2504.06046v1","title":"Rhythmic neuromorphic control of a pendulum: A hybrid systems analysis","summary":"Neuromorphic engineering is an emerging research domain that aims to realize\nimportant implementation advantages that brain-inspired technologies can offer\nover classical digital technologies, including energy efficiency, adaptability,\nand robustness. For the field of systems and control, neuromorphic controllers\ncould potentially bring many benefits, but their advancement is hampered by\nlack of systematic analysis and design tools. In this paper, the objective is\nto show that hybrid systems methods can aid in filling this gap. We do this by\nformally analyzing rhythmic neuromorphic control of a pendulum system, which\nwas recently proposed as a prototypical setup. The neuromorphic controller\ngenerates spikes, which we model as a Dirac delta pulse, whenever the pendulum\nangular position crosses its resting position, with the goal of inducing a\nstable limit cycle. This leads to modeling the closed-loop system as a hybrid\ndynamical system, which in between spikes evolves in open loop and where the\njumps correspond to the spiking control actions. Exploiting the hybrid system\nmodel, we formally prove the existence, uniqueness, and a stability property of\nthe hybrid limit cycle for the closed-loop system. Numerical simulations\nillustrate our approach. We finally elaborate on a possible spiking adaptation\nmechanism on the pulse amplitude to generate a hybrid limit cycle of a desired\nmaximal angular amplitude.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T13:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.06059v1","title":"New designs of linear optical interferometers with minimal depth and\n  component count","summary":"We adapt an algorithm for CNOT circuits synthesis based on the Bruhat\ndecomposition to the design of linear optical circuits with Mach-Zehnder\ninterferometers (MZI). The synthesis algorithm reduces to designing sorting\nnetworks with nearest neighbor swapping operations as elementary gates. We\nrecover previous designs from the literature but with additional theoretical\nproperties regarding the compiler that implements unitaries on the\ninterferometer. Notably the compiler can always decide whether a unitary can be\nimplemented on a given interferometer and, if so, returns the shallowest\npossible implementation. We also show natural extensions of our framework for\nboson sampling experiments and for the coupling of multiple integrated\ninterferometers to design larger linear optical systems. In both cases, the\ndesigns are optimal in terms of number of optical components. Finally, we\npropose a greedy design which exploits the arbritrary-but-fixed coupling of\nseparate integrated interferometers to perform shallow boson sampling. We\ndiscuss the optimal interferometer dimensions to maximize the transmission.\nBeyond boson sampling, our developed framework allows a resource-favourable\nimplemention of any non-adaptive linear optical quantum algorithm, by providing\nthe shallowest possible interferometer for implementing this algorithm.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T14:03:04Z"}
{"aid":"http://arxiv.org/abs/2504.06069v1","title":"Physics-Constrained Neural Network for Metasurface Optical Response\n  Prediction","summary":"A physics-constrained neural network is presented for predicting the optical\nresponse of metasurfaces. Our approach incorporates physical laws directly into\nthe neural network architecture and loss function, addressing critical\nchallenges in the modeling of metasurfaces. Unlike methods that require\nspecialized weighting strategies or separate architectural branches to handle\ndifferent data regimes and phase wrapping discontinuities, this unified\napproach effectively addresses phase discontinuities, energy conservation\nconstraints, and complex gap-dependent behavior. We implement sine-cosine phase\nrepresentation with Euclidean normalization as a non-trainable layer within the\nnetwork, enabling the model to account for the periodic nature of phase while\nenforcing the mathematical constraint $\\sin^2 \\phi + \\cos^2 \\phi = 1$. A\nEuclidean distance-based loss function in the sine-cosine space ensures a\nphysically meaningful error metric while preventing discontinuity issues. The\nmodel achieves good, consistent performance with small, imbalanced datasets of\n580 and 1075 data points, compared to several thousand typically required by\nalternative approaches. This physics-informed approach preserves physical\ninterpretability while reducing reliance on large datasets and could be\nextended to other photonic structures by incorporating additional physical\nconstraints tailored to specific applications.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T14:10:28Z"}
{"aid":"http://arxiv.org/abs/2504.06091v1","title":"Real-Time LaCAM","summary":"The vast majority of Multi-Agent Path Finding (MAPF) methods with\ncompleteness guarantees require planning full horizon paths. However, planning\nfull horizon paths can take too long and be impractical in real-world\napplications. Instead, real-time planning and execution, which only allows the\nplanner a finite amount of time before executing and replanning, is more\npractical for real world multi-agent systems. Several methods utilize real-time\nplanning schemes but none are provably complete, which leads to livelock or\ndeadlock. Our main contribution is to show the first Real-Time MAPF method with\nprovable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023)\nin an incremental fashion. Our results show how we can iteratively plan for\ncongested environments with a cutoff time of milliseconds while still\nmaintaining the same success rate as full horizon LaCAM. We also show how it\ncan be used with a single-step learned MAPF policy. The proposed Real-Time\nLaCAM also provides us with a general mechanism for using iterative constraints\nfor completeness in future real-time MAPF algorithms.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.RO","published":"2025-04-08T14:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.06094v1","title":"On the structure of DHR bimodules of abstract spin chains","summary":"Abstract spin chains axiomatize the structure of local observables on the 1D\nlattice which are invariant under a global symmetry, and arise at the physical\nboundary of 2+1D topologically ordered spin systems. In this paper, we study\ntensor categorical properties of DHR bimodules over abstract spin chains.\nAssuming that the charge transporters generate the algebra of observables, we\nprove that the associated category has a structure of modular tensor category\nwith respect to the natural braiding. Under an additional assumption of\nalgebraic Haag duality, this category becomes the Drinfeld center of the\nhalf-line fusion category.","main_category":"math.QA","categories":"math.QA,math-ph,math.MP,math.OA","published":"2025-04-08T14:35:19Z"}
{"aid":"http://arxiv.org/abs/2504.06096v1","title":"Observation of the very rare $Î£^+ \\to p Î¼^+ Î¼^-$ decay","summary":"The first observation of the $\\Sigma^+ \\to p \\mu^+ \\mu^-$ decay is reported\nwith high significance using proton-proton collision data, corresponding to an\nintegrated luminosity of $5.4\\,\\rm{fb}^{-1}$, collected with the LHCb detector\nat a centre-of-mass energy of 13~TeV. A yield of $237\\pm 16$ $\\Sigma^+ \\to p\n\\mu^+ \\mu^-$ decays is obtained, where the uncertainty is statistical only. A\nbranching fraction of $(1.08 \\pm 0.17) \\times 10^{-8}$ is measured, where the\nuncertainty includes statistical and systematic sources. No evidence of\nresonant structures is found in the dimuon invariant-mass distribution. All\nresults are compatible with Standard Model expectations. This represents the\nrarest decay of a baryon ever observed.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-08T14:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.06102v1","title":"Sherlock: A Dataset for Process-aware Intrusion Detection Research on\n  Power Grid Networks","summary":"Physically distributed components and legacy protocols make the protection of\npower grids against increasing cyberattack threats challenging. Infamously, the\n2015 and 2016 blackouts in Ukraine were caused by cyberattacks, and the German\nFederal Office for Information Security (BSI) recorded over 200 cyber incidents\nagainst the German energy sector between 2023 and 2024. Intrusion detection\npromises to quickly detect such attacks and mitigate the worst consequences.\nHowever, public datasets of realistic scenarios are vital to evaluate these\nsystems. This paper introduces Sherlock, a dataset generated with the\nco-simulator Wattson. In total, Sherlock covers three scenarios with various\nattacks manipulating the process state by injecting malicious commands or\nmanipulating measurement values. We additionally test five recently-published\nintrusion detection systems on Sherlock, highlighting specific challenges for\nintrusion detection in power grids. Dataset and documentation are available at\nhttps://sherlock.wattson.it/.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-04-08T14:46:35Z"}
{"aid":"http://arxiv.org/abs/2504.06121v1","title":"A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature\n  Fusion for Foggy Conditions","summary":"Lane detection is a critical component of Advanced Driver Assistance Systems\n(ADAS). Existing lane detection algorithms generally perform well under\nfavorable weather conditions. However, their performance degrades significantly\nin adverse conditions, such as fog, which increases the risk of traffic\naccidents. This challenge is compounded by the lack of specialized datasets and\nmethods designed for foggy environments. To address this, we introduce the\nFoggyLane dataset, captured in real-world foggy scenarios, and synthesize two\nadditional datasets, FoggyCULane and FoggyTusimple, from existing popular lane\ndetection datasets. Furthermore, we propose a robust Fog-Enhanced Network for\nlane detection, incorporating a Global Feature Fusion Module (GFFM) to capture\nglobal relationships in foggy images, a Kernel Feature Fusion Module (KFFM) to\nmodel the structural and positional relationships of lane instances, and a\nLow-level Edge Enhanced Module (LEEM) to address missing edge details in foggy\nconditions. Comprehensive experiments demonstrate that our method achieves\nstate-of-the-art performance, with F1-scores of 95.04 on FoggyLane, 79.85 on\nFoggyCULane, and 96.95 on FoggyTusimple. Additionally, with TensorRT\nacceleration, the method reaches a processing speed of 38.4 FPS on the NVIDIA\nJetson AGX Orin, confirming its real-time capabilities and robustness in foggy\nenvironments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:13:01Z"}
{"aid":"http://arxiv.org/abs/2504.06124v1","title":"Safe Interaction via Monte Carlo Linear-Quadratic Games","summary":"Safety is critical during human-robot interaction. But -- because people are\ninherently unpredictable -- it is often difficult for robots to plan safe\nbehaviors. Instead of relying on our ability to anticipate humans, here we\nidentify robot policies that are robust to unexpected human decisions. We\nachieve this by formulating human-robot interaction as a zero-sum game, where\n(in the worst case) the human's actions directly conflict with the robot's\nobjective. Solving for the Nash Equilibrium of this game provides robot\npolicies that maximize safety and performance across a wide range of human\nactions. Existing approaches attempt to find these optimal policies by\nleveraging Hamilton-Jacobi analysis (which is intractable) or linear-quadratic\napproximations (which are inexact). By contrast, in this work we propose a\ncomputationally efficient and theoretically justified method that converges\ntowards the Nash Equilibrium policy. Our approach (which we call MCLQ)\nleverages linear-quadratic games to obtain an initial guess at safe robot\nbehavior, and then iteratively refines that guess with a Monte Carlo search.\nNot only does MCLQ provide real-time safety adjustments, but it also enables\nthe designer to tune how conservative the robot is -- preventing the system\nfrom focusing on unrealistic human behaviors. Our simulations and user study\nsuggest that this approach advances safety in terms of both computation time\nand expected performance. See videos of our experiments here:\nhttps://youtu.be/KJuHeiWVuWY.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T15:18:38Z"}
{"aid":"http://arxiv.org/abs/2504.06135v1","title":"Decentralizing AI Memory: SHIMI, a Semantic Hierarchical Memory Index\n  for Scalable Agent Reasoning","summary":"Retrieval-Augmented Generation (RAG) and vector-based search have become\nfoundational tools for memory in AI systems, yet they struggle with\nabstraction, scalability, and semantic precision - especially in decentralized\nenvironments. We present SHIMI (Semantic Hierarchical Memory Index), a unified\narchitecture that models knowledge as a dynamically structured hierarchy of\nconcepts, enabling agents to retrieve information based on meaning rather than\nsurface similarity. SHIMI organizes memory into layered semantic nodes and\nsupports top-down traversal from abstract intent to specific entities, offering\nmore precise and explainable retrieval. Critically, SHIMI is natively designed\nfor decentralized ecosystems, where agents maintain local memory trees and\nsynchronize them asynchronously across networks. We introduce a lightweight\nsync protocol that leverages Merkle-DAG summaries, Bloom filters, and\nCRDT-style conflict resolution to enable partial synchronization with minimal\noverhead. Through benchmark experiments and use cases involving decentralized\nagent collaboration, we demonstrate SHIMI's advantages in retrieval accuracy,\nsemantic fidelity, and scalability - positioning it as a core infrastructure\nlayer for decentralized cognitive systems.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-08T15:31:00Z"}
{"aid":"http://arxiv.org/abs/2504.06140v1","title":"Cosmic ray transport and acceleration with magnetic mirroring","summary":"We analyse the transport of cosmic rays (CR) in magnetic fields that are\nstructured on scales greater than the CR Larmor radius. We solve the\nVlasov-Fokker-Planck (VFP) equation for various mixes of mirroring and\nsmall-angle scattering and show that relatively small deviations from a uniform\nmagnetic field can induce mirroring and inhibit CR transport to levels that\nmimic Bohm diffusion in which the CR mean free path is comparable with the CR\nLarmor radius. Our calculations suggest that shocks may accelerate CR to the\nHillas (1984) energy without the need for magnetic field amplification on the\nLarmor scale. This re-opens the possibility, subject to more comprehensive\nsimulations, that young supernova remnants may be accelerating CR to PeV\nenergies, and maybe even to higher energies beyond the knee in the energy\nspectrum. We limit our discussion of CR acceleration to shocks that are\nnon-relativistic.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-08T15:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.06144v1","title":"A Training-Free Style-aligned Image Generation with Scale-wise\n  Autoregressive Model","summary":"We present a training-free style-aligned image generation method that\nleverages a scale-wise autoregressive model. While large-scale text-to-image\n(T2I) models, particularly diffusion-based methods, have demonstrated\nimpressive generation quality, they often suffer from style misalignment across\ngenerated image sets and slow inference speeds, limiting their practical\nusability. To address these issues, we propose three key components: initial\nfeature replacement to ensure consistent background appearance, pivotal feature\ninterpolation to align object placement, and dynamic style injection, which\nreinforces style consistency using a schedule function. Unlike previous methods\nrequiring fine-tuning or additional training, our approach maintains fast\ninference while preserving individual content details. Extensive experiments\nshow that our method achieves generation quality comparable to competing\napproaches, significantly improves style alignment, and delivers inference\nspeeds over six times faster than the fastest model.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.06154v1","title":"Exploring Adversarial Obstacle Attacks in Search-based Path Planning for\n  Autonomous Mobile Robots","summary":"Path planning algorithms, such as the search-based A*, are a critical\ncomponent of autonomous mobile robotics, enabling robots to navigate from a\nstarting point to a destination efficiently and safely. We investigated the\nresilience of the A* algorithm in the face of potential adversarial\ninterventions known as obstacle attacks. The adversary's goal is to delay the\nrobot's timely arrival at its destination by introducing obstacles along its\noriginal path.\n  We developed malicious software to execute the attacks and conducted\nexperiments to assess their impact, both in simulation using TurtleBot in\nGazebo and in real-world deployment with the Unitree Go1 robot. In simulation,\nthe attacks resulted in an average delay of 36\\%, with the most significant\ndelays occurring in scenarios where the robot was forced to take substantially\nlonger alternative paths. In real-world experiments, the delays were even more\npronounced, with all attacks successfully rerouting the robot and causing\nmeasurable disruptions. These results highlight that the algorithm's robustness\nis not solely an attribute of its design but is significantly influenced by the\noperational environment. For example, in constrained environments like tunnels,\nthe delays were maximized due to the limited availability of alternative\nroutes.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T15:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.06160v1","title":"Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack\n  Narratives Targeting Mental Health Groups","summary":"Large Language Models (LLMs) have been shown to demonstrate imbalanced biases\nagainst certain groups. However, the study of unprovoked targeted attacks by\nLLMs towards at-risk populations remains underexplored. Our paper presents\nthree novel contributions: (1) the explicit evaluation of LLM-generated attacks\non highly vulnerable mental health groups; (2) a network-based framework to\nstudy the propagation of relative biases; and (3) an assessment of the relative\ndegree of stigmatization that emerges from these attacks. Our analysis of a\nrecently released large-scale bias audit dataset reveals that mental health\nentities occupy central positions within attack narrative networks, as revealed\nby a significantly higher mean centrality of closeness (p-value = 4.06e-10) and\ndense clustering (Gini coefficient = 0.7). Drawing from sociological\nfoundations of stigmatization theory, our stigmatization analysis indicates\nincreased labeling components for mental health disorder-related targets\nrelative to initial targets in generation chains. Taken together, these\ninsights shed light on the structural predilections of large language models to\nheighten harmful discourse and highlight the need for suitable approaches for\nmitigation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG,cs.SI","published":"2025-04-08T15:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.06161v1","title":"A Hom formula for Soergel modules","summary":"We study Soergel modules for arbitrary Coxeter groups. For infinite Coxeter\ngroups, we show that the homomorphisms between Soergel modules are in general\nmore than those coming from morphisms of Soergel bimodules. This result\nprovides a negative answer to a question posed by Soergel.\n  We further show that the dimensions of the morphism spaces agree with the\npairing in the Hecke algebra when Soergel modules are instead regarded as\nmodules over the structure algebra. Moreover, we use this module structure to\ndefine a distinguished submodule of indecomposable Soergel bimodules that\nmimics the cohomology submodule of the intersection cohomology. Combined with\nthe Hodge theory of Soergel bimodules, this can be used to extend results\nregarding the shape of Bruhat intervals, such as top-heaviness, to arbitrary\nCoxeter groups.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T15:58:42Z"}
{"aid":"http://arxiv.org/abs/2504.06163v1","title":"Action Valuation in Sports: A Survey","summary":"Action Valuation (AV) has emerged as a key topic in Sports Analytics,\noffering valuable insights by assigning scores to individual actions based on\ntheir contribution to desired outcomes. Despite a few surveys addressing\nrelated concepts such as Player Valuation, there is no comprehensive review\ndedicated to an in-depth analysis of AV across different sports. In this\nsurvey, we introduce a taxonomy with nine dimensions related to the AV task,\nencompassing data, methodological approaches, evaluation techniques, and\npractical applications. Through this analysis, we aim to identify the essential\ncharacteristics of effective AV methods, highlight existing gaps in research,\nand propose future directions for advancing the field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:59:19Z"}
{"aid":"http://arxiv.org/abs/2504.06169v1","title":"Linear Regulator-Based Synchronization of Positive Multi-Agent Systems","summary":"This paper addresses the positive synchronization of interconnected systems\non undirected graphs. For homogeneous positive systems, a static feedback\nprotocol design is proposed, based on the Linear Regulator problem. The\nsolution to the algebraic equation associated to the stabilizing policy can be\nfound using a linear program. Necessary and sufficient conditions on the\npositivity of each agent's trajectory for all nonnegative initial conditions\nare also provided. Simulations on large regular graphs with different nodal\ndegree illustrate the proposed results.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T16:08:07Z"}
{"aid":"http://arxiv.org/abs/2504.06170v1","title":"Investigating Embedded Structures and Gas Kinematics in the IRDC Hosting\n  Bubble N59-North","summary":"We present a multi-wavelength study of an extended area hosting the bubble\nN59-North to explore the physical processes driving massive star formation\n(MSF). The Spitzer 8 $\\mu$m image reveals an elongated/filamentary\ninfrared-dark cloud (length $\\sim$28 pc) associated with N59-North, which\ncontains several protostars and seven ATLASGAL dust clumps at the same\ndistance. The existence of this filament is confirmed through $^{13}$CO and\nNH$_3$ molecular line data in a velocity range of [95, 106] km s$^{-1}$. All\ndust clumps satisfy Kauffmann & Pillai's condition for MSF. Using Spitzer 8\n$\\mu$m image, a new embedded hub-filament system candidate (C-HFS) is\ninvestigated toward the ATLASGAL clump, located near the filament's central\nregion. MeerKAT 1.3 GHz continuum emission, detected for the first time toward\nC-HFS, reveals an ultracompact HII region driven by a B2-type star, suggesting\nan early stage of HFS with minimal feedback from the young massive star. The\ncomparison of the position-velocity (PV) and position-position-velocity (PPV)\ndiagrams with existing theoretical models suggests that rotation, central\ncollapse, and end-dominated collapse are not responsible for the observed gas\nmotion in the filament. The PPV diagram indicates the expansion of N59-North by\nrevealing blue- and red-shifted gas velocities at the edge of the bubble. Based\non comparisons with magnetohydrodynamic simulations, this study suggests that\ncloud-cloud collision (CCC) led to the formation of the filament, likely giving\nit a conical structure with gas converging toward its central region, where\nC-HFS is located. Overall, the study supports multi-scale filamentary mass\naccretion for MSF, likely triggered by CCC.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T16:13:05Z"}
{"aid":"http://arxiv.org/abs/2504.06172v1","title":"Monotonicity of functionals associated to product measures via their\n  Fourier transform and applications","summary":"Let $\\mu$ be a probability measure on $\\mathbb{R}$. We give conditions on the\nFourier transform of its density for functionals of the form\n$H(a)=\\int_{\\mathbb{R}^n}h(\\langle a,x\\rangle)\\mu^n(dx)$ to be Schur monotone.\nAs applications, we put certain known and new results under the same umbrella,\ngiven by a condition on the Fourier transform of the density. These results\ninclude certain moment comparisons for independent and identically distributed\nrandom vectors, when the norm is given by intersection bodies, and the\ncorresponding vector Khinchin inequalities. We also extend the discussion to\nhigher dimensions.","main_category":"math.PR","categories":"math.PR,math.FA","published":"2025-04-08T16:16:55Z"}
{"aid":"http://arxiv.org/abs/2504.06183v1","title":"Primordial Features in light of the Effective Field Theory of Large\n  Scale Structure","summary":"While the simplest inflationary models predict a power-law form of the\nprimordial power spectrum (PPS), various UV complete scenarios predict features\non top of the standard power law that leave characteristic imprints in the\nlate-time distribution of matter, encoded in the galaxy power spectrum. In this\nwork, we assess the validity of the Effective Field Theory of Large Scale\nStructure (EFTofLSS) and the IR-resummation scheme of PyBird in the context of\nprimordial (oscillatory) features. We find an excellent agreement at the level\nof the matter power spectrum between N-body simulations and the one-loop EFT\npredictions, for models commonly studied in the literature. We then apply the\nEFTofLSS to the galaxy power spectrum measurements from BOSS LRG and eBOSS QSO\nto constrain specific global and local features in the PPS. We demonstrate that\nwhile such features can improve the fit to cosmic microwave background (CMB)\ndata, they may result in a poorer fit to clustering measurements at low\nredshift. The resulting constraints on the amplitude of the primordial\noscillations are competitive with those obtained from CMB data, despite the\nwell-known damping of oscillations due to non-linear structure formation\nprocesses. For the first time in this context, we jointly analyze the galaxy\npower spectrum (monopole and quadrupole) in combination with Planck CMB data to\nderive strong constraints on the amplitude of primordial features. This work\nhighlights the EFTofLSS as a powerful tool for testing early universe scenarios\non scales that complement CMB observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-08T16:23:36Z"}
{"aid":"http://arxiv.org/abs/2504.06190v1","title":"No-scale supergravity","summary":"To connect supergravity with the real world, a highly non-trivial requirement\nis complete spontaneous supersymmetry breaking in an approximately flat\nfour-dimensional space-time. In no-scale supergravity models, this naturally\nhappens at the classical level: the gravitino mass, setting the scale of\nsupersymmetry breaking, slides along a flat direction of the potential with\nvanishing energy. This contribution briefly describes, with a personal\nselection of simple illustrative examples, some qualitative features of\nno-scale models that relate them to a possible dynamical generation of the\nhierarchies between the vacuum energy scale, the weak scale and the Planck\nscale. It includes comments on their versions with extended supersymmetry, on\ntheir higher-dimensional origin and on how their still unsolved problems of\nquantum stability can already be addressed, with some results, at the level of\nsupergravity compactifications, although their solution (if any) will\neventually require a better understanding of superstring theories.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T16:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.06213v1","title":"Guidelines for designs for ultrastable laser with $\\mathbf{10^{-17}}$\n  fractional frequency instability","summary":"Lasers with long coherence time and narrow linewidth are an essential tool\nfor quantum sensors and clocks. Ultrastable cavities and laser systems are now\ncommercially available with fractional frequency instabilities in the mid\n$10^{-16}$ range. This document aims to provide technical guidance for\nresearchers starting in the field of ultrastable lasers and to give an outlook\ntoward the next generation of improved ultrastable lasers. These guidelines\nhave arisen from the scope of the EMPIR project ``Next generation ultrastable\nlasers'' ( https://www.ptb.de/empir2021/nextlasers ) with contributions from\nthe European project partners.","main_category":"physics.optics","categories":"physics.optics,physics.ins-det","published":"2025-04-08T16:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.06246v1","title":"Appearance of Multiple Spectral Gaps in Voltage-Biased Josephson\n  Junctions Without Floquet Hybridization","summary":"A time-periodic drive enables the engineering of non-equilibrium quantum\nsystems by hybridizing Floquet sidebands. We investigated DC voltage-biased\nplanar Josephson junctions built upon epitaxial Al/InAs heterostructures in\nwhich the intrinsic AC Josephson effect is theoretically expected to provide a\ntime-periodic drive leading to Floquet hybridization. Tunneling spectroscopy is\nperformed using probes positioned at the ends of the junction to study the\nevolution of the local density of states. With applied drive, we observe\nmultiple coherence peaks which are studied as a function of DC voltage bias and\nin-plane magnetic field. Our analysis suggests that these spectral gaps arise\nfrom a direct mesoscopic coupling between the tunneling probe and the\nsuperconducting leads rather than from a Floquet-driven gap opening. Our\nnumerical simulations indicate that an increase in the ratio of junction width\nto coherence length will enhance the contribution of Floquet hybridization.\nThis work lays a foundation for the exploration of Floquet physics utilizing\nvoltage-biased hybrid superconductor-semiconductor Josephson junctions and\nprovides means for distinguishing direct couplings from genuine Floquet\neffects.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-08T17:44:06Z"}
{"aid":"http://arxiv.org/abs/2504.06248v1","title":"Kuramoto meets Koopman: Constants of motion, symmetries, and network\n  motifs","summary":"The partial integrability of the Kuramoto model is often thought to be\nrestricted to identically connected oscillators or groups thereof. Yet, the\nexact connectivity prerequisites for having constants of motion on more general\ngraphs have remained elusive. Using spectral properties of the Koopman\ngenerator, we derive necessary and sufficient conditions for the existence of\ndistinct constants of motion in the Kuramoto model with heterogeneous phase\nlags on any weighted, directed, signed graph. This reveals a broad class of\nnetwork motifs that support conserved quantities. Furthermore, we identify Lie\nsymmetries that generate new constants of motion. Our results provide a\nrigorous theoretical application of Koopman's framework to nonlinear dynamics\non complex networks.","main_category":"nlin.AO","categories":"nlin.AO,math-ph,math.MP,nlin.SI","published":"2025-04-08T17:53:08Z"}
{"aid":"http://arxiv.org/abs/2504.06250v1","title":"Fractal and Regular Geometry of Deep Neural Networks","summary":"We study the geometric properties of random neural networks by investigating\nthe boundary volumes of their excursion sets for different activation\nfunctions, as the depth increases. More specifically, we show that, for\nactivations which are not very regular (e.g., the Heaviside step function), the\nboundary volumes exhibit fractal behavior, with their Hausdorff dimension\nmonotonically increasing with the depth. On the other hand, for activations\nwhich are more regular (e.g., ReLU, logistic and $\\tanh$), as the depth\nincreases, the expected boundary volumes can either converge to zero, remain\nconstant or diverge exponentially, depending on a single spectral parameter\nwhich can be easily computed. Our theoretical results are confirmed in some\nnumerical experiments based on Monte Carlo simulations.","main_category":"math.PR","categories":"math.PR,cs.LG,stat.ML","published":"2025-04-08T17:56:05Z"}
{"aid":"http://arxiv.org/abs/2504.06258v1","title":"Two-Dimensional Ferroelectric Altermagnets: From Model to Material\n  Realization","summary":"Multiferroic altermagnets offer new opportunities for magnetoelectric\ncoupling and electrically tunable spintronics. However, due to intrinsic\nsymmetry conflicts between altermagnetism and ferroelectricity, achieving their\ncoexistence, known as ferroelectric altermagnets (FEAM), remains an outstanding\nchallenge, especially in two-dimensional (2D) systems. Here, we propose a\nuniversal, symmetry-based design principle for 2D FEAM, supported by\ntight-binding models and first-principles calculations. We show that\nferroelectric lattice distortions can break spin equivalence and introduce the\nnecessary rotational symmetry, enabling altermagnetism with electrically\nreversible spin splitting. Guided by this framework, we identify a family of 2D\nvanadium oxyhalides and sulfide halides as promising FEAM candidates. In these\ncompounds, pseudo Jahn-Teller distortions and Peierls-like dimerization\ncooperatively establish the required symmetry conditions. We further propose\nthe magneto-optical Kerr effect as an experimental probe to confirm FEAM and\nits electric spin reversal. Our findings provide a practical framework for 2D\nFEAM and advancing electrically controlled spintronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.06259v1","title":"Realization and Calibration of Continuously Parameterized Two-Qubit\n  Gates on a Trapped-Ion Quantum Processor","summary":"Continuously parameterized two-qubit gates are a key feature of\nstate-of-the-art trapped-ion quantum processors as they have favorable error\nscalings and show distinct improvements in circuit performance over more\nrestricted maximally entangling gatesets. In this work, we provide a\ncomprehensive and pedagogical discussion on how to practically implement these\ncontinuously parameterized M{\\o}lmer-S{\\o}rensen gates on the Quantum\nScientific Computing Open User Testbed (QSCOUT), a low-level trapped-ion\nprocessor. To generate the arbitrary entangling angles, $\\theta$, we simply\nscale the amplitude of light used to generate the entanglement. However, doing\nso requires careful consideration of amplifier saturation as well as the\nvariable light shifts that result. As such, we describe a method to calibrate\nand cancel the dominant fourth-order effects, followed by a dynamic virtual\nphase advance during the gate to cancel any residual light shifts, and find a\nlinear scaling between $\\theta$ and the residual light shift. Once, we have\nconsidered and calibrated these effects, we demonstrate performance improvement\nwith decreasing $\\theta$. Finally, we describe nuances of hardware control to\ntransform the XX-type interaction of the arbitrary-angle M{\\o}lmer-S{\\o}rensen\ngate into a phase-agnostic and crosstalk-mitigating ZZ interaction.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T17:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.06264v1","title":"D^2USt3R: Enhancing 3D Reconstruction with 4D Pointmaps for Dynamic\n  Scenes","summary":"We address the task of 3D reconstruction in dynamic scenes, where object\nmotions degrade the quality of previous 3D pointmap regression methods, such as\nDUSt3R, originally designed for static 3D scene reconstruction. Although these\nmethods provide an elegant and powerful solution in static settings, they\nstruggle in the presence of dynamic motions that disrupt alignment based solely\non camera poses. To overcome this, we propose D^2USt3R that regresses 4D\npointmaps that simultaneiously capture both static and dynamic 3D scene\ngeometry in a feed-forward manner. By explicitly incorporating both spatial and\ntemporal aspects, our approach successfully encapsulates spatio-temporal dense\ncorrespondence to the proposed 4D pointmaps, enhancing downstream tasks.\nExtensive experimental evaluations demonstrate that our proposed approach\nconsistently achieves superior reconstruction performance across various\ndatasets featuring complex motions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.06265v1","title":"GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning\n  through Bayesian Optimization","summary":"Large Language Models (LLMs) can encode complex relationships in their latent\nspaces, yet harnessing them for optimization under uncertainty remains\nchallenging. We address this gap with a novel architecture that reframes LLM\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\nto preserve the benefits of both - LLMs to provide a rich and flexible input\nspace for Bayesian optimization and - GPs to model this space with predictive\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\noptimization, our method nearly doubles the discovery rate of high-performing\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\nimprovement over domain-specific representations without requiring specialized\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\ngeneral chemistry to reaction and molecular property optimization -\ndemonstrates our method's robustness, generality, and consistent improvements\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\nthese improvements: joint LLM-GP optimization through marginal likelihood\nimplicitly performs contrastive learning, aligning representations to produce\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\nand (3) more efficient sampling - without requiring any external loss. This\nwork provides both practical advances in sample-efficient optimization and\ninsights into what makes effective Bayesian optimization.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.06545v1","title":"Radio emission across the entire rotation phases of pulsars","summary":"Super-sensitive observations of bright pulsars by the Five-hundred-meter\nAperture Spherical radio Telescope (FAST) have revealed weak radio emission\ncontinuously emerged in the rotation phases between the main pulse and\ninterpulse of an rotating neutron star. We develop a model for the polarized\nradio emission radiated from different heights in the pulsar magnetosphere and\nexamine emission intensity distribution over the whole rotation phases of\npulsars seen from all directions by the line of sight. We find that for pulsars\nwith small periods and the magnetosphere filled with much more relativistic\nparticles, the polarized radio emission can be generated in all rotation phases\nfor both the aligned and perpendicular rotating neutron stars. When the line of\nsight cuts the pulsar emission beam between the rotation and magnetic axes, the\npolarization angles have the same sense of variation gradient for the ``main''\npulse and ``interpulse''. If the line of sight cuts the beams between the\ninclined magnetic axis and the equator, the opposite senses can be found for\nthe main pulse and interpulse. In addition to the pulsed emission, we find\npersistent radio emission generated in the pulsar magnetosphere. The model can\nnaturally explain the emission across the entire rotation phases.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T03:00:39Z"}
{"aid":"http://arxiv.org/abs/2504.06548v1","title":"Artificial Spin Ice: A Tutorial on Design and Control of Geometry,\n  Microstate, Magnon Dynamics & Neuromorphic Computing","summary":"Artificial spin ice, arrays of strongly interacting nanomagnets, are complex\nmagnetic systems with many emergent properties, rich microstate spaces,\nintrinsic physical memory, high-frequency dynamics in the GHz range and\ncompatibility with a broad range of measurement approaches. This tutorial\narticle aims to provide the foundational knowledge needed to understand,\ndesign, develop, and improve the dynamic properties of artificial spin ice\n(ASI). Special emphasis is placed on introducing the theory of micromagnetics,\nwhich describes the complex dynamics within these systems, along with their\ndesign, fabrication methods, and standard measurement and control techniques.\nThe article begins with a review of the historical background, introducing the\nunderlying physical phenomena and interactions that govern artificial spin ice.\nWe then explore standard experimental techniques used to prepare the microstate\nspace of the nanomagnetic array and to characterize magnetization dynamics,\nboth in artificial spin ice and more broadly in ferromagnetic materials.\nFinally, we introduce the basics of neuromorphic computing applied to the case\nof artificial spin ice systems with goal to help researchers new to the field\ngrasp these exciting new developments.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.dis-nn,cond-mat.mtrl-sci","published":"2025-04-09T03:07:07Z"}
{"aid":"http://arxiv.org/abs/2504.06550v1","title":"Blameocracy: Causal Attribution in Political Communication","summary":"We propose a supervised method to detect causal attribution in political\ntexts, distinguishing between expressions of merit and blame. Analyzing four\nmillion tweets shared by U.S. Congress members from 2012 to 2023, we document a\npronounced shift toward causal attribution following the 2016 presidential\nelection. The shift reflects changes in rhetorical strategy rather than\ncompositional variation in the actors or topics of the political debate. Within\ncausal communication, a trade-off emerges between positive and negative tone,\nwith power status as the key determinant: government emphasizes merit, while\nopposition casts blame. This pattern distinguishes causal from purely affective\ncommunication. Additionally, we find that blame is associated with lower trust\nin politicians, perceived government effectiveness, and spreads more virally\nthan merit.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-09T03:12:16Z"}
{"aid":"http://arxiv.org/abs/2504.06551v1","title":"Bridging Queries and Tables through Entities in Table Retrieval","summary":"Table retrieval is essential for accessing information stored in structured\ntabular formats; however, it remains less explored than text retrieval. The\ncontent of the table primarily consists of phrases and words, which include a\nlarge number of entities, such as time, locations, persons, and organizations.\nEntities are well-studied in the context of text retrieval, but there is a\nnoticeable lack of research on their applications in table retrieval. In this\nwork, we explore how to leverage entities in tables to improve retrieval\nperformance. First, we investigate the important role of entities in table\nretrieval from a statistical perspective and propose an entity-enhanced\ntraining framework. Subsequently, we use the type of entities to highlight\nentities instead of introducing an external knowledge base. Moreover, we design\nan interaction paradigm based on entity representations. Our proposed framework\nis plug-and-play and flexible, making it easy to integrate into existing table\nretriever training processes. Empirical results on two table retrieval\nbenchmarks, NQ-TABLES and OTT-QA, show that our proposed framework is both\nsimple and effective in enhancing existing retrievers. We also conduct\nextensive analyses to confirm the efficacy of different components. Overall,\nour work provides a promising direction for elevating table retrieval,\nenlightening future research in this area.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T03:16:33Z"}
{"aid":"http://arxiv.org/abs/2504.06556v1","title":"Improved Bounds for Codes over Trees","summary":"Codes over trees were introduced recently to bridge graph theory and coding\ntheory with diverse applications in computer science and beyond. A central\nchallenge lies in determining the maximum number of labelled trees over $n$\nnodes with pairwise distance at least $d$, denoted by $A(n,d)$, where the\ndistance between any two labelled trees is the minimum number of edit edge\noperations in order to transform one tree to another. By various tools from\ngraph theory and algebra, we show that when $n$ is large,\n$A(n,d)=O((Cn)^{n-d})$ for any $d\\leq n-2$, and $A(n,d)=\\Omega((cn)^{n-d})$ for\nany $d$ linear with $n$, where constants $c\\in(0,1)$ and $C\\in [1/2,1)$\ndepending on $d$. Previously, only $A(n,d)=O(n^{n-d-1})$ for fixed $d$ and\n$A(n,d)=\\Omega(n^{n-2d})$ for $d\\leq n/2$ were known, while the upper bound is\nimproved for any $d$ and the lower bound is improved for $d\\geq 2\\sqrt{n}$.\nFurther, for any fixed integer $k$, we prove the existence of codes of size\n$\\Omega(n^k)$ when $n-d=o(n)$, and give explicit constructions of codes which\nshow $A(n,n-4)=\\Omega(n^2)$ and $A(n,n-13)=\\Omega(n^3)$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T03:35:21Z"}
{"aid":"http://arxiv.org/abs/2504.06564v1","title":"Do Reasoning Models Show Better Verbalized Calibration?","summary":"Large reasoning models (LRMs) have recently shown impressive capabilities in\ncomplex reasoning by leveraging increased test-time computation and exhibiting\nbehaviors akin to human-like deliberation. Despite these advances, it remains\nan open question whether LRMs are better calibrated - particularly in their\nverbalized confidence - compared to instruction-tuned counterparts. In this\npaper, we investigate the calibration properties of LRMs trained via supervised\nfine-tuning distillation on long reasoning traces (henceforth SFT reasoning\nmodels) and outcome-based reinforcement learning for reasoning (henceforth RL\nreasoning models) across diverse domains. Our findings reveal that LRMs\nsignificantly outperform instruction-tuned models on complex reasoning tasks in\nboth accuracy and confidence calibration. In contrast, we find surprising\ntrends in the domain of factuality in particular. On factuality tasks, while\nDeepseek-R1 shows strong calibration behavior, smaller QwQ-32B shows no\nimprovement over instruct models; moreover, SFT reasoning models display worse\ncalibration (greater overconfidence) compared to instruct models. Our results\nprovide evidence for a potentially critical role of reasoning-oriented RL\ntraining in improving LLMs' capacity for generating trustworthy, self-aware\noutputs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.06569v1","title":"An Unbiased Variance Estimator with Denominator $N$","summary":"Standard practice obtains an unbiased variance estimator by dividing by $N-1$\nrather than $N$. Yet if only half the data are used to compute the mean,\ndividing by $N$ can still yield an unbiased estimator. We show that an\nalternative mean estimator $\\hat{X} = \\sum c_n X_n$ can produce such an\nunbiased variance estimator with denominator $N$. These average-adjusted\nunbiased variance (AAUV) permit infinitely many unbiased forms, though each has\nlarger variance than the usual sample variance. Moreover, permuting and\nsymmetrizing any AAUV recovers the classical formula with denominator $N-1$. We\nfurther demonstrate a continuum of unbiased variances by interpolating between\nthe standard and AAUV-based means. Extending this average-adjusting method to\nhigher-order moments remains a topic for future work.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-09T04:08:45Z"}
{"aid":"http://arxiv.org/abs/2504.06577v1","title":"Bypassing Safety Guardrails in LLMs Using Humor","summary":"In this paper, we show it is possible to bypass the safety guardrails of\nlarge language models (LLMs) through a humorous prompt including the unsafe\nrequest. In particular, our method does not edit the unsafe request and follows\na fixed template -- it is simple to implement and does not need additional LLMs\nto craft prompts. Extensive experiments show the effectiveness of our method\nacross different LLMs. We also show that both removing and adding more humor to\nour method can reduce its effectiveness -- excessive humor possibly distracts\nthe LLM from fulfilling its unsafe request. Thus, we argue that LLM\njailbreaking occurs when there is a proper balance between focus on the unsafe\nrequest and presence of humor.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-09T04:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.06578v1","title":"Attributes-aware Visual Emotion Representation Learning","summary":"Visual emotion analysis or recognition has gained considerable attention due\nto the growing interest in understanding how images can convey rich semantics\nand evoke emotions in human perception. However, visual emotion analysis poses\ndistinctive challenges compared to traditional vision tasks, especially due to\nthe intricate relationship between general visual features and the different\naffective states they evoke, known as the affective gap. Researchers have used\ndeep representation learning methods to address this challenge of extracting\ngeneralized features from entire images. However, most existing methods\noverlook the importance of specific emotional attributes such as brightness,\ncolorfulness, scene understanding, and facial expressions. Through this paper,\nwe introduce A4Net, a deep representation network to bridge the affective gap\nby leveraging four key attributes: brightness (Attribute 1), colorfulness\n(Attribute 2), scene context (Attribute 3), and facial expressions (Attribute\n4). By fusing and jointly training all aspects of attribute recognition and\nvisual emotion analysis, A4Net aims to provide a better insight into emotional\ncontent in images. Experimental results show the effectiveness of A4Net,\nshowcasing competitive performance compared to state-of-the-art methods across\ndiverse visual emotion datasets. Furthermore, visualizations of activation maps\ngenerated by A4Net offer insights into its ability to generalize across\ndifferent visual emotion datasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.MM","published":"2025-04-09T05:00:43Z"}
{"aid":"http://arxiv.org/abs/2504.06579v1","title":"Coherence-decoherence interplay in quantum systems due to projective\n  stochastic pulses: The case of Rabi oscillations","summary":"The interplay of coherence and decoherence is played out in a three-level\nquantum system, in which the third level is incoherently coupled to the second\none which itself is in coherent interaction with the first level. The study is\nbased on a stochastic scenario in which the coherent, unitary evolution of the\nsystem is randomly interrupted by a Poisson-driven pulse sequence. In the\nabsence of an external pulse, the system undergoes coherent, unitary evolution\nrestricted to the subspace spanned by the first level (level $1$) and the\nsecond level (level $2$). The application of a pulse induces transitions\nbetween the second and the third level (level $3$), thereby introducing\nnon-unitary effects that perturb the otherwise isolated two-level dynamics. The\npulses are assumed to have infinitesimal duration, with strengths modeled as\nrandom variables that are uncorrelated across different pulses. A\nrepresentative model for the stochastically-averaged transition (super)operator\nmimicking the dynamics induced by the application of pulses allows for an\nanalytical derivation of the matrix elements of the averaged density operator.\nWhen the system is initially in level $1$, we obtain in particular the temporal\nbehavior of the stay-put probability, that is, the probability $P_1(t)$ that\nthe system is still in level $1$ at time $t$. As a function of time, the\nquantity $P_1(t)$ exhibits a coherence-to-decoherence crossover behavior. At\nshort times $t \\ll 1/\\lambda$, where $\\lambda$ is the average frequency at\nwhich pulses are applied to the system, coherent dynamics dominate.\nConsequently, $P_1(t)$ displays pronounced Rabi-like oscillations. At long\ntimes $t \\gg 1/\\lambda$, decoherence effects prevail, leading to an exponential\ndecay of the form $P_1(t) \\sim \\exp(-\\lambda t)$.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-09T05:02:08Z"}
{"aid":"http://arxiv.org/abs/2504.06581v1","title":"Right Prediction, Wrong Reasoning: Uncovering LLM Misalignment in RA\n  Disease Diagnosis","summary":"Large language models (LLMs) offer a promising pre-screening tool, improving\nearly disease detection and providing enhanced healthcare access for\nunderprivileged communities. The early diagnosis of various diseases continues\nto be a significant challenge in healthcare, primarily due to the nonspecific\nnature of early symptoms, the shortage of expert medical practitioners, and the\nneed for prolonged clinical evaluations, all of which can delay treatment and\nadversely affect patient outcomes. With impressive accuracy in prediction\nacross a range of diseases, LLMs have the potential to revolutionize clinical\npre-screening and decision-making for various medical conditions. In this work,\nwe study the diagnostic capability of LLMs for Rheumatoid Arthritis (RA) with\nreal world patients data. Patient data was collected alongside diagnoses from\nmedical experts, and the performance of LLMs was evaluated in comparison to\nexpert diagnoses for RA disease prediction. We notice an interesting pattern in\ndisease diagnosis and find an unexpected \\textit{misalignment between\nprediction and explanation}. We conduct a series of multi-round analyses using\ndifferent LLM agents. The best-performing model accurately predicts rheumatoid\narthritis (RA) diseases approximately 95\\% of the time. However, when medical\nexperts evaluated the reasoning generated by the model, they found that nearly\n68\\% of the reasoning was incorrect. This study highlights a clear misalignment\nbetween LLMs high prediction accuracy and its flawed reasoning, raising\nimportant questions about relying on LLM explanations in clinical settings.\n\\textbf{LLMs provide incorrect reasoning to arrive at the correct answer for RA\ndisease diagnosis.}","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-09T05:04:01Z"}
{"aid":"http://arxiv.org/abs/2504.06593v1","title":"A Multi-Modal Interaction Framework for Efficient Human-Robot\n  Collaborative Shelf Picking","summary":"The growing presence of service robots in human-centric environments, such as\nwarehouses, demands seamless and intuitive human-robot collaboration. In this\npaper, we propose a collaborative shelf-picking framework that combines\nmultimodal interaction, physics-based reasoning, and task division for enhanced\nhuman-robot teamwork.\n  The framework enables the robot to recognize human pointing gestures,\ninterpret verbal cues and voice commands, and communicate through visual and\nauditory feedback. Moreover, it is powered by a Large Language Model (LLM)\nwhich utilizes Chain of Thought (CoT) and a physics-based simulation engine for\nsafely retrieving cluttered stacks of boxes on shelves, relationship graph for\nsub-task generation, extraction sequence planning and decision making.\nFurthermore, we validate the framework through real-world shelf picking\nexperiments such as 1) Gesture-Guided Box Extraction, 2) Collaborative Shelf\nClearing and 3) Collaborative Stability Assistance.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-09T05:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.06626v1","title":"Localization of deformation in the central hub of hub-and-spoke kirigami","summary":"A recent approach to the design of flexible electronic devices consists of\ncutting a two-dimensional sheet to form a central hub connected to several\ntapered `spokes', resembling the hub-and-spoke of a bicycle wheel. When\nradially compressed, the resulting cut sheet buckles out-of-plane forming a\nstructure whose three-dimensional shape can be chosen by designing the tapering\nof the spokes. While the deformation of the spokes in this `hub-and-spoke'\nkirigami are approximately cylindrical (i.e.~zero Gaussian curvature and hence\nsmall elastic strain), this is not the case in the central hub. The central hub\nis deformed radially because of continuity with the spokes but, because of its\nown circular symmetry, it must develop Gaussian curvature, and hence strain. In\nthis article we quantify this strain, focussing in particular on its magnitude\nand its location. We find that the strain is localized in a boundary layer near\nthe edge of the hub region, whose size is controlled by the moment applied on\nit by the deformed spokes. We discuss the implications of our results for\navoiding material failure in flexible-electronic devices.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-04-09T07:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.06635v1","title":"On BPS Equations of Generalized $SU(2)$ Yang-Mills-Higgs Model with\n  Scalars-Dependent Coupling $Î¸$-term","summary":"We consider a most general $SU(2)$ Yang-Mills-Higgs model consist of terms up\nto quadratic in first-derivative of the fields, that is the generalized $SU(2)$\nYang-Mills-Higgs with additional scalars-dependent coupling $\\theta$-term.\nUsing the BPS Lagrangian method we try to find Bogomolnyi's equations for BPS\nmonopoles and dyons by taking most general BPS Lagrangian density. We obtain\nmore general Bogomolnyi's equations and a relation between all scalars\ndependent couplings. Interestingly we find the value of $\\theta$-term's\ncoupling gives additional contribution to electric charge of BPS Dyons, and\nthus can determine whether we get BPS monopoles or BPS dyons.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-09T07:17:51Z"}
{"aid":"http://arxiv.org/abs/2504.06636v1","title":"BBQRec: Behavior-Bind Quantization for Multi-Modal Sequential\n  Recommendation","summary":"Multi-modal sequential recommendation systems leverage auxiliary signals\n(e.g., text, images) to alleviate data sparsity in user-item interactions.\nWhile recent methods exploit large language models to encode modalities into\ndiscrete semantic IDs for autoregressive prediction, we identify two critical\nlimitations: (1) Existing approaches adopt fragmented quantization, where\nmodalities are independently mapped to semantic spaces misaligned with\nbehavioral objectives, and (2) Over-reliance on semantic IDs disrupts\ninter-modal semantic coherence, thereby weakening the expressive power of\nmulti-modal representations for modeling diverse user preferences.\n  To address these challenges, we propose a Behavior-Bind multi-modal\nQuantization for Sequential Recommendation (BBQRec for short) featuring\ndual-aligned quantization and semantics-aware sequence modeling. First, our\nbehavior-semantic alignment module disentangles modality-agnostic behavioral\npatterns from noisy modality-specific features through contrastive codebook\nlearning, ensuring semantic IDs are inherently tied to recommendation tasks.\nSecond, we design a discretized similarity reweighting mechanism that\ndynamically adjusts self-attention scores using quantized semantic\nrelationships, preserving multi-modal synergies while avoiding invasive\nmodifications to the sequence modeling architecture. Extensive evaluations\nacross four real-world benchmarks demonstrate BBQRec's superiority over the\nstate-of-the-art baselines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T07:19:48Z"}
{"aid":"http://arxiv.org/abs/2504.06640v1","title":"Design and use of devices to assist movement of the upper limb: review\n  of the literature","summary":"This article explores assistive devices for upper limb movement in people\nwith disabilities through a systematic review based on the PRISMA methodology.\nThe studied devices encompass technologies ranging from orthoses to advanced\nrobotics, aiming to compensate for or supplement motor impairments. The results\nhighlight the diversity of applications (rehabilitation, daily living\nactivities), targeted body segments (distal, proximal, or global), as well as\ncontrol mechanisms and interfaces used. However, despite the variety of\npromising prototypes, few devices are commercially available, limiting their\nreal impact on end users. Existing technologies, while effective in improving\nfunctional autonomy and quality of life, still face challenges in terms of\nergonomics, cost, and portability. In conclusion, this article emphasizes the\nimportance of a user-centered approach and proposes avenues for the development\nof innovative, modular, and accessible assistive devices.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:32:02Z"}
{"aid":"http://arxiv.org/abs/2504.06641v1","title":"A remark on shadowing and the dimension of periodic points","summary":"We show that if a continuous self-map of a compact metric space is\nh-expansive and has the shadowing property, then the set of periodic points is\nzero-dimensional if not empty.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T07:32:03Z"}
{"aid":"http://arxiv.org/abs/2504.06643v1","title":"AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series\n  Anomaly Detection","summary":"Unsupervised multivariate time series anomaly detection (UMTSAD) plays a\ncritical role in various domains, including finance, networks, and sensor\nsystems. In recent years, due to the outstanding performance of deep learning\nin general sequential tasks, many models have been specialized for deep UMTSAD\ntasks and have achieved impressive results, particularly those based on the\nTransformer and self-attention mechanisms. However, the sequence anomaly\nassociation assumptions underlying these models are often limited to specific\npredefined patterns and scenarios, such as concentrated or peak anomaly\npatterns. These limitations hinder their ability to generalize to diverse\nanomaly situations, especially where the lack of labels poses significant\nchallenges. To address these issues, we propose AMAD, which integrates\n\\textbf{A}uto\\textbf{M}asked Attention for UMTS\\textbf{AD} scenarios. AMAD\nintroduces a novel structure based on the AutoMask mechanism and an attention\nmixup module, forming a simple yet generalized anomaly association\nrepresentation framework. This framework is further enhanced by a Max-Min\ntraining strategy and a Local-Global contrastive learning approach. By\ncombining multi-scale feature extraction with automatic relative association\nmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.\nExtensive experimental results demonstrate that the proposed model achieving\ncompetitive performance results compared to SOTA benchmarks across a variety of\ndatasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI,I.5.1","published":"2025-04-09T07:32:59Z"}
{"aid":"http://arxiv.org/abs/2504.06647v1","title":"Uni-PrevPredMap: Extending PrevPredMap to a Unified Framework of\n  Prior-Informed Modeling for Online Vectorized HD Map Construction","summary":"Safety constitutes a foundational imperative for autonomous driving systems,\nnecessitating the maximal incorporation of accessible external prior\ninformation. This study establishes that temporal perception buffers and\ncost-efficient maps inherently form complementary prior sources for online\nvectorized high-definition (HD) map construction. We present Uni-PrevPredMap, a\nunified prior-informed framework that systematically integrates two synergistic\ninformation sources: previous predictions and simulated outdated HD maps. The\nframework introduces two core innovations: a tile-indexed 3D vectorized global\nmap processor enabling efficient refreshment, storage, and retrieval of 3D\nvectorized priors; a tri-mode operational optimization paradigm ensuring\nconsistency across prior-free, map-absent, and map-prior scenarios while\nmitigating reliance on idealized map fidelity assumptions. Uni-PrevPredMap\nachieves state-of-the-art performance in map-free scenarios across established\nonline vectorized HD map construction benchmarks. When provided with simulated\noutdated HD maps, the framework exhibits robust capabilities in error-resilient\nprior fusion, empirically confirming the synergistic complementarity between\nprevious predictions and simulated outdated HD maps. Code will be available at\nhttps://github.com/pnnnnnnn/Uni-PrevPredMap.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:36:17Z"}
{"aid":"http://arxiv.org/abs/2504.06649v1","title":"GRAIN: Multi-Granular and Implicit Information Aggregation Graph Neural\n  Network for Heterophilous Graphs","summary":"Graph neural networks (GNNs) have shown significant success in learning graph\nrepresentations. However, recent studies reveal that GNNs often fail to\noutperform simple MLPs on heterophilous graph tasks, where connected nodes may\ndiffer in features or labels, challenging the homophily assumption. Existing\nmethods addressing this issue often overlook the importance of information\ngranularity and rarely consider implicit relationships between distant nodes.\nTo overcome these limitations, we propose the Granular and Implicit Graph\nNetwork (GRAIN), a novel GNN model specifically designed for heterophilous\ngraphs. GRAIN enhances node embeddings by aggregating multi-view information at\nvarious granularity levels and incorporating implicit data from distant,\nnon-neighboring nodes. This approach effectively integrates local and global\ninformation, resulting in smoother, more accurate node representations. We also\nintroduce an adaptive graph information aggregator that efficiently combines\nmulti-granularity and implicit data, significantly improving node\nrepresentation quality, as shown by experiments on 13 datasets covering varying\nhomophily and heterophily. GRAIN consistently outperforms 12 state-of-the-art\nmodels, excelling on both homophilous and heterophilous graphs.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T07:36:44Z"}
{"aid":"http://arxiv.org/abs/2504.06658v1","title":"A Neuro-inspired Interpretation of Unlearning in Large Language Models\n  through Sample-level Unlearning Difficulty","summary":"Driven by privacy protection laws and regulations, unlearning in Large\nLanguage Models (LLMs) is gaining increasing attention. However, current\nresearch often neglects the interpretability of the unlearning process,\nparticularly concerning sample-level unlearning difficulty. Existing studies\ntypically assume a uniform unlearning difficulty across samples. This\nsimplification risks attributing the performance of unlearning algorithms to\nsample selection rather than the algorithm's design, potentially steering the\ndevelopment of LLM unlearning in the wrong direction. Thus, we investigate the\nrelationship between LLM unlearning and sample characteristics, with a focus on\nunlearning difficulty. Drawing inspiration from neuroscience, we propose a\nMemory Removal Difficulty ($\\mathrm{MRD}$) metric to quantify sample-level\nunlearning difficulty. Using $\\mathrm{MRD}$, we analyze the characteristics of\nhard-to-unlearn versus easy-to-unlearn samples. Furthermore, we propose an\n$\\mathrm{MRD}$-based weighted sampling method to optimize existing unlearning\nalgorithms, which prioritizes easily forgettable samples, thereby improving\nunlearning efficiency and effectiveness. We validate the proposed metric and\nmethod using public benchmarks and datasets, with results confirming its\neffectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-09T07:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.06672v1","title":"RAGME: Retrieval Augmented Video Generation for Enhanced Motion Realism","summary":"Video generation is experiencing rapid growth, driven by advances in\ndiffusion models and the development of better and larger datasets. However,\nproducing high-quality videos remains challenging due to the high-dimensional\ndata and the complexity of the task. Recent efforts have primarily focused on\nenhancing visual quality and addressing temporal inconsistencies, such as\nflickering. Despite progress in these areas, the generated videos often fall\nshort in terms of motion complexity and physical plausibility, with many\noutputs either appearing static or exhibiting unrealistic motion. In this work,\nwe propose a framework to improve the realism of motion in generated videos,\nexploring a complementary direction to much of the existing literature.\nSpecifically, we advocate for the incorporation of a retrieval mechanism during\nthe generation phase. The retrieved videos act as grounding signals, providing\nthe model with demonstrations of how the objects move. Our pipeline is designed\nto apply to any text-to-video diffusion model, conditioning a pretrained model\non the retrieved samples with minimal fine-tuning. We demonstrate the\nsuperiority of our approach through established metrics, recently proposed\nbenchmarks, and qualitative results, and we highlight additional applications\nof the framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.06674v1","title":"The row left rank of a quaternion unit gain graph in terms of maximum\n  degree","summary":"Let $\\Phi=(G,U(\\mathbb{Q}),\\varphi)$ be a quaternion unit gain graph (or\n$U(\\mathbb{Q})$-gain graph) of order $n$, $A(\\Phi)$ be the adjacency matrix of\n$\\Phi$ and $r(\\Phi)$ be the row left rank of $\\Phi$. Let $\\Delta$ be the\nmaximum degree of $\\Phi$. In this paper, we prove that\n$r(\\Phi)\\geq\\frac{n}{\\Delta}$. Moreover, if $\\Phi$ is connected, we obtain that\n$r(\\Phi)\\geq\\frac{n-2}{\\Delta-1}$. All the corresponding extremal graphs are\ncharacterized.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T08:20:01Z"}
{"aid":"http://arxiv.org/abs/2504.06679v1","title":"Some bounds for the eigenfunctions of the Stokes problem under Navier\n  boundary conditions in a cube","summary":"We prove some bounds for the eigenfunctions of the Stokes problem under\nNavier boundary conditions in a cube.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T08:35:51Z"}
{"aid":"http://arxiv.org/abs/2504.06688v1","title":"Efficient Timestamping for Sampling-based Race Detection","summary":"Dynamic race detection based on the happens before (HB) partial order has now\nbecome the de facto approach to quickly identify data races in multi-threaded\nsoftware. Most practical implementations for detecting these races use\ntimestamps to infer causality between events and detect races based on these\ntimestamps. Such an algorithm updates timestamps (stored in vector clocks) at\nevery event in the execution, and is known to induce excessive overhead. Random\nsampling has emerged as a promising algorithmic paradigm to offset this\noverhead. It offers the promise of making sound race detection scalable. In\nthis work we consider the task of designing an efficient sampling based race\ndetector with low overhead for timestamping when the number of sampled events\nis much smaller than the total events in an execution. To solve this problem,\nwe propose (1) a new notion of freshness timestamp, (2) a new data structure to\nstore timestamps, and (3) an algorithm that uses a combination of them to\nreduce the cost of timestamping in sampling based race detection. Further, we\nprove that our algorithm is close to optimal -- the number of vector clock\ntraversals is bounded by the number of sampled events and number of threads,\nand further, on any given dynamic execution, the cost of timestamping due to\nour algorithm is close to the amount of work any timestamping-based algorithm\nmust perform on that execution, that is it is instance optimal. Our evaluation\non real world benchmarks demonstrates the effectiveness of our proposed\nalgorithm over prior timestamping algorithms that are agnostic to sampling.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-09T08:49:24Z"}
{"aid":"http://arxiv.org/abs/2504.06694v1","title":"Comparison of Frobenius algebra structures on Calabi-Yau toric\n  hypersurfaces","summary":"We establish an isomorphism between two Frobenius algebra structures, termed\nCY and LG, on the primitive cohomology of a smooth Calabi--Yau hypersurface in\na simplicial Gorenstein toric Fano variety. As an application of our comparison\nisomorphism, we observe the existence of a Frobenius manifold structure on a\nfinite-dimensional subalgebra of the Jacobian algebra of a homogeneous\npolynomial which may exhibit a non-compact singularity locus.","main_category":"math.AG","categories":"math.AG,math-ph,math.MP","published":"2025-04-09T08:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.06698v1","title":"Emergent Metric from Wavelet-transformed Quantum Field Theory","summary":"We introduce a method of reverse holography by which a bulk metric is shown\nto arise from locally computable multiscale correlations of a boundary quantum\nfield theory (QFT). The metric is obtained from the Petz-R\\'enyi mutual\ninformation using as input the correlations computed from the continuous\nwavelet transform. We show for free massless fermionic and bosonic QFTs that\nthe emerging metric is asymptotically anti-de Sitter space (AdS), and that the\nparameters fixing the geometry are tunable by changing the chosen wavelet\nbasis. The method is applicable to a variety of boundary QFTs that need not be\nconformal field theories.","main_category":"hep-th","categories":"hep-th,quant-ph","published":"2025-04-09T09:04:54Z"}
{"aid":"http://arxiv.org/abs/2504.06710v1","title":"Clustering and novel class recognition: evaluating bioacoustic deep\n  learning feature extractors","summary":"In computational bioacoustics, deep learning models are composed of feature\nextractors and classifiers. The feature extractors generate vector\nrepresentations of the input sound segments, called embeddings, which can be\ninput to a classifier. While benchmarking of classification scores provides\ninsights into specific performance statistics, it is limited to species that\nare included in the models' training data. Furthermore, it makes it impossible\nto compare models trained on very different taxonomic groups. This paper aims\nto address this gap by analyzing the embeddings generated by the feature\nextractors of 15 bioacoustic models spanning a wide range of setups (model\narchitectures, training data, training paradigms). We evaluated and compared\ndifferent ways in which models structure embedding spaces through clustering\nand kNN classification, which allows us to focus our comparison on feature\nextractors independent of their classifiers. We believe that this approach lets\nus evaluate the adaptability and generalization potential of models going\nbeyond the classes they were trained on.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.06711v1","title":"Pogorelov type $C^2$ estimates for sum Hessian equations","summary":"In this paper, We establish Pogorelov type $C^2$ estimates for the admissible\nsolutions with $\\sigma_k(D^2u)$ bounded from below of Sum Hessian equations. We\nalso proved the lower bounded condition can be removed when $k = n$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.06712v1","title":"Large-Scale (Semi-)Automated Security Assessment of Consumer IoT Devices\n  -- A Roadmap","summary":"The Internet of Things (IoT) has rapidly expanded across various sectors,\nwith consumer IoT devices - such as smart thermostats and security cameras -\nexperiencing growth. Although these devices improve efficiency and promise\nadditional comfort, they also introduce new security challenges. Common and\neasy-to-explore vulnerabilities make IoT devices prime targets for malicious\nactors.\n  Upcoming mandatory security certifications offer a promising way to mitigate\nthese risks by enforcing best practices and providing transparency. Regulatory\nbodies are developing IoT security frameworks, but a universal standard for\nlarge-scale systematic security assessment is lacking. Existing manual testing\napproaches are expensive, limiting their efficacy in the diverse and rapidly\nevolving IoT domain.\n  This paper reviews current IoT security challenges and assessment efforts,\nidentifies gaps, and proposes a roadmap for scalable, automated security\nassessment, leveraging a model-based testing approach and machine learning\ntechniques to strengthen consumer IoT security.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T09:15:04Z"}
{"aid":"http://arxiv.org/abs/2504.06714v1","title":"Unifying Search and Recommendation: A Generative Paradigm Inspired by\n  Information Theory","summary":"Recommender systems and search engines serve as foundational elements of\nonline platforms, with the former delivering information proactively and the\nlatter enabling users to seek information actively. Unifying both tasks in a\nshared model is promising since it can enhance user modeling and item\nunderstanding. Previous approaches mainly follow a discriminative paradigm,\nutilizing shared encoders to process input features and task-specific heads to\nperform each task. However, this paradigm encounters two key challenges:\ngradient conflict and manual design complexity. From the information theory\nperspective, these challenges potentially both stem from the same issue -- low\nmutual information between the input features and task-specific outputs during\nthe optimization process.\n  To tackle these issues, we propose GenSR, a novel generative paradigm for\nunifying search and recommendation (S&R), which leverages task-specific prompts\nto partition the model's parameter space into subspaces, thereby enhancing\nmutual information. To construct effective subspaces for each task, GenSR first\nprepares informative representations for each subspace and then optimizes both\nsubspaces in one unified model. Specifically, GenSR consists of two main\nmodules: (1) Dual Representation Learning, which independently models\ncollaborative and semantic historical information to derive expressive item\nrepresentations; and (2) S&R Task Unifying, which utilizes contrastive learning\ntogether with instruction tuning to generate task-specific outputs effectively.\nExtensive experiments on two public datasets show GenSR outperforms\nstate-of-the-art methods across S&R tasks. Our work introduces a new generative\nparadigm compared with previous discriminative methods and establishes its\nsuperiority from the mutual information perspective.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T09:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.06721v1","title":"Learning global control of underactuated systems with Model-Based\n  Reinforcement Learning","summary":"This short paper describes our proposed solution for the third edition of the\n\"AI Olympics with RealAIGym\" competition, held at ICRA 2025. We employed\nMonte-Carlo Probabilistic Inference for Learning Control (MC-PILCO), an MBRL\nalgorithm recognized for its exceptional data efficiency across various\nlow-dimensional robotic tasks, including cart-pole, ball \\& plate, and Furuta\npendulum systems. MC-PILCO optimizes a system dynamics model using interaction\ndata, enabling policy refinement through simulation rather than direct system\ndata optimization. This approach has proven highly effective in physical\nsystems, offering greater data efficiency than Model-Free (MF) alternatives.\nNotably, MC-PILCO has previously won the first two editions of this\ncompetition, demonstrating its robustness in both simulated and real-world\nenvironments. Besides briefly reviewing the algorithm, we discuss the most\ncritical aspects of the MC-PILCO implementation in the tasks at hand: learning\na global policy for the pendubot and acrobot systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-09T09:20:37Z"}
{"aid":"http://arxiv.org/abs/2504.06724v1","title":"End-to-end design framework for compressed on-chip pixel-wise\n  spectro-polarimeters","summary":"Modern detector manufacturing allows spectral and polarimetric filters to be\ndirectly integrated on top of separate detector pixels. This enables the\ncreation of CubeSat-sized spectro-polarimetric instruments that are not much\nlarger than the detector and a lens. Redundancy inherent to the observed scene,\noffers the opportunity for sparse sampling in the form of not scanning all\nfilters at every location. However, when there are fewer pushbroom steps than\nfilters, data are missing in the resulting data cube. The missing, largely\nredundant data can be filled in with interpolation methods, often called\ndemosaicers. The choice of filters and their precise layout influences the\nperformance of the instrument after the demosaicing process. In these\nproceedings we describe a part of a design toolbox for both the filter layout\nand the optimum parameters for the reconstruction to a full\nspectro-polarimetric data cube. The design tool is based on training a (neural)\nnetwork and jointly updating the values of the filters and demosaicer. We\noptimized a filter layout by training on spectro-polarimetric remote\nobservations of the Earth acquired by SPEX airborne. This optimised filter\nlayout could reconstruct a validation scene from five overlapping snapshots\n(pushbroom steps), which would take 109 pushbroom steps when measuring with a\nclassical layout and no reconstruction.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.optics","published":"2025-04-09T09:29:30Z"}
{"aid":"http://arxiv.org/abs/2504.06744v1","title":"More Efficient Stealth Address Protocol","summary":"The integration of privacy-preserving transactions into public blockchains\nsuch as Ethereum remains a major challenge. The Stealth Address Protocol (SAP)\nprovides recipient anonymity by generating unlinkable stealth addresses.\nExisting SAPs, such as the Dual-Key Stealth Address Protocol and the Curvy\nProtocol, have shown significant improvements in efficiency, but remain\nvulnerable to quantum attacks. Post-quantum SAPs based on lattice-based\ncryptography, such as the Module-LWE SAP, on the other hand, offer quantum\nresistance while achieving better performance.\n  In this paper, we present a novel hybrid SAP that combines the Curvy protocol\nwith the computational advantages of the Module-LWE technique while remaining\nEthereum-friendly. In contrast to full post-quantum solutions, our approach\ndoes not provide quantum security, but achieves a significant speedup in\nscanning the ephemeral public key registry, about three times faster than the\nCurvy protocol. We present a detailed cryptographic construction of our\nprotocol and compare its performance with existing solutions. Our results prove\nthat this hybrid approach is the most efficient Ethereum-compatible SAP to\ndate.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T10:01:24Z"}
{"aid":"http://arxiv.org/abs/2504.06745v1","title":"A pluripotential theoretic framework for polynomial interpolation of\n  vector-valued functions and differential forms","summary":"We consider the problem of uniform interpolation of functions with values in\na complex inner product space of finite dimension. This problem can be casted\nwithin a modified weighted pluripotential theoretic framework. Indeed, in the\nproposed modification a vector valued weight is considered, allowing to\npartially extend the main asymptotic results holding for interpolation of\nscalar valued functions to the case of vector valued ones. As motivating\nexample and main application we specialize our results to interpolation of\ndifferential forms by differential forms with polynomial coefficients.","main_category":"math.CV","categories":"math.CV","published":"2025-04-09T10:04:23Z"}
{"aid":"http://arxiv.org/abs/2504.06765v1","title":"Characterization of infinitesimal boundedness of SchrÃ¶dinger\n  operator","summary":"In this paper, we characterize the weighted infinitesimal boundedness: for\n$0<\\alpha<n$ and $1<p<\\infty$,\n  $$\\|V\\phi\\|_{L^{p}(w)}^{p}\\leq\\epsilon\\|(-\\Delta)^{\\frac{\\alpha}{2}}\\phi\\|_{L^{p}(w)}^{p}+C(\\epsilon)\\|\\phi\\|_{L^{p}(w)}^{p}.$$\n  In particular, we extend the classical result due to Maz'ya and Verbitsky by\nusing Carleson condition, localization estimates and capacity theory.","main_category":"math.CA","categories":"math.CA","published":"2025-04-09T10:41:02Z"}
{"aid":"http://arxiv.org/abs/2504.06766v1","title":"FamilyTool: A Multi-hop Personalized Tool Use Benchmark","summary":"The integration of tool learning with Large Language Models (LLMs) has\nexpanded their capabilities in handling complex tasks by leveraging external\ntools. However, existing benchmarks for tool learning inadequately address\ncritical real-world personalized scenarios, particularly those requiring\nmulti-hop reasoning and inductive knowledge adaptation in dynamic environments.\nTo bridge this gap, we introduce FamilyTool, a novel benchmark grounded in a\nfamily-based knowledge graph (KG) that simulates personalized, multi-hop tool\nuse scenarios. FamilyTool challenges LLMs with queries spanning 1 to 3\nrelational hops (e.g., inferring familial connections and preferences) and\nincorporates an inductive KG setting where models must adapt to unseen user\npreferences and relationships without re-training, a common limitation in prior\napproaches that compromises generalization. We further propose KGETool: a\nsimple KG-augmented evaluation pipeline to systematically assess LLMs' tool use\nability in these settings. Experiments reveal significant performance gaps in\nstate-of-the-art LLMs, with accuracy dropping sharply as hop complexity\nincreases and inductive scenarios exposing severe generalization deficits.\nThese findings underscore the limitations of current LLMs in handling\npersonalized, evolving real-world contexts and highlight the urgent need for\nadvancements in tool-learning frameworks. FamilyTool serves as a critical\nresource for evaluating and advancing LLM agents' reasoning, adaptability, and\nscalability in complex, dynamic environments. Code and dataset are available at\nGithub.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-09T10:42:36Z"}
{"aid":"http://arxiv.org/abs/2504.06777v1","title":"End2end-ALARA: Approaching the ALARA Law in CT Imaging with End-to-end\n  Learning","summary":"Computed tomography (CT) examination poses radiation injury to patient. A\nconsensus performing CT imaging is to make the radiation dose as low as\nreasonably achievable, i.e. the ALARA law. In this paper, we propose an\nend-to-end learning framework, named End2end-ALARA, that jointly optimizes dose\nmodulation and image reconstruction to meet the goal of ALARA in CT imaging.\nEnd2end-ALARA works by building a dose modulation module and an image\nreconstruction module, connecting these modules with a differentiable\nsimulation function, and optimizing the them with a constrained hinge loss\nfunction. The objective is to minimize radiation dose subject to a prescribed\nimage quality (IQ) index. The results show that End2end-ALARA is able to preset\npersonalized dose levels to gain a stable IQ level across patients, which may\nfacilitate image-based diagnosis and downstream model training. Moreover,\ncompared to fixed-dose and conventional dose modulation strategies,\nEnd2end-ALARA consumes lower dose to reach the same IQ level. Our study sheds\nlight on a way of realizing the ALARA law in CT imaging.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T10:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.06779v1","title":"What if we find nothing? Bayesian analysis of the statistical\n  information of null results in future exoplanet habitability and biosignature\n  surveys","summary":"Future telescopes will survey temperate, terrestrial exoplanets to estimate\nthe frequency of habitable ($\\eta_{\\text{Hab}}$) or inhabited\n($\\eta_{\\text{Life}}$) planets. This study aims to determine the minimum number\nof planets ($N$) required to draw statistically significant conclusions,\nparticularly in the case of a null result (i.e., no detections). Using a\nBayesian framework, we analyzed surveys of up to $N=100$ planets to infer the\nfrequency of a binary observable feature ($\\eta_{\\text{obs}}$) after null\nresults. Posterior best fits and upper limits were derived for various survey\nsizes and compared with predicted yields from missions like the Large\nInterferometer for Exoplanets (LIFE) and the Habitable Worlds Observatory\n(HWO). Our findings indicate that $N=20-50$ ``perfect'' observations (100\\%\nconfidence in detecting or excluding the feature) yield conclusions relatively\nindependent of priors. To achieve 99.9\\% upper limits of $\\eta_{\\text{obs}}\n\\leq 0.2/0.1$, approximately $N \\simeq 40/80$ observations are needed. For\n``imperfect'' observations, uncertainties in interpretation and sample biases\nbecome limiting factors. We show that LIFE and HWO aim for sufficiently large\nsurvey sizes to provide statistically meaningful estimates of habitable\nenvironments and life prevalence under these assumptions. However, robust\nconclusions require careful sample selection and high-confidence detection or\nexclusion of features in each observation.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-09T11:02:19Z"}
{"aid":"http://arxiv.org/abs/2504.06789v1","title":"When is the partial map classifier a SierpiÅski cone?","summary":"We study the relationship between partial map classifiers, Sierpi\\'nski\ncones, and axioms for synthetic higher categories and domains within univalent\nfoundations. In particular, we show that synthetic $\\infty$-categories are\nclosed under partial map classifiers assuming Phoa's principle, and we isolate\na new reflective subuniverse of types within which the Sierpi\\'nski cone (a lax\ncolimit) can be computed as a partial map classifier by strengthening the Segal\ncondition.","main_category":"cs.LO","categories":"cs.LO,cs.PL,math.CT","published":"2025-04-09T11:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.06792v1","title":"Domain-Specific Pruning of Large Mixture-of-Experts Models with Few-shot\n  Demonstrations","summary":"Mixture-of-Experts (MoE) models achieve a favorable trade-off between\nperformance and inference efficiency by activating only a subset of experts.\nHowever, the memory overhead of storing all experts remains a major limitation,\nespecially in large-scale MoE models such as DeepSeek-R1 (671B). In this study,\nwe investigate domain specialization and expert redundancy in large-scale MoE\nmodels and uncover a consistent behavior we term few-shot expert localization,\nwith only a few demonstrations, the model consistently activates a sparse and\nstable subset of experts. Building on this observation, we propose a simple yet\neffective pruning framework, EASY-EP, that leverages a few domain-specific\ndemonstrations to identify and retain only the most relevant experts. EASY-EP\ncomprises two key components: output-aware expert importance assessment and\nexpert-level token contribution estimation. The former evaluates the importance\nof each expert for the current token by considering the gating scores and\nmagnitudes of the outputs of activated experts, while the latter assesses the\ncontribution of tokens based on representation similarities after and before\nrouted experts. Experiments show that our method can achieve comparable\nperformances and $2.99\\times$ throughput under the same memory budget with full\nDeepSeek-R1 with only half the experts. Our code is available at\nhttps://github.com/RUCAIBox/EASYEP.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-09T11:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.06795v1","title":"Winning and nullity of inhomogeneous bad","summary":"We prove the hyperplane absolute winning property of weighted inhomogeneous\nbadly approximable vectors in $\\mathbb{R}^d$. This answers a question by\nBeresnevich--Nesharim--Yang and extends the main result of [Geometric and\nFunctional Analysis, 31 (1), 1-33, 2021] to the inhomogeneous set-up.\n  We also show for any nondegenerate curve and nondegenerate analytic manifold\nthat almost every point is not weighted inhomogeneous badly approximable for\nany weight. This is achieved by duality and the quantitative nondivergence\nestimates from homogeneous dynamics motivated by [Acta Math. 231 (2023), 1-30],\ntogether with the methods from [arXiv:2307.10109].","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-09T11:38:28Z"}
{"aid":"http://arxiv.org/abs/2504.06818v1","title":"Deep Neural Koopman Operator-based Economic Model Predictive Control of\n  Shipboard Carbon Capture System","summary":"Shipboard carbon capture is a promising solution to help reduce carbon\nemissions in international shipping. In this work, we propose a data-driven\ndynamic modeling and economic predictive control approach within the Koopman\nframework. This integrated modeling and control approach is used to achieve\nsafe and energy-efficient process operation of shipboard post-combustion carbon\ncapture plants. Specifically, we propose a deep neural Koopman operator\nmodeling approach, based on which a Koopman model with time-varying model\nparameters is established. This Koopman model predicts the overall economic\noperational cost and key system outputs, based on accessible partial state\nmeasurements. By leveraging this learned model, a constrained economic\npredictive control scheme is developed. Despite time-varying parameters\ninvolved in the formulated model, the formulated optimization problem\nassociated with the economic predictive control design is convex, and it can be\nsolved efficiently during online control implementations. Extensive tests are\nconducted on a high-fidelity simulation environment for shipboard\npost-combustion carbon capture processes. Four ship operational conditions are\ntaken into account. The results show that the proposed method significantly\nimproves the overall economic operational performance and carbon capture rate.\nAdditionally, the proposed method guarantees safe operation by ensuring that\nhard constraints on the system outputs are satisfied.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-09T12:22:42Z"}
{"aid":"http://arxiv.org/abs/2504.06820v1","title":"Regret Bounds for Robust Online Decision Making","summary":"We propose a framework which generalizes \"decision making with structured\nobservations\" by allowing robust (i.e. multivalued) models. In this framework,\neach model associates each decision with a convex set of probability\ndistributions over outcomes. Nature can choose distributions out of this set in\nan arbitrary (adversarial) manner, that can be nonoblivious and depend on past\nhistory. The resulting framework offers much greater generality than classical\nbandits and reinforcement learning, since the realizability assumption becomes\nmuch weaker and more realistic. We then derive a theory of regret bounds for\nthis framework. Although our lower and upper bounds are not tight, they are\nsufficient to fully characterize power-law learnability. We demonstrate this\ntheory in two special cases: robust linear bandits and tabular robust online\nreinforcement learning. In both cases, we derive regret bounds that improve\nstate-of-the-art (except that we do not address computational efficiency).","main_category":"cs.LG","categories":"cs.LG,I.2.6","published":"2025-04-09T12:25:00Z"}
{"aid":"http://arxiv.org/abs/2504.06824v1","title":"A Roadmap for Improving Data Reliability and Sharing in Crosslinking\n  Mass Spectrometry","summary":"Crosslinking Mass Spectrometry (MS) can uncover protein-protein interactions\nand provide structural information on proteins in their native cellular\nenvironments. Despite its promise, the field remains hampered by inconsistent\ndata formats, variable approaches to error control, and insufficient\ninteroperability with global data repositories. Recent advances, especially in\nfalse discovery rate (FDR) models and pipeline benchmarking, show that\nCrosslinking MS data can reach a reliability that matches the demand of\nintegrative structural biology. To drive meaningful progress, however, the\ncommunity must agree on error estimation, open data formats, and streamlined\nrepository submissions. This perspective highlights these challenges, clarifies\nremaining barriers, and frames practical next steps. Successful field\nharmonisation will enhance the acceptance of Crosslinking MS in the broader\nbiological community and is critical for the dependability of the data, no\nmatter where it is produced.","main_category":"q-bio.OT","categories":"q-bio.OT","published":"2025-04-09T12:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.06825v1","title":"Some new findings concerning value distribution of a pair of\n  delay-differential polynomials","summary":"The paired Hayman's conjecture of different types are considered. More\naccurately speaking, the zeros of a pair of $f^n(z)L(z,g)-a_1(z)$ and\n$g^m(z)L(z,f)-a_2(z)$ are characterized using different methods from those\npreviously employed, where $f(z)$ and $g(z)$ are both transcendental entire\nfunctions, $L(z,f)$ and $L(z,g)$ are non-zero linear delay-differential\npolynomials, $\\min\\{n,m\\}\\ge 2$, $a_1(z),a_2(z)$ are non-zero small functions\nwith relative to $f$ and $g$, or to $f^n(z)L(z,g)$ and $g^m(z)L(z,f)$,\nrespectively. These results give answers to three open questions raised by Gao,\nLiu\\cite{Gao22} and Liu, Liu\\cite{Liu25}.","main_category":"math.CV","categories":"math.CV","published":"2025-04-09T12:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.06831v1","title":"Hubble tension and small-scale inhomogeneities on light propagation","summary":"One of the observational challenges in the standard cosmological model is\nknown as the Hubble tension. This $\\sim$ 5$\\sigma$ discrepancy between early\nand late measurements of the Hubble Constant arises from observations that rely\non cosmological distance estimates, either explicitly or implicitly. In this\nstudy, we relax the assumption of the Friedmann-Lema\\^itre-Robertson-Walker\n(FLRW) distance-redshift relation and explore the influence of small-scale\ninhomogeneities on the propagation of light from distant sources, using the\nZeldovich-Kantowski-Dyer-Roeder (ZKDR) approximation as an alternative approach\nto address this tension. We employ the ZKDR equation along with a modified\nversion to test our hypothesis using recent Type Ia supernovae data from the\nPantheon+ compilation and the SH0ES collaboration and six gravitational lens\nsystems from the H0LiCOW collaboration. Our findings indicate that a background\nmodel characterized by the ZKDR approximation and its modifications does not\nsolve or alleviate the Hubble tension.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-09T12:45:50Z"}
{"aid":"http://arxiv.org/abs/2504.06833v1","title":"Symbolic Parallel Composition for Multi-language Protocol Verification","summary":"The implementation of security protocols often combines different languages.\nThis practice, however, poses a challenge to traditional verification\ntechniques, which typically assume a single-language environment and,\ntherefore, are insufficient to handle challenges presented by the interplay of\ndifferent languages. To address this issue, we establish principles for\ncombining multiple programming languages operating on different atomic types\nusing a symbolic execution semantics. This facilitates the (parallel)\ncomposition of labeled transition systems, improving the analysis of complex\nsystems by streamlining communication between diverse programming languages. By\ntreating the Dolev-Yao (DY) model as a symbolic abstraction, our approach\neliminates the need for translation between different base types, such as\nbitstrings and DY terms. Our technique provides a foundation for securing\ninteractions in multi-language environments, enhancing program verification and\nsystem analysis in complex, interconnected systems.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T12:50:03Z"}
{"aid":"http://arxiv.org/abs/2504.06841v1","title":"Classifying the Unknown: In-Context Learning for Open-Vocabulary Text\n  and Symbol Recognition","summary":"We introduce Rosetta, a multimodal model that leverages Multimodal In-Context\nLearning (MICL) to classify sequences of novel script patterns in documents by\nleveraging minimal examples, thus eliminating the need for explicit retraining.\nTo enhance contextual learning, we designed a dataset generation process that\nensures varying degrees of contextual informativeness, improving the model's\nadaptability in leveraging context across different scenarios. A key strength\nof our method is the use of a Context-Aware Tokenizer (CAT), which enables\nopen-vocabulary classification. This allows the model to classify text and\nsymbol patterns across an unlimited range of classes, extending its\nclassification capabilities beyond the scope of its training alphabet of\npatterns. As a result, it unlocks applications such as the recognition of new\nalphabets and languages. Experiments on synthetic datasets demonstrate the\npotential of Rosetta to successfully classify Out-Of-Distribution visual\npatterns and diverse sets of alphabets and scripts, including but not limited\nto Chinese, Greek, Russian, French, Spanish, and Japanese.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T12:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.06848v1","title":"TOI-6478 b: a cold under-dense Neptune transiting a fully convective M\n  dwarf from the thick disc","summary":"Growing numbers of exoplanet detections continue to reveal the diverse nature\nof planetary systems. Planet formation around late-type M dwarfs is of\nparticular interest. These systems provide practical laboratories to measure\nexoplanet occurrence rates for M dwarfs, thus testing how the outcomes of\nplanet formation scale with host mass, and how they compare to Sun-like stars.\nHere, we report the discovery of TOI-6478b, a cold ($T_{\\text{eq}}=204\\,$K)\nNeptune-like planet orbiting an M5 star\n($R_\\star=0.234\\pm0.012\\,\\text{R}_\\odot$,\n$M_\\star=0.230\\pm0.007\\,\\text{M}_\\odot$, $T_{\\text{eff}}=3230\\pm75\\,$K) which\nis a member of the Milky Way's thick disc. We measure a planet radius of\n$R_b=4.6\\pm0.24\\,\\text{R}_\\oplus$ on a $P_b=34.005019\\pm0.000025\\,$d orbit.\nUsing radial velocities, we calculate an upper mass limit of\n$M_b\\leq9.9\\,\\text{M}_\\oplus$ ($M_b\\leq0.6\\,\\text{M}_{\\text{Nep}})$, with\n$3\\,\\sigma$ confidence. TOI-6478b is a milestone planet in the study of cold,\nNeptune-like worlds. Thanks to its large atmospheric scale height, it is\namenable to atmospheric characterisation with facilities such as JWST, and will\nprovide an excellent probe of atmospheric chemistry in this cold regime. It is\none of very few transiting exoplanets that orbit beyond their system's ice-line\nwhose atmospheric chemical composition can be measured. Based on our current\nunderstanding of this planet, we estimate TOI-6478b's spectroscopic features\n(in transmission) can be $\\sim2.5\\times$ as high as the widely studied planet\nK2-18b.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-09T13:03:16Z"}
{"aid":"http://arxiv.org/abs/2504.06865v1","title":"On manifolds with almost non-negative Ricci curvature and\n  integrally-positive $k^{th}$-scalar curvature","summary":"We consider manifolds with almost non-negative Ricci curvature and strictly\npositive integral lower bounds on the sum of the lowest $k$ eigenvalues of the\nRicci tensor.\n  If $(M^n,g)$ is a Riemannian manifold satisfying such curvature bounds for\n$k=2$, then we show that $M$ is contained in a neighbourhood of controlled\nwidth of an isometrically embedded $1$-dimensional sub-manifold. From this, we\ndeduce several metric and topological consequences: $M$ has at most linear\nvolume growth and at most two ends, the first Betti number of $M$ is bounded\nabove by $1$, and there is precise information on elements of infinite order in\n$\\pi_1(M)$.\n  If $(M^n,g)$ is a Riemannian manifold satisfying such bounds for $k\\geq 2$\nand additionally the Ricci curvature is asymptotically non-negative, then we\nshow that $M$ has at most $(k-1)$-dimensional behavior at large scales. If\n$k=n={\\rm dim}(M)$, so that the integral lower bound is on the scalar\ncurvature, assuming in addition that the $n-2$-Ricci curvature is\nasymptotically non-negative, then we prove that the dimension drop at large\nscales improves to $n-2$. From the above results, we deduce topological\nrestrictions, such as upper bounds on the first Betti number.","main_category":"math.DG","categories":"math.DG,math.MG","published":"2025-04-09T13:13:24Z"}
{"aid":"http://arxiv.org/abs/2504.06867v1","title":"xApp Conflict Mitigation with Scheduler","summary":"Open RAN (O-RAN) fosters multi-vendor interoperability and data-driven\ncontrol but simultaneously introduces the challenge of managing pre-trained\nxApps that can produce conflicting actions. Although O-RAN specifications\nmandate offline training and validation to prevent untrained models,\noperational conflicts remain likely under dynamic, context-dependent\nconditions. This work proposes a scheduler-based conflict mitigation framework\nto address these challenges without requiring training xApps together or\nfurther xApp re-training. By examining an indirect conflict involving power and\nresource block allocation xApps and employing an Advantage Actor-Critic (A2C)\napproach to train both xApps and the scheduler, we illustrate that a\nstraightforward A2C-based scheduler improves performance relative to\nindependently deployed xApps and conflicting cases. Notably, augmenting the\nsystem with baseline xApps and allowing the scheduler to select from a broader\npool yields the best results, underscoring the importance of adaptive\nscheduling mechanisms. These findings highlight the context-dependent nature of\nconflicts in automated network management, as two xApps may conflict under\ncertain conditions but coexist under others. Consequently, the ability to\ndynamically update and adapt the scheduler to accommodate diverse operational\nintents is vital for future network deployments. By offering dynamic scheduling\nwithout re-training xApps, this framework advances practical conflict\nresolution solutions while supporting real-world scalability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T13:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.06870v1","title":"Bayesian Component Separation for DESI LAE Automated Spectroscopic\n  Redshifts and Photometric Targeting","summary":"Lyman Alpha Emitters (LAEs) are valuable high-redshift cosmological probes\ntraditionally identified using specialized narrow-band photometric surveys. In\nground-based spectroscopy, it can be difficult to distinguish the sharp LAE\npeak from residual sky emission lines using automated methods, leading to\nmisclassified redshifts. We present a Bayesian spectral component separation\ntechnique to automatically determine spectroscopic redshifts for LAEs while\nmarginalizing over sky residuals. We use visually inspected spectra of LAEs\nobtained using the Dark Energy Spectroscopic Instrument (DESI) to create a\ndata-driven prior and can determine redshift by jointly inferring sky residual,\nLAE, and residual components for each individual spectrum. We demonstrate this\nmethod on 910 spectroscopically observed $z = 2-4$ DESI LAE candidate spectra\nand determine their redshifts with $>$90% accuracy when validated against\nvisually inspected redshifts. Using the $\\Delta \\chi^2$ value from our pipeline\nas a proxy for detection confidence, we then explore potential survey design\nchoices and implications for targeting LAEs with medium-band photometry. This\nmethod allows for scalability and accuracy in determining redshifts from DESI\nspectra, and the results provide recommendations for LAE targeting in\nanticipation of future high-redshift spectroscopic surveys.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO,stat.AP","published":"2025-04-09T13:21:20Z"}
{"aid":"http://arxiv.org/abs/2504.06871v1","title":"Two types of elliptic dark soliton solutions for the Hirota equation","summary":"We primarily study concave-downward and convex-upward types of elliptic dark\nsoliton solutions for the Hirota equation, exhibiting a concave-downward shape\non both upper and lower envelope surfaces and showing a convex-upward shape on\nthe lower envelope surface, respectively. By analyzing the supremum and infimum\nof solutions, we provide the existence conditions for these two types of\nelliptic dark solitons. Additionally, we study two-elliptic dark soliton\nsolutions combining both types with the same velocity and investigate the\nelastic collisions between these two types of solutions with different\nvelocities.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-09T13:21:54Z"}
{"aid":"http://arxiv.org/abs/2504.06885v1","title":"A Practical Cross-Platform, Multi-Algorithm Study of Quantum\n  Optimisation for Configurational Analysis of Materials","summary":"Quantum computers show potential for achieving computational advantage over\nclassical computers, with many candidate applications in the domains of\nchemistry and materials science. We consider the well-studied problem of\nconfigurational analysis of materials and, more specifically, finding the\nlowest energy configuration of defective graphene structures. This problem acts\nas a test-case which allows us to study various algorithms that are applicable\nto Quadratic Unconstrained Binary Optimisation (QUBO) problems, which are\ngenerally classically intractable exactly. To solve this problem, we implement\ntwo methods, the Variational Quantum Eigensolver (VQE) and Quantum Annealing\n(QA), on commercially-available gate-based and quantum annealing devices that\nare accessible via Quantum-Computing-as-a-Service (QCaaS) models. To analyse\nthe performance of these algorithms, we use a toolbox of relevant metrics and\ncompare performance against three classical algorithms. We employ quantum\nmethods to solve fully-connected QUBOs of up to $72$ variables, and find that\nalgorithm performance beyond this is restricted by device connectivity, noise\nand classical computation time overheads. The applicability of our approach\ngoes beyond the selected configurational analysis test-case, and we anticipate\nthat our approach will be of use for optimisation problems in general.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:38:44Z"}
{"aid":"http://arxiv.org/abs/2504.06902v1","title":"A Measurement Device Independent Quantum Key Distribution protocol in\n  the service of three users","summary":"Quantum Key Distribution (QKD) is the only theoretically proven method for\nsecure key distribution between two users. In this work, we propose and analyze\na Measurement Device Independent (MDI) protocol designed to distribute keys\namong three users in a pairwise manner. Each user randomly selects a basis,\nencodes bit values in the phase of coherent states, and sends the resulting\npulses to a central measurement unit (MU) composed of three beam splitters and\nthree photon detectors. When the three pulses arrive simultaneously at the MU\nand under the condition of successful detection of photons, a key bit is\ndistributed to at least one pair of users. This protocol extends the\nfoundational phase-encoding MDI protocol introduced by [K. Tamaki, et al.,\nPhys. Rev. A 85, 042307 (2012)] to three users, but this comes at the cost of\nintroducing a systematic error in the implementation of the honest protocol.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T14:01:49Z"}
{"aid":"http://arxiv.org/abs/2504.06904v1","title":"Engineering solutions for non-stationary gas pipeline reconstruction and\n  emergency management","summary":"The reconstruction, management, and optimization of gas pipelines is of\nsignificant importance for solving modern engineering problems. This paper\npresents innovative methodologies aimed at the effective reconstruction of gas\npipelines under unstable conditions. The research encompasses the application\nof machine learning and optimization algorithms, targeting the enhancement of\nsystem reliability and the optimization of interventions during emergencies.\nThe findings of the study present engineering solutions aimed at addressing the\nchallenges in real-world applications by comparing the performance of various\nalgorithms. Consequently, this work contributes to the advancement of\ncutting-edge approaches in the field of engineering and opens new perspectives\nfor future research. A highly reliable and efficient technological Figure has\nbeen proposed for managing emergency processes in gas transportation based on\nthe principles of the reconstruction phase. For complex gas pipeline systems,\nnew approaches have been investigated for the modernization of existing control\nprocess monitoring systems. These approaches are based on modern achievements\nin control theory and information technology, aiming to select emergency and\ntechnological modes. One of the pressing issues is to develop a method to\nminimize the transmission time of measured and controlled data on\nnon-stationary flow parameters of gas networks to dispatcher control centers.\nTherefore, the reporting Figures obtained for creating a reliable information\nbase for dispatcher centers using modern methods to efficiently manage the gas\ndynamic processes of non-stationary modes are of particular importance.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T14:05:44Z"}
{"aid":"http://arxiv.org/abs/2504.06923v1","title":"The Importance of Being Discrete: Measuring the Impact of Discretization\n  in End-to-End Differentially Private Synthetic Data","summary":"Differentially Private (DP) generative marginal models are often used in the\nwild to release synthetic tabular datasets in lieu of sensitive data while\nproviding formal privacy guarantees. These models approximate low-dimensional\nmarginals or query workloads; crucially, they require the training data to be\npre-discretized, i.e., continuous values need to first be partitioned into\nbins. However, as the range of values (or their domain) is often inferred\ndirectly from the training data, with the number of bins and bin edges\ntypically defined arbitrarily, this approach can ultimately break end-to-end DP\nguarantees and may not always yield optimal utility.\n  In this paper, we present an extensive measurement study of four\ndiscretization strategies in the context of DP marginal generative models. More\nprecisely, we design DP versions of three discretizers (uniform, quantile, and\nk-means) and reimplement the PrivTree algorithm. We find that optimizing both\nthe choice of discretizer and bin count can improve utility, on average, by\nalmost 30% across six DP marginal models, compared to the default strategy and\nnumber of bins, with PrivTree being the best-performing discretizer in the\nmajority of cases. We demonstrate that, while DP generative models with\nnon-private discretization remain vulnerable to membership inference attacks,\napplying DP during discretization effectively mitigates this risk. Finally, we\npropose an optimized approach for automatically selecting the optimal number of\nbins, achieving high utility while reducing both privacy budget consumption and\ncomputational overhead.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-09T14:30:30Z"}
{"aid":"http://arxiv.org/abs/2504.06927v1","title":"RO-FIGS: Efficient and Expressive Tree-Based Ensembles for Tabular Data","summary":"Tree-based models are often robust to uninformative features and can\naccurately capture non-smooth, complex decision boundaries. Consequently, they\noften outperform neural network-based models on tabular datasets at a\nsignificantly lower computational cost. Nevertheless, the capability of\ntraditional tree-based ensembles to express complex relationships efficiently\nis limited by using a single feature to make splits. To improve the efficiency\nand expressiveness of tree-based methods, we propose Random Oblique Fast\nInterpretable Greedy-Tree Sums (RO-FIGS). RO-FIGS builds on Fast Interpretable\nGreedy-Tree Sums, and extends it by learning trees with oblique or multivariate\nsplits, where each split consists of a linear combination learnt from random\nsubsets of features. This helps uncover interactions between features and\nimproves performance. The proposed method is suitable for tabular datasets with\nboth numerical and categorical features. We evaluate RO-FIGS on 22 real-world\ntabular datasets, demonstrating superior performance and much smaller models\nover other tree- and neural network-based methods. Additionally, we analyse\ntheir splits to reveal valuable insights into feature interactions, enriching\nthe information learnt from SHAP summary plots, and thereby demonstrating the\nenhanced interpretability of RO-FIGS models. The proposed method is well-suited\nfor applications, where balance between accuracy and interpretability is\nessential.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T14:35:24Z"}
{"aid":"http://arxiv.org/abs/2504.06936v1","title":"On Macdonald expansions of $q$-chromatic symmetric functions and the\n  Stanley-Stembridge Conjecture","summary":"The Stanley-Stembridge conjecture asserts that the chromatic symmetric\nfunction of a $(3+1)$-free graph is $e$-positive. Recently, Hikita proved this\nconjecture by giving an explicit $e$-expansion of the Shareshian-Wachs\n$q$-chromatic refinement for unit interval graphs. Using the $\\mathbb{A}_{q,t}$\nalgebra, we give an expansion of these $q$-chromatic symmetric functions into\nMacdonald polynomials. Upon setting $t=1$, we obtain another proof of the\nStanley-Stembridge conjecture and rederive Hikita's formula. Upon setting\n$t=0$, we obtain an expansion into Hall-Littlewood symmetric functions.","main_category":"math.CO","categories":"math.CO,math.RT","published":"2025-04-09T14:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.06950v1","title":"PathSegDiff: Pathology Segmentation using Diffusion model\n  representations","summary":"Image segmentation is crucial in many computational pathology pipelines,\nincluding accurate disease diagnosis, subtyping, outcome, and survivability\nprediction. The common approach for training a segmentation model relies on a\npre-trained feature extractor and a dataset of paired image and mask\nannotations. These are used to train a lightweight prediction model that\ntranslates features into per-pixel classes. The choice of the feature extractor\nis central to the performance of the final segmentation model, and recent\nliterature has focused on finding tasks to pre-train the feature extractor. In\nthis paper, we propose PathSegDiff, a novel approach for histopathology image\nsegmentation that leverages Latent Diffusion Models (LDMs) as pre-trained\nfeatured extractors. Our method utilizes a pathology-specific LDM, guided by a\nself-supervised encoder, to extract rich semantic information from H\\&E stained\nhistopathology images. We employ a simple, fully convolutional network to\nprocess the features extracted from the LDM and generate segmentation masks.\nOur experiments demonstrate significant improvements over traditional methods\non the BCSS and GlaS datasets, highlighting the effectiveness of\ndomain-specific diffusion pre-training in capturing intricate tissue structures\nand enhancing segmentation accuracy in histopathology images.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T14:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.06966v1","title":"Tractable reformulations of DRO problems over structured optimal\n  transport ambiguity sets","summary":"Structuring ambiguity sets in Wasserstein-based distributionally robust\noptimization (DRO) can improve their statistical properties when the\nuncertainty consists of multiple independent components. The aim of this paper\nis to solve stochastic optimization problems with unknown uncertainty when we\nonly have access to a finite set of samples from it. Exploiting strong duality\nof DRO problems over structured ambiguity sets, we derive tractable\nreformulations for certain classes of DRO and uncertainty quantification\nproblems. We also derive tractable reformulations for distributionally robust\nchance-constrained problems. As the complexity of the reformulations may grow\nexponentially with the number of independent uncertainty components, we employ\nclustering strategies to obtain informative estimators, which yield problems of\nmanageable complexity. We demonstrate the effectiveness of the theoretical\nresults in a numerical simulation example.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T15:19:56Z"}
{"aid":"http://arxiv.org/abs/2504.06969v1","title":"Towards LLMs Robustness to Changes in Prompt Format Styles","summary":"Large language models (LLMs) have gained popularity in recent years for their\nutility in various applications. However, they are sensitive to non-semantic\nchanges in prompt formats, where small changes in the prompt format can lead to\nsignificant performance fluctuations. In the literature, this problem is\ncommonly referred to as prompt brittleness. Previous research on prompt\nengineering has focused mainly on developing techniques for identifying the\noptimal prompt for specific tasks. Some studies have also explored the issue of\nprompt brittleness and proposed methods to quantify performance variations;\nhowever, no simple solution has been found to address this challenge. We\npropose Mixture of Formats (MOF), a simple and efficient technique for\naddressing prompt brittleness in LLMs by diversifying the styles used in the\nprompt few-shot examples. MOF was inspired by computer vision techniques that\nutilize diverse style datasets to prevent models from associating specific\nstyles with the target variable. Empirical results show that our proposed\ntechnique reduces style-induced prompt brittleness in various LLMs while also\nenhancing overall performance across prompt variations and different datasets.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T15:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.06983v1","title":"Free Random Projection for In-Context Reinforcement Learning","summary":"Hierarchical inductive biases are hypothesized to promote generalizable\npolicies in reinforcement learning, as demonstrated by explicit hyperbolic\nlatent representations and architectures. Therefore, a more flexible approach\nis to have these biases emerge naturally from the algorithm. We introduce Free\nRandom Projection, an input mapping grounded in free probability theory that\nconstructs random orthogonal matrices where hierarchical structure arises\ninherently. The free random projection integrates seamlessly into existing\nin-context reinforcement learning frameworks by encoding hierarchical\norganization within the input space without requiring explicit architectural\nmodifications. Empirical results on multi-environment benchmarks show that free\nrandom projection consistently outperforms the standard random projection,\nleading to improvements in generalization. Furthermore, analyses within\nlinearly solvable Markov decision processes and investigations of the spectrum\nof kernel random matrices reveal the theoretical underpinnings of free random\nprojection's enhanced performance, highlighting its capacity for effective\nadaptation in hierarchically structured state spaces.","main_category":"cs.LG","categories":"cs.LG,math.PR,stat.ML","published":"2025-04-09T15:38:50Z"}
{"aid":"http://arxiv.org/abs/2504.06989v1","title":"Exact Current Fluctuations in a Tight-Binding Chain with Dephasing Noise","summary":"For a tight-binding chain with dephasing noise on an infinite interval, we\nexactly calculate the variance of the integrated current for a step initial\ncondition with average densities, $\\rho_a$ on the negative axis and $\\rho_b$ on\nthe positive axis. Our exact solution reveals that the presence of dephasing,\nno matter how small, alters the nature of current fluctuations from ballistic\nto diffusive in the long-time limit. The derivation relies on the Bethe ansatz\non the infinite interval and a nontrivial parameter dependence, referred to as\nthe $\\omega$-dependence, of the moment generating function for the integrated\ncurrent. Furthermore, we demonstrate that the asymptotic form of the variance\nand a numerically obtained cumulant generating function coincide with those in\nthe symmetric simple exclusion process.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.quant-gas,math-ph,math.MP,quant-ph","published":"2025-04-09T15:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.06991v1","title":"Dissimilar Batch Decompositions of Random Datasets","summary":"For better learning, large datasets are often split into small batches and\nfed sequentially to the predictive model. In this paper, we study such batch\ndecompositions from a probabilistic perspective. We assume that data points\n(possibly corrupted) are drawn independently from a given space and define a\nconcept of similarity between two data points. We then consider decompositions\nthat restrict the amount of similarity within each batch and obtain high\nprobability bounds for the minimum size. We demonstrate an inherent tradeoff\nbetween relaxing the similarity constraint and the overall size and also use\nmartingale methods to obtain bounds for the maximum size of data subsets with a\ngiven similarity.","main_category":"cs.LG","categories":"cs.LG,math.PR,stat.ML","published":"2025-04-09T15:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.06995v1","title":"Broadband Optical Modulation and Control at Millikelvin Temperatures","summary":"A universal experimental challenge when studying radiation effects on\ncryogenic devices is to precisely and accurately characterize the\nposition-dependent device response very near the energy detection threshold. We\nhave developed a compact cryogenic optical beam steering system that can be\nused to generate O({\\mu}s) pulses of small numbers of photons over the energy\nrange of 1.2 - 4.5eV at room temperature, and deliver those photons via fiber\noptic to any specified location on the surface of a detector operating at\ncryogenic temperatures. This new system will allow for robust calibration of\nany photon-sensitive detector, including supercondcting devices. The system can\nbe used efficiently to explore the physics of target materials, quantify the\nposition sensitivity of different sensor designs, measure phonon transport, and\nstudy the effects of quasiparticle poisoning on detector operation. We describe\nthe design of this pulsed calibration method and present first results obtained\nwith a second-generation system operated at room temperature and sub-Kelvin\ntemperatures.","main_category":"physics.ins-det","categories":"physics.ins-det,astro-ph.IM,hep-ex,nucl-ex,physics.app-ph","published":"2025-04-09T16:08:39Z"}
{"aid":"http://arxiv.org/abs/2504.06999v1","title":"Extremal Planar Matchings of Inhomogenous Random Bipartite Graphs","summary":"In this paper we study maximum size and minimum weight planar matchings of\ninhomogenous random bipartite graphs. Our motivation for this study comes from\nefficient usage of cross edges in relay networks for overall improvement in\nnetwork performance. We first consider Bernoulli planar matchings with a\nconstraint on the edge length and obtain deviation estimates for the maximum\nsize of a planar matching. We then equip each edge of the complete bipartite\ngraph with a positive random weight and obtain bounds on the minimum weight of\na planar matching containing a given number of edges. We also use segmentation\nand martingale methods to obtain~\\(L^2-\\)convergence of the minimum weight,\nappropriately scaled and centred.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T16:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.07005v1","title":"A stacky approach to prismatic crystals via $q$-prism charts","summary":"Let $Y$ be a locally complete intersection over $\\mathcal{O}_K$ containing a\n$p$-power root of unity $\\zeta_p$. We classify the derived category of\nprismatic crystals on the absolute prismatic site of $Y$ by studying\nquasi-coherent complexes on the prismatization of $Y$ via $q$-prism charts. We\nalso develop a Galois descent mechanism to remove the assumption on\n$\\mathcal{O}_K$. As an application, we classify quasi-coherent complexes on the\nCartier-Witt stack and give a purely algebraic calculation of the cohomology of\nthe structure sheaf on the absolute prismatic site of $\\mathbb{Z}_p$. Along the\nway, for $Y$ a locally complete intersection over $\\overline{A}$ with $A$ lying\nover a $q$-prism, we classify quasi-coherent complexes on the relative\nprismatization of $Y$.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-09T16:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.07011v1","title":"FAME: Introducing Fuzzy Additive Models for Explainable AI","summary":"In this study, we introduce the Fuzzy Additive Model (FAM) and FAM with\nExplainability (FAME) as a solution for Explainable Artificial Intelligence\n(XAI). The family consists of three layers: (1) a Projection Layer that\ncompresses the input space, (2) a Fuzzy Layer built upon Single Input-Single\nOutput Fuzzy Logic Systems (SFLS), where SFLS functions as subnetworks within\nan additive index model, and (3) an Aggregation Layer. This architecture\nintegrates the interpretability of SFLS, which uses human-understandable\nif-then rules, with the explainability of input-output relationships,\nleveraging the additive model structure. Furthermore, using SFLS inherently\naddresses issues such as the curse of dimensionality and rule explosion. To\nfurther improve interpretability, we propose a method for sculpting antecedent\nspace within FAM, transforming it into FAME. We show that FAME captures the\ninput-output relationships with fewer active rules, thus improving clarity. To\nlearn the FAM family, we present a deep learning framework. Through the\npresented comparative results, we demonstrate the promising potential of FAME\nin reducing model complexity while retaining interpretability, positioning it\nas a valuable tool for XAI.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T16:29:55Z"}
{"aid":"http://arxiv.org/abs/2504.07015v1","title":"LLM-IFT: LLM-Powered Information Flow Tracking for Secure Hardware","summary":"As modern hardware designs grow in complexity and size, ensuring security\nacross the confidentiality, integrity, and availability (CIA) triad becomes\nincreasingly challenging. Information flow tracking (IFT) is a widely-used\napproach to tracing data propagation, identifying unauthorized activities that\nmay compromise confidentiality or/and integrity in hardware. However,\ntraditional IFT methods struggle with scalability and adaptability,\nparticularly in high-density and interconnected architectures, leading to\ntracing bottlenecks that limit applicability in large-scale hardware. To\naddress these limitations and show the potential of transformer-based models in\nintegrated circuit (IC) design, this paper introduces LLM-IFT that integrates\nlarge language models (LLM) for the realization of the IFT process in hardware.\nLLM-IFT exploits LLM-driven structured reasoning to perform hierarchical\ndependency analysis, systematically breaking down even the most complex\ndesigns. Through a multi-step LLM invocation, the framework analyzes both\nintra-module and inter-module dependencies, enabling comprehensive IFT\nassessment. By focusing on a set of Trust-Hub vulnerability test cases at both\nthe IP level and the SoC level, our experiments demonstrate a 100\\% success\nrate in accurate IFT analysis for confidentiality and integrity checks in\nhardware.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T16:32:13Z"}
{"aid":"http://arxiv.org/abs/2504.07028v1","title":"UAV Position Estimation using a LiDAR-based 3D Object Detection Method","summary":"This paper explores the use of applying a deep learning approach for 3D\nobject detection to compute the relative position of an Unmanned Aerial Vehicle\n(UAV) from an Unmanned Ground Vehicle (UGV) equipped with a LiDAR sensor in a\nGPS-denied environment. This was achieved by evaluating the LiDAR sensor's data\nthrough a 3D detection algorithm (PointPillars). The PointPillars algorithm\nincorporates a column voxel point-cloud representation and a 2D Convolutional\nNeural Network (CNN) to generate distinctive point-cloud features representing\nthe object to be identified, in this case, the UAV. The current localization\nmethod utilizes point-cloud segmentation, Euclidean clustering, and predefined\nheuristics to obtain the relative position of the UAV. Results from the two\nmethods were then compared to a reference truth solution.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T16:43:59Z"}
{"aid":"http://arxiv.org/abs/2504.07041v1","title":"Efficient Storage Integrity in Adversarial Settings","summary":"Storage integrity is essential to systems and applications that use untrusted\nstorage (e.g., public clouds, end-user devices). However, known methods for\nachieving storage integrity either suffer from high (and often prohibitive)\noverheads or provide weak integrity guarantees. In this work, we demonstrate a\nhybrid approach to storage integrity that simultaneously reduces overhead while\nproviding strong integrity guarantees. Our system, partially asynchronous\nintegrity checking (PAC), allows disk write commitments to be deferred while\nstill providing guarantees around read integrity. PAC delivers a 5.5X\nthroughput and latency improvement over the state of the art, and 85% of the\nthroughput achieved by non-integrity-assuring approaches. In this way, we show\nthat untrusted storage can be used for integrity-critical workloads without\nmeaningfully sacrificing performance.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T16:58:22Z"}
{"aid":"http://arxiv.org/abs/2504.07050v1","title":"Minimal mechanism for fluidic flocks in interacting active colloids","summary":"Collective motion as a flock is a widely observed phenomenon in active matter\nsystems. Finding possible mechanisms of attaining a global polar order via\ndynamical mechanisms - without any explicit alignment interaction - is an area\nof active current research. Here, we report a flocking transition sustained\npurely by chemo-repulsive torques at low to medium densities in a system of\nchemically interacting colloidal particles. The basic requirements to sustain\nthe flock are excluded volume repulsions and deterministic long-ranged net\nrepulsive torques, with the time scale individual colloids move a unit length\nbeing dominant with respect to the time they deterministically sense chemicals.\nSwitching on the translational repulsive forces renders the flock a crystalline\nstructure. The generality of this phenomenon is displayed for a range of\nattractive translational forces to which the flock is robust. We rationalize\nthese results with a phenomenological hydrodynamical model.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-09T17:09:48Z"}
{"aid":"http://arxiv.org/abs/2504.07063v1","title":"Non-Gaussianity of Tensor Induced Density Perturbations","summary":"We investigate the non-Gaussianity of second-order matter density\nperturbations induced by primordial gravitational waves (GWs). These\ntensor-induced scalar modes arise from local fluctuations in the GWs energy\ndensity, which is quadratic in tensor perturbations. The resulting second-order\ndensity contrast follows a chi-squared distribution, naturally exhibiting\nsignificant non-Gaussianity. We compute the bispectrum of these tensor-induced\nscalar modes and analyze its dependence on various primordial GWs power\nspectra, including scale-invariant, blue-tilted, Gaussian-bump, and\nmonochromatic sources. We find that the bispectrum shape is inherently\nsensitive to the underlying GWs spectrum by construction. In particular,\nGaussian-bump and monochromatic sources produce a strong signal peaking in the\nequilateral configuration, similar to the effect of scalar-induced tensor\nmodes. Our findings reveal a new way to probe primordial GWs via galaxy surveys\nand highlight a unique feature of tensor-induced density perturbations,\notherwise mimicking linear ones on sub-horizon scales.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T17:26:41Z"}
{"aid":"http://arxiv.org/abs/2504.07065v1","title":"Enhancing Downstream Analysis in Genome Sequencing: Species\n  Classification While Basecalling","summary":"The ability to quickly and accurately identify microbial species in a sample,\nknown as metagenomic profiling, is critical across various fields, from\nhealthcare to environmental science. This paper introduces a novel method to\nprofile signals coming from sequencing devices in parallel with determining\ntheir nucleotide sequences, a process known as basecalling, via a\nmulti-objective deep neural network for simultaneous basecalling and\nmulti-class genome classification. We introduce a new loss strategy where\nlosses for basecalling and classification are back-propagated separately, with\nmodel weights combined for the shared layers, and a pre-configured ranking\nstrategy allowing top-K species accuracy, giving users flexibility to choose\nbetween higher accuracy or higher speed at identifying the species. We achieve\nstate-of-the-art basecalling accuracies, while classification accuracies meet\nand exceed the results of state-of-the-art binary classifiers, attaining an\naverage of 92.5%/98.9% accuracy at identifying the top-1/3 species among a\ntotal of 17 genomes in the Wick bacterial dataset. The work presented here has\nimplications for future studies in metagenomic profiling by accelerating the\nbottleneck step of matching the DNA sequence to the correct genome.","main_category":"q-bio.GN","categories":"q-bio.GN,cs.LG","published":"2025-04-09T17:30:43Z"}
{"aid":"http://arxiv.org/abs/2504.07074v1","title":"The Lyman-alpha and Continuum Origins Survey II: the uneventful journey\n  of escaping Ly$Î±$ and ionizing radiation through the neutral ISM and CGM\n  of galaxies","summary":"One of the current challenges in galaxy evolution studies is to establish the\nmechanisms that govern the escape of ionizing radiation from galaxies. In this\nwork, we investigate the connection between Lyman Continuum (LyC) escape and\nthe conditions of the Circumgalactic Medium (CGM), as probed by Ly$\\alpha$\nhalos (LAHs) in emission. We use Ly$\\alpha$ and UV continuum imaging data from\nthe Lyman alpha and Continuum Origins Survey (LaCOS), targeting 42 nearby ($z\n\\simeq 0.3$), star-forming galaxies with LyC observations (escape fractions of\n$f_{\\rm esc}^{\\rm LyC} \\simeq 0.01-0.49$). LaCOS galaxies show extended\nLy$\\alpha$ emission ubiquitously, with LyC emitters (LCEs) having more compact\nLy$\\alpha$ morphologies relative to the UV size than non-LCEs, and Ly$\\alpha$\nspatial offsets that do not exceed the extent of the UV continuum. We model the\ndiffuse LAHs using a combined Sersic plus exponential 2D profile, and find that\nthe characteristic scale length of the Ly$\\alpha$ is ten times the scale length\nof the UV, on average. We unveil a tight anti-correlation between $f_{\\rm\nesc}^{\\rm LyC}$ and the Ly$\\alpha$ Halo Fraction (HF, or contribution of the\nhalo to the total Ly$\\alpha$ luminosity), that we propose as a new LyC\nindicator. Our observations also show that the HF scales positively with the\nneutral gas in the ISM, revealing a picture in which Ly$\\alpha$ and LyC photons\nin LCEs emerge through clear sight-lines directly from the central starbursts\nand, in the case of Ly$\\alpha$, minimizing the number of scattering\ninteractions in the CGM. The properties of LAHs in LaCOS resemble those of LAHs\nat $z \\geq 3$, suggesting a lack of evolution in the $f_{\\rm esc}^{\\rm LyC}$\npredictors that rely on the spatial properties of Ly$\\alpha$, and ensuring the\napplicability of these indicators to observations of high-redshift galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T17:46:13Z"}
{"aid":"http://arxiv.org/abs/2504.07088v1","title":"Pauli 'unlimited': magnetic field induced-superconductivity in UTe$_2$","summary":"Inspired by the observation of extreme field-boosted superconductivity in\nuranium ditelluride, we present a scenario in which superconductivity can be\ninduced by a strong Zeeman field, rather than destroyed by it, as is the case\nin Pauli-limited superconductivity. The resulting superconducting state has an\nupper critical field far greater than the superconducting transition\ntemperature, and with spin-orbit coupling, it is sensitive to the field\norientation. We demonstrate the interplay between superconductivity and\nmetamagnetism in a simple effective theory.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-09T17:58:57Z"}
{"aid":"http://arxiv.org/abs/2504.07091v1","title":"AssistanceZero: Scalably Solving Assistance Games","summary":"Assistance games are a promising alternative to reinforcement learning from\nhuman feedback (RLHF) for training AI assistants. Assistance games resolve key\ndrawbacks of RLHF, such as incentives for deceptive behavior, by explicitly\nmodeling the interaction between assistant and user as a two-player game where\nthe assistant cannot observe their shared goal. Despite their potential,\nassistance games have only been explored in simple settings. Scaling them to\nmore complex environments is difficult because it requires both solving\nintractable decision-making problems under uncertainty and accurately modeling\nhuman users' behavior. We present the first scalable approach to solving\nassistance games and apply it to a new, challenging Minecraft-based assistance\ngame with over $10^{400}$ possible goals. Our approach, AssistanceZero, extends\nAlphaZero with a neural network that predicts human actions and rewards,\nenabling it to plan under uncertainty. We show that AssistanceZero outperforms\nmodel-free RL algorithms and imitation learning in the Minecraft-based\nassistance game. In a human study, our AssistanceZero-trained assistant\nsignificantly reduces the number of actions participants take to complete\nbuilding tasks in Minecraft. Our results suggest that assistance games are a\ntractable framework for training effective AI assistants in complex\nenvironments. Our code and models are available at\nhttps://github.com/cassidylaidlaw/minecraft-building-assistance-game.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-09T17:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.07410v1","title":"Distributing graph states with a photon-weaving quantum server","summary":"One of the key aims of quantum networks is the efficient distribution of\nmultipartite entangled states among end users. While various architectures have\nbeen proposed, each comes with distinct advantages and limitations. Many\ndesigns depend on long-lived quantum memories and deterministic gates, which,\nwhile powerful, introduce considerable cost and technical challenges.\nExperimentally cheaper alternatives that circumvent these constraints are often\nlimited to specific types of entanglement and a specific number of users. Here,\nwe present an experiment-friendly quantum server that relies only on linear\noptical elements, offering a flexible approach to multipartite entanglement\ndistribution. Our so-called photon-weaving quantum server can generate and\ndistribute one of several locally nonequivalent graph states, including\nGreenberger-Horne-Zeilinger (GHZ) states, as well as path, cycle, and\ncaterpillar graph states. This is achieved through two distinct fusion\nprotocols, i.e., multiphoton graph-state fusion (graph-state weaving) and\nmultiphoton GHZ-state fusion (GHZ-state weaving), and can readily be\nimplemented.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T03:03:14Z"}
{"aid":"http://arxiv.org/abs/2504.07418v1","title":"ThermoStereoRT: Thermal Stereo Matching in Real Time via Knowledge\n  Distillation and Attention-based Refinement","summary":"We introduce ThermoStereoRT, a real-time thermal stereo matching method\ndesigned for all-weather conditions that recovers disparity from two rectified\nthermal stereo images, envisioning applications such as night-time drone\nsurveillance or under-bed cleaning robots. Leveraging a lightweight yet\npowerful backbone, ThermoStereoRT constructs a 3D cost volume from thermal\nimages and employs multi-scale attention mechanisms to produce an initial\ndisparity map. To refine this map, we design a novel channel and spatial\nattention module. Addressing the challenge of sparse ground truth data in\nthermal imagery, we utilize knowledge distillation to boost performance without\nincreasing computational demands. Comprehensive evaluations on multiple\ndatasets demonstrate that ThermoStereoRT delivers both real-time capacity and\nrobust accuracy, making it a promising solution for real-world deployment in\nvarious challenging environments. Our code will be released on\nhttps://github.com/SJTU-ViSYS-team/ThermoStereoRT","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T03:24:21Z"}
{"aid":"http://arxiv.org/abs/2504.07424v1","title":"Routing to the Right Expertise: A Trustworthy Judge for\n  Instruction-based Image Editing","summary":"Instruction-based Image Editing (IIE) models have made significantly\nimprovement due to the progress of multimodal large language models (MLLMs) and\ndiffusion models, which can understand and reason about complex editing\ninstructions. In addition to advancing current IIE models, accurately\nevaluating their output has become increasingly critical and challenging.\nCurrent IIE evaluation methods and their evaluation procedures often fall short\nof aligning with human judgment and often lack explainability. To address these\nlimitations, we propose JUdgement through Routing of Expertise (JURE). Each\nexpert in JURE is a pre-selected model assumed to be equipped with an atomic\nexpertise that can provide useful feedback to judge output, and the router\ndynamically routes the evaluation task of a given instruction and its output to\nappropriate experts, aggregating their feedback into a final judge. JURE is\ntrustworthy in two aspects. First, it can effortlessly provide explanations\nabout its judge by examining the routed experts and their feedback. Second,\nexperimental results demonstrate that JURE is reliable by achieving superior\nalignment with human judgments, setting a new standard for automated IIE\nevaluation. Moreover, JURE's flexible design is future-proof - modular experts\ncan be seamlessly replaced or expanded to accommodate advancements in IIE,\nmaintaining consistently high evaluation quality. Our evaluation data and\nresults are available at https://github.com/Cyyyyyrus/JURE.git.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T03:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.07427v1","title":"Deep Learning-Based Wideband Spectrum Sensing with Dual-Representation\n  Inputs and Subband Shuffling Augmentation","summary":"The widespread adoption of mobile communication technology has led to a\nsevere shortage of spectrum resources, driving the development of cognitive\nradio technologies aimed at improving spectrum utilization, with spectrum\nsensing being the key enabler. This paper presents a novel deep learning-based\nwideband spectrum sensing framework that leverages multi-taper power spectral\ninputs to achieve high-precision and sample-efficient sensing. To enhance\nsensing accuracy, we incorporate a feature fusion strategy that combines\nmultiple power spectrum representations. To tackle the challenge of limited\nsample sizes, we propose two data augmentation techniques designed to expand\nthe training set and improve the network's detection probability. Comprehensive\nsimulation results demonstrate that our method outperforms existing approaches,\nparticularly in low signal-to-noise ratio conditions, achieving higher\ndetection probabilities and lower false alarm rates. The method also exhibits\nstrong robustness across various scenarios, highlighting its significant\npotential for practical applications in wireless communication systems.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T03:38:15Z"}
{"aid":"http://arxiv.org/abs/2504.07431v1","title":"LLM-Enabled Data Transmission in End-to-End Semantic Communication","summary":"Emerging services such as augmented reality (AR) and virtual reality (VR)\nhave increased the volume of data transmitted in wireless communication\nsystems, revealing the limitations of traditional Shannon theory. To address\nthese limitations, semantic communication has been proposed as a solution that\nprioritizes the meaning of messages over the exact transmission of bits. This\npaper explores semantic communication for text data transmission in end-to-end\n(E2E) systems through a novel approach called KG-LLM semantic communication,\nwhich integrates knowledge graph (KG) extraction and large language model (LLM)\ncoding. In this method, the transmitter first utilizes a KG to extract key\nentities and relationships from sentences. The extracted information is then\nencoded using an LLM to obtain the semantic meaning. On the receiver side,\nmessages are decoded using another LLM, while a bidirectional encoder\nrepresentations from transformers (i.e., BERT) model further refines the\nreconstructed sentences for improved semantic similarity. The KG-LLM semantic\ncommunication method reduces the transmitted text data volume by 30% through\nKG-based compression and achieves 84\\% semantic similarity between the original\nand received messages. This demonstrates the KG-LLM methods efficiency and\nrobustness in semantic communication systems, outperforming the deep\nlearning-based semantic communication model (DeepSC), which achieves only 63%.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-10T04:00:11Z"}
{"aid":"http://arxiv.org/abs/2504.07434v1","title":"Fast response of deep ocean circulation to mid-latitude winds in the\n  Atlantic","summary":"\\textit{In situ} observations of transbasin deep ocean transports at\n$26^\\circ$N show variability on monthly to decadal timescales (2004--2015).\nSatellite-based estimates of ocean bottom pressure from the Gravity Recovery\nand Climate Experiment (GRACE) satellites were previously used to estimate\ninterannual variability of deep ocean transports at $26^\\circ$N. Here, we use\nGRACE ocean bottom pressure, reanalysis winds and \\textit{in situ} transport\nestimates at $26^\\circ$N to diagnose the large-scale response of the deep ocean\ncirculation to wind-forcing. We find that deep ocean transports -- including\nthose associated with a reversal of the Atlantic meridional overturning\ncirculation in 2009/10 and 2010/11 -- are part of a large-scale response to\nwind stress curl over the intergyre-gyre region. Wind-forcing dominates deep\nocean circulation variability on monthly timescales, but interannual\nfluctuations in the residual \\textit{in situ} transports (after removing the\nwind-effect) are also captured by GRACE bottom pressure measurements. On\ndecadal timescales, uncertainty in regional trends in GRACE ocean bottom\npressure preclude investigation of decadal-timescale transport trends.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-10T04:05:14Z"}
{"aid":"http://arxiv.org/abs/2504.07440v1","title":"Revisiting LLM Evaluation through Mechanism Interpretability: a New\n  Metric and Model Utility Law","summary":"Large Language Models (LLMs) have become indispensable across academia,\nindustry, and daily applications, yet current evaluation methods struggle to\nkeep pace with their rapid development. In this paper, we analyze the core\nlimitations of traditional evaluation pipelines and propose a novel metric, the\nModel Utilization Index (MUI), which introduces mechanism interpretability\ntechniques to complement traditional performance metrics. MUI quantifies the\nextent to which a model leverages its capabilities to complete tasks. The core\nidea is that to assess an LLM's overall ability, we must evaluate not only its\ntask performance but also the effort expended to achieve the outcome. Our\nextensive experiments reveal an inverse relationship between MUI and\nperformance, from which we deduce a common trend observed in popular LLMs,\nwhich we term the Utility Law. Based on this, we derive four corollaries that\naddress key challenges, including training judgement, the issue of data\ncontamination, fairness in model comparison, and data diversity. We hope that\nour survey, novel metric, and utility law will foster mutual advancement in\nboth evaluation and mechanism interpretability. Our code can be found at\nhttps://github.com/ALEX-nlp/MUI-Eva.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T04:09:47Z"}
{"aid":"http://arxiv.org/abs/2504.07456v1","title":"Sums with Stern-Brocot sequences and Minkowski question mark function","summary":"We give an affirmative answer to a question asked by N. Moshchevitin\n\\cite{m1} in his lecture at International Congress of Basic Science, Beijing,\n2024 (see also \\cite{m}, Section 6.3). The question is that whether the\nremainder $$\nR_n=\\sum_{j=1}^{2^n}\\left(\\xi_{j,n}-\\frac{j}{2^n}\\right)^2-2^n\\int_0^1(?(x)-x))^2\\text{d}x\n$$ tends to $0$ when $n$ tends to infinity, where $\\xi_{j,n}$ are elements of\nthe Stern-Brocot sequence and $?(x)$ denotes Minkowski Question-Mark Function.\nWe present some extended results and give a correct proof of a theorem on the\nFourier-Stieltjes coefficient of the inverse function of $?(x)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T05:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.07467v1","title":"Defense against Prompt Injection Attacks via Mixture of Encodings","summary":"Large Language Models (LLMs) have emerged as a dominant approach for a wide\nrange of NLP tasks, with their access to external information further enhancing\ntheir capabilities. However, this introduces new vulnerabilities, known as\nprompt injection attacks, where external content embeds malicious instructions\nthat manipulate the LLM's output. Recently, the Base64 defense has been\nrecognized as one of the most effective methods for reducing success rate of\nprompt injection attacks. Despite its efficacy, this method can degrade LLM\nperformance on certain NLP tasks. To address this challenge, we propose a novel\ndefense mechanism: mixture of encodings, which utilizes multiple character\nencodings, including Base64. Extensive experimental results show that our\nmethod achieves one of the lowest attack success rates under prompt injection\nattacks, while maintaining high performance across all NLP tasks, outperforming\nexisting character encoding-based defense methods. This underscores the\neffectiveness of our mixture of encodings strategy for both safety and task\nperformance metrics.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T05:35:21Z"}
{"aid":"http://arxiv.org/abs/2504.07470v1","title":"Transformer-Based Temporal Information Extraction and Application: A\n  Review","summary":"Temporal information extraction (IE) aims to extract structured temporal\ninformation from unstructured text, thereby uncovering the implicit timelines\nwithin. This technique is applied across domains such as healthcare, newswire,\nand intelligence analysis, aiding models in these areas to perform temporal\nreasoning and enabling human users to grasp the temporal structure of text.\nTransformer-based pre-trained language models have produced revolutionary\nadvancements in natural language processing, demonstrating exceptional\nperformance across a multitude of tasks. Despite the achievements garnered by\nTransformer-based approaches in temporal IE, there is a lack of comprehensive\nreviews on these endeavors. In this paper, we aim to bridge this gap by\nsystematically summarizing and analyzing the body of work on temporal IE using\nTransformers while highlighting potential future research directions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T05:48:24Z"}
{"aid":"http://arxiv.org/abs/2504.07477v1","title":"Enabling Gigantic MIMO Beamforming with Analog Computing","summary":"In our previous work, we have introduced a microwave linear analog computer\n(MiLAC) as an analog computer that processes microwave signals linearly,\ndemonstrating its potential to reduce the computational complexity of specific\nsignal processing tasks. In this paper, we extend these benefits to wireless\ncommunications, showcasing how MiLAC enables gigantic multiple-input\nmultiple-output (MIMO) beamforming entirely in the analog domain. MiLAC-aided\nbeamforming can implement regularized zero-forcing beamforming (R-ZFBF) at the\ntransmitter and minimum mean square error (MMSE) detection at the receiver,\nwhile significantly reducing hardware costs by minimizing the number of\nradio-frequency (RF) chains and only relying on low-resolution\nanalog-to-digital converters (ADCs) and digital-to-analog converters (DACs). In\naddition, it eliminates per-symbol operations by completely avoiding\ndigital-domain processing and remarkably reduces the computational complexity\nof R-ZFBF, which scales quadratically with the number of antennas instead of\ncubically. Numerical results show that it can perform R-ZFBF with a\ncomputational complexity reduction of up to 7400 times compared to digital\nbeamforming.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-10T06:06:03Z"}
{"aid":"http://arxiv.org/abs/2504.07478v1","title":"Intelligent DoS and DDoS Detection: A Hybrid GRU-NTM Approach to Network\n  Security","summary":"Detecting Denial of Service (DoS) and Distributed Denial of Service (DDoS)\nattacks remains a critical challenge in cybersecurity. This research introduces\na hybrid deep learning model combining Gated Recurrent Units (GRUs) and a\nNeural Turing Machine (NTM) for enhanced intrusion detection. Trained on the\nUNSW-NB15 and BoT-IoT datasets, the model employs GRU layers for sequential\ndata processing and an NTM for long-term pattern recognition. The proposed\napproach achieves 99% accuracy in distinguishing between normal, DoS, and DDoS\ntraffic. These findings offer promising advancements in real-time threat\ndetection and contribute to improved network security across various domains.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-10T06:08:04Z"}
{"aid":"http://arxiv.org/abs/2504.07480v1","title":"Echoes of Disagreement: Measuring Disparity in Social Consensus","summary":"Public discourse and opinions stem from multiple social groups. Each group\nhas beliefs about a topic (such as vaccination, abortion, gay marriage, etc.),\nand opinions are exchanged and blended to produce consensus. A particular\nmeasure of interest corresponds to measuring the influence of each group on the\nconsensus and the disparity between groups on the extent to which they\ninfluence the consensus. In this paper, we study and give provable algorithms\nfor optimizing the disparity under the DeGroot or the Friedkin-Johnsen models\nof opinion dynamics. Our findings provide simple poly-time algorithms to\noptimize disparity for most cases, fully characterize the instances that\noptimize disparity, and show how simple interventions such as contracting\nvertices or adding links affect disparity. Finally, we test our developed\nalgorithms in a variety of real-world datasets.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T06:18:27Z"}
{"aid":"http://arxiv.org/abs/2504.07481v1","title":"A Mechanism-Learning Deeply Coupled Model for Remote Sensing Retrieval\n  of Global Land Surface Temperature","summary":"Land surface temperature (LST) retrieval from remote sensing data is pivotal\nfor analyzing climate processes and surface energy budgets. However, LST\nretrieval is an ill-posed inverse problem, which becomes particularly severe\nwhen only a single band is available. In this paper, we propose a deeply\ncoupled framework integrating mechanistic modeling and machine learning to\nenhance the accuracy and generalizability of single-channel LST retrieval.\nTraining samples are generated using a physically-based radiative transfer\nmodel and a global collection of 5810 atmospheric profiles. A physics-informed\nmachine learning framework is proposed to systematically incorporate the first\nprinciples from classical physical inversion models into the learning workflow,\nwith optimization constrained by radiative transfer equations. Global\nvalidation demonstrated a 30% reduction in root-mean-square error versus\nstandalone methods. Under extreme humidity, the mean absolute error decreased\nfrom 4.87 K to 2.29 K (53% improvement). Continental-scale tests across five\ncontinents confirmed the superior generalizability of this model.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.LG","published":"2025-04-10T06:19:01Z"}
{"aid":"http://arxiv.org/abs/2504.07492v1","title":"Homogeneous nucleation rate of carbon dioxide hydrate formation under\n  experimental condition from Seeding simulations","summary":"We investigate the nucleation of carbon dioxide (CO$_2$) hydrates from carbon\ndioxide aqueous solutions by means of molecular dynamics simulations using the\nTIP4P/Ice and the TraPPE models for water and CO$_2$ respectively. We work at\n400 bar and different temperatures and CO$_2$ concentrations. We use brute\nforce molecular dynamics when the supersaturation or the supercooling are so\nhigh so that nucleation occurs spontaneously and Seeding otherwise. We used\nboth methods for a particular state and we get a rate of\n10$^{25}\\,\\text{m}^{-3}\\text{s}^{-1}$ for nucleation in a CO$_2$ saturated\nsolution at 255 K (35 K of supercooling). By comparison with our previous work\non methane hydrates, we conclude that nucleation of CO$_2$ hydrates is several\norders of magnitude faster due to a lower interfacial free energy between the\ncrystal and the solution. By combining our nucleation studies with a recent\ncalculation of the hydrate-solution interfacial free energy at coexistence, we\nobtain a prediction of the nucleation rate temperature dependence for\nCO$_{2}$-saturated solutions (the experimentally relevant concentration). On\nthe one hand, we open the window for comparison with experiments for\nsupercooling larger than 25 K. On the other hand, we conclude that homogeneous\nnucleation is impossible for supercooling lower than 20 K. Therefore,\nnucleation must be heterogeneous in typical experiments where hydrate formation\nis observed at low supercooling. To assess the hypothesis that nucleation\noccurs at the solution-CO$_2$ interface we run spontaneous nucleation\nsimulations in two-phase systems and find, by comparison with single-phase\nsimulations, that the interface does not affect hydrate nucleation, at least at\nthe deep supercooling at which this study was carried out (40 and 45 K).\nOverall, our work sheds light on molecular and thermodynamic aspects of hydrate\nnucleation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T06:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.07508v1","title":"Parton Distribution Functions in the Schwinger model from Tensor Network\n  States","summary":"Parton distribution functions (PDFs) describe the inner, non-perturbative\nstructure of hadrons. Their computation involves matrix elements with a Wilson\nline along a direction on the light cone, posing significant challenges in\nEuclidean lattice calculations, where the time direction is not directly\naccessible. We propose implementing the light-front Wilson line within the\nHamiltonian formalism using tensor network techniques. The approach is\ndemonstrated in the massive Schwinger model (quantum electrodynamics in 1+1\ndimensions), a toy model that shares key features with quantum chromodynamics.\nWe present accurate continuum results for the fermion PDF of the vector meson\nat varying fermion masses, obtained from first principle calculations directly\nin Minkowski space. Our strategy also provides a useful path for quantum\nsimulations and quantum computing.","main_category":"hep-lat","categories":"hep-lat,hep-ph,hep-th,physics.comp-ph,quant-ph","published":"2025-04-10T07:10:53Z"}
{"aid":"http://arxiv.org/abs/2504.07510v1","title":"Wigner distribution, Wigner entropy, and Anomalous Transport of a\n  Generalized Aubry-AndrÃ© model","summary":"In this paper, we study a generalized Aubry-Andr\\'{e} model with tunable\nquasidisordered potentials. The model has an invariable mobility edge that\nseparates the extended states from the localized states. At the mobility edge,\nthe wave function presents critical characteristics, which can be verified by\nfinite-size scaling analysis. Our numerical investigations demonstrate that the\nextended, critical, and localized states can be effectively distinguished via\ntheir phase space representation, specially the Wigner distribution. Based on\nthe Wigner distribution function, we can further obtain the corresponding\nWigner entropy and employ the feature that the critical state has the maximum\nWigner entropy to locate the invariable mobility edge. Finally, we reveal that\nthere are anomalous transport phenomena between the transition from ballistic\ntransport to the absence of diffusion.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-10T07:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.07513v1","title":"GPT Carry-On: Training Foundation Model for Customization Could Be\n  Simple, Scalable and Affordable","summary":"Modern large language foundation models (LLM) have now entered the daily\nlives of millions of users. We ask a natural question whether it is possible to\ncustomize LLM for every user or every task. From system and industrial economy\nconsideration, general continue-training or fine-tuning still require\nsubstantial computation and memory of training GPU nodes, whereas most\ninference nodes under deployment, possibly with lower-end GPUs, are configured\nto make forward pass fastest possible. We propose a framework to take full\nadvantages of existing LLMs and systems of online service. We train an\nadditional branch of transformer blocks on the final-layer embedding of\npretrained LLMs, which is the base, then a carry-on module merge the base\nmodels to compose a customized LLM. We can mix multiple layers, or multiple\nLLMs specialized in different domains such as chat, coding, math, to form a new\nmixture of LLM that best fit a new task. As the base model don't need to update\nparameters, we are able to outsource most computation of the training job on\ninference nodes, and only train a lightweight carry-on on training nodes, where\nwe consume less than 1GB GPU memory to train a 100M carry-on layer on 30B LLM.\nWe tested Qwen and DeepSeek opensourced models for continue-pretraining and got\nfaster loss convergence. We use it to improve solving math questions with\nextremely small computation and model size, with 1000 data samples of\nchain-of-thoughts, and as small as 1 MB parameters of two layer layer carry-on,\nand the results are promising.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC,stat.ML","published":"2025-04-10T07:15:40Z"}
{"aid":"http://arxiv.org/abs/2504.07528v1","title":"Deep Learning Based Service Composition in Integrated Aerial-Terrestrial\n  Networks","summary":"The explosive growth of user devices and emerging applications is driving\nunprecedented traffic demands, accompanied by stringent Quality of Service\n(QoS) requirements. Addressing these challenges necessitates innovative service\norchestration methods capable of seamless integration across the edge-cloud\ncontinuum. Terrestrial network-based service orchestration methods struggle to\ndeliver timely responses to growing traffic demands or support users with poor\nor lack of access to terrestrial infrastructure. Exploiting both aerial and\nterrestrial resources in service composition increases coverage and facilitates\nthe use of full computing and communication potentials. This paper proposes a\nservice placement and composition mechanism for integrated aerial-terrestrial\nnetworks over the edge-cloud continuum while considering the dynamic nature of\nthe network. The service function placement and service orchestration are\nmodeled in an optimization framework. Considering the dynamicity, the Aerial\nBase Station (ABS) trajectory might not be deterministic, and their mobility\npattern might not be known as assumed knowledge. Also, service requests can\ntraverse through access nodes due to users' mobility. By incorporating\npredictive algorithms, including Deep Reinforcement Learning (DRL) approaches,\nthe proposed method predicts ABS locations and service requests. Subsequently,\na heuristic isomorphic graph matching approach is proposed to enable efficient,\nlatency-aware service orchestration. Simulation results demonstrate the\nefficiency of the proposed prediction and service composition schemes in terms\nof accuracy, cost optimization, scalability, and responsiveness, ensuring\ntimely and reliable service delivery under diverse network conditions.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-10T07:52:00Z"}
{"aid":"http://arxiv.org/abs/2504.07537v1","title":"Formalizing Representation Theorems for a Logical Framework with\n  Rewriting","summary":"Representation theorems for formal systems often take the form of an\ninductive translation that satisfies certain invariants, which are proved\ninductively. Theory morphisms and logical relations are common patterns of such\ninductive constructions. They allow representing the translation and the proofs\nof the invariants as a set of translation rules, corresponding to the cases of\nthe inductions. Importantly, establishing the invariants is reduced to checking\na finite set of, typically decidable, statements. Therefore, in a framework\nsupporting theory morphisms and logical relations, translations that fit one of\nthese patterns become much easier to formalize and to verify. The\n$\\lambda\\Pi$-calculus modulo rewriting is a logical framework designed for\nrepresenting and translating between formal systems that has previously not\nsystematically supported such patterns. In this paper, we extend it with theory\nmorphisms and logical relations. We apply these to define and verify invariants\nfor a number of translations between formal systems. In doing so, we identify\nsome best practices that enable us to obtain elegant novel formalizations of\nsome challenging translations, in particular type erasure translations from\ntyped to untyped languages.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-10T08:02:40Z"}
{"aid":"http://arxiv.org/abs/2504.07553v1","title":"Single-Cell Trajectory Reconstruction Reveals Migration Potential of\n  Cell Populations","summary":"Cell migration, which is strictly regulated by intracellular and\nextracellular cues, is crucial for normal physiological processes and the\nprogression of certain diseases. However, there is a lack of an efficient\napproach to analyze super-statistical and time-varying characteristics of cell\nmigration based on single trajectories. Here, we propose an approach to\nreconstruct single-cell trajectories, which incorporates wavelet transform,\npower spectrum of an OU-process, and fits of the power spectrum to analyze\nstatistical and time-varying properties of customized target-finding and\nmigration metrics. Our results reveal diverse relationships between motility\nparameters and dynamic metrics, especially the existence of an optimal\nparameter range. Moreover, the analysis reveals that the loss of Arpin protein\nenhances the migration potential of D. discoideum, and a previously reported\nresult that the rescued amoeba is distinguishable from the wild-type amoeba.\nSignificantly, time-varying dynamic metrics emerge periodic phenomena under the\ninfluence of irregularly changing parameters, which correlates with migration\npotential. Our analysis suggests that the approach provides a powerful tool for\nestimating time-dependent migration potential and statistical features of\nsingle-cell trajectories, enabling a better understanding of the relationship\nbetween intracellular proteins and cellular behaviors. This also provides more\ninsights on the migration dynamics of single cells and cell populations.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-10T08:30:07Z"}
{"aid":"http://arxiv.org/abs/2504.07558v1","title":"Atomic structure analysis of PL5 in silicon carbide with single-spin\n  spectroscopy","summary":"Divacancy (VV) spin defects in 4H polytype of silicon carbide (4H-SiC) are\nemerging candidates for quantum information processing and quantum sensing.\nAmong these defects, PL5 and PL6 stand out due to their superior charge\nstability and optically detected magnetic resonance (ODMR) properties at room\ntemperature. However, their atomic structures remain unresolved, with ongoing\ncontroversy regarding their potential association with stacking faults.\nPrevious measurements relying on spin ensemble detection are insufficient to\ndraw definitive conclusions. In this study, we conduct correlative imaging of\nstacking faults and PL5-6 at single-defect level, conclusively demonstrating\nthat PL5-6 are not associated with stacking faults. Further investigation of\nPL5 through single-spin ODMR spectroscopy allows us to determine its six\nspatial orientations, as well as to measure the orientation of its transverse\nanisotropy spin splitting (E) and the statistical distribution of hyperfine\nsplitting. These results and ab initio calculations suggest that PL5 should be\nVsiVc(hk) divacancy coupled with a nearby antisite atom (VVA). The structure\nresolution of PL5 starts the first step toward its controllable fabrication,\npaving the way for various applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.comp-ph,quant-ph","published":"2025-04-10T08:39:40Z"}
{"aid":"http://arxiv.org/abs/2504.07560v1","title":"PhaseGen: A Diffusion-Based Approach for Complex-Valued MRI Data\n  Generation","summary":"Magnetic resonance imaging (MRI) raw data, or k-Space data, is\ncomplex-valued, containing both magnitude and phase information. However,\nclinical and existing Artificial Intelligence (AI)-based methods focus only on\nmagnitude images, discarding the phase data despite its potential for\ndownstream tasks, such as tumor segmentation and classification. In this work,\nwe introduce $\\textit{PhaseGen}$, a novel complex-valued diffusion model for\ngenerating synthetic MRI raw data conditioned on magnitude images, commonly\nused in clinical practice. This enables the creation of artificial\ncomplex-valued raw data, allowing pretraining for models that require k-Space\ninformation. We evaluate PhaseGen on two tasks: skull-stripping directly in\nk-Space and MRI reconstruction using the publicly available FastMRI dataset.\nOur results show that training with synthetic phase data significantly improves\ngeneralization for skull-stripping on real-world data, with an increased\nsegmentation accuracy from $41.1\\%$ to $80.1\\%$, and enhances MRI\nreconstruction when combined with limited real-world data. This work presents a\nstep forward in utilizing generative AI to bridge the gap between\nmagnitude-based datasets and the complex-valued nature of MRI raw data. This\napproach allows researchers to leverage the vast amount of avaliable image\ndomain data in combination with the information-rich k-Space data for more\naccurate and efficient diagnostic tasks. We make our code publicly\n$\\href{https://github.com/TIO-IKIM/PhaseGen}{\\text{available here}}$.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-10T08:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07583v1","title":"Do LLMs Understand Your Translations? Evaluating Paragraph-level MT with\n  Question Answering","summary":"Despite the steady progress in machine translation evaluation, existing\nautomatic metrics struggle to capture how well meaning is preserved beyond\nsentence boundaries. We posit that reliance on a single intrinsic quality\nscore, trained to mimic human judgments, might be insufficient for evaluating\ntranslations of long, complex passages, and a more ``pragmatic'' approach that\nassesses how accurately key information is conveyed by a translation in context\nis needed. We introduce TREQA (Translation Evaluation via Question-Answering),\na framework that extrinsically evaluates translation quality by assessing how\naccurately candidate translations answer reading comprehension questions that\ntarget key information in the original source or reference texts. In\nchallenging domains that require long-range understanding, such as literary\ntexts, we show that TREQA is competitive with and, in some cases, outperforms\nstate-of-the-art neural and LLM-based metrics in ranking alternative\nparagraph-level translations, despite never being explicitly optimized to\ncorrelate with human judgments. Furthermore, the generated questions and\nanswers offer interpretability: empirical analysis shows that they effectively\ntarget translation errors identified by experts in evaluated datasets. Our code\nis available at https://github.com/deep-spin/treqa","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-10T09:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.07589v1","title":"Copy-and-Paste? Identifying EVM-Inequivalent Code Smells in Multi-chain\n  Reuse Contracts","summary":"As the development of Solidity contracts on Ethereum, more developers are\nreusing them on other compatible blockchains. However, developers may overlook\nthe differences between the designs of the blockchain system, such as the Gas\nMechanism and Consensus Protocol, leading to the same contracts on different\nblockchains not being able to achieve consistent execution as on Ethereum. This\ninconsistency reveals design flaws in reused contracts, exposing code smells\nthat hinder code reusability, and we define this inconsistency as\nEVM-Inequivalent Code Smells. In this paper, we conducted the first empirical\nstudy to reveal the causes and characteristics of EVM-Inequivalent Code Smells.\nTo ensure the identified smells reflect real developer concerns, we collected\nand analyzed 1,379 security audit reports and 326 Stack Overflow posts related\nto reused contracts on EVM-compatible blockchains, such as Binance Smart Chain\n(BSC) and Polygon. Using the open card sorting method, we defined six types of\nEVM-Inequivalent Code Smells. For automated detection, we developed a tool\nnamed EquivGuard. It employs static taint analysis to identify key paths from\ndifferent patterns and uses symbolic execution to verify path reachability. Our\nanalysis of 905,948 contracts across six major blockchains shows that\nEVM-Inequivalent Code Smells are widespread, with an average prevalence of\n17.70%. While contracts with code smells do not necessarily lead to financial\nloss and attacks, their high prevalence and significant asset management\nunderscore the potential threats of reusing these smelly Ethereum contracts.\nThus, developers are advised to abandon Copy-and-Paste programming practices\nand detect EVM-Inequivalent Code Smells before reusing Ethereum contracts.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T09:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.07605v1","title":"Strong Decays of Charmonia","summary":"In this work, we calculate the charmonium spectrum and strong decay widths of\ncc states. The calculations are performed using the quark potential model with\nwhich incorporates the relativistic effects. The resulting cc spectrum exhibits\na good agreement with experimental data. The open flavor strong decay widths\nare calculated employing the 3P0 model. We adopt two choices of wave functions\nto determine the observables: the first involves the utilization of realistic\nwave functions obtained by solving relativistic Schrodinger equation, while the\nsecond employs Simple harmonic oscillator (SHO) wave functions whose parameters\nare fitted to the realistic wave functions. We find that the decay widths of\nhigher charmonia states above the threshold value of open charm mesons are well\ndescribed with these wave functions. We provide a comprehensive analysis of the\nstrong decay widths and assigned specific charmonium states: X(3940) is\nassigned to the {\\eta}c(3S) state, Y (4660) to the {\\psi}(5S) state, X(3915) to\nthe \\c{hi}0(2P) state, Zc(3900) to the hc(2P) state, X(4350) to the \\c{hi}2(3P)\nstate, and X(3842) to the {\\psi}3(1D) state. We also compare our results with\navailable experimental data and theoretical predictions of other models.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T09:56:23Z"}
{"aid":"http://arxiv.org/abs/2504.07624v1","title":"ConceptFormer: Towards Efficient Use of Knowledge-Graph Embeddings in\n  Large Language Models","summary":"Retrieval Augmented Generation (RAG) has enjoyed increased attention in the\nrecent past and recent advancements in Large Language Models (LLMs) have\nhighlighted the importance of integrating world knowledge into these systems.\nCurrent RAG methodologies often modify the internal architecture of pre-trained\nlanguage models (PLMs) or rely on textifying knowledge graphs (KGs), which is\ninefficient in terms of token usage. This paper introduces ConceptFormer, a new\napproach to augment LLMs with structured knowledge from KGs, such as Wikidata,\nwithout altering their internal structure or relying on textual input of KGs.\nConceptFormer operates in the LLM embedding vector space, creating and\ninjecting \\emph{concept vectors} that encapsulate the information of the KG\nnodes directly. Trained in conjunction with a frozen LLM, ConceptFormer\ngenerates a comprehensive lookup table that maps KG nodes to their respective\nconcept vectors. The approach aims to enhance the factual recall capabilities\nof LLMs by enabling them to process these concept vectors natively, thus\nenriching them with structured world knowledge in an efficient and scalable\nmanner. Our experiments demonstrate that the addition of concept vectors to\nGPT-2 0.1B substantially increases its factual recall ability (Hit@10) by up to\n272\\% when tested on sentences from Wikipedia and up to 348\\% on synthetically\ngenerated sentences. Even injecting only a single concept vector into the\nprompt increases factual recall ability (Hit@10) by up to 213\\% on Wikipedia\nsentences, significantly outperforming RAG with graph textification while\nconsuming 130x fewer input tokens.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-04-10T10:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.07630v1","title":"An intrinsic cosmological observer","summary":"There has been much recent interest in the necessity of an observer degree of\nfreedom in the description of local algebras in semiclassical gravity. In this\nwork, we describe an example where the observer can be constructed\nintrinsically from the quantum fields. This construction involves the slow-roll\ninflation example recently analyzed by Chen and Penington, in which the\ngauge-invariant gravitational algebra arises from marginalizing over modular\nflow in a de Sitter static patch. We relate this procedure to the\nConnes-Takesaki theory of the flow of weights for type III von Neumann\nalgebras, and further show that the resulting gravitational algebra can\nnaturally be presented as a crossed product. This leads to a decomposition of\nthe gravitational algebra into quantum field and observer degrees of freedom,\nwith different choices of observer being related to changes in a quantum\nreference frame for the algebra. We also connect this example to other\nconstructions of type II algebras in semiclassical gravity, and argue they all\nshare the feature of being the result of gauging modular flow. The arguments in\nthis work involve various properties of automorphism groups of hyperfinite\nfactors, and so in an appendix we review the structure of these groups, which\nmay be of independent interest for further investigations into von Neumann\nalgebras in quantum gravity.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-10T10:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.07651v1","title":"Nonperturbative quantum theory of multiplasmonic electron emission from\n  surfaces: Gauge-specific cumulant expansions vs. Volkov ansatz over plasmonic\n  coherent states","summary":"Energetic electromagnetic fields produce a variety of elementary excitations\nin solids that can strongly modify their primary photoemission spectra. Such is\nthe plasmon excitation or pumping mechanism which, although indirect, is very\nefficient and hence may give rise to formation of plasmonic coherent states. In\nturn, these states may act as a source or sink of energy and momentum for\nescaping electrons. Starting from the model Hamiltonian approach we show that\nprepumped plasmonic bath of coherent states gives rise to ponderomotive\npotentials and Floquet electronic band structure that support multiple\nplasmon-induced electron emission or plasmoemission from metals. Theoretical\ndescription of multiple plasmoemission requires a nonperturbative approch which\nis here formulated by applying cumulant expansion and Volkov ansatz to the\ncalculations of electron wavefunctions and emission rates. The calculations are\nperformed in the standard length gauge as well as in the Pauli-transformed\nvelocity gauge for electron-plasmon interaction. The applicability of two\nnonperturbative approaches to calculation of excitation amplitudes are examined\nin each gauge. They smoothly interpolate between the fully quantal first order\nBorn approximation and semiclassical multiplasmon-induced electron excitation\nlimit. This is illustrated on the example of plasmoemission from Floquet\nsurface bands on Ag(111) from which this channel of electron yield has been\ndetected. Our calculations indicate that even subsingle mode occupations of\nplasmonic coherent states can support multiplasmon electron emission from\nsurface bands. A way of calibration of plasmonic coherent states is proposed.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-10T10:58:28Z"}
{"aid":"http://arxiv.org/abs/2504.07659v1","title":"Tidal heating in binary inspiral of strange quark stars","summary":"We investigate tidal heating associated with the binary inspiral of strange\nquark stars and its impact on the resulting gravitational wave signal. Tidal\nheating during the merger of neutron stars composed of nuclear matter may be\nconsidered negligible, but it has been demonstrated recently that the presence\nof hyperons at high densities could significantly enhance the dissipation\nduring inspiral. In this work, we evaluate the bulk viscosity arising from\nnon-leptonic weak processes involving quarks and show that it can be several\norders of magnitude higher than the viscosity of nuclear matter at temperatures\nrelevant to the inspiral phase of the merger of strange stars. We model strange\nquark matter in the normal phase using a non-ideal bag model including\nelectrons and ensure compatibility with astrophysical constraints. By analysing\nequal-mass binary systems with component masses ranging from 1.4 to 1.8 $\\,\nM_{\\odot}$, we find that temperatures close to 0.1 MeV are reached by the end\nof the inspiral phase. We also estimate the effect on the gravitational\nwaveform and conclude that the additional phase shift could range from $0.1$ to\n$0.5$ radians for strange quark masses of 200 MeV, making it potentially\ndetectable by next-generation gravitational wave detectors. Given that tidal\nheating from hyperons is dominant only for very massive neutron stars having\nmasses 1.8 to 2.0 $\\, M_{\\odot}$, a successful detection of this phase shift\nduring the inspiral of binary systems with relatively low masses of 1.4 to 1.6\n$\\, M_{\\odot}$ could be a smoking gun signature for the existence of strange\nquark stars.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,nucl-th","published":"2025-04-10T11:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.07671v1","title":"Cross-Laplacians Based Topological Signal Processing over Cell\n  MultiComplexes","summary":"The study of the interactions among different types of interconnected systems\nin complex networks has attracted significant interest across many research\nfields. However, effective signal processing over layered networks requires\ntopological descriptors of the intra- and cross-layers relationships that are\nable to disentangle the homologies of different domains, at different scales,\naccording to the specific learning task. In this paper, we present Cell\nMultiComplex (CMC) spaces, which are novel topological domains for representing\nmultiple higher-order relationships among interconnected complexes. We\nintroduce cross-Laplacians matrices, which are algebraic descriptors of CMCs\nenabling the extraction of topological invariants at different scales, whether\nglobal or local, inter-layer or intra-layer. Using the eigenvectors of these\ncross-Laplacians as signal bases, we develop topological signal processing\ntools for CMC spaces. In this first study, we focus on the representation and\nfiltering of noisy flows observed over cross-edges between different layers of\nCMCs to identify cross-layer hubs, i.e., key nodes on one layer controlling the\nothers.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T11:42:58Z"}
{"aid":"http://arxiv.org/abs/2504.07678v1","title":"Exploiting Beamforming for Enforcing Semantic Secrecy in 5G NR mmWave\n  Communications","summary":"We experimentally investigate the performance of semantically-secure physical\nlayer security (PLS) in 5G new radio (NR) mmWave communications during the\ninitial cell search procedure in the NR band n257 at 27 GHz. A gNB transmits\nPLS-encoded messages in the presence of an eavesdropper, who intercepts the\ncommunication by non-intrusively collecting channel readings in the form of IQ\nsamples. For the message transmission, we use the physical broadcast channel\n(PBCH) within the synchronization signal block. We analyze different\nsignal-to-noise ratio (SNR) conditions by progressively reducing the transmit\npower of the subcarriers carrying the PBCH channel, while ensuring optimal\nconditions for over-the-air frequency and timing synchronization. We measure\nthe secrecy performance of the communication in terms of upper and lower bounds\nfor the distinguishing error rate (DER) metric for different SNR levels and\nbeam angles when performing beamsteering in indoor scenarios, such as office\nenvironments and laboratory settings.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T12:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.07683v1","title":"Effects of Berry Curvature and Orbital Magnetic Moment in the\n  Magnetothermoelectric Transport of Bloch Electron Systems","summary":"Thermoelectric transport coefficients up to linear order in the applied\nmagnetic field are microscopically studied using Kubo-Luttinger linear response\ntheory and thermal Green's functions. We derive exact formulas for the\nthermoelectric conductivity and thermal conductivity in the limit of small\nrelaxation rates for Bloch electrons in terms of Bloch wave functions, which\nshow that the Sommerfeld-Bethe relationship holds. Our final formula contains\nthe Berry curvature contributions as well as the orbital magnetic moment\ncontributions, that arise naturally from the microscopic theory. We show that\ngeneralized $f$-sum rules containing the Berry curvature and orbital magnetic\nmoment play essential roles in taking into account the interband effects of the\nmagnetic field. As an application, we study a model of a gapped Dirac electron\nsystem with broken time-reversal symmetry and show the presence of a linear\nmagnetothermopower in such systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T12:13:35Z"}
{"aid":"http://arxiv.org/abs/2504.07684v1","title":"Improving Photometric Redshift Estimation for CSST Mock Catalog Using\n  SED Templates Calibrated with Perturbation Algorithm","summary":"Photometric redshifts of galaxies obtained by multi-wavelength data are\nwidely used in photometric surveys because of its high efficiency. Although\nvarious methods have been developed, template fitting is still adopted as one\nof the most popular approaches. Its accuracy strongly depends on the quality of\nthe Spectral Energy Distribution (SED) templates, which can be calibrated using\nbroadband photometric data from galaxies with known spectroscopic redshifts.\nSuch calibration is expected to improve photometric redshift accuracy, as the\ncalibrated templates will align with observed photometric data more closely.\nThe upcoming China Space Station Survey Telescope (CSST) is one of the Stage IV\nsurveys, which aiming for high precision cosmological studies. To improve the\naccuracy of photometric redshift estimation for CSST, we calibrated the CWW+KIN\ntemplates using a perturbation algorithm with broadband photometric data from\nthe CSST mock catalog. This calibration used a training set consisting of\napproximately 4,500 galaxies, which is 10% of the total galaxy sample. The\noutlier fraction and scatter of the photometric redshifts derived from the\ncalibrated templates are 2.55% and 0.036, respectively. Compared to the CWW+KIN\ntemplates, these values are reduced by 34% and 23%, respectively. This\ndemonstrates that SED templates calibrated with a small training set can\neffectively optimize photometric redshift accuracy for future large-scale\nsurveys like CSST, especially with limited spectral training data.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T12:13:55Z"}
{"aid":"http://arxiv.org/abs/2504.07692v1","title":"Singularity resolution and inflation from an infinite tower of\n  regularized curvature corrections","summary":"We explore four-dimensional scalar-tensor theories obtained from well-defined\ndimensional regularizations of Lovelock invariants. When an infinite tower of\ncorrections is considered, these theories allow for cosmological models in\nwhich the Big Bang singularity is replaced by an inflationary phase in the\nearly-universe, and they also admit a specific class of regular black hole\nsolutions.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-04-10T12:26:03Z"}
{"aid":"http://arxiv.org/abs/2504.07695v1","title":"Learning Higher-Order Interactions in Brain Networks via Topological\n  Signal Processing","summary":"Our goal in this paper is to leverage the potential of the topological signal\nprocessing (TSP) framework for analyzing brain networks. Representing brain\ndata as signals over simplicial complexes allows us to capture higher-order\nrelationships within brain regions of interest (ROIs). Here, we focus on\nlearning the underlying brain topology from observed neural signals using two\ndistinct inference strategies. The first method relies on higher-order\nstatistical metrics to infer multiway relationships among ROIs. The second\nmethod jointly learns the brain topology and sparse signal representations, of\nboth the solenoidal and harmonic components of the signals, by minimizing the\ntotal variation along triangles and the data-fitting errors. Leveraging the\nproperties of solenoidal and irrotational signals, and their physical\ninterpretations, we extract functional connectivity features from brain\ntopologies and uncover new insights into functional organization patterns. This\nallows us to associate brain functional connectivity (FC) patterns of\nconservative signals with well-known functional segregation and integration\nproperties. Our findings align with recent neuroscience research, suggesting\nthat our approach may offer a promising pathway for characterizing the\nhigher-order brain functional connectivities.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T12:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.07699v1","title":"How to identify the object with mass range of $(2.2-3)M_\\odot$ in the\n  merger of compact star systems","summary":"High-frequency gravitational-wave (GW) radiation has been detected by\nLIGO-Virgo-KAGRA in the merger of compact stars. However, two GW events,\nGW190814 and GW200210, the mass of one companion object falls into the mass\nregion of $(2.2-3)\\rm~M_\\odot$, and how to identify such object (e.g., as a\nlow-mass black hole (BH) or a massive neutron star (NS)) remains an open\nquestion. In this paper, we propose a method to identify the mystery compact\nobject (MCO) with the mass region of $(2.2-3)\\rm~M_\\odot$ in a binary system\nvia the possible electromagnetic (EM) radiations before and after the mergers.\nA multi-band EM emission can be produced with $L\\propto(-t)^{7/4}$ (or\n$L\\propto(-t)^{-5/4}$) during the inspiral phase due to the BH battery (or\ninteraction magnetospheres) mechanism, and a bright (or dark) kilonova emission\nis powered by radioactive decay with ejecta mass ratio $q>1.7$ (or $q<1.7$)\nduring the post-merge state when MCO is as a low-mass BH (or massive NS) to\nmerger with NS. Moreover, by considering the merger system between MCO and a BH\nwhen MCO is a massive NS, we find that it requires the BH with high spin (e.g.,\n$a\\sim0.8-0.99$) to make sure the tidal disruption event (TDE) occurred, and a\nmulti-band precursor emission and bright kilonova emission can also be produced\nduring the inspiral phase and post-merge state, respectively. In any case, no\nmatter which mechanism we adopt, such precursor emissions are too weak to be\ndetected by most current telescopes unless the distance is close enough.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T12:34:23Z"}
{"aid":"http://arxiv.org/abs/2504.07701v1","title":"Magnetic polarons at finite temperature: One-hole spectroscopy study","summary":"The physics of strongly correlated fermions described by Hubbard or $t$-$J$\nmodels in the underdoped regime -- relevant for high-temperature\nsuperconductivity in cuprate compounds -- remains a subject of ongoing debate.\nIn particular, the nature of charge carriers in this regime is poorly\nunderstood, in part due to the unusual properties of their spectral function.\nIn this Letter, we present unbiased numerical results for the one-hole spectral\nfunction in a $t$-$J$ model at finite temperatures. Our study provides valuable\ninsights into the underlying physics of magnetic (or spin-) polaron formation\nin a doped antiferromagnet (AFM). For example, we find how the suppression of\nspectral weight outside the magnetic Brillouin zone -- a precursor of Fermi arc\nformation -- disappears with increasing temperature, revealing\nnearly-deconfined spinon excitations of the undoped AFM. The pristine setting\nwe consider can be directly explored using quantum simulators. Our calculations\ndemonstrate that coherent quasiparticle peaks associated with magnetic polarons\ncan be observed up to temperatures $T>J$ above the spin-exchange $J$, routinely\nobtained in such experiments. This paves the way for future studies of the fate\nof magnetic polarons in the pseudogap phase.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.quant-gas","published":"2025-04-10T12:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.07704v1","title":"Measures of non-simplifyingness for conditional copulas and vines","summary":"In copula modeling, the simplifying assumption has recently been the object\nof much interest. Although it is very useful to reduce the computational\nburden, it remains far from obvious whether it is actually satisfied in\npractice. We propose a theoretical framework which aims at giving a precise\nmeaning to the following question: how non-simplified or close to be simplified\nis a given conditional copula? For this, we propose a theoretical framework\ncentered at the notion of measure of non-constantness. Then we discuss\ngeneralizations of the simplifying assumption to the case where the conditional\nmarginal distributions may not be continuous, and corresponding measures of\nnon-simplifyingness in this case. The simplifying assumption is of particular\nimportance for vine copula models, and we therefore propose a notion of measure\nof non-simplifyingness of a given copula for a particular vine structure, as\nwell as different scores measuring how non-simplified such a vine\ndecompositions would be for a general vine. Finally, we propose estimators for\nthese measures of non-simplifyingness given an observed dataset.","main_category":"math.ST","categories":"math.ST,stat.OT,stat.TH","published":"2025-04-10T12:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.07706v1","title":"Strong laws of large numbers for sequences of blockwise $m$-dependent\n  and orthogonal random variables under sublinear expectations","summary":"In this paper, we establish some strong laws of large numbers (SLLN) for\nnon-independent variables under the framework of sublinear expectations. One of\nour main results is for blockwise m-dependent random variables and another is\nfor orthogonal random variables, both of which are the generalization of SLLN\nfor independent random variables in sublinear expectation spaces.","main_category":"math.PR","categories":"math.PR","published":"2025-04-10T12:47:27Z"}
{"aid":"http://arxiv.org/abs/2504.07708v1","title":"TOCALib: Optimal control library with interpolation for bimanual\n  manipulation and obstacles avoidance","summary":"The paper presents a new approach for constructing a library of optimal\ntrajectories for two robotic manipulators, Two-Arm Optimal Control and\nAvoidance Library (TOCALib). The optimisation takes into account kinodynamic\nand other constraints within the FROST framework. The novelty of the method\nlies in the consideration of collisions using the DCOL method, which allows\nobtaining symbolic expressions for assessing the presence of collisions and\nusing them in gradient-based optimization control methods. The proposed\napproach allowed the implementation of complex bimanual manipulations. In this\npaper we used Mobile Aloha as an example of TOCALib application. The approach\ncan be extended to other bimanual robots, as well as to gait control of bipedal\nrobots. It can also be used to construct training data for machine learning\ntasks for manipulation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T12:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.07712v1","title":"On the instabilities of naive FEM discretizations for PDEs with\n  sign-changing coefficients","summary":"We consider a scalar diffusion equation with a sign-changing coefficient in\nits principle part. The well-posedness of such problems has already been\nstudied extensively provided that the contrast of the coefficient is\nnon-critical. Furthermore, many different approaches have been proposed to\nconstruct stable discretizations thereof, because naive finite element\ndiscretizations are expected to be non-reliable in general. However, no\nexplicit example proving the actual instability is known and numerical\nexperiments often do not manifest instabilities in a conclusive manner. To this\nend we construct an explicit example with a broad family of meshes for which we\nprove that the corresponding naive finite element discretizations are unstable.\nOn the other hand, we also provide a broad family of (non-symmetric) meshes for\nwhich we prove that the discretizations are stable. Together, these two\nfindings explain the results observed in numerical experiments.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-10T13:04:58Z"}
{"aid":"http://arxiv.org/abs/2504.07727v1","title":"Exploratory calculation of the rare hyperon decay $Î£^+ \\to p \\ell^+\n  \\ell^-$ from lattice QCD","summary":"The rare hyperon decay $\\Sigma^+ \\to p \\ell^+ \\ell^-$ is a flavour-changing\nneutral current process mediated by an $s \\to d$ transition that occurs only at\nloop level within the Standard Model. Consequently, this decay is highly\nsuppressed, making it a promising avenue for probing potential new physics.\nWhile phenomenological calculations have made important progress in predicting\nthe decay amplitude, there remains a four-fold ambiguity in the relevant\ntransition form factors that prevents a unique prediction for the branching\nfraction and angular observables. Fully resolving this ambiguity requires a\nfirst-principles Standard-Model calculation, and the recent observation of this\nprocess using LHCb Run 2 data reinforces the timeliness of such a calculation.\nIn this work, we present the first lattice-QCD calculation of this decay,\nperformed using a 2+1-flavour domain-wall fermion ensemble with a pion mass of\n340 MeV. At a small baryon source-sink separation, we observe the emergence of\na signal in the relevant baryonic four-point functions. This allows us to\ndetermine the positive-parity form factors for the rare hyperon decays from\nfirst-principles, albeit with large statistical and systematic uncertainties.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-10T13:20:40Z"}
{"aid":"http://arxiv.org/abs/2504.07748v1","title":"Versatile ultrafast single-shot imaging","summary":"Ultrafast single-shot imaging techniques now reach frame rates of tens of\ntera-frame-per-second (Tfps) and long sequence depths but are often too complex\nfor large-scale use, both in terms of image acquisition and reconstruction. We\npropose an extremely simple yet high-performance method that leverages the\ncapabilities of two prominent technologies: acousto-optical pulse shaping and\nlight-field based hyperspectral imaging. We demonstrate the capabilities of the\ntechnique by capturing laser-induced phenomena at frame rates on par with the\nstate-of-the-art, and with the potential to reach the peta-frame-per-second,\nwhile keeping a versatile setup that is easily adaptable to various input pulse\nshapes and dynamic events. Furthermore, an extra degree of freedom is added to\nthe system through the use of digital in-line holography on the single-shot\nmotion pictures. The agility and performance of this technique could then open\nup new horizons for single-shot imaging techniques, making them accessible to a\nwider community.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T13:44:33Z"}
{"aid":"http://arxiv.org/abs/2504.07759v1","title":"Characterization of the Electronic Noise in the Readout of Resistive\n  Micromegas in the High-Angle Time Projection Chambers of the T2K Experiment","summary":"The two high-angle Time Projection Chambers of the T2K experiment are\nequipped with a new readout system based on resistive Micromegas detector\ntechnology, and utilize custom-made electronics based on AFTER chips for signal\nprocessing. This study analyzes and characterizes the electronic noise of the\ndetector readout chain to develop a comprehensive noise model. The model\nenables the generation of Monte Carlo simulations to investigate systematic\neffects in signal processing. The analysis is based on data collected from 32\nresistive Micromegas detectors, recorded without zero suppression. All\ndetectors exhibit a quasi-identical and time-stable noise level. The developed\nanalytical model accurately describes the observed noise, and derived Monte\nCarlo simulations show excellent agreement with experimental data.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-10T13:56:40Z"}
{"aid":"http://arxiv.org/abs/2504.07761v1","title":"Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection","summary":"In an increasingly digitalized world, verifying the authenticity of ID\ndocuments has become a critical challenge for real-life applications such as\ndigital banking, crypto-exchanges, renting, etc. This study focuses on the\ntopic of fake ID detection, covering several limitations in the field. In\nparticular, no publicly available data from real ID documents exists, and most\nstudies rely on proprietary in-house databases that are not available due to\nprivacy reasons. In order to shed some light on this critical challenge that\nmakes difficult to advance in the field, we explore a trade-off between privacy\n(i.e., amount of sensitive data available) and performance, proposing a novel\npatch-wise approach for privacy-preserving fake ID detection. Our proposed\napproach explores how privacy can be enhanced through: i) two levels of\nanonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii)\ndifferent patch size configurations, varying the amount of sensitive data\nvisible in the patch image. Also, state-of-the-art methods such as Vision\nTransformers and Foundation Models are considered in the analysis. The\nexperimental framework shows that, on an unseen database (DLC-2021), our\nproposal achieves 13.91% and 0% EERs at patch and ID document level, showing a\ngood generalization to other databases. In addition to this exploration,\nanother key contribution of our study is the release of the first publicly\navailable database that contains 48,400 patches from both real and fake ID\ndocuments, along with the experimental framework and models, which will be\navailable in our GitHub.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-10T14:01:22Z"}
{"aid":"http://arxiv.org/abs/2504.07771v1","title":"Penalized Linear Models for Highly Correlated High-Dimensional\n  Immunophenotyping Data","summary":"Accurate prediction and identification of variables associated with outcomes\nor disease states are critical for advancing diagnosis, prognosis, and\nprecision medicine in biomedical research. Regularized regression techniques,\nsuch as lasso, are widely employed to enhance interpretability by reducing\nmodel complexity and identifying significant variables. However, when applying\nto biomedical datasets, e.g., immunophenotyping dataset, there are two major\nchallenges that may lead to unsatisfactory results using these methods: 1) high\ncorrelation between predictors, which leads to the exclusion of important\nvariables with included predictors in variable selection, and 2) the presence\nof skewness, which violates key statistical assumptions of these methods.\nCurrent approaches that fail to address these issues simultaneously may lead to\nbiased interpretations and unreliable coefficient estimates. To overcome these\nlimitations, we propose a novel two-step approach, the Bootstrap-Enhanced\nRegularization Method (BERM). BERM outperforms existing two-step approaches and\ndemonstrates consistent performance in terms of variable selection and\nestimation accuracy across simulated sparsity scenarios. We further demonstrate\nthe effectiveness of BERM by applying it to a human immunophenotyping dataset\nidentifying important immune parameters associated the autoimmune disease, type\n1 diabetes.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-10T14:10:42Z"}
{"aid":"http://arxiv.org/abs/2504.07775v1","title":"Focal Cortical Dysplasia Type II Detection Using Cross Modality Transfer\n  Learning and Grad-CAM in 3D-CNNs for MRI Analysis","summary":"Focal cortical dysplasia (FCD) type II is a major cause of drug-resistant\nepilepsy, often curable only by surgery. Despite its clinical importance, the\ndiagnosis of FCD is very difficult in MRI because of subtle abnormalities,\nleading to misdiagnosis. This study investigates the use of 3D convolutional\nneural networks (3D-CNNs) for FCD detection, using a dataset of 170 subjects\n(85 FCD patients and 85 controls) composed of T1-weighted and FLAIR MRI scans.\nIn particular, it investigates the benefits obtained from cross-modality\ntransfer learning and explainable artificial intelligence (XAI) techniques, in\nparticular Gradient-weighted Class Activation Mapping (Grad-CAM). ResNet\narchitectures (ResNet-18, -34, and -50) were implemented, employing transfer\nlearning strategies that used pre-trained weights from segmentation tasks.\nResults indicate that transfer learning significantly enhances classification\naccuracy (up to 80.3%) and interpretability, as measured by a novel Heat-Score\nmetric, which evaluates the model's focus on clinically relevant regions.\nImprovements in the Heat-Score metric underscore the model's seizure zone\nlocalization capabilities, bringing AI predictions and clinical insights closer\ntogether. These results highlight the importance of transfer learning,\nincluding cross-modality, and XAI in advancing AI-based medical diagnostics,\nespecially for difficult-to-diagnose pathologies such as FCD.","main_category":"eess.IV","categories":"eess.IV,cs.CV,physics.med-ph","published":"2025-04-10T14:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.07783v1","title":"On approximation of convex functionals with a convexity constraint and\n  general Lagrangians","summary":"In this note, we prove that minimizers of convex functionals with a convexity\nconstraint and a general class of Lagrangians can be approximated by solutions\nto fourth-order equations of Abreu type. Our result generalizes that of Le\n(Twisted Harnack inequality and approximation of variational problems with a\nconvexity constraint by singular Abreu equations. Adv. Math. 434 (2023)) where\nthe case of quadratically growing Lagrangians was treated.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T14:22:04Z"}
{"aid":"http://arxiv.org/abs/2504.07788v1","title":"Generalized Passivity Sensitivity Methodology for Small-Signal Stability\n  Analysis","summary":"This paper proposes a generalized passivity sensitivity analysis for power\nsystem stability studies. The method uncovers the most effective instability\nmitigation actions for both device-level and system-level investigations. The\nparticular structure of the admittance and nodal models is exploited in the\ndetailed derivation of the passivity sensitivity expressions. These proposed\nsensitivities are validated for different parameters at device-level and at\nsystem-level. Compared to previous stability and sensitivity methods, it does\nnot require detailed system information, such as exact system eigenvalues,\nwhile it provides valuable information for a less conservative stable system\ndesign. In addition, we demonstrate how to utilize the proposed method through\ncase studies with different converter controls and system-wide insights showing\nits general applicability.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T14:23:23Z"}
{"aid":"http://arxiv.org/abs/2504.07790v1","title":"Electronic structure of fullerene nanoribbons","summary":"Using first-principles calculations, we examine the electronic structure of\nquasi-one-dimensional fullerene nanoribbons derived from two-dimensional\nfullerene networks. Depending on the edge geometry and width, these nanoribbons\nexhibit a rich variety of properties, including direct and indirect band gaps,\npositive and negative effective masses, as well as dispersive and flat bands.\nOur findings establish a comprehensive understanding of the electronic\nproperties of fullerene nanoribbons, with potential implications for the design\nof future nanoscale devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.app-ph,physics.atm-clus,physics.chem-ph","published":"2025-04-10T14:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.07796v1","title":"Numerical solution by shape optimization method to an inverse shape\n  problem in multi-dimensional advection-diffusion problem with space dependent\n  coefficients","summary":"This work focuses on numerically solving a shape identification problem\nrelated to advection-diffusion processes with space-dependent coefficients\nusing shape optimization techniques. Two boundary-type cost functionals are\nconsidered, and their corresponding variations with respect to shapes are\nderived using the adjoint method, employing the chain rule approach. This\ninvolves firstly utilizing the material derivative of the state system and\nsecondly using its shape derivative. Subsequently, an alternating direction\nmethod of multipliers (ADMM) combined with the Sobolev-gradient-descent\nalgorithm is applied to stably solve the shape reconstruction problem.\nNumerical experiments in two and three dimensions are conducted to demonstrate\nthe feasibility of the methods.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-10T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.07815v1","title":"Siren Federate: Bridging document, relational, and graph models for\n  exploratory graph analysis","summary":"Investigative workflows require interactive exploratory analysis on large\nheterogeneous knowledge graphs. Current databases show limitations in enabling\nsuch task. This paper discusses the architecture of Siren Federate, a system\nthat efficiently supports exploratory graph analysis by bridging\ndocument-oriented, relational and graph models. Technical contributions include\ndistributed join algorithms, adaptive query planning, query plan folding,\nsemantic caching, and semi-join decomposition for path query. Semi-join\ndecomposition addresses the exponential growth of intermediate results in\npath-based queries. Experiments show that Siren Federate exhibits low latency\nand scales well with the amount of data, the number of users, and the number of\ncomputing nodes.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T14:52:03Z"}
{"aid":"http://arxiv.org/abs/2504.07818v1","title":"Performance of Rank-One Tensor Approximation on Incomplete Data","summary":"We are interested in the estimation of a rank-one tensor signal when only a\nportion $\\varepsilon$ of its noisy observation is available. We show that the\nstudy of this problem can be reduced to that of a random matrix model whose\nspectral analysis gives access to the reconstruction performance. These results\nshed light on and specify the loss of performance induced by an artificial\nreduction of the memory cost of a tensor via the deletion of a random part of\nits entries.","main_category":"stat.ML","categories":"stat.ML,cs.LG,math.PR","published":"2025-04-10T14:57:09Z"}
{"aid":"http://arxiv.org/abs/2504.07822v1","title":"DG-STMTL: A Novel Graph Convolutional Network for Multi-Task\n  Spatio-Temporal Traffic Forecasting","summary":"Spatio-temporal traffic prediction is crucial in intelligent transportation\nsystems. The key challenge of accurate prediction is how to model the complex\nspatio-temporal dependencies and adapt to the inherent dynamics in data.\nTraditional Graph Convolutional Networks (GCNs) often struggle with static\nadjacency matrices that introduce domain bias or learnable matrices that may be\noverfitting to specific patterns. This challenge becomes more complex when\nconsidering Multi-Task Learning (MTL). While MTL has the potential to enhance\nprediction accuracy through task synergies, it can also face significant\nhurdles due to task interference. To overcome these challenges, this study\nintroduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task\nLearning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation\nmodule that combines static matrices with dynamic ones through a task-specific\ngating mechanism. We also introduce a group-wise GCN module to enhance the\nmodelling capability of spatio-temporal dependencies. We conduct extensive\nexperiments on two real-world datasets to evaluate our method. Results show\nthat our method outperforms other state-of-the-arts, indicating its\neffectiveness and robustness.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T15:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.07828v1","title":"Dynamic disruption index across citation and cited references windows:\n  Recommendations for thresholds in research evaluation","summary":"The temporal dimension of citation accumulation poses fundamental challenges\nfor quantitative research evaluations, particularly in assessing disruptive and\nconsolidating research through the disruption index (D). While prior studies\nemphasize minimum citation windows (mostly 3-5 years) for reliable citation\nimpact measurements, the time-sensitive nature of D - which quantifies a paper'\ns capacity to eclipse prior knowledge - remains underexplored. This study\naddresses two critical gaps: (1) determining the temporal thresholds required\nfor publications to meet citation/reference prerequisites, and (2) identifying\n\"optimal\" citation windows that balance early predictability and longitudinal\nvalidity. By analyzing millions of publications across four fields with varying\ncitation dynamics, we employ some metrics to track D stabilization patterns.\nKey findings reveal that a 10-year window achieves >80% agreement with final D\nclassifications, while shorter windows (3 years) exhibit instability.\nPublications with >=30 references stabilize 1-3 years faster, and extreme cases\n(top/bottom 5% D values) become identifiable within 5 years - enabling early\ndetection of 60-80% of highly disruptive and consolidating works. The findings\noffer significant implications for scholarly evaluation and science policy,\nemphasizing the need for careful consideration of citation window length in\nresearch assessment (based on D).","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-10T15:05:01Z"}
{"aid":"http://arxiv.org/abs/2504.07851v1","title":"Independence Is Not an Issue in Neurosymbolic AI","summary":"A popular approach to neurosymbolic AI is to take the output of the last\nlayer of a neural network, e.g. a softmax activation, and pass it through a\nsparse computation graph encoding certain logical constraints one wishes to\nenforce. This induces a probability distribution over a set of random\nvariables, which happen to be conditionally independent of each other in many\ncommonly used neurosymbolic AI models. Such conditionally independent random\nvariables have been deemed harmful as their presence has been observed to\nco-occur with a phenomenon dubbed deterministic bias, where systems learn to\ndeterministically prefer one of the valid solutions from the solution space\nover the others. We provide evidence contesting this conclusion and show that\nthe phenomenon of deterministic bias is an artifact of improperly applying\nneurosymbolic AI.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T15:28:36Z"}
{"aid":"http://arxiv.org/abs/2504.07858v1","title":"Empowering Global Voices: A Data-Efficient, Phoneme-Tone Adaptive\n  Approach to High-Fidelity Speech Synthesis","summary":"Text-to-speech (TTS) technology has achieved impressive results for widely\nspoken languages, yet many under-resourced languages remain challenged by\nlimited data and linguistic complexities. In this paper, we present a novel\nmethodology that integrates a data-optimized framework with an advanced\nacoustic model to build high-quality TTS systems for low-resource scenarios. We\ndemonstrate the effectiveness of our approach using Thai as an illustrative\ncase, where intricate phonetic rules and sparse resources are effectively\naddressed. Our method enables zero-shot voice cloning and improved performance\nacross diverse client applications, ranging from finance to healthcare,\neducation, and law. Extensive evaluations - both subjective and objective -\nconfirm that our model meets state-of-the-art standards, offering a scalable\nsolution for TTS production in data-limited settings, with significant\nimplications for broader industry adoption and multilingual accessibility.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-10T15:32:57Z"}
{"aid":"http://arxiv.org/abs/2504.07861v1","title":"Horizons, throats and bounces in hybrid metric-Palatini gravity with a\n  non-zero potential","summary":"This work conducts an in-depth exploration of exact electrically charged\nsolutions, including traversable wormholes, black holes, and black bounces,\nwithin the framework of the scalar-tensor representation of hybrid\nmetric-Palatini gravity (HMPG) with a non-zero scalar potential. By integrating\nprinciples from both the metric and Palatini formulations, HMPG provides a\nflexible approach to addressing persistent challenges in General Relativity\n(GR), such as the late-time cosmic acceleration and the nature of dark matter.\nUnder the assumption of spherical symmetry, we employ an inverse problem\ntechnique to derive exact solutions in both the Jordan and Einstein conformal\nframes. This method naturally leads to configurations involving either\ncanonical or phantom scalar fields. A thorough examination of horizon\nstructures, throat conditions, asymptotic behaviour, and curvature regularity\n(via the Kretschmann scalar) reveals the intricate causal structures permitted\nby this theoretical model. The analysis uncovers a diverse range of geometric\nconfigurations, with the phantom sector exhibiting a notably richer spectrum of\nsolutions than the canonical case. These solutions encompass traversable\nwormholes, black universe models, where the interior of a black hole evolves\ninto an expanding cosmological phase rather than a singularity, as well as\nblack bounce structures and multi-horizon black holes. The results demonstrate\nthat introducing a non-zero scalar potential within HMPG significantly expands\nthe array of possible gravitational solutions, yielding complex causal and\ncurvature properties that go beyond standard GR. Consequently, HMPG stands out\nas a powerful theoretical framework for modelling extreme astrophysical\nenvironments, where deviations from classical gravity are expected to play a\ncrucial role.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th","published":"2025-04-10T15:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.07869v1","title":"Short-range magnetic order and planar anisotropy in the topological\n  ferrimagnet Mn3Si2Te6","summary":"Mn3Si2Te6 is a ferrimagnetic topological nodal-line semiconductor that\nexhibits unconventional colossal magnetoresitance (CMR) behavior, with\nshort-range spin fluctuations being potentially intimately linked to the\nemergent properties. In this work, we determine the short range magnetic order\nand quantify the local magnetic anisotropy through total neutron scattering and\npolarized neutron powder diffraction (pNPD) measurements on polycrystalline\nMn3Si2Te6. The real space local and long range spin structure was determined\nthrough the application of magnetic pair distribution function (mPDF) analysis,\nwith measurements from the low temperature ordered phase to the high\ntemperature paramagnetic state. Short-range order over a frustrated trimer of\nthree nearest neighbors was found to exist well above the long range\nferrimagnetic transition. pNPD measurements in the spin polarized paramagnetic\nstate were used to extract the local site susceptibility tensor of the Mn ions\nto quantify the magnetic anisotropy. Our combined mPDF and pNPD results provide\nquantitative information on the short-range order intrinsic to Mn3Si2Te6,\nshowing strong in-plane anisotropy with the spins largely confined to the\nab-plane in zero field and remain stable with increasing temperature through\nthe long-range to short-range ordered transition.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-10T15:44:14Z"}
{"aid":"http://arxiv.org/abs/2504.07872v1","title":"Dual Engines of Thoughts: A Depth-Breadth Integration Framework for\n  Open-Ended Analysis","summary":"We propose the Dual Engines of Thoughts (DEoT), an analytical framework for\ncomprehensive open-ended reasoning. While traditional reasoning frameworks\nprimarily focus on finding \"the best answer\" or \"the correct answer\" for\nsingle-answer problems, DEoT is specifically designed for \"open-ended\nquestions,\" enabling both broader and deeper analytical exploration. The\nframework centers on three key components: a Base Prompter for refining user\nqueries, a Solver Agent that orchestrates task decomposition, execution, and\nvalidation, and a Dual-Engine System consisting of a Breadth Engine (to explore\ndiverse impact factors) and a Depth Engine (to perform deep investigations).\nThis integrated design allows DEoT to balance wide-ranging coverage with\nin-depth analysis, and it is highly customizable, enabling users to adjust\nanalytical parameters and tool configurations based on specific requirements.\nExperimental results show that DEoT excels in addressing complex, multi-faceted\nquestions, achieving a total win rate of 77-86% compared to existing reasoning\nmodels, thus highlighting its effectiveness in real-world applications.","main_category":"cs.AI","categories":"cs.AI,cs.CE,cs.CL,cs.MA","published":"2025-04-10T15:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.07875v1","title":"QubitHammer Attacks: Qubit Flipping Attacks in Multi-tenant\n  Superconducting Quantum Computers","summary":"Quantum computing is rapidly evolving its capabilities, with a corresponding\nsurge in its deployment within cloud-based environments. Various quantum\ncomputers are accessible today via pay-as-you-go cloud computing models,\noffering unprecedented convenience. Due to its rapidly growing demand, quantum\ncomputers are shifting from a single-tenant to a multi-tenant model to enhance\nresource utilization. However, this widespread accessibility to shared\nmulti-tenant systems also introduces potential security vulnerabilities. In\nthis work, we present for the first time a set of novel attacks, named together\nas the QubitHammer attacks, which target state-of-the-art superconducting\nquantum computers. We show that in a multi-tenant cloud-based quantum system,\nan adversary with the basic capability to deploy custom pulses, similar to any\nstandard user today, can utilize the QubitHammer attacks to significantly\ndegrade the fidelity of victim circuits located on the same quantum computer.\nUpon extensive evaluation, the QubitHammer attacks achieve a very high\nvariational distance of up to 0.938 from the expected outcome, thus\ndemonstrating their potential to degrade victim computation. Our findings\nexhibit the effectiveness of these attacks across various superconducting\nquantum computers from a leading vendor, suggesting that QubitHammer represents\na new class of security attacks. Further, the attacks are demonstrated to\nbypass all existing defenses proposed so far for ensuring the reliability in\nmulti-tenant superconducting quantum computers.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-10T15:50:57Z"}
{"aid":"http://arxiv.org/abs/2504.07878v1","title":"Token Level Routing Inference System for Edge Devices","summary":"The computational complexity of large language model (LLM) inference\nsignificantly constrains their deployment efficiency on edge devices. In\ncontrast, small language models offer faster decoding and lower resource\nconsumption but often suffer from degraded response quality and heightened\nsusceptibility to hallucinations. To address this trade-off, collaborative\ndecoding, in which a large model assists in generating critical tokens, has\nemerged as a promising solution. This paradigm leverages the strengths of both\nmodel types by enabling high-quality inference through selective intervention\nof the large model, while maintaining the speed and efficiency of the smaller\nmodel. In this work, we present a novel collaborative decoding inference system\nthat allows small models to perform on-device inference while selectively\nconsulting a cloud-based large model for critical token generation. Remarkably,\nthe system achieves a 60% performance gain on CommonsenseQA using only a 0.5B\nmodel on an M1 MacBook, with under 7% of tokens generation uploaded to the\nlarge model in the cloud.","main_category":"cs.CL","categories":"cs.CL,cs.DC","published":"2025-04-10T15:54:19Z"}
{"aid":"http://arxiv.org/abs/2504.07882v1","title":"Large black-hole scalar charges induced by cosmology in Horndeski\n  theories","summary":"The regularity of black hole solutions, embedded in an expanding Universe, is\nstudied in a subclass of Horndeski theories, namely the sum of the simplest\nquadratic, cubic and quintic actions. We find that in presence of a time\nderivative of the scalar field, driven by the cosmological expansion, this\nregularity generically imposes large scalar charges for black holes, even when\nassuming strictly no direct coupling of matter to the scalar field. Such\ncharges cause a significant accretion of the scalar field by the black holes,\ndriving its local time derivative to a small value. This phenomenon, together\nwith the Vainshtein screening typical of these theories, strongly suppresses\nobservable scalar effects. We show that this full class of models is consistent\nwith LIGO/Virgo detections of gravitational waves, but that the LISA mission\nshould be able to constrain the coefficient of the quintic term at the\n$10^{-30}$ level in a self-acceleration scenario, an improvement by 16 orders\nof magnitude with respect to what is imposed by the speed of gravitational\nwaves.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T15:55:38Z"}
{"aid":"http://arxiv.org/abs/2504.07889v1","title":"A Steklov eigenvalue estimate for affine connections and its application\n  to substatic triples","summary":"Choi-Wang obtained a lower bound of the first eigenvalue of the Laplacian on\nclosed minimal hypersurfaces. On minimal hypersurfaces with boundary, Fraser-Li\nestablished an inequality giving a lower bound of the first Steklov eigenvalue\nas a counterpart of the Choi-Wang type inequality. These inequalities were\nshown under lower bounds of the Ricci curvature. In this paper, under\nnon-negative Ricci curvature associated with an affine connection introduced by\nWylie-Yeroshkin, we give a generalization of Fraser-Li type inequality. Our\nresults hold not only for weighted manifolds under non-negative $1$-weighted\nRicci curvature but also for substatic triples.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T16:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.07893v1","title":"Molecular excited state in the interaction quench dynamics of two\n  different atoms in a two-dimensional anisotropic trap","summary":"We explore the interaction quench dynamics of two atoms with different masses\nand subject to different trapping potentials. Notably, under such anisotropic\nconditions, the nonequilibrium dynamics can lead to the occupation of molecular\nexcited states. We consider cases of quenching from attractive to repulsive\ninteraction and vice versa, analyzing the impact of the pre- and postquench\nstates. The analysis of overlap integrals for the both states reveals a\nsignificant contribution from the molecular excited state. Moreover, the\noverlap with the prequench states might serve as an indicator of when this\nexcited state may emerge. Additionally, we calculate the energy spectrum for\nthe lowest levels in the both isotropic and anisotropic harmonic traps.\nThroughout our study, we use a Gaussian-shaped finite-range interaction\npotential.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.atm-clus,physics.comp-ph,quant-ph","published":"2025-04-10T16:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.07894v1","title":"DiverseFlow: Sample-Efficient Diverse Mode Coverage in Flows","summary":"Many real-world applications of flow-based generative models desire a diverse\nset of samples that cover multiple modes of the target distribution. However,\nthe predominant approach for obtaining diverse sets is not sample-efficient, as\nit involves independently obtaining many samples from the source distribution\nand mapping them through the flow until the desired mode coverage is achieved.\nAs an alternative to repeated sampling, we introduce DiverseFlow: a\ntraining-free approach to improve the diversity of flow models. Our key idea is\nto employ a determinantal point process to induce a coupling between the\nsamples that drives diversity under a fixed sampling budget. In essence,\nDiverseFlow allows exploration of more variations in a learned flow model with\nfewer samples. We demonstrate the efficacy of our method for tasks where\nsample-efficient diversity is desirable, such as text-guided image generation\nwith polysemous words, inverse problems like large-hole inpainting, and\nclass-conditional image synthesis.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T16:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.07896v1","title":"Fast Adaptation with Behavioral Foundation Models","summary":"Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerful\nparadigm for pretraining behavioral foundation models (BFMs), enabling agents\nto solve a wide range of downstream tasks specified via reward functions in a\nzero-shot fashion, i.e., without additional test-time learning or planning.\nThis is achieved by learning self-supervised task embeddings alongside\ncorresponding near-optimal behaviors and incorporating an inference procedure\nto directly retrieve the latent task embedding and associated policy for any\ngiven reward function. Despite promising results, zero-shot policies are often\nsuboptimal due to errors induced by the unsupervised training process, the\nembedding, and the inference procedure. In this paper, we focus on devising\nfast adaptation strategies to improve the zero-shot performance of BFMs in a\nfew steps of online interaction with the environment while avoiding any\nperformance drop during the adaptation process. Notably, we demonstrate that\nexisting BFMs learn a set of skills containing more performant policies than\nthose identified by their inference procedure, making them well-suited for fast\nadaptation. Motivated by this observation, we propose both actor-critic and\nactor-only fast adaptation strategies that search in the low-dimensional\ntask-embedding space of the pre-trained BFM to rapidly improve the performance\nof its zero-shot policies on any downstream task. Notably, our approach\nmitigates the initial \"unlearning\" phase commonly observed when fine-tuning\npre-trained RL models. We evaluate our fast adaptation strategies on top of\nfour state-of-the-art zero-shot RL methods in multiple navigation and\nlocomotion domains. Our results show that they achieve 10-40% improvement over\ntheir zero-shot performance in a few tens of episodes, outperforming existing\nbaselines.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.RO","published":"2025-04-10T16:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.07900v1","title":"Temporal Tensors and Quantum Shortcut Dynamics in a Supermaze of\n  Multidimensional Time","summary":"We develop a theoretical framework that unifies concepts of multiple time\ndimensions, quantum shortcut dynamics, and complex topological structures\n('supermazes') to explore novel phenomena in quantum and classical systems. In\nparticular, we introduce a Temporal Tensor Formalism to describe\nmultidimensional time, define Quantum Shortcut Operators that enact\nnear-instantaneous state transitions, and incorporate these into a supermaze\ntopological model inspired by labyrinthine geometry and network complexity. We\nshow how this framework can give rise to surprising effects such as anomalous\nthermodynamic relaxation (analogous to the Mpemba effect) in quantum systems.\nTheoretical implications for quantum computing (including quantum cloud\nnetworks) are discussed, and connections are drawn to established mathematical\nparadoxes and physical principles.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-10T16:19:56Z"}
{"aid":"http://arxiv.org/abs/2504.07906v1","title":"Deflection angle in the strong deflection limit of axisymmetric\n  spacetimes: local curvature, matter fields, and quasinormal modes","summary":"We investigate the deflection of photons in the strong deflection limit\nwithin static, axisymmetric spacetimes possessing reflection symmetry. As the\nimpact parameter approaches its critical value, the deflection angle exhibits a\nlogarithmic divergence. This divergence is characterized by a logarithmic rate\nand a constant offset, which we express in terms of coordinate-invariant\ncurvature evaluated at the unstable photon circular orbit. The curvature\ncontribution is encoded in the electric part of the Weyl tensor, reflecting\ntidal effects, and the matter contribution is encoded in the Einstein tensor,\ncapturing the influence of local energy and pressure. We also express these\ncoefficients using Newman--Penrose scalars. By exploiting the relationship\nbetween the strong deflection limit and quasinormal modes, we derive a new\nexpression for the quasinormal mode frequency in the eikonal limit in terms of\nthe curvature scalars. Our results provide a unified and coordinate-invariant\nframework that connects observable lensing features and quasinormal modes to\nthe local geometry and matter distribution near compact objects.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th","published":"2025-04-10T16:28:45Z"}
{"aid":"http://arxiv.org/abs/2504.07947v1","title":"Activating high-power parametric oscillation in photonic-crystal\n  resonators","summary":"By engineering the mode spectrum of a Kerr microresonator, we selectively\nactivate nonlinear phase matching amongst broadband parametric gain. At\nthreshold, optical parametric oscillators (OPOs) emerge from vacuum\nfluctuations in the presence of a pump laser, and above threshold, OPOs seed\nthe formation of intraresonator patterns and states, such as chaos and\nsolitons. These competing nonlinear processes hinder an important application\nof OPOs as wavelength-variable, low-noise sources. Recently, nanopatterned\nmicroresonator OPOs have leveraged photonic crystal bandgaps to enable\nuniversal phase matching and control of nonlinear interactions. Here, we\nexplore a design paradigm optimized for high-output power that uses geometric\ndispersion to suppress nonlinear interactions and a photonic crystal bandgap to\nactivate only a single OPO interaction. Our devices convert an input pump laser\nto output signal and idler waves with powers exceeding 40 mW while maintaining\nspectral purity and side-mode suppression ratios greater than 40 dB. We show\nthat this approach suits custom wavelengths by measuring four independent\noscillators that vary only photonic crystal parameters to select output waves.\nOur experiments demonstrate that microresonators functionalized by photonic\ncrystals offer a versatile and lossless palette of controls for nonlinear laser\nconversion.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T17:54:33Z"}
{"aid":"http://arxiv.org/abs/2504.07950v1","title":"Localized quasiparticles in a fluxonium with quasi-two-dimensional\n  amorphous kinetic inductors","summary":"Disordered superconducting materials with high kinetic inductance are an\nimportant resource to generate nonlinearity in quantum circuits and create\nhigh-impedance environments. In thin films fabricated from these materials, the\ncombination of disorder and the low effective dimensionality leads to increased\norder parameter fluctuations and enhanced kinetic inductance values. Among the\nchallenges of harnessing these compounds in coherent devices are their\nproximity to the superconductor-insulator phase transition, the presence of\nbroken Cooper pairs, and the two-level systems located in the disordered\nstructure. In this work, we fabricate tungsten silicide wires from\nquasi-two-dimensional films with one spatial dimension smaller than the\nsuperconducting coherence length and embed them into microwave resonators and\nfluxonium qubits, where the kinetic inductance provides the inductive part of\nthe circuits. We study the dependence of loss on the frequency, disorder, and\ngeometry of the device, and find that the loss increases with the level of\ndisorder and is dominated by the localized quasiparticles trapped in the\nspatial variations of the superconducting gap.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-10T17:56:04Z"}
{"aid":"http://arxiv.org/abs/2504.07954v1","title":"Perception-R1: Pioneering Perception Policy with Reinforcement Learning","summary":"Inspired by the success of DeepSeek-R1, we explore the potential of\nrule-based reinforcement learning (RL) in MLLM post-training for perception\npolicy learning. While promising, our initial experiments reveal that\nincorporating a thinking process through RL does not consistently lead to\nperformance gains across all visual perception tasks. This leads us to delve\ninto the essential role of RL in the context of visual perception. In this\nwork, we return to the fundamentals and explore the effects of RL on different\nperception tasks. We observe that the perceptual complexity is a major factor\nin determining the effectiveness of RL. We also observe that reward design\nplays a crucial role in further approching the upper limit of model perception.\nTo leverage these findings, we propose Perception-R1, a scalable RL framework\nusing GRPO during MLLM post-training. With a standard Qwen2.5-VL-3B-Instruct,\nPerception-R1 achieves +4.2% on RefCOCO+, +17.9% on PixMo-Count, +4.2% on\nPageOCR, and notably, 31.9% AP on COCO2017 val for the first time, establishing\na strong baseline for perception policy learning.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-10T17:58:27Z"}
{"aid":"http://arxiv.org/abs/2504.07956v1","title":"VCR-Bench: A Comprehensive Evaluation Framework for Video\n  Chain-of-Thought Reasoning","summary":"The advancement of Chain-of-Thought (CoT) reasoning has significantly\nenhanced the capabilities of large language models (LLMs) and large\nvision-language models (LVLMs). However, a rigorous evaluation framework for\nvideo CoT reasoning remains absent. Current video benchmarks fail to adequately\nassess the reasoning process and expose whether failures stem from deficiencies\nin perception or reasoning capabilities. Therefore, we introduce VCR-Bench, a\nnovel benchmark designed to comprehensively evaluate LVLMs' Video\nChain-of-Thought Reasoning capabilities. VCR-Bench comprises 859 videos\nspanning a variety of video content and durations, along with 1,034\nhigh-quality question-answer pairs. Each pair is manually annotated with a\nstepwise CoT rationale, where every step is tagged to indicate its association\nwith the perception or reasoning capabilities. Furthermore, we design seven\ndistinct task dimensions and propose the CoT score to assess the entire CoT\nprocess based on the stepwise tagged CoT rationals. Extensive experiments on\nVCR-Bench highlight substantial limitations in current LVLMs. Even the\ntop-performing model, o1, only achieves a 62.8% CoT score and an 56.7%\naccuracy, while most models score below 40%. Experiments show most models score\nlower on perception than reasoning steps, revealing LVLMs' key bottleneck in\ntemporal-spatial information processing for complex video reasoning. A robust\npositive correlation between the CoT score and accuracy confirms the validity\nof our evaluation framework and underscores the critical role of CoT reasoning\nin solving complex video reasoning tasks. We hope VCR-Bench to serve as a\nstandardized evaluation framework and expose the actual drawbacks in complex\nvideo reasoning task.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-10T17:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.07958v1","title":"Detect Anything 3D in the Wild","summary":"Despite the success of deep learning in close-set 3D object detection,\nexisting approaches struggle with zero-shot generalization to novel objects and\ncamera configurations. We introduce DetAny3D, a promptable 3D detection\nfoundation model capable of detecting any novel object under arbitrary camera\nconfigurations using only monocular inputs. Training a foundation model for 3D\ndetection is fundamentally constrained by the limited availability of annotated\n3D data, which motivates DetAny3D to leverage the rich prior knowledge embedded\nin extensively pre-trained 2D foundation models to compensate for this\nscarcity. To effectively transfer 2D knowledge to 3D, DetAny3D incorporates two\ncore modules: the 2D Aggregator, which aligns features from different 2D\nfoundation models, and the 3D Interpreter with Zero-Embedding Mapping, which\nmitigates catastrophic forgetting in 2D-to-3D knowledge transfer. Experimental\nresults validate the strong generalization of our DetAny3D, which not only\nachieves state-of-the-art performance on unseen categories and novel camera\nconfigurations, but also surpasses most competitors on in-domain data.DetAny3D\nsheds light on the potential of the 3D foundation model for diverse\napplications in real-world scenarios, e.g., rare object detection in autonomous\ndriving, and demonstrates promise for further exploration of 3D-centric tasks\nin open-world settings. More visualization results can be found at DetAny3D\nproject page.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.09897v1","title":"TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language\n  Models","summary":"Multimodal Large Language Models (MLLMs) have shown remarkable versatility in\nunderstanding diverse multimodal data and tasks. However, these capabilities\ncome with an increased model scale. While post-training pruning reduces model\nsize in unimodal models, its application to MLLMs often yields limited success.\nOur analysis discovers that conventional methods fail to account for the unique\ntoken attributes across layers and modalities inherent to MLLMs. Inspired by\nthis observation, we propose TAMP, a simple yet effective pruning framework\ntailored for MLLMs, featuring two key components: (1) Diversity-Aware Sparsity,\nwhich adjusts sparsity ratio per layer based on diversities among multimodal\noutput tokens, preserving more parameters in high-diversity layers; and (2)\nAdaptive Multimodal Input Activation, which identifies representative\nmultimodal input tokens using attention scores to guide unstructured weight\npruning. We validate our method on two state-of-the-art MLLMs: LLaVA-NeXT,\ndesigned for vision-language tasks, and VideoLLaMA2, capable of processing\naudio, visual, and language modalities. Empirical experiments across various\nmultimodal evaluation benchmarks demonstrate that each component of our\napproach substantially outperforms existing pruning techniques.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T05:44:38Z"}
{"aid":"http://arxiv.org/abs/2504.09918v1","title":"Berry curvature-induced intrinsic spin Hall effect in\n  light-element-based CrN system for magnetization switching","summary":"The current-induced spin-orbit torque-based devices for magnetization\nswitching are commonly relied on the 4d and 5d heavy metals owing to their\nstrong spin-orbit coupling (SOC) to produce large spin current via spin Hall\neffect (SHE). Here we present the sizable SHE in CrN, a light element-based\nsystem and demonstrate the current-induced magnetization switching in the\nadjacent ferromagnetic layer [Co(0.35nm)/Pt(0.3nm)]3, which exhibits\nperpendicular magnetic anisotropy. We found the switching current density of\n2.6 MA/cm2. The first principles calculation gives the spin Hall conductivity\n(SHC) to be 120 (hcross/e) S/cm due to intrinsic Berry curvature arising from\nSOC induced band splitting near Fermi-energy. The theoretically calculated\nintrinsic SHC is close to the experimental SHC extracted from second harmonic\nHall measurement. We estimated spin Hall angle to be 0.09, demonstrating\nefficient charge-to-spin conversion in CrN system.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T06:26:39Z"}
{"aid":"http://arxiv.org/abs/2504.09931v1","title":"A posteriori estimates for problems with monotone operators","summary":"We propose a method of obtaining a posteriori estimates which does not use\nthe duality theory and which applies to variational inequalities with monotone\noperators, without assuming the potentiality of operators. The effectiveness of\nthe method is demonstrated on problems driven by nonlinear operators of the\n$p$-Laplacian type, including the anisotropic $p$-Laplacian, polyharmonic\n$p$-Laplacian, and fractional $p$-Laplacian.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA","published":"2025-04-14T06:45:20Z"}
{"aid":"http://arxiv.org/abs/2504.09932v1","title":"A Theory of Universal Rate-Distortion-Classification Representations for\n  Lossy Compression","summary":"In lossy compression, Blau and Michaeli [5] introduced the information\nrate-distortion-perception (RDP) function, extending traditional\nrate-distortion theory by incorporating perceptual quality. More recently, this\nframework was expanded by defining the\nrate-distortion-perception-classification (RDPC) function, integrating\nmulti-task learning that jointly optimizes generative tasks such as perceptual\nquality and classification accuracy alongside reconstruction tasks [28]. To\nthat end, motivated by the concept of a universal RDP encoder introduced in\n[34], we investigate universal representations that enable diverse\ndistortion-classification tradeoffs through a single fixed encoder combined\nwith multiple decoders. Specifically, theoretical analysis and numerical\nexperiment demonstrate that for the Gaussian source under mean squared error\n(MSE) distortion, the entire distortion-classification tradeoff region can be\nachieved using one universal encoder. In addition, this paper characterizes\nachievable distortion-classification regions for fixed universal\nrepresentations in general source distributions, identifying conditions that\nensure minimal distortion penalty when reusing encoders across varying tradeoff\npoints. Experimental results using MNIST and SVHN datasets validate our\ntheoretical insights, showing that universal encoders can obtain distortion\nperformance comparable to task-specific encoders, thus supporting the\npracticality and effectiveness of our proposed universal representations.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T06:46:02Z"}
{"aid":"http://arxiv.org/abs/2504.09944v1","title":"On the mean value of $\\mathrm{GL}_1$ and $\\mathrm{GL}_2$ $L$-functions,\n  with applications to murmurations","summary":"We determine the mean value of $L$-functions attached to quadratic twists of\nautomorphic representations on $\\mathrm{GL}_1$ or $\\mathrm{GL}_2$ in large\nregions of the critical strip. In the case of $\\mathrm{GL}_1$, we go on to\nexhibit a recently discovered type of fine structure called \"murmurations\"\nunconditionally for all of our families. Our main tool is a new variant of the\napproximate functional equation imbued with a mechanism for dynamically\nrebalancing error terms while preserving holomorphicity.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T07:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.09950v1","title":"Constrained Error-Correcting Codes for Efficient DNA Synthesis","summary":"DNA synthesis is considered as one of the most expensive components in\ncurrent DNA storage systems. In this paper, focusing on a common synthesis\nmachine, which generates multiple DNA strands in parallel following a fixed\nsupersequence,we propose constrained codes with polynomial-time encoding and\ndecoding algorithms. Compared to the existing works, our codes simultaneously\nsatisfy both l-runlength limited and {\\epsilon}-balanced constraints. By\nenumerating all valid sequences, our codes achieve the maximum rate, matching\nthe capacity. Additionally, we design constrained error-correcting codes\ncapable of correcting one insertion or deletion in the obtained DNA sequence\nwhile still adhering to the constraints.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T07:25:18Z"}
{"aid":"http://arxiv.org/abs/2504.09951v1","title":"Towards Weaker Variance Assumptions for Stochastic Optimization","summary":"We revisit a classical assumption for analyzing stochastic gradient\nalgorithms where the squared norm of the stochastic subgradient (or the\nvariance for smooth problems) is allowed to grow as fast as the squared norm of\nthe optimization variable. We contextualize this assumption in view of its\ninception in the 1960s, its seemingly independent appearance in the recent\nliterature, its relationship to weakest-known variance assumptions for\nanalyzing stochastic gradient algorithms, and its relevance in deterministic\nproblems for non-Lipschitz nonsmooth convex optimization. We build on and\nextend a connection recently made between this assumption and the Halpern\niteration. For convex nonsmooth, and potentially stochastic, optimization, we\nanalyze horizon-free, anytime algorithms with last-iterate rates. For problems\nbeyond simple constrained optimization, such as convex problems with functional\nconstraints or regularized convex-concave min-max problems, we obtain rates for\noptimality measures that do not require boundedness of the feasible set.","main_category":"math.OC","categories":"math.OC,cs.LG,stat.ML","published":"2025-04-14T07:26:34Z"}
{"aid":"http://arxiv.org/abs/2504.09953v1","title":"Efficient 2D to Full 3D Human Pose Uplifting including Joint Rotations","summary":"In sports analytics, accurately capturing both the 3D locations and rotations\nof body joints is essential for understanding an athlete's biomechanics. While\nHuman Mesh Recovery (HMR) models can estimate joint rotations, they often\nexhibit lower accuracy in joint localization compared to 3D Human Pose\nEstimation (HPE) models. Recent work addressed this limitation by combining a\n3D HPE model with inverse kinematics (IK) to estimate both joint locations and\nrotations. However, IK is computationally expensive. To overcome this, we\npropose a novel 2D-to-3D uplifting model that directly estimates 3D human\nposes, including joint rotations, in a single forward pass. We investigate\nmultiple rotation representations, loss functions, and training strategies -\nboth with and without access to ground truth rotations. Our models achieve\nstate-of-the-art accuracy in rotation estimation, are 150 times faster than the\nIK-based approach, and surpass HMR models in joint localization precision.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T07:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.09958v1","title":"C-MTCSD: A Chinese Multi-Turn Conversational Stance Detection Dataset","summary":"Stance detection has become an essential tool for analyzing public\ndiscussions on social media. Current methods face significant challenges,\nparticularly in Chinese language processing and multi-turn conversational\nanalysis. To address these limitations, we introduce C-MTCSD, the largest\nChinese multi-turn conversational stance detection dataset, comprising 24,264\ncarefully annotated instances from Sina Weibo, which is 4.2 times larger than\nthe only prior Chinese conversational stance detection dataset. Our\ncomprehensive evaluation using both traditional approaches and large language\nmodels reveals the complexity of C-MTCSD: even state-of-the-art models achieve\nonly 64.07% F1 score in the challenging zero-shot setting, while performance\nconsistently degrades with increasing conversation depth. Traditional models\nparticularly struggle with implicit stance detection, achieving below 50% F1\nscore. This work establishes a challenging new benchmark for Chinese stance\ndetection research, highlighting significant opportunities for future\nimprovements.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T07:55:47Z"}
{"aid":"http://arxiv.org/abs/2504.09962v1","title":"Static Magnetic Properties of Cryogel$^{\\tiny{\\circledR}}$ and\n  Pyrogel$^{\\tiny{\\circledR}}$ at Low Temperatures and in High Magnetic Fields","summary":"The static magnetic properties of the silica-based aergoels of\nCryogel$^{\\tiny{\\circledR}}$ and Pyrogel$^{\\tiny{\\circledR}}$, manufactured by\nAspen Aerogels$^{\\tiny{\\circledR}}$, were measured over a range of temperatures\n(2 K $\\leq$ T $\\leq$ 400 K) and in magnetic fields up to 70 kG. These data and\na model of the responses are reported so these properties are familiar to\nothers who may benefit from knowing them before the materials are employed in\npotential applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T07:59:19Z"}
{"aid":"http://arxiv.org/abs/2504.09964v1","title":"Characterizing the Palomar 5 Stream: HDBSCAN Analysis and Galactic Halo\n  Constraints","summary":"We utilize the DESI Legacy Imaging Surveys DR10 to investigate the previously\nundetected faint extension of the Palomar 5 stellar stream. By applying the\nHDBSCAN clustering algorithm, we identify stream members and successfully\nextend the leading arm of the stream to approximately $\\mathrm{DEC} \\sim\n-15^\\circ$. Combining the fully detected stream with a suite of mock stream\nsimulations, we conduct a detailed comparison to constrain both the intrinsic\nproperties of the stream and the dynamical parameters of the Milky Way (MW)\nhalo. Our analysis yields a best-fit model characterized by eight parameters:\n$M_{\\mathrm{halo}} = 5.67\\times10^{11}\\ M_{\\odot}$, $r_{s,\\mathrm{halo}} =\n28.94\\ \\mathrm{kpc}$, $q_z = 0.93$, $M_{\\mathrm{gc}} = 4.31\\times10^{3}\\\nM_{\\odot}$, $dM_{\\mathrm{gc}}/dt = 1.81\\ M_{\\odot}\\ \\mathrm{Myr}^{-1}$,\n$\\mu_{\\alpha}\\cos\\delta = -2.28\\ \\mathrm{mas\\ yr}^{-1}$, $\\mu_{\\delta} = -2.26\\\n\\mathrm{mas\\ yr}^{-1}$, and $D = 23.25\\ \\mathrm{kpc}$. Notably, our constraints\non the halo shape indicate that the MW's dark matter halo exhibits a flattened\npotential, with a minor-to-major axis ratio of $q_z = 0.93$. This finding\naligns well with theoretical expectations and previous observational estimates.\nAdditionally, the best-fit model accurately reproduces the observed stream\nmorphology and dynamics, providing a more precise understanding of both the\nevolution of the stream and the overall structure of the Galactic halo.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-14T08:05:19Z"}
{"aid":"http://arxiv.org/abs/2504.09967v1","title":"Enhancing Multi-task Learning Capability of Medical Generalist\n  Foundation Model via Image-centric Multi-annotation Data","summary":"The emergence of medical generalist foundation models has revolutionized\nconventional task-specific model development paradigms, aiming to better handle\nmultiple tasks through joint training on large-scale medical datasets. However,\nrecent advances prioritize simple data scaling or architectural component\nenhancement, while neglecting to re-examine multi-task learning from a\ndata-centric perspective. Critically, simply aggregating existing data\nresources leads to decentralized image-task alignment, which fails to cultivate\ncomprehensive image understanding or align with clinical needs for\nmulti-dimensional image interpretation. In this paper, we introduce the\nimage-centric multi-annotation X-ray dataset (IMAX), the first attempt to\nenhance the multi-task learning capabilities of medical multi-modal large\nlanguage models (MLLMs) from the data construction level. To be specific, IMAX\nis featured from the following attributes: 1) High-quality data curation. A\ncomprehensive collection of more than 354K entries applicable to seven\ndifferent medical tasks. 2) Image-centric dense annotation. Each X-ray image is\nassociated with an average of 4.10 tasks and 7.46 training entries, ensuring\nmulti-task representation richness per image. Compared to the general\ndecentralized multi-annotation X-ray dataset (DMAX), IMAX consistently\ndemonstrates significant multi-task average performance gains ranging from\n3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs.\nMoreover, we investigate differences in statistical patterns exhibited by IMAX\nand DMAX training processes, exploring potential correlations between\noptimization dynamics and multi-task performance. Finally, leveraging the core\nconcept of IMAX data construction, we propose an optimized DMAX-based training\nstrategy to alleviate the dilemma of obtaining high-quality IMAX data in\npractical scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-14T08:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.09973v1","title":"Beyond Degradation Redundancy: Contrastive Prompt Learning for\n  All-in-One Image Restoration","summary":"All-in-one image restoration, addressing diverse degradation types with a\nunified model, presents significant challenges in designing task-specific\nprompts that effectively guide restoration across multiple degradation\nscenarios. While adaptive prompt learning enables end-to-end optimization, it\noften yields overlapping or redundant task representations. Conversely,\nexplicit prompts derived from pretrained classifiers enhance discriminability\nbut may discard critical visual information for reconstruction. To address\nthese limitations, we introduce Contrastive Prompt Learning (CPL), a novel\nframework that fundamentally enhances prompt-task alignment through two\ncomplementary innovations: a \\emph{Sparse Prompt Module (SPM)} that efficiently\ncaptures degradation-specific features while minimizing redundancy, and a\n\\emph{Contrastive Prompt Regularization (CPR)} that explicitly strengthens task\nboundaries by incorporating negative prompt samples across different\ndegradation types. Unlike previous approaches that focus primarily on\ndegradation classification, CPL optimizes the critical interaction between\nprompts and the restoration model itself. Extensive experiments across five\ncomprehensive benchmarks demonstrate that CPL consistently enhances\nstate-of-the-art all-in-one restoration models, achieving significant\nimprovements in both standard multi-task scenarios and challenging composite\ndegradation settings. Our framework establishes new state-of-the-art\nperformance while maintaining parameter efficiency, offering a principled\nsolution for unified image restoration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.09974v1","title":"Towards Resilient Tracking in Autonomous Vehicles: A Distributionally\n  Robust Input and State Estimation Approach","summary":"This paper proposes a novel framework for the distributionally robust input\nand state estimation (DRISE) for autonomous vehicles operating under model\nuncertainties and measurement outliers. The proposed framework improves the\ninput and state estimation (ISE) approach by integrating distributional\nrobustness, enhancing the estimator's resilience and robustness to adversarial\ninputs and unmodeled dynamics. Moment-based ambiguity sets capture\nprobabilistic uncertainties in both system dynamics and measurement noise,\noffering analytical tractability and efficiently handling uncertainties in mean\nand covariance. In particular, the proposed framework minimizes the worst-case\nestimation error, ensuring robustness against deviations from nominal\ndistributions. The effectiveness of the proposed approach is validated through\nsimulations conducted in the CARLA autonomous driving simulator, demonstrating\nimproved performance in state estimation accuracy and robustness in dynamic and\nuncertain environments.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-14T08:26:06Z"}
{"aid":"http://arxiv.org/abs/2504.09978v1","title":"New exponential law for real networks","summary":"In this article we have shown that the distributions of ksi satisfy an\nexponential law for real networks while the distributions of ksi for random\nnetworks are bell-shaped and closer to the normal distribution. The ksi\ndistributions for Barabasi-Albert and Watts-Strogatz networks are similar to\nthe ksi distributions for random networks (bell-shaped) for most parameters,\nbut when these parameters become small enough, the Barabasi-Albert and\nWatts-Strogatz networks become more realistic with respect to the ksi\ndistributions.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-14T08:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.09990v1","title":"Correlative and Discriminative Label Grouping for Multi-Label Visual\n  Prompt Tuning","summary":"Modeling label correlations has always played a pivotal role in multi-label\nimage classification (MLC), attracting significant attention from researchers.\nHowever, recent studies have overemphasized co-occurrence relationships among\nlabels, which can lead to overfitting risk on this overemphasis, resulting in\nsuboptimal models. To tackle this problem, we advocate for balancing\ncorrelative and discriminative relationships among labels to mitigate the risk\nof overfitting and enhance model performance. To this end, we propose the\nMulti-Label Visual Prompt Tuning framework, a novel and parameter-efficient\nmethod that groups classes into multiple class subsets according to label\nco-occurrence and mutual exclusivity relationships, and then models them\nrespectively to balance the two relationships. In this work, since each group\ncontains multiple classes, multiple prompt tokens are adopted within Vision\nTransformer (ViT) to capture the correlation or discriminative label\nrelationship within each group, and effectively learn correlation or\ndiscriminative representations for class subsets. On the other hand, each group\ncontains multiple group-aware visual representations that may correspond to\nmultiple classes, and the mixture of experts (MoE) model can cleverly assign\nthem from the group-aware to the label-aware, adaptively obtaining label-aware\nrepresentation, which is more conducive to classification. Experiments on\nmultiple benchmark datasets show that our proposed approach achieves\ncompetitive results and outperforms SOTA methods on multiple pre-trained\nmodels.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.10004v1","title":"An Image is Worth $K$ Topics: A Visual Structural Topic Model with\n  Pretrained Image Embeddings","summary":"Political scientists are increasingly interested in analyzing visual content\nat scale. However, the existing computational toolbox is still in need of\nmethods and models attuned to the specific challenges and goals of social and\npolitical inquiry. In this article, we introduce a visual Structural Topic\nModel (vSTM) that combines pretrained image embeddings with a structural topic\nmodel. This has important advantages compared to existing approaches. First,\npretrained embeddings allow the model to capture the semantic complexity of\nimages relevant to political contexts. Second, the structural topic model\nprovides the ability to analyze how topics and covariates are related, while\nmaintaining a nuanced representation of images as a mixture of multiple topics.\nIn our empirical application, we show that the vSTM is able to identify topics\nthat are interpretable, coherent, and substantively relevant to the study of\nonline political communication.","main_category":"cs.CV","categories":"cs.CV,cs.CY,stat.AP,stat.ME","published":"2025-04-14T09:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.10019v1","title":"Sagbi bases, defining ideals and algebra of minors","summary":"This paper extends the article of the Bruns and Conca on SAGBI bases and\ntheir computation (J. Symb. Comput. 120 (2024)) in two directions. (i) We\ndescribe the extension of the Singular library sagbiNormaliz.sing to the\ncomputation of defining ideals of subalgebras of polynomial rings. (ii) We give\na complete classification of the algebras of minors for which the generating\nset is a SAGBI basis with respect to a suitable monomial order and we identify\nuniversal SAGBI basis in three cases. The investigation is illustrated by\nseveral examples.","main_category":"math.AC","categories":"math.AC","published":"2025-04-14T09:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.10020v1","title":"The Mirage of Performance Gains: Why Contrastive Decoding Fails to\n  Address Multimodal Hallucination","summary":"Contrastive decoding strategies are widely used to reduce hallucinations in\nmultimodal large language models (MLLMs). These methods work by constructing\ncontrastive samples to induce hallucinations and then suppressing them in the\noutput distribution. However, this paper demonstrates that such approaches fail\nto effectively mitigate the hallucination problem. The performance improvements\nobserved on POPE Benchmark are largely driven by two misleading factors: (1)\ncrude, unidirectional adjustments to the model's output distribution and (2)\nthe adaptive plausibility constraint, which reduces the sampling strategy to\ngreedy search. To further illustrate these issues, we introduce a series of\nspurious improvement methods and evaluate their performance against contrastive\ndecoding techniques. Experimental results reveal that the observed performance\ngains in contrastive decoding are entirely unrelated to its intended goal of\nmitigating hallucinations. Our findings challenge common assumptions about the\neffectiveness of contrastive decoding strategies and pave the way for\ndeveloping genuinely effective solutions to hallucinations in MLLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CV","published":"2025-04-14T09:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.10021v1","title":"Masked Autoencoder Self Pre-Training for Defect Detection in\n  Microelectronics","summary":"Whereas in general computer vision, transformer-based architectures have\nquickly become the gold standard, microelectronics defect detection still\nheavily relies on convolutional neural networks (CNNs). We hypothesize that\nthis is due to the fact that a) transformers have an increased need for data\nand b) labelled image generation procedures for microelectronics are costly,\nand labelled data is therefore sparse. Whereas in other domains, pre-training\non large natural image datasets can mitigate this problem, in microelectronics\ntransfer learning is hindered due to the dissimilarity of domain data and\nnatural images. Therefore, we evaluate self pre-training, where models are\npre-trained on the target dataset, rather than another dataset. We propose a\nvision transformer (ViT) pre-training framework for defect detection in\nmicroelectronics based on masked autoencoders (MAE). In MAE, a large share of\nimage patches is masked and reconstructed by the model during pre-training. We\nperform pre-training and defect detection using a dataset of less than 10.000\nscanning acoustic microscopy (SAM) images labelled using transient thermal\nanalysis (TTA). Our experimental results show that our approach leads to\nsubstantial performance gains compared to a) supervised ViT, b) ViT pre-trained\non natural image datasets, and c) state-of-the-art CNN-based defect detection\nmodels used in the literature. Additionally, interpretability analysis reveals\nthat our self pre-trained models, in comparison to ViT baselines, correctly\nfocus on defect-relevant features such as cracks in the solder material. This\ndemonstrates that our approach yields fault-specific feature representations,\nmaking our self pre-trained models viable for real-world defect detection in\nmicroelectronics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10027v1","title":"Deconfined Quantum Critical Point: A Review of Progress","summary":"Deconfined quantum critical points (DQCPs) have been proposed as a class of\ncontinuous quantum phase transitions occurring between two ordered phases with\ndistinct symmetry-breaking patterns, beyond the conventional framework of\nLandau-Ginzburg-Wilson (LGW) theory. At the DQCP, the system exhibits emergent\ngauge fields, fractionalized excitations, and enhanced symmetries. Here we\nreview recent theoretical and experimental progress on exploring DQCPs in\ncondensed matter systems. We first introduce theoretical advancements in the\nstudy of DQCPs over the past twenty years, particularly in magnetic models on\nsquare lattices, honeycomb lattices, kagome lattices, and one-dimensional spin\nchains. We then discuss recent progress on experimental realization of DQCP in\nquantum magnetic systems. Experimentally, the Shastry-Sutherland model,\nrealized in SrCu$_2$(BO$_3$)$_2$, offers a particularly promising platform for\nrealizing DQCPs. The magnetic frustration inherent to this model drives phase\ntransitions between two distinct symmetry-breaking states: a valence bond solid\n(VBS) phase and a N\\'{e}el antiferromagnetic phase. Remarkably,\nSrCu$_2$(BO$_3$)$_2$ has provided the first experimental evidence of a\nproximate DQCP through a field-induced Bose-Einstein condensation,\ntransitioning from the VBS state to the N\\'{e}el state. Nevertheless, the\ndirect experimental realization of a DQCP remains a significant challenge.\nDespite this, it offers a promising platform for exploring emergent phenomena\nthrough quantum phase transition in low-dimensional quantum systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-14T09:31:58Z"}
{"aid":"http://arxiv.org/abs/2504.10030v1","title":"EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical\n  Challenge in Multi-Robot Control","summary":"This paper introduces EmbodiedAgent, a hierarchical framework for\nheterogeneous multi-robot control. EmbodiedAgent addresses critical limitations\nof hallucination in impractical tasks. Our approach integrates a next-action\nprediction paradigm with a structured memory system to decompose tasks into\nexecutable robot skills while dynamically validating actions against\nenvironmental constraints. We present MultiPlan+, a dataset of more than 18,000\nannotated planning instances spanning 100 scenarios, including a subset of\nimpractical cases to mitigate hallucination. To evaluate performance, we\npropose the Robot Planning Assessment Schema (RPAS), combining automated\nmetrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's\nsuperiority over state-of-the-art models, achieving 71.85% RPAS score.\nReal-world validation in an office service task highlights its ability to\ncoordinate heterogeneous robots for long-horizon objectives.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T09:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.10054v1","title":"Implementation and Performance Evaluation of TCP over QUIC Tunnels","summary":"QUIC, a UDP-based transport protocol, addresses several limitations of TCP by\noffering built-in encryption, stream multiplexing, and improved loss recovery.\nTo extend these benefits to legacy TCP-based applications, this paper explores\nthe implementation and evaluation of a TCP over QUIC tunneling approach. A\nlightweight, stream-based tunnel is constructed using the Rust-based Quinn\nlibrary, enabling TCP traffic to traverse QUIC connections transparently.\nPerformance is evaluated under varying network conditions, including packet\nloss, high latency, and out-of-order delivery. Results indicate that TCP over\nQUIC maintains significantly higher throughput than native TCP in lossy or\nunstable environments, with up to a high improvement under 20\\% packet loss.\nHowever, under ideal network conditions, tunneling introduces modest overhead\ndue to encryption and user-space processing. These findings provide insights\ninto the trade-offs of TCP over QUIC tunneling and its suitability for\ndeployment in dynamic or impaired networks.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-14T09:57:35Z"}
{"aid":"http://arxiv.org/abs/2504.10056v1","title":"CMOS-compatible vanadium dioxide via Pulsed Laser and Atomic Layer\n  deposition: towards ultra-thin film phase-change layers","summary":"Vanadium dioxide, a well-known Mott insulator, is a highly studied electronic\nmaterial with promising applications in information processing and storage.\nWhile fully crystalline layers exhibit exceptional properties, such as a sharp\nand abrupt conductivity change at the metal-insulator transition, fabricating\npoly-crystalline films on silicon substrates often involves trade-offs in\ntransport characteristics and switching performance, especially for ultra-thin\nlayers required in advanced gate applications. In this study, we explore the\ngrowth of vanadium dioxide films on standard wet-oxidized silicon wafers using\ntwo established deposition techniques with pulsed laser deposition and atomic\nlayer deposition. Thin films, ranging in thickness from 200 to 10 nano meters,\nwere systematically characterized through structural and electrical analyses to\noptimize key growth parameters. Temperature and pressure were identified as the\nprimary factors affecting film quality, and the optimal growth conditions\nacross the entire thickness range are discussed in detail. We demonstrate that\nboth pulsed laser deposition and atomic layer deposition methods can\nsuccessfully produce ultra-thin vanadium dioxide layers down to 8 nano meters\nwith functional properties suitable for practical applications. This work\nunderscores the potential of vanadium dioxide for fully industry compatible\nphase-change switching devices and provides valuable insights into optimizing\ngrowth processes for poly-crystalline films.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-14T09:59:24Z"}
{"aid":"http://arxiv.org/abs/2504.10074v1","title":"MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation\n  Framework","summary":"Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2\\% on the Single-Hop subset and\n+0.4\\% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8\\% on the Unseen-Q subset, +8.2\\% on the Unseen-E subset, and +8.1\\% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-14T10:19:47Z"}
{"aid":"http://arxiv.org/abs/2504.10090v1","title":"CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography","summary":"Large language models (LLMs) and multimodal large language models (MLLMs)\nhave significantly advanced artificial intelligence. However, visual reasoning,\nreasoning involving both visual and textual inputs, remains underexplored.\nRecent advancements, including the reasoning models like OpenAI o1 and Gemini\n2.0 Flash Thinking, which incorporate image inputs, have opened this\ncapability. In this ongoing work, we focus specifically on photography-related\ntasks because a photo is a visual snapshot of the physical world where the\nunderlying physics (i.e., illumination, blur extent, etc.) interplay with the\ncamera parameters. Successfully reasoning from the visual information of a\nphoto to identify these numerical camera settings requires the MLLMs to have a\ndeeper understanding of the underlying physics for precise visual\ncomprehension, representing a challenging and intelligent capability essential\nfor practical applications like photography assistant agents. We aim to\nevaluate MLLMs on their ability to distinguish visual differences related to\nnumerical camera settings, extending a methodology previously proposed for\nvision-language models (VLMs). Our preliminary results demonstrate the\nimportance of visual reasoning in photography-related tasks. Moreover, these\nresults show that no single MLLM consistently dominates across all evaluation\ntasks, demonstrating ongoing challenges and opportunities in developing MLLMs\nwith better visual reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-14T10:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.10092v1","title":"Bayesian optimal experimental design with Wasserstein information\n  criteria","summary":"Bayesian optimal experimental design (OED) provides a principled framework\nfor selecting the most informative observational settings in experiments. With\nrapid advances in computational power, Bayesian OED has become increasingly\nfeasible for inference problems involving large-scale simulations, attracting\ngrowing interest in fields such as inverse problems. In this paper, we\nintroduce a novel design criterion based on the expected Wasserstein-$p$\ndistance between the prior and posterior distributions. Especially, for $p=2$,\nthis criterion shares key parallels with the widely used expected information\ngain (EIG), which relies on the Kullback--Leibler divergence instead. First,\nthe Wasserstein-2 criterion admits a closed-form solution for Gaussian\nregression, a property which can be also leveraged for approximative schemes.\nSecond, it can be interpreted as maximizing the information gain measured by\nthe transport cost incurred when updating the prior to the posterior. Our main\ncontribution is a stability analysis of the Wasserstein-1 criterion, where we\nprovide a rigorous error analysis under perturbations of the prior or\nlikelihood. We partially extend this study also to the Wasserstein-2 criterion.\nIn particular, these results yield error rates when empirical approximations of\npriors are used. Finally, we demonstrate the computability of the Wasserstein-2\ncriterion and demonstrate our approximation rates through simulations.","main_category":"stat.ME","categories":"stat.ME,cs.NA,math.NA,stat.CO","published":"2025-04-14T10:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.10116v1","title":"Application of nanodiamond-polymer composite holographic gratings in a\n  very cold neutron interferometer","summary":"In recent decades, photosensitive materials have been used for the\ndevelopment of optical devices not only for light, but also for cold and very\ncold neutrons. We show that holographically recorded gratings in\nnanodiamond-polymer composites (nDPC) form ideal diffraction elements for very\ncold neutrons. Their advantage of high diffraction efficiency, combined with\nlow angular selectivity as a two-port beam splitter, meets the necessary\nconditions for application in a very cold neutron interferometer. We provide an\noverview of the latest achievements in the construction of such a triple Laue\ninterferometer. A first operational test of the interferometer is planned\nimmediately after this conference in May 2025.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T11:26:03Z"}
{"aid":"http://arxiv.org/abs/2504.10119v1","title":"Non-intrusive Auto-detecting and Adaptive Hybrid Scheme for Multiscale\n  Heat Transfer: Thermal Runaway in a Battery Pack","summary":"Accurately capturing and simulating multiscale systems is a formidable\nchallenge, as both spatial and temporal scales can span many orders of\nmagnitude. Rigorous upscaling methods not only ensure efficient computation,\nbut also maintains errors within a priori prescribed limits. This provides a\nbalance between computational costs and accuracy. However, the most significant\ndifficulties arise when the conditions under which upscaled models can be\napplied cease to hold. To address this, we develop an automatic-detecting and\nadaptive, nonintrusive two-sided hybrid method for multiscale heat transfer and\napply it to thermal runaway in a battery pack. To allow adaptive hybrid\nsimulations, two kernels are developed to dynamically map the values between\nthe fine-scale and the upscaled subdomains in a single simulation. The accuracy\nof the developed hybrid method is demonstrated through conducting a series of\nthermal runaway test cases in a battery pack. Our results show that the maximum\nspatial errors consistently remain below the threshold bounded by upscaling\nerrors.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-14T11:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.10122v1","title":"Design Optimization of Flip FET Standard Cells with Dual-sided Pins for\n  Ultimate Scaling","summary":"Recently, we proposed a novel transistor architecture for 3D stacked FETs\ncalled Flip FET (FFET), featuring N/P transistors back-to-back stacked and\ndual-sided interconnects. With dual-sided power rails and signal tracks, FFET\ncan achieve an aggressive 2.5T cell height. As a tradeoff, the complex\nstructure and limited numbers of M0 tracks could limit the standard cell\ndesign. As a solution, multiple innovations were introduced and examined in\nthis work. Based on an advanced node design rule, several unique building\nblocks in FFET such as drain merge (DM), gate merge (GM), field drain merge\n(FDM) and buried signal track (BST) were investigated. Other key design\nconcepts of multi-row, split gate and dummy gate insertion (DG) were also\ncarefully studied, delivering around 35.6% area reduction compared with 3T\nCFET. Furthermore, the symmetric design of FFET has unique superiority over\nCFET thanks to the separate N/P logic on two sides of the wafer and their\nconnections using DM and GM. New routing scheme with dual-sided output pins on\nboth wafer frontside (FS) and backside (BS) was proposed for the first time.\nFinally, we conducted a comprehensive evaluation on complex cell design, taking\nAOI22 as an example. New strategies were proposed and examined. The FDM design\nis identified as the best, outperforming the BST and dummy gate design by 1.93%\nand 5.13% for the transition delay.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T11:31:44Z"}
{"aid":"http://arxiv.org/abs/2504.10128v1","title":"Probing Binary Lens Caustics with Gravitational Waves: A Uniform\n  Approximation Approach","summary":"We present a new framework for modeling gravitational wave diffraction near\nfold caustics using the Uniform Approximation (UA), focusing on binary mass\nlenses-axially asymmetric systems with complex caustic structures. Full-wave\nmethods based on the Kirchhoff integral become impractical in this regime due\nto highly oscillatory integrands. The UA provides a robust and accurate\ndescription of the wave field near folds, resolving the breakdown of\nGeometrical Optics at caustics and improving upon Transitional\nAsymptotics-based on Airy function approximations-which lack global validity.\nCentral to our approach is the concept of the caustic width, $d_c$, a\ncharacteristic length scale defining the region where diffraction significantly\nalters wave propagation. We find that $d_c$ scales universally with the\ngravitational wavelength as ~ $ \\lambda^{2/3}$ and inversely with the\nredshifted lens mass as ~ $ M_{Lz}^{-2/3}$. The wave amplification near the\nfold grows as ~ $ d_c^{-1/4}$, substantially enhancing the signal and\npotentially playing a key role in the detection of gravitational waves lensed\nnear caustics. Notably, for lens masses below the galactic scale, the caustic\nwidth for gravitational waves is not negligible compared to the Einstein\nradius-as it is in electromagnetic lensing-making the UA essential for\naccurately capturing wave effects.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T11:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.10131v1","title":"A three-functor formalism for commutative von Neumann algebras","summary":"A three-functor formalism is the half of a six-functor formalism that\nsupports the projection and base change formulas. In this paper, we provide a\nthree-functor formalism for commutative von Neumann algebras and their modules.\nUsing the Gelfand-Naimark theorem, this gives rise to a three-functor formalism\nfor measure spaces and measurable bundles of Hilbert spaces. We use this to\nprove Fell absorption for unitary representations of measure groupoids.\n  The three-functor formalism for commutative von Neumann algebras takes values\nin W*-categories, and we discuss in what sense it is a unitary three-functor\nformalism.","main_category":"math.OA","categories":"math.OA,math.CT,math.QA","published":"2025-04-14T11:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.10140v1","title":"The topology of synergy: linking topological and information-theoretic\n  approaches to higher-order interactions in complex systems","summary":"The study of irreducible higher-order interactions has become a core topic of\nstudy in complex systems. Two of the most well-developed frameworks,\ntopological data analysis and multivariate information theory, aim to provide\nformal tools for identifying higher-order interactions in empirical data.\nDespite similar aims, however, these two approaches are built on markedly\ndifferent mathematical foundations and have been developed largely in parallel.\nIn this study, we present a head-to-head comparison of topological data\nanalysis and information-theoretic approaches to describing higher-order\ninteractions in multivariate data; with the aim of assessing the similarities\nand differences between how the frameworks define ``higher-order structures.\"\nWe begin with toy examples with known topologies, before turning to\nnaturalistic data: fMRI signals collected from the human brain. We find that\nintrinsic, higher-order synergistic information is associated with\nthree-dimensional cavities in a point cloud: shapes such as spheres are\nsynergy-dominated. In fMRI data, we find strong correlations between\nsynergistic information and both the number and size of three-dimensional\ncavities. Furthermore, we find that dimensionality reduction techniques such as\nPCA preferentially represent higher-order redundancies, and largely fail to\npreserve both higher-order information and topological structure, suggesting\nthat common manifold-based approaches to studying high-dimensional data are\nsystematically failing to identify important features of the data. These\nresults point towards the possibility of developing a rich theory of\nhigher-order interactions that spans topological and information-theoretic\napproaches while simultaneously highlighting the profound limitations of more\nconventional methods.","main_category":"cs.IT","categories":"cs.IT,math.IT,q-bio.NC","published":"2025-04-14T11:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.10143v1","title":"Negate or Embrace: On How Misalignment Shapes Multimodal Representation\n  Learning","summary":"Multimodal representation learning, exemplified by multimodal contrastive\nlearning (MMCL) using image-text pairs, aims to learn powerful representations\nby aligning cues across modalities. This approach relies on the core assumption\nthat the exemplar image-text pairs constitute two representations of an\nidentical concept. However, recent research has revealed that real-world\ndatasets often exhibit misalignment. There are two distinct viewpoints on how\nto address this issue: one suggests mitigating the misalignment, and the other\nleveraging it. We seek here to reconcile these seemingly opposing perspectives,\nand to provide a practical guide for practitioners. Using latent variable\nmodels we thus formalize misalignment by introducing two specific mechanisms:\nselection bias, where some semantic variables are missing, and perturbation\nbias, where semantic variables are distorted -- both affecting latent variables\nshared across modalities. Our theoretical analysis demonstrates that, under\nmild assumptions, the representations learned by MMCL capture exactly the\ninformation related to the subset of the semantic variables invariant to\nselection and perturbation biases. This provides a unified perspective for\nunderstanding misalignment. Based on this, we further offer actionable insights\ninto how misalignment should inform the design of real-world ML systems. We\nvalidate our theoretical findings through extensive empirical studies on both\nsynthetic data and real image-text datasets, shedding light on the nuanced\nimpact of misalignment on multimodal representation learning.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-14T11:54:19Z"}
{"aid":"http://arxiv.org/abs/2504.10151v1","title":"Continual learning for rotating machinery fault diagnosis with\n  cross-domain environmental and operational variations","summary":"Although numerous machine learning models exist to detect issues like rolling\nbearing strain and deformation, typically caused by improper mounting,\noverloading, or poor lubrication, these models often struggle to isolate faults\nfrom the noise of real-world operational and environmental variability.\nConditions such as variable loads, high temperatures, stress, and rotational\nspeeds can mask early signs of failure, making reliable detection challenging.\nTo address these limitations, this work proposes a continual deep learning\napproach capable of learning across domains that share underlying structure\nover time. This approach goes beyond traditional accuracy metrics by addressing\nfour second-order challenges: catastrophic forgetting (where new learning\noverwrites past knowledge), lack of plasticity (where models fail to adapt to\nnew data), forward transfer (using past knowledge to improve future learning),\nand backward transfer (refining past knowledge with insights from new domains).\nThe method comprises a feature generator and domain-specific classifiers,\nallowing capacity to grow as new domains emerge with minimal interference,\nwhile an experience replay mechanism selectively revisits prior domains to\nmitigate forgetting. Moreover, nonlinear dependencies across domains are\nexploited by prioritizing replay from those with the highest prior errors,\nrefining models based on most informative past experiences. Experiments show\nhigh average domain accuracy (up to 88.96%), with forgetting measures as low as\n.0027 across non-stationary class-incremental environments.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T12:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.10168v1","title":"HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for\n  Hallucination Detection","summary":"In this paper, we present HalluSearch, a multilingual pipeline designed to\ndetect fabricated text spans in Large Language Model (LLM) outputs. Developed\nas part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and\nRelated Observable Overgeneration Mistakes, HalluSearch couples\nretrieval-augmented verification with fine-grained factual splitting to\nidentify and localize hallucinations in fourteen different languages. Empirical\nevaluations show that HalluSearch performs competitively, placing fourth in\nboth English (within the top ten percent) and Czech. While the system's\nretrieval-based strategy generally proves robust, it faces challenges in\nlanguages with limited online coverage, underscoring the need for further\nresearch to ensure consistent hallucination detection across diverse linguistic\ncontexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.10175v1","title":"Global-in-time Well-posedness of Classical Solutions to the Vacuum Free\n  Boundary Problem for the Viscous Saint-Venant System with Large Data","summary":"We establish the global well-posedness of classical solutions to the vacuum\nfree boundary problem of the 1-D viscous Saint-Venant system with large data.\nSince the depth $\\rho$ of the fluid vanishes on the moving boundary, the\nmomentum equations become degenerate both in the time evolution and spatial\ndissipation, which may lead to singularities for the derivatives of the\nvelocity u of the fluid and then makes it challenging to study classical\nsolutions. By exploiting the intrinsic degenerate-singular structures of this\nsystem, we are able to identify two classes of admissible initial depth profile\nand obtain the global well-posedness theory here: $\\rho_0^\\alpha\\in H^3$\n$(\\frac{1}{3}<\\alpha<1)$ vanishes as the distance to the moving boundary, which\nsatisfies the BD entropy condition; while $\\rho_0\\in H^3$ vanishes as the\ndistance to the moving boundary, which satisfies the physical vacuum boundary\ncondition, but violates the BD entropy condition. Further, it is shown that for\narbitrarily large time, the solutions obtained here are smooth (in Sobolev\nspaces) all the way up to the moving boundary. One of the key ingredients of\nthe analysis here is to establish some degenerate weighted estimates for the\neffective velocity $v=u+ (\\log\\rho)_y$ (y is the Eulerian spatial coordinate)\nvia its transport properties, which enables one to obtain the upper bounds for\nthe first order derivatives of the flow map $\\eta$. Then the global regularity\nuniformly up to the vacuum boundary can be obtained by carrying out a series of\nweighted energy estimates carefully designed for this system. It is worth\npointing out that the result here seems to be the first global existence theory\nof classical solutions with large data that is independent of the BD entropy\nfor such degenerate systems, and the methodology developed here can be applied\nto more general degenerate CNS.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T12:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.10179v1","title":"The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental\n  Evaluation of Prompt Engineering Methods for Robust Multimodal Performance","summary":"Multimodal Large Language Models (MLLMs) are set to transform how machines\nprocess and generate human-like responses by integrating diverse modalities\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\nhinges on optimal prompt engineering. We present a comprehensive experimental\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\nand Integration. Our approach stratifies models by parameter count into Small\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\nin structured tasks such as code generation, achieving accuracies up to 96.88%\nunder Few-Shot prompting, all models struggle with complex reasoning and\nabstract understanding, often yielding accuracies below 60% and high\nhallucination rates. Structured reasoning prompts frequently increased\nhallucination up to 75% in small models and led to longer response times (over\n20 seconds in Large MLLMs), while simpler prompting methods provided more\nconcise and efficient outputs. No single prompting method uniformly optimises\nall task types. Instead, adaptive strategies combining example-based guidance\nwith selective structured reasoning are essential to enhance robustness,\nefficiency, and factual accuracy. Our findings offer practical recommendations\nfor prompt engineering and support more reliable deployment of MLLMs across\napplications including AI-assisted coding, knowledge retrieval, and multimodal\ncontent understanding.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.ET","published":"2025-04-14T12:31:39Z"}
{"aid":"http://arxiv.org/abs/2504.10191v1","title":"Localized Cultural Knowledge is Conserved and Controllable in Large\n  Language Models","summary":"Just as humans display language patterns influenced by their native tongue\nwhen speaking new languages, LLMs often default to English-centric responses\neven when generating in other languages. Nevertheless, we observe that local\ncultural information persists within the models and can be readily activated\nfor cultural customization. We first demonstrate that explicitly providing\ncultural context in prompts significantly improves the models' ability to\ngenerate culturally localized responses. We term the disparity in model\nperformance with versus without explicit cultural context the explicit-implicit\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\nit may not naturally surface in multilingual interactions if cultural context\nis not explicitly provided. Despite the explicit prompting benefit, however,\nthe answers reduce in diversity and tend toward stereotypes. Second, we\nidentify an explicit cultural customization vector, conserved across all\nnon-English languages we explore, which enables LLMs to be steered from the\nsynthetic English cultural world-model toward each non-English cultural world.\nSteered responses retain the diversity of implicit prompting and reduce\nstereotypes to dramatically improve the potential for customization. We discuss\nthe implications of explicit cultural customization for understanding the\nconservation of alternative cultural world models within LLMs, and their\ncontrollable utility for translation, cultural customization, and the\npossibility of making the explicit implicit through soft control for expanded\nLLM function and appeal.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.10206v1","title":"Approximation by Neural Network Sampling Operators in Mixed Lebesgue\n  Spaces","summary":"In this paper, we prove the rate of approximation for the Neural Network\nSampling Operators activated by sigmoidal functions with mixed Lebesgue norm in\nterms of averaged modulus of smoothness for a bounded measurable functions on\nbounded domain. In order to achieve the above result, we first establish that\nthe averaged modulus of smoothness is finite for certain suitable subspaces of\n$L^{p,q}(\\mathbb{R}\\times\\mathbb{R}).$ Using the properties of averaged modulus\nof smoothness, we estimate the rate of approximation of certain linear\noperators in mixed Lebesgue norm. Then, as an application of these linear\noperators, we obtain the Jackson type approximation theorem, in order to give a\ncharacterization for the rate of approximation of neural network operators\nin-terms of averaged modulus of smoothness in mixed norm. Lastly, we discuss\nsome examples of sigmoidal functions and using these sigmoidal functions, we\nshow the implementation of continuous and discontinuous functions by neural\nnetwork operators.","main_category":"math.FA","categories":"math.FA","published":"2025-04-14T13:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.10211v1","title":"Energy-preserving iteration schemes for Gauss collocation integrators","summary":"In this work, we develop energy-preserving iterative schemes for the\n(non-)linear systems arising in the Gauss integration of Poisson systems with\nquadratic Hamiltonian. Exploiting the relation between Gauss collocation\nintegrators and diagonal Pad\\'e approximations, we establish a Krylov-subspace\niteration scheme based on a $Q$-Arnoldi process for linear systems that\nprovides energy conservation not only at convergence --as standard iteration\nschemes do--, but also at the level of the individual iterates. It is\ncompetitive with GMRES in terms of accuracy and cost for a single iteration\nstep and hence offers significant efficiency gains, when it comes to time\nintegration of high-dimensional Poisson systems within given error tolerances.\nOn top of the linear results, we consider non-linear Poisson systems and design\nnon-linear solvers for the implicit midpoint rule (Gauss integrator of second\norder), using the fact that the associated Pad\\'e approximation is a Cayley\ntransformation. For the non-linear systems arising at each time step, we\npropose fixed-point and Newton-type iteration schemes that inherit the\nconvergence order with comparable cost from their classical versions, but have\nenergy-preserving iterates.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T13:26:38Z"}
{"aid":"http://arxiv.org/abs/2504.10213v1","title":"The HYDRA pion-tracker for hypernuclei studies at R3B","summary":"The HYpernuclei-Decay at R3B Apparatus (HYDRA) tracker is a novel time\nprojection chamber combined with a plastic scintillator wall for timing and\ntrigger purposes. This detector is a low radiation length tracker dedicated to\nmeasuring pions from the weak decay of light hypernuclei produced from ion-ion\ncollisions at few GeV/nucleon in the magnetic field of the large-acceptance\ndipole magnet GLAD at the Reactions with Relativistic Radioactive Beams (R3B)\nexperiment at GSI-FAIR. In this paper, we describe the design of the detector\nand provide the results of its first characterizations.","main_category":"physics.ins-det","categories":"physics.ins-det,nucl-ex","published":"2025-04-14T13:29:59Z"}
{"aid":"http://arxiv.org/abs/2504.10220v1","title":"Modeling the Thermal Structure of a Protoplanetary Disk Using Multiband\n  Flux-Limited Diffusion Approximation","summary":"This work continues the analysis of the model for calculating the thermal\nstructure of an axisymmetric protoplanetary disk, initiated in the paper by\nPavlyuchenkov (2024). The model is based on the well-known Flux-Limited\nDiffusion (FLD) approximation with separate calculation of heating by direct\nstellar radiation (hereinafter referred to as the FLD$^{\\rm s}$ method). In\naddition to the previously described FLD$^{\\rm s}$ model with\nwavelength-averaged opacities, we present a multiband model mFLD$^{\\rm s}$,\nwhere the spectrum of thermal radiation is divided into several frequency\nbands. The model is based on an implicit finite-difference scheme for the\nequations of thermal radiation diffusion, which reduces to a system of linear\nalgebraic equations written in hypermatrix form. A modified Gauss method for\ninverting the sparse hypermatrix of the original system of linear equations is\nproposed. The simulation results described in the article show that the\nmidplane radial temperature profile obtained with the mFLD$^{\\rm s}$ method has\na variable slope in accordance with the reference Monte Carlo radiative\ntransfer simulations. The mFLD$^{\\rm s}$ model also qualitatively reproduces\nthe non-isothermality of the temperature distribution along the angular\ncoordinate near the midplane, which is not provided by the FLD$^{\\rm s}$\nmethod. However, quantitative differences remain between the reference\ntemperature values and the results of mFLD$^{\\rm s}$. These differences are\nlikely due to the diffusive nature of the FLD approximation. It is also shown\nthat the characteristic times for the disk to reach thermal equilibrium within\nthe mFLD$^{\\rm s}$ model can be significantly shorter than in FLD$^{\\rm s}$.\nThis property should be taken into account when modeling non-stationary\nprocesses in protoplanetary disks within FLD-based models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-14T13:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.10223v1","title":"A proof of the Krzyz conjecture","summary":"A proof of the Krzyz conjecture is presented, based on the application of the\nvariational method, as well as on the use of two classical results and some of\ntheir consequences. The mentioned results are the Caratheodory-Toeplitz\ncriterion of continuing a polynomial to a Caratheodory class function, and the\nRiesz-Fejer theorem about trigonometric polynomials. This is an English\ntranslation of a preprint originally published in Russian:\nhttps://preprints.ru/article/1799","main_category":"math.CV","categories":"math.CV","published":"2025-04-14T13:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.10224v1","title":"Simulation and Experimental Validation of Optical Camera Communication","summary":"While simulation tools for visible light communication (VLC) with photo\ndetectors (PDs) have been widely investigated, similar tools for optical camera\ncommunication (OCC) with complementary metal oxide semiconductor (CMOS) sensors\nare lacking in this regard. Camera based VLC systems have much lower data rates\nowing to camera exposure times. Among the few extant OCC simulation tools, none\nallow for simulation of images when exposure time is greater than the signal\nperiod. An accurate simulation of the OCC system can be used to improve the\ndata rate and quality of performance. We propose a simple simulation technique\nfor OCC which allows to test for system performance at frequencies beyond the\ncamera shutter speed. This will allow much needed data rate improvement by\noperating at the actual frequency a decoding algorithm ceases detection instead\nof the exposure limit used now. We have tested the accuracy of simulation by\ncomparing the detection success rates of simulated images with experimental\nimages. The proposed simulation technique was shown to be accurate through\nexperimental validation for two different cameras.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T13:45:09Z"}
{"aid":"http://arxiv.org/abs/2504.10228v1","title":"Magneto-Hydrodynamic Simulations of Eccentric Binary Neutron Star\n  Mergers","summary":"Highly eccentric binary neutron star mergers exhibit unique dynamical and\nobservational signatures compared to quasi-circular ones in terms of their\ngravitational wave signal and the ejection of matter, leading to different\nelectromagnetic counterparts. In this article, we present general relativistic\nmagneto-hydrodynamic simulations of binary neutron star systems on highly\neccentric orbits. While in quasi-circular binaries, the influence of the\nmagnetic field is too weak to affect the general pre-merger dynamics, the close\nencounters in eccentric systems could potentially trigger magneto-hydrodynamic\ninstabilities. Therefore, we investigate possible effects before, during, and\nafter the merger for a total of three different systems with varying initial\neccentricity.\n  We study the f-mode oscillations excited by tidal interaction in close\nencounters and find good agreement with predicted f-mode frequency estimates.\nHowever, our simulations reveal no significant differences compared to results\nneglecting the magnetic field. Although we observe a rearrangement of the\npoloidal structure of the magnetic field inside the stars, there is no relevant\nincrease in the magnetic energy during the encounters. Also, during the merger,\nthe amplification of the magnetic field seems to be largely independent of the\neccentricity in our systems. Consistent with studies of merging non-magnetized\nbinary neutron stars, we find a correlation between eccentricity and mass\nejection, with a higher impact parameter leading to a larger amount of unbound\nmaterial.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-14T13:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.10237v1","title":"Tailoring Neel orders in Layered Topological Antiferromagnets","summary":"In the two-dimensional limit, the interplay between Neel order and band\ntopology in van der Waals topological antiferromagnets can give rise to novel\nquantum phenomena in the quantum anomalous Hall state, including the cascaded\nquantum phase transition and spin-modulation effect. However, due to the\nabsence of net magnetization in antiferromagnets, probing the energetically\ndegenerate Neel orders has long remained a significant challenge. Inspired by\nrecent advances in realizing the quantum anomalous Hall effect in AlOx-capped\nlayered topological antiferromagnet MnBi2Te4, we demonstrate deterministic\ncontrol over the Neel order through surface anisotropy engineering enabled by\nthe AlOx capping layer. By tuning the surface anisotropy, we uncover\nparitydependent symmetry breaking states that manifest as distinct odd-even\nboundary architectures, including 180 degree domain walls or continuous spin\nstructures. Comparative studies between AlOx-capped and pristine odd-layer\nMnBi2Te4 flakes using domain-resolved magnetic force microscopy reveal\npronounced differences in coercivity and magnetization-reversal dynamics.\nNotably, an unconventional giant exchange bias, which arises from perpendicular\nmagnetic anisotropy rather than traditional interface pinning mechanisms, is\nobserved for the first time. Our findings establish a pathway for manipulating\nNeel order through surface modification in A-type antiferromagnets, offering\nnew opportunities for spintronic devices and quantum information technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T14:01:21Z"}
{"aid":"http://arxiv.org/abs/2504.10240v1","title":"GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction","summary":"Circuit link prediction identifying missing component connections from\nincomplete netlists is crucial in automating analog circuit design. However,\nexisting methods face three main challenges: 1) Insufficient use of topological\npatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to\nthe complexity of annotations hinders model generalization; 3) Limited\nadaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural\nNetworks (GNNs) based framework featuring three innovations to tackle these\nchallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes\nfor Link Prediction) framework and achieve port-level accuracy in circuit link\nprediction. Second, we propose Netlist Babel Fish, a netlist format conversion\ntool leveraging retrieval-augmented generation (RAG) with large language model\n(LLM) to enhance the compatibility of netlist formats. Finally, we construct\nSpiceNetlist, a comprehensive dataset that contains 775 annotated circuits\nacross 10 different classes of components. The experimental results demonstrate\nan improvement of 15.05% on the SpiceNetlist dataset and 12.01% on the\nImage2Net dataset over the existing approach.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-14T14:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.10246v1","title":"Simplified and Verified: A Second Look at a Proof-Producing Union-Find\n  Algorithm","summary":"Using Isabelle/HOL, we verify a union-find data structure with an explain\noperation due to Nieuwenhuis and Oliveras. We devise a simpler, more naive\nversion of the explain operation whose soundness and completeness is easy to\nverify. Then, we prove the original formulation of the explain operation to be\nequal to our version. Finally, we refine this data structure to Imperative HOL,\nenabling us to export efficient imperative code. The formalisation provides a\nstepping stone towards the verification of proof-producing congruence closure\nalgorithms which are a core ingredient of Satisfiability Modulo Theories (SMT)\nsolvers.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T14:09:09Z"}
{"aid":"http://arxiv.org/abs/2504.10248v1","title":"Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for\n  Dynamic Data Acquisition in Digital Twins","summary":"This paper introduces a sensor steering methodology based on deep\nreinforcement learning to enhance the predictive accuracy and decision support\ncapabilities of digital twins by optimising the data acquisition process.\nTraditional sensor placement techniques are often constrained by one-off\noptimisation strategies, which limit their applicability for online\napplications requiring continuous informative data assimilation. The proposed\napproach addresses this limitation by offering an adaptive framework for sensor\nplacement within the digital twin paradigm. The sensor placement problem is\nformulated as a Markov decision process, enabling the training and deployment\nof an agent capable of dynamically repositioning sensors in response to the\nevolving conditions of the physical structure as represented by the digital\ntwin. This ensures that the digital twin maintains a highly representative and\nreliable connection to its physical counterpart. The proposed framework is\nvalidated through a series of comprehensive case studies involving a cantilever\nplate structure subjected to diverse conditions, including healthy and damaged\nconditions. The results demonstrate the capability of the deep reinforcement\nlearning agent to adaptively reposition sensors improving the quality of data\nacquisition and hence enhancing the overall accuracy of digital twins.","main_category":"stat.ML","categories":"stat.ML,cs.LG,eess.SP","published":"2025-04-14T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.10250v1","title":"MURR: Model Updating with Regularized Replay for Searching a Document\n  Stream","summary":"The Internet produces a continuous stream of new documents and user-generated\nqueries. These naturally change over time based on events in the world and the\nevolution of language. Neural retrieval models that were trained once on a\nfixed set of query-document pairs will quickly start misrepresenting\nnewly-created content and queries, leading to less effective retrieval.\nTraditional statistical sparse retrieval can update collection statistics to\nreflect these changes in the use of language in documents and queries. In\ncontrast, continued fine-tuning of the language model underlying neural\nretrieval approaches such as DPR and ColBERT creates incompatibility with\npreviously-encoded documents. Re-encoding and re-indexing all\npreviously-processed documents can be costly. In this work, we explore updating\na neural dual encoder retrieval model without reprocessing past documents in\nthe stream. We propose MURR, a model updating strategy with regularized replay,\nto ensure the model can still faithfully search existing documents without\nreprocessing, while continuing to update the model for the latest topics. In\nour simulated streaming environments, we show that fine-tuning models using\nMURR leads to more effective and more consistent retrieval results than other\nstrategies as the stream of documents and queries progresses.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-14T14:13:03Z"}
{"aid":"http://arxiv.org/abs/2504.10257v1","title":"Spectral estimation for high-dimensional linear processes","summary":"We propose a novel estimation procedure for certain spectral distributions\nassociated with a class of high dimensional linear time series. The processes\nunder consideration are of the form $X_t = \\sum_{\\ell=0}^\\infty \\mathbf{A}_\\ell\nZ_{t-\\ell}$ with iid innovations $(Z_t)$. The key structural assumption is that\nthe coefficient matrices and the variance of the innovations are simultaneously\ndiagonalizable in a common orthonormal basis. We develop a strategy for\nestimating the joint spectral distribution of the coefficient matrices and the\ninnovation variance by making use of the asymptotic behavior of the eigenvalues\nof appropriately weighted integrals of the sample periodogram. Throughout we\nwork under the asymptotic regime $p,n \\to \\infty$, such that $p/n\\to c \\in\n(0,\\infty)$, where $p$ is the dimension and $n$ is the sample size. Under this\nsetting, we first establish a weak limit for the empirical distribution of\neigenvalues of the aforementioned integrated sample periodograms. This result\nis proved using techniques from random matrix theory, in particular the\ncharacterization of weak convergence by means of the Stieltjes transform of\nrelevant distributions. We utilize this result to develop an estimator of the\njoint spectral distribution of the coefficient matrices, by minimizing an\n$L^\\kappa$ discrepancy measure, for $\\kappa \\geq 1$, between the empirical and\nlimiting Stieltjes transforms of the integrated sample periodograms. This is\naccomplished by assuming that the joint spectral distribution is a discrete\nmixture of point masses. We also prove consistency of the estimator\ncorresponding to the $L^2$ discrepancy measure. We illustrate the methodology\nthrough simulations and an application to stock price data from the S\\&P 500\nseries.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-14T14:19:43Z"}
{"aid":"http://arxiv.org/abs/2504.10259v1","title":"Dual-grid parameter choice method with application to image deblurring","summary":"Variational regularization of ill-posed inverse problems is based on\nminimizing the sum of a data fidelity term and a regularization term. The\nbalance between them is tuned using a positive regularization parameter, whose\nautomatic choice remains an open question in general. A novel approach for\nparameter choice is introduced, based on the use of two slightly different\ncomputational models for the same inverse problem. Small parameter values\nshould give two very different reconstructions due to amplification of noise.\nLarge parameter values lead to two identical but trivial reconstructions.\nOptimal parameter is chosen between the extremes by matching image similarity\nof the two reconstructions with a pre-defined value. Efficacy of the new method\nis demonstrated with image deblurring using measured data and two different\nregularizers.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T14:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.10261v1","title":"Universality, Robustness, and Limits of the Eigenstate Thermalization\n  Hypothesis in Open Quantum Systems","summary":"The eigenstate thermalization hypothesis (ETH) underpins much of our modern\nunderstanding of the thermalization of closed quantum many-body systems. Here,\nwe investigate the statistical properties of observables in the eigenbasis of\nthe Lindbladian operator of a Markovian open quantum system. We demonstrate the\nvalidity of a Lindbladian ETH ansatz through extensive numerical simulations of\nseveral physical models. To highlight the robustness of Lindbladian ETH, we\nconsider what we dub the dilute-click regime of the model, in which one\npostselects only quantum trajectories with a finite fraction of quantum jumps.\nThe average dynamics are generated by a non-trace-preserving Liouvillian, and\nwe show that the Lindbladian ETH ansatz still holds in this case. On the other\nhand, the no-click limit is a singular point at which the Lindbladian reduces\nto a doubled non-Hermitian Hamiltonian and Lindbladian ETH breaks down.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,nlin.CD,quant-ph","published":"2025-04-14T14:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.10263v1","title":"Quantized Axial Charge in the Hamiltonian Approach to Wilson Fermions","summary":"We investigate the Hamiltonian formulation of 1+1~D staggered fermions and\nreconstruct vector and axial charge operators, found by Arkya Chatterjee et\nal., using the Wilson fermion formalism. These operators commute with the\nHamiltonian and become the generators of vector and axial $\\mathrm{U}(1)$\nsymmetries in the continuum limit. An interesting feature of the axial charge\noperator is that it acts locally on operators and has quantized eigenvalues in\nmomentum space. Therefore, the eigenstates of this operator can be interpreted\nas fermion states with a well-defined integer chirality, analogous to those in\nthe continuum theory. This allows us to realize a gauge theory where the axial\n$\\mathrm{U}(1)_A$ symmetry acts as a gauge symmetry. We construct a Hamiltonian\nusing the eigenstates of the axial charge operator, preserving exact axial\nsymmetry on the lattice and vector symmetry in the continuum. As applications,\nwe examine the implementation of the Symmetric Mass Generation (SMG) mechanism\nin the $1^4(-1)^4$ and 3-4-5-0 models. Our formulation supports\nsymmetry-preserving interactions with quantized chiral charges, although\nfurther numerical studies are required to verify the SMG mechanism in\ninteracting models.","main_category":"hep-lat","categories":"hep-lat,hep-th","published":"2025-04-14T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.10270v1","title":"Affine and cyclotomic $q$-Schur categories via webs","summary":"We formulate two new $\\mathbb Z[q,q^{-1}]$-linear diagrammatic monoidal\ncategories, the affine $q$-web category and the affine $q$-Schur category, as\nwell as their respective cyclotomic quotient categories. Diagrammatic integral\nbases for the Hom-spaces of all these categories are established. In addition,\nwe establish the following isomorphisms, providing diagrammatic presentations\nof these $q$-Schur algebras for the first time: (i)~ the path algebras of the\naffine $q$-web category to R.~Green's affine $q$-Schur algebras, (ii)~ the path\nalgebras of the affine $q$-Schur category to Maksimau-Stroppel's higher level\naffine $q$-Schur algebras, and most significantly, (iii)~ the path algebras of\nthe cyclotomic $q$-Schur categories to Dipper-James-Mathas' cyclotomic\n$q$-Schur algebras.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-04-14T14:34:52Z"}
{"aid":"http://arxiv.org/abs/2504.10280v1","title":"Look-to-Touch: A Vision-Enhanced Proximity and Tactile Sensor for\n  Distance and Geometry Perception in Robotic Manipulation","summary":"Camera-based tactile sensors provide robots with a high-performance tactile\nsensing approach for environment perception and dexterous manipulation.\nHowever, achieving comprehensive environmental perception still requires\ncooperation with additional sensors, which makes the system bulky and limits\nits adaptability to unstructured environments. In this work, we present a\nvision-enhanced camera-based dual-modality sensor, which realizes full-scale\ndistance sensing from 50 cm to -3 mm while simultaneously keeping\nultra-high-resolution texture sensing and reconstruction capabilities. Unlike\nconventional designs with fixed opaque gel layers, our sensor features a\npartially transparent sliding window, enabling mechanical switching between\ntactile and visual modes. For each sensing mode, a dynamic distance sensing\nmodel and a contact geometry reconstruction model are proposed. Through\nintegration with soft robotic fingers, we systematically evaluate the\nperformance of each mode, as well as in their synergistic operation.\nExperimental results show robust distance tracking across various speeds,\nnanometer-scale roughness detection, and sub-millimeter 3D texture\nreconstruction. The combination of both modalities improves the robot's\nefficiency in executing grasping tasks. Furthermore, the embedded mechanical\ntransmission in the sensor allows for fine-grained intra-hand adjustments and\nprecise manipulation, unlocking new capabilities for soft robotic hands.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T14:49:09Z"}
{"aid":"http://arxiv.org/abs/2504.10284v1","title":"Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the\n  Evaluation Protocol","summary":"Literature review tables are essential for summarizing and comparing\ncollections of scientific papers. We explore the task of generating tables that\nbest fulfill a user's informational needs given a collection of scientific\npapers. Building on recent work (Newman et al., 2024), we extend prior\napproaches to address real-world complexities through a combination of\nLLM-based methods and human annotations. Our contributions focus on three key\nchallenges encountered in real-world use: (i) User prompts are often\nunder-specified; (ii) Retrieved candidate papers frequently contain irrelevant\ncontent; and (iii) Task evaluation should move beyond shallow text similarity\ntechniques and instead assess the utility of inferred tables for\ninformation-seeking tasks (e.g., comparing papers). To support reproducible\nevaluation, we introduce ARXIV2TABLE, a more realistic and challenging\nbenchmark for this task, along with a novel approach to improve literature\nreview table generation in real-world scenarios. Our extensive experiments on\nthis benchmark show that both open-weight and proprietary LLMs struggle with\nthe task, highlighting its difficulty and the need for further advancements.\nOur dataset and code are available at https://github.com/JHU-CLSP/arXiv2Table.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T14:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.10285v1","title":"Grothendieck-Springer resolutions and TQFTs","summary":"Let $G$ be a connected complex semisimple group with Lie algebra\n$\\mathfrak{g}$ and fixed Kostant slice $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$.\nIn a previous work, we show that\n$((T^*G)_{\\text{reg}}\\rightrightarrows\\mathfrak{g}^*_{\\text{reg}},\\mathrm{Kos})$\nyields the open Moore-Tachikawa TQFT. Morphisms in the image of this TQFT are\ncalled open Moore-Tachikawa varieties. By replacing\n$T^*G\\rightrightarrows\\mathfrak{g}^*$ and $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$\nwith the double $\\mathrm{D}(G)\\rightrightarrows G$ and a Steinberg slice\n$\\mathrm{Ste}\\subseteq G$, respectively, one obtains quasi-Hamiltonian\nanalogues of the open Moore-Tachikawa TQFT and varieties.\n  We consider a conjugacy class $\\mathcal{C}$ of parabolic subalgebras of\n$\\mathfrak{g}$. This class determines partial Grothendieck-Springer resolutions\n$\\mu_{\\mathcal{C}}:\\mathfrak{g}_{\\mathcal{C}}\\longrightarrow\\mathfrak{g}^*=\\mathfrak{g}$\nand $\\nu_{\\mathcal{C}}:G_{\\mathcal{C}}\\longrightarrow G$. We construct a\ncanonical symplectic groupoid\n$(T^*G)_{\\mathcal{C}}\\rightrightarrows\\mathfrak{g}_{\\mathcal{C}}$ and\nquasi-symplectic groupoid $\\mathrm{D}(G)_{\\mathcal{C}}\\rightrightarrows\nG_{\\mathcal{C}}$. In addition, we prove that the pairs\n$(((T^*G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(\\mathfrak{g}_{\\mathcal{C}})_{\\text{reg}},\\mu_{\\mathcal{C}}^{-1}(\\mathrm{Kos}))$\nand\n$((\\mathrm{D}(G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(G_{\\mathcal{C}})_{\\text{reg}},\\nu_{\\mathcal{C}}^{-1}(\\mathrm{Ste}))$\ndetermine TQFTs in a $1$-shifted Weinstein symplectic category. Our main result\nis about the Hamiltonian symplectic varieties arising from the former TQFT; we\nshow that these have canonical Lagrangian relations to the open Moore-Tachikawa\nvarieties. Pertinent specializations of our results to the full\nGrothendieck-Springer resolution are discussed throughout this manuscript.","main_category":"math.SG","categories":"math.SG,math.AG,math.RT","published":"2025-04-14T14:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.10290v1","title":"Maximizing subgraph density in graphs of bounded degree and clique\n  number","summary":"We asymptotically determine the maximum density of subgraphs isomorphic to\n$H$, where $H$ is any graph containing a dominating vertex, in graphs $G$ on\n$n$ vertices with bounded maximum degree and bounded clique number. That is, we\nasymptotically determine the constant $c=c(H,\\Delta,\\omega)$ such that\nex$(n,H,\\{K_{1,\\Delta+1},K_{\\omega+1}\\})=(1-o_n(1))cn$. More generally, if $H$\nhas at least $u$ dominating vertices, then we find the maximum density of\nsubgraphs isomorphic to $H$ in graphs $G$ that have $p$ cliques of size $u$,\nhave bounded clique number, and are $K_u\\vee I_{\\Delta+1}$-free. For example,\nwe asymptotically determine the constant $d=d(H,\\Delta,\\omega)$ such that\nmex$(m,H,\\{K_{1,1,\\Delta+1},K_{\\omega+1}\\})=(1-o_m(1))dm$. Then we localize\nthese results, proving a tight inequality involving the sizes of the locally\nlargest cliques and complete split graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T15:02:24Z"}
{"aid":"http://arxiv.org/abs/2504.10298v1","title":"Cross-talk in superconducting qubit lattices with tunable couplers -\n  comparing transmon and fluxonium architectures","summary":"Cross-talk between qubits is one of the main challenges for scaling\nsuperconducting quantum processors. Here, we use the density-matrix\nrenormalization-group to numerically analyze lattices of superconducting qubits\nfrom a perspective of many-body localization. Specifically, we compare\ndifferent architectures that include tunable couplers designed to decouple\nqubits in the idle state, and calculate the residual ZZ interactions as well as\nthe inverse participation ratio in the computational basis states. For transmon\nqubits outside of the straddling regime, the results confirm that tunable\nC-shunt flux couplers are significantly more efficient in mitigating the ZZ\ninteractions than tunable transmons. A recently proposed fluxonium architecture\nwith tunable transmon couplers is demonstrated to also maintain its strong\nsuppression of the ZZ interactions in larger systems, while having a higher\ninverse participation ratio in the computational basis states than lattices of\ntransmon qubits. Our results thus suggest that fluxonium architectures may\nfeature lower cross talk than transmon lattices when designed to achieve\nsimilar gate speeds and fidelities.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T15:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.10306v1","title":"Global existence of measure-valued solutions to the multicomponent\n  Smoluchowski coagulation equation","summary":"Global solutions to the multicomponent Smoluchowski coagulation equation are\nconstructed for measure-valued initial data with minimal assumptions on the\nmoments. The framework is based on an abstract formulation of the\nArzel\\`a-Ascoli theorem for uniform spaces. The result holds for a large class\nof coagulation rate kernels, satisfying a power-law upper bound with possibly\ndifferent singularities at small-small, small-large and large-large coalescence\npairs. This includes in particular both mass-conserving and gelling kernels, as\nwell as interpolation kernels used in applications. We also provide short\nproofs of mass-conservation and gelation results for any weak solution, which\nextends previous results for one-component systems.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-14T15:14:22Z"}
{"aid":"http://arxiv.org/abs/2504.10315v1","title":"An energy optimization method based on mixed-integer model and\n  variational quantum computing algorithm for faster IMPT","summary":"Intensity-modulated proton therapy (IMPT) offers superior dose conformity\nwith reduced exposure to surrounding healthy tissues compared to conventional\nphoton therapy. Improving IMPT delivery efficiency reduces motion-related\nuncertainties, enhances plan robustness, and benefits breath-hold techniques by\nshortening treatment time. Among various factors, energy switching time plays a\ncritical role, making energy layer optimization (ELO) essential. This work\ndevelops an energy layer optimization method based on mixed integer model and\nvariational quantum computing algorithm to enhance the efficiency of IMPT. The\nenergy layer optimization problem is modeled as a mixed-integer program, where\ncontinuous variables optimize the dose distribution and binary variables\nindicate energy layer selection. To solve it, iterative convex relaxation\ndecouples the dose-volume constraints, followed by the alternating direction\nmethod of multipliers (ADMM) to separate mixed-variable optimization and the\nminimum monitor unit (MMU) constraint. The resulting beam intensity subproblem,\nsubject to MMU, either admits a closed-form solution or is efficiently solvable\nvia conjugate gradient. The binary subproblem is cast as a quadratic\nunconstrained binary optimization (QUBO) problem, solvable using variational\nquantum computing algorithms. With nearly the same plan quality, the proposed\nmethod noticeable reduces the number of the used energies. For example,\ncompared to conventional IMPT, QC can reduce the number of energy layers from\n61 to 35 in HN case, from 56 to 35 in lung case, and from 59 to 32 to abdomen\ncase. The reduced number of energies also results in fewer delivery time, e.g.,\nthe delivery time is reduced from 100.6, 232.0, 185.3 seconds to 90.7, 215.4,\n154.0 seconds, respectively.","main_category":"physics.med-ph","categories":"physics.med-ph,math.OC","published":"2025-04-14T15:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.10323v1","title":"Rel: A Programming Language for Relational Data","summary":"From the moment of their inception, languages for relational data have been\ndescribed as sublanguages embedded in a host programming language. Rel is a new\nrelational language whose key design goal is to go beyond this paradigm with\nfeatures that allow for programming in the large, making it possible to fully\ndescribe end to end application semantics. With the new approach we can model\nthe semantics of entire enterprise applications relationally, which helps\nsignificantly reduce architecture complexity and avoid the well-known impedance\nmismatch problem. This paradigm shift is enabled by 50 years of database\nresearch, making it possible to revisit the sublanguage/host language paradigm,\nstarting from the fundamental principles. We present the main features of Rel:\nthose that give it the power to express traditional query language operations\nand those that are designed to grow the language and allow programming in the\nlarge.","main_category":"cs.DB","categories":"cs.DB,cs.PL","published":"2025-04-14T15:32:47Z"}
{"aid":"http://arxiv.org/abs/2504.10337v1","title":"Heimdall: test-time scaling on the generative verification","summary":"An AI system can create and maintain knowledge only to the extent that it can\nverify that knowledge itself. Recent work on long Chain-of-Thought reasoning\nhas demonstrated great potential of LLMs on solving competitive problems, but\ntheir verification ability remains to be weak and not sufficiently\ninvestigated. In this paper, we propose Heimdall, the long CoT verification LLM\nthat can accurately judge the correctness of solutions. With pure reinforcement\nlearning, we boost the verification accuracy from 62.5% to 94.5% on competitive\nmath problems. By scaling with repeated sampling, the accuracy further\nincreases to 97.5%. Through human evaluation, Heimdall demonstrates impressive\ngeneralization capabilities, successfully detecting most issues in challenging\nmath proofs, the type of which is not included during training. Furthermore, we\npropose Pessimistic Verification to extend the functionality of Heimdall to\nscaling up the problem solving. It calls Heimdall to judge the solutions from a\nsolver model and based on the pessimistic principle, selects the most likely\ncorrect solution with the least uncertainty. Taking\nDeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification\nimproves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute\nbudget and to 83.3% with more compute budget. With the stronger solver Gemini\n2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge\ndiscovery system, a ternary system where one poses questions, another provides\nsolutions, and the third verifies the solutions. Using the data synthesis work\nNuminaMath for the first two components, Heimdall effectively identifies\nproblematic records within the dataset and reveals that nearly half of the data\nis flawed, which interestingly aligns with the recent ablation studies from\nNuminaMath.","main_category":"cs.AI","categories":"cs.AI,I.2.7","published":"2025-04-14T15:46:33Z"}
{"aid":"http://arxiv.org/abs/2504.10344v1","title":"ALMTokenizer: A Low-bitrate and Semantic-rich Audio Codec Tokenizer for\n  Audio Language Modeling","summary":"Recent advancements in audio language models have underscored the pivotal\nrole of audio tokenization, which converts audio signals into discrete tokens,\nthereby facilitating the application of language model architectures to the\naudio domain. In this study, we introduce ALMTokenizer, a novel low-bitrate and\nsemantically rich audio codec tokenizer for audio language models. Prior\nmethods, such as Encodec, typically encode individual audio frames into\ndiscrete tokens without considering the use of context information across\nframes. Unlike these methods, we introduce a novel query-based compression\nstrategy to capture holistic information with a set of learnable query tokens\nby explicitly modeling the context information across frames. This design not\nonly enables the codec model to capture more semantic information but also\nencodes the audio signal with fewer token sequences. Additionally, to enhance\nthe semantic information in audio codec models, we introduce the following: (1)\nA masked autoencoder (MAE) loss, (2) Vector quantization based on semantic\npriors, and (3) An autoregressive (AR) prediction loss. As a result,\nALMTokenizer achieves competitive reconstruction performance relative to\nstate-of-the-art approaches while operating at a lower bitrate. Within the same\naudio language model framework, ALMTokenizer outperforms previous tokenizers in\naudio understanding and generation tasks.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-14T15:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10353v1","title":"Patch and Shuffle: A Preprocessing Technique for Texture Classification\n  in Autonomous Cementitious Fabrication","summary":"Autonomous fabrication systems are transforming construction and\nmanufacturing, yet they remain vulnerable to print errors. Texture\nclassification is a key component of computer vision systems that enable\nreal-time monitoring and adjustment during cementitious fabrication.\nTraditional classification methods often rely on global image features, which\ncan bias the model toward semantic content rather than low-level textures. In\nthis paper, we introduce a novel preprocessing technique called \"patch and\nshuffle,\" which segments input images into smaller patches, shuffles them, and\nreconstructs a jumbled image before classification. This transformation removes\nsemantic context, forcing the classifier to rely on local texture features.\n  We evaluate this approach on a dataset of extruded cement images, using a\nResNet-18-based architecture. Our experiments compare the patch and shuffle\nmethod to a standard pipeline, holding all other factors constant. Results show\na significant improvement in accuracy: the patch and shuffle model achieved\n90.64% test accuracy versus 72.46% for the baseline. These findings suggest\nthat disrupting global structure enhances performance in texture-based\nclassification tasks.\n  This method has implications for broader vision tasks where low-level\nfeatures matter more than high-level semantics. The technique may improve\nclassification in applications ranging from fabrication monitoring to medical\nimaging.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:03:21Z"}
{"aid":"http://arxiv.org/abs/2504.10355v1","title":"A geometric analysis of the Bazykin-Berezovskaya predator-prey model\n  with Allee effect in an economic framework","summary":"We study a fast-slow version of the Bazykin-Berezovskaya predator-prey model\nwith Allee effect evolving on two timescales, through the lenses of Geometric\nSingular Perturbation Theory (GSPT). The system we consider is in non-standard\nform. We completely characterize its dynamics, providing explicit threshold\nquantities to distinguish between a rich variety of possible asymptotic\nbehaviors. Moreover, we propose numerical results to illustrate our findings.\nLastly, we comment on the real-world interpretation of these results, in an\neconomic framework and in the context of predator-prey models.","main_category":"math.DS","categories":"math.DS,q-bio.PE","published":"2025-04-14T16:04:03Z"}
{"aid":"http://arxiv.org/abs/2504.10359v1","title":"DICE: A Framework for Dimensional and Contextual Evaluation of Language\n  Models","summary":"Language models (LMs) are increasingly being integrated into a wide range of\napplications, yet the modern evaluation paradigm does not sufficiently reflect\nhow they are actually being used. Current evaluations rely on benchmarks that\noften lack direct applicability to the real-world contexts in which LMs are\nbeing deployed. To address this gap, we propose Dimensional and Contextual\nEvaluation (DICE), an approach that evaluates LMs on granular,\ncontext-dependent dimensions. In this position paper, we begin by examining the\ninsufficiency of existing LM benchmarks, highlighting their limited\napplicability to real-world use cases. Next, we propose a set of granular\nevaluation parameters that capture dimensions of LM behavior that are more\nmeaningful to stakeholders across a variety of application domains.\nSpecifically, we introduce the concept of context-agnostic parameters - such as\nrobustness, coherence, and epistemic honesty - and context-specific parameters\nthat must be tailored to the specific contextual constraints and demands of\nstakeholders choosing to deploy LMs into a particular setting. We then discuss\npotential approaches to operationalize this evaluation framework, finishing\nwith the opportunities and challenges DICE presents to the LM evaluation\nlandscape. Ultimately, this work serves as a practical and approachable\nstarting point for context-specific and stakeholder-relevant evaluation of LMs.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-04-14T16:08:13Z"}
{"aid":"http://arxiv.org/abs/2504.10360v1","title":"Reactive power flow optimization in AC drive systems","summary":"This paper explores a limit avoidance approach in the case of input\n(modulation) and output (current) constraints with the aim of enhancing system\navailability of AC drives. Drawing on the observation that, in a certain range\nof reactive power, there exists a trade-off between current and modulation\nmagnitude, we exploit this freedom and define a constrained optimization\nproblem. We propose two approaches, one in the form of an activation-function\nwhich drives the reactive power set-point towards safety, and an approach which\nuses online feedback optimization to set the reactive power dynamically. Both\nmethods compromise reactive power tracking accuracy for increased system\nrobustness. Through a high fidelity simulation, we compare the benefits of the\ntwo methods, highlighting their effectiveness in industrial applications.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-14T16:08:32Z"}
{"aid":"http://arxiv.org/abs/2504.10369v1","title":"SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired\n  Symbolic Reasoning","summary":"Optimizing Register Transfer Level (RTL) code is crucial for improving the\npower, performance, and area (PPA) of digital circuits in the early stages of\nsynthesis. Manual rewriting, guided by synthesis feedback, can yield\nhigh-quality results but is time-consuming and error-prone. Most existing\ncompiler-based approaches have difficulty handling complex design constraints.\nLarge Language Model (LLM)-based methods have emerged as a promising\nalternative to address these challenges. However, LLM-based approaches often\nface difficulties in ensuring alignment between the generated code and the\nprovided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL\noptimization framework that seamlessly integrates LLM-based code rewriting with\nsymbolic reasoning techniques. Our method incorporates a retrieval-augmented\ngeneration (RAG) system of optimization rules and Abstract Syntax Tree\n(AST)-based templates, enabling LLM-based rewriting that maintains syntactic\ncorrectness while minimizing undesired circuit behaviors. A symbolic module is\nproposed for analyzing and optimizing finite state machine (FSM) logic,\nallowing fine-grained state merging and partial specification handling beyond\nthe scope of pattern-based compilers. Furthermore, a fast verification\npipeline, combining formal equivalence checks with test-driven validation,\nfurther reduces the complexity of verification. Experiments on the RTL-Rewriter\nbenchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves\npower, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%,\nrespectively, compared to the state-of-the-art methods.","main_category":"cs.AR","categories":"cs.AR,cs.AI,cs.LG,cs.PL","published":"2025-04-14T16:15:55Z"}
{"aid":"http://arxiv.org/abs/2504.10372v1","title":"Simple physical systems as a reference for multivariate information\n  dynamics","summary":"Understanding a complex system entails capturing the non-trivial collective\nphenomena that arise from interactions between its different parts. Information\ntheory is a flexible and robust framework to study such behaviours, with\nseveral measures designed to quantify and characterise the interdependencies\namong the system's components. However, since these estimators rely on the\nstatistical distributions of observed quantities, it is crucial to examine the\nrelationships between information-theoretic measures and the system's\nunderlying mechanistic structure. To this end, here we present an\ninformation-theoretic analytical investigation of an elementary system of\ninteractive random walkers subject to Gaussian noise. Focusing on partial\ninformation decomposition, causal emergence, and integrated information, our\nresults help us develop some intuitions on their relationship with the physical\nparameters of the system. For instance, we observe that uncoupled systems can\nexhibit emergent properties, in a way that we suggest may be better described\nas ''statistically autonomous''. Overall, we observe that in this simple\nscenario information measures align more reliably with the system's mechanistic\nproperties when calculated at the level of microscopic components, rather than\ntheir coarse-grained counterparts, and over timescales comparable with the\nsystem's intrinsic dynamics. Moreover, we show that approaches that separate\nthe contributions of the system's dynamics and steady-state distribution (e.g.\nvia causal perturbations) may help strengthen the interpretation of\ninformation-theoretic analyses.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T16:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.10381v1","title":"Abstract simplicial complexes in {\\tt Macaulay2}","summary":"{\\tt AbstractSimplicialComplexes.m2} is a computer algebra package written\nfor the computer algebra system {\\tt Macaulay2} \\cite{M2}. It provides new\ninfrastructure to work with abstract simplicial complexes and related\nhomological constructions. Its key novel feature is to implement each given\nabstract simplicial complex as a certain graded list in the form of a hash\ntable with integer keys. Among other features, this allows for a direct\nimplementation of the associated reduced and non-reduced simplicial chain\ncomplexes. Further, it facilitates construction of random simplicial complexes.\nThe approach that we employ here builds on the {\\tt Macaulay2} package {\\tt\nComplexes.m2} \\cite{Stillman:Smith:Complexes.m2}. It complements and is\nentirely different from the existing {\\tt Macaulay2} simplicial complexes\nframework that is made possible by the package {\\tt SimplicialComplexes.m2}\n\\cite{Smith:et:al:SimplicialComplexes.m2:jsag}.","main_category":"math.AG","categories":"math.AG,math.AC,math.AT,math.CO,math.KT","published":"2025-04-14T16:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10422v1","title":"Foundation models for electronic health records: representation dynamics\n  and transferability","summary":"Foundation models (FMs) trained on electronic health records (EHRs) have\nshown strong performance on a range of clinical prediction tasks. However,\nadapting these models to local health systems remains challenging due to\nlimited data availability and resource constraints. In this study, we\ninvestigated what these models learn and evaluated the transferability of an FM\ntrained on MIMIC-IV to an institutional EHR dataset at the University of\nChicago Medical Center. We assessed their ability to identify outlier patients\nand examined representation-space patient trajectories in relation to future\nclinical outcomes. We also evaluated the performance of supervised fine-tuned\nclassifiers on both source and target datasets. Our findings offer insights\ninto the adaptability of FMs across different healthcare systems, highlight\nconsiderations for their effective implementation, and provide an empirical\nanalysis of the underlying factors that contribute to their predictive\nperformance.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T17:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.10424v1","title":"Lowering the Cost of Diamond Open Access Journals","summary":"Many scholarly societies face challenges in adapting their publishing to an\nopen access model where neither authors nor readers pay any fees. Some have\nargued that one of the main barriers is the actual cost of publishing. The goal\nof this paper is to show that the actual costs can be extremely low while still\nmaintaining scholarly quality. We accomplish this by building a journal\npublishing workflow that minimizes the amount of required human labor. We\nrecently built a software system for this and launched a journal using the\nsystem, and we estimate estimate our cost to publish this journal is\napproximately \\$705 per year, plus \\$1 per article and about 10 minutes of\nvolunteer labor per article. We benefited from two factors, namely the fact\nthat authors in our discipline use LaTeX to prepare their manuscripts, and we\nhad volunteer labor to develop software and run the journal. We have made most\nof this software open source in the hopes that it can help others.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-14T17:13:45Z"}
{"aid":"http://arxiv.org/abs/2504.10441v1","title":"Position Uncertainty in a Prisoner's Dilemma Game : An Experiment","summary":"Gallice and Monzon (2019) present a natural environment that sustains full\ncooperation in one-shot social dilemmas among a finite number of\nself-interested agents. They demonstrate that in a sequential public goods\ngame, where agents lack knowledge of their position in the sequence but can\nobserve some predecessors' actions, full contribution emerges in equilibrium\ndue to agents' incentive to induce potential successors to follow suit.\nFurthermore, they show that this principle extends to a number of social\ndilemmas, with the prominent example that of the prisoner's dilemma. In this\nstudy, we experimentally test the theoretical predictions of this model in a\nmulti- player prisoner's dilemma environment, where subjects are not aware of\ntheir position in the sequence and receive only partial information on past\ncooperating actions. We test the predictions of the model, and through rigorous\nstructural econometric analysis, we test the descriptive capacity of the model\nagainst alternative behavioural strategies, such as conditional cooperation,\naltruistic play and free-riding behaviour. We find that the majority resorts to\nfree-riding behaviour, around 30% is classified as Gallice and Monzon (2019)\ntypes, followed by those with social preference considerations and the\nunconditional altruists.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-14T17:32:07Z"}
{"aid":"http://arxiv.org/abs/2504.10452v1","title":"Integrating Vision and Location with Transformers: A Multimodal Deep\n  Learning Framework for Medical Wound Analysis","summary":"Effective recognition of acute and difficult-to-heal wounds is a necessary\nstep in wound diagnosis. An efficient classification model can help wound\nspecialists classify wound types with less financial and time costs and also\nhelp in deciding on the optimal treatment method. Traditional machine learning\nmodels suffer from feature selection and are usually cumbersome models for\naccurate recognition. Recently, deep learning (DL) has emerged as a powerful\ntool in wound diagnosis. Although DL seems promising for wound type\nrecognition, there is still a large scope for improving the efficiency and\naccuracy of the model. In this study, a DL-based multimodal classifier was\ndeveloped using wound images and their corresponding locations to classify them\ninto multiple classes, including diabetic, pressure, surgical, and venous\nulcers. A body map was also created to provide location data, which can help\nwound specialists label wound locations more effectively. The model uses a\nVision Transformer to extract hierarchical features from input images, a\nDiscrete Wavelet Transform (DWT) layer to capture low and high frequency\ncomponents, and a Transformer to extract spatial features. The number of\nneurons and weight vector optimization were performed using three swarm-based\noptimization techniques (Monster Gorilla Toner (MGTO), Improved Gray Wolf\nOptimization (IGWO), and Fox Optimization Algorithm). The evaluation results\nshow that weight vector optimization using optimization algorithms can increase\ndiagnostic accuracy and make it a very effective approach for wound detection.\nIn the classification using the original body map, the proposed model was able\nto achieve an accuracy of 0.8123 using image data and an accuracy of 0.8007\nusing a combination of image data and wound location. Also, the accuracy of the\nmodel in combination with the optimization models varied from 0.7801 to 0.8342.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:39:18Z"}
{"aid":"http://arxiv.org/abs/2504.10465v1","title":"Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding","summary":"Multimodal Large Language Models (MLLMs) achieve remarkable performance for\nfine-grained pixel-level understanding tasks. However, all the works rely\nheavily on extra components, such as vision encoder (CLIP), segmentation\nexperts, leading to high system complexity and limiting model scaling. In this\nwork, our goal is to explore a highly simplified MLLM without introducing extra\ncomponents. Our work is motivated by the recent works on Single trAnsformer as\na unified vIsion-Language Model (SAIL) design, where these works jointly learn\nvision tokens and text tokens in transformers. We present Pixel-SAIL, a single\ntransformer for pixel-wise MLLM tasks. In particular, we present three\ntechnical improvements on the plain baseline. First, we design a learnable\nupsampling module to refine visual token features. Secondly, we propose a novel\nvisual prompt injection strategy to enable the single transformer to understand\nvisual prompt inputs and benefit from the early fusion of visual prompt\nembeddings and vision tokens. Thirdly, we introduce a vision expert\ndistillation strategy to efficiently enhance the single transformer's\nfine-grained feature extraction capability. In addition, we have collected a\ncomprehensive pixel understanding benchmark (PerBench), using a manual check.\nIt includes three tasks: detailed object description, visual prompt-based\nquestion answering, and visual-text referring segmentation. Extensive\nexperiments on four referring segmentation benchmarks, one visual prompt\nbenchmark, and our PerBench show that our Pixel-SAIL achieves comparable or\neven better results with a much simpler pipeline. Code and model will be\nreleased at https://github.com/magic-research/Sa2VA.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.10480v1","title":"Probing Long-Range Forces in Neutrino Oscillations at the ESSnuSB\n  Experiment","summary":"Neutrino oscillations constitute an excellent tool to probe physics beyond\nthe Standard Model. In this paper, we investigate the potential of the \\ess\nexperiment to constrain the effects of flavour-dependent long-range forces\n(LRFs) in neutrino oscillations, which may arise due to the extension of the\nStandard Model gauge group by introducing new $U(1)$ symmetries. Focusing on\nthree specific $U(1)$ symmetries -- $L_e - L_\\mu$, $L_e - L_\\tau$, and $L_\\mu -\nL_\\tau$, we demonstrate that \\ess offers a favourable environment to search for\nLRF effects. Our analyses reveal that \\ess can set 90\\% confidence level bounds\nof $V_{e\\mu} < 2.99 \\times 10^{-14} \\, \\text{eV}$, $V_{e\\tau} < 2.05 \\times\n10^{-14} \\, \\text{eV}$, and $V_{\\mu\\tau} < 1.81 \\times 10^{-14} \\, \\text{eV}$,\nwhich are competitive to the upcoming Deep Underground Neutrino Experiment\n(DUNE). It is also observed that reducing the systematic uncertainties from\n$5\\%$ to $2\\%$ improves the \\ess limits on $V_{\\alpha\\beta}$. Interestingly, we\nfind limited correlations between LRF parameters and the less constrained\nlepton mixing parameters $\\theta_{23}$ and $\\delta_{\\text{CP}}$, preserving the\nrobustness of ESSnuSB's sensitivity to CP violation. Even under extreme LRF\npotentials ($V_{\\alpha\\beta} \\gg 10^{-13} \\, \\text{eV}$), the CP-violation\nsensitivity and $\\delta_{\\text{CP}}$ precision remain largely unaffected. These\nresults establish ESSnuSB as a competitive experimental setup for probing LRF\neffects, complementing constraints from other neutrino sources and offering\ncritical insights into the physics of long-range forces.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-14T17:59:25Z"}
