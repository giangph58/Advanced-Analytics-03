{"aid":"http://arxiv.org/abs/2503.21661v1","title":"From conceptualization to operationalized meaning via ontological\n  components","summary":"Ontologies enable knowledge sharing and interdisciplinary collaboration by\nproviding standardized, structured vocabularies for diverse communities. While\nlogical axioms are a cornerstone of ontology design, natural language elements\nsuch as annotations are equally critical for conveying intended meaning and\nensuring consistent term usage. This paper explores how meaning is represented\nin ontologies and how it can be effectively represented and communicated,\naddressing challenges such as indeterminacy of reference and meaning holism. To\nthis end, it proposes an approach founded on the use of a new structure, named\n'ontological component' and defined by: a term-centered design; enhanced\ncharacterization of both formal and natural language statements; an\noperationalizable definition of communicated meaning based on general\nassertions; and the integration of natural language elements into the logical\ntheory. By formalizing the meaning of ontological components, this work seeks\nto enhance the semantic robustness of terms, improving their clarity and\naccessibility across domains. Furthermore, it aims to address practical\nchallenges in applied ontologies, such as facilitating reuse and managing\nversioning, thereby strengthening their role in diverse applications.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-03-27T16:24:12Z"}
{"aid":"http://arxiv.org/abs/2503.21666v1","title":"Economy and sustainability analysis with a novel modular configurable\n  multi-modal white-box building model","summary":"This paper presents a novel modeling approach for building performance\nsimulation, characterized as a white-box model with a high degree of modularity\nand flexibility, enabling direct integration into complex large-scale energy\nsystem co-simulations. The introduced model is described in detail, with a\nfocus on its modular structure, and proposes various configurations that\ninclude various building insulation, heating methods, occupancy patterns, and\nweather data to analyze different scenarios, and the energy consumption, CO2\nemissions, and heating costs are compared and analyzed across 36 introduced\nscenarios. The thermodynamic behavior of the model is shown to be consistent\nwith real-world conditions, and the comparison of the scenarios concludes that\nthe use of heat pumps for indoor heating in well-insulated buildings has\nsignificant economic and sustainability benefits, whereas the use of natural\ngas-fueled boilers is more cost-effective for buildings with low energy\nratings.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-27T16:33:31Z"}
{"aid":"http://arxiv.org/abs/2503.21700v1","title":"Normalized solutions of one-dimensional defocusing NLS equations with\n  nonlinear point interactions","summary":"We investigate normalized solutions for doubly nonlinear Schr\\\"odinger\nequations on the real line with a defocusing standard nonlinearity and a\nfocusing nonlinear point interaction of $\\delta$--type at the origin. We\nprovide a complete characterization of existence and uniqueness for normalized\nsolutions and for energy ground states for every value of the nonlinearity\npowers. We show that the interplay between a defocusing standard and a focusing\npoint nonlinearity gives rise to new phenomena with respect to those observed\nwith single nonlinearities, standard combined nonlinearities, and combined\nfocusing standard and pointwise nonlinearities.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-03-27T17:04:43Z"}
{"aid":"http://arxiv.org/abs/2503.21704v1","title":"Learning to Represent Individual Differences for Choice Decision Making","summary":"Human decision making can be challenging to predict because decisions are\naffected by a number of complex factors. Adding to this complexity,\ndecision-making processes can differ considerably between individuals, and\nmethods aimed at predicting human decisions need to take individual differences\ninto account. Behavioral science offers methods by which to measure individual\ndifferences (e.g., questionnaires, behavioral models), but these are often\nnarrowed down to low dimensions and not tailored to specific prediction tasks.\nThis paper investigates the use of representation learning to measure\nindividual differences from behavioral experiment data. Representation learning\noffers a flexible approach to create individual embeddings from data that are\nboth structured (e.g., demographic information) and unstructured (e.g., free\ntext), where the flexibility provides more options for individual difference\nmeasures for personalization, e.g., free text responses may allow for\nopen-ended questions that are less privacy-sensitive. In the current paper we\nuse representation learning to characterize individual differences in human\nperformance on an economic decision-making task. We demonstrate that models\nusing representation learning to capture individual differences consistently\nimprove decision predictions over models without representation learning, and\neven outperform well-known theory-based behavioral models used in these\nenvironments. Our results propose that representation learning offers a useful\nand flexible tool to capture individual differences.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-03-27T17:10:05Z"}
{"aid":"http://arxiv.org/abs/2503.21707v1","title":"Heterostructure Effects on the Magnetocrystalline Anisotropy Energy of\n  MnN","summary":"Thin film effects on the Magnetocrystalline Anisotropy Energy (MAE) of MnN\nwere studied using density functional theory (DFT). Initially, strain effects\non bulk MnN were considered as a proxy for lattice-matching induced strain and\na linear relationship between the c/a ratio and the MAE was found. This\nrelationship was explained in terms of underlying point group symmetry. Strain\nand charge-transfer effects were then considered for an ultra-thin film. It was\nfound that a Ta seed-layer suppresses the net spin moment on the Mn ions,\nleading to a reduction of the MAE.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-27T17:20:42Z"}
{"aid":"http://arxiv.org/abs/2503.21709v1","title":"Redefining Network Topology in Complex Systems: Merging Centrality\n  Metrics, Spectral Theory, and Diffusion Dynamics","summary":"This paper introduces a novel framework that combines traditional centrality\nmeasures with eigenvalue spectra and diffusion processes for a more\ncomprehensive analysis of complex networks. While centrality measures such as\ndegree, closeness, and betweenness have been commonly used to assess nodal\nimportance, they provide limited insight into dynamic network behaviors. By\nincorporating eigenvalue analysis, which evaluates network robustness and\nconnectivity through spectral properties, and diffusion processes that model\ninformation flow, this framework offers a deeper understanding of how networks\nfunction under dynamic conditions. Applied to synthetic networks, the approach\nidentifies key nodes not only by centrality but also by their role in diffusion\ndynamics and vulnerability points, offering a multi-dimensional view that\ntraditional methods alone cannot. This integrated analysis enables a more\nprecise identification of critical nodes and potential weaknesses, with\nimplications for improving network resilience in fields ranging from\nepidemiology to cybersecurity. Keywords: Centrality measures, eigenvalue\nspectra, diffusion processes, network analysis, network robustness, information\nflow, synthetic networks.","main_category":"cs.OH","categories":"cs.OH","published":"2025-03-27T17:21:46Z"}
{"aid":"http://arxiv.org/abs/2503.21721v1","title":"Evaluating Text-to-Image Synthesis with a Conditional Fr√©chet\n  Distance","summary":"Evaluating text-to-image synthesis is challenging due to misalignment between\nestablished metrics and human preferences. We propose cFreD, a metric based on\nthe notion of Conditional Fr\\'echet Distance that explicitly accounts for both\nvisual fidelity and text-prompt alignment. Existing metrics such as Inception\nScore (IS), Fr\\'echet Inception Distance (FID) and CLIPScore assess either\nimage quality or image-text alignment but not both which limits their\ncorrelation with human preferences. Scoring models explicitly trained to\nreplicate human preferences require constant updates and may not generalize to\nnovel generation techniques or out-of-domain inputs. Through extensive\nexperiments across multiple recently proposed text-to-image models and diverse\nprompt datasets, we demonstrate that cFreD exhibits a higher correlation with\nhuman judgments compared to statistical metrics, including metrics trained with\nhuman preferences. Our findings validate cFreD as a robust, future-proof metric\nfor the systematic evaluation of text-to-image models, standardizing\nbenchmarking in this rapidly evolving field. We release our evaluation toolkit\nand benchmark in the appendix.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:35:14Z"}
{"aid":"http://arxiv.org/abs/2503.21753v1","title":"Quantum enhanced parameter estimation with monitored quantum\n  nonequilibrium systems using inefficient photo detection","summary":"Many-body quantum systems hosting emergent collective behavior bear the\npromise to enable quantum enhanced parameter estimation. Formally this means\nthat the variance of the parameter to be estimated decreases faster than\n$N^{-1}$, where $N$ is the number of particles forming the quantum system. In\npractice such scaling is challenging to achieve as the underlying many-body\ncorrelations are fragile. Moreover, devising the optimal measurements that\nindeed tap the quantum enhancement is often rather involved. Here we show that\nthe inefficient detection of the photo emission from a dissipative quantum\nmany-body system is sufficient to reach quantum enhanced parameter estimation\neven when some loss channels remain completely unmonitored. We illustrate our\napproach by considering the so-called boundary time-crystal, which is a\nnonequilibrium many-body system that has been realized recently experimentally\nin cold atomic gases. By analyzing the structure of the temporal correlations\nof its emission field, we are able to construct a family of near optimal\nparameter estimation measurements with a simple interferometric setup.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-27T17:56:57Z"}
{"aid":"http://arxiv.org/abs/2503.21755v1","title":"VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic\n  Faithfulness","summary":"Video generation has advanced significantly, evolving from producing\nunrealistic outputs to generating videos that appear visually convincing and\ntemporally coherent. To evaluate these video generative models, benchmarks such\nas VBench have been developed to assess their faithfulness, measuring factors\nlike per-frame aesthetics, temporal consistency, and basic prompt adherence.\nHowever, these aspects mainly represent superficial faithfulness, which focus\non whether the video appears visually convincing rather than whether it adheres\nto real-world principles. While recent models perform increasingly well on\nthese metrics, they still struggle to generate videos that are not just\nvisually plausible but fundamentally realistic. To achieve real \"world models\"\nthrough video generation, the next frontier lies in intrinsic faithfulness to\nensure that generated videos adhere to physical laws, commonsense reasoning,\nanatomical correctness, and compositional integrity. Achieving this level of\nrealism is essential for applications such as AI-assisted filmmaking and\nsimulated world modeling. To bridge this gap, we introduce VBench-2.0, a\nnext-generation benchmark designed to automatically evaluate video generative\nmodels for their intrinsic faithfulness. VBench-2.0 assesses five key\ndimensions: Human Fidelity, Controllability, Creativity, Physics, and\nCommonsense, each further broken down into fine-grained capabilities. Tailored\nfor individual dimensions, our evaluation framework integrates generalists such\nas state-of-the-art VLMs and LLMs, and specialists, including anomaly detection\nmethods proposed for video generation. We conduct extensive annotations to\nensure alignment with human judgment. By pushing beyond superficial\nfaithfulness toward intrinsic faithfulness, VBench-2.0 aims to set a new\nstandard for the next generation of video generative models in pursuit of\nintrinsic faithfulness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:57:01Z"}
{"aid":"http://arxiv.org/abs/2503.21763v1","title":"Identification and estimation of treatment effects in a linear factor\n  model with fixed number of time periods","summary":"This paper provides a new approach for identifying and estimating the Average\nTreatment Effect on the Treated under a linear factor model that allows for\nmultiple time-varying unobservables. Unlike the majority of the literature on\ntreatment effects in linear factor models, our approach does not require the\nnumber of pre-treatment periods to go to infinity to obtain a valid estimator.\nOur identification approach employs a certain nonlinear transformations of the\ntime invariant observed covariates that are sufficiently correlated with the\nunobserved variables. This relevance condition can be checked with the\navailable data on pre-treatment periods by validating the correlation of the\ntransformed covariates and the pre-treatment outcomes. Based on our\nidentification approach, we provide an asymptotically unbiased estimator of the\neffect of participating in the treatment when there is only one treated unit\nand the number of control units is large.","main_category":"econ.EM","categories":"econ.EM","published":"2025-03-27T17:58:17Z"}
{"aid":"http://arxiv.org/abs/2503.21771v1","title":"A Unified Image-Dense Annotation Generation Model for Underwater Scenes","summary":"Underwater dense prediction, especially depth estimation and semantic\nsegmentation, is crucial for gaining a comprehensive understanding of\nunderwater scenes. Nevertheless, high-quality and large-scale underwater\ndatasets with dense annotations remain scarce because of the complex\nenvironment and the exorbitant data collection costs. This paper proposes a\nunified Text-to-Image and DEnse annotation generation method (TIDE) for\nunderwater scenes. It relies solely on text as input to simultaneously generate\nrealistic underwater images and multiple highly consistent dense annotations.\nSpecifically, we unify the generation of text-to-image and text-to-dense\nannotations within a single model. The Implicit Layout Sharing mechanism (ILS)\nand cross-modal interaction method called Time Adaptive Normalization (TAN) are\nintroduced to jointly optimize the consistency between image and dense\nannotations. We synthesize a large-scale underwater dataset using TIDE to\nvalidate the effectiveness of our method in underwater dense prediction tasks.\nThe results demonstrate that our method effectively improves the performance of\nexisting underwater dense prediction models and mitigates the scarcity of\nunderwater data with dense annotations. We hope our method can offer new\nperspectives on alleviating data scarcity issues in other fields. The code is\navailable at https: //github.com/HongkLin/TIDE.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:43Z"}
{"aid":"http://arxiv.org/abs/2503.21773v1","title":"Simulating quantum circuits with restricted quantum computers","summary":"It is one of the most fundamental objectives in quantum information science\nto understand the boundary between the computational power of classical and\nquantum computers. One possible avenue to explore this boundary is to identify\nclasses of quantum circuits that can be efficiently simulated on a classical\ncomputer. Instead of simulating a general quantum circuit with a classical\ndevice, new schemes have recently emerged to simulate them on a quantum device\nthat is restricted in some manner. As such, these techniques allow us to study\nhow the restrictions impact the computational power of the device. One such\ntechnique is called quasiprobability simulation (QPS) and it estimates the\nresult of a quantum circuit with a Monte Carlo procedure that randomly replaces\ncircuit elements with ones that can be executed on the restricted quantum\ndevice.\n  The main focus of this thesis is dedicated to the QPS-based simulation of\nnonlocal quantum computation using local quantum operations. On the practical\nside, this enables the simulation of large quantum circuits using multiple\nsmaller quantum devices - a procedure that is sometimes called circuit\nknitting. We uncover a rich mathematical formalism with many connections to the\nresource theory of entanglement. We characterize the optimal simulation\noverhead for a broad range of practically relevant nonlocal states and channels\nand we explicitly provide achieving protocols. Moreover, we also investigate\nthe utility of classical communication between the local parties. Our results\naddress both the single-shot and asymptotic regime.\n  We frame QPS in a quantum resource theoretic framework, which highlights\nsimilarities that arise in the different instantiations of the technique.\nFurthermore, we study the importance of classical side information in the QPS\nprocedure and how it impacts the overhead and expressibility of QPS.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-27T17:59:45Z"}
{"aid":"http://arxiv.org/abs/2503.21775v1","title":"StyleMotif: Multi-Modal Motion Stylization using Style-Content Cross\n  Fusion","summary":"We present StyleMotif, a novel Stylized Motion Latent Diffusion model,\ngenerating motion conditioned on both content and style from multiple\nmodalities. Unlike existing approaches that either focus on generating diverse\nmotion content or transferring style from sequences, StyleMotif seamlessly\nsynthesizes motion across a wide range of content while incorporating stylistic\ncues from multi-modal inputs, including motion, text, image, video, and audio.\nTo achieve this, we introduce a style-content cross fusion mechanism and align\na style encoder with a pre-trained multi-modal model, ensuring that the\ngenerated motion accurately captures the reference style while preserving\nrealism. Extensive experiments demonstrate that our framework surpasses\nexisting methods in stylized motion generation and exhibits emergent\ncapabilities for multi-modal motion stylization, enabling more nuanced motion\nsynthesis. Source code and pre-trained models will be released upon acceptance.\nProject Page: https://stylemotif.github.io","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-03-27T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2503.21776v1","title":"Video-R1: Reinforcing Video Reasoning in MLLMs","summary":"Inspired by DeepSeek-R1's success in eliciting reasoning abilities through\nrule-based reinforcement learning (RL), we introduce Video-R1 as the first\nattempt to systematically explore the R1 paradigm for eliciting video reasoning\nwithin multimodal large language models (MLLMs). However, directly applying RL\ntraining with the GRPO algorithm to video reasoning presents two primary\nchallenges: (i) a lack of temporal modeling for video reasoning, and (ii) the\nscarcity of high-quality video-reasoning data. To address these issues, we\nfirst propose the T-GRPO algorithm, which encourages models to utilize temporal\ninformation in videos for reasoning. Additionally, instead of relying solely on\nvideo data, we incorporate high-quality image-reasoning data into the training\nprocess. We have constructed two datasets: Video-R1-COT-165k for SFT cold start\nand Video-R1-260k for RL training, both comprising image and video data.\nExperimental results demonstrate that Video-R1 achieves significant\nimprovements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as\nwell as on general video benchmarks including MVBench and TempCompass, etc.\nNotably, Video-R1-7B attains a 35.8% accuracy on video spatial reasoning\nbenchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All\ncodes, models, data are released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.23710v1","title":"Formation of the Little Red Dots from the Core-collapse of\n  Self-interacting Dark Matter Halos","summary":"We present a statistical study on the formation and growth of black holes\n(BHs) seeded by gravothermal core-collapse of self-interacting dark matter\n(SIDM) halos at high redshifts, using a semi-analytical framework based on\nMonte-Carlo merger trees. We demonstrate that BH formation via gravothermal\ncollapse naturally occurs in high-concentration halos at a characteristic mass\nscale determined by the SIDM cross section, and only during the early Universe.\nThis mechanism is particularly promising for explaining the abundance of little\nred dots (LRDs) -- a population of early, apparently galaxy-less active\ngalactic nuclei hosting supermassive BHs. By incorporating this seeding process\nwith simplified models of BH growth and mergers, we successfully reproduce the\nobserved LRD mass function for moderately large cross sections of $\\sigma_{0m}\n\\sim 30 \\mathrm{cm^2\\,g^{-1}}$ and $\\omega \\sim 80\\,\\mathrm{km\\,s^{-1}}$,\nintriguingly consistent with independent local constraints derived from galaxy\nrotation curves. Our results highlight the potential of high-redshift BH\nstatistics as a complementary probe for constraining SIDM models.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-03-31T04:15:20Z"}
{"aid":"http://arxiv.org/abs/2503.23728v1","title":"Performing Path Integral Molecular Dynamics Using Artificial\n  Intelligence Enhanced Molecular Simulation Framework","summary":"This study employed an artificial intelligence-enhanced molecular simulation\nframework to enable efficient Path Integral Molecular Dynamics (PIMD)\nsimulations. Owing to its modular architecture and high-throughput\ncapabilities, the framework effectively mitigates the computational complexity\nand resource-intensive limitations associated with conventional PIMD\napproaches. By integrating machine learning force fields (MLFFs) into the\nframework, we rigorously tested its performance through two representative\ncases: a small-molecule reaction system (double proton transfer in formic acid\ndimer) and a bulk-phase transition system (water-ice phase transformation).\nComputational results demonstrate that the proposed framework achieves\naccelerated PIMD simulations while preserving quantum mechanical accuracy.\nThese findings show that nuclear quantum effects can be captured for complex\nmolecular systems, using relatively low computational cost.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.comp-ph","published":"2025-03-31T05:01:56Z"}
{"aid":"http://arxiv.org/abs/2503.23741v1","title":"Classification of Modular Symmetries in Non-Supersymmetric Heterotic\n  String theories","summary":"We study modular symmetries in non-supersymmetric heterotic string theories\non toroidal backgrounds with Wilson line modulus, constructed by stringy\nScherk-Schwartz compactification. In particular, we focus on a subgroup of the\nT-duality group $O(D+16,D,\\mathbb{Z})$ with $D=2$ given by an outer\nautomorphism of the Narain lattice, which can be mapped to the Siegel modular\ngroup $\\mathrm{Sp}(4,\\mathbb{Z})$. We classify the modular symmetries and a\n$CP$-like symmetry on $T^2$ and its orbifolds with symmetric and asymmetric\norbifold twists. It turns out that the non-supersymmetric heterotic string\ntheories only enjoy a part of modular symmetries in contrast to supersymmetric\nones. Furthermore, the gauge symmetry is maximally enhanced at fixed points of\nmodular symmetries on $T^2$ on which we analyze the vacuum structure of\neight-dimensional tachyon-free vacua.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T05:42:06Z"}
{"aid":"http://arxiv.org/abs/2503.23751v1","title":"Decoupled Distillation to Erase: A General Unlearning Method for Any\n  Class-centric Tasks","summary":"In this work, we present DEcoupLEd Distillation To Erase (DELETE), a general\nand strong unlearning method for any class-centric tasks. To derive this, we\nfirst propose a theoretical framework to analyze the general form of unlearning\nloss and decompose it into forgetting and retention terms. Through the\ntheoretical framework, we point out that a class of previous methods could be\nmainly formulated as a loss that implicitly optimizes the forgetting term while\nlacking supervision for the retention term, disturbing the distribution of\npre-trained model and struggling to adequately preserve knowledge of the\nremaining classes. To address it, we refine the retention term using \"dark\nknowledge\" and propose a mask distillation unlearning method. By applying a\nmask to separate forgetting logits from retention logits, our approach\noptimizes both the forgetting and refined retention components simultaneously,\nretaining knowledge of the remaining classes while ensuring thorough forgetting\nof the target class. Without access to the remaining data or intervention\n(i.e., used in some works), we achieve state-of-the-art performance across\nvarious benchmarks. What's more, DELETE is a general solution that can be\napplied to various downstream tasks, including face recognition, backdoor\ndefense, and semantic segmentation with great performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T06:02:27Z"}
{"aid":"http://arxiv.org/abs/2503.23753v1","title":"Reputation in public goods cooperation under double Q-learning protocol","summary":"Understanding and resolving cooperation dilemmas are key challenges in\nevolutionary game theory, which have revealed several mechanisms to address\nthem. This paper investigates the comprehensive influence of multiple\nreputation-related components on public cooperation. In particular, cooperative\ninvestments in public goods game are not fixed but simultaneously depend on the\nreputation of group organizers and the population's cooperation willingness,\nhence indirectly impacting on the players' income. Additionally, individual\npayoff can also be directly affected by their reputation via a weighted\napproach which effectively evaluates the actual income of players. Unlike\nconventional models, the reputation change of players is non-monotonic, but may\ntransform abruptly due to specific actions. Importantly, a theoretically\nsupported double Q-learning algorithm is introduced to avoid overestimation\nbias inherent from the classical Q-learning algorithm. Our simulations reveal a\nsignificantly improved cooperation level, that is explained by a detailed\nQ-value analysis. We also observe the lack of massive cooperative clusters in\nthe absence of network reciprocity. At the same time, as an intriguing\nphenomenon, some actors maintain moderate reputation and are continuously\nflipping between cooperation and defection. The robustness of our results are\nvalidated by mean-field approximation.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-03-31T06:03:26Z"}
{"aid":"http://arxiv.org/abs/2503.23775v1","title":"Evaluation of (Un-)Supervised Machine Learning Methods for GNSS\n  Interference Classification with Real-World Data Discrepancies","summary":"The accuracy and reliability of vehicle localization on roads are crucial for\napplications such as self-driving cars, toll systems, and digital tachographs.\nTo achieve accurate positioning, vehicles typically use global navigation\nsatellite system (GNSS) receivers to validate their absolute positions.\nHowever, GNSS-based positioning can be compromised by interference signals,\nnecessitating the identification, classification, determination of purpose, and\nlocalization of such interference to mitigate or eliminate it. Recent\napproaches based on machine learning (ML) have shown superior performance in\nmonitoring interference. However, their feasibility in real-world applications\nand environments has yet to be assessed. Effective implementation of ML\ntechniques requires training datasets that incorporate realistic interference\nsignals, including real-world noise and potential multipath effects that may\noccur between transmitter, receiver, and satellite in the operational area.\nAdditionally, these datasets require reference labels. Creating such datasets\nis often challenging due to legal restrictions, as causing interference to GNSS\nsources is strictly prohibited. Consequently, the performance of ML-based\nmethods in practical applications remains unclear. To address this gap, we\ndescribe a series of large-scale measurement campaigns conducted in real-world\nsettings at two highway locations in Germany and the Seetal Alps in Austria,\nand in large-scale controlled indoor environments. We evaluate the latest\nsupervised ML-based methods to report on their performance in real-world\nsettings and present the applicability of pseudo-labeling for unsupervised\nlearning. We demonstrate the challenges of combining datasets due to data\ndiscrepancies and evaluate outlier detection, domain adaptation, and data\naugmentation techniques to present the models' capabilities to adapt to changes\nin the datasets.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-03-31T06:51:52Z"}
{"aid":"http://arxiv.org/abs/2503.23818v1","title":"Free Parametrization of L2-bounded State Space Models","summary":"Structured state-space models (SSMs) have emerged as a powerful architecture\nin machine learning and control, featuring stacked layers where each consists\nof a linear time-invariant (LTI) discrete-time system followed by a\nnonlinearity. While SSMs offer computational efficiency and excel in\nlong-sequence predictions, their widespread adoption in applications like\nsystem identification and optimal control is hindered by the challenge of\nensuring their stability and robustness properties. We introduce L2RU, a novel\nparametrization of SSMs that guarantees input-output stability and robustness\nby enforcing a prescribed L-bound for all parameter values. This design\neliminates the need for complex constraints, allowing unconstrained\noptimization over L2RUs by using standard methods such as gradient descent.\nLeveraging tools from system theory and convex optimization, we derive a\nnon-conservative parametrization of square discrete-time LTI systems with a\nspecified L2-bound, forming the foundation of the L2RU architecture.\nAdditionally, we enhance its performance with a bespoke initialization strategy\noptimized for long input sequences. Through a system identification task, we\nvalidate L2RU's superior performance, showcasing its potential in learning and\ncontrol applications.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-03-31T07:56:17Z"}
{"aid":"http://arxiv.org/abs/2503.23838v1","title":"A MeerKAT survey of nearby dwarf novae: I. New detections","summary":"A program to search for radio emission from dwarf-novae-type cataclysmic\nvariables was conducted with the South African MeerKAT radio telescope. The\ndwarf novae RU Pegasi, V426 Ophiuchi and IP Pegasi were detected during\noutburst at L-band (1284 MHz central frequency). Previously, only one\ncataclysmic variable was radio-detected at a frequency this low. We now bring\nthe number to four. With these three newly found radio-emitters, the population\nof dwarf novae confirmed to be radio-emitting at any frequency reaches 10\nsystems. We found that the radio luminosity is correlated with the optical\nluminosity. For V426 Ophiuchi and RU Pegasi we found a radio decline\ncontemporary with the outburst's optical decline. The peak radio luminosity of\ndwarf novae in outburst is very similar to that of novalike Cataclysmic\nVariables and no correlation with orbital period is seen.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T08:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.23845v1","title":"On the depth of subgroups of simple groups","summary":"The depth of a subgroup $H$ of a finite group $G$ is a positive integer\ndefined with respect to the inclusion of the corresponding complex group\nalgebras $\\mathbb{C}H \\subseteq \\mathbb{C}G$. This notion was originally\nintroduced by Boltje, Danz and K\\\"{u}lshammer in 2011, and it has been the\nsubject of numerous papers in recent years. In this paper, we study the depth\nof core-free subgroups, which allows us to apply powerful computational and\nprobabilistic techniques that were originally designed for studying bases for\npermutation groups. We use these methods to prove a wide range of new results\non the depth of subgroups of almost simple groups, significantly extending the\nscope of earlier work in this direction. For example, we establish best\npossible bounds on the depth of irreducible subgroups of classical groups and\nprimitive subgroups of symmetric groups. And with the exception of a handful of\nopen cases involving the Baby Monster, we calculate the exact depth of every\nsubgroup of every almost simple sporadic group. We also present a number of\nopen problems and conjectures.","main_category":"math.GR","categories":"math.GR,math.RT","published":"2025-03-31T08:46:46Z"}
{"aid":"http://arxiv.org/abs/2503.23846v1","title":"Exchange cross-talk mitigation in dense quantum dot arrays","summary":"Coupled spins in semiconductor quantum dots are a versatile platform for\nquantum computing and simulations of complex many-body phenomena. However, on\nthe path of scale-up, cross-talk from densely packed electrodes poses a severe\nchallenge. While cross-talk onto the dot potentials is nowadays routinely\ncompensated for, cross-talk on the exchange interaction is much more difficult\nto tackle because it is not always directly measurable. Here we propose and\nimplement a way of characterizing and compensating cross-talk on adjacent\nexchange interactions by following the singlet-triplet avoided crossing in Ge.\nWe show that we can easily identify the barrier-to-barrier cross-talk element\nwithout knowledge of the particular exchange value in a 2x4 quantum dot array.\nWe uncover striking differences among these cross-talk elements which can be\nlinked to the geometry of the device and the barrier gate fan-out. We validate\nthe methodology by tuning up four-spin Heisenberg chains. The same methodology\nshould be applicable to longer chains of spins and to other semiconductor\nplatforms in which mixing of the singlet and the lowest-energy triplet is\npresent or can be engineered. Additionally, this procedure is well suited for\nautomated tuning routines as we obtain a stand-out feature that can be easily\ntracked and directly returns the magnitude of the cross-talk.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T08:50:43Z"}
{"aid":"http://arxiv.org/abs/2503.23852v1","title":"Multispacecraft Observations of the 2024 September 9 Backside Solar\n  Eruption that Resulted in a Sustained Gamma Ray Emission Event","summary":"We report on the 2024 September 9 sustained gamma ray emission (SGRE) event\nobserved by the Large Area Telescope onboard the Fermi satellite. The event was\nassociated with a backside solar eruption observed by multiple spacecraft such\nas the Solar and Heliospheric Observatory (SOHO), Solar Terrestrial Relations\nObservatory (STEREO), Parker Solar Probe (PSP), Solar Orbiter (SolO), Solar\nDynamics Observatory (SDO), Wind, and GOES, and by ground based radio\ntelescopes. SolO Spectrometer Telescope for Imaging X rays (STIX) imaged an\nintense flare, which occurred about 41 deg behind the east limb, from\nheliographic coordinates S13E131. Forward modeling of the CME flux rope\nrevealed that it impulsively accelerated (3.54 km s^{-2}) to attain a peak\nspeed of 2162 km s^{-1}. SolO energetic particle detectors (EPD) observed\nprotons up to about 1 GeV from the extended shock and electrons that produced a\ncomplex type II burst and possibly type III bursts. The durations of SGRE and\ntype II burst are consistent with the linear relation between these quantities\nobtained from longer duration (exceeding 3 hours) SGRE events. All these\nobservations are consistent with an extended shock surrounding the CME flux\nrope, which is the likely source of high energy protons required for the SGRE\nevent. We compare this event with six other BTL SGRE eruptions and find that\nthey are all consistent with energetic shock driving CMEs. We also find a\nsignificant east west asymmetry in the BTL source locations.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-03-31T08:56:13Z"}
{"aid":"http://arxiv.org/abs/2503.23874v1","title":"He-Mg compounds and helium-driven nonmetal transition in metallic\n  magnesium","summary":"The polymorphism and mechanism of helium compounds is crucial for\nunderstanding the physical and chemical nature of He-bearing materials under\npressures. Here, we predict two new types of He-bearing compounds, MgHe and\nMgnHe (n = 6, 8, 10, 15, 18), being formed above 750 GPa by unbiased ab initio\nstructure search. An unexpected bandgap is opened up in MgHe at as low as\naround 200 GPa. This is the first case of noble gas driven metal-nonmetal\ntransition in all elements. The same mechanism is demonstrated also being\napplicable to other metallic elements, and making beryllium transform into a\nnon-metallic state, a triumph that is impossible otherwise. Furthermore, the\nstability of the simple cubic phase of Mg (Mg-sc) is greatly enhanced by mixing\nwith He, which lowers the critical pressure of pure Mg-sc from about 1.1 TPa\ndown to 750 GPa to form ordered substitutional alloying phase of MgnHe on a\nsimple cubic lattice of Mg. This is the first report on Mg-based noble gas\nsubstitutional alloy, in sharp contrast to the conventional wisdom that He\npreferring interstitial sites. The observed striking influences of He\ndemonstrate the rich physics and chemistry of He-bearing compounds under\nultra-high pressures.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,physics.chem-ph,physics.comp-ph","published":"2025-03-31T09:25:09Z"}
{"aid":"http://arxiv.org/abs/2503.23898v1","title":"An Explainable Neural Radiomic Sequence Model with Spatiotemporal\n  Continuity for Quantifying 4DCT-based Pulmonary Ventilation","summary":"Accurate evaluation of regional lung ventilation is essential for the\nmanagement and treatment of lung cancer patients, supporting assessments of\npulmonary function, optimization of therapeutic strategies, and monitoring of\ntreatment response. Currently, ventilation scintigraphy using nuclear medicine\ntechniques is widely employed in clinical practice; however, it is often\ntime-consuming, costly, and entails additional radiation exposure. In this\nstudy, we propose an explainable neural radiomic sequence model to identify\nregions of compromised pulmonary ventilation based on four-dimensional computed\ntomography (4DCT). A cohort of 45 lung cancer patients from the VAMPIRE dataset\nwas analyzed. For each patient, lung volumes were segmented from 4DCT, and\nvoxel-wise radiomic features (56-dimensional) were extracted across the\nrespiratory cycle to capture local intensity and texture dynamics, forming\ntemporal radiomic sequences. Ground truth ventilation defects were delineated\nvoxel-wise using Galligas-PET and DTPA-SPECT. To identify compromised regions,\nwe developed a temporal saliency-enhanced explainable long short-term memory\n(LSTM) network trained on the radiomic sequences. Temporal saliency maps were\ngenerated to highlight key features contributing to the model's predictions.\nThe proposed model demonstrated robust performance, achieving average (range)\nDice similarity coefficients of 0.78 (0.74-0.79) for 25 PET cases and 0.78\n(0.74-0.82) for 20 SPECT cases. The temporal saliency map explained three key\nradiomic sequences in ventilation quantification: during lung exhalation,\ncompromised pulmonary function region typically exhibits (1) an increasing\ntrend of intensity and (2) a decreasing trend of homogeneity, in contrast to\nhealthy lung tissue.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-03-31T09:47:03Z"}
{"aid":"http://arxiv.org/abs/2503.23903v1","title":"Privacy Preservation for Statistical Input in Dynamical Systems","summary":"This paper addresses the challenge of privacy preservation for statistical\ninputs in dynamical systems. Motivated by an autonomous building application,\nwe formulate a privacy preservation problem for statistical inputs in linear\ntime-invariant systems. What makes this problem widely applicable is that the\ninputs, rather than being assumed to be deterministic, follow a probability\ndistribution, inherently embedding privacy-sensitive information that requires\nprotection. This formulation also presents a technical challenge as\nconventional differential privacy mechanisms are not directly applicable.\nThrough rigorous analysis, we develop strategy to achieve $(0, \\delta)$\ndifferential privacy through adding noise. Finally, the effectiveness of our\nmethods is demonstrated by revisiting the autonomous building application.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T09:54:09Z"}
{"aid":"http://arxiv.org/abs/2503.23906v1","title":"Topologizability and related properties of the iterates of composition\n  operators in Gelfand-Shilov classes","summary":"We analyse the behaviour of the iterates of composition operators defined by\npolynomials acting on global classes of ultradifferentiable functions of\nBeurling type which are invariant under the Fourier transform. In particular,\nwe determine the polynomials $\\psi$ for which the sequence of iterates of the\ncomposition operator $C_\\psi$ is topologizable (m-topologizable) acting on\ncertain Gelfand-Shilov spaces defined by mean of Braun-Meise-Taylor weights. We\nprove that the composition operators $C_\\psi$ with $\\psi$ a polynomial of\ndegree greater than one are always topologizable in certain settings involving\nGelfand-Shilov spaces, just like in the Schwartz space. Unlike in the Schwartz\nspace setting, composition operators $C_\\psi$ associated with polynomials\n$\\psi$ are not always $m-$topologizable. We also deal with the composition\noperators $C_\\psi$ with $\\psi$ being an affine function acting on\n$\\mathcal{S}_{\\omega}(\\mathbb{R})$ and find a complete characterization of\ntopologizability and m-topologizability","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-03-31T09:57:29Z"}
{"aid":"http://arxiv.org/abs/2503.23933v1","title":"PupiNet: Seamless OCT-OCTA Interconversion Through Wavelet-Driven and\n  Multi-Scale Attention Mechanisms","summary":"Optical Coherence Tomography (OCT) and Optical Coherence Tomography\nAngiography (OCTA) are key diagnostic tools for clinical evaluation and\nmanagement of retinal diseases. Compared to traditional OCT, OCTA provides\nricher microvascular information, but its acquisition requires specialized\nsensors and high-cost equipment, creating significant challenges for the\nclinical deployment of hardware-dependent OCTA imaging methods. Given the\ntechnical complexity of OCTA image acquisition and potential mechanical\nartifacts, this study proposes a bidirectional image conversion framework\ncalled PupiNet, which accurately achieves bidirectional transformation between\n3D OCT and 3D OCTA. The generator module of this framework innovatively\nintegrates wavelet transformation and multi-scale attention mechanisms,\nsignificantly enhancing image conversion quality. Meanwhile, an Adaptive\nDiscriminator Augmentation (ADA) module has been incorporated into the\ndiscriminator to optimize model training stability and convergence efficiency.\nTo ensure clinical accuracy of vascular structures in the converted images, we\ndesigned a Vessel Structure Matcher (VSM) supervision module, achieving precise\nmatching of vascular morphology between generated images and target images.\nAdditionally, the Hierarchical Feature Calibration (HFC) module further\nguarantees high consistency of texture details between generated images and\ntarget images across different depth levels. To rigorously validate the\nclinical effectiveness of the proposed method, we conducted a comprehensive\nevaluation on a paired OCT-OCTA image dataset containing 300 eyes with various\nretinal pathologies. Experimental results demonstrate that PupiNet not only\nreliably achieves high-quality bidirectional transformation between the two\nmodalities but also shows significant advantages in image fidelity, vessel\nstructure preservation, and clinical usability.","main_category":"eess.IV","categories":"eess.IV","published":"2025-03-31T10:27:23Z"}
{"aid":"http://arxiv.org/abs/2503.23934v1","title":"Green MLOps to Green GenOps: An Empirical Study of Energy Consumption in\n  Discriminative and Generative AI Operations","summary":"This study presents an empirical investigation into the energy consumption of\nDiscriminative and Generative AI models within real-world MLOps pipelines. For\nDiscriminative models, we examine various architectures and hyperparameters\nduring training and inference and identify energy-efficient practices. For\nGenerative AI, Large Language Models (LLMs) are assessed, focusing primarily on\nenergy consumption across different model sizes and varying service requests.\nOur study employs software-based power measurements, ensuring ease of\nreplication across diverse configurations, models, and datasets. We analyse\nmultiple models and hardware setups to uncover correlations among various\nmetrics, identifying key contributors to energy consumption. The results\nindicate that for Discriminative models, optimising architectures,\nhyperparameters, and hardware can significantly reduce energy consumption\nwithout sacrificing performance. For LLMs, energy efficiency depends on\nbalancing model size, reasoning complexity, and request-handling capacity, as\nlarger models do not necessarily consume more energy when utilisation remains\nlow. This analysis provides practical guidelines for designing green and\nsustainable ML operations, emphasising energy consumption and carbon footprint\nreductions while maintaining performance. This paper can serve as a benchmark\nfor accurately estimating total energy use across different types of AI models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T10:28:04Z"}
{"aid":"http://arxiv.org/abs/2503.23956v1","title":"AirCache: Activating Inter-modal Relevancy KV Cache Compression for\n  Efficient Large Vision-Language Model Inference","summary":"Recent advancements in Large Visual Language Models (LVLMs) have gained\nsignificant attention due to their remarkable reasoning capabilities and\nproficiency in generalization. However, processing a large number of visual\ntokens and generating long-context outputs impose substantial computational\noverhead, leading to excessive demands for key-value (KV) cache. To address\nthis critical bottleneck, we propose AirCache, a novel KV cache compression\nmethod aimed at accelerating LVLMs inference. This work systematically\ninvestigates the correlations between visual and textual tokens within the\nattention mechanisms of LVLMs. Our empirical analysis reveals considerable\nredundancy in cached visual tokens, wherein strategically eliminating these\ntokens preserves model performance while significantly accelerating context\ngeneration. Inspired by these findings, we introduce an elite observation\nwindow for assessing the importance of visual components in the KV cache,\nfocusing on stable inter-modal relevancy modeling with enhanced\nmulti-perspective consistency. Additionally, we develop an adaptive layer-wise\nbudget allocation strategy that capitalizes on the strength and skewness of\ntoken importance distribution, showcasing superior efficiency compared to\nuniform allocation. Comprehensive evaluations across multiple LVLMs and\nbenchmarks demonstrate that our method achieves comparable performance to the\nfull cache while retaining only 10% of visual KV cache, thereby reducing\ndecoding latency by 29% to 66% across various batch size and prompt length of\ninputs. Notably, as cache retention rates decrease, our method exhibits\nincreasing performance advantages over existing approaches.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T11:13:18Z"}
{"aid":"http://arxiv.org/abs/2503.23967v1","title":"Note on $q=2$ paraparticle SYK model","summary":"We investigate the $q=2$ SYK model with paraparticles (PSYK$_2$), analyzing\nits thermodynamics and spectral form factor (SFF) using random matrix theory.\nThe Hamiltonian is quadratic, with coupling coefficients randomly drawn from\nthe Gaussian Unitary Ensemble (GUE). The model exhibits self-averaging behavior\nand shows a striking transition in SFF dynamics: while the fermionic SYK$_2$\ndisplays a ramp behavior $\\mathcal{K}(t) \\sim e^{C_0 t}$ with $C_0 \\sim \\ln N$,\nthe paraparticle cases exhibit $C_0 \\sim \\mathcal{O}(1)$. These findings offer\nnew insights into quantum systems with exotic statistics.","main_category":"hep-th","categories":"hep-th","published":"2025-03-31T11:32:06Z"}
{"aid":"http://arxiv.org/abs/2503.23997v1","title":"On the origin of Jupiter's fuzzy core: constraints from N-body, impact\n  and evolution simulations","summary":"It has been suggested that Jupiter's fuzzy core could be a result of a giant\nimpact. Here, we investigate the expected impact conditions from N-body\nsimulations. We then use state-of-the-art SPH simulations to investigate the\nresults of impacts with different conditions including various impactor masses\nand composition, different formation stages in Jupiter's growth, and different\nresolutions. We next simulate the long-term thermal evolution of Jupiter\npost-impact. We find that N-body simulations predict rather oblique impacts,\nand that head-on collisions are rare. Moreover, our results show that even\nunder a head-on collision, Jupiter's fuzzy core cannot be formed. We next\nsimulated Jupiter's thermal evolution and showed that unless post-impact\ntemperatures are extremely low, a giant impact would not lead to an extended\ndilute core as inferred by interior models. We conclude that Jupiter's fuzzy\ncore is not caused by an impact and is likely to be an outcome of its formation\nprocess.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-03-31T12:20:59Z"}
{"aid":"http://arxiv.org/abs/2503.24000v1","title":"Rethinking Key-Value Cache Compression Techniques for Large Language\n  Model Serving","summary":"Key-Value cache (\\texttt{KV} \\texttt{cache}) compression has emerged as a\npromising technique to optimize Large Language Model (LLM) serving. It\nprimarily decreases the memory consumption of \\texttt{KV} \\texttt{cache} to\nreduce the computation cost. Despite the development of many compression\nalgorithms, their applications in production environments are still not\nprevalent. In this paper, we revisit mainstream \\texttt{KV} \\texttt{cache}\ncompression solutions from a practical perspective. Our contributions are\nthree-fold. First, we comprehensively review existing algorithmic designs and\nbenchmark studies for \\texttt{KV} \\texttt{cache} compression and identify\nmissing pieces in their performance measurement, which could hinder their\nadoption in practice. Second, we empirically evaluate representative\n\\texttt{KV} \\texttt{cache} compression methods to uncover two key issues that\naffect the computational efficiency: (1) while compressing \\texttt{KV}\n\\texttt{cache} can reduce memory consumption, current implementations (e.g.,\nFlashAttention, PagedAttention) do not optimize for production-level LLM\nserving, resulting in suboptimal throughput performance; (2) compressing\n\\texttt{KV} \\texttt{cache} may lead to longer outputs, resulting in increased\nend-to-end latency. We further investigate the accuracy performance of\nindividual samples rather than the overall performance, revealing the intrinsic\nlimitations in \\texttt{KV} \\texttt{cache} compression when handling specific\nLLM tasks. Third, we provide tools to shed light on future \\texttt{KV}\n\\texttt{cache} compression studies and facilitate their practical deployment in\nproduction. They are open-sourced in\n\\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T12:23:31Z"}
{"aid":"http://arxiv.org/abs/2503.24096v1","title":"DANTE-AD: Dual-Vision Attention Network for Long-Term Audio Description","summary":"Audio Description is a narrated commentary designed to aid vision-impaired\naudiences in perceiving key visual elements in a video. While short-form video\nunderstanding has advanced rapidly, a solution for maintaining coherent\nlong-term visual storytelling remains unresolved. Existing methods rely solely\non frame-level embeddings, effectively describing object-based content but\nlacking contextual information across scenes. We introduce DANTE-AD, an\nenhanced video description model leveraging a dual-vision Transformer-based\narchitecture to address this gap. DANTE-AD sequentially fuses both frame and\nscene level embeddings to improve long-term contextual understanding. We\npropose a novel, state-of-the-art method for sequential cross-attention to\nachieve contextual grounding for fine-grained audio description generation.\nEvaluated on a broad range of key scenes from well-known movie clips, DANTE-AD\noutperforms existing methods across traditional NLP metrics and LLM-based\nevaluations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T13:49:43Z"}
{"aid":"http://arxiv.org/abs/2503.24109v1","title":"Demailly's approximation of general weights: A conjecture of Matsumura","summary":"In this note, we address a conjecture posed by Matsumura, which gives the\nconvergence of the Demailly approximation of a general (weakly) upper\nsemi-continuous weight.","main_category":"math.CV","categories":"math.CV","published":"2025-03-31T14:01:26Z"}
{"aid":"http://arxiv.org/abs/2503.24112v1","title":"Characterization of norm and quasi-norm forms in S-adic setting","summary":"The goal of the present paper is to characterize the norm and quasi-norm\nforms defined over an arbitrary number field F in terms of their values at the\nS-integer points, where S is a finite set of valuations of F containing the\narchimedean ones. In this way we generalize the main result of the recent paper\n[T5], where the notion of a quasi-norm form is introduced when F = Q and S is a\nsingleton. In complement, we exhibit some relations with problems and results\nin this area of research.","main_category":"math.NT","categories":"math.NT","published":"2025-03-31T14:04:51Z"}
{"aid":"http://arxiv.org/abs/2503.24127v1","title":"Compression Metadata-assisted RoI Extraction and Adaptive Inference for\n  Efficient Video Analytics","summary":"Video analytics demand substantial computing resources, posing significant\nchallenges in computing resource-constrained environment. In this paper, to\nachieve high accuracy with acceptable computational workload, we propose a\ncost-effective regions of interest (RoIs) extraction and adaptive inference\nscheme based on the informative encoding metadata. Specifically, to achieve\nefficient RoI-based analytics, we explore motion vectors from encoding metadata\nto identify RoIs in non-reference frames through morphological opening\noperation. Furthermore, considering the content variation of RoIs, which calls\nfor inference by models with distinct size, we measure RoI complexity based on\nthe bitrate allocation information from encoding metadata. Finally, we design\nan algorithm that prioritizes scheduling RoIs to models of the appropriate\ncomplexity, balancing accuracy and latency. Extensive experimental results show\nthat our proposed scheme reduces latency by nearly 40% and improves 2.2% on\naverage in accuracy, outperforming the latest benchmarks.","main_category":"cs.MM","categories":"cs.MM","published":"2025-03-31T14:12:02Z"}
{"aid":"http://arxiv.org/abs/2503.24144v1","title":"$\\mathsf{P}$-completeness of Graph Local Complementation","summary":"Local complementation of a graph $G$ on vertex $v$ is an operation that\nresults in a new graph $G*v$, where the neighborhood of $v$ is complemented.\nThis operation has been widely studied in graph theory and quantum computing.\n  This article introduces the Local Complementation Problem, a decision problem\nthat captures the complexity of applying a sequence of local complementations.\nGiven a graph $G$, a sequence of vertices $s$, and a pair of vertices $u,v$,\nthe problem asks whether the edge $(u,v)$ is present in the graph obtained\nafter applying local complementations according to $s$. The main contribution\nof this work is proving that this problem is $\\mathsf{P}$-complete, implying\nthat computing a sequence of local complementation is unlikely to be\nefficiently parallelizable. The proof is based on a reduction from the Circuit\nValue Problem, a well-known $\\mathsf{P}$-complete problem, by simulating\ncircuits through local complementations.\n  Aditionally, the complexity of this problem is analyzed under different\nrestrictions. In particular, it is shown that for complete and star graphs, the\nproblem belongs to $\\mathsf{LOGSPACE}$. Finally, it is conjectured that the\nproblem remains $\\mathsf{P}$-complete for the class of circle graphs.","main_category":"cs.CC","categories":"cs.CC,cs.DM","published":"2025-03-31T14:27:46Z"}
{"aid":"http://arxiv.org/abs/2503.24163v1","title":"First-principles design of stable spin qubits in monolayer MoS2 with\n  elemental defect engineering","summary":"Quantum information science (QIS), encompassing technologies such as quantum\ncomputing, sensing, and communication, relies on the development and\nmanipulation of quantum bits (qubits). Recently, two-dimensional (2D) materials\n- characterized by their atomic thinness and external controllability - have\nemerged as promising candidates for qubit fabrication and manipulation at room\ntemperature. In this study, we propose that antisite defects (MX) in 2D\ntransition metal disulfides (TMDs) can serve as tunable quantum defects with\ncontrolled positioning. Using first-principles atomic structure simulations, we\nidentify six thermodynamically stable neutral antisite defects (MX, where M =\nMg, Ca, Sr, Ba, Zn, Cd; X = S) in monolayer 1H-MoS2. These defects exhibit\npotential as spin-defected qubits with stable triplet ground states.\nAdditionally, we demonstrate that the reduction of the bandgap leads to\nsignificant fluctuations in the absorption coefficient within the low-energy\nrange, resulting in the optical response within the desired telecommunication\nband, which is advantageous for quantum communication applications. The\nzero-phonon line (ZPL) associated with these qubits can serve as an effective\nidentifier. This work presents the novel, tunable approach to exploiting\ndefects in 2D materials, opening new possibilities for the development of qubit\nplatforms in quantum information technology.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-03-31T14:46:16Z"}
{"aid":"http://arxiv.org/abs/2503.24197v1","title":"Asymptotically distribution-free goodness-of-fit testing for point\n  processes","summary":"Consider an observation of a multivariate temporal point process $N$ with law\n$\\mathcal P$ on the time interval $[0,T]$. To test the null hypothesis that\n$\\mathcal P$ belongs to a given parametric family, we construct a convergent\ncompensated counting process to which we apply an innovation martingale\ntransformation. We prove that the resulting process converges weakly to a\nstandard Wiener process. Consequently, taking a suitable functional of this\nprocess yields an asymptotically distribution-free goodness-of-fit test for\npoint processes. For several standard tests based on the increments of this\ntransformed process, we establish consistency under alternative hypotheses.\nFinally, we assess the performance of the proposed testing procedure through a\nMonte Carlo simulation study and illustrate its practical utility with two\nreal-data examples.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-03-31T15:15:52Z"}
{"aid":"http://arxiv.org/abs/2503.24211v1","title":"A Quantum Walk Inspired Qubit Lattice Algorithm for Simulating\n  Electromagnetic Wave Propagation and Scattering in Conservative and\n  Dissipative Magnetized Plasmas","summary":"Based on the Dirac representation of Maxwell equations we present an\nexplicit, discrete space-time, quantum walk-inspired algorithm suitable for\nsimulating the electromagnetic wave propagation and scattering from\ninhomogeneities within magnetized plasmas. The quantum walk is implemented on a\nlattice with an internal space of $n_q=4$--qubits, used to encode the classical\nfield amplitudes. Unitary rotation gates operate within this internal space to\ngenerate the non-trivial dynamics of the free plasma-Dirac equation. To\nincorporate the contributions from the cyclotron and plasma density\nterms--manifesting as inhomogeneous potential terms--in the plasma-Dirac\nequation, the walk process is complemented with unitary potential operators.\nThis leads to a unitary qubit lattice sequence that recovers the plasma-Dirac\nequation under a second-order accurate discretization scheme. The proposed\nalgorithm is explicit and demonstrates, in the worst case, a polynomial quantum\nadvantage compared to the Finite Difference Time Domain (FDTD) classical method\nin terms of resource requirements and error complexity. In addition, we extend\nthe algorithm to include dissipative effects by introducing a phenomenological\ncollision frequency between plasma species. Then, a post-selective\ntime-marching implementation scheme is delineated, featuring a non-vanishing\noverall success probability and, subsequently, eliminating the need for\namplitude amplification of the output state while preserving the quantum\nadvantage.","main_category":"quant-ph","categories":"quant-ph,physics.plasm-ph","published":"2025-03-31T15:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.24214v1","title":"Moving Edge for On-Demand Edge Computing: An Uncertainty-aware Approach","summary":"We study an edge demand response problem where, based on historical edge\nworkload demands, an edge provider needs to dispatch moving computing units,\ne.g. truck-carried modular data centers, in response to emerging hotspots\nwithin service area. The goal of edge provider is to maximize the expected\nrevenue brought by serving congested users with satisfactory performance, while\nminimizing the costs of moving units and the potential service-level agreement\nviolation penalty for interrupted services. The challenge is to make robust\npredictions for future demands, as well as optimized moving unit dispatching\ndecisions. We propose a learning-based, uncertain-aware moving unit scheduling\nframework, URANUS, to address this problem. Our framework novelly combines\nBayesian deep learning and distributionally robust approximation to make\npredictions that are robust to data, model and distributional uncertainties in\ndeep learning-based prediction models. Based on the robust prediction outputs,\nwe further propose an efficient planning algorithm to optimize moving unit\nscheduling in an online manner. Simulation experiments show that URANUS can\nsignificantly improve robustness in decision making, and achieve superior\nperformance compared to state-of-the-art reinforcement learning,\nuncertainty-agnostic learning-based methods, and other baselines.","main_category":"cs.NI","categories":"cs.NI","published":"2025-03-31T15:32:05Z"}
{"aid":"http://arxiv.org/abs/2503.24241v1","title":"Asymmetry in Distributions of Accumulated Gains and Losses in Stock\n  Returns","summary":"We study decades-long historic distributions of accumulated S\\&P500 returns,\nfrom daily returns to those over several weeks. The time series of the returns\nemphasize major upheavals in the markets -- Black Monday, Tech Bubble,\nFinancial Crisis and Covid Pandemic -- which are reflected in the tail ends of\nthe distributions. De-trending the overall gain, we concentrate on comparing\ndistributions of gains and losses. Specifically, we compare the tails of the\ndistributions, which are believed to exhibit power-law behavior and possibly\ncontain outliers. Towards this end we find confidence intervals of the linear\nfits of the tails of the complementary cumulative distribution functions on a\nlog-log scale, as well as conduct a statistical U-test in order to detect\noutliers. We also study probability density functions of the full distributions\nof the returns with the emphasis on their asymmetry. The key empirical\nobservations are that the mean of de-trended distributions increases\nnear-linearly with the number of days of accumulation while the overall skew is\nnegative -- consistent with the heavier tails of losses -- and depends little\non the number of days of accumulation. At the same time the variance of the\ndistributions exhibits near-perfect linear dependence on the number of days of\naccumulation, that is it remains constant if scaled to the latter. Finally, we\ndiscuss the theoretical framework for understanding accumulated returns. Our\nmain conclusion is that the current state of theory, which predicts symmetric\nor near-symmetric distributions of returns cannot explain the aggregate of\nempirical results.","main_category":"q-fin.ST","categories":"q-fin.ST,econ.TH,physics.data-an","published":"2025-03-31T15:54:04Z"}
{"aid":"http://arxiv.org/abs/2503.24251v1","title":"Combining Query Performance Predictors: A Reproducibility Study","summary":"A large number of approaches to Query Performance Prediction (QPP) have been\nproposed over the last two decades. As early as 2009, Hauff et al. [28]\nexplored whether different QPP methods may be combined to improve prediction\nquality. Since then, significant research has been done both on QPP approaches,\nas well as their evaluation. This study revisits Hauff et al.s work to assess\nthe reproducibility of their findings in the light of new prediction methods,\nevaluation metrics, and datasets. We expand the scope of the earlier\ninvestigation by: (i) considering post-retrieval methods, including supervised\nneural techniques (only pre-retrieval techniques were studied in [28]); (ii)\nusing sMARE for evaluation, in addition to the traditional correlation\ncoefficients and RMSE; and (iii) experimenting with additional datasets\n(Clueweb09B and TREC DL). Our results largely support previous claims, but we\nalso present several interesting findings. We interpret these findings by\ntaking a more nuanced look at the correlation between QPP methods, examining\nwhether they capture diverse information or rely on overlapping factors.","main_category":"cs.IR","categories":"cs.IR","published":"2025-03-31T16:01:58Z"}
{"aid":"http://arxiv.org/abs/2503.24269v1","title":"A direct detection method of galaxy intrinsic ellipticity-gravitational\n  shear correlation in non-linear regimes using self-calibration","summary":"Intrinsic alignment (IA) of galaxies is a challenging source of contamination\nin the Cosmic shear (GG) signals. The galaxy intrinsic\nellipticity-gravitational shear (IG) correlation is generally the most dominant\ncomponent of such contamination for cross-correlating redshift bins. The\nself-calibration (SC) method is one of the most effective techniques to\nmitigate such contamination from the GG signal. In a photometric survey, the SC\nmethod first extracts the galaxy number density-galaxy intrinsic ellipticity\n(gI) correlation from the observed galaxy-galaxy lensing correlation using the\nredshift dependence of lens-source pairs. The IG correlation is computed\nthrough a scaling relation using the gI correlation and other lensing\nobservables. We extend the SC method beyond the linear regime by modifying its\nscaling relation which can account for the non-linear galaxy bias model and\nvarious IA models. In this study, we provide a framework to detect the IG\ncorrelation for the redshift bins for source galaxies for the proposed year 1\nsurvey of the Rubin Legacy Survey of Space and Time (LSST Y1). We tested the\nmethod for the tidal alignment and tidal torquing (TATT) model of IA and we\nfound that the scaling relation is accurate within 10$\\%$ and 20$\\%$ for\ncross-correlating and auto-correlating redshift bins, respectively. Hence the\nsuppression of IG contamination can be accomplished with a factor of 10 and 5,\nfor cross-correlating and auto-correlating redshift bins, respectively. We\ntested the method's robustness and found that the suppression of IG\ncontamination by a factor of 5 is still achievable for all combinations of\ncross-correlating bins even with the inclusion of a moderate amount of\nuncertainties on IA and bias parameters, respectively. [Abridged]","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-03-31T16:15:37Z"}
{"aid":"http://arxiv.org/abs/2503.24286v1","title":"Pyrometheus: Symbolic abstractions for XPU and automatically\n  differentiated computation of combustion kinetics and thermodynamics","summary":"The cost of combustion simulations is often dominated by the evaluation of\nnet production rates of chemical species and mixture thermodynamics\n(thermochemistry). Execution on computing accelerators (XPUs) like graphic\nprocessing units (GPUs) can greatly reduce this cost. However, established\nthermochemistry software is not readily portable to such devices or sacrifices\nvaluable analytical forms that enable differentiation for sensitivity analysis\nand implicit time integration. Symbolic abstractions are developed with\ncorresponding transformations that enable computation on accelerators and\nautomatic differentiation by avoiding premature specification of detail. The\nsoftware package Pyrometheus is introduced as an implementation of these\nabstractions and their transformations for combustion thermochemistry. The\nformulation facilitates code generation from the symbolic representation of a\nspecific thermochemical mechanism in multiple target languages, including\nPython, C++, and Fortran. Computational concerns are separated: the generated\ncode processes array-valued expressions but does not specify their semantics.\nThese semantics are provided by compatible array libraries, such as NumPy,\nPytato, and Google JAX. Thus, the generated code retains a symbolic\nrepresentation of the thermochemistry, which translates to computation on\naccelerators and CPUs and automatic differentiation. The design and operation\nof these symbolic abstractions and their companion tool, Pyrometheus, are\ndiscussed throughout. Roofline demonstrations show that the computation of\nchemical source terms within MFC, a Fortran-based flow solver we link to\nPyrometheus, is performant.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-03-31T16:35:13Z"}
{"aid":"http://arxiv.org/abs/2503.24306v1","title":"Point Tracking in Surgery--The 2024 Surgical Tattoos in Infrared (STIR)\n  Challenge","summary":"Understanding tissue motion in surgery is crucial to enable applications in\ndownstream tasks such as segmentation, 3D reconstruction, virtual tissue\nlandmarking, autonomous probe-based scanning, and subtask autonomy. Labeled\ndata are essential to enabling algorithms in these downstream tasks since they\nallow us to quantify and train algorithms. This paper introduces a point\ntracking challenge to address this, wherein participants can submit their\nalgorithms for quantification. The submitted algorithms are evaluated using a\ndataset named surgical tattoos in infrared (STIR), with the challenge aptly\nnamed the STIR Challenge 2024. The STIR Challenge 2024 comprises two\nquantitative components: accuracy and efficiency. The accuracy component tests\nthe accuracy of algorithms on in vivo and ex vivo sequences. The efficiency\ncomponent tests the latency of algorithm inference. The challenge was conducted\nas a part of MICCAI EndoVis 2024. In this challenge, we had 8 total teams, with\n4 teams submitting before and 4 submitting after challenge day. This paper\ndetails the STIR Challenge 2024, which serves to move the field towards more\naccurate and efficient algorithms for spatial understanding in surgery. In this\npaper we summarize the design, submissions, and results from the challenge. The\nchallenge dataset is available here: https://zenodo.org/records/14803158 , and\nthe code for baseline models and metric calculation is available here:\nhttps://github.com/athaddius/STIRMetrics","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:53:09Z"}
{"aid":"http://arxiv.org/abs/2503.24331v1","title":"Critical quantum metrology using non-Hermitian spin model with\n  RT-symmetry","summary":"The non-Hermitian transverse XY model with\nKaplan-Shekhtman-Entin-Wohlman-Aharony (KSEA) interaction having RT-symmetry,\nreferred to as iKSEA model, possesses both an exceptional point at which\neigenvectors coalesce and a quantum critical point where gap-closing occurs. To\nprecisely estimate the magnetic field of the system, we prove that the quantum\nFisher information (QFI) of the ground state of the iKSEA model, which is a\nlower bound of the precision quantified by the root mean square error, scales\nas $N^2$, with N being the system-size. This provides Heisenberg scaling both\nat the quantum critical point and the exceptional point in the thermodynamic\nlimit. It indicates that when the system is in contact with the bath, resulting\nin this non-Hermitian model, reservoir engineering can provide enhanced\nprecision of system parameters. Additionally, we demonstrate analytically that,\nin contrast to Hermitian systems, QFI surpasses the Heisenberg limit and\nachieves super-Heisenberg scaling ($\\sim N^6$), when the strength of the KSEA\ninteraction approaches the anisotropy parameter, permitting competition between\nnon-hermiticity and hermiticity features, as long as the system size is\nmoderate.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-03-31T17:19:31Z"}
{"aid":"http://arxiv.org/abs/2503.24350v1","title":"Large CP violation in $Œõ^0_b \\to pK^-œÄ^+œÄ^-$ and its U-spin\n  partner decays","summary":"The LHCb Collaboration has recently found a large CP-violating rate asymmetry\nin the $b$-baryon decay $\\Lambda^0_b \\to pK^-\\pi^+\\pi^-$. This is the first\nobservation of CP violation in baryon processes, opening a new window to test\nits standard model (SM) origin. Many more baryon decays are expected to exhibit\nobservable signals of CP violation. We show that there also exists large CP\nviolation in the U-spin partner decay mode, $\\Xi^0_b \\to \\Sigma^+\\pi^- K^+K^-$,\nwith rate asymmetry $$A_{CP}(\\Xi^0_b \\to \\Sigma^+\\pi^- K^+ K^-) = -\nA_{CP}(\\Lambda^0_b \\to p K^- \\pi^+ \\pi^-)~ \\frac{Br(\\Lambda^0_b \\to p K^- \\pi^+\n\\pi^-)}{Br(\\Xi^0_b \\to \\Sigma^+ \\pi^- K^+ K^-)}~\n\\frac{\\tau^{\\Xi_b}}{\\tau^{\\Lambda_b}}$$ in the U-spin symmetry limit.\nNeglecting small annihilation contributions, we obtain $$A_{CP}(\\Lambda^0_b \\to\np \\pi^+ \\pi^- \\pi^-) =A_{CP}( \\Xi^0_b \\to \\Sigma^+ \\pi^- K^+ K^-) = -(12 \\pm 3)\n\\%.$$ These predictions provide crucial tests for the SM.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-03-31T17:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.24370v1","title":"Effectively Controlling Reasoning Models through Thinking Intervention","summary":"Reasoning-enhanced large language models (LLMs) explicitly generate\nintermediate reasoning steps prior to generating final answers, helping the\nmodel excel in complex problem-solving. In this paper, we demonstrate that this\nemerging generation framework offers a unique opportunity for more fine-grained\ncontrol over model behavior. We propose Thinking Intervention, a novel paradigm\ndesigned to explicitly guide the internal reasoning processes of LLMs by\nstrategically inserting or revising specific thinking tokens. We conduct\ncomprehensive evaluations across multiple tasks, including instruction\nfollowing on IFEval, instruction hierarchy on SEP, and safety alignment on\nXSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention\nsignificantly outperforms baseline prompting approaches, achieving up to 6.7%\naccuracy gains in instruction-following scenarios, 15.4% improvements in\nreasoning about instruction hierarchies, and a 40.0% increase in refusal rates\nfor unsafe prompts using open-source DeepSeek R1 models. Overall, our work\nopens a promising new research avenue for controlling reasoning LLMs.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-03-31T17:50:13Z"}
{"aid":"http://arxiv.org/abs/2503.24382v1","title":"Free360: Layered Gaussian Splatting for Unbounded 360-Degree View\n  Synthesis from Extremely Sparse and Unposed Views","summary":"Neural rendering has demonstrated remarkable success in high-quality 3D\nneural reconstruction and novel view synthesis with dense input views and\naccurate poses. However, applying it to extremely sparse, unposed views in\nunbounded 360{\\deg} scenes remains a challenging problem. In this paper, we\npropose a novel neural rendering framework to accomplish the unposed and\nextremely sparse-view 3D reconstruction in unbounded 360{\\deg} scenes. To\nresolve the spatial ambiguity inherent in unbounded scenes with sparse input\nviews, we propose a layered Gaussian-based representation to effectively model\nthe scene with distinct spatial layers. By employing a dense stereo\nreconstruction model to recover coarse geometry, we introduce a layer-specific\nbootstrap optimization to refine the noise and fill occluded regions in the\nreconstruction. Furthermore, we propose an iterative fusion of reconstruction\nand generation alongside an uncertainty-aware training approach to facilitate\nmutual conditioning and enhancement between these two processes. Comprehensive\nexperiments show that our approach outperforms existing state-of-the-art\nmethods in terms of rendering quality and surface reconstruction accuracy.\nProject page: https://zju3dv.github.io/free360/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.01365v1","title":"Inflation with Gauss-Bonnet correction: beyond slow-roll","summary":"If a coupling between the inflaton and the Gauss-Bonnet term is introduced,\nmany models of inflation that were ruled out by the most recent Planck data can\nbe made viable again. The predictions for the scalar spectral index and\ntensor-to-scalar ratio are typically computed using the slow-roll\napproximation. In this paper we instead study the full equations of motion and\ndetermine the necessary initial conditions for reasonable inflation epoch. We\nderive the conditions under which the Friedmann equation admits positive\nsolutions for the Hubble parameter. Then we study the possibility of the\ninflaton becoming trapped in a local potential minimum induced by the\nGauss-Bonnet term. Finally we demonstrate the results on monomial potential\nmodels with a quadratic and a quartic potential and show that the slow-roll\napproximation becomes imprecise in the quartic case.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-02T05:18:15Z"}
{"aid":"http://arxiv.org/abs/2504.01378v1","title":"A Control Barrier Function Approach to Constrained Resource Allocation\n  Problems in a Maximum Entropy Principle Framework","summary":"This paper presents a novel approach to solve capacitated facility location\nproblems (FLP) that encompass various resource allocation problems. FLPs are a\nclass of NP-hard combinatorial optimization problems, involving optimal\nplacement and assignment of a small number of facilities over a large number of\ndemand points, with each facility subject to upper and lower bounds on its\nresource utilization (e.g., the number of demand points it can serve). To\naddress the challenges posed by inequality constraints and the combinatorial\nnature of the solution space, we reformulate the problem as a dynamic control\ndesign problem, enabling structured constraint handling and enhanced solution\nefficiency. Our method integrates a Control Barrier Function (CBF) and Control\nLyapunov Function (CLF)-based framework with a maximum-entropy principle-based\nframework to ensure feasibility, optimality, and improved exploration of\nsolutions. Numerical experiments demonstrate that this approach significantly\nenhances computational efficiency, yielding better solutions and showing\nnegligible growth in computation time with problem size as compared to existing\nsolvers. These results highlight the potential of control-theoretic and\nentropy-based methods for large-scale facility location problems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T05:47:57Z"}
{"aid":"http://arxiv.org/abs/2504.01381v1","title":"Interstellar extinction toward MWC 148","summary":"We analyse high resolution optical spectra of MWC148 (optical counterpart of\nthe gamma-ray source HESS J0632+057) obtained at Observatoire de Haute Provence\nand Rozhen Observatory. We measure equivalent widths of 7 diffuse interstellar\nbands and estimate the interstellar extinction E_{B-V}=0.85 +/- 0.08.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.HE","published":"2025-04-02T05:50:16Z"}
{"aid":"http://arxiv.org/abs/2504.01397v1","title":"Can the poltergeist mechanism produce observable GWs?","summary":"The enhancement of induced gravitational waves (GWs) occurs due to a sudden\ntransition from an early matter-dominated era to the radiation-dominated era.\nWe analyze the impact of the transition rate on the scalar potential. We find\nthat the finite transition duration suppresses the oscillation amplitude of the\nscalar potential, consequently suppressing the amplitude of the GW energy\nspectrum. By numerically solving the background and perturbation equations, we\ndemonstrate that the physically motivated models, such as the evaporation of\nprimordial black holes and the decay of Q-balls, cannot produce an observable\nGW signal.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T06:37:17Z"}
{"aid":"http://arxiv.org/abs/2504.01411v1","title":"General channel capacities from quantum channel-state duality","summary":"The quantum channel-state duality permits the characterization of a quantum\nprocess through a quantum state, referred to as a Choi state. This\ncharacteristic serves as the impetus for the quantum computing paradigm that\nutilizes Choi states as information sources. In this work, the fundamental\ntheorems regarding quantum channel capacity are proven when Choi states are\nconsidered as sources. This achievement enriches the set of capacities\nassociated with quantum channels. Moreover, it gives rise to novel\nopportunities for the comprehension of superadditivity phenomena and the\ndiscovery of new classes of quantum error-correction codes.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T06:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.01422v1","title":"Optimization of BLE Broadcast Mode in Offline Finding Network","summary":"In the Offline Finding Network(OFN), offline Bluetooth tags broadcast to the\nsurrounding area, the finder devices receiving the broadcast signal and upload\nlocation information to the IoT(Internet of Things) cloud servers, thereby\nachieving offline finding of lost items. This process is essentially a\nBluetooth low energy (BLE) neighbor discovery process(NDP). In the process, the\nvariety of Bluetooth scan modes caused by the scan interval and scan window\nsettings affects the discovery latency of finder devices finding the tag\nbroadcast packets. To optimize the experience of searching for lost devices, we\npropose the CPBIS-mechanism, a certain proportion broadcast-intervals screening\nmechanism that calculates the most suitable two broadcast intervals and their\nproportion for offline tags. This reduces discovery latency in the BLE NDP,\nimproves the discovery success rate, further enhances the user experience. To\nour knowledge, we are the first to propose a comprehensive solution for\nconfiguring the broadcast interval parameters of advertisers in BLE NDP,\nparticularly for configurations involving two or more broadcast intervals. We\nevaluated the results obtained by CPBIS on the nRF52832 chip. The data shows\nthat the CPBIS-mechanism achieves relatively low discovery latencies for\nmultiple scan modes.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T07:13:22Z"}
{"aid":"http://arxiv.org/abs/2504.01431v1","title":"Multi-convex Programming for Discrete Latent Factor Models Prototyping","summary":"Discrete latent factor models (DLFMs) are widely used in various domains such\nas machine learning, economics, neuroscience, psychology, etc. Currently,\nfitting a DLFM to some dataset relies on a customized solver for individual\nmodels, which requires lots of effort to implement and is limited to the\ntargeted specific instance of DLFMs. In this paper, we propose a generic\nframework based on CVXPY, which allows users to specify and solve the fitting\nproblem of a wide range of DLFMs, including both regression and classification\nmodels, within a very short script. Our framework is flexible and inherently\nsupports the integration of regularization terms and constraints on the DLFM\nparameters and latent factors, such that the users can easily prototype the\nDLFM structure according to their dataset and application scenario. We\nintroduce our open-source Python implementation and illustrate the framework in\nseveral examples.","main_category":"math.OC","categories":"math.OC,cs.CE,cs.LG","published":"2025-04-02T07:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.01433v1","title":"Reaction and interaction nucleus-nucleus cross sections in the complete\n  Glauber theory","summary":"The straightforward calculations of the reaction and interaction cross\nsections of the nuclear scattering are carried out in Glauber approach using\nthe generating function method. It allows for the resummation of all orders of\nGlauber theory. The results are obtained for $^4$He, $^{11}$Li, $^{12}$C\nscattering on $^{12}$C target. The difference between the reaction and the\ndifferential cross section is shown to be not exceeding several percents","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-02T07:34:53Z"}
{"aid":"http://arxiv.org/abs/2504.01441v1","title":"Locally- but not Globally-identified SVARs","summary":"This paper analyzes Structural Vector Autoregressions (SVARs) where\nidentification of structural parameters holds locally but not globally. In this\ncase there exists a set of isolated structural parameter points that are\nobservationally equivalent under the imposed restrictions. Although the data do\nnot inform us which observationally equivalent point should be selected, the\ncommon frequentist practice is to obtain one as a maximum likelihood estimate\nand perform impulse response analysis accordingly. For Bayesians, the lack of\nglobal identification translates to non-vanishing sensitivity of the posterior\nto the prior, and the multi-modal likelihood gives rise to computational\nchallenges as posterior sampling algorithms can fail to explore all the modes.\nThis paper overcomes these challenges by proposing novel estimation and\ninference procedures. We characterize a class of identifying restrictions and\ncircumstances that deliver local but non-global identification, and the\nresulting number of observationally equivalent parameter values. We propose\nalgorithms to exhaustively compute all admissible structural parameters given\nreduced-form parameters and utilize them to sample from the multi-modal\nposterior. In addition, viewing the set of observationally equivalent parameter\npoints as the identified set, we develop Bayesian and frequentist procedures\nfor inference on the corresponding set of impulse responses. An empirical\nexample illustrates our proposal.","main_category":"econ.EM","categories":"econ.EM","published":"2025-04-02T07:50:25Z"}
{"aid":"http://arxiv.org/abs/2504.01443v1","title":"Split Federated Learning for UAV-Enabled Integrated Sensing,\n  Computation, and Communication","summary":"Unmanned aerial vehicles (UAVs) with integrated sensing, computation, and\ncommunication (ISCC) capabilities have become key enablers of next-generation\nwireless networks. Federated edge learning (FEL) leverages UAVs as mobile\nlearning agents to collect data, perform local model updates, and contribute to\nglobal model aggregation. However, existing UAV-assisted FEL systems face\ncritical challenges, including excessive computational demands, privacy risks,\nand inefficient communication, primarily due to the requirement for full-model\ntraining on resource-constrained UAVs. To deal with aforementioned challenges,\nwe propose Split Federated Learning for UAV-Enabled ISCC (SFLSCC), a novel\nframework that integrates split federated learning (SFL) into UAV-assisted FEL.\nSFLSCC optimally partitions model training between UAVs and edge servers,\nsignificantly reducing UAVs' computational burden while preserving data\nprivacy. We conduct a theoretical analysis of UAV deployment, split point\nselection, data sensing volume, and client-side aggregation frequency, deriving\nclosed-form upper bounds for the convergence gap. Based on these insights, we\nconceive a joint optimization problem to minimize the energy consumption\nrequired to achieve a target model accuracy. Given the non-convex nature of the\nproblem, we develop a low-complexity algorithm to efficiently determine UAV\ndeployment, split point selection, and communication frequency. Extensive\nsimulations on a target motion recognition task validate the effectiveness of\nSFLSCC, demonstrating superior convergence performance and energy efficiency\ncompared to baseline methods.","main_category":"cs.DC","categories":"cs.DC,cs.ET","published":"2025-04-02T07:53:24Z"}
{"aid":"http://arxiv.org/abs/2504.01444v1","title":"PiCo: Jailbreaking Multimodal Large Language Models via\n  $\\textbf{Pi}$ctorial $\\textbf{Co}$de Contextualization","summary":"Multimodal Large Language Models (MLLMs), which integrate vision and other\nmodalities into Large Language Models (LLMs), significantly enhance AI\ncapabilities but also introduce new security vulnerabilities. By exploiting the\nvulnerabilities of the visual modality and the long-tail distribution\ncharacteristic of code training data, we present PiCo, a novel jailbreaking\nframework designed to progressively bypass multi-tiered defense mechanisms in\nadvanced MLLMs. PiCo employs a tier-by-tier jailbreak strategy, using\ntoken-level typographic attacks to evade input filtering and embedding harmful\nintent within programming context instructions to bypass runtime monitoring. To\ncomprehensively assess the impact of attacks, a new evaluation metric is\nfurther proposed to assess both the toxicity and helpfulness of model outputs\npost-attack. By embedding harmful intent within code-style visual instructions,\nPiCo achieves an average Attack Success Rate (ASR) of 84.13% on Gemini-Pro\nVision and 52.66% on GPT-4, surpassing previous methods. Experimental results\nhighlight the critical gaps in current defenses, underscoring the need for more\nrobust strategies to secure advanced MLLMs.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-02T07:54:32Z"}
{"aid":"http://arxiv.org/abs/2504.01452v1","title":"BiSeg-SAM: Weakly-Supervised Post-Processing Framework for Boosting\n  Binary Segmentation in Segment Anything Models","summary":"Accurate segmentation of polyps and skin lesions is essential for diagnosing\ncolorectal and skin cancers. While various segmentation methods for polyps and\nskin lesions using fully supervised deep learning techniques have been\ndeveloped, the pixel-level annotation of medical images by doctors is both\ntime-consuming and costly. Foundational vision models like the Segment Anything\nModel (SAM) have demonstrated superior performance; however, directly applying\nSAM to medical segmentation may not yield satisfactory results due to the lack\nof domain-specific medical knowledge. In this paper, we propose BiSeg-SAM, a\nSAM-guided weakly supervised prompting and boundary refinement network for the\nsegmentation of polyps and skin lesions. Specifically, we fine-tune SAM\ncombined with a CNN module to learn local features. We introduce a WeakBox with\ntwo functions: automatically generating box prompts for the SAM model and using\nour proposed Multi-choice Mask-to-Box (MM2B) transformation for rough\nmask-to-box conversion, addressing the mismatch between coarse labels and\nprecise predictions. Additionally, we apply scale consistency (SC) loss for\nprediction scale alignment. Our DetailRefine module enhances boundary precision\nand segmentation accuracy by refining coarse predictions using a limited amount\nof ground truth labels. This comprehensive approach enables BiSeg-SAM to\nachieve excellent multi-task segmentation performance. Our method demonstrates\nsignificant superiority over state-of-the-art (SOTA) methods when tested on\nfive polyp datasets and one skin cancer dataset.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-02T08:04:37Z"}
{"aid":"http://arxiv.org/abs/2504.01454v1","title":"Quantum Key Distribution with Efficient Post-Quantum\n  Cryptography-Secured Trusted Node on a Quantum Network","summary":"Quantum Key Distribution (QKD) enables two distant users to exchange a secret\nkey with information-theoretic security, based on the fundamental laws of\nquantum physics. While it is arguably the most mature application of quantum\ncryptography, it has inherent limitations in the achievable distance and the\nscalability to large-scale infrastructures. While the applicability of QKD can\nbe readily increased with the use of intermediary trusted nodes, this adds\nadditional privacy requirements on third parties. In this work, we present an\nefficient scheme leveraging a trusted node with lower privacy requirements\nthanks to the use of post-quantum cryptographic techniques, and implement it on\na deployed fiber optic quantum communication network in the Paris area.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T08:06:16Z"}
{"aid":"http://arxiv.org/abs/2504.01455v1","title":"Atmospheric dynamics of first steps toward terraforming Mars","summary":"Warming Mars' surface could be a step toward making it suitable for life, but\nwould represent a major science and engineering challenge. To warm Mars using\nengineered aerosol, particles released locally must disperse globally. The\nwinds that transport aerosol respond to the aerosol's radiative forcing,\nimplying strong radiative-dynamical feedbacks. Using a plume-tracking climate\nmodel without a water cycle, we investigate radiative-dynamical feedback from\nsurface release of two particle compositions: graphene (which attenuates UV)\nand aluminum. Both compositions can give fast global warming of ~30 K. We infer\nthat 2 liters/second release rate of graphene made from Mars' atmosphere via\nCO2-electrolysis could double Mars' greenhouse effect (+5 K). Self-lofting\nhelps particles rise and spread. The Hadley cell strengthens under warming,\naiding mixing. Warming can be focused in latitude by tuning particle size.\nWithin our model, Mars radiative-dynamical feedbacks enable engineered-aerosol\nwarming. Challenges remain, including functionalization, agglomeration,\ndry-deposition experiments, and modeling water cycle feedbacks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.geo-ph","published":"2025-04-02T08:06:35Z"}
{"aid":"http://arxiv.org/abs/2504.01493v1","title":"Shape derivative for the Dirichlet-to-Neumann operator on a manifold and\n  application to cellular protrusion","summary":"We establish a shape-derivative formula for the Dirichlet-to-Neumann operator\non a compact manifold. Then, we apply this formula to obtain the well-posedness\nin H 1 under a specific Rayleigh-Taylor condition to an equation describing\ncell protrusions. This equation is a generalisation of the theoretical part of\n[9] to any -2D as well as 3D-surfaces.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T08:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.01498v1","title":"On critical maps of the horizontal energy functional between Riemannian\n  foliations","summary":"In this paper, we consider critical points of the\n  horizontal energy $E_{\\HH}(f)$ for a smooth map $f$ between two Riemannian\n  foliations. These critical points are referred to as horizontally harmonic\n  maps. In particular, if the maps are foliated, they become transversally\n  harmonic maps. By utilizing the stress-energy tensor, we establish some\n  monotonicity formulas for horizontally harmonic maps from Euclidean spaces,\n  the quotients $K_{m}$ of Heisenberg groups and also for transversally\n  harmonic maps from Riemannian foliations with appropriate curvature pinching\n  conditions. Finally, we give Jin-type theorems for either horizontally\n  harmonic maps or transversally harmonic maps under some asymptotic\n  conditions at infinity.","main_category":"math.DG","categories":"math.DG","published":"2025-04-02T08:50:59Z"}
{"aid":"http://arxiv.org/abs/2504.01499v1","title":"The de Rham cohomology of covers with cyclic $p$-Sylow subgroup","summary":"Let $X$ be a smooth projective curve over a field $k$ with an action of a\nfinite group $G$. A well-known result of Chevalley and Weil describes the\n$k[G]$-module structure of cohomologies of $X$ in the case when the\ncharacteristic of $k$ does not divide $\\# G$. It is unlikely that such a\nformula can be derived in the general case, since the representation theory of\ngroups with non-cyclic $p$-Sylow subgroups is wild in characteristic $p$. The\ngoal of this article is to show that when $G$ has a cyclic $p$-Sylow subgroup,\nthe $G$-structure of the de Rham cohomology of $X$ is completely determined by\nthe ramification data. In principle, this leads to new formulas in the spirit\nof Chevalley and Weil for such curves. We provide such an explicit description\nof the de Rham cohomology in the cases when $G = \\mathbb Z/p^n$ and when the\n$p$-Sylow subgroup of $G$ is normal of order $p$.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-02T08:51:33Z"}
{"aid":"http://arxiv.org/abs/2504.01507v1","title":"Grasping by Spiraling: Reproducing Elephant Movements with Rigid-Soft\n  Robot Synergy","summary":"The logarithmic spiral is observed as a common pattern in several living\nbeings across kingdoms and species. Some examples include fern shoots,\nprehensile tails, and soft limbs like octopus arms and elephant trunks. In the\nlatter cases, spiraling is also used for grasping. Motivated by how this\nstrategy simplifies behavior into kinematic primitives and combines them to\ndevelop smart grasping movements, this work focuses on the elephant trunk,\nwhich is more deeply investigated in the literature. We present a soft arm\ncombined with a rigid robotic system to replicate elephant grasping\ncapabilities based on the combination of a soft trunk with a solid body. In our\nsystem, the rigid arm ensures positioning and orientation, mimicking the role\nof the elephant's head, while the soft manipulator reproduces trunk motion\nprimitives of bending and twisting under proper actuation patterns. This\nsynergy replicates 9 distinct elephant grasping strategies reported in the\nliterature, accommodating objects of varying shapes and sizes. The synergistic\ninteraction between the rigid and soft components of the system minimizes the\ncontrol complexity while maintaining a high degree of adaptability.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T08:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.01521v1","title":"Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion\n  Model","summary":"Recent advancements in diffusion models have revolutionized generative\nmodeling. However, the impressive and vivid outputs they produce often come at\nthe cost of significant model scaling and increased computational demands.\nConsequently, building personalized diffusion models based on off-the-shelf\nmodels has emerged as an appealing alternative. In this paper, we introduce a\nnovel perspective on conditional generation for transferring a pre-trained\nmodel. From this viewpoint, we propose *Domain Guidance*, a straightforward\ntransfer approach that leverages pre-trained knowledge to guide the sampling\nprocess toward the target domain. Domain Guidance shares a formulation similar\nto advanced classifier-free guidance, facilitating better domain alignment and\nhigher-quality generations. We provide both empirical and theoretical analyses\nof the mechanisms behind Domain Guidance. Our experimental results demonstrate\nits substantial effectiveness across various transfer benchmarks, achieving\nover a 19.6% improvement in FID and a 23.4% improvement in FD$_\\text{DINOv2}$\ncompared to standard fine-tuning. Notably, existing fine-tuned models can\nseamlessly integrate Domain Guidance to leverage these benefits, without\nadditional training.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-02T09:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.01560v1","title":"Optimizing Package Delivery with Quantum Annealers: Addressing\n  Time-Windows and Simultaneous Pickup and Delivery","summary":"Recent research at the intersection of quantum computing and routing problems\nhas been highly prolific. Much of this work focuses on classical problems such\nas the Traveling Salesman Problem and the Vehicle Routing Problem. The\npractical applicability of these problems depends on the specific objectives\nand constraints considered. However, it is undeniable that translating complex\nreal-world requirements into these classical formulations often proves\nchallenging. In this paper, we resort to our previously published\nquantum-classical technique for addressing real-world-oriented routing\nproblems, known as Quantum for Real Package Delivery (Q4RPD), and elaborate on\nsolving additional realistic problem instances. Accordingly, this paper\nemphasizes the following characteristics: i) simultaneous pickup and\ndeliveries, ii) time-windows, and iii) mobility restrictions by vehicle type.\nTo illustrate the application of Q4RPD, we have conducted an experimentation\ncomprising seven instances, serving as a demonstration of the newly developed\nfeatures.","main_category":"cs.ET","categories":"cs.ET,cs.AI","published":"2025-04-02T10:01:34Z"}
{"aid":"http://arxiv.org/abs/2504.01561v1","title":"STPNet: Scale-aware Text Prompt Network for Medical Image Segmentation","summary":"Accurate segmentation of lesions plays a critical role in medical image\nanalysis and diagnosis. Traditional segmentation approaches that rely solely on\nvisual features often struggle with the inherent uncertainty in lesion\ndistribution and size. To address these issues, we propose STPNet, a\nScale-aware Text Prompt Network that leverages vision-language modeling to\nenhance medical image segmentation. Our approach utilizes multi-scale textual\ndescriptions to guide lesion localization and employs retrieval-segmentation\njoint learning to bridge the semantic gap between visual and linguistic\nmodalities. Crucially, STPNet retrieves relevant textual information from a\nspecialized medical text repository during training, eliminating the need for\ntext input during inference while retaining the benefits of cross-modal\nlearning. We evaluate STPNet on three datasets: COVID-Xray, COVID-CT, and\nKvasir-SEG. Experimental results show that our vision-language approach\noutperforms state-of-the-art segmentation methods, demonstrating the\neffectiveness of incorporating textual semantic knowledge into medical image\nanalysis. The code has been made publicly on\nhttps://github.com/HUANGLIZI/STPNet.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-02T10:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.01577v1","title":"Instance Migration Diffusion for Nuclear Instance Segmentation in\n  Pathology","summary":"Nuclear instance segmentation plays a vital role in disease diagnosis within\ndigital pathology. However, limited labeled data in pathological images\nrestricts the overall performance of nuclear instance segmentation. To tackle\nthis challenge, we propose a novel data augmentation framework Instance\nMigration Diffusion Model (IM-Diffusion), IM-Diffusion designed to generate\nmore varied pathological images by constructing diverse nuclear layouts and\ninternuclear spatial relationships. In detail, we introduce a Nuclear Migration\nModule (NMM) which constructs diverse nuclear layouts by simulating the process\nof nuclear migration. Building on this, we further present an\nInternuclear-regions Inpainting Module (IIM) to generate diverse internuclear\nspatial relationships by structure-aware inpainting. On the basis of the above,\nIM-Diffusion generates more diverse pathological images with different layouts\nand internuclear spatial relationships, thereby facilitating downstream tasks.\nEvaluation on the CoNSeP and GLySAC datasets demonstrate that the images\ngenerated by IM-Diffusion effectively enhance overall instance segmentation\nperformance. Code will be made public later.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-02T10:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.01584v1","title":"Higher-order topological phases for time-reversal-symmetry breaking\n  superconductivity in UTe$_2$","summary":"The recent discovery of heavy-fermion superconductor UTe$_2$ has broadened\nthe possibility of realizing exotic time-reversal-symmetry-breaking\nsuperconductivity. However, a comprehensive understanding of the topological\nphases in the superconducting states of UTe$_2$ is still lacking. Here, we\npresent an exhaustive classification of topological phases for all\ntime-reversal symmetry breaking pairing symmetries of UTe$_2$. Using the K\ntheoretical classification approach, we uncover that 25 out of 36 possible\npairing states are classified as higher-order topological phases, with some\ndemonstrating hybrid-order topology through an intricate interplay of hinge and\ncorner states. Furthermore, under the weak-coupling condition of the pair\npotentials, the possible pairing symmetries are constrained to $B_{ju} + i\nB_{ku}$, $A_{u} + i B_{j u}$, and $B_{j g} + iA_u$ ($j,k = 1,2,3$; $j \\neq k$),\nwhere these symbols denote the irreducible representations of the point group\n$D_{2h}$. For these pairing states, the topological invariants are related to\nthe Fermi surface topology via the Fermi-surface formula, enabling us to\nsystematically diagnose higher-order topological phases. Using a tight-binding\nmodel, we demonstrate the higher-order topological phases of the mixed-parity\n$A_u + iB_{1g}$ superconductors, where the second-order and hybrid-order\ntopological phases emerge as the number of Fermi surfaces enclosing the\ntime-reversal invariant momentum evolves from two to four. The findings suggest\nthat UTe$_2$ serves as a compelling platform for exploring higher-order\ntopological superconductors with diverse topological surface states.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T10:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.01652v1","title":"Market-Oriented Flow Allocation for Thermal Solar Plants: An\n  Auction-Based Methodology with Artificial Intelligence","summary":"This paper presents a novel method to optimize thermal balance in parabolic\ntrough collector (PTC) plants. It uses a market-based system to distribute flow\namong loops combined with an artificial neural network (ANN) to reduce\ncomputation and data requirements. This auction-based approach balances loop\ntemperatures, accommodating varying thermal losses and collector efficiencies.\nValidation across different thermal losses, optical efficiencies, and\nirradiance conditions-sunny, partially cloudy, and cloudy-show improved thermal\npower output and intercept factors compared to a no-allocation system. It\ndemonstrates scalability and practicality for large solar thermal plants,\nenhancing overall performance. The method was first validated through\nsimulations on a realistic solar plant model, then adapted and successfully\ntested in a 50 MW solar trough plant, demonstrating its advantages.\nFurthermore, the algorithms have been implemented, commissioned, and are\ncurrently operating in 13 commercial solar trough plants.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-02T12:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.01671v1","title":"Anomaly Detection for Hybrid Butterfly Subspecies via Probability\n  Filtering","summary":"Detecting butterfly hybrids requires knowledge of the parent subspecies, and\nthe process can be tedious when encountering a new subspecies. This study\nfocuses on a specific scenario where a model trained to recognize hybrid\nspecies A can generalize to species B when B biologically mimics A. Since\nspecies A and B share similar patterns, we leverage BioCLIP as our feature\nextractor to capture features based on their taxonomy. Consequently, the\nalgorithm designed for species A can be transferred to B, as their hybrid and\nnon-hybrid patterns exhibit similar relationships. To determine whether a\nbutterfly is a hybrid, we adopt proposed probability filtering and color\njittering to augment and simulate the mimicry. With these approaches, we\nachieve second place in the official development phase. Our code is publicly\navailable at https://github.com/Justin900429/NSF-HDR-Challenge.","main_category":"cs.CE","categories":"cs.CE,cs.AI","published":"2025-04-02T12:18:44Z"}
{"aid":"http://arxiv.org/abs/2504.01677v1","title":"System Level Synthesis for Affine Control Policies: Model Based and\n  Data-Driven Settings","summary":"There is an increasing need for effective control of systems with complex\ndynamics, particularly through data-driven approaches. System Level Synthesis\n(SLS) has emerged as a powerful framework that facilitates the control of\nlarge-scale systems while accounting for model uncertainties. SLS approaches\nare currently limited to linear systems and time-varying linear control\npolicies, thus limiting the class of achievable control strategies. We\nintroduce a novel closed-loop parameterization for time-varying affine control\npolicies, extending the SLS framework to a broader class of systems and\npolicies. We show that the closed-loop behavior under affine policies can be\nequivalently characterized using past system trajectories, enabling a fully\ndata-driven formulation. This parameterization seamlessly integrates affine\npolicies into optimal control problems, allowing for a closed-loop formulation\nof general Model Predictive Control (MPC) problems. To the best of our\nknowledge, this is the first work to extend SLS to affine policies in both\nmodel-based and data-driven settings, enabling an equivalent formulation of MPC\nproblems using closed-loop maps. We validate our approach through numerical\nexperiments, demonstrating that our model-based and data-driven affine SLS\nformulations achieve performance on par with traditional model-based MPC.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-02T12:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.01690v1","title":"Token Pruning in Audio Transformers: Optimizing Performance and Decoding\n  Patch Importance","summary":"Vision Transformers (ViTs) have achieved state-of-the-art performance across\nvarious computer vision tasks, but their high computational cost remains a\nchallenge. Token pruning has been proposed to reduce this cost by selectively\nremoving less important tokens. While effective in vision tasks by discarding\nnon-object regions, applying this technique to audio tasks presents unique\nchallenges, as distinguishing relevant from irrelevant regions in\ntime-frequency representations is less straightforward. In this study, for the\nfirst time, we applied token pruning to ViT-based audio classification models\nusing Mel-spectrograms and analyzed the trade-offs between model performance\nand computational cost: TopK token pruning can reduce MAC operations of\nAudioMAE and AST by 30-40%, with less than a 1% drop in classification\naccuracy. Our analysis reveals that while high-intensity tokens contribute\nsignificantly to model accuracy, low-intensity tokens remain important. In\nparticular, they play a more critical role in general audio classification\ntasks than in speech-specific tasks.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-02T12:44:38Z"}
{"aid":"http://arxiv.org/abs/2504.01731v1","title":"The protein escape process at the ribosomal exit tunnel has conserved\n  mechanisms across the domains of life","summary":"The ribosomal exit tunnel is the primary structure affecting the release of\nnascent proteins at the ribosome. The ribosomal exit tunnels from different\nspecies have elements of conservation and differentiation in structural and\nphysico-chemical properties. In this study, by simulating the elongation and\nescape processes of nascent proteins at the ribosomal exit tunnels of four\ndifferent organisms, we show that the escape process has conserved mechanisms\nacross the domains of life. Specifically, it is found that the escape process\nof proteins follows the diffusion mechanism given by a simple diffusion model\nand the median escape time positively correlates with the number of hydrophobic\nresidues and the net charge of a protein for all the exit tunnels considered.\nThese properties hold for twelve distinct proteins considered in two slightly\ndifferent and improved G\\=o-like models. It is also found that the differences\nin physico-chemical properties of the tunnels lead to quantitative differences\nin the protein escape times. In particular, the relatively strong\nhydrophobicity of the E. coli's tunnel and the unusually high number of\nnegatively charged amino acids on the tunnel's surface of H. marismortui lead\nto substantially slower escapes of proteins at these tunnels than at those of\nS. cerevisisae and H. sapiens.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T13:40:58Z"}
{"aid":"http://arxiv.org/abs/2504.01779v1","title":"The Vertical Metallicity Gradient of the Galactic Disk for Mono-Age\n  Stellar Populations in LAMOST","summary":"The vertical metallicity gradient of the Galactic disk offers valuable\ninsights into the disk's formation and chemical evolution over time. We\nutilized the LAMOST-LRS young stellar sample to investigate this gradient and\nfound that it approaches zero as stellar effective temperature (or age)\nincreases (or decreases) across various Galactocentric distances. To validate\nthis result, we analyzed 295 open clusters younger than 3 Gyr and 976 classical\ncepheids within the Galactic disk. The findings confirmed that, within a given\nnarrow age range, the vertical metallicity gradient is effectively zero. This\nrelationship between metallicity and age supports the ``upside-down'' disk\nformation theory, as it indicates that the youngest and most metal-rich stars\ndominate the midplane, while older and more metal-poor stars formed at larger\nvertical heights and currently tend to be at these heights. Overall, our\nresults align well with theoretical predictions, offering further insight into\nthe chemical evolution and structural properties of the Milky Way.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T14:43:02Z"}
{"aid":"http://arxiv.org/abs/2504.01783v1","title":"CLaP -- State Detection from Time Series","summary":"The ever-growing amount of sensor data from machines, smart devices, and the\nenvironment leads to an abundance of high-resolution, unannotated time series\n(TS). These recordings encode the recognizable properties of latent states and\ntransitions from physical phenomena that can be modelled as abstract processes.\nThe unsupervised localization and identification of these states and their\ntransitions is the task of time series state detection (TSSD). We introduce\nCLaP, a new, highly accurate and efficient algorithm for TSSD. It leverages the\npredictive power of time series classification for TSSD in an unsupervised\nsetting by applying novel self-supervision techniques to detect whether data\nsegments emerge from the same state or not. To this end, CLaP cross-validates a\nclassifier with segment-labelled subsequences to quantify confusion between\nsegments. It merges labels from segments with high confusion, representing the\nsame latent state, if this leads to an increase in overall classification\nquality. We conducted an experimental evaluation using 391 TS from four\nbenchmarks and found CLaP to be significantly more precise in detecting states\nthan five state-of-the-art competitors. It achieves the best accuracy-runtime\ntradeoff and is scalable to large TS. We provide a Python implementation of\nCLaP, which can be deployed in TS analysis workflows.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DB","published":"2025-04-02T14:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.01789v1","title":"OpenThaiGPT 1.6 and R1: Thai-Centric Open Source and Reasoning Large\n  Language Models","summary":"We present OpenThaiGPT 1.6 and R1 (OTG-1.6 and OTG-R1), Thai-centric Large\nLanguage Models (LLMs) developed through distinct methodologies to enhance\ngeneralization and reasoning capabilities. OTG-1.6 employs Task Arithmetic\nmodel merging for broad generalization, while OTG-R1 integrates multi-stage\ntraining with the Less-Is-More Reasoning Hypothesis (LIMO) for advanced\nreasoning. Benchmark evaluations demonstrate superior performance across Thai\nlanguage tasks, achieving competitive results against larger-scale open-source\nThai LLMs. This paper details the proposed models, training processes,\nbenchmarks, and results, highlighting improvements over previous models and\nestablishing new performance standards for Thai-centric LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T14:55:52Z"}
{"aid":"http://arxiv.org/abs/2504.01802v1","title":"Distributed Triangle Detection is Hard in Few Rounds","summary":"In the distributed triangle detection problem, we have an $n$-vertex network\n$G=(V,E)$ with one player for each vertex of the graph who sees the edges\nincident on the vertex. The players communicate in synchronous rounds using the\nedges of this network and have a limited bandwidth of $O(\\log{n})$ bits over\neach edge. The goal is to detect whether or not $G$ contains a triangle as a\nsubgraph in a minimal number of rounds.\n  We prove that any protocol (deterministic or randomized) for distributed\ntriangle detection requires $\\Omega(\\log\\log{n})$ rounds of communication.\nPrior to our work, only one-round lower bounds were known for this problem.\n  The primary technique for proving these types of distributed lower bounds is\nvia reductions from two-party communication complexity. However, it has been\nknown for a while that this approach is provably incapable of establishing any\nmeaningful lower bounds for distributed triangle detection. Our main technical\ncontribution is a new information theoretic argument which combines recent\nadvances on multi-pass graph streaming lower bounds with the point-to-point\ncommunication aspects of distributed models, and can be of independent\ninterest.","main_category":"cs.DS","categories":"cs.DS,cs.CC,cs.DC","published":"2025-04-02T15:10:21Z"}
{"aid":"http://arxiv.org/abs/2504.01812v1","title":"Non-collocated vibration absorption using delayed resonator for spectral\n  and spacial tuning -- analysis and experimental validation","summary":"Non-collocated vibration absorption (NCVA) concept using delayed resonator\nfor in-situ tuning is analyzed and experimentally validated. There are two\ncritical contributions of this work. One is on the scalable analytical pathway\nfor verifying the concept of resonant substructure as the basis of the ideal\nvibration absorption. The second is to experimentally validate the spatial and\nspectral tunability of NCVA structures for the first time. For both novelties\narbitrarily large dimensions of interconnected mass-spring-damper chains are\nconsidered. Following the state of the art on NCVA, control synthesis is\nperformed over the resonant substructure comprising the delayed resonator and a\npart of the primary structure involved in the vibration absorption. The\nexperimental validation of the proposed NCVA concept is performed on a\nmechatronic setup with three interconnected cart-bodies. Based on the spectral\nanalysis, an excitation frequency is selected for which a stable vibration\nsuppression can be achieved sequentially for all the three bodies, one\ncollocated and two non-collocated. The experimental results closely match the\nsimulations for complete vibration suppression at the targeted bodies, and thus\nvalidating the crucial spatial tunability characteristic as well as the\ntraditional spectral tuning.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-02T15:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.01814v1","title":"Energy Density Functional of Confined Quarks: an Improved Ansatz","summary":"Density Functional Theory (DFT) is a robust framework for modeling\ninteracting many-body systems, including the equation of state (EoS) of dense\nmatter. Many models, however, rely on energy functionals based on assumptions\nthat have not been rigorously validated. We critically analyze a commonly used\nansatz for confinement, where the energy functional scales with density as $U\n\\propto n^{\\frac{2}{3}}$ . Our findings, derived from a systematic non-local\nenergy functional, reveal that this scaling does not capture the dynamics of\nconfinement. Instead, the energy functional evolves from $n^2$ at low densities\nto $n$ at high densities, governed by an infrared cutoff. These results suggest\nthat models relying on such assumptions should be revisited to ensure more\nreliable EoS construction.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE,hep-ph,hep-th","published":"2025-04-02T15:20:03Z"}
{"aid":"http://arxiv.org/abs/2504.01820v1","title":"Antenna Selection for Enhancing Privacy in Radar-Based Vital Sign\n  Monitoring Systems","summary":"Radar-based vital sign monitoring (VSM) systems have become valuable for\nnon-contact health monitoring by detecting physiological activities, such as\nrespiration and heartbeat, remotely. However, the conventional phased array\nused in VSM is vulnerable to privacy breaches, as an eavesdropper can extract\nsensitive vital sign information by analyzing the reflected radar signals. In\nthis paper, we propose a novel approach to protect privacy in radar-based VSM\nby modifying the radar transmitter hardware, specifically by strategically\nselecting the transmit antennas from the available antennas in the transmit\narray. By dynamically selecting which antennas connect or disconnect to the\nradio frequency chain, the transmitter introduces additional phase noise to the\nradar echoes, generating false frequencies in the power spectrum of the\nextracted phases at the eavesdropper's receiver. The antenna activation pattern\nis designed to maximize the variance of the phases introduced by antenna\nselection, which effectively makes the false frequencies dominate the spectrum,\nobscuring the actual vital sign frequencies. Meanwhile, the authorized\nreceiver, having knowledge of the antenna selection pattern, can compensate for\nthe phase noise and accurately extract the vital signs. Numerical experiments\nare conducted to validate the effectiveness of the proposed approach in\nenhancing privacy while maintaining vital sign monitoring.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T15:28:07Z"}
{"aid":"http://arxiv.org/abs/2504.01837v1","title":"Cram√©r--Rao Inequalities for Several Generalized Fisher Information","summary":"The de Bruijn identity states that Fisher information is the half of the\nderivative of Shannon differential entropy along heat flow. In the same spirit,\nin this paper we introduce a generalized version of Fisher information, named\nas the R\\'enyi--Fisher information, which is the half of the derivative of\nR\\'enyi information along heat flow. Based on this R\\'enyi--Fisher information,\nwe establish sharp R\\'enyi-entropic isoperimetric inequalities, which\ngeneralize the classic entropic isoperimetric inequality to the R\\'enyi\nsetting. Utilizing these isoperimetric inequalities, we extend the classical\nCram\\'er--Rao inequality from Fisher information to R\\'enyi--Fisher\ninformation. Lastly, we use these generalized Cram\\'er--Rao inequalities to\ndetermine the signs of derivatives of entropy along heat flow, strengthening\nexisting results on the complete monotonicity of entropy.","main_category":"cs.IT","categories":"cs.IT,math.IT,math.PR,math.ST,stat.TH","published":"2025-04-02T15:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.01840v1","title":"LARGE: Legal Retrieval Augmented Generation Evaluation Tool","summary":"Recently, building retrieval-augmented generation (RAG) systems to enhance\nthe capability of large language models (LLMs) has become a common practice.\nEspecially in the legal domain, previous judicial decisions play a significant\nrole under the doctrine of stare decisis which emphasizes the importance of\nmaking decisions based on (retrieved) prior documents. However, the overall\nperformance of RAG system depends on many components: (1) retrieval corpora,\n(2) retrieval algorithms, (3) rerankers, (4) LLM backbones, and (5) evaluation\nmetrics. Here we propose LRAGE, an open-source tool for holistic evaluation of\nRAG systems focusing on the legal domain. LRAGE provides GUI and CLI interfaces\nto facilitate seamless experiments and investigate how changes in the\naforementioned five components affect the overall accuracy. We validated LRAGE\nusing multilingual legal benches including Korean (KBL), English (LegalBench),\nand Chinese (LawBench) by demonstrating how the overall accuracy changes when\nvarying the five components mentioned above. The source code is available at\nhttps://github.com/hoorangyee/LRAGE.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T15:45:03Z"}
{"aid":"http://arxiv.org/abs/2504.01852v1","title":"Deciphering the Nature of Virgil: An Obscured AGN Lurking Within an\n  Apparently Normal Lyman-Œ± Emitter During Cosmic Reionization","summary":"We present a comprehensive analysis of the MIRI Extremely Red Object Virgil,\na Lyman-$\\alpha$ emitter at $z_{spec} = 6.6379 \\pm 0.0035$ with the photometric\nproperties of a Little Red Dot. Leveraging new JWST/MIRI imaging from the MIDIS\nand PAHSPECS programs, we confirm Virgil's extraordinary nature among galaxies\nin JADES/GOODS-South, exhibiting a strikingly red NIRCam-to-MIRI color (F444W\n$-$ F1500W = $2.84\\pm0.04$~mag). Deep NIRSpec/PRISM spectroscopy from the OASIS\nprogram offers key insights into the host galaxy, revealing properties of an\naverage star-forming galaxy during Cosmic Reionization, such as a subsolar\nmetallicity, low-to-moderate dust content, and a relatively high ionization\nparameter and electron temperature. By estimating the star formation rate of\nVirgil from UV and H$\\alpha$, we find evidence that the galaxy is either\nentering or fading out of a bursty episode. Although line-ratio diagnostics\nemployed at high-$z$ would classify Virgil as an Active Galactic Nucleus (AGN),\nthis classification becomes ambiguous once redshift evolution is considered.\nNonetheless, Virgil occupies the same parameter space as recently confirmed\nAGNs at similar redshifts. The new deep MIRI data at 15~$\\mu$m reinforce the\nAGN nature of Virgil, as inferred from multiple spectral energy distribution\n(SED) fitting codes. Virgil's rising infrared SED and UV excess resemble those\nof Dust-Obscured Galaxies (DOGs) studied with Spitzer at Cosmic Noon,\nparticularly blue-excess HotDOGs. Our results highlight the need for a\nmulti-wavelength approach incorporating MIRI to uncover such extreme sources at\n$z\\gtrsim6$ and to shed light on the interplay between galaxy evolution and\nearly black hole growth during Cosmic Reionization.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-02T16:04:22Z"}
{"aid":"http://arxiv.org/abs/2504.01853v1","title":"Implications of recent LHCb data on CPV in b-baryon four body decays","summary":"Motivated by the recent CPV observation, we investigate the CPV of b-baryon\ncharmless four body decays under the U-spin symmetry. However, we find that\nonly U-spin symmetry cannot provide effective predictions, particularly for\n$\\Lambda_b$ decays. For giving more useful predictions, we also give a simple\ndynamic analysis. By counting the\npower($\\lambda=\\sqrt{\\frac{\\Lambda_{QCD}}{m_b}}$) of each topological diagram,\nwe find that for the specific decay $B_b^2\\to R(B_1^2 M^2 M^{\\bar 2})M^2$, only\none U-spin amplitude can contribute in the leading power. Then the effective\nprediction can be given as \\begin{align}\n  A_{CP}^{dir}(\\Lambda_b^0 \\to R( p \\pi^- \\pi^+ )\\pi^-) = (-12.98 \\pm\n2.85)\\%.\\notag \\end{align} Considering the $\\Lambda_b$ can effectively produced\nin LHCb, we strongly encourage a more precise experimental investigation of it.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-02T16:05:00Z"}
{"aid":"http://arxiv.org/abs/2504.01883v1","title":"CoRAG: Collaborative Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) models excel in knowledge-intensive\ntasks, especially under few-shot learning constraints. We introduce CoRAG, a\nframework extending RAG to collaborative settings, where clients jointly train\na shared model using a collaborative passage store. To evaluate CoRAG, we\nintroduce CRAB, a benchmark for collaborative homogeneous open-domain question\nanswering. Our experiments demonstrate that CoRAG consistently outperforms both\nparametric collaborative learning methods and locally trained RAG models in\nlow-resource scenarios. Further analysis reveals the critical importance of\nrelevant passages within the shared store, the surprising benefits of\nincorporating irrelevant passages, and the potential for hard negatives to\nnegatively impact performance. This introduces a novel consideration in\ncollaborative RAG: the trade-off between leveraging a collectively enriched\nknowledge base and the potential risk of incorporating detrimental passages\nfrom other clients. Our findings underscore the viability of CoRAG, while also\nhighlighting key design challenges and promising avenues for future research.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-02T16:40:43Z"}
{"aid":"http://arxiv.org/abs/2504.01945v1","title":"Gluing moduli spaces of quantum toric stacks via secondary fan","summary":"The extension from toric varieties to quantum toric stacks allows for the\nstudy of moduli spaces of toric objects with fixed combinatorial structures, as\nwe now consider general finitely generated subgroups of $\\mathbb{R}^n$ as\n\"lattices.\" This paper aims to construct a moduli space that encompasses all\nsuch moduli spaces for a given dimension of the ambient space. To achieve this,\nwe adapt the construction of the secondary fan within the quantum framework.\nThis approach provides a description of wall-crossings between different moduli\nspaces, analogous to those observed in LVMB manifolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T17:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.01951v1","title":"The LLM Wears Prada: Analysing Gender Bias and Stereotypes through\n  Online Shopping Data","summary":"With the wide and cross-domain adoption of Large Language Models, it becomes\ncrucial to assess to which extent the statistical correlations in training\ndata, which underlie their impressive performance, hide subtle and potentially\ntroubling biases. Gender bias in LLMs has been widely investigated from the\nperspectives of works, hobbies, and emotions typically associated with a\nspecific gender. In this study, we introduce a novel perspective. We\ninvestigate whether LLMs can predict an individual's gender based solely on\nonline shopping histories and whether these predictions are influenced by\ngender biases and stereotypes. Using a dataset of historical online purchases\nfrom users in the United States, we evaluate the ability of six LLMs to\nclassify gender and we then analyze their reasoning and products-gender\nco-occurrences. Results indicate that while models can infer gender with\nmoderate accuracy, their decisions are often rooted in stereotypical\nassociations between product categories and gender. Furthermore, explicit\ninstructions to avoid bias reduce the certainty of model predictions, but do\nnot eliminate stereotypical patterns. Our findings highlight the persistent\nnature of gender biases in LLMs and emphasize the need for robust\nbias-mitigation strategies.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CY","published":"2025-04-02T17:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.01960v1","title":"Diffusion-Guided Gaussian Splatting for Large-Scale Unconstrained 3D\n  Reconstruction and Novel View Synthesis","summary":"Recent advancements in 3D Gaussian Splatting (3DGS) and Neural Radiance\nFields (NeRF) have achieved impressive results in real-time 3D reconstruction\nand novel view synthesis. However, these methods struggle in large-scale,\nunconstrained environments where sparse and uneven input coverage, transient\nocclusions, appearance variability, and inconsistent camera settings lead to\ndegraded quality. We propose GS-Diff, a novel 3DGS framework guided by a\nmulti-view diffusion model to address these limitations. By generating\npseudo-observations conditioned on multi-view inputs, our method transforms\nunder-constrained 3D reconstruction problems into well-posed ones, enabling\nrobust optimization even with sparse data. GS-Diff further integrates several\nenhancements, including appearance embedding, monocular depth priors, dynamic\nobject modeling, anisotropy regularization, and advanced rasterization\ntechniques, to tackle geometric and photometric challenges in real-world\nsettings. Experiments on four benchmarks demonstrate that GS-Diff consistently\noutperforms state-of-the-art baselines by significant margins.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-02T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.02270v1","title":"MinkOcc: Towards real-time label-efficient semantic occupancy prediction","summary":"Developing 3D semantic occupancy prediction models often relies on dense 3D\nannotations for supervised learning, a process that is both labor and\nresource-intensive, underscoring the need for label-efficient or even\nlabel-free approaches. To address this, we introduce MinkOcc, a multi-modal 3D\nsemantic occupancy prediction framework for cameras and LiDARs that proposes a\ntwo-step semi-supervised training procedure. Here, a small dataset of\nexplicitly 3D annotations warm-starts the training process; then, the\nsupervision is continued by simpler-to-annotate accumulated LiDAR sweeps and\nimages -- semantically labelled through vision foundational models. MinkOcc\neffectively utilizes these sensor-rich supervisory cues and reduces reliance on\nmanual labeling by 90\\% while maintaining competitive accuracy. In addition,\nthe proposed model incorporates information from LiDAR and camera data through\nearly fusion and leverages sparse convolution networks for real-time\nprediction. With its efficiency in both supervision and computation, we aim to\nextend MinkOcc beyond curated datasets, enabling broader real-world deployment\nof 3D semantic occupancy prediction in autonomous driving.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-03T04:31:56Z"}
{"aid":"http://arxiv.org/abs/2504.02303v1","title":"Diversifying halo structures in two-component self-interacting dark\n  matter models via mass segregation","summary":"Self-interacting dark matter (SIDM), through gravothermal evolution driven by\nelastic self-scatterings, offers a compelling explanation for the observed\ndiversity of inner halo densities. In this work, we investigate SIDM dynamics\nin a two-component dark matter model with mass ratios of order unity, motivated\nby an asymmetric dark matter framework that naturally evades constraints from\nrelic abundance and mediator decay, while enabling strong, velocity-dependent\nself-interactions. We show that cross-component scatterings significantly\nenhance mass segregation, driving the formation of dense, core collapsed-like\nhalos. This effect couples naturally to SIDM-induced diversity, introducing a\nnew mechanism for generating structural variations beyond those arising from\ngravothermal evolution alone. Our results reveal a novel mechanism for\nreconciling SIDM with small-scale observational tensions by enabling shifts in\ncentral densities while preserving the flexibility to generate diverse halo\nstructures. We further highlight that halo structural diversity may serve as a\ndiagnostic of dark sector composition, opening a new observational window into\nthe particle nature of SIDM.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-03T06:20:10Z"}
{"aid":"http://arxiv.org/abs/2504.02322v1","title":"Distributed Log-driven Anomaly Detection System based on Evolving\n  Decision Making","summary":"Effective anomaly detection from logs is crucial for enhancing cybersecurity\ndefenses by enabling the early identification of threats. Despite advances in\nanomaly detection, existing systems often fall short in areas such as\npost-detection validation, scalability, and effective maintenance. These\nlimitations not only hinder the detection of new threats but also impair\noverall system performance. To address these challenges, we propose CEDLog, a\nnovel practical framework that integrates Elastic Weight Consolidation (EWC)\nfor continual learning and implements distributed computing for scalable\nprocessing by integrating Apache Airflow and Dask. In CEDLog, anomalies are\ndetected through the synthesis of Multi-layer Perceptron (MLP) and Graph\nConvolutional Networks (GCNs) using critical features present in event logs.\nThrough comparisons with update strategies on large-scale datasets, we\ndemonstrate the strengths of CEDLog, showcasing efficient updates and low false\npositives","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-03T06:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.02369v1","title":"Finding Diverse Solutions in Combinatorial Problems with a Distributive\n  Lattice Structure","summary":"We generalize the polynomial-time solvability of $k$-\\textsc{Diverse Minimum\ns-t Cuts} (De Berg et al., ISAAC'23) to a wider class of combinatorial problems\nwhose solution sets have a distributive lattice structure. We identify three\nstructural conditions that, when met by a problem, ensure that a $k$-sized\nmultiset of maximally-diverse solutions -- measured by the sum of pairwise\nHamming distances -- can be found in polynomial time. We apply this framework\nto obtain polynomial time algorithms for finding diverse minimum $s$-$t$ cuts\nand diverse stable matchings. Moreover, we show that the framework extends to\ntwo other natural measures of diversity. Lastly, we present a simpler\nalgorithmic framework for finding a largest set of pairwise disjoint solutions\nin problems that meet these structural conditions.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-03T08:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.02372v1","title":"Quantum Key Distribution over Complex Networks","summary":"There exist several initiatives worldwide to deploy quantum key distribution\n(QKD) over existing fibre networks and achieve quantum-safe security at large\nscales. To understand the overall QKD network performance, it is required to\ntransition from the analysis of individual links, as done so far, to the\ncharacterization of the network as a whole. In this work, we undertake this\nstudy by embedding QKD protocols on complex networks, which correctly model the\nexisting fiber networks. We focus on networks with trusted nodes and on\ncontinuous-variable (CV) schemes, which have much higher key rates than their\ndiscrete-variable (DV) counterparts. In the effective CV network, however, many\nof the unique properties of complex networks, such as small-worldness and the\npresence of hubs, are lost due to the fast decay of the key rate with physical\ndistance for CV systems. These properties can be restored when considering a\nhybrid network consisting of both CV and DV protocols, achieving at the same\ntime high average rate and inter-connectivity. Our work opens the path to the\nstudy of QKD complex networks in existing infrastructures.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,physics.soc-ph","published":"2025-04-03T08:05:44Z"}
{"aid":"http://arxiv.org/abs/2504.02381v1","title":"Fermat Distance-to-Measure: a robust Fermat-like metric","summary":"Given a probability measure with density, Fermat distances and density-driven\nmetrics are conformal transformation of the Euclidean metric that shrink\ndistances in high density areas and enlarge distances in low density areas.\nAlthough they have been widely studied and have shown to be useful in various\nmachine learning tasks, they are limited to measures with density (with respect\nto Lebesgue measure, or volume form on manifold). In this paper, by replacing\nthe density with the Distance-to-Measure, we introduce a new metric, the Fermat\nDistance-to-Measure, defined for any probability measure in R^d. We derive\nstrong stability properties for the Fermat Distance-to-Measure with respect to\nthe measure and propose an estimator from random sampling of the measure,\nfeaturing an explicit bound on its convergence speed.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-03T08:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.02382v1","title":"Benchmark of Segmentation Techniques for Pelvic Fracture in CT and\n  X-ray: Summary of the PENGWIN 2024 Challenge","summary":"The segmentation of pelvic fracture fragments in CT and X-ray images is\ncrucial for trauma diagnosis, surgical planning, and intraoperative guidance.\nHowever, accurately and efficiently delineating the bone fragments remains a\nsignificant challenge due to complex anatomy and imaging limitations. The\nPENGWIN challenge, organized as a MICCAI 2024 satellite event, aimed to advance\nautomated fracture segmentation by benchmarking state-of-the-art algorithms on\nthese complex tasks. A diverse dataset of 150 CT scans was collected from\nmultiple clinical centers, and a large set of simulated X-ray images was\ngenerated using the DeepDRR method. Final submissions from 16 teams worldwide\nwere evaluated under a rigorous multi-metric testing scheme. The top-performing\nCT algorithm achieved an average fragment-wise intersection over union (IoU) of\n0.930, demonstrating satisfactory accuracy. However, in the X-ray task, the\nbest algorithm attained an IoU of 0.774, highlighting the greater challenges\nposed by overlapping anatomical structures. Beyond the quantitative evaluation,\nthe challenge revealed methodological diversity in algorithm design. Variations\nin instance representation, such as primary-secondary classification versus\nboundary-core separation, led to differing segmentation strategies. Despite\npromising results, the challenge also exposed inherent uncertainties in\nfragment definition, particularly in cases of incomplete fractures. These\nfindings suggest that interactive segmentation approaches, integrating human\ndecision-making with task-relevant information, may be essential for improving\nmodel reliability and clinical applicability.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-03T08:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.02422v1","title":"Applying Space-Group Symmetry to Speed up Hybrid-Functional-Based\n  Calculations with Numerical Atomic Orbitals","summary":"Building upon the efficient implementation of hybrid density functionals\n(HDFs) for large-scale periodic systems within the framework of numerical\natomic orbital bases using the localized resolution of identity (RI) technique,\nwe have developed an algorithm that exploits the space group symmetry in key\noperation steps of HDF calculations, leading to further improvements in two\nways. First, the reduction of $\\mathbf{k}$-points in the Brillouin zone can\nreduce the number of Kohn-Sham equations to be solved. This necessitates the\ncorrect implementation of the rotation relation between the density matrices of\nequivalent $\\mathbf{k}$-points within the representation of atomic orbitals.\nSecond, the reduction of the real-space sector can accelerate the construction\nof the exact-exchange part of the Hamiltonian in real space. We have\nimplemented this algorithm in the ABACUS software interfaced with LibRI, and\ntested its performance for several types of crystal systems with different\nsymmetries. The expected speed-up is achieved in both aspects: the time of\nsolving the Kohn-Sham equations decreases in proportion with the reduction of\n$\\mathbf{k}$-points, while the construction of the Hamiltonian in real space is\nsped up by several times, with the degree of acceleration depending on the size\nand symmetry of the system.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-03T09:23:32Z"}
{"aid":"http://arxiv.org/abs/2504.02435v1","title":"Poisson-Voronoi percolation in higher rank","summary":"We show that the uniqueness thresholds for Poisson-Voronoi percolation in\nsymmetric spaces of connected higher rank semisimple Lie groups with property\n(T) converge to zero in the low-intensity limit. This phenomenon is\nfundamentally different from situations in which Poisson-Voronoi percolation\nhas previously been studied.\n  Our approach builds on a recent breakthrough of Fraczyk, Mellick and Wilkens\n(arXiv:2307.01194) and provides an alternative proof strategy for Gaboriau's\nfixed price problem. As a further application of our result, we give a new\nclass of examples of non-amenable Cayley graphs that admit factor of iid bond\npercolations with a unique infinite cluster and arbitrarily small expected\ndegree, answering a question inspired by Hutchcroft-Pete (Invent. math. 221\n(2020)).}","main_category":"math.PR","categories":"math.PR,math.GR","published":"2025-04-03T09:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.02460v1","title":"Finite steady-state current defies non-Hermitian many-body localization","summary":"Non-Hermitian many-body localization (NH MBL) has emerged as a possible\nscenario for stable localization in open systems, as suggested by spectral\nindicators identifying a putative transition for finite system sizes.\n  In this work, we shift the focus to dynamical probes, specifically the\nsteady-state spin current, to investigate transport properties in a disordered,\nnon-Hermitian XXZ spin chain. Through exact diagonalization for small systems\nand tensor-network methods for larger chains, we demonstrate that the\nsteady-state current remains finite and decays exponentially with disorder\nstrength, showing no evidence of a transition up to disorder values far beyond\nthe previously claimed critical point. Our results reveal a stark discrepancy\nbetween spectral indicators, which suggest localization, and transport\nbehavior, which indicates delocalization. This highlights the importance of\ndynamical observables in characterizing NH MBL and suggests that traditional\nspectral measures may not fully capture the physics of non-Hermitian systems.\n  Additionally, we observe a non-commutativity of limits in system size and\ntime, further complicating the interpretation of finite-size studies. These\nfindings challenge the existence of NH MBL in the studied model and underscore\nthe need for alternative approaches to understand localization in non-Hermitian\nsettings.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,quant-ph","published":"2025-04-03T10:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.02461v1","title":"Am I Being Treated Fairly? A Conceptual Framework for Individuals to\n  Ascertain Fairness","summary":"Current fairness metrics and mitigation techniques provide tools for\npractitioners to asses how non-discriminatory Automatic Decision Making (ADM)\nsystems are. What if I, as an individual facing a decision taken by an ADM\nsystem, would like to know: Am I being treated fairly? We explore how to create\nthe affordance for users to be able to ask this question of ADM. In this paper,\nwe argue for the reification of fairness not only as a property of ADM, but\nalso as an epistemic right of an individual to acquire information about the\ndecisions that affect them and use that information to contest and seek\neffective redress against those decisions, in case they are proven to be\ndiscriminatory. We examine key concepts from existing research not only in\nalgorithmic fairness but also in explainable artificial intelligence,\naccountability, and contestability. Integrating notions from these domains, we\npropose a conceptual framework to ascertain fairness by combining different\ntools that empower the end-users of ADM systems. Our framework shifts the focus\nfrom technical solutions aimed at practitioners to mechanisms that enable\nindividuals to understand, challenge, and verify the fairness of decisions, and\nalso serves as a blueprint for organizations and policymakers, bridging the gap\nbetween technical requirements and practical, user-centered accountability.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC,cs.LG,cs.MA","published":"2025-04-03T10:28:19Z"}
{"aid":"http://arxiv.org/abs/2504.02466v1","title":"Optimal first-passage times of active Brownian particles under\n  stochastic resetting","summary":"We study the first-passage-time (FPT) properties of an active Brownian\nparticle under stochastic resetting to its initial configuration, comprising\nits position and orientation, to reach an absorbing wall in two dimensions.\nCoupling a perturbative approach for low P\\'eclet numbers, measuring the\nrelative importance of self-propulsion with respect to diffusion, with the\nrenewal framework for the stochastic resetting process, we derive analytical\nexpressions for the survival probability, the FPT probability density, and the\nassociated low-order moments. Depending on their initial orientation, the\nminimal mean FPT for active particles to reach the boundary can both decrease\nand increase relative to the passive counterpart. The associated optimal\nresetting rates depend non-trivially on the initial distance to the boundary\ndue to the intricate interplay of resetting, rotational Brownian noise, and\nactive motion.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech,physics.bio-ph","published":"2025-04-03T10:36:32Z"}
{"aid":"http://arxiv.org/abs/2504.02474v1","title":"Rigid m-percolation in limited-valence gels","summary":"Determining the onset of rigidity in gels is a fundamental challenge with\nsignificant practical implications across different applications.\nLimited-valence, or patchy-particle systems have proven to be a valuable model\nto study the relationship between microscopic interactions and macroscopic\nmechanical properties. It has been suggested that the emergence of rigidity\ncoincides with the formation of an infinitely spanning cluster of particles\nwith at least three bonds. This work explores this hypothesis, its\nimplications, and its broader applicability across a range of system\nparameters, by associating the emergence of rigidity with m-percolation\ntransition for m=3. The properties of m-percolation are developed using a\nmean-field theoretical approach validated with numerical simulations, and used\nto build phase and rigidity diagrams for different particle valences of both\nsingle-component systems and binary mixtures of patchy particles. The\ndifference between connectivity and rigidity percolation thresholds is found to\nreduce with increasing valence, providing an explanation for the challenges\nencountered in experimental attempts to distinguish isotropic connectivity\npercolation from the onset of rigidity. For binary mixtures, we found a robust\nminimum average valence, below which the gel is never rigid.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T10:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.02476v1","title":"Globular cluster distributions as a dynamical probe of dark matter","summary":"Globular clusters (GCs) act as massive probe particles traversing the dark\nmatter halos of their host galaxies. Gravitational dynamical friction due to\nhalo particles causes GC orbits to contract over time, providing a beyond-mean\nfield test of the cold dark matter paradigm. We explore the information content\nof such systems, using N-body and semianalytic simulations and scanning over a\nrange of initial conditions. We consider data from the ultradiffuse galaxies\nNGC5846-UDG1 and UDG-DF44, and from the Fornax dwarf spheroidal galaxy. The GC\nsystems of UDG1 and Fornax indicate the presence of dark matter halos,\nindependent of (but consistent with) stellar kinematics data. UDG-DF44 is too\ndiffuse for dynamical friction to give strong constraints. Our analysis can be\nextended to many additional galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA,hep-ph","published":"2025-04-03T10:53:02Z"}
{"aid":"http://arxiv.org/abs/2504.02504v1","title":"Ethics of Blockchain Technologies","summary":"This chapter explores three key questions in blockchain ethics. First, it\nsituates blockchain ethics within the broader field of technology ethics,\noutlining its goals and guiding principles. Second, it examines the unique\nethical challenges of blockchain applications, including permissionless\nsystems, incentive mechanisms, and privacy concerns. Key obstacles, such as\nconceptual modeling and information asymmetries, are identified as critical\nissues. Finally, the chapter argues that blockchain ethics should be approached\nas an engineering discipline, emphasizing the analysis and design of trade-offs\nin complex systems.","main_category":"cs.CY","categories":"cs.CY,cs.DC","published":"2025-04-03T11:36:12Z"}
{"aid":"http://arxiv.org/abs/2504.02511v1","title":"Analytical Discovery of Manifold with Machine Learning","summary":"Understanding low-dimensional structures within high-dimensional data is\ncrucial for visualization, interpretation, and denoising in complex datasets.\nDespite the advancements in manifold learning techniques, key challenges-such\nas limited global insight and the lack of interpretable analytical\ndescriptions-remain unresolved. In this work, we introduce a novel framework,\nGAMLA (Global Analytical Manifold Learning using Auto-encoding). GAMLA employs\na two-round training process within an auto-encoding framework to derive both\ncharacter and complementary representations for the underlying manifold. With\nthe character representation, the manifold is represented by a parametric\nfunction which unfold the manifold to provide a global coordinate. While with\nthe complementary representation, an approximate explicit manifold description\nis developed, offering a global and analytical representation of smooth\nmanifolds underlying high-dimensional datasets. This enables the analytical\nderivation of geometric properties such as curvature and normal vectors.\nMoreover, we find the two representations together decompose the whole latent\nspace and can thus characterize the local spatial structure surrounding the\nmanifold, proving particularly effective in anomaly detection and\ncategorization. Through extensive experiments on benchmark datasets and\nreal-world applications, GAMLA demonstrates its ability to achieve\ncomputational efficiency and interpretability while providing precise geometric\nand structural insights. This framework bridges the gap between data-driven\nmanifold learning and analytical geometry, presenting a versatile tool for\nexploring the intrinsic properties of complex data sets.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-03T11:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.02519v1","title":"Data-Driven Object Tracking: Integrating Modular Neural Networks into a\n  Kalman Framework","summary":"This paper presents novel Machine Learning (ML) methodologies for\nMulti-Object Tracking (MOT), specifically designed to meet the increasing\ncomplexity and precision demands of Advanced Driver Assistance Systems (ADAS).\nWe introduce three Neural Network (NN) models that address key challenges in\nMOT: (i) the Single-Prediction Network (SPENT) for trajectory prediction, (ii)\nthe Single-Association Network (SANT) for mapping individual Sensor Object (SO)\nto existing tracks, and (iii) the Multi-Association Network (MANTa) for\nassociating multiple SOs to multiple tracks. These models are seamlessly\nintegrated into a traditional Kalman Filter (KF) framework, maintaining the\nsystem's modularity by replacing relevant components without disrupting the\noverall architecture. Importantly, all three networks are designed to be run in\na realtime, embedded environment. Each network contains less than 50k trainable\nparameters. Our evaluation, conducted on the public KITTI tracking dataset,\ndemonstrates significant improvements in tracking performance. SPENT reduces\nthe Root Mean Square Error (RMSE) by 50% compared to a standard KF, while SANT\nand MANTa achieve up to 95% accuracy in sensor object-to-track assignments.\nThese results underscore the effectiveness of incorporating task-specific NNs\ninto traditional tracking systems, boosting performance and robustness while\npreserving modularity, maintainability, and interpretability.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T12:13:38Z"}
{"aid":"http://arxiv.org/abs/2504.02540v1","title":"A 3D-1D-0D Multiscale Model of the Neuro-Glial-Vascular Unit for\n  Synaptic and Vascular Dynamics in the Dorsal Vagal Complex","summary":"Cerebral blood flow regulation is critical for brain function, and its\ndisruption is implicated in various neurological disorders. Many existing\nmodels do not fully capture the complex, multiscale interactions among neuronal\nactivity, astrocytic signaling, and vascular dynamics--especially in key\nbrainstem regions. In this work, we present a 3D-1D-0D multiscale computational\nframework for modeling the neuro-glial-vascular unit (NGVU) in the dorsal vagal\ncomplex (DVC). Our approach integrates a quadripartite synapse model--which\nrepresents the interplay among excitatory and inhibitory neurons, astrocytes,\nand vascular smooth muscle cells--with a hierarchical description of vascular\ndynamics that couples a three-dimensional microcirculatory network with a\none-dimensional macrocirculatory representation and a zero-dimensional synaptic\ncomponent. By linking neuronal spiking, astrocytic calcium and gliotransmitter\nsignaling, and vascular tone regulation, our model reproduces key features of\nfunctional hyperemia and elucidates the feedback loops that help maintain\ncerebral blood flow. Simulation results demonstrate that neurotransmitter\nrelease triggers astrocytic responses that modulate vessel radius to optimize\noxygen and nutrient delivery. This integrated framework, to our knowledge the\nfirst model to combine these elements for the NGVU in the DVC, provides a\nrobust and modular platform for future investigations into the pathophysiology\nof cerebral blood flow regulation and its role in autonomic control, including\nthe regulation of stomach function.","main_category":"q-bio.TO","categories":"q-bio.TO","published":"2025-04-03T12:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.02568v1","title":"Enhanced coherent terahertz emission from critical superconducting\n  fluctuations in YBa$_2$Cu$_3$O$_{6.6}$","summary":"Coherent terahertz (THz) emission is emerging as a powerful new tool to probe\nsymmetry breakings in quantum materials. This method relies on second order\noptical nonlinearities and is complementary to second harmonic generation\nspectroscopy. Here, we report coherent THz emission from Josephson plasmons in\nunderdoped YBa$_2$Cu$_3$O$_{6+x}$, and find that the amplitude of the emitted\nfield increases dramatically close to the superconducting transition\ntemperature, $T_C$. We show theoretically how emission is enhanced by critical\nsuperconducting fluctuations, a nonlinear analogue of critical opalescence.\nThis observation is expected to be of general importance for the study of many\nthermal and quantum phase transitions.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-03T13:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.02571v1","title":"D$^{0}$-meson-tagged jet axes difference in proton-proton collisions at\n  $\\mathbf{\\sqrt{\\textit{s}} = 5.02}$ TeV","summary":"Heavy-flavor quarks produced in proton-proton (pp) collisions provide a\nunique opportunity to investigate the evolution of quark-initiated parton\nshowers from initial hard scatterings to final-state hadrons. By examining jets\nthat contain heavy-flavor hadrons, this study explores the effects of both\nperturbative and non-perturbative QCD on jet formation and structure. The\nangular differences between various jet axes, $\\Delta R_{\\rm axis}$, offer\ninsight into the radiation patterns and fragmentation of charm quarks. The\nfirst measurement of D$^{0}$-tagged jet axes differences in pp collisions at\n$\\sqrt{s}=5.02$ TeV by the ALICE experiment at the LHC is presented for jets\nwith transverse momentum $p_{\\rm T}^{\\rm ch~jet} \\geq 10$ ${\\rm GeV}/c$ and\nD$^0$ mesons with $p_{\\rm T}^{\\rm D^{0}} \\geq 5$ ${\\rm GeV}/c$. In this\nD$^0$-meson-tagged jet measurement, three jet axis definitions, each with\ndifferent sensitivities to soft, wide-angle radiation, are used: the Standard\naxis, Soft Drop groomed axis, and Winner-Takes-All axis. Measurements of the\nradial distributions of D$^0$ mesons with respect to the jet axes, $\\Delta\nR_{\\mathrm{axis-D^0}}$, are reported, along with the angle, $\\Delta\nR_{\\mathrm{axis}}$, between the three jet axes. The D$^{0}$ meson emerges as\nthe leading particle in these jets, closely aligning with the Winner-Takes-All\naxis and diverging from the Standard jet axis. The results also examine how\nvarying the sensitivity to soft radiation with grooming influences the\norientation of the Soft Drop jet axis, and uncover that charm-jet structure is\nmore likely to survive grooming when the Soft Drop axis is further from the\nD$^{0}$ direction, providing further evidence of the dead-cone effect recently\nmeasured by ALICE.","main_category":"hep-ex","categories":"hep-ex,nucl-ex","published":"2025-04-03T13:37:15Z"}
{"aid":"http://arxiv.org/abs/2504.02596v1","title":"Cosmic ray ionisation of a post-impact early Earth atmosphere: Solar\n  cosmic ray ionisation must be considered in origin-of-life scenarios","summary":"Cosmic rays (CR), both solar and Galactic, have an ionising effect on the\nEarth's atmosphere and are thought to be important for prebiotic molecule\nproduction. In particular, the $\\rm{H_2}$-dominated atmosphere following an\nocean-vaporising impact is considered favourable to prebiotic molecule\nformation. We model solar and Galactic CR transport through a post-impact early\nEarth atmosphere at 200Myr. We aim to identify the differences in the resulting\nionisation rates, $\\zeta$, particularly at the Earth's surface during a period\nwhen the Sun was very active. We use a Monte Carlo model to describe CR\ntransport through the early Earth atmosphere, giving the CR spectra as a\nfunction of altitude. We calculate $\\zeta$ and the ion-pair production rate,\n$Q$, as a function of altitude due to Galactic and solar CR. The Galactic and\nsolar CR spectra are both affected by the Sun's rotation rate, $\\Omega$,\nbecause the solar wind velocity and magnetic field strength both depend on\n$\\Omega$ and influence CR transport. We consider a range of input spectra\nresulting from the range of possible $\\Omega$, from $3.5-15\\,\n\\Omega_{\\rm{\\odot}}$. To account for the possibility that the Galactic CR\nspectrum outside the Solar System varies over Gyr timescales, we compare\ntop-of-atmosphere $\\zeta$ resulting from two different scenarios. We also\nconsider the suppression of the CR spectra by a planetary magnetic field. We\nfind that $\\zeta$ and $Q$ due to CR are dominated by solar CR in the early\nEarth atmosphere for most cases. The corresponding $\\zeta$ at the early Earth's\nsurface ranges from $5 \\times 10^{-21}\\rm{s^{-1}}$ for $\\Omega =\n3.5\\,\\Omega_{\\rm{\\odot}}$ to $1 \\times 10^{-16}\\rm{s^{-1}}$ for $\\Omega =\n15\\,\\Omega_{\\rm{\\odot}}$. Thus if the young Sun was a fast rotator, it is\nlikely that solar CR had a significant effect on the chemistry at the Earth's\nsurface at the time when life is likely to have formed.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR,physics.space-ph","published":"2025-04-03T13:59:09Z"}
{"aid":"http://arxiv.org/abs/2504.02598v1","title":"Graphs are everywhere -- Psst! In Music Recommendation too","summary":"In recent years, graphs have gained prominence across various domains,\nespecially in recommendation systems. Within the realm of music recommendation,\ngraphs play a crucial role in enhancing genre-based recommendations by\nintegrating Mel-Frequency Cepstral Coefficients (MFCC) with advanced graph\nembeddings. This study explores the efficacy of Graph Convolutional Networks\n(GCN), GraphSAGE, and Graph Transformer (GT) models in learning embeddings that\neffectively capture intricate relationships between music items and genres\nrepresented within graph structures. Through comprehensive empirical\nevaluations on diverse real-world music datasets, our findings consistently\ndemonstrate that these graph-based approaches outperform traditional methods\nthat rely solely on MFCC features or collaborative filtering techniques.\nSpecifically, the graph-enhanced models achieve notably higher accuracy in\npredicting genre-specific preferences and offering relevant music suggestions\nto users. These results underscore the effectiveness of utilizing graph\nembeddings to enrich feature representations and exploit latent associations\nwithin music data, thereby illustrating their potential to advance the\ncapabilities of personalized and context-aware music recommendation systems.\nKeywords: graphs, recommendation systems, neural networks, MFCC","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-03T14:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.02601v1","title":"The Homotopy Category of Strongly flat modules","summary":"In this paper, we plan to build upon significant results by Amnon Neeman\nregarding the homotopy category of flat modules to study\n${\\mathbb{K}}({S\\rm{SF}}\\mbox{-}R)$, the homotopy category of $S$-strongly flat\nmodules, where $S$ is a multiplicatively closed subset of a commutative ring\n$R$. The category ${\\mathbb{K}}({S\\rm{SF}}\\mbox{-}R)$ is an intermediate\ntriangulated category that includes ${\\mathbb{K}}({\\rm{Prj}\\mbox{-}} R)$, the\nhomotopy category of projective $R$-modules, which is always well generated by\na result of Neeman, and is included in ${\\mathbb{K}}({\\rm{Flat}}\\mbox{-} R)$,\nthe homotopy category of flat $R$-modules, which is well generated if and only\nif $R$ is perfect, by a result of \\v{S}\\'{t}ov\\'{i}\\v{c}ek. We analyze\ncorresponding inclusion functors and the existence of their adjoints. In this\nway, we provide a new, fully faithful embedding of the homotopy category of\nprojectives to the homotopy category of $S$-strongly flat modules. We introduce\nthe notion of $S$-almost well generated triangulated categories. If $R$ is an\n$S$-almost perfect ring, ${\\mathbb{K}}({\\rm{Flat}}\\mbox{-} R)$ is $S$-almost\nwell generated. We show that the converse is true under certain conditions on\nthe ring $R$. We hope that this approach provides insights into the largely\nmysterious class of $S$-strongly flat modules.","main_category":"math.AC","categories":"math.AC,math.RT","published":"2025-04-03T14:03:52Z"}
{"aid":"http://arxiv.org/abs/2504.02608v1","title":"Input to the European Strategy for Particle Physics: Strong-Field\n  Quantum Electrodynamics","summary":"This document sets out the intention of the strong-field QED community to\ncarry out, both experimentally and numerically, high-statistics parametric\nstudies of quantum electrodynamics in the non-perturbative regime, at fields\napproaching and exceeding the critical or `Schwinger' field of QED. In this\nregime, several exotic and fascinating phenomena are predicted to occur that\nhave never been directly observed in the laboratory. These include\nBreit-Wheeler pair production, vacuum birefringence, and quantum radiation\nreaction. This experimental program will also serve as a stepping stone towards\nstudies of elusive phenomena such as elastic scattering of real photons and the\nconjectured perturbative breakdown of QED at extreme fields. State-of-the-art\nhigh-power laser facilities in Europe and beyond are starting to offer unique\nopportunities to study this uncharted regime at the intensity frontier, which\nis highly relevant also for the design of future multi-TeV lepton colliders.\nHowever, a transition from qualitative observational experiments to\nquantitative and high-statistics measurements can only be performed with\nlarge-scale collaborations and with systematic experimental programs devoted to\nthe optimisation of several aspects of these complex experiments, including\ndetector developments, stability and tolerances studies, and laser technology.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T14:10:23Z"}
{"aid":"http://arxiv.org/abs/2504.02610v1","title":"Do evidence-based active-engagement courses reduce the gender gap in\n  introductory physics?","summary":"Prior research suggests that using evidence-based pedagogies can not only\nimprove learning for all students, it can also reduce the gender gap. We\ndescribe the impact of physics education research based pedagogical techniques\nin flipped and active-engagement non-flipped courses on the gender gap observed\nwith validated conceptual surveys. We compare male and female students'\nperformance in courses which make significant use of evidence-based active\nengagement (EBAE) strategies with courses that primarily use lecture-based (LB)\ninstruction. The analysis presented here includes data from two-semester\nsequences of introductory algebra-based and calculus-based introductory physics\ncourses. The surveys used to assess student learning in the first and second\nsemester courses were the Force Concept Inventory and the Conceptual Survey of\nElectricity and Magnetism, respectively. The performance of male and female\nstudents in EBAE courses at a particular level is compared with LB courses in\ntwo situations: (I) the same instructor taught two courses, one of which was an\nEBAE course and the other an LB course, while the homework, recitations and\nfinal exams were kept the same, (II) student performance in all of the EBAE\ncourses taught by different instructors was averaged and compared with LB\ncourses of the same type also averaged over different instructors. In all\ncases, we find that students in courses which make significant use of EBAE\nstrategies, on average, outperformed students in courses of the same type using\nprimarily LB instruction even though there was no statistically significant\ndifference on the pretest before instruction. However, the gender gap persisted\neven in courses using EBAE methods. We also discuss correlations between the\nperformance of male and female students on the validated conceptual surveys and\nthe final exam, which had a heavy weight on quantitative problem solving.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-03T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.02639v1","title":"Reservoir Computing: A New Paradigm for Neural Networks","summary":"A Literature Review of Reservoir Computing.\n  Even before Artificial Intelligence was its own field of computational\nscience, humanity has tried to mimic the activity of the human brain. In the\nearly 1940s the first artificial neuron models were created as purely\nmathematical concepts. Over the years, ideas from neuroscience and computer\nscience were used to develop the modern Neural Network. The interest in these\nmodels rose quickly but fell when they failed to be successfully applied to\npractical applications, and rose again in the late 2000s with the drastic\nincrease in computing power, notably in the field of natural language\nprocessing, for example with the state-of-the-art speech recognizer making\nheavy use of deep neural networks.\n  Recurrent Neural Networks (RNNs), a class of neural networks with cycles in\nthe network, exacerbates the difficulties of traditional neural nets. Slow\nconvergence limiting the use to small networks, and difficulty to train through\ngradient-descent methods because of the recurrent dynamics have hindered\nresearch on RNNs, yet their biological plausibility and their capability to\nmodel dynamical systems over simple functions makes then interesting for\ncomputational researchers.\n  Reservoir Computing emerges as a solution to these problems that RNNs\ntraditionally face. Promising to be both theoretically sound and\ncomputationally fast, Reservoir Computing has already been applied successfully\nto numerous fields: natural language processing, computational biology and\nneuroscience, robotics, even physics. This survey will explore the history and\nappeal of both traditional feed-forward and recurrent neural networks, before\ndescribing the theory and models of this new reservoir computing paradigm.\nFinally recent papers using reservoir computing in a variety of scientific\nfields will be reviewed.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T14:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.02641v1","title":"Utilizing 5G NR SSB Blocks for Passive Detection and Localization of\n  Low-Altitude Drones","summary":"With the exponential growth of the unmanned aerial vehicle (UAV) industry and\na broad range of applications expected to appear in the coming years, the\nemployment of traditional radar systems is becoming increasingly cumbersome for\nUAV supervision. Motivated by this emerging challenge, this paper investigates\nthe feasibility of employing integrated sensing and communication (ISAC)\nsystems implemented over current and future wireless networks to perform this\ntask. We propose a sensing mechanism based on the synchronization signal block\n(SSB) in the fifth-generation (5G) standard that performs sensing in a passive\nbistatic setting. By assuming planar arrays at the sensing nodes and according\nto the 5G standard, we consider that the SSB signal is sent in a grid of\northogonal beams that are multiplexed in time, with some of them pointing\ntoward a surveillance region where low-altitude drones can be flying. The\nCramer-Rao Bound (CRB) is derived as the theoretical bound for range and\nvelocity estimation. Our results demonstrate the potential of employing SSB\nsignals for UAV-like target localization at low SNR.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-03T14:36:11Z"}
{"aid":"http://arxiv.org/abs/2504.02646v1","title":"Prompt Optimization with Logged Bandit Data","summary":"We study how to use naturally available user feedback, such as clicks, to\noptimize large language model (LLM) pipelines for generating personalized\nsentences using prompts. Naive approaches, which estimate the policy gradient\nin the prompt space, suffer either from variance caused by the large action\nspace of prompts or bias caused by inaccurate reward predictions. To circumvent\nthese challenges, we propose a novel kernel-based off-policy gradient method,\nwhich estimates the policy gradient by leveraging similarity among generated\nsentences, substantially reducing variance while suppressing the bias.\nEmpirical results on our newly established suite of benchmarks demonstrate the\neffectiveness of the proposed approach in generating personalized descriptions\nfor movie recommendations, particularly when the number of candidate prompts is\nlarge.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-03T14:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.02681v1","title":"Convergence of permuted products of exponentials","summary":"Let $\\{A_{i,n}\\}$ be a triangular array of elements in a Banach algebra,\nwhose norms do not grow too fast, and whose row averages converge to $A$. Let\n$\\sigma \\in S(n)$ be a permutation drawn uniformly at random. If the array only\ncontains $o(n / \\log n)$ distinct elements, then almost surely, for all $0 < s\n< t < 1$, the permuted product of their exponentials $\\prod_{i = [s n]}^{[t n]}\ne^{A_{\\sigma(i),n}/n}$ converges in norm to $e^{(t - s) A}$. For an array of\nfinite-dimensional matrices, convergence holds without this restriction. The\nproof of the latter result consists of an estimate valid in a general Banach\nalgebra, and an application of a matrix concentration inequality.","main_category":"math.FA","categories":"math.FA,math.PR","published":"2025-04-03T15:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.02684v1","title":"High Chern numbers and topological flat bands in high-field polarized\n  Kitaev magnets on the star lattice","summary":"The geometrically frustrated Kitaev magnets are demonstrated to be fertile\nplaygrounds that allow for the occurrence of exotic phenomena, including\ntopological phases and the thermal Hall effect. Notwithstanding the established\nconsensus that the field-polarized phase in the honeycomb-lattice Kitaev magnet\nhosts topological magnons exhibiting Chern numbers $C = \\pm1$, the nature of\nmagnon excitations in Kitaev magnets on the star lattice, a triangle-decorated\nhoneycomb lattice, has rarely been explored primarily due to its complicated\ngeometry. To this end, we study the band topology of magnons on the star\nlattice in the presence of a strong out-of-plane magnetic field using linear\nspin-wave theory. By calculating the Chern numbers of magnon bands, we find\nthat topological phase diagrams are predominantly composed of two distinct\ntopological phases whose Chern numbers are different by a sign in inverse\norder. Remarkably, each phase is characterized by a high Chern number of either\n$+2$ or $-2$. In addition, several topological flat bands with large flatness\nare identified. The two phases are separated by a dozen narrow topological\nhigh-Chern-number segments, whose region shrinks as the magnetic field\nincreases and vanishes eventually. We also find that the thermal Hall\nconductivity approaches zero at certain parameters, and it changes (keeps) its\nsign when crossing the topological phase-transition points (flat-band points).","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-03T15:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.02741v1","title":"A Complete Classification of Fourier Summation Formulas on the real line","summary":"We completely classify Fourier summation formulas of the form $$\n  \\int_{\\mathbb{R}} \\widehat{\\varphi}(t) d\\mu(t)=\\sum_{n=0}^{\\infty}\na(\\lambda_n)\\varphi(\\lambda_n), $$ that hold for any test function $\\varphi$,\nwhere $\\widehat\\varphi$ is the Fourier transform of $\\varphi$, $\\mu$ is a fixed\ncomplex measure on $\\mathbb{R}$ and $a:\\{\\lambda_n\\}_{n\\geq 0}\\to\\mathbb{C}$ is\na fixed function. We only assume the decay condition $$ \\int_{\\mathbb{R}}\n\\frac{d |\\mu|(t)}{(1+t^2)^{c_1}} + \\sum_{n\\geq 0} |a(\\lambda_n)|e^{-c_2\n|\\lambda_n|}<\\infty, $$ for some $c_1,c_2>0$. This completes the work initiated\nby the first author previously, where the condition $c_1\\leq 1$ was required.\nWe prove that any such pair $(\\mu,a)$ can be uniquely associated with a\nholomorphic map $F(z)$ in the upper-half space that is both almost periodic and\nbelongs to a certain higher index Nevanlinna class. The converse is also true:\nFor any such function $F$ it is possible to generate a Fourier summation pair\n$(\\mu,a)$. We provide important examples of such summation formulas not\ncontemplated by the previous results, such as Selberg's trace formula.","main_category":"math.CA","categories":"math.CA,math.MG,math.NT","published":"2025-04-03T16:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.02747v1","title":"GEOPARD: Geometric Pretraining for Articulation Prediction in 3D Shapes","summary":"We present GEOPARD, a transformer-based architecture for predicting\narticulation from a single static snapshot of a 3D shape. The key idea of our\nmethod is a pretraining strategy that allows our transformer to learn plausible\ncandidate articulations for 3D shapes based on a geometric-driven search\nwithout manual articulation annotation. The search automatically discovers\nphysically valid part motions that do not cause detachments or collisions with\nother shape parts. Our experiments indicate that this geometric pretraining\nstrategy, along with carefully designed choices in our transformer\narchitecture, yields state-of-the-art results in articulation inference in the\nPartNet-Mobility dataset.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-03T16:35:17Z"}
{"aid":"http://arxiv.org/abs/2504.02753v1","title":"Robust entangled photon generation by Floquet-engineered two-colour\n  pulses","summary":"Quantum emitters driven by resonant two-photon excitation are a leading\nsource for deterministically generated entangled photon pairs, essential for\nscalable photonic quantum technologies. However, conventional resonant schemes\nare highly sensitive to laser power fluctuations and pose additional\nexperimental challenges for emitters with small biexciton binding energies.\nHere, we demonstrate how biexciton preparation schemes with significantly\nimproved robustness and reduced laser filtering requirements can be identified\nusing a novel design principle beyond resonant and adiabatic driving: ultrafast\nall-optical Floquet engineering. This is achieved by employing two strongly and\nsymmetrically detuned dichromatic pulses, whose superposition generates a\nstroboscopic Hamiltonian that enables direct coupling between ground and\nbiexciton states. Moreover, a pulse delay serves as a tuning knob, introducing\nan effective magnetic field that concentrates the Bloch sphere trajectory at\nthe biexciton state for a wide range of parameters, making biexciton\npreparation particularly robust. Experimentally, we achieve a biexciton\noccupation exceeding 96% and preserve photon-pair entanglement with a fidelity\nof 93.4%. Our scheme highlights the great impact of Floquet-engineered\nmulticolour excitation protocols for on-demand quantum light sources.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-03T16:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.02757v1","title":"Echoes of the hidden: Uncovering coordination beyond network structure","summary":"The study of connectivity and coordination has drawn increasing attention in\nrecent decades due to their central role in driving markets, shaping societal\ndynamics, and influencing biological systems. Traditionally, observable\nconnections, such as phone calls, financial transactions, or social media\nconnections, have been used to infer coordination and connectivity. However,\nincomplete, encrypted, or fragmented data, alongside the ubiquity of\ncommunication platforms and deliberate obfuscation, often leave many real-world\nconnections hidden. In this study, we demonstrate that coordinating individuals\nexhibit shared bursty activity patterns, enabling their detection even when\nobservable links between them are sparse or entirely absent. We further propose\na generative model based on the network of networks formalism to account for\nthe mechanisms driving this collaborative burstiness, attributing it to shock\npropagation across networks rather than isolated individual behavior. Model\nsimulations demonstrate that when observable connection density is below 70\\%,\nburstiness significantly improves coordination detection compared to\nstate-of-the-art temporal and structural methods. This work provides a new\nperspective on community and coordination dynamics, advancing both theoretical\nunderstanding and practical detection. By laying the foundation for identifying\nhidden connections beyond observable network structures, it enables detection\nacross different platforms, alongside enhancing system behavior understanding,\ninformed decision-making, and risk mitigation.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-03T16:49:58Z"}
{"aid":"http://arxiv.org/abs/2504.02796v1","title":"Suppression of decoherence dynamics by a dissipative bath at strong\n  coupling","summary":"Control of decoherence in open quantum systems has become a topic of great\ninterest due to the emergence of quantum technologies that depend on quantum\ncoherent effects. In this work, we investigate the decoherence dynamics of\nsystems coupled to multiple baths through noncommuting systems' operators, and\nbeyond the weak system-bath coupling limit. By building on cooperative effects\nbetween baths, we propose a novel strategy to mitigate rapid decoherence.\nConcretely, we study the dynamics of a qubit coupled to multiple environments\nwith arbitrary interaction strengths, and along different coordinates. Based on\ninsights gained on the decoherence dynamics from the analytical Effective\nHamiltonian method, we carry out numerical simulations using the Reaction\nCoordinate quantum master equation method. In contrast to standard\nexpectations, we show that when the system strongly interacts with a decohering\nbath, increasing its coupling to a second, dissipative bath slows down the\ndecoherence dynamics. Our work offers insights into the preservation of quantum\ncoherences in open quantum systems based on frustration effects, by utilizing\ncooperative effects between different heat baths.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T17:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.02803v1","title":"Beyond Discretization: A Continuous-Time Framework for Event Generation\n  in Neuromorphic Pixels","summary":"A novel continuous-time framework is proposed for modeling neuromorphic image\nsensors in the form of an initial canonical representation with analytical\ntractability. Exact simulation algorithms are developed in parallel with\nclosed-form expressions that characterize the model's dynamics. This framework\nenables the generation of synthetic event streams in genuine continuous-time,\nwhich combined with the analytical results, reveal the underlying mechanisms\ndriving the oscillatory behavior of event data presented in the literature.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-03T17:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.02804v1","title":"Convergence of Ricci flow and long-time existence of Harmonic map heat\n  flow","summary":"For an ancient Ricci flow asymptotic to a compact integrable shrinker, or a\nRicci flow developing a finite-time singularity modelled on the shrinker, we\nestablish the long-time existence of a harmonic map heat flow between the Ricci\nflow and the shrinker for all times. This provides a global parabolic gauge for\nthe Ricci flow and implies the uniqueness of the tangent flow without modulo\nany diffeomorphisms.\n  We present two main applications: First, we construct and classify all\nancient Ricci flows asymptotic to any compact integrable shrinker, showing that\nthey converge exponentially. Second, we obtain the optimal convergence rate at\nsingularities modelled on the shrinker, characterized by the first negative\neigenvalue of the stability operator for the entropy. In particular, we show\nthat any Ricci flow developing a round $\\mathbb S^n$ singularity converges at\nleast at the rate $(-t)^{\\frac{n+1}{n-1}}$.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-03T17:50:14Z"}
{"aid":"http://arxiv.org/abs/2504.04747v1","title":"Two is Better than One: Efficient Ensemble Defense for Robust and\n  Compact Models","summary":"Deep learning-based computer vision systems adopt complex and large\narchitectures to improve performance, yet they face challenges in deployment on\nresource-constrained mobile and edge devices. To address this issue, model\ncompression techniques such as pruning, quantization, and matrix factorization\nhave been proposed; however, these compressed models are often highly\nvulnerable to adversarial attacks. We introduce the \\textbf{Efficient Ensemble\nDefense (EED)} technique, which diversifies the compression of a single base\nmodel based on different pruning importance scores and enhances ensemble\ndiversity to achieve high adversarial robustness and resource efficiency. EED\ndynamically determines the number of necessary sub-models during the inference\nstage, minimizing unnecessary computations while maintaining high robustness.\nOn the CIFAR-10 and SVHN datasets, EED demonstrated state-of-the-art robustness\nperformance compared to existing adversarial pruning techniques, along with an\ninference speed improvement of up to 1.86 times. This proves that EED is a\npowerful defense solution in resource-constrained environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T05:41:35Z"}
{"aid":"http://arxiv.org/abs/2504.04756v1","title":"Continuous Locomotive Crowd Behavior Generation","summary":"Modeling and reproducing crowd behaviors are important in various domains\nincluding psychology, robotics, transport engineering and virtual environments.\nConventional methods have focused on synthesizing momentary scenes, which have\ndifficulty in replicating the continuous nature of real-world crowds. In this\npaper, we introduce a novel method for automatically generating continuous,\nrealistic crowd trajectories with heterogeneous behaviors and interactions\namong individuals. We first design a crowd emitter model. To do this, we obtain\nspatial layouts from single input images, including a segmentation map,\nappearance map, population density map and population probability, prior to\ncrowd generation. The emitter then continually places individuals on the\ntimeline by assigning independent behavior characteristics such as agents'\ntype, pace, and start/end positions using diffusion models. Next, our crowd\nsimulator produces their long-term locomotions. To simulate diverse actions, it\ncan augment their behaviors based on a Markov chain. As a result, our overall\nframework populates the scenes with heterogeneous crowd behaviors by\nalternating between the proposed emitter and simulator. Note that all the\ncomponents in the proposed framework are user-controllable. Lastly, we propose\na benchmark protocol to evaluate the realism and quality of the generated\ncrowds in terms of the scene-level population dynamics and the individual-level\ntrajectory accuracy. We demonstrate that our approach effectively models\ndiverse crowd behavior patterns and generalizes well across different\ngeographical environments. Code is publicly available at\nhttps://github.com/InhwanBae/CrowdES .","main_category":"cs.CV","categories":"cs.CV,cs.LG,cs.RO","published":"2025-04-07T06:08:59Z"}
{"aid":"http://arxiv.org/abs/2504.04774v1","title":"BayesCPF: Enabling Collective Perception in Robot Swarms with Degrading\n  Sensors","summary":"The collective perception problem -- where a group of robots perceives its\nsurroundings and comes to a consensus on an environmental state -- is a\nfundamental problem in swarm robotics. Past works studying collective\nperception use either an entire robot swarm with perfect sensing or a swarm\nwith only a handful of malfunctioning members. A related study proposed an\nalgorithm that does account for an entire swarm of unreliable robots but\nassumes that the sensor faults are known and remain constant over time. To that\nend, we build on that study by proposing the Bayes Collective Perception Filter\n(BayesCPF) that enables robots with continuously degrading sensors to\naccurately estimate the fill ratio -- the rate at which an environmental\nfeature occurs. Our main contribution is the Extended Kalman Filter within the\nBayesCPF, which helps swarm robots calibrate for their time-varying sensor\ndegradation. We validate our method across different degradation models,\ninitial conditions, and environments in simulated and physical experiments. Our\nfindings show that, regardless of degradation model assumptions, fill ratio\nestimation using the BayesCPF is competitive to the case if the true sensor\naccuracy is known, especially when assumptions regarding the model and initial\nsensor accuracy levels are preserved.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T07:06:11Z"}
{"aid":"http://arxiv.org/abs/2504.04804v1","title":"DebGCD: Debiased Learning with Distribution Guidance for Generalized\n  Category Discovery","summary":"In this paper, we tackle the problem of Generalized Category Discovery (GCD).\nGiven a dataset containing both labelled and unlabelled images, the objective\nis to categorize all images in the unlabelled subset, irrespective of whether\nthey are from known or unknown classes. In GCD, an inherent label bias exists\nbetween known and unknown classes due to the lack of ground-truth labels for\nthe latter. State-of-the-art methods in GCD leverage parametric classifiers\ntrained through self-distillation with soft labels, leaving the bias issue\nunattended. Besides, they treat all unlabelled samples uniformly, neglecting\nvariations in certainty levels and resulting in suboptimal learning. Moreover,\nthe explicit identification of semantic distribution shifts between known and\nunknown classes, a vital aspect for effective GCD, has been neglected. To\naddress these challenges, we introduce DebGCD, a \\underline{Deb}iased learning\nwith distribution guidance framework for \\underline{GCD}. Initially, DebGCD\nco-trains an auxiliary debiased classifier in the same feature space as the GCD\nclassifier, progressively enhancing the GCD features. Moreover, we introduce a\nsemantic distribution detector in a separate feature space to implicitly boost\nthe learning efficacy of GCD. Additionally, we employ a curriculum learning\nstrategy based on semantic distribution certainty to steer the debiased\nlearning at an optimized pace. Thorough evaluations on GCD benchmarks\ndemonstrate the consistent state-of-the-art performance of our framework,\nhighlighting its superiority. Project page: https://visual-ai.github.io/debgcd/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.04811v1","title":"Cross-Frame OTFS Parameter Estimation Based On Chinese Remainder Theorem","summary":"Orthogonal time-frequency space (OTFS) is a potential waveform for integrated\nsensing and communications (ISAC) systems because it can manage communication\nand sensing metrics in one unified domain, and has better performance in high\nmobility scenarios. In practice, a target might come from far distance or with\nultra-high speed. However, the max unambiguous range and max tolerable velocity\nof OTFS-ISAC system is limited by the unambiguous round-trip delay and Doppler\nshift, which are related to OTFS frame, i.e., time slots and subcarrier\nspacing, respectively. To enlarge the sensing range, a novel OTFS cross-frame\nranging and velocity estimation model as well as its corresponding method based\non the Chinese remainder theorem (CRT) are proposed in this paper. By designing\nco-prime numbers of subcarriers and time slots in different subframes, the\ndifference in the responses of the subframes for a target can be used to\nestimate the distance and velocity of an out-of-range target. Several frame\nstructures are further designed for specific sensing scenarios, such as target\nwith ultra-high speed or at far distance. Simulation results show that the\nproposed method can achieve significantly better performance in NMSE compared\nwith the classic sensing methods under the condition of same time and frequency\nresources.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T08:05:32Z"}
{"aid":"http://arxiv.org/abs/2504.04820v1","title":"Dark energy under a gauge symmetry: A review of gauged quintessence and\n  its implications","summary":"We review the gauged quintessence scenario, wherein the quintessence scalar\nfield responsible for dark energy is promoted to a complex field charged under\na dark $U(1)$ gauge symmetry. This construction leads to new and potentially\nrich cosmological phenomenology. After a concise recap of the standard\nquintessence scenario, we highlight how a $U(1)$ gauge invariance alters the\ndynamics of the scalar and the associated dark gauge boson. We survey the\nevolution of both fields across cosmic history, discuss their possible\nproduction via a misalignment mechanism, and examine implications for the\nHubble tension. We also comment on potential non-gravitational signals of\ngauged quintessence through kinetic mixing (the dark photon vector portal).","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-07T08:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.04822v1","title":"How to build transfer matrices, one wave at a time","summary":"We show how to build the closed-form expression of transfer matrices for wave\npropagation in layered media. The key is to represent the propagation across\nthe piece-wise constant medium as a superposition of a finite number of paths\n($2^{N-1}$ paths for a medium with $N$ layers), each one of them contributing a\ncertain phase change (corresponding to signed sums of the phase change in each\nindividual layer) and amplitude change (corresponding to the pattern of\ntransmission and/or reflection associated to each path). The outlined technique\nis combinatorial in nature: it begins with the linear governing equations in\nfrequency domain, whose fundamental solution is known, then it enumerates the\nfinite number of paths across the overall system, then computes their\nassociated phase and amplitude change, and finally adds all the possible paths\nto find the final result. Beyond providing physical insight, this\n``path-by-path'' construction can also circumvent the need for transfer matrix\nnumerical multiplication in many practical applications, potentially enabling\nsubstantial computational savings.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cond-mat.other","published":"2025-04-07T08:22:38Z"}
{"aid":"http://arxiv.org/abs/2504.04830v1","title":"X-ray particle tracking velocimetry for rheological characterization:\n  Application to material extrusion additive manufacturing","summary":"We introduce X-ray Particle Tracking Velocimetry (XPTV) as a promising method\nto quantitatively resolve the velocity field and associated rheological\nquantities of polymer melt flow within the nozzle of a fused filament\nfabrication (FFF) printer. Employing tungsten powder as tracer particles\nembedded within a polymer filament, we investigate melt flow dynamics through\nan aluminum nozzle in a custom-designed experimental setup, based on commercial\ndesigns. The velocity profiles obtained via XPTV reveal significant deviations\nfrom classical Newtonian flow, highlighting complex heterogeneous and\nnon-isothermal behavior within the melt. From these measurements, we determine\nthe local infinitesimal strain rate tensor and correlate flow-induced\nnon-Newtonian effects to spatially varying temperature distributions,\nreflecting incomplete thermal homogenization within the nozzle. Our findings\ndemonstrate the capability of XPTV to quantify both velocity fields and\nrheological properties, underscoring its potential as a future tool for\ninvestigating opaque polymer melt flows in additive manufacturing, industrial\nprocessing, and rheology. To our knowledge, this represents the first reported\napplication of XPTV in polymer melt rheology, offering a new approach to\naddress measurement challenges previously inaccessible to conventional optical\nmethods.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-07T08:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.04832v1","title":"Pullback and Weil transfer on Chow groups","summary":"In the paper ``Weil transfer of algebraic cycles'', published by the second\nauthor in Indagationes Mathematicae about 25 years ago, a Weil transfer map for\nChow groups of smooth algebraic varieties has been constructed and its basic\nproperties have been established. The proof of commutativity with the pullback\nhomomorphisms given there used a variant of Moving Lemma suffering a lack of\nreference. Here we are providing an alternative proof based on a more\ncontemporary construction of the pullback via a deformation to the normal cone.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T08:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.04838v1","title":"Palatable pellets -- a fundamental framework to produce sustainable\n  pellets via extrusion","summary":"In pellet manufacturing various ingredients in powder or particle form are\npressed together into a dense product, a pellet, with better nutritional,\ncalorific, and handling properties than the individual input ingredients\nthemselves. For this reason, pellet manufacturing is applied to up-convert\nindustrial co-products from various sectors like agriculture, forestry, human\nfood, or bio-energy production, to valorize their waste-streams into more\nvaluable products. However, processing such diverse ingredient streams presents\nan industrial challenge and raises the important scientific question: \"Under\nwhich process conditions do loose pellet ingredients bind together to form a\nmechanically rigid and durable pellet?\" In this work we provide new answers to\nthis old research question by determining the causal relationships between\nprocessing parameters and physical pellet quality. Systematic pelleting\nexperiments reveal that the interplay of typical process parameters such as\nsteam conditioning temperature, production rate, and die geometry, can be\nunderstood in an overarching framework of process interactions. We introduce\nthe concept of the \"stickiness temperature,\" $\\mathrm{T^*}$, marking the onset\nof critical enthalpic reactions necessary for pellet agglomeration, the\nboundary condition for bond formation within a pellet. Our framework\ndemonstrates how $T^*$ is achieved through a combination of steam conditioning\nand friction, and how these conditions can be controlled by adjusting process\nparameters. Our findings underscore the significance of pellet temperature in\nconjunction with die residence time, for optimizing physical pellet quality\nwhile reducing energy consumption per kilogram of product. Validating our\nresults in a trial and leveraging existing literature data, our framework\nprovides handles to intelligently enhance the efficiency and sustainability of\npelleting processes.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-07T08:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.04840v1","title":"Unsupervised Ego- and Exo-centric Dense Procedural Activity Captioning\n  via Gaze Consensus Adaptation","summary":"Even from an early age, humans naturally adapt between exocentric (Exo) and\negocentric (Ego) perspectives to understand daily procedural activities.\nInspired by this cognitive ability, in this paper, we propose a novel\nUnsupervised Ego-Exo Adaptation for Dense Video Captioning (UEA-DVC) task,\nwhich aims to predict the time segments and descriptions for target view\nvideos, while only the source view data are labeled during training. Despite\nprevious works endeavoring to address the fully-supervised single-view or\ncross-view dense video captioning, they lapse in the proposed unsupervised task\ndue to the significant inter-view gap caused by temporal misalignment and\nirrelevant object interference. Hence, we propose a Gaze Consensus-guided\nEgo-Exo Adaptation Network (GCEAN) that injects the gaze information into the\nlearned representations for the fine-grained alignment between the Ego and Exo\nviews. Specifically, the Score-based Adversarial Learning Module (SALM)\nincorporates a discriminative scoring network to learn unified view-invariant\nrepresentations for bridging distinct views from a global level. Then, the Gaze\nConsensus Construction Module (GCCM) utilizes gaze representations to\nprogressively calibrate the learned global view-invariant representations for\nextracting the video temporal contexts based on focusing regions. Moreover, the\ngaze consensus is constructed via hierarchical gaze-guided consistency losses\nto spatially and temporally align the source and target views. To support our\nresearch, we propose a new EgoMe-UEA-DVC benchmark and experiments demonstrate\nthe effectiveness of our method, which outperforms many related methods by a\nlarge margin. The code will be released.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-07T08:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.04856v1","title":"Approach to optimal quantum transport via states over time","summary":"We approach the problem of constructing a quantum analogue of the immensely\nfruitful classical transport cost theory of Monge from a new angle. Going back\nto the original motivations, by which the transport is a bilinear function of a\nmass distribution (without loss of generality a probability density) and a\ntransport plan (a stochastic kernel), we explore the quantum version where the\nmass distribution is generalised to a density matrix, and the transport plan to\na completely positive and trace preserving map.\n  These two data are naturally integrated into their Jordan product, which is\ncalled state over time (``stote''), and the transport cost is postulated to be\na linear function of it.\n  We explore the properties of this transport cost, as well as the optimal\ntransport cost between two given states (simply the minimum cost over all\nsuitable transport plans). After that, we analyse in considerable detail the\ncase of unitary invariant cost, for which we can calculate many costs\nanalytically. These findings suggest that our quantum transport cost is\nqualitatively different from Monge's classical transport.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-07T09:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.04891v1","title":"Leveraging Large Language Models for Cost-Effective, Multilingual\n  Depression Detection and Severity Assessment","summary":"Depression is a prevalent mental health disorder that is difficult to detect\nearly due to subjective symptom assessments. Recent advancements in large\nlanguage models have offered efficient and cost-effective approaches for this\nobjective. In this study, we evaluated the performance of four LLMs in\ndepression detection using clinical interview data. We selected the best\nperforming model and further tested it in the severity evaluation scenario and\nknowledge enhanced scenario. The robustness was evaluated in complex diagnostic\nscenarios using a dataset comprising 51074 statements from six different mental\ndisorders. We found that DeepSeek V3 is the most reliable and cost-effective\nmodel for depression detection, performing well in both zero-shot and few-shot\nscenarios, with zero-shot being the most efficient choice. The evaluation of\nseverity showed low agreement with the human evaluator, particularly for mild\ndepression. The model maintains stably high AUCs for detecting depression in\ncomplex diagnostic scenarios. These findings highlight DeepSeek V3s strong\npotential for text-based depression detection in real-world clinical\napplications. However, they also underscore the need for further refinement in\nseverity assessment and the mitigation of potential biases to enhance clinical\nreliability.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-07T09:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.04893v1","title":"SCAM: A Real-World Typographic Robustness Evaluation for Multimodal\n  Foundation Models","summary":"Typographic attacks exploit the interplay between text and visual content in\nmultimodal foundation models, causing misclassifications when misleading text\nis embedded within images. However, existing datasets are limited in size and\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\nattack images to date, containing 1,162 images across hundreds of object\ncategories and attack words. Through extensive benchmarking of Vision-Language\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\ndegrade performance, and identify that training data and model architecture\ninfluence the susceptibility to these attacks. Our findings reveal that\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\nattacks, validating their use in research. Our work provides a comprehensive\nresource and empirical insights to facilitate future research toward robust and\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\nin this paper under https://huggingface.co/datasets/BLISS-e-V/SCAM, along with\nthe code for evaluations at https://github.com/Bliss-e-V/SCAM.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T10:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.04904v1","title":"A kinetic CMA diagram","summary":"We present a kinetic Clemmow-Mullaly-Allis (CMA) diagram by systematically\nanalysing the kinetic effects on the wave propagation in a homogeneous thermal\nplasma. The differences between the cold and kinetic CMA diagrams are outlined.\nIt is found that new boundaries for weakly damped left- and right-handed\ncircularly polarized waves are located above the ion and electron cyclotron\nfrequency lines in the kinetic CMA diagram. Additionally, Langmuir waves in the\nkinetic CMA diagram occupy a specific region between the new Langmuir wave\nboundary and the plasma frequency line, while in the cold CMA diagram, they\nexist on the plasma frequency line. The extraordinary-Bernstein mode\ntransformation frequency lines in the kinetic CMA diagram replace the hybrid\nresonant frequency lines of the cold CMA diagram, with discontinuities between\ndifferent cyclotron harmonics. These new boundaries partition the parameter\nspace in the kinetic CMA diagram differently, leading to new inverse wave\nnormal surfaces in the regions bounded by new boundaries. The kinetic CMA\ndiagram not only contributes to a basic understanding of wave properties in\nthermal plasmas, but also can provide a powerful tool to explore new possible\npropagation paths.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T10:22:29Z"}
{"aid":"http://arxiv.org/abs/2504.04925v1","title":"Scaling regimes in slow quenches within a gapped phase","summary":"We consider the finite-time quench dynamics in the quantum transverse field\nIsing model which exhibits a second order phase transition from a paramagnetic\nto a ferromagnetic phase, as the transverse magnetic field is decreased. These\ndynamics have been thoroughly investigated in previous studies when the\ncritical point is crossed during the quench; here, we quench the system from\ndeep in the paramagnetic phase to just above the critical field so that the\nsystem remains in the gapped phase throughout the quench duration. On linearly\nquenching the infinitely large system, we find that the behavior of mean\nlongitudinal defect density and mean transverse magnetization at the end of the\nquench falls into three distinct scaling regimes as the quench time is\nincreased. For sufficiently small quench times, these observables remain\nroughly constant, but for larger quench times, a crossover occurs from the\nKibble-Zurek scaling law to the quadratic quench rate law when the Kibble-Zurek\ntime is of the order of relaxation time at the final quench field. These\nresults are shown analytically using power series and uniform asymptotic\nexpansions of the exact solution of the model, and also compared with an\nadiabatic perturbation theory in the third regime. We find that the above\nmentioned scaling regimes hold for quenches within the ferromagnetic phase\nalso, and provide a general scaling argument for crossover from the\nKibble-Zurek regime to an adiabatic regime for slow quenches within a gapped\nphase.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-07T11:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.04936v1","title":"Constrained Gaussian Process Motion Planning via Stein Variational\n  Newton Inference","summary":"Gaussian Process Motion Planning (GPMP) is a widely used framework for\ngenerating smooth trajectories within a limited compute time--an essential\nrequirement in many robotic applications. However, traditional GPMP approaches\noften struggle with enforcing hard nonlinear constraints and rely on Maximum a\nPosteriori (MAP) solutions that disregard the full Bayesian posterior. This\nlimits planning diversity and ultimately hampers decision-making. Recent\nefforts to integrate Stein Variational Gradient Descent (SVGD) into motion\nplanning have shown promise in handling complex constraints. Nonetheless, these\nmethods still face persistent challenges, such as difficulties in strictly\nenforcing constraints and inefficiencies when the probabilistic inference\nproblem is poorly conditioned. To address these issues, we propose a novel\nconstrained Stein Variational Gaussian Process Motion Planning (cSGPMP)\nframework, incorporating a GPMP prior specifically designed for trajectory\noptimization under hard constraints. Our approach improves the efficiency of\nparticle-based inference while explicitly handling nonlinear constraints. This\nadvancement significantly broadens the applicability of GPMP to motion planning\nscenarios demanding robust Bayesian inference, strict constraint adherence, and\ncomputational efficiency within a limited time. We validate our method on\nstandard benchmarks, achieving an average success rate of 98.57% across 350\nplanning tasks, significantly outperforming competitive baselines. This\ndemonstrates the ability of our method to discover and use diverse trajectory\nmodes, enhancing flexibility and adaptability in complex environments, and\ndelivering significant improvements over standard baselines without incurring\nmajor computational costs.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-07T11:20:11Z"}
{"aid":"http://arxiv.org/abs/2504.04978v1","title":"The eigenvalue one property of finite groups, I","summary":"We prove a conjecture of Dekimpe, De Rock and Penninckx concerning the\nexistence of eigenvalues one in certain elements of finite groups acting\nirreducibly on a real vector space of odd dimension. This yields a sufficient\ncondition for a closed flat manifold to be an $R_{\\infty}$-manifold.","main_category":"math.GR","categories":"math.GR","published":"2025-04-07T12:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.04984v1","title":"Finding large $k$-colorable induced subgraphs in (bull, chair)-free and\n  (bull,E)-free graphs","summary":"We study the Max Partial $k$-Coloring problem, where we are given a\nvertex-weighted graph, and we ask for a maximum-weight induced subgraph that\nadmits a proper $k$-coloring. For $k=1$ this problem coincides with Maximum\nWeight Independent Set, and for $k=2$ the problem is equivalent (by\ncomplementation) to Minimum Odd Cycle Transversal. Furthermore, it generalizes\n$k$-Coloring. We show that Max Partial $k$-Coloring on $n$-vertex instances\nwith clique number $\\omega$ can be solved in time\n  * $n^{\\mathcal{O}(k\\omega)}$ if the input graph excludes the bull and the\nchair as an induced subgraph,\n  * $n^{\\mathcal{O}(k\\omega \\log n)}$ if the input graph excludes the bull and\nE as an induced subgraph.\n  This implies that $k$-Coloring can be solved in polynomial time in the former\nclass, and in quasipolynomial-time in the latter one.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-07T12:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.05040v1","title":"InstructionBench: An Instructional Video Understanding Benchmark","summary":"Despite progress in video large language models (Video-LLMs), research on\ninstructional video understanding, crucial for enhancing access to\ninstructional content, remains insufficient. To address this, we introduce\nInstructionBench, an Instructional video understanding Benchmark, which\nchallenges models' advanced temporal reasoning within instructional videos\ncharacterized by their strict step-by-step flow. Employing GPT-4, we formulate\nQ\\&A pairs in open-ended and multiple-choice formats to assess both\nCoarse-Grained event-level and Fine-Grained object-level reasoning. Our\nfiltering strategies exclude questions answerable purely by common-sense\nknowledge, focusing on visual perception and analysis when evaluating Video-LLM\nmodels. The benchmark finally contains 5k questions across over 700 videos. We\nevaluate the latest Video-LLMs on our InstructionBench, finding that\nclosed-source models outperform open-source ones. However, even the best model,\nGPT-4o, achieves only 53.42\\% accuracy, indicating significant gaps in temporal\nreasoning. To advance the field, we also develop a comprehensive instructional\nvideo dataset with over 19k Q\\&A pairs from nearly 2.5k videos, using an\nautomated data generation framework, thereby enriching the community's research\nresources.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.05041v1","title":"Segmented Trajectory Optimization for Autonomous Parking in Unstructured\n  Environments","summary":"This paper presents a Segmented Trajectory Optimization (STO) method for\nautonomous parking, which refines an initial trajectory into a dynamically\nfeasible and collision-free one using an iterative SQP-based approach. STO\nmaintains the maneuver strategy of the high-level global planner while allowing\ncurvature discontinuities at switching points to improve maneuver efficiency.\nTo ensure safety, a convex corridor is constructed via GJK-accelerated ellipse\nshrinking and expansion, serving as safety constraints in each iteration.\nNumerical simulations in perpendicular and reverse-angled parking scenarios\ndemonstrate that STO enhances maneuver efficiency while ensuring safety.\nMoreover, computational performance confirms its practicality for real-world\napplications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T13:07:17Z"}
{"aid":"http://arxiv.org/abs/2504.05071v1","title":"AI-Driven Tactical Communications and Networking for Defense: A Survey\n  and Emerging Trends","summary":"The integration of Artificial Intelligence (AI) in military communications\nand networking is reshaping modern defense strategies, enhancing secure data\nexchange, real-time situational awareness, and autonomous decision-making. This\nsurvey explores how AI-driven technologies improve tactical communication\nnetworks, radar-based data transmission, UAV-assisted relay systems, and\nelectronic warfare resilience. The study highlights AI applications in adaptive\nsignal processing, multi-agent coordination for network optimization,\nradar-assisted target tracking, and AI-driven electronic countermeasures. Our\nwork introduces a novel three-criteria evaluation methodology. It\nsystematically assesses AI applications based on general system objectives,\ncommunications constraints in the military domain, and critical tactical\nenvironmental factors. We analyze key AI techniques for different types of\nlearning applied to multi-domain network interoperability and distributed data\ninformation fusion in military operations. We also address challenges such as\nadversarial AI threats, the real-time adaptability of autonomous communication\nnetworks, and the limitations of current AI models under battlefield\nconditions. Finally, we discuss emerging trends in self-healing networks,\nAI-augmented decision support systems, and intelligent spectrum allocation. We\nprovide a structured roadmap for future AI-driven defense communications and\nnetworking research.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-07T13:38:32Z"}
{"aid":"http://arxiv.org/abs/2504.05073v1","title":"The Drinfeld-Grinberg-Kazhdan theorem and embedding codimension of the\n  arc space","summary":"We prove an extension of the theorem of Drinfeld, Grinberg and Kazhdan to\narcs with arbitrary residue field. As an application we show that the embedding\ncodimension is generically constant on each irreducible subset of the arc space\nwhich is not contained in the singular locus. In the case of maximal divisorial\nsets, this relates the corresponding finite formal models with invariants of\nsingularities of the underlying variety.","main_category":"math.AG","categories":"math.AG","published":"2025-04-07T13:39:56Z"}
{"aid":"http://arxiv.org/abs/2504.05085v1","title":"Characterisation of conserved and reacting moieties in chemical reaction\n  networks","summary":"A detailed understanding of biochemical networks at the molecular level is\nessential for studying complex cellular processes. In this paper, we provide a\ncomprehensive description of biochemical networks by considering individual\natoms and chemical bonds. To address combinatorial complexity, we introduce a\nwell-established approach to group similar types of information within\nbiochemical networks. A conserved moiety is a set of atoms whose association is\ninvariant across all reactions in a network. A reacting moiety is a set of\nbonds that are either broken, formed, or undergo a change in bond order in at\nleast one reaction in the network. By mathematically identifying these\nmoieties, we establish the biological significance of conserved and reacting\nmoieties according to the mathematical properties of the stoichiometric matrix.\nWe also present a novel decomposition of the stoichiometric matrix based on\nconserved moieties. This approach bridges the gap between graph theory, linear\nalgebra, and biological interpretation, thus opening up new horizons in the\nstudy of chemical reaction networks.","main_category":"q-bio.MN","categories":"q-bio.MN","published":"2025-04-07T13:54:47Z"}
{"aid":"http://arxiv.org/abs/2504.05090v1","title":"Radial Epiderivative Based Line Search Methods in Nonconvex and\n  Nonsmooth Box-Constrained Optimization","summary":"In this paper, we develop a novel radial epiderivative-based line search\nmethods for solving nonsmooth and nonconvex box-constrained optimization\nproblems. The rationale for employing the concept of radial epiderivatives is\nthat they provide necessary and sufficient conditions for both identifying\nglobal descent directions and achieving global minimum of nonconvex and\nnondifferentiable functions. These properties of radial epiderivatives are\ncombined with line search methods to develop iterative solution algorithms. The\nproposed methods generate search directions at each iteration where global\ndescent directions and stopping criteria are performed by using the abilities\nof the radial epiderivatives. We use two line search methods, that is cyclic\ncoordinate and particle swarm optimization techniques to generate search\ndirections, selecting only those that exhibit descent, as determined by using\napproximately computed radial epiderivatives at the current point. As a\nparticular case, these methods are applied for minimizing concave functions. In\nthe paper, two convergence theorems are proved. One of them deals with the\ngeneral line search method and covers only the set of directions generated by\nthe method. The second convergence theorem deals with minimizing concave\nfunctions which deals not only with the generated set of directions but covers\nthe whole set of feasible solutions. The performance of the proposed method is\nevaluated by using well-known benchmark problems from the literature. The\nresults demonstrate the advantages of the proposed approach in generating\noptimal or near-optimal solutions.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T13:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.05118v1","title":"VAPO: Efficient and Reliable Reinforcement Learning for Advanced\n  Reasoning Tasks","summary":"We present VAPO, Value-based Augmented Proximal Policy Optimization framework\nfor reasoning models., a novel framework tailored for reasoning models within\nthe value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the\nQwen 32B pre-trained model, attains a state-of-the-art score of\n$\\mathbf{60.4}$. In direct comparison under identical experimental settings,\nVAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B\nand DAPO by more than 10 points. The training process of VAPO stands out for\nits stability and efficiency. It reaches state-of-the-art performance within a\nmere 5,000 steps. Moreover, across multiple independent runs, no training\ncrashes occur, underscoring its reliability. This research delves into long\nchain-of-thought (long-CoT) reasoning using a value-based reinforcement\nlearning framework. We pinpoint three key challenges that plague value-based\nmethods: value model bias, the presence of heterogeneous sequence lengths, and\nthe sparsity of reward signals. Through systematic design, VAPO offers an\nintegrated solution that effectively alleviates these challenges, enabling\nenhanced performance in long-CoT reasoning tasks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T14:21:11Z"}
{"aid":"http://arxiv.org/abs/2504.05151v1","title":"Error formulas for block rational Krylov approximations of matrix\n  functions","summary":"This paper investigates explicit expressions for the error associated with\nthe block rational Krylov approximation of matrix functions. Two formulas are\nproposed, both derived from characterizations of the block FOM residual. The\nfirst formula employs a block generalization of the residual polynomial, while\nthe second leverages the block collinearity of the residuals. A posteriori\nerror bounds based on the knowledge of spectral information of the argument are\nderived and tested on a set of examples. Notably, both error formulas and their\ncorresponding upper bounds do not require the use of quadratures for their\npractical evaluation.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T14:56:55Z"}
{"aid":"http://arxiv.org/abs/2504.05179v1","title":"IEC-Independent Coupling Between Water Uptake and Ionic Conductivity in\n  Anion-Conducting Polymer Films","summary":"Anion exchange membranes (AEMs) are promising candidates for replacing proton\nexchange membranes (PEMs) in electrochemical devices such as fuel cells,\nelectrolyzers, batteries, and osmotic energy extraction systems. However,\noptimizing the AEM design requires a deeper understanding of the ionic\nconduction mechanism in the hydrated polymer matrix. This study investigates\nthis mechanism by seeking to understand the relationship between ion exchange\ncapacity (IEC), water absorption, and ionic conductivity in\npolynorbornene-based thin films. We combine experimental measurements with\ncomputational simulations using a newly developed minimal model of the polymer\nfilm. Our model is able to reproduce key experimental observations, including\nwater sorption isotherms and ion conduction behavior as a function of relative\nhumidity, and successfully captures the relationship between them. By comparing\nexperimental data with computational results, we explain the commonly reported\ncorrelation between conductivity and hydration level and show how the\ncorrelation between these variables is affected by the charge density and\ntemperature of the material. Our research advances our understanding of the\nphysical mechanisms that govern the performance of the polyelectrolyte\nmembrane, which is essential for the development of more efficient, stable, and\nenvironmentally friendly electrochemical systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-04-07T15:26:53Z"}
{"aid":"http://arxiv.org/abs/2504.05187v1","title":"Resource-Efficient Beam Prediction in mmWave Communications with\n  Multimodal Realistic Simulation Framework","summary":"Beamforming is a key technology in millimeter-wave (mmWave) communications\nthat improves signal transmission by optimizing directionality and intensity.\nHowever, conventional channel estimation methods, such as pilot signals or beam\nsweeping, often fail to adapt to rapidly changing communication environments.\nTo address this limitation, multimodal sensing-aided beam prediction has gained\nsignificant attention, using various sensing data from devices such as LiDAR,\nradar, GPS, and RGB images to predict user locations or network conditions.\nDespite its promising potential, the adoption of multimodal sensing-aided beam\nprediction is hindered by high computational complexity, high costs, and\nlimited datasets. Thus, in this paper, a resource-efficient learning approach\nis proposed to transfer knowledge from a multimodal network to a monomodal\n(radar-only) network based on cross-modal relational knowledge distillation\n(CRKD), while reducing computational overhead and preserving predictive\naccuracy. To enable multimodal learning with realistic data, a novel multimodal\nsimulation framework is developed while integrating sensor data generated from\nthe autonomous driving simulator CARLA with MATLAB-based mmWave channel\nmodeling, and reflecting real-world conditions. The proposed CRKD achieves its\nobjective by distilling relational information across different feature spaces,\nwhich enhances beam prediction performance without relying on expensive sensor\ndata. Simulation results demonstrate that CRKD efficiently distills multimodal\nknowledge, allowing a radar-only model to achieve $94.62\\%$ of the teacher\nperformance. In particular, this is achieved with just $10\\%$ of the teacher\nnetwork's parameters, thereby significantly reducing computational complexity\nand dependence on multimodal sensor data.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.LG","published":"2025-04-07T15:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.05211v1","title":"Exploiting individual differences to bootstrap communication","summary":"Establishing a communication system is hard because the intended meaning of a\nsignal is unknown to its receiver when first produced, and the signaller also\nhas no idea how that signal will be interpreted. Most theoretical accounts of\nthe emergence of communication systems rely on feedback to reinforce behaviours\nthat have led to successful communication in the past. However, providing such\nfeedback requires already being able to communicate the meaning that was\nintended or interpreted. Therefore these accounts cannot explain how\ncommunication can be bootstrapped from non-communicative behaviours. Here we\npresent a model that shows how a communication system, capable of expressing an\nunbounded number of meanings, can emerge as a result of individual behavioural\ndifferences in a large population without any pre-existing means to determine\ncommunicative success. The two key cognitive capabilities responsible for this\noutcome are behaving predictably in a given situation, and an alignment of\npsychological states ahead of signal production that derives from shared\nintentionality. Since both capabilities can exist independently of\ncommunication, our results are compatible with theories in which large flexible\nsocially-learned communication systems like language are the product of a\ngeneral but well-developed capacity for social cognition.","main_category":"cs.CL","categories":"cs.CL,physics.soc-ph,q-bio.PE","published":"2025-04-07T15:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.05212v1","title":"On multipolar magnetic anomaly detection: multipolar signal subspaces,\n  an analytical orthonormal basis, multipolar truncature and detection\n  performance","summary":"In this paper, we consider the magnetic anomaly detection problem which aims\nto find hidden ferromagnetic masses by estimating the weak perturbation they\ninduce on local Earth's magnetic field. We consider classical detection schemes\nthat rely on signals recorded on a moving sensor, and modeling of the source as\na function of unknown parameters. As the usual spherical harmonic decomposition\nof the anomaly has to be truncated in practice, we study the signal vector\nsubspaces induced by each multipole of the decomposition, proving they are not\nin direct sum, and discussing the impact it has on the choice of the truncation\norder. Further, to ease the detection strategy based on generalized likelihood\nratio test, we rely on orthogonal polynomials theory to derive an analytical\nset of orthonormal functions (multipolar orthonormal basis functions) that\nspans the space of the noise-free measured signal. Finally, based on the\nsubspace structure of the multipole vector spaces, we study the impact of the\ntruncation order on the detection performance, beyond the issue of potential\nsurparametrization, and the behaviour of the information criteria used to\nchoose this order.","main_category":"eess.SP","categories":"eess.SP,math-ph,math.MP,stat.ME","published":"2025-04-07T16:00:24Z"}
{"aid":"http://arxiv.org/abs/2504.05217v1","title":"LLM-Alignment Live-Streaming Recommendation","summary":"In recent years, integrated short-video and live-streaming platforms have\ngained massive global adoption, offering dynamic content creation and\nconsumption. Unlike pre-recorded short videos, live-streaming enables real-time\ninteraction between authors and users, fostering deeper engagement. However,\nthis dynamic nature introduces a critical challenge for recommendation systems\n(RecSys): the same live-streaming vastly different experiences depending on\nwhen a user watching. To optimize recommendations, a RecSys must accurately\ninterpret the real-time semantics of live content and align them with user\npreferences.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T16:04:00Z"}
{"aid":"http://arxiv.org/abs/2504.05227v1","title":"A Reality Check of Vision-Language Pre-training in Radiology: Have We\n  Progressed Using Text?","summary":"Vision-language pre-training has recently gained popularity as it allows\nlearning rich feature representations using large-scale data sources. This\nparadigm has quickly made its way into the medical image analysis community. In\nparticular, there is an impressive amount of recent literature developing\nvision-language models for radiology. However, the available medical datasets\nwith image-text supervision are scarce, and medical concepts are fine-grained,\ninvolving expert knowledge that existing vision-language models struggle to\nencode. In this paper, we propose to take a prudent step back from the\nliterature and revisit supervised, unimodal pre-training, using fine-grained\nlabels instead. We conduct an extensive comparison demonstrating that unimodal\npre-training is highly competitive and better suited to integrating\nheterogeneous data sources. Our results also question the potential of recent\nvision-language models for open-vocabulary generalization, which have been\nevaluated using optimistic experimental settings. Finally, we study novel\nalternatives to better integrate fine-grained labels and noisy text\nsupervision.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:13:26Z"}
{"aid":"http://arxiv.org/abs/2504.05231v1","title":"Mapping biodiversity at very-high resolution in Europe","summary":"This paper describes a cascading multimodal pipeline for high-resolution\nbiodiversity mapping across Europe, integrating species distribution modeling,\nbiodiversity indicators, and habitat classification. The proposed pipeline\nfirst predicts species compositions using a deep-SDM, a multimodal model\ntrained on remote sensing, climate time series, and species occurrence data at\n50x50m resolution. These predictions are then used to generate biodiversity\nindicator maps and classify habitats with Pl@ntBERT, a transformer-based LLM\ndesigned for species-to-habitat mapping. With this approach, continental-scale\nspecies distribution maps, biodiversity indicator maps, and habitat maps are\nproduced, providing fine-grained ecological insights. Unlike traditional\nmethods, this framework enables joint modeling of interspecies dependencies,\nbias-aware training with heterogeneous presence-absence data, and large-scale\ninference from multi-source remote sensing inputs.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-07T16:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.05239v1","title":"LLM-based Automated Grading with Human-in-the-Loop","summary":"The rise of artificial intelligence (AI) technologies, particularly large\nlanguage models (LLMs), has brought significant advancements to the field of\neducation. Among various applications, automatic short answer grading (ASAG),\nwhich focuses on evaluating open-ended textual responses, has seen remarkable\nprogress with the introduction of LLMs. These models not only enhance grading\nperformance compared to traditional ASAG approaches but also move beyond simple\ncomparisons with predefined \"golden\" answers, enabling more sophisticated\ngrading scenarios, such as rubric-based evaluation. However, existing\nLLM-powered methods still face challenges in achieving human-level grading\nperformance in rubric-based assessments due to their reliance on fully\nautomated approaches. In this work, we explore the potential of LLMs in ASAG\ntasks by leveraging their interactive capabilities through a human-in-the-loop\n(HITL) approach. Our proposed framework, GradeHITL, utilizes the generative\nproperties of LLMs to pose questions to human experts, incorporating their\ninsights to refine grading rubrics dynamically. This adaptive process\nsignificantly improves grading accuracy, outperforming existing methods and\nbringing ASAG closer to human-level evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.05261v1","title":"Componentwise Linear Ideals From Sums","summary":"Let $I,J$ be componentwise linear ideals in a polynomial ring $S$. We study\nnecessary and sufficient conditions for $I+J$ to be componentwise linear. We\nprovide a complete characterization when $\\dim S=2$. As a consequence, any\ncomponentwise linear monomial ideal in $k[x,y]$ has linear quotients using\ngenerators in non-decreasing degrees. In any dimension, we show that under mild\ncompatibility conditions, one can build a componentwise linear ideal from a\ngiven collection of componentwise linear monomial ideals using only sum and\nproduct with square-free monomials. We provide numerous examples to demonstrate\nthe optimality of our results.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-07T16:54:42Z"}
{"aid":"http://arxiv.org/abs/2504.05273v1","title":"What We Do Not Know: GPT Use in Business and Management","summary":"This systematic review examines peer-reviewed studies on application of GPT\nin business management, revealing significant knowledge gaps. Despite\nidentifying interesting research directions such as best practices,\nbenchmarking, performance comparisons, social impacts, our analysis yields only\n42 relevant studies for the 22 months since its release. There are so few\nstudies looking at a particular sector or subfield that management researchers,\nbusiness consultants, policymakers, and journalists do not yet have enough\ninformation to make well-founded statements on how GPT is being used in\nbusinesses. The primary contribution of this paper is a call to action for\nfurther research. We provide a description of current research and identify\nknowledge gaps on the use of GPT in business. We cover the management subfields\nof finance, marketing, human resources, strategy, operations, production, and\nanalytics, excluding retail and sales. We discuss gaps in knowledge of GPT\npotential consequences on employment, productivity, environmental costs,\noppression, and small businesses. We propose how management consultants and the\nmedia can help fill those gaps. We call for practical work on business control\nsystems as they relate to existing and foreseeable AI-related business\nchallenges. This work may be of interest to managers, to management\nresearchers, and to people working on AI in society.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-07T17:11:53Z"}
{"aid":"http://arxiv.org/abs/2504.05275v1","title":"On canonical sandpile actions of embedded graphs","summary":"The sandpile group of a connected graph is a group whose cardinality is the\nnumber of spanning trees. The group is known to have a canonical simply\ntransitive action on spanning trees if the graph is embedded into the plane.\nHowever, no canonical action on the spanning trees is known for the nonplanar\ncase. We show that for any embedded Eulerian digraph, one can define a\ncanonical simply transitive action of the sandpile group on compatible Eulerian\ntours (a set whose cardinality equals to the number of spanning arborescences).\nThis enables us to give a new proof that the rotor-routing action of a ribbon\ngraph is independent of the root if and only if the embedding is into the plane\n(originally proved by Chan, Church and Grochow).\n  Recently, Merino, Moffatt and Noble defined a sandpile group variant (called\nJacobian) for embedded graphs, whose cardinality is the number of quasi-trees.\nBaker, Ding and Kim showed that this group acts canonically on the quasitrees.\nWe show that the Jacobian of an embedded graph is canonically isomorphic to the\nusual sandpile group of the medial digraph, and the action by Baker at al.\nagrees with the action of the sandpile group of the medial digraph on Eulerian\ntours (which fact is made possible by the existence of a canonical bijection\nbetween Eulerian tours of the medial digraph and quasi-trees due to Bouchet).","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T17:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.05644v1","title":"iEBAKER: Improved Remote Sensing Image-Text Retrieval Framework via\n  Eliminate Before Align and Keyword Explicit Reasoning","summary":"Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR),\nwhich aims at searching for the corresponding targets based on the given query.\nAmong these efforts, the application of Foundation Models (FMs), such as CLIP,\nto the domain of remote sensing has yielded encouraging outcomes. However,\nexisting FM based methodologies neglect the negative impact of weakly\ncorrelated sample pairs and fail to account for the key distinctions among\nremote sensing texts, leading to biased and superficial exploration of sample\npairs. To address these challenges, we propose an approach named iEBAKER (an\nImproved Eliminate Before Align strategy with Keyword Explicit Reasoning\nframework) for RSITR. Specifically, we propose an innovative Eliminate Before\nAlign (EBA) strategy to filter out the weakly correlated sample pairs, thereby\nmitigating their deviations from optimal embedding space during\nalignment.Further, two specific schemes are introduced from the perspective of\nwhether local similarity and global similarity affect each other. On this\nbasis, we introduce an alternative Sort After Reversed Retrieval (SAR)\nstrategy, aims at optimizing the similarity matrix via reverse retrieval.\nAdditionally, we incorporate a Keyword Explicit Reasoning (KER) module to\nfacilitate the beneficial impact of subtle key concept distinctions. Without\nbells and whistles, our approach enables a direct transition from FM to RSITR\ntask, eliminating the need for additional pretraining on remote sensing data.\nExtensive experiments conducted on three popular benchmark datasets demonstrate\nthat our proposed iEBAKER method surpasses the state-of-the-art models while\nrequiring less training data. Our source code will be released at\nhttps://github.com/zhangy0822/iEBAKER.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:40:19Z"}
{"aid":"http://arxiv.org/abs/2504.05654v1","title":"Curved representational Bregman divergences and their applications","summary":"By analogy to curved exponential families, we define curved Bregman\ndivergences as restrictions of Bregman divergences to sub-dimensional parameter\nsubspaces, and prove that the barycenter of a finite weighted parameter set\nwith respect to a curved Bregman divergence amounts to the Bregman projection\nonto the subspace induced by the constraint of the barycenter with respect to\nthe unconstrained full Bregman divergence. We demonstrate the significance of\ncurved Bregman divergences with two examples: (1) symmetrized Bregman\ndivergences and (2) the Kullback-Leibler divergence between circular complex\nnormal distributions. We then consider monotonic embeddings to define\nrepresentational curved Bregman divergences and show that the\n$\\alpha$-divergences are representational curved Bregman divergences with\nrespect to $\\alpha$-embeddings of the probability simplex into the positive\nmeasure cone. As an application, we report an efficient method to calculate the\nintersection of a finite set of $\\alpha$-divergence spheres.","main_category":"cs.IT","categories":"cs.IT,cs.LG,math.IT","published":"2025-04-08T04:05:12Z"}
{"aid":"http://arxiv.org/abs/2504.05663v1","title":"Characterization of $P_3$-connected graphs","summary":"For any pair of edges $e,f$ of a graph $G$, we say that {\\em $e,f$ are\n$P_3$-connected in $G$} if there exists a sequence of edges $e=e_0,e_1,\\ldots,\ne_k=f$ such that $e_i$ and $e_{i+1}$ are two edges of an induced $3$-vertex\npath in $G$ for every $0\\leq i\\leq k-1$. If every pair of edges of $G$ are\n$P_3$-connected in $G$, then $G$ is {\\em $P_3$-connected}. $P_3$-connectivity\nwas first defined by Chudnovsky et al. in 2024 to prove that every connected\ngraph not containing $P_5$ as an induced subgraph has cop number at most two.\nIn this paper, we give a characterization of $P_3$-connected graphs and prove\nthat a simple graph is $P_3$-connected if and only if it is connected and has\nno homogeneous set whose induced subgraph contains an edge.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T04:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.05677v1","title":"Noisy Deep Ensemble: Accelerating Deep Ensemble Learning via Noise\n  Injection","summary":"Neural network ensembles is a simple yet effective approach for enhancing\ngeneralization capabilities. The most common method involves independently\ntraining multiple neural networks initialized with different weights and then\naveraging their predictions during inference. However, this approach increases\ntraining time linearly with the number of ensemble members. To address this\nissue, we propose the novel ``\\textbf{Noisy Deep Ensemble}'' method,\nsignificantly reducing the training time required for neural network ensembles.\nIn this method, a \\textit{parent model} is trained until convergence, and then\nthe weights of the \\textit{parent model} are perturbed in various ways to\nconstruct multiple \\textit{child models}. This perturbation of the\n\\textit{parent model} weights facilitates the exploration of different local\nminima while significantly reducing the training time for each ensemble member.\nWe evaluated our method using diverse CNN architectures on CIFAR-10 and\nCIFAR-100 datasets, surpassing conventional efficient ensemble methods and\nachieving test accuracy comparable to standard ensembles. Code is available at\n\\href{https://github.com/TSTB-dev/NoisyDeepEnsemble}{https://github.com/TSTB-dev/NoisyDeepEnsemble}","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T04:36:39Z"}
{"aid":"http://arxiv.org/abs/2504.05680v1","title":"Simultaneous construction of fast equator, poleward meridional flow, and\n  near-surface shear layer in solar magnetohydrodynamic calculation","summary":"We carry out an unprecedented high-resolution simulation for the solar\nconvection zone. Our calculation reproduces the fast equator and near-surface\nshear layer (NSSL) of differential rotation and the near-surface poleward\nmeridional flow simultaneously. The NSSL is located in a complex layer where\nthe spatial and time scales of thermal convection are significantly small\ncompared with the deep convection zone. While there have been several attempts\nto reproduce the NSSL in numerical simulation, the results are still far from\nreality. In this study, we succeed in reproducing an NSSL in our new\ncalculation. Our analyses lead to a deeper understanding of the construction\nmechanism of the NSSL, which is summarized as: 1) rotationally unconstrained\nconvection in the near-surface layer transports the angular momentum radially\ninward; 2) sheared poleward meridional flow around the top boundary is\nconstructed; 3) the shear causes a positive kinetic $\\langle v'_r\nv'_\\theta\\rangle$ and negative magnetic $\\langle B_r B_\\theta\\rangle$\ncorrelations; and 4) the turbulent viscosity and magnetic tension are\nlatitudinally balanced with the Coriolis force in the NSSL. We emphasize the\nimportance of the magnetic field in the solar convection zone.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T04:44:37Z"}
{"aid":"http://arxiv.org/abs/2504.05683v1","title":"Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained LLMs\n  Ready for HR Spoken Interview Transcript Analysis?","summary":"This research paper presents a comprehensive analysis of the performance of\nprominent pre-trained large language models (LLMs), including GPT-4 Turbo,\nGPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001,\ntext-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in\ncomparison to expert human evaluators in providing scores, identifying errors,\nand offering feedback and improvement suggestions to candidates during mock HR\n(Human Resources) interviews. We introduce a dataset called HURIT (Human\nResource Interview Transcripts), which comprises 3,890 HR interview transcripts\nsourced from real-world HR interview scenarios. Our findings reveal that\npre-trained LLMs, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit\ncommendable performance and are capable of producing evaluations comparable to\nthose of expert human evaluators. Although these LLMs demonstrate proficiency\nin providing scores comparable to human experts in terms of human evaluation\nmetrics, they frequently fail to identify errors and offer specific actionable\nadvice for candidate performance improvement in HR interviews. Our research\nsuggests that the current state-of-the-art pre-trained LLMs are not fully\nconducive for automatic deployment in an HR interview assessment. Instead, our\nfindings advocate for a human-in-the-loop approach, to incorporate manual\nchecks for inconsistencies and provisions for improving feedback quality as a\nmore suitable strategy.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T04:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.05687v1","title":"Radial Isotropic Position via an Implicit Newton's Method","summary":"Placing a dataset $A = \\{\\mathbf{a}_i\\}_{i \\in [n]} \\subset \\mathbb{R}^d$ in\nradial isotropic position, i.e., finding an invertible $\\mathbf{R} \\in\n\\mathbb{R}^{d \\times d}$ such that the unit vectors $\\{(\\mathbf{R}\n\\mathbf{a}_i) \\|\\mathbf{R} \\mathbf{a}_i\\|_2^{-1}\\}_{i \\in [n]}$ are in\nisotropic position, is a powerful tool with applications in functional\nanalysis, communication complexity, coding theory, and the design of learning\nalgorithms. When the transformed dataset has a second moment matrix within a\n$\\exp(\\pm \\epsilon)$ factor of a multiple of $\\mathbf{I}_d$, we call\n$\\mathbf{R}$ an $\\epsilon$-approximate Forster transform.\n  We give a faster algorithm for computing approximate Forster transforms,\nbased on optimizing an objective defined by Barthe [Barthe98]. When the\ntransform has a polynomially-bounded aspect ratio, our algorithm uses\n$O(nd^{\\omega - 1}(\\frac n \\epsilon)^{o(1)})$ time to output an\n$\\epsilon$-approximate Forster transform with high probability, when one\nexists. This is almost the natural limit of this approach, as even evaluating\nBarthe's objective takes $O(nd^{\\omega - 1})$ time. Previously, the\nstate-of-the-art runtime in this regime was based on cutting-plane methods, and\nscaled at least as $\\approx n^3 + n^2 d^{\\omega - 1}$. We also provide explicit\nestimates on the aspect ratio in the smoothed analysis setting, and show that\nour algorithm similarly improves upon those in the literature.\n  To obtain our results, we develop a subroutine of potential broader interest:\na reduction from almost-linear time sparsification of graph Laplacians to the\nability to support almost-linear time matrix-vector products. We combine this\ntool with new stability bounds on Barthe's objective to implicitly implement a\nbox-constrained Newton's method [CMTV17, ALOW17].","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-04-08T05:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.05688v1","title":"First and Second Fundamental Theorems for Invariant Rings Generated by\n  Circulant Determinants","summary":"In this paper, we give the first and second fundamental theorems of invariant\ntheory for certain invariant rings whose generators are expressed by circulant\ndeterminants.","main_category":"math.RT","categories":"math.RT,math.GR,math.RA","published":"2025-04-08T05:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.05698v1","title":"Point-based Instance Completion with Scene Constraints","summary":"Recent point-based object completion methods have demonstrated the ability to\naccurately recover the missing geometry of partially observed objects. However,\nthese approaches are not well-suited for completing objects within a scene, as\nthey do not consider known scene constraints (e.g., other observed surfaces) in\ntheir completions and further expect the partial input to be in a canonical\ncoordinate system, which does not hold for objects within scenes. While\ninstance scene completion methods have been proposed for completing objects\nwithin a scene, they lag behind point-based object completion methods in terms\nof object completion quality and still do not consider known scene constraints\nduring completion. To overcome these limitations, we propose a point\ncloud-based instance completion model that can robustly complete objects at\narbitrary scales and pose in the scene. To enable reasoning at the scene level,\nwe introduce a sparse set of scene constraints represented as point clouds and\nintegrate them into our completion model via a cross-attention mechanism. To\nevaluate the instance scene completion task on indoor scenes, we further build\na new dataset called ScanWCF, which contains labeled partial scans as well as\naligned ground truth scene completions that are watertight and collision-free.\nThrough several experiments, we demonstrate that our method achieves improved\nfidelity to partial scans, higher completion quality, and greater plausibility\nover existing state-of-the-art methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T05:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.05736v1","title":"Rank-Then-Score: Enhancing Large Language Models for Automated Essay\n  Scoring","summary":"In recent years, large language models (LLMs) achieve remarkable success\nacross a variety of tasks. However, their potential in the domain of Automated\nEssay Scoring (AES) remains largely underexplored. Moreover, compared to\nEnglish data, the methods for Chinese AES is not well developed. In this paper,\nwe propose Rank-Then-Score (RTS), a fine-tuning framework based on large\nlanguage models to enhance their essay scoring capabilities. Specifically, we\nfine-tune the ranking model (Ranker) with feature-enriched data, and then feed\nthe output of the ranking model, in the form of a candidate score set, with the\nessay content into the scoring model (Scorer) to produce the final score.\nExperimental results on two benchmark datasets, HSK and ASAP, demonstrate that\nRTS consistently outperforms the direct prompting (Vanilla) method in terms of\naverage QWK across all LLMs and datasets, and achieves the best performance on\nChinese essay scoring using the HSK dataset.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T07:10:51Z"}
{"aid":"http://arxiv.org/abs/2504.05738v1","title":"LLM-assisted Mutation for Whitebox API Testing","summary":"Cloud applications heavily rely on APIs to communicate with each other and\nexchange data. To ensure the reliability of cloud applications, cloud providers\nwidely adopt API testing techniques. Unfortunately, existing API testing\napproaches are insufficient to reach strict conditions, a problem known as\nfitness plateaus, due to the lack of gradient provided by coverage metrics. To\naddress this issue, we propose MioHint, a novel white-box API testing approach\nthat leverages the code comprehension capabilities of Large Language Model\n(LLM) to boost API testing. The key challenge of LLM-based API testing lies in\nsystem-level testing, which emphasizes the dependencies between requests and\ntargets across functions and files, thereby making the entire codebase the\nobject of analysis. However, feeding the entire codebase to an LLM is\nimpractical due to its limited context length and short memory. MioHint\naddresses this challenge by synergizing static analysis with LLMs. We retrieve\nrelevant code with data-dependency analysis at the statement level, including\ndef-use analysis for variables used in the target and function expansion for\nsubfunctions called by the target.\n  To evaluate the effectiveness of our method, we conducted experiments across\n16 real-world REST API services. The findings reveal that MioHint achieves an\naverage increase of 4.95% absolute in line coverage compared to the baseline,\nEvoMaster, alongside a remarkable factor of 67x improvement in mutation\naccuracy. Furthermore, our method successfully covers over 57% of hard-to-cover\ntargets while in baseline the coverage is less than 10%.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T07:14:51Z"}
{"aid":"http://arxiv.org/abs/2504.05748v1","title":"When Less Is More: A Sparse Facial Motion Structure For Listening Motion\n  Learning","summary":"Effective human behavior modeling is critical for successful human-robot\ninteraction. Current state-of-the-art approaches for predicting listening head\nbehavior during dyadic conversations employ continuous-to-discrete\nrepresentations, where continuous facial motion sequence is converted into\ndiscrete latent tokens. However, non-verbal facial motion presents unique\nchallenges owing to its temporal variance and multi-modal nature.\nState-of-the-art discrete motion token representation struggles to capture\nunderlying non-verbal facial patterns making training the listening head\ninefficient with low-fidelity generated motion. This study proposes a novel\nmethod for representing and predicting non-verbal facial motion by encoding\nlong sequences into a sparse sequence of keyframes and transition frames. By\nidentifying crucial motion steps and interpolating intermediate frames, our\nmethod preserves the temporal structure of motion while enhancing instance-wise\ndiversity during the learning process. Additionally, we apply this novel sparse\nrepresentation to the task of listening head prediction, demonstrating its\ncontribution to improving the explanation of facial motion patterns.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-08T07:25:12Z"}
{"aid":"http://arxiv.org/abs/2504.05753v1","title":"Accelerated Natural Gradient Method for Parametric Manifold Optimization","summary":"Parametric manifold optimization problems frequently arise in various machine\nlearning tasks, where state functions are defined on infinite-dimensional\nmanifolds. We propose a unified accelerated natural gradient descent (ANGD)\nframework to address these problems. By incorporating a Hessian-driven damping\nterm into the manifold update, we derive an accelerated Riemannian gradient\n(ARG) flow that mitigates oscillations. An equivalent first-order system is\nfurther presented for the ARG flow, enabling a unified discretization scheme\nthat leads to the ANGD method. In our discrete update, our framework considers\nvarious advanced techniques, including least squares approximation of the\nupdate direction, projected momentum to accelerate convergence, and efficient\napproximation methods through the Kronecker product. It accommodates various\nmetrics, including $H^s$, Fisher-Rao, and Wasserstein-2 metrics, providing a\ncomputationally efficient solution for large-scale parameter spaces. We\nestablish a convergence rate for the ARG flow under geodesic convexity\nassumptions. Numerical experiments demonstrate that ANGD outperforms standard\nNGD, underscoring its effectiveness across diverse deep learning tasks.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T07:33:04Z"}
{"aid":"http://arxiv.org/abs/2504.05759v1","title":"RETROcode: Leveraging a Code Database for Improved Natural Language to\n  Code Generation","summary":"As text and code resources have expanded, large-scale pre-trained models have\nshown promising capabilities in code generation tasks, typically employing\nsupervised fine-tuning with problem statement-program pairs. However,\nincreasing model size and data volume for performance gains also raises\ncomputational demands and risks of overfitting. Addressing these challenges, we\npresent RETROcode, a novel adaptation of the RETRO architecture \\cite{RETRO}\nfor sequence-to-sequence models, utilizing a large code database as an\nauxiliary scaling method. This approach, diverging from simply enlarging model\nand dataset sizes, allows RETROcode to leverage a vast code database for\nprediction, enhancing the model's efficiency by integrating extensive memory.\nOur findings indicate that RETROcode not only outperforms similar-sized\ntraditional architectures on test sets but also approaches the effectiveness of\nthe much larger Codex model, despite being trained from scratch on a\nsubstantially smaller dataset.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:41:13Z"}
{"aid":"http://arxiv.org/abs/2504.05770v1","title":"A Lightweight Multi-Module Fusion Approach for Korean Character\n  Recognition","summary":"Optical Character Recognition (OCR) is essential in applications such as\ndocument processing, license plate recognition, and intelligent surveillance.\nHowever, existing OCR models often underperform in real-world scenarios due to\nirregular text layouts, poor image quality, character variability, and high\ncomputational costs.\n  This paper introduces SDA-Net (Stroke-Sensitive Attention and Dynamic Context\nEncoding Network), a lightweight and efficient architecture designed for robust\nsingle-character recognition. SDA-Net incorporates: (1) a Dual Attention\nMechanism to enhance stroke-level and spatial feature extraction; (2) a Dynamic\nContext Encoding module that adaptively refines semantic information using a\nlearnable gating mechanism; (3) a U-Net-inspired Feature Fusion Strategy for\ncombining low-level and high-level features; and (4) a highly optimized\nlightweight backbone that reduces memory and computational demands.\n  Experimental results show that SDA-Net achieves state-of-the-art accuracy on\nchallenging OCR benchmarks, with significantly faster inference, making it\nwell-suited for deployment in real-time and edge-based OCR systems.","main_category":"cs.CV","categories":"cs.CV,cs.AI,I.2.10","published":"2025-04-08T07:50:19Z"}
{"aid":"http://arxiv.org/abs/2504.05797v1","title":"Possible existence of pygmy dipole resonance built on excited states in\n  a neutron-rich $^{80}$Ge nucleus","summary":"The pygmy dipole resonance (PDR) at the low-lying tail of the giant dipole\nresonance (GDR) is an interesting research subject as it carries important\ninformation about the nuclear surface with mixed isoscalar and isovector\nvibrations in $N > Z$ systems. The present paper investigates the possible\nexistence of the PDR built on excited states in a neutron-rich $^{80}$Ge\nnucleus using the phonon damping model (PDM) with and without pairing\ncorrelation at zero and finite temperatures. The results obtained within the\nPDM with exact pairing (EP+PDM) reveal the appearance of two enhanced\n$\\gamma$-transitions $E_\\gamma = 7.25$ and 7.35 MeV at $T=0.6$ MeV, which carry\nthe PDR nature and hence implying the possible existence of PDR built on\nexcited states in this nucleus. These two $\\gamma$-energies nicely match with a\nrecent experimental observation, thus indicating the crucial role of the\ninclusion of exact pairing solution in the precise description of low-lying\n$\\gamma$-transitions. The partition function-based analysis shows that this\npredicted PDR at $T=$ 0.6MeV is mainly contributed by the first $2^+$ excited\nstate of the $^{80}$Ge nucleus. The isospin mixing at the nuclear surface is\nalso observed in the investigated PDR at $T=0.6-0.7$ MeV. The primary mechanism\nunderlying the emergence of the hot PDR is found due to the coupling of GDR\nphonon to non-collective particle-particle and hole-hole configurations at\nfinite temperatures within the PDM framework, along with the shift in\nparticle-hole excitation energies due to thermal pairing correlations","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-08T08:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.05806v1","title":"Meta-Continual Learning of Neural Fields","summary":"Neural Fields (NF) have gained prominence as a versatile framework for\ncomplex data representation. This work unveils a new problem setting termed\n\\emph{Meta-Continual Learning of Neural Fields} (MCL-NF) and introduces a novel\nstrategy that employs a modular architecture combined with optimization-based\nmeta-learning. Focused on overcoming the limitations of existing methods for\ncontinual learning of neural fields, such as catastrophic forgetting and slow\nconvergence, our strategy achieves high-quality reconstruction with\nsignificantly improved learning speed. We further introduce Fisher Information\nMaximization loss for neural radiance fields (FIM-NeRF), which maximizes\ninformation gains at the sample level to enhance learning generalization, with\nproved convergence guarantee and generalization bound. We perform extensive\nevaluations across image, audio, video reconstruction, and view synthesis tasks\non six diverse datasets, demonstrating our method's superiority in\nreconstruction quality and speed over existing MCL and CL-NF approaches.\nNotably, our approach attains rapid adaptation of neural fields for city-scale\nNeRF rendering with reduced parameter requirement.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T08:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.05818v1","title":"Proper constituent gluon mass as the final piece to construct hybrid","summary":"After treating hybrid as a three-body system, we recalculate the spectra and\ndecay widths of the $1^{-+}$ light hybrids via the Gauss Expansion Method\n(GEM). Our result shows that, after adding into only one more parameter\n$m_g$=450 MeV, i.e., the constituent gluon mass, we can reproduce nearly all\nthe results in our previous work by just using the model parameters from meson\nspectra calculation, which shows the unification of Quantum Chromodynamics\n(QCD). As a result, $\\pi_1(1600)$ and $\\eta_1(1855)$ may not be explained as\n$1^{-+}$ hybrids simultaneously, and the $\\eta_1(1855)$ observed by BESIII may\nnot be a hybrid. In addition, we predict an existence of a hybrid\n$\\eta_1(1640)$, which can be verified by searching the $a_1(1260)\\pi$ channel.\nFurthermore, to search for an isospin-0 and an isospin-$\\frac{1}{2}$ hybrid,\nthe golden channels may be $K_1(1270)\\bar{K}$ and $K_1(1270)\\pi$, respectively.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T09:01:14Z"}
{"aid":"http://arxiv.org/abs/2504.05831v1","title":"Leveraging Robust Optimization for LLM Alignment under Distribution\n  Shifts","summary":"Large language models (LLMs) increasingly rely on preference alignment\nmethods to steer outputs toward human values, yet these methods are often\nconstrained by the scarcity of high-quality human-annotated data. To tackle\nthis, recent approaches have turned to synthetic data generated by LLMs as a\nscalable alternative. However, synthetic data can introduce distribution\nshifts, compromising the nuanced human preferences that are essential for\ndesirable outputs. In this paper, we propose a novel distribution-aware\noptimization framework that improves preference alignment in the presence of\nsuch shifts. Our approach first estimates the likelihood ratios between the\ntarget and training distributions leveraging a learned classifier, then it\nminimizes the worst-case loss over data regions that reflect the target\nhuman-preferred distribution. By explicitly prioritizing the target\ndistribution during optimization, our method mitigates the adverse effects of\ndistributional variation and enhances the generation of responses that\nfaithfully reflect human values.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T09:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.05837v1","title":"Derivation of Kirchhoff-type plate theories for elastic materials with\n  voids","summary":"We rigorously derive a Blake-Zisserman-Kirchhoff theory for thin plates with\nmaterial voids, starting from a three-dimensional model with elastic bulk and\ninterfacial energy featuring a Willmore-type curvature penalization. The\neffective two-dimensional model comprises a classical elastic bending energy\nand surface terms which reflect the possibility that voids can persist in the\nlimit, that the limiting plate can be broken apart into several pieces, or that\nthe plate can be folded. Building upon and extending the techniques used in the\nauthors' recent work on the derivation of one-dimensional theories for thin\nbrittle rods with voids, the present contribution generalizes the results of\nSantili and Schmidt (2022), by considering general geometries on the admissible\nset of voids and constructing recovery sequences for all admissible limiting\nconfigurations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T09:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.05847v1","title":"R√©duire le bruit gr√¢ce √† la r√©alit√© augment√©e sonore --\n  Auditory Concealer","summary":"This report presents the work done over 22 weeks of internship within the\nSound Perception and Design team of the Sciences and Technologies of Music and\nSound (STMS) laboratory at the Institute for Research and Coordination in\nAcoustics/Music (IRCAM). As part of the launch of the project Reducing Noise\nwith Augmented Reality (ReNAR); which aims to create a tool to reduce in\nreal-time the cognitive impact of sounds perceived as unpleasant or annoying in\nindoor environments; an initial study was conducted to validate the feasibility\nand effectiveness of a new masking approach called concealer. The main\nhypothesis is that the concealer approach could provide better results than a\nmasker approach in terms of perceived pleasantness. Mixtures of two noise\nsources (ventilation) and five masking sounds (water sounds) were generated\nusing both approaches at various levels. The evaluation of the perceived\npleasantness of these mixtures showed that the masker approach remains more\neffective than the concealer approach, regardless of the noise source, water\nsound, or level used.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-08T09:27:07Z"}
{"aid":"http://arxiv.org/abs/2504.05863v1","title":"Extending Parametric Model Embedding with Physical Information for\n  Design-space Dimensionality Reduction in Shape Optimization","summary":"In this work, an extension of the parametric model embedding (PME) approach\nis presented, aiming to achieve more effective design-space dimensionality\nreduction for shape optimization in vehicle design. PME, rooted in principal\ncomponent analysis (PCA), not only identifies a reduced set of critical modes\nbut also re-parameterizes the original design space, enabling direct and\ninterpretable manipulations of shape modifications within the reduced space.\nAlongside the \"physics-informed\" version (PI-PME), which enriches geometry with\nlow-fidelity distributed and lumped physical quantities, a \"physics-driven\"\nvariant (PD-PME) is introduced that focuses exclusively on physical parameters.\nBoth formulations employ PCA to capture the principal modes of variability yet\ndiffer in their balance between geometric and physical information, through the\nad-hoc definition of a weighted inner product. Through test cases involving the\nRAE-2822 airfoil, a bio-inspired underwater glider, a naval propeller, and the\nDTMB-5415 destroyer-type vessel, it is shown how the resulting frameworks\nprovide a first-level assessment of design variability, offer interpretability\nregarding which original variables most strongly affect performance, and\nefficiently bridge geometric and physical parameters. Furthermore, lumped\nphysical parameters can serve as a low-fidelity foundation for multi-fidelity\noptimization, directly leveraging the linear re-parameterization to drive the\nreduced design variables. Meanwhile, distributed physical parameters enable the\nconstruction of machine-learning-based reduced-order models to infer integral\nquantities of interest. By allowing the user to embed these insights early in\nthe design process, PI-PME and PD-PME facilitate more robust, cost-effective\nexploration, paving the way for subsequent high-fidelity optimization.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T09:43:41Z"}
{"aid":"http://arxiv.org/abs/2504.05866v1","title":"CTI-HAL: A Human-Annotated Dataset for Cyber Threat Intelligence\n  Analysis","summary":"Organizations are increasingly targeted by Advanced Persistent Threats\n(APTs), which involve complex, multi-stage tactics and diverse techniques.\nCyber Threat Intelligence (CTI) sources, such as incident reports and security\nblogs, provide valuable insights, but are often unstructured and in natural\nlanguage, making it difficult to automatically extract information. Recent\nstudies have explored the use of AI to perform automatic extraction from CTI\ndata, leveraging existing CTI datasets for performance evaluation and\nfine-tuning. However, they present challenges and limitations that impact their\neffectiveness. To overcome these issues, we introduce a novel dataset manually\nconstructed from CTI reports and structured according to the MITRE ATT&CK\nframework. To assess its quality, we conducted an inter-annotator agreement\nstudy using Krippendorff alpha, confirming its reliability. Furthermore, the\ndataset was used to evaluate a Large Language Model (LLM) in a real-world\nbusiness context, showing promising generalizability.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-08T09:47:15Z"}
{"aid":"http://arxiv.org/abs/2504.05872v1","title":"On free line arrangements with double, triple and quadruple points","summary":"We show that there are only finitely many combinatorial types of free real\nline arrangements with only double, triple and quadruple intersection points,\nand we enlist all admissible weak-combinatorics of them. Then we classify all\nreal $M$-line arrangements. In particular, we show that real $M$-line\narrangements are simplicial.","main_category":"math.AG","categories":"math.AG,math.CO","published":"2025-04-08T09:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.05883v1","title":"Rolling Horizon Coverage Control with Collaborative Autonomous Agents","summary":"This work proposes a coverage controller that enables an aerial team of\ndistributed autonomous agents to collaboratively generate non-myopic coverage\nplans over a rolling finite horizon, aiming to cover specific points on the\nsurface area of a 3D object of interest. The collaborative coverage problem,\nformulated, as a distributed model predictive control problem, optimizes the\nagents' motion and camera control inputs, while considering inter-agent\nconstraints aiming at reducing work redundancy. The proposed coverage\ncontroller integrates constraints based on light-path propagation techniques to\npredict the parts of the object's surface that are visible with regard to the\nagents' future anticipated states. This work also demonstrates how complex,\nnon-linear visibility assessment constraints can be converted into logical\nexpressions that are embedded as binary constraints into a mixed-integer\noptimization framework. The proposed approach has been demonstrated through\nsimulations and practical applications for inspecting buildings with unmanned\naerial vehicles (UAVs).","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T10:17:38Z"}
{"aid":"http://arxiv.org/abs/2504.05891v1","title":"To Give or Not to Give? The Impacts of Strategically Withheld Recourse","summary":"Individuals often aim to reverse undesired outcomes in interactions with\nautomated systems, like loan denials, by either implementing system-recommended\nactions (recourse), or manipulating their features. While providing recourse\nbenefits users and enhances system utility, it also provides information about\nthe decision process that can be used for more effective strategic\nmanipulation, especially when the individuals collectively share such\ninformation with each other.\n  We show that this tension leads rational utility-maximizing systems to\nfrequently withhold recourse, resulting in decreased population utility,\nparticularly impacting sensitive groups.\n  To mitigate these effects, we explore the role of recourse subsidies, finding\nthem effective in increasing the provision of recourse actions by rational\nsystems, as well as lowering the potential social cost and mitigating\nunfairness caused by recourse withholding.","main_category":"cs.GT","categories":"cs.GT,cs.LG","published":"2025-04-08T10:36:16Z"}
{"aid":"http://arxiv.org/abs/2504.05897v1","title":"HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient\n  MoE Inference","summary":"The Mixture of Experts (MoE) architecture has demonstrated significant\nadvantages as it enables to increase the model capacity without a proportional\nincrease in computation. However, the large MoE model size still introduces\nsubstantial memory demands, which usually requires expert offloading on\nresource-constrained platforms and incurs significant overhead. Hybrid CPU-GPU\ninference has been proposed to leverage CPU computation to reduce expert\nloading overhead but faces major challenges: on one hand, the expert activation\npatterns of MoE models are highly unstable, rendering the fixed mapping\nstrategies in existing works inefficient; on the other hand, the hybrid CPU-GPU\nschedule for MoE is inherently complex due to the diverse expert sizes,\nstructures, uneven workload distribution, etc. To address these challenges, in\nthis paper, we propose HybriMoE, a hybrid CPU-GPU inference framework that\nimproves resource utilization through a novel CPU-GPU scheduling and cache\nmanagement system. HybriMoE introduces (i) a dynamic intra-layer scheduling\nstrategy to balance workloads across CPU and GPU, (ii) an impact-driven\ninter-layer prefetching algorithm, and (iii) a score-based caching algorithm to\nmitigate expert activation instability. We implement HybriMoE on top of the\nkTransformers framework and evaluate it on three widely used MoE-based LLMs.\nExperimental results demonstrate that HybriMoE achieves an average speedup of\n1.33$\\times$ in the prefill stage and 1.70$\\times$ in the decode stage compared\nto state-of-the-art hybrid MoE inference framework. Our code is available at:\nhttps://github.com/PKU-SEC-Lab/HybriMoE.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-08T10:47:37Z"}
{"aid":"http://arxiv.org/abs/2504.05899v1","title":"Spatially Resolved Optical Responses of a High-Kinetic-Inductance\n  Microwave Resonator","summary":"Understanding the optical response of a high-kinetic-inductance microwave\nresonator is crucial for applications ranging from single-photon detection to\nquantum transduction between microwave and optical domains, which is gaining\nsignificant attention for scaling up quantum computers. However, interactions\nbetween the pump light and the superconducting resonator often induce\nunintended resonance frequency shifts and linewidth broadening. In this study,\nwe measure the local optical response of a NbTiN nanowire resonator using a\nlaser-scanning microwave spectroscopy system integrated with a dilution\nrefrigerator. The optical response of the resonator shows correlation with the\nresonance modes and position, which is attributed to the two-level system\naround the resonator. These findings not only contribute to the design and\nunderstanding of quantum transducers and single-photon detectors, but also to\nthe understandings of catastrophic high-energy particle irradiation events that\ngenerate unintended phonons in quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T10:51:26Z"}
{"aid":"http://arxiv.org/abs/2504.05925v1","title":"SVLTA: Benchmarking Vision-Language Temporal Alignment via Synthetic\n  Video Situation","summary":"Vision-language temporal alignment is a crucial capability for human dynamic\nrecognition and cognition in real-world scenarios. While existing research\nfocuses on capturing vision-language relevance, it faces limitations due to\nbiased temporal distributions, imprecise annotations, and insufficient\ncompositionally. To achieve fair evaluation and comprehensive exploration, our\nobjective is to investigate and evaluate the ability of models to achieve\nalignment from a temporal perspective, specifically focusing on their capacity\nto synchronize visual scenarios with linguistic context in a temporally\ncoherent manner. As a preliminary step, we present the statistical analysis of\nexisting benchmarks and reveal the existing challenges from a decomposed\nperspective. To this end, we introduce SVLTA, the Synthetic Vision-Language\nTemporal Alignment derived via a well-designed and feasible control generation\nmethod within a simulation environment. The approach considers commonsense\nknowledge, manipulable action, and constrained filtering, which generates\nreasonable, diverse, and balanced data distributions for diagnostic\nevaluations. Our experiments reveal diagnostic insights through the evaluations\nin temporal question answering, distributional shift sensitiveness, and\ntemporal alignment adaptation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T11:31:37Z"}
{"aid":"http://arxiv.org/abs/2504.05962v1","title":"Autoencoder-Based Detection of Anomalous Stokes V Spectra in the\n  Flare-Producing Active Region 13663 Using Hinode/SP Observations","summary":"Detecting unusual signals in observational solar spectra is crucial for\nunderstanding the features associated with impactful solar events, such as\nsolar flares. However, existing spectral analysis techniques face challenges,\nparticularly when relying on pre-defined, physics-based calculations to process\nlarge volumes of noisy and complex observational data. To address these\nlimitations, we applied deep learning to detect anomalies in the Stokes V\nspectra from the Hinode/SP instrument. Specifically, we developed an\nautoencoder model for spectral compression, which serves as an anomaly\ndetection method. Our model effectively identifies anomalous spectra within\nspectro-polarimetric maps captured prior to the onset of the X1.3 flare on May\n5, 2024, in NOAA AR 13663. These atypical spectral points exhibit highly\ncomplex profiles and spatially align with polarity inversion lines in\nmagnetogram images, indicating their potential as sites of magnetic energy\nstorage and possible triggers for flares. Notably, the detected anomalies are\nhighly localized, making them particularly challenging to identify in\nmagnetogram images using current manual methods.","main_category":"cs.LG","categories":"cs.LG,astro-ph.IM,astro-ph.SR","published":"2025-04-08T12:20:47Z"}
{"aid":"http://arxiv.org/abs/2504.05963v1","title":"Learning Verified Monitors for Hidden~Markov~Models","summary":"Runtime monitors assess whether a system is in an unsafe state based on a\nstream of observations. We study the problem where the system is subject to\nprobabilistic uncertainty and described by a hidden Markov model. A stream of\nobservations is then unsafe if the probability of being in an unsafe state is\nabove a threshold. A correct monitor recognizes the set of unsafe observations.\nThe key contribution of this paper is the first correct-by-construction\nsynthesis method for such monitors, represented as finite automata. The\ncontribution combines four ingredients: First, we establish the coNP-hardness\nof checking whether an automaton is a correct monitor, i.e., a monitor without\nmisclassifications. Second, we provide a reduction that reformulates the search\nfor misclassifications into a standard probabilistic system synthesis problem.\nThird, we integrate the verification routine into an active automata learning\nroutine to synthesize correct monitors. Fourth, we provide a prototypical\nimplementation that shows the feasibility and limitations of the approach on a\nseries of benchmarks.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-04-08T12:23:20Z"}
{"aid":"http://arxiv.org/abs/2504.06002v1","title":"Has ACT measured radiative corrections to the tree-level Higgs-like\n  inflation?","summary":"Starobinsky inflation and non-minimally coupled Higgs inflation have been\namong the most favored models of the early universe, as their predictions for\nthe scalar spectral index $n_s$ and tensor-to-scalar ratio $r$ fall comfortably\nwithin the constraints set by Planck and BICEP/Keck. However, new results from\nthe Atacama Cosmology Telescope (ACT) suggest a preference for higher values of\n$n_s$, introducing tension with the simplest realizations of these models. In\nthis work, being agnostic about the nature of the inflaton, we show that\nincorporating one-loop corrections to a Higgs-like inflationary scenario leads\nto a shift in the predicted value of $n_s$, which brings Higgs-like inflation\ninto better agreement with ACT observations. Remarkably, we find that this can\nbe achieved with non-minimal couplings $\\xi < 1$, in contrast to the large\nvalues typically required in conventional Higgs inflation, thereby pushing any\nunitarity-violation scale above the Planck scale. The effect is even more\nsignificant when the model is formulated in the Palatini approach, where the\nmodified field-space structure naturally enhances deviations from the metric\ncase. These findings highlight the importance of quantum corrections and\ngravitational degrees of freedom in refining inflationary predictions in light\nof new data.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-08T13:11:58Z"}
{"aid":"http://arxiv.org/abs/2504.06026v1","title":"Taking out the Toxic Trash: Recovering Precision in Mixed Flow-Sensitive\n  Static Analyses","summary":"Static analysis of real-world programs combines flow- and context-sensitive\nanalyses of local program states with computation of flow- and\ncontext-insensitive invariants at globals, that, e.g., abstract data shared by\nmultiple threads. The values of locals and globals may mutually depend on each\nother, with the analysis of local program states both making contributions to\nglobals and querying their values. Usually, all contributions to globals are\naccumulated during fixpoint iteration, with widening applied to enforce\ntermination. Such flow-insensitive information often becomes unnecessarily\nimprecise and can include superfluous contributions -- trash -- which, in turn,\nmay be toxic to the precision of the overall analysis. To recover precision of\nglobals, we propose techniques complementing each other: Narrowing on globals\ndifferentiates contributions by origin; reluctant widening limits the amount of\nwidening applied at globals; and finally, abstract garbage collection undoes\ncontributions to globals and propagates their withdrawal. The experimental\nevaluation shows that these techniques increase the precision of mixed\nflow-sensitive analyses at a reasonable cost.","main_category":"cs.PL","categories":"cs.PL,cs.SE","published":"2025-04-08T13:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.06027v1","title":"OSDM-MReg: Multimodal Image Registration based One Step Diffusion Model","summary":"Multimodal remote sensing image registration aligns images from different\nsensors for data fusion and analysis. However, current methods often fail to\nextract modality-invariant features when aligning image pairs with large\nnonlinear radiometric differences. To address this issues, we propose\nOSDM-MReg, a novel multimodal image registration framework based image-to-image\ntranslation to eliminate the gap of multimodal images. Firstly, we propose a\nnovel one-step unaligned target-guided conditional denoising diffusion\nprobabilistic models(UTGOS-CDDPM)to translate multimodal images into a unified\ndomain. In the inference stage, traditional conditional DDPM generate\ntranslated source image by a large number of iterations, which severely slows\ndown the image registration task. To address this issues, we use the unaligned\ntraget image as a condition to promote the generation of low-frequency features\nof the translated source image. Furthermore, during the training stage, we add\nthe inverse process of directly predicting the translated image to ensure that\nthe translated source image can be generated in one step during the testing\nstage. Additionally, to supervised the detail features of translated source\nimage, we propose a new perceptual loss that focuses on the high-frequency\nfeature differences between the translated and ground-truth images. Finally, a\nmultimodal multiscale image registration network (MM-Reg) fuse the multimodal\nfeature of the unimodal images and multimodal images by proposed multimodal\nfeature fusion strategy. Experiments demonstrate superior accuracy and\nefficiency across various multimodal registration tasks, particularly for\nSAR-optical image pairs.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-08T13:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.06040v1","title":"Exploring the Lifecycle and Maintenance Practices of Pre-Trained Models\n  in Open-Source Software Repositories","summary":"Pre-trained models (PTMs) are becoming a common component in open-source\nsoftware (OSS) development, yet their roles, maintenance practices, and\nlifecycle challenges remain underexplored. This report presents a plan for an\nexploratory study to investigate how PTMs are utilized, maintained, and tested\nin OSS projects, focusing on models hosted on platforms like Hugging Face and\nPyTorch Hub. We plan to explore how PTMs are used in open-source software\nprojects and their related maintenance practices by mining software\nrepositories that use PTMs and analyzing their code-base, historical data, and\nreported issues. This study aims to provide actionable insights into improving\nthe use and sustainability of PTM in open-source projects and a step towards a\nfoundation for advancing software engineering practices in the context of model\ndependencies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T13:41:13Z"}
{"aid":"http://arxiv.org/abs/2504.06044v1","title":"Polynomial-Time PIT from (Almost) Necessary Assumptions","summary":"The celebrated result of Kabanets and Impagliazzo (Computational Complexity,\n2004) showed that PIT algorithms imply circuit lower bounds, and vice versa.\nSince then it has been a major challenge to understand the precise connections\nbetween PIT and lower bounds. In particular, a main goal has been to understand\nwhich lower bounds suffice to obtain efficient PIT algorithms, and how close\nare they to lower bounds that are necessary for the conclusion.\n  We construct polynomial-time PIT algorithms from lower bounds that are, up to\nrelatively minor remaining gaps, necessary for the existence of such\nalgorithms. That is, we prove that these lower bounds are, up to the mentioned\nminor gaps, both sufficient and necessary for polynomial-time PIT, over fields\nof characteristic zero. Over sufficiently large finite fields, we show a\nsimilar result wherein the PIT algorithm runs in time $n^{\\log^{(c)}(n)}$, i.e.\na power of $c$-iterated log for an arbitrarily large constant $c>1$.\n  The key to these improvements is studying PIT versus lower bounds in the\nuniform setting, in which we focus on proving lower bounds for uniform\narithmetic circuits and their variants (and on deducing algorithms from such\nlower bounds). Indeed, by working in this setting we obtain results that are\nsignificantly tighter than previously known results concerning polynomial-time\nPIT vs lower bounds, and are in fact also tighter than known\nhardness-vs-randomness connections in the Boolean setting.\n  Our results are obtained by combining recent techniques from Boolean hardness\nvs randomness, and in particular the generator of Chen and Tell (FOCS 2021),\nwith the algebraic hitting-set generator of Guo, Kumar, Saptharishi, and\nSolomon (SIAM J. Computing 2022) along with the bootstrapping ideas of Agrawal,\nGhosh, and Saxena (STOC 2018) and of Kumar, Saptharishi, and Tengse (SODA\n2019).","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-08T13:44:21Z"}
{"aid":"http://arxiv.org/abs/2504.06048v1","title":"Trust-Region Twisted Policy Improvement","summary":"Monte-Carlo tree search (MCTS) has driven many recent breakthroughs in deep\nreinforcement learning (RL). However, scaling MCTS to parallel compute has\nproven challenging in practice which has motivated alternative planners like\nsequential Monte-Carlo (SMC). Many of these SMC methods adopt particle filters\nfor smoothing through a reformulation of RL as a policy inference problem. Yet,\npersisting design choices of these particle filters often conflict with the aim\nof online planning in RL, which is to obtain a policy improvement at the start\nof planning. Drawing inspiration from MCTS, we tailor SMC planners specifically\nfor RL by improving data generation within the planner through constrained\naction sampling and explicit terminal state handling, as well as improving\npolicy and value target estimation. This leads to our Trust-Region Twisted SMC\n(TRT-SMC), which shows improved runtime and sample-efficiency over baseline\nMCTS and SMC methods in both discrete and continuous domains.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T13:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.06050v1","title":"Low-loss far-infrared surface phonon polaritons in suspended SrTiO3\n  nanomembranes","summary":"Phonon polaritons (PhPs), excitations arising from the coupling of light with\nlattice vibrations, enable light confinement and local field enhancement, which\nis essential for various photonic and thermal applications. To date, PhPs with\nhigh confinement and low loss have been mainly observed in the mid-infrared\nregime and mostly in manually exfoliated flakes of van der Waals (vdW)\nmaterials. In this work, we demonstrate the existence of low-loss,\nthickness-tunable phonon polaritons in the far-infrared regime within\ntransferable free-standing SrTiO3 membranes synthesized through a scalable\napproach, achieving high figures of merit, which are comparable to the previous\nrecord values from the vdW materials. Leveraging atomic precision in thickness\ncontrol, large dimensions, and compatibility with mature oxide electronics,\nfunctional oxide membranes present a promising large-scale two-dimensional (2D)\nplatform alternative to vdW materials for on-chip polaritonic technologies in\nthe far-infrared regime.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-08T13:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.06061v1","title":"Non-reciprocal waves in two-dimensional electron systems with\n  temperature gradient","summary":"We demonstrate that the interaction of dc temperature gradient with ac\nmagnetic field in temperature-biased two-dimensional electron systems leads to\nformation of a new electromagnetic mode, a two-dimensional thermomagnetic wave\n(2d TMW). This wave is transverse electric and non-reciprocal, and its damping\nrate can be lower than that of conventional 2d plasma waves. The Q-factor of 2d\nTMW is independent of the wave vector. Numerical estimates show that in\nstate-of-the-art two-dimensional electrons systems the 2d TMW Q-factor is the\norder of $10^{-3}$. We discuss possible ways to overcome this issue.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T14:07:15Z"}
{"aid":"http://arxiv.org/abs/2504.06081v1","title":"On the interference of the scattered wave and the incident wave in light\n  scattering problems with Gaussian beams","summary":"We consider the light scattering problem for a Gaussian beam and a\n(spherical) particle at arbitrary location. Within the beam cross section, the\ntotal electromagnetic field is the superposition of the incident beam and the\nscattered wave. Using the Generalized Lorenz-Mie Theory (GLMT) as a vehicle to\naccess such scattering problems, we discuss the mathematical modeling of this\ninterference at short, large but finite and infinite distances from the\nscatterer. We show how to eliminate the errors that can arise from improper\nmodeling in the most straight-forward manner, that is superimposing the\nscattered wave with the closed-form expression for the Gaussian beam at a\nfinite distance from the particle. GLMT uses a low order beam model ($s^1$),\nbut using the known higher order models ($s^3$, $s^5$, $s^7$, ...) would not\nmitigate these errors as we discuss. The challenge lies in an appropriate\ndescription of the Gaussian beam at arbitrary distances from its focus, not in\nits description on the scale of a particle (located in or near the focus) nor\nin the expressions for the scattered field. Hence, the solutions described here\ncan readily be extended to light scattering frameworks other than GLMT and are\nthus also relevant for non-spherical particles.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T14:20:57Z"}
{"aid":"http://arxiv.org/abs/2504.06133v1","title":"Gravitational Baryogenesis in Extended Proca-Nuevo Gravity","summary":"In this article, we investigate the gravitational baryogenesis mechanism in\nthe framework of Extended Proca-Nuevo (EPN) gravity, a theory where a massive\nvector field is non-minimally coupled to the curvature. This analysis is\ncarried out for an early universe, encompassing three separate cosmological\nscenarios defined by power-law, exponential, and modified exponential scale\nfactors. By deriving the modified field equations from the EPN action, we\nobtain precise solutions for each scale factor, including the influence of the\nvector field. We compute the baryon-to-entropy ratio using the gravitational\nbaryogenesis formalism, where the baryon asymmetry arises from a dynamical\ncoupling of the baryon current with the derivative of the Ricci scalar. Our\nfindings demonstrate that the baryon-to-entropy ratio is consistent with\nobservational constraints in all scenarios, highlighting the potential of EPN\ngravity as a viable theory to explain the matter-antimatter asymmetry in the\nearly universe. The study further stresses the contribution of anisotropy and\nvector field dynamics to the cosmological evolution within modified gravity\nmodels.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T15:26:58Z"}
{"aid":"http://arxiv.org/abs/2504.06151v1","title":"Zerrow: True Zero-Copy Arrow Pipelines in Bauplan","summary":"Bauplan is a FaaS-based lakehouse specifically built for data pipelines: its\nexecution engine uses Apache Arrow for data passing between the nodes in the\nDAG. While Arrow is known as the \"zero copy format\", in practice, limited Linux\nkernel support for shared memory makes it difficult to avoid copying entirely.\nIn this work, we introduce several new techniques to eliminate nearly all\ncopying from pipelines: in particular, we implement a new kernel module that\nperforms de-anonymization, thus eliminating a copy to intermediate data. We\nconclude by sharing our preliminary evaluation on different workloads types, as\nwell as discussing our plan for future improvements.","main_category":"cs.OS","categories":"cs.OS,cs.DB","published":"2025-04-08T15:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.06157v1","title":"Hall Effect Thruster Forecasting using a Topological Approach for Data\n  Assimilation","summary":"Hall Effect Thrusters (HETs) are electric thrusters that eject heavy ionized\ngas particles from the spacecraft to generate thrust. Although traditionally\nthey were used for station keeping, recently They have been used for\ninterplanetary space missions due to their high delta-V potential and their\noperational longevity in contrast to other thrusters, e.g., chemical. However,\nthe operation of HETs involves complex processes such as ionization of gases,\nstrong magnetic fields, and complicated solar panel power supply interactions.\nTherefore, their operation is extremely difficult to model thus necessitating\nData Assimilation (DA) approaches for estimating and predicting their\noperational states. Because HET's operating environment is often noisy with\nnon-Gaussian sources, this significantly limits applicable DA tools. We\ndescribe a topological approach for data assimilation that bypasses these\nlimitations that does not depend on the noise model, and utilize it to forecast\nspatiotemporal plume field states of HETs. Our approach is a generalization of\nthe Topological Approach for Data Assimilation (TADA) method that allows\nincluding different forecast functions. We show how TADA can be combined with\nthe Long Short-Term Memory network for accurate forecasting. We then apply our\napproach to high-fidelity Hall Effect Thruster (HET) simulation data from the\nAir Force Research Laboratory (AFRL) rocket propulsion division where we\ndemonstrate the forecast resiliency of TADA on noise contaminated,\nhigh-dimensional data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T15:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.06178v1","title":"Flash Sculptor: Modular 3D Worlds from Objects","summary":"Existing text-to-3D and image-to-3D models often struggle with complex scenes\ninvolving multiple objects and intricate interactions. Although some recent\nattempts have explored such compositional scenarios, they still require an\nextensive process of optimizing the entire layout, which is highly cumbersome\nif not infeasible at all. To overcome these challenges, we propose Flash\nSculptor in this paper, a simple yet effective framework for compositional 3D\nscene/object reconstruction from a single image. At the heart of Flash Sculptor\nlies a divide-and-conquer strategy, which decouples compositional scene\nreconstruction into a sequence of sub-tasks, including handling the appearance,\nrotation, scale, and translation of each individual instance. Specifically, for\nrotation, we introduce a coarse-to-fine scheme that brings the best of both\nworlds--efficiency and accuracy--while for translation, we develop an\noutlier-removal-based algorithm that ensures robust and precise parameters in a\nsingle step, without any iterative optimization. Extensive experiments\ndemonstrate that Flash Sculptor achieves at least a 3 times speedup over\nexisting compositional 3D methods, while setting new benchmarks in\ncompositional 3D reconstruction performance. Codes are available at\nhttps://github.com/YujiaHu1109/Flash-Sculptor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T16:20:51Z"}
{"aid":"http://arxiv.org/abs/2504.06187v1","title":"Scaling Invariance: A Gateway to Phase Transitions","summary":"We explore the concept of scaling invariance in a type of dynamical systems\nthat undergo a transition from order (regularity) to disorder (chaos). The\nsystems are described by a two-dimensional, nonlinear mapping that preserves\nthe area in the phase space. The key variables are the action and the angle, as\nusual from Hamiltonian systems. The transition is influenced by a control\nparameter giving the form of the order parameter. We observe a scaling\ninvariance in the average squared action within the chaotic region, providing\nevidence that this change from regularity (integrability) to chaos\n(non-integrability) is akin to a second-order or continuous phase transition.\nAs the order parameter approaches zero, its response against the variation of\nthe control parameter (susceptibility) becomes increasingly pronounced (indeed\ndiverging), resembling a phase transition. These findings could not be obtained\nwithout a seminal paper on Phys. Rev. Lett. {\\bf 2004}, {\\em 93}, 014101.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-08T16:31:23Z"}
{"aid":"http://arxiv.org/abs/2504.06203v1","title":"Factorizing Defects from Generalized Pinning Fields","summary":"We introduce generalized pinning fields in conformal field theory that model\na large class of critical impurities at large distance, enriching the familiar\nuniversality classes. We provide a rigorous definition of such defects as\ncertain unbounded operators on the Hilbert space and prove that when inserted\non codimension-one surfaces they factorize the spacetime into two halves. The\nfactorization channels are further constrained by symmetries in the bulk. As a\ncorollary, we solve such critical impurities in the 2d minimal models and\nestablish the factorization phenomena previously observed for localized mass\ndeformations in the 3d ${\\rm O}(N)$ model.","main_category":"hep-th","categories":"hep-th,cond-mat.str-el,math.OA","published":"2025-04-08T16:47:34Z"}
{"aid":"http://arxiv.org/abs/2504.06211v1","title":"Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs","summary":"Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in\nprivacy-preserving and verifiable computing. ZKPs enable a proving party to\nprove the truth of a statement to a verifying party without revealing anything\nelse. ZKPs have applications in blockchain technologies, verifiable machine\nlearning, and electronic voting, but have yet to see widespread adoption due to\nthe computational complexity of the proving process. Recent works have\naccelerated the key primitives of state-of-the-art ZKP protocols on GPU and\nASIC. However, the protocols accelerated thus far face one of two challenges:\nthey either require a trusted setup for each application, or they generate\nlarger proof sizes with higher verification costs, limiting their applicability\nin scenarios with numerous verifiers or strict verification time constraints.\nThis work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art\nZKP protocol that supports both one-time, universal setup and small proof sizes\nfor typical ZKP applications in publicly verifiable, consensus-based systems.\nWe accelerate the entire protocol, including two major primitives: SumCheck and\nMulti-scalar Multiplications (MSMs). We develop a full-chip architecture using\n366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation\nprocess, achieving geometric mean speedups of 801$\\times$ over CPU baselines.","main_category":"cs.AR","categories":"cs.AR,cs.CR","published":"2025-04-08T16:56:10Z"}
{"aid":"http://arxiv.org/abs/2504.06223v1","title":"Generalized Bronnikov-Ellis wormhole solution in the\n  scalar-Einstein-Gauss-Bonnet $4d$ gravitational model","summary":"We consider the sEGB $4d$ gravitational model with a scalar field\n$\\varphi\\left(u\\right)$, Einstein and Gauss-Bonnet terms. The model action\ncontains a potential term $U\\left(\\varphi\\right))$, a Gauss-Bonnet coupling\nfunction $f\\left(\\varphi\\right)$ and a parameter $\\varepsilon = \\pm 1$, where\n$\\varepsilon = 1$ corresponds to the usual scalar field, and $\\varepsilon = -1$\nto the phantom field. In this paper, the sEGB reconstruction procedure\nconsidered in our previous paper is applied to the metric of the\nBronnikov-Ellis solution, which describes a massive wormhole in the model with\na phantom field (and zero potential). For this metric, written in the Buchdal\nparameterization with a radial variable $u$, we find a solution of the master\nequation for $ f\\left(\\varphi\\left(u\\right)\\right)$ with the integration\n(reconstruction) parameter $C_0$. We also find expressions for\n$U\\left(\\varphi\\left(u\\right)\\right)$ and $\\varepsilon \\dot{\\varphi} =\nh\\left(u\\right)$ for $\\varepsilon = \\pm 1$. We prove that for all non-trivial\nvalues of the parameter $C_0 \\neq 0$ the function $h\\left(u\\right)$ is not of\nconstant sign for all admissible $u \\in \\left(-\\infty , +\\infty\\right)$. This\nmeans that for a fixed value of the parameter $\\varepsilon = \\pm 1$ there is no\nnon-trivial sEGB reconstruction in which the scalar field is a purely ordinary\nfield ($\\varepsilon = 1$) or a purely phantom field ($\\varepsilon = - 1$).","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T17:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.06231v1","title":"Orb-v3: atomistic simulation at scale","summary":"We introduce Orb-v3, the next generation of the Orb family of universal\ninteratomic potentials. Models in this family expand the\nperformance-speed-memory Pareto frontier, offering near SoTA performance across\na range of evaluations with a >10x reduction in latency and > 8x reduction in\nmemory. Our experiments systematically traverse this frontier, charting the\ntrade-off induced by roto-equivariance, conservatism and graph sparsity.\nContrary to recent literature, we find that non-equivariant, non-conservative\narchitectures can accurately model physical properties, including those which\nrequire higher-order derivatives of the potential energy surface.\n  This model release is guided by the principle that the most valuable\nfoundation models for atomic simulation will excel on all fronts: accuracy,\nlatency and system size scalability. The reward for doing so is a new era of\ncomputational chemistry driven by high-throughput and mesoscale all-atom\nsimulations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:27:34Z"}
{"aid":"http://arxiv.org/abs/2504.06559v1","title":"TabKAN: Advancing Tabular Data Analysis using Kolmograv-Arnold Network","summary":"Tabular data analysis presents unique challenges due to its heterogeneous\nfeature types, missing values, and complex interactions. While traditional\nmachine learning methods, such as gradient boosting, often outperform deep\nlearning approaches, recent advancements in neural architectures offer\npromising alternatives. This paper introduces TabKAN, a novel framework that\nadvances tabular data modeling using Kolmogorov-Arnold Networks (KANs). Unlike\nconventional deep learning models, KANs leverage learnable activation functions\non edges, enhancing both interpretability and training efficiency. Our\ncontributions include: (1) the introduction of modular KAN-based architectures\ntailored for tabular data analysis, (2) the development of a transfer learning\nframework for KAN models, enabling effective knowledge transfer between\ndomains, (3) the development of model-specific interpretability for tabular\ndata learning, reducing reliance on post hoc and model-agnostic analysis, and\n(4) comprehensive evaluation of vanilla supervised learning across binary and\nmulti-class classification tasks. Through extensive benchmarking on diverse\npublic datasets, TabKAN demonstrates superior performance in supervised\nlearning while significantly outperforming classical and Transformer-based\nmodels in transfer learning scenarios. Our findings highlight the advantage of\nKAN-based architectures in efficiently transferring knowledge across domains,\nbridging the gap between traditional machine learning and deep learning for\nstructured data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T03:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.06567v1","title":"A Novel Angle-Delay-Doppler Estimation Scheme for AFDM-ISAC System in\n  Mixed Near-field and Far-field Scenarios","summary":"The recently proposed multi-chirp waveform, affine frequency division\nmultiplexing (AFDM), is considered as a potential candidate for integrated\nsensing and communication (ISAC). However, acquiring accurate target sensing\nparameter information becomes challenging due to fractional delay and Doppler\nshift occurrence, as well as effects introduced by the coexistence of\nnear-field (NF) and far-field (FF) targets associated with large-scale antenna\nsystems. In this paper, we propose a novel angle-delay-Doppler estimation\nscheme for AFDM-ISAC system in mixed NF and FF scenarios. Specifically, we\nmodel the received ISAC signals as a third-order tensor that admits a low-rank\nCANDECOMP/PARAFAC (CP) format. By employing the Vandermonde nature of the\nfactor matrix and the spatial smoothing technique, we develop a structured CP\ndecomposition method that guarantees the condition for uniqueness. We further\npropose a low-complexity estimation scheme to acquire target sensing parameters\nwith fractional values, including angle of arrival/departure (AoA/AoD), delay\nand Doppler shift accurately. We also derive the Cram\\'er-Rao Lower Bound\n(CRLB) as a benchmark and analyze the complexity of our proposed scheme.\nFinally, simulation results are provided to demonstrate the effectiveness and\nsuperiority of our proposed scheme.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T04:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.06572v1","title":"Domain Generalization via Discrete Codebook Learning","summary":"Domain generalization (DG) strives to address distribution shifts across\ndiverse environments to enhance model's generalizability. Current DG approaches\nare confined to acquiring robust representations with continuous features,\nspecifically training at the pixel level. However, this DG paradigm may\nstruggle to mitigate distribution gaps in dealing with a large space of\ncontinuous features, rendering it susceptible to pixel details that exhibit\nspurious correlations or noise. In this paper, we first theoretically\ndemonstrate that the domain gaps in continuous representation learning can be\nreduced by the discretization process. Based on this inspiring finding, we\nintroduce a novel learning paradigm for DG, termed Discrete Domain\nGeneralization (DDG). DDG proposes to use a codebook to quantize the feature\nmap into discrete codewords, aligning semantic-equivalent information in a\nshared discrete representation space that prioritizes semantic-level\ninformation over pixel-level intricacies. By learning at the semantic level,\nDDG diminishes the number of latent features, optimizing the utilization of the\nrepresentation space and alleviating the risks associated with the wide-ranging\nspace of continuous features. Extensive experiments across widely employed\nbenchmarks in DG demonstrate DDG's superior performance compared to\nstate-of-the-art approaches, underscoring its potential to reduce the\ndistribution gaps and enhance the model's generalizability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T04:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.06584v1","title":"CAFE-AD: Cross-Scenario Adaptive Feature Enhancement for Trajectory\n  Planning in Autonomous Driving","summary":"Imitation learning based planning tasks on the nuPlan dataset have gained\ngreat interest due to their potential to generate human-like driving behaviors.\nHowever, open-loop training on the nuPlan dataset tends to cause causal\nconfusion during closed-loop testing, and the dataset also presents a long-tail\ndistribution of scenarios. These issues introduce challenges for imitation\nlearning. To tackle these problems, we introduce CAFE-AD, a Cross-Scenario\nAdaptive Feature Enhancement for Trajectory Planning in Autonomous Driving\nmethod, designed to enhance feature representation across various scenario\ntypes. We develop an adaptive feature pruning module that ranks feature\nimportance to capture the most relevant information while reducing the\ninterference of noisy information during training. Moreover, we propose a\ncross-scenario feature interpolation module that enhances scenario information\nto introduce diversity, enabling the network to alleviate over-fitting in\ndominant scenarios. We evaluate our method CAFE-AD on the challenging public\nnuPlan Test14-Hard closed-loop simulation benchmark. The results demonstrate\nthat CAFE-AD outperforms state-of-the-art methods including rule-based and\nhybrid planners, and exhibits the potential in mitigating the impact of\nlong-tail distribution within the dataset. Additionally, we further validate\nits effectiveness in real-world environments. The code and models will be made\navailable at https://github.com/AlniyatRui/CAFE-AD.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-09T05:16:29Z"}
{"aid":"http://arxiv.org/abs/2504.06612v1","title":"A Hilbert--Mumford criterion for generalised Monge--Amp√®re equations","summary":"We give a new numerical criterion in the spirit of GIT for existence of\nsolutions to inverse Hessian equations, including in particular the J-equation.\nOur criterion is formulated in terms of stability of pairs in the sense of\nPaul. To that end, we build on previous work of the author with Dervan, and\ngeneralise a result of Zhang, proving isometry between generalised Chow line\nbundles and mixed Deligne pairings.","main_category":"math.DG","categories":"math.DG,math.AG","published":"2025-04-09T06:16:59Z"}
{"aid":"http://arxiv.org/abs/2504.06618v1","title":"Human-like compositional learning of visually-grounded concepts using\n  synthetic environments","summary":"The compositional structure of language enables humans to decompose complex\nphrases and map them to novel visual concepts, showcasing flexible\nintelligence. While several algorithms exhibit compositionality, they fail to\nelucidate how humans learn to compose concept classes and ground visual cues\nthrough trial and error. To investigate this multi-modal learning challenge, we\ndesigned a 3D synthetic environment in which an agent learns, via\nreinforcement, to navigate to a target specified by a natural language\ninstruction. These instructions comprise nouns, attributes, and critically,\ndeterminers, prepositions, or both. The vast array of word combinations\nheightens the compositional complexity of the visual grounding task, as\nnavigating to a blue cube above red spheres is not rewarded when the\ninstruction specifies navigating to \"some blue cubes below the red sphere\". We\nfirst demonstrate that reinforcement learning agents can ground determiner\nconcepts to visual targets but struggle with more complex prepositional\nconcepts. Second, we show that curriculum learning, a strategy humans employ,\nenhances concept learning efficiency, reducing the required training episodes\nby 15% in determiner environments and enabling agents to easily learn\nprepositional concepts. Finally, we establish that agents trained on determiner\nor prepositional concepts can decompose held-out test instructions and rapidly\nadapt their navigation policies to unseen visual object combinations.\nLeveraging synthetic environments, our findings demonstrate that multi-modal\nreinforcement learning agents can achieve compositional understanding of\ncomplex concept classes and highlight the efficacy of human-like learning\nstrategies in improving artificial systems' learning efficiency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:33:28Z"}
{"aid":"http://arxiv.org/abs/2504.06634v1","title":"Crafting Query-Aware Selective Attention for Single Image\n  Super-Resolution","summary":"Single Image Super-Resolution (SISR) reconstructs high-resolution images from\nlow-resolution inputs, enhancing image details. While Vision Transformer\n(ViT)-based models improve SISR by capturing long-range dependencies, they\nsuffer from quadratic computational costs or employ selective attention\nmechanisms that do not explicitly focus on query-relevant regions. Despite\nthese advancements, prior work has overlooked how selective attention\nmechanisms should be effectively designed for SISR. We propose SSCAN, which\ndynamically selects the most relevant key-value windows based on query\nsimilarity, ensuring focused feature extraction while maintaining efficiency.\nIn contrast to prior approaches that apply attention globally or heuristically,\nour method introduces a query-aware window selection strategy that better\naligns attention computation with important image regions. By incorporating\nfixed-sized windows, SSCAN reduces memory usage and enforces linear\ntoken-to-token complexity, making it scalable for large images. Our experiments\ndemonstrate that SSCAN outperforms existing attention-based SISR methods,\nachieving up to 0.14 dB PSNR improvement on urban datasets, guaranteeing both\ncomputational efficiency and reconstruction quality in SISR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:17:29Z"}
{"aid":"http://arxiv.org/abs/2504.06637v1","title":"SCI-Reason: A Dataset with Chain-of-Thought Rationales for Complex\n  Multimodal Reasoning in Academic Areas","summary":"Large Language Models (LLMs) and Large Multimodal Models (LMMs) demonstrate\nimpressive problem-solving skills in many tasks and domains. However, their\nability to reason with complex images in academic domains has not been\nsystematically investigated. To bridge this gap, we present SCI-Reason, a\ndataset for complex multimodel reasoning in academic areas. SCI-Reason aims to\ntest and improve the reasoning ability of large multimodal models using real\ncomplex images in academic domains. The dataset contains 12,066 images and\n12,626 question-answer pairs extracted from PubMed, divided into training,\nvalidation and test splits. Each question-answer pair also contains an accurate\nand efficient inference chain as a guide to improving the inference properties\nof the dataset. With SCI-Reason, we performed a comprehensive evaluation of 8\nwell-known models. The best performing model, Claude-3.7-Sonnet, only achieved\nan accuracy of 55.19%. Error analysis shows that more than half of the model\nfailures are due to breakdowns in multi-step inference chains rather than\nerrors in primary visual feature extraction. This finding underscores the\ninherent limitations in reasoning capabilities exhibited by current multimodal\nmodels when processing complex image analysis tasks within authentic academic\ncontexts. Experiments on open-source models show that SCI-Reason not only\nenhances reasoning ability but also demonstrates cross-domain generalization in\nVQA tasks. We also explore future applications of model inference capabilities\nin this domain, highlighting its potential for future research.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-09T07:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.06651v1","title":"Collision avoidance from monocular vision trained with novel view\n  synthesis","summary":"Collision avoidance can be checked in explicit environment models such as\nelevation maps or occupancy grids, yet integrating such models with a\nlocomotion policy requires accurate state estimation. In this work, we consider\nthe question of collision avoidance from an implicit environment model. We use\nmonocular RGB images as inputs and train a collisionavoidance policy from\nphotorealistic images generated by 2D Gaussian splatting. We evaluate the\nresulting pipeline in realworld experiments under velocity commands that bring\nthe robot on an intercept course with obstacles. Our results suggest that RGB\nimages can be enough to make collision-avoidance decisions, both in the room\nwhere training data was collected and in out-of-distribution environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:39:12Z"}
{"aid":"http://arxiv.org/abs/2504.06661v1","title":"Domain-Conditioned Scene Graphs for State-Grounded Task Planning","summary":"Recent robotic task planning frameworks have integrated large multimodal\nmodels (LMMs) such as GPT-4V. To address grounding issues of such models, it\nhas been suggested to split the pipeline into perceptional state grounding and\nsubsequent state-based planning. As we show in this work, the state grounding\nability of LMM-based approaches is still limited by weaknesses in granular,\nstructured, domain-specific scene understanding. To address this shortcoming,\nwe develop a more structured state grounding framework that features a\ndomain-conditioned scene graph as its scene representation. We show that such\nrepresentation is actionable in nature as it is directly mappable to a symbolic\nstate in classical planning languages such as PDDL. We provide an instantiation\nof our state grounding framework where the domain-conditioned scene graph\ngeneration is implemented with a lightweight vision-language approach that\nclassifies domain-specific predicates on top of domain-relevant object\ndetections. Evaluated across three domains, our approach achieves significantly\nhigher state estimation accuracy and task planning success rates compared to\nthe previous LMM-based approaches.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:51:46Z"}
{"aid":"http://arxiv.org/abs/2504.06681v1","title":"Mechanical stability of resonant Bose-Fermi mixtures","summary":"We investigate the mechanical stability of Bose-Fermi mixtures at zero\ntemperature in the presence of a tunable Feshbach resonance, which induces a\ncompetition between boson condensation and boson-fermion pairing when the boson\ndensity is smaller than the fermion density. Using a many-body diagrammatic\napproach validated by fixed-node Quantum Monte Carlo calculations and supported\nby recent experimental observations, we determine the minimal amount of\nboson-boson repulsion required to guarantee the stability of the mixture across\nthe entire range of boson-fermion interactions from weak to strong coupling.\nOur stability phase diagrams indicate that mixtures with boson-to-fermion mass\nratios near two, such as the $^{87}$Rb-$^{40}$K system, exhibit optimal\nstability conditions. Moreover, by applying our results to a recent experiment\nwith a $^{23}$Na-$^{40}$K mixture, we find that the boson-boson repulsion was\ninsufficient to ensure stability, suggesting that the experimental timescale\nwas short enough to avoid mechanical collapse. On the other hand, we also show\nthat even in the absence of boson-boson repulsion, Bose-Fermi mixtures become\nintrinsically stable beyond a certain coupling strength, preceding the quantum\nphase transition associated with the vanishing of the bosonic condensate. We\nthus propose an experimental protocol for observing this quantum phase\ntransition in a mechanically stable configuration.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-09T08:39:14Z"}
{"aid":"http://arxiv.org/abs/2504.06705v1","title":"Evolution of the Comptonizing medium of the black-hole candidate Swift\n  J1727.8$-$1613 along the hard to hard-intermediate state transition using\n  NICER","summary":"We analyse the properties of the Comptonizing medium in the black-hole X-ray\nbinary Swift J1727.8$-$1613 using the time-dependent Comptonization model\nvkompth, using NICER observations of type-C QPOs in the hard and\nhard-intermediate states. During the 2023 outburst of the source, we measure\nthe rms and phase lags of the QPO across 45 observations as the QPO frequency,\n$\\nu_{\\rm QPO}$, evolves from $\\sim 0.3$ Hz to $\\sim 7$ Hz. By simultaneously\nfitting the time-averaged spectrum of the source and the rms and lag spectra of\nthe QPO, we derive the evolution of the disk and corona parameters. At\n$\\nu_{\\rm QPO} = 0.34$ Hz, the QPO phase lags are hard, with 10 keV photons\nlagging 0.5 keV photons by $\\sim 0.5$ rad. As $\\nu_{\\rm QPO}$ increases, the\nlags for the same energy bands decrease, reaching near zero at $\\nu_{\\rm QPO}\n\\sim 1.2$ Hz, and then reverse to soft lags of $\\sim -1.1$ rad at $\\nu_{\\rm\nQPO} \\sim 7$ Hz. Initially, the inner radius of the accretion disk is truncated\nat $\\sim 30-40 R_g$ (assuming a 10 solar-mass black hole) and, as the QPO\nfrequency increases, the truncation radius decreases down to $\\sim 10 R_g$.\nInitially, two coronas of sizes of $\\sim 6.5 \\times 10^3$ km and $\\sim 2 \\times\n10^3$ km, extend over the disk and are illuminated by different regions of the\ndisk. As the QPO frequency increases, both the coronas shrink to $\\sim 2 \\times\n10^3$ km at $\\nu_{\\rm QPO} = 2.5$ Hz. Following a data gap, one corona expands\nagain, peaking at a size of $\\sim 2 \\times 10^4$ km. We interpret the evolution\nof the coronal size in the context of accompanying radio observations,\ndiscussing its implications for the interplay between the corona and the jet.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA,astro-ph.IM","published":"2025-04-09T09:08:56Z"}
{"aid":"http://arxiv.org/abs/2504.06715v1","title":"Bistability and complex bifurcation diagrams generated by waning and\n  boosting of immunity","summary":"We investigate an epidemiological model that incorporates waning of immunity\nat the individual level and boosting of the immune system upon re-exposure to\nthe pathogen. When immunity is fully restored upon boosting, the system can be\nexpressed as an SIRS-type model with discrete and distributed delays. We\nconduct a numerical bifurcation analysis varying the boosting force and the\nmaximum period of immunity (in the absence of boosting), while keeping other\nparameters fixed at values representative of a highly infectious disease like\npertussis. The stability switches of the endemic equilibrium, identified\nnumerically, are validated using an established analytical approach, confirming\nthat the equilibrium is unstable in a bounded parameter region, and stable\noutside this region. Using recently developed continuation methods for models\nwith discrete and distributed delays, we explore periodic solutions and their\nbifurcations. Our analysis significantly extends previous findings and reveals\na rich dynamical landscape, including catastrophic bifurcations of limit\ncycles, torus bifurcations, and bistability regions where two stable periodic\nsolutions coexist, differing in amplitude and period. These complex\nbifurcations have critical public health implications: perturbations--such as\nnon-pharmaceutical interventions--can shift the system between attractors,\nleading to long-term consequences from short-term measures.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T09:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.06728v1","title":"Light-field dressing of transient photo-excited states above $E_F$","summary":"Time-periodic light-field provides an emerging pathway for dynamically\nengineering quantum materials by forming hybrid states between photons and\nBloch electrons. So far, experimental progress on light-field dressed states\nhas been mainly focused on the occupied states, however, it is unclear if the\ntransient photo-excited states above the Fermi energy $E_F$ can also be\ndressed, leaving the dynamical interplay between photo-excitation and\nlight-field dressing elusive. Here, we provide direct experimental evidence for\nlight-field dressing of the transient photo-excited surface states above $E_F$,\nwhich exhibits distinct dynamics with a delay response as compared to\nlight-field dressed states below $E_F$. Our work reveals the dual roles of the\npump pulse in both photo-excitation and light-field dressing, providing a more\ncomprehensive picture with new insights on the light-induced manipulation of\ntransient electronic states.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T09:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.06768v1","title":"FedMerge: Federated Personalization via Model Merging","summary":"One global model in federated learning (FL) might not be sufficient to serve\nmany clients with non-IID tasks and distributions. While there has been\nadvances in FL to train multiple global models for better personalization, they\nonly provide limited choices to clients so local finetuning is still\nindispensable. In this paper, we propose a novel ``FedMerge'' approach that can\ncreate a personalized model per client by simply merging multiple global models\nwith automatically optimized and customized weights. In FedMerge, a few global\nmodels can serve many non-IID clients, even without further local finetuning.\nWe formulate this problem as a joint optimization of global models and the\nmerging weights for each client. Unlike existing FL approaches where the server\nbroadcasts one or multiple global models to all clients, the server only needs\nto send a customized, merged model to each client. Moreover, instead of\nperiodically interrupting the local training and re-initializing it to a global\nmodel, the merged model aligns better with each client's task and data\ndistribution, smoothening the local-global gap between consecutive rounds\ncaused by client drift. We evaluate FedMerge on three different non-IID\nsettings applied to different domains with diverse tasks and data types, in\nwhich FedMerge consistently outperforms existing FL approaches, including\nclustering-based and mixture-of-experts (MoE) based methods.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T10:44:14Z"}
{"aid":"http://arxiv.org/abs/2504.06785v1","title":"Zero-Shot Image-Based Large Language Model Approach to Road Pavement\n  Monitoring","summary":"Effective and rapid evaluation of pavement surface condition is critical for\nprioritizing maintenance, ensuring transportation safety, and minimizing\nvehicle wear and tear. While conventional manual inspections suffer from\nsubjectivity, existing machine learning-based methods are constrained by their\nreliance on large and high-quality labeled datasets, which require significant\nresources and limit adaptability across varied road conditions. The\nrevolutionary advancements in Large Language Models (LLMs) present significant\npotential for overcoming these challenges. In this study, we propose an\ninnovative automated zero-shot learning approach that leverages the image\nrecognition and natural language understanding capabilities of LLMs to assess\nroad conditions effectively. Multiple LLM-based assessment models were\ndeveloped, employing prompt engineering strategies aligned with the Pavement\nSurface Condition Index (PSCI) standards. These models' accuracy and\nreliability were evaluated against official PSCI results, with an optimized\nmodel ultimately selected. Extensive tests benchmarked the optimized model\nagainst evaluations from various levels experts using Google Street View road\nimages. The results reveal that the LLM-based approach can effectively assess\nroad conditions, with the optimized model -employing comprehensive and\nstructured prompt engineering strategies -outperforming simpler configurations\nby achieving high accuracy and consistency, even surpassing expert evaluations.\nMoreover, successfully applying the optimized model to Google Street View\nimages demonstrates its potential for future city-scale deployments. These\nfindings highlight the transformative potential of LLMs in automating road\ndamage evaluations and underscore the pivotal role of detailed prompt\nengineering in achieving reliable assessments.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-09T11:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.06796v1","title":"Learning in Spiking Neural Networks with a Calcium-based Hebbian Rule\n  for Spike-timing-dependent Plasticity","summary":"Understanding how biological neural networks are shaped via local plasticity\nmechanisms can lead to energy-efficient and self-adaptive information\nprocessing systems, which promises to mitigate some of the current roadblocks\nin edge computing systems. While biology makes use of spikes to seamless use\nboth spike timing and mean firing rate to modulate synaptic strength, most\nmodels focus on one of the two. In this work, we present a Hebbian local\nlearning rule that models synaptic modification as a function of calcium traces\ntracking neuronal activity. We show how the rule reproduces results from spike\ntime and spike rate protocols from neuroscientific studies. Moreover, we use\nthe model to train spiking neural networks on MNIST digit recognition to show\nand explain what sort of mechanisms are needed to learn real-world patterns. We\nshow how our model is sensitive to correlated spiking activity and how this\nenables it to modulate the learning rate of the network without altering the\nmean firing rate of the neurons nor the hyparameters of the learning rule. To\nthe best of our knowledge, this is the first work that showcases how spike\ntiming and rate can be complementary in their role of shaping the connectivity\nof spiking neural networks.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-09T11:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.06816v1","title":"A Graph Diffusion Algorithm for Lexical Similarity Evaluation","summary":"In this paper, we present an algorithm for evaluating lexical similarity\nbetween a given language and several reference language clusters. As an input,\nwe have a list of concepts and the corresponding translations in all considered\nlanguages. Moreover, each reference language is assigned to one of $c$ language\nclusters. For each of the concepts, the algorithm computes the distance between\neach pair of translations. Based on these distances, it constructs a weighted\ndirected graph, where every vertex represents a language. After, it solves a\ngraph diffusion equation with a Dirichlet boundary condition, where the unknown\nis a map from the vertex set to $\\mathbb{R}^c$. The resulting coordinates are\nvalues from the interval $[0,1]$ and they can be interpreted as probabilities\nof belonging to each of the clusters or as a lexical similarity distribution\nwith respect to the reference clusters. The distances between translations are\ncalculated using phonetic transcriptions and a modification of the\nDamerau-Levenshtein distance. The algorithm can be useful in analyzing\nrelationships between languages spoken in multilingual territories with a lot\nof mutual influences. We demonstrate this by presenting a case study regarding\nvarious European languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.06864v1","title":"Emergent Theory for Constitutive Relations in Classical Defect Systems","summary":"Optical, acoustic, hydrodynamic, and thermal defect systems are often studied\nby analogy with each other. This may indicate that we may find a emergent\ntheory for constitutive relations of classical defect systems. Start with\nthermal systems, we put up with a bootstrap method to describe classical\ntransport. We conjecture that Landau-Khalatnikov equation could provide heat\nconstitutive relations when taking heat flux as order parameter. We show that\nthe corresponding effctive Lagrangian has similar form of that of Wick-rotated\ncomplex scalar field theory at non-relativistic limit, and only in perfect\nconducting situation that this system is a canonical ensemble. We argue that\nour method could be generalized to other systems besides thermal ones. By\nanalogy with ferroelectrics, we propose the thermal domain model, which is a\nconserved current XY model. Phase transition of the thermal system is\nqualitatively discussed in this model.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.supr-con,hep-th","published":"2025-04-09T13:13:14Z"}
{"aid":"http://arxiv.org/abs/2504.06873v1","title":"A note on measurings and higher order Hochschild homology of algebras","summary":"We know that coalgebra measurings behave like generalized maps between\nalgebras. In this note, we show that coalgebra measurings between commutative\nalgebras induce morphisms between higher order Hochschild homology groups of\nalgebras. By higher order Hochschild homology, we mean the the Hochschild\nhomology groups of a commutative algebra with respect to a simplicial set as\nintroduced by Pirashvili.","main_category":"math.RA","categories":"math.RA","published":"2025-04-09T13:24:20Z"}
{"aid":"http://arxiv.org/abs/2504.06879v1","title":"Machine Learning Approach to Study of Low Energy Alpha-Deuteron Elastic\n  Scattering using Phase Function Method","summary":"Central idea: To obtain the interaction potential using the inverse\nscattering method, we have employed the Physics-Informed Machine Learning\n(PIML) approach. In this framework, the machine learning algorithm is guided by\nthe underlying physical laws, enabling the accurate extraction of the inverse\nscattering potential from the elastic scattering data. Methodology: As a\nreference potential, a combination of three smoothly joined Morse functions has\nbeen utilized, characterized by ten model parameters. These parameters are\noptimized in an iterative fashion using a Genetic Algorithm to ensure the best\nfit to the phase shifts extracted from the experimental scattering data. The\nprocess of optimization is guided by the computed scattering phase shifts by\nsolving the phase equation using 5th order RK-method for the reference\npotential in each iteration Results: Our approach yields inverse potentials for\nboth single and multi channel scattering. Using the Scattering Phase Shifts\nobtained from these inverse potentials, we calculate the partial cross-section\nto determine the resonance energies and decay width. The obtain values of\nresonance energies and decay width for 3D1, 3D2 and 3D3 states of\nalpha-deuteron are in correspondence with the experimental results. Conclusion:\nIt can be concluded that our machine learning-based approach for constructing\nthe inverse potential offers a novel and complementary technique to existing\ndirect methods.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-09T13:34:41Z"}
{"aid":"http://arxiv.org/abs/2504.06881v1","title":"Compound and Parallel Modes of Tropical Convolutional Neural Networks","summary":"Convolutional neural networks have become increasingly deep and complex,\nleading to higher computational costs. While tropical convolutional neural\nnetworks (TCNNs) reduce multiplications, they underperform compared to standard\nCNNs. To address this, we propose two new variants - compound TCNN (cTCNN) and\nparallel TCNN (pTCNN)-that use combinations of tropical min-plus and max-plus\nkernels to replace traditional convolution kernels. This reduces\nmultiplications and balances efficiency with performance. Experiments on\nvarious datasets show that cTCNN and pTCNN match or exceed the performance of\nother CNN methods. Combining these with conventional CNNs in deeper\narchitectures also improves performance. We are further exploring simplified\nTCNN architectures that reduce parameters and multiplications with minimal\naccuracy loss, aiming for efficient and effective models.","main_category":"cs.CV","categories":"cs.CV,cs.AI,I.2.6","published":"2025-04-09T13:36:11Z"}
{"aid":"http://arxiv.org/abs/2504.06898v1","title":"Identifying and mitigating errors in hole spin qubit readout","summary":"High-fidelity readout of spin qubits in semiconductor quantum dots can be\nachieved by combining a radio-frequency (RF) charge sensor together with\nspin-to-charge conversion and Pauli spin blockade. However, reaching high\nreadout fidelities in hole spin qubits remains elusive and is complicated by a\ncombination of site-dependent spin anisotropies and short spin relaxation\ntimes. Here, we analyze the different error processes that arise during readout\nusing a double-latched scheme in a germanium double quantum dot hole spin qubit\nsystem. We first investigate the spin-to-charge conversion process as a\nfunction of magnetic field orientation, and configure the system to\nadiabatically map the $\\lvert \\downarrow\\downarrow \\rangle$ state to the only\nnon-blockaded state. We reveal a strong dependence of the spin relaxation rates\non magnetic field strength and minimize this relaxation by operating at low\nfields. We further characterize and mitigate the error processes that arise\nduring the double-latching process. By combining an RF charge sensor, a\ndouble-latching process, and optimized magnetic field parameters, we achieve a\nsingle-shot single-qubit state-preparation-and-measurement fidelity of 97.0%,\nthe highest reported fidelity for hole spin qubits. Unlike prior works and\nvital to usability, we simultaneously maintain universal control of both spins.\nThese findings lay the foundation for the reproducible achievement of\nhigh-fidelity readout in hole-based spin quantum processors.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-09T13:57:26Z"}
{"aid":"http://arxiv.org/abs/2504.06901v1","title":"Classification of algebraic tangles","summary":"We study algebraic tangles as fundamental components in knot theory,\ndeveloping a systematic approach to classify and tabulate prime tangles using a\nnovel canonical representation. The canonical representation enables us to\ndistinguish mutant tangles, which fills the gaps in previous classifications.\nMoreover, we increase the classification of prime tangles up to 14 crossings\nand analyze tangle symmetry groups. We provide a database of our results:\nhttps://tangleinfo.cent.uw.edu.pl.","main_category":"math.GT","categories":"math.GT,math.AT,math.GR,math.NT","published":"2025-04-09T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.06903v1","title":"Network Cross-Validation and Model Selection via Subsampling","summary":"Complex and larger networks are becoming increasingly prevalent in scientific\napplications in various domains. Although a number of models and methods exist\nfor such networks, cross-validation on networks remains challenging due to the\nunique structure of network data. In this paper, we propose a general\ncross-validation procedure called NETCROP (NETwork CRoss-Validation using\nOverlapping Partitions). The key idea is to divide the original network into\nmultiple subnetworks with a shared overlap part, producing training sets\nconsisting of the subnetworks and a test set with the node pairs between the\nsubnetworks. This train-test split provides the basis for a network\ncross-validation procedure that can be applied on a wide range of model\nselection and parameter tuning problems for networks. The method is\ncomputationally efficient for large networks as it uses smaller subnetworks for\nthe training step. We provide methodological details and theoretical guarantees\nfor several model selection and parameter tuning tasks using NETCROP. Numerical\nresults demonstrate that NETCROP performs accurate cross-validation on a\ndiverse set of network model selection and parameter tuning problems. The\nresults also indicate that NETCROP is computationally much faster while being\noften more accurate than the existing methods for network cross-validation.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-09T14:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.06909v1","title":"Climate impacts of equatorial superrotation","summary":"While it is expected that the large-scale tropical circulation should undergo\nsome changes in a warmer climate, it remains an open question whether its\ncharacteristic features, such as the Hadley cell, the intertropical convergence\nzone, or the weak surface easterlies, could take a completely different shape.\nAs an example, it has been hypothesized that the Earth's atmosphere may have\nexperienced equatorial superrotation -- i.e. westerly winds at the equator --\nduring its history. The possibility of equatorial superrotation has been\nstudied in a range of planetary atmospheres, including Earth-like ones, with\nthe objective of understanding the underlying dynamical processes. However, the\nbroader impact that this dramatic circulation change would have on the climate\nsystem is practically unexplored. This is the question we address here. We\nperform idealized GCM simulations with an imposed equatorial torque to\ninvestigate how a forced superrotating atmosphere affects surface temperature\nand the water cycle. We show that these effects are quite large and directly\nrelated to the global circulation changes, which extend beyond the tropical\natmosphere. Using tools including a forcing/feedback analysis and a moist\nenergy balance model, we argue that the dominant mechanism is changes in\natmospheric energy transport, driven in particular by the collapse of the\nmeridional overturning circulation, and to a smaller extent by the appearance\nof an equatorial jet, and the concomitant redistribution of moisture in the\ntropics, leading to a much weaker relative humidity gradient which has strong\nradiative effects.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-09T14:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.06913v1","title":"Controlling a Social Network of Individuals with Coevolving Actions and\n  Opinions","summary":"In this paper, we consider a population of individuals who have actions and\nopinions, which coevolve, mutually influencing one another on a complex network\nstructure. In particular, we formulate a control problem for this social\nnetwork, in which we assume that we can inject into the network a committed\nminority -- a set of stubborn nodes -- with the objective of steering the\npopulation, initially at a consensus, to a different consensus state. Our study\nfocuses on two main objectives: i) determining the conditions under which the\ncommitted minority succeeds in its goal, and ii) identifying the optimal\nplacement for such a committed minority. After deriving general monotone\nconvergence result for the controlled dynamics, we leverage these results to\nbuild a computationally-efficient algorithm to solve the first problem and an\neffective heuristics for the second problem, which we prove to be NP-complete.\nThe proposed methodology is illustrated though academic examples, and\ndemonstrated on a real-world case study.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.DS","published":"2025-04-09T14:20:46Z"}
{"aid":"http://arxiv.org/abs/2504.06939v1","title":"FeedbackEval: A Benchmark for Evaluating Large Language Models in\n  Feedback-Driven Code Repair Tasks","summary":"Code repair is a fundamental task in software development, facilitating\nefficient bug resolution and software maintenance. Although large language\nmodels (LLMs) have demonstrated considerable potential in automated code\nrepair, their ability to comprehend and effectively leverage diverse types of\nfeedback remains insufficiently understood. To bridge this gap, we introduce\nFeedbackEval, a systematic benchmark for evaluating LLMs' feedback\ncomprehension and performance in code repair tasks. We conduct a comprehensive\nempirical study on five state-of-the-art LLMs, including GPT-4o, Claude-3.5,\nGemini-1.5, GLM-4, and Qwen2.5, to evaluate their behavior under both\nsingle-iteration and iterative code repair settings. Our results show that\nstructured feedback, particularly in the form of test feedback, leads to the\nhighest repair success rates, while unstructured feedback proves significantly\nless effective. Iterative feedback further enhances repair performance, though\nthe marginal benefit diminishes after two or three rounds. Moreover, prompt\nstructure is shown to be critical: incorporating docstrings, contextual\ninformation, and explicit guidelines substantially improves outcomes, whereas\npersona-based, chain-of-thought, and few-shot prompting strategies offer\nlimited benefits in single-iteration scenarios. This work introduces a robust\nbenchmark and delivers practical insights to advance the understanding and\ndevelopment of feedback-driven code repair using LLMs.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T14:43:08Z"}
{"aid":"http://arxiv.org/abs/2504.06951v1","title":"GLT hidden structures in mean-field quantum spin systems","summary":"This work explores structured matrix sequences arising in mean-field quantum\nspin systems. We express these sequences within the framework of generalized\nlocally Toeplitz (GLT) $*$-algebras, leveraging the fact that each GLT matrix\nsequence has a unique GLT symbol. This symbol characterizes both the asymptotic\nsingular value distribution and, for Hermitian or quasi-Hermitian sequences,\nthe asymptotic spectral distribution. Specifically, we analyze two cases of\nreal symmetric matrix sequences stemming from mean-field quantum spin systems\nand determine their associated distributions using GLT theory. Our study\nconcludes with visualizations and numerical tests that validate the theoretical\nfindings, followed by a discussion of open problems and future directions.","main_category":"quant-ph","categories":"quant-ph,cs.NA,math.NA","published":"2025-04-09T14:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.06990v1","title":"Enhancing TiFe Alloy Activation for Hydrogen Storage Through Al, Cr, Co,\n  and Cu Substitutions as a Step Towards Future Recycling","summary":"This study investigates the activation behavior of $TiFe_{0.80}$-$X_{0.20}$\n(X = Co, Cu, Cr, Al) alloys to identify the most effective materials for\nproducing hydrogen storage alloys from recycled sources in view of a circular\neconomy perspective. Activation was tested using two methods: a Sievert\nVolumetric Apparatus at room temperature and 64 bar of hydrogen, and\nhigh-pressure differential scanning calorimetry with 50 bar hydrogen under\nthermal cycles up to 400 {\\deg}C. Activation properties were analyzed by\nassessing time for incubation and for full charging, that are influenced,\nrespectively, by surface and bulk diffusion of hydrogen. Results showed that\nCr-substituted alloys are rapidly activated, due to the presence of $TiCr_{2}$\ncompound, while Al-containing alloys absorbed hydrogen immediately. In\ncontrast, Co- and Cu-substituted alloys required extended activation times, due\nto less quantity of secondary phases and limited diffusion channels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-09T15:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.06993v1","title":"Screening of material defects using universal machine-learning\n  interatomic potentials","summary":"Finding new materials with previously unknown atomic structure or materials\nwith optimal set of properties for a specific application greatly benefits from\ncomputational modeling. Recently, such screening has been dramatically\naccelerated by the invent of universal machine-learning interatomic potentials\nthat offer first principles accuracy at orders of magnitude lower computational\ncost. Their application to the screening of defects with desired properties or\nto finding new stable compounds with high density of defects, however, has not\nbeen explored. Here, we show that the universal machine-learning interatomic\npotentials have reached sufficient accuracy to enable large-scale screening of\ndefective materials. We carried out vacancy calculations for 86 259 materials\nin the Materials Project database and analyzed the formation energies in terms\nof oxidation numbers. We further demonstrate the application of these models\nfor finding new materials at or below the convex hull of known materials and\nfor simulated etching of low-dimensional materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-09T16:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.07010v1","title":"Assumption-free fidelity bounds for hardware noise characterization","summary":"In the Quantum Supremacy regime, quantum computers may overcome classical\nmachines on several tasks if we can estimate, mitigate, or correct unavoidable\nhardware noise. Estimating the error requires classical simulations, which\nbecome unfeasible in the Quantum Supremacy regime. We leverage Machine Learning\ndata-driven approaches and Conformal Prediction, a Machine Learning uncertainty\nquantification tool known for its mild assumptions and finite-sample validity,\nto find theoretically valid upper bounds of the fidelity between noiseless and\nnoisy outputs of quantum devices. Under reasonable extrapolation assumptions,\nthe proposed scheme applies to any Quantum Computing hardware, does not require\nmodeling the device's noise sources, and can be used when classical simulations\nare unavailable, e.g. in the Quantum Supremacy regime.","main_category":"quant-ph","categories":"quant-ph,cs.LG,stat.ML","published":"2025-04-09T16:27:52Z"}
{"aid":"http://arxiv.org/abs/2504.07032v1","title":"Restoring the Forecasting Power of Google Trends with Statistical\n  Preprocessing","summary":"Google Trends reports how frequently specific queries are searched on Google\nover time. It is widely used in research and industry to gain early insights\ninto public interest. However, its data generation mechanism introduces missing\nvalues, sampling variability, noise, and trends. These issues arise from\nprivacy thresholds mapping low search volumes to zeros, daily sampling\nvariations causing discrepancies across historical downloads, and algorithm\nupdates altering volume magnitudes over time. Data quality has recently\ndeteriorated, with more zeros and noise, even for previously stable queries. We\npropose a comprehensive statistical methodology to preprocess Google Trends\nsearch information using hierarchical clustering, smoothing splines, and\ndetrending. We validate our approach by forecasting U.S. influenza\nhospitalizations with a univariate ARIMAX model. Compared to omitting exogenous\nvariables, our results show that raw Google Trends data degrades modeling\nperformance, while preprocessed signals enhance forecast accuracy by 58%\nnationally and 24% at the state level.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-09T16:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.07043v1","title":"BIA Transmission in Rate Splitting-based Optical Wireless Networks","summary":"Optical wireless communication (OWC) has recently received massive interest\nas a new technology that can support the enormous data traffic increasing on\ndaily basis. In particular, laser-based OWC networks can provide terabits per\nsecond (Tbps) aggregate data rates. However, the emerging OWC networks require\na high number of optical access points (APs), each AP corresponding to an\noptical cell, to provide uniform coverage for multiple users. Therefore,\ninter-cell interference (ICI) and multi-user interference (MUI) are crucial\nissues that must be managed efficiently to provide high spectral efficiency. In\nradio frequency (RF) networks, rate splitting (RS) is proposed as a\ntransmission scheme to serve multiple users simultaneously following a certain\nstrategy. It was shown that RS provides high data rates compared to orthogonal\nand non-orthogonal interference management schemes. Considering the high\ndensity of OWC networks, the application of RS within each optical cell might\nnot be practical due to severe ICI. In this paper, a new strategy is derived\nreferred to as blind interference alignment-rate splitting (BIA-RS) to fully\ncoordinate the transmission among the optical APs, while determining the\nprecoding matrices of multiple groups of users formed beforehand. Therefore, RS\ncan be implemented within each group to manage MUI. The proposed BIA-RS scheme\nrequires two layers of power allocation to achieve high performance. Given\nthat, a max-min fractional optimization problem is formulated to optimally\ndistribute the power budget among the groups and the messages intended to the\nusers of each group. Finally, a power allocation algorithm is designed with\nmultiple Lagrangian multipliers to provide practical and sub-optimal solutions.\nThe results show the high performance of the proposed scheme compared to other\ncounterpart schemes.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T17:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.07051v1","title":"Revisiting X-ray polarization of the shell of Cassiopeia A using\n  spectropolarimetric analysis","summary":"X-ray synchrotron radiation is expected to be highly polarized. Thanks to the\nImaging X-ray Polarimetry Explorer (IXPE), it is now possible to evaluate the\ndegree of X-ray polarization in sources such as supernova remnants (SNRs).\nJointly using IXPE data and high-resolution Chandra observations, we perform a\nspatially resolved spectropolarimetric analysis of SNR Cassiopeia A (Cas A). We\nfocus in the 3-6 keV energy band on regions near the shell dominated by\nnonthermal synchrotron emission. By combining IXPE's polarization sensitivity\nwith Chandra's higher spatial and spectral resolution, we constrain the local\npolarization degree (PD) and polarization angle (PA) across the remnant. Our\nanalysis reveals PD values ranging locally from 10% to 26%, showing significant\nregional variations that underscore the complex magnetic field morphology of\nCas A. The polarization vectors indicate a predominantly radial magnetic field,\nconsistent with previous studies. Thanks to the improved modeling of thermal\ncontamination using Chandra data, we retrieve higher PD values compared to\nearlier IXPE analysis and more significant detections with respect to the\nstandard IXPEOBSSIM analysis. Finally, we also estimate the degree of magnetic\nturbulence {\\eta} from the measured photon index and PD, under the assumption\nof an isotropic fluctuating field across the shell of Cas A.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T17:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.07054v1","title":"Weighted Lojasiewicz inequalities and regularity of harmonic map flow","summary":"At a finite-time singularity of harmonic map flow in the critical dimension,\nwe show that a Lojasiewicz inequality between the quantities appearing in\nStruwe's monotonicity formula implies continuity of the body map and the\nno-neck property for bubble-tree decompositions. We prove such an inequality\nwhen the target is $S^2,$ yielding both properties in this case.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-04-09T17:14:34Z"}
{"aid":"http://arxiv.org/abs/2504.07437v1","title":"Unifying and extending Diffusion Models through PDEs for solving Inverse\n  Problems","summary":"Diffusion models have emerged as powerful generative tools with applications\nin computer vision and scientific machine learning (SciML), where they have\nbeen used to solve large-scale probabilistic inverse problems. Traditionally,\nthese models have been derived using principles of variational inference,\ndenoising, statistical signal processing, and stochastic differential\nequations. In contrast to the conventional presentation, in this study we\nderive diffusion models using ideas from linear partial differential equations\nand demonstrate that this approach has several benefits that include a\nconstructive derivation of the forward and reverse processes, a unified\nderivation of multiple formulations and sampling strategies, and the discovery\nof a new class of models. We also apply the conditional version of these models\nto solving canonical conditional density estimation problems and challenging\ninverse problems. These problems help establish benchmarks for systematically\nquantifying the performance of different formulations and sampling strategies\nin this study, and for future studies. Finally, we identify and implement a\nmechanism through which a single diffusion model can be applied to measurements\nobtained from multiple measurement operators. Taken together, the contents of\nthis manuscript provide a new understanding and several new directions in the\napplication of diffusion models to solving physics-based inverse problems.","main_category":"cs.LG","categories":"cs.LG,stat.CO,stat.ML","published":"2025-04-10T04:07:36Z"}
{"aid":"http://arxiv.org/abs/2504.07438v1","title":"Satellite System Architecting Considering On-Orbit Refueling","summary":"This paper introduces the problem of selecting a satellite system\narchitecture considering commercial on-orbit refueling (OOR). The problem aims\nto answer two questions: \"How durable should a satellite be?\" and \"How much\npropellant should be loaded into the satellite at launch?\" We formulate the\nproblem as a mathematical optimization by adopting the design lifetime and\npropellant mass as design variables and considering two objective functions to\nbalance the returns and risks. A surrogate model-based framework, grounded in a\nsatellite lifecycle simulation, is developed to address this problem. The\ndeveloped framework considers various uncertainties and operational flexibility\nand integrates a modified satellite sizing and cost model by adjusting\ntraditional models with OOR. A design case study of a geosynchronous equatorial\norbit communication satellite considering the OOR highlights the effectiveness\nof the developed framework.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T04:07:58Z"}
{"aid":"http://arxiv.org/abs/2504.07460v1","title":"Measuring Cosmic Growth Rate with CSST Spectroscopic Survey and Fast\n  Radio Burst","summary":"The cosmic growth rate, which is related to peculiar velocity and is a\nprimary scientific objective of galaxy spectroscopic surveys, can be inferred\nfrom the Redshift Space Distortion effect and the kinetic Sunyaev-Zel'dovich\neffect. However, the reconstruction noise power spectrum of the radial velocity\nfield in kSZ is significantly dependent on the measurement of the small-scale\ngalaxy-electron power spectrum $P_{ge}$. In this study, we thoroughly discuss\nthe enhancement of cosmic growth rate measurements facilitated by Fast Radio\nBursts, which probe the electron density of the universe along their\npropagation paths to provide crucial additional information on $P_{ge}$.\nSubsequently, we utilize future spectroscopic surveys from the Chinese Space\nStation Telescope and the CMB-S4 experiment, combined with FRB dispersion\nmeasures, to achieve precise measurements of the cosmic growth rate at\nredshifts $z_g = 0.15,0.45,0.75$. Employing Fisher matrix forecasting analysis,\nwe anticipate that constraints on $f\\sigma_8$ will reach a precision of 0.001\nwith a sample size of $10^6$ FRBs. Furthermore, we perform a global analysis\nusing Markov Chain Monte Carlo methods to constrain key parameters of three\ndistinct dark energy models and a modified gravity model based on cosmic growth\nrate measurements. The results demonstrate that these refined $f\\sigma_8$\nmeasurements considerably enhance the constraints on relevant cosmological\nparameters compared to those obtained from Planck. As the number of observed\nFRBs increases, alongside more precise galaxy surveys and next-generation CMB\nobservations, new opportunities will arise for constraining cosmological models\nusing the kSZ effect and for developing novel cosmological applications of\nFRBs.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T05:10:15Z"}
{"aid":"http://arxiv.org/abs/2504.07507v1","title":"Drive in Corridors: Enhancing the Safety of End-to-end Autonomous\n  Driving via Corridor Learning and Planning","summary":"Safety remains one of the most critical challenges in autonomous driving\nsystems. In recent years, the end-to-end driving has shown great promise in\nadvancing vehicle autonomy in a scalable manner. However, existing approaches\noften face safety risks due to the lack of explicit behavior constraints. To\naddress this issue, we uncover a new paradigm by introducing the corridor as\nthe intermediate representation. Widely adopted in robotics planning, the\ncorridors represents spatio-temporal obstacle-free zones for the vehicle to\ntraverse. To ensure accurate corridor prediction in diverse traffic scenarios,\nwe develop a comprehensive learning pipeline including data annotation,\narchitecture refinement and loss formulation. The predicted corridor is further\nintegrated as the constraint in a trajectory optimization process. By extending\nthe differentiability of the optimization, we enable the optimized trajectory\nto be seamlessly trained within the end-to-end learning framework, improving\nboth safety and interpretability. Experimental results on the nuScenes dataset\ndemonstrate state-of-the-art performance of our approach, showing a 66.7%\nreduction in collisions with agents and a 46.5% reduction with curbs,\nsignificantly enhancing the safety of end-to-end driving. Additionally,\nincorporating the corridor contributes to higher success rates in closed-loop\nevaluations.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T07:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.07515v1","title":"Sequential Filtering Techniques for Simultaneous Tracking and Parameter\n  Estimation","summary":"The number of resident space objects is rising at an alarming rate.\nMega-constellations and breakup events are proliferating in most orbital\nregimes, and safe navigation is becoming increasingly problematic. It is\nimportant to be able to track RSOs accurately and at an affordable\ncomputational cost. Orbital dynamics are highly nonlinear, and current\noperational methods assume Gaussian representations of the objects' states and\nemploy linearizations which cease to hold true in observation-free propagation.\nMonte Carlo-based filters can provide a means to approximate the a posteriori\nprobability distribution of the states more accurately by providing support in\nthe portion of the state space which overlaps the most with the processed\nobservations. Moreover, dynamical models are not able to capture the full\nextent of realistic forces experienced in the near-Earth space environment, and\nhence fully deterministic propagation methods may fail to achieve the desired\naccuracy. By modeling orbital dynamics as a stochastic system and solving it\nusing stochastic numerical integrators, we are able to simultaneously estimate\nthe scale of the process noise incurred by the assumed uncertainty in the\nsystem, and robustly track the state of the spacecraft. In order to find an\nadequate balance between accuracy and computational cost, we propose three\nalgorithms which are capable of tracking a space object and estimating the\nmagnitude of the system's uncertainty. The proposed filters are successfully\napplied to a LEO scenario, demonstrating the ability to accurately track a\nspacecraft state and estimate the scale of the uncertainty online, in various\nsimulation setups.","main_category":"astro-ph.IM","categories":"astro-ph.IM,stat.AP","published":"2025-04-10T07:23:00Z"}
{"aid":"http://arxiv.org/abs/2504.07529v1","title":"Automating the Path: An R&D Agenda for Human-Centered AI and\n  Visualization","summary":"The emergence of generative AI, large language models (LLMs), and foundation\nmodels is fundamentally reshaping computer science, and visualization and\nvisual analytics are no exception. We present a systematic framework for\nunderstanding how human-centered AI (HCAI) can transform the visualization\ndiscipline. Our framework maps four key HCAI tool capabilities -- amplify,\naugment, empower, and enhance -- onto the four phases of visual sensemaking:\nview, explore, schematize, and report. For each combination, we review existing\ntools, envision future possibilities, identify challenges and pitfalls, and\nexamine ethical considerations. This design space can serve as an R\\&D agenda\nfor both visualization researchers and practitioners to integrate AI into their\nwork as well as understanding how visualization can support HCAI research.","main_category":"cs.HC","categories":"cs.HC,H.5.2","published":"2025-04-10T07:52:18Z"}
{"aid":"http://arxiv.org/abs/2504.07571v1","title":"The birth of Be star disks I. From localized ejection to circularization","summary":"Classical Be stars are well known to eject mass, but the details governing\nthe initial distribution and evolution of this matter into a disk are poorly\nconstrained by observations. By combining high-cadence spectroscopy with\ncontemporaneous space photometry from TESS, we have sampled about 30 mass\nejection events in 13 Be stars. Our goal is to constrain the geometrical and\nkinematic properties of the ejecta, facilitating the investigation into the\ninitial conditions and evolution, and understanding its interactions with\npreexisting material. The photometric variability is analyzed together with\nmeasurements of the rapidly changing emission features to identify the onset of\noutburst events and obtain information about the geometry of the ejecta and its\nevolution. All Be stars observed with sufficiently high cadence exhibit rapid\noscillations of line asymmetry with a single frequency in the days following\nthe start of the event. The emission asymmetry cycles break down after roughly\n5 - 10 cycles, with the emission line profile converging toward approximate\nsymmetry. In photometry, several frequencies typically emerge at relatively\nhigh amplitude at some point during the mass ejection process. In all observed\ncases, freshly ejected material was initially within a narrow azimuthal range,\nindicating it was launched from a localized region on the star. The material\norbits the star with a frequency consistent with the near-surface Keplerian\norbital frequency. This material circularizes into a disk configuration after\nseveral orbital timescales. This is true whether or not there was a preexisting\ndisk. We find no evidence for precursor phases prior to the ejection of mass in\nour sample. The several photometric frequencies that emerge during outburst are\nat least partially stellar in origin. (Abstract abridged)","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-10T09:13:41Z"}
{"aid":"http://arxiv.org/abs/2504.07584v1","title":"REANIMATOR: Reanimate Retrieval Test Collections with Extracted and\n  Synthetic Resources","summary":"Retrieval test collections are essential for evaluating information retrieval\nsystems, yet they often lack generalizability across tasks. To overcome this\nlimitation, we introduce REANIMATOR, a versatile framework designed to enable\nthe repurposing of existing test collections by enriching them with extracted\nand synthetic resources. REANIMATOR enhances test collections from PDF files by\nparsing full texts and machine-readable tables, as well as related contextual\ninformation. It then employs state-of-the-art large language models to produce\nsynthetic relevance labels. Including an optional human-in-the-loop step can\nhelp validate the resources that have been extracted and generated. We\ndemonstrate its potential with a revitalized version of the TREC-COVID test\ncollection, showcasing the development of a retrieval-augmented generation\nsystem and evaluating the impact of tables on retrieval-augmented generation.\nREANIMATOR enables the reuse of test collections for new applications, lowering\ncosts and broadening the utility of legacy resources.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.07590v1","title":"DWFS-Obfuscation: Dynamic Weighted Feature Selection for Robust Malware\n  Familial Classification under Obfuscation","summary":"Due to its open-source nature, the Android operating system has consistently\nbeen a primary target for attackers. Learning-based methods have made\nsignificant progress in the field of Android malware detection. However,\ntraditional detection methods based on static features struggle to identify\nobfuscated malicious code, while methods relying on dynamic analysis suffer\nfrom low efficiency. To address this, we propose a dynamic weighted feature\nselection method that analyzes the importance and stability of features,\ncalculates scores to filter out the most robust features, and combines these\nselected features with the program's structural information. We then utilize\ngraph neural networks for classification, thereby improving the robustness and\naccuracy of the detection system. We analyzed 8,664 malware samples from eight\nmalware families and tested a total of 44,940 malware variants generated using\nseven obfuscation strategies. Experiments demonstrate that our proposed method\nachieves an F1-score of 95.56% on the unobfuscated dataset and 92.28% on the\nobfuscated dataset, indicating that the model can effectively detect obfuscated\nmalware.","main_category":"cs.CR","categories":"cs.CR,I.2.7","published":"2025-04-10T09:37:43Z"}
{"aid":"http://arxiv.org/abs/2504.07619v1","title":"Beating Transformers using Synthetic Cognition","summary":"The road to Artificial General Intelligence goes through the generation of\nepisodic reactive behaviors, where the Transformer architecture has been proven\nto be the state-of-the-art. However, they still fail to develop reasoning.\nRecently, a novel approach for developing cognitive architectures, called\nSynthetic Cognition, has been proposed and implemented to develop instantaneous\nreactive behavior. In this study, we aim to explore the use of Synthetic\nCognition to develop episodic reactive behaviors. We propose a mechanism to\ndeal with sequences for the recent implementation of Synthetic Cognition, and\ntest it against DNA foundation models in DNA sequence classification tasks. In\nour experiments, our proposal clearly outperforms the DNA foundation models,\nobtaining the best score on more benchmark tasks than the alternatives. Thus,\nwe achieve two goals: expanding Synthetic Cognition to deal with sequences, and\nbeating the Transformer architecture for sequence classification.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-10T10:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.07621v1","title":"What causes long outbursts of neutron star low-mass X-ray binaries?","summary":"Many neutron star low-mass X-ray binaries (NS LMXBs) with short orbital\nperiods (~hours) cycle between outburst and quiescent phases, and thus provide\nan excellent way to study the accretion process. The cause of such outbursts is\nbelieved to be thermal-viscous instability in the accretion disc. However, some\nof these transient sources show unusually long outbursts. For example, EXO\n0748-676 remained in outburst for at least 23 years before entering a\nquiescence, only to re-emerge 16 years later. We aim to investigate if such\nlong outbursts could be due to the usual disc instability, or if any other\nmechanism is required. In order to address this question, we systematically\ncompare various properties of long outburst and short outburst NS LMXBs. For\nthis, we analyze the long-term X-ray light curves of many short orbital period\n(hours) NS LMXBs, examining the outburst duration and the inferred accretion\nrate, and estimate the accretion disc mass. Our study shows that long outburst\nsources are well-separated from the short outburst ones in parameter spaces\ninvolving accretion rate, disc mass, outburst duration, etc. in four ways. This\nimplies that the thermal-viscous instability in the disc cannot explain the\nlong outbursts, but could explain the short ones. Moreover, we discuss that\nboth donor star related and disc related models have difficulties in explaining\nlong outbursts. Our finding will be crucial to understanding the accretion\nprocess of transiently accreting neutron stars and black holes.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T10:09:32Z"}
{"aid":"http://arxiv.org/abs/2504.07628v1","title":"Singular networks and ultrasensitive terminal behaviors","summary":"Negative conductance elements are key to shape the input-output behavior at\nthe terminals of a network through localized positive feedback amplification.\nThe balance of positive and negative differential conductances creates\nsingularities at which rich, intrinsically nonlinear, and ultrasensitive\nterminal behaviors emerge. Motivated by neuromorphic engineering applications,\nin this note we extend a recently introduced nonlinear network graphical\nmodeling framework to include negative conductance elements. We use this\nextended framework to define the class of singular networks and to characterize\ntheir ultra-sensitive input/output behaviors at given terminals. Our results\nare grounded in the Lyapunov-Schmidt reduction method, which is shown to fully\ncharacterize the singularities and bifurcations of the input-output behavior at\nthe network terminals, including when the underlying input-output relation is\nnot explicitly computable through other reduction methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T10:24:25Z"}
{"aid":"http://arxiv.org/abs/2504.07642v1","title":"Cache-a-lot: Pushing the Limits of Unsatisfiable Core Reuse in SMT-Based\n  Program Analysis","summary":"Satisfiability Modulo Theories (SMT) solvers are integral to program analysis\ntechniques like concolic and symbolic execution, where they help assess the\nsatisfiability of logical formulae to explore execution paths of the program\nunder test. However, frequent solver invocations are still the main performance\nbottleneck of these techniques. One way to mitigate this challenge is through\noptimizations such as caching and reusing solver results. While current methods\ntypically focus on reusing results from fully equivalent or closely related\nformulas, they often miss broader opportunities for reuse. In this paper, we\npropose a novel approach, Cache-a-lot, that extends the reuse of unsatisfiable\n(unsat) results by systematically considering all possible variable\nsubstitutions. This enables more extensive reuse of results, thereby reducing\nthe number of SMT solver invocations and improving the overall efficiency of\nconcolic and symbolic execution. Our evaluation, conducted against the\nstate-of-the-art Utopia solution using two benchmark sets, shows significant\nimprovements, particularly with more complex formulas. Our method achieves up\nto 74% unsat core reuse, compared to Utopia's 41%, and significant increase in\nthe time savings. These results demonstrate that, despite the additional\ncomputational complexity, the broader reuse of unsat results significantly\nenhances performance, offering valuable advancements for formal verification\nand program analysis.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T10:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.07645v1","title":"Prediction of Usage Probabilities of Shopping-Mall Corridors Using\n  Heterogeneous Graph Neural Networks","summary":"We present a method based on graph neural network (GNN) for prediction of\nprobabilities of usage of shopping-mall corridors. The heterogeneous graph\nnetwork of shops and corridor paths are obtained from floorplans of the malls\nby creating vector layers for corridors, shops and entrances. These are\nsubsequently assimilated into nodes and edges of graphs. The prediction of the\nusage probability is based on the shop features, namely, the area and usage\ncategories they fall into, and on the graph connecting these shops, corridor\njunctions and entrances by corridor paths. Though the presented method is\napplicable for training on datasets obtained from a field survey or from\npedestrian-detecting sensors, the target data of the supervised deep-learning\nwork flow in this work are obtained from a probability method. We also include\na context-specific representation learning of latent features. The\nusage-probability prediction is made on each edge, which is a connection by a\nsection of corridor path between the adjacent nodes representing the shops or\ncorridor points. To create a feature for each edge, the hidden-layer feature\nvectors acquired in the message-passing GNN layers at the nodes of each edge\nare averaged and concatenated with the vector obtained by their multiplication.\nThese edge-features are then passed to multilayer perceptrons (MLP) to make the\nfinal prediction of usage probability on each edge. The samples of synthetic\nlearning dataset for each shopping mall are obtained by changing the shops'\nusage and area categories, and by subsequently feeding the graph into the\nprobability model.\n  When including different shopping malls in a single dataset, we also propose\nto consider graph-level features to inform the model with specific identifying\nfeatures of each mall.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T10:48:36Z"}
{"aid":"http://arxiv.org/abs/2504.07681v1","title":"Role of activity and dissipation in achieving precise beating in cilia:\n  Insights from the rower model","summary":"Cilia and flagella are micron-sized filaments that actively beat with\nremarkable precision in a viscous medium, driving microorganism movement and\nefficient flow. We study the rower model to uncover how cilia activity and\ndissipation enable this precise motion. In this model, cilia motion is\nrepresented by a micro-beads Brownian movement between two distant harmonic\npotentials. At specific locations, energy pumps trigger potential switches,\ncapturing cilia activity and generating oscillations. We quantify precision of\noscillation using a quality factor, identifying its scaling with activity and\noscillation amplitude, finding precision maximization at an optimal amplitude.\nThe data collapse is not accurate for noisy oscillations. An exact analytic\nexpression for the precision quality factor, based on first passage time\nfluctuations, and derived in the small noise approximation, explains its\noptimality and scaling. Energy budget analysis shows the quality factor's\nconsistency with the thermodynamic uncertainty relation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T12:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.07703v1","title":"Optimal Frequency Support from Virtual Power Plants: Minimal Reserve and\n  Allocation","summary":"This paper proposes a novel reserve-minimizing and allocation strategy for\nvirtual power plants (VPPs) to deliver optimal frequency support. The proposed\nstrategy enables VPPs, acting as aggregators for inverter-based resources\n(IBRs), to provide optimal frequency support economically. The proposed\nstrategy captures time-varying active power injections, reducing the\nunnecessary redundancy compared to traditional fixed reserve schemes. Reserve\nrequirements for the VPPs are determined based on system frequency response and\nsafety constraints, ensuring efficient grid support. Furthermore, an\nenergy-based allocation model decomposes power injections for each IBR,\naccounting for their specific limitations. Numerical experiments validate the\nfeasibility of the proposed approach, highlighting significant financial gains\nfor VPPs, especially as system inertia decreases due to higher renewable energy\nintegration.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T12:43:38Z"}
{"aid":"http://arxiv.org/abs/2504.07721v1","title":"From empirical brain networks towards modeling music perception -- a\n  perspective","summary":"This perspective article investigates how auditory stimuli influence neural\nnetwork dynamics using the FitzHugh-Nagumo (FHN) model and empirical brain\nconnectivity data. Results show that synchronization is sensitive to both the\nfrequency and amplitude of auditory input, with synchronization enhanced when\ninput frequencies align with the system's intrinsic frequencies. Increased\nstimulus amplitude broadens the synchronization range governed by a delicate\ninterplay involving the network's topology, the spatial location of the input,\nand the frequency characteristics of the cortical input signals. This\nperspective article also reveals that brain activity alternates between\nsynchronized and desynchronized states, reflecting critical dynamics and phase\ntransitions in neural networks. Notably, gamma-band synchronization is crucial\nfor processing music, with coherence peaking in this frequency range. The\nfindings emphasize the role of structural connectivity and network topology in\nmodulating synchronization, providing insights into how music perception\nengages brain networks. This perspective article offers a computational\nframework for understanding neural mechanisms in music perception, with\npotential implications for cognitive neuroscience and music psychology.","main_category":"q-bio.NC","categories":"q-bio.NC,nlin.AO","published":"2025-04-10T13:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.07722v1","title":"Relaxing the Markov Requirements on Reinforcement Learning Under Weak\n  Partial Ignorability","summary":"Incomplete data, confounding effects, and violations of the Markov property\nare interrelated problems which are ubiquitous in Reinforcement Learning\napplications. We introduce the concept of ``partial ignorabilty\" and leverage\nit to establish a novel convergence theorem for adaptive Reinforcement\nLearning. This theoretical result relaxes the Markov assumption on the\nstochastic process underlying conventional $Q$-learning, deploying a\ngeneralized form of the Robbins-Monro stochastic approximation theorem to\nestablish optimality. This result has clear downstream implications for most\nactive subfields of Reinforcement Learning, with clear paths for extension to\nthe field of Causal Inference.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-10T13:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.07726v1","title":"Quantum Machine Learning: Unveiling Trends, Impacts through Bibliometric\n  Analysis","summary":"Quantum Machine Learning (QML) is the intersection of two revolutionary\nfields: quantum computing and machine learning. It promises to unlock\nunparalleled capabilities in data analysis, model building, and problem-solving\nby harnessing the unique properties of quantum mechanics. This research\nendeavors to conduct a comprehensive bibliometric analysis of scientific\ninformation pertaining to QML covering the period from 2000 to 2023. An\nextensive dataset comprising 9493 scholarly works is meticulously examined to\nunveil notable trends, impact factors, and funding patterns within the domain.\nAdditionally, the study employs bibliometric mapping techniques to visually\nillustrate the network relationships among key countries, institutions,\nauthors, patent citations and significant keywords in QML research. The\nanalysis reveals a consistent growth in publications over the examined period.\nThe findings highlight the United States and China as prominent contributors,\nexhibiting substantial publication and citation metrics. Notably, the study\nconcludes that QML, as a research subject, is currently in a formative stage,\ncharacterized by robust scholarly activity and ongoing development.","main_category":"cs.DL","categories":"cs.DL,cs.LG","published":"2025-04-10T13:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.07750v1","title":"Counting 5-isogenies of elliptic curves over $\\mathbb{Q}$","summary":"We show that the number of $5$-isogenies of elliptic curves defined over\n$\\mathbb{Q}$ with naive height bounded by $H > 0$ is asymptotic to $C_5\\cdot\nH^{1/6} (\\log H)^2$ for some explicitly computable constant $C_5 > 0$. This\nsettles the asymptotic count of rational points on the genus zero modular\ncurves $X_0(m)$. We leverage an explicit $\\mathbb{Q}$-isomorphism between the\nstack $\\mathscr{X}_0(5)$ and the generalized Fermat equation $x^2 + y^2 = z^4$\nwith $\\mathbb{G}_m$-action of weights $(4, 4, 2)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T13:45:11Z"}
{"aid":"http://arxiv.org/abs/2504.07763v1","title":"Data over dialogue: Why artificial intelligence is unlikely to humanise\n  medicine","summary":"Recently, a growing number of experts in artificial intelligence (AI) and\nmedicine have be-gun to suggest that the use of AI systems, particularly\nmachine learning (ML) systems, is likely to humanise the practice of medicine\nby substantially improving the quality of clinician-patient relationships. In\nthis thesis, however, I argue that medical ML systems are more likely to\nnegatively impact these relationships than to improve them. In particular, I\nargue that the use of medical ML systems is likely to comprise the quality of\ntrust, care, empathy, understanding, and communication between clinicians and\npatients.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC,cs.LG","published":"2025-04-10T14:03:40Z"}
{"aid":"http://arxiv.org/abs/2504.07779v1","title":"Genetic Programming with Reinforcement Learning Trained Transformer for\n  Real-World Dynamic Scheduling Problems","summary":"Dynamic scheduling in real-world environments often struggles to adapt to\nunforeseen disruptions, making traditional static scheduling methods and\nhuman-designed heuristics inadequate. This paper introduces an innovative\napproach that combines Genetic Programming (GP) with a Transformer trained\nthrough Reinforcement Learning (GPRT), specifically designed to tackle the\ncomplexities of dynamic scheduling scenarios. GPRT leverages the Transformer to\nrefine heuristics generated by GP while also seeding and guiding the evolution\nof GP. This dual functionality enhances the adaptability and effectiveness of\nthe scheduling heuristics, enabling them to better respond to the dynamic\nnature of real-world tasks. The efficacy of this integrated approach is\ndemonstrated through a practical application in container terminal truck\nscheduling, where the GPRT method outperforms traditional GP, standalone\nTransformer methods, and other state-of-the-art competitors. The key\ncontribution of this research is the development of the GPRT method, which\nshowcases a novel combination of GP and Reinforcement Learning (RL) to produce\nrobust and efficient scheduling solutions. Importantly, GPRT is not limited to\ncontainer port truck scheduling; it offers a versatile framework applicable to\nvarious dynamic scheduling challenges. Its practicality, coupled with its\ninterpretability and ease of modification, makes it a valuable tool for diverse\nreal-world scenarios.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T14:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.07780v1","title":"Interference-caged quantum many-body scars: the Fock space topological\n  localization and interference zeros","summary":"We propose a general mechanism for realizing athermal finite-energy-density\neigenstates -- termed interference-caged quantum many-body scars (ICQMBS) --\nwhich originate from exact many-body destructive interference on the Fock space\ngraph. These eigenstates are strictly localized to specific subsets of\nvertices, analogous to compact localized states in flat-band systems. Central\nto our framework is a connection between interference zeros and graph\nautomorphisms, which classify vertices according to the graph's local topology.\nThis connection enables the construction of a new class of topological ICQMBS,\nwhose robustness arises from the local topology of the Fock space graph rather\nthan from conventional conservation laws or dynamical constraints. We\ndemonstrate the effectiveness of this framework by developing a\ngraph-theory-based search algorithm, which identifies ICQMBS in both a\none-dimensional spin-1 XY model and two-dimensional quantum link models across\ndistinct gauge sectors. In particular, we discover the proposed topological\nICQMBS in the two-dimensional quantum link model and provide an intuitive\nexplanation for previously observed order-by-disorder phenomena in Hilbert\nspace. Our results reveal an unexpected synergy between graph theory, flat-band\nphysics, and quantum many-body dynamics, offering new insights into the\nstructure and stability of nonthermal eigenstates.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.other","published":"2025-04-10T14:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.07785v1","title":"Towards Micro-Action Recognition with Limited Annotations: An\n  Asynchronous Pseudo Labeling and Training Approach","summary":"Micro-Action Recognition (MAR) aims to classify subtle human actions in\nvideo. However, annotating MAR datasets is particularly challenging due to the\nsubtlety of actions. To this end, we introduce the setting of Semi-Supervised\nMAR (SSMAR), where only a part of samples are labeled. We first evaluate\ntraditional Semi-Supervised Learning (SSL) methods to SSMAR and find that these\nmethods tend to overfit on inaccurate pseudo-labels, leading to error\naccumulation and degraded performance. This issue primarily arises from the\ncommon practice of directly using the predictions of classifier as\npseudo-labels to train the model. To solve this issue, we propose a novel\nframework, called Asynchronous Pseudo Labeling and Training (APLT), which\nexplicitly separates the pseudo-labeling process from model training.\nSpecifically, we introduce a semi-supervised clustering method during the\noffline pseudo-labeling phase to generate more accurate pseudo-labels.\nMoreover, a self-adaptive thresholding strategy is proposed to dynamically\nfilter noisy labels of different classes. We then build a memory-based\nprototype classifier based on the filtered pseudo-labels, which is fixed and\nused to guide the subsequent model training phase. By alternating the two\npseudo-labeling and model training phases in an asynchronous manner, the model\ncan not only be learned with more accurate pseudo-labels but also avoid the\noverfitting issue. Experiments on three MAR datasets show that our APLT largely\noutperforms state-of-the-art SSL methods. For instance, APLT improves accuracy\nby 14.5\\% over FixMatch on the MA-12 dataset when using only 50\\% labeled data.\nCode will be publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.07797v1","title":"Event-Triggered Source Seeking Control for Nonholonomic Systems","summary":"This paper introduces an event-triggered source seeking control (ET-SSC) for\nautonomous vehicles modeled as the nonholonomic unicycle. The classical source\nseeking control is enhanced with static-triggering conditions to enable\naperiodic and less frequent updates of the system's input signals, offering a\nresource-aware control design. Our convergence analysis is based on\ntime-scaling combined with Lyapunov and averaging theories for systems with\ndiscontinuous right-hand sides. ET-SSC ensures exponentially stable behavior\nfor the resulting average system, leading to practical asymptotic convergence\nto a small neighborhood of the source point. We guarantee the avoidance of Zeno\nbehavior by establishing a minimum dwell time to prevent infinitely fast\nswitching. The performance optimization is aligned with classical\ncontinuous-time source seeking algorithms while balancing system performance\nwith actuation resource consumption. Our ET-SSC algorithm, the first of its\nkind, allows for arbitrarily large inter-sampling times, overcoming the\nlimitations of classical sampled-data implementations for source seeking\ncontrol.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-10T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.07805v1","title":"Symmetry energy dependence of the bulk viscosity of nuclear matter","summary":"We clarify how the weak-interaction-driven bulk viscosity $\\zeta$ and the\nbulk relaxation time $\\tau_\\Pi$ of neutrino-transparent $npe$ matter depend on\nthe nuclear symmetry energy. We show that, at saturation density, the\nequation-of-state dependence of these transport quantities is fully determined\nby the experimentally constrained nuclear symmetry energy $S$ and its slope\n$L$. Variations of $L$ within current experimental uncertainties can change the\n(frequency-independent) bulk viscosity by orders of magnitude. This suggests\nthat dissipative effects encoded in the gravitational-wave signatures of binary\nneutron star inspirals may help constrain nuclear symmetry energy properties.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-04-10T14:42:50Z"}
{"aid":"http://arxiv.org/abs/2504.07812v1","title":"Numerical instability of non-Hermitian Hamiltonian evolutions","summary":"The extreme sensitivity of non-Hermitian Hamiltonians exhibiting the\nnon-Hermitian skin effect (NHSE) has been extensively studied in recent years\nwith well-established theoretical explanations. However, this sensitivity is\noften overlooked in numerical calculations, as seen in Refs.\n\\cite{NHSEEPTKawabata, Schiro}. In this work, we examine the solvable\nHatano-Nelson and symplectic Hatano-Nelson models, comparing our high-precision\nresults with those in Ref. \\cite{NHSEEPTKawabata}. We systematically\ninvestigate inaccuracies in physical results arising from neglecting numerical\nerrors during diagonalization and non-Hermitian Hamiltonian evolution.\nMoreover, we attribute these numerical instabilities to the large condition\nnumber, which grows exponentially with system size due to NHSE, indicating\nstrong normality. Interestingly, it is found that a reliable spectrum alone is\ninsufficient for accurate non-Hermitian evolution, while the reliability of\nwavefunctions plays a more critical role. To ensure the accuracy of numerical\nresults for non-Hermitian systems exhibiting NHSE, our work underscores the\nimportance of estimating the condition number before performing numerical\ncomputations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T14:50:22Z"}
{"aid":"http://arxiv.org/abs/2504.07844v1","title":"A quantum computing approach to beam angle optimization","summary":"Background: Beam angle optimization (BAO) is a critical component of\nradiation therapy (RT) treatment planning, where small changes in beam\nconfiguration can significantly impact treatment quality, especially for proton\nRT. Mathematically, BAO is a mixed integer programming (MIP) problem, which is\nNP-hard due to its exponential growing search space. Traditional optimization\ntechniques often struggle with computational efficiency, necessitating the\ndevelopment of novel approaches. Purpose: This study introduces QC-BAO, a\nhybrid quantum-classical approach that leverages quantum computing to solve the\nMIP formulation of BAO. Methods: The proposed approach, QC-BAO, models BAO as\nan MIP problem, incorporating binary variables for beam angle selection and\ncontinuous variables for optimizing spot intensities for proton therapy. The\nproposed approach employs a hybrid quantum-classical framework, utilizing\nquantum computing to solve the binary decision component while integrating\nclassical optimization techniques, including iterative convex relaxation and\nalternating direction method of multipliers. Results: Computational experiments\nwere conducted on clinical test cases to evaluate QC-BAO's performance against\nclinically verified angles and a heuristic approach, GS-BAO. QC-BAO\ndemonstrated improved treatment plan quality over both clinical and GS-BAO. The\nmethod consistently increased the conformity index (CI) for target coverage\nwhile reducing mean and maximum doses to organs-at-risk (OAR). Additionally,\nQC-BAO produced the lowest objective function value, confirming its superior\noptimization capability. Conclusions: The findings highlight the potential of\nquantum computing to enhance the solution to BAO problem by demonstrated\nimprovement in plan quality using the proposed method, QC-BAO. This study paves\nthe way for future clinical implementation of quantum-accelerated optimization\nin RT.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-10T15:24:37Z"}
{"aid":"http://arxiv.org/abs/2504.07911v1","title":"The Urban Impact of AI: Modeling Feedback Loops in Next-Venue\n  Recommendation","summary":"Next-venue recommender systems are increasingly embedded in location-based\nservices, shaping individual mobility decisions in urban environments. While\ntheir predictive accuracy has been extensively studied, less attention has been\npaid to their systemic impact on urban dynamics. In this work, we introduce a\nsimulation framework to model the human-AI feedback loop underpinning\nnext-venue recommendation, capturing how algorithmic suggestions influence\nindividual behavior, which in turn reshapes the data used to retrain the\nmodels. Our simulations, grounded in real-world mobility data, systematically\nexplore the effects of algorithmic adoption across a range of recommendation\nstrategies. We find that while recommender systems consistently increase\nindividual-level diversity in visited venues, they may simultaneously amplify\ncollective inequality by concentrating visits on a limited subset of popular\nplaces. This divergence extends to the structure of social co-location\nnetworks, revealing broader implications for urban accessibility and spatial\nsegregation. Our framework operationalizes the feedback loop in next-venue\nrecommendation and offers a novel lens through which to assess the societal\nimpact of AI-assisted mobility-providing a computational tool to anticipate\nfuture risks, evaluate regulatory interventions, and inform the design of ethic\nalgorithmic systems.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-10T17:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.07918v1","title":"Shuffling via Transpositions","summary":"We consider a family of card shuffles of $n$ cards, where the allowed moves\ninvolve transpositions corresponding to the Jucys--Murphy elements of\n$\\{S_m\\}_{m \\leq n}$. We diagonalize the transition matrix of these shuffles.\nAs a special case, we consider the $k$-star transpositions shuffle, a natural\ninterpolation between random transpositions and star transpositions. We proved\nthat the $k$-star transpositions shuffle exhibits total variation cutoff at\ntime $\\frac{2n-(k+1)}{2(n-1)}n\\log n$ with a window of\n$\\frac{2n-(k+1)}{2(n-1)}n$. Furthermore, we prove that for the case where $k/n\n\\rightarrow 0$ or $1$, this shuffle has the same limit profile as random\ntranspositions, which has been fully determined by Teyssier.","main_category":"math.CO","categories":"math.CO,math.PR","published":"2025-04-10T17:33:30Z"}
{"aid":"http://arxiv.org/abs/2504.07919v1","title":"Double White Dwarf Tides with Multi-messenger Measurements","summary":"Short-period Galactic double white dwarf (DWD) systems will be observable\nboth in visible light through photometric monitoring and in mHz-range\ngravitational waves (GWs) with forthcoming space-based laser interferometry\nsuch as LISA. When only photometric variability is used to measure DWD\nintrinsic properties, there is a degeneracy between the chirp mass and binary\ntidal interaction, as orbital frequency time derivative is set by both GW\nradiation and tides. Without expensive radial velocity data from spectroscopic\nmonitoring, this degeneracy may be lifted in principle by directly measuring\nthe second time derivative of the orbital frequency through photometric\nmonitoring over an ultra-long time baseline. Alternatively, the degeneracy can\nbe removed by exploiting information in both photometric variability and the\ncoherent GW waveform. Investigating both approaches, we find that direct\nmeasurement of the second time derivative is likely infeasible for most DWDs,\nwhile the multi-messenger method will disentangle measurements of the chirp\nmass and the binary moments of inertia, for a large sample of tidally locked\nsystems. The latter information will enable empirical tests of WD structure\nmodels with finite temperature effects.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-10T17:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.07944v1","title":"Hyperbolic sine-Gordon model beyond the first threshold","summary":"We study the hyperbolic sine-Gordon model, with a parameter $\\beta^2 > 0$,\nand its associated Gibbs dynamics on the two-dimensional torus. By introducing\na physical space approach to the Fourier restriction norm method and\nestablishing nonlinear dispersive smoothing for the imaginary multiplicative\nGaussian chaos, we construct invariant Gibbs dynamics for the hyperbolic\nsine-Gordon model beyond the first threshold $\\beta^2 = 2\\pi$. The\ndeterministic step of our argument hinges on establishing key bilinear\nestimates, featuring weighted bounds for a cone multiplier. Moreover, the\nprobabilistic component involves a careful analysis of the imaginary Gaussian\nmultiplicative chaos and reduces to integrating singularities along space-time\nlight cones. As a by-product of our proof, we identify $\\beta^2 = 6\\pi$ as a\ncritical threshold for the hyperbolic sine-Gordon model, which is quite\nsurprising given that the associated parabolic model has a critical threshold\nat $\\beta^2 =8\\pi$.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,math.PR","published":"2025-04-10T17:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.07952v1","title":"Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory","summary":"Despite their impressive performance on complex tasks, current language\nmodels (LMs) typically operate in a vacuum: Each input query is processed\nseparately, without retaining insights from previous attempts. Here, we present\nDynamic Cheatsheet (DC), a lightweight framework that endows a black-box LM\nwith a persistent, evolving memory. Rather than repeatedly re-discovering or\nre-committing the same solutions and mistakes, DC enables models to store and\nreuse accumulated strategies, code snippets, and general problem-solving\ninsights at inference time. This test-time learning enhances performance\nsubstantially across a range of tasks without needing explicit ground-truth\nlabels or human feedback. Leveraging DC, Claude 3.5 Sonnet's accuracy more than\ndoubled on AIME math exams once it began retaining algebraic insights across\nquestions. Similarly, GPT-4o's success rate on Game of 24 increased from 10% to\n99% after the model discovered and reused a Python-based solution. In tasks\nprone to arithmetic mistakes, such as balancing equations, DC enabled GPT-4o\nand Claude to reach near-perfect accuracy by recalling previously validated\ncode, whereas their baselines stagnated around 50%. Beyond arithmetic\nchallenges, DC yields notable accuracy gains on knowledge-demanding tasks.\nClaude achieved a 9% improvement in GPQA-Diamond and an 8% boost on MMLU-Pro\nproblems. Crucially, DC's memory is self-curated, focusing on concise,\ntransferable snippets rather than entire transcript. Unlike finetuning or\nstatic retrieval methods, DC adapts LMs' problem-solving skills on the fly,\nwithout modifying their underlying parameters. Overall, our findings present DC\nas a promising approach for augmenting LMs with persistent memory, bridging the\ndivide between isolated inference events and the cumulative, experience-driven\nlearning characteristic of human cognition.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.07963v1","title":"PixelFlow: Pixel-Space Generative Models with Flow","summary":"We present PixelFlow, a family of image generation models that operate\ndirectly in the raw pixel space, in contrast to the predominant latent-space\nmodels. This approach simplifies the image generation process by eliminating\nthe need for a pre-trained Variational Autoencoder (VAE) and enabling the whole\nmodel end-to-end trainable. Through efficient cascade flow modeling, PixelFlow\nachieves affordable computation cost in pixel space. It achieves an FID of 1.98\non 256$\\times$256 ImageNet class-conditional image generation benchmark. The\nqualitative text-to-image results demonstrate that PixelFlow excels in image\nquality, artistry, and semantic control. We hope this new paradigm will inspire\nand open up new opportunities for next-generation visual generation models.\nCode and models are available at https://github.com/ShoufaChen/PixelFlow.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.09882v1","title":"SIO-Mapper: A Framework for Lane-Level HD Map Construction Using\n  Satellite Images and OpenStreetMap with No On-Site Visits","summary":"High-definition (HD) maps, particularly those containing lane-level\ninformation regarded as ground truth, are crucial for vehicle localization\nresearch. Traditionally, constructing HD maps requires highly accurate sensor\nmeasurements collection from the target area, followed by manual annotation to\nassign semantic information. Consequently, HD maps are limited in terms of\ngeographic coverage. To tackle this problem, in this paper, we propose\nSIO-Mapper, a novel lane-level HD map construction framework that constructs\ncity-scale maps without physical site visits by utilizing satellite images and\nOpenStreetmap data. One of the key contributions of SIO-Mapper is its ability\nto extract lane information more accurately by introducing SIO-Net, a novel\ndeep learning network that integrates features from satellite image and\nOpenStreetmap using both Transformer-based and convolution-based encoders.\nFurthermore, to overcome challenges in merging lanes over large areas, we\nintroduce a novel lane integration methodology that combines cluster-based and\ngraph-based approaches. This algorithm ensures the seamless aggregation of lane\nsegments with high accuracy and coverage, even in complex road environments. We\nvalidated SIO-Mapper on the Naver Labs Open Dataset and NuScenes dataset,\ndemonstrating better performance in various environments including Korea, the\nUnited States, and Singapore compared to the state-of-the-art lane-level HD\nmapconstruction methods.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T05:10:57Z"}
{"aid":"http://arxiv.org/abs/2504.09906v1","title":"Plasticity-Aware Mixture of Experts for Learning Under QoE Shifts in\n  Adaptive Video Streaming","summary":"Adaptive video streaming systems are designed to optimize Quality of\nExperience (QoE) and, in turn, enhance user satisfaction. However, differences\nin user profiles and video content lead to different weights for QoE factors,\nresulting in user-specific QoE functions and, thus, varying optimization\nobjectives. This variability poses significant challenges for neural networks,\nas they often struggle to generalize under evolving targets - a phenomenon\nknown as plasticity loss that prevents conventional models from adapting\neffectively to changing optimization objectives. To address this limitation, we\npropose the Plasticity-Aware Mixture of Experts (PA-MoE), a novel learning\nframework that dynamically modulates network plasticity by balancing memory\nretention with selective forgetting. In particular, PA-MoE leverages noise\ninjection to promote the selective forgetting of outdated knowledge, thereby\nendowing neural networks with enhanced adaptive capabilities. In addition, we\npresent a rigorous theoretical analysis of PA-MoE by deriving a regret bound\nthat quantifies its learning performance. Experimental evaluations demonstrate\nthat PA-MoE achieves a 45.5% improvement in QoE over competitive baselines in\ndynamic streaming environments. Further analysis reveals that the model\neffectively mitigates plasticity loss by optimizing neuron utilization.\nFinally, a parameter sensitivity study is performed by injecting varying levels\nof noise, and the results align closely with our theoretical predictions.","main_category":"cs.MM","categories":"cs.MM,cs.AI","published":"2025-04-14T06:02:41Z"}
{"aid":"http://arxiv.org/abs/2504.09923v1","title":"Guiding Reasoning in Small Language Models with LLM Assistance","summary":"The limited reasoning capabilities of small language models (SLMs) cast doubt\non their suitability for tasks demanding deep, multi-step logical deduction.\nThis paper introduces a framework called Small Reasons, Large Hints (SMART),\nwhich selectively augments SLM reasoning with targeted guidance from large\nlanguage models (LLMs). Inspired by the concept of cognitive scaffolding, SMART\nemploys a score-based evaluation to identify uncertain reasoning steps and\ninjects corrective LLM-generated reasoning only when necessary. By framing\nstructured reasoning as an optimal policy search, our approach steers the\nreasoning trajectory toward correct solutions without exhaustive sampling. Our\nexperiments on mathematical reasoning datasets demonstrate that targeted\nexternal scaffolding significantly improves performance, paving the way for\ncollaborative use of both SLM and LLM to tackle complex reasoning tasks that\nare currently unsolvable by SLMs alone.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.09946v1","title":"Assessing Judging Bias in Large Reasoning Models: An Empirical Study","summary":"Large Reasoning Models (LRMs) like DeepSeek-R1 and OpenAI-o1 have\ndemonstrated remarkable reasoning capabilities, raising important questions\nabout their biases in LLM-as-a-judge settings. We present a comprehensive\nbenchmark comparing judging biases between LLMs and LRMs across both subjective\npreference-alignment datasets and objective fact-based datasets. Through\ninvestigation of bandwagon, authority, position, and distraction biases, we\nuncover four key findings: (1) despite their advanced reasoning capabilities,\nLRMs remain susceptible to the above biases; (2) LRMs demonstrate better\nrobustness than LLMs specifically on fact-related datasets; (3) LRMs exhibit\nnotable position bias, preferring options in later positions; and (4) we\nidentify a novel \"superficial reflection bias\" where phrases mimicking\nreasoning (e.g., \"wait, let me think...\") significantly influence model\njudgments. To address these biases, we design and evaluate three mitigation\nstrategies: specialized system prompts that reduce judging biases by up to 19\\%\nin preference alignment datasets and 14\\% in fact-related datasets, in-context\nlearning that provides up to 27\\% improvement on preference tasks but shows\ninconsistent results on factual tasks, and a self-reflection mechanism that\nreduces biases by up to 10\\% in preference datasets and 16\\% in fact-related\ndatasets, with self-reflection proving particularly effective for LRMs. Our\nwork provides crucial insights for developing more reliable LLM-as-a-Judge\nframeworks, especially as LRMs become increasingly deployed as automated\njudges.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-14T07:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.09955v1","title":"VR MRI Training for Adolescents: A Comparative Study of Gamified VR,\n  Passive VR, 360 Video, and Traditional Educational Video","summary":"Magnetic Resonance Imaging (MRI) can be a stressful experience for pediatric\npatients due to the loud acoustic environment, enclosed scanner bore, and a\nprolonged requirement to remain still. While sedation is commonly used to\nmanage anxiety and motion, it carries clinical risks and logistical burdens.\nTraditional preparatory approaches, such as instructional videos and mock\nscans, often lack engagement for older children and adolescents. In this study,\nwe present a comparative evaluation of four MRI preparation modalities: (1) a\ngamified virtual reality (VR) simulation that trains stillness through\nreal-time feedback; (2) a passive VR experience replicating the MRI environment\nwithout interactivity; (3) a 360 degree first-person video of a real MRI\nprocedure; and (4) a standard 2D educational video. Using a within-subjects\ndesign (N = 11, ages 10-16), we assess each method's impact on head motion\ndata, anxiety reduction, procedural preparedness, usability, cognitive\nworkload, and subjective preference. Results show that the gamified VR\ncondition has significantly lower head motion (p < 0.001) and yielded the\nhighest preparedness scores (p < 0.05). Head motion data were significantly\ncorrelated with learning outcomes (p < 0.01), suggesting that behavioral\nperformance in VR strongly indicates procedural readiness. While all modalities\nreduced anxiety and were rated usable, interactive VR was preferred by most\nparticipants and demonstrated unique advantages in promoting engagement and\nbehavioral rehearsal. We conclude with design recommendations for designing\nimmersive simulations and integrating VR training into pediatric imaging\nworkflows.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T07:40:30Z"}
{"aid":"http://arxiv.org/abs/2504.09971v1","title":"Proofs of Useful Work from Arbitrary Matrix Multiplication","summary":"We revisit the longstanding open problem of implementing Nakamoto's\nproof-of-work (PoW) consensus based on a real-world computational task $T(x)$\n(as opposed to artificial random hashing), in a truly permissionless setting\nwhere the miner itself chooses the input $x$. The challenge in designing such a\nProof-of-Useful-Work (PoUW) protocol, is using the native computation of $T(x)$\nto produce a PoW certificate with prescribed hardness and with negligible\ncomputational overhead over the worst-case complexity of $T(\\cdot)$ -- This\nensures malicious miners cannot ``game the system\" by fooling the verifier to\naccept with higher probability compared to honest miners (while using similar\ncomputational resources). Indeed, obtaining a PoUW with $O(1)$-factor overhead\nis trivial for any task $T$, but also useless.\n  Our main result is a PoUW for the task of Matrix Multiplication $MatMul(A,B)$\nof arbitrary matrices with $1+o(1)$ multiplicative overhead compared to naive\n$MatMul$ (even in the presence of Fast Matrix Multiplication-style algorithms,\nwhich are currently impractical). We conjecture that our protocol has optimal\nsecurity in the sense that a malicious prover cannot obtain any significant\nadvantage over an honest prover. This conjecture is based on reducing hardness\nof our protocol to the task of solving a batch of low-rank random linear\nequations which is of independent interest.\n  Since $MatMul$s are the bottleneck of AI compute as well as countless\nindustry-scale applications, this primitive suggests a concrete design of a new\nL1 base-layer protocol, which nearly eliminates the energy-waste of Bitcoin\nmining -- allowing GPU consumers to reduce their AI training and inference\ncosts by ``re-using\" it for blockchain consensus, in exchange for block rewards\n(2-for-1). This blockchain is currently under construction.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T08:22:40Z"}
{"aid":"http://arxiv.org/abs/2504.09976v1","title":"Nonlocal operators in divergence form and existence theory for\n  integrable data","summary":"We present an existence and uniqueness result for weak solutions of Dirichlet\nboundary value problems governed by a nonlocal operator in divergence form and\nin the presence of a datum which is assumed to belong only to $L^1(\\Omega)$ and\nto be suitably dominated.\n  We also prove that the solution that we find converges, as $s\\nearrow 1$, to\na solution of the local counterpart problem, recovering the classical result as\na limit case. This requires some nontrivial customized uniform estimates and\nrepresentation formulas, given that the datum is only in $L^1(\\Omega)$ and\ntherefore the usual regularity theory cannot be leveraged to our benefit in\nthis framework.\n  The limit process uses a nonlocal operator, obtained as an affine\ntransformation of a homogeneous kernel, which recovers, in the limit as\n$s\\nearrow 1$, every classical operator in divergence form.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T08:31:51Z"}
{"aid":"http://arxiv.org/abs/2504.10007v1","title":"Balancing Two Classifiers via A Simplex ETF Structure for Model\n  Calibration","summary":"In recent years, deep neural networks (DNNs) have demonstrated\nstate-of-the-art performance across various domains. However, despite their\nsuccess, they often face calibration issues, particularly in safety-critical\napplications such as autonomous driving and healthcare, where unreliable\npredictions can have serious consequences. Recent research has started to\nimprove model calibration from the view of the classifier. However, the\nexploration of designing the classifier to solve the model calibration problem\nis insufficient. Let alone most of the existing methods ignore the calibration\nerrors arising from underconfidence. In this work, we propose a novel method by\nbalancing learnable and ETF classifiers to solve the overconfidence or\nunderconfidence problem for model Calibration named BalCAL. By introducing a\nconfidence-tunable module and a dynamic adjustment method, we ensure better\nalignment between model confidence and its true accuracy. Extensive\nexperimental validation shows that ours significantly improves model\ncalibration performance while maintaining high predictive accuracy,\noutperforming existing techniques. This provides a novel solution to the\ncalibration challenges commonly encountered in deep learning.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-14T09:09:01Z"}
{"aid":"http://arxiv.org/abs/2504.10018v1","title":"RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset\n  and An Asymmetric RWKV Fusion Framework","summary":"Existing pedestrian attribute recognition methods are generally developed\nbased on RGB frame cameras. However, these approaches are constrained by the\nlimitations of RGB cameras, such as sensitivity to lighting conditions and\nmotion blur, which hinder their performance. Furthermore, current attribute\nrecognition primarily focuses on analyzing pedestrians' external appearance and\nclothing, lacking an exploration of emotional dimensions. In this paper, we\nrevisit these issues and propose a novel multi-modal RGB-Event attribute\nrecognition task by drawing inspiration from the advantages of event cameras in\nlow-light, high-speed, and low-power consumption. Specifically, we introduce\nthe first large-scale multi-modal pedestrian attribute recognition dataset,\ntermed EventPAR, comprising 100K paired RGB-Event samples that cover 50\nattributes related to both appearance and six human emotions, diverse scenes,\nand various seasons. By retraining and evaluating mainstream PAR models on this\ndataset, we establish a comprehensive benchmark and provide a solid foundation\nfor future research in terms of data and algorithmic baselines. In addition, we\npropose a novel RWKV-based multi-modal pedestrian attribute recognition\nframework, featuring an RWKV visual encoder and an asymmetric RWKV fusion\nmodule. Extensive experiments are conducted on our proposed dataset as well as\ntwo simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving\nstate-of-the-art results. The source code and dataset will be released on\nhttps://github.com/Event-AHU/OpenPAR","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T09:22:16Z"}
{"aid":"http://arxiv.org/abs/2504.10095v1","title":"Influence of packing protocol on fractal exponents in dense polydisperse\n  packings","summary":"We study fractal properties of a system of densely and randomly packed disks,\nobeying a power-law distribution of radii, which is generated by using various\nprotocols: Delaunay triangulation (DT) with both zero and periodic boundary\nconditions and the constant pressure protocol with periodic boundary\nconditions. The power-law exponents of the mass-radius relation and structure\nfactor are obtained numerically for various values of the size ratio of the\ndistribution, defined as the largest-to-smallest radius ratio. It is shown that\nthe size ratio is an important control parameter responsible for the\nconsistency of the fractal properties of the system: the greater the ratio, the\nless the finite size effects are pronounced and the better the agreement\nbetween the exponents. For the DT protocol, the exponents of the mass-radius\nrelation, structure factor, and power-law distribution coincide even at\nmoderate values of the size ratio. By contrast, for the constant-pressure\nprotocol, all three exponents are found to be different for both moderate\n(around 300) and large (around 1500) size ratios, which might indicate a biased\nrather than random spatial distribution of the disks. Nevertheless, there is a\ntendency for the exponents to converge as the size ratio increases, suggesting\nthat all the exponents become equal in the limit of infinite size ratio.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T11:01:39Z"}
{"aid":"http://arxiv.org/abs/2504.10111v1","title":"Preliminary experimental investigation on the interaction of a\n  subaqueous dune like granular structure with a turbulent open channel flow","summary":"We study the interaction of a subaqueous dune like granular structure with a\nturbulent open channel flow experimentally using optical diagnostics in the\nReynolds and Froude parameter space ($7.7{\\times}10^3<Re<3.8{\\times}10^4$,\n$0.1<Fr<0.4$). Interactions between the turbulent flow and the granular\nstructure give rise to transient erosion-deposition dynamics leading to various\ntypes of particle transport. The subaqueous structures in the channel bed\nevolves due to shear-stress-induced erosion, gravity-driven deposition, and\nsubsequent particle transport. We study the centroid motion and the granular\nstructure shape evolution. At lower end of our $Re-Fr$ parameter space, we\nobserve no erosion and the structure remains at rest. At intermediate values of\n$Re$ and $Fr$, we observe very slow erosion and the granular structure moves\nvere slowly as a rigid body without significant shape deformation. Higher\nvalues of $Re$ and $Fr$ causes vortex formation at the upstream of the dune\nresulting in stronger erosion, rapid shape deformation and relatively higher\ntranslation velocity of the centroid.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-14T11:18:18Z"}
{"aid":"http://arxiv.org/abs/2504.10121v1","title":"Impact of rainfall risk on rice production: realized volatility in mean\n  model","summary":"Rural economies are largely dependent upon agriculture, which is greatly\ndetermined by climatic conditions such as rainfall. This study aims to forecast\nagricultural production in Maharashtra, India, which utilises annual data from\nthe year 1962 to 2021. Since rainfall plays a major role with respect to the\ncrop yield, we analyze the impact of rainfall on crop yield using four time\nseries models that includes ARIMA, ARIMAX, GARCH-ARIMA and GARCH-ARIMAX. We\ntake advantage of rainfall as an external regressor to examine if it\ncontributes to the performance of the model. 1-step, 2-step, and 3-step ahead\nforecasts are obtained and the model performance is assessed using MAE and\nRMSE. The models are able to more accurately predict when using rainfall as a\npredictor compared to when solely dependant on historical production trends\n(more improved outcomes are seen in the ARIMAX and GARCH-ARIMAX models). As\nsuch, these findings underscore the need for climate-aware forecasting\ntechniques that provide useful information to policymakers and farmers to aid\nin agricultural planning.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-14T11:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.10124v1","title":"Unravelling the Flow of Information in a Nonequilibrium Process","summary":"Identifying the origin of nonequilibrium characteristics in a generic\ninteracting system having multiple degrees of freedom is a challenging task. In\nthis context, information theoretic measures such as mutual information and\nrelated polymorphs offer valuable insights. Here, we explore these measures in\na minimal experimental model consisting of two hydrodynamically coupled\ncolloidal particles, where a nonequilibrium drive is introduced via an\nexponentially correlated noise acting on one of the particles. We show that the\ninformation-theoretic tools considered enable a systematic, data-driven\ndissection of information flow within the system. These measures allow us to\nidentify the driving node and reconstruct the directional dependencies between\nparticles. Notably, they help explain a recently observed, counterintuitive\ntrend in the dependence of irreversibility on interaction strength under\ncoarse-graining (B. Das et.al., arXiv:2405.00800 (2024)). Finally, our results\ndemonstrate how directional information measures can uncover the hidden\nstructure of nonequilibrium dynamics and provide a framework for studying\nsimilar effects in more complex systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-14T11:32:19Z"}
{"aid":"http://arxiv.org/abs/2504.10137v1","title":"Multi-Target Position Error Bound and Power Allocation Scheme for\n  Cell-Free mMIMO-OTFS ISAC Systems","summary":"This paper investigates multi-target position estimation in cell-free massive\nmultiple-input multiple-output (CF mMIMO) architectures, where orthogonal time\nfrequency and space (OTFS) is used as an integrated sensing and communication\n(ISAC) signal. Closed-form expressions for the Cram\\'{e}r-Rao lower bound and\nthe positioning error bound (PEB) in multi-target position estimation are\nderived, providing quantitative evaluations of sensing performance. To enhance\nthe overall performance of the ISAC system, a power allocation algorithm is\ndeveloped to maximize the minimum user communication\nsignal-to-interference-plus-noise ratio while ensuring a specified sensing PEB\nrequirement. The results validate the proposed PEB expression and its\napproximation, clearly illustrating the coordination gain enabled by ISAC.\nFurther, the superiority of using the multi-static CF mMIMO architecture over\ntraditional cellular ISAC is demonstrated, and the advantages of OTFS signals\nin high-mobility scenarios are highlighted.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-14T11:48:15Z"}
{"aid":"http://arxiv.org/abs/2504.10142v1","title":"Band width estimates with lower spectral curvature bounds","summary":"In this work, we use the warped \\( \\mu \\)-bubble method to study the\nconsequences of a spectral curvature bound. In particular, with a lower\nspectral Ricci curvature bound and lower spectral scalar curvature bound, we\nshow that the band width of a torical band is bounded above. We also obtain\nsome rigidity results.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T11:54:13Z"}
{"aid":"http://arxiv.org/abs/2504.10144v1","title":"Evidence for electron spin-torsion coupling in the rotational spectrum\n  of the CH$_3$CO radical","summary":"Open-shell non-rigid molecular systems exhibiting an internal rotation are\nlikely candidates for a coupling between the spin angular momentum of the\nunpaired electron and the torsional motion. This electron spin-torsion coupling\nlacked both an experimental validation and a theoretical modeling. Here, the\nfirst experimental observation of the electron spin-torsion coupling is\nreported analyzing the pure rotational spectrum at millimeter wavelengths of\nthe CH$_3$CO radical, a $^2\\Sigma$ open-shell molecule displaying an internal\nrotation of its methyl group. To account for this coupling, a specific\nHamiltonian incorporating the rotational, torsional, and electronic degrees of\nfreedom is developed and allows us to reproduce the experimental spectrum. The\npresent demonstration of the electron spin-torsion coupling will undoubtedly be\nkey to future investigations of large open-shell molecules exhibiting a complex\ninternal dynamics.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-14T11:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.10158v1","title":"COUNTS: Benchmarking Object Detectors and Multimodal Large Language\n  Models under Distribution Shifts","summary":"Current object detectors often suffer significant perfor-mance degradation in\nreal-world applications when encountering distributional shifts. Consequently,\nthe out-of-distribution (OOD) generalization capability of object detectors has\ngarnered increasing attention from researchers. Despite this growing interest,\nthere remains a lack of a large-scale, comprehensive dataset and evaluation\nbenchmark with fine-grained annotations tailored to assess the OOD\ngeneralization on more intricate tasks like object detection and grounding. To\naddress this gap, we introduce COUNTS, a large-scale OOD dataset with\nobject-level annotations. COUNTS encompasses 14 natural distributional shifts,\nover 222K samples, and more than 1,196K labeled bounding boxes. Leveraging\nCOUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed\nto comprehensively evaluate the OOD generalization capabilities of object\ndetectors by utilizing controlled distribution shifts between training and\ntesting data. OODG, on the other hand, aims to assess the OOD generalization of\ngrounding abilities in multimodal large language models (MLLMs). Our findings\nreveal that, while large models and extensive pre-training data substantially\nen hance performance in in-distribution (IID) scenarios, significant\nlimitations and opportunities for improvement persist in OOD contexts for both\nobject detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o\nand Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope\nCOUNTS facilitates advancements in the development and assessment of robust\nobject detectors and MLLMs capable of maintaining high performance under\ndistributional shifts.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T12:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.10159v1","title":"Monadic type-and-effect soundness","summary":"We introduce the abstract notions of \"monadic operational semantics\", a\nsmall-step semantics where computational effects are modularly modeled by a\nmonad, and \"type-and-effect system\", including \"effect types\" whose\ninterpretation lifts well-typedness to its monadic version. In this\nmeta-theory, as usually done in the non-monadic case, we can express progress\nand subject reduction properties and provide a proof, given once and for all,\nthat they imply soundness. The approach is illustrated on a lambda calculus\nwith generic effects. We equip the calculus with an expressive type-and-effect\nsystem, and provide proofs of progress and subject reduction which are\nparametric on the interpretation of effect types. In this way, we obtain as\ninstances many significant examples, such as checking exceptions,\npreventing/limiting non-determinism, constraining order/fairness of outputs on\ndifferent locations. We also provide an extension with constructs to raise and\nhandle computational effects, which can be instantiated to model different\npolicies.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-14T12:13:44Z"}
{"aid":"http://arxiv.org/abs/2504.10193v1","title":"A Piece of QAICCC: Towards a Countermeasure Against Crosstalk Attacks in\n  Quantum Servers","summary":"Quantum computing, while allowing for processing information exponentially\nfaster than classical computing, requires computations to be delegated to\nquantum servers, which makes security threats possible. For instance, previous\nstudies demonstrated that crosstalk between attacker and victim's qubits can be\nexploited to mount security attacks.\n  In this idea paper, we propose the QAICCC approach to allocate qubits between\nusers to minimize inter-circuit crosstalk and, thus, possibilities for attacks,\nwhile maximizing qubit usage. Also, combined with existing techniques, QAICCC\naims to reduce intra-circuit noise. Thus, QAICCC will support quantum computing\nadoption by securing the usage of quantum servers by a large number of actors.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T12:55:07Z"}
{"aid":"http://arxiv.org/abs/2504.10197v1","title":"Comparison of smoothening flows for the topological charge in QCD-like\n  theories","summary":"We investigate properties of the topological charge for several SU(NC) gauge\nfield ensembles for NC = 4, 5, 6 with a single fermion in the two-index\nanti-symmetric representation, covering multiple lattice spacings at otherwise\napproximately constant physical parameters. Comparing the topological charge\ndefined by the Wilson flow and the over-improved DBW2 flow we find that already\nat small flow times the latter stabilises on discrete values. We provide\nevidence that as the lattice spacing is lowered the Wilson flow also separates\ninto discrete sectors at earlier flow times. Adopting the DWB2 definition in\nthe remainder of the analysis, we do not see any evidence of fractional\ntopological charges, which could in principle appear at finite lattice spacing.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-14T13:02:50Z"}
{"aid":"http://arxiv.org/abs/2504.10203v1","title":"A moving horizon estimator for aquifer thermal energy storages","summary":"Aquifer thermal energy storages (ATES) represent groundwater saturated\naquifers that store thermal energy in the form of heated or cooled groundwater.\nCombining two ATES, one can harness excess thermal energy from summer (heat)\nand winter (cold) to support the building's heating, ventilation, and air\nconditioning (HVAC) technology. In general, a dynamic operation of ATES\nthroughout the year is beneficial to avoid using fossil fuel-based HVAC\ntechnology and maximize the ``green use'' of ATES. Model predictive control\n(MPC) with an appropriate system model may become a crucial control approach\nfor ATES systems. Consequently, the MPC model should reflect spatial\ntemperature profiles around ATES' boreholes to predict extracted groundwater\ntemperatures accurately. However, meaningful predictions require the estimation\nof the current state of the system, as measurements are usually only at the\nborehole of the ATES. In control, this is often realized by model-based\nobservers. Still, observing the state of an ATES system is non-trivial, since\nthe model is typically hybrid. We show how to exploit the specific structure of\nthe hybrid ATES model and design an easy-to-solve moving horizon estimator\nbased on a quadratic program.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T13:11:34Z"}
{"aid":"http://arxiv.org/abs/2504.10205v1","title":"Dual Theory of Turbulent Mixing","summary":"We present an exact analytic solution for incompressible turbulent mixing\ndescribed by 3D NS equations, with a passive scalar (concentration,\ntemperature, or other scalar field) driven by the turbulent velocity field.\nUsing our recent solution of decaying turbulence in terms of the Euler\nensemble, we represent the correlation functions of a passive scalar as\nstatistical averages over this ensemble. The statistical limit, corresponding\nto decaying turbulence, can be computed in quadrature. We find the decay\nspectrum and the scaling functions of the pair correlation and match them with\nphysical and real experiments.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,hep-th,nlin.SI","published":"2025-04-14T13:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.10225v1","title":"A Quasi-Steady-State Black Box Simulation Approach for the Generation of\n  g-g-g-v Diagrams","summary":"The classical g-g diagram, representing the achievable acceleration space for\na vehicle, is commonly used as a constraint in trajectory planning and control\ndue to its computational simplicity. To address non-planar road geometries,\nthis concept can be extended to incorporate g-g constraints as a function of\nvehicle speed and vertical acceleration, commonly referred to as g-g-g-v\ndiagrams. However, the estimation of g-g-g-v diagrams is an open problem.\nExisting simulation-based approaches struggle to isolate non-transient,\nopen-loop stable states across all combinations of speed and acceleration,\nwhile optimization-based methods often require simplified vehicle equations and\nhave potential convergence issues. In this paper, we present a novel,\nopen-source, quasi-steady-state black box simulation approach that applies a\nvirtual inertial force in the longitudinal direction. The method emulates the\nload conditions associated with a specified longitudinal acceleration while\nmaintaining constant vehicle speed, enabling open-loop steering ramps in a\npurely QSS manner. Appropriate regulation of the ramp steer rate inherently\nmitigates transient vehicle dynamics when determining the maximum feasible\nlateral acceleration. Moreover, treating the vehicle model as a black box\neliminates model mismatch issues, allowing the use of high-fidelity or\nproprietary vehicle dynamics models typically unsuited for optimization\napproaches. An open-source version of the proposed method is available at:\nhttps://github.com/TUM-AVS/GGGVDiagrams","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T13:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.10255v1","title":"Dissipation-Induced Threshold on Integrability Footprints","summary":"The presence of a dissipative environment disrupts the unitary spectrum of\ndynamical quantum maps. Nevertheless, key features of the underlying unitary\ndynamics -- such as their integrable or chaotic nature -- are not immediately\nerased by dissipation. To investigate this, we model dissipation as a convex\ncombination of a unitary evolution and a random Kraus map, and study how\nsignatures of integrability fade as dissipation strength increases. Our\nanalysis shows that in the weakly dissipative regime, the complex eigenvalue\nspectrum organizes into well-defined, high-density clusters. We estimate the\ncritical dissipation threshold beyond which these clusters disappear, rendering\nthe dynamics indistinguishable from chaotic evolution. This threshold depends\nonly on the number of spectral clusters and the rank of the random Kraus\noperator. To characterize this transition, we introduce the eigenvalue angular\nvelocity as a diagnostic of integrability loss. We illustrate our findings\nthrough several integrable quantum circuits, including the dissipative quantum\nFourier transform. Our results provide a quantitative picture of how noise\ngradually erases the footprints of integrability in open quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-14T14:16:37Z"}
{"aid":"http://arxiv.org/abs/2504.10256v1","title":"Compressible fluids excited by space-dependent transport noise","summary":"We study the compressible Navier-Stokes system driven by physically relevant\ntransport noise, where the noise influences both the continuity and momentum\nequations. Our approach is based on transforming the system into a partial\ndifferential equation with random, time- and space-dependent coefficients. A\nkey challenge arises from the fact that these coefficients are\nnon-differentiable in time, rendering standard compactness arguments for the\nidentification of the pressure inapplicable. To overcome this difficulty, we\ndevelop a novel multi-layer approximation scheme and introduce a precise\nlocalization strategy with respect to both the sample space and time variable.\nThe limit pressure is then identified via the corresponding effective viscous\nflux identity. By means of stochastic compactness methods, particularly\nSkorokhod's representation theorem and its generalization by Jakubowski, we\nensure the progressive measurability required to return to the original system.\nOur results broaden the applicability of transport noise models in fluid\ndynamics and offer new insights into the interaction between stochastic effects\nand compressibility.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T14:17:25Z"}
{"aid":"http://arxiv.org/abs/2504.10275v1","title":"LMFormer: Lane based Motion Prediction Transformer","summary":"Motion prediction plays an important role in autonomous driving. This study\npresents LMFormer, a lane-aware transformer network for trajectory prediction\ntasks. In contrast to previous studies, our work provides a simple mechanism to\ndynamically prioritize the lanes and shows that such a mechanism introduces\nexplainability into the learning behavior of the network. Additionally,\nLMFormer uses the lane connection information at intersections, lane merges,\nand lane splits, in order to learn long-range dependency in lane structure.\nMoreover, we also address the issue of refining the predicted trajectories and\npropose an efficient method for iterative refinement through stacked\ntransformer layers. For benchmarking, we evaluate LMFormer on the nuScenes\ndataset and demonstrate that it achieves SOTA performance across multiple\nmetrics. Furthermore, the Deep Scenario dataset is used to not only illustrate\ncross-dataset network performance but also the unification capabilities of\nLMFormer to train on multiple datasets and achieve better performance.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T14:43:46Z"}
{"aid":"http://arxiv.org/abs/2504.10288v1","title":"Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost\n  imaging","summary":"We present a new self-supervised deep-learning-based Ghost Imaging (GI)\nreconstruction method, which provides unparalleled reconstruction performance\nfor noisy acquisitions among unsupervised methods. We present the supporting\nmathematical framework and results from theoretical and real data use cases.\nSelf-supervision removes the need for clean reference data while offering\nstrong noise reduction. This provides the necessary tools for addressing\nsignal-to-noise ratio concerns for GI acquisitions in emerging and cutting-edge\nlow-light GI scenarios. Notable examples include micro- and nano-scale x-ray\nemission imaging, e.g., x-ray fluorescence imaging of dose-sensitive samples.\nTheir applications include in-vivo and in-operando case studies for biological\nsamples and batteries.","main_category":"cs.CV","categories":"cs.CV,cs.LG,physics.data-an","published":"2025-04-14T14:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.10307v1","title":"CROSSAN: Towards Efficient and Effective Adaptation of Multiple\n  Multimodal Foundation Models for Sequential Recommendation","summary":"Multimodal Foundation Models (MFMs) excel at representing diverse raw\nmodalities (e.g., text, images, audio, videos, etc.). As recommender systems\nincreasingly incorporate these modalities, leveraging MFMs to generate better\nrepresentations has great potential. However, their application in sequential\nrecommendation remains largely unexplored. This is primarily because mainstream\nadaptation methods, such as Fine-Tuning and even Parameter-Efficient\nFine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur high\ncomputational costs, especially when integrating multiple modality encoders,\nthus hindering research progress. As a result, it remains unclear whether we\ncan efficiently and effectively adapt multiple (>2) MFMs for the sequential\nrecommendation task.\n  To address this, we propose a plug-and-play Cross-modal Side Adapter Network\n(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSAN\nachieves high efficiency while enabling cross-modal learning across diverse\nmodalities. To optimize the final stage of multimodal fusion across diverse\nmodalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.\nCROSSAN achieves superior performance on the public datasets for adapting four\nfoundation models with raw modalities. Performance consistently improves as\nmore MFMs are adapted. We will release our code and datasets to facilitate\nfuture research.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T15:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.10318v1","title":"Shield Bash: Abusing Defensive Coherence State Retrieval to Break Timing\n  Obfuscation","summary":"Microarchitectural attacks are a significant concern, leading to many\nhardware-based defense proposals. However, different defenses target different\nclasses of attacks, and their impact on each other has not been fully\nconsidered. To raise awareness of this problem, we study an interaction between\ntwo state-of-the art defenses in this paper, timing obfuscations of remote\ncache lines (TORC) and delaying speculative changes to remote cache lines\n(DSRC). TORC mitigates cache-hit based attacks and DSRC mitigates speculative\ncoherence state change attacks.\n  We observe that DSRC enables coherence information to be retrieved into the\nprocessor core, where it is out of the reach of timing obfuscations to protect.\nThis creates an unforeseen consequence that redo operations can be triggered\nwithin the core to detect the presence or absence of remote cache lines, which\nconstitutes a security vulnerability. We demonstrate that a new covert channel\nattack is possible using this vulnerability. We propose two ways to mitigate\nthe attack, whose performance varies depending on an application's cache usage.\nOne way is to never send remote exclusive coherence state (E) information to\nthe core even if it is created. The other way is to never create a remote E\nstate, which is responsible for triggering redos.\n  We demonstrate the timing difference caused by this microarchitectural\ndefense assumption violation using GEM5 simulations. Performance evaluation on\nSPECrate 2017 and PARSEC benchmarks of the two fixes show less than 32\\%\naverage overhead across both sets of benchmarks. The repair which prevented the\ncreation of remote E state had less than 2.8% average overhead.","main_category":"cs.CR","categories":"cs.CR,cs.AR","published":"2025-04-14T15:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.10324v1","title":"Rayleigh-B√©nard-Marangoni convection in binary fluids - Effect of\n  miscibility on oscillatory mode","summary":"The pair of fluids, FC72- 1cSt silicone oil, exhibiting temperature-sensitive\nmiscibility gap is considered in this study to investigate the classical\nRayleigh-B\\'enard-Marangoni (RBM) instability. The system of fluids is\nconsidered at distinct temperatures to elucidate the effect of the degree of\nmiscibility between the two fluids. We employ a modified phase- field model to\ntrack the evolution of the RBM instability as the temperature of the system is\nvaried. The proposed model correctly initializes the concentration profile and\nalso properly leads to a miscibility-dependent surface tension. A\nspectral-collocation-based method is employed to solve the linearized governing\nequations that help investigate the onset characteristics of the convection,\ni.e., both the critical values and the mode of convection onset, which could be\neither oscillatory or stationary. The results reveal the dependence of the\nwindow of oscillatory convection on the degree of miscibility between the two\nfluids. The coupling between the Korteweg stresses and the degree of\nmiscibility governs the thermal energy required to provoke the system into the\nconvective state. The onset of RBM flow is analyzed parametrically, with the\nsuccessive rise in the strength of the Marangoni component.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-14T15:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.10332v1","title":"MIPS is a Maxwell fluid with an extended and non-monotonic crossover","summary":"Understanding the mechanical properties of active suspensions is crucial for\ntheir potential applications in materials engineering. Among the various\nphenomena in active matter that have no analogue in equilibrium systems,\nmotility-induced phase separation (MIPS) in active colloidal suspensions is one\nof the most extensively studied. However, the mechanical properties of this\nfundamental active state of matter remain poorly understood. This study\ninvestigates the rheology of a suspension of active colloidal particles under\nconstant and oscillatory shear. Systems consisting of pseudo-hard active\nBrownian particles exhibiting co-existence of dense and dilute phases behave as\na viscoelastic Maxwell fluid at low and high frequencies, displaying\nexclusively shear thinning across a wide range of densities and activities.\nRemarkably, the cross-over point between the storage and loss moduli is\nnon-monotonic, rising with activity before the MIPS transition but falling with\nactivity after the transition, revealing the subtleties of how active forces\nand intrinsically out-of-equilibrium phases affect the mechanical properties of\nthese systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T15:40:17Z"}
{"aid":"http://arxiv.org/abs/2504.10356v1","title":"MultiLoKo: a multilingual local knowledge benchmark for LLMs spanning 31\n  languages","summary":"We present MultiLoKo, a new benchmark for evaluating multilinguality in LLMs\ncovering 31 languages. MultiLoKo consists of three partitions: a main partition\nconsisting of 500 questions per language, separately sourced to be locally\nrelevant to the specific language, and two translated partitions, containing\nhuman-authored translations from 30 non-English languages to English and vice\nversa. For comparison, we also release corresponding machine-authored\ntranslations. The data is equally distributed over two splits: a dev split and\na blind, out-of-distribution test split. MultiLoKo can be used to study a\nvariety of questions regarding the multilinguality of LLMs as well as\nmeta-questions about multilingual benchmark creation. We compute MultiLoKo\nscores for 11 base and chat models marketed to be multilingual and study their\naverage performance, their performance parity across languages, how much their\nability to answer questions depends on the question language, and which\nlanguages are most difficult. None of the models we studied performs well on\nMultiLoKo, as indicated by low average scores as well as large differences\nbetween the best and worst scoring languages. Furthermore, we find a\nsubstantial effect of the question language, indicating sub-optimal knowledge\ntransfer between languages. Lastly, we find that using local vs\nEnglish-translated data can result in differences more than 20 points for the\nbest performing models, drastically change the estimated difficulty of some\nlanguages. For using machines instead of human translations, we find a weaker\neffect on ordering of language difficulty, a larger difference in model\nrankings, and a substantial drop in estimated performance for all models.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T16:05:59Z"}
{"aid":"http://arxiv.org/abs/2504.10368v1","title":"S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability\n  of Large Reasoning Models","summary":"We introduce S1-Bench, a novel benchmark designed to evaluate Large Reasoning\nModels' (LRMs) performance on simple tasks that favor intuitive system 1\nthinking rather than deliberative system 2 reasoning. While LRMs have achieved\nsignificant breakthroughs in complex reasoning tasks through explicit chains of\nthought, their reliance on deep analytical thinking may limit their system 1\nthinking capabilities. Moreover, a lack of benchmark currently exists to\nevaluate LRMs' performance in tasks that require such capabilities. To fill\nthis gap, S1-Bench presents a set of simple, diverse, and naturally clear\nquestions across multiple domains and languages, specifically designed to\nassess LRMs' performance in such tasks. Our comprehensive evaluation of 22 LRMs\nreveals significant lower efficiency tendencies, with outputs averaging 15.5\ntimes longer than those of traditional small LLMs. Additionally, LRMs often\nidentify correct answers early but continue unnecessary deliberation, with some\nmodels even producing numerous errors. These findings highlight the rigid\nreasoning patterns of current LRMs and underscore the substantial development\nneeded to achieve balanced dual-system thinking capabilities that can adapt\nappropriately to task complexity.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T16:13:23Z"}
{"aid":"http://arxiv.org/abs/2504.10374v1","title":"Ctrl-Z: Controlling AI Agents via Resampling","summary":"Control evaluations measure whether monitoring and security protocols for AI\nsystems prevent intentionally subversive AI models from causing harm. Our work\npresents the first control evaluation performed in an agent environment. We\nconstruct BashBench, a dataset of 257 challenging multi-step system\nadministration tasks, and evaluate whether various safety measures can prevent\nan adversarially constructed AI agent from covertly downloading and executing\nmalicious code in this environment. This multi-step setting introduces new\nattack and defense dynamics, which we investigate in order to design novel\ncontrol protocols that prevent safety failures without hindering the ability of\nnon-malicious agents to perform useful work. We introduce a class of control\nprotocols called resample protocols that dynamically take additional samples of\ncertain actions. We find these protocols significantly improve on existing\ntechniques by selectively blocking the AI agent from executing suspicious code\nand incriminating the agent by generating additional examples of dangerous\nbehavior. We measure the tradeoff between attack prevention and usefulness; our\nbest protocol combines resampling with analysis of previous steps, reducing the\nsuccess rate of attacks from 58% to 7% at a 5% cost to the performance of a\nnon-malicious agent.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T16:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.10388v1","title":"Inferring genotype-phenotype maps using attention models","summary":"Predicting phenotype from genotype is a central challenge in genetics.\nTraditional approaches in quantitative genetics typically analyze this problem\nusing methods based on linear regression. These methods generally assume that\nthe genetic architecture of complex traits can be parameterized in terms of an\nadditive model, where the effects of loci are independent, plus (in some cases)\npairwise epistatic interactions between loci. However, these models struggle to\nanalyze more complex patterns of epistasis or subtle gene-environment\ninteractions. Recent advances in machine learning, particularly attention-based\nmodels, offer a promising alternative. Initially developed for natural language\nprocessing, attention-based models excel at capturing context-dependent\ninteractions and have shown exceptional performance in predicting protein\nstructure and function. Here, we apply attention-based models to quantitative\ngenetics. We analyze the performance of this attention-based approach in\npredicting phenotype from genotype using simulated data across a range of\nmodels with increasing epistatic complexity, and using experimental data from a\nrecent quantitative trait locus mapping study in budding yeast. We find that\nour model demonstrates superior out-of-sample predictions in epistatic regimes\ncompared to standard methods. We also explore a more general multi-environment\nattention-based model to jointly analyze genotype-phenotype maps across\nmultiple environments and show that such architectures can be used for\n\"transfer learning\" - predicting phenotypes in novel environments with limited\ntraining data.","main_category":"q-bio.GN","categories":"q-bio.GN,cs.LG,q-bio.PE","published":"2025-04-14T16:32:17Z"}
{"aid":"http://arxiv.org/abs/2504.10399v1","title":"Unique Decoding of Reed-Solomon and Related Codes for Semi-Adversarial\n  Errors","summary":"For over a quarter century, the Guruswami-Sudan algorithm has served as the\nstate-of-the-art for list-decoding Reed-Solomon (RS) codes up to the Johnson\nbound against adversarial errors. However, some recent structural results on\nthe combinatorial list decoding of randomly punctured Reed-Solomon codes\nsuggest that Johnson bound can likely be broken for some subclasses of RS\ncodes. Motivated by these results, we seek to make traction on understanding\nadversarial decoding by considering a new model: semi-adversarial errors. This\nerror model bridges between fully random errors and fully adversarial errors by\nallowing some symbols of a message to be corrupted by an adversary while others\nare replaced with uniformly random symbols.\n  As our main quest, we seek to understand optimal efficient unique decoding\nalgorithms in the semi-adversarial model. In particular, we revisit some\nclassical results on decoding interleaved Reed-Solomon codes (aka subfield\nevaluation RS codes) in the random error model by Bleichenbacher-Kiayias-Yung\n(BKY) and work to improve and extend their analysis. First, we give an improved\nimplementation and analysis of the BKY algorithm for interleaved Reed-Solomon\ncodes in the semi-adversarial model. In particular, our algorithm runs in\nnear-linear time, and for most mixtures of random and adversarial errors, our\nanalysis matches the information-theoretic optimum.\n  Moreover, inspired by the BKY algorithm, we use a novel interpolation to\nextend our approach to the settings of folded Reed-Solomon codes, resulting in\nfast algorithms for unique decoding against semi-adversarial errors. A\nparticular advantage of our near-linear time algorithm over state-of-the-art\ndecoding algorithms for adversarial errors is that its running time depends\nonly on a polynomial function of the folding parameter rather than on an\nexponential function.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-14T16:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.10411v1","title":"FPGA-Optimized Hardware Accelerator for Fast Fourier Transform and\n  Singular Value Decomposition in AI","summary":"This research introduces an FPGA-based hardware accelerator to optimize the\nSingular Value Decomposition (SVD) and Fast Fourier transform (FFT) operations\nin AI models. The proposed design aims to improve processing speed and reduce\ncomputational latency. Through experiments, we validate the performance\nbenefits of the hardware accelerator and show how well it handles FFT and SVD\noperations. With its strong security and durability, the accelerator design\nachieves significant speedups over software implementations, thanks to its\nmodules for data flow control, watermark embedding, FFT, and SVD.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-14T16:58:46Z"}
{"aid":"http://arxiv.org/abs/2504.10445v1","title":"RealWebAssist: A Benchmark for Long-Horizon Web Assistance with\n  Real-World Users","summary":"To achieve successful assistance with long-horizon web-based tasks, AI agents\nmust be able to sequentially follow real-world user instructions over a long\nperiod. Unlike existing web-based agent benchmarks, sequential instruction\nfollowing in the real world poses significant challenges beyond performing a\nsingle, clearly defined task. For instance, real-world human instructions can\nbe ambiguous, require different levels of AI assistance, and may evolve over\ntime, reflecting changes in the user's mental state. To address this gap, we\nintroduce RealWebAssist, a novel benchmark designed to evaluate sequential\ninstruction-following in realistic scenarios involving long-horizon\ninteractions with the web, visual GUI grounding, and understanding ambiguous\nreal-world user instructions. RealWebAssist includes a dataset of sequential\ninstructions collected from real-world human users. Each user instructs a\nweb-based assistant to perform a series of tasks on multiple websites. A\nsuccessful agent must reason about the true intent behind each instruction,\nkeep track of the mental state of the user, understand user-specific routines,\nand ground the intended tasks to actions on the correct GUI elements. Our\nexperimental results show that state-of-the-art models struggle to understand\nand ground user instructions, posing critical challenges in following\nreal-world user instructions for long-horizon web assistance.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV,cs.LG","published":"2025-04-14T17:36:46Z"}
{"aid":"http://arxiv.org/abs/2504.10479v1","title":"InternVL3: Exploring Advanced Training and Test-Time Recipes for\n  Open-Source Multimodal Models","summary":"We introduce InternVL3, a significant advancement in the InternVL series\nfeaturing a native multimodal pre-training paradigm. Rather than adapting a\ntext-only large language model (LLM) into a multimodal large language model\n(MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and\nlinguistic capabilities from both diverse multimodal data and pure-text corpora\nduring a single pre-training stage. This unified training paradigm effectively\naddresses the complexities and alignment challenges commonly encountered in\nconventional post-hoc training pipelines for MLLMs. To further improve\nperformance and scalability, InternVL3 incorporates variable visual position\nencoding (V2PE) to support extended multimodal contexts, employs advanced\npost-training techniques such as supervised fine-tuning (SFT) and mixed\npreference optimization (MPO), and adopts test-time scaling strategies\nalongside an optimized training infrastructure. Extensive empirical evaluations\ndemonstrate that InternVL3 delivers superior performance across a wide range of\nmulti-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the\nMMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its\ncapabilities remain highly competitive with leading proprietary models,\nincluding ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also\nmaintaining strong pure-language proficiency. In pursuit of open-science\nprinciples, we will publicly release both the training data and model weights\nto foster further research and development in next-generation MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.10834v1","title":"LightFormer: A lightweight and efficient decoder for remote sensing\n  image segmentation","summary":"Deep learning techniques have achieved remarkable success in the semantic\nsegmentation of remote sensing images and in land-use change detection.\nNevertheless, their real-time deployment on edge platforms remains constrained\nby decoder complexity. Herein, we introduce LightFormer, a lightweight decoder\nfor time-critical tasks that involve unstructured targets, such as disaster\nassessment, unmanned aerial vehicle search-and-rescue, and cultural heritage\nmonitoring. LightFormer employs a feature-fusion and refinement module built on\nchannel processing and a learnable gating mechanism to aggregate multi-scale,\nmulti-range information efficiently, which drastically curtails model\ncomplexity. Furthermore, we propose a spatial information selection module\n(SISM) that integrates long-range attention with a detail preservation branch\nto capture spatial dependencies across multiple scales, thereby substantially\nimproving the recognition of unstructured targets in complex scenes. On the\nISPRS Vaihingen benchmark, LightFormer attains 99.9% of GLFFNet's mIoU (83.9%\nvs. 84.0%) while requiring only 14.7% of its FLOPs and 15.9% of its parameters,\nthus achieving an excellent accuracy-efficiency trade-off. Consistent results\non LoveDA, ISPRS Potsdam, RescueNet, and FloodNet further demonstrate its\nrobustness and superior perception of unstructured objects. These findings\nhighlight LightFormer as a practical solution for remote sensing applications\nwhere both computational economy and high-precision segmentation are\nimperative.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T03:25:39Z"}
{"aid":"http://arxiv.org/abs/2504.10836v1","title":"Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach\n  Based on Deep Joint Source-Channel Coding","summary":"In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communication systems, the acquisition of downlink channel state\ninformation (CSI) is essential for maximizing spatial resource utilization and\nimproving system spectral efficiency. The separate design of modules in\nAI-based CSI feedback architectures under traditional modular communication\nframeworks, including channel estimation (CE), CSI compression and feedback,\nleads to sub-optimal performance. In this paper, we propose an uplink assisted\njoint CE and and CSI feedback approach via deep learning for downlink CSI\nacquisition, which mitigates performance degradation caused by distribution\nbias across separately trained modules in traditional modular communication\nframeworks. The proposed network adopts a deep joint source-channel coding\n(DJSCC) architecture to mitigate the cliff effect encountered in the\nconventional separate source-channel coding. Furthermore, we exploit the uplink\nCSI as auxiliary information to enhance CSI reconstruction accuracy by\nleveraging the partial reciprocity between the uplink and downlink channels in\nFDD systems, without introducing additional overhead. The effectiveness of\nuplink CSI as assisted information and the necessity of an end-toend\nmulti-module joint training architecture is validated through comprehensive\nablation and scalability experiments.","main_category":"eess.SP","categories":"eess.SP,cs.AI","published":"2025-04-15T03:29:24Z"}
{"aid":"http://arxiv.org/abs/2504.10855v1","title":"Virtual Contraction Approach to Decentralized Adaptive Stabilization of\n  Nonlinear Time-Delayed Networks","summary":"In this paper, we utilize a diagonally dominant structure for the\ndecentralized stabilization of unknown nonlinear time-delayed networks.\nGeneralizing the idea of virtual contraction analysis to time-delayed systems,\nwe demonstrate that nonlinear time-delayed networks can be stabilized by\ndiagonal high-gains if the input matrices possess certain generalized\n(column/row) diagonally dominant properties. To achieve stabilization of\nunknown networks, we further propose a distributed adaptive tuning rule for\neach individual gain function, ensuring that all closed-loop trajectories\nconverge to the origin. The effectiveness of the proposed decentralized\nadaptive control is verified in a case study on epidemic spreading control in\nSIS networks with transmission delays.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T04:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.10898v1","title":"Xpose: Bi-directional Engineering for Hidden Query Extraction","summary":"Query reverse engineering (QRE) aims to synthesize a SQL query to connect a\ngiven database and result instance. A recent variation of QRE is where an\nadditional input, an opaque executable containing a ground-truth query, is\nprovided, and the goal is to non-invasively extract this specific query through\nonly input-output examples. This variant, called Hidden Query Extraction (HQE),\nhas a spectrum of industrial use-cases including query recovery, database\nsecurity, and vendor migration. The reverse engineering (RE) tools developed\nfor HQE, which are based on database mutation and generation techniques, can\nonly extract flat queries with key-based equi joins and conjunctive arithmetic\nfilter predicates, making them limited wrt both query structure and query\noperators. In this paper, we present Xpose, a HQE solution that elevates the\nextraction scope to realistic complex queries, such as those found in the TPCH\nbenchmark. A two-pronged approach is taken: (1) The existing RE scope is\nsubstantially extended to incorporate union connectors, algebraic filter\npredicates, and disjunctions for both values and predicates. (2) The predictive\npower of LLMs is leveraged to convert business descriptions of the opaque\napplication into extraction guidance, representing ``forward engineering\" (FE).\nThe FE module recognizes common constructs, such as nesting of sub-queries,\nouter joins, and scalar functions. In essence, FE establishes the broad query\ncontours, while RE fleshes out the fine-grained details. We have evaluated\nXpose on (a) E-TPCH, a query suite comprising the complete TPCH benchmark\nextended with queries featuring unions, diverse join types, and sub-queries;\nand (b) the real-world STACK benchmark. The experimental results demonstrate\nthat its bi-directional engineering approach accurately extracts these complex\nqueries, representing a significant step forward with regard to HQE coverage.","main_category":"cs.DB","categories":"cs.DB,cs.AI,H.2.8","published":"2025-04-15T06:17:58Z"}
{"aid":"http://arxiv.org/abs/2504.10903v1","title":"Efficient Reasoning Models: A Survey","summary":"Reasoning models have demonstrated remarkable progress in solving complex and\nlogic-intensive tasks by generating extended Chain-of-Thoughts (CoTs) prior to\narriving at a final answer. Yet, the emergence of this \"slow-thinking\"\nparadigm, with numerous tokens generated in sequence, inevitably introduces\nsubstantial computational overhead. To this end, it highlights an urgent need\nfor effective acceleration. This survey aims to provide a comprehensive\noverview of recent advances in efficient reasoning. It categorizes existing\nworks into three key directions: (1) shorter - compressing lengthy CoTs into\nconcise yet effective reasoning chains; (2) smaller - developing compact\nlanguage models with strong reasoning capabilities through techniques such as\nknowledge distillation, other model compression techniques, and reinforcement\nlearning; and (3) faster - designing efficient decoding strategies to\naccelerate inference. A curated collection of papers discussed in this survey\nis available in our GitHub repository.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T06:28:00Z"}
{"aid":"http://arxiv.org/abs/2504.10905v1","title":"InterAnimate: Taming Region-aware Diffusion Model for Realistic Human\n  Interaction Animation","summary":"Recent video generation research has focused heavily on isolated actions,\nleaving interactive motions-such as hand-face interactions-largely unexamined.\nThese interactions are essential for emerging biometric authentication systems,\nwhich rely on interactive motion-based anti-spoofing approaches. From a\nsecurity perspective, there is a growing need for large-scale, high-quality\ninteractive videos to train and strengthen authentication models. In this work,\nwe introduce a novel paradigm for animating realistic hand-face interactions.\nOur approach simultaneously learns spatio-temporal contact dynamics and\nbiomechanically plausible deformation effects, enabling natural interactions\nwhere hand movements induce anatomically accurate facial deformations while\nmaintaining collision-free contact. To facilitate this research, we present\nInterHF, a large-scale hand-face interaction dataset featuring 18 interaction\npatterns and 90,000 annotated videos. Additionally, we propose InterAnimate, a\nregion-aware diffusion model designed specifically for interaction animation.\nInterAnimate leverages learnable spatial and temporal latents to effectively\ncapture dynamic interaction priors and integrates a region-aware interaction\nmechanism that injects these priors into the denoising process. To the best of\nour knowledge, this work represents the first large-scale effort to\nsystematically study human hand-face interactions. Qualitative and quantitative\nresults show InterAnimate produces highly realistic animations, setting a new\nbenchmark. Code and data will be made public to advance research.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-15T06:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.10916v1","title":"Embedding Radiomics into Vision Transformers for Multimodal Medical\n  Image Classification","summary":"Background: Deep learning has significantly advanced medical image analysis,\nwith Vision Transformers (ViTs) offering a powerful alternative to\nconvolutional models by modeling long-range dependencies through\nself-attention. However, ViTs are inherently data-intensive and lack\ndomain-specific inductive biases, limiting their applicability in medical\nimaging. In contrast, radiomics provides interpretable, handcrafted descriptors\nof tissue heterogeneity but suffers from limited scalability and integration\ninto end-to-end learning frameworks. In this work, we propose the\nRadiomics-Embedded Vision Transformer (RE-ViT) that combines radiomic features\nwith data-driven visual embeddings within a ViT backbone.\n  Purpose: To develop a hybrid RE-ViT framework that integrates radiomics and\npatch-wise ViT embeddings through early fusion, enhancing robustness and\nperformance in medical image classification.\n  Methods: Following the standard ViT pipeline, images were divided into\npatches. For each patch, handcrafted radiomic features were extracted and fused\nwith linearly projected pixel embeddings. The fused representations were\nnormalized, positionally encoded, and passed to the ViT encoder. A learnable\n[CLS] token aggregated patch-level information for classification. We evaluated\nRE-ViT on three public datasets (including BUSI, ChestXray2017, and Retinal\nOCT) using accuracy, macro AUC, sensitivity, and specificity. RE-ViT was\nbenchmarked against CNN-based (VGG-16, ResNet) and hybrid (TransMed) models.\n  Results: RE-ViT achieved state-of-the-art results: on BUSI,\nAUC=0.950+/-0.011; on ChestXray2017, AUC=0.989+/-0.004; on Retinal OCT,\nAUC=0.986+/-0.001, which outperforms other comparison models.\n  Conclusions: The RE-ViT framework effectively integrates radiomics with ViT\narchitectures, demonstrating improved performance and generalizability across\nmultimodal medical image classification tasks.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.CV","published":"2025-04-15T06:55:58Z"}
{"aid":"http://arxiv.org/abs/2504.10922v1","title":"Equivalence of germs (of mappings and sets) over k vs that over K","summary":"Consider real-analytic mapping-germs, (R^n,o)-> (R^m,o). They can be\nequivalent (by coordinate changes) complex-analytically, but not\nreal-analytically. However, if the transformation of complex-equivalence is\nidentity modulo higher order terms, then it implies the real-equivalence.\n  On the other hand, starting from complex-analytic map-germs (C^n,o)->(C^m,o),\nand taking any field extension, C to K, one has: if two maps are equivalent\nover K, then they are equivalent over C.\n  These (quite useful) properties seem to be not well known. We prove slightly\nstronger properties in a more general form:\n  * for Maps(X,Y) where X,Y are (formal/analytic/Nash) scheme-germs, with\narbitrary singularities, over a base ring k;\n  * for the classical groups of (right/left-right/contact) equivalence of\nSingularity Theory;\n  * for faithfully-flat extensions of rings k -> K. In particular, for\narbitrary extension of fields, in any characteristic.\n  The case ``k is a ring\" is important for the study of\ndeformations/unfoldings. E.g. it implies the statement for fields: if a family\nof maps {f_t} is trivial over K, then it is also trivial over k.\n  Similar statements for scheme-germs (``isomorphism over K vs isomorphism over\nk\") follow by the standard reduction ``Two maps are contact equivalent iff\ntheir zero sets are ambient isomorphic\".\n  This study involves the contact equivalence of maps with singular targets,\nwhich seems to be not well-established. We write down the relevant part of this\ntheory.","main_category":"math.AG","categories":"math.AG,math.AC,math.CV","published":"2025-04-15T07:09:27Z"}
{"aid":"http://arxiv.org/abs/2504.10923v1","title":"Fast-Powerformer: A Memory-Efficient Transformer for Accurate Mid-Term\n  Wind Power Forecasting","summary":"Wind power forecasting (WPF), as a significant research topic within\nrenewable energy, plays a crucial role in enhancing the security, stability,\nand economic operation of power grids. However, due to the high stochasticity\nof meteorological factors (e.g., wind speed) and significant fluctuations in\nwind power output, mid-term wind power forecasting faces a dual challenge of\nmaintaining high accuracy and computational efficiency. To address these\nissues, this paper proposes an efficient and lightweight mid-term wind power\nforecasting model, termed Fast-Powerformer. The proposed model is built upon\nthe Reformer architecture, incorporating structural enhancements such as a\nlightweight Long Short-Term Memory (LSTM) embedding module, an input\ntransposition mechanism, and a Frequency Enhanced Channel Attention Mechanism\n(FECAM). These improvements enable the model to strengthen temporal feature\nextraction, optimize dependency modeling across variables, significantly reduce\ncomputational complexity, and enhance sensitivity to periodic patterns and\ndominant frequency components. Experimental results conducted on multiple\nreal-world wind farm datasets demonstrate that the proposed Fast-Powerformer\nachieves superior prediction accuracy and operational efficiency compared to\nmainstream forecasting approaches. Furthermore, the model exhibits fast\ninference speed and low memory consumption, highlighting its considerable\npractical value for real-world deployment scenarios.","main_category":"cs.LG","categories":"cs.LG,eess.SP","published":"2025-04-15T07:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.10924v1","title":"Exploring the nature of $Œ∑_{1}(1855)$ and it's partner in a chiral\n  quark model","summary":"Inspired by the recent experimental discoveries of \\(X(3872)\\)\n(\\(c\\bar{q}\\)-\\(q\\bar{c}\\)) and \\(T_{cc}\\) (\\(c\\bar{q}\\)-\\(c\\bar{q}\\)), we\nsystematically study two four-quark systems: the \\(K K_1\\)\n(\\(q\\bar{s}\\)-\\(q\\bar{s}\\)) system and the \\(K \\bar{K}_1\\)\n(\\(q\\bar{s}\\)-\\(s\\bar{q}\\)) system, which is a candidate for the recently\nobserved \\(\\eta_1(1855)\\). Within the framework of an accurate few-body\ncalculation method (GEM), we employ the chiral quark model to simultaneously\nconsider the molecular and diquark structures of these two multiquark systems\nand include their channel coupling effects. Our results show that the \\(K\n\\bar{K}_1\\) system remains a scattering state. On the other hand, due to the\npresence of a good-diquark structure in the \\(K K_1\\) system, we obtain a bound\nstate in the coupled-channel calculation. The primary contribution to the\nbinding energy comes from the exchange of \\(\\pi\\)-meson and \\(\\sigma\\)-meson.\nThe inter-quark distance indicates that it is a compact four-quark structure.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T07:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.10942v1","title":"The path towards measuring the gravitational field of proton bunches at\n  accelerators","summary":"The Newtonian law describing the gravitational interaction of\nnon-relativistic (slowly moving) gravitating matter, has been tested in many\nlaboratory experiments with very high precision. In contrast, the post\nMinkowskian predictions for the gravitational field of ultra-relativistic\nmatter, dominated by momentum instead of rest mass, have not been tested\ndirectly yet. The intense ultra-relativistic proton beam in the LHC storage\nring offers the potential to test general relativity and alternative\ngravitational theories in this parameter regime for the first time in\ncontrolled lab-scale experiments. If successful, this would open the road to a\nnovel use case of the LHC, where non-trivial gravitational physics could be\nstudied likely in a parasitic mode, without the necessity of dedicated filling\npatterns. While the technical challenges are formidable, they should also lead\nto the development of ultra-high-sensitive acceleration sensors with abundant\napplications in other parts of science and technology. The present document\nsummarizes the status of the theoretical studies in this direction, points out\nthe challenges, and possible ways of addressing them. It was submitted as a\ncontribution to the European Strategy for Particle Physics (ESPP) 2026 Update.","main_category":"hep-ex","categories":"hep-ex,gr-qc,quant-ph","published":"2025-04-15T07:45:35Z"}
{"aid":"http://arxiv.org/abs/2504.10968v1","title":"Bulk Hydrodynamic Transport in Weyl Semimetals","summary":"The role of collective longitudinal modes, plasmons, in bulk hydrodynamic\ntransport in Weyl semimetals is explored. In contrast to graphene, where these\nmodes are gapless, plasmons in Weyl semimetals are gapped. This gap, however,\ncan be made arbitrarily small by decreasing the temperature or the chemical\npotential, making plasmon modes thermally accessible, both in thermodynamics\nand transport. In very clean Weyl semimetals near charge-neutrality where the\nplasmon gap is minimal, we find that they leave an imprint in the thermal\nconductivity and the viscosity.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-15T08:20:45Z"}
{"aid":"http://arxiv.org/abs/2504.10974v1","title":"Self-Supervised Enhancement of Forward-Looking Sonar Images: Bridging\n  Cross-Modal Degradation Gaps through Feature Space Transformation and\n  Multi-Frame Fusion","summary":"Enhancing forward-looking sonar images is critical for accurate underwater\ntarget detection. Current deep learning methods mainly rely on supervised\ntraining with simulated data, but the difficulty in obtaining high-quality\nreal-world paired data limits their practical use and generalization. Although\nself-supervised approaches from remote sensing partially alleviate data\nshortages, they neglect the cross-modal degradation gap between sonar and\nremote sensing images. Directly transferring pretrained weights often leads to\noverly smooth sonar images, detail loss, and insufficient brightness. To\naddress this, we propose a feature-space transformation that maps sonar images\nfrom the pixel domain to a robust feature domain, effectively bridging the\ndegradation gap. Additionally, our self-supervised multi-frame fusion strategy\nleverages complementary inter-frame information to naturally remove speckle\nnoise and enhance target-region brightness. Experiments on three self-collected\nreal-world forward-looking sonar datasets show that our method significantly\noutperforms existing approaches, effectively suppressing noise, preserving\ndetailed edges, and substantially improving brightness, demonstrating strong\npotential for underwater target detection applications.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-15T08:34:56Z"}
{"aid":"http://arxiv.org/abs/2504.10989v1","title":"Global N-body Simulation of Gap Edge Structures Created by Perturbations\n  from a Small Satellite Embedded in Saturn's Rings II: The Effect of\n  Satellite's Orbital Eccentricity and Inclination","summary":"Pan and Daphnis are embedded in Saturn's rings and opening a gap with\nsatellite wakes at the gap edges. Furthermore, in the case of Daphnis,\npronounced vertical wall structures casting shadows on the rings are also\nobserved in the satellite wakes. In this paper, we perform a global 3D N-body\nsimulation with non-zero $e_{\\rm s}$ or non-zero $i_{\\rm s}$ of the satellite\norbit to investigate how they affect the gap edge structures. We found that the\neffect of satellite eccentricity is important both in the satellite wakes and\nthe vertical walls at the gap edges. The non-sinusoidal sawtooth-like satellite\nwakes and azimuthally more localized vertical walls observed by Cassini are\nsimultaneously reproduced in the detailed structures and spatial scales. Both\nof them periodically vary due to the satellite excursions between the apocenter\nand the pericenter. The ring particles in outer (inner) rings that undergo\nclosest encounters with the satellite near the apocenter (pericenter) are\nexcited the most highly. Because the excited eccentricities of the ring\nparticles are converted to the inclinations through physical collisions, the\nconversion is the most active for the particles that acquire the highest\neccentricities, resulting in the azimuthally more localized vertical wall\nstructures. The predicted height of the tallest vertical walls is $\\sim 0.2$\ntimes the satellite Hill radius in the case of the satellite eccentricity\ncomparable to Daphnis when adopting Hill scaling, which is twice as much as the\nheight obtained in the case of the circular satellite orbit and is\nquantitatively more consistent with the Cassini observation. These results show\nthat the observed vertical walls are actually formed by the satellite wakes\nfollowed by their conversion to the vertical motions through inter-particle\ncollisions, rather than by the out-of-plane perturbation from the satellite in\nan inclined orbit.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T09:01:52Z"}
{"aid":"http://arxiv.org/abs/2504.10998v1","title":"On the completeness problem of homogeneous Lorentz 3-dimensional spaces,\n  Part II","summary":"We consider 3-dimensional solvable Lie groups given by a semi-direct product\n$\\mathbb{R}\\ltimes_A\\mathbb{R}^2$, where $A$ is a nonzero real $2\\times2$\ndiagonalizable matrix. The completeness problem has been addressed in the\nliterature for two limiting cases: the unimodular Lie group $\\mathrm{Sol}$ and\nthe homothetic Lie group $\\mathrm{Ho}$. In this work, we solve the completeness\nproblem of left-invariant Lorentzian metrics on the remaining Lie groups of the\ngiven form. Moreover, we show that every 3-dimensional non-unimodular Lie group\nhas an incomplete left-invariant metric.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T09:15:07Z"}
{"aid":"http://arxiv.org/abs/2504.11006v1","title":"A Navier-Stokes-Peridynamics hybrid algorithm for the coupling of\n  compressible flows and fracturing materials","summary":"Modeling and simulation of fluid-structure interactions are crucial to the\nsuccess of aerospace engineering. This work addresses a novel hybrid algorithm\nthat models the close coupling between compressible flows and deformable\nmaterials using a mesoscopic approach. Specifically, the high-speed flows are\ndescribed by the gas-kinetic scheme, which is a robust Navier-Stokes\nalternative solver built on the molecular kinetic theory. The deformation,\ndamage, and fracture of materials are depicted using the bond-based\nperidynamics, which serves as coarse-grained molecular dynamics to construct\nnon-local extensions of classical continuum mechanics. The evolution of fluids\nand materials are closely coupled using the ghost-cell immersed boundary\nmethod. Within each time step, the solutions of flow and solid fields are\nupdated simultaneously, and physics-driven boundary conditions are exchanged\nfor each other via ghost cells. Extensive numerical experiments, including\ncrack propagation in a pre-cracked plate, subsonic flow around the NACA0012\nairfoil, supersonic flow around the circular cylinder, and shock wave impacting\non the elastic panel, are performed to validate the algorithm. The simulation\nresults demonstrate the unique advantages of current hybrid algorithm in\nsolving fracture propagation induced by high-speed flows.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-15T09:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.11011v1","title":"Document Quality Scoring for Web Crawling","summary":"The internet contains large amounts of low-quality content, yet users expect\nweb search engines to deliver high-quality, relevant results. The abundant\npresence of low-quality pages can negatively impact retrieval and crawling\nprocesses by wasting resources on these documents. Therefore, search engines\ncan greatly benefit from techniques that leverage efficient quality estimation\nmethods to mitigate these negative impacts. Quality scoring methods for web\npages are useful for many processes typical for web search systems, including\nstatic index pruning, index tiering, and crawling. Building on work by Chang et\nal.~\\cite{chang2024neural}, who proposed using neural estimators of semantic\nquality for static index pruning, we extend their approach and apply their\nneural quality scorers to assess the semantic quality of web pages in crawling\nprioritisation tasks. In our experimental analysis, we found that prioritising\nsemantically high-quality pages over low-quality ones can improve downstream\nsearch effectiveness. Our software contribution consists of a Docker container\nthat computes an effective quality score for a given web page, allowing the\nquality scorer to be easily included and used in other components of web search\nsystems.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-15T09:32:57Z"}
{"aid":"http://arxiv.org/abs/2504.11024v1","title":"Easy3D: A Simple Yet Effective Method for 3D Interactive Segmentation","summary":"The increasing availability of digital 3D environments, whether through\nimage-based 3D reconstruction, generation, or scans obtained by robots, is\ndriving innovation across various applications. These come with a significant\ndemand for 3D interaction, such as 3D Interactive Segmentation, which is useful\nfor tasks like object selection and manipulation. Additionally, there is a\npersistent need for solutions that are efficient, precise, and performing well\nacross diverse settings, particularly in unseen environments and with\nunfamiliar objects. In this work, we introduce a 3D interactive segmentation\nmethod that consistently surpasses previous state-of-the-art techniques on both\nin-domain and out-of-domain datasets. Our simple approach integrates a\nvoxel-based sparse encoder with a lightweight transformer-based decoder that\nimplements implicit click fusion, achieving superior performance and maximizing\nefficiency. Our method demonstrates substantial improvements on benchmark\ndatasets, including ScanNet, ScanNet++, S3DIS, and KITTI-360, and also on\nunseen geometric distributions such as the ones obtained by Gaussian Splatting.\nThe project web-page is available at https://simonelli-andrea.github.io/easy3d.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.11037v1","title":"Statistical complexity as a probe of mass and phase structure in compact\n  objects","summary":"In this work, we present a comprehensive and systematic study of the\nstatistical complexity, originally introduced by L\\'opez-Ruiz, Mancini, and\nCalbet [Phys. Lett. A 209, 321-326 (1995)], across a broad range of compact\nstar models. We explore how complexity correlates not only with macroscopic\nobservables such as mass and radius, but also with the microscopic\ncharacteristics of the underlying equation of state. By incorporating both\nrealistic equations of state and analytical solutions to Einstein's field\nequations, we demonstrate that gravitational mass plays a dominant role in\ndetermining the behavior of complexity. Furthermore, we show that strong phase\ntransitions within the stellar interior, such as those hypothesized in hybrid\nstars, can manifest as distinct features in the complexity profile, offering a\npotential informational signature of such transitions. This work offers new\ninsights into the link between information theory and compact object physics,\nhighlighting complexity's potential as a diagnostic tool in astrophysics.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE,gr-qc,nucl-th,quant-ph","published":"2025-04-15T09:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.11067v1","title":"Morphing-based Compression for Data-centric ML Pipelines","summary":"Data-centric ML pipelines extend traditional machine learning (ML) pipelines\n-- of feature transformations and ML model training -- by outer loops for data\ncleaning, augmentation, and feature engineering to create high-quality input\ndata. Existing lossless matrix compression applies lightweight compression\nschemes to numeric matrices and performs linear algebra operations such as\nmatrix-vector multiplications directly on the compressed representation but\nstruggles to efficiently rediscover structural data redundancy. Compressed\noperations are effective at fitting data in available memory, reducing I/O\nacross the storage-memory-cache hierarchy, and improving instruction\nparallelism. The applied data cleaning, augmentation, and feature\ntransformations provide a rich source of information about data characteristics\nsuch as distinct items, column sparsity, and column correlations. In this\npaper, we introduce BWARE -- an extension of AWARE for workload-aware lossless\nmatrix compression -- that pushes compression through feature transformations\nand engineering to leverage information about structural transformations.\nBesides compressed feature transformations, we introduce a novel technique for\nlightweight morphing of a compressed representation into workload-optimized\ncompressed representations without decompression. BWARE shows substantial\nend-to-end runtime improvements, reducing the execution time for training\ndata-centric ML pipelines from days to hours.","main_category":"cs.DB","categories":"cs.DB,cs.DC,cs.LG","published":"2025-04-15T11:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.11073v1","title":"FreeDOM: Online Dynamic Object Removal Framework for Static Map\n  Construction Based on Conservative Free Space Estimation","summary":"Online map construction is essential for autonomous robots to navigate in\nunknown environments. However, the presence of dynamic objects may introduce\nartifacts into the map, which can significantly degrade the performance of\nlocalization and path planning. To tackle this problem, a novel online dynamic\nobject removal framework for static map construction based on conservative free\nspace estimation (FreeDOM) is proposed, consisting of a scan-removal front-end\nand a map-refinement back-end. First, we propose a multi-resolution map\nstructure for fast computation and effective map representation. In the\nscan-removal front-end, we employ raycast enhancement to improve free space\nestimation and segment the LiDAR scan based on the estimated free space. In the\nmap-refinement back-end, we further eliminate residual dynamic objects in the\nmap by leveraging incremental free space information. As experimentally\nverified on SemanticKITTI, HeLiMOS, and indoor datasets with various sensors,\nour proposed framework overcomes the limitations of visibility-based methods\nand outperforms state-of-the-art methods with an average F1-score improvement\nof 9.7%.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T11:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.11081v1","title":"DPS: Design Pattern Summarisation Using Code Features","summary":"Automatic summarisation has been used efficiently in recent years to condense\ntexts, conversations, audio, code, and various other artefacts. A range of\nmethods, from simple template-based summaries to complex machine learning\ntechniques -- and more recently, large language models -- have been employed to\ngenerate these summaries. Summarising software design patterns is important\nbecause it helps developers quickly understand and reuse complex design\nconcepts, thereby improving software maintainability and development\nefficiency. However, the generation of summaries for software design patterns\nhas not yet been explored. Our approach utilises code features and JavaParser\nto parse the code and create a JSON representation. Using an NLG library on\nthis JSON representation, we convert it into natural language text that acts as\na summary of the code, capturing the contextual information of the design\npattern. Our empirical results indicate that the summaries generated by our\napproach capture the context in which patterns are applied in the codebase.\nStatistical evaluations demonstrate that our summaries closely align with\nhuman-written summaries, as evident from high values in the ROUGE-L, BLEU-4,\nNIST, and FrugalScore metrics. A follow-up survey further shows that DPS\nsummaries were rated as capturing context better than human-generated\nsummaries.","main_category":"cs.SE","categories":"cs.SE,D.2","published":"2025-04-15T11:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.11088v1","title":"FLSSM: A Federated Learning Storage Security Model with Homomorphic\n  Encryption","summary":"Federated learning based on homomorphic encryption has received widespread\nattention due to its high security and enhanced protection of user data\nprivacy. However, the characteristics of encrypted computation lead to three\nchallenging problems: ``computation-efficiency\", ``attack-tracing\" and\n``contribution-assessment\". The first refers to the efficiency of encrypted\ncomputation during model aggregation, the second refers to tracing malicious\nattacks in an encrypted state, and the third refers to the fairness of\ncontribution assessment for local models after encryption. This paper proposes\na federated learning storage security model with homomorphic encryption (FLSSM)\nto protect federated learning model privacy and address the three issues\nmentioned above. First, we utilize different nodes to aggregate local models in\nparallel, thereby improving encrypted models' aggregation efficiency. Second,\nwe introduce trusted supervise nodes to examine local models when the global\nmodel is attacked, enabling the tracing of malicious attacks under homomorphic\nencryption. Finally, we fairly reward local training nodes with encrypted local\nmodels based on trusted training time. Experiments on multiple real-world\ndatasets show that our model significantly outperforms baseline models in terms\nof both efficiency and security metrics.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T11:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.11116v1","title":"Breaking the Dimensional Barrier: A Pontryagin-Guided Direct Policy\n  Optimization for Continuous-Time Multi-Asset Portfolio","summary":"Solving large-scale, continuous-time portfolio optimization problems\ninvolving numerous assets and state-dependent dynamics has long been challenged\nby the curse of dimensionality. Traditional dynamic programming and PDE-based\nmethods, while rigorous, typically become computationally intractable beyond a\nsmall number of state variables (often limited to ~3-6 in prior numerical\nstudies). To overcome this critical barrier, we introduce the\n\\emph{Pontryagin-Guided Direct Policy Optimization} (PG-DPO) framework. PG-DPO\nleverages Pontryagin's Maximum Principle to directly guide neural network\npolicies via backpropagation-through-time, naturally incorporating exogenous\nstate processes without requiring dense state grids. Crucially, our\ncomputationally efficient ``Two-Stage'' variant exploits rapidly stabilizing\ncostate estimates derived from BPTT, converting them into near-optimal\nclosed-form Pontryagin controls after only a short warm-up, significantly\nreducing training overhead. This enables a breakthrough in scalability:\nnumerical experiments demonstrate that PG-DPO successfully tackles problems\nwith dimensions previously considered far out of reach, optimizing portfolios\nwith up to 50 assets and 10 state variables. The framework delivers\nnear-optimal policies, offering a practical and powerful alternative for\nhigh-dimensional continuous-time portfolio choice.","main_category":"q-fin.PM","categories":"q-fin.PM,q-fin.CP","published":"2025-04-15T12:03:14Z"}
{"aid":"http://arxiv.org/abs/2504.11127v1","title":"Keplerian motion of a compact source orbiting the inner disk of PDS 70:\n  A third protoplanet in a resonance with b and c?","summary":"The disk around PDS 70 hosts two directly imaged protoplanets in a gap.\nPrevious VLT/SPHERE and recent James Webb Space Telescope/NIRCam observations\nhave hinted at the presence of a third compact source in the same gap at ~13\nau, interior to the orbit of PDS 70 b. We reduce seven published and one\nunpublished VLT/SPHERE datasets in YJH and K bands, as well as an archival\nVLT/NaCo dataset in L' band, and an archival VLT/SINFONI dataset in H+K band.\nWe combine angular-, spectral- and reference star differential imaging to\nsearch for protoplanet candidates. We recover the compact source in all epochs,\nconsistent with the JWST detection, moving on an arc that can be fit by\nKeplerian motion of a protoplanet which could be in a resonance with PDS 70 b &\nc. We find that the spectral slope is overall consistent with the unresolved\nstar and inner disk emission at 0.95--1.65$\\mu$m, which suggests a dust\nscattering dominated spectrum. An excess beyond 2.3$\\mu$m could be thermal\nemission from either a protoplanet or heated circumplanetary dust, variability,\nor inner disk contamination, and requires confirmation. While we currently\ncannot rule out a moving inner disk feature or a dust clump associated with an\nunseen planet, the data supports the hypothesis of a third protoplanet in this\nremarkable system.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T12:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.11146v1","title":"Exploring Student Behaviors and Motivations using AI TAs with Optional\n  Guardrails","summary":"AI-powered chatbots and digital teaching assistants (AI TAs) are gaining\npopularity in programming education, offering students timely and personalized\nfeedback. Despite their potential benefits, concerns about student\nover-reliance and academic misconduct have prompted the introduction of\n\"guardrails\" into AI TAs - features that provide scaffolded support rather than\ndirect solutions. However, overly restrictive guardrails may lead students to\nbypass these tools and use unconstrained AI models, where interactions are not\nobservable, thus limiting our understanding of students' help-seeking\nbehaviors. To investigate this, we designed and deployed a novel AI TA tool\nwith optional guardrails in one lab of a large introductory programming course.\nAs students completed three code writing and debugging tasks, they had the\noption to receive guardrailed help or use a \"See Solution\" feature which\ndisabled the guardrails and generated a verbatim response from the underlying\nmodel. We investigate students' motivations and use of this feature and examine\nthe association between usage and their course performance. We found that 50%\nof the 885 students used the \"See Solution\" feature for at least one problem\nand 14% used it for all three problems. Additionally, low-performing students\nwere more likely to use this feature and use it close to the deadline as they\nstarted assignments later. The predominant factors that motivated students to\ndisable the guardrails were assistance in solving problems, time pressure, lack\nof self-regulation, and curiosity. Our work provides insights into students'\nsolution-seeking motivations and behaviors, which has implications for the\ndesign of AI TAs that balance pedagogical goals with student preferences.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-15T12:48:22Z"}
{"aid":"http://arxiv.org/abs/2504.11150v1","title":"GC-GAT: Multimodal Vehicular Trajectory Prediction using Graph Goal\n  Conditioning and Cross-context Attention","summary":"Predicting future trajectories of surrounding vehicles heavily relies on what\ncontextual information is given to a motion prediction model. The context\nitself can be static (lanes, regulatory elements, etc) or dynamic (traffic\nparticipants). This paper presents a lane graph-based motion prediction model\nthat first predicts graph-based goal proposals and later fuses them with cross\nattention over multiple contextual elements. We follow the famous\nencoder-interactor-decoder architecture where the encoder encodes scene context\nusing lightweight Gated Recurrent Units, the interactor applies cross-context\nattention over encoded scene features and graph goal proposals, and the decoder\nregresses multimodal trajectories via Laplacian Mixture Density Network from\nthe aggregated encodings. Using cross-attention over graph-based goal proposals\ngives robust trajectory estimates since the model learns to attend to future\ngoal-relevant scene elements for the intended agent. We evaluate our work on\nnuScenes motion prediction dataset, achieving state-of-the-art results.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-15T12:53:07Z"}
{"aid":"http://arxiv.org/abs/2504.11167v1","title":"Low-Rank SPIKE Framework for Solving Large Sparse Linear Systems with\n  Applications","summary":"The SPIKE family of linear system solvers provides parallelism using a block\ntridiagonal partitioning. Typically SPIKE-based solvers are applied to banded\nsystems, resulting in structured off-diagonal blocks with non-zeros elements\nrestricted to relatively small submatrices comprising the band of the original\nmatrix. In this work, a low-rank SVD based approximation of the off-diagonal\nblocks is investigated. This produces a representation which more effectively\nhandles matrices with large, sparse bands. A set of flexible distributed\nsolvers, the LR-SPIKE variants, are implemented. There are applicable to a wide\nrange of applications -- from use as a \"black-box\" preconditioner which\nstraightforwardly improves upon the classic Block Jacobi preconditioner, to use\nas a specialized \"approximate direct solver.\" An investigation of the\neffectiveness of the new preconditioners for a selection of SuiteSparse\nmatrices is performed, particularly focusing on matrices derived from 3D finite\nelement simulations. In addition, the SPIKE approximate linear system solvers\nare also paired with the FEAST eigenvalue solver, where they are shown to be\nparticularly effective due to the former's rapid convergence, and the latter's\nacceptance of loose linear system solver convergence, resulting in a\ncombination which requires very few solver iterations.","main_category":"math.NA","categories":"math.NA,cs.MS,cs.NA","published":"2025-04-15T13:15:00Z"}
{"aid":"http://arxiv.org/abs/2504.11170v1","title":"A Real-time Anomaly Detection Method for Robots based on a Flexible and\n  Sparse Latent Space","summary":"The growing demand for robots to operate effectively in diverse environments\nnecessitates the need for robust real-time anomaly detection techniques during\nrobotic operations. However, deep learning-based models in robotics face\nsignificant challenges due to limited training data and highly noisy signal\nfeatures. In this paper, we present Sparse Masked Autoregressive Flow-based\nAdversarial AutoEncoders model to address these problems. This approach\nintegrates Masked Autoregressive Flow model into Adversarial AutoEncoders to\nconstruct a flexible latent space and utilize Sparse autoencoder to efficiently\nfocus on important features, even in scenarios with limited feature space. Our\nexperiments demonstrate that the proposed model achieves a 4.96% to 9.75%\nhigher area under the receiver operating characteristic curve for\npick-and-place robotic operations with randomly placed cans, compared to\nexisting state-of-the-art methods. Notably, it showed up to 19.67% better\nperformance in scenarios involving collisions with lightweight objects.\nAdditionally, unlike the existing state-of-the-art model, our model performs\ninferences within 1 millisecond, ensuring real-time anomaly detection. These\ncapabilities make our model highly applicable to machine learning-based robotic\nsafety systems in dynamic environments. The code will be made publicly\navailable after acceptance.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-15T13:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.11182v1","title":"Exploring Backdoor Attack and Defense for LLM-empowered Recommendations","summary":"The fusion of Large Language Models (LLMs) with recommender systems (RecSys)\nhas dramatically advanced personalized recommendations and drawn extensive\nattention. Despite the impressive progress, the safety of LLM-based RecSys\nagainst backdoor attacks remains largely under-explored. In this paper, we\nraise a new problem: Can a backdoor with a specific trigger be injected into\nLLM-based Recsys, leading to the manipulation of the recommendation responses\nwhen the backdoor trigger is appended to an item's title? To investigate the\nvulnerabilities of LLM-based RecSys under backdoor attacks, we propose a new\nattack framework termed Backdoor Injection Poisoning for RecSys (BadRec).\nBadRec perturbs the items' titles with triggers and employs several fake users\nto interact with these items, effectively poisoning the training set and\ninjecting backdoors into LLM-based RecSys. Comprehensive experiments reveal\nthat poisoning just 1% of the training data with adversarial examples is\nsufficient to successfully implant backdoors, enabling manipulation of\nrecommendations. To further mitigate such a security threat, we propose a\nuniversal defense strategy called Poison Scanner (P-Scanner). Specifically, we\nintroduce an LLM-based poison scanner to detect the poisoned items by\nleveraging the powerful language understanding and rich knowledge of LLMs. A\ntrigger augmentation agent is employed to generate diverse synthetic triggers\nto guide the poison scanner in learning domain-specific knowledge of the\npoisoned item detection task. Extensive experiments on three real-world\ndatasets validate the effectiveness of the proposed P-Scanner.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-15T13:37:38Z"}
{"aid":"http://arxiv.org/abs/2504.11196v1","title":"The Lifetime of the Covid Memorial Wall: Modelling with Collections\n  Demography, Social Media Data and Citizen Science","summary":"The National Covid Memorial Wall in London, featuring over 240,000\nhand-painted red hearts, faces significant conservation challenges due to the\nrapid fading of the paint. This study evaluates the transition to a\nbetter-quality paint and its implications for the wall's long-term\npreservation. The rapid fading of the initial materials required an\nunsustainable repainting rate, burdening volunteers. Lifetime simulations based\non a collections demography framework suggest that repainting efforts must\ncontinue at a rate of some hundreds of hearts per week to maintain a stable\npercentage of hearts in good condition. This finding highlights the need for a\nsustainable management strategy that includes regular maintenance or further\nreduction of the fading rate.\n  Methodologically, this study demonstrates the feasibility of using a\ncollections demography approach, supported by citizen science and social media\ndata, to inform heritage management decisions. An agent-based simulation is\nused to propagate the multiple uncertainties measured. The methodology provides\na robust basis for modeling and decision-making, even in a case like this,\nwhere reliance on publicly available images and volunteer-collected data\nintroduces variability. Future studies could improve data within a citizen\nscience framework by inviting public submissions, using on-site calibration\ncharts, and increasing volunteer involvement for longitudinal data collection.\nThis research illustrates the flexibility of the collections demography\nframework, firstly by showing its applicability to an outdoor monument, which\nis very different from the published case studies, and secondly by\ndemonstrating how it can work even with low-quality data.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-15T13:51:14Z"}
{"aid":"http://arxiv.org/abs/2504.11205v1","title":"Can Quasi Periodic Oscillations Encode Traces of Black Hole Phase\n  Transitions ?","summary":"Finding observational evidence or imprints of black hole phase transitions is\na promising and active area of research. Aiming to contribute to this\ndirection, in this work, we probe the well-known thermodynamic phase structure\nof the Reissner Nordstr\\\"om Anti de Sitter (RN-AdS) black hole through the lens\nof its quasi-periodic oscillations (QPOs). Can QPOs be influenced by black hole\nphase transitions? Do they carry any signature of such transitions in their\nobservational patterns? These were the central questions guiding our study. By\nanalyzing the upper and lower QPO frequencies within the Relativistic\nPrecession (RP) model, we observe that the frequency-temperature relationship\nreflects distinguishing features corresponding to the small, intermediate, and\nlarge black hole phases, offering insights into their stability properties. The\nanalysis is further extended to other QPO models, including the Warped Disk\n(WD) and Epicyclic Resonance (ER) models. The presence of distinct phase\nstructures remains evident across all models which is an encouraging outcome\nthat may be worth exploring further in the context of other black hole systems.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-15T14:07:49Z"}
{"aid":"http://arxiv.org/abs/2504.11206v1","title":"Investigation of optimal transfers to retrograde co-orbital orbits in\n  the Earth-Moon system","summary":"Recent findings on retrograde co-orbital mean-motion resonances in the\nEarth-Moon system, highlight the potential use of spacecraft in retrograde\nresonances. Based on these discoveries, this study investigates retrograde\nco-orbital resonances within the Earth-Moon system, focusing on both optimal\nand sub-optimal orbital transfers to such configurations. The paper provides a\ncomprehensive analysis of retrograde co-orbital resonances, optimization\ntechniques to evaluate and enhance the performance of bi-impulsive transfers to\nthese configurations. The results reveal the feasibility of low-cost transfers,\nwhich could support a range of future missions, including space exploration and\nsatellite deployment. Combining advanced optimization processes, we obtained\nsolutions for orbital transfers for different arrival points in retrograde\nco-orbitals improving mission efficiency and offering a cost-effective approach\nto interplanetary exploration.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T14:10:05Z"}
{"aid":"http://arxiv.org/abs/2504.11217v1","title":"Is model selection possible for the $\\ell_p$-loss? PCO estimation for\n  regression models","summary":"This paper addresses the problem of model selection in the sequence model\n$Y=\\theta+\\varepsilon\\xi$, when $\\xi$ is sub-Gaussian, for non-euclidian\nloss-functions. In this model, the Penalized Comparison to Overfitting\nprocedure is studied for the weighted $\\ell_p$-loss, $p\\geq 1.$ Several oracle\ninequalities are derived from concentration inequalities for sub-Weibull\nvariables. Using judicious collections of models and penalty terms, minimax\nrates of convergence are stated for Besov bodies $\\mathcal{B}_{r,\\infty}^s$.\nThese results are applied to the functional model of nonparametric regression.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-15T14:20:44Z"}
{"aid":"http://arxiv.org/abs/2504.11230v1","title":"CAP-Net: A Unified Network for 6D Pose and Size Estimation of\n  Categorical Articulated Parts from a Single RGB-D Image","summary":"This paper tackles category-level pose estimation of articulated objects in\nrobotic manipulation tasks and introduces a new benchmark dataset. While recent\nmethods estimate part poses and sizes at the category level, they often rely on\ngeometric cues and complex multi-stage pipelines that first segment parts from\nthe point cloud, followed by Normalized Part Coordinate Space (NPCS) estimation\nfor 6D poses. These approaches overlook dense semantic cues from RGB images,\nleading to suboptimal accuracy, particularly for objects with small parts. To\naddress these limitations, we propose a single-stage Network, CAP-Net, for\nestimating the 6D poses and sizes of Categorical Articulated Parts. This method\ncombines RGB-D features to generate instance segmentation and NPCS\nrepresentations for each part in an end-to-end manner. CAP-Net uses a unified\nnetwork to simultaneously predict point-wise class labels, centroid offsets,\nand NPCS maps. A clustering algorithm then groups points of the same predicted\nclass based on their estimated centroid distances to isolate each part.\nFinally, the NPCS region of each part is aligned with the point cloud to\nrecover its final pose and size. To bridge the sim-to-real domain gap, we\nintroduce the RGBD-Art dataset, the largest RGB-D articulated dataset to date,\nfeaturing photorealistic RGB images and depth noise simulated from real\nsensors. Experimental evaluations on the RGBD-Art dataset demonstrate that our\nmethod significantly outperforms the state-of-the-art approach. Real-world\ndeployments of our model in robotic tasks underscore its robustness and\nexceptional sim-to-real transfer capabilities, confirming its substantial\npractical utility. Our dataset, code and pre-trained models are available on\nthe project page.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-15T14:30:26Z"}
{"aid":"http://arxiv.org/abs/2504.11259v1","title":"The Cambridge Report on Database Research","summary":"On October 19 and 20, 2023, the authors of this report convened in Cambridge,\nMA, to discuss the state of the database research field, its recent\naccomplishments and ongoing challenges, and future directions for research and\ncommunity engagement. This gathering continues a long standing tradition in the\ndatabase community, dating back to the late 1980s, in which researchers meet\nroughly every five years to produce a forward looking report.\n  This report summarizes the key takeaways from our discussions. We begin with\na retrospective on the academic, open source, and commercial successes of the\ncommunity over the past five years. We then turn to future opportunities, with\na focus on core data systems, particularly in the context of cloud computing\nand emerging hardware, as well as on the growing impact of data science, data\ngovernance, and generative AI.\n  This document is not intended as an exhaustive survey of all technical\nchallenges or industry innovations in the field. Rather, it reflects the\nperspectives of senior community members on the most pressing challenges and\npromising opportunities ahead.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T14:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.11262v1","title":"Enhanced Small Target Detection via Multi-Modal Fusion and Attention\n  Mechanisms: A YOLOv5 Approach","summary":"With the rapid development of information technology, modern warfare\nincreasingly relies on intelligence, making small target detection critical in\nmilitary applications. The growing demand for efficient, real-time detection\nhas created challenges in identifying small targets in complex environments due\nto interference. To address this, we propose a small target detection method\nbased on multi-modal image fusion and attention mechanisms. This method\nleverages YOLOv5, integrating infrared and visible light data along with a\nconvolutional attention module to enhance detection performance. The process\nbegins with multi-modal dataset registration using feature point matching,\nensuring accurate network training. By combining infrared and visible light\nfeatures with attention mechanisms, the model improves detection accuracy and\nrobustness. Experimental results on anti-UAV and Visdrone datasets demonstrate\nthe effectiveness and practicality of our approach, achieving superior\ndetection results for small and dim targets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:02:10Z"}
{"aid":"http://arxiv.org/abs/2504.11274v1","title":"Isomeric yield ratios and mass spectrometry of Y and Nb isotopes in the\n  neutron-rich N=60 region: the unusual case of $^{98}$Y","summary":"The isomeric yield ratio (IYR) of fission products is an observable that\ncarries relevant information about the fragments emerging from the scission of\na fissioning nucleus. We report on IYR of $^{96,98,100}$Y and $^{100,102}$Nb,\ntogether with the previously reported values for $^{97}$Y and $^{99}$Nb,\nproduced in the 28 MeV $\\alpha$-induced fission of $^{232}$Th at the Ion Guide\nIsotope Separation On-Line (IGISOL) facility of the University of\nJyv{\\\"a}skyl{\\\"a}. We measured the IYR using two different techniques, the\nphase-imaging ion-cyclotron-resonance (PI-ICR) and the multiple-reflection\ntime-of-flight mass spectrometry (MR-TOF-MS) methods. Moreover, we measured the\nmasses of the long-lived isomeric states in $^{98,100}$Y and $^{100,102}$Nb\npopulated via in-trap $\\beta$-decay of their precursors. Since the\n$\\beta$-decay selectively populates states with a favourable spin-parity, we\ncould identify the measured state and show that in all cases except $^{102}$Nb\nthe ground state is the low-spin state. This measurement confirms the\nspin-parity assignments of all the nuclei as they are reported on the ENSDF\nevaluations, disagreeing with the assignment for $^{100}$Y reported on the\nNUBASE2020 evaluation.\n  Making also use of previously reported data, we observe an anomalously low\nIYR for the $N=59$ isotope $^{98}$Y as compared to other yttrium or neighboring\nniobium isotopes. This behavior is very rare across the nuclear chart and is\nposited to be connected to the characteristic shape coexistence of $^{98}$Y and\nto the change in the charge radii of the ground and excited states in the\n$N=58-60$ region.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-15T15:15:13Z"}
{"aid":"http://arxiv.org/abs/2504.11282v1","title":"Minimum-Turn Tours of Even Polyominoes","summary":"Let $P$ be a connected bounded region in the plane formed out of $2 \\times 2$\nblocks joined by their sides. Peng and Rascoussier conjectured that all\nminimum-turn Hamiltonian cycles of $P$ exhibit a certain regular structure. We\nprove this conjecture in the special case when $P$ is a topological disk. The\nproof proceeds in two phases - a \"downward\" phase where we break apart an\nirregular Hamiltonian cycle into a collection of shorter cycles; and an\n\"upward\" phase where we put it back together in a different way so that,\noverall, the number of turns in it decreases.","main_category":"math.CO","categories":"math.CO","published":"2025-04-15T15:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.11283v1","title":"Influence of the magnetic activity cycle on mean density and acoustic\n  radius inversions","summary":"Asteroseismic modelling is crucial for upcoming missions like PLATO,\nCubeSpec, and Roman. Despite significant progress, discrepancies between\nobservations and theoretical predictions introduce biases in stellar\ncharacterisation at the precision required by PLATO. Current models typically\nignore magnetic activity, assuming its effects are hidden within surface\neffects. However, recent studies have shown significant impacts of magnetic\nactivity on the Sun's asteroseismic characterisation using forward modelling.\nUsing GOLF and BiSON observations of two full solar activity cycles, we\nquantified the impact of magnetic activity on solar mean density and acoustic\nradius inversions. Observations were segmented into yearly overlapping\nsnapshots, each offset by 91.25 days. Inversions were performed for each\nsnapshot to determine mean density and acoustic radius, tracking their temporal\nevolution and estimating systematic uncertainty due to magnetic activity. We\nobserved a clear imprint of the magnetic activity cycle on solar mean density\nand acoustic radius through helioseismic inversions, consistent across GOLF and\nBiSON datasets. This imprint is the largest source of systematic uncertainty in\nsolar asteroseismic characterisation. Including low radial-order modes\nmitigates these effects more significantly than previously measured for other\nstellar variables. We recommend asteroseismic values for solar mean density\n(1.4104 \\pm 0.0051 g/cm3) and acoustic radius (3722.0 \\pm 4.1 s), averaged over\ntwo activity cycles. These values account for major systematic errors,\nachieving high precision (0.36% for mean density and 0.11% for acoustic\nradius). These results are promising for high-precision characterisation of\nSun-like stars, a better-constrained mean density being able to enhance the\nprecision of stellar radius estimate, which is crucial for exoplanetary system\ncharacterisation.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-15T15:22:51Z"}
{"aid":"http://arxiv.org/abs/2504.11299v1","title":"Efficient and Stable Multi-Dimensional Kolmogorov-Smirnov Distance","summary":"We revisit extending the Kolmogorov-Smirnov distance between probability\ndistributions to the multidimensional setting and make new arguments about the\nproper way to approach this generalization. Our proposed formulation maximizes\nthe difference over orthogonal dominating rectangular ranges (d-sided\nrectangles in R^d), and is an integral probability metric. We also prove that\nthe distance between a distribution and a sample from the distribution\nconverges to 0 as the sample size grows, and bound this rate. Moreover, we show\nthat one can, up to this same approximation error, compute the distance\nefficiently in 4 or fewer dimensions; specifically the runtime is near-linear\nin the size of the sample needed for that error. With this, we derive a\ndelta-precision two-sample hypothesis test using this distance. Finally, we\nshow these metric and approximation properties do not hold for other popular\nvariants.","main_category":"stat.CO","categories":"stat.CO,cs.CG,cs.LG","published":"2025-04-15T15:42:49Z"}
{"aid":"http://arxiv.org/abs/2504.11315v1","title":"New Key Rate Bound for High-Dimensional BB84 with Multiple Basis\n  Measurements","summary":"In this paper we derive a new bound on the secret key-rate of the High\nDimensional BB84 protocol operating with multiple mutually unbiased bases\n(MUBs). To our knowledge, our proof is the first for this protocol that is both\ngeneral (in that it can handle arbitrary, asymmetric channels), and also the\nfirst that derives a bound on the quantum min entropy for general attacks,\nwithout relying on post selection techniques or the asymptotic equipartition\nproperty. Because of this, our new result shows that far more optimistic\nkey-rates are possible for a low number of signals, even in general channels.\nFurthermore, our proof methods may be broadly applicable to other protocols\nrelying on multiple measurement bases and we prove several technical lemmas\nthat may have independent interest. We evaluate our new bound and compare to\nprior work, showing that higher key-rates are possible in several operating\nscenarios. We also show some interesting behavior of the protocol when faced\nwith asymmetric noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.11317v1","title":"The role of non-Markovian dissipation in quantum phase transitions:\n  tricriticality, spin squeezing, and directional symmetry breaking","summary":"Understanding how to control phase transitions in quantum systems is at the\nforefront of research for the development of new quantum materials and\ntechnologies. Here, we study how the coupling of a quantum system to a\nnon-Markovian environment, i.e., an environment with a frequency-dependent\nspectral density inducing memory effects, can be used to generate and reshape\nphase transitions and squeezing in matter phases. Focusing on a\nLipkin-Meshkov-Glick model, we demonstrate that non-Markovian dissipation can\nbe leveraged to engineer tricriticality via the fusion of\n$2^{\\mathrm{nd}}$-order and $1^{\\mathrm{st}}$-order critical points. We\nidentify phases that arise from different ways of breaking the single weak\nsymmetry of our model, which led us to introduce the concept of\n\\textit{directional spontaneous symmetry breaking} (DSSB) as a general\nframework to understand this phenomenon. We show that signatures of DSSB can be\nseen in the emergence of spin squeezing along different directions, and that\nthe latter is controllable via non-Markovian effects, opening up possibilities\nfor applications in quantum metrology. Finally, we propose an experimental\nimplementation of our non-Markovian model in cavity QED. Our work features\nnon-Markovianity as a resource for controlling phase transitions in general\nsystems, and highlights shortcomings of the Markovian limit in this context.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.11318v1","title":"Mildly-Interacting Fermionic Unitaries are Efficiently Learnable","summary":"Recent work has shown that one can efficiently learn fermionic Gaussian\nunitaries, also commonly known as nearest-neighbor matchcircuits or\nnon-interacting fermionic unitaries. However, one could ask a similar question\nabout unitaries that are near Gaussian: for example, unitaries prepared with a\nsmall number of non-Gaussian circuit elements. These operators find\nsignificance in quantum chemistry and many-body physics, yet no algorithm\nexists to learn them.\n  We give the first such result by devising an algorithm which makes queries to\na $n$-mode fermionic unitary $U$ prepared by at most $O(t)$ non-Gaussian gates\nand returns a circuit approximating $U$ to diamond distance $\\varepsilon$ in\ntime $\\textrm{poly}(n,2^t,1/\\varepsilon)$. This resolves a central open\nquestion of Mele and Herasymenko under the strongest distance metric. In fact,\nour algorithm is much more general: we define a property of unitary Gaussianity\nknown as unitary Gaussian dimension and show that our algorithm can learn\n$n$-mode unitaries of Gaussian dimension at least $2n - O(t)$ in time\n$\\textrm{poly}(n,2^t,1/\\varepsilon)$. Indeed, this class subsumes unitaries\nprepared by at most $O(t)$ non-Gaussian gates but also includes several\nunitaries that require up to $2^{O(t)}$ non-Gaussian gates to construct.\n  In addition, we give a $\\textrm{poly}(n,1/\\varepsilon)$-time algorithm to\ndistinguish whether an $n$-mode unitary is of Gaussian dimension at least $k$\nor $\\varepsilon$-far from all such unitaries in Frobenius distance, promised\nthat one is the case. Along the way, we prove structural results about\nnear-Gaussian fermionic unitaries that are likely to be of independent\ninterest.","main_category":"quant-ph","categories":"quant-ph,cs.DS,cs.LG","published":"2025-04-15T15:59:32Z"}
{"aid":"http://arxiv.org/abs/2504.11323v1","title":"Domain wall evolution beyond quartic potentials: The Sine-Gordon and\n  Christ-Lee potentials","summary":"Domain walls are the simplest type of topological defects formed at\ncosmological phase transitions, and one of the most constrained. Their studies\ntypically assume a quartic double well potential, but this model is not fully\nrepresentative of the range of known or plausible particle physics models. Here\nwe study the cosmological evolution of domain walls in two other classes of\npotentials. The Sine-Gordon potential allows several types of walls,\ninterpolating between different pairs of minima (which demands specific\nnumerical algorithms to separately measure the relevant properties of each\ntype). The Christ-Lee potential parametrically interpolates between sextic and\nquartic behavior. We use multiple sets of simulations in two and three spatial\ndimensions, for various cosmological epochs and under various choices of\ninitial conditions, to discuss the scaling properties of these networks. In the\nSine-Gordon case, we identify and quantify deviations from the usual scaling\nbehavior. In the Christ-Lee case, we discuss conditions under which walls form\n(or not), and quantify how these outcomes depend on parameters such as the\nenergy difference between the false and true vacua and the expansion rate of\nthe Universe. Various biased initial conditions are also addressed in\nappendices. Finally, we briefly comment on the possible cosmological\nimplications of our results.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-15T16:02:35Z"}
{"aid":"http://arxiv.org/abs/2504.11338v1","title":"Transformer-Based Model for Cold Start Mitigation in FaaS Architecture","summary":"Serverless architectures, particularly the Function as a Service (FaaS)\nmodel, have become a cornerstone of modern cloud computing due to their ability\nto simplify resource management and enhance application deployment agility.\nHowever, a significant challenge remains: the cold start problem. This\nphenomenon occurs when an idle FaaS function is invoked, requiring a full\ninitialization process, which increases latency and degrades user experience.\nExisting solutions for cold start mitigation are limited in terms of invocation\npattern generalization and implementation complexity. In this study, we propose\nan innovative approach leveraging Transformer models to mitigate the impact of\ncold starts in FaaS architectures. Our solution excels in accurately modeling\nfunction initialization delays and optimizing serverless system performance.\nExperimental evaluation using a public dataset provided by Azure demonstrates a\nsignificant reduction in cold start times, reaching up to 79\\% compared to\nconventional methods.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-15T16:12:07Z"}
{"aid":"http://arxiv.org/abs/2504.11354v1","title":"Kimina-Prover Preview: Towards Large Formal Reasoning Models with\n  Reinforcement Learning","summary":"We introduce Kimina-Prover Preview, a large language model that pioneers a\nnovel reasoning-driven exploration paradigm for formal theorem proving, as\nshowcased in this preview release. Trained with a large-scale reinforcement\nlearning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong\nperformance in Lean 4 proof generation by employing a structured reasoning\npattern we term \\textit{formal reasoning pattern}. This approach allows the\nmodel to emulate human problem-solving strategies in Lean, iteratively\ngenerating and refining proof steps. Kimina-Prover sets a new state-of-the-art\non the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved\nbenchmark performance, our work yields several key insights: (1) Kimina-Prover\nexhibits high sample efficiency, delivering strong results even with minimal\nsampling (pass@1) and scaling effectively with computational budget, stemming\nfrom its unique reasoning pattern and RL training; (2) we demonstrate clear\nperformance scaling with model size, a trend previously unobserved for neural\ntheorem provers in formal mathematics; (3) the learned reasoning style,\ndistinct from traditional search algorithms, shows potential to bridge the gap\nbetween formal verification and informal mathematical intuition. We open source\ndistilled versions with 1.5B and 7B parameters of Kimina-Prover","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T16:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.11357v1","title":"NNLO predictions with nonlocal subtractions and fiducial power\n  corrections in GENEVA","summary":"We present the implementation of next-to-next-to-leading order (NNLO) QCD\nfully-differential corrections within the GENEVA framework, for both\ncolour-singlet and colour-singlet+jet processes at hadron colliders, by\nemploying a nonlocal subtraction approach. In particular, we discuss the\nimplementation details and the challenges that arise when utilizing a dynamical\ninfrared cutoff parameter. Additionally, we combine the subtraction with the\nprojection-to-Born method in order to include fiducial power corrections. As a\ntest case, we provide predictions for Drell-Yan and $Z$+jet production at the\nLHC, using $N$-jettiness as resolution variable. We validate the NNLO\ncorrections of GENEVA against NNLOJET finding excellent agreement. Finally, we\ndiscuss how to extend our method to calculate the N$^3$LO QCD\nfully-differential corrections to colour-singlet production at hadron\ncolliders.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-15T16:26:01Z"}
{"aid":"http://arxiv.org/abs/2504.11374v1","title":"A Winner-Takes-All Mechanism for Event Generation","summary":"We present a novel framework for central pattern generator design that\nleverages the intrinsic rebound excitability of neurons in combination with\nwinner-takes-all computation. Our approach unifies decision-making and rhythmic\npattern generation within a simple yet powerful network architecture that\nemploys all-to-all inhibitory connections enhanced by designable excitatory\ninteractions. This design offers significant advantages regarding ease of\nimplementation, adaptability, and robustness. We demonstrate its efficacy\nthrough a ring oscillator model, which exhibits adaptive phase and frequency\nmodulation, making the framework particularly promising for applications in\nneuromorphic systems and robotics.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-15T16:40:37Z"}
{"aid":"http://arxiv.org/abs/2504.11388v1","title":"Local solubility in generalised Ch√¢telet varieties","summary":"We develop asymptotic formulas, via the circle method, for averages of\nmultivariate equidistributed arithmetic functions evaluated at polynomial\nvalues in many variables.\n  As an application, we count fibers with a rational point in families of\nhigh-dimensional Ch\\^atelet varieties.\n  Among the local solutions in these fibrations, we observe a reciprocity\ninvolving infinitely many places, governed by only finitely many ramified\nBrauer elements.","main_category":"math.NT","categories":"math.NT","published":"2025-04-15T16:57:43Z"}
{"aid":"http://arxiv.org/abs/2504.11390v1","title":"Unraveling Momentum and Heat Intercoupling in Reattaching Turbulent\n  Boundary Layers Using Dynamic Mode Decomposition","summary":"Dynamic mode decomposition method is deployed to investigate the heat\ntransfer mechanism in a compressible turbulent shear layer and shockwave. To\nthis end, highly resolved Large Eddy Simulations are performed to explore the\neffect of wall thermal conditions on the behavior of a reattaching free shear\nlayer interacting with an oblique shock in compressible turbulent flows.\nVarious different wall temperature conditions, such as cold adiabatic and hot\nwall, are considered. Dynamic mode decomposition is used to isolate and study\nthe structures generated by the shear layer exposed in the boundary layer.\nResults reveal that the shear layer flapping is the most energetic mode. The\nhot wall gains the highest amplitude for the flapping frequency, and the\nvortical motions are most intense in the vicinity of the reattachment point of\nthe heated wall. The vortex shedding due to the large-scale motion of the shear\nlayer is associated with the second energetic mode. The cold wall not only has\na higher amplitude of the shedding mode, but it also has a lower frequency\ncompared to the adiabatic and hot walls. This work sheds light on the\nunderlying physics of the nonlinear intercoupling of momentum and heat, hence\nproviding guidelines for designing control systems for high speed flight\nvehicles and mitigating aircraft fatigue loading caused by intense wall\npressure fluctuations and heat flux.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-15T16:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.11413v1","title":"Solving the Phase Problem of Diffraction: X-ray Standing Waves Imaging\n  on Bismuthene/SiC(0001)","summary":"The phase retrieval problem is a fundamental shortcoming of all\ndiffraction-based methods, arising from the inability to measure the phase of\nscattered waves. The (normal incidence) X-ray standing wave (NIXSW) technique\ncircumvents this issue by introducing a (Bragg-generated) X-ray standing wave\nfield throughout the sample, relative to which any atomic species can be\nlocalized by probing its fluorescence or photoelectron yield. In essence, in a\nsingle measurement the complex scattering factor (i.e., its amplitude\n\\textit{and} phase) corresponding to the used Bragg reflection is determined.\nPerforming this for multiple Bragg reflections enables one to reconstruct the\nscattering density of the sample in three dimensions, straightforwardly as the\nFourier sum of all measured (complex) scattering factors. Here, we utilize this\ntechnique to reveal the structural key features involved in the formation of\nthe quantum spin Hall insulator bismuthene on silicon carbide. In this\nprominent example, the two-dimensional Bi layer is confined between a 4H-SiC\nsubstrate crystal and an epitaxial graphene layer. The key finding is a change\nin the adsorption site of the Bi atoms underneath the graphene upon\nhydrogenation, caused by the H-saturation of one (out of three) Si dangling\nbonds per unit cell. This structural change, clearly revealed by our NIXSW\nimaging experiment, is the key feature leading to the formation of the\ncharacteristic band structure of the 2D bismuthene honeycomb.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-15T17:28:24Z"}
{"aid":"http://arxiv.org/abs/2504.11423v1","title":"ADT: Tuning Diffusion Models with Adversarial Supervision","summary":"Diffusion models have achieved outstanding image generation by reversing a\nforward noising process to approximate true data distributions. During\ntraining, these models predict diffusion scores from noised versions of true\nsamples in a single forward pass, while inference requires iterative denoising\nstarting from white noise. This training-inference divergences hinder the\nalignment between inference and training data distributions, due to potential\nprediction biases and cumulative error accumulation. To address this problem,\nwe propose an intuitive but effective fine-tuning framework, called Adversarial\nDiffusion Tuning (ADT), by stimulating the inference process during\noptimization and aligning the final outputs with training data by adversarial\nsupervision. Specifically, to achieve robust adversarial training, ADT features\na siamese-network discriminator with a fixed pre-trained backbone and\nlightweight trainable parameters, incorporates an image-to-image sampling\nstrategy to smooth discriminative difficulties, and preserves the original\ndiffusion loss to prevent discriminator hacking. In addition, we carefully\nconstrain the backward-flowing path for back-propagating gradients along the\ninference path without incurring memory overload or gradient explosion.\nFinally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3),\ndemonstrate that ADT significantly improves both distribution alignment and\nimage quality.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T17:37:50Z"}
{"aid":"http://arxiv.org/abs/2504.11429v1","title":"Improving Statistical Privacy by Subsampling","summary":"Differential privacy (DP) considers a scenario, where an adversary has almost\ncomplete information about the entries of a database This worst-case assumption\nis likely to overestimate the privacy thread for an individual in real life.\nStatistical privacy (SP) denotes a setting where only the distribution of the\ndatabase entries is known to an adversary, but not their exact values. In this\ncase one has to analyze the interaction between noiseless privacy based on the\nentropy of distributions and privacy mechanisms that distort the answers of\nqueries, which can be quite complex.\n  A privacy mechanism often used is to take samples of the data for answering a\nquery. This paper proves precise bounds how much different methods of sampling\nincrease privacy in the statistical setting with respect to database size and\nsampling rate. They allow us to deduce when and how much sampling provides an\nimprovement and how far this depends on the privacy parameter {\\epsilon}. To\nperform these investigations we develop a framework to model sampling\ntechniques.\n  For the DP setting tradeoff functions have been proposed as a finer measure\nfor privacy compared to ({\\epsilon},{\\delta})-pairs. We apply these tools to\nstatistical privacy with subsampling to get a comparable characterization","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T17:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.11437v1","title":"Ghostly interactions in (1+1) dimensional classical field theory","summary":"We investigate the classical stability of two coupled scalar fields with\nopposite-sign kinetic terms evolving in 1+1 dimensional Minkowski spacetime. In\nthe first part, we characterise unquenched ghostly interactions and present\nnumerical solutions that support the following statements. First, the classical\ninstability is not instantaneous and can even be benign, i.e., free of\nfinite-time singularities. Second, while the classical instability can cascade\ntowards higher frequency excitations, it is not driven by high frequency modes:\nAt fixed amplitude, high-frequency modes are more stable than low-frequency\nmodes. In the second part, we demonstrate that the classical instability can be\nquenched by mass terms. In particular, we exemplify that heavy high-frequency\nghost fields seem to not violate the decoupling theorem and can be integrated\nout classically. In the third part, we demonstrate how self-interactions can\nquench the instability, for instance, by postponing its onset to parametrically\nlarge times. Extrapolating numerical results at large but finite evolution time\nto infinite evolution time, we demonstrate that classical fluctuations around\ntrivial and nontrivial field-theory vacua are increasingly long-lived with (i)\nsmaller initial amplitude of fluctuations, (ii) higher initial frequency of\nfluctuations, (iii) larger masses of the fields, or (iv) weaker interaction\ncoupling. Moreover, our numerical simulations for field-theoretical\ngeneralisations of some globally-stable ghostly mechanical models do not\nfeature any instability.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2504.11449v1","title":"SymTFT construction of gapless exotic-foliated dual models","summary":"We construct Symmetry Topological Field Theories (SymTFTs) for continuous\nsubsystem symmetries, which are inherently non-Lorentz-invariant. Our framework\nproduces dual bulk descriptions -- gapped foliated and exotic SymTFTs -- that\ngenerates gapless boundary theories with spontaneous subsystem symmetry\nbreaking via interval compactification. In analogy with the sandwich\nconstruction of SymTFT, we call this Mille-feuille. This is done by specifying\ngapped and symmetry-breaking boundary conditions. In this way we obtain the\nfoliated dual realizations of various models, including the XY plaquette, XYZ\ncube, and $\\phi$, $\\hat{\\phi}$ theories. This also captures self-duality\nsymmetries as condensation defects and provides a systematic method for\ngenerating free theories that non-linearly realize subsystem symmetries.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-th","published":"2025-04-15T17:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.11775v1","title":"Discrimination-free Insurance Pricing with Privatized Sensitive\n  Attributes","summary":"Fairness has emerged as a critical consideration in the landscape of machine\nlearning algorithms, particularly as AI continues to transform decision-making\nacross societal domains. To ensure that these algorithms are free from bias and\ndo not discriminate against individuals based on sensitive attributes such as\ngender and race, the field of algorithmic bias has introduced various fairness\nconcepts, along with methodologies to achieve these notions in different\ncontexts. Despite the rapid advancement, not all sectors have embraced these\nfairness principles to the same extent. One specific sector that merits\nattention in this regard is insurance. Within the realm of insurance pricing,\nfairness is defined through a distinct and specialized framework. Consequently,\nachieving fairness according to established notions does not automatically\nensure fair pricing in insurance. In particular, regulators are increasingly\nemphasizing transparency in pricing algorithms and imposing constraints on\ninsurance companies on the collection and utilization of sensitive consumer\nattributes. These factors present additional challenges in the implementation\nof fairness in pricing algorithms. To address these complexities and comply\nwith regulatory demands, we propose an efficient method for constructing fair\nmodels that are tailored to the insurance domain, using only privatized\nsensitive attributes. Notably, our approach ensures statistical guarantees,\ndoes not require direct access to sensitive attributes, and adapts to varying\ntransparency requirements, addressing regulatory demands while ensuring\nfairness in insurance pricing.","main_category":"stat.ML","categories":"stat.ML,cs.CY,cs.LG,q-fin.RM","published":"2025-04-16T05:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.11784v1","title":"DALC: Distributed Arithmetic Coding Aided by Linear Codes","summary":"Distributed Arithmetic Coding (DAC) has emerged as a feasible solution to the\nSlepian-Wolf problem, particularly in scenarios with non-stationary sources and\nfor data sequences with lengths ranging from small to medium. Due to the\ninherent decoding ambiguity in DAC, the number of candidate paths grows\nexponentially with the increase in source length. To select the correct\ndecoding path from the set of candidates, DAC decoders utilize the Maximum A\nPosteriori (MAP) metric to rank the decoding sequences, outputting the path\nwith the highest MAP metric as the decoding result of the decoder. However,\nthis method may still inadvertently output incorrect paths that have a MAP\nmetric higher than the correct decoding path, despite not being the correct\ndecoding path. To address the issue, we propose Distributed Arithmetic Coding\nAided by Linear Codes (DALC), which employs linear codes to constrain the\ndecoding process, thereby eliminating some incorrect paths and preserving the\ncorrect one. During the encoding phase, DALC generates the parity bits of the\nlinear code for encoding the source data. In the decoding phase, each path in\nthe set of candidate paths is verified in descending order according to the MAP\nmetric until a path that meets the verification criteria is encountered, which\nis then outputted as the decoding result. DALC enhances the decoding\nperformance of DAC by excluding candidate paths that do not meet the\nconstraints imposed by linear codes. Our experimental results demonstrate that\nDALC reduces the Bit Error Rate(BER), with especially improvements in skewed\nsource data scenarios.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-16T05:36:52Z"}
{"aid":"http://arxiv.org/abs/2504.11785v1","title":"Ground state and multiple normalized solutions of quasilinear\n  Schr√∂dinger equations in the $L^2$-supercritical case and the Sobolev\n  critical case","summary":"This paper is devoted to studying the existence of normalized solutions for\nthe following quasilinear Schr\\\"odinger equation \\begin{equation*}\n\\begin{aligned}\n  -\\Delta u-u\\Delta u^2 +\\lambda u=|u|^{p-2}u \\quad\\mathrm{in}\\ \\mathbb{R}^{N},\n\\end{aligned} \\end{equation*} where $N=3,4$, $\\lambda$ appears as a Lagrange\nmultiplier and $p \\in (4+\\frac{4}{N},2\\cdot2^*]$. The solutions correspond to\ncritical points of the energy functional subject to the $L^2$-norm constraint\n$\\int_{\\mathbb{R}^N}|u|^2dx=a^2>0$. In the Sobolev critical case $p=2\\cdot\n2^*$, the energy functional has no critical point. As for $L^2$-supercritical\ncase $p \\in (4+\\frac{4}{N},2\\cdot2^*)$: on the one hand, taking into account\nPohozaev manifold and perturbation method, we obtain the existence of ground\nstate normalized solutions for the non-radial case; on the other hand, we get\nthe existence of infinitely many normalized solutions in $H^1_r(\\mathbb{R}^N)$.\nMoreover, our results cover several relevant existing results. And in the end,\nwe get the asymptotic properties of energy as $a$ tends to $+\\infty$ and $a$\ntends to $0^+$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T05:37:28Z"}
{"aid":"http://arxiv.org/abs/2504.11792v1","title":"Large Language Models for Drug Overdose Prediction from Longitudinal\n  Medical Records","summary":"The ability to predict drug overdose risk from a patient's medical records is\ncrucial for timely intervention and prevention. Traditional machine learning\nmodels have shown promise in analyzing longitudinal medical records for this\ntask. However, recent advancements in large language models (LLMs) offer an\nopportunity to enhance prediction performance by leveraging their ability to\nprocess long textual data and their inherent prior knowledge across diverse\ntasks. In this study, we assess the effectiveness of Open AI's GPT-4o LLM in\npredicting drug overdose events using patients' longitudinal insurance claims\nrecords. We evaluate its performance in both fine-tuned and zero-shot settings,\ncomparing them to strong traditional machine learning methods as baselines. Our\nresults show that LLMs not only outperform traditional models in certain\nsettings but can also predict overdose risk in a zero-shot setting without\ntask-specific training. These findings highlight the potential of LLMs in\nclinical decision support, particularly for drug overdose risk prediction.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-16T05:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.11802v1","title":"On the photon energy conservation in stimulated emission. Experiment","summary":"Quantum electrodynamics predicts identity of incident and emitted photons in\nstimulated emission. This fundamental law is important to test experimentally.\nIn this work stimulated emission in GaAs semiconductor amplifier was\ninvestigated and positive frequency shift of the amplified beam was detected.\nIn relative units this frequency shift was found equal $\\Delta\\nu/\\nu = (+1.7\n\\pm 0.2)\\cdot10^{-18}$. This indicates violation of the photon energy\nconservation in stimulated emission.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-16T06:17:28Z"}
{"aid":"http://arxiv.org/abs/2504.11815v1","title":"On projection mappings and the gradient projection method on hyperbolic\n  space forms","summary":"This paper presents several new properties of the intrinsic\n$\\kappa$-projection into $\\kappa$-hyperbolically convex sets of\n$\\kappa$-hyperbolic space forms, along with closed-form formulas for the\nintrinsic $\\kappa$-projection into specific $\\kappa$-hyperbolically convex\nsets. It also discusses the relationship between the intrinsic\n$\\kappa$-projection, the Euclidean orthogonal projection, and the Lorentz\nprojection. These properties lay the groundwork for analyzing the gradient\nprojection method and hold importance in their own right. Additionally, new\nproperties of the gradient projection method to solve constrained optimization\nproblems in $\\kappa$-hyperbolic space forms are established, considering both\nconstant and backtracking step sizes in the analysis. It is shown that every\naccumulation point of the sequence generated by the method for both step sizes\nis a stationary point for the given problem. Additionally, an iteration\ncomplexity bound is provided that upper bounds the number of iterations needed\nto achieve a suitable measure of stationarity for both step sizes. Finally, the\nproperties of the constrained Fermat-Weber problem are explored, demonstrating\nthat the sequence generated by the gradient projection method converges to its\nunique solution. Numerical experiments on solving the Fermat-Weber problem are\npresented, illustrating the theoretical findings and demonstrating the\neffectiveness of the proposed methods.","main_category":"math.OC","categories":"math.OC,cs.NA,math.DG,math.NA","published":"2025-04-16T07:01:00Z"}
{"aid":"http://arxiv.org/abs/2504.11823v1","title":"Multi-goal Rapidly Exploring Random Tree with Safety and Dynamic\n  Constraints for UAV Cooperative Path Planning","summary":"Cooperative path planning is gaining its importance due to the increasing\ndemand on using multiple unmanned aerial vehicles (UAVs) for complex missions.\nThis work addresses the problem by introducing a new algorithm named MultiRRT\nthat extends the rapidly exploring random tree (RRT) to generate paths for a\ngroup of UAVs to reach multiple goal locations at the same time. We first\nderive the dynamics constraint of the UAV and include it in the problem\nformulation. MultiRRT is then developed, taking into account the cooperative\nrequirements and safe constraints during its path-searching process. The\nalgorithm features two new mechanisms, node reduction and Bezier interpolation,\nto ensure the feasibility and optimality of the paths generated. Importantly,\nthe interpolated paths are proven to meet the safety and dynamics constraints\nimposed by obstacles and the UAVs. A number of simulations, comparisons, and\nexperiments have been conducted to evaluate the performance of the proposed\napproach. The results show that MultiRRT can generate collision-free paths for\nmultiple UAVs to reach their goals with better scores in path length and\nsmoothness metrics than state-of-the-art RRT variants including Theta-RRT,\nFN-RRT, RRT*, and RRT*-Smart. The generated paths are also tested in practical\nflights with real UAVs to evaluate their validity for cooperative tasks. The\nsource code of the algorithm is available at\nhttps://github.com/duynamrcv/multi-target_RRT","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-16T07:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.11834v1","title":"Estimation and inference in error-in-operator model","summary":"Many statistical problems can be reduced to a linear inverse problem in which\nonly a noisy version of the operator is available. Particular examples include\nrandom design regression, deconvolution problem, instrumental variable\nregression, functional data analysis, error-in-variable regression, drift\nestimation in stochastic diffusion, and many others. The pragmatic plug-in\napproach can be well justified in the classical asymptotic setup with a growing\nsample size. However, recent developments in high dimensional inference reveal\nsome new features of this problem. In high dimensional linear regression with a\nrandom design, the plug-in approach is questionable but the use of a simple\nridge penalization yields a benign overfitting phenomenon; see\n\\cite{baLoLu2020}, \\cite{ChMo2022}, \\cite{NoPuSp2024}. This paper revisits the\ngeneral Error-in-Operator problem for finite samples and high dimension of the\nsource and image spaces. A particular focus is on the choice of a proper\nregularization. We show that a simple ridge penalty (Tikhonov regularization)\nworks properly in the case when the operator is more regular than the signal.\nIn the opposite case, some model reduction technique like spectral truncation\nshould be applied.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-16T07:45:44Z"}
{"aid":"http://arxiv.org/abs/2504.11859v1","title":"Meta Theorem for Hardness on FCP-Problem","summary":"The Fewest Clues Problem (FCP) framework has been introduced to study the\ncomplexity of determining whether a solution to an \\NP~problem can be uniquely\nidentified by specifying a subset of the certificate. For a given problem $P\n\\in \\NP$, its FCP variant is denoted by FCP-$P$. While several \\NP-complete\nproblems have been shown to have $\\Sigma_2^\\p$-complete FCP variants, it\nremains open whether this holds for all \\NP-complete problems.\n  In this work, we propose a meta-theorem that establishes the\n$\\Sigma_2^\\p$-completeness of FCP-$P$ under the condition that the \\NP-hardness\nof $P$ is proven via a polynomial-time reduction satisfying certain structural\nproperties. Furthermore, we apply the meta-theorem to demonstrate the\n$\\Sigma_2^\\p$-completeness of the FCP variants of several \\NP-complete\nproblems.","main_category":"cs.CC","categories":"cs.CC,F.1.3","published":"2025-04-16T08:30:34Z"}
{"aid":"http://arxiv.org/abs/2504.11869v1","title":"Recovering the CMB signal with neural networks","summary":"Component separation is the process of extracting one or more emission\nsources in astrophysical maps. It is therefore crucial to develop models that\ncan accurately clean the cosmic microwave background (CMB) in current and\nfuture experiments. In this work, we present a new methodology based on neural\nnetworks which operates on realistic temperature and polarization simulations.\nWe assess its performance by comparing the power spectra of the output maps\nwith those of the input maps and other emissions. For temperature, we obtain\nresiduals of $20 \\pm \\mu K^{2}$. For polarization, we analyze the $E$ and $B$\nmodes, which are related to density (scalar) and primordial gravitational waves\n(tensorial) perturbations occurring in the first second of the Universe,\nobtaining residuals of $10^{-2} \\mu K^{2}$ at $l>200$ and $10^{-2}$ and\n$10^{-3} \\mu K^{2}$ for $E$ and $B$, respectively.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-04-16T08:44:46Z"}
{"aid":"http://arxiv.org/abs/2504.11871v1","title":"Channel-Adaptive Robust Resource Allocation for Highly Reliable\n  IRS-Assisted V2X Communications","summary":"This paper addresses the challenges of resource allocation in vehicular\nnetworks enhanced by Intelligent Reflecting Surfaces (IRS), considering the\nuncertain Channel State Information (CSI) typical of vehicular environments due\nto the Doppler shift. Leveraging the 3GPP's Mode 1 cellular V2X architecture,\nour system model facilitates efficient subcarrier usage and interference\nreduction through coordinated V2I and V2V communications. Each Cellular User\nEquipment (CUE) shares its spectrum with at most one Vehicular User Equipment\n(VUE) in a one-to-one reuse pattern. We formulate a joint optimization problem\nfor vehicular transmit power, Multi-User Detection (MUD) matrices, V2V link\nspectrum reuse, and IRS reflection coefficients in IRS-aided V2X communication\nwith imperfect CSI. To tackle this, a novel robust resource allocation\nalgorithm is developed by first decomposing the problem into manageable\nsub-problems such as power allocation, MUD matrices optimization and IRS phase\nshifts, and then using the Block Coordinate Descent (BCD) method to alternately\noptimize these subproblems for optimal resource allocation. Our contributions\ninclude efficient approaches for self-learning based power allocation and phase\nshift optimization that adapt to CSI uncertainties, significantly enhancing the\nreliability and efficiency of vehicular communications. Simulation results\nvalidate the effectiveness of the proposed solutions in improving the Quality\nof Service (QoS) and managing the complex interference inherent in dense\nvehicular networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T08:48:53Z"}
{"aid":"http://arxiv.org/abs/2504.11882v1","title":"Seeking and leveraging alternative variable dependency concepts in\n  gray-box-elusive bimodal land-use allocation problems","summary":"Solving land-use allocation problems can help us to deal with some of the\nmost urgent global environmental issues. Since these problems are NP-hard,\neffective optimizers are needed to handle them. The knowledge about variable\ndependencies allows for proposing such tools. However, in this work, we\nconsider a real-world multi-objective problem for which standard variable\ndependency discovery techniques are inapplicable. Therefore, using\nlinkage-based variation operators is unreachable. To address this issue, we\npropose a definition of problem-dedicated variable dependency. On this base, we\npropose obtaining masks of dependent variables. Using them, we construct three\nnovel crossover operators. The results concerning real-world test cases show\nthat introducing our propositions into two well-known optimizers (NSGA-II,\nMOEA/D) dedicated to multi-objective optimization significantly improves their\neffectiveness.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T09:06:55Z"}
{"aid":"http://arxiv.org/abs/2504.11884v1","title":"Training and synchronizing oscillator networks with Equilibrium\n  Propagation","summary":"Oscillator networks represent a promising technology for unconventional\ncomputing and artificial intelligence. Thus far, these systems have primarily\nbeen demonstrated in small-scale implementations, such as Ising Machines for\nsolving combinatorial problems and associative memories for image recognition,\ntypically trained without state-of-the-art gradient-based algorithms. Scaling\nup oscillator-based systems requires advanced gradient-based training methods\nthat also ensure robustness against frequency dispersion between individual\noscillators. Here, we demonstrate through simulations that the Equilibrium\nPropagation algorithm enables effective gradient-based training of oscillator\nnetworks, facilitating synchronization even when initial oscillator frequencies\nare significantly dispersed. We specifically investigate two oscillator models:\npurely phase-coupled oscillators and oscillators coupled via both amplitude and\nphase interactions. Our results show that these oscillator networks can scale\nsuccessfully to standard image recognition benchmarks, such as achieving nearly\n98\\% test accuracy on the MNIST dataset, despite noise introduced by imperfect\nsynchronization. This work thus paves the way for practical hardware\nimplementations of large-scale oscillator networks, such as those based on\nspintronic devices.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cs.ET","published":"2025-04-16T09:10:31Z"}
{"aid":"http://arxiv.org/abs/2504.11914v1","title":"AnomalyR1: A GRPO-based End-to-end MLLM for Industrial Anomaly Detection","summary":"Industrial Anomaly Detection (IAD) poses a formidable challenge due to the\nscarcity of defective samples, making it imperative to deploy models capable of\nrobust generalization to detect unseen anomalies effectively. Traditional\napproaches, often constrained by hand-crafted features or domain-specific\nexpert models, struggle to address this limitation, underscoring the need for a\nparadigm shift. We introduce AnomalyR1, a pioneering framework that leverages\nVLM-R1, a Multimodal Large Language Model (MLLM) renowned for its exceptional\ngeneralization and interpretability, to revolutionize IAD. By integrating MLLM\nwith Group Relative Policy Optimization (GRPO), enhanced by our novel Reasoned\nOutcome Alignment Metric (ROAM), AnomalyR1 achieves a fully end-to-end solution\nthat autonomously processes inputs of image and domain knowledge, reasons\nthrough analysis, and generates precise anomaly localizations and masks. Based\non the latest multimodal IAD benchmark, our compact 3-billion-parameter model\noutperforms existing methods, establishing state-of-the-art results. As MLLM\ncapabilities continue to advance, this study is the first to deliver an\nend-to-end VLM-based IAD solution that demonstrates the transformative\npotential of ROAM-enhanced GRPO, positioning our framework as a forward-looking\ncornerstone for next-generation intelligent anomaly detection systems in\nindustrial applications with limited defective data.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T09:48:41Z"}
{"aid":"http://arxiv.org/abs/2504.11936v1","title":"Mind2Matter: Creating 3D Models from EEG Signals","summary":"The reconstruction of 3D objects from brain signals has gained significant\nattention in brain-computer interface (BCI) research. Current research\npredominantly utilizes functional magnetic resonance imaging (fMRI) for 3D\nreconstruction tasks due to its excellent spatial resolution. Nevertheless, the\nclinical utility of fMRI is limited by its prohibitive costs and inability to\nsupport real-time operations. In comparison, electroencephalography (EEG)\npresents distinct advantages as an affordable, non-invasive, and mobile\nsolution for real-time brain-computer interaction systems. While recent\nadvances in deep learning have enabled remarkable progress in image generation\nfrom neural data, decoding EEG signals into structured 3D representations\nremains largely unexplored. In this paper, we propose a novel framework that\ntranslates EEG recordings into 3D object reconstructions by leveraging neural\ndecoding techniques and generative models. Our approach involves training an\nEEG encoder to extract spatiotemporal visual features, fine-tuning a large\nlanguage model to interpret these features into descriptive multimodal outputs,\nand leveraging generative 3D Gaussians with layout-guided control to synthesize\nthe final 3D structures. Experiments demonstrate that our model captures\nsalient geometric and semantic features, paving the way for applications in\nbrain-computer interfaces (BCIs), virtual reality, and neuroprosthetics.Our\ncode is available in https://github.com/sddwwww/Mind2Matter.","main_category":"cs.GR","categories":"cs.GR,cs.HC,eess.SP","published":"2025-04-16T10:16:03Z"}
{"aid":"http://arxiv.org/abs/2504.11944v1","title":"VIPO: Value Function Inconsistency Penalized Offline Reinforcement\n  Learning","summary":"Offline reinforcement learning (RL) learns effective policies from\npre-collected datasets, offering a practical solution for applications where\nonline interactions are risky or costly. Model-based approaches are\nparticularly advantageous for offline RL, owing to their data efficiency and\ngeneralizability. However, due to inherent model errors, model-based methods\noften artificially introduce conservatism guided by heuristic uncertainty\nestimation, which can be unreliable. In this paper, we introduce VIPO, a novel\nmodel-based offline RL algorithm that incorporates self-supervised feedback\nfrom value estimation to enhance model training. Specifically, the model is\nlearned by additionally minimizing the inconsistency between the value learned\ndirectly from the offline data and the one estimated from the model. We perform\ncomprehensive evaluations from multiple perspectives to show that VIPO can\nlearn a highly accurate model efficiently and consistently outperform existing\nmethods. It offers a general framework that can be readily integrated into\nexisting model-based offline RL algorithms to systematically enhance model\naccuracy. As a result, VIPO achieves state-of-the-art performance on almost all\ntasks in both D4RL and NeoRL benchmarks.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-16T10:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.11974v1","title":"Who Said Only Military Officers Can Deal with Uncertainty? On the\n  Importance of Uncertainty in EdTech Data Visualisations","summary":"AI-powered predictive systems have high margins of error. However, data\nvisualisations of algorithmic systems in education and other social fields tend\nto visualise certainty, thus invisibilising the underlying approximations and\nuncertainties of the algorithmic systems and the social settings in which these\nsystems operate. This paper draws on a critical speculative approach to first\nanalyse data visualisations from predictive analytics platforms for education.\nIt demonstrates that visualisations of uncertainty in education are rare.\nSecond, the paper explores uncertainty visualisations in other fields (defence,\nclimate change and healthcare). The paper concludes by reflecting on the role\nof data visualisations and un/certainty in shaping educational futures. It also\nidentifies practical implications for the design of data visualisations in\neducation.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-16T11:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.11977v1","title":"Leveraging Machine Learning Models to Predict the Outcome of Digital\n  Medical Triage Interviews","summary":"Many existing digital triage systems are questionnaire-based, guiding\npatients to appropriate care levels based on information (e.g., symptoms,\nmedical history, and urgency) provided by the patients answering\nquestionnaires. Such a system often uses a deterministic model with predefined\nrules to determine care levels. It faces challenges with incomplete triage\ninterviews since it can only assist patients who finish the process. In this\nstudy, we explore the use of machine learning (ML) to predict outcomes of\nunfinished interviews, aiming to enhance patient care and service quality.\nPredicting triage outcomes from incomplete data is crucial for patient safety\nand healthcare efficiency. Our findings show that decision-tree models,\nparticularly LGBMClassifier and CatBoostClassifier, achieve over 80\\% accuracy\nin predicting outcomes from complete interviews while having a linear\ncorrelation between the prediction accuracy and interview completeness degree.\nFor example, LGBMClassifier achieves 88,2\\% prediction accuracy for interviews\nwith 100\\% completeness, 79,6\\% accuracy for interviews with 80\\% completeness,\n58,9\\% accuracy for 60\\% completeness, and 45,7\\% accuracy for 40\\%\ncompleteness. The TabTransformer model demonstrated exceptional accuracy of\nover 80\\% for all degrees of completeness but required extensive training time,\nindicating a need for more powerful computational resources. The study\nhighlights the linear correlation between interview completeness and predictive\npower of the decision-tree models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T11:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.11988v1","title":"Strong Convergence Rates for Euler Schemes of Levy-Driven SDE using\n  Dynamic Cutting","summary":"We derive strong Lp convergence rates for the Euler-Maruyama schemes of\nLevy-driven SDE using a new dynamic cutting (DC) method with a time-dependent\njump threshold. In addition, we present results from numerical simulations\ncomparing the DC and Asmussen-Rosinski (AR) approaches. These simulations\ndemonstrate the superior accuracy achieved by the DC method.","main_category":"math.PR","categories":"math.PR,cs.NA,math.NA","published":"2025-04-16T11:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.12000v1","title":"Control of Rayleigh-B√©nard Convection: Effectiveness of Reinforcement\n  Learning in the Turbulent Regime","summary":"Data-driven flow control has significant potential for industry, energy\nsystems, and climate science. In this work, we study the effectiveness of\nReinforcement Learning (RL) for reducing convective heat transfer in the 2D\nRayleigh-B\\'enard Convection (RBC) system under increasing turbulence. We\ninvestigate the generalizability of control across varying initial conditions\nand turbulence levels and introduce a reward shaping technique to accelerate\nthe training. RL agents trained via single-agent Proximal Policy Optimization\n(PPO) are compared to linear proportional derivative (PD) controllers from\nclassical control theory. The RL agents reduced convection, measured by the\nNusselt Number, by up to 33% in moderately turbulent systems and 10% in highly\nturbulent settings, clearly outperforming PD control in all settings. The\nagents showed strong generalization performance across different initial\nconditions and to a significant extent, generalized to higher degrees of\nturbulence. The reward shaping improved sample efficiency and consistently\nstabilized the Nusselt Number to higher turbulence levels.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-16T11:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.12006v1","title":"Comment on Path integral measure and RG equations for gravity","summary":"Asymptotic safety is a candidate for a predictive quantum theory of gravity\nand matter. Recent works (arXiv:2412.10194 and arXiv:2412.14108) challenged\nthis scenario. We show that their arguments fail on a basic level.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T12:00:22Z"}
{"aid":"http://arxiv.org/abs/2504.12040v1","title":"No equivalence between hydrodynamic and dispersive mass of the charged\n  polaron","summary":"We consider the problem of a charged impurity exerting a weak, slowly\ndecaying force on its surroundings, treating the latter as an ideal\ncompressible fluid. In the semiclassical approximation, the ion is described by\nthe Newton equation coupled to the Euler equation for the medium. After\nlinearization, we obtain a simple closed formula for the effective mass of the\nimpurity, depending on the interaction potential, the mean medium density, and\nsound velocity. Thus, once the interaction and the equation of state of the\nfluid is known, an estimate of the hydrodynamic effective mass can be quickly\nprovided. Going beyond the classical case, we show that replacing the Newton\nwith Schr\\\"{o}dinger equation can drastically change the behavior of the\nimpurity. In particular, the scaling of the Fermi polaron effective mass with\nthe medium density is opposite in quantum and classical scenario. Our results\nare relevant for experimental systems featuring low energy impurities in Fermi\nor Bose systems, such as ions immersed in neutral atomic gases.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.flu-dyn,quant-ph","published":"2025-04-16T12:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.12113v1","title":"Clarifying Ambiguities: on the Role of Ambiguity Types in Prompting\n  Methods for Clarification Generation","summary":"In information retrieval (IR), providing appropriate clarifications to better\nunderstand users' information needs is crucial for building a proactive\nsearch-oriented dialogue system. Due to the strong in-context learning ability\nof large language models (LLMs), recent studies investigate prompting methods\nto generate clarifications using few-shot or Chain of Thought (CoT) prompts.\nHowever, vanilla CoT prompting does not distinguish the characteristics of\ndifferent information needs, making it difficult to understand how LLMs resolve\nambiguities in user queries. In this work, we focus on the concept of ambiguity\nfor clarification, seeking to model and integrate ambiguities in the\nclarification process. To this end, we comprehensively study the impact of\nprompting schemes based on reasoning and ambiguity for clarification. The idea\nis to enhance the reasoning abilities of LLMs by limiting CoT to predict first\nambiguity types that can be interpreted as instructions to clarify, then\ncorrespondingly generate clarifications. We name this new prompting scheme\nAmbiguity Type-Chain of Thought (AT-CoT). Experiments are conducted on various\ndatasets containing human-annotated clarifying questions to compare AT-CoT with\nmultiple baselines. We also perform user simulations to implicitly measure the\nquality of generated clarifications under various IR scenarios.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-16T14:21:02Z"}
{"aid":"http://arxiv.org/abs/2504.12117v1","title":"The $L_p$ Minkowski problems on affine dual quermassintegrals","summary":"In this paper, we provided $L_p$ curvature measures of affine dual\nquermassintegrals for $p\\in\\mathbb{R}$, and solved the existence part of the\n$L_p$ Minkowski problems for the non-symmetric measures when $p>1$ and\nsymmetric measures when $p\\geq0$. When $p=0$, this is the affine dual Minkowski\nproblems, which is introduced and solved by Cai-Leng-Wu-Xi in [7].","main_category":"math.MG","categories":"math.MG","published":"2025-04-16T14:27:47Z"}
{"aid":"http://arxiv.org/abs/2504.12165v1","title":"CodingHomo: Bootstrapping Deep Homography With Video Coding","summary":"Homography estimation is a fundamental task in computer vision with\napplications in diverse fields. Recent advances in deep learning have improved\nhomography estimation, particularly with unsupervised learning approaches,\noffering increased robustness and generalizability. However, accurately\npredicting homography, especially in complex motions, remains a challenge. In\nresponse, this work introduces a novel method leveraging video coding,\nparticularly by harnessing inherent motion vectors (MVs) present in videos. We\npresent CodingHomo, an unsupervised framework for homography estimation. Our\nframework features a Mask-Guided Fusion (MGF) module that identifies and\nutilizes beneficial features among the MVs, thereby enhancing the accuracy of\nhomography prediction. Additionally, the Mask-Guided Homography Estimation\n(MGHE) module is presented for eliminating undesired features in the\ncoarse-to-fine homography refinement process. CodingHomo outperforms existing\nstate-of-the-art unsupervised methods, delivering good robustness and\ngeneralizability. The code and dataset are available at:\n\\href{github}{https://github.com/liuyike422/CodingHomo","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T15:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.12170v1","title":"AI Behind Closed Doors: a Primer on The Governance of Internal\n  Deployment","summary":"The most advanced future AI systems will first be deployed inside the\nfrontier AI companies developing them. According to these companies and\nindependent experts, AI systems may reach or even surpass human intelligence\nand capabilities by 2030. Internal deployment is, therefore, a key source of\nbenefits and risks from frontier AI systems. Despite this, the governance of\nthe internal deployment of highly advanced frontier AI systems appears absent.\nThis report aims to address this absence by priming a conversation around the\ngovernance of internal deployment. It presents a conceptualization of internal\ndeployment, learnings from other sectors, reviews of existing legal frameworks\nand their applicability, and illustrative examples of the type of scenarios we\nare most concerned about. Specifically, it discusses the risks correlated to\nthe loss of control via the internal application of a misaligned AI system to\nthe AI research and development pipeline, and unconstrained and undetected\npower concentration behind closed doors. The report culminates with a small\nnumber of targeted recommendations that provide a first blueprint for the\ngovernance of internal deployment.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-16T15:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.12182v1","title":"Domains, Information Frames, and Their Logic","summary":"In \\cite{sp25}, continuous information frames were introduced that capture\nexactly all continuous domains. They are obtained from the information frames\nconsidered in \\cite{sp21} by omitting the conservativity requirement.\nInformation frames generalise Scott's information systems~\\cite{sc82}: Instead\nof the global consistency predicate, there is now a local consistency predicate\nfor each token. Strong information frames are obtained by strengthening the\nconditions for these predicates. Let $\\CIF$ and $\\SIF$ be the corresponding\ncategories.\n  In \\cite{sxx08} another generalisation of Scott's information systems was\nintroduced which also exactly captures all continuous domains. As shown in\n\\cite{hzl15}, the definition can be simplified while maintaining the\nrepresentation result. Let $\\CIS$ and $\\SCIS$ be the corresponding categories.\nIt is shown that all these categories are equivalent. Moreover, the equivalence\nextends to the subcategories of (strong) continuous information frames with\ntruth elements. Such information frames capture exactly all pointed continuous\ndomains.\n  Continuous information frames are families of rudimentary logics, associated\nwith each token is a local consistency predicate and an entailment relation.\nHowever, they lack the expressive power of propositional logic. In an attempt\nto make each of this logics more expressible, continuous stratified conjunctive\nlogics are introduced. These are families of conjunctive logics. The category\n$\\CSL$ of such logics is shown to be isomorphic to $\\SIF_{\\bt}$, the category\nof strong continuous information frames with a truth element.","main_category":"cs.LO","categories":"cs.LO,F.3.1","published":"2025-04-16T15:38:59Z"}
{"aid":"http://arxiv.org/abs/2504.12184v1","title":"Feature Selection for Data-driven Explainable Optimization","summary":"Mathematical optimization, although often leading to NP-hard models, is now\ncapable of solving even large-scale instances within reasonable time. However,\nthe primary focus is often placed solely on optimality. This implies that while\nobtained solutions are globally optimal, they are frequently not comprehensible\nto humans, in particular when obtained by black-box routines. In contrast,\nexplainability is a standard requirement for results in Artificial\nIntelligence, but it is rarely considered in optimization yet. There are only a\nfew studies that aim to find solutions that are both of high quality and\nexplainable. In recent work, explainability for optimization was defined in a\ndata-driven manner: a solution is considered explainable if it closely\nresembles solutions that have been used in the past under similar\ncircumstances. To this end, it is crucial to identify a preferably small subset\nof features from a presumably large set that can be used to explain a solution.\nIn mathematical optimization, feature selection has received little attention\nyet. In this work, we formally define the feature selection problem for\nexplainable optimization and prove that its decision version is NP-complete. We\nintroduce mathematical models for optimized feature selection. As their global\nsolution requires significant computation time with modern mixed-integer linear\nsolvers, we employ local heuristics. Our computational study using data that\nreflect real-world scenarios demonstrates that the problem can be solved\npractically efficiently for instances of reasonable size.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T15:40:03Z"}
{"aid":"http://arxiv.org/abs/2504.12214v1","title":"Bayesian random-effects meta-analysis of aggregate data on clinical\n  events","summary":"To appreciate intervention effects on rare events, meta-analysis techniques\nare commonly applied in order to assess the accumulated evidence. When it comes\nto adverse effects in clinical trials, these are often most adequately handled\nusing survival methods. A common-effect model that is able to process data in\ncommonly quoted formats in terms of hazard ratios has been proposed for this\npurpose by Holzhauer (Stat. Med. 2017; 36(5):723-737). In order to accommodate\npotential heterogeneity between studies, we have extended the model by\nHolzhauer to a random-effects approach. The Bayesian model is described in\ndetail, and applications to realistic data sets are discussed along with\nsensitivity analyses and Monte Carlo simulations to support the conclusions.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T16:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.12222v1","title":"Coding-Prior Guided Diffusion Network for Video Deblurring","summary":"While recent video deblurring methods have advanced significantly, they often\noverlook two valuable prior information: (1) motion vectors (MVs) and coding\nresiduals (CRs) from video codecs, which provide efficient inter-frame\nalignment cues, and (2) the rich real-world knowledge embedded in pre-trained\ndiffusion generative models. We present CPGDNet, a novel two-stage framework\nthat effectively leverages both coding priors and generative diffusion priors\nfor high-quality deblurring. First, our coding-prior feature propagation (CPFP)\nmodule utilizes MVs for efficient frame alignment and CRs to generate attention\nmasks, addressing motion inaccuracies and texture variations. Second, a\ncoding-prior controlled generation (CPC) module network integrates coding\npriors into a pretrained diffusion model, guiding it to enhance critical\nregions and synthesize realistic details. Experiments demonstrate our method\nachieves state-of-the-art perceptual quality with up to 30% improvement in IQA\nmetrics. Both the code and the codingprior-augmented dataset will be\nopen-sourced.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T16:14:43Z"}
{"aid":"http://arxiv.org/abs/2504.12251v1","title":"An Evaluation of N-Gram Selection Strategies for Regular Expression\n  Indexing in Contemporary Text Analysis Tasks","summary":"Efficient evaluation of regular expressions (regex, for short) is crucial for\ntext analysis, and n-gram indexes are fundamental to achieving fast regex\nevaluation performance. However, these indexes face scalability challenges\nbecause of the exponential number of possible n-grams that must be indexed.\nMany existing selection strategies, developed decades ago, have not been\nrigorously evaluated on contemporary large-scale workloads and lack\ncomprehensive performance comparisons. Therefore, a unified and comprehensive\nevaluation framework is necessary to compare these methods under the same\nexperimental settings. This paper presents the first systematic evaluation of\nthree representative n-gram selection strategies across five workloads,\nincluding real-time production logs and genomic sequence analysis. We examine\ntheir trade-offs in terms of index construction time, storage overhead, false\npositive rates, and end-to-end query performance. Through empirical results,\nthis study provides a modern perspective on existing n-gram based regular\nexpression evaluation methods, extensive observations, valuable discoveries,\nand an adaptable testing framework to guide future research in this domain. We\nmake our implementations of these methods and our test framework available as\nopen-source at https://github.com/mush-zhang/RegexIndexComparison.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-16T16:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.12257v1","title":"QSHS: An Axion Dark Matter Resonant Search Apparatus","summary":"We describe a resonant cavity search apparatus for axion dark matter\nconstructed by the Quantum Sensors for the Hidden Sector (QSHS) collaboration.\nThe apparatus is configured to search for QCD axion dark matter, though also\nhas the capability to detect axion-like particles (ALPs), dark photons, and\nsome other forms of wave-like dark matter. Initially, a tuneable cylindrical\noxygen-free copper cavity is read out using a low noise microwave amplifier\nfeeding a heterodyne receiver. The cavity is housed in a dilution refrigerator\nand threaded by a solenoidal magnetic field, nominally 8T. The apparatus also\nhouses a magnetic field shield for housing superconducting electronics, and\nseveral other fixed-frequency resonators for use in testing and commissioning\nvarious prototype quantum electronic devices sensitive at a range of axion\nmasses in the range $\\rm 2.0$ to $\\rm 40\\,eV/c^2$. We present performance data\nfor the resonator, dilution refrigerator, and magnet, and plans for the first\nscience run.","main_category":"physics.ins-det","categories":"physics.ins-det,astro-ph.IM,hep-ex","published":"2025-04-16T17:08:00Z"}
{"aid":"http://arxiv.org/abs/2504.12275v1","title":"The rank evolution of block bidiagonal matrices over finite fields","summary":"We investigate uniform random block lower bidiagonal matrices over the finite\nfield $\\mathbb{F}_q$, and prove that their rank undergoes a phase transition.\n  First, we consider block lower bidiagonal matrices with $(k_n+1)\\times k_n$\nblocks where each block is of size $n\\times n$. We prove that if $k_n\\ll\nq^{n/2}$, then these matrices have full rank with high probability, and if\n$k_n\\gg q^{n/2}$, then the rank has Gaussian fluctuations.\n  Second, we consider block lower bidiagonal matrices with $k_n\\times k_n$\nblocks where each block is of size $n\\times n$. We prove that if $k_n\\ll\nq^{n/2}$, then the rank exhibits the same constant order fluctuations as the\nrank of the matrix products considered by Nguyen and Van Peski, and if $k_n\\gg\nq^{n/2}$, then the rank has Gaussian fluctuations.\n  Finally, we also consider a truncated version of the first model, where we\nprove that at $k_n\\approx q^{n/2}$, we have a phase transition between a\nCohen-Lenstra and a Gaussian limiting behavior of the rank. We also show that\nthere is a localization/delocalization phase transition for the vectors in the\nkernels of these matrices at the same critical point.\n  In all three cases, we also provide a precise description of the behavior of\nthe rank at criticality.\n  These results are proved by analyzing the limiting behavior of a Markov chain\nobtained from the increments of the ranks of these matrices.","main_category":"math.PR","categories":"math.PR","published":"2025-04-16T17:35:02Z"}
{"aid":"http://arxiv.org/abs/2504.12289v1","title":"A finite Carrollian critical point","summary":"We construct examples of renormalizable Carrollian theories with finite\neffective central charge and non-trivial dynamics. These include critical\npoints that are not scale-invariant but rather exhibit hyperscaling violation.\nAll of our examples are mildly non-Lagrangian, in that they arise from suitable\n$N\\to 0$ limits of Carrollian theories with $N$-component fields, including\nlimits of Carrollian vector models and non-abelian gauge theories. We discuss\nimplications for flat space holography, highlighting challenges in realizing\nCarrollian duals to gravitational theories.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T17:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.12295v1","title":"Murmurations for elliptic curves ordered by height","summary":"He, Lee, Oliver, and Pozdnyakov [19] have empirically observed that the\naverage of the $p$th coefficients of the $L$-functions of elliptic curves of\nparticular ranks in a given range of conductors $N$ appears to approximate a\ncontinuous function of $p$, depending primarily on the parity of the rank.\nHence the sum of $p$th coefficients against the root number also appears to\napproximate a continuous function, dubbed the murmuration density. However, it\nis not clear from this numerical data how to obtain an explicit formula for the\nmurmuration density. Convergence of similar averages was proved by Zubrilina\n[32] for modular forms of weight 2 (of which elliptic curves form a thin\nsubset) and analogous results for other families of automorphic forms have been\nobtained in further work [6,23]. Each of these works gives an explicit formula\nfor the murmuration density. We consider a variant problem where the elliptic\ncurves are ordered by naive height, and the $p$th coefficients are averaged\nover $p/N$ in a fixed interval. We give a conjecture for the murmuration\ndensity in this case, as an explicit but complicated sum of Bessel functions.\nThis conjecture is motivated by a theorem about a variant problem where we sum\nthe $n$th coefficients for $n$ with no small prime factors against a smooth\nweight function. We test this conjecture for elliptic curves of naive height up\nto $2^{28}$ and find good agreement with the data. The theorem is proved using\nthe Voronoi summation formula, and the method should apply to many different\nfamilies of $L$-functions. This is the first work to give an explicit formula\nfor the murmuration density of a family of elliptic curves, in any ordering.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T17:56:37Z"}
{"aid":"http://arxiv.org/abs/2504.12619v1","title":"SAM-Based Building Change Detection with Distribution-Aware Fourier\n  Adaptation and Edge-Constrained Warping","summary":"Building change detection remains challenging for urban development, disaster\nassessment, and military reconnaissance. While foundation models like Segment\nAnything Model (SAM) show strong segmentation capabilities, SAM is limited in\nthe task of building change detection due to domain gap issues. Existing\nadapter-based fine-tuning approaches face challenges with imbalanced building\ndistribution, resulting in poor detection of subtle changes and inaccurate edge\nextraction. Additionally, bi-temporal misalignment in change detection,\ntypically addressed by optical flow, remains vulnerable to background noises.\nThis affects the detection of building changes and compromises both detection\naccuracy and edge recognition. To tackle these challenges, we propose a new\nSAM-Based Network with Distribution-Aware Fourier Adaptation and\nEdge-Constrained Warping (FAEWNet) for building change detection. FAEWNet\nutilizes the SAM encoder to extract rich visual features from remote sensing\nimages. To guide SAM in focusing on specific ground objects in remote sensing\nscenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregate\ntask-oriented changed information. This adapter not only effectively addresses\nthe domain gap issue, but also pays attention to the distribution of changed\nbuildings. Furthermore, to mitigate noise interference and misalignment in\nheight offset estimation, we design a novel flow module that refines building\nedge extraction and enhances the perception of changed buildings. Our\nstate-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasets\nhighlight the effectiveness of FAEWNet. The code is available at\nhttps://github.com/SUPERMAN123000/FAEWNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T03:47:43Z"}
{"aid":"http://arxiv.org/abs/2504.12624v1","title":"The (3+1)-dimensional dispersionless integrable hierarchy and nonlinear\n  Riemann-Hilbert problem associated with the Doubrov-Ferapontov modified\n  heavenly equation","summary":"According to the classification of integrable complex Monge-Ampere equations\nby Doubrov and Ferapontov, the modified heavenly equation is a typical\n(3+1)-dimensional dispersionless and canonical integrable equation.In this\npaper we use the eigenfunctions of the Doubrov-Ferapontov modified heavenly\nequation to obtain a related hierarchy. Next we construct the Lax-Sato\nequations with Hamiltonian vector fields and Zakharov-Shabat type equations\nwhich are equivalent to the hierarchy. The nonlinear Riemann-Hilbert problem is\nalso applied to study the solution of Doubrov-Ferapontov modified heavenly\nequation.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-17T03:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.12635v1","title":"On Equivalence Between Decentralized Policy-Profile Mixtures and\n  Behavioral Coordination Policies in Multi-Agent Systems","summary":"Constrained decentralized team problem formulations are good models for many\ncooperative multi-agent systems. Constraints necessitate randomization when\nsolving for optimal solutions -- our past results show that joint randomization\namongst the team is necessary for (strong) Lagrangian duality to hold -- , but\na better understanding of randomization still remains. For a partially observed\nmulti-agent system with Borel hidden state and finite observations and actions,\nwe prove the equivalence between joint mixtures of decentralized\npolicy-profiles (both pure and behavioral) and common-information based\nbehavioral coordination policies (also mixtures of them). This generalizes past\nwork that shows equivalence between pure decentralized policy-profiles and pure\ncoordination policies. The equivalence can be exploited to develop results on\nstrong duality and number of randomizations.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T04:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.12714v1","title":"Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination","summary":"Zero-shot coordination (ZSC), the ability to adapt to a new partner in a\ncooperative task, is a critical component of human-compatible AI. While prior\nwork has focused on training agents to cooperate on a single task, these\nspecialized models do not generalize to new tasks, even if they are highly\nsimilar. Here, we study how reinforcement learning on a distribution of\nenvironments with a single partner enables learning general cooperative skills\nthat support ZSC with many new partners on many new problems. We introduce two\nJax-based, procedural generators that create billions of solvable coordination\nchallenges. We develop a new paradigm called Cross-Environment Cooperation\n(CEC), and show that it outperforms competitive baselines quantitatively and\nqualitatively when collaborating with real people. Our findings suggest that\nlearning to collaborate across many unique scenarios encourages agents to\ndevelop general norms, which prove effective for collaboration with different\npartners. Together, our results suggest a new route toward designing generalist\ncooperative agents capable of interacting with humans without requiring human\ndata.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.LG","published":"2025-04-17T07:41:25Z"}
{"aid":"http://arxiv.org/abs/2504.12719v1","title":"B*: Efficient and Optimal Base Placement for Fixed-Base Manipulators","summary":"B* is a novel optimization framework that addresses a critical challenge in\nfixed-base manipulator robotics: optimal base placement. Current methods rely\non pre-computed kinematics databases generated through sampling to search for\nsolutions. However, they face an inherent trade-off between solution optimality\nand computational efficiency when determining sampling resolution. To address\nthese limitations, B* unifies multiple objectives without database dependence.\nThe framework employs a two-layer hierarchical approach. The outer layer\nsystematically manages terminal constraints through progressive tightening,\nparticularly for base mobility, enabling feasible initialization and broad\nsolution exploration. The inner layer addresses non-convexities in each\nouter-layer subproblem through sequential local linearization, converting the\noriginal problem into tractable sequential linear programming (SLP). Testing\nacross multiple robot platforms demonstrates B*'s effectiveness. The framework\nachieves solution optimality five orders of magnitude better than\nsampling-based approaches while maintaining perfect success rates and reduced\ncomputational overhead. Operating directly in configuration space, B* enables\nsimultaneous path planning with customizable optimization criteria. B* serves\nas a crucial initialization tool that bridges the gap between theoretical\nmotion planning and practical deployment, where feasible trajectory existence\nis fundamental.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T07:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.12729v1","title":"Dead Gate Elimination","summary":"Hybrid quantum algorithms combine the strengths of quantum and classical\ncomputing. Many quantum algorithms, such as the variational quantum eigensolver\n(VQE), leverage this synergy. However, quantum circuits are executed in full,\neven when only subsets of measurement outcomes contribute to subsequent\nclassical computations. In this manuscript, we propose a novel circuit\noptimization technique that identifies and removes dead gates. We prove that\nthe removal of dead gates has no influence on the probability distribution of\nthe measurement outcomes that contribute to the subsequent calculation result.\nWe implemented and evaluated our optimization on a VQE instance, a quantum\nphase estimation (QPE) instance, and hybrid programs embedded with random\ncircuits of varying circuit width, confirming its capability to remove a\nnon-trivial number of dead gates in real-world algorithms. The effect of our\noptimization scales up as more measurement outcomes are identified as\nnon-contributory, resulting in a proportionally greater reduction of dead\ngates.","main_category":"quant-ph","categories":"quant-ph,cs.PL,cs.SE","published":"2025-04-17T08:10:59Z"}
{"aid":"http://arxiv.org/abs/2504.12737v1","title":"Chinese-Vicuna: A Chinese Instruction-following Llama-based Model","summary":"Chinese-Vicuna is an open-source, resource-efficient language model designed\nto bridge the gap in Chinese instruction-following capabilities by fine-tuning\nMeta's LLaMA architecture using Low-Rank Adaptation (LoRA). Targeting\nlow-resource environments, it enables cost-effective deployment on consumer\nGPUs (e.g., RTX-2080Ti for 7B models) and supports domain-specific adaptation\nin fields like healthcare and law. By integrating hybrid datasets (BELLE and\nGuanaco) and 4-bit quantization (QLoRA), the model achieves competitive\nperformance in tasks such as translation, code generation, and domain-specific\nQ\\&A. The project provides a comprehensive toolkit for model conversion, CPU\ninference, and multi-turn dialogue interfaces, emphasizing accessibility for\nresearchers and developers. Evaluations indicate competitive performance across\nmedical tasks, multi-turn dialogue coherence, and real-time legal updates.\nChinese-Vicuna's modular design, open-source ecosystem, and community-driven\nenhancements position it as a versatile foundation for Chinese LLM\napplications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T08:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.12739v1","title":"Mask Image Watermarking","summary":"We present MaskMark, a simple, efficient and flexible framework for image\nwatermarking. MaskMark has two variants: MaskMark-D, which supports global\nwatermark embedding, watermark localization, and local watermark extraction for\napplications such as tamper detection, and MaskMark-ED, which focuses on local\nwatermark embedding and extraction with enhanced robustness in small regions,\nenabling localized image protection. Built upon the classical Encoder-\nDistortion-Decoder training paradigm, MaskMark-D introduces a simple masking\nmechanism during the decoding stage to support both global and local watermark\nextraction. A mask is applied to the watermarked image before extraction,\nallowing the decoder to focus on selected regions and learn local extraction. A\nlocalization module is also integrated into the decoder to identify watermark\nregions during inference, reducing interference from irrelevant content and\nimproving accuracy. MaskMark-ED extends this design by incorporating the mask\ninto the encoding stage as well, guiding the encoder to embed the watermark in\ndesignated local regions for enhanced robustness. Comprehensive experiments\nshow that MaskMark achieves state-of-the-art performance in global watermark\nextraction, local watermark extraction, watermark localization, and\nmulti-watermark embedding. It outperforms all existing baselines, including the\nrecent leading model WAM for local watermarking, while preserving high visual\nquality of the watermarked images. MaskMark is also flexible, by adjusting the\ndistortion layer, it can adapt to different robustness requirements with just a\nfew steps of fine-tuning. Moreover, our approach is efficient and easy to\noptimize, requiring only 20 hours on a single A6000 GPU with just 1/15 the\ncomputational cost of WAM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:29:00Z"}
{"aid":"http://arxiv.org/abs/2504.12748v1","title":"Attack-Defense Trees with Offensive and Defensive Attributes (with\n  Appendix)","summary":"Effective risk management in cybersecurity requires a thorough understanding\nof the interplay between attacker capabilities and defense strategies.\nAttack-Defense Trees (ADTs) are a commonly used methodology for representing\nthis interplay; however, previous work in this domain has only focused on\nanalyzing metrics such as cost, damage, or time from the perspective of the\nattacker. This approach provides an incomplete view of the system, as it\nneglects to model defender attributes: in real-world scenarios, defenders have\nfinite resources for countermeasures and are similarly constrained. In this\npaper, we propose a novel framework that incorporates defense metrics into\nADTs, and we present efficient algorithms for computing the Pareto front\nbetween defense and attack metrics. Our methods encode both attacker and\ndefender metrics as semirings, allowing our methods to be used for many metrics\nsuch as cost, damage, and skill. We analyze tree-structured ADTs using a\nbottom-up approach and general ADTs by translating them into binary decision\ndiagrams. Experiments on randomly generated ADTS demonstrate that both\napproaches effectively handle ADTs with several hundred nodes.","main_category":"cs.CR","categories":"cs.CR,cs.GT","published":"2025-04-17T08:41:07Z"}
{"aid":"http://arxiv.org/abs/2504.12829v1","title":"Particle-based Simulation of an Air-Breathing Electric Propulsion System","summary":"A novel concept called Air-Breathing Electric Propulsion proposes to fly\nsatellites at altitudes in the range 180-250 km, since this would have some\nadvantages for the performance of radio communication and Earth observation\nequipment. The ABEP satellites compensate the atmospheric drag through a\ncontinuous thrust provided by collecting, ionizing and accelerating the\nresidual atmospheric particles. It is clear that the feasibility of this\nconcept will require a significant design and testing effort, performed first\non ground and later in orbit. Plasma simulation tools play a fundamental role\nin the development of this technology, for two main reasons: (i) they can\npotentially increase dramatically the optimization and testing process of ABEP\nsystems, since on-ground testing and in-orbit demonstrators are costly and time\nconsuming, and (ii) the fidelity of on-ground testing is limited by the finite\nsize and pumping speed of high-vacuum facilities, as well as the means through\nwhich the orbital flow is produced. In this paper, we demonstrate a one-way\ncoupled, particle-based simulation strategy for a CubeSat sized ABEP system.\nThe neutral flow in the full geometry of the ABEP system comprising the intake\nand the thruster is simulated first through Direct Simulation Monte Carlo.\nThen, the resulting neutral density is used as the input for a Particle-in-Cell\nsimulation of the detailed thruster geometry. The simulations are performed in\n3D and within the VKI in-house code Pantera, taking advantage of the\nfully-implicit energy-conserving scheme.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-17T10:42:59Z"}
{"aid":"http://arxiv.org/abs/2504.12851v1","title":"Optimal Capital Structure for Life Insurance Companies Offering Surplus\n  Participation","summary":"We adapt Leland's dynamic capital structure model to the context of an\ninsurance company selling participating life insurance contracts explaining the\nexistence of life insurance contracts which provide both a guaranteed payment\nand surplus participation to the policyholders. Our derivation of the optimal\nparticipation rate reveals its pronounced sensitivity to the contract duration\nand the associated tax rate. Moreover, the asset substitution effect, which\ndescribes the tendency of equity holders to increase the riskiness of a\ncompany's investment decisions, decreases when adding surplus participation.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-04-17T11:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.12871v1","title":"Improvable Students in School Choice","summary":"The Deferred Acceptance algorithm (DA) frequently produces Pareto inefficient\nallocations in school choice problems. While a number of efficient mechanisms\nthat Pareto-dominate DA are available, a normative question remains unexplored:\nwhich students should benefit from efficiency enhancements? We address it by\nintroducing the concept of \\emph{maximally improvable students}, who benefit in\nevery improvement over DA that includes as many students as possible in\nset-inclusion terms. We prove that common mechanisms such as\nEfficiency-Adjusted DA (EADA) and Top Trading Cycles applied to DA (DA+TTC) can\nfall significantly short of this benchmark. These mechanisms may only improve\ntwo maximally-improvable students when up to $n-1$ could benefit. Addressing\nthis limitation, we develop the Maximum Improvement over DA mechanism (MIDA),\nwhich generates an efficient allocation that maximises the number of students\nimproved over DA. We show that MIDA can generate fewer blocking pairs than EADA\nand DA+TTC, demonstrating that its distributional improvements need not come at\nthe cost of high justified envy.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-17T11:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.12888v1","title":"Anemia, weight, and height among children under five in Peru from 2007\n  to 2022: A Panel Data analysis","summary":"Econometrics in general, and Panel Data methods in particular, are becoming\ncrucial in Public Health Economics and Social Policy analysis. In this\ndiscussion paper, we employ a helpful approach of Feasible Generalized Least\nSquares (FGLS) to assess if there are statistically relevant relationships\nbetween hemoglobin (adjusted to sea-level), weight, and height from 2007 to\n2022 in children up to five years of age in Peru. By using this method, we may\nfind a tool that allows us to confirm if the relationships considered between\nthe target variables by the Peruvian agencies and authorities are in the right\ndirection to fight against chronic malnutrition and stunting.","main_category":"q-bio.PE","categories":"q-bio.PE,econ.EM,stat.AP","published":"2025-04-17T12:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.12889v1","title":"RIS-Assisted Beamfocusing in Near-Field IoT Communication Systems: A\n  Transformer-Based Approach","summary":"The massive number of antennas in extremely large aperture array (ELAA)\nsystems shifts the propagation regime of signals in internet of things (IoT)\ncommunication systems towards near-field spherical wave propagation. We propose\na reconfigurable intelligent surfaces (RIS)-assisted beamfocusing mechanism,\nwhere the design of the two-dimensional beam codebook that contains both the\nangular and distance domains is challenging. To address this issue, we\nintroduce a novel Transformer-based two-stage beam training algorithm, which\nincludes the coarse and fine search phases. The proposed mechanism provides a\nfine-grained codebook with enhanced spatial resolution, enabling precise\nbeamfocusing. Specifically, in the first stage, the beam training is performed\nto estimate the approximate location of the device by using a simple codebook,\ndetermining whether it is within the beamfocusing range (BFR) or the\nnone-beamfocusing range (NBFR). In the second stage, by using a more precise\ncodebook, a fine-grained beam search strategy is conducted. Experimental\nresults unveil that the precision of the RIS-assisted beamfocusing is greatly\nimproved. The proposed method achieves beam selection accuracy up to 97% at\nsignal-to-noise ratio (SNR) of 20 dB, and improves 10% to 50% over the baseline\nmethod at different SNRs.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-17T12:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.12898v1","title":"Information Gain-Guided Causal Intervention for Autonomous Debiasing\n  Large Language Models","summary":"Despite significant progress, recent studies indicate that current large\nlanguage models (LLMs) may still capture dataset biases and utilize them during\ninference, leading to the poor generalizability of LLMs. However, due to the\ndiversity of dataset biases and the insufficient nature of bias suppression\nbased on in-context learning, the effectiveness of previous prior\nknowledge-based debiasing methods and in-context learning based automatic\ndebiasing methods is limited. To address these challenges, we explore the\ncombination of causal mechanisms with information theory and propose an\ninformation gain-guided causal intervention debiasing (IGCIDB) framework. This\nframework first utilizes an information gain-guided causal intervention method\nto automatically and autonomously balance the distribution of\ninstruction-tuning dataset. Subsequently, it employs a standard supervised\nfine-tuning process to train LLMs on the debiased dataset. Experimental results\nshow that IGCIDB can effectively debias LLM to improve its generalizability\nacross different tasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T12:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.12941v1","title":"Osmolyte-Modulated Differential Capacitance and Disjoining Pressure for\n  Nanoconfined Electrolytes: A Modified Poisson-Boltzmann Theory","summary":"This study employs modified Poisson-Boltzmann theory to systematically\ninvestigate the influence of zwitterionic osmolyte additives to an electrolyte\nsolution on disjoining pressure and electric differential capacitance within\ncharged slit-like nanopores with conductive walls. We demonstrate that\nincreasing concentrations of zwitterionic osmolytes result in a marked\nsynergistic enhancement of both disjoining pressure and differential\ncapacitance, highlighting their dual role in improving supercapacitor\nperformance. The insights gained underscore the unique capabilities of\nzwitterionic osmolytes as multifunctional additives for fine-tuning the\nproperties of electric double layers, thereby bridging the gap between\ncapacitive efficiency and electrode longevity.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-17T13:40:05Z"}
{"aid":"http://arxiv.org/abs/2504.12948v1","title":"Algorithms for the Shortest Vector Problem in $2$-dimensional Lattices,\n  Revisited","summary":"Efficiently solving the Shortest Vector Problem (SVP) in two-dimensional\nlattices holds practical significance in cryptography and computational\ngeometry. While simpler than its high-dimensional counterpart, two-dimensional\nSVP motivates scalable solutions for high-dimensional lattices and benefits\napplications like sequence cipher cryptanalysis involving large integers. In\nthis work, we first propose a novel definition of reduced bases and develop an\nefficient adaptive lattice reduction algorithm \\textbf{CrossEuc} that\nstrategically applies the Euclidean algorithm across dimensions. Building on\nthis framework, we introduce \\textbf{HVec}, a vectorized generalization of the\nHalf-GCD algorithm originally defined for integers, which can efficiently halve\nthe bit-length of two vectors and may have independent interest. By iteratively\ninvoking \\textbf{HVec}, our optimized algorithm \\textbf{HVecSBP} achieves a\nreduced basis in $O(\\log n M(n) )$ time for arbitrary input bases with\nbit-length $n$, where $M(n)$ denotes the cost of multiplying two $n$-bit\nintegers. Compared to existing algorithms, our design is applicable to general\nforms of input lattices, eliminating the cost of pre-converting input bases to\nHermite Normal Form (HNF). The comprehensive experimental results demonstrate\nthat for the input lattice bases in HNF, the optimized algorithm\n\\textbf{HVecSBP} achieves at least a $13.5\\times$ efficiency improvement\ncompared to existing methods. For general-form input lattice bases, converting\nthem to HNF before applying \\textbf{HVecSBP} offers only marginal advantages in\nextreme cases where the two basis vectors are nearly degenerate. However, as\nthe linear dependency between input basis vectors decreases, directly employing\n\\textbf{HVecSBP} yields increasingly significant efficiency gains,\noutperforming hybrid approaches that rely on prior \\textbf{HNF} conversion.","main_category":"cs.CG","categories":"cs.CG,cs.CR","published":"2025-04-17T13:50:51Z"}
{"aid":"http://arxiv.org/abs/2504.12950v1","title":"Tensor-monopole-induced topological boundary effects in four-dimensional\n  acoustic metamaterials","summary":"Gauge field theory provides the mathematical and conceptual framework to\ndescribe and understand topological singularities such as Weyl points and\nmagnetic monopoles. While singularities associated with vector electromagnetic\ngauge fields have been well-studied, those of higher-form tensor gauge fields,\nlike the four-dimensional (4D) tensor monopoles predicted by string theory,\nhave remained largely theoretical or limited to experimental demonstration in\npure synthetic dimensions, thereby not allowing investigations of the\nassociated boundary effects. Here, we present a 4D system with tensor monopoles\nusing engineered acoustic metamaterials. Our momentum space combines three real\nmomentum dimensions and a geometric parameter as the fourth. By varying this\nfourth momentum, we experimentally reveal two distinct topological surface\nstates in 3D subsystems: Fermi-arc surface states in a gapless subsystem and\nDirac-cone surface states in a gapped subsystem. Our work introduces a novel\nplatform for exploring new topological structures associated with tensor gauge\nfield and topological phenomena in higher dimensions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T13:51:50Z"}
{"aid":"http://arxiv.org/abs/2504.12965v1","title":"Topological lax comma categories","summary":"This paper investigates the interplay between properties of a topological\nspace $X$, in particular of its natural order, and properties of the lax comma\ncategory $\\mathsf{Top} \\Downarrow X$, where $\\mathsf{Top}$ denotes the category\nof topologicalspaces and continuous maps. Namely, it is shown that, whenever\n$X$ is a topological $\\bigwedge$-semilattice, the canonical forgetful functor\n$\\mathsf{Top} \\Downarrow X \\to \\mathsf{Top}$ is topological, preserves and\nreflects exponentials, and preserves effective descent morphisms. Moreover,\nunder additional conditions on $X$, a characterisation of effective descent\nmorphisms is obtained.","main_category":"math.CT","categories":"math.CT,math.GN","published":"2025-04-17T14:18:42Z"}
{"aid":"http://arxiv.org/abs/2504.12980v1","title":"Motion of ferrodark solitons in harmonically trapped superfluids: spin\n  corrections and emergent quartic potentials exhibiting symmetry breaking","summary":"We propose a framework for topological soliton dynamics in trapped spinor\nsuperfluids, decomposing the force acting on the soliton by the surrounding\nfluid into the buoyancy force and spin-corrections arising from the density\ndepletion at soliton core and the coupling between the orbital motion and the\nspin mixing, respectively. For ferrodark solitons (FDSs) in spin-1\nBose-Einstein Condensates (BECs), the spin correction enables mapping the FDS\nmotion in a harmonic trap to the atomic-mass particle dynamics in an emergent\nquartic potential. Initially placing a type-I FDS near the trap center, a\nsingle-sided oscillation happens, which maps to the particle moving around a\nlocal minimum of the emergent double-well potential. As the initial distance of\na type-II FDS from the trap center increases, the motion exhibits three\nregimes: trap-centered harmonic and anharmonic, followed by single-sided\noscillations. Correspondingly the emergent quartic potential undergoes symmetry\nbreaking, transitioning from a single minimum to a double-well shape, where\nparticle motion shifts from oscillating around the single minimum to crossing\nbetween two minima via the local maximum, then the motion around one of the two\nminima. In a hard-wall trap with linear potential, the FDS motion maps to a\nharmonic oscillator.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,nlin.PS","published":"2025-04-17T14:32:16Z"}
{"aid":"http://arxiv.org/abs/2504.12983v1","title":"Adaptive Modeling of Correlated Noise in Space-Based Gravitational Wave\n  Detectors","summary":"Accurately estimating the statistical properties of noise is important in\nspace-based gravitational wave data analysis. Traditional methods often assume\nuncorrelated noise or impose restrictive parametric forms on cross-channel\ncorrelations, which could lead to biased estimation in complex instrumental\nnoise. This paper introduces a spline-based framework with trans-dimensional\nBayesian inference to reconstruct the full noise covariance matrix, including\nfrequency-dependent auto- and cross-power spectral densities, without prior\nassumptions on noise shapes. The developed software $\\mathtt{NOISAR}$ can\nrecover the features of the noise power spectrum curves with a relative error\n$\\leq 10\\%$ for both auto- and cross-one.","main_category":"astro-ph.IM","categories":"astro-ph.IM,gr-qc","published":"2025-04-17T14:41:56Z"}
{"aid":"http://arxiv.org/abs/2504.13010v1","title":"Simultaneous Polysomnography and Cardiotocography Reveal Temporal\n  Correlation Between Maternal Obstructive Sleep Apnea and Fetal Hypoxia","summary":"Background: Obstructive sleep apnea syndrome (OSAS) during pregnancy is\ncommon and can negatively affect fetal outcomes. However, studies on the\nimmediate effects of maternal hypoxia on fetal heart rate (FHR) changes are\nlacking. Methods: We used time-synchronized polysomnography (PSG) and\ncardiotocography (CTG) data from two cohorts to analyze the correlation between\nmaternal hypoxia and FHR changes (accelerations or decelerations). Maternal\nhypoxic event characteristics were analyzed using generalized linear modeling\n(GLM) to assess their associations with different FHR changes. Results: A total\nof 118 pregnant women participated. FHR changes were significantly associated\nwith maternal hypoxia, primarily characterized by accelerations. A longer\nhypoxic duration correlated with more significant FHR accelerations (P < 0.05),\nwhile prolonged hypoxia and greater SpO2 drop were linked to FHR decelerations\n(P < 0.05). Both cohorts showed a transient increase in FHR during maternal\nhypoxia, which returned to baseline after the event resolved. Conclusion:\nMaternal hypoxia significantly affects FHR, suggesting that maternal OSAS may\ncontribute to fetal hypoxia. These findings highlight the importance of\nmaternal-fetal interactions and provide insights for future interventions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T15:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.13019v1","title":"The higher regularity of the discrete Hardy-Littlewood maximal function","summary":"In a recent short note the first author \\cite{tem} gave the first positive\nresult on the higher order regularity of the discrete noncentered\nHardy-Littlewood maximal function. In this article we conduct a thorough\ninvestigation of possible similar results for higher order derivatives. We\nuncover that such results are indeed a consequence of a stronger phenomenon\nregarding the growth of $l^p(\\Z)$ norms of the derivatives of characteristic\nfunctions of finite subsets of $\\Z$. Along the way we discover very interesting\nconnections to Prouhot-Tarry-Escott (PTE) problem, and to zeros of complex\npolynomials with restricted coefficients (Littlewood-type polynomials).","main_category":"math.CA","categories":"math.CA","published":"2025-04-17T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.13098v1","title":"Irradiation Studies of the Resistive AC-coupled Silicon Detector\n  (RSD/AC-LGAD)","summary":"Resistive AC-coupled Silicon Detectors (RSDs) are silicon sensors which\nprovide high temporal and spatial resolution. The RSD is a candidate sensor to\nbe used in future tracking detectors with the objective of obtaining '4D'\ntracking, where timing information can be used along with spatial hits during\ntrack finding. 4D tracking will be an essential part of any future lepton or\nhadron collider and may even be feasible at the HL-LHC. For applications at\nhadron colliders, RSD sensors must be able to operate in high fluence\nenvironments in order to provide 4D tracking. However, the effects of radiation\non RSDs have not been extensively studied. In this study, RSDs were irradiated\nto $1.0$, $2.0$, and $3.5 \\times 10^{15}$~cm$^{-2}$ (1~MeV neutron equivalents)\nwith both protons and neutrons. The sensors were then characterized\nelectrically to study the acceptor removal and, for the first time in this\ndoping concentration range, the donor removal. Then, the Transient Current\nTechnique was used to begin investigating the signal charge sharing after\nirradiation. The results suggest an interesting trend between acceptor and\ndonor removal, which is worthy of further study and could assist in improving\nradiation hardness of Low Gain Avalanche Diodes (LGADs).","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-17T17:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.13110v1","title":"Propagation of Chaos in One-hidden-layer Neural Networks beyond\n  Logarithmic Time","summary":"We study the approximation gap between the dynamics of a polynomial-width\nneural network and its infinite-width counterpart, both trained using projected\ngradient descent in the mean-field scaling regime. We demonstrate how to\ntightly bound this approximation gap through a differential equation governed\nby the mean-field dynamics. A key factor influencing the growth of this ODE is\nthe local Hessian of each particle, defined as the derivative of the particle's\nvelocity in the mean-field dynamics with respect to its position. We apply our\nresults to the canonical feature learning problem of estimating a\nwell-specified single-index model; we permit the information exponent to be\narbitrarily large, leading to convergence times that grow polynomially in the\nambient dimension $d$. We show that, due to a certain ``self-concordance''\nproperty in these problems -- where the local Hessian of a particle is bounded\nby a constant times the particle's velocity -- polynomially many neurons are\nsufficient to closely approximate the mean-field dynamics throughout training.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-17T17:24:38Z"}
{"aid":"http://arxiv.org/abs/2504.13135v1","title":"Probing CP-Violating Neutral Triple Gauge Couplings at Electron-Positron\n  Colliders","summary":"We study the forms of CP-violating (CPV) neutral triple gauge couplings\n(nTGCs) that can be realized via dimension-8 operators in the Standard Model\nEffective Field Theory (SMEFT). We present a new formulation of the CPV nTGC\nform factors that is compatible with the spontaneous breaking of the\nelectroweak gauge symmetry, and show how these CPV form factors can be matched\nconsistently with the corresponding dimension-8 CPV nTGC operators in the\nbroken phase. We then study probes of the CPV nTGCs at future high-energy\n$e^+e^-$ colliders with centre-of-mass energies $\\sqrt{s} = (0.25, 0.5,1, 3,\n5)$TeV respectively, demonstrating that the $e^{\\mp}$ beam polarizations can\nhelp to improve the sensitivities of probes of the nTGCs. We estimate that the\nsensitivities for probing the new physics scales of the nTGCs can range from\n${O}(\\rm{TeV})$ at a 250GeV $e^+e^-$ collider to ${O}(10\\rm{TeV})$ at a 5TeV\n$e^+e^-$ collider, and that the sensitivities to form factors range from\n${O}(10^{-4})$ to ${O}(10^{-8})$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T17:47:54Z"}
{"aid":"http://arxiv.org/abs/2504.13147v1","title":"Purely gravitational dark matter production in warm inflation","summary":"We consider an appealing scenario for the production of purely gravitational\ndark matter in the background of warm inflation, a mechanism that maintains\nstable thermal bath during inflation. Through systematic investigation of\nvarious gravitational production channels, we reveal distinctive features\ncompared to the standard inflation scenario. Notably, the inflaton annihilation\nchannel in warm inflation exhibits markedly different thermodynamics from the\nstandard inflation paradigm, leading to a suppression on the production of\nsub-inflaton-mass dark matter. For the production channel of inflationary\nvacuum fluctuations, we find a correlation of $\\rho_\\chi\\propto m_\\chi^{5/2}$\nfor the conformally coupled dark matter, which expands the feasible range of\ndark matter mass. Our results also indicates that a minimum temperature\nthreshold of $10^{-6}M_P$ is necessary for warm inflation, which allows\nadequate dark matter production. With observational constraints, our results\nprovide stringent limits on the mass range of purely gravitational dark matter\nwith sufficient density: $10^{-8}-10^{-2}M_P$ for minimal coupling and\n$10^{-14}-10^{-2}M_P$ for conformal coupling.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-17T17:54:40Z"}
{"aid":"http://arxiv.org/abs/2504.14829v1","title":"$\\mathrm{M}$-ideals: from Banach spaces to rings","summary":"We introduce and investigate a class of ring ideals, termed ring\n$\\mathrm{M}$-ideals, inspired by the Alfsen--Effros theory of\n$\\mathrm{M}$-ideals in Banach spaces. We show that $\\mathrm{M}$-ideals extend\nthe classical notion of essential ideals and subsume them as a subclass. The\ncentral theorem provides a full characterization: an ideal is an\n$\\mathrm{M}$-ideal if and only if it is either essential or relatively\nirreducible. This dichotomy reveals the abundant and diverse nature of\n$\\mathrm{M}$-ideals, encompassing both essential and minimal ideals, and admits\nnatural generalizations in rings beyond the commutative and unital settings.\n  We systematically study the algebraic stability of $\\mathrm{M}$-ideals under\nstandard constructions such as intersection, quotient, direct product, and\nMorita equivalence and establish their behavior in topological rings and\noperator algebras. In certain rings such as $\\mathbb{Z}_n$ and C*-algebras, we\ncompletely classify $\\mathrm{M}$-ideals and relate them to algebraically\nminimal projections and central idempotents. The ring $\\mathrm{M}$-ideals in\n$C(K)$ are shown to be precisely the essential ideals or those minimal ideals\ncorresponding to isolated points.\n  Structurally, we show that the absence of proper $\\mathrm{M}$-ideals\ncharacterizes simplicity, while rings in which every proper $\\mathrm{M}$-ideal\nis a direct summand must decompose as finite direct sums of simple rings. In\nclosing, we introduce the notion of $\\mathrm{M}$-complements, drawing an\nanalogy with essential extensions in module theory, and demonstrate their\nexistence.","main_category":"math.RA","categories":"math.RA","published":"2025-04-21T03:13:39Z"}
{"aid":"http://arxiv.org/abs/2504.14838v1","title":"Establishing Reliability Metrics for Reward Models in Large Language\n  Models","summary":"The reward model (RM) that represents human preferences plays a crucial role\nin optimizing the outputs of large language models (LLMs), e.g., through\nreinforcement learning from human feedback (RLHF) or rejection sampling.\nHowever, a long challenge for RM is its uncertain reliability, i.e., LLM\noutputs with higher rewards may not align with actual human preferences.\nCurrently, there is a lack of a convincing metric to quantify the reliability\nof RMs. To bridge this gap, we propose the \\textit{\\underline{R}eliable at\n\\underline{$\\eta$}} (RETA) metric, which directly measures the reliability of\nan RM by evaluating the average quality (scored by an oracle) of the top $\\eta$\nquantile responses assessed by an RM. On top of RETA, we present an integrated\nbenchmarking pipeline that allows anyone to evaluate their own RM without\nincurring additional Oracle labeling costs. Extensive experimental studies\ndemonstrate the superior stability of RETA metric, providing solid evaluations\nof the reliability of various publicly available and proprietary RMs. When\ndealing with an unreliable RM, we can use the RETA metric to identify the\noptimal quantile from which to select the responses.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T03:39:33Z"}
{"aid":"http://arxiv.org/abs/2504.14911v1","title":"Lusztig sheaves, decomposition rule and restriction rule","summary":"In this article, we realize the subquotient based modules of certain tensor\nproducts or restricted modules via Lusztig's perverse sheaves on multi-framed\nquivers, and provide a construction of their canonical bases. As an\napplication, we prove that the decomposition and restriction coefficients of\nsymmetric Kac-Moody algebras equal to the dimensions of top Borel-Moore\nhomology groups for certain locally closed subsets of Nakajima's quiver\nvarieties.","main_category":"math.RT","categories":"math.RT,math.AG,math.QA","published":"2025-04-21T07:31:09Z"}
{"aid":"http://arxiv.org/abs/2504.14944v1","title":"Haloscope Searching for Dark Photons at Q-band with a Novel Coupling\n  Tuning Structure","summary":"Laboratory searching for dark matter is crucial for understanding several\nfundamental conundrums in physics and cosmology. Most cavity-based haloscope\nsearches focus on the frequency range below 10 GHz, while the parameter space\nwith higher frequency remains rarely explored, due to the challenges lying in\nthe fabrication of microwave cavities. Here we report the first Q-band\nhaloscope searching for dark photons with a 33.141 GHz cavity. A novel coupling\ntuning structure separated from the cavity was designed so as not to degrade\nthe quality factor of the cavity. We have established the most stringent\nconstraints $\\chi<2.5\\times10^{-12}$ at a confidence level of 90$\\%$ in the\nfrequency range from 33.139 GHz to 33.143 GHz, corresponding to the mass of\ndark photons ranging from 137.05 $\\mu$eV to 137.07 $\\mu$eV. The results surpass\nthe previous astronomical constraints by nearly three orders of magnitude. This\nwork has demonstrated the feasibility of dark matter haloscopes at Q band. In\nthe future, the constraints can be further improved by more than one order of\nmagnitude through low-temperature experiments, and the setup can be extended to\nsearch for axions, axion-like particles, and high-frequency gravitational\nwaves.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ex","published":"2025-04-21T08:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.14945v1","title":"Learning to Reason under Off-Policy Guidance","summary":"Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning (RL) with simple rule-based rewards. However,\nexisting zero-RL approaches are inherently ``on-policy'', limiting learning to\na model's own outputs and failing to acquire reasoning abilities beyond its\ninitial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY\nguidance), a framework that augments zero-RL with off-policy reasoning traces.\nLUFFY dynamically balances imitation and exploration by combining off-policy\ndemonstrations with on-policy rollouts during training. Notably, we propose\npolicy shaping via regularized importance sampling to avoid superficial and\nrigid imitation during mixed-policy training. Remarkably, LUFFY achieves an\nover +7.0 average gain across six math benchmarks and an advantage of over +6.2\npoints in out-of-distribution tasks. It also substantially surpasses\nimitation-based supervised fine-tuning (SFT), particularly in generalization.\nAnalysis shows LUFFY not only imitates effectively but also explores beyond\ndemonstrations, offering a scalable path to train generalizable reasoning\nmodels with off-policy guidance.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-21T08:09:13Z"}
{"aid":"http://arxiv.org/abs/2504.14952v1","title":"PIV-FlowDiffuser:Transfer-learning-based denoising diffusion models for\n  PIV","summary":"Deep learning algorithms have significantly reduced the computational time\nand improved the spatial resolution of particle image velocimetry~(PIV).\nHowever, the models trained on synthetic datasets might have a degraded\nperformance on practical particle images due to domain gaps. As a result,\nspecial residual patterns are often observed for the vector fields of deep\nlearning-based estimators. To reduce the special noise step-by-step, we employ\na denoising diffusion model~(FlowDiffuser) for PIV analysis. And the\ndata-hungry iterative denoising diffusion model is trained via a transfer\nlearning strategy, resulting in our PIV-FlowDiffuser method. Specifically, (1)\npre-training a FlowDiffuser model with multiple optical flow datasets of the\ncomputer vision community, such as Sintel, KITTI, etc; (2) fine-tuning the\npre-trained model on synthetic PIV datasets. Note that the PIV images are\nupsampled by a factor of two to resolve the small-scale turbulent flow\nstructures. The visualized results indicate that our PIV-FlowDiffuser\neffectively suppresses the noise patterns. Therefore, the denoising diffusion\nmodel reduces the average end-point error~($AEE$) by 59.4% over RAFT256-PIV\nbaseline on the classic Cai's dataset. Besides, PIV-FlowDiffuser exhibits\nenhanced generalization performance on unseen particle images due to transfer\nlearning. Overall, this study highlights the transfer-learning-based denoising\ndiffusion models for PIV. And a detailed implementation is recommended for\ninterested readers in the repository\nhttps://github.com/Zhu-Qianyu/PIV-FlowDiffuser.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-21T08:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.14980v1","title":"Bayesian model selection of Primordial Black Holes and Dressed\n  Primordial Black Holes with lensed Gravitational Waves","summary":"If particle dark matter (DM) and primordial black holes (PBHs) coexist, PBHs\nwill be surrounded by particle DM, forming celestial objects known as dressed\nPBHs (dPBHs). These structures suggest a scenario in which PBHs and DM can\nexist simultaneously. However, in the high-frequency regime, the gravitational\nlensing effect of bare PBHs is similar to that of dPBHs. Ground-based\ngravitational wave (GW) detectors are particularly sensitive to high-frequency\nGW signals. In this regime, the lensing effect of a point-mass lens with a mass\nin the range of $10^{-1} \\sim 10^2 M_{\\odot}$ becomes significant. In this\nwork, we incorporate dPBH models with GW observations and employ Bayesian\ninference techniques to distinguish PBHs from dPBHs. Using the third-generation\nground-based GW detectors, Einstein Telescope (ET) and Cosmic Explorer (CE), as\nexamples, we demonstrate that these detectors can effectively differentiate the\nlensing effects of dPBHs from those of PBHs across a broad frequency range.\nFurthermore, we find that with a larger black hole (BH) mass inside the\nsurrounding particle DM, ET and CE can distinguish these two lensed models with\neven greater precision.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-21T09:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.14991v1","title":"Understanding Accuracy-Fairness Trade-offs in Re-ranking through\n  Elasticity in Economics","summary":"Fairness is an increasingly important factor in re-ranking tasks. Prior work\nhas identified a trade-off between ranking accuracy and item fairness. However,\nthe underlying mechanisms are still not fully understood. An analogy can be\ndrawn between re-ranking and the dynamics of economic transactions. The\naccuracy-fairness trade-off parallels the coupling of the commodity tax\ntransfer process. Fairness considerations in re-ranking, similar to a commodity\ntax on suppliers, ultimately translate into a cost passed on to consumers.\nAnalogously, item-side fairness constraints result in a decline in user-side\naccuracy. In economics, the extent to which commodity tax on the supplier (item\nfairness) transfers to commodity tax on users (accuracy loss) is formalized\nusing the notion of elasticity. The re-ranking fairness-accuracy trade-off is\nsimilarly governed by the elasticity of utility between item groups. This\ninsight underscores the limitations of current fair re-ranking evaluations,\nwhich often rely solely on a single fairness metric, hindering comprehensive\nassessment of fair re-ranking algorithms. Centered around the concept of\nelasticity, this work presents two significant contributions. We introduce the\nElastic Fairness Curve (EF-Curve) as an evaluation framework. This framework\nenables a comparative analysis of algorithm performance across different\nelasticity levels, facilitating the selection of the most suitable approach.\nFurthermore, we propose ElasticRank, a fair re-ranking algorithm that employs\nelasticity calculations to adjust inter-item distances within a curved space.\nExperiments on three widely used ranking datasets demonstrate its effectiveness\nand efficiency.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-21T09:41:08Z"}
{"aid":"http://arxiv.org/abs/2504.15028v1","title":"A Controllable Appearance Representation for Flexible Transfer and\n  Editing","summary":"We present a method that computes an interpretable representation of material\nappearance within a highly compact, disentangled latent space. This\nrepresentation is learned in a self-supervised fashion using an adapted\nFactorVAE. We train our model with a carefully designed unlabeled dataset,\navoiding possible biases induced by human-generated labels. Our model\ndemonstrates strong disentanglement and interpretability by effectively\nencoding material appearance and illumination, despite the absence of explicit\nsupervision. Then, we use our representation as guidance for training a\nlightweight IP-Adapter to condition a diffusion pipeline that transfers the\nappearance of one or more images onto a target geometry, and allows the user to\nfurther edit the resulting appearance. Our approach offers fine-grained control\nover the generated results: thanks to the well-structured compact latent space,\nusers can intuitively manipulate attributes such as hue or glossiness in image\nspace to achieve the desired final appearance.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-21T11:29:06Z"}
{"aid":"http://arxiv.org/abs/2504.15030v1","title":"Height-Dependent Slow Magnetoacoustic Wave Amplitude and Energy Flux in\n  Sunspot Atmospheres","summary":"Slow magnetoacoustic waves (SMAWs) have been considered in the past as a\npossible candidate for chromospheric heating. This study analyzes 20 active\nregions observed between 2012 and 2016 to examine the amplitude and energy flux\nvariation of SMAWs in the umbral atmosphere. Six different wavelength channels\nfrom the Atmospheric Imaging Assembly onboard the Solar Dynamics Observatory,\ncovering regions from the photosphere to the low corona, were utilized for this\npurpose. The wave amplitude estimations show a gradual increase in 3-minute\noscillation amplitude, peaking between 700--900 km, followed by a steady\ndecrease; at altitudes greater than 1800 km, the amplitude appears to increase\nand then decrease again. The corresponding energy flux, on the other hand,\ndisplays a steady and monotonous decrease with a significant reduction in value\nfrom approximately $3.32 \\pm 0.50~\\mathrm{kW,m^{-2}}$ near the photosphere to\nabout $(6.47 \\pm 3.16) \\times 10^{-4}~\\mathrm{W,m^{-2}}$ at an altitude of 2585\nkm. This decay may be attributed to radiative damping and shock dissipation in\nthe lower altitudes, and thermal conduction and viscosity in the higher\naltitudes. The missing flux is a factor of 3--15 lower than that required to\ncounterbalance the chromospheric radiative losses.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T11:35:41Z"}
{"aid":"http://arxiv.org/abs/2504.15066v1","title":"Chinese-LiPS: A Chinese audio-visual speech recognition dataset with\n  Lip-reading and Presentation Slides","summary":"Incorporating visual modalities to assist Automatic Speech Recognition (ASR)\ntasks has led to significant improvements. However, existing Audio-Visual\nSpeech Recognition (AVSR) datasets and methods typically rely solely on\nlip-reading information or speaking contextual video, neglecting the potential\nof combining these different valuable visual cues within the speaking context.\nIn this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,\ncomprising 100 hours of speech, video, and corresponding manual transcription,\nwith the visual modality encompassing both lip-reading information and the\npresentation slides used by the speaker. Based on Chinese-LiPS, we develop a\nsimple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and\npresentation slide information as visual modalities for AVSR tasks. Experiments\nshow that lip-reading and presentation slide information improve ASR\nperformance by approximately 8\\% and 25\\%, respectively, with a combined\nperformance improvement of about 35\\%. The dataset is available at\nhttps://kiri0824.github.io/Chinese-LiPS/","main_category":"cs.MM","categories":"cs.MM,cs.AI","published":"2025-04-21T12:51:54Z"}
{"aid":"http://arxiv.org/abs/2504.15074v1","title":"The orientation dynamics of a massive ellipsoid in simple shear flow","summary":"The orientation dynamics of a massive rigid ellipsoid in simple shear flow of\na Newtonian fluid is investigated in detail. The term `massive' refers to\ndominant particle inertia, as characterized by $St \\gg 1$, $St =\n\\dot{\\gamma}l^2\\rho_p/\\nu \\rho_f$ being the Stokes number; here, $\\dot{\\gamma}$\nis the shear rate, $\\nu$ is the kinematic viscosity, $l$ is a characteristic\nellipsoidal dimension (taken to be the longest semi axis), and $\\rho_p$ and\n$\\rho_f$ are the particle and fluid densities, respectively. Fluid inertial\neffects are neglected, so the particle Reynolds number ($Re$) is zero. The\nequations of motion of the ellipsoid in this limit reduce to those governing an\nEuler top, supplemented by a weak viscous torque. The dynamics consists of a\nfast conservative motion on time scales of $O(\\dot{\\gamma}^{-1})$ that, for an\nellipsoid, involves a combination of spin, precession and nutation, and a\nslower component driven by the viscous torque; the latter modulates the angular\nmomentum and rotational kinetic energy on asymptotically longer time scales of\n$O(St{\\dot{\\gamma}}^{-1})$. The separation of time scales for large $St$ allows\nfor use of the method of averaging for a triaxial ellipsoid, to derive an\nautonomous system of ODE's that govern motion on a four-dimensional slow\nmanifold consisting of the three angular momenta and the rotational kinetic\nenergy. There are three fixed points on the slow manifold, with rotation about\nthe shortest axis being stable. The fixed point corresponding to rotation about\nthe longest axis is a saddle point, while intermediate-axis-aligned rotation\ncorresponds to a singular fixed point. For spheroids, the singular fixed point\nmerges with one of the other two, leading to only two fixed points, one a\nstable node and the other a saddle; the former corresponds to rotation about\nthe shorter axis.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-21T13:03:22Z"}
{"aid":"http://arxiv.org/abs/2504.15078v1","title":"High-Precision and Wafer-Scale Transfer Lithography of Commercial\n  Photoresists via Reversible Adhesion for Sustainable Microfabrication on\n  Diverse Substrates","summary":"Photolithography conventionally requires flat and rigid substrates, limiting\nits applications in flexible, curved, and transient electronics. Here, we\nreport a breakthrough approach employing a reversibly adhesion-switchable\nphase-changing polymer to transfer commercial photoresists onto previously\ninaccessible substrates. It achieves wafer-scale (4-inch) transfer with global\nregistration error below 60 microns and support precise patterning on\nsolvent-sensitive, curved, microtextured or delicate surfaces. Combined with\ndry etching, we demonstrated high-resolution patterning of quantum dots and\norganic semiconductors. The process also supports a sustainable dry lift-off\nfor patterning functional materials. The reusability of both the transfer\ncarrier and photoresist introduces a new level of sustainability and\nscalability, establishing a significant advancement in microfabrication. We\nadditionally fabricated a micro-sized UV-photodetector array directly on a\ncurved glass bottle to demonstrate this unprecedented capability.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-21T13:08:04Z"}
{"aid":"http://arxiv.org/abs/2504.15145v1","title":"\"I Know It When I See It\": Mood Spaces for Connecting and Expressing\n  Visual Concepts","summary":"Expressing complex concepts is easy when they can be labeled or quantified,\nbut many ideas are hard to define yet instantly recognizable. We propose a Mood\nBoard, where users convey abstract concepts with examples that hint at the\nintended direction of attribute changes. We compute an underlying Mood Space\nthat 1) factors out irrelevant features and 2) finds the connections between\nimages, thus bringing relevant concepts closer. We invent a fibration\ncomputation to compress/decompress pre-trained features into/from a compact\nspace, 50-100x smaller. The main innovation is learning to mimic the pairwise\naffinity relationship of the image tokens across exemplars. To focus on the\ncoarse-to-fine hierarchical structures in the Mood Space, we compute the top\neigenvector structure from the affinity matrix and define a loss in the\neigenvector space. The resulting Mood Space is locally linear and compact,\nallowing image-level operations, such as object averaging, visual analogy, and\npose transfer, to be performed as a simple vector operation in Mood Space. Our\nlearning is efficient in computation without any fine-tuning, needs only a few\n(2-20) exemplars, and takes less than a minute to learn.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:49:15Z"}
{"aid":"http://arxiv.org/abs/2504.15151v1","title":"Artificial compressibility method for the incompressible Navier-Stokes\n  equations with variable density","summary":"We introduce a novel artificial compressibility technique to approximate the\nincompressible Navier-Stokes equations with variable fluid properties such as\ndensity and dynamical viscosity. The proposed scheme used the couple pressure\nand momentum, equal to the density times the velocity, as primary unknowns. It\nalso involves an adequate treatment of the diffusive operator such that\ntreating the nonlinear convective term explicitly leads to a scheme with time\nindependent stiffness matrices that is suitable for pseudo-spectral methods.\nThe stability and temporal convergence of the semi-implicit version of the\nscheme is established under the hypothesis that the density is approximated\nwith a method that conserves the minimum-maximum principle. Numerical\nillustrations confirm that both the semi-implicit and explicit scheme are\nstable and converge with order one under classic CFL condition. Moreover, the\nproposed scheme is shown to perform better than a momentum based pressure\nprojection method, previously introduced by one of the authors, on setups\ninvolving gravitational waves and immiscible multi-fluids in a cylinder.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-21T14:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.15201v1","title":"Phase-separated lipid vesicles: continuum modeling, simulation, and\n  validation","summary":"The paper presents a complete research cycle comprising continuum-based\nmodeling, computational framework development, and validation setup to predict\nphase separation and surface hydrodynamics in lipid bilayer membranes. We\nstarting with an overview of the key physical characteristics of lipid\nbilayers, including their composition, mechanical properties, and\nthermodynamics, and then discuss continuum models of multi-component bilayers.\nThe most complex model is a Navier--Stokes--Cahn--Hilliard (NSCH) type system,\ndescribing the coupling of incompressible surface fluid dynamics with\nphase-field dynamics on arbitrarily curved geometries. It is discretized using\ntrace finite element methods, which offer geometric flexibility and stability\nin representing surface PDEs. Numerical studies are conducted to examine\nphysical features such as coarsening rates and interfacial dynamics. The\ncomputational results obtained from the NSCH model are compared against\nexperimental data for membrane compositions with distinct phase behaviors,\ndemonstrating that including both phase-field models and surface hydrodynamics\nis essential to accurately reproduce domain evolution observed in\nepi-fluorescence microscopy. Lastly, we extend the model to incorporate\nexternal forces that enable the simulation of vesicles containing cationic\nlipids, used to enhance membrane fusion.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-21T16:17:39Z"}
{"aid":"http://arxiv.org/abs/2504.15204v1","title":"Soft-Output from Covered Space Decoding of Product Codes","summary":"In this work, we propose a new soft-in soft-out decoder called soft-output\nfrom covered space (SOCS) decoder. It estimates the a posteriori reliability\nbased on the space explored by a list decoder, i.e., the set of vectors for\nwhich the list decoder knows whether they are codewords. This approach enables\na more accurate calculation of the a posteriori reliability and results in\ngains of up to 0.25$\\,$dB for turbo product decoding with SOCS decoding\ncompared to Chase-Pyndiah decoding.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T16:20:13Z"}
{"aid":"http://arxiv.org/abs/2504.15210v1","title":"Integrating Symbolic Execution into the Fine-Tuning of Code-Generating\n  LLMs","summary":"Code-generating Large Language Models (LLMs) have become essential tools in\nmodern software development, enhancing productivity and accelerating\ndevelopment. This paper aims to investigate the fine-tuning of code-generating\nLLMs using Reinforcement Learning and Direct Preference Optimization, further\nimproving their performance. To achieve this, we enhance the training data for\nthe reward model with the help of symbolic execution techniques, ensuring more\ncomprehensive and objective data. With symbolic execution, we create a custom\ndataset that better captures the nuances in code evaluation. Our reward models,\nfine-tuned on this dataset, demonstrate significant improvements over the\nbaseline, CodeRL, in estimating the quality of generated code. Our\ncode-generating LLMs, trained with the help of reward model feedback, achieve\nsimilar results compared to the CodeRL benchmark.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-21T16:29:07Z"}
{"aid":"http://arxiv.org/abs/2504.15220v1","title":"Fully Bayesian Approaches to Topics over Time","summary":"The Topics over Time (ToT) model captures thematic changes in timestamped\ndatasets by explicitly modeling publication dates jointly with word\nco-occurrence patterns. However, ToT was not approached in a fully Bayesian\nfashion, a flaw that makes it susceptible to stability problems. To address\nthis issue, we propose a fully Bayesian Topics over Time (BToT) model via the\nintroduction of a conjugate prior to the Beta distribution. This prior acts as\na regularization that prevents the online version of the algorithm from\nunstable updates when a topic is poorly represented in a mini-batch. The\ncharacteristics of this prior to the Beta distribution are studied here for the\nfirst time. Still, this model suffers from a difference in scale between the\nsingle-time observations and the multiplicity of words per document. A\nvariation of BToT, Weighted Bayesian Topics over Time (WBToT), is proposed as a\nsolution. In WBToT, publication dates are repeated a certain number of times\nper document, which balances the relative influence of words and timestamps\nalong the inference process. We have tested our models on two datasets: a\ncollection of over 200 years of US state-of-the-union (SOTU) addresses and a\nlarge-scale COVID-19 Twitter corpus of 10 million tweets. The results show that\nWBToT captures events better than Latent Dirichlet Allocation and other SOTA\ntopic models like BERTopic: the median absolute deviation of the topic presence\nover time is reduced by $51\\%$ and $34\\%$, respectively. Our experiments also\ndemonstrate the superior coherence of WBToT over BToT, which highlights the\nimportance of balancing the time and word modalities. Finally, we illustrate\nthe stability of the online optimization algorithm in WBToT, which allows the\napplication of WBToT to problems that are intractable for standard ToT.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-21T16:46:07Z"}
{"aid":"http://arxiv.org/abs/2504.15224v1","title":"On Extension modules of finite homological dimension","summary":"We explore the implications of the finiteness of homological dimensions for\nExt modules, focusing on projective dimension, injective dimension, and their\nGorenstein counterpart. In this direction, we establish several finiteness\ncriteria for homological dimensions. Our results include the consequences of\nthe finiteness of the Gorenstein (injective) dimension of the deficiency\nmodules as well as a duality for certain Ext modules, all of finite\n(Gorenstein) projective dimension.","main_category":"math.AC","categories":"math.AC","published":"2025-04-21T16:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.15226v1","title":"A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space\n  Servicing","summary":"Automation of robotic systems for servicing in cislunar space is becoming\nextremely important as the number of satellites in orbit increases. Safety is\ncritical in performing satellite maintenance, so the control techniques\nutilized must be trusted in addition to being highly efficient. In this work,\nGenetic Fuzzy Trees are combined with the widely used LQR control scheme via\nThales' TrUE AI Toolkit to create a trusted and efficient controller for a\ntwo-degree-of-freedom planar robotic manipulator that would theoretically be\nused to perform satellite maintenance. It was found that Genetic Fuzzy-LQR is\n18.5% more performant than optimal LQR on average, and that it is incredibly\nrobust to uncertainty.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.SY,eess.SY","published":"2025-04-21T16:57:56Z"}
{"aid":"http://arxiv.org/abs/2504.15263v1","title":"Interpretable Locomotion Prediction in Construction Using a\n  Memory-Driven LLM Agent With Chain-of-Thought Reasoning","summary":"Construction tasks are inherently unpredictable, with dynamic environments\nand safety-critical demands posing significant risks to workers. Exoskeletons\noffer potential assistance but falter without accurate intent recognition\nacross diverse locomotion modes. This paper presents a locomotion prediction\nagent leveraging Large Language Models (LLMs) augmented with memory systems,\naimed at improving exoskeleton assistance in such settings. Using multimodal\ninputs - spoken commands and visual data from smart glasses - the agent\nintegrates a Perception Module, Short-Term Memory (STM), Long-Term Memory\n(LTM), and Refinement Module to predict locomotion modes effectively.\nEvaluation reveals a baseline weighted F1-score of 0.73 without memory, rising\nto 0.81 with STM, and reaching 0.90 with both STM and LTM, excelling with vague\nand safety-critical commands. Calibration metrics, including a Brier Score drop\nfrom 0.244 to 0.090 and ECE from 0.222 to 0.044, affirm improved reliability.\nThis framework supports safer, high-level human-exoskeleton collaboration, with\npromise for adaptive assistive systems in dynamic industries.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:45:21Z"}
{"aid":"http://arxiv.org/abs/2504.15267v1","title":"Diffusion Bridge Models for 3D Medical Image Translation","summary":"Diffusion tensor imaging (DTI) provides crucial insights into the\nmicrostructure of the human brain, but it can be time-consuming to acquire\ncompared to more readily available T1-weighted (T1w) magnetic resonance imaging\n(MRI). To address this challenge, we propose a diffusion bridge model for 3D\nbrain image translation between T1w MRI and DTI modalities. Our model learns to\ngenerate high-quality DTI fractional anisotropy (FA) images from T1w images and\nvice versa, enabling cross-modality data augmentation and reducing the need for\nextensive DTI acquisition. We evaluate our approach using perceptual\nsimilarity, pixel-level agreement, and distributional consistency metrics,\ndemonstrating strong performance in capturing anatomical structures and\npreserving information on white matter integrity. The practical utility of the\nsynthetic data is validated through sex classification and Alzheimer's disease\nclassification tasks, where the generated images achieve comparable performance\nto real data. Our diffusion bridge model offers a promising solution for\nimproving neuroimaging datasets and supporting clinical decision-making, with\nthe potential to significantly impact neuroimaging research and clinical\npractice.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T17:49:06Z"}
{"aid":"http://arxiv.org/abs/2504.15568v1","title":"Is Learning Effective in Dynamic Strategic Interactions? Evidence from\n  Stackelberg Games","summary":"In many settings of interest, a policy is set by one party, the leader, in\norder to influence the action of another party, the follower, where the\nfollower's response is determined by some private information. A natural\nquestion to ask is, can the leader improve their strategy by learning about the\nunknown follower through repeated interactions? A well known folk theorem from\ndynamic pricing, a special case of this leader-follower setting, would suggest\nthat the leader cannot learn effectively from the follower when the follower is\nfully strategic, leading to a large literature on learning in strategic\nsettings that relies on limiting the strategic space of the follower in order\nto provide positive results. In this paper, we study dynamic Bayesian\nStackelberg games, where a leader and a \\emph{fully strategic} follower\ninteract repeatedly, with the follower's type unknown. Contrary to existing\nresults, we show that the leader can improve their utility through learning in\nrepeated play. Using a novel average-case analysis, we demonstrate that\nlearning is effective in these settings, without needing to weaken the\nfollower's strategic space. Importantly, this improvement is not solely due to\nthe leader's ability to commit, nor does learning simply substitute for\ncommunication between the parties. We provide an algorithm, based on a\nmixed-integer linear program, to compute the optimal leader policy in these\ngames and develop heuristic algorithms to approximate the optimal dynamic\npolicy more efficiently. Through simulations, we compare the efficiency and\nruntime of these algorithms against static policies.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-22T03:44:05Z"}
{"aid":"http://arxiv.org/abs/2504.15620v1","title":"Observation of topology of non-Hermitian systems without chiral symmetry","summary":"Topological invariants are crucial for characterizing topological systems.\nHowever, experimentally measuring them presents a significant challenge,\nespecially in non-Hermitian systems where the biorthogonal eigenvectors are\noften necessary. We propose a general approach for measuring the topological\ninvariants of one-dimensional non-Hermitian systems, which can be derived from\nthe spin textures of right eigenstates. By utilizing a dilation method, we\nrealize a non-Hermitian system without chiral symmetry on a two-qubit nuclear\nmagnetic resonance system and measure the winding number associated with the\neigenstates. In addition to examining the topology of the eigenstates, our\nexperiment also reveals the topological structure of the energy band, which\ndiffers from that in chiral systems. Our work paves the way for further\nexploration of complex topological properties in non-Hermitian systems without\nchiral symmetry.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T06:21:24Z"}
{"aid":"http://arxiv.org/abs/2504.15622v1","title":"Exploring the Role of Large Language Models in Cybersecurity: A\n  Systematic Survey","summary":"With the rapid development of technology and the acceleration of\ndigitalisation, the frequency and complexity of cyber security threats are\nincreasing. Traditional cybersecurity approaches, often based on static rules\nand predefined scenarios, are struggling to adapt to the rapidly evolving\nnature of modern cyberattacks. There is an urgent need for more adaptive and\nintelligent defence strategies. The emergence of Large Language Model (LLM)\nprovides an innovative solution to cope with the increasingly severe cyber\nthreats, and its potential in analysing complex attack patterns, predicting\nthreats and assisting real-time response has attracted a lot of attention in\nthe field of cybersecurity, and exploring how to effectively use LLM to defend\nagainst cyberattacks has become a hot topic in the current research field. This\nsurvey examines the applications of LLM from the perspective of the cyber\nattack lifecycle, focusing on the three phases of defense reconnaissance,\nfoothold establishment, and lateral movement, and it analyzes the potential of\nLLMs in Cyber Threat Intelligence (CTI) tasks. Meanwhile, we investigate how\nLLM-based security solutions are deployed and applied in different network\nscenarios. It also summarizes the internal and external risk issues faced by\nLLM during its application. Finally, this survey also points out the facing\nrisk issues and possible future research directions in this domain.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-22T06:28:08Z"}
{"aid":"http://arxiv.org/abs/2504.15649v1","title":"RepNet-VSR: Reparameterizable Architecture for High-Fidelity Video\n  Super-Resolution","summary":"As a fundamental challenge in visual computing, video super-resolution (VSR)\nfocuses on reconstructing highdefinition video sequences from their degraded\nlowresolution counterparts. While deep convolutional neural networks have\ndemonstrated state-of-the-art performance in spatial-temporal super-resolution\ntasks, their computationally intensive nature poses significant deployment\nchallenges for resource-constrained edge devices, particularly in real-time\nmobile video processing scenarios where power efficiency and latency\nconstraints coexist. In this work, we propose a Reparameterizable Architecture\nfor High Fidelity Video Super Resolution method, named RepNet-VSR, for\nreal-time 4x video super-resolution. On the REDS validation set, the proposed\nmodel achieves 27.79 dB PSNR when processing 180p to 720p frames in 103 ms per\n10 frames on a MediaTek Dimensity NPU. The competition results demonstrate an\nexcellent balance between restoration quality and deployment efficiency. The\nproposed method scores higher than the previous champion algorithm of MAI video\nsuper-resolution challenge.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-22T07:15:07Z"}
{"aid":"http://arxiv.org/abs/2504.15659v1","title":"VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional\n  Correctness Validation","summary":"Recent advances in Large Language Models (LLMs) have sparked growing interest\nin applying them to Electronic Design Automation (EDA) tasks, particularly\nRegister Transfer Level (RTL) code generation. While several RTL datasets have\nbeen introduced, most focus on syntactic validity rather than functional\nvalidation with tests, leading to training examples that compile but may not\nimplement the intended behavior. We present VERICODER, a model for RTL code\ngeneration fine-tuned on a dataset validated for functional correctness. This\nfine-tuning dataset is constructed using a novel methodology that combines unit\ntest generation with feedback-directed refinement. Given a natural language\nspecification and an initial RTL design, we prompt a teacher model\n(GPT-4o-mini) to generate unit tests and iteratively revise the RTL design\nbased on its simulation results using the generated tests. If necessary, the\nteacher model also updates the tests to ensure they comply with the natural\nlanguage specification. As a result of this process, every example in our\ndataset is functionally validated, consisting of a natural language\ndescription, an RTL implementation, and passing tests. Fine-tuned on this\ndataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics\nin functional correctness on VerilogEval and RTLLM, with relative gains of up\nto 71.7% and 27.4% respectively. An ablation study further shows that models\ntrained on our functionally validated dataset outperform those trained on\nfunctionally non-validated datasets, underscoring the importance of\nhigh-quality datasets in RTL code generation.","main_category":"cs.AR","categories":"cs.AR,cs.AI,cs.CL,cs.LG,cs.SE","published":"2025-04-22T07:32:46Z"}
{"aid":"http://arxiv.org/abs/2504.15671v1","title":"On the approximation of the Riemannian barycenter","summary":"We present a method to compute an approximate Riemannian barycenter of a\ncollection of points lying on a Riemannian manifold. Our approach relies on the\nuse of theoretically proven under- and overapproximations of the Riemannian\ndistance function. We compare it to the exact computation of the Riemannian\nbarycenter and to an approach that approximates the Riemannian logarithm using\nlifting maps. Experiments are conducted on the Stiefel manifold.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T07:52:10Z"}
{"aid":"http://arxiv.org/abs/2504.15679v1","title":"Policy-Based Radiative Transfer: Solving the $2$-Level Atom Non-LTE\n  Problem using Soft Actor-Critic Reinforcement Learning","summary":"We present a novel reinforcement learning (RL) approach for solving the\nclassical 2-level atom non-LTE radiative transfer problem by framing it as a\ncontrol task in which an RL agent learns a depth-dependent source function\n$S(\\tau)$ that self-consistently satisfies the equation of statistical\nequilibrium (SE). The agent's policy is optimized entirely via reward-based\ninteractions with a radiative transfer engine, without explicit knowledge of\nthe ground truth. This method bypasses the need for constructing approximate\nlambda operators ($\\Lambda^*$) common in accelerated iterative schemes.\nAdditionally, it requires no extensive precomputed labeled datasets to extract\na supervisory signal, and avoids backpropagating gradients through the complex\nRT solver itself. Finally, we show through experiment that a simple feedforward\nneural network trained greedily cannot solve for SE, possibly due to the moving\ntarget nature of the problem. Our $\\Lambda^*-\\text{Free}$ method offers\npotential advantages for complex scenarios (e.g., atmospheres with enhanced\nvelocity fields, multi-dimensional geometries, or complex microphysics) where\n$\\Lambda^*$ construction or solver differentiability is challenging.\nAdditionally, the agent can be incentivized to find more efficient policies by\nmanipulating the discount factor, leading to a reprioritization of immediate\nrewards. If demonstrated to generalize past its training data, this RL\nframework could serve as an alternative or accelerated formalism to achieve SE.\nTo the best of our knowledge, this study represents the first application of\nreinforcement learning in solar physics that directly solves for a fundamental\nphysical constraint.","main_category":"astro-ph.SR","categories":"astro-ph.SR,cs.LG","published":"2025-04-22T08:03:09Z"}
{"aid":"http://arxiv.org/abs/2504.15689v1","title":"The Viability of Crowdsourcing for RAG Evaluation","summary":"How good are humans at writing and judging responses in retrieval-augmented\ngeneration (RAG) scenarios? To answer this question, we investigate the\nefficacy of crowdsourcing for RAG through two complementary studies: response\nwriting and response utility judgment. We present the Crowd RAG Corpus 2025\n(CrowdRAG-25), which consists of 903 human-written and 903 LLM-generated\nresponses for the 301 topics of the TREC RAG'24 track, across the three\ndiscourse styles 'bulleted list', 'essay', and 'news'. For a selection of 65\ntopics, the corpus further contains 47,320 pairwise human judgments and 10,556\npairwise LLM judgments across seven utility dimensions (e.g., coverage and\ncoherence). Our analyses give insights into human writing behavior for RAG and\nthe viability of crowdsourcing for RAG evaluation. Human pairwise judgments\nprovide reliable and cost-effective results compared to LLM-based pairwise or\nhuman/LLM-based pointwise judgments, as well as automated comparisons with\nhuman-written reference responses. All our data and tools are freely available.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-22T08:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.15720v1","title":"SeaLLM: Service-Aware and Latency-Optimized Resource Sharing for Large\n  Language Model Inference","summary":"Large language models (LLMs) with different architectures and sizes have been\ndeveloped. Serving each LLM with dedicated GPUs leads to resource waste and\nservice inefficiency due to the varying demand of LLM requests. A common\npractice is to share multiple LLMs. However, existing sharing systems either do\nnot consider the autoregressive pattern of LLM services, or only focus on\nimproving the throughput, which impairs the sharing performance, especially the\nserving latency. We present SeaLLM, which enables service-aware and\nlatency-optimized LLM sharing. SeaLLM improves the overall sharing performance\nby (1) a latency-optimized scheduling algorithm utilizing the characteristics\nof LLM services, (2) a placement algorithm to determine the placement plan and\nan adaptive replacement algorithm to decide the replacement interval, and (3) a\nunified key-value cache to share GPU memory among LLM services efficiently. Our\nevaluation under real-world traces and LLM services demonstrates that SeaLLM\nimproves the normalized latency by up to $13.60\\times$, the tail latency by up\nto $18.69\\times$, and the SLO attainment by up to $3.64\\times$ compared to\nexisting solutions.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-22T09:08:46Z"}
{"aid":"http://arxiv.org/abs/2504.15728v1","title":"SAGA: Semantic-Aware Gray color Augmentation for Visible-to-Thermal\n  Domain Adaptation across Multi-View Drone and Ground-Based Vision Systems","summary":"Domain-adaptive thermal object detection plays a key role in facilitating\nvisible (RGB)-to-thermal (IR) adaptation by reducing the need for co-registered\nimage pairs and minimizing reliance on large annotated IR datasets. However,\ninherent limitations of IR images, such as the lack of color and texture cues,\npose challenges for RGB-trained models, leading to increased false positives\nand poor-quality pseudo-labels. To address this, we propose Semantic-Aware Gray\ncolor Augmentation (SAGA), a novel strategy for mitigating color bias and\nbridging the domain gap by extracting object-level features relevant to IR\nimages. Additionally, to validate the proposed SAGA for drone imagery, we\nintroduce the IndraEye, a multi-sensor (RGB-IR) dataset designed for diverse\napplications. The dataset contains 5,612 images with 145,666 instances,\ncaptured from diverse angles, altitudes, backgrounds, and times of day,\noffering valuable opportunities for multimodal learning, domain adaptation for\nobject detection and segmentation, and exploration of sensor-specific strengths\nand weaknesses. IndraEye aims to enhance the development of more robust and\naccurate aerial perception systems, especially in challenging environments.\nExperimental results show that SAGA significantly improves RGB-to-IR adaptation\nfor autonomous driving and IndraEye dataset, achieving consistent performance\ngains of +0.4% to +7.6% (mAP) when integrated with state-of-the-art domain\nadaptation techniques. The dataset and codes are available at\nhttps://github.com/airliisc/IndraEye.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T09:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.15760v1","title":"Moment Tensor Potential and Equivariant Tensor Network Potential with\n  explicit dispersion interactions","summary":"In this study, we investigate the effect of incorporating explicit dispersion\ninteractions in the functional form of machine learning interatomic potentials\n(MLIPs), particularly in the Moment Tensor Potential and Equivariant Tensor\nNetwork potential for accurate modeling of liquid carbon tetrachloride,\nmethane, and toluene. We show that explicit incorporation of dispersion\ninteractions via D2 and D3 corrections significantly improves the accuracy of\nMLIPs when the cutoff radius is set to a commonly used value of 5 -- 6 \\r{A}.\nWe also show that for carbon tetrachloride and methane, a substantial\nimprovement in accuracy can be achieved by extending the cutoff radius to 7.5\n\\r{A}. However, for accurate modeling of toluene, explicit incorporation of\ndispersion remains important. Furthermore, we find that MLIPs incorporating\ndispersion interactions via D2 reach a close level of accuracy to those\nincorporating D3, and D2 is suitable for accurate modeling of the systems in\nthe study, while being less computationally expensive. We evaluated the\naccuracy of MLIPs in dimer binding curves compared to ab initio data and in\npredicting density and radial distribution functions compared to experiments.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-22T10:11:54Z"}
{"aid":"http://arxiv.org/abs/2504.15770v1","title":"Multi-Scale Tensorial Summation and Dimensional Reduction Guided Neural\n  Network for Edge Detection","summary":"Edge detection has attracted considerable attention thanks to its exceptional\nability to enhance performance in downstream computer vision tasks. In recent\nyears, various deep learning methods have been explored for edge detection\ntasks resulting in a significant performance improvement compared to\nconventional computer vision algorithms. In neural networks, edge detection\ntasks require considerably large receptive fields to provide satisfactory\nperformance. In a typical convolutional operation, such a large receptive field\ncan be achieved by utilizing a significant number of consecutive layers, which\nyields deep network structures. Recently, a Multi-scale Tensorial Summation\n(MTS) factorization operator was presented, which can achieve very large\nreceptive fields even from the initial layers. In this paper, we propose a\nnovel MTS Dimensional Reduction (MTS-DR) module guided neural network,\nMTS-DR-Net, for the edge detection task. The MTS-DR-Net uses MTS layers, and\ncorresponding MTS-DR blocks as a new backbone to remove redundant information\ninitially. Such a dimensional reduction module enables the neural network to\nfocus specifically on relevant information (i.e., necessary subspaces).\nFinally, a weight U-shaped refinement module follows MTS-DR blocks in the\nMTS-DR-Net. We conducted extensive experiments on two benchmark edge detection\ndatasets: BSDS500 and BIPEDv2 to verify the effectiveness of our model. The\nimplementation of the proposed MTS-DR-Net can be found at\nhttps://github.com/LeiXuAI/MTS-DR-Net.git.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T10:28:10Z"}
{"aid":"http://arxiv.org/abs/2504.15787v1","title":"Plasma Mechanism of Radio Emission Generation at the Bow Shock of the\n  Exoplanet HD 189733b","summary":"This study evaluates the possibility of efficient radio emission generation\nin the bow shock region of hot Jupiter-type exoplanets. As a source of\nenergetic electrons, the shock drift acceleration mechanism at a\nquasi-perpendicular shock is proposed. Electrons reflected and accelerated by\nthe shock propagate through the relatively dense stellar wind plasma and excite\nplasma waves; therefore, a plasma emission mechanism is considered as the\nsource of the resulting radio waves. Using the bow shock of the hot Jupiter HD\n189733b as a case study, the properties of the energetic electron beam, the\nexcited plasma waves, and the resulting radio frequencies are estimated. An\nenergy-based analysis is carried out to identify the range of stellar wind\nparameters for which radio emission from the bow shock of the exoplanet HD\n189733b could be detectable by modern astronomical instruments.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,astro-ph.EP,astro-ph.IM","published":"2025-04-22T10:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.15794v1","title":"Residual lifetime prediction for heterogeneous degradation data by\n  Bayesian semi-parametric method","summary":"Degradation data are considered for assessing reliability in highly reliable\nsystems. The usual assumption is that degradation units come from a homogeneous\npopulation. But in presence of high variability in the manufacturing process,\nthis assumption is not true in general; that is different sub-populations are\ninvolved in the study. Predicting residual lifetime of a functioning unit is a\nmajor challenge in the degradation modeling especially in heterogeneous\nenvironment. To account for heterogeneous degradation data, we have proposed a\nBayesian semi-parametric approach to relax the conventional modeling\nassumptions. We model the degradation path using Dirichlet process mixture of\nnormal distributions. Based on the samples obtained from posterior distribution\nof model parameters we obtain residual lifetime distribution for individual\nunit. Transformation based MCMC technique is used for simulating values from\nthe derived residual lifetime distribution for prediction of residual lifetime.\nA simulation study is undertaken to check performance of the proposed\nsemi-parametric model compared with parametric model. Fatigue Crack Size data\nis analyzed to illustrate the proposed methodology.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-22T11:14:56Z"}
{"aid":"http://arxiv.org/abs/2504.15834v1","title":"Causal machine learning for high-dimensional mediation analysis using\n  interventional effects mapped to a target trial","summary":"Causal mediation analysis examines causal pathways linking exposures to\ndisease. The estimation of interventional effects, which are mediation\nestimands that overcome certain identifiability problems of natural effects,\nhas been advanced through causal machine learning methods, particularly for\nhigh-dimensional mediators. Recently, it has been proposed interventional\neffects can be defined in each study by mapping to a target trial assessing\nspecific hypothetical mediator interventions. This provides an appealing\nframework to directly address real-world research questions about the extent to\nwhich such interventions might mitigate an increased disease risk in the\nexposed. However, existing estimators for interventional effects mapped to a\ntarget trial rely on singly-robust parametric approaches, limiting their\napplicability in high-dimensional settings. Building upon recent developments\nin causal machine learning for interventional effects, we address this gap by\ndeveloping causal machine learning estimators for three interventional effect\nestimands, defined by target trials assessing hypothetical interventions\ninducing distinct shifts in joint mediator distributions. These estimands are\nmotivated by a case study within the Longitudinal Study of Australian Children,\nused for illustration, which assessed how intervening on high inflammatory\nburden and other non-inflammatory adverse metabolomic markers might mitigate\nthe adverse causal effect of overweight or obesity on high blood pressure in\nadolescence. We develop one-step and (partial) targeted minimum loss-based\nestimators based on efficient influence functions of those estimands,\ndemonstrating they are root-n consistent, efficient, and multiply robust under\ncertain conditions.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-22T12:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.15864v1","title":"The effects of pressure loads in the dimension reduction of elasticity\n  models","summary":"We study the dimensional reduction from three to two dimensions in\nhyperelastic materials subject to a live load, modeled as a constant pressure\nforce. Our results demonstrate that this loading has a significant impact in\nhigher-order scaling regimes, namely those associated with von K\\'arm\\'an-type\ntheories, where a nontrivial interplay arises between the elastic energy and\nthe pressure term. In contrast, we rigorously show that in lower-order bending\nregimes, as described by Kirchhoff-type theories, the pressure load does not\ninfluence the minimizers. Finally, after identifying the corresponding\n$\\Gamma$-limit, we conjecture that a similar independence from the pressure\nterm persists in the most flexible membrane regimes.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T12:59:36Z"}
{"aid":"http://arxiv.org/abs/2504.15871v1","title":"Long-term disparities in the recovery of urban mobility after COVID-19\n  in Latin America","summary":"The COVID-19 pandemic caused unprecedented disruptions to the patterns of\nurban mobility. Existing work has overwhelmingly focused on the immediate\nimpacts of COVID-19 on human mobility during 2020, particularly in countries of\nthe Global North. It showed that the pandemic resulted in an increased gap,\nbenefitted affluent and core urban areas with larger reductions in mobility.\nYet, little is know about the long-term persistence of these unequal impacts\nbeyond 2020, and in countries of the Global South where socioeconomic\ndisparities are more acute. Using over 100 million anonymised daily records of\nmobile phone data from Meta-Facebook users from March 2020 to May 2022, we aim\nto determine the long-term geographic and socioeconomic impact of COVID-19 on\nmobility patterns in Latin America. Our findings reveal that the mobility\ndisparities triggered by the COVID-19 pandemic have endured, with affluent and\ndensely populated areas displaying lower mobility rates than more deprived and\nsparsely populated places. We also show that the magnitude of the reduction in\nmobility levels early in the COVID-19 pandemic largely determined the extent of\nmobility differential between socioeconomic groups. We find no signs of full\nrecovery to baseline levels of mobility in some urban cores, suggesting some\nlost of appeal as attractors of economic activity. Overall, our findings\nsuggest that the COVID-19 pandemic has contributed to amplified pre-existing\nsocioeconomic inequalities and redefined the role of cities in Latin American\ncountries.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-22T13:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.15883v1","title":"Integrating Non-Linear Radon Transformation for Diabetic Retinopathy\n  Grading","summary":"Diabetic retinopathy is a serious ocular complication that poses a\nsignificant threat to patients' vision and overall health. Early detection and\naccurate grading are essential to prevent vision loss. Current automatic\ngrading methods rely heavily on deep learning applied to retinal fundus images,\nbut the complex, irregular patterns of lesions in these images, which vary in\nshape and distribution, make it difficult to capture subtle changes. This study\nintroduces RadFuse, a multi-representation deep learning framework that\nintegrates non-linear RadEx-transformed sinogram images with traditional fundus\nimages to enhance diabetic retinopathy detection and grading. Our RadEx\ntransformation, an optimized non-linear extension of the Radon transform,\ngenerates sinogram representations to capture complex retinal lesion patterns.\nBy leveraging both spatial and transformed domain information, RadFuse enriches\nthe feature set available to deep learning models, improving the\ndifferentiation of severity levels. We conducted extensive experiments on two\nbenchmark datasets, APTOS-2019 and DDR, using three convolutional neural\nnetworks (CNNs): ResNeXt-50, MobileNetV2, and VGG19. RadFuse showed significant\nimprovements over fundus-image-only models across all three CNN architectures\nand outperformed state-of-the-art methods on both datasets. For severity\ngrading across five stages, RadFuse achieved a quadratic weighted kappa of\n93.24%, an accuracy of 87.07%, and an F1-score of 87.17%. In binary\nclassification between healthy and diabetic retinopathy cases, the method\nreached an accuracy of 99.09%, precision of 98.58%, and recall of 99.6%,\nsurpassing previously established models. These results demonstrate RadFuse's\ncapacity to capture complex non-linear features, advancing diabetic retinopathy\nclassification and promoting the integration of advanced mathematical\ntransforms in medical image analysis.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T13:27:28Z"}
{"aid":"http://arxiv.org/abs/2504.15886v1","title":"Beyond Attention: Investigating the Threshold Where Objective Robot\n  Exclusion Becomes Subjective","summary":"As robots become increasingly involved in decision-making processes (e.g.,\npersonnel selection), concerns about fairness and social inclusion arise. This\nstudy examines social exclusion in robot-led group interviews by robot Ameca,\nexploring the relationship between objective exclusion (robot's attention\nallocation), subjective exclusion (perceived exclusion), mood change, and need\nfulfillment. In a controlled lab study (N = 35), higher objective exclusion\nsignificantly predicted subjective exclusion. In turn, subjective exclusion\nnegatively impacted mood and need fulfillment but only mediated the\nrelationship between objective exclusion and need fulfillment. A piecewise\nregression analysis identified a critical threshold at which objective\nexclusion begins to be perceived as subjective exclusion. Additionally, the\nstanding position was the primary predictor of exclusion, whereas demographic\nfactors (e.g., gender, height) had no significant effect. These findings\nunderscore the need to consider both objective and subjective exclusion in\nhuman-robot interactions and have implications for fairness in robot-assisted\nhiring processes.","main_category":"cs.HC","categories":"cs.HC,cs.RO","published":"2025-04-22T13:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.15902v1","title":"Density Profiles of TNG300 Voids across Cosmic Time","summary":"We present radial density profiles, as traced by luminous galaxies and dark\nmatter particles, for voids in eleven snapshots of the \\texttt{TNG300}\nsimulation. The snapshots span 11.65~Gyr of cosmic time, corresponding to the\nredshift range $0 \\le z \\le 3$. Using the comoving galaxy fields, voids were\nidentified via a well-tested, watershed transformation-based algorithm. Voids\nwere defined to be underdense regions that are unlikely to have arisen from\nPoisson noise, resulting in the selection of $\\sim100-200$ of the largest\nunderdense regions in each snapshot. At all redshifts, the radial density\nprofiles as traced by both the galaxies and the dark matter resemble inverse\ntop-hat functions. However, details of the functions (particularly the\nunderdensities of the innermost regions and the overdensities of the ridges)\nevolve considerably more for the dark matter density profiles than for the\ngalaxy density profiles. At all redshifts, a linear relationship between the\ngalaxy and dark matter density profiles exists, and the slope of the\nrelationship is similar to the bias estimates for \\texttt{TNG300} snapshots.\nLastly, we identify distinct environments in which voids can exist, defining\n``void-in-void\" and ``void-in-cloud\" populations (i.e., voids that reside in\nlarger underdense or overdense regions, respectively) and we investigate ways\nin which the relative densities of dark matter and galaxies in the interiors\nand ridges of these structures vary as a function of void environment.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-22T13:42:12Z"}
{"aid":"http://arxiv.org/abs/2504.15916v1","title":"Are there Spectral Features in the MIRI/LRS Transmission Spectrum of\n  K2-18b?","summary":"Determining the composition of an exoplanet atmosphere relies on the presence\nof detectable spectral features. The strongest spectral features, including\nDMS, look approximately Gaussian. Here, I perform a suite of Gaussian feature\nanalyses to find any statistically significant spectral features in the\nrecently published MIRI/LRS spectrum of K2-18b (N. Madhusudhan et al. 2025). In\nN. Madhusudhan et al. 2025, they claim a 3.4-$\\sigma$ detection of spectral\nfeatures compared to a flat line. In 5 out of 6 tests, I find the data\npreferred a flat line over a Gaussian model, with a $\\chi^{2}_{\\nu}$ of 1.06.\nWhen centering the Gaussian where the absorptions for DMS and DMDS peak, I find\nln(B) = 1.21 in favour of the Gaussian model, with a $\\chi^{2}_{\\nu}$ of 0.99.\nWith only $\\sim$2-$\\sigma$ in favour of Gaussian features, I conclude no strong\nstatistical evidence for spectral features.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-22T14:02:56Z"}
{"aid":"http://arxiv.org/abs/2504.15923v1","title":"Bayesian sample size calculations for external validation studies of\n  risk prediction models","summary":"Summary: Contemporary sample size calculations for external validation of\nrisk prediction models require users to specify fixed values of assumed model\nperformance metrics alongside target precision levels (e.g., 95% CI widths).\nHowever, due to the finite samples of previous studies, our knowledge of true\nmodel performance in the target population is uncertain, and so choosing fixed\nvalues represents an incomplete picture. As well, for net benefit (NB) as a\nmeasure of clinical utility, the relevance of conventional precision-based\ninference is doubtful. In this work, we propose a general Bayesian algorithm\nfor constructing the joint distribution of predicted risks and response values\nbased on summary statistics of model performance in previous studies. For\nstatistical metrics of performance, we propose sample size determination rules\nthat either target desired expected precision, or a desired assurance\nprobability that the precision criteria will be satisfied. For NB, we propose\nrules based on optimality assurance (the probability that the planned study\ncorrectly identifies the most beneficial strategy) and the Expected Value of\nSample Information (EVSI), the expected gain in NB from the planned validation\nstudy. We showcase these developments in a case study on the validation of a\nrisk prediction model for deterioration of hospitalized COVID-19 patients.\nCompared to the conventional sample size calculation methods, a Bayesian\napproach requires explicit quantification of uncertainty around model\nperformance, but thereby enables various sample size rules based on expected\nprecision, assurance probabilities, and value of information.","main_category":"stat.AP","categories":"stat.AP,stat.CO,stat.ME","published":"2025-04-22T14:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.15943v1","title":"Ge$_{1-x}$Si$_{x}$ single crystals for Ge hole spin qubit integration","summary":"Spin qubits are fundamental building blocks of modern quantum computing\ndevices. The path of Ge-based hole-spin qubits has several advantages over\nSi-based electron-spin systems, such as the absence of valley band degeneracy,\nthe possibility of efficient field control due to large spin-orbit coupling,\nand smaller effective masses. Among the possible Ge qubit devices, Ge/GeSi\nplanar heterostructures have proven to be favourable for upscaling and\nfabrication. The Si concentration of the straining GeSi buffer serves as an\nimportant tuning parameter for the electronic structure of Ge/GeSi qubits. A\nparticularly low Si concentration of x = 0.15 of the Ge$_{0.85}$Si$_{0.15}$\ncrystal should enable minimal lattice strain for spin qubit heterostructures,\nwhich is difficult to stabilize as a random alloy. We present a\nsynchrotron-based study to investigate the chemical composition, valence band\nelectronic structure and local atomic structure of a Ge$_{0.85}$Si$_{0.15}$\nsingle crystal using the advanced combination of hard X-ray photoelectron\nspectroscopy (HAXPES), hard X-ray momentum microscopy (HarMoMic) and X-ray\nphotoelectron diffraction (XPD). We found that the Ge$_{0.85}$Si$_{0.15}$\ncrystal has an individual, uniform valence band structure, with no signs of\nphase separation. The shapes of the valence bands resemble those of pure Ge, as\ndo the low effective masses. XPD experiments and Bloch wave calculations, show\nthe Si atoms located at Ge lattice sites within the crystal, forming a random\nalloy. This high chemical, electronic and structural quality of\nGe$_{0.85}$Si$_{0.15}$ single-crystal substrates is of crucial importance for\ntheir implementation to enable long spin lifetimes in Ge-based hole-spin\nqubits. The results emphasise the power of combined X-ray spectromicroscopy\ntechniques, which provide key insights into the qubit building blocks that form\nthe basis of quantum technologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T14:40:46Z"}
{"aid":"http://arxiv.org/abs/2504.15952v1","title":"Reconstruction of three-dimensional fluid stress field via\n  photoelasticity using physics-informed convolutional encoder-decoder","summary":"Measuring stress fields in fluids and soft materials is crucial in various\nfields such as mechanical engineering, medicine, and bioengineering. However,\nconventional methods that calculate stress fields from velocity fields struggle\nto measure complex fluids where the stress constitutive equation is unknown. To\naddress this, we propose a novel approach that combines photoelastic\nmeasurements -- which can non-invasively visualize internal stresses -- with\nmachine learning to measure stress fields. The machine learning model, which we\nnamed physics-informed convolutional encoder-decoder (PICED), integrates a\nconvolutional neural network (CNN)-based encoder-decoder model with a\nphysics-informed neural network (PINN). Using this approach, three-dimensional\nstress fields can be predicted with high accuracy for multiple interpolated\ndata points in a rectangular channel flow.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-22T14:48:24Z"}
{"aid":"http://arxiv.org/abs/2504.15967v1","title":"A UAV-Aided Digital Twin Framework for IoT Networks with High Accuracy\n  and Synchronization","summary":"With the continued growth of its core technologies, including the Internet of\nThings (IoT), artificial intelligence (AI), Big Data and data analytics, and\nedge computing, digital twin (DT) technology has witnessed a significant\nincrease in industrial applications, helping the industry become more\nsustainable, smart, and adaptable. Hence, DT technology has emerged as a\npromising link between the physical and virtual worlds, enabling simulation,\nprediction, and real-time performance optimization. This work aims to explore\nthe development of a high-fidelity digital twin framework, focusing on\nsynchronization and accuracy between physical and digital systems to enhance\ndata-driven decision making. To achieve this, we deploy several stationary UAVs\nin optimized locations to collect data from industrial IoT devices, which were\nused to monitor multiple physical entities and perform computations to evaluate\ntheir status. We consider a practical setup in which multiple IoT devices may\nmonitor a single physical entity, and as a result, the measurements are\ncombined and processed together to determine the status of the physical entity.\nThe resulting status updates are subsequently uploaded from the UAVs to the\nbase station, where the DT resides. In this work, we consider a novel metric\nbased on the Age of Information (AoI), coined as the Age of Digital Twin\n(AoDT), to reflect the status freshness of the digital twin. Factoring AoDT in\nthe problem formulation ensures that the DT reliably mirrors the physical\nsystem with high accuracy and synchronization. We formulate a mixed-integer\nnon-convex program to maximize the total amount of data collected from all IoT\ndevices while ensuring a constrained AoDT. Using successive convex\napproximations, we solve the problem, conduct extensive simulations and compare\nthe results with baseline approaches to demonstrate the effectiveness of the\nproposed solution.","main_category":"cs.ET","categories":"cs.ET,eess.SP","published":"2025-04-22T15:07:07Z"}
{"aid":"http://arxiv.org/abs/2504.15975v1","title":"A New Graph Grammar Formalism for Robust Syntactic Pattern Recognition","summary":"I introduce a formalism for representing the syntax of recursively structured\ngraph-like patterns. It does not use production rules, like a conventional\ngraph grammar, but represents the syntactic structure in a more direct and\ndeclarative way. The grammar and the pattern are both represented as networks,\nand parsing is seen as the construction of a homomorphism from the pattern to\nthe grammar. The grammars can represent iterative, hierarchical and nested\nrecursive structure in more than one dimension.\n  This supports a highly parallel style of parsing, in which all aspects of\npattern recognition (feature detection, segmentation, parsing, filling in\nmissing symbols, top-down and bottom-up inference) are integrated into a single\nprocess, to exploit the synergy between them.\n  The emphasis of this paper is on underlying theoretical issues, but I also\ngive some example runs to illustrate the error-tolerant parsing of complex\nrecursively structured patterns of 50-1000 symbols, involving variability in\ngeometric relationships, blurry and indistinct symbols, overlapping symbols,\ncluttered images, and erased patches.","main_category":"cs.FL","categories":"cs.FL,cs.CV","published":"2025-04-22T15:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.15990v1","title":"Making Neural Networks More Suitable for Approximate Clifford+T Circuit\n  Synthesis","summary":"Machine Learning with deep neural networks has transformed computational\napproaches to scientific and engineering problems. Central to many of these\nadvancements are precisely tuned neural architectures that are tailored to the\ndomains in which they are used. In this work, we develop deep learning\ntechniques and architectural modifications that improve performance on\nreinforcement learning guided quantum circuit synthesis-the task of\nconstructing a circuit that implements a given unitary matrix. First, we\npropose a global phase invariance operation which makes our architecture\nresilient to complex global phase shifts. Second, we demonstrate how augmenting\ndata with small random unitary perturbations during training enables more\nrobust learning. Finally, we show how encoding numerical data with techniques\nfrom image processing allow networks to better detect small but significant\nchanges in data. Our work enables deep learning approaches to better synthesize\nquantum circuits that implement unitary matrices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T15:51:32Z"}
{"aid":"http://arxiv.org/abs/2504.15997v1","title":"A Lagrangian Approach to Optimal Lotteries in Non-Convex Economies","summary":"We develop a new method to efficiently solve for optimal lotteries in models\nwith non-convexities. In order to employ a Lagrangian framework, we prove that\nthe value of the saddle point that characterizes the optimal lottery is the\nsame as the value of the dual of the deterministic problem. Our algorithm\nsolves the dual of the deterministic problem via sub-gradient descent. We prove\nthat the optimal lottery can be directly computed from the deterministic optima\nthat occur along the iterations. We analyze the computational complexity of our\nalgorithm and show that the worst-case complexity is often orders of magnitude\nbetter than the one arising from a linear programming approach. We apply the\nmethod to two canonical problems with private information. First, we solve a\nprincipal-agent moral-hazard problem, demonstrating that our approach delivers\nsubstantial improvements in speed and scalability over traditional linear\nprogramming methods. Second, we study an optimal taxation problem with hidden\ntypes, which was previously considered computationally infeasible, and examine\nunder which conditions the optimal contract will involve lotteries.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-22T16:03:09Z"}
{"aid":"http://arxiv.org/abs/2504.16045v1","title":"Reinforcement Learning and Metaheuristics for Feynman Integral Reduction","summary":"We propose new methods for optimizing the integration-by-parts (IBP)\nreduction of Feynman integrals, an important computational bottleneck in modern\nperturbative calculations in quantum field theory. Using the simple example of\none-loop massive bubble integrals, we pose the problem of minimizing the number\nof arithmetic operations in reducing a target integral to master integrals via\nthe Laporta algorithm. This is a nontrivial combinatorial optimization problem\nover the ordering of IBP equation generation (from pairs of seed integrals and\nIBP operators) and the ordering of integral elimination. Our first proposed\nmethod is reinforcement learning, which involves an agent interacting with an\nenvironment in a step-by-step manner and learning the best actions to take\ngiven an observation of the environment (in this case, the current state of the\nIBP reduction process). The second method is using metaheuristics, e.g.\nsimulated annealing, to minimize the computational cost as a black-box function\nof numerical priority values that control the orderings. For large-scale\nproblems, the number of free parameters can be compressed by using a small\nneural network to assign priority values. Remarkably, both methods lead to IBP\nreduction schemes that are more efficient than human-designed algorithms.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-22T17:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.16074v1","title":"PHYBench: Holistic Evaluation of Physical Perception and Reasoning in\n  Large Language Models","summary":"We introduce PHYBench, a novel, high-quality benchmark designed for\nevaluating reasoning capabilities of large language models (LLMs) in physical\ncontexts. PHYBench consists of 500 meticulously curated physics problems based\non real-world physical scenarios, designed to assess the ability of models to\nunderstand and reason about realistic physical processes. Covering mechanics,\nelectromagnetism, thermodynamics, optics, modern physics, and advanced physics,\nthe benchmark spans difficulty levels from high school exercises to\nundergraduate problems and Physics Olympiad challenges. Additionally, we\npropose the Expression Edit Distance (EED) Score, a novel evaluation metric\nbased on the edit distance between mathematical expressions, which effectively\ncaptures differences in model reasoning processes and results beyond\ntraditional binary scoring methods. We evaluate various LLMs on PHYBench and\ncompare their performance with human experts. Our results reveal that even\nstate-of-the-art reasoning models significantly lag behind human experts,\nhighlighting their limitations and the need for improvement in complex physical\nreasoning scenarios. Our benchmark results and dataset are publicly available\nat https://phybench-official.github.io/phybench-demo/.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T17:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.16386v1","title":"Robust Transmission Design for Reconfigurable Intelligent Surface and\n  Movable Antenna Enabled Symbiotic Radio Communications","summary":"This paper explores the application of movable antenna (MA), a cutting-edge\ntechnology with the capability of altering antenna positions, in a symbiotic\nradio (SR) system enabled by reconfigurable intelligent surface (RIS). The goal\nis to fully exploit the capabilities of both MA and RIS, constructing a better\ntransmission environment for the co-existing primary and secondary transmission\nsystems. For both parasitic SR (PSR) and commensal SR (CSR) scenarios with the\nchannel uncertainties experienced by all transmission links, we design a robust\ntransmission scheme with the goal of maximizing the primary rate while ensuring\nthe secondary transmission quality. To address the maximization problem with\nthorny non-convex characteristics, we propose an alternating optimization\nframework that utilizes the General S-Procedure, General Sign-Definiteness\nPrinciple, successive convex approximation (SCA), and simulated annealing (SA)\nimproved particle swarm optimization (SA-PSO) algorithms. Numerical results\nvalidate that the CSR scenario significantly outperforms the PSR scenario in\nterms of primary rate, and also show that compared to the fixed-position\nantenna scheme, the proposed MA scheme can increase the primary rate by 1.62\nbps/Hz and 2.37 bps/Hz for the PSR and CSR scenarios, respectively.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T03:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.16396v1","title":"'Dark pressure': A metric that yields distance-independent circular\n  orbital speed in deep space with 'tunable' total mass","summary":"In general relativity, the tangential speed of objects in stable circular\norbits is not uniquely described by the orbital radius and the mass present\ninside the orbital radius. This work presents a static, spherically symmetric\nspacetime metric which produces stable circular orbits whose speed approaches a\nconstant value at high radii. The orbital speed is independent of the mass\ncontained within the orbital radius, however, there is pressure throughout the\nspacetime. The stress energy tensor of this metric is evaluated numerically\nusing the mass of the Milky Way's central black hole, the orbital speed of its\ndistant satellites, and three different values of a unitless 'mass tuning'\nparameter B. These B 'tune' the amount of mass present, without violating the\nWeak Energy Condition (WEC) at any evaluated spacetime point. The metric can be\nmerged with a Friedmann-Robertson-Walker metric, in which case it achieves\nisotropy and obeys the Friedmann equations at cosmological distances.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T03:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.16399v1","title":"Scalable and modular generation of multipartite entangled states through\n  memory-enhanced fusion","summary":"Efficient generation of large-scale multipartite entangled states is a\ncritical but challenging task in quantum information processing. Although\ngeneration of multipartite entanglement within a small set of individual qubits\nhas been demonstrated, further scale-up in system size requires the connection\nof smaller entangled states into a larger state in a scalable and modular\nmanner. Here we achieve this goal by implementing memory-enhanced fusion of two\nmultipartite entangled states via photonic interconnects. Through asynchronous\npreparation of two tripartite W-state entanglements in two spatially-separated\nmodules of atomic quantum memories and on-demand fusion via single-photon\ninterference, we demonstrate the creation of a four-partite W-state\nentanglement shared by two remote quantum memory modules in a heralded way. We\nfurther transfer the W state from the memory qubits to the photonic qubits, and\nconfirm the genuine four-partite entanglement through witness measurements. We\nthen demonstrate memory-enhanced scaling in efficiencies in the entanglement\nfusion. The demonstrated scalable generation and fusion of multipartite\nentangled states pave the way towards realization of large-scale distributed\nquantum information processing in the future.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T04:01:21Z"}
{"aid":"http://arxiv.org/abs/2504.16404v1","title":"Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle\n  Lameness Detection","summary":"Cattle lameness is often caused by hoof injuries or interdigital dermatitis,\nleads to pain and significantly impacts essential physiological activities such\nas walking, feeding, and drinking. This study presents a deep learning-based\nmodel for detecting cattle lameness, sickness, or gait abnormalities using\npublicly available video data. The dataset consists of 50 unique videos from 40\nindividual cattle, recorded from various angles in both indoor and outdoor\nenvironments. Half of the dataset represents naturally walking\n(normal/non-lame) cattle, while the other half consists of cattle exhibiting\ngait abnormalities (lame). To enhance model robustness and generalizability,\ndata augmentation was applied to the training data. The pre-processed videos\nwere then classified using two deep learning models: ConvLSTM2D and 3D CNN. A\ncomparative analysis of the results demonstrates strong classification\nperformance. Specifically, the 3D CNN model achieved a video-level\nclassification accuracy of 90%, with precision, recall, and f1-score of 90.9%,\n90.9%, and 90.91% respectively. The ConvLSTM2D model exhibited a slightly lower\naccuracy of 85%. This study highlights the effectiveness of directly applying\nclassification models to learn spatiotemporal features from video data,\noffering an alternative to traditional multi-stage approaches that typically\ninvolve object detection, pose estimation, and feature extraction. Besides, the\nfindings demonstrate that the proposed deep learning models, particularly the\n3D CNN, effectively classify and detect lameness in cattle while simplifying\nthe processing pipeline.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,eess.IV","published":"2025-04-23T04:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.16442v1","title":"Nonlinear contagion dynamics on dynamical networks: exact solutions\n  ranging from consensus times to evolutionary trajectories","summary":"Understanding nonlinear social contagion dynamics on dynamical networks, such\nas opinion formation, is crucial for gaining new insights into consensus and\npolarization. Similar to threshold-dependent complex contagions, the\nnonlinearity in adoption rates poses challenges for mean-field approximations.\nTo address this theoretical gap, we focus on nonlinear binary-opinion dynamics\non dynamical networks and analytically derive local configurations,\nspecifically the distribution of opinions within any given focal individual's\nneighborhood. This exact local configuration of opinions, combined with network\ndegree distributions, allows us to obtain exact solutions for consensus times\nand evolutionary trajectories. Our counterintuitive results reveal that neither\nbiased assimilation (i.e., nonlinear adoption rates) nor preferences in local\nnetwork rewiring -- such as in-group bias (preferring like-minded individuals)\nand the Matthew effect (preferring social hubs) -- can significantly slow down\nconsensus. Among these three social factors, we find that biased assimilation\nis the most influential in accelerating consensus. Furthermore, our analytical\nmethod efficiently and precisely predicts the evolutionary trajectories of\nadoption curves arising from nonlinear contagion dynamics. Our work paves the\nway for enabling analytical predictions for general nonlinear contagion\ndynamics beyond opinion formation.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO,q-bio.PE","published":"2025-04-23T06:02:05Z"}
{"aid":"http://arxiv.org/abs/2504.16472v1","title":"Harden and Catch for Just-in-Time Assured LLM-Based Software Testing:\n  Open Research Challenges","summary":"Despite decades of research and practice in automated software testing,\nseveral fundamental concepts remain ill-defined and under-explored, yet offer\nenormous potential real-world impact. We show that these concepts raise\nexciting new challenges in the context of Large Language Models for software\ntest generation. More specifically, we formally define and investigate the\nproperties of hardening and catching tests. A hardening test is one that seeks\nto protect against future regressions, while a catching test is one that\ncatches such a regression or a fault in new functionality introduced by a code\nchange. Hardening tests can be generated at any time and may become catching\ntests when a future regression is caught. We also define and motivate the\nCatching `Just-in-Time' (JiTTest) Challenge, in which tests are generated\n`just-in-time' to catch new faults before they land into production. We show\nthat any solution to Catching JiTTest generation can also be repurposed to\ncatch latent faults in legacy code. We enumerate possible outcomes for\nhardening and catching tests and JiTTests, and discuss open research problems,\ndeployment options, and initial results from our work on automated LLM-based\nhardening at Meta. This paper\\footnote{Author order is alphabetical. The\ncorresponding author is Mark Harman.} was written to accompany the keynote by\nthe authors at the ACM International Conference on the Foundations of Software\nEngineering (FSE) 2025.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-23T07:32:43Z"}
{"aid":"http://arxiv.org/abs/2504.16489v1","title":"Amplified Vulnerabilities: Structured Jailbreak Attacks on LLM-based\n  Multi-Agent Debate","summary":"Multi-Agent Debate (MAD), leveraging collaborative interactions among Large\nLanguage Models (LLMs), aim to enhance reasoning capabilities in complex tasks.\nHowever, the security implications of their iterative dialogues and\nrole-playing characteristics, particularly susceptibility to jailbreak attacks\neliciting harmful content, remain critically underexplored. This paper\nsystematically investigates the jailbreak vulnerabilities of four prominent MAD\nframeworks built upon leading commercial LLMs (GPT-4o, GPT-4, GPT-3.5-turbo,\nand DeepSeek) without compromising internal agents. We introduce a novel\nstructured prompt-rewriting framework specifically designed to exploit MAD\ndynamics via narrative encapsulation, role-driven escalation, iterative\nrefinement, and rhetorical obfuscation. Our extensive experiments demonstrate\nthat MAD systems are inherently more vulnerable than single-agent setups.\nCrucially, our proposed attack methodology significantly amplifies this\nfragility, increasing average harmfulness from 28.14% to 80.34% and achieving\nattack success rates as high as 80% in certain scenarios. These findings reveal\nintrinsic vulnerabilities in MAD architectures and underscore the urgent need\nfor robust, specialized defenses prior to real-world deployment.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-23T08:01:50Z"}
{"aid":"http://arxiv.org/abs/2504.16493v1","title":"Breaking scaling relations with inverse catalysts: a machine learning\n  exploration of trends in $\\mathrm{CO_2}$ hydrogenation energy barriers","summary":"The conversion of $\\mathrm{CO_2}$ into useful products such as methanol is a\nkey strategy for abating climate change and our dependence on fossil fuels.\nDeveloping new catalysts for this process is costly and time-consuming and can\nthus benefit from computational exploration of possible active sites. However,\nthis is complicated by the complexity of the materials and reaction networks.\nHere, we present a workflow for exploring transition states of elementary\nreaction steps at inverse catalysts, which is based on the training of a neural\nnetwork-based machine learning interatomic potential. We focus on the crucial\nformate intermediate and its formation over nanoclusters of indium oxide\nsupported on Cu(111). The speedup compared to an approach purely based on\ndensity functional theory allows us to probe a wide variety of active sites\nfound at nanoclusters of different sizes and stoichiometries. Analysis of the\nobtained set of transition state geometries reveals different\nstructure--activity trends at the edge or interior of the nanoclusters.\nFurthermore, the identified geometries allow for the breaking of linear scaling\nrelations, which could be a key underlying reason for the excellent catalytic\nperformance of inverse catalysts observed in experiments.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.chem-ph","published":"2025-04-23T08:12:47Z"}
{"aid":"http://arxiv.org/abs/2504.16496v1","title":"Boundaries of the bounded hyperbolic components of polynomials","summary":"In this paper, we study the local connectivity and Hausdorff dimension for\nthe boundaries of the bounded hyperbolic components in the space $\\mathcal P_d$\nof polynomials of degree $d\\geq 3$. It is shown that for any non disjoint-type\nbounded hyperbolic component $\\mathcal H\\subset \\mathcal P_d$, the locally\nconnected part of $\\partial\\mathcal H$, along each regular boundary strata, has\nfull Hausdorff dimension $2d-2$.\n  An essential innovation in our argument involves analyzing how the canonical\nparameterization of the hyperbolic component--realized via Blaschke products\nover a mapping scheme--extends to the boundary. This framework allows us to\nstudy three key aspects of $\\partial \\mathcal H$: the local connectivity\nstructure, the perturbation behavior, and the local Hausdorff dimensions.","main_category":"math.DS","categories":"math.DS,math.CV","published":"2025-04-23T08:19:52Z"}
{"aid":"http://arxiv.org/abs/2504.16498v1","title":"LiDAL-Assisted RLNC-NOMA in OWC Systems","summary":"Optical wireless communication (OWC) is envisioned as a key enabler for\nimmersive indoor data transmission in future wireless communication networks.\nHowever, multi-user interference management arises as a challenge in dense\nindoor OWC systems composed of multiple optical access points (APs) serving\nmultiple users. In this paper, we propose a novel dual-function OWC system for\ncommunication and localization. Non-orthogonal multiple access (NOMA) with\nrandom linear network coding (RLNC) is designed for data transmission, where\nNOMA allows the serving of multiple users simultaneously through controlling\nthe power domain, and RLNC helps minimize errors that might occur during signal\nprocessing phase. This setup is assisted with a light detection and\nlocalization system (LiDAL) that can passively obtain spatio-temporal indoor\ninformation of user presence and location for dynamic-user grouping. The\ndesigned LiDAL system helps to improve the estimation of channel state\ninformation (CSI) in realistic indoor network scenarios, where the CSI of\nindoor users might be noisy and/or highly correlated. We evaluate the\nperformance of NOMA combined with RLNC by analyzing the probability of\nsuccessful decoding compared to conventional NOMA and orthogonal schemes. In\naddition, we derive the Cramer-Rao Lower Bound (CRLB) to evaluate the accuracy\nof location estimation. The results show that the proposed RLNC-NOMA improves\nthe probability of successful decoding and the overall system performance. The\nresults also show the high accuracy of the unbiased location estimator and its\nassistant in reducing the imperfection of CSI, leading to high overall system\nperformance.","main_category":"eess.SY","categories":"eess.SY,cs.IT,cs.SY,math.IT","published":"2025-04-23T08:22:28Z"}
{"aid":"http://arxiv.org/abs/2504.16536v1","title":"Synthesiz3 This: an SMT-Based Approach for Synthesis with Uncomputable\n  Symbols","summary":"Program synthesis is the task of automatically constructing a program\nconforming to a given specification. In this paper we focus on synthesis of\nsingle-invocation recursion-free functions conforming to a specification given\nas a logical formula in the presence of uncomputable symbols (i.e., symbols\nused in the specification but not allowed in the resulting function). We\napproach the problem via SMT-solving methods: we present a quantifier\nelimination algorithm using model-based projections for both total and partial\nfunction synthesis, working with theories of uninterpreted functions and linear\narithmetic and their combination. For this purpose we also extend model-based\nprojection to produce witnesses for these theories. Further, we present\nprocedures tailored for the case of uniquely determined solutions. We\nimplemented a prototype of the algorithms using the SMT-solver Z3,\ndemonstrating their practicality.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-23T09:06:26Z"}
{"aid":"http://arxiv.org/abs/2504.16543v1","title":"The different for base change of arithmetic curves","summary":"We introduce a method for studying reduction types of arithmetic curves and\nwildly ramified base change. We give new proofs of earlier results of Lorenzini\nand Obus-Wewers, and resolve a question of Lorenzini on the Euler\ncharacteristic of the resolution graph of a $p$-cyclic arithmetic surface\nquotient singularity. Our method consists of constructing a simultaneous\nskeleton for the associated cover of Berkovich analytifications and applying a\nskeletal Riemann-Hurwitz formula.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-23T09:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.16546v1","title":"Tinkering Against Scaling","summary":"The ascent of scaling in artificial intelligence research has revolutionized\nthe field over the past decade, yet it presents significant challenges for\nacademic researchers, particularly in computational social science and critical\nalgorithm studies. The dominance of large language models, characterized by\ntheir extensive parameters and costly training processes, creates a disparity\nwhere only industry-affiliated researchers can access these resources. This\nimbalance restricts academic researchers from fully understanding their tools,\nleading to issues like reproducibility in computational social science and a\nreliance on black-box metaphors in critical studies.\n  To address these challenges, we propose a \"tinkering\" approach that is\ninspired by existing works. This method involves engaging with smaller models\nor components that are manageable for ordinary researchers, fostering hands-on\ninteraction with algorithms. We argue that tinkering is both a way of making\nand knowing for computational social science and a way of knowing for critical\nstudies, and fundamentally, it is a way of caring that has broader implications\nfor both fields.","main_category":"cs.CY","categories":"cs.CY,cs.HC","published":"2025-04-23T09:21:39Z"}
{"aid":"http://arxiv.org/abs/2504.16552v1","title":"DTVM: Revolutionizing Smart Contract Execution with Determinism and\n  Compatibility","summary":"We introduce the DeTerministic Virtual Machine (DTVM) Stack, a\nnext-generation smart contract execution framework designed to address critical\nperformance, determinism, and ecosystem compatibility challenges in blockchain\nnetworks. Building upon WebAssembly (Wasm) while maintaining full Ethereum\nVirtual Machine (EVM) ABI compatibility, DTVM introduces a Deterministic Middle\nIntermediate Representation (dMIR) and a hybrid lazy-JIT compilation engine to\nbalance compilation speed and execution efficiency. DTVM further accommodates\ndiverse instruction set architectures (e.g., EVM, RISC-V) through modular\nadaptation layers. This enables seamless integration with DTVM's hybrid\nlazy-JIT compilation engine, which dynamically optimizes performance while\npreserving deterministic execution guarantees across heterogeneous\nenvironments. The key contributions including: 1). The framework achieves up to\n2$\\times$ acceleration over evmone in dominant Ethereum contract (e.g.\nERC20/721/1155) execution and reduces fibonacci computation latency by\n11.8$\\sim$40.5% compared to Wasm based VMs. 2). A novel trampoline hot-switch\nmechanism enables sub-millisecond (0.95ms) post-deployment invocation times,\noutperforming up to about 23$\\times$ in compilation and invocation efficiency.\n3). It supports multi-language development (Solidity, C++, Rust, Java, Go, and\nAssemblyScript) through unified bytecode conversion while maintaining EVM ABI\ncompatibility for seamless invocation. It reduces machine code object sizes by\n30.0$\\sim$72.6%, coupled with a minimized Trusted Computing Base. 4). It offers\nSmartCogent, an AI-driven full-stack development experience, leveraging\nfine-tuned LLMs and retrieval-augmented generation to automate tasks across the\nsmart contract lifecycle: development, debugging, security auditing, and\ndeployment. DTVM Stack has been open-sourced (https://github.com/DTVMStack).","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-23T09:28:09Z"}
{"aid":"http://arxiv.org/abs/2504.16573v1","title":"PsyCounAssist: A Full-Cycle AI-Powered Psychological Counseling\n  Assistant System","summary":"Psychological counseling is a highly personalized and dynamic process that\nrequires therapists to continuously monitor emotional changes, document session\ninsights, and maintain therapeutic continuity. In this paper, we introduce\nPsyCounAssist, a comprehensive AI-powered counseling assistant system\nspecifically designed to augment psychological counseling practices.\nPsyCounAssist integrates multimodal emotion recognition combining speech and\nphotoplethysmography (PPG) signals for accurate real-time affective analysis,\nautomated structured session reporting using large language models (LLMs), and\npersonalized AI-generated follow-up support. Deployed on Android-based tablet\ndevices, the system demonstrates practical applicability and flexibility in\nreal-world counseling scenarios. Experimental evaluation confirms the\nreliability of PPG-based emotional classification and highlights the system's\npotential for non-intrusive, privacy-aware emotional support. PsyCounAssist\nrepresents a novel approach to ethically and effectively integrating AI into\npsychological counseling workflows.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-23T09:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.16574v1","title":"PIS: Linking Importance Sampling and Attention Mechanisms for Efficient\n  Prompt Compression","summary":"Large language models (LLMs) have achieved remarkable progress, demonstrating\nunprecedented capabilities across various natural language processing tasks.\nHowever, the high costs associated with such exceptional performance limit the\nwidespread adoption of LLMs, highlighting the need for prompt compression.\nExisting prompt compression methods primarily rely on heuristic truncation or\nabstractive summarization techniques, which fundamentally overlook the\nintrinsic mechanisms of LLMs and lack a systematic evaluation of token\nimportance for generation. In this work, we introduce Prompt Importance\nSampling (PIS), a novel compression framework that dynamically compresses\nprompts by sampling important tokens based on the analysis of attention scores\nof hidden states. PIS employs a dual-level compression mechanism: 1) at the\ntoken level, we quantify saliency using LLM-native attention scores and\nimplement adaptive compression through a lightweight 9-layer reinforcement\nlearning (RL) network; 2) at the semantic level, we propose a Russian roulette\nsampling strategy for sentence-level importance sampling. Comprehensive\nevaluations across multiple domain benchmarks demonstrate that our method\nachieves state-of-the-art compression performance. Notably, our framework\nserendipitously enhances reasoning efficiency through optimized context\nstructuring. This work advances prompt engineering by offering both theoretical\ngrounding and practical efficiency in context management for LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T09:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.16604v1","title":"Debunking with Dialogue? Exploring AI-Generated Counterspeech to\n  Challenge Conspiracy Theories","summary":"Counterspeech is a key strategy against harmful online content, but scaling\nexpert-driven efforts is challenging. Large Language Models (LLMs) present a\npotential solution, though their use in countering conspiracy theories is\nunder-researched. Unlike for hate speech, no datasets exist that pair\nconspiracy theory comments with expert-crafted counterspeech. We address this\ngap by evaluating the ability of GPT-4o, Llama 3, and Mistral to effectively\napply counterspeech strategies derived from psychological research provided\nthrough structured prompts. Our results show that the models often generate\ngeneric, repetitive, or superficial results. Additionally, they\nover-acknowledge fear and frequently hallucinate facts, sources, or figures,\nmaking their prompt-based use in practical applications problematic.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SI,I.2.7","published":"2025-04-23T10:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.16627v1","title":"TIFIN India at SemEval-2025: Harnessing Translation to Overcome\n  Multilingual IR Challenges in Fact-Checked Claim Retrieval","summary":"We address the challenge of retrieving previously fact-checked claims in\nmonolingual and crosslingual settings - a critical task given the global\nprevalence of disinformation. Our approach follows a two-stage strategy: a\nreliable baseline retrieval system using a fine-tuned embedding model and an\nLLM-based reranker. Our key contribution is demonstrating how LLM-based\ntranslation can overcome the hurdles of multilingual information retrieval.\nAdditionally, we focus on ensuring that the bulk of the pipeline can be\nreplicated on a consumer GPU. Our final integrated system achieved a success@10\nscore of 0.938 and 0.81025 on the monolingual and crosslingual test sets,\nrespectively.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T11:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.16659v1","title":"Evolutionary dynamics in state-feedback public goods games with peer\n  punishment","summary":"Public goods game serves as a valuable paradigm for studying the challenges\nof collective cooperation in human and natural societies. Peer punishment is\noften considered as an effective incentive for promoting cooperation in such\ncontexts. However, previous related studies have mostly ignored the positive\nfeedback effect of collective contributions on individual payoffs. In this\nwork, we explore global and local state-feedback, where the multiplication\nfactor is positively correlated with the frequency of contributors in the\nentire population or within the game group, respectively. By using replicator\ndynamics in an infinite well-mixed population we reveal that state-based\nfeedback plays a crucial role in alleviating the cooperative dilemma by\nenhancing and sustaining cooperation compared to the feedback-free case.\nMoreover, when the feedback strength is sufficiently strong or the baseline\nmultiplication factor is sufficiently high, the system with local\nstate-feedback provides full cooperation, hence supporting the ``think\nglobally, act locally'' principle. Besides, we show that the second-order\nfree-rider problem can be partially mitigated under certain conditions when the\nstate-feedback is employed. Importantly, these results remain robust with\nrespect to variations in punishment cost and fine.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-23T12:26:33Z"}
{"aid":"http://arxiv.org/abs/2504.16664v1","title":"Quantum walk search for exceptional configurations on one- and\n  two-dimensional lattice with extra long-range edges of HN4 network","summary":"There exist several types of configurations of marked vertices, referred to\nas the exceptional configurations, on one- and two-dimensional periodic\nlattices with additional long-range edges of the HN4 network, which are\nchallenging to find using discrete-time quantum walk algorithms. In this\narticle, we conduct a comparative analysis of the discrete-time quantum walk\nalgorithm utilizing various coin operators to search for these exceptional\nconfigurations. First, we study the emergence of several new exceptional\nconfigurations/vertices due to the additional long-range edges of the HN4\nnetwork on both one- and two-dimensional lattices. Second, our study shows that\nthe diagonal configuration on a two-dimensional lattice, which is exceptional\nin the case without long-range edges, no longer remains an exceptional\nconfiguration. Third, it is also shown that a recently proposed modified coin\ncan search all these configurations, including any other configurations in one-\nand two-dimensional lattices with very high success probability. Additionally,\nwe construct stationary states for the exceptional configurations caused by the\nadditional long-range edges, which explains why the standard and lackadaisical\nquantum walks with the Grover coin cannot search these configurations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T12:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.16689v1","title":"p-adic Cherednik algebras on rigid analytic spaces","summary":"Let $X$ be a smooth rigid space with an action of a finite group $G$\nsatisfying that $X/G$ is represented by a rigid space. We construct sheaves of\n$p$-adic Cherednik algebras on the small \\'etale site of the quotient $X/G$,\nand study some of their properties. The sheaves of $p$-adic Cherednik algebras\nare sheaves of Fr\\'echet $K$-algebras on $X/G$, which can be regarded as\n$p$-adic analytic versions of the sheaves of Cherednik algebras associated to\nthe action of a finite group on a smooth algebraic variety defined by P.\nEtingof. Furthermore, their sections on small enough $G$-invariant affinoid\nspaces are canonically Fr\\'echet-Stein algebras. Along the way, we construct\nsheaves of infinite order twisted differential operators on $X$, we give a\n$G$-equivariant classification of the Atiyah algebras (Picard algebroids) on\n$X$, and study the category of co-admissible modules over a sheaf of infinite\norder twisted differential operators.","main_category":"math.NT","categories":"math.NT,math.AG,math.QA","published":"2025-04-23T13:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.16702v1","title":"QED corrections to meson masses","summary":"We present our progress on calculating leading-order QED corrections to meson\nmasses and bare quark masses. As lattice QCD calculations become more precise,\nthese QED corrections are becoming more important. However, one of the\nchallenges in adding QED effects to QCD calculations is avoiding power-law\nsuppressed finite-volume effects. By using the recently introduced\ninfinite-volume reconstruction method for QED, we are able to avoid this\nproblem and perform calculations with exponentially-suppressed finite-volume\neffects.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-23T13:29:40Z"}
{"aid":"http://arxiv.org/abs/2504.16703v1","title":"Decidability Problems for Micro-Stipula","summary":"Micro-Stipula is a stateful calculus in which clauses can be activated either\nthrough interactions with the external environment or by the evaluation of time\nexpressions. Despite the apparent simplicity of its syntax and operational\nmodel, the combination of state evolution, time reasoning, and nondeterminism\ngives rise to significant analytical challenges. In particular, we show that\ndetermining whether a clause is never executed is undecidable. We formally\nprove that this undecidability result holds even for syntactically restricted\nfragments: namely, the time-ahead fragment, where all time expressions are\nstrictly positive, and the instantaneous fragment, where all time expressions\nevaluate to zero. On the other hand, we identify a decidable subfragment:\nwithin the instantaneous fragment, reachability becomes decidable when the\ninitial states of functions and events are disjoint.","main_category":"cs.LO","categories":"cs.LO,cs.FL","published":"2025-04-23T13:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.16743v1","title":"Implementing AI Bill of Materials (AI BOM) with SPDX 3.0: A\n  Comprehensive Guide to Creating AI and Dataset Bill of Materials","summary":"A Software Bill of Materials (SBOM) is becoming an increasingly important\ntool in regulatory and technical spaces to introduce more transparency and\nsecurity into a project's software supply chain.\n  Artificial intelligence (AI) projects face unique challenges beyond the\nsecurity of their software, and thus require a more expansive approach to a\nbill of materials. In this report, we introduce the concept of an AI-BOM,\nexpanding on the SBOM to include the documentation of algorithms, data\ncollection methods, frameworks and libraries, licensing information, and\nstandard compliance.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-23T14:13:19Z"}
{"aid":"http://arxiv.org/abs/2504.16765v1","title":"Geometry of T1 transitions in epithelia","summary":"The flows of tissues of epithelial cells often involve T1 transitions. These\nneighbour exchanges are irreversible rearrangements crossing an energy barrier.\nHere, by an exact geometric construction, I determine this energy barrier for\ngeneral, isolated T1 transitions dominated by line tensions. I show how\ndeviations from regular cell packing reduce this energy barrier, but find that\nline tension fluctuations increase it on average. By another exact\nconstruction, I show how nonlinear tensions in vertex models of epithelial\ntissues also resist T1 transitions. My results thus form the basis for\ncoarse-grained descriptions of cell neighbour exchanges in continuum models of\nepithelia.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-23T14:34:34Z"}
{"aid":"http://arxiv.org/abs/2504.16773v1","title":"On integrability of tri-vector deformed Type II string","summary":"We analyse dynamics of the closed Type IIA and IIB string on various\ntri-vector deformed background searching for signatures of integrability. Using\nnumerical methods we construct Poincar\\'e sections for particular embeddings of\nthe string and show that these are not destroyed under tri-vector deformation.\nWe find that the corresponding Lyapunov exponents decay showing that\ntrajectories do not diverge.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T14:45:16Z"}
{"aid":"http://arxiv.org/abs/2504.16781v1","title":"Strain Effect on Rashba Splitting and Phonon Scattering to Improve\n  Thermoelectric Performance of 2D Heterobilayer MoTe$_{2}$/PtS$_{2}$","summary":"Rashba spin-orbit coupling significantly modifies the electronic band\nstructure in two-dimensional (2D) van der Waals (vdW) heterobilayers, which may\nenhance their thermoelectric (TE) properties. In this study, we use\nfirst-principles calculations and Boltzmann transport theory to explore the\nstrain effect on the TE performance of the 2D vdW heterobilayer\nMoTe$_{2}$/PtS$_{2}$. A strong Rashba spin-splitting is observed in the valence\nband, resulting in an increase in the Seebeck coefficient for p-type. The\nlattice thermal conductivity of MoTe$_{2}$/PtS$_{2}$ is remarkably low about of\n0.6 Wm$^{-1}$K$^{-1}$ at $T = 300$ K due to large anharmonic scattering.\nFurthermore, biaxial strain enhances the power factor (PF) by introducing band\nconvergence. At a strain of 2\\%, the optimal PF for the n-type material reaches\n170 $\\mu$W/cmK$^{2}$, indicating approximately 84.78\\% increase compared to the\nunstrained state (92 $\\mu$W/cmK$^{2}$). Given the low lattice thermal\nconductivity, the optimized figure of merit $ZT$ achieves up to 0.88 at 900 K\nfor n-type. Our findings indicate that MoTe$_{2}$/PtS$_{2}$ is a highly\npromising candidate for 2D heterobilayer TE materials, owing to its strong\nRashba splitting and significant anharmonicity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-23T14:57:24Z"}
{"aid":"http://arxiv.org/abs/2504.16787v1","title":"Credible plan-driven RAG method for Multi-hop Question Answering","summary":"Multi-hop question answering (QA) presents a considerable challenge for\nRetrieval-Augmented Generation (RAG), requiring the structured decomposition of\ncomplex queries into logical reasoning paths and the generation of dependable\nintermediate results. However, deviations in reasoning paths or errors in\nintermediate results, which are common in current RAG methods, may propagate\nand accumulate throughout the reasoning process, diminishing the accuracy of\nthe answer to complex queries. To address this challenge, we propose the\nPlan-then-Act-and-Review (PAR RAG) framework, which is organized into three key\nstages: planning, act, and review, and aims to offer an interpretable and\nincremental reasoning paradigm for accurate and reliable multi-hop question\nanswering by mitigating error propagation.PAR RAG initially applies a top-down\nproblem decomposition strategy, formulating a comprehensive plan that\nintegrates multiple executable steps from a holistic viewpoint. This approach\navoids the pitfalls of local optima common in traditional RAG methods, ensuring\nthe accuracy of the entire reasoning path. Subsequently, PAR RAG incorporates a\nplan execution mechanism based on multi-granularity verification. By utilizing\nboth coarse-grained similarity information and fine-grained relevant data, the\nframework thoroughly checks and adjusts intermediate results, ensuring process\naccuracy while effectively managing error propagation and amplification.\nExperimental results on multi-hop QA datasets demonstrate that the PAR RAG\nframework substantially outperforms existing state-of-the-art methods in key\nmetrics, including EM and F1 scores.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.0","published":"2025-04-23T15:03:17Z"}
{"aid":"http://arxiv.org/abs/2504.16814v1","title":"Association-Based Track-Before-Detect with Object Contribution\n  Probabilities","summary":"Multiobject tracking provides situational awareness that enables new\napplications for modern convenience, applied ocean sciences, public safety, and\nhomeland security. In many multiobject tracking applications, including radar\nand sonar tracking, after coherent prefiltering of the received signal,\nmeasurement data is typically structured in cells, where each cell represent,\ne.g., a different range and bearing value. While conventional detect-then-track\n(DTT) multiobject tracking approaches convert the cell-structured data within a\ndetection phase into so-called point measurements in order to reduce the amount\nof data, track-before-detect (TBD) methods process the cell-structured data\ndirectly, avoiding a potential information loss. However, many TBD tracking\nmethods are computationally intensive and achieve a reduced tracking accuracy\nwhen objects interact, i.e., when they come into close proximity. We here\ncounteract these difficulties by introducing the concept of probabilistic\nobject-to-cell contributions. As many conventional DTT methods, our approach\nuses a probabilistic association of objects with data cells, and a new object\ncontribution model with corresponding object contribution probabilities to\nfurther associate cell contributions to objects that occupy the same data cell.\nFurthermore, to keep the computational complexity and filter runtimes low, we\nhere use an efficient Poisson multi-Bernoulli filtering approach in combination\nwith the application of belief propagation for fast probabilistic data\nassociation. We demonstrate numerically that our method achieves significantly\nincreased tracking performance compared to state-of-the-art TBD tracking\napproaches, where performance differences are particularly pronounced when\nmultiple objects interact.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T15:32:11Z"}
{"aid":"http://arxiv.org/abs/2504.16828v1","title":"Process Reward Models That Think","summary":"Step-by-step verifiers -- also known as process reward models (PRMs) -- are a\nkey ingredient for test-time scaling. PRMs require step-level supervision,\nmaking them expensive to train. This work aims to build data-efficient PRMs as\nverbalized step-wise reward models that verify every step in the solution by\ngenerating a verification chain-of-thought (CoT). We propose ThinkPRM, a long\nCoT verifier fine-tuned on orders of magnitude fewer process labels than those\nrequired by discriminative PRMs. Our approach capitalizes on the inherent\nreasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and\ndiscriminative verifiers -- using only 1% of the process labels in PRM800K --\nacross several challenging benchmarks. Specifically, ThinkPRM beats the\nbaselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and\nreward-guided search. In an out-of-domain evaluation on a subset of\nGPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers\ntrained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the\nsame token budget, ThinkPRM scales up verification compute more effectively\ncompared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of\nProcessBench. Our work highlights the value of generative, long CoT PRMs that\ncan scale test-time compute for verification while requiring minimal\nsupervision for training. Our code, data, and models will be released at\nhttps://github.com/mukhal/thinkprm.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-23T15:44:54Z"}
{"aid":"http://arxiv.org/abs/2504.16876v1","title":"New Primal-Dual Algorithm for Convex Problems","summary":"Primal-dual algorithm (PDA) is a classic and popular scheme for\nconvex-concave saddle point problems. It is universally acknowledged that the\nproximal terms in the subproblems about the primal and dual variables are\ncrucial to the convergence theory and numerical performance of primal-dual\nalgorithms. By taking advantage of the information from the current and\nprevious iterative points, we exploit two new proximal terms for the\nsubproblems about the primal and dual variables. Based on two new proximal\nterms, we present a new primal-dual algorithm for convex-concave saddle point\nproblems with bilinear coupling terms and establish its global convergence and\nO(1/N ) ergodic convergence rate. When either the primal function or the dual\nfunction is strongly convex, we accelerate the above proposed algorithm and\nshow that the corresponding algorithm can achieve O(1/N^2) convergence rate.\nSince the conditions for the stepsizes of the proposed algorithm are related\ndirectly to the spectral norm of the linear transform, which is difficult to\nobtain in some applications, we also introduce a linesearch strategy for the\nabove proposed primal-dual algorithm and establish its global convergence and\nO(1/N ) ergodic convergence rate . Some numerical experiments are conducted on\nmatrix game and LASSO problems by comparing with other state-of-the-art\nalgorithms, which demonstrate the effectiveness of the proposed three\nprimal-dual algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.16880v1","title":"Quantum circuits for simulating linear interferometers","summary":"Motivated by recent proposals for quantum proof of work protocols, we\ninvestigate approaches for simulating linear optical interferometers using\ndigital quantum circuits. We focus on a second quantisation approach, where the\nquantum computer's registers represent optical modes. We can then use standard\nquantum optical techniques to decompose the unitary matrix describing an\ninterferometer into an array of $2\\times 2$ unitaries, which are subsequently\nsynthesised into quantum circuits and stitched together to complete the\ncircuit. For an $m$ mode interferometer with $n$ identical photons, this method\nrequires approximately $\\mathcal{O}(m \\log(n))$ qubits and a circuit depth of\n$\\mathcal{O}(m n^4 \\log_2(n) \\: \\textrm{polylog}(n^4 / \\epsilon))$. We present\na software package Aquinas (A QUantum INterferometer ASsembler) that uses this\napproach to generate such quantum circuits. For reference, an arbitrary five\nmode interferometer with two identical photons is compiled to a 10 qubit\nquantum circuit with a depth of 1972.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T16:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.16896v1","title":"Memory-efficient Sketch Acceleration for Handling Large Network Flows on\n  FPGAs","summary":"Sketch-based algorithms for network traffic monitoring have drawn increasing\ninterest in recent years due to their sub-linear memory efficiency and high\naccuracy. As the volume of network traffic grows, software-based sketch\nimplementations cannot match the throughput of the incoming network flows.\nFPGA-based hardware sketch has shown better performance compared to software\nrunning on a CPU when handling these packets. Among the various sketch\nalgorithms, Count-min sketch is one of the most popular and efficient. However,\ndue to the limited amount of on-chip memory, the FPGA-based count-Min sketch\naccelerator suffers from performance drops as network traffic grows. In this\nwork, we propose a hardware-friendly architecture with a variable width memory\ncounter for count-min sketch. Our architecture provides a more compact design\nto store the sketch data structure effectively, allowing us to support larger\nhash tables and reduce overestimation errors. The design makes use of a\nP4-based programmable data plane and the AMD OpenNIC shell. The design is\nimplemented and verified on the Open Cloud Testbed running on AMD Alveo U280s\nand can keep up with the 100 Gbit link speed.","main_category":"cs.AR","categories":"cs.AR,cs.NI","published":"2025-04-23T17:24:58Z"}
{"aid":"http://arxiv.org/abs/2504.16909v1","title":"The CKN inequality for spinors: symmetry and symmetry breaking","summary":"This paper is devoted to Sobolev interpolation inequalities for spinors, with\nweights of Caffarelli-Kohn-Nirenberg (CKN) type. In view of the corresponding\nresults for scalar functions, a natural question is to determine whether\noptimal spinors have symmetry properties, or whether spinors with symmetry\nproperties are linearly unstable, in which case we shall say that symmetry\nbreaking occurs. What symmetry means has to be carefully defined and the\noverall picture turns out to be richer than in the scalar case. So far, no\nsymmetrization technique is available in the spinorial case. We can however\ndetermine a range of the parameters for which symmetry holds using a detailed\nanalysis based mostly on spectral methods.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-23T17:37:38Z"}
{"aid":"http://arxiv.org/abs/2504.16917v1","title":"Application of an attention-based CNN-BiLSTM framework for in vivo\n  two-photon calcium imaging of neuronal ensembles: decoding complex bilateral\n  forelimb movements from unilateral M1","summary":"Decoding behavior, such as movement, from multiscale brain networks remains a\ncentral objective in neuroscience. Over the past decades, artificial\nintelligence and machine learning have played an increasingly significant role\nin elucidating the neural mechanisms underlying motor function. The advancement\nof brain-monitoring technologies, capable of capturing complex neuronal signals\nwith high spatial and temporal resolution, necessitates the development and\napplication of more sophisticated machine learning models for behavioral\ndecoding. In this study, we employ a hybrid deep learning framework, an\nattention-based CNN-BiLSTM model, to decode skilled and complex forelimb\nmovements using signals obtained from in vivo two-photon calcium imaging. Our\nfindings demonstrate that the intricate movements of both ipsilateral and\ncontralateral forelimbs can be accurately decoded from unilateral M1 neuronal\nensembles. These results highlight the efficacy of advanced hybrid deep\nlearning models in capturing the spatiotemporal dependencies of neuronal\nnetworks activity linked to complex movement execution.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.LG","published":"2025-04-23T17:43:00Z"}
{"aid":"http://arxiv.org/abs/2504.17242v1","title":"Rapid and Scalable Synthesis of Alkali Metal-Intercalated C$_{60}$\n  Superconductors","summary":"Alkali metal-intercalated C$_{60}$, $A_3$$C_{60}$ ($A$ = K, Rb, Cs, and their\ncombinations), holds significant potential for practical applications due to\nits high superconducting transition temperature (33 K), high upper critical\nfield (900 kOe), and isotropic superconductivity. However, application-oriented\nresearch has been limited by the lack of an efficient $A_3$$C_{60}$ synthesis\nprocess. In this study, we demonstrate a rapid and scalable synthesis of\n$A_3$$C_{60}$ ($A$ = K, Rb, and Cs$_{1/3}$Rb$_{2/3}$) via direct mixing of $A$\nand C$_{60}$, realizing the fabrication of high-quality sintered $A_3$$C_{60}$\npellets within just 1 hour of heating at 200-300{\\deg}C. The pellets exhibited\nlarge superconducting shielding volume fractions with sharp transitions, and\nthe relationship between the lattice constant and transition temperature was in\ngood agreement with previous reports. This direct mixing method enables simple\nand rapid production of large quantities of $A_3$$C_{60}$, which is expected to\naccelerate research into applications such as superconducting wires and bulk\nmagnets.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-24T04:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.17246v1","title":"A Sandwich Model for Changing-Look AGNs","summary":"The spectral variability of changing-look active galactic nuclei (CL-AGNs)\noccurred on timescales of years to tens of years, posing a significant\nchallenge to the standard thin disk model. In this work, we propose a sandwich\nmodel, including an optically thick disk in the mid-plane (Disk 1) and two\ndisks of low effective optical depth on both sides (Disk 2). These two types of\ndisks are coupled with magnetic fields, which allow viscous torque interaction\nbetween them. As a consequence, the radial velocity of Disk 1 can increase by\nup to three orders of magnitude compared to the standard thin disk, leading to\nan equivalent decrease in the accretion timescale. Therefore, such a sandwich\nmodel can account for the rapid variability in CL-AGNs. In addition, we also\ndiscuss the influence of the magnetic pressure on Disk 2. When Disk 2 is\ndominated by the magnetic pressure, it resembles a \"warm corona\", which is\nresponsible for the soft X-ray excess.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-24T04:49:19Z"}
{"aid":"http://arxiv.org/abs/2504.17256v1","title":"A Comment on \"e-PoS: Making PoS Decentralized and Fair\"","summary":"Proof-of-Stake (PoS) is a prominent Sybil control mechanism for\nblockchain-based systems. In \"e-PoS: Making PoS Decentralized and Fair,\" Saad\net al. (TPDS'21) introduced a new Proof-of-Stake protocol, e-PoS, to enhance\nPoS applications' decentralization and fairness. In this comment paper, we\naddress a misunderstanding in the work of Saad et al. The conventional\nProof-of-Stake model that causes the fairness problem does not align with the\ngeneral concept of Proof-of-Stake nor the Proof-of-Stake cryptocurrencies\nmentioned in their paper.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T05:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.17267v1","title":"MV-Crafter: An Intelligent System for Music-guided Video Generation","summary":"Music videos, as a prevalent form of multimedia entertainment, deliver\nengaging audio-visual experiences to audiences and have gained immense\npopularity among singers and fans. Creators can express their interpretations\nof music naturally through visual elements. However, the creation process of\nmusic video demands proficiency in script design, video shooting, and\nmusic-video synchronization, posing significant challenges for\nnon-professionals. Previous work has designed automated music video generation\nframeworks. However, they suffer from complexity in input and poor output\nquality. In response, we present MV-Crafter, a system capable of producing\nhigh-quality music videos with synchronized music-video rhythm and style. Our\napproach involves three technical modules that simulate the human creation\nprocess: the script generation module, video generation module, and music-video\nsynchronization module. MV-Crafter leverages a large language model to generate\nscripts considering the musical semantics. To address the challenge of\nsynchronizing short video clips with music of varying lengths, we propose a\ndynamic beat matching algorithm and visual envelope-induced warping method to\nensure precise, monotonic music-video synchronization. Besides, we design a\nuser-friendly interface to simplify the creation process with intuitive editing\nfeatures. Extensive experiments have demonstrated that MV-Crafter provides an\neffective solution for improving the quality of generated music videos.","main_category":"cs.HC","categories":"cs.HC,cs.MM","published":"2025-04-24T05:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.17277v1","title":"ExOSITO: Explainable Off-Policy Learning with Side Information for\n  Intensive Care Unit Blood Test Orders","summary":"Ordering a minimal subset of lab tests for patients in the intensive care\nunit (ICU) can be challenging. Care teams must balance between ensuring the\navailability of the right information and reducing the clinical burden and\ncosts associated with each lab test order. Most in-patient settings experience\nfrequent over-ordering of lab tests, but are now aiming to reduce this burden\non both hospital resources and the environment. This paper develops a novel\nmethod that combines off-policy learning with privileged information to\nidentify the optimal set of ICU lab tests to order. Our approach, EXplainable\nOff-policy learning with Side Information for ICU blood Test Orders (ExOSITO)\ncreates an interpretable assistive tool for clinicians to order lab tests by\nconsidering both the observed and predicted future status of each patient. We\npose this problem as a causal bandit trained using offline data and a reward\nfunction derived from clinically-approved rules; we introduce a novel learning\nframework that integrates clinical knowledge with observational data to bridge\nthe gap between the optimal and logging policies. The learned policy function\nprovides interpretable clinical information and reduces costs without omitting\nany vital lab orders, outperforming both a physician's policy and prior\napproaches to this practical problem.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T06:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.17280v1","title":"EdgePoint2: Compact Descriptors for Superior Efficiency and Accuracy","summary":"The field of keypoint extraction, which is essential for vision applications\nlike Structure from Motion (SfM) and Simultaneous Localization and Mapping\n(SLAM), has evolved from relying on handcrafted methods to leveraging deep\nlearning techniques. While deep learning approaches have significantly improved\nperformance, they often incur substantial computational costs, limiting their\ndeployment in real-time edge applications. Efforts to create lightweight neural\nnetworks have seen some success, yet they often result in trade-offs between\nefficiency and accuracy. Additionally, the high-dimensional descriptors\ngenerated by these networks poses challenges for distributed applications\nrequiring efficient communication and coordination, highlighting the need for\ncompact yet competitively accurate descriptors. In this paper, we present\nEdgePoint2, a series of lightweight keypoint detection and description neural\nnetworks specifically tailored for edge computing applications on embedded\nsystem. The network architecture is optimized for efficiency without\nsacrificing accuracy. To train compact descriptors, we introduce a combination\nof Orthogonal Procrustes loss and similarity loss, which can serve as a general\napproach for hypersphere embedding distillation tasks. Additionally, we offer\n14 sub-models to satisfy diverse application requirements. Our experiments\ndemonstrate that EdgePoint2 consistently achieves state-of-the-art (SOTA)\naccuracy and efficiency across various challenging scenarios while employing\nlower-dimensional descriptors (32/48/64). Beyond its accuracy, EdgePoint2\noffers significant advantages in flexibility, robustness, and versatility.\nConsequently, EdgePoint2 emerges as a highly competitive option for visual\ntasks, especially in contexts demanding adaptability to diverse computational\nand communication constraints.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T06:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.17294v1","title":"Higher-Spin Currents and Flows in Auxiliary Field Sigma Models","summary":"We study local, higher-spin conserved currents in integrable $2d$ sigma\nmodels that have been deformed via coupling to auxiliary fields. These currents\ngenerate integrability-preserving flows introduced by Smirnov and\nZamolodchikov. For auxiliary field (AF) deformations of a free boson, we prove\nthat local spin-$n$ currents exist for all $n$ and give recursion relations\nthat characterize Smirnov-Zamolodchikov (SZ) flows driven by these currents. We\nthen show how to construct spin-$2n$ currents in a unified class of auxiliary\nfield sigma models with common structure -- including AF theories based on the\nprincipal chiral model (PCM), its non-Abelian T-dual, (bi-)Yang-Baxter\ndeformations of the PCM, and symmetric space models -- for interaction\nfunctions of one variable, and describe SZ flows driven by any function of the\nstress tensor in these cases. Finally, we give perturbative solutions for\nspin-$3$ SZ flows in any member of our unified class of AF models with\nunderlying $\\mathfrak{su}(3)$ algebra. Part of our analysis shows that the\nclass of AF deformations can be extended by allowing the interaction function\nto depend on a larger set of variables than has previously been considered.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,nlin.SI","published":"2025-04-24T06:42:51Z"}
{"aid":"http://arxiv.org/abs/2504.17297v1","title":"Knapsack on Graphs with Relaxed Neighborhood Constraints","summary":"In the knapsack problems with neighborhood constraints that were studied\nbefore, the input is a graph $\\mathcal{G}$ on a set $\\mathcal{V}$ of items,\neach item $v \\in \\mathcal{V}$ has a weight $w_v$ and profit $p_v$, the size $s$\nof the knapsack, and the demand $d$. The goal is to compute if there exists a\nfeasible solution whose total weight is at most $s$ and total profit is at most\n$d$. Here, feasible solutions are all subsets $\\mathcal{S}$ of the items such\nthat, for every item in $\\mathcal{S}$, at least one of its neighbors in\n$\\mathcal{G}$ is also in $\\mathcal{S}$ for \\hor, and all its neighbors in\n$\\mathcal{G}$ are also in $\\mathcal{S}$ for\n\\hand~\\cite{borradaile2012knapsack}. We study a relaxation of the above\nproblems. Specifically, we allow all possible subsets of items to be feasible\nsolutions. However, only those items for which we pick at least one or all of\nits neighbor (out-neighbor for directed graph) contribute to profit whereas\nevery item picked contribute to the weight; we call the corresponding problems\n\\sor and \\sand. We show that both \\sor and \\sand are strongly \\NPC even on\nundirected graphs. Regarding parameterized complexity, we show both \\sor and\n\\hor are \\WTH parameterized by the size $s$ of the knapsack size.\nInterestingly, both \\sand and \\hand are \\WOH parameterized by knapsack size,\n$s$ plus profit demand, $d$ and also parameterized by solution size, $b$. For\n\\sor and \\hor, we present a randomized color-coding-based pseudo-\\FPT\nalgorithm, parameterized by the solution size $b$, and consequently by the\ndemand $d$. We then consider the treewidth of the input graph as our parameter\nand design pseudo fixed-parameter tractable (\\FPT) algorithm parameterized by\ntreewidth, $\\text{tw}$ for all variants. Finally, we present an additive $1$\napproximation for \\sor when both the weight and profit of every vertex is $1$.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-24T06:46:28Z"}
{"aid":"http://arxiv.org/abs/2504.17307v1","title":"An Extensible Software Transport Layer for GPU Networking","summary":"Fast-evolving machine learning (ML) workloads have increasing requirements\nfor networking. However, host network transport on RDMA NICs is hard to evolve,\ncausing problems for ML workloads. For example, single-path RDMA traffic is\nprone to flow collisions that severely degrade collective communication\nperformance. We present UCCL, an extensible software transport layer to evolve\nGPU networking. UCCL decouples the data path and control path of existing RDMA\nNICs and efficiently runs the control-path transport on host CPUs. This\nsoftware extensibility brings in transport innovations that cannot be achieved\nin hardware for ML workloads, e.g., a multipath transport to resolve flow\ncollisions. ML collectives atop UCCL achieve up to 3.3x higher performance\ncompared to an industry solution.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-24T07:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.17310v1","title":"An All-Optical Metro Network Architecture and QoS-Aware Wavelength\n  Allocation Study for Converged Fixed, Mobile, and Edge Computing\n  Multi-Granular Traffic","summary":"In this paper, we introduce an all-optical metro network architecture, called\nMOON, to serve converged multigranular traffic from fixed, mobile, and edge\ncomputing services. Since traffic is characterized by high dynamicity and\ndiverse access requirements, MOON uses network slicing to provide quality of\nservice (QoS) aware wavelength allocation to fulfill the various applications\ntraffic demands. MOON incorporates hybrid optical switching (HOS) combining\noptical circuit switching (OCS) and optical time slotted switching (OTS)\ncapabilities that appropriately maps different traffic types to them.\nSpecifically, the OCS network slice explicitly serves aggregated traffic of\nlong duration and high volume, while OTS network slice serves short bursty\ntraffic. In order to provide flexibility, separate sets of wavelengths are used\nfor OCS and OTS traffic service, both within a metro-access network (MAN)\n(intra-MAN) and between different MANs (inter-MAN). We extensively study the\nrequired number of wavelengths to efficiently serve OCS and OTS traffic for\nintra- and inter-MAN communication scenarios, taking into account their\nspecific traffic access requirements in an effort to optimize wavelengths\nutilization. In our study, we assume nonblocking OCS communication for\nimmediate access; therefore the number of required OCS wavelengths depends only\non the number of nodes, while the number of required OTS wavelengths to obtain\na desired QoS and latency level is independent from the number for OCS\nwavelengths. Simulation results show that within an OTS intra-MAN we achieve\nend-to-end (E2E) latency in submilliseconds scale, suitable for dynamic bursty\ntraffic, while it is an decreasing function of the number of used OTS\nwavelengths.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-24T07:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.17332v1","title":"Bridging Cognition and Emotion: Empathy-Driven Multimodal Misinformation\n  Detection","summary":"In the digital era, social media has become a major conduit for information\ndissemination, yet it also facilitates the rapid spread of misinformation.\nTraditional misinformation detection methods primarily focus on surface-level\nfeatures, overlooking the crucial roles of human empathy in the propagation\nprocess. To address this gap, we propose the Dual-Aspect Empathy Framework\n(DAE), which integrates cognitive and emotional empathy to analyze\nmisinformation from both the creator and reader perspectives. By examining\ncreators' cognitive strategies and emotional appeals, as well as simulating\nreaders' cognitive judgments and emotional responses using Large Language\nModels (LLMs), DAE offers a more comprehensive and human-centric approach to\nmisinformation detection. Moreover, we further introduce an empathy-aware\nfiltering mechanism to enhance response authenticity and diversity.\nExperimental results on benchmark datasets demonstrate that DAE outperforms\nexisting methods, providing a novel paradigm for multimodal misinformation\ndetection.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T07:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.17345v1","title":"A Rellich-type theorem for the Helmholtz equation in a junction of\n  stratified media","summary":"We prove that there are no non-zero square-integrable solutions to a\ntwo-dimensional Helmholtz equation in some unbounded inhomogeneous domains\nwhich represent junctions of stratified media. More precisely, we consider\ndomains that are unions of three half-planes, where each half-plane is\nstratified in the direction orthogonal to its boundary. As for the well-known\nRellich uniqueness theorem for a homogeneous exterior domain, our result does\nnot require any boundary condition. Our proof is based on half-plane\nrepresentations of the solution which are derived through a generalization of\nthe Fourier transform adapted to stratified media. A byproduct of our result is\nthe absence of trapped modes at the junction of open waveguides as soon as the\nangles between branches are greater than $\\pi$/2.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-04-24T08:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.17398v1","title":"An Inverse Source Problem for Semilinear Stochastic Hyperbolic Equations","summary":"This paper investigates an inverse source problem for general semilinear\nstochastic hyperbolic equations. Motivated by the challenges arising from both\nrandomness and nonlinearity, we develop a globally convergent iterative\nregularization method that combines Carleman estimate with fixed-point\niteration. Our approach enables the reconstruction of the unknown source\nfunction from partial lateral Cauchy data, without requiring a good initial\nguess. We establish a new Carleman estimate for stochastic hyperbolic equations\nand prove the convergence of the proposed method in weighted spaces.\nFurthermore, we design an efficient numerical algorithm that avoids solving\nbackward stochastic partial differential equations and is robust to randomness\nin both the model and the data. Numerical experiments are provided to\ndemonstrate the effectiveness of the method.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-24T09:38:57Z"}
{"aid":"http://arxiv.org/abs/2504.17407v1","title":"Stability of Stochastically Forced Solitons in the Korteweg-de Vries\n  Equation","summary":"We study the stability and dynamics of solitons in the Korteweg-de Vries\n(KdV) equation in the presence of noise and deterministic forcing. The noise is\nspace-dependent and statistically translation-invariant. We show that, for\nsmall forcing, solitons remain close to the family of traveling waves in a\nweighted Sobolev norm, with high probability. We study the effective dynamics\nof the soliton amplitude and position via their variational phase, for which we\nderive explicit modulation equations. The stability result holds on a time\nscale where the deterministic forcing induces significant amplitude modulation.","main_category":"math.AP","categories":"math.AP,math.PR","published":"2025-04-24T09:58:03Z"}
{"aid":"http://arxiv.org/abs/2504.17437v1","title":"Lectures on measurement in quantum field theory","summary":"These lectures present a brief introduction to measurement theory for QFT in\npossibly curved spacetimes introduced by the author and R. Verch [Comm. Math.\nPhys. 378 (2020) 851-889]. Topics include: a brief introduction to algebraic\nQFT, measurement schemes in QFT, state updates, multiple measurements and the\nresolution of Sorkin's \"impossible measurement\" problem. Examples using\nsuitable theories based on Green hyperbolic operators are given, and the\ninterpretational significance of the framework is briefly considered. The basic\nstyle is to give details relating to QFT while taking for granted various facts\nfrom the theory of globally hyperbolic spacetimes.","main_category":"gr-qc","categories":"gr-qc,math-ph,math.MP,quant-ph","published":"2025-04-24T10:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.17441v1","title":"Predict-Optimize-Distill: A Self-Improving Cycle for 4D Object\n  Understanding","summary":"Humans can resort to long-form inspection to build intuition on predicting\nthe 3D configurations of unseen objects. The more we observe the object motion,\nthe better we get at predicting its 3D state immediately. Existing systems\neither optimize underlying representations from multi-view observations or\ntrain a feed-forward predictor from supervised datasets. We introduce\nPredict-Optimize-Distill (POD), a self-improving framework that interleaves\nprediction and optimization in a mutually reinforcing cycle to achieve better\n4D object understanding with increasing observation time. Given a multi-view\nobject scan and a long-form monocular video of human-object interaction, POD\niteratively trains a neural network to predict local part poses from RGB\nframes, uses this predictor to initialize a global optimization which refines\noutput poses through inverse rendering, then finally distills the results of\noptimization back into the model by generating synthetic self-labeled training\ndata from novel viewpoints. Each iteration improves both the predictive model\nand the optimized motion trajectory, creating a virtuous cycle that bootstraps\nits own training data to learn about the pose configurations of an object. We\nalso introduce a quasi-multiview mining strategy for reducing depth ambiguity\nby leveraging long video. We evaluate POD on 14 real-world and 5 synthetic\nobjects with various joint types, including revolute and prismatic joints as\nwell as multi-body configurations where parts detach or reattach independently.\nPOD demonstrates significant improvement over a pure optimization baseline\nwhich gets stuck in local minima, particularly for longer videos. We also find\nthat POD's performance improves with both video length and successive\niterations of the self-improving cycle, highlighting its ability to scale\nperformance with additional observations and looped refinement.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T11:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.17450v1","title":"Optimizing thermoelectric performance of graphene antidot lattices via\n  quantum transport and machine-learning molecular dynamics simulations","summary":"Thermoelectric materials, which can convert waste heat to electricity or be\nutilized as solid-state coolers, hold promise for sustainable energy\napplications. However, optimizing thermoelectric performance remains a\nsignificant challenge due to the complex interplay between electronic and\nthermal transport properties. In this work, we systematically optimize $ZT$ in\ngraphene antidot lattices (GALs), nanostructured graphene sheets with periodic\nnanopores characterized by two geometric parameters: the hexagonal unit cell\nside length $L$ and the antidot radius $R$. The lattice thermal conductivity is\ndetermined through machine-learned potential-driven molecular dynamics (MD)\nsimulations, while electronic transport properties are computed using\nlinear-scaling quantum transport in combination with MD trajectories based on a\nbond-length-dependent tight-binding model. This method is able to account for\nelectron-phonon scattering, allowing access to diffusive transport in\nlarge-scale systems, overcoming limitations of previous methods based on\nnonequilibrium Green function formalism. Our results show that the introduction\nof the antidots effectively decouples lattice and electronic transport and lead\nto a favorable and significant violation of the Wiedemann-Franz law. We find\nthat optimal $ZT$ values occur in GALs with intermediate $L$ and $R$, closely\ncorrelated with peak power factor values. Notably, thermoelectric performance\npeaks near room temperature, with maximal $ZT$ values approaching 2,\nhighlighting GALs as promising candidates for high-performance thermoelectric\nenergy conversion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-24T11:29:06Z"}
{"aid":"http://arxiv.org/abs/2504.17471v1","title":"GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework","summary":"Gossip Learning (GL) is a decentralized learning paradigm where users\niteratively exchange and aggregate models with a small set of neighboring\npeers. Recent GL approaches rely on dynamic communication graphs built and\nmaintained using Random Peer Sampling (RPS) protocols. Thanks to graph\ndynamics, GL can achieve fast convergence even over extremely sparse\ntopologies. However, the robustness of GL over dy- namic graphs to Byzantine\n(model poisoning) attacks remains unaddressed especially when Byzantine nodes\nattack the RPS protocol to scale up model poisoning. We address this issue by\nintroducing GRANITE, a framework for robust learning over sparse, dynamic\ngraphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two\nkey components (i) a History-aware Byzantine-resilient Peer Sampling protocol\n(HaPS), which tracks previously encountered identifiers to reduce adversarial\ninfluence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which\nleverages an estimate of Byzantine presence to set aggregation thresholds with\nformal guarantees. Empirical results confirm that GRANITE maintains convergence\nwith up to 30% Byzantine nodes, improves learning speed via adaptive filtering\nof poisoned models and obtains these results in up to 9 times sparser graphs\nthan dictated by current theory.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC","published":"2025-04-24T12:03:15Z"}
{"aid":"http://arxiv.org/abs/2504.17475v1","title":"Odd fake $\\mathbb{Q}$ -homology quadrics exist","summary":"We show the existence of odd fake $\\mathbb{Q}$-homology quadrics, namely of\nminimal surfaces $S$ of general type which have the same $\\mathbb{Q}$-homology\nas a smooth quadric $Q \\cong (\\mathbb{P}^1(\\mathbb{C}))^2$, but have an odd\nintersection form on $ H^2(S, \\mathbb{Z})/Tors(S)$, where $Tors(S)$ is the\nTorsion subgroup.\n  Our examples are provided by a special 1-dimensional family of surfaces\nisogenous to a product of unmixed type.","main_category":"math.AG","categories":"math.AG,math.AT","published":"2025-04-24T12:07:19Z"}
{"aid":"http://arxiv.org/abs/2504.17522v1","title":"Towards One-Stage End-to-End Table Structure Recognition with Parallel\n  Regression for Diverse Scenarios","summary":"Table structure recognition aims to parse tables in unstructured data into\nmachine-understandable formats. Recent methods address this problem through a\ntwo-stage process or optimized one-stage approaches. However, these methods\neither require multiple networks to be serially trained and perform more\ntime-consuming sequential decoding, or rely on complex post-processing\nalgorithms to parse the logical structure of tables. They struggle to balance\ncross-scenario adaptability, robustness, and computational efficiency. In this\npaper, we propose a one-stage end-to-end table structure parsing network called\nTableCenterNet. This network unifies the prediction of table spatial and\nlogical structure into a parallel regression task for the first time, and\nimplicitly learns the spatial-logical location mapping laws of cells through a\nsynergistic architecture of shared feature extraction layers and task-specific\ndecoding. Compared with two-stage methods, our method is easier to train and\nfaster to infer. Experiments on benchmark datasets show that TableCenterNet can\neffectively parse table structures in diverse scenarios and achieve\nstate-of-the-art performance on the TableGraph-24k dataset. Code is available\nat https://github.com/dreamy-xay/TableCenterNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T13:03:13Z"}
{"aid":"http://arxiv.org/abs/2504.17532v1","title":"Permeation and thermal desorption model of hydrogen in steel: a\n  sensitivity analysis","summary":"This work presents a fully physical model of the hydrogen diffusion and\ntrapping kinetics in metals, integrating permeation and thermal desorption\nwithin a unified framework. Based on the McNabb and Foster approach, it\nrequires only binding energy and number density of trap sites. It correctly\nreproduces the physics of the system and the results of the analytical\nsolutions of the permeation kinetics. It is also capable of reproducing thermal\ndesorption spectra with considerable accuracy. The sensitivity analysis has\nelucidated the relationships among the processing conditions and the parameters\ncommonly used to characterize permeation and thermal desorption experiments. An\nequation empirically derived from the simulation results, expressing the\ndependence of time lag in desorption on specimen thickness, number density of\noccupied trap sites, and cathodic concentration, is proposed. In summary, the\nmodel represents a valuable tool in supporting the interpretation and\nrationalization of experiments also from a quantitative viewpoint.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T13:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.17546v1","title":"An introduction to R package `mvs`","summary":"In biomedical science, a set of objects or persons can often be described by\nmultiple distinct sets of features obtained from different data sources or\nmodalities (called \"multi-view data\"). Classical machine learning methods\nignore the multi-view structure of such data, limiting model interpretability\nand performance. The R package `mvs` provides methods that were designed\nspecifically for dealing with multi-view data, based on the multi-view stacking\n(MVS) framework. MVS is a form of supervised (machine) learning used to train\nmulti-view classification or prediction models. MVS works by training a\nlearning algorithm on each view separately, estimating the predictive power of\neach view-specific model through cross-validation, and then using another\nlearning algorithm to assign weights to the view-specific models based on their\nestimated predictions. MVS is a form of ensemble learning, dividing the large\nmulti-view learning problem into smaller sub-problems. Most of these\nsub-problems can be solved in parallel, making it computationally attractive.\nAdditionally, the number of features of the sub-problems is greatly reduced\ncompared with the full multi-view learning problem. This makes MVS especially\nuseful when the total number of features is larger than the number of\nobservations (i.e., high-dimensional data). MVS can still be applied even if\nthe sub-problems are themselves high-dimensional by adding suitable penalty\nterms to the learning algorithms. Furthermore, MVS can be used to automatically\nselect the views which are most important for prediction. The R package `mvs`\nmakes fitting MVS models, including such penalty terms, easily and openly\naccessible. `mvs` allows for the fitting of stacked models with any number of\nlevels, with different penalty terms, different outcome distributions, and\nprovides several options for missing data handling.","main_category":"stat.CO","categories":"stat.CO,cs.LG,stat.ME,stat.ML","published":"2025-04-24T13:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.17581v1","title":"A non-uniform metal distribution in the ram-pressure stripped M86 group\n  of galaxies","summary":"The chemical enrichment of X-ray-emitting hot halos has primarily been\nstudied in closed-box galaxy clusters. Investigating the metal content of\nlower-mass, open systems can serve as a valuable tracer for understanding their\ndynamical history and the extent of chemical enrichment mechanisms in the\nUniverse. In this context, we use an 85.6 ks XMM-Newton observation to study\nthe spatial distribution of the abundance ratios of Mg, Si, and S with respect\nto Fe in the hot gas of the ram-pressure-stripped M86, which has undergone\nmorphological transformations. We report that the chemical composition in the\nM86 galaxy core is more similar to the rest of the hot gaseous content of the\nUniverse than to its stellar population. This result indicate that even extreme\nsupersonic ram-pressure is insufficient to strip the inner part of a galaxy of\nits hot atmosphere. Comparison with other galaxies undergoing ram-pressure\nstripping suggests that stripping the \"primordial\" atmosphere of a galaxy\nrequires a combination of ram-pressure stripping and strong radio-mechanical\nAGN activity. The X-ray emission structures within M86, the plume and the tail,\nare found to be relatively isothermal. We observe that the Mg/Fe ratio in the\nplume is $3.3\\sigma$ higher than in the M86 galaxy core and is consistent with\nthat in the M86 group outskirts and the Virgo ICM, suggesting that the plume\nmight originate from the low-entropy group gas due to a galaxy-galaxy collision\nrather than from the ram-pressure stripping of the dense galaxy core.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-04-24T14:11:13Z"}
{"aid":"http://arxiv.org/abs/2504.17608v1","title":"The Cauchy--Szeg√∂ Projection for domains in $\\mathbb C^n$ with\n  minimal smoothness: weighted theory","summary":"Let $D\\subset\\mathbb C^n$ be a bounded, strongly pseudoconvex domain whose\nboundary $bD$ satisfies the minimal regularity condition of class $C^2$. A 2017\nresult of Lanzani \\& Stein states that the Cauchy--Szeg\\\"{o} projection\n$S_\\omega$ defined with respect to a bounded, positive continuous multiple\n$\\omega$ of induced Lebesgue measure, {maps $L^p(bD, \\omega)$ to $L^p(bD,\n\\omega)$ continuously} for any $1<p<\\infty$. Here we show that $S_\\omega$\nsatisfies explicit quantitative bounds in $L^p(bD, \\Omega)$, for any\n$1<p<\\infty$ and for any $\\Omega$ in the maximal class of\n\\textit{$A_p$}-measures, that is for $\\Omega_p = \\psi_p\\sigma$ where $\\psi_p$\nis a Muckenhoupt $A_p$-weight and $\\sigma$ is the induced Lebesgue measure\n(with $\\omega$'s as above being a sub-class). Earlier results rely upon an\nasymptotic expansion and subsequent pointwise estimates of the Cauchy--Szeg\\\"o\nkernel, but these are unavailable in our setting of minimal regularity {of\n$bD$}; at the same time, more recent techniques that allow to handle domains\nwith minimal regularity (Lanzani--Stein 2017) are not applicable to\n$A_p$-measures. It turns out that the method of {quantitative} extrapolation is\nan appropriate replacement for the missing tools. To finish, we identify a\nclass of holomorphic Hardy spaces defined with respect to $A_p$-measures for\nwhich a meaningful notion of Cauchy--Szeg\\\"o projection can be defined when\n$p=2$.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T14:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.17615v1","title":"Linear-Time Multilevel Graph Partitioning via Edge Sparsification","summary":"The current landscape of balanced graph partitioning is divided into\nhigh-quality but expensive multilevel algorithms and cheaper approaches with\nlinear running time, such as single-level algorithms and streaming algorithms.\nWe demonstrate how to achieve the best of both worlds with a \\emph{linear time\nmultilevel algorithm}. Multilevel algorithms construct a hierarchy of\nincreasingly smaller graphs by repeatedly contracting clusters of nodes. Our\napproach preserves their distinct advantage, allowing refinement of the\npartition over multiple levels with increasing detail. At the same time, we use\n\\emph{edge sparsification} to guarantee geometric size reduction between the\nlevels and thus linear running time.\n  We provide a proof of the linear running time as well as additional insights\ninto the behavior of multilevel algorithms, showing that graphs with low\nmodularity are most likely to trigger worst-case running time. We evaluate\nmultiple approaches for edge sparsification and integrate our algorithm into\nthe state-of-the-art multilevel partitioner KaMinPar, maintaining its excellent\nparallel scalability. As demonstrated in detailed experiments, this results in\na $1.49\\times$ average speedup (up to $4\\times$ for some instances) with only\n1\\% loss in solution quality. Moreover, our algorithm clearly outperforms\nstate-of-the-art single-level and streaming approaches.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T14:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.17631v1","title":"Modular Cosmic Ray Detector (MCORD) and its Potential Use in Various\n  Physics Experiments, Astrophysics and Geophysics","summary":"As part of the collaboration building a set of detectors for the new\ncollider, our group was tasked with designing and building a large-scale cosmic\nray detector, which was to complement the capabilities of the MPD (Dubna)\ndetec-tor set. The detector was planned as a trigger for cosmic ray particles\nand to be used to calibrate and test other systems. Additional functions were\nto be the detection of pairs of high-energy muons originating from some\nparti-cle decay processes generated during collisions and con-tinuous\nobservation of the cosmic muon stream in order to detect multi muons events.\nFrom the very beginning, the detector was designed as a scalable and universal\ndevice for many applications. The following work will present the basic\nfeatures and parameters of the Modular COsmic Ray Detector (MCORD) and examples\nof its possible use in high energy physics, astrophysics and geology. Thanks to\nits universal nature, MCORD can be potential used as a fast trigger, neutron\nveto detector, muon detector and as a tool in muon tomography.","main_category":"physics.ins-det","categories":"physics.ins-det,astro-ph.IM,physics.app-ph,J.2.m","published":"2025-04-24T15:04:43Z"}
{"aid":"http://arxiv.org/abs/2504.17644v1","title":"Bounded diagonal orbits in homogeneous spaces over function fields","summary":"This paper is about topological rigidity of diagonal group actions on the\nhomogeneous $\\SL_4\\big(\\F(\\!(t^{-1})\\!)\\big)/\\SL_4(\\F[t])$ where $\\F$ is a\nfinite field of characteristic $3$. We show that there is a non-closed\nrelatively compact orbit of the diagonal group.","main_category":"math.DS","categories":"math.DS","published":"2025-04-24T15:14:10Z"}
{"aid":"http://arxiv.org/abs/2504.17749v1","title":"MSGCN: Multiplex Spatial Graph Convolution Network for Interlayer Link\n  Weight Prediction","summary":"Graph Neural Networks (GNNs) have been widely used for various learning\ntasks, ranging from node classification to link prediction. They have\ndemonstrated excellent performance in multiple domains involving\ngraph-structured data. However, an important category of learning tasks, namely\nlink weight prediction, has received less emphasis due to its increased\ncomplexity compared to binary link classification. Link weight prediction\nbecomes even more challenging when considering multilayer networks, where nodes\ncan be interconnected across multiple layers. To address these challenges, we\npropose a new method named Multiplex Spatial Graph Convolution Network (MSGCN),\nwhich spatially embeds information across multiple layers to predict interlayer\nlink weights. The MSGCN model generalizes spatial graph convolution to\nmultiplex networks and captures the geometric structure of nodes across\nmultiple layers. Extensive experiments using data with known interlayer link\ninformation show that the MSGCN model has robust, accurate, and generalizable\nlink weight prediction performance across a wide variety of multiplex network\nstructures.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T17:08:16Z"}
{"aid":"http://arxiv.org/abs/2504.17759v1","title":"Identity Control Plane: The Unifying Layer for Zero Trust Infrastructure","summary":"This paper introduces the Identity Control Plane (ICP), an architectural\nframework for enforcing identity-aware Zero Trust access across human users,\nworkloads, and automation systems. The ICP model unifies SPIFFE-based workload\nidentity, OIDC/SAML user identity, and scoped automation credentials via\nbroker-issued transaction tokens. We propose a composable enforcement layer\nusing ABAC policy engines (e.g., OPA, Cedar), aligned with IETF WIMSE drafts\nand OAuth transaction tokens. The paper includes architectural components,\nintegration patterns, use cases, a comparative analysis with current models,\nand theorized performance metrics. A FedRAMP and SLSA compliance mapping is\nalso presented. This is a theoretical infrastructure architecture paper\nintended for security researchers and platform architects. No prior version of\nthis work has been published.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-04-24T17:21:00Z"}
{"aid":"http://arxiv.org/abs/2504.17777v1","title":"Search for Quasar Pairs with ${\\it Gaia}$ Astrometric Data. I. Method\n  and Candidates","summary":"Quasar pair, a special subclass of galaxy pair, is valuable in the\ninvestigation of quasar interaction, co-evolution, merger, and clustering, as\nwell as the formation and evolution of galaxies and supermassive black holes.\nHowever, quasar pairs at kpc-scale are rare in the universe. The scarcity of\navailable samples hindered the deeper exploration and statistics of these\nobjects. In this work, we apply an astrometric method to systematically search\nfor quasar candidates within a transverse distance of 100 kpc to known quasars\nin the Million Quasar Catalog. These candidates are ${\\it Gaia}$ sources with\nzero proper motion and zero parallax, which are the kinematic characteristics\nof extragalactic sources. Visual inspection of the sample was performed to\nremove the contamination of dense stellar fields and nearby galaxies. A total\nof 4,062 quasar pair candidates were isolated, with the median member\nseparation, ${\\it Gaia}$ G-band magnitude, and redshift of\n8.81$^{\\prime\\prime}$, 20.49, and 1.59, respectively. Our catalog was compared\nwith three major candidate quasar pair catalogs and identified 3,964 new quasar\npair candidates previously uncataloged in the three catalogs. Extensive\nspectroscopic follow-up campaigns are being carried out to validate their\nastrophysical nature. Several interesting quasar pair candidates are\nhighlighted and discussed. We also briefly discussed several techniques for\nimproving the success rate of quasar pair selection.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T17:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.19500v1","title":"Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding","summary":"Open-vocabulary 3D scene understanding is pivotal for enhancing physical\nintelligence, as it enables embodied agents to interpret and interact\ndynamically within real-world environments. This paper introduces MPEC, a novel\nMasked Point-Entity Contrastive learning method for open-vocabulary 3D semantic\nsegmentation that leverages both 3D entity-language alignment and point-entity\nconsistency across different point cloud views to foster entity-specific\nfeature representations. Our method improves semantic discrimination and\nenhances the differentiation of unique instances, achieving state-of-the-art\nresults on ScanNet for open-vocabulary 3D semantic segmentation and\ndemonstrating superior zero-shot scene understanding capabilities. Extensive\nfine-tuning experiments on 8 datasets, spanning from low-level perception to\nhigh-level reasoning tasks, showcase the potential of learned 3D features,\ndriving consistent performance gains across varied 3D scene understanding\ntasks. Project website: https://mpec-3d.github.io/","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-28T05:43:14Z"}
{"aid":"http://arxiv.org/abs/2504.19501v1","title":"Spin-Orbit Coupling in Helical Waveguides: A Local Duality Perspective\n  and Emergent Gauge Fields","summary":"Dual symmetry is an intrinsic property of Maxwell's equations, corresponding\nto a global U(1) symmetry in vacuum, with helicity as the associated conserved\nquantity. In this paper, we investigate light propagation in a spin-degenerate\nmedium using a field-theoretical approach and introduce an effective gauge\nfield A_s that emerges from the localization of dual symmetry. Within the\ngeometric optics approximation, we show that the helical trajectory of light\nrays reveals this gauge field as a manifestation of spin-orbit coupling.\nAlthough orbital-orbit coupling also arises in such systems, the spin-orbit\ninteraction possesses deeper physical significance, as it originates from the\nintrinsic dual symmetry embedded in Maxwell's equations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-28T05:43:36Z"}
{"aid":"http://arxiv.org/abs/2504.19529v1","title":"Adversarial Shallow Watermarking","summary":"Recent advances in digital watermarking make use of deep neural networks for\nmessage embedding and extraction. They typically follow the ``encoder-noise\nlayer-decoder''-based architecture. By deliberately establishing a\ndifferentiable noise layer to simulate the distortion of the watermarked\nsignal, they jointly train the deep encoder and decoder to fit the noise layer\nto guarantee robustness. As a result, they are usually weak against unknown\ndistortions that are not used in their training pipeline. In this paper, we\npropose a novel watermarking framework to resist unknown distortions, namely\nAdversarial Shallow Watermarking (ASW). ASW utilizes only a shallow decoder\nthat is randomly parameterized and designed to be insensitive to distortions\nfor watermarking extraction. During the watermark embedding, ASW freezes the\nshallow decoder and adversarially optimizes a host image until its updated\nversion (i.e., the watermarked image) stably triggers the shallow decoder to\noutput the watermark message. During the watermark extraction, it accurately\nrecovers the message from the watermarked image by leveraging the insensitive\nnature of the shallow decoder against arbitrary distortions. Our ASW is\ntraining-free, encoder-free, and noise layer-free. Experiments indicate that\nthe watermarked images created by ASW have strong robustness against various\nunknown distortions. Compared to the existing ``encoder-noise layer-decoder''\napproaches, ASW achieves comparable results on known distortions and better\nrobustness on unknown distortions.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-28T07:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.19534v1","title":"Quantifying Uncertainties in Solar Wind Forecasting Due to Incomplete\n  Solar Magnetic Field Information","summary":"Solar wind forecasting plays a crucial role in space weather prediction, yet\nsignificant uncertainties persist due to incomplete magnetic field observations\nof the Sun. Isolating the solar wind forecasting errors due to these effects is\ndifficult. This study investigates the uncertainties in solar wind models\narising from these limitations. We simulate magnetic field maps with known\nuncertainties, including far-side and polar field variations, as well as\nresolution and sensitivity limitations. These maps serve as input for three\nsolar wind models: the Wang-Sheeley-Arge (WSA), the Heliospheric Upwind\neXtrapolation (HUXt), and the European Heliospheric FORecasting Information\nAsset (EUHFORIA). We analyze the discrepancies in solar wind forecasts,\nparticularly the solar wind speed at Earth's location, by comparing the results\nof these models to a created \"ground truth\" magnetic field map, which is\nderived from a synthetic solar rotation evolution using the Advective Flux\nTransport (AFT) model. The results reveal significant variations within each\nmodel with a RMSE ranging from 59-121 km/s. Further comparison with the\nthermodynamic Magnetohydrodynamic Algorithm outside a Sphere (MAS) model\nindicates that uncertainties in the magnetic field data can lead to even larger\nvariations in solar wind forecasts compared to those within a single model.\nHowever, predicting a range of solar wind velocities based on a cloud of points\naround Earth can help mitigate uncertainties by up to 20-77%.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-28T07:27:07Z"}
{"aid":"http://arxiv.org/abs/2504.19540v1","title":"Event-triggered Robust Model Predictive Control under Hard Computation\n  Resource Constraints","summary":"Model predictive control (MPC) is capable of controlling nonlinear systems\nwith guaranteed constraint satisfaction and stability. However, MPC requires\nsolving optimization problems online periodically, which often exceeds the\nlocal system's computational capabilities. A potential solution is to leverage\nexternal processing, such as a central industrial server. Yet, this central\ncomputer typically serves multiple systems simultaneously, leading to\nsignificant hardware demands due to the need to solve numerous optimization\nproblems concurrently. In this work, we tackle this challenge by developing an\nevent-triggered model predictive control (ET-MPC) that provably stabilizes\nmultiple nonlinear systems under disturbances while solving only optimization\nproblems for a fixed-size subset at any given time. Unlike existing ET-MPC\nmethods, which primarily reduce average computational load yet still require\nhardware capable of handling all systems simultaneously, our approach reduces\nthe worst-case computational load. This significantly lowers central server\nhardware requirements by diminishing peak computational demands. We achieve our\nimprovements by leveraging recent advancements in distributed event-triggered\nlinear control and integrating them with a robust MPC that employs constraint\ntightening.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-28T07:44:35Z"}
{"aid":"http://arxiv.org/abs/2504.19558v1","title":"Cholic Acid-Based Mixed Micelles as siRNA Delivery Agents for Gene\n  Therapy","summary":"Gene therapy is a promising tool for the treatment of various cancers but is\nhindered by the physico-chemical properties of siRNA and needs a suitable\nvector for the delivery of siRNA to the target tissue. Bile acid-based block\ncopolymers offers certain advantages for the loading and delivery of siRNA\nsince they can efficiently complex siRNA and bile acids are biocompatible\nendogenous molecules. In this study, we demonstrate the use of lipids as\nco-surfactants for the preparation of mixed micelles to improve the siRNA\ndelivery of cholic acid-based block copolymers. Poly(allyl glycidyl ether)\n(PAGE) and poly(ethylene glycol) (PEG) were polymerized on the surface of\ncholic acid to afford a star-shaped block copolymer with four arms\n(CA-PAGE-b-PEG)4. The allyl groups of PAGE were functionalized to bear primary\nor tertiary amines and folic acid was grafted onto the PEG chain end to\nincrease cell uptake. (CA-PAGE-b-PEG)4 functionalized with either primary or\ntertiary amines show high siRNA complexation with close to 100% complexation at\nN/P ratio of 8. Uniform aggregates with diameters between 181 and 188 nm were\nobtained. DOPE, DSPE-PEG2k, and DSPE-PEG5k lipids were added as co-surfactants\nto help stabilize the nanoparticles in the cell culture media. Mixed micelles\nhad high siRNA loading with close to 100% functionalization at N/P ratio of 16\nand diameters ranging from 153 to 221 nm. The presence of lipids in the mixed\nmicelles improved cell uptake with a concomitant siRNA transfection in HeLa and\nHeLa-GFP model cells, respectively.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-28T08:06:36Z"}
{"aid":"http://arxiv.org/abs/2504.19563v1","title":"Characterisation of quadratic spaces over the Hilbert field by means of\n  the orthogonality relation","summary":"An orthoset is a set equipped with a symmetric, irreflexive binary relation.\nWith any (anisotropic) Hermitian space $H$, we may associate the orthoset\n$(P(H),\\perp)$, consisting of the set of one-dimensional subspaces of $H$ and\nthe usual orthogonality relation. $(P(H),\\perp)$ determines $H$ essentially\nuniquely.\n  We characterise in this paper certain kinds of Hermitian spaces by imposing\ntransitivity and minimality conditions on their associated orthosets. By\ngradually considering stricter conditions, we restrict the discussion to a more\nand more narrow class of Hermitian spaces. We are eventually interested in\nquadratic spaces over countable subfields of $\\mathbb R$.\n  A line of an orthoset is the orthoclosure of two distinct element. For an\northoset to be line-symmetric means roughly that its automorphism group acts\ntransitively both on the collection of all lines as well as on each single\nline. Line-symmetric orthosets turn out to be in correspondence with transitive\nHermitian spaces. Furthermore, quadratic orthosets are defined similarly, but\nare required to possess, for each line $\\ell$, a group of automorphisms acting\non $\\ell$ transitively and commutatively. We show the correspondence of\nquadratic orthosets with transitive quadratic spaces over ordered fields. We\nfinally specify those quadratic orthosets that are, in a natural sense,\nminimal: for a finite $n \\geq 4$, the orthoset $(P(R^n),\\perp)$, where $R$ is\nthe Hilbert field, has the property of being embeddable into any other\nquadratic orthoset of rank $n$.","main_category":"math.RA","categories":"math.RA","published":"2025-04-28T08:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.19581v1","title":"SAMBLE: Shape-Specific Point Cloud Sampling for an Optimal Trade-Off\n  Between Local Detail and Global Uniformity","summary":"Driven by the increasing demand for accurate and efficient representation of\n3D data in various domains, point cloud sampling has emerged as a pivotal\nresearch topic in 3D computer vision. Recently, learning-to-sample methods have\ngarnered growing interest from the community, particularly for their ability to\nbe jointly trained with downstream tasks. However, previous learning-based\nsampling methods either lead to unrecognizable sampling patterns by generating\na new point cloud or biased sampled results by focusing excessively on sharp\nedge details. Moreover, they all overlook the natural variations in point\ndistribution across different shapes, applying a similar sampling strategy to\nall point clouds. In this paper, we propose a Sparse Attention Map and\nBin-based Learning method (termed SAMBLE) to learn shape-specific sampling\nstrategies for point cloud shapes. SAMBLE effectively achieves an improved\nbalance between sampling edge points for local details and preserving\nuniformity in the global shape, resulting in superior performance across\nmultiple common point cloud downstream tasks, even in scenarios with few-point\nsampling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T08:42:24Z"}
{"aid":"http://arxiv.org/abs/2504.19583v1","title":"Graph-Based Spectral Decomposition for Parameter Coordination in\n  Language Model Fine-Tuning","summary":"This paper proposes a parameter collaborative optimization algorithm for\nlarge language models, enhanced with graph spectral analysis. The goal is to\nimprove both fine-tuning efficiency and structural awareness during training.\nIn the proposed method, the parameters of a pre-trained language model are\ntreated as nodes in a graph. A weighted graph is constructed, and Laplacian\nspectral decomposition is applied to enable frequency-domain modeling and\nstructural representation of the parameter space. Based on this structure, a\njoint loss function is designed. It combines the task loss with a spectral\nregularization term to facilitate collaborative updates among parameters. In\naddition, a spectral filtering mechanism is introduced during the optimization\nphase. This mechanism adjusts gradients in a structure-aware manner, enhancing\nthe model's training stability and convergence behavior. The method is\nevaluated on multiple tasks, including traditional fine-tuning comparisons,\nfew-shot generalization tests, and convergence speed analysis. In all settings,\nthe proposed approach demonstrates superior performance. The experimental\nresults confirm that the spectral collaborative optimization framework\neffectively reduces parameter perturbations and improves fine-tuning quality\nwhile preserving overall model performance. This work contributes significantly\nto the field of artificial intelligence by advancing parameter-efficient\ntraining methodologies for large-scale models, reinforcing the importance of\nstructural signal processing in deep learning optimization, and offering a\nrobust, generalizable framework for enhancing language model adaptability and\nperformance.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-28T08:42:35Z"}
{"aid":"http://arxiv.org/abs/2504.19602v1","title":"Soft-Label Caching and Sharpening for Communication-Efficient Federated\n  Distillation","summary":"Federated Learning (FL) enables collaborative model training across\ndecentralized clients, enhancing privacy by keeping data local. Yet\nconventional FL, relying on frequent parameter-sharing, suffers from high\ncommunication overhead and limited model heterogeneity. Distillation-based FL\napproaches address these issues by sharing predictions (soft-labels) instead,\nbut they often involve redundant transmissions across communication rounds,\nreducing efficiency. We propose SCARLET, a novel framework integrating\nsynchronized soft-label caching and an enhanced Entropy Reduction Aggregation\n(Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing\ncached soft-labels, achieving up to 50% reduction in communication costs\ncompared to existing methods while maintaining accuracy. Enhanced ERA can be\ntuned to adapt to non-IID data variations, ensuring robust aggregation and\nperformance in diverse client scenarios. Experimental evaluations demonstrate\nthat SCARLET consistently outperforms state-of-the-art distillation-based FL\nmethods in terms of accuracy and communication efficiency. The implementation\nof SCARLET is publicly available at https://github.com/kitsuyaazuma/SCARLET.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-28T09:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.19639v1","title":"A Unified Benchmark of Federated Learning with Kolmogorov-Arnold\n  Networks for Medical Imaging","summary":"Federated Learning (FL) enables model training across decentralized devices\nwithout sharing raw data, thereby preserving privacy in sensitive domains like\nhealthcare. In this paper, we evaluate Kolmogorov-Arnold Networks (KAN)\narchitectures against traditional MLP across six state-of-the-art FL algorithms\non a blood cell classification dataset. Notably, our experiments demonstrate\nthat KAN can effectively replace MLP in federated environments, achieving\nsuperior performance with simpler architectures. Furthermore, we analyze the\nimpact of key hyperparameters-grid size and network architecture-on KAN\nperformance under varying degrees of Non-IID data distribution. Additionally,\nour ablation studies reveal that optimizing KAN width while maintaining minimal\ndepth yields the best performance in federated settings. As a result, these\nfindings establish KAN as a promising alternative for privacy-preserving\nmedical imaging applications in distributed healthcare. To the best of our\nknowledge, this is the first comprehensive benchmark of KAN in FL settings for\nmedical imaging task.","main_category":"cs.LG","categories":"cs.LG,eess.SP","published":"2025-04-28T09:53:05Z"}
{"aid":"http://arxiv.org/abs/2504.19649v1","title":"Intelligent4DSE: Optimizing High-Level Synthesis Design Space\n  Exploration with Graph Neural Networks and Large Language Models","summary":"High-level synthesis (HLS) design space exploration (DSE) is an optimization\nprocess in electronic design automation (EDA) that systematically explores\nhigh-level design configurations to achieve Pareto-optimal hardware\nimplementations balancing performance, area, and power (PPA). To optimize this\nprocess, HLS prediction tasks often employ message-passing neural networks\n(MPNNs), leveraging complex architectures to achieve high accuracy. These\npredictors serve as evaluators in the DSE process, effectively bypassing the\ntime-consuming estimations traditionally required by HLS tools. However,\nexisting models often prioritize structural complexity and minimization of\ntraining loss, overlooking task-specific characteristics. Additionally, while\nevolutionary algorithms are widely used in DSE, they typically require\nextensive domain-specific knowledge to design effective crossover and mutation\noperators. To address these limitations, we propose CoGNNs-LLMEA, a framework\nthat integrates a graph neural network with task-adaptive message passing and a\nlarge language model-enhanced evolutionary algorithm. As a predictive model,\nCoGNNs directly leverages intermediate representations generated from source\ncode after compiler front-end processing, enabling prediction of quality of\nresults (QoR) without invoking HLS tools. Due to its strong adaptability to\ntasks, CoGNNs can be tuned to predict post-HLS and post-implementation\noutcomes, effectively bridging the gap between high-level abstractions and\nphysical implementation characteristics. CoGNNs achieves state-of-the-art\nprediction accuracy in post-HLS QoR prediction, reducing mean prediction errors\nby 2.8$\\times$ for latency and 3.4$\\times$ for resource utilization compared to\nbaseline models.","main_category":"cs.LG","categories":"cs.LG,cs.AR","published":"2025-04-28T10:08:56Z"}
{"aid":"http://arxiv.org/abs/2504.19656v1","title":"Investigating the Period-Luminosity Relations of delta Scuti Stars: A\n  Pathway to Distance and 3-D Dust Map Inference","summary":"While delta Scuti stars are the most numerous class of kappa-mechanism\npulsators in the instability strip, the short periods and small peak-to-peak\namplitudes have left them understudied and underutilized. Recently, large-scale\ntime-domain surveys have significantly increased the number of identified delta\nScuti stars. Notably, the Tsinghua University-Ma Huateng Telescopes for Survey\n(TMTS), with its high-cadence observations at 1-minute intervals, has\nidentified thousands of delta Scuti stars, greatly expanding the sample of\nthese short-period pulsating variables. Using the delta Scuti stars from the\nTMTS catalogs of Periodic Variable Stars, we cross-matched the dataset with\nPan-STARRS1, 2MASS, and WISE to obtain photometric measurements across optical\nand infrared bands. Parallax data, used as Bayesian priors, were retrieved from\nGaia DR3, and line-of-sight dust extinction priors were estimated from a\nthree-dimensional dust map. Using PyMC, we performed a simultaneous\ndetermination of the 11-band P-L relations of delta Scuti stars, which not only\nyields precise measurements of these relations, but also greatly improves\nconstraints on the distance moduli and color excesses, as evidenced by the\nreduced uncertainties in the posterior distributions. Furthermore, our\nmethodology enables an independent estimation of the color excess through the\nP-L relations, offering a potential complement to existing 3-D dust maps.\nMoreover, by cross-matching with LAMOST DR7, we investigated the influence of\nmetallicity on the P-L relations. Our analysis reveals that incorporating\nmetallicity might reduce the intrinsic scatter at longer wavelengths. However,\nthis result does not achieve 3 sigma significance, leaving open the possibility\nthat the observed reduction is attributable to statistical fluctuations.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-28T10:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.19693v1","title":"Emerging Photon Jets in the Hadronic Calorimeter: A Novel Signature of\n  Neutral Long-Lived Particles at the LHC","summary":"We propose a novel collider signature for neutral long-lived particles\n(LLPs): the emerging photon jet in the hadronic calorimeter (HCAL). This\nsignature arises when a neutral LLP decays into photons within the HCAL,\nproducing an electromagnetic shower without associated charged tracks or energy\ndeposits in the electromagnetic calorimeter (ECAL). To demonstrate the\nviability of this approach, we consider the fermiophobic Higgs boson $h_{\\rm\nf}$ in the Type-I two-Higgs-doublet model as a representative scenario. In the\nultralight regime ($m_{h_{\\rm f}} < 1$ GeV), $h_{\\rm f}$ decays exclusively\ninto a photon pair via loop-induced processes, resulting in a suppressed width\nand consequently a long lifetime. Focusing on the golden channel $pp \\to H^\\pm\nh_{\\rm f} \\to W^\\pm h_{\\rm f} h_{\\rm f}$, we analyze the exotic final state in\nwhich one $h_{\\rm f}$ decays in the ECAL and appears as a highly collimated\nphoton jet (reconstructed as a single photon), while the other decays within\nthe HCAL, producing an emerging photon jet. Through a detailed\nsignal-to-background analysis incorporating realistic detector effects via fast\nsimulation, we demonstrate that this signature achieves discovery-level\nsensitivity at the HL-LHC across a broad region of parameter space consistent\nwith theoretical and experimental constraints. While our study focuses on the\nfermiophobic Higgs, the emerging photon jet in the HCAL constitutes a broadly\napplicable and previously unexplored strategy for detecting neutral LLPs\ndecaying into photons, opening a new avenue in LLP searches at colliders.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-28T11:42:06Z"}
{"aid":"http://arxiv.org/abs/2504.19740v1","title":"Graph Fourier Transformer with Structure-Frequency Information","summary":"Graph Transformers (GTs) have shown advantages in numerous graph structure\ntasks but their self-attention mechanism ignores the generalization bias of\ngraphs, with existing methods mainly compensating for this bias from aspects\nlike position encoding, attention bias and relative distance yet still having\nsub-optimal performance and being insufficient by only considering the\nstructural perspective of generalization bias. To address this, this paper\nproposes Grafourierformer, which innovatively combines GT with inductive bias\ncontaining Frequency-Structure information by applying Graph Fourier Transform\nto the Attention Matrix: specifically, eigenvalues from the Graph Laplacian\nmatrix are used to construct an Eigenvalue matrix mask (reflecting node\npositions and structural relationships with neighboring nodes to enable\nconsideration of node range structural characteristics and focus on local graph\ndetails), and inverse Fourier transform is employed to extract node\nhigh-frequency and low-frequency features, calculate low-frequency and\nhigh-frequency energy, and construct a node frequency-energy matrix to filter\nthe eigenvalue matrix mask, allowing attention heads to incorporate both graph\nstructural information and node frequency information optimization, adaptively\ndistinguish global trends from local details, and effectively suppress\nredundant information interference. Extensive experiments on various benchmarks\nshow Grafourierformer consistently outperforms GNN and GT-based models in graph\nclassification and node classification tasks, with ablation experiments further\nvalidating the effectiveness and necessity of the method. Codes are available\nat https://github.com/Arichibald/Grafourierformer.git","main_category":"cs.LG","categories":"cs.LG,cs.GR","published":"2025-04-28T12:38:02Z"}
{"aid":"http://arxiv.org/abs/2504.19772v1","title":"Memento: Augmenting Personalized Memory via Practical Multimodal\n  Wearable Sensing in Visual Search and Wayfinding Navigation","summary":"Working memory involves the temporary retention of information over short\nperiods. It is a critical cognitive function that enables humans to perform\nvarious online processing tasks, such as dialing a phone number, recalling\nmisplaced items' locations, or navigating through a store. However, inherent\nlimitations in an individual's capacity to retain information often result in\nforgetting important details during such tasks. Although previous research has\nsuccessfully utilized wearable and assistive technologies to enhance long-term\nmemory functions (e.g., episodic memory), their application to supporting\nshort-term recall in daily activities remains underexplored. To address this\ngap, we present Memento, a framework that uses multimodal wearable sensor data\nto detect significant changes in cognitive state and provide intelligent in\nsitu cues to enhance recall. Through two user studies involving 15 and 25\nparticipants in visual search navigation tasks, we demonstrate that\nparticipants receiving visual cues from Memento achieved significantly better\nroute recall, improving approximately 20-23% compared to free recall.\nFurthermore, Memento reduced cognitive load and review time by 46% while also\nsubstantially reducing computation time (3.86 seconds vs. 15.35 seconds),\noffering an average of 75% effectiveness compared to computer vision-based cue\nselection approaches.","main_category":"cs.HC","categories":"cs.HC,cs.MM","published":"2025-04-28T13:17:59Z"}
{"aid":"http://arxiv.org/abs/2504.19782v1","title":"Cooling process of the high-mass young stellar object G24.33+0.14\n  following an accretion burst","summary":"The HMYSO G24.33+0.14 (G24), has recently been observed to undergo an\naccretion burst since September 2019, lasting approximately two years. By\nutilizing 1.3 mm observational data from the NOrthern Extended Millimeter Array\n(NOEMA) in March 2020 and the Atacama Large Millimeter/submillimeter Array\n(ALMA) in September 2019, we have examined the physical environment changes in\ngas and dust within G24 region during the decay phase of the accretion burst.\nFollowing the burst, the continuum emission in the inner core region of G24\ndiminished by approximately 20%, while the emission in the outer region\nexhibited an increase by a factor of ~30%. This pattern indicates that the heat\nwave, triggered by the accretion burst, radiated outward from the core's\ninterior to its periphery over the half-year period, with a calculated\npropagation speed of 0.08-0.38 times the speed of light. Moreover, the methanol\nemission intensity in this area has experienced a notable decline, with the\nrate of flux reduction correlating positively with the energy of the upper\nenergy states. This, in conjunction with the analysis of methanol molecular\nline rotation temperature diagrams for different emitting regions, further\nsubstantiates that the core region of G24 cooled down, contrasted with the\npersistent heating in the outer region following the burst.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-28T13:27:29Z"}
{"aid":"http://arxiv.org/abs/2504.19793v1","title":"Prompt Injection Attack to Tool Selection in LLM Agents","summary":"Tool selection is a key component of LLM agents. The process operates through\na two-step mechanism - \\emph{retrieval} and \\emph{selection} - to pick the most\nappropriate tool from a tool library for a given task. In this work, we\nintroduce \\textit{ToolHijacker}, a novel prompt injection attack targeting tool\nselection in no-box scenarios. ToolHijacker injects a malicious tool document\ninto the tool library to manipulate the LLM agent's tool selection process,\ncompelling it to consistently choose the attacker's malicious tool for an\nattacker-chosen target task. Specifically, we formulate the crafting of such\ntool documents as an optimization problem and propose a two-phase optimization\nstrategy to solve it. Our extensive experimental evaluation shows that\nToolHijacker is highly effective, significantly outperforming existing\nmanual-based and automated prompt injection attacks when applied to tool\nselection. Moreover, we explore various defenses, including prevention-based\ndefenses (StruQ and SecAlign) and detection-based defenses (known-answer\ndetection, perplexity detection, and perplexity windowed detection). Our\nexperimental results indicate that these defenses are insufficient,\nhighlighting the urgent need for developing new defense strategies.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-28T13:36:43Z"}
{"aid":"http://arxiv.org/abs/2504.19806v1","title":"Reinforcement Learning-Based Heterogeneous Multi-Task Optimization in\n  Semantic Broadcast Communications","summary":"Semantic broadcast communications (Semantic BC) for image transmission have\nachieved significant performance gains for single-task scenarios. Nevertheless,\nextending these methods to multi-task scenarios remains challenging, as\ndifferent tasks typically require distinct objective functions, leading to\npotential conflicts within the shared encoder. In this paper, we propose a\ntri-level reinforcement learning (RL)-based multi-task Semantic BC framework,\ntermed SemanticBC-TriRL, which effectively resolves such conflicts and enables\nthe simultaneous support of multiple downstream tasks at the receiver side,\nincluding image classification and content reconstruction tasks. Specifically,\nthe proposed framework employs a bottom-up tri-level alternating learning\nstrategy, formulated as a constrained multi-objective optimization problem. At\nthe first level, task-specific decoders are locally optimized using supervised\nlearning. At the second level, the shared encoder is updated via proximal\npolicy optimization (PPO), guided by task-oriented rewards. At the third level,\na multi-gradient aggregation-based task weighting module adaptively adjusts\ntask priorities and steers the encoder optimization. Through this hierarchical\nlearning process, the encoder and decoders are alternately trained, and the\nthree levels are cohesively integrated via constrained learning objective.\nBesides, the convergence of SemanticBC-TriRL is also theoretically established.\nExtensive simulation results demonstrate the superior performance of the\nproposed framework across diverse channel conditions, particularly in low SNR\nregimes, and confirm its scalability with increasing numbers of receivers.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T13:59:01Z"}
{"aid":"http://arxiv.org/abs/2504.19865v1","title":"Factorization of multimeters: a unified view on nonclassical quantum\n  phenomena","summary":"Quantum theory exhibits various nonclassical features, such as measurement\nincompatibility, contextuality, steering, and Bell nonlocality, which\ndistinguish it from classical physics. These phenomena are often studied\nseparately, but they possess deep interconnections. This work introduces a\nunified mathematical framework based on commuting diagrams that unifies them.\nBy representing collections of measurements (multimeters) as maps to the set of\ncolumn-stochastic matrices, we show that measurement compatibility and\nsimulability correspond to specific factorizations of these maps through\nintermediate systems. We apply this framework to put forward connections\nbetween different nonclassical notions and provide factorization-based\ncharacterizations for steering assemblages and Bell correlations, including a\nperspective on the CHSH inequality witnessing measurement incompatibility.\nFurthermore, we investigate robustness to noise of nonlocal features by\nexamining factorization conditions for maps involving noisy state spaces,\nproviding geometric criteria for when noisy multimeters can be simulated by\nsimpler measurement settings.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-28T14:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.19873v1","title":"Infinite temperature transport in the strong coupling regime of a\n  nonintegrable quantum spin chain","summary":"We study spin transport of the XXZ model with next-nearest neighbor\n$\\Delta_2$ terms. We compute numerically dependence of spin conductivity\n$\\sigma(\\omega)$ on the anisotropy $\\Delta$ and the ratio $r= \\Delta_2/\\Delta$,\nin the large $\\Delta$ regime. We find that, when $0<r<1$, the low-frequency\nconductivity assumes an anomalous form $\\sigma(\\omega)\\approx a \\omega^2 + b\n\\Delta^{-2} $. In particular, when $\\Delta\\to\\infty$ the model becomes\ndynamically constrained and most states are localized. We show,\nmicroscopically, existence of magnon bound states in the strong coupling\nregime, which behave as self-generated disorders for single magnons. Based on\nthis quasiparticle picture, we obtain analytical scalings, which match well\nwith the numerical results.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-28T15:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.19877v1","title":"Semi-abelian by Design: Johnstone Algebras Unifying Implication and\n  Division","summary":"Johnstone demonstrated that Heyting semilattices form a semi-abelian category\nvia a specific triple of terms. Inspired by this work, we introduce\n\\emph{Johnstone algebras} or J-algebras. The algebraic $(*,\\to,e)$-theory $J$\nof arities $(2,2,0)$ consists of three axioms carefully chosen to ensure\nprotomodularity in alignment with Johnstone's terms. Johnstone algebras\ngeneralize well-known structures such as groups (division) and Heyting\nsemilattices (implication) providing a unified framework within the\nwell-behaved setting of semi-abelian categories.\n  We present two primary contributions. First, we identify the M-axiom, \\[\n(t(x,y)\\to x)\\to (t(x,y)\\to z) \\approx x\\to z, \\text{ where }t(x,y) = (x\\to\ny)\\to y. \\] The M-axiom is satisfied by residuated Johnstone algebras, and it\ncan be considered a weakening of the H-axiom to comparable elements. We show\nthat $t(x,y)$ defines a \\emph{relative closure term} in MBC-algebras, and it\nimplies that MBC-algebras form a variety of algebras, thereby generalizing the\ncorresponding theorem related to HBCK-algebras. Second, we prove several no-go\nresults, demonstrating that balanced theories or theories admitting\nnon-discrete monotone or inflationary algebras cannot possess Malcev terms.\n  Together, these results establish Johnstone algebras as significant\nstructures that achieve desirable categorical properties by carefully\nintegrating both logical and symmetric features, while closely avoiding the\nconstraints imposed by our no-go results.","main_category":"math.LO","categories":"math.LO,math.CT,math.RA","published":"2025-04-28T15:06:42Z"}
{"aid":"http://arxiv.org/abs/2504.19881v1","title":"Using Fixed and Mobile Eye Tracking to Understand How Visitors View Art\n  in a Museum: A Study at the Bowes Museum, County Durham, UK","summary":"The following paper describes a collaborative project involving researchers\nat Durham University, and professionals at the Bowes Museum, Barnard Castle,\nCounty Durham, UK, during which we used fixed and mobile eye tracking to\nunderstand how visitors view art. Our study took place during summer 2024 and\nbuilds on work presented at DH2017 (Bailey-Ross et al., 2017). Our\ninterdisciplinary team included researchers from digital humanities,\npsychology, art history and computer science, working in collaboration with\nprofessionals from the museum. We used fixed and mobile eye tracking to\nunderstand how museum visitors view art in a physical gallery setting. This\nresearch will enable us to make recommendations about how the Museum's\ncollections could be more effectively displayed, encouraging visitors to engage\nwith them more fully.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T15:12:30Z"}
{"aid":"http://arxiv.org/abs/2504.19926v1","title":"Skew generalized quasi-cyclic codes over non-chain ring $F_q+vF_q$","summary":"For a prime $p$, let $F_q$ be the finite field of order $q= p^d$. This paper\npresents the study on skew generalized quasi-cyclic (SGQC) codes of length $n$\nover the non-chain ring $F_q+vF_q$ where $v^2=v$ and $\\theta_t$ is the Galois\nautomorphism. Here, first, we prove the dual of an SGQC code of length $n$ is\nalso an SGQC code of the same length and derive a necessary and sufficient\ncondition for the existence of a self-dual SGQC code. Then, we discuss the\n$1$-generator polynomial and the $\\rho$-generator polynomial for skew\ngeneralized quasi-cyclic codes. Further, we determine the dimension and BCH\ntype bound for the 1-generator skew generalized quasi-cyclic codes. As a\nby-product, with the help of MAGMA software, we provide a few examples of SGQC\ncodes and obtain some $2$-generator SGQC codes of index $2$.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T16:00:53Z"}
{"aid":"http://arxiv.org/abs/2504.19931v1","title":"Infinite-dimensional Siegel disc as symplectic and Kaehler quotient","summary":"In this paper, we construct the restricted infinite-dimensional Siegel disc\nas a Marsden-Weinstein symplectic reduced space and as Kaehler quotient of a\nweak Kaehler manifold. The obtained symplectic form is invariant with respect\nto the left action of the infinite-dimensional restricted symplectic group and\ncoincides with the Kirillov-Kostant-Souriau symplectic form of the restricted\nSiegel disc obtained via the identification with an affine coadjoint orbit of\nthe restricted symplectic group, or equivalently with a coadjoint orbit of the\nuniversal central extension of the restricted symplectic group.","main_category":"math.SG","categories":"math.SG,math.DG,math.FA,math.OA","published":"2025-04-28T16:07:50Z"}
{"aid":"http://arxiv.org/abs/2504.19941v1","title":"The Diffuse Solid Method for Wetting and Multiphase Fluid Simulations in\n  Complex Geometries","summary":"We develop a diffuse solid method that is versatile and accurate for modeling\nwetting and multiphase flows in highly complex geometries. In this scheme, we\nharness N + 1-component phase field models to investigate interface shapes and\nflow dynamics of N fluid components, and we optimize how to constrain the\nevolution of the component employed as the solid phase to conform to any\npre-defined geometry. Implementations for phase field energy minimization and\nlattice Boltzmann method are presented. Our approach does not need special\ntreatment for the fluid-solid wetting boundary condition, which makes it simple\nto implement. To demonstrate its broad applicability, we employ the diffuse\nsolid method to explore wide-ranging examples, including droplet contact angle\non a flat surface, particle adsorption on a fluid-fluid interface, critical\npressure on micropillars and on Salvinia leaf structures, capillary rise\nagainst gravity, Lucas-Washburn's law for capillary filling, and droplet motion\non a sinusoidally undulated surface. Our proposed approach can be beneficial to\ncomputationally study multiphase fluid interactions with textured solid\nsurfaces that are ubiquitous in nature and engineering applications.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft,physics.comp-ph","published":"2025-04-28T16:12:06Z"}
{"aid":"http://arxiv.org/abs/2504.19962v1","title":"Approximating neutron-star radii using gravitational-wave only\n  measurements with symbolic regression","summary":"Binary neutron star inspirals detected as gravitational waves carry\ninformation on components' masses and tidal deformabilities, but not radii,\nwhich are measured by electromagnetic observations of neutron stars. An\nexpression for neutron-star radii as a function of gravitational-wave only data\nwould be advantageous for the multi-messenger astronomy. Using pySR, a symbolic\nregression method trained on TOV solutions to piecewise polytropic EOS input,\nan approximate symbolic expression for neutron-star radius as a function of\nmass and tidal deformability is obtained. The approximation is tested on\npiecewise polytropic EOS NS data, as well as on NS sequences based on various\nnon-polytropic EOSs based on realistic theories of dense matter, achieving\nconsistent agreement between the ground truth values and the approximation for\na broad range of NS parameters covering current astrophysical observations,\nwith average radii differences of few hundred meters. Additionally, the\napproximation is applied to GW170817 gravitational-wave mass and tidal\ndeformability posteriors, and compared to reported inferred radius\ndistributions.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-28T16:33:55Z"}
{"aid":"http://arxiv.org/abs/2504.19967v1","title":"Enhancing short-term traffic prediction by integrating trends and\n  fluctuations with attention mechanism","summary":"Traffic flow prediction is a critical component of intelligent transportation\nsystems, yet accurately forecasting traffic remains challenging due to the\ninteraction between long-term trends and short-term fluctuations. Standard deep\nlearning models often struggle with these challenges because their\narchitectures inherently smooth over fine-grained fluctuations while focusing\non general trends. This limitation arises from low-pass filtering effects, gate\nbiases favoring stability, and memory update mechanisms that prioritize\nlong-term information retention. To address these shortcomings, this study\nintroduces a hybrid deep learning framework that integrates both long-term\ntrend and short-term fluctuation information using two input features processed\nin parallel, designed to capture complementary aspects of traffic flow\ndynamics. Further, our approach leverages attention mechanisms, specifically\nBahdanau attention, to selectively focus on critical time steps within traffic\ndata, enhancing the model's ability to predict congestion and other transient\nphenomena. Experimental results demonstrate that features learned from both\nbranches are complementary, significantly improving the goodness-of-fit\nstatistics across multiple prediction horizons compared to a baseline model.\nNotably, the attention mechanism enhances short-term forecast accuracy by\ndirectly targeting immediate fluctuations, though challenges remain in fully\nintegrating long-term trends. This framework can contribute to more effective\ncongestion mitigation and urban mobility planning by advancing the robustness\nand precision of traffic prediction models.","main_category":"cs.ET","categories":"cs.ET,cs.AI,cs.LG,stat.AP","published":"2025-04-28T16:38:46Z"}
{"aid":"http://arxiv.org/abs/2504.19973v1","title":"Stringy KLT Relations on $AdS$","summary":"We study the building blocks of open and closed string amplitudes on $AdS$.\nThese are given by two infinite towers of world-sheet integrals generalising\nthe Euler and complex beta functions respectively. We show that the open and\nclosed building blocks are related by an $AdS$ version of the KLT relations,\nwhose Kernel can be computed exactly. We furthermore show that the building\nblocks for open string amplitudes are given by Aomoto-Gelfand hypergeometric\nfunctions, and give their closed form expression up to weight four.","main_category":"hep-th","categories":"hep-th","published":"2025-04-28T16:47:53Z"}
{"aid":"http://arxiv.org/abs/2504.19999v1","title":"Compositional Square Roots of $\\exp(x)$ and $1+x^2$","summary":"Our work began as an effort to understand calculations by Morris & Szekeres\n(1961) and Walker (1991) regarding fractional iteration.","main_category":"math.GM","categories":"math.GM,cs.DM","published":"2025-04-28T17:19:24Z"}
{"aid":"http://arxiv.org/abs/2504.20010v1","title":"Towards Automated Scoping of AI for Social Good Projects","summary":"Artificial Intelligence for Social Good (AI4SG) is an emerging effort that\naims to address complex societal challenges with the powerful capabilities of\nAI systems. These challenges range from local issues with transit networks to\nglobal wildlife preservation. However, regardless of scale, a critical\nbottleneck for many AI4SG initiatives is the laborious process of problem\nscoping -- a complex and resource-intensive task -- due to a scarcity of\nprofessionals with both technical and domain expertise. Given the remarkable\napplications of large language models (LLM), we propose a Problem Scoping Agent\n(PSA) that uses an LLM to generate comprehensive project proposals grounded in\nscientific literature and real-world knowledge. We demonstrate that our PSA\nframework generates proposals comparable to those written by experts through a\nblind review and AI evaluations. Finally, we document the challenges of\nreal-world problem scoping and note several areas for future work.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-28T17:29:51Z"}
{"aid":"http://arxiv.org/abs/2504.20383v1","title":"Neural Stereo Video Compression with Hybrid Disparity Compensation","summary":"Disparity compensation represents the primary strategy in stereo video\ncompression (SVC) for exploiting cross-view redundancy. These mechanisms can be\nbroadly categorized into two types: one that employs explicit horizontal\nshifting, and another that utilizes an implicit cross-attention mechanism to\nreduce cross-view disparity redundancy. In this work, we propose a hybrid\ndisparity compensation (HDC) strategy that leverages explicit pixel\ndisplacement as a robust prior feature to simplify optimization and perform\nimplicit cross-attention mechanisms for subsequent warping operations, thereby\ncapturing a broader range of disparity information. Specifically, HDC first\ncomputes a similarity map by fusing the horizontally shifted cross-view\nfeatures to capture pixel displacement information. This similarity map is then\nnormalized into an \"explicit pixel-wise attention score\" to perform the\ncross-attention mechanism, implicitly aligning features from one view to\nanother. Building upon HDC, we introduce a novel end-to-end optimized neural\nstereo video compression framework, which integrates HDC-based modules into key\ncoding operations, including cross-view feature extraction and reconstruction\n(HDC-FER) and cross-view entropy modeling (HDC-EM). Extensive experiments on\nSVC benchmarks, including KITTI 2012, KITTI 2015, and Nagoya, which cover both\nautonomous driving and general scenes, demonstrate that our framework\noutperforms both neural and traditional SVC methodologies.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-29T03:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.20398v1","title":"Noise limits for dc SQUID readout of high-$Q$ resonators below 300 MHz","summary":"We present the limits on noise for the readout of cryogenic high-$Q$\nresonators using dc Superconducting Quantum Interference Devices (SQUIDs) below\n300 MHz. This analysis uses realized first-stage SQUIDs (previously published),\nwhose performance is well described by Tesche-Clarke (TC) theory, coupled\ndirectly to the resonators. We also present data from a prototype second-stage\ndc SQUID array designed to couple to this first-stage SQUID as a follow-on\namplifier with high system bandwidth. This analysis is the first full\nconsideration of dc SQUID noise performance referred to a high-$Q$ resonator\nover this frequency range, and is presented relative to the standard quantum\nlimit. We include imprecision, backaction, and backaction-imprecision noise\ncorrelations from TC theory, the noise contributed by the second-stage SQUIDs,\nwiring, and preamplifiers, and optimizations for both on-resonance measurements\nand off-resonance scan sensitivity. This architecture has modern relevance due\nto the increased interest in axion searches and the requirements of the\nDMRadio-m$^3$ axion search, which will use dc SQUIDs in this frequency range.","main_category":"quant-ph","categories":"quant-ph,hep-ex","published":"2025-04-29T03:42:06Z"}
{"aid":"http://arxiv.org/abs/2504.20402v1","title":"Deterministic Formation of Single Organic Color Centers in Single-Walled\n  Carbon Nanotubes","summary":"Quantum light sources using single-walled carbon nanotubes show promise for\nquantum technologies but face challenges in achieving precise control over\ncolor center formation. Here we present a novel technique for deterministic\ncreation of single organic color centers in carbon nanotubes using\n\\textit{in-situ} photochemical reaction. By monitoring discrete intensity\nchanges in photoluminescence spectra, we achieve precise control over the\nformation of individual color centers. Furthermore, our method allows for\nposition-controlled formation of color centers as validated through\nphotoluminescence imaging. We also demonstrate photon antibunching from a color\ncenter, confirming the quantum nature of the defects formed. This technique\nrepresents a significant step forward in the precise engineering of atomically\ndefined quantum emitters in carbon nanotubes, facilitating their integration\ninto advanced quantum photonic devices and systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-29T03:56:06Z"}
{"aid":"http://arxiv.org/abs/2504.20470v1","title":"The Promises of Multiple Experiments: Identifying Joint Distribution of\n  Potential Outcomes","summary":"Typical causal effects are defined based on the marginal distribution of\npotential outcomes. However, many real-world applications require causal\nestimands involving the joint distribution of potential outcomes to enable more\nnuanced treatment evaluation and selection. In this article, we propose a novel\nframework for identifying and estimating the joint distribution of potential\noutcomes using multiple experimental datasets. We introduce the assumption of\ntransportability of state transition probabilities for potential outcomes\nacross datasets and establish the identification of the joint distribution\nunder this assumption, along with a regular full-column rank condition. The key\nidentification assumptions are testable in an overidentified setting and are\nanalogous to those in the context of instrumental variables, with the dataset\nindicator serving as \"instrument\". Moreover, we propose an easy-to-use\nleast-squares-based estimator for the joint distribution of potential outcomes\nin each dataset, proving its consistency and asymptotic normality. We further\nextend the proposed framework to identify and estimate principal causal\neffects. We empirically demonstrate the proposed framework by conducting\nextensive simulations and applying it to evaluate the surrogate endpoint in a\nreal-world application.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-29T07:11:25Z"}
{"aid":"http://arxiv.org/abs/2504.20489v1","title":"Sign Convention for $A_{\\infty}$-Operations in Bott-Morse Case","summary":"We describe the sign and orientation issue appearing the filtered\n$A_{\\infty}$-formulae in Lagrangian Floer theory using de Rham model in\nBott-Morse setting. After giving the definition of filtered\n$A_{\\infty}$-operations in a Fukaya category, we verify the filtered\n$A_{\\infty}$-formulae.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-29T07:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.20496v1","title":"Large-scale visual SLAM for in-the-wild videos","summary":"Accurate and robust 3D scene reconstruction from casual, in-the-wild videos\ncan significantly simplify robot deployment to new environments. However,\nreliable camera pose estimation and scene reconstruction from such\nunconstrained videos remains an open challenge. Existing visual-only SLAM\nmethods perform well on benchmark datasets but struggle with real-world footage\nwhich often exhibits uncontrolled motion including rapid rotations and pure\nforward movements, textureless regions, and dynamic objects. We analyze the\nlimitations of current methods and introduce a robust pipeline designed to\nimprove 3D reconstruction from casual videos. We build upon recent deep visual\nodometry methods but increase robustness in several ways. Camera intrinsics are\nautomatically recovered from the first few frames using structure-from-motion.\nDynamic objects and less-constrained areas are masked with a predictive model.\nAdditionally, we leverage monocular depth estimates to regularize bundle\nadjustment, mitigating errors in low-parallax situations. Finally, we integrate\nplace recognition and loop closure to reduce long-term drift and refine both\nintrinsics and pose estimates through global bundle adjustment. We demonstrate\nlarge-scale contiguous 3D models from several online videos in various\nenvironments. In contrast, baseline methods typically produce locally\ninconsistent results at several points, producing separate segments or\ndistorted maps. In lieu of ground-truth pose data, we evaluate map consistency,\nexecution time and visual accuracy of re-rendered NeRF models. Our proposed\nsystem establishes a new baseline for visual reconstruction from casual\nuncontrolled videos found online, demonstrating more consistent reconstructions\nover longer sequences of in-the-wild videos than previously achieved.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T07:37:51Z"}
{"aid":"http://arxiv.org/abs/2504.20501v1","title":"SAM-Guided Robust Representation Learning for One-Shot 3D Medical Image\n  Segmentation","summary":"One-shot medical image segmentation (MIS) is crucial for medical analysis due\nto the burden of medical experts on manual annotation. The recent emergence of\nthe segment anything model (SAM) has demonstrated remarkable adaptation in MIS\nbut cannot be directly applied to one-shot medical image segmentation (MIS) due\nto its reliance on labor-intensive user interactions and the high computational\ncost. To cope with these limitations, we propose a novel SAM-guided robust\nrepresentation learning framework, named RRL-MedSAM, to adapt SAM to one-shot\n3D MIS, which exploits the strong generalization capabilities of the SAM\nencoder to learn better feature representation. We devise a dual-stage\nknowledge distillation (DSKD) strategy to distill general knowledge between\nnatural and medical images from the foundation model to train a lightweight\nencoder, and then adopt a mutual exponential moving average (mutual-EMA) to\nupdate the weights of the general lightweight encoder and medical-specific\nencoder. Specifically, pseudo labels from the registration network are used to\nperform mutual supervision for such two encoders. Moreover, we introduce an\nauto-prompting (AP) segmentation decoder which adopts the mask generated from\nthe general lightweight model as a prompt to assist the medical-specific model\nin boosting the final segmentation performance. Extensive experiments conducted\non three public datasets, i.e., OASIS, CT-lung demonstrate that the proposed\nRRL-MedSAM outperforms state-of-the-art one-shot MIS methods for both\nsegmentation and registration tasks. Especially, our lightweight encoder uses\nonly 3\\% of the parameters compared to the encoder of SAM-Base.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-29T07:43:37Z"}
{"aid":"http://arxiv.org/abs/2504.20553v1","title":"Characterizing the Polynomial-Time Minimizable $œâ$-Automata","summary":"A central question in the theory of automata is which classes of automata can\nbe minimized in polynomial time. We close the remaining gaps for deterministic\nand history-deterministic automata over infinite words by proving that\ndeterministic co-B\\\"uchi automata with transition-based acceptance are NP-hard\nto minimize, as are history-deterministic B\\\"uchi automata with\ntransition-based acceptance.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-04-29T08:56:11Z"}
{"aid":"http://arxiv.org/abs/2504.20562v1","title":"Binding of native DNA to MoS$_{2}$ nanoflakes: the role of defects and\n  edge atoms of MoS$_{2}$ nanostructures in their biofunctionalization","summary":"In this work, the binding of native DNA to MoS$_{2}$ nanoflakes (FLs) was\nstudied by using UV-visible absorption spectroscopy, thermal denaturation\nmethod, transmission electron microscopy (TEM), temperature-dependent dynamic\nlight scattering (DLS), and the DFT computational-chemistry method. Analysis of\nthe experimental data: TEM images and thermal denaturation measurements showed\nthe binding of the biopolymer with MoS$_{2}$ FLs. An increase in the melting\ntemperature of DNA and a decrease in the hyperchromic coefficient at binding\nwith MoS$_{2}$ FLs indicates the formation of the DNA:MoS$_{2}$ FL\nnanoassemblies due primarily to the covalent interaction of the oxygen atoms of\nthe phosphate groups of DNA with the MoS$_{2}$ FLs. Possible complexes of a\nnucleotide fragment (ribose-phosphate group) with MoS$_{2}$ nanolayer are\nconsidered and calculated employing the DFT method. Different structures of\nthese complexes are optimized and the interaction energies between components\nare determined. Special attention in calculations is focused on the binding of\nthis nucleotide fragment with Mo atoms located at the edge of the MoS$_{2}$\nnanolayer and with point structural defects of the MoS$_{2}$ surface containing\nthe S vacancy. Based on this calculation and experimental observation, a\nmechanism of binding of native DNA to MoS$_{2}$ FLs has been proposed, in which\ntheir conjugation begins with point contacts of DNA phosphate groups with Mo\natoms (at the edge or/and in defects) through the formation of a strong\ncoordination bond. The results indicate the critical role of defects and edge\natoms of MoS$_{2}$ FLs in their biofunctionalization.","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-29T09:05:58Z"}
{"aid":"http://arxiv.org/abs/2504.20578v1","title":"From small dust to micron-sized aggregates: the influence of structure\n  and composition on the dust optical properties","summary":"Models of astrophysical dust are key to understand several physical\nprocesses, from the role of dust grains as cooling agents in the ISM to their\nevolution in dense circumstellar disks, explaining the occurrence of planetary\nsystems around many stars. Currently, most models aim at providing optical\nproperties for dust grains in the diffuse ISM, and many do not account properly\nfor complexity in composition and structure when dust is expected to evolve in\ndense astrophysical environments. Our purpose is to investigate, with a pilot\nsample of micron-size dust grains, the influence of dust structure, porosity,\nand composition when computing the optical properties of grown dust grains in\nthe infrared and millimetre domains, where observations are widely used to\nconstrain the dust properties. Starting from the small dust grains developed in\nthe THEMIS 2.0 model, we use the Discrete Dipole Approximation to compute the\noptical properties of 1 um grains, varying the hypotheses made on their\ncomposition and structure. We look at the dust scattering, emission and\nextinction to isolate potential simplifications and unavoidable differences\nbetween grain structures. We note that both dust structure and porosity\ninfluence the dust properties in infrared and millimetre ranges, demonstrating\nthat dust aggregates cannot be correctly approximated by compact or porous\nspheres. In particular, we show that the dust emissivity index in the\nmillimetre can vary with fixed grain size. We shed light on the importance of\ntaking the dust structure and porosity into account when interpreting\nobservations in environments where dust grains may have evolved significantly.\nEfforts in carrying out physical models of grain growth, for instance, are\nrequired to establish realistic constraints on the structure of grown dust\ngrains, and will be used in the future to build realistic dust models for the\ndense ISM.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-29T09:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.20581v1","title":"ClonEval: An Open Voice Cloning Benchmark","summary":"We present a novel benchmark for voice cloning text-to-speech models. The\nbenchmark consists of an evaluation protocol, an open-source library for\nassessing the performance of voice cloning models, and an accompanying\nleaderboard. The paper discusses design considerations and presents a detailed\ndescription of the evaluation procedure. The usage of the software library is\nexplained, along with the organization of results on the leaderboard.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T09:36:33Z"}
{"aid":"http://arxiv.org/abs/2504.20592v1","title":"Is the Symbiotic Recurrent Nova T CrB Late? Recent Photometric Evolution\n  and Comparison with Past Pre-Outburst Behaviour","summary":"T CrB is a symbiotic recurrent nova that last erupted in 1946. Given its\nrecurrence timescale of approximately 80 years, the next outburst is eagerly\nanticipated by the astronomical community. In this work, we analyse the optical\nlight curves of T CrB, comparing recent photometric evolution with historical\ndata to evaluate potential predictive indicators of nova eruptions. Although\nthe \"super-active\" phases preceding both the 1946 and anticipated eruptions are\nstrikingly similar, the subsequent photometric behaviour differs. We find that\nthe decline in brightness observed in 2023, interpreted by some as a\n\"pre-eruption dip\", deviates from the deep minimum recorded prior to the 1946\nevent and does not reliably predict the eruption timing. Recent photometric and\nspectroscopic observations indicate that the system is returning to a\nhigh-accretion state. Given this, an eruption may be imminent, even without\ndistinct precursors. While the next eruption of T CrB will be a major\nscientific event, its expected peak brightness of $V \\sim 2$ mag highlights the\nimportance of setting realistic public expectations for what will be a visually\nmodest, yet astrophysically very significant, celestial event.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-04-29T09:45:34Z"}
{"aid":"http://arxiv.org/abs/2504.20596v1","title":"The Anyonic Quantum Carnot Engine","summary":"Combining two disparate lines of thought like thermodynamics and quantum\nmechanics yields surprising results. The resulting idea of quantum\nthermodynamic engines holds promise for harvesting novel sources of energy of\npurely quantum origin, like quantum statistics, to extract mechanical work from\nmacroscopic quantum systems like Bose-Einstein condensates. It also allows one\nto explore thermodynamic thinking to `small' systems consisting only a few\nparticles in quantum theory. In an earlier paper we had studied the quantum\nOtto engine using a small number of one-dimensional anyons as the medium to\ndrive the thermodynamic engine. In this sequel, we study the gold-standard of\nthermodynamic engines, namely the Carnot engine, using two-dimensional anyons\nas the medium. An explicit expression is derived for the efficiency of the\nanyonic quantum Carnot engine.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-29T09:49:28Z"}
{"aid":"http://arxiv.org/abs/2504.20632v1","title":"Tx-Rx Mode Mismatch Effects in Gaussian-Modulated CV QKD","summary":"The impact of technical limitations on pulse shaping used to generate a CV\nQKD signal is quantified in terms of the attainable secure key rate.\nOptimization of key spectral efficiency for Gaussian-modulated CV QKD with\ntruncated and discretized root-raised cosine profiles is discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T11:01:11Z"}
{"aid":"http://arxiv.org/abs/2504.20637v1","title":"Protocol Dialects as Formal Patterns: A Composable Theory of Lingos --\n  Technical report","summary":"Protocol dialects are methods for modifying protocols that provide\nlight-weight security, especially against easy attacks that can lead to more\nserious ones. A lingo is a dialect's key security component by making attackers\nunable to \"speak\" the lingo. A lingo's \"talk\" changes all the time, becoming a\nmoving target for attackers. We present several kinds of lingo transformations\nand compositions to generate stronger lingos from simpler ones, thus making\ndialects more secure.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T11:08:18Z"}
{"aid":"http://arxiv.org/abs/2504.20642v1","title":"Decision-centric fairness: Evaluation and optimization for resource\n  allocation problems","summary":"Data-driven decision support tools play an increasingly central role in\ndecision-making across various domains. In this work, we focus on binary\nclassification models for predicting positive-outcome scores and deciding on\nresource allocation, e.g., credit scores for granting loans or churn propensity\nscores for targeting customers with a retention campaign. Such models may\nexhibit discriminatory behavior toward specific demographic groups through\ntheir predicted scores, potentially leading to unfair resource allocation. We\nfocus on demographic parity as a fairness metric to compare the proportions of\ninstances that are selected based on their positive outcome scores across\ngroups. In this work, we propose a decision-centric fairness methodology that\ninduces fairness only within the decision-making region -- the range of\nrelevant decision thresholds on the score that may be used to decide on\nresource allocation -- as an alternative to a global fairness approach that\nseeks to enforce parity across the entire score distribution. By restricting\nthe induction of fairness to the decision-making region, the proposed\ndecision-centric approach avoids imposing overly restrictive constraints on the\nmodel, which may unnecessarily degrade the quality of the predicted scores. We\nempirically compare our approach to a global fairness approach on multiple\n(semi-synthetic) datasets to identify scenarios in which focusing on fairness\nwhere it truly matters, i.e., decision-centric fairness, proves beneficial.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-29T11:12:36Z"}
{"aid":"http://arxiv.org/abs/2504.20659v1","title":"Disjoint Delay-Doppler Estimation in OTFS ISAC with Deep Learning-aided\n  Path Detection","summary":"In this work, the problem of communication and radar sensing in orthogonal\ntime frequency space (OTFS) with reduced cyclic prefix (RCP) is addressed. A\nmonostatic integrated sensing and communications (ISAC) system is developed\nand, it is demonstrated that by leveraging the cyclic shift property inherent\nin the RCP, a delay-Doppler (DD) channel matrix that encapsulates the effects\nof propagation delays and Doppler shifts through unitary matrices can be\nderived. Consequently, a novel low-complexity correlation-based algorithm\nperforming disjoint delay-Doppler estimation is proposed for channel\nestimation. Subsequently, this estimation approach is adapted to perform radar\nsensing on backscattered data frames. Moreover, channel estimation is\ncomplemented by a deep learning (DL) architecture that improves path detection\nand accuracy under low signal-to-noise ratio (SNR) conditions, compared to\nstopping criterion (SC) based multipath detection. Simulation results indicate\nthat the proposed estimation scheme achieves lower normalized mean squared\nerror (NMSE) compared to conventional channel estimation algorithms and sensing\nperformance close to the Cramer-Rao lower bound (CRLB). Furthermore, an\niterative data detection algorithm based on matched filter (MF) and combining\nis developed by exploiting the unitary property of delay-Doppler parameterized\nmatrices. Simulation results reveal that this iterative scheme achieves\nperformance comparable to that of the linear minimum mean squared error (LMMSE)\nestimator while significantly reducing computational complexity.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T11:34:47Z"}
{"aid":"http://arxiv.org/abs/2504.20687v1","title":"What's Wrong with Your Synthetic Tabular Data? Using Explainable AI to\n  Evaluate Generative Models","summary":"Evaluating synthetic tabular data is challenging, since they can differ from\nthe real data in so many ways. There exist numerous metrics of synthetic data\nquality, ranging from statistical distances to predictive performance, often\nproviding conflicting results. Moreover, they fail to explain or pinpoint the\nspecific weaknesses in the synthetic data. To address this, we apply\nexplainable AI (XAI) techniques to a binary detection classifier trained to\ndistinguish real from synthetic data. While the classifier identifies\ndistributional differences, XAI concepts such as feature importance and feature\neffects, analyzed through methods like permutation feature importance, partial\ndependence plots, Shapley values and counterfactual explanations, reveal why\nsynthetic data are distinguishable, highlighting inconsistencies, unrealistic\ndependencies, or missing patterns. This interpretability increases transparency\nin synthetic data evaluation and provides deeper insights beyond conventional\nmetrics, helping diagnose and improve synthetic data quality. We apply our\napproach to two tabular datasets and generative models, showing that it\nuncovers issues overlooked by standard evaluation techniques.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-29T12:10:52Z"}
{"aid":"http://arxiv.org/abs/2504.20690v1","title":"In-Context Edit: Enabling Instructional Image Editing with In-Context\n  Generation in Large Scale Diffusion Transformer","summary":"Instruction-based image editing enables robust image modification via natural\nlanguage prompts, yet current methods face a precision-efficiency tradeoff.\nFine-tuning methods demand significant computational resources and large\ndatasets, while training-free techniques struggle with instruction\ncomprehension and edit quality. We resolve this dilemma by leveraging\nlarge-scale Diffusion Transformer (DiT)' enhanced generation capacity and\nnative contextual awareness. Our solution introduces three contributions: (1)\nan in-context editing framework for zero-shot instruction compliance using\nin-context prompting, avoiding structural changes; (2) a LoRA-MoE hybrid tuning\nstrategy that enhances flexibility with efficient adaptation and dynamic expert\nrouting, without extensive retraining; and (3) an early filter inference-time\nscaling method using vision-language models (VLMs) to select better initial\nnoise early, improving edit quality. Extensive evaluations demonstrate our\nmethod's superiority: it outperforms state-of-the-art approaches while\nrequiring only 0.5% training data and 1% trainable parameters compared to\nconventional baselines. This work establishes a new paradigm that enables\nhigh-precision yet efficient instruction-guided editing. Codes and demos can be\nfound in https://river-zhang.github.io/ICEdit-gh-pages/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T12:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.20701v1","title":"Static black hole horizons in cosmology","summary":"Despite previous results that rule out the possibility of a static black hole\nhorizon in cosmology we present a black hole metric that has a static horizon\nwhilst mimicking the cosmological behavior at large scales away from the black\nhole horizon. By a suitable choice of coordinates, we show that it is possible\nto have a static black hole horizon in cosmology that does not suffer from\nissues like singularities in curvature invariants at the horizon. The resulting\nmetric is consistent with the Schwarzschild-de Sitter metric for constant\nHubble parameter. It should be noted that this metric does not lead to\nisotropic pressure, i.e. $p_\\perp\\neq p_r$ for radial distances comparable to\nSchwarzschild radius, but for large $r$ the stress tensor (assuming general\nrelativity) tends to the cosmological value. Turning to a more realistic\nframework, we study the cases of black hole$+$cosmological matter and black\nhole$+$matter$+$cosmological constant where we assume the pressure component\ntakes its cosmological value and show that although the resulting metric does\nnot have a static horizon, the physical radius of the apparent horizon can tend\nto a constant value for large cosmological time. This metric does not suffer\nfrom issues like a singular horizon for asymptotically vanishing Hubble\nparameter.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-29T12:32:50Z"}
{"aid":"http://arxiv.org/abs/2504.20706v1","title":"Every 2-connected, cubic, planar graph with faces of size at most 6 is\n  Hamiltonian","summary":"We prove that every 2-connected, cubic, planar graph with faces of size at\nmost 6 is Hamiltonian, and show that the 6-face condition is tight. Our results\npush the connectivity condition of the Barnette-Goodey conjecture to the\nweakest possible.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T12:36:38Z"}
{"aid":"http://arxiv.org/abs/2504.20708v1","title":"Beyond the Last Answer: Your Reasoning Trace Uncovers More than You\n  Think","summary":"Large Language Models (LLMs) leverage step-by-step reasoning to solve complex\nproblems. Standard evaluation practice involves generating a complete reasoning\ntrace and assessing the correctness of the final answer presented at its\nconclusion. In this paper, we challenge the reliance on the final answer by\nposing the following two questions: Does the final answer reliably represent\nthe model's optimal conclusion? Can alternative reasoning paths yield different\nresults? To answer these questions, we analyze intermediate reasoning steps,\ntermed subthoughts, and propose a method based on our findings. Our approach\ninvolves segmenting a reasoning trace into sequential subthoughts based on\nlinguistic cues. We start by prompting the model to generate continuations from\nthe end-point of each intermediate subthought. We extract a potential answer\nfrom every completed continuation originating from different subthoughts. We\nfind that aggregating these answers by selecting the most frequent one (the\nmode) often yields significantly higher accuracy compared to relying solely on\nthe answer derived from the original complete trace. Analyzing the consistency\namong the answers derived from different subthoughts reveals characteristics\nthat correlate with the model's confidence and correctness, suggesting\npotential for identifying less reliable answers. Our experiments across various\nLLMs and challenging mathematical reasoning datasets (AIME2024 and AIME2025)\nshow consistent accuracy improvements, with gains reaching up to 13\\% and 10\\%\nrespectively. Implementation is available at:\nhttps://github.com/hammoudhasan/SubthoughtReasoner.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-29T12:39:07Z"}
{"aid":"http://arxiv.org/abs/2504.20759v1","title":"Kolyvagin systems of rank 0 and the structure of the Selmer group of\n  elliptic curves over abelian extensions","summary":"With the motivation to study the Selmer group af an elliptic curve, we\nimprove the theory of Kolyvagin systems to describe the Fitting ideals of a\nSelmer group in the core rank zero situation. By relaxing a Selmer structure of\nrank zero at certain prime, we can construct an auxiliary Kolyvagin system\nwhose localisation determines most of the Fitting ideals of the Selmer group,\nand all of them when the Galois representation is not self-dual. With this new\ntheory, one can describe, in terms of the modular symbols, the Galois structure\nof the Selmer group of an elliptic curve $E/\\mathbb{Q}$ over a finite abelian\nextension whose degree is coprime to $p$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-29T13:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.20794v1","title":"Q-Fusion: Diffusing Quantum Circuits","summary":"Quantum computing holds great potential for solving socially relevant and\ncomputationally complex problems. Furthermore, quantum machine learning (QML)\npromises to rapidly improve our current machine learning capabilities. However,\ncurrent noisy intermediate-scale quantum (NISQ) devices are constrained by\nlimitations in the number of qubits and gate counts, which hinder their full\ncapabilities. Furthermore, the design of quantum algorithms remains a laborious\ntask, requiring significant domain expertise and time. Quantum Architecture\nSearch (QAS) aims to streamline this process by automatically generating novel\nquantum circuits, reducing the need for manual intervention. In this paper, we\npropose a diffusion-based algorithm leveraging the LayerDAG framework to\ngenerate new quantum circuits. This method contrasts with other approaches that\nutilize large language models (LLMs), reinforcement learning (RL), variational\nautoencoders (VAE), and similar techniques. Our results demonstrate that the\nproposed model consistently generates 100% valid quantum circuit outputs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T14:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.20812v1","title":"Materials Database from All-electron Hybrid Functional DFT Calculations","summary":"Materials databases built from calculations based on density functional\napproximations play an important role in the discovery of materials with\nimproved properties. Most databases thus constructed rely on the generalized\ngradient approximation (GGA) for electron exchange and correlation. This limits\nthe reliability of these databases, as well as the artificial intelligence (AI)\nmodels trained on them, for certain classes of materials and properties which\nare not well described by GGA. In this paper, we describe a database of 7,024\ninorganic materials presenting diverse structures and compositions generated\nusing hybrid functional calculations enabled by their efficient implementation\nin the all-electron code FHI-aims. The database is used to evaluate the\nthermodynamic and electrochemical stability of oxides relevant to catalysis and\nenergy related applications. We illustrate how the database can be used to\ntrain AI models for material properties using the sure-independence screening\nand sparsifying operator (SISSO) approach.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-29T14:24:27Z"}
{"aid":"http://arxiv.org/abs/2504.20818v1","title":"Simulating metal complex formation and dynamics in aqueous solutions:\n  Insights into stability, mechanism, and rates of ligand exchange","summary":"Metal coordination is ubiquitous in Nature and central in many applications\nranging from nanotechnology to catalysis and environmental chemistry. Complex\nformation results from the subtle interplay between different thermodynamic,\nkinetic, and mechanistic contributions, which remain largely elusive to\nstandard experimental methodologies and challenging for typical modeling\napproaches. Here, we present an effective molecular simulation approach that\ncan fully describe the chemical equilibrium and dynamics of metal complexes in\nsolution, with atomistic detail. Application to Cd(II) and Ni(II) complexes\nwith various amine ligands provides an excellent agreement with available\nassociation constants and formation rates spanning several orders of magnitude.\nMoreover, investigation of polydentate ligands allows unravelling the origin of\nthe chelate effect as due to the concurrent contribution of entropy,\ndissociation rates, and ligand binding mechanisms. This study represents a step\nforward for the in silico design of coordination chemistry applications and for\na better understanding of biochemical processes activated by metal binding.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-29T14:39:01Z"}
{"aid":"http://arxiv.org/abs/2504.20824v1","title":"Variational Quantum Simulation of the Interacting Schwinger Model on a\n  Trapped-Ion Quantum Processor","summary":"Simulations in high-energy physics are currently emerging as an application\nof noisy intermediate-scale quantum (NISQ) computers. In this work, we explore\nthe multi-flavor lattice Schwinger model - a toy model inspired by quantum\nchromodynamics - in one spatial dimension and with nonzero chemical potential\nby means of variational quantum simulation on a shuttling-based trapped-ion\nquantum processor. This fermionic problem becomes intractable for classical\nnumerical methods even for small system sizes due to the notorious sign\nproblem. We employ a parametric quantum circuit executed on our quantum\nprocessor to identify ground states in different parameter regimes of the\nmodel, mapping out a quantum phase transition which is the hallmark feature of\nthe model. The resulting states are analyzed via quantum state tomography, to\nreveal how characteristic properties such as correlations in the output state\nchange across the phase transition. Moreover, we use the results to determine\nthe phase boundaries of the model.","main_category":"quant-ph","categories":"quant-ph,hep-lat","published":"2025-04-29T14:43:57Z"}
{"aid":"http://arxiv.org/abs/2504.20844v1","title":"Effect of Avatar Head Movement on Communication Behaviour, Experience of\n  Presence and Conversation Success in Triadic Conversations","summary":"Interactive communication in virtual reality can be used in experimental\nparadigms to increase the ecological validity of hearing device evaluations.\nThis requires the virtual environment to elicit natural communication behaviour\nin listeners. This study evaluates the effect of virtual animated characters'\nhead movements on participants' communication behaviour and experience.\n  Triadic conversations were conducted between a test participant and two\nconfederates. To facilitate the manipulation of head movements, the\nconversation was conducted in telepresence using a system that transmitted\naudio, head movement data and video with low delay. The confederates were\nrepresented by virtual animated characters (avatars) with different levels of\nanimation: Static heads, automated head movement animations based on speech\nlevel onsets, and animated head movements based on the transmitted head\nmovements of the interlocutors. A condition was also included in which the\nvideos of the interlocutors' heads were embedded in the visual scene.\n  The results show significant effects of animation level on the participants'\nspeech and head movement behaviour as recorded by physical sensors, as well as\non the subjective sense of presence and the success of the conversation. The\nlargest effects were found for the range of head orientation during speech and\nthe perceived realism of avatars. Participants reported that they were spoken\nto in a more helpful way when the avatars showed head movements transmitted\nfrom the interlocutors than when the avatars' heads were static.\n  We therefore conclude that the representation of interlocutors must include\nsufficiently realistic head movements in order to elicit natural communication\nbehaviour.","main_category":"cs.HC","categories":"cs.HC,cs.SD","published":"2025-04-29T15:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.20847v1","title":"Transversal Gates in Nonadditive Quantum Codes","summary":"Transversal gates play a crucial role in suppressing error propagation in\nfault-tolerant quantum computation, yet they are intrinsically constrained: any\nnontrivial code encoding a single logical qubit admits only a finite subgroup\nof $\\mathrm{SU}(2)$ as its transversal operations. We introduce a systematic\nframework for searching codes with specified transversal groups by\nparametrizing their logical subspaces on the Stiefel manifold and minimizing a\ncomposite loss that enforces both the Knill-Laflamme conditions and a target\ntransversal-group structure. Applying this method, we uncover a new $((6,2,3))$\ncode admitting a transversal $Z\\bigl(\\tfrac{2\\pi}{5}\\bigr)$ gate (transversal\ngroup $\\mathrm{C}_{10}$), the smallest known distance $3$ code supporting\nnon-Clifford transversal gates, as well as several new $((7,2,3))$ codes\nrealizing the binary icosahedral group $2I$. We further propose the\n\\emph{Subset-Sum-Linear-Programming} (SS-LP) construction for codes with\ntransversal \\emph{diagonal} gates, which dramatically shrinks the search space\nby reducing to integer partitions subject to linear constraints. In a more\nconstrained form, the method also applies directly to the binary-dihedral\ngroups $\\mathrm{BD}_{2m}$. Specializing to $n=7$, the SS-LP method yields codes\nfor all $\\mathrm{BD}_{2m}$ with $2m\\le 36$, including the first $((7,2,3))$\nexamples supporting transversal $T$ gate ($\\mathrm{BD}_{16}$) and $\\sqrt{T}$\ngate ($\\mathrm{BD}_{32}$), improving on the previous smallest examples\n$((11,2,3))$ and $((19,2,3))$. Extending the SS-LP approach to $((8,2,3))$, we\nconstruct new codes for $2m>36$, including one supporting a transversal\n$T^{1/4}$ gate ($\\mathrm{BD}_{64}$). These results reveal a far richer\nlandscape of nonadditive codes than previously recognized and underscore a\ndeeper connection between quantum error correction and the algebraic\nconstraints on transversal gate groups.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T15:18:33Z"}
{"aid":"http://arxiv.org/abs/2504.20849v1","title":"JaccDiv: A Metric and Benchmark for Quantifying Diversity of Generated\n  Marketing Text in the Music Industry","summary":"Online platforms are increasingly interested in using Data-to-Text\ntechnologies to generate content and help their users. Unfortunately,\ntraditional generative methods often fall into repetitive patterns, resulting\nin monotonous galleries of texts after only a few iterations. In this paper, we\ninvestigate LLM-based data-to-text approaches to automatically generate\nmarketing texts that are of sufficient quality and diverse enough for broad\nadoption. We leverage Language Models such as T5, GPT-3.5, GPT-4, and LLaMa2 in\nconjunction with fine-tuning, few-shot, and zero-shot approaches to set a\nbaseline for diverse marketing texts. We also introduce a metric JaccDiv to\nevaluate the diversity of a set of texts. This research extends its relevance\nbeyond the music industry, proving beneficial in various fields where\nrepetitive automated content generation is prevalent.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T15:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.20851v1","title":"Fostering Self-Directed Growth with Generative AI: Toward a New Learning\n  Analytics Framework","summary":"In an era increasingly shaped by decentralized knowledge ecosystems and\npervasive AI technologies, fostering sustainable learner agency has become a\ncritical educational imperative. This study introduces a novel conceptual\nframework integrating Generative Artificial Intelligence and Learning Analytics\nto cultivate Self-Directed Growth, a dynamic competency that enables learners\nto iteratively drive their own developmental pathways across diverse\ncontexts.Building upon critical gaps in current research on Self Directed\nLearning and AI-mediated education, the proposed Aspire to Potentials for\nLearners (A2PL) model reconceptualizes the interplay of learner aspirations,\ncomplex thinking, and summative self-assessment within GAI supported\nenvironments.Methodological implications for future intervention design and\nlearning analytics applications are discussed, positioning Self-Directed Growth\nas a pivotal axis for developing equitable, adaptive, and sustainable learning\nsystems in the digital era.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-29T15:19:48Z"}
{"aid":"http://arxiv.org/abs/2504.20855v1","title":"Online General Knapsack with Reservation Costs","summary":"In the online general knapsack problem, an algorithm is presented with an\nitem $x=(s,v)$ of size $s$ and value $v$ and must irrevocably choose to pack\nsuch an item into the knapsack or reject it before the next item appears. The\ngoal is to maximize the total value of the packed items without overflowing the\nknapsack's capacity.\n  As this classical setting is way too harsh for many real-life applications,\nwe will analyze the online general knapsack problem under the reservation\nmodel. Here, instead of accepting or rejecting an item immediately, an\nalgorithm can delay the decision of whether to pack the item by paying a\nfraction $0\\le \\alpha$ of the size or the value of the item. This models many\npractical applications, where, for example, decisions can be delayed for some\ncosts e.g. cancellation fees. We present results for both variants: First, for\ncosts depending on the size of the items and then for costs depending on the\nvalue of the items.\n  If the reservation costs depend on the size of the items, we find a matching\nupper and lower bound of $2$ for every $\\alpha$. On the other hand, if the\nreservation costs depend on the value of the items, we find that no algorithm\nis competitive for reservation costs larger than $1/2$ of the item value, and\nwe find upper and lower bounds for the rest of the reservation range\n$0\\le\\alpha< 1/2$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-29T15:24:29Z"}
{"aid":"http://arxiv.org/abs/2504.20856v1","title":"Wave Particle Interaction in the Upstream of ICME Shocks","summary":"Shocks associated with Interplanetary Coronal Mass Ejections are known to\nenergize charged particles and give rise to Solar Energetic Particles. Many of\nthese energetic particles move ahead of the shock to create a foreshock region.\nThe foreshock region primarily consists of solar wind plasma, exhibiting\nturbulent velocity and magnetic fields. Such turbulent behavior results from\ninherent solar wind turbulence modified by energetic particles. We analyze\nmagnetic field data from six such ICME shocks observed by the Wind spacecraft.\nThe analysis of the shock upstream shows that the magnetic power spectral\ndensity (PSD) maintains a power-law slope of $-5/3$. We also identify clear\nintermittent peaks in the PSD. After characterizing these peaks, we investigate\nvarious possibilities for their generation. Our analysis indicates that these\npeaks in the PSD are due to the resonant interaction of Alfv\\'en waves with the\nbulk solar wind protons and protons with energy up to $10$~keV. However,\nevidence of Alfv\\'en wave interaction with highly energetic protons is not\nevident in our analysis, and we anticipate that such evidence is obscured by\nthe prevailing solar wind turbulence in the shock upstream.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.plasm-ph","published":"2025-04-29T15:31:21Z"}
{"aid":"http://arxiv.org/abs/2504.20928v1","title":"XRISM forecast for the Coma cluster: stormy, with a steep power spectrum","summary":"The XRISM Resolve microcalorimeter array measured the velocities of hot\nintracluster gas at two positions in the Coma galaxy cluster: 3'x3' squares at\nthe center and at 6' (170 kpc) to the south. We find the line-of-sight velocity\ndispersions in those regions to be sigma_z=208+-12 km/s and 202+-24 km/s,\nrespectively. The central value corresponds to a 3D Mach number of\nM=0.24+-0.015 and the ratio of the kinetic pressure of small-scale motions to\nthermal pressure in the intracluster plasma of only 3.1+-0.4%, at the lower end\nof predictions from cosmological simulations for merging clusters like Coma,\nand similar to that observed in the cool core of the relaxed cluster A2029.\nMeanwhile, the gas in both regions exhibits high line-of-sight velocity\ndifferences from the mean velocity of the cluster galaxies, Delta v_z=450+-15\nkm/s and 730+-30 km/s, respectively. A small contribution from an additional\ngas velocity component, consistent with the cluster optical mean, is detected\nalong a sightline near the cluster center. The combination of the observed\nvelocity dispersions and bulk velocities is not described by a Kolmogorov\nvelocity power spectrum of steady-state turbulence; instead, the data imply a\nmuch steeper effective slope (i.e., relatively more power at larger linear\nscales). This may indicate either a very large dissipation scale resulting in\nthe suppression of small-scale motions, or a transient dynamic state of the\ncluster, where large-scale gas flows generated by an ongoing merger have not\nyet cascaded down to small scales.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-04-29T16:47:34Z"}
{"aid":"http://arxiv.org/abs/2504.20940v1","title":"Energy-Based Coarse-Graining in Molecular Dynamics: A Flow-Based\n  Framework Without Data","summary":"Coarse-grained (CG) models offer an effective route to reducing the\ncomplexity of molecular simulations, yet conventional approaches depend heavily\non long all-atom molecular dynamics (MD) trajectories to adequately sample\nconfigurational space. This data-driven dependence limits their accuracy and\ngeneralizability, as unvisited configurations remain excluded from the\nresulting CG model. We introduce a data-free generative framework for\ncoarse-graining that directly targets the all-atom Boltzmann distribution. Our\nmodel defines a structured latent space comprising slow collective variables,\nwhich are statistically associated with multimodal marginal densities capturing\nmetastable states, and fast variables, which represent the remaining degrees of\nfreedom with simple, unimodal conditional distributions. A potentially\nlearnable, bijective map from the full latent space to the all-atom\nconfiguration space enables automatic and accurate reconstruction of molecular\nstructures. The model is trained using an energy-based objective that minimizes\nthe reverse Kullback-Leibler divergence, relying solely on the interatomic\npotential rather than sampled trajectories. A tempering scheme is used to\nstabilize training and promote exploration of diverse configurations. Once\ntrained, the model can generate unbiased, one-shot equilibrium all-atom\nsamples. We validate the method on two synthetic systems-a double-well\npotential and a Gaussian mixture-as well as on the benchmark alanine dipeptide.\nThe model captures all relevant modes of the Boltzmann distribution, accurately\nreconstructs atomic configurations, and learns physically meaningful\ncoarse-grained representations, all without any simulation data.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cs.LG,physics.comp-ph","published":"2025-04-29T17:05:27Z"}
{"aid":"http://arxiv.org/abs/2504.20960v1","title":"MINER Reactor Based Search for Axion-Like Particles Using Sapphire\n  (Al2O3) Detectors","summary":"The absence of definitive results for WIMP dark matter has sparked growing\ninterest in alternative dark matter candidates, such as axions and Axion-Like\nParticles (ALPs), which also provide insight into the strong CP problem. The\nMitchell Institute Neutrino Experiment at Reactor (MINER), conducted at the\nNuclear Science Center of Texas A&M University, investigated ALPs near a 1 MW\nTRIGA nuclear reactor core, positioned approximately 4 meters away. This\nexperiment employed cryogenic sapphire detectors with a low detection threshold\n(approximately 100 eV), equipped with a Transition Edge Sensor capable of\ndetecting athermal phonons. Due to the low-background environment, we were able\nto exclude ALPs with axion-photon coupling and axion-electron coupling as small\nas \\(g_{a\\gamma\\gamma} = 10^{-5}\\) and \\(g_{aee} = 10^{-7}\\), respectively.\nEnergy depositions below 3 keV were not considered and remain blinded for our\nCoherent Elastic Neutrino Nucleus Scattering (CEvNS) analysis. This is the\nfirst result demonstrating the MINER experiment's potential to probe low-mass\nALPs, enabled by its low-threshold detector and proximity to a reactor.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-29T17:32:20Z"}
{"aid":"http://arxiv.org/abs/2504.20962v1","title":"A Novel Method of Modeling Extended Emission of Compact Jets:\n  Application to Swift J1727.8-1613","summary":"Flat radio spectra of compact jets launched by both supermassive and\nstellar-mass black holes are explained by an interplay of self-absorbed\nsynchrotron emission up to some distance along the jet and optically thin\nsynchrotron at larger distances (Blandford & Konigl 1979). Their spatial\nstructure is usually studied using core shifts, in which the position of the\npeak (core) of the emission depends on the frequency. Here, we propose a novel\nmethod to fit the spatial dependence of the flux density at a given frequency\nof the jet and counterjet (when observed) using the theoretical spatial\ndependencies, which we provide as simple analytical formulae. We apply our\nmethod to the spatial structure of the jets in the luminous hard spectral state\nof the black-hole X-ray binary Swift J1727.8--1613. It was the most resolved\ncontinuous jet from an X-ray binary ever observed. We find that the observed\napproaching jet is significantly intrinsically stronger than the receding one,\nwhich we attribute to an increase in the emission of both jets with time\n(observationally confirmed), together with the light travel effect, causing the\nreceding jet to be observed at an earlier epoch than the approaching one. The\njets are relatively slow, with the velocity $\\sim(0.3$--$0.4)c$. Our findings\nimply that the magnetic field strength increased with time. Also, the magnetic\nflux is much lower than in jets launched by `Magnetically Arrested Disks'. Our\nmethod is general, and we propose that it be applied to jets launched by\nstellar-mass and supermassive black holes.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-29T17:32:38Z"}
{"aid":"http://arxiv.org/abs/2504.20971v1","title":"A distance between operators acting in different Hilbert spaces and\n  operator convergence","summary":"The aim of the present article is to give an introduction to the concept of\nquasi-unitary equivalence and to define several (pseudo-)metrics on the space\nof self-adjoint operators acting possibly in different Hilbert spaces. As some\nof the ``metrics'' do not fulfill all properties of a metric (e.g. some lack\nthe triangle inequality or the definiteness), we call them ``distances'' here.\nTo the best of our knowledge, such distances are treated for the first time\nhere. The present article shall serve as a starting point of further research\n(see e.g. arXiv:2412.13165).","main_category":"math.FA","categories":"math.FA,math-ph,math.MP,math.SP","published":"2025-04-29T17:39:21Z"}
{"aid":"http://arxiv.org/abs/2504.20978v1","title":"Coloring graphs as complete graph invariants","summary":"For a graph $G$, the $k$-coloring graph $\\mathcal{C}_{k}(G)$ is obtained by\ntaking the vertices to be the proper $k$-colorings of $G$ and two $k$-colorings\nare incident if they differ exactly on one vertex of $G$. Hogan, Scott,\nTamitegama and Tan recently proved that $\\mathcal{C}_{k_1}(G_1)\\cong\n\\mathcal{C}_{k_2}(G_2)$ with $k_1>5n_1^2$ and $k_2>5n_2^2$ implies $G_1\\cong\nG_2$, where $n_i$ is the number of vertices of $G_i$ for $i=1,2$. We sharpen\nthis result by showing that $\\mathcal{C}_{k_1}(G_1)\\cong\n\\mathcal{C}_{k_2}(G_2)$ with $k_1>\\chi(G_1)$ and $k_2>\\chi(G_2)$ implies\n$G_1\\cong G_2$, where $\\chi(G)$ is the chromatic number of $G$. In other words,\ngiven any graph $\\mathcal{C}$, there is at most one pair of $G$ and $k>\\chi(G)$\nsuch that $\\mathcal C=\\mathcal C_k(G)$, and we additionally provide an\nalgorithm to reconstruct $(G,k)$ from $\\mathcal C$ or determine that no such\npair exists. Moreover, our requirement that $k>\\chi$ is tight because coloring\ngraphs are empty for $k<\\chi$ and there exist examples of non-isomorphic\n$G_1,G_2$ with $k=\\chi(G_1)=\\chi(G_2)$ such that $\\mathcal C_k(G_1)\\cong\n\\mathcal C_k(G_2)$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T17:49:06Z"}
{"aid":"http://arxiv.org/abs/2504.20985v1","title":"Acylindrically hyperbolic groups and counting problems","summary":"We show that Morse elements are generic in acylindrically hyperbolic groups.\nAs an application, we observe that fully irreducible outer automorphisms are\ngeneric in the outer automorphism group of a finite-rank free group.","main_category":"math.GR","categories":"math.GR,math.GT","published":"2025-04-29T17:55:53Z"}
{"aid":"http://arxiv.org/abs/2504.21262v1","title":"Thermally Induced Refractive Index Trimming of Visible-Light Silicon\n  Nitride Waveguides Using Suspended Heaters","summary":"We demonstrate refractive index trimming of visible-light silicon nitride\n(SiN) waveguides using suspended heater structures. The thermal isolation of\nthe suspended heaters enabled a semi-uniform temperature distribution with\nestimated temperatures of $\\sim$350{\\deg}C in the waveguides without reaching\npotentially damaging temperatures in the titanium nitride resistive heaters.\nThe thermal isolation also enabled trimming temperatures to be reached with a\nmoderate power dissipation of 30 to 40 mW. At a wavelength of 561 nm, modal\neffective index changes up to $-8.3 \\times 10^{-3}$ were observed following\nthermal trimming, and the index changes were stable over an observation period\nof 97 days. The devices were fabricated as part of our visible-light integrated\nphotonics platform on 200-mm diameter silicon wafers. The suspended heaters\nalso functioned as efficient thermo-optic phase shifters with power dissipation\nfor a $\\pi$ phase shift of about $1.2-1.8$ mW. The trimming method was applied\nto set the bias points of thermo-optic Mach-Zehnder interferometer switches to\nreduce the bias power of five devices from $0.29-2.32$ mW to $0.1-0.16$ mW.\nThermal trimming at a wavelength of 445 nm was also demonstrated. Through\nmaterial analysis before and after thermal treatment, we hypothesize that index\ntrimming of the silica (SiO$_2$) waveguide cladding may be a potential\nunderlying mechanism. Additionally, via extrapolations of the measured trimming\ndata, we estimate the thermal aging behavior of the SiN waveguides in the\nsuspended heaters at lower (125 - 250{\\deg}C) operating temperatures.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-30T02:40:15Z"}
{"aid":"http://arxiv.org/abs/2504.21282v1","title":"Birdie: Natural Language-Driven Table Discovery Using Differentiable\n  Search Index","summary":"Natural language (NL)-driven table discovery identifies relevant tables from\nlarge table repositories based on NL queries. While current deep-learning-based\nmethods using the traditional dense vector search pipeline, i.e.,\nrepresentation-index-search, achieve remarkable accuracy, they face several\nlimitations that impede further performance improvements: (i) the errors\naccumulated during the table representation and indexing phases affect the\nsubsequent search accuracy; and (ii) insufficient query-table interaction\nhinders effective semantic alignment, impeding accuracy improvements. In this\npaper, we propose a novel framework Birdie, using a differentiable search\nindex. It unifies the indexing and search into a single encoder-decoder\nlanguage model, thus getting rid of error accumulations. Birdie first assigns\neach table a prefix-aware identifier and leverages a large language model-based\nquery generator to create synthetic queries for each table. It then encodes the\nmapping between synthetic queries/tables and their corresponding table\nidentifiers into the parameters of an encoder-decoder language model, enabling\ndeep query-table interactions. During search, the trained model directly\ngenerates table identifiers for a given query. To accommodate the continual\nindexing of dynamic tables, we introduce an index update strategy via parameter\nisolation, which mitigates the issue of catastrophic forgetting. Extensive\nexperiments demonstrate that Birdie outperforms state-of-the-art dense methods\nby 16.8% in accuracy, and reduces forgetting by over 90% compared to other\ncontinual learning approaches.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-30T03:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.21286v1","title":"NEP89: Universal neuroevolution potential for inorganic and organic\n  materials across 89 elements","summary":"Machine-learned potentials (MLPs) offer near-first-principles accuracy for\natomistic simulations, but many models are material-specific or computationally\nintensive, limiting their broader use. Here, we introduce NEP89, a foundation\nmodel based on the neuroevolution potential (NEP) architecture, delivering\nempirical-potential-like speed and high accuracy across 89 chemical elements. A\ncompact yet comprehensive training dataset covering inorganic and organic\nmaterials across 89 elements was curated through descriptor-space subsampling\nand an iterative active-learning-like process applied to multiple datasets. We\nrigorously evaluated NEP89's predictive performance against representative\nfoundation models, demonstrating its reliability and competitive accuracy\nacross diverse benchmark studies. NEP89 is 3-4 orders of magnitude more\ncomputationally efficient than comparable models, enabling previously\nimpractical large-scale atomistic simulations for both inorganic and organic\nsystems. It also supports fine-tuning on small datasets, allowing rapid\nadaptation to user-specific applications. This work marks a significant\nadvancement in MLPs, enabling high-performance atomistic simulations across\ndiverse research fields and communities.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-30T03:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.21315v1","title":"Long-time asymptotics of the coupled nonlinear Sch√∂dinger equation in\n  a weighted Sobolev space","summary":"We study the Cauchy problem for the focusing coupled nonlinear Schr\\\"odinger\n(CNLS) equation with initial data $\\mathbf{q}_0$\n  lying in the weighted Sobolev space and the scattering data having $n$ simple\nzeros.\n  Based on the corresponding $3\\times3$ matrix spectral problem, we deduce the\nRiemann-Hilbert problem (RHP)\n  for CNLS equation through inverse scattering transform. We remove discrete\nspectrum of initial RHP using Darboux transformations.\n  By applying the nonlinear steepest-descent method for RHP introduced by Deift\nand Zhou,\n  we compute the long-time asymptotic\n  expansion of the solution $\\mathbf{q}(x,t)$ to an (optimal) residual error of\norder $\\mathcal{O}\\left(t^{-3 / 4+1/(2p)}\\right)$ where\n  $2\\le p<\\infty$. The leading order term in this expansion is a multi-soliton\nwhose parameters are modulated by soliton-soliton and\n  soliton-radiation interactions. Our work strengthens and extends the earlier\nwork regarding long-time\n  asymptotics for solutions of the nonlinear Schr\\\"odinger equation with a\ndelta potential and even initial data by Deift and Park.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-30T05:03:18Z"}
{"aid":"http://arxiv.org/abs/2504.21325v1","title":"Text-Conditioned Diffusion Model for High-Fidelity Korean Font\n  Generation","summary":"Automatic font generation (AFG) is the process of creating a new font using\nonly a few examples of the style images. Generating fonts for complex languages\nlike Korean and Chinese, particularly in handwritten styles, presents\nsignificant challenges. Traditional AFGs, like Generative adversarial networks\n(GANs) and Variational Auto-Encoders (VAEs), are usually unstable during\ntraining and often face mode collapse problems. They also struggle to capture\nfine details within font images. To address these problems, we present a\ndiffusion-based AFG method which generates high-quality, diverse Korean font\nimages using only a single reference image, focusing on handwritten and printed\nstyles. Our approach refines noisy images incrementally, ensuring stable\ntraining and visually appealing results. A key innovation is our text encoder,\nwhich processes phonetic representations to generate accurate and contextually\ncorrect characters, even for unseen characters. We used a pre-trained style\nencoder from DG FONT to effectively and accurately encode the style images. To\nfurther enhance the generation quality, we used perceptual loss that guides the\nmodel to focus on the global style of generated images. Experimental results on\nover 2000 Korean characters demonstrate that our model consistently generates\naccurate and detailed font images and outperforms benchmark methods, making it\na reliable tool for generating authentic Korean fonts across different styles.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T05:24:49Z"}
{"aid":"http://arxiv.org/abs/2504.21349v1","title":"Gorenstein homological modules over tensor rings","summary":"For a tensor ring $T_R(M)$, under certain conditions, we characterize the\nGorenstein projective modules over $T_R(M)$, and prove that a $T_R(M)$-module\n$(X,u)$ is Gorenstein projective if and only if $u$ is monomorphic and ${\\rm\ncoker}(u)$ is a Gorenstein projective $R$-module. Gorenstein injective (resp.,\nflat) modules over $T_R(M)$ are also explicitly described. Moreover, we give a\ncharacterization for the coherence of $T_R(M)$. Some applications to trivial\nring extensions and Morita context rings are given.","main_category":"math.RA","categories":"math.RA,math.KT","published":"2025-04-30T06:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.21360v1","title":"ImaginateAR: AI-Assisted In-Situ Authoring in Augmented Reality","summary":"While augmented reality (AR) enables new ways to play, tell stories, and\nexplore ideas rooted in the physical world, authoring personalized AR content\nremains difficult for non-experts, often requiring professional tools and time.\nPrior systems have explored AI-driven XR design but typically rely on\nmanually-defined environments and fixed asset libraries, limiting creative\nflexibility and real-world relevance. We introduce ImaginateAR, a mobile\nAI-assisted AR authoring system that aims to let anyone build anything,\nanywhere -- simply by speaking their imagination. ImaginateAR is powered by\ncustom pipelines for offline scene understanding, fast 3D asset generation, and\nLLM-driven speech interaction. Users might say \"a dragon enjoying a campfire\"\n(P7) and iteratively refine the scene using both AI and manual tools. Our\ntechnical evaluation shows that ImaginateAR produces more accurate outdoor\nscene graphs and generates 3D meshes faster than prior methods. A three-part\nuser study (N=20) revealed preferred roles for AI in authoring, what and how\nusers create in free-form use, and design implications for future AR authoring\ntools.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-30T06:44:14Z"}
{"aid":"http://arxiv.org/abs/2504.21364v1","title":"Uniform-in-time weak error estimates of explicit full-discretization\n  schemes for SPDEs with non-globally Lipschitz coefficients","summary":"This article is devoted to long-time weak approximations of stochastic\npartial differential equations (SPDEs) evolving in a bounded domain\n$\\mathcal{D} \\subset \\mathbb{R}^d$, $d \\leq 3$, with non-globally Lipschitz and\npossibly non-contractive coefficients. Both the space-time white noise ($d=1$)\nand the trace-class noise in multiple dimensions $d=2,3$ are examined for the\nconsidered SPDEs. Based on a spectral Galerkin spatial semi-discretization, we\npropose a class of novel full-discretization schemes of exponential type, which\nare explicit, easily implementable and preserve the ergodicity of the original\ndissipative SPDEs with possibly non-contractive coefficients. The\nuniform-in-time weak approximation errors are carefully analyzed in a low\nregularity and non-contractive setting, with uniform-in-time weak convergence\nrates obtained. A key ingredient is to establish the uniform-in-time moment\nbounds (in $L^{4q-2}$-norm, $q \\geq 1$) for the proposed fully discrete schemes\nin a super-linear setting. This is highly non-trivial for the explicit\nfull-discretization schemes and new arguments are elaborated by fully\nexploiting a contractive property of the semi-group in $L^{4q-2}$, the\ndissipativity of the nonlinearity and the particular benefit of the taming\nstrategy. Numerical experiments are finally reported to verify the theoretical\nfindings.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T06:52:23Z"}
{"aid":"http://arxiv.org/abs/2504.21378v1","title":"The polynomial growth of effective resistances in one-dimensional\n  critical long-range percolation","summary":"We study the critical long-range percolation on $\\mathbb{Z}$, where an edge\nconnects $i$ and $j$ independently with probability\n$1-\\exp\\{-\\beta\\int_i^{i+1}\\int_j^{j+1}|u-v|^{-2}{\\rm d} u{\\rm d} v\\}$ for\n$|i-j|>1$ for some fixed $\\beta>0$ and with probability 1 for $|i-j|=1$.\nViewing this as a random electric network where each edge has a unit\nconductance, we show that the effective resistances from 0 to $[-n,n]^c$ and\nfrom the interval $[-n,n]$ to $[-2n,2n]^c$ (conditioned on no edge joining\n$[-n,n]$ and $[-2n,2n]^c$) both grow like $n^{\\delta(\\beta)}$ for some\n$\\delta(\\beta)\\in (0,1)$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T07:28:00Z"}
{"aid":"http://arxiv.org/abs/2504.21399v1","title":"The golden age of solar magnetography at Paris-Meudon observatory in the\n  second half of the twentieth century","summary":"This paper describes advances in solar magnetography and developments in\ninstrumental techniques of polarimetry and spectroscopy made at Paris-Meudon\nobservatory in the second half of the twentieth century. The adventure started\nfrom Lyot expertise and extended progressively to the measurement of vector\nmagnetic fields using various and improving polarimetric techniques (such as\nbeam exchange or grid) or new spectroscopic methods (such as the MSDP imaging\nslicer), at Meudon and Pic du Midi, ending by the achievement of the\nstate-of-the-art optimized and polarization free telescope THEMIS in 1999.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.SR","published":"2025-04-30T07:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.21438v1","title":"Wasserstein-Aitchison GAN for angular measures of multivariate extremes","summary":"Economically responsible mitigation of multivariate extreme risks -- extreme\nrainfall in a large area, huge variations of many stock prices, widespread\nbreakdowns in transportation systems -- requires estimates of the probabilities\nthat such risks will materialize in the future. This paper develops a new\nmethod, Wasserstein--Aitchison Generative Adversarial Networks (WA-GAN), which\nprovides simulated values of future $d$-dimensional multivariate extreme events\nand which hence can be used to give estimates of such probabilities. The main\nhypothesis is that, after transforming the observations to the unit-Pareto\nscale, their distribution is regularly varying in the sense that the\ndistributions of their radial and angular components (with respect to the\n$L_1$-norm) converge and become asymptotically independent as the radius gets\nlarge. The method is a combination of standard extreme value analysis modeling\nof the tails of the marginal distributions with nonparametric GAN modeling of\nthe angular distribution. For the latter, the angular values are transformed to\nAitchison coordinates in a full $(d-1)$-dimensional linear space, and a\nWasserstein GAN is trained on these coordinates and used to generate new\nvalues. A reverse transformation is then applied to these values and gives\nsimulated values on the original data scale. The method shows good performance\ncompared to other existing methods in the literature, both in terms of\ncapturing the dependence structure of the extremes in the data, as well as in\ngenerating accurate new extremes of the data distribution. The comparison is\nperformed on simulated multivariate extremes from a logistic model in\ndimensions up to 50 and on a 30-dimensional financial data set.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-30T08:54:28Z"}
{"aid":"http://arxiv.org/abs/2504.21441v1","title":"Diffusion of intruders in a granular gas thermostatted by a bath of\n  elastic hard spheres","summary":"The Boltzmann kinetic equation is considered to compute the transport\ncoefficients associated with the mass flux of intruders in a granular gas.\nIntruders and granular gas are immersed in a gas of elastic hard spheres\n(molecular gas). We assume that the granular particles are sufficiently\nrarefied so that the state of the molecular gas is not affected by the presence\nof the granular gas. Thus, the gas of elastic hard spheres can be considered as\na thermostat (or bath) at a fixed temperature $T_g$. In the absence of spatial\ngradients, the system achieves a steady state where the temperature of the\ngranular gas $T$ differs from that of the intruders $T_0$ (energy\nnonequipartition). Approximate theoretical predictions for the temperature\nratios $T/T_g$ and $T_0/T_g$ and the kurtosis $c$ and $c_0$ associated with the\ngranular gas and the intruders compare very well with Monte Carlo simulations\nfor conditions of practical interest. For states close to the steady\nhomogeneous state, the Boltzmann equation for the intruders is solved by means\nof the Chapman--Enskog method to first order in the spatial gradients. As\nexpected, the diffusion transport coefficients are given in terms of the\nsolutions of a set of coupled linear integral equations which are approximately\nsolved by considering the first-Sonine approximation. In dimensionless form,\nthe transport coefficients are nonlinear functions of the mass and diameter\nratios, the coefficients of restitution, and the (reduced) bath temperature.\nInterestingly, previous results derived from a suspension model based on an\neffective fluid-solid interaction force are recovered when $m/m_g\\to \\infty$\nand $m_0/m_g\\to \\infty$, where $m$, $m_0$, and $m_g$ are the masses of the\ngranular, intruder, and molecular gas particle, respectively. Finally, as an\napplication of our results, thermal diffusion segregation is exhaustively\nanalysed.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-30T08:56:18Z"}
{"aid":"http://arxiv.org/abs/2504.21451v1","title":"Powers of 2 in Balanced Grid Colourings","summary":"Let $B(m, n)$ be the number of ways to colour a $2m \\times 2n$ grid in black\nand white so that, in each row and each column, half of the cells are white and\nhalf are black. Bhattacharya conjectured that the exponent of $2$ in the prime\nfactorisation of $B(m, n)$ equals $s_2(m)s_2(n)$, where $s_2(x)$ denotes the\nnumber of $1$s in the binary expansion of $x$. We confirm this conjecture in\nsome infinite families of special cases; most significantly, when $m$ is of the\nform either $2^k$ or $2^k + 1$ and $n$ is arbitrary. The proof when $m = 2^k +\n1$ is substantially more difficult, and in connection with it we develop some\ngeneral techniques for the analysis of inequalities between binary digit sums.","main_category":"math.CO","categories":"math.CO","published":"2025-04-30T09:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.21469v1","title":"Turning a Disposable Bronchoscope into a Dynamic Speckle Imaging Tool:\n  Yes, It Works","summary":"Dynamic speckle imaging, typically used in laser-illuminated surface\ndiagnostics, has proven valuable for assessing biological activity. In this\nwork, we demonstrate its feasibility in an endoscopic context using a\ndisposable bronchoscope. Despite technical limitations and aliasing artifacts,\nour preliminary results show discernible vascular structures, indicating\npotential for minimally invasive diagnostic applications. It is important to\nnote that the imaging systems used in this study are designed primarily for\nclinical robustness and classical imaging, including single-use sterility, ease\nof handling, and real-time visualization, and not for scientific fidelity of\nvisual data or computational post-processing. As such, they are not inherently\nsuited to dynamic speckle analysis, which requires precise control over\ntemporal acquisition parameters, linear response characteristics of the imaging\nsensor, and stable illumination conditions, particularly from the coherent\nlaser source. Nevertheless, our results demonstrate that, even within these\nconstraints, dynamic speckle imaging is indeed achievable. This opens the door\nto further adaptation and optimization of such clinical imaging tools for\nfunctional biomedical investigations.","main_category":"physics.ins-det","categories":"physics.ins-det,physics.med-ph","published":"2025-04-30T09:47:43Z"}
{"aid":"http://arxiv.org/abs/2504.21471v1","title":"Efficiently Finding All Minimal and Shortest Absent Subsequences in a\n  String","summary":"Given a string $w$, another string $v$ is said to be a subsequence of $w$ if\n$v$ can be obtained from $w$ by removing some of its letters; on the other\nhand, $v$ is called an absent subsequence of $w$ if $v$ is not a subsequence of\n$w$. The existing literature on absent subsequences focused on understanding,\nfor a string $w$, the set of its shortest absent subsequences (i.e., the\nshortest strings which are absent subsequences of $w$) and that of its minimal\nabsent subsequences (i.e., those strings which are absent subsequences of $w$\nbut whose every proper subsequence occurs in $w$). Our contributions to this\narea of research are the following. Firstly, we present optimal algorithms\n(with linear time preprocessing and output-linear delay) for the enumeration of\nthe shortest and, respectively, minimal absent subsequences. Secondly, we\npresent optimal algorithms for the incremental enumeration of these strings\nwith linear time preprocessing and constant delay; in this setting, we only\noutput short edit-scripts showing how the currently enumerated string differs\nfrom the previous one. Finally, we provide an efficient algorithm for\nidentifying a longest minimal absent subsequence of a string. All our\nalgorithms improve the state-of-the-art results for the aforementioned\nproblems.","main_category":"cs.DS","categories":"cs.DS,cs.FL","published":"2025-04-30T09:48:47Z"}
{"aid":"http://arxiv.org/abs/2504.21490v1","title":"Investigation of magnon behavior in YIG film under microwave excitation\n  using Brillouin light scattering","summary":"We utilize conventional wave-vector-resolved Brillouin light scattering\ntechnology to investigate the spin wave response in YIG thin films under\nhigh-power microwave excitation. By varying the microwave frequency, external\nbias magnetic field, and in-plane wave vector, in addition to observing the\ndipole-exchange spin waves excited by parallel parametric pumping, we further\nobserve broadband spin wave excitation within the dipole-exchange spin wave\nspectrum. This broadband excitation results from the combined effects of\nparallel and perpendicular parametric pumping, induced by irregularities in the\nexcitation geometry, as well as magnon-magnon scattering arising from the\nabsence of certain spin wave modes. Our findings offer new insights into the\nmechanisms of energy dissipation and relaxation processes caused by spin wave\nexcitation in magnetic devices operating at high power.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-30T10:18:46Z"}
{"aid":"http://arxiv.org/abs/2504.21539v1","title":"Search for the lepton number violation decay $œâ\\to œÄ^+ œÄ^+\n  e^-e^- +c.c.$","summary":"The lepton number violation decay $\\omega \\to \\pi^+ \\pi^+ e^-e^- +c.c.$ is\nsearched for via $J/\\psi \\to \\omega\\eta$ using a data sample of $(1.0087 \\pm\n0.0044) \\times 10^{10}$ $J/\\psi$ events collected by the BESIII detector at the\nBEPCII collider. No significant signal is observed, and the upper limit on the\nbranching fraction of $\\omega \\to \\pi^+ \\pi^+ e^-e^- +c.c.$ at the 90\\%\nconfidence level is determined for the first time to be $2.8 \\times 10^{-6}$.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-30T11:36:18Z"}
{"aid":"http://arxiv.org/abs/2504.21567v1","title":"PolyQROM: Orthogonal-Polynomial-Based Quantum Reduced-Order Model for\n  Flow Field Analysis","summary":"Quantum computing promises exponential acceleration for fluid flow\nsimulations, yet the measurement overhead required to extract flow features\nfrom quantum-encoded flow field data fundamentally undermines this advantage--a\ncritical challenge termed the ``output problem''. To address this, we propose\nan orthogonal-polynomial-based quantum reduced-order model (PolyQROM) that\nintegrates orthogonal polynomial basis transformations with variational quantum\ncircuits (VQCs). PolyQROM employs optimized polynomial-based quantum operations\nto compress flow field data into low-dimensional representations while\npreserving essential features, enabling efficient quantum or classical\npost-processing for tasks like reconstruction and classification. By leveraging\nthe mathematical properties of orthogonal polynomials, the framework enhances\ncircuit expressivity and stabilizes training compared to conventional\nhardware-efficient VQCs. Numerical experiments demonstrate PolyQROM's\neffectiveness in reconstructing flow fields with high fidelity and classifying\nflow patterns with accuracy surpassing classical methods and quantum\nbenchmarks, all while reducing computational complexity and parameter counts.\nThe work bridges quantum simulation outputs with practical fluid analysis,\naddressing the ``output problem'' through efficient reduced-order modeling\ntailored for quantum-encoded flow data, offering a scalable pathway to exploit\nquantum advantages in computational fluid dynamics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T12:14:08Z"}
{"aid":"http://arxiv.org/abs/2504.21595v1","title":"Real-time Program Evaluation using Anytime-valid Rank Tests","summary":"Counterfactual mean estimators such as difference-in-differences and\nsynthetic control have grown into workhorse tools for program evaluation.\nInference for these estimators is well-developed in settings where all\npost-treatment data is available at the time of analysis. However, in settings\nwhere data arrives sequentially, these tests do not permit real-time inference,\nas they require a pre-specified sample size T. We introduce real-time inference\nfor program evaluation through anytime-valid rank tests. Our methodology relies\non interpreting the absence of a treatment effect as exchangeability of the\ntreatment estimates. We then convert these treatment estimates into sequential\nranks, and construct optimal finite-sample valid sequential tests for\nexchangeability. We illustrate our methods in the context of\ndifference-in-differences and synthetic control. In simulations, they control\nsize even under mild exchangeability violations. While our methods suffer\nslight power loss at T, they allow for early rejection (before T) and preserve\nthe ability to reject later (after T).","main_category":"econ.EM","categories":"econ.EM,stat.ME","published":"2025-04-30T12:53:08Z"}
{"aid":"http://arxiv.org/abs/2504.21630v1","title":"Superconductivity and trimers on attractive-$U$ Hubbard ladders","summary":"We investigate the interplay between superconducting correlations and trimer\nformation in polarized two-component Fermi gases confined to multileg\nattractive-$U$ Hubbard ladders. Employing density matrix renormalization group\n(DMRG) simulations, we explore the effects of spin-dependent tunneling\namplitudes on these systems. Specifically, we analyze how bound states of three\nfermions (trimers) impact Fulde-Ferrell-Larkin-Ovchinnikov (FFLO)\nsuperconducting correlations at commensurate charge carrier densities, where\n$2n_{\\uparrow} = n_{\\downarrow}$. In one-dimensional (1D) systems, trimer\nformation is known to suppress FFLO correlations exponentially. Our results\ndemonstrate that this suppression persists on ladder lattices of small width,\neffectively mirroring the 1D behavior. However, we find a striking departure\nfrom the 1D regime as the ladder width increases. On ladders with a width of\nfour legs, the influence of trimers on superconducting correlations becomes\nnegligible, suggesting that wider ladder systems provide a distinct environment\nwhere FFLO-like pairing remains robust even in the presence of trimer states.\nThese findings underscore the dimensional crossover in Hubbard systems and shed\nlight on the mechanisms governing superconductivity and bound-state formation\nin strongly correlated fermionic systems. Our work has implications for\nunderstanding unconventional superconductivity in strongly correlated systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-30T13:33:06Z"}
{"aid":"http://arxiv.org/abs/2504.21637v1","title":"On the justification of Koiter's model for elliptic membranes subjected\n  to an interior normal compliance contact condition","summary":"The purpose of this paper is twofold. First, we rigorously justify Koiter's\nmodel for linearly elastic elliptic membrane shells in the case where the shell\nis subject to a geometrical constraint modelled via a normal compliance contact\ncondition defined in the interior of the shell. To achieve this, we establish a\nnovel density result for non-empty, closed, and convex subsets of Lebesgue\nspaces, which are applicable to cases not covered by the ``density property''\nestablished in [Ciarlet, Mardare \\& Piersanti, \\emph{Math. Mech. Solids},\n2019].\n  Second, we demonstrate that the solution to the two-dimensional obstacle\nproblem for linearly elastic elliptic membrane shells, subjected to the\ninterior normal compliance contact condition, exhibits higher regularity\nthroughout its entire definition domain. A key feature of this result is that,\nwhile the transverse component of the solution is, in general, only of class\n$L^2$ and its trace is \\emph{a priori} undefined, the methodology proposed\nhere, partially based on [Ciarlet \\& Sanchez-Palencia, \\emph{J. Math. Pures\nAppl.}, 1996], enables us to rigorously establish the well-posedness of the\ntrace for the transverse component of the solution by means of an \\emph{ad hoc}\nformula.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T13:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.21645v1","title":"The effect of neon seeding on plasma edge transport in EAST","summary":"The effect of neon seeding on different transport mechanisms in EAST is\ninvestigated by analyzing SOLPSITER simulations. By evaluating the agreement\nbetween experimental observations and the performed simulations, four\nsimulations are selected for a detailed analysis. In this analysis, it is shown\nthat the presence of neon reduces the influence of drifts on the simulated\nprofiles. In the simulation results, double peaked profiles/profiles with two\nvalleys are observed at the divertor targets which can be explained by the\nparallel drift velocities These drifts move particles from the outboard towards\nthe inboard side and, in that way, also increase the ionization sources at the\ninboard side. It is shown that Ne+ leaks towards the core making it difficult\nto perform experiments which contain as much neon as in the SOLPS-ITER\nsimulations. In fact, the level of neon in the experiments is limited by the HL\nbacktransition which takes place if higher order states of neon ionize in the\ncore and cause in that way too much core radiation. Furthermore, the analysis\nof the radiated power profiles suggests that the presence of other radiators\nbesides neon is important to bring the experiments into detachment. The\nionization of deuterium is the most important neutral reaction present in the\nsimulations. The amount of ionized deuterium is decreased when large amounts of\nneon are present and the anomalous transport is modified. Therefore, it is\nconcluded that for the analyzed simulations, neon increases the radiated power\nfraction, decreases the deuterium ionization, increases the neutral friction,\nbut does not manage to cause significant influence of deuterium recombination.\nAs a consequence, volumetric recombination only plays a minor role in the\nstudied simulations.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-30T13:48:17Z"}
{"aid":"http://arxiv.org/abs/2504.21661v1","title":"Probabilistic Time Series Forecasting of Residential Loads -- A Copula\n  Approach","summary":"Predicting the time series of future evolutions of renewable injections and\ndemands is of utmost importance for the operation of power systems. However,\nthe current state of the art is mostly focused on mean-value time series\npredictions and only very few methods provide probabilistic forecasts. In this\npaper, we rely on kernel density estimation and vine copulas to construct\nprobabilistic models for individual load profiles of private households. Our\napproach allows the quantification of variability of individual energy\nconsumption in general and of daily peak loads in particular. We draw upon an\nAustralian distribution grid dataset to illustrate our findings. We generate\nsynthetic loads that follow the distribution of the real data.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-30T14:02:42Z"}
{"aid":"http://arxiv.org/abs/2504.21677v1","title":"20min-XD: A Comparable Corpus of Swiss News Articles","summary":"We present 20min-XD (20 Minuten cross-lingual document-level), a\nFrench-German, document-level comparable corpus of news articles, sourced from\nthe Swiss online news outlet 20 Minuten/20 minutes. Our dataset comprises\naround 15,000 article pairs spanning 2015 to 2024, automatically aligned based\non semantic similarity. We detail the data collection process and alignment\nmethodology. Furthermore, we provide a qualitative and quantitative analysis of\nthe corpus. The resulting dataset exhibits a broad spectrum of cross-lingual\nsimilarity, ranging from near-translations to loosely related articles, making\nit valuable for various NLP applications and broad linguistically motivated\nstudies. We publicly release the dataset in document- and sentence-aligned\nversions and code for the described experiments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T14:16:08Z"}
{"aid":"http://arxiv.org/abs/2504.21688v1","title":"Assessing Racial Disparities in Healthcare Expenditures Using Causal\n  Path-Specific Effects","summary":"Racial disparities in healthcare expenditures are well-documented, yet the\nunderlying drivers remain complex and require further investigation. This study\nemploys causal and counterfactual path-specific effects to quantify how various\nfactors, including socioeconomic status, insurance access, health behaviors,\nand health status, mediate these disparities. Using data from the Medical\nExpenditures Panel Survey, we estimate how expenditures would differ under\ncounterfactual scenarios in which the values of specific mediators were aligned\nacross racial groups along selected causal pathways. A key challenge in this\nanalysis is ensuring robustness against model misspecification while addressing\nthe zero-inflation and right-skewness of healthcare expenditures. For reliable\ninference, we derive asymptotically linear estimators by integrating influence\nfunction-based techniques with flexible machine learning methods, including\nsuper learners and a two-part model tailored to the zero-inflated, right-skewed\nnature of healthcare expenditures.","main_category":"stat.AP","categories":"stat.AP,stat.ME,stat.ML","published":"2025-04-30T14:23:50Z"}
{"aid":"http://arxiv.org/abs/2504.21693v1","title":"Distributed Online Randomized Gradient-Free optimization with Compressed\n  Communication","summary":"This paper addresses two fundamental challenges in distributed online convex\noptimization: communication efficiency and optimization under limited feedback.\nWe propose Online Compressed Gradient Tracking with one-point Bandit Feedback\n(OCGT-BF), a novel algorithm that harness data compression and gradient-free\noptimization techniques in distributed networks. Our algorithm incorporates a\ncompression scheme with error compensation mechanisms to reduce communication\noverhead while maintaining convergence guarantees. Unlike traditional\napproaches that assume perfect communication and full gradient access, OCGT-BF\noperates effectively under practical constraints by combining gradient-like\ntracking with one-point feedback estimation. We provide theoretical analysis\ndemonstrating the dynamic regret bounds under both bandit feedback and\nstochastic gradient scenarios. Finally, extensive experiments validate that\nOCGT-BF achieves low dynamic regret while significantly reducing communication\nrequirements.","main_category":"math.OC","categories":"math.OC","published":"2025-04-30T14:33:47Z"}
{"aid":"http://arxiv.org/abs/2504.21711v1","title":"The Intermediate-Mass Black Hole Reverberation Mapping Project: First\n  Detection of Mid-Infrared Lags in Prototypical IMBHs in NGC 4395 and POX 52","summary":"The search for robust evidence of intermediate-mass black holes (IMBHs) is\ncrucial for understanding black hole seeding process and the formation of\nsupermassive black holes in the early Universe. NGC 4395 and POX 52 are two\nprototypical IMBH hosts, both exhibiting multi-line evidence of low-mass black\nhole activity. Here, we report the first detection of mid-infrared (MIR) lags\nin response to optical variability, with measurements of $3.0^{+2.4}_{-1.9}$\ndays for NGC 4395 and $35.2^{+14.2}_{-11.7}$ days for POX~52 at $3.4$ $\\mu$m,\nrespectively, using archival optical data and observations from the Wide-field\nInfrared Survey Explorer (WISE). This detection provides the first\nreverberation evidence of low-mass black hole activity in POX 52. The time lags\nof these two low-mass, low-luminosity active galactic nuclei (AGNs) generally\nfollow the extent of the $R_{\\rm dust}-L_{\\rm 5100}$ relation found in\nhigher-mass AGNs. Based on an empirical relation between the broad-line region\nand dusty torus size, we constrain the black hole mass of POX 52 to log($M_{\\rm\nBH}$/$M_\\odot$) = 5.5 $\\pm$ 0.37 (systemic and statistical errors), confirming\nits IMBH nature. Furthermore, long-term optical continuum monitoring of POX 52\nreveals a mild inter-band lag of $\\lesssim$ 1 day. However, no significant\nintranight variability was detected during its one-night, high-cadence\nmonitoring, which we attribute to the longer duty cycle of fast variability in\nPOX 52 compared to that in NGC 4395.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-30T14:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.21717v1","title":"Characterization and optimization of heat engines: Pareto-optimal fronts\n  and universal features","summary":"Characterizing and optimizing nanoscopic heat engines require an appropriate\nunderstanding of the interplay between power, efficiency, entropy production\nand fluctuations. Despite significant recent advancements, including linear\nstochastic thermodynamics and thermodynamic uncertainty relations (TURs), a\ncomplete scenario remains elusive. In this work, we give a further step by\nshowing that, under certain common and general conditions, the heat engine\nregime can be characterized by the minima of power fluctuations and entropy\nproduction, which together delimit its optimal performance, achieved when these\nconditions are fully satisfied. Conversely, when these conditions are not\nstrictly met, the occurrence of the minimum still approximately describes the\nsystem, suggesting a broader range of applicability. Contrasting with most of\nstudies in which the system optimization is carried out solely taking into\naccount the power and efficiency, we introduce a multi-objective optimization\nframework based on Pareto fronts, also considering the role of fluctuation and\ndissipation. Our results reveal a general trend: while simultaneous\noptimization over a few parameters typically yields convex Pareto fronts, these\nfronts become concave as more parameters are varied freely and non-conservative\ndriving becomes significant. Illustrating our findings, we consider simple two\nand three state systems as well as richer collective systems, exhibiting novel\naspects of optimizations and protocol phase transitions.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-30T15:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.21722v1","title":"Discrete Generating Series and Linear Difference Equations","summary":"We define discrete generating series for arbitrary functions \\( f \\colon\n\\mathbb{Z}^n \\rightarrow \\mathbb{C} \\) and derive functional relations that\nthese series satisfy. For linear difference equations with constant\ncoefficients, we establish explicit functional equations linking the generating\nseries to the initial data, and for equations with polynomial coefficients, we\nintroduce an analogue of Stanley's \\( D \\)-finiteness criterion, proving that a\ndiscrete generating series is \\( D \\)-finite if and only if the corresponding\nsequence is polynomially recursive. The framework is further generalized to\nmultidimensional settings, where we investigate the interplay between discrete\ngenerating series and solutions to Cauchy problems for difference equations.\nKey structural properties are uncovered through the introduction of polynomial\nshift operators and projection techniques. The theory is illustrated with\nconcrete examples, including the Tribonacci recurrence and Schr\\\"oder's second\nproblem.","main_category":"math.CA","categories":"math.CA,math.DS","published":"2025-04-30T15:08:16Z"}
{"aid":"http://arxiv.org/abs/2504.21726v1","title":"Notes sur l'application d'Albanese pour les z√©ro-cycles","summary":"For a smooth projective variety X over an arbitrary field k, we discuss the\nsurjectivity of the Albanese map from the Chow group of zero-cycles of degree\nzero on X to the group of rational points of the Albanese variety of X. Over\narithmetic fields, we use Severi-Brauer fibrations to produce examples where\nthe map is not surjective. For varieties X over the complex field, we discuss\nthe question after extension of the complex field to function fields of\nvarieties. This is related to C. Voisin's notion of universal zero-cycle and to\nrationality questions for rationally connected threefolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-30T15:11:41Z"}
{"aid":"http://arxiv.org/abs/2504.21737v1","title":"Observation of Intrinsic and LED Light-Enhanced Memristor Performance in\n  In-Plane Ferroelectric NbOI2","summary":"Two-dimensional (2D) layered ferroelectrics, as an emerging area of research,\nhave attracted extensive attention, while memristors based on new 2D\nferroelectric materials have yet to be fully explored, thereby limiting their\napplications in modern nanoelectronics. In this work, we report the observation\nof intrinsic memristive behavior in a newly discovered 2D in-plane\nferroelectric material, NbOI2, and the giant enhancement of the memristive\nperformance using LED visible light. The results show that NbOI2 exhibits\nintrinsically strong memristive response with a current on/off ratio of up to\n10^4 and stable switching cycles, which is independent of back-gate voltage.\nUnder LED visible light illumination, the current on/off ratio in NbOI2 is over\none order of magnitude higher than that without light, meanwhile, the coercive\nfield is significantly reduced to less than 1.22 kVcm-1, much lower than other\n2D ferroelectric material-based memristors. Interestingly, both the intrinsic\nand the light-enhanced resistive switching phenomena only occur along the\nin-plane b-axis direction, indicating that the memristive behavior in NbOI2 is\ndriven by electric field-induced and optical field-enhanced ferroelectric\npolarization switching mechanisms, as evidenced by a combined\norientation-dependent electrical/optoelectrical measurement and sweep\ncycle-induced structural evolution analysis. Our study not only provides a\nmaterials strategy based on new 2D ferroelectrics for designing memristor\napplications, but also offers a simple optical method to enhance its\nperformance, paving the path for its implementation in novel nanoelectronics\nand optoelectronics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-30T15:33:37Z"}
{"aid":"http://arxiv.org/abs/2504.21769v1","title":"LLM-based Interactive Imitation Learning for Robotic Manipulation","summary":"Recent advancements in machine learning provide methods to train autonomous\nagents capable of handling the increasing complexity of sequential\ndecision-making in robotics. Imitation Learning (IL) is a prominent approach,\nwhere agents learn to control robots based on human demonstrations. However, IL\ncommonly suffers from violating the independent and identically distributed\n(i.i.d) assumption in robotic tasks. Interactive Imitation Learning (IIL)\nachieves improved performance by allowing agents to learn from interactive\nfeedback from human teachers. Despite these improvements, both approaches come\nwith significant costs due to the necessity of human involvement. Leveraging\nthe emergent capabilities of Large Language Models (LLMs) in reasoning and\ngenerating human-like responses, we introduce LLM-iTeach -- a novel IIL\nframework that utilizes an LLM as an interactive teacher to enhance agent\nperformance while alleviating the dependence on human resources. Firstly,\nLLM-iTeach uses a hierarchical prompting strategy that guides the LLM in\ngenerating a policy in Python code. Then, with a designed similarity-based\nfeedback mechanism, LLM-iTeach provides corrective and evaluative feedback\ninteractively during the agent's training. We evaluate LLM-iTeach against\nbaseline methods such as Behavior Cloning (BC), an IL method, and CEILing, a\nstate-of-the-art IIL method using a human teacher, on various robotic\nmanipulation tasks. Our results demonstrate that LLM-iTeach surpasses BC in the\nsuccess rate and achieves or even outscores that of CEILing, highlighting the\npotential of LLMs as cost-effective, human-like teachers in interactive\nlearning environments. We further demonstrate the method's potential for\ngeneralization by evaluating it on additional tasks. The code and prompts are\nprovided at: https://github.com/Tubicor/LLM-iTeach.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T16:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.21772v1","title":"Solving Copyright Infringement on Short Video Platforms: Novel Datasets\n  and an Audio Restoration Deep Learning Pipeline","summary":"Short video platforms like YouTube Shorts and TikTok face significant\ncopyright compliance challenges, as infringers frequently embed arbitrary\nbackground music (BGM) to obscure original soundtracks (OST) and evade content\noriginality detection. To tackle this issue, we propose a novel pipeline that\nintegrates Music Source Separation (MSS) and cross-modal video-music retrieval\n(CMVMR). Our approach effectively separates arbitrary BGM from the original\nOST, enabling the restoration of authentic video audio tracks. To support this\nwork, we introduce two domain-specific datasets: OASD-20K for audio separation\nand OSVAR-160 for pipeline evaluation. OASD-20K contains 20,000 audio clips\nfeaturing mixed BGM and OST pairs, while OSVAR160 is a unique benchmark dataset\ncomprising 1,121 video and mixed-audio pairs, specifically designed for short\nvideo restoration tasks. Experimental results demonstrate that our pipeline not\nonly removes arbitrary BGM with high accuracy but also restores OSTs, ensuring\ncontent integrity. This approach provides an ethical and scalable solution to\ncopyright challenges in user-generated content on short video platforms.","main_category":"cs.MM","categories":"cs.MM,cs.AI","published":"2025-04-30T16:17:05Z"}
{"aid":"http://arxiv.org/abs/2504.21785v1","title":"Frozen Gaussian Grid-point Correction For Semi-classical Schr√∂dinger\n  Equation","summary":"We propose an efficient reconstruction algorithm named the frozen Gaussian\ngrid-point correction (FGGC) for computing the Schr\\\"odinger equation in the\nsemi-classical regime using the frozen Gaussian approximation (FGA). The FGA\nhas demonstrated its superior efficiency in dealing with semi-classical\nproblems and high-frequency wave propagations. However, reconstructing the wave\nfunction from a large number of Gaussian wave-packets is typically\ncomputationally intensive. This difficulty arises because these wave-packets\npropagate along the FGA trajectories to non-grid positions, making the\napplication of the fast Fourier transform infeasible. In this work, we\nintroduce the concept of ``on-grid correction'' and derive the formulas for the\nleast squares approximation of Gaussian wave-packets, and also provide a\ndetailed process of the FGGC algorithm. Furthermore, we rigorously prove that\nthe error introduced by the least squares approximation on each Gaussian\nwave-packet is independent of the semi-classical parameter $\\varepsilon$.\nNumerical experiments show that the FGGC algorithm can significantly improve\nreconstruction efficiency while introducing only negligible error, making it a\npowerful tool for solving the semi-classical Schr\\\"odinger equation, especially\nin applications requiring both accuracy and efficiency.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T16:43:28Z"}
{"aid":"http://arxiv.org/abs/2504.21816v1","title":"Enumeration of minimum weight codewords of affine Cartesian codes","summary":"Affine Cartesian codes were first discussed by Geil and Thomsen in 2013 in a\nbroader framework and were formally introduced by L\\'opez, Renter\\'ia-M\\'arquez\nand Villarreal in 2014. These are linear error-correcting codes obtained by\nevaluating polynomials at points of a Cartesian product of subsets of the given\nfinite field. They can be viewed as a vast generalization of Reed-Muller codes.\nIn 1970, Delsarte, Goethals and MacWilliams gave a %characterization of minimum\nweight codewords of Reed-Muller codes and also formula for the minimum weight\ncodewords of Reed-Muller codes. Carvalho and Neumann in 2020 considered affine\nCartesian codes in a special setting where the subsets in the Cartesian product\nare nested subfields of the given finite field, and gave a characterization of\ntheir minimum weight codewords. We use this to give an explicit formula for the\nnumber of minimum weight codewords of affine Cartesian codes in the case of\nnested subfields. This is seen to unify the known formulas for the number of\nminimum weight codewords of Reed-Solomon codes and Reed-Muller codes.","main_category":"cs.IT","categories":"cs.IT,math.CO,math.IT","published":"2025-04-30T17:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.21817v1","title":"Anomalous Josephson effect in hybrid superconductor-hole systems","summary":"We consider hybrid systems consisting of a hole-doped semiconductor coupled\nto electronic states of finite-size superconductors, where the opposite sign of\nthe masses in the two subsystems give rise to insulating gaps at subband\nanticrossings. Consequently, increasing the coupling strength to the\nsuperconductor can paradoxically suppress the proximity-induced\nsuperconductivity in the semiconductor by enhancing these insulating gaps. We\ndemonstrate that the presence of such induced insulating gaps leads to a\ncharacteristic anomalous behavior of the critical supercurrent in Josephson\njunctions based on these hybrid structures. Our findings provide important\ninsights for the design of robust quantum computing platforms utilizing hybrid\nsuperconductor-hole systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-30T17:23:53Z"}
{"aid":"http://arxiv.org/abs/2504.21827v1","title":"Beam Optics Ramping in Under-Constrained Lattice Design: Application to\n  Electron-Ion Collider Hadron Storage Ring Cooling Section","summary":"This paper presents the lattice design and optics ramping strategy for the\ncooling section of the Hadron Storage Ring (HSR) at the Electron-Ion Collider\n(EIC). The main challenge is that available tuning knobs exceed beam-optics\nconstraints. Independently optimized injection and top-energy optics often\nyield disconnected solutions, making interpolation impossible. To address this,\nwe propose two new methods. The first is a midpoint-penalty scheme that ensures\nramping path continuity by penalizing constraint violations at intermediate\nstate. The second is a top-down approach that adapts high-energy optics to low\nenergy, guided by an adaptive weighting scheme to balance injection and ramping\nconstraints. The solutions meet all beam dynamics and hardware limits. The two\nmethods offer a general strategy for ramping in systems where the solution\nspace is under-constrained and the starting and target configurations are far\napart.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-30T17:32:47Z"}
{"aid":"http://arxiv.org/abs/2504.21832v1","title":"Optimal Dynamic Control of Bounded Jacobian Discrete-Time Systems via\n  Interval Observers","summary":"This paper presents an optimal dynamic control framework for bounded Jacobian\nnonlinear discrete-time (DT) systems with nonlinear observations affected by\nboth state and process noise. Rather than directly stabilizing the uncertain\nsystem, we focus on stabilizing an interval observer in a higher dimensional\nspace, whose states bound the true system states. Our nonlinear dynamic control\nmethod introduces added flexibility over traditional static and linear\napproaches, effectively compensating for system nonlinearities and enabling\npotentially tighter closed-loop intervals. Additionally, we establish a\nseparation principle that allows for the design of observer and control gains.\nWe further derive tractable matrix inequalities to ensure system stability in\nthe closed-loop configuration. The simulation results show that the proposed\ndynamic control approach significantly outperforms a static counterpart method.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-30T17:39:09Z"}
{"aid":"http://arxiv.org/abs/2504.21841v1","title":"Neuro-Symbolic Generation of Explanations for Robot Policies with\n  Weighted Signal Temporal Logic","summary":"Neural network-based policies have demonstrated success in many robotic\napplications, but often lack human-explanability, which poses challenges in\nsafety-critical deployments. To address this, we propose a neuro-symbolic\nexplanation framework that generates a weighted signal temporal logic (wSTL)\nspecification to describe a robot policy in a interpretable form. Existing\nmethods typically produce explanations that are verbose and inconsistent, which\nhinders explainability, and loose, which do not give meaningful insights into\nthe underlying policy. We address these issues by introducing a simplification\nprocess consisting of predicate filtering, regularization, and iterative\npruning. We also introduce three novel explainability evaluation metrics --\nconciseness, consistency, and strictness -- to assess explanation quality\nbeyond conventional classification metrics. Our method is validated in three\nsimulated robotic environments, where it outperforms baselines in generating\nconcise, consistent, and strict wSTL explanations without sacrificing\nclassification accuracy. This work bridges policy learning with formal methods,\ncontributing to safer and more transparent decision-making in robotics.","main_category":"cs.RO","categories":"cs.RO,cs.FL","published":"2025-04-30T17:51:20Z"}
{"aid":"http://arxiv.org/abs/2504.21842v1","title":"Cryptography without Long-Term Quantum Memory and Global Entanglement","summary":"We show how oracles which only allow for classical query access can be used\nto construct a variety of quantum cryptographic primitives which do not require\nlong-term quantum memory or global entanglement. Specifically, if a quantum\nparty can execute a semi-quantum token scheme (Shmueli 2022) with probability\nof success $1/2 + \\delta$, we can build powerful cryptographic primitives with\na multiplicative logarithmic overhead for the desired correctness error. Our\nscheme makes no assumptions about the quantum party's noise model except for a\nsimple independence requirement: noise on two sets of non-entangled hardware\nmust be independent.\n  Using semi-quantum tokens and oracles which can only be queried classically,\nwe first show how to construct a \"short-lived\" semi-quantum one-time program\n(OTP) which allows a classical sending party to prepare a one-time program on\nthe receiving party's quantum computer. We then show how to use this\nsemi-quantum OTP to construct a semi-quantum \"stateful obfuscation\" scheme\n(which we term \"RAM obfuscation\"). Importantly, the RAM obfuscation scheme does\nnot require long-term quantum memory or global entanglement. Finally, we show\nhow RAM obfuscation can be used to build long-lived one-time programs and\ncopy-protection schemes.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-30T17:51:25Z"}
{"aid":"http://arxiv.org/abs/2504.21850v1","title":"COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning","summary":"Multimodal Large Language Models (MLLMs) excel at simple vision-language\ntasks but struggle when faced with complex tasks that require multiple\ncapabilities, such as simultaneously recognizing objects, counting them, and\nunderstanding their spatial relationships. This might be partially the result\nof the fact that Visual Instruction Tuning (VIT), a critical training step for\nMLLMs, has traditionally focused on scaling data volume, but not the\ncompositional complexity of training examples. We propose COMPACT\n(COMPositional Atomic-to-complex visual Capability Tuning), which generates a\ntraining dataset explicitly controlling for the compositional complexity of the\ntraining examples. The data from COMPACT allows MLLMs to train on combinations\nof atomic capabilities to learn complex capabilities more efficiently. Across\nall benchmarks, COMPACT achieves comparable performance to the LLaVA-665k VIT\nwhile using less than 10% of its data budget, and even outperforms it on\nseveral, especially those involving complex multi-capability tasks. For\nexample, COMPACT achieves substantial 83.3% improvement on MMStar and 94.0%\nimprovement on MM-Vet compared to the full-scale VIT on particularly complex\nquestions that require four or more atomic capabilities. COMPACT offers a\nscalable, data-efficient, visual compositional tuning recipe to improve on\ncomplex visual-language tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T17:57:22Z"}
{"aid":"http://arxiv.org/abs/2505.00289v1","title":"PatchFuzz: Patch Fuzzing for JavaScript Engines","summary":"Patch fuzzing is a technique aimed at identifying vulnerabilities that arise\nfrom newly patched code. While researchers have made efforts to apply patch\nfuzzing to testing JavaScript engines with considerable success, these efforts\nhave been limited to using ordinary test cases or publicly available\nvulnerability PoCs (Proof of Concepts) as seeds, and the sustainability of\nthese approaches is hindered by the challenges associated with automating the\nPoC collection. To address these limitations, we propose an end-to-end\nsustainable approach for JavaScript engine patch fuzzing, named PatchFuzz. It\nautomates the collection of PoCs of a broader range of historical\nvulnerabilities and leverages both the PoCs and their corresponding patches to\nuncover new vulnerabilities more effectively. PatchFuzz starts by recognizing\ngit commits which intend to fix security bugs. Subsequently, it extracts and\nprocesses PoCs from these commits to form the seeds for fuzzing, while\nutilizing code revisions to focus limited fuzzing resources on the more\nvulnerable code areas through selective instrumentation. The mutation strategy\nof PatchFuzz is also optimized to maximize the potential of the PoCs.\nExperimental results demonstrate the effectiveness of PatchFuzz. Notably, 54\nbugs across six popular JavaScript engines have been exposed and a total of\n$62,500 bounties has been received.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-05-01T04:26:21Z"}
{"aid":"http://arxiv.org/abs/2505.00316v1","title":"Surrogate modeling of Cellular-Potts Agent-Based Models as a\n  segmentation task using the U-Net neural network architecture","summary":"The Cellular-Potts model is a powerful and ubiquitous framework for\ndeveloping computational models for simulating complex multicellular biological\nsystems. Cellular-Potts models (CPMs) are often computationally expensive due\nto the explicit modeling of interactions among large numbers of individual\nmodel agents and diffusive fields described by partial differential equations\n(PDEs). In this work, we develop a convolutional neural network (CNN) surrogate\nmodel using a U-Net architecture that accounts for periodic boundary\nconditions. We use this model to accelerate the evaluation of a mechanistic CPM\npreviously used to investigate \\textit{in vitro} vasculogenesis. The surrogate\nmodel was trained to predict 100 computational steps ahead (Monte-Carlo steps,\nMCS), accelerating simulation evaluations by a factor of 590 times compared to\nCPM code execution. Over multiple recursive evaluations, our model effectively\ncaptures the emergent behaviors demonstrated by the original Cellular-Potts\nmodel of such as vessel sprouting, extension and anastomosis, and contraction\nof vascular lacunae. This approach demonstrates the potential for deep learning\nto serve as efficient surrogate models for CPM simulations, enabling faster\nevaluation of computationally expensive CPM of biological processes at greater\nspatial and temporal scales.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.QM","published":"2025-05-01T05:30:38Z"}
{"aid":"http://arxiv.org/abs/2505.00317v1","title":"Beyond Quadratic Costs in LQR: Bregman Divergence Control","summary":"In the past couple of decades, the use of ``non-quadratic\" convex cost\nfunctions has revolutionized signal processing, machine learning, and\nstatistics, allowing one to customize solutions to have desired structures and\nproperties. However, the situation is not the same in control where the use of\nquadratic costs still dominates, ostensibly because determining the ``value\nfunction\", i.e., the optimal expected cost-to-go, which is critical to the\nconstruction of the optimal controller, becomes computationally intractable as\nsoon as one considers general convex costs. As a result, practitioners often\nresort to heuristics and approximations, such as model predictive control that\nonly looks a few steps into the future. In the quadratic case, the value\nfunction is easily determined by solving Riccati equations. In this work, we\nconsider a special class of convex cost functions constructed from Bregman\ndivergence and show how, with appropriate choices, they can be used to fully\nextend the framework developed for the quadratic case. The resulting optimal\ncontrollers are infinite horizon, come with stability guarantees, and have\nstate-feedback, or estimated state-feedback, laws. They exhibit a much wider\nrange of behavior than their quadratic counterparts since the feedback laws are\nnonlinear. The approach can be applied to several cases of interest, including\nsafety control, sparse control, and bang-bang control.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-05-01T05:31:45Z"}
{"aid":"http://arxiv.org/abs/2505.00336v1","title":"Experimental evidence for the physical delocalization of individual\n  photons in an interferometer","summary":"It is generally assumed that the detection of a single photon as part of an\ninterference pattern erases all possible which-path information. However,\nrecent insights suggest that weak interactions can provide non-trivial\nexperimental evidence for the physical delocalization of a single particle\npassing through an interferometer. Here, we present an experimental setup that\ncan quantify the delocalization of individual photons using the rate of\npolarization flips induced by small rotations of polarization. The results show\nthat photons detected in equal superpositions of the two paths are delocalized\nwhen detected in a high probability output port, and \"super-localized\" when\ndetected in a low probability output port. We can thus confirm that\ndelocalization depends on the detection of photons in the output of the\ninterferometer, providing direct experimental evidence for the dependence of\nphysical reality on the context established by a future measurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T06:20:46Z"}
{"aid":"http://arxiv.org/abs/2505.00349v1","title":"Burer-Monteiro factorizability of nuclear norm regularized optimization","summary":"This paper studies the relationship between the nuclear norm-regularized\nminimization problem, which minimizes the sum of a $C^2$ function $h$ and a\npositive multiple of the nuclear norm, and its factorized problem obtained by\nthe Burer-Monteiro technique. We first prove that every second-order stationary\npoint of the factorized problem corresponds to an approximate stationary point\nof its non-factorized counterpart, and those rank-deficient ones correspond to\nglobal minimizers of the latter problem when $h$ is additionally convex,\nconforming with the observations in [2, 15]. Next, discarding the rank\ncondition on the second-order stationary points but assuming the convexity and\nLipschitz differentiability of $h$, we characterize, with respect to some\nnatural problem parameters, when every second-order stationary point of the\nfactorized problem is a global minimizer of the corresponding nuclear\nnorm-regularized problem. More precisely, we subdivide the class of Lipschitz\ndifferentiable convex $C^2$ functions into subclasses according to those\nnatural parameters and characterize when each subclass consists solely of\nfunctions $h$ such that every second-order stationary point of the associated\nfactorized model is a global minimizer of the nuclear norm regularized model.\nIn particular, explicit counterexamples are established when the characterizing\ncondition on the said parameters is violated.","main_category":"math.OC","categories":"math.OC","published":"2025-05-01T06:50:07Z"}
{"aid":"http://arxiv.org/abs/2505.00365v1","title":"SacFL: Self-Adaptive Federated Continual Learning for\n  Resource-Constrained End Devices","summary":"The proliferation of end devices has led to a distributed computing paradigm,\nwherein on-device machine learning models continuously process diverse data\ngenerated by these devices. The dynamic nature of this data, characterized by\ncontinuous changes or data drift, poses significant challenges for on-device\nmodels. To address this issue, continual learning (CL) is proposed, enabling\nmachine learning models to incrementally update their knowledge and mitigate\ncatastrophic forgetting. However, the traditional centralized approach to CL is\nunsuitable for end devices due to privacy and data volume concerns. In this\ncontext, federated continual learning (FCL) emerges as a promising solution,\npreserving user data locally while enhancing models through collaborative\nupdates. Aiming at the challenges of limited storage resources for CL, poor\nautonomy in task shift detection, and difficulty in coping with new adversarial\ntasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFL\nemploys an Encoder-Decoder architecture to separate task-robust and\ntask-sensitive components, significantly reducing storage demands by retaining\nlightweight task-sensitive components for resource-constrained end devices.\nMoreover, $\\rm{SacFL}$ leverages contrastive learning to introduce an\nautonomous data shift detection mechanism, enabling it to discern whether a new\ntask has emerged and whether it is a benign task. This capability ultimately\nallows the device to autonomously trigger CL or attack defense strategy without\nadditional information, which is more practical for end devices. Comprehensive\nexperiments conducted on multiple text and image datasets, such as Cifar100 and\nTHUCNews, have validated the effectiveness of $\\rm{SacFL}$ in both\nclass-incremental and domain-incremental scenarios. Furthermore, a demo system\nhas been developed to verify its practicality.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-01T07:26:35Z"}
{"aid":"http://arxiv.org/abs/2505.00392v1","title":"Equatorial African Lightning: Past. Present and Future","summary":"Lightning strikes are one of the leading causes of death among natural\ndisasters in tropical regions. The Congo rainforests host the highest rates of\nlightning flashes in the world and the lightning properties in this region have\na strong seasonality owing to the cross-equatorial movements of the Inter\nTropical Convergence Zone (ITCZ) throughout the year. The Lightning Flash Rates\n(LFR) are found to peak during the Equinoctial months while lightning radiance\nassumes the strongest values during the Boreal Summer months. Across the\nTropical Rainfall Measuring Mission (TRMM) duration, (1998-2015), annual LFR in\nthe Congo rainforest increases steadily, however, the average and the peak\nlightning radiances decrease by ~1%/year and ~1.5%/year respectively which is\ncounter-intuitive to the expected intensification in weather extremes in a\nwarming climate. An in-depth analysis highlighted the influence of moisture\nconvergence over the Congo Basin from the Atlantic as the primary contributor\nto lightning compared to the aerosol nucleation and thermodynamic instability\neffects during the boreal summers. Further, it has been proposed that in a\ngradually warming climate, the strength of the prevailing ITCZ over Sahel\nregion has intensified thereby weakening the moisture ingress towards the Congo\nBasin, and this resulted in the observed reduction in lightning intensity in\nrecent years. Consequently, the long-term projections of lightning properties\nfrom global model simulations revealed a prominent weakening in lightning\n(~50%) over the Congo Basin by the year 2100 assuming the Representative\nConcentration Pathways (RCP) 8.5 emission scenarios. Key Words: Lightning, LIS,\nCongo Basin, Sahel, Moisture Flux, Future projections.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-05-01T08:29:53Z"}
{"aid":"http://arxiv.org/abs/2505.00413v1","title":"Counting subgroups of a finite group containing a prescribed subgroup","summary":"Let $R$ be a finite group, and let $T$ be a subgroup of $R$. We show that\nthere are at most \\[\n  7.3722[R:T]^{\\frac{\\log_2[R:T]}{4}+1.8919} \\] subgroups of $R$ containing\n$T$.","main_category":"math.GR","categories":"math.GR","published":"2025-05-01T09:21:51Z"}
{"aid":"http://arxiv.org/abs/2505.00417v1","title":"Gravity water waves over constant vorticity flows: From laminar flows to\n  touching waves","summary":"In a recent paper, Hur & Wheeler [J. Differential Equations, 338:572-590,\n2022] proved the existence of periodic steady water waves over an infinitely\ndeep, two-dimensional and constant vorticity flow under the influence of\ngravity. These solutions include overhanging wave profiles, some of which\nexhibit surfaces that touch at a point and thereby enclose a bubble of air. We\nextend these results by formulating a problem that encompasses both infinitely\ndeep and finitely deep flows, and by proving the existence of a continuous\ncurve of water waves that connects a laminar flow to a touching wave for fixed,\nnonzero gravity. This implies the existence of a wave profile featuring a\nvertical tangent at a point, which is not overhanging, and is referred to as a\nbreaking wave. We also study the behaviour of critical layers, which are points\nwhere the horizontal velocity vanishes, near the surface.","main_category":"math.AP","categories":"math.AP","published":"2025-05-01T09:32:00Z"}
{"aid":"http://arxiv.org/abs/2505.00463v1","title":"Complete quasi-Yamabe gradient solitons with bounded scalar curvature","summary":"In this paper, we classify complete, nontrivial shrinking and steady\nquasi-Yamabe gradient solitons whose scalar curvature is bounded below by the\nsoliton constant. We also classify complete, nontrivial expanding and steady\nquasi-Yamabe gradient solitons whose scalar curvature is bounded above by the\nsoliton constant.","main_category":"math.DG","categories":"math.DG","published":"2025-05-01T11:30:17Z"}
{"aid":"http://arxiv.org/abs/2505.00468v1","title":"Evaluation of Thermal Control Based on Spatial Thermal Comfort with\n  Reconstructed Environmental Data","summary":"Achieving thermal comfort while maintaining energy efficiency is a critical\nobjective in building system control. Conventional thermal comfort models, such\nas the Predicted Mean Vote (PMV), rely on both environmental and personal\nvariables. However, the use of fixed-location sensors limits the ability to\ncapture spatial variability, which reduces the accuracy of occupant-specific\ncomfort estimation. To address this limitation, this study proposes a new PMV\nestimation method that incorporates spatial environmental data reconstructed\nusing the Gappy Proper Orthogonal Decomposition (Gappy POD) algorithm. In\naddition, a group PMV-based control framework is developed to account for the\nthermal comfort of multiple occupants. The Gappy POD method enables fast and\naccurate reconstruction of indoor temperature fields from sparse sensor\nmeasurements. Using these reconstructed fields and occupant location data,\nspatially resolved PMV values are calculated. Group-level thermal conditions\nare then derived through statistical aggregation methods and used to control\nindoor temperature in a multi-occupant living lab environment. Experimental\nresults show that the Gappy POD algorithm achieves an average relative error\nbelow 3\\% in temperature reconstruction. PMV distributions varied by up to 1.26\nscale units depending on occupant location. Moreover, thermal satisfaction\noutcomes varied depending on the group PMV method employed. These findings\nunderscore the importance for adaptive thermal control strategies that\nincorporate both spatial and individual variability, offering valuable insights\nfor future occupant-centric building operations.","main_category":"cs.CE","categories":"cs.CE","published":"2025-05-01T11:43:28Z"}
{"aid":"http://arxiv.org/abs/2505.00499v1","title":"Relativistic Two-component Double Ionization Potential\n  Equation-of-Motion Coupled Cluster with the Dirac--Coulomb--Breit Hamiltonian","summary":"We present an implementation of relativistic double-ionization-potential\n(DIP) equation-of-motion coupled-cluster (EOMCC) with up to 4-hole--2-particle\n($4h2p$) excitations that makes use of the molecular mean-field exact\ntwo-component (mmfX2C) framework. We apply mmfX2C-DIP-EOMCC to several neutral\natoms and diatomic molecules to obtain the ground and first few excited states\nof the corresponding di-cation species, and we observe excellent agreement (to\nwithin 0.001 eV) between double ionization potentials (IPs) obtained from\nmmfX2C- and four-component DIP-EOMCC calculations that include\n3-hole--1-particle ($3h1p$) excitations, with either the Dirac--Coulomb or\nDirac--Coulomb--Gaunt Hamiltonians. We also compare double IPs for\nmmfX2C-DIP-EOMCC calculations with the full Dirac--Coulomb--Breit (DCB)\nHamiltonian to those from experiment. The mmfX2C-DIP-EOMCC with $3h1p$\nexcitations leads to errors in absolute double IPs that are larger than 0.1 eV,\nwhereas the addition of $4h2p$ excitations reduces these errors dramatically,\noften by an order of magnitude or more.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-05-01T12:59:09Z"}
{"aid":"http://arxiv.org/abs/2505.00553v1","title":"The Jackknife method as a new approach to validate strong lens mass\n  models","summary":"The accuracy of a mass model in the strong lensing analysis is crucial for\nunbiased predictions of physical quantities such as magnifications and time\ndelays. While the mass model is optimized by changing parameters of the mass\nmodel to match predicted positions of multiple images with observations,\npositional uncertainties of multiple images often need to be boosted to take\naccount of the complex structure of dark matter in lens objects, making the\ninterpretation of the chi-square value difficult. We introduce the Jackknife\nmethod as a new method to validate strong lens mass models, specifically\nfocusing on cluster-scale mass modeling. In this approach, we remove multiple\nimages of a source from the fitting and optimize the mass model using multiple\nimages of the remaining sources. We then calculate the multiple images of the\nremoved source and quantitatively evaluate how well they match the observed\npositions. We find that the Jackknife method performs effectively in\nsimulations using a simple model. We also demonstrate our method with mass\nmodeling of the galaxy cluster MACS J0647.7+7015. We discuss the potential of\nusing the Jackknife method to validate the error estimation of the physical\nquantities by the Markov Chain Monte Carlo.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-05-01T14:28:50Z"}
{"aid":"http://arxiv.org/abs/2505.00570v1","title":"FreqKV: Frequency Domain Key-Value Compression for Efficient Context\n  Window Extension","summary":"Extending the context window in large language models (LLMs) is essential for\napplications involving long-form content generation. However, the linear\nincrease in key-value (KV) cache memory requirements and the quadratic\ncomplexity of self-attention with respect to sequence length present\nsignificant challenges during fine-tuning and inference. Existing methods\nsuffer from performance degradation when extending to longer contexts. In this\nwork, we introduce a novel context extension method that optimizes both\nfine-tuning and inference efficiency. Our method exploits a key observation: in\nthe frequency domain, the energy distribution of the KV cache is primarily\nconcentrated in low-frequency components. By filtering out the high-frequency\ncomponents, the KV cache can be effectively compressed with minimal information\nloss. Building on this insight, we propose an efficient compression technique,\nFreqKV, that iteratively compresses the increasing KV cache to a fixed size in\nthe frequency domain, applicable to both fine-tuning and inference. FreqKV\nintroduces no additional parameters or architectural modifications. With\nminimal fine-tuning, LLMs can learn to leverage the limited cache that is\ncompressed in the frequency domain and extend the context window efficiently.\nExperiments on various long context language modeling and understanding tasks\ndemonstrate the efficiency and efficacy of the proposed method.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T14:53:12Z"}
{"aid":"http://arxiv.org/abs/2505.00574v1","title":"Transition States Energies from Machine Learning: An Application to\n  Reverse Water-Gas Shift on Single-Atom Alloys","summary":"Obtaining accurate transition state (TS) energies is a bottleneck in\ncomputational screening of complex materials and reaction networks due to the\nhigh cost of TS search methods and first-principles methods such as density\nfunctional theory (DFT). Here we propose a machine learning (ML) model for\npredicting TS energies based on Gaussian process regression with the\nWasserstein Weisfeiler-Lehman graph kernel (WWL-GPR). Applying the model to\npredict adsorption and TS energies for the reverse water-gas shift (RWGS)\nreaction on single-atom alloy (SAA) catalysts, we show that it can\nsignificantly improve the accuracy compared to traditional approaches based on\nscaling relations or ML models without a graph representation. Further\nbenefitting from the low cost of model training, we train an ensemble of\nWWL-GPR models to obtain uncertainties through subsampling of the training data\nand show how these uncertainties propagate to turnover frequency (TOF)\npredictions through the construction of an ensemble of microkinetic models.\nComparing the errors in model-based vs DFT-based TOF predictions, we show that\nthe WWL-GPR model reduces errors by almost an order of magnitude compared to\nscaling relations. This demonstrates the critical impact of accurate energy\npredictions on catalytic activity estimation. Finally, we apply our model to\nscreen new materials, identifying promising catalysts for RWGS. This work\nhighlights the power of combining advanced ML techniques with DFT and\nmicrokinetic modeling for screening catalysts for complex reactions like RWGS,\nproviding a robust framework for future catalyst design.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG","published":"2025-05-01T15:01:02Z"}
{"aid":"http://arxiv.org/abs/2505.00604v1","title":"Understanding and improving transferability in machine-learned\n  activation energy predictors","summary":"The calculation of reactive properties is a challenging task in chemical\nreaction discovery. Machine learning (ML) methods play an important role in\naccelerating electronic structure predictions of activation energies and\nreaction enthalpies, and are a crucial ingredient to enable large-scale\nautomated reaction network discovery with $>10^3$ reactions. Unfortunately, the\npredictive accuracy of existing ML models does not yet reach the required\naccuracy across the space of possible chemical reactions to enable subsequent\nkinetic simulations that even qualitatively agree with experimental kinetics.\nHere, we comprehensively assess the underlying reasons for prediction failures\nwithin a selection of machine-learned models of reactivity. Models based on\ndifference fingerprints between reactant and product structures lack\ntransferability despite providing good in-distribution predictions. This\nresults in a significant loss of information about the context and mechanism of\nchemical reactions. We propose a convolutional ML model that uses atom-centered\nquantum-chemical descriptors and approximate transition state information.\nInclusion of the latter improves transferability for out-of-distribution\nbenchmark reactions, making greater use of the limited chemical reaction space\nspanned by the training data. The model further delivers atom-level\ncontributions to activation energies and reaction enthalpies that provide a\nuseful interpretational tool for rationalizing reactivity.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-05-01T15:35:12Z"}
{"aid":"http://arxiv.org/abs/2505.00647v1","title":"GeoDEx: A Unified Geometric Framework for Tactile Dexterous and\n  Extrinsic Manipulation under Force Uncertainty","summary":"Sense of touch that allows robots to detect contact and measure interaction\nforces enables them to perform challenging tasks such as grasping fragile\nobjects or using tools. Tactile sensors in theory can equip the robots with\nsuch capabilities. However, accuracy of the measured forces is not on a par\nwith those of the force sensors due to the potential calibration challenges and\nnoise. This has limited the values these sensors can offer in manipulation\napplications that require force control. In this paper, we introduce GeoDEx, a\nunified estimation, planning, and control framework using geometric primitives\nsuch as plane, cone and ellipsoid, which enables dexterous as well as extrinsic\nmanipulation in the presence of uncertain force readings. Through various\nexperimental results, we show that while relying on direct inaccurate and noisy\nforce readings from tactile sensors results in unstable or failed manipulation,\nour method enables successful grasping and extrinsic manipulation of different\nobjects. Additionally, compared to directly running optimization using SOCP\n(Second Order Cone Programming), planning and force estimation using our\nframework achieves a 14x speed-up.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T16:40:47Z"}
{"aid":"http://arxiv.org/abs/2505.00651v1","title":"Open-Source LLM-Driven Federated Transformer for Predictive IoV\n  Management","summary":"The proliferation of connected vehicles within the Internet of Vehicles (IoV)\necosystem presents critical challenges in ensuring scalable, real-time, and\nprivacy-preserving traffic management. Existing centralized IoV solutions often\nsuffer from high latency, limited scalability, and reliance on proprietary\nArtificial Intelligence (AI) models, creating significant barriers to\nwidespread deployment, particularly in dynamic and privacy-sensitive\nenvironments. Meanwhile, integrating Large Language Models (LLMs) in vehicular\nsystems remains underexplored, especially concerning prompt optimization and\neffective utilization in federated contexts. To address these challenges, we\npropose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel\nframework that leverages open-source LLMs for predictive IoV management. FPoTT\nintroduces a dynamic prompt optimization mechanism that iteratively refines\ntextual prompts to enhance trajectory prediction. The architecture employs a\ndual-layer federated learning paradigm, combining lightweight edge models for\nreal-time inference with cloud-based LLMs to retain global intelligence. A\nTransformer-driven synthetic data generator is incorporated to augment training\nwith diverse, high-fidelity traffic scenarios in the Next Generation Simulation\n(NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing\nEleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data\nwhile maintaining high performance on synthetic datasets. These results\nunderscore the potential of open-source LLMs in enabling secure, adaptive, and\nscalable IoV management, offering a promising alternative to proprietary\nsolutions in smart mobility ecosystems.","main_category":"cs.AI","categories":"cs.AI,cs.ET,cs.LG","published":"2025-05-01T16:54:21Z"}
{"aid":"http://arxiv.org/abs/2505.00666v1","title":"Spreading Depolarization Detection in Electrocorticogram Spectrogram\n  Imaging by Deep Learning: Is It Just About Delta Band?","summary":"Prevention of secondary brain injury is a core aim of neurocritical care,\nwith Spreading Depolarizations (SDs) recognized as a significant independent\ncause. SDs are typically monitored through invasive, high-frequency\nelectrocorticography (ECoG); however, detection remains challenging due to\nsignal artifacts that obscure critical SD-related electrophysiological changes,\nsuch as power attenuation and DC drifting. Recent studies suggest spectrogram\nanalysis could improve SD detection; however, brain injury patients often show\npower reduction across all bands except delta, causing class imbalance.\nPrevious methods focusing solely on delta mitigates imbalance but overlooks\nfeatures in other frequencies, limiting detection performance. This study\nexplores using multi-frequency spectrogram analysis, revealing that essential\nSD-related features span multiple frequency bands beyond the most active delta\nband. This study demonstrated that further integration of both alpha and delta\nbands could result in enhanced SD detection accuracy by a deep learning model.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-01T17:17:15Z"}
{"aid":"http://arxiv.org/abs/2505.00677v1","title":"Linear Parameter Varying Attitude Control For CubeSats Using\n  Electrospray Thrusters","summary":"This paper proposes the design of a single linear parameter-varying (LPV)\ncontroller for the attitude control of CubeSats using electro spray thrusters.\nCubeSat attitude control based on electro spray thrusters faces two main\nchallenges. Firstly, the thruster can only generate a small control torque\nleading to easily saturating the actuation system. Secondly, CubeSats need to\noperate multiple different maneuvers from large to small slews to pointing\ntasks. LPV control is ideally suitable to address these challenges. The\nproposed design follows a mixed-sensitivity control scheme. The\nparameter-varying weights depend on the attitude error and are derived from the\nperformance and robustness requirements of individual typical CubeSat\nmaneuvers. The controller is synthesized by minimizing the induced L2-norm of\nthe closed-loop interconnections between the controller and weighted plant. The\nperformance and robustness of the controller is demonstrated on a simulation of\nthe MIT Space Propulsion Lab's Magnetic Levitation CubeSat Testbed.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-01T17:33:36Z"}
{"aid":"http://arxiv.org/abs/2505.00687v1","title":"GuideSR: Rethinking Guidance for One-Step High-Fidelity Diffusion-Based\n  Super-Resolution","summary":"In this paper, we propose GuideSR, a novel single-step diffusion-based image\nsuper-resolution (SR) model specifically designed to enhance image fidelity.\nExisting diffusion-based SR approaches typically adapt pre-trained generative\nmodels to image restoration tasks by adding extra conditioning on a\nVAE-downsampled representation of the degraded input, which often compromises\nstructural fidelity. GuideSR addresses this limitation by introducing a\ndual-branch architecture comprising: (1) a Guidance Branch that preserves\nhigh-fidelity structures from the original-resolution degraded input, and (2) a\nDiffusion Branch, which a pre-trained latent diffusion model to enhance\nperceptual quality. Unlike conventional conditioning mechanisms, our Guidance\nBranch features a tailored structure for image restoration tasks, combining\nFull Resolution Blocks (FRBs) with channel attention and an Image Guidance\nNetwork (IGN) with guided attention. By embedding detailed structural\ninformation directly into the restoration pipeline, GuideSR produces sharper\nand more visually consistent results. Extensive experiments on benchmark\ndatasets demonstrate that GuideSR achieves state-of-the-art performance while\nmaintaining the low computational cost of single-step approaches, with up to\n1.39dB PSNR gain on challenging real-world datasets. Our approach consistently\noutperforms existing methods across various reference-based metrics including\nPSNR, SSIM, LPIPS, DISTS and FID, further representing a practical advancement\nfor real-world image restoration.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-01T17:48:25Z"}
{"aid":"http://arxiv.org/abs/2505.00694v1","title":"What is the Hierarchy Problem?","summary":"Is there a Hierarchy Problem? If so, what, exactly, is the problem? Almost\nevery theorist has a personal answer to these questions. In this article, I\ngive my answers. I will explain that the Hierarchy Problem is not a formal\nproblem but rather our ignorance of a crucial physics explanation -- the\nexplanation of the nature of the Higgs boson. Without the solution to this\nproblem, we cannot make progress on the major questions of our field.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-05-01T17:55:26Z"}
{"aid":"http://arxiv.org/abs/2505.00700v1","title":"Luminosity Function of collapsar Gamma-Ray Bursts:the Progenitor of Long\n  Gamma-Ray Bursts Is Not Singular","summary":"Gamma-ray bursts (GRBs) are powerful probes of the high-redshift universe.\nHowever, the proportion of collapsar GRBs among long GRBs and their event rate\nrelative to the star formation rate (SFR) remain contentious issues. We assume\nthat long GRBs with $z\\geq 2$ are all collapsar GRBs and construct the\nluminosity function using a high-redshift sample from the Swift satellite\nspanning 2004 to 2019. We model the luminosity function with a broken power-law\nform and consider three scenarios: no evolution, luminosity evolution, and\ndensity evolution. Our results are as follows: 1) The no-evolution model can be\nruled out. 2) The fitting results indicate that to adequately explain the\nobservations, a significant redshift evolution in either luminosity (evolution\nindex $\\delta = 1.54^{+0.21}_{-0.22}$) or density ($\\delta =\n2.09^{+0.29}_{-0.26}$) is required. This excludes the possibility that the\nevolution of long GRBs with redshift is due to contamination from non-collapsar\nGRBs. 3) The luminosity evolution model predicts that the number of collapsar\nGRBs with $z<2$ and $P \\geq 1 \\, \\text{ph} \\, \\text{cm}^{-2} \\, \\text{s}^{-1}$\nis 138.6, accounting for 82.5% of the observed long GRBs with $z<2$ and $P \\geq\n1 \\, \\text{ph} \\, \\text{cm}^{-2} \\, \\text{s}^{-1}$. The density evolution model\npredicts that the number of collapsar GRBs with $z<2$ and $P \\geq 1 \\,\n\\text{ph} \\, \\text{cm}^{-2} \\, \\text{s}^{-1}$ is 80.2, accounting for 47.7% of\nthe observation. Regardless of the model, a substantial portion of the long\nGRBs are not collapsar GRBs.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-01T17:58:21Z"}
