{"aid":"http://arxiv.org/abs/2503.21669v1","title":"Proton-Driven Plasma Wakefield Acceleration for Future HEP Colliders","summary":"We discuss the main elements of a collider facility based on proton-driven\nplasma wakefield acceleration. We show that very competitive luminosities could\nbe reached for high energy $e^+e^-$ colliders. A first set of parameters was\ndeveloped for a Higgs Factory indicating that such a scheme is indeed\npotentially feasible. There are clearly many challenges to the development of\nthis scheme, including novel RF acceleration modules and high precision and\nstrong magnets for the proton driver. Challenges in the plasma acceleration\nstage include the ability to accelerate positrons while maintaining necessary\nemittance and the energy transfer efficiency from the driver to the witness.\nSince many exciting applications would become available from our approach, its\ndevelopment should be pursued.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex,physics.plasm-ph","published":"2025-03-27T16:36:33Z"}
{"aid":"http://arxiv.org/abs/2503.21678v1","title":"Orderings on measures induced by higher-order monotone functions","summary":"The main aim of this paper is to study the functional inequality\n\\begin{equation*} \\int_{[0,1]}f\\bigl((1-t)x+ty\\bigr)d\\mu(t)\\geq 0, \\qquad\nx,y\\in I \\mbox{ with } x<y, \\end{equation*} for a continuous unknown function\n$f:I\\to{\\mathbb R}$, where $I$ is a nonempty open real interval and $\\mu$ is a\nsigned and bounded Borel measure on $[0,1]$. We derive necessary as well as\nsufficient conditions for its validity in terms of higher-order monotonicity\nproperties of $f$.\n  Using the results so obtained we can derive sufficient conditions under which\nthe inequality $${\\mathbb E} f(X)\\leq {\\mathbb E} f(Y)$$ is satisfied by all\nfunctions which are simultaneously: $k_1$-increasing (or decreasing),\n$k_2$-increasing (or decreasing), \\dots , $k_l$-increasing (or decreasing) for\ngiven nonnegative integers $k_1,\\dots,k_l.$ This extends several well-known\nresults on stochastic ordering.\n  A necessary condition for the $(n,n+1,\\dots,m)$-increasing ordering is also\npresented.","main_category":"math.CA","categories":"math.CA","published":"2025-03-27T16:48:37Z"}
{"aid":"http://arxiv.org/abs/2503.21720v1","title":"Collab: Controlled Decoding using Mixture of Agents for LLM Alignment","summary":"Alignment of Large Language models (LLMs) is crucial for safe and trustworthy\ndeployment in applications. Reinforcement learning from human feedback (RLHF)\nhas emerged as an effective technique to align LLMs to human preferences and\nbroader utilities, but it requires updating billions of model parameters, which\nis computationally expensive. Controlled Decoding, by contrast, provides a\nmechanism for aligning a model at inference time without retraining. However,\nsingle-agent decoding approaches often struggle to adapt to diverse tasks due\nto the complexity and variability inherent in these tasks. To strengthen the\ntest-time performance w.r.t the target task, we propose a mixture of\nagent-based decoding strategies leveraging the existing off-the-shelf aligned\nLLM policies. Treating each prior policy as an agent in the spirit of mixture\nof agent collaboration, we develop a decoding method that allows for\ninference-time alignment through a token-level selection strategy among\nmultiple agents. For each token, the most suitable LLM is dynamically chosen\nfrom a pool of models based on a long-term utility metric. This\npolicy-switching mechanism ensures optimal model selection at each step,\nenabling efficient collaboration and alignment among LLMs during decoding.\nTheoretical analysis of our proposed algorithm establishes optimal performance\nwith respect to the target task represented via a target reward for the given\noff-the-shelf models. We conduct comprehensive empirical evaluations with\nopen-source aligned models on diverse tasks and preferences, which demonstrates\nthe merits of this approach over single-agent decoding baselines. Notably,\nCollab surpasses the current SoTA decoding strategy, achieving an improvement\nof up to 1.56x in average reward and 71.89% in GPT-4 based win-tie rate.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-27T17:34:25Z"}
{"aid":"http://arxiv.org/abs/2503.21738v1","title":"Galaxy Morphologies at Cosmic Noon with JWST : A Foundation for\n  Exploring Gas Transport with Bars and Spiral Arms","summary":"How radial flows shape galaxy structure and evolution remains an open\nquestion. Internal drivers of such flows, such as bars and spiral arms, known\nto mediate gas flows in the local Universe, are now observable at high redshift\nthanks to JWST's unobscured view. We investigate the morphology of massive\nstar-forming galaxies at 0.8 < z < 1.3 and 2.0 < z < 2.5, epochs marking the\npeak and decline of cosmic star formation, both well-covered by kinematic\nsurveys. Using JWST/NIRCam imaging, we visually classify 1,451 galaxies,\nidentify non-axisymmetric features, count the number of spiral arms, analyze\nnon-parametric morphological indicators and study the dynamical support of the\nsample covered by kinematics (10% of the sample) as measured via v/{\\sigma}.\nDisk galaxies dominate the sample (82%), with 48% exhibiting spiral structure\nand 11% hosting bars. Both fractions decline with redshift, consistent with\nprevious studies. The proportion of two- and three-armed spirals remains\nlargely unchanged across redshift, with roughly two-thirds showing two arms and\none-third showing three arms in both bins. Notably, we find a higher incidence\nof three-armed spirals than reported in the local Universe, suggesting a mild\nevolution in spiral arm multiplicity. Non-parametric morphological metrics\nstrongly correlate with stellar mass but show no significant redshift\nevolution. Finally, kinematic analysis reveals a strong correlation between\ndisk morphology and rotational support, with most disks exhibiting v/{\\sigma} >\n3 and median values of v/{\\sigma} > 7 for spirals and v/{\\sigma} > 5 for barred\ngalaxies. This study establishes a population-wide framework for linking galaxy\nmorphology and dynamics at cosmic noon, providing a key reference for future\nstudies on the role of detailed structural features in galaxy evolution.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:50:32Z"}
{"aid":"http://arxiv.org/abs/2503.21743v1","title":"Three-Dimensional Stacking as a Line Intensity Mapping Statistic","summary":"Line-intensity mapping (LIM) is a growing technique that measures the\nintegrated spectral-line emission from unresolved galaxies over a\nthree-dimensional region of the Universe. Although LIM experiments ultimately\naim to provide powerful cosmological constraints via auto-correlation, many LIM\nexperiments are also designed to take advantage of overlapping galaxy surveys,\nenabling joint analyses of the two datasets. We introduce a flexible simulation\npipeline that can generate mock galaxy surveys and mock LIM data simultaneously\nfor the same population of simulated galaxies. Using this pipeline, we explore\na simple joint analysis technique: three-dimensional co-addition (stacking) of\nLIM data on the positions of galaxies from a traditional galaxy catalogue. We\ntest how the output of this technique reacts to changes in experimental design\nof both the LIM experiment and the galaxy survey, its sensitivity to various\nastrophysical parameters, and its susceptibility to common systematic errors.\nWe find that an ideal catalogue for a stacking analysis targets as many\nhigh-mass dark matter halos as possible. We also find that the signal in a LIM\nstacking analysis originates almost entirely from the large-scale clustering of\nhalos around the catalogue objects, rather than the catalogue objects\nthemselves. While stacking is a sensitive and conceptually simple way to\nachieve a LIM detection, thus providing a valuable way to validate a LIM\nauto-correlation detection, it will likely require a full cross-correlation to\nachieve further characterization of the galaxy tracers involved, as the\ncosmological and astrophysical parameters we explore here have degenerate\neffects on the stack.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-03-27T17:52:27Z"}
{"aid":"http://arxiv.org/abs/2503.21745v1","title":"3DGen-Bench: Comprehensive Benchmark Suite for 3D Generative Models","summary":"3D generation is experiencing rapid advancements, while the development of 3D\nevaluation has not kept pace. How to keep automatic evaluation equitably\naligned with human perception has become a well-recognized challenge. Recent\nadvances in the field of language and image generation have explored human\npreferences and showcased respectable fitting ability. However, the 3D domain\nstill lacks such a comprehensive preference dataset over generative models. To\nmitigate this absence, we develop 3DGen-Arena, an integrated platform in a\nbattle manner. Then, we carefully design diverse text and image prompts and\nleverage the arena platform to gather human preferences from both public users\nand expert annotators, resulting in a large-scale multi-dimension human\npreference dataset 3DGen-Bench. Using this dataset, we further train a\nCLIP-based scoring model, 3DGen-Score, and a MLLM-based automatic evaluator,\n3DGen-Eval. These two models innovatively unify the quality evaluation of\ntext-to-3D and image-to-3D generation, and jointly form our automated\nevaluation system with their respective strengths. Extensive experiments\ndemonstrate the efficacy of our scoring model in predicting human preferences,\nexhibiting a superior correlation with human ranks compared to existing\nmetrics. We believe that our 3DGen-Bench dataset and automated evaluation\nsystem will foster a more equitable evaluation in the field of 3D generation,\nfurther promoting the development of 3D generative models and their downstream\napplications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.23685v1","title":"An In-Situ Spatial-Temporal Sequence Detector for Neuromorphic Vision\n  Sensor Empowered by High Density Vertical NAND Storage","summary":"Neuromorphic vision sensors require efficient real-time pattern recognition,\nyet conventional architectures struggle with energy and latency constraints.\nHere, we present a novel in-situ spatiotemporal sequence detector that\nleverages vertical NAND storage to achieve massively parallel pattern\ndetection. By encoding each cell with two single-transistor-based multi-level\ncell (MLC) memory elements, such as ferroelectric field-effect transistors\n(FeFETs), and mapping a pixel's temporal sequence onto consecutive word lines\n(WLs), we enable direct temporal pattern detection within NAND strings. Each\nNAND string serves as a dedicated reference for a single pixel, while different\nblocks store patterns for distinct pixels, allowing large-scale\nspatial-temporal pattern recognition via simple direct bit-line (BL) sensing, a\nwell-established operation in vertical NAND storage. We experimentally validate\nour approach at both the cell and array levels, demonstrating that vertical\nNAND-based detector achieves more than six orders of magnitude improvement in\nenergy efficiency and more than three orders of magnitude reduction in latency\ncompared to conventional CPU-based methods. These findings establish vertical\nNAND storage as a scalable and energy-efficient solution for next-generation\nneuromorphic vision processing.","main_category":"cs.ET","categories":"cs.ET","published":"2025-03-31T03:34:29Z"}
{"aid":"http://arxiv.org/abs/2503.23687v1","title":"MKA: Leveraging Cross-Lingual Consensus for Model Abstention","summary":"Reliability of LLMs is questionable even as they get better at more tasks. A\nwider adoption of LLMs is contingent on whether they are usably factual. And if\nthey are not, on whether they can properly calibrate their confidence in their\nresponses. This work focuses on utilizing the multilingual knowledge of an LLM\nto inform its decision to abstain or answer when prompted. We develop a\nmultilingual pipeline to calibrate the model's confidence and let it abstain\nwhen uncertain. We run several multilingual models through the pipeline to\nprofile them across different languages. We find that the performance of the\npipeline varies by model and language, but that in general they benefit from\nit. This is evidenced by the accuracy improvement of $71.2\\%$ for Bengali over\na baseline performance without the pipeline. Even a high-resource language like\nEnglish sees a $15.5\\%$ improvement. These results hint at possible further\nimprovements.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-03-31T03:38:12Z"}
{"aid":"http://arxiv.org/abs/2503.23707v1","title":"From Geometry to Culture: An Iterative VLM Layout Framework for Placing\n  Objects in Complex 3D Scene Contexts","summary":"3D layout tasks have traditionally concentrated on geometric constraints, but\nmany practical applications demand richer contextual understanding that spans\nsocial interactions, cultural traditions, and usage conventions. Existing\nmethods often rely on rule-based heuristics or narrowly trained learning\nmodels, making them difficult to generalize and frequently prone to orientation\nerrors that break realism. To address these challenges, we define four\nescalating context levels, ranging from straightforward physical placement to\ncomplex cultural requirements such as religious customs and advanced social\nnorms. We then propose a Vision-Language Model-based pipeline that inserts\nminimal visual cues for orientation guidance and employs iterative feedback to\npinpoint, diagnose, and correct unnatural placements in an automated fashion.\nEach adjustment is revisited through the system's verification process until it\nachieves a coherent result, thereby eliminating the need for extensive user\noversight or manual parameter tuning. Our experiments across these four context\nlevels reveal marked improvements in rotation accuracy, distance control, and\noverall layout plausibility compared with native VLM. By reducing the\ndependence on pre-programmed constraints or prohibitively large training sets,\nour method enables fully automated scene composition for both everyday\nscenarios and specialized cultural tasks, moving toward a universally adaptable\nframework for 3D arrangement.","main_category":"cs.GR","categories":"cs.GR","published":"2025-03-31T04:09:00Z"}
{"aid":"http://arxiv.org/abs/2503.23742v1","title":"On the Steady-State Distributionally Robust Kalman Filter","summary":"State estimation in the presence of uncertain or data-driven noise\ndistributions remains a critical challenge in control and robotics. Although\nthe Kalman filter is the most popular choice, its performance degrades\nsignificantly when distributional mismatches occur, potentially leading to\ninstability or divergence. To address this limitation, we introduce a novel\nsteady-state distributionally robust (DR) Kalman filter that leverages\nWasserstein ambiguity sets to explicitly account for uncertainties in both\nprocess and measurement noise distributions. Our filter achieves computational\nefficiency by requiring merely the offline solution of a single convex\nsemidefinite program, which yields a constant DR Kalman gain for robust state\nestimation under distributional mismatches. Additionally, we derive explicit\ntheoretical conditions on the ambiguity set radius that ensure the asymptotic\nconvergence of the time-varying DR Kalman filter to the proposed steady-state\nsolution. Numerical simulations demonstrate that our approach outperforms\nexisting baseline filters in terms of robustness and accuracy across both\nGaussian and non-Gaussian uncertainty scenarios, highlighting its significant\npotential for real-world control and estimation applications.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-03-31T05:46:42Z"}
{"aid":"http://arxiv.org/abs/2503.23743v1","title":"DUNE Software and Computing Research and Development","summary":"The international collaboration designing and constructing the Deep\nUnderground Neutrino Experiment (DUNE) at the Long-Baseline Neutrino Facility\n(LBNF) has developed a two-phase strategy toward the implementation of this\nleading-edge, large-scale science project. The ambitious physics program of\nPhase I and Phase II of DUNE is dependent upon deployment and utilization of\nsignificant computing resources, and successful research and development of\nsoftware (both infrastructure and algorithmic) in order to achieve these\nscientific goals. This submission discusses the computing resources\nprojections, infrastructure support, and software development needed for DUNE\nduring the coming decades as an input to the European Strategy for Particle\nPhysics Update for 2026. The DUNE collaboration is submitting four main\ncontributions to the 2026 Update of the European Strategy for Particle Physics\nprocess. This submission to the 'Computing' stream focuses on DUNE software and\ncomputing. Additional inputs related to the DUNE science program, DUNE detector\ntechnologies and R&D, and European contributions to Fermilab accelerator\nupgrades and facilities for the DUNE experiment, are also being submitted to\nother streams.","main_category":"physics.data-an","categories":"physics.data-an,hep-ex,physics.ins-det","published":"2025-03-31T05:47:08Z"}
{"aid":"http://arxiv.org/abs/2503.23754v1","title":"On doubly commuting operators in $C_{1, r}$ class and quantum annulus","summary":"For $ 0 < r < 1 $, let $ \\mathbb{A}_r = \\{ z \\in \\mathbb{C} : r < |z| < 1 \\}\n$ be the annulus with boundary $ \\partial \\overline{\\mathbb{A}}_r = \\mathbb{T}\n\\cup r\\mathbb{T} $, where $ \\mathbb{T} $ is the unit circle in the complex\nplane $\\mathbb C$. We study the class of operators \\[ C_{1,r} = \\{ T : T \\text{\nis invertible and } \\|T\\|, \\|rT^{-1}\\| \\leq 1 \\}, \\] introduced by Bello and\nYakubovich. Any operator $T$ for which the closed annulus\n$\\overline{\\mathbb{A}}_r$ is a spectral set is in $C_{1,r}$. The class $C_{1,\nr}$ is closely related to the \\textit{quantum annulus} which is given by \\[\nQA_r = \\{ T : T \\text{ is invertible and } \\|rT\\|, \\|rT^{-1}\\| \\leq 1 \\}. \\]\nMcCullough and Pascoe proved that an operator in $ QA_r $ admits a dilation to\nan operator $ S $ satisfying $(r^{-2} + r^2)I - S^*S - S^{-1}S^{-*} = 0$. An\nanalogous dilation result holds for operators in $ C_{1,r}$ class. We extend\nthese dilation results to doubly commuting tuples of operators in quantum\nannulus as well as in $C_{1,r}$ class. We also provide characterizations and\ndecomposition results for such tuples.","main_category":"math.FA","categories":"math.FA","published":"2025-03-31T06:07:12Z"}
{"aid":"http://arxiv.org/abs/2503.23769v1","title":"Acceleration Theorem for Low-Dimensional Electron Systems with\n  Off-Diagonal Effective Mass Components","summary":"The motion of electrons under homogeneously applied electric fields in\nlow-dimensional systems with non-zero off-diagonal effective mass (ODEM) is\nstudied. The equation describing the time evolution of a probability\ncoefficient of finding an electron in a subband is derived using the\nKrieger-Iafrate theory in the effective mass approximation. It is shown that an\nelectron can change subbands during free flight due to the ODEM-induced\ninter-subband transitions. By introducing an effective dispersion defined as a\nweighted average of the subband dispersions, it is also shown that the initial\nacceleration of an electron effectively follows the bulk dispersion relation.\nThe results obtained suggest that the transport properties of the quantized\nsystems when many subbands are occupied in the weak confinement limit approach\nthe values one would find without considering the quantization.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mes-hall","published":"2025-03-31T06:40:52Z"}
{"aid":"http://arxiv.org/abs/2503.23788v1","title":"Detection of an extraterrestrial technical civilisation on the\n  extrasolar planet GJ 1132b","summary":"We report the detection of whisky in the atmosphere of the extrasolar\nsuper-Earth planet GJ 1132b from transmission spectroscopic data. It is seen\nboth in atmospheric absorption as well as in chromospheric emission, the latter\nprobably due to the intense heating of the co-rotating planet's day-side\nsurface. This detection cannot be explained using natural sources of alcohol,\nimplying that there must be a technically advanced civilisation -- possibly\noriginating from the neighboring habitable planet GJ 1132c -- that is engaged\nin massive distilling operations accompanied by high levels of industrial\npollution. The reason for the necessarily vast scale of production is either to\nproduce rocket fuel for an interplanetary economy or, more likely, for an\nunusually high level of personal consumption. The latter hypothesis suggests a\nnovel explanation for the Fermi Paradox (the lack of indirect or direct contact\nwith extraterrestrials): a technically versed civilisation would be incapable\nof achieving the higher technical levels necessary for the development of a\ndetectable radio signature -- much less interstellar travel -- at the suggested\nrates of consumption.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.soc-ph","published":"2025-03-31T07:03:23Z"}
{"aid":"http://arxiv.org/abs/2503.23793v1","title":"Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables","summary":"Recently, deep learning-based pan-sharpening algorithms have achieved notable\nadvancements over traditional methods. However, many deep learning-based\napproaches incur substantial computational overhead during inference,\nespecially with high-resolution images. This excessive computational demand\nlimits the applicability of these methods in real-world scenarios, particularly\nin the absence of dedicated computing devices such as GPUs and TPUs. To address\nthese challenges, we propose Pan-LUT, a novel learnable look-up table (LUT)\nframework for pan-sharpening that strikes a balance between performance and\ncomputational efficiency for high-resolution remote sensing images. To finely\ncontrol the spectral transformation, we devise the PAN-guided look-up table\n(PGLUT) for channel-wise spectral mapping. To effectively capture fine-grained\nspatial details and adaptively learn local contexts, we introduce the spatial\ndetails look-up table (SDLUT) and adaptive aggregation look-up table (AALUT).\nOur proposed method contains fewer than 300K parameters and processes a 8K\nresolution image in under 1 ms using a single NVIDIA GeForce RTX 2080 Ti GPU,\ndemonstrating significantly faster performance compared to other methods.\nExperiments reveal that Pan-LUT efficiently processes large remote sensing\nimages in a lightweight manner, bridging the gap to real-world applications.\nFurthermore, our model surpasses SOTA methods in full-resolution scenes under\nreal-world conditions, highlighting its effectiveness and efficiency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T07:13:59Z"}
{"aid":"http://arxiv.org/abs/2503.23809v1","title":"Nuclear clustering process in heavy-ion collisions : experimental\n  constraints on the low-temperature region of the QCD phase diagram","summary":"In this article, we study the production of Hydrogen and Helium isotopes in\nheavy-ion collisions in the incident energy range between 80 and 150\nMeV/nucleon. We compare their inclusive multiplicities emitted in the\ntransverse plane of the reaction with the predictions given by the thermal\nmodel. As a first step, we validate the choice of this approach to describe the\nexperimental measurements. We also show that the transient states have to be\nexplicitly taken into account for a good statistical description of the\nexperimental multiplicities. From the thermodynamical parameter values obtained\nwe complete the existing database built with the use of thermal-statistical\nmodels to reproduce particle production in the (ultra-)relativistic-energy\nmeasurements. We then proposed a new constraint on the so-called freeze-out\nregion in the temperature (T) versus baryonic chemical potential (muB) phase\ndiagram of the quantum chromodynamics. These new results indicate that there is\na common framework to describe the hadron production and nuclear clustering\nprocesses in heavy-ion collisions.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex","published":"2025-03-31T07:43:48Z"}
{"aid":"http://arxiv.org/abs/2503.23810v1","title":"Adaptive Attention-Based Model for 5G Radio-based Outdoor Localization","summary":"Radio-based localization in dynamic environments, such as urban and vehicular\nsettings, requires systems that can efficiently adapt to varying signal\nconditions and environmental changes. Factors such as multipath interference\nand obstructions introduce different levels of complexity that affect the\naccuracy of the localization. Although generalized models offer broad\napplicability, they often struggle to capture the nuances of specific\nenvironments, leading to suboptimal performance in real-world deployments. In\ncontrast, specialized models can be tailored to particular conditions, enabling\nmore precise localization by effectively handling domain-specific variations\nand noise patterns. However, deploying multiple specialized models requires an\nefficient mechanism to select the most appropriate one for a given scenario. In\nthis work, we develop an adaptive localization framework that combines shallow\nattention-based models with a router/switching mechanism based on a\nsingle-layer perceptron (SLP). This enables seamless transitions between\nspecialized localization models optimized for different conditions, balancing\naccuracy, computational efficiency, and robustness to environmental variations.\nWe design three low-complex localization models tailored for distinct\nscenarios, optimized for reduced computational complexity, test time, and model\nsize. The router dynamically selects the most suitable model based on real-time\ninput characteristics. The proposed framework is validated using real-world\nvehicle localization data collected from a massive MIMO base station (BS),\ndemonstrating its ability to seamlessly adapt to diverse deployment conditions\nwhile maintaining high localization accuracy.","main_category":"eess.SP","categories":"eess.SP,cs.LG","published":"2025-03-31T07:44:14Z"}
{"aid":"http://arxiv.org/abs/2503.23825v1","title":"Calibration requirements for Epoch of Reionization 21-cm signal\n  observations -- IV. Bias and variance with time and frequency correlated\n  residual gains","summary":"Observation of multifrequency angular power spectrum of the redshifted 21-cm\nbrightness temperature fluctuation from the neutral hydrogen holds the key to\nunderstand the structure formation and its evolution during the reionization\nand post-reionization era. A major challenge in observing the neutral hydrogen\narises from presence of strong foreground signals in the frequency range of\ninterest. Mitigating the direct effect of foregrounds are being addressed\nthrough various techniques in literature. An additional second order effect\narises, in presence of foreground, with limited accuracy in time and frequency\ndependent gain calibrations. This manifests as the residual gain and bandpass\nerror in the observed data, introduces bias and increases uncertainty in the\nestimates of multifrequency angular power spectrum. In this work, we present an\nanalytic method to estimate the bias and excess uncertainty in the estimates of\nmultifrequency angular power spectrum in presence of residual gain and bandpass\nerrors. We use this framework to estimate the effect of these errors for\ndetection of redshifted 21-cm emission from a redshift of $\\sim 8$ with the\nupcoming SKA1-Low. Due to the high baseline density at the required range of\nangular multipoles, the SKA1-Low is found to be a tuned instrument for the\nredshifted 21-cm signal detection. We find that, there are scenario with\nresidual gain and bandpass errors where there can be significant bias in these\nestimates. Certain foreground mitigation strategies, is expected to reduce a\npart of the bias. The detailed study of different aspects of gain and bandpass\nerrors and their relative effects are discussed. We find, with assumed models\nof gain and bandpass errors, signal detection is possible at this redshift with\n$128$ hours of observations. However, to achieve this one needs to have better\ncalibration accuracy than present day interferometers.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-03-31T08:19:59Z"}
{"aid":"http://arxiv.org/abs/2503.23826v1","title":"Determinization of Min-Plus Weighted Automata is Decidable","summary":"We show that the determinization problem for min-plus (tropical) weighted\nautomata is decidable, thus resolving this long-standing open problem. In doing\nso, we develop a new toolbox for analyzing and reasoning about the\nrun-structure of nondeterministic automata.","main_category":"cs.FL","categories":"cs.FL,cs.LO","published":"2025-03-31T08:21:09Z"}
{"aid":"http://arxiv.org/abs/2503.23842v1","title":"Toward the detection of spin-vortex-induced loop currents in a single\n  bilayer Bi$_2$Sr$_2$CaCu$_2$O$_{8+Î´}$ thin film and their possible use\n  as qubits: Model calculations for three nano-island architecture","summary":"A theory for cuprate superconductivity predicts the existence of nano-sized\nloop currents called, ``spin-vortex-induced loop currents (SVILCs)''. In this\nwok, we first calculate magnetic fields produced by them in a single bilayer\nBi$_2$Sr$_2$CaCu$_2$O$_{8+\\delta}$ (Bi-2212) thin film for the purpose of\ndetecting the SVILCs. The estimated magnitude of the magnetic field at the\npoint 10$a$ ($a$ is the lattice constant of the CuO$_2$ plane) above the\nsurface could be in the order of 100mT; thus, they may be detectable by\ncurrently available detection methods. Next, we investigate the use of them as\nqubits (the ``SVILC qubits'') in an architecture composed of three nano-islands\nof the thin film; and consider the use of the detection of the magnetic field\ngenerated by the SVILCs as the qubit readout. We show there are a number of\nenergy levels suitable for qubit states that can be manipulated by external\ncurrent feeding, and the magnetic field generated by the SVILCs is large enough\nto be used for the readout.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T08:44:36Z"}
{"aid":"http://arxiv.org/abs/2503.23844v1","title":"FlexiMo: A Flexible Remote Sensing Foundation Model","summary":"The rapid expansion of multi-source satellite imagery drives innovation in\nEarth observation, opening unprecedented opportunities for Remote Sensing\nFoundation Models to harness diverse data. However, many existing models remain\nconstrained by fixed spatial resolutions and patch sizes, limiting their\nability to fully exploit the heterogeneous spatial characteristics inherent in\nsatellite imagery. To address these challenges, we propose FlexiMo, a flexible\nremote sensing foundation model that endows the pre-trained model with the\nflexibility to adapt to arbitrary spatial resolutions. Central to FlexiMo is a\nspatial resolution-aware module that employs a parameter-free alignment\nembedding mechanism to dynamically recalibrate patch embeddings based on the\ninput image's resolution and dimensions. This design not only preserves\ncritical token characteristics and ensures multi-scale feature fidelity but\nalso enables efficient feature extraction without requiring modifications to\nthe underlying network architecture. In addition, FlexiMo incorporates a\nlightweight channel adaptation module that leverages prior spectral information\nfrom sensors. This mechanism allows the model to process images with varying\nnumbers of channels while maintaining the data's intrinsic physical properties.\nExtensive experiments on diverse multimodal, multi-resolution, and multi-scale\ndatasets demonstrate that FlexiMo significantly enhances model generalization\nand robustness. In particular, our method achieves outstanding performance\nacross a range of downstream tasks, including scene classification, land cover\nclassification, urban building segmentation, and cloud detection. By enabling\nparameter-efficient and physically consistent adaptation, FlexiMo paves the way\nfor more adaptable and effective foundation models in real-world remote sensing\napplications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T08:46:05Z"}
{"aid":"http://arxiv.org/abs/2503.23859v1","title":"Evaluating small vision-language models as AI assistants for radio\n  astronomical source analysis tasks","summary":"The advent of next-generation radio telescopes is set to transform radio\nastronomy by producing massive data volumes that challenge traditional\nprocessing methods. Deep learning techniques have shown strong potential in\nautomating radio analysis tasks, yet are often constrained by the limited\navailability of large annotated datasets. Recent progress in self-supervised\nlearning has led to foundational radio vision models, but adapting them for new\ntasks typically requires coding expertise, limiting their accessibility to a\nbroader astronomical community. Text-based AI interfaces offer a promising\nalternative by enabling task-specific queries and example-driven learning. In\nthis context, Large Language Models (LLMs), with their remarkable zero-shot\ncapabilities, are increasingly used in scientific domains. However, deploying\nlarge-scale models remains resource-intensive, and there is a growing demand\nfor AI systems that can reason over both visual and textual data in\nastronomical analysis. This study explores small-scale Vision-Language Models\n(VLMs) as AI assistants for radio astronomy, combining LLM capabilities with\nvision transformers. We fine-tuned the LLaVA VLM on a dataset of 59k radio\nimages from multiple surveys, enriched with 38k image-caption pairs from the\nliterature. The fine-tuned models show clear improvements over base models in\nradio-specific tasks, achieving ~30% F1-score gains in extended source\ndetection, but they underperform pure vision models and exhibit ~20% drop on\ngeneral multimodal tasks. Inclusion of caption data and LoRA fine-tuning\nenhances instruction-following and helps recover ~10% accuracy on standard\nbenchmarks. This work lays the foundation for future advancements in radio\nVLMs, highlighting their potential and limitations, such as the need for better\nmultimodal alignment, higher-quality datasets, and mitigation of catastrophic\nforgetting.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T09:06:23Z"}
{"aid":"http://arxiv.org/abs/2503.23865v1","title":"$L^p$-solvability of boundary value problems for the Laplacian in\n  locally flat unbounded domains","summary":"We establish the solvability of the $L^p$-Dirichlet and\n$L^{p^\\prime}$-Neumann problems for the Laplacian for $p\\in\n(\\frac{n}{n-1}-\\varepsilon,\\frac{2n}{n-1}]$ for some $\\varepsilon>0$ in\n$2$-sided chord-arc domains with unbounded boundary that is sufficiently flat\nat large scales and outward unit normal vector whose oscillation fails to be\nsmall only at finitely many dyadic boundary balls.","main_category":"math.AP","categories":"math.AP,math.CA,math.FA","published":"2025-03-31T09:15:23Z"}
{"aid":"http://arxiv.org/abs/2503.23918v1","title":"Hint of $r\\simeq 0.01$ after DESI DR2 ?","summary":"In the report by BICEP and Keck collaborations, the tensor-to-scalar ratio is\n$r_{0.05}<0.036$ (95\\% C.L.) and $ <1.3\\sigma$ non-zero (with pre-DESI BAO\ndata). However, recent datasets have significantly shifted the bestfit values\nof relevant $\\Lambda$CDM cosmological parameters, and thus possibly alter the\namplitude of lensing B-mode spectrum, which would affect the search for $r$.\nHere, the joint analysis of Planck and BICEP/Keck data with DESI DR2 reveals\nthat the lower bound of $r_{0.05}$ is $2.0\\sigma$ and $2.1\\sigma$ non-zero for\nPantheonPlus and DES-Y5, respectively, and the bestfit $r$ is $r_{0.05}\\simeq\n0.01$. The results are consistent with those with DESI DR1, but slightly\nstrengthened. There might be still systematic uncertainties in B-mode\nmeasurements due to the foreground contamination, however, our work is to not\nsay what about the value of $r$, but emphasize that the detection for $r$ is\nmodel-dependent and depends potentially on our insight into the dark universe,\nhighlighting the important role of cosmological surveys in comprehending our\nvery early universe.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-03-31T10:08:04Z"}
{"aid":"http://arxiv.org/abs/2503.23945v1","title":"DiffuSE: Cross-Layer Design Space Exploration of DNN Accelerator via\n  Diffusion-Driven Optimization","summary":"The proliferation of deep learning accelerators calls for efficient and\ncost-effective hardware design solutions, where parameterized modular hardware\ngenerator and electronic design automation (EDA) tools play crucial roles in\nimproving productivity and final Quality-of-Results (QoR). To strike a good\nbalance across multiple QoR of interest (e.g., performance, power, and area),\nthe designers need to navigate a vast design space, encompassing tunable\nparameters for both hardware generator and EDA synthesis tools. However, the\nsignificant time for EDA tool invocations and complex interplay among numerous\ndesign parameters make this task extremely challenging, even for experienced\ndesigners. To address these challenges, we introduce DiffuSE, a\ndiffusion-driven design space exploration framework for cross-layer\noptimization of DNN accelerators. DiffuSE leverages conditional diffusion\nmodels to capture the inverse, one-to-many mapping from QoR objectives to\nparameter combinations, allowing for targeted exploration within promising\nregions of the design space. By carefully selecting the conditioning QoR\nvalues, the framework facilitates an effective trade-off among multiple QoR\nmetrics in a sample-efficient manner. Experimental results under 7nm technology\ndemonstrate the superiority of the proposed framework compared to previous\narts.","main_category":"cs.AR","categories":"cs.AR","published":"2025-03-31T10:50:00Z"}
{"aid":"http://arxiv.org/abs/2503.23980v1","title":"SALT: A Flexible Semi-Automatic Labeling Tool for General LiDAR Point\n  Clouds with Cross-Scene Adaptability and 4D Consistency","summary":"We propose a flexible Semi-Automatic Labeling Tool (SALT) for general LiDAR\npoint clouds with cross-scene adaptability and 4D consistency. Unlike recent\napproaches that rely on camera distillation, SALT operates directly on raw\nLiDAR data, automatically generating pre-segmentation results. To achieve this,\nwe propose a novel zero-shot learning paradigm, termed data alignment, which\ntransforms LiDAR data into pseudo-images by aligning with the training\ndistribution of vision foundation models. Additionally, we design a\n4D-consistent prompting strategy and 4D non-maximum suppression module to\nenhance SAM2, ensuring high-quality, temporally consistent presegmentation.\nSALT surpasses the latest zero-shot methods by 18.4% PQ on SemanticKITTI and\nachieves nearly 40-50% of human annotator performance on our newly collected\nlow-resolution LiDAR data and on combined data from three LiDAR types,\nsignificantly boosting annotation efficiency. We anticipate that SALT's\nopen-sourcing will catalyze substantial expansion of current LiDAR datasets and\nlay the groundwork for the future development of LiDAR foundation models. Code\nis available at https://github.com/Cavendish518/SALT.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-03-31T11:46:55Z"}
{"aid":"http://arxiv.org/abs/2503.23983v1","title":"Quantum-computing within a bosonic context: Assessing finite basis\n  effects on prototypical vibrational Hamiltonian spectra","summary":"Quantum computing has recently been emerging in theoretical chemistry as a\nrealistic avenue meant to offer computational speedup to challenging\neigenproblems in the context of strongly-correlated molecular systems or\nextended materials. Most studies so far have been devoted to the quantum\ntreatment of electronic structure and only a few were directed to the quantum\ntreatment of vibrational structure, which at the moment remains not devoid of\nunknowns. In particular, we address here a formal problem that arises when\nsimulating a vibrational model under harmonic second quantization, whereby the\ndisruption of the closure relation (resolution of the identity) -- which occurs\nwhen truncating the infinite bosonic basis set -- may have some serious effects\nas regards the correct evaluation of Hamiltonian matrix elements. This relates\nintimately to the normal ordering of products of ladder operators. In addition,\nwe discuss the relevance of choosing an adequate primitive basis set within the\npresent context with respect to its variational convergence properties. Such\nfundamental, yet consequential, aspects are illustrated numerically in the\npresent work on a one-dimensional anharmonic Hamiltonian model corresponding to\na double-well potential showing strong tunneling, of interest both for\nvibrational spectroscopy and chemical reactivity.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T11:52:04Z"}
{"aid":"http://arxiv.org/abs/2503.23984v1","title":"Two-wheel-driven Electric Superbike Powertrain Optimization","summary":"In this paper, we propose an optimization framework for the powertrain design\nof a two-wheel-driven electric superbike, minimizing energy consumption.\nSpecifically, we jointly optimize the force distribution between the wheels\nwith the gear ratio, and rear motor and battery sizing while explicitly\nconsidering vehicle dynamics and performance constraints. First, we present an\nenergy consumption model of the vehicle, including a scalable model of the\nelectric machine based on data from the industry, accounting for iron, copper,\nand mechanical losses. Then, we analyze the propulsive blending strategy to\ndistribute the required power to the wheels while considering adherence limits.\nFinally, we demonstrate the effectiveness of our approach by analyzing the\ndesign of a superbike, based on regulatory driving cycles and a custom\nhigh-performance circuit by comparing the force distribution approaches. The\nresults underline the significance of joint optimization of powertrain\ncomponents and propulsive bias, achieving a reduction of up to 22.36% in energy\nconsumption for the Sport high-performance driving cycle.","main_category":"eess.SY","categories":"eess.SY,cs.SY,J.6","published":"2025-03-31T11:54:50Z"}
{"aid":"http://arxiv.org/abs/2503.24004v1","title":"Multivariate Species Sampling Models","summary":"Species sampling processes have long served as the framework for studying\nrandom discrete distributions. However, their statistical applicability is\nlimited when partial exchangeability is assumed as probabilistic invariance for\nthe observables. Despite numerous discrete models for partially exchangeable\nobservations, a unifying framework is currently missing, leaving many questions\nabout the induced learning mechanisms unanswered in this setting. To fill this\ngap, we consider the natural extension of species sampling models to a\nmultivariate framework, obtaining a general class of models characterized by\ntheir partially exchangeable partition probability function. A notable\nsubclass, named regular multivariate species sampling models, exists among\nthese models. In the subclass, dependence across processes is accurately\ncaptured by the correlation among them: a correlation of one equals full\nexchangeability and a null correlation corresponds to independence. Regular\nmultivariate species sampling models encompass discrete processes for partial\nexchangeable data used in Bayesian models, thereby highlighting their core\ndistributional properties and providing a means for developing new models.","main_category":"math.ST","categories":"math.ST,stat.ME,stat.TH","published":"2025-03-31T12:30:54Z"}
{"aid":"http://arxiv.org/abs/2503.24007v1","title":"CITRAS: Covariate-Informed Transformer for Time Series Forecasting","summary":"Covariates play an indispensable role in practical time series forecasting,\noffering rich context from the past and sometimes extending into the future.\nHowever, their availability varies depending on the scenario, and situations\noften involve multiple target variables simultaneously. Moreover, the\ncross-variate dependencies between them are multi-granular, with some\ncovariates having a short-term impact on target variables and others showing\nlong-term correlations. This heterogeneity and the intricate dependencies\narising in covariate-informed forecasting present significant challenges to\nexisting deep models. To address these issues, we propose CITRAS, a patch-based\nTransformer that flexibly leverages multiple targets and covariates covering\nboth the past and the future forecasting horizon. While preserving the strong\nautoregressive capabilities of the canonical Transformer, CITRAS introduces two\nnovel mechanisms in patch-wise cross-variate attention: Key-Value (KV) Shift\nand Attention Score Smoothing. KV Shift seamlessly incorporates future known\ncovariates into the forecasting of target variables based on their concurrent\ndependencies. Additionally, Attention Score Smoothing transforms locally\naccurate patch-wise cross-variate dependencies into global variate-level\ndependencies by smoothing the past series of attention scores. Experimentally,\nCITRAS achieves state-of-the-art performance in both covariate-informed and\nmultivariate forecasting, demonstrating its versatile ability to leverage\ncross-variate dependency for improved forecasting accuracy.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T12:32:23Z"}
{"aid":"http://arxiv.org/abs/2503.24035v1","title":"Using directed acyclic graphs to determine whether multiple imputation\n  or subsample multiple imputation estimates of an exposure-outcome association\n  are unbiased","summary":"Background: Missing data is a pervasive problem in epidemiology, with\ncomplete records analyses (CRA) or multiple imputation (MI) the most common\nmethods to deal with incomplete data. MI is valid when incomplete variables are\nindependent of response indicators, conditional on complete variables -\nhowever, this can be hard to assess with multiple incomplete variables.\nPrevious literature has shown that MI may be valid in subsamples of the data,\neven if not necessarily valid in the full dataset. Current guidance on how to\ndecide whether MI is appropriate is lacking.\n  Methods: We develop an algorithm that is sufficient to indicate when MI will\nestimate an exposure-outcome coefficient without bias and show how to implement\nthis using directed acyclic graphs (DAGs). We extend the algorithm to\ninvestigate whether MI applied to a subsample of the data, in which some\nvariables and complete and the remaining are imputed, will be unbiased for the\nsame estimand. We demonstrate the algorithm by applying it to several simple\nexamples and a more complex real-life example.\n  Conclusions: Multiple incomplete variables are common in practice. Assessing\nthe plausibility of each of CRA and MI estimating an exposure-outcome\nassociation without bias is crucial in analysing and interpreting results. Our\nalgorithm provides researchers with the tools to decide whether (and how) to\nuse MI in practice. Further work could focus on the likely size and direction\nof biases, and the impact of different missing data patterns.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T13:00:18Z"}
{"aid":"http://arxiv.org/abs/2503.24054v1","title":"Infinite matrix associated to sequences","summary":"In this paper, we study the Euler-Seidel matrices with coefficients and\ndetermine the associated Riordan matrix to a given matrix, if it does exist.\nComputation of the generating fonction of the final sequence is established by\nthe associated Riordan matrix. Applications are given.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T13:15:17Z"}
{"aid":"http://arxiv.org/abs/2503.24092v1","title":"New universal operator approximation theorem for encoder-decoder\n  architectures (Preprint)","summary":"Motivated by the rapidly growing field of mathematics for operator\napproximation with neural networks, we present a novel universal operator\napproximation theorem for a broad class of encoder-decoder architectures. In\nthis study, we focus on approximating continuous operators in\n$\\mathcal{C}(\\mathcal{X}, \\mathcal{Y})$, where $\\mathcal{X}$ and $\\mathcal{Y}$\nare infinite-dimensional normed or metric spaces, and we consider uniform\nconvergence on compact subsets of $\\mathcal{X}$. Unlike standard results in the\noperator learning literature, we investigate the case where the approximating\noperator sequence can be chosen independently of the compact sets. Taking a\ntopological perspective, we analyze different types of operator approximation\nand show that compact-set-independent approximation is a strictly stronger\nproperty in most relevant operator learning frameworks. To establish our\nresults, we introduce a new approximation property tailored to encoder-decoder\narchitectures, which enables us to prove a universal operator approximation\ntheorem ensuring uniform convergence on every compact subset. This result\nunifies and extends existing universal operator approximation theorems for\nvarious encoder-decoder architectures, including classical DeepONets,\nBasisONets, special cases of MIONets, architectures based on frames and other\nrelated approaches.","main_category":"math.FA","categories":"math.FA,cs.LG,math.GN","published":"2025-03-31T13:43:21Z"}
{"aid":"http://arxiv.org/abs/2503.24093v1","title":"Active Reconfigurable Intelligent Surfaces: Circuit Modeling and\n  Reflection Amplification Optimization","summary":"Reconfigurable Intelligent Surfaces (RISs) constitute a promising emerging\ntechnology that enables wireless systems to control the propagation environment\nto enhance diverse communication objectives. To mitigate double-fading\nattenuation in RIS-aided links, the paradigm of active metamaterials capable of\namplifying their incident wave has emerged. In this paper, capitalizing on the\ninherent negative-resistance region of tunnel diodes, we propose their\nintegration into each RIS unit element to enable RISs with reflection\namplification entirely in the analog domain. We derive novel realistic\nphase-amplitude relationships and power constraints specific to this model,\naddressing gaps in the existing literature where amplitude limits are often\nchosen arbitrarily. This characterization of our active RIS unit elements is\nincorporated into two novel optimization frameworks targeting the spectral\nefficiency maximization of RIS-assisted Multiple-Input-Multiple-Output (MIMO)\nsystems, which are solved via an one-step approach and an iterative Alternating\nOptimization (AO) method. The former approach is used to initialize the AO\nframework, enhancing both its performance and convergence. Our numerical\ninvestigations emphasize the importance of accurately modeling phase-amplitude\ndependencies, and provide key insights into the impact of RIS-induced noise as\nwell as the trade-off between available power and the number of active\nelements.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T13:44:03Z"}
{"aid":"http://arxiv.org/abs/2503.24122v1","title":"Position-Momenta Uncertainties in Classical Systems","summary":"We design a thermal bath that preserves the conservation of a system's\nangular momentum or allows it to fluctuate around a specified nonzero mean\nwhile maintaining a Boltzmann distribution of energy in the steady state.We\ndemonstrate that classical particles immersed in such baths exhibit\nposition-momentum uncertainties with a strictly positive lower bound\nproportional to the absolute value of the mean angular momentum. The\nproportionality constant, $c$, is dimensionless and independent of the system's\nparameters. Remarkably, while $c$ is universally bounded by unity, it attains\nthe exact value $c=1/2$ for particles in central potentials.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-03-31T14:08:41Z"}
{"aid":"http://arxiv.org/abs/2503.24135v1","title":"PixelCAM: Pixel Class Activation Mapping for Histology Image\n  Classification and ROI Localization","summary":"Weakly supervised object localization (WSOL) methods allow training models to\nclassify images and localize ROIs. WSOL only requires low-cost image-class\nannotations yet provides a visually interpretable classifier, which is\nimportant in histology image analysis. Standard WSOL methods rely on class\nactivation mapping (CAM) methods to produce spatial localization maps according\nto a single- or two-step strategy. While both strategies have made significant\nprogress, they still face several limitations with histology images.\nSingle-step methods can easily result in under- or over-activation due to the\nlimited visual ROI saliency in histology images and the limited localization\ncues. They also face the well-known issue of asynchronous convergence between\nclassification and localization tasks. The two-step approach is sub-optimal\nbecause it is tied to a frozen classifier, limiting the capacity for\nlocalization. Moreover, these methods also struggle when applied to\nout-of-distribution (OOD) datasets. In this paper, a multi-task approach for\nWSOL is introduced for simultaneous training of both tasks to address the\nasynchronous convergence problem. In particular, localization is performed in\nthe pixel-feature space of an image encoder that is shared with classification.\nThis allows learning discriminant features and accurate delineation of\nforeground/background regions to support ROI localization and image\nclassification. We propose PixelCAM, a cost-effective foreground/background\npixel-wise classifier in the pixel-feature space that allows for spatial object\nlocalization. PixelCAM is trained using pixel pseudo-labels collected from a\npretrained WSOL model. Both image and pixel-wise classifiers are trained\nsimultaneously using standard gradient descent. In addition, our pixel\nclassifier can easily be integrated into CNN- and transformer-based\narchitectures without any modifications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T14:18:01Z"}
{"aid":"http://arxiv.org/abs/2503.24160v1","title":"A Comparative Study of Scanpath Models in Graph-Based Visualization","summary":"Information Visualization (InfoVis) systems utilize visual representations to\nenhance data interpretation. Understanding how visual attention is allocated is\nessential for optimizing interface design. However, collecting Eye-tracking\n(ET) data presents challenges related to cost, privacy, and scalability.\nComputational models provide alternatives for predicting gaze patterns, thereby\nadvancing InfoVis research. In our study, we conducted an ET experiment with 40\nparticipants who analyzed graphs while responding to questions of varying\ncomplexity within the context of digital forensics. We compared human scanpaths\nwith synthetic ones generated by models such as DeepGaze, UMSS, and Gazeformer.\nOur research evaluates the accuracy of these models and examines how question\ncomplexity and number of nodes influence performance. This work contributes to\nthe development of predictive modeling in visual analytics, offering insights\nthat can enhance the design and effectiveness of InfoVis systems.","main_category":"cs.HC","categories":"cs.HC,cs.CV","published":"2025-03-31T14:43:42Z"}
{"aid":"http://arxiv.org/abs/2503.24174v1","title":"Low-energy electron microscopy as a tool for analysis of self-assembled\n  molecular layers on surfaces","summary":"Low-energy electron microscopy (LEEM) is a surface science method that works\nprimarily in the UHV environment. It provides information complementary to the\nother established techniques: it extends the limited view of scanning probe\nmicroscopies from nanometers to micrometers and measurement time down to tens\nof milliseconds, enabling to visualize the changes during sample treatment,\ne.g., annealing, deposition, and gas or light exposure. From the point of\nstructural analysis, it allows the measurement of diffraction patterns from an\narea of diameter below 200 nm and imaging of phase distribution on the surfaces\neither through dark-filed imaging or LEEM-I(V) fingerprinting. The advanced\nmodes provide local angle-resolved photoelectron spectra and surface potential\ndistribution. In this review, we aim to describe the utilization of LEEM to\nstudy self-assembled molecular structures on solid surfaces. We present the\nLEEM instrumentation and analysis of measured data in a tutorial way to provide\nthe necessary background knowledge to enter the field. In the second part, we\nsummarize the knowledge obtained by LEEM for several selected systems, which\npoints to the strength of LEEM in understanding the self-assembled molecular\nsystems and its synergy with other surface science techniques.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-31T14:51:52Z"}
{"aid":"http://arxiv.org/abs/2503.24176v1","title":"Tunable macroscopic defect patterns induced by a low-frequency AC\n  electric field in ferroelectric nematic liquid crystals","summary":"Regulation of topological structures and pattern formation is attracting wide\ninterest in the field of condensed matter. Liquid crystals (LCs) represent soft\nmatter with a remarkable combination of fluidity and anisotropic properties.\nTopological defects may appear in confined LCs under external stimuli. Recently\ndiscovered ferroelectric nematics (NF) opened exceptional opportunities in\ntechnologies owing to high permittivity and polarisation. Polar properties of\nNF supply more variability to topological structures. In this research, we\npresent tunable 2D topological defect arrays in NF compound, induced by an\nalternating (AC) electric field in simple sandwich cells without\npre-patterning. The observed arrays of defects form pseudo-square lattices,\nwhich character and periodicity depend on the frequency of the applied field\nand partially on the cell thickness. The observed effect is explained to occur\ndue to the competition between elastic and electrical forces. The proposed\nsystem can be useful to create reconfigurable spatially periodic polarisation\nstructures.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-03-31T14:53:41Z"}
{"aid":"http://arxiv.org/abs/2503.24225v1","title":"Compressible N-phase fluid mixture models","summary":"Fluid mixture models are essential for describing a wide range of physical\nphenomena, including wave dynamics and spinodal decomposition. However, there\nis a lack of consensus in the modeling of compressible mixtures, with limited\nconnections between different classes of models. On the one hand, existing\ncompressible two-phase flow models accurately describe wave dynamics, but do\nnot incorporate phase separation mechanisms. On the other hand, phase-field\ntechnology in fluid dynamics consists of models incorporating spinodal\ndecomposition, however, a general phase-field theory for compressible mixtures\nremains largely undeveloped.\n  In this paper, we take an initial step toward bridging the gap between\ncompressible two-phase flow models and phase-field models by developing a\ntheory for compressible, isothermal N-phase mixtures. Our theory establishes a\nsystem of reduced complexity by formulating N mass balance laws alongside a\nsingle momentum balance law, thereby naturally extending the Navier-Stokes\nKorteweg model to N-phases and providing the Navier-Stokes\nCahn-Hilliard/Allen-Cahn model for compressible mixtures. Key aspects of the\nframework include its grounding in continuum mixture theory and its\npreservation of thermodynamic consistency despite its reduced complexity.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,math-ph,math.AP,math.MP","published":"2025-03-31T15:38:49Z"}
{"aid":"http://arxiv.org/abs/2503.24231v1","title":"Distinct parallel electrostatic collisionless shocks in hot-cold\n  ablative mixing plasmas","summary":"Hot-cold ablative mixing plasmas are ubiquitous in astrophysical and\nlaboratory systems, where a cold/dense plasma is roughly in pressure balance\nwith a hot/dilute plasma. Examples include the plasma thermal quench during\nmajor disruptions in tokamaks, interaction between a central hot-spot and the\nsolid liner in an inertial confinement fusion (ICF) capsule, and the formation\nof large-scale structures in galaxy clusters. In such systems, a parallel\nelectrostatic collisionless shock forms and plays a critical role in both the\nthermal collapse of the hot plasma and the ablative mixing of cold ions. The\nformation and dynamics of such shocks are investigated by employing\none-dimensional VPIC simulations and theoretical analyses, revealing key\ndifferences from the well-studied collisionless shocks where an over-pressured,\nhigh-density plasma expands into a rarefied background. Notably, the shock\nformation has a weak dependence on the plasma pressure, provided that the\ndensity ratio between the cold and hot plasmas is large. Instead, the shock is\nprimarily governed by the plasma temperatures on both sides. The collisionless\nelectron thermal conduction flux in both upstream and downstream regions\nfollows the free-streaming limit itself, but its spatial gradient exhibits\nconvective scaling, ensuring the same characteristic length scale of the\nelectron temperature and density evolution.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-03-31T15:44:34Z"}
{"aid":"http://arxiv.org/abs/2503.24233v1","title":"Input from the SND@LHC collaboration to the 2026 Update to the European\n  Strategy for Particle Physics","summary":"By observing collider neutrino interactions of different flavours, the\nSND@LHC and Faser experiments have shown that the LHC can make interesting\ncontributions to neutrino physics. This document summarizes why the SND@LHC\nCollaboration intends to continue taking data at the High Luminosity LHC\n(HL-LHC). The upgraded detector will instrument the regions of both the\nneutrino vertex and the magnetized calorimeter with silicon microstrips. The\nuse of this technology will allow us to continue the physics program of the\ncurrent SND@LHC detector with higher statistics. It will also offer new\npossibilities. For instance, the magnetization of the hadron calorimeter will\nenable the separation between neutrinos and antineutrinos. This could lead to\nthe first direct observation of tau antineutrinos. The use of ultrafast timing\nlayers will enable triggers to be sent to ATLAS, potentially allowing the\nidentification of the charm quark pair that produced the neutrino interacting\nin the detector. Such tagging of the neutrino source would fulfill Pontecorvo\noriginal proposal of a tagged neutrino beam. The experiment will perform unique\nmeasurements with high energy neutrinos and will also provide a means to\nmeasure gluon parton distribution functions in a previously unexplored domain\n(Bjorkenx <10^-5). Furthermore, the technological advancements of the upgrade\nand the experience that will be gained in the areas of operation and data\nanalysis will play a crucial role in the design of the neutrino detector for\nthe SHiP experiment.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T15:45:38Z"}
{"aid":"http://arxiv.org/abs/2503.24260v1","title":"MaintainCoder: Maintainable Code Generation Under Dynamic Requirements","summary":"Modern code generation has made significant strides in functional correctness\nand execution efficiency. However, these systems often overlook a critical\ndimension in real-world software development: maintainability. To handle\ndynamic requirements with minimal rework, we propose MaintainCoder as a\npioneering solution. It integrates Waterfall model, design patterns, and\nmulti-agent collaboration to systematically enhance cohesion, reduce coupling,\nand improve adaptability. We also introduce MaintainBench, a benchmark\ncomprising requirement changes and corresponding dynamic metrics on\nmaintainance effort. Experiments demonstrate that existing code generation\nmethods struggle to meet maintainability standards when requirements evolve. In\ncontrast, MaintainCoder improves maintainability metrics by 14-30% with even\nhigher correctness, i.e. pass@k. Our work not only provides the foundation of\nmaintainable code generation, but also highlights the need for more holistic\ncode quality research. Resources:\nhttps://github.com/IAAR-Shanghai/MaintainCoder.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-03-31T16:06:47Z"}
{"aid":"http://arxiv.org/abs/2503.24262v1","title":"New Statistical Framework for Extreme Error Probability in High-Stakes\n  Domains for Reliable Machine Learning","summary":"Machine learning is vital in high-stakes domains, yet conventional validation\nmethods rely on averaging metrics like mean squared error (MSE) or mean\nabsolute error (MAE), which fail to quantify extreme errors. Worst-case\nprediction failures can have substantial consequences, but current frameworks\nlack statistical foundations for assessing their probability. In this work a\nnew statistical framework, based on Extreme Value Theory (EVT), is presented\nthat provides a rigorous approach to estimating worst-case failures. Applying\nEVT to synthetic and real-world datasets, this method is shown to enable robust\nestimation of catastrophic failure probabilities, overcoming the fundamental\nlimitations of standard cross-validation. This work establishes EVT as a\nfundamental tool for assessing model reliability, ensuring safer AI deployment\nin new technologies where uncertainty quantification is central to\ndecision-making or scientific analysis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ME,stat.ML","published":"2025-03-31T16:08:11Z"}
{"aid":"http://arxiv.org/abs/2503.24288v1","title":"Magnetic Confinement of a Bubble of Supercooled $^3$He-A","summary":"We have designed and constructed a magnet surrounding a cylindrical volume of\nsuperfluid helium-3 to isolate a region of metastable, supercooled A-phase,\nentirely surrounded by bulk A-phase - isolating the 'bubble' from rough\nsurfaces that can trigger the transition to the stable B-phase. We outline the\ndesign of the experimental cell and magnet, and show that the performance of\nthe magnet is consistent with simulations, including the capability to\nproducing the high field gradient required for generating a bubble. Future\nplans include the investigation of possible intrinsic mechanisms underpinning\nthe A-B transition, with potential implications for early-universe cosmological\nphase transitions.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-03-31T16:35:56Z"}
{"aid":"http://arxiv.org/abs/2503.24292v1","title":"Implicit Electric Field Conjugation with the Photonic Lantern Nuller","summary":"The Photonic Lantern Nuller (PLN) is an instrument concept designed to\ncharacterize exoplanets within a single beam-width from its host star. The PLN\nleverages the spatial symmetry of a mode-selective photonic lantern (MSPL) to\ncreate nulled ports, which cancel out on-axis starlight but allow off-axis\nexoplanet light to couple. The null-depths are limited by wavefront aberrations\nin the system as well as by imperfections in the lantern. We show that the\nimplicit electric field conjugation algorithm can be used to reduce the stellar\ncoupling through the PLN by orders of magnitude while maintaining the majority\nof the off-axis light, leading to deeper null depths (~10^{-4}) and thus higher\nsensitivity to potential planet signals. We discuss a theory for the tradeoff\nwe observed between the different ports, where iEFC improves the nulls of some\nports at the expense of others, and show that targeting one port alone can lead\nto deeper starlight rejection through that port than when targeting all ports\nat once. We also observe different levels of stability depending on the port\nand discuss the implications for practically implementing this technique for\nscience observations.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP","published":"2025-03-31T16:38:18Z"}
{"aid":"http://arxiv.org/abs/2503.24296v1","title":"Fair Dynamic Spectrum Access via Fully Decentralized Multi-Agent\n  Reinforcement Learning","summary":"We consider a decentralized wireless network with several source-destination\npairs sharing a limited number of orthogonal frequency bands. Sources learn to\nadapt their transmissions (specifically, their band selection strategy) over\ntime, in a decentralized manner, without sharing information with each other.\nSources can only observe the outcome of their own transmissions (i.e., success\nor collision), having no prior knowledge of the network size or of the\ntransmission strategy of other sources. The goal of each source is to maximize\ntheir own throughput while striving for network-wide fairness. We propose a\nnovel fully decentralized Reinforcement Learning (RL)-based solution that\nachieves fairness without coordination. The proposed Fair Share RL (FSRL)\nsolution combines: (i) state augmentation with a semi-adaptive time reference;\n(ii) an architecture that leverages risk control and time difference\nlikelihood; and (iii) a fairness-driven reward structure. We evaluate FSRL in\nmore than 50 network settings with different number of agents, different\namounts of available spectrum, in the presence of jammers, and in an ad-hoc\nsetting. Simulation results suggest that, when we compare FSRL with a common\nbaseline RL algorithm from the literature, FSRL can be up to 89.0% fairer (as\nmeasured by Jain's fairness index) in stringent settings with several sources\nand a single frequency band, and 48.1% fairer on average.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-03-31T16:42:11Z"}
{"aid":"http://arxiv.org/abs/2503.24315v1","title":"Multiscale Insights of Domain Unfolding in Fibrin Mechanical Response","summary":"Fibrinogen, the monomeric unit of fibrin, the main constituent of blood clot,\nhas a very complex structure. The fibrinogen builds the fibrin fiber and\nnetwork through the half-staggered packing via knob-hole interaction and the\n$\\alpha$C crosslinkers. Due to its rich structure, the elastic behavior also\nshows a unique nature of very high stretchability and multiple regimes in\nstress-strain behaviour, which is not yet fully understood. We develop an\nUnfolding-incorporated Coarse-Grained Polymer (UCGP) model for fibrinogen to\nstudy the effect of domain unfolding on the mechanical behavior of fibrin fiber\nand network. Our model captures the stretching behavior of fibrinogen as\nobserved in AFM and all-atom simulations. We further extend our model to fibrin\nfiber to study the effect of molecular unfolding at the fiber and network\nlevel. We anticipate that our model will be able to account for the nonlinear\nmechanical behavior of crosslinked fibrin gel. It is possibly the first model\nof this sort to consider the precise, controllable knowledge of the effects of\ndomain unfolding in crosslinked proteins. This model can also be used to model\nsystems that have sacrificial bonds.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-03-31T17:05:39Z"}
{"aid":"http://arxiv.org/abs/2503.24340v1","title":"Faster Rates for No-Regret Learning in General Games via Cautious\n  Optimism","summary":"We establish the first uncoupled learning algorithm that attains $O(n \\log^2\nd \\log T)$ per-player regret in multi-player general-sum games, where $n$ is\nthe number of players, $d$ is the number of actions available to each player,\nand $T$ is the number of repetitions of the game. Our results exponentially\nimprove the dependence on $d$ compared to the $O(n\\, d \\log T)$ regret\nattainable by Log-Regularized Lifted Optimistic FTRL [Far+22c], and also reduce\nthe dependence on the number of iterations $T$ from $\\log^4 T$ to $\\log T$\ncompared to Optimistic Hedge, the previously well-studied algorithm with $O(n\n\\log d \\log^4 T)$ regret [DFG21]. Our algorithm is obtained by combining the\nclassic Optimistic Multiplicative Weights Update (OMWU) with an adaptive,\nnon-monotonic learning rate that paces the learning process of the players,\nmaking them more cautious when their regret becomes too negative.","main_category":"cs.GT","categories":"cs.GT,cs.LG,math.OC","published":"2025-03-31T17:25:33Z"}
{"aid":"http://arxiv.org/abs/2503.24358v1","title":"SQuat: Subspace-orthogonal KV Cache Quantization","summary":"The key-value (KV) cache accelerates LLMs decoding by storing KV tensors from\npreviously generated tokens. It reduces redundant computation at the cost of\nincreased memory usage. To mitigate this overhead, existing approaches compress\nKV tensors into lower-bit representations; however, quantization errors can\naccumulate as more tokens are generated, potentially resulting in undesired\noutputs. In this paper, we introduce SQuat (Subspace-orthogonal KV cache\nquantization). It first constructs a subspace spanned by query tensors to\ncapture the most critical task-related information. During key tensor\nquantization, it enforces that the difference between the (de)quantized and\noriginal keys remains orthogonal to this subspace, minimizing the impact of\nquantization errors on the attention mechanism's outputs. SQuat requires no\nmodel fine-tuning, no additional calibration dataset for offline learning, and\nis grounded in a theoretical framework we develop. Through numerical\nexperiments, we show that our method reduces peak memory by 2.17 to 2.82,\nimproves throughput by 2.45 to 3.60, and achieves more favorable benchmark\nscores than existing KV cache quantization algorithms.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,cs.IT,math.IT","published":"2025-03-31T17:37:32Z"}
{"aid":"http://arxiv.org/abs/2503.24368v1","title":"Adapting Vision Foundation Models for Real-time Ultrasound Image\n  Segmentation","summary":"We propose a novel approach that adapts hierarchical vision foundation models\nfor real-time ultrasound image segmentation. Existing ultrasound segmentation\nmethods often struggle with adaptability to new tasks, relying on costly manual\nannotations, while real-time approaches generally fail to match\nstate-of-the-art performance. To overcome these limitations, we introduce an\nadaptive framework that leverages the vision foundation model Hiera to extract\nmulti-scale features, interleaved with DINOv2 representations to enhance visual\nexpressiveness. These enriched features are then decoded to produce precise and\nrobust segmentation. We conduct extensive evaluations on six public datasets\nand one in-house dataset, covering both cardiac and thyroid ultrasound\nsegmentation. Experiments show that our approach outperforms state-of-the-art\nmethods across multiple datasets and excels with limited supervision,\nsurpassing nnUNet by over 20\\% on average in the 1\\% and 10\\% data settings.\nOur method achieves $\\sim$77 FPS inference speed with TensorRT on a single GPU,\nenabling real-time clinical applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:47:42Z"}
{"aid":"http://arxiv.org/abs/2503.24378v1","title":"ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning","summary":"The ACPBench dataset provides atomic reasoning tasks required for efficient\nplanning. The dataset is aimed at distilling the complex plan generation task\ninto separate atomic reasoning tasks in their easiest possible form, boolean or\nmultiple-choice questions, where the model has to choose the right answer from\nthe provided options. While the aim of ACPBench is to test the simplest form of\nreasoning about action and change, when tasked with planning, a model does not\ntypically have options to choose from and thus the reasoning required for\nplanning dictates an open-ended, generative form for these tasks. To that end,\nwe introduce ACPBench Hard, a generative version of ACPBench, with open-ended\nquestions which the model needs to answer. Models that perform well on these\ntasks could in principle be integrated into a planner or be used directly as a\npolicy. We discuss the complexity of these tasks as well as the complexity of\nvalidating the correctness of their answers and present validation algorithms\nfor each task. Equipped with these validators, we test the performance of a\nvariety of models on our tasks and find that for most of these tasks the\nperformance of even the largest models is still subpar. Our experiments show\nthat no model outperforms another in these tasks and with a few exceptions all\ntested language models score below 65%, indicating that even the current\nfrontier language models have a long way to go before they can reliably reason\nabout planning. In fact, even the so-called reasoning models struggle with\nsolving these reasoning tasks. ACPBench Hard collection is available at the\nfollowing link: https://ibm.github.io/ACPBench","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T17:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.01323v1","title":"The optimal strong convergence rates of the truncated EM and logarithmic\n  truncated EM methods for multi-dimensional nonlinear stochastic differential\n  equations","summary":"The truncated Euler--Maruyama (EM) method, developed by Mao (2015), is used\nto solve multi-dimensional nonlinear stochastic differential equations (SDEs).\nHowever, its convergence rate is suboptimal due to an unnecessary infinitesimal\nfactor. The primary goal of this paper is to demonstrate the optimal\nconvergence of the truncated EM method without infinitesimal factors. Besides,\nthe logarithmic truncated EM method has not been studied in multi-dimensional\ncases, which is the other goal of this paper. We will show the optimal strong\nconvergence order of the positivity-preserving logarithmic truncated EM method\nfor solving multi-dimensional SDEs with positive solutions. Numerical examples\nare given to support our theoretical conclusions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T03:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.01350v1","title":"Intuitive Human-Drone Collaborative Navigation in Unknown Environments\n  through Mixed Reality","summary":"Considering the widespread integration of aerial robots in inspection, search\nand rescue, and monitoring tasks, there is a growing demand to design intuitive\nhuman-drone interfaces. These aim to streamline and enhance the user\ninteraction and collaboration process during drone navigation, ultimately\nexpediting mission success and accommodating users' inputs. In this paper, we\npresent a novel human-drone mixed reality interface that aims to (a) increase\nhuman-drone spatial awareness by sharing relevant spatial information and\nrepresentations between the human equipped with a Head Mounted Display (HMD)\nand the robot and (b) enable safer and intuitive human-drone interactive and\ncollaborative navigation in unknown environments beyond the simple command and\ncontrol or teleoperation paradigm. We validate our framework through extensive\nuser studies and experiments in a simulated post-disaster scenarios, comparing\nits performance against a traditional First-Person View (FPV) control systems.\nFurthermore, multiple tests on several users underscore the advantages of the\nproposed solution, which offers intuitive and natural interaction with the\nsystem. This demonstrates the solution's ability to assist humans during a\ndrone navigation mission, ensuring its safe and effective execution.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-02T04:45:32Z"}
{"aid":"http://arxiv.org/abs/2504.01368v1","title":"Proton cumulants from hydrodynamics in light of new STAR data","summary":"New measurements of proton number cumulants from the Beam Energy Scan Phase\nII (BES-II) program at RHIC by the STAR Collaboration provide unprecedented\nprecision and insights into the properties of strongly interacting matter. This\nreport discusses the measurements in the context of predictions from\nhydrodynamics, emphasizing the enhanced sensitivity of factorial cumulants and\ntheir implications for the search for the QCD critical point. The experimental\ndata shows enhancement of second-order factorial cumulants and suppression of\nthird-order factorial cumulants relative to the non-critical baseline at $7.7 <\n\\sqrt{s_{\\rm NN}} \\lesssim 10$ GeV. We discuss implications of this observation\nfor the possible location of the critical point in the QCD phase diagram and\nopportunities for future measurements of acceptance dependence of factorial\ncumulants.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex","published":"2025-04-02T05:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.01384v1","title":"On the efficient computation of Fourier coefficients of eta-quotients","summary":"We give formulas for computing efficiently the generalized Kloosterman sums\nappearing in the Hardy-Ramanujan-Rademacher expansions of the Fourier\ncoefficients of general eta-quotients given by Sussman and Chern, as well as\nexplicit bounds for the tails of these series.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T05:52:33Z"}
{"aid":"http://arxiv.org/abs/2504.01389v1","title":"De Novo Molecular Design Enabled by Direct Preference Optimization and\n  Curriculum Learning","summary":"De novo molecular design has extensive applications in drug discovery and\nmaterials science. The vast chemical space renders direct molecular searches\ncomputationally prohibitive, while traditional experimental screening is both\ntime- and labor-intensive. Efficient molecular generation and screening methods\nare therefore essential for accelerating drug discovery and reducing costs.\nAlthough reinforcement learning (RL) has been applied to optimize molecular\nproperties via reward mechanisms, its practical utility is limited by issues in\ntraining efficiency, convergence, and stability. To address these challenges,\nwe adopt Direct Preference Optimization (DPO) from NLP, which uses molecular\nscore-based sample pairs to maximize the likelihood difference between high-\nand low-quality molecules, effectively guiding the model toward better\ncompounds. Moreover, integrating curriculum learning further boosts training\nefficiency and accelerates convergence. A systematic evaluation of the proposed\nmethod on the GuacaMol Benchmark yielded excellent scores. For instance, the\nmethod achieved a score of 0.883 on the Perindopril MPO task, representing a\n6\\% improvement over competing models. And subsequent target protein binding\nexperiments confirmed its practical efficacy. These results demonstrate the\nstrong potential of DPO for molecular design tasks and highlight its\neffectiveness as a robust and efficient solution for data-driven drug\ndiscovery.","main_category":"cs.LG","categories":"cs.LG,physics.chem-ph,q-bio.BM","published":"2025-04-02T06:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.01392v1","title":"Spatial-Filter-Bank-Based Neural Method for Multichannel Speech\n  Enhancement","summary":"The performance of deep learning-based multi-channel speech enhancement\nmethods often deteriorates when the geometric parameters of the microphone\narray change. Traditional approaches to mitigate this issue typically involve\ntraining on multiple microphone arrays, which can be costly. To address this\nchallenge, we focus on uniform circular arrays and propose the use of a spatial\nfilter bank to extract features that are approximately invariant to geometric\nparameters. These features are then processed by a two-stage conformer-based\nmodel (TSCBM) to enhance speech quality. Experimental results demonstrate that\nour proposed method can be trained on a fixed microphone array while\nmaintaining effective performance across uniform circular arrays with unseen\ngeometric configurations during applications.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-02T06:13:37Z"}
{"aid":"http://arxiv.org/abs/2504.01413v1","title":"Quantum light sources with configurable lifetime leveraging parity-time\n  symmetry","summary":"Quantum light sources with configurable photon lifetimes are essential for\nlarge-scale quantum circuits, enabling applications in programmable quantum\ncomputing, various quantum key distribution protocols, and quantum tomography\ntechniques. However, the fundamental trade-off between efficiency and photon\nlifetime imposes significant challenges on the design of high-performance large\nconfigurable lifetime quantum light sources. Here, we report on such chip-scale\nquantum light sources by harnessing the unique feature of parity-time (PT)\nsymmetry. The core design centers on employing PT-symmetric coupling between\ntwo microresonators of distinct circumferences, enabling broad-range and\nselective tuning of intracavity photon density of states. By controlling the\nalignment between resonators, we achieved a 38-fold photon lifetime tuning\nrange (4 ~ 158 ps), with the shortest lifetimes near the exceptional points of\nthe PT-symmetric systems. The device generates energy-time entangled photon\npairs with 87.1 +- 1.1% interference visibility and a heralded second-order\nautocorrelation of g_h^((2) ) (0)= 0.069 +- 0.001. Our work highlights the\npotential of PT symmetry for advanced quantum applications, including\nhigh-speed communication and programmable quantum computing, quantum coherent\ntomography, and beyond.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-02T07:04:31Z"}
{"aid":"http://arxiv.org/abs/2504.01421v1","title":"Interacting $p$-form gauge theories: New developments","summary":"Gauge $p$-forms in diverse dimensions are ubiquitous in supergravity and\nstring theory. This work reviews novel covariant formulations designed to\ngenerate arbitrary interacting duality-invariant or chiral (self-dual) $p$-form\ntheories in $d = 2p + 2$ space-time dimensions. For odd $p$, such theories\npossess $\\mathsf{U}(1)$ duality invariance and include the Born-Infeld and\nModMax theories. For even $p$, they describe a self-interacting chiral $p$-form\nwith its gauge-invariant field strength obeying a nonlinear self-duality\ncondition. We provide a complete description of $T\\bar T$-like deformations of\n$\\mathsf{U}(1)$ duality-invariant models for nonlinear electrodynamics in four\ndimensions and their six-dimensional counterparts -- interacting chiral\ntwo-form field theories. We also elaborate on consistent flows in the spaces of\nduality-invariant or chiral (self-dual) $p$-form theories beyond six\ndimensions.","main_category":"hep-th","categories":"hep-th","published":"2025-04-02T07:12:51Z"}
{"aid":"http://arxiv.org/abs/2504.01427v1","title":"Observational diversity of bright long-lived Type II supernovae","summary":"In various types of supernovae (SNe), strong interaction between the SN\nejecta and circumstellar material (CSM) has been reported. This raises\nquestions on their progenitors and mass-loss processes shortly before the\nexplosion. Recently, the bright long-lived Type~II SN 2021irp was proposed to\nbe a standard Type II SN interacting with disk-like CSM. The observational\nproperties suggest that the progenitor was a massive star in a binary system\nand underwent a mass-ejection process due to the binary interaction just before\nthe explosion. Here, we study the diversity of the observational properties of\nbright long-lived Type II (21irp-like) SNe. We analyse the diversity of their\nCSM properties, in order to understand their progenitors and mass-loss\nmechanisms and their relations with the other types of interacting SNe. We\nperformed photometry, spectroscopy, and/or polarimetry for four 21irp-like SNe.\nBased on these observations as well as published data of SN~2021irp itself and\nwell-observed bright and long-lived type II SNe including SNe~2010jl, 2015da\nand 2017hcc, we discuss their CSM characteristics. This sample of SNe shows\nluminous and long-lived photometric evolution, with some variations in the\nphotometric evolution (from $\\sim-17$ to $\\sim-20$ absolute mag in the $r$/$o$\nband even at $\\sim 200$ days after the explosion). They show photospheric\nspectra characterized mainly by Balmer lines for several hundreds of days, with\nsome variations in the shapes of the lines. They show high polarization with\nslight variations in the polarization degrees with rapid declines with time\n(from $\\sim3-6$ \\% before the peak to $\\sim1$ \\% at $\\sim200$ days after the\npeak). The observational properties are consistent with the\ndisk-CSM-interaction scenario, i.e., typical Type~II SNe interacting with\ndisk-like CSM.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-02T07:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.01450v1","title":"CASCADE Your Datasets for Cross-Mode Knowledge Retrieval of Language\n  Models","summary":"Language models often struggle with cross-mode knowledge retrieval -- the\nability to access knowledge learned in one format (mode) when queried in\nanother. We demonstrate that models trained on multiple data sources (e.g.,\nWikipedia and TinyStories) exhibit significantly reduced accuracy when\nretrieving knowledge in a format different from its original training mode.\nThis paper quantitatively investigates this phenomenon through a controlled\nstudy of random token sequence memorization across different modes. We first\nexplore dataset rewriting as a solution, revealing that effective cross-mode\nretrieval requires prohibitively extensive rewriting efforts that follow a\nsigmoid-like relationship. As an alternative, we propose CASCADE, a novel\npretraining algorithm that uses cascading datasets with varying sequence\nlengths to capture knowledge at different scales. Our experiments demonstrate\nthat CASCADE outperforms dataset rewriting approaches, even when compressed\ninto a single model with a unified loss function. This work provides both\nqualitative evidence of cross-mode retrieval limitations and a practical\nsolution to enhance language models' ability to access knowledge independently\nof its presentational format.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-02T08:02:07Z"}
{"aid":"http://arxiv.org/abs/2504.01462v1","title":"Characterization of the chaotic phase in the tilted Bose-Hubbard model","summary":"The chaotic phase of the tilted Bose-Hubbard model is identified as a\nfunction of energy, tilt strength and particle interaction, from the eigenstate\nstructure and the statistical features of the energy spectrum. Our analysis\nreveals that the chaotic phase of the bare Bose-Hubbard Hamiltonian can\nactually be enhanced by the presence of a moderate tilt. We further unveil the\ndevelopment and scaling of the chaotic regime from the perspective of a\nhomogeneous density configuration typically used in cold atom experiments,\nproviding a valuable phase diagram for future theoretical and experimental\nstudies of this system.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas","published":"2025-04-02T08:18:33Z"}
{"aid":"http://arxiv.org/abs/2504.01466v1","title":"Mesh Mamba: A Unified State Space Model for Saliency Prediction in\n  Non-Textured and Textured Meshes","summary":"Mesh saliency enhances the adaptability of 3D vision by identifying and\nemphasizing regions that naturally attract visual attention. To investigate the\ninteraction between geometric structure and texture in shaping visual\nattention, we establish a comprehensive mesh saliency dataset, which is the\nfirst to systematically capture the differences in saliency distribution under\nboth textured and non-textured visual conditions. Furthermore, we introduce\nmesh Mamba, a unified saliency prediction model based on a state space model\n(SSM), designed to adapt across various mesh types. Mesh Mamba effectively\nanalyzes the geometric structure of the mesh while seamlessly incorporating\ntexture features into the topological framework, ensuring coherence throughout\nappearance-enhanced modeling. More importantly, by subgraph embedding and a\nbidirectional SSM, the model enables global context modeling for both local\ngeometry and texture, preserving the topological structure and improving the\nunderstanding of visual details and structural complexity. Through extensive\ntheoretical and empirical validation, our model not only improves performance\nacross various mesh types but also demonstrates high scalability and\nversatility, particularly through cross validations of various visual features.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:22:25Z"}
{"aid":"http://arxiv.org/abs/2504.01468v1","title":"HH-PIM: Dynamic Optimization of Power and Performance with\n  Heterogeneous-Hybrid PIM for Edge AI Devices","summary":"Processing-in-Memory (PIM) architectures offer promising solutions for\nefficiently handling AI applications in energy-constrained edge environments.\nWhile traditional PIM designs enhance performance and energy efficiency by\nreducing data movement between memory and processing units, they are limited in\nedge devices due to continuous power demands and the storage requirements of\nlarge neural network weights in SRAM and DRAM. Hybrid PIM architectures,\nincorporating non-volatile memories like MRAM and ReRAM, mitigate these\nlimitations but struggle with a mismatch between fixed computing resources and\ndynamically changing inference workloads. To address these challenges, this\nstudy introduces a Heterogeneous-Hybrid PIM (HH-PIM) architecture, comprising\nhigh-performance MRAM-SRAM PIM modules and low-power MRAM-SRAM PIM modules. We\nfurther propose a data placement optimization algorithm that dynamically\nallocates data based on computational demand, maximizing energy efficiency.\nFPGA prototyping and power simulations with processors featuring HH-PIM and\nother PIM types demonstrate that the proposed HH-PIM achieves up to $60.43$\npercent average energy savings over conventional PIMs while meeting application\nlatency requirements. These results confirm the suitability of HH-PIM for\nadaptive, energy-efficient AI processing in edge devices.","main_category":"cs.AR","categories":"cs.AR,cs.AI","published":"2025-04-02T08:22:32Z"}
{"aid":"http://arxiv.org/abs/2504.01472v1","title":"ANNEXE: Unified Analyzing, Answering, and Pixel Grounding for Egocentric\n  Interaction","summary":"Egocentric interaction perception is one of the essential branches in\ninvestigating human-environment interaction, which lays the basis for\ndeveloping next-generation intelligent systems. However, existing egocentric\ninteraction understanding methods cannot yield coherent textual and pixel-level\nresponses simultaneously according to user queries, which lacks flexibility for\nvarying downstream application requirements. To comprehend egocentric\ninteractions exhaustively, this paper presents a novel task named Egocentric\nInteraction Reasoning and pixel Grounding (Ego-IRG). Taking an egocentric image\nwith the query as input, Ego-IRG is the first task that aims to resolve the\ninteractions through three crucial steps: analyzing, answering, and pixel\ngrounding, which results in fluent textual and fine-grained pixel-level\nresponses. Another challenge is that existing datasets cannot meet the\nconditions for the Ego-IRG task. To address this limitation, this paper creates\nthe Ego-IRGBench dataset based on extensive manual efforts, which includes over\n20k egocentric images with 1.6 million queries and corresponding multimodal\nresponses about interactions. Moreover, we design a unified ANNEXE model to\ngenerate text- and pixel-level outputs utilizing multimodal large language\nmodels, which enables a comprehensive interpretation of egocentric\ninteractions. The experiments on the Ego-IRGBench exhibit the effectiveness of\nour ANNEXE model compared with other works.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:24:35Z"}
{"aid":"http://arxiv.org/abs/2504.01516v1","title":"An addendum on the Mathieu Conjecture for $SU(N)$, $Sp(N)$ and $G_2$","summary":"In this paper, we sharpen results obtained by the author in 2023. The new\nresults reduce the Mathieu Conjecture on $SU(N)$ (formulated for all compact\nconnected Lie groups by O. Mathieu in 1997) to a conjecture involving only\nfunctions on $\\mathbb{R}^n\\times (S^1)^m$ with $n,m$ non-negative integers\ninstead of involving functions on $\\mathbb{R}^n\\times (S^1\\setminus\\{1\\})^m$.\nThe proofs rely on a more recent work of the author (2024) and a specific $KAK$\ndecomposition. Finally, with these results we can also improve the results on\nthe groups $Sp(N)$ and $G_2$ in the latter paper, since they relied on the\nconstruction introduced in the 2023 paper.","main_category":"math.GR","categories":"math.GR","published":"2025-04-02T09:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.01522v1","title":"Redefining technology for indigenous languages","summary":"In this paper, we offer an overview of indigenous languages, identifying the\ncauses of their devaluation and the need for legislation on language rights. We\nreview the technologies used to revitalize these languages, finding that when\nthey come from outside, they often have the opposite effect to what they seek;\nhowever, when developed from within communities, they become powerful\ninstruments of expression. We propose that the inclusion of Indigenous\nknowledge in large language models (LLMs) will enrich the technological\nlandscape, but must be done in a participatory environment that encourages the\nexchange of knowledge.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL","published":"2025-04-02T09:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.01528v1","title":"Analytical and Numerical Linear Analyses of Convection Revisited","summary":"We conduct linear analyses of convection in domains larger than the\ntemperature scale height. We employ both analytical and numerical methods in\nthese analyses. In the case excluding all dissipation, the typical time scale\nof convection is determined by the free fall time over the temperature scale\nheight. We quantitatively show the condition for the Boussinesq and\nWentzel-Kramers-Brillouin (WKB) approximations to be applicable. We provide a\nreassessment of the critical Rayleigh number, a key indicator of convection,\nand show that WKB approximation tends to underestimate the critical Rayleigh\nnumber, particularly when the temperature scale height is comparable to or\nsmaller than the domain height. We show clear explanation why both thermal\nconduction and viscosity are required for stabilizing negative entropy gradient\nmedium.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-02T09:13:31Z"}
{"aid":"http://arxiv.org/abs/2504.01529v1","title":"Improvement of fully-implicit two-phase pore-network models by employing\n  generalized flux functions with additional throat variables","summary":"In fully-implicit two-phase pore-network models, developing a well-converged\nscheme remains a major challenge, primarily due to the discontinuities in the\nphase conductivities. This paper addresses these numerical issues by proposing\na generalized flux function that establishes a continuous flux expression for\ntwo-phase flows by introducing an additional throat variable $\\Theta$. Two\napproaches for expressing this additional throat variable are introduced: the\nfirst applies regularization strategies, while the second constructs an\nadditional residual constraint equation. It is shown that this approach\nsignificantly improves accuracy and ensures the temporal convergence, as\ndemonstrated through various numerical examples.","main_category":"math.NA","categories":"math.NA,cs.NA,math-ph,math.MP","published":"2025-04-02T09:14:42Z"}
{"aid":"http://arxiv.org/abs/2504.01540v1","title":"From SmÃ¸r-re-brÃ¸d to Subwords: Training LLMs on Danish, One\n  Morpheme at a Time","summary":"The best performing transformer-based language models use subword\ntokenization techniques, such as Byte-Pair-Encoding (BPE). However, these\napproaches often overlook linguistic principles, such as morphological\nsegmentation, which we believe is fundamental for understanding\nlanguage-specific word structure. In this study, we leverage an annotated\nDanish morphological dataset to train a semisupervised model for morphological\nsegmentation, enabling the development of tokenizers optimized for Danish\nmorphology. We evaluate four distinct tokenizers, including two custom\nmorphological tokenizers, by analyzing their performance in morphologically\nsegmenting Danish words. Additionally, we train two generative transformer\nmodels, \\textit{CerebrasGPT-111M} and \\textit{LLaMA-3.2 1B}, using these\ntokenizers and evaluate their downstream performance. Our findings reveal that\nour custom-developed tokenizers substantially enhance morphological\nsegmentation, achieving an F1 score of 58.84, compared to 39.28 achieved by a\nDanish BPE tokenizer. In downstream tasks, models trained with our\nmorphological tokenizers outperform those using BPE tokenizers across different\nevaluation metrics. These results highlight that incorporating Danish\nmorphological segmentation strategies into tokenizers leads to improved\nperformance in generative transformer models on Danish language","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T09:26:02Z"}
{"aid":"http://arxiv.org/abs/2504.01549v1","title":"Business Process Modeling Using a Metamodeling Approach","summary":"The thesis discusses topics related to the development of business process\nmanagement systems. Business process management systems have evolved on the\nbasis of workflow management systems through incremental inclusion of standard\ninformation system functions, for example, resource and client management. The\napplication of model driven development is required to deal with the complexity\nof business management systems and to increase development efficiency. In\ncontrast to conventional information systems, the behavior of business\nmanagement systems is strongly affected by the business models that they\nexecute. Thus, business process models also can be used for designing and\ndeveloping business management systems using sequentially applied model\ntransformations that adapt models to a specific execution platform.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T09:46:54Z"}
{"aid":"http://arxiv.org/abs/2504.01554v1","title":"8-DoFs Cable Driven Parallel Robots for Bimanual Teleportation","summary":"Teleoperation plays a critical role in intuitive robot control and imitation\nlearning, particularly for complex tasks involving mobile manipulators with\nredundant degrees of freedom (DoFs). However, most existing master controllers\nare limited to 6-DoF spatial control and basic gripper control, making them\ninsufficient for controlling high-DoF robots and restricting the operator to a\nsmall workspace. In this work, we present a novel, low-cost, high-DoF master\ncontroller based on Cable-Driven Parallel Robots (CDPRs), designed to overcome\nthese limitations. The system decouples translation and orientation control,\nfollowing a scalable 3 + 3 + n DoF structure: 3 DoFs for large-range\ntranslation using a CDPR, 3 DoFs for orientation using a gimbal mechanism, and\nn additional DoFs for gripper and redundant joint control. Its lightweight\ncable-driven design enables a large and adaptable workspace while minimizing\nactuator load. The end-effector remains stable without requiring continuous\nhigh-torque input, unlike most serial robot arms. We developed the first\ndual-arm CDPR-based master controller using cost-effective actuators and a\nsimple mechanical structure. In demonstrations, the system successfully\ncontrolled an 8-DoF robotic arm with a 2-DoF pan-tilt camera, performing tasks\nsuch as pick-and-place, knot tying, object sorting, and tape application. The\nresults show precise, versatile, and practical high-DoF teleoperation.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-02T09:54:16Z"}
{"aid":"http://arxiv.org/abs/2504.01562v1","title":"Asymptotic analysis of the finite predictor for the fractional Gaussian\n  noise","summary":"The goal of this paper is to propose a new approach to asymptotic analysis of\nthe finite predictor for stationary sequences. It produces the exact\nasymptotics of the relative prediction error and the partial correlation\ncoefficients. The assumptions are analytic in nature and applicable to\nprocesses with long range dependence. The ARIMA type process driven by the\nfractional Gaussian noise (fGn), which previously remained elusive, serves as\nour study case.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-02T10:03:53Z"}
{"aid":"http://arxiv.org/abs/2504.01568v1","title":"Ab-initio investigation of transition metal dichalcogenides for the\n  hydrogenation of carbon dioxide to methanol","summary":"We computationally investigate the catalytic potential of MoSe$_2$, WS$_2$,\nand WSe$_2$ nanoribbons and nanosheets for the partial hydrogenation of CO$_2$\nto methanol by comparing their electronic, adsorption, and defect properties to\nMoS$_2$, a known thermo-catalyst. We identify Se-deficient MoSe$_2$ (followed\nby WSe$_2$) nanosheets to be favorable for selective methanol formation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T10:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.01602v1","title":"Comment Staytime Prediction with LLM-enhanced Comment Understanding","summary":"In modern online streaming platforms, the comments section plays a critical\nrole in enhancing the overall user experience. Understanding user behavior\nwithin the comments section is essential for comprehensive user interest\nmodeling. A key factor of user engagement is staytime, which refers to the\namount of time that users browse and post comments. Existing watchtime\nprediction methods struggle to adapt to staytime prediction, overlooking\ninteractions with individual comments and their interrelation. In this paper,\nwe present a micro-video recommendation dataset with video comments (named as\nKuaiComt) which is collected from Kuaishou platform. correspondingly, we\npropose a practical framework for comment staytime prediction with LLM-enhanced\nComment Understanding (LCU). Our framework leverages the strong text\ncomprehension capabilities of large language models (LLMs) to understand\ntextual information of comments, while also incorporating fine-grained comment\nranking signals as auxiliary tasks. The framework is two-staged: first, the LLM\nis fine-tuned using domain-specific tasks to bridge the video and the comments;\nsecond, we incorporate the LLM outputs into the prediction model and design two\ncomment ranking auxiliary tasks to better understand user preference. Extensive\noffline experiments demonstrate the effectiveness of our framework, showing\nsignificant improvements on the task of comment staytime prediction.\nAdditionally, online A/B testing further validates the practical benefits on\nindustrial scenario. Our dataset KuaiComt\n(https://github.com/lyingCS/KuaiComt.github.io) and code for LCU\n(https://github.com/lyingCS/LCU) are fully released.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-02T11:09:18Z"}
{"aid":"http://arxiv.org/abs/2504.01627v1","title":"Horizon Scans can be accelerated using novel information retrieval and\n  artificial intelligence tools","summary":"Introduction: Horizon scanning in healthcare assesses early signals of\ninnovation, crucial for timely adoption. Current horizon scanning faces\nchallenges in efficient information retrieval and analysis, especially from\nunstructured sources like news, presenting a need for innovative tools.\nMethodology: The study introduces SCANAR and AIDOC, open-source Python-based\ntools designed to improve horizon scanning. SCANAR automates the retrieval and\nprocessing of news articles, offering functionalities such as de-duplication\nand unsupervised relevancy ranking. AIDOC aids filtration by leveraging AI to\nreorder textual data based on relevancy, employing neural networks for semantic\nsimilarity, and subsequently prioritizing likely relevant entries for human\nreview. Results: Twelve internal datasets from horizon scans and four external\nbenchmarking datasets were used. SCANAR improved retrieval efficiency by\nautomating processes previously dependent on manual labour. AIDOC displayed\nwork-saving potential, achieving around 62% reduction in manual review efforts\nat 95% recall. Comparative analysis with benchmarking data showed AIDOC's\nperformance was similar to existing systematic review automation tools, though\nperformance varied depending on dataset characteristics. A smaller case-study\non our news datasets shows the potential of ensembling large language models\nwithin the active-learning process for faster detection of relevant articles\nacross news datasets. Conclusion: The validation indicates that SCANAR and\nAIDOC show potential to enhance horizon scanning efficiency by streamlining\ndata retrieval and prioritisation. These tools may alleviate methodological\nlimitations and allow broader, swifter horizon scans. Further studies are\nsuggested to optimize these models and to design new workflows and validation\nprocesses that integrate large language models.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-02T11:33:08Z"}
{"aid":"http://arxiv.org/abs/2504.01640v1","title":"Controlling photo-excited electron-spin by light-polarization in\n  ultrafast-pumped altermagnets","summary":"Altermagnets (AMs) constitute a novel class of spin-compensated materials in\nwhich the symmetry connecting opposite-spin sublattices involves a spatial\nrotation. Here, we uncover a set of unique non-linear, light-driven properties\nthat set AMs apart from traditional ferro- and antiferromagnets. We demonstrate\ntheoretically that the polarization of an electromagnetic pulse that\nphoto-excites electrons and holes in an AM, controls the spin orientation of\nthese non-equilibrium charge carriers. For a d-wave AM model and a prototype\nmaterial, we show that very large post-pump spin polarizations may be attained\nby exploiting resonances. We show that this protocol also allows, in an AM, to\ndirectly probe the spin splitting of the electronic states in energy and\nmomentum space. Thus, it can be used to identify and characterize altermagnetic\nmaterials via ultrafast pump-probe Kerr/Faraday spectroscopy or spin- and\ntime-resolved ARPES. This opens up the possibility of devising ultrafast\noptical switches of non-equilibrium spin-polarization, finely tunable by\nadjusting the pump-pulse characteristics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T11:43:45Z"}
{"aid":"http://arxiv.org/abs/2504.01649v1","title":"Modeling the Siege of Syracuse: Resources, strategy, and collapse","summary":"The Siege of Syracuse ($214-212$ BC) was a decisive event in the Second Punic\nWar, leading to the city's fall to Rome despite its formidable defenses,\nincluding the war machines devised by Archimedes. In this work, we propose a\nmathematical model to describe the dynamics of the siege, incorporating the\ndepletion of resources, the decline of Syracuse's population, and the\npersistence of the Roman army. Our analysis reveals the existence of a critical\nthreshold $\\lambda_{c}$, which determines the outcome of the siege. This\nthreshold marks a phase transition: if the effectiveness of Syracuse's\ndefenses, represented by $\\lambda$, had exceeded $\\lambda_{c}$, the city could\nhave withstood the Roman assault. However, since history records Syracuse's\nfall, we conclude that $\\lambda < \\lambda_{c}$. This result provides a\nquantitative framework to understand the inevitability of the city's conquest\nand demonstrates how mathematical modeling can offer new insights into\nhistorical military conflicts. We also explore different scenarios and assess\nthe impact of key factors such as siege duration, supply constraints, and\ndefensive capabilities. The results provide insight into how strategic elements\ninfluenced the eventual fall of Syracuse and demonstrate the applicability of\nmathematical modeling in historical military analysis.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-02T11:59:21Z"}
{"aid":"http://arxiv.org/abs/2504.01658v1","title":"Scaling in Magnetic Neutron Scattering","summary":"We report the discovery of scaling in the mesoscale magnetic microstructure\nof bulk ferromagnets. Supported by analytical micromagnetic theory, we\nintroduce the field-dependent scaling length $l_{\\mathrm{C}}(H)$, which\ndescribes the characteristic long-wavelength magnetization fluctuations that\nare caused by microstructural defects by means of magnetoelastic and\nmagnetocrystalline anisotropy. The scaling length $l_{\\mathrm{C}}$ is\nidentified to consist of the micromagnetic exchange length of the field\n$l_{\\mathrm{H}}$, which depends on the magnetic interactions, and a\nfield-independent contribution that reflects the properties of the magnetic\nanisotropy field and the magnetostatic fluctuations. The latter finding is\nrooted in the convolution relationship between the grain microstructure and\nmicromagnetic response functions. We validated the scaling property by\nanalyzing experimental data for the magnetic neutron scattering cross section.\nWhen plotted as a function of the dimensionless scaled scattering vector\n$\\mathfrak{q}(H) = q \\, l_{\\mathrm{C}}(H)$, the field-dependent\namplitude-scaled neutron data of nanocrystalline Co and a Nd-Fe-B-based\nnanocomposite collapse onto a single master curve, demonstrating universal\nbehavior. The scaling length $l_{\\mathrm{C}}$ provides a framework for\nanalyzing the field-dependent neutron scattering cross section, highlighting\nthe existence of critical length scales that govern the mesoscale\nmicrostructure of magnetic materials.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T12:11:12Z"}
{"aid":"http://arxiv.org/abs/2504.01685v1","title":"Augmenting chemical databases for atomistic machine learning by sampling\n  conformational space","summary":"Machine learning (ML) has become a standard tool for the exploration of\nchemical space. Much of the performance of such models depends on the chosen\ndatabase for a given task. Here, this aspect is investigated for \"chemical\ntasks\" including the prediction of hybridization, oxidation, substituent\neffects, and aromaticity, starting from an initial \"restricted\" database (iRD).\nChoosing molecules for augmenting this iRD, including increasing numbers of\nconformations generated at different temperatures, and retraining the models\ncan improve predictions of the models on the selected \"tasks\". Addition of a\nsmall percentage of conformers (1 % ) obtained at 300 K improves the\nperformance in almost all cases. On the other hand, and in line with previous\nstudies, redundancy and highly deformed structures in the augmentation set\ncompromise prediction quality. Energy and bond distributions were evaluated by\nmeans of Kullback-Leibler ($D_{\\rm KL}$) and Jensen-Shannon ($D_{\\rm JS}$)\ndivergence and Wasserstein distance ($W_{1}$). The findings of this work\nprovide a baseline for the rational augmentation of chemical databases or the\ncreation of synthetic databases.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.data-an","published":"2025-04-02T12:32:37Z"}
{"aid":"http://arxiv.org/abs/2504.01697v1","title":"Single-atom-at-a-time adsorption studies of $^{211}$Bi and its precursor\n  $^{211}$Pb on SiO$_{2}$ surfaces","summary":"In preparation of gas-phase chemical experiments with moscovium (Mc, element\n115), we studied the chemical behavior of the short-lived bismuth radioisotope\n$^{211}$Bi in helium, argon, and oxygen atmosphere. Internal chromatograms were\nrecorded as a function of various parameters including carrier gas type and\nflow rate, thus characterizing the novel miniCOMPACT detector array. This aids\nto optimize the conditions for experiments with superheavy elements. The\nbismuth progeny of $^{219}$Rn deposited on the SiO$_{2}$ surface of the\nminiCOMPACT via diffusion-controlled deposition. Bismuth showed the expected\nhigh reactivity towards the SiO$_{2}$ surface of the miniCOMPACT. Experiments\nin argon and oxygen atmosphere showed no measurable differences in the\ndeposition distribution of the activity. The intermediate 36-min $^{211}$Pb is\na member of the $^{227}$Ac decay chain, feeding the studied bismuth isotope,\nwas taken into account. To extract thermodynamical data from the results,\nnamely the lower limit of the value of the adsorption enthalpy of Bi on\nSiO$_{2}$, we performed Monte Carlo simulations, adapted to account for the\nprecursor effect, and compared the experimental results to their output.\nSimulations were also performed for bismuths heavier homologue, moscovium,\nusing a theoretically predicted value for the adsorption enthalpy of this\nelement on SiO$_{2}$. These suggest moscovium to adsorb in the first part of\nthe miniCOMPACT detection array, in line with recent observations.","main_category":"nucl-ex","categories":"nucl-ex,physics.ins-det","published":"2025-04-02T12:58:04Z"}
{"aid":"http://arxiv.org/abs/2504.01705v1","title":"Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via\n  Selective Pruning","summary":"The Internet of Drones (IoD), where drones collaborate in data collection and\nanalysis, has become essential for applications such as surveillance and\nenvironmental monitoring. Federated learning (FL) enables drones to train\nmachine learning models in a decentralized manner while preserving data\nprivacy. However, FL in IoD networks is susceptible to attacks like data\npoisoning and model inversion. Federated unlearning (FU) mitigates these risks\nby eliminating adversarial data contributions, preventing their influence on\nthe model. This paper proposes sky of unlearning (SoUL), a federated unlearning\nframework that efficiently removes the influence of unlearned data while\nmaintaining model performance. A selective pruning algorithm is designed to\nidentify and remove neurons influential in unlearning but minimally impact the\noverall performance of the model. Simulations demonstrate that SoUL outperforms\nexisting unlearning methods, achieves accuracy comparable to full retraining,\nand reduces computation and communication overhead, making it a scalable and\nefficient solution for resource-constrained IoD networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.MA","published":"2025-04-02T13:07:30Z"}
{"aid":"http://arxiv.org/abs/2504.01713v1","title":"A two-player voting game in Euclidean space","summary":"Given a finite set $S$ of points in $\\mathbb{R}^d$, which we regard as the\nlocations of voters on a $d$-dimensional political `spectrum', two candidates\n(Alice and Bob) select one point in $\\mathbb{R}^d$ each, in an attempt to get\nas many votes as possible. Alice goes first and Bob goes second, and then each\nvoter simply votes for the candidate closer to them in terms of Euclidean\ndistance. If a voter's distance from the two candidates is the same, they vote\nfor nobody. We give a geometric characterization of the sets $S$ for which each\ncandidate wins, assuming that Alice wins if they get an equal number of votes.\nWe also show that, if not all the voters lie on a single line, then, whenever\nAlice has a winning strategy, there is a unique winning point for her. We also\nprovide an algorithm which decides whether Alice has a winning point, and\ndetermines the location of that point, both in finite (in fact polynomial)\ntime.","main_category":"math.CO","categories":"math.CO,math.OC","published":"2025-04-02T13:20:43Z"}
{"aid":"http://arxiv.org/abs/2504.01716v1","title":"Studies of Hadronic Showers in SND@LHC","summary":"The SND@LHC experiment was built for observing neutrinos arising from LHC pp\ncollisions. The detector consists of two sections: a target instrumented with\nSciFi modules and a hadronic calorimeter/muon detector. Energetic $\\nu$N\ncollisions in the target produce hadronic showers. Reconstruction of the shower\ntotal energy requires an estimate of the fractions deposited in both the target\nand the calorimeter. In order to calibrate the SND@LHC response, a replica of\nthe detector was exposed to hadron beams with 100 to 300 GeV in the CERN SPS H8\ntest beam line in Summer 2023. This report describes the methods developed to\ntag the presence of a shower, to locate the shower origin in the target, and to\ncombine the target SciFi and the calorimeter signals so to measure the shower\ntotal energy.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-02T13:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.01717v1","title":"Construction of MDS Euclidean Self-Dual Codes via Multiple Subsets","summary":"MDS self-dual codes have good algebraic structure, and their parameters are\ncompletely determined by the code length. In recent years, the construction of\nMDS Euclidean self-dual codes with new lengths has become an important issue in\ncoding theory. In this paper, we are committed to constructing new MDS\nEuclidean self-dual codes via generalized Reed-Solomon (GRS) codes and their\nextended (EGRS) codes. The main effort of our constructions is to find suitable\nsubsets of finite fields as the evaluation sets, ensuring that the\ncorresponding (extended) GRS codes are Euclidean self-dual. Firstly, we present\na method for selecting evaluation sets from multiple intersecting subsets and\nprovide a theorem to guarantee that the chosen evaluation sets meet the desired\ncriteria. Secondly, based on this theorem, we construct six new classes of MDS\nEuclidean self-dual codes using the norm function, as well as the union of\nthree multiplicity subgroups and their cosets respectively. Finally, in our\nconstructions, the proportion of possible MDS Euclidean self-dual codes exceeds\n85\\%, which is much higher than previously reported results.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-02T13:26:04Z"}
{"aid":"http://arxiv.org/abs/2504.01724v1","title":"DreamActor-M1: Holistic, Expressive and Robust Human Image Animation\n  with Hybrid Guidance","summary":"While recent image-based human animation methods achieve realistic body and\nfacial motion synthesis, critical gaps remain in fine-grained holistic\ncontrollability, multi-scale adaptability, and long-term temporal coherence,\nwhich leads to their lower expressiveness and robustness. We propose a\ndiffusion transformer (DiT) based framework, DreamActor-M1, with hybrid\nguidance to overcome these limitations. For motion guidance, our hybrid control\nsignals that integrate implicit facial representations, 3D head spheres, and 3D\nbody skeletons achieve robust control of facial expressions and body movements,\nwhile producing expressive and identity-preserving animations. For scale\nadaptation, to handle various body poses and image scales ranging from\nportraits to full-body views, we employ a progressive training strategy using\ndata with varying resolutions and scales. For appearance guidance, we integrate\nmotion patterns from sequential frames with complementary visual references,\nensuring long-term temporal coherence for unseen regions during complex\nmovements. Experiments demonstrate that our method outperforms the\nstate-of-the-art works, delivering expressive results for portraits,\nupper-body, and full-body generation with robust long-term consistency. Project\nPage: https://grisoon.github.io/DreamActor-M1/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T13:30:32Z"}
{"aid":"http://arxiv.org/abs/2504.01725v1","title":"Brillouin-enhanced four-wave mixing with optical chiral states","summary":"Brillouin-enhanced four-wave mixing - also known as Brillouin dynamic\ngratings - is an important nonlinear effect in photonics that couples four\nlight waves by travelling acoustic waves. The effect has received a lot of\nattention in the last few decades, especially for applications in fiber\nsensing, signal processing and optical delay lines. Here, we report\nBrillouin-enhanced four-wave mixing with optical chiral states (i.e. circular\npolarization and vortex states) in twisted photonic crystal fiber, by\nleveraging the topology-selective Brillouin effect. Phase-matching has the\nconsequence that the travelling acoustic gratings created by\ncircularly-polarized vortex pump and Stokes in the stimulated Brillouin\nscattering can be used to modulate a frequency-shifted probe, where the\npump/Stokes and probe have different circular polarization or topological\ncharges. We demonstrate cross-frequency selective information transfer and show\nthat the information is transferred only when pump and probe have opposite\ncircular polarization.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T13:31:57Z"}
{"aid":"http://arxiv.org/abs/2504.01774v1","title":"Memory-efficient Low-latency Remote Photoplethysmography through\n  Temporal-Spatial State Space Duality","summary":"Remote photoplethysmography (rPPG), enabling non-contact physiological\nmonitoring through facial light reflection analysis, faces critical\ncomputational bottlenecks as deep learning introduces performance gains at the\ncost of prohibitive resource demands. This paper proposes ME-rPPG, a\nmemory-efficient algorithm built on temporal-spatial state space duality, which\nresolves the trilemma of model scalability, cross-dataset generalization, and\nreal-time constraints. Leveraging a transferable state space, ME-rPPG\nefficiently captures subtle periodic variations across facial frames while\nmaintaining minimal computational overhead, enabling training on extended video\nsequences and supporting low-latency inference. Achieving cross-dataset MAEs of\n5.38 (MMPD), 0.70 (VitalVideo), and 0.25 (PURE), ME-rPPG outperforms all\nbaselines with improvements ranging from 21.3% to 60.2%. Our solution enables\nreal-time inference with only 3.6 MB memory usage and 9.46 ms latency --\nsurpassing existing methods by 19.5%-49.7% accuracy and 43.2% user satisfaction\ngains in real-world deployments. The code and demos are released for\nreproducibility on https://github.com/Health-HCI-Group/ME-rPPG-demo.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T14:34:04Z"}
{"aid":"http://arxiv.org/abs/2504.01822v1","title":"Track and Trace: Automatically Uncovering Cross-chain Transactions in\n  the Multi-blockchain Ecosystems","summary":"Cross-chain technology enables seamless asset transfer and message-passing\nwithin decentralized finance (DeFi) ecosystems, facilitating multi-chain\ncoexistence in the current blockchain environment. However, this development\nalso raises security concerns, as malicious actors exploit cross-chain asset\nflows to conceal the provenance and destination of assets, thereby facilitating\nillegal activities such as money laundering. Consequently, the need for\ncross-chain transaction traceability has become increasingly urgent. Prior\nresearch on transaction traceability has predominantly focused on single-chain\nand centralized finance (CeFi) cross-chain scenarios, overlooking DeFispecific\nconsiderations. This paper proposes ABCTRACER, an automated, bi-directional\ncross-chain transaction tracing tool, specifically designed for DeFi\necosystems. By harnessing transaction event log mining and named entity\nrecognition techniques, ABCTRACER automatically extracts explicit cross-chain\ncues. These cues are then combined with information retrieval techniques to\nencode implicit cues. ABCTRACER facilitates the autonomous learning of latent\nassociated information and achieves bidirectional, generalized cross-chain\ntransaction tracing. Our experiments on 12 mainstream cross-chain bridges\ndemonstrate that ABCTRACER attains 91.75% bi-directional traceability (F1\nmetrics) with self-adaptive capability. Furthermore, we apply ABCTRACER to\nreal-world cross-chain attack transactions and money laundering traceability,\nthereby bolstering the traceability and blockchain ecological security of DeFi\nbridging applications.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-02T15:28:25Z"}
{"aid":"http://arxiv.org/abs/2504.01826v1","title":"The properties of general Fourier partial sums of functions $f \\in C_L$","summary":"In this paper, we investigated the Fourier partial sums with respect to\ngeneral orthonormal systems when the function $f$ belongs to some\ndifferentiable class of functions","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T15:33:13Z"}
{"aid":"http://arxiv.org/abs/2504.01828v1","title":"Acoustic modes in M67 cluster stars trace deepening convective envelopes","summary":"Acoustic oscillations in stars are sensitive to stellar interiors. Frequency\ndifferences between overtone modes -- large separations -- probe stellar\ndensity, while differences between low-degree modes -- small separations --\nprobe the sound speed gradient in the energy-generating core of main sequence\nSun-like stars, and hence their ages. At later phases of stellar evolution,\ncharacterised by inert cores, small separations are believed to lose much of\ntheir power to probe deep interiors and simply become proportional to large\nseparations. Here, we present clear evidence of a rapidly evolving convective\nzone as stars evolve from the subgiant phase into red giants. By measuring\nacoustic oscillations in 27 stars from the open cluster M67, we observe\ndeviations of proportionality between small and large separations, which are\ncaused by the influence of the bottom of the convective envelope. These\ndeviations become apparent as the convective envelope penetrates deep into the\nstar during subgiant and red giant evolution, eventually entering an ultra-deep\nregime that leads to the red giant branch luminosity bump. The tight sequence\nof cluster stars, free of large spreads in ages and fundamental properties, is\nessential for revealing the connection between the observed small separations\nand the chemical discontinuities occurring at the bottom of the convective\nenvelope. We use this sequence to show that combining large and small\nseparations can improve estimations of the masses and ages of field stars well\nafter the main sequence.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-02T15:37:26Z"}
{"aid":"http://arxiv.org/abs/2504.01839v1","title":"A Randomized Zeroth-Order Hierarchical Framework for Heterogeneous\n  Federated Learning","summary":"Heterogeneity in federated learning (FL) is a critical and challenging aspect\nthat significantly impacts model performance and convergence. In this paper, we\npropose a novel framework by formulating heterogeneous FL as a hierarchical\noptimization problem. This new framework captures both local and global\ntraining process through a bilevel formulation and is capable of the following:\n(i) addressing client heterogeneity through a personalized learning framework;\n(ii) capturing pre-training process on server's side; (iii) updating global\nmodel through nonstandard aggregation; (iv) allowing for nonidentical local\nsteps; and (v) capturing clients' local constraints. We design and analyze an\nimplicit zeroth-order FL method (ZO-HFL), provided with nonasymptotic\nconvergence guarantees for both the server-agent and the individual\nclient-agents, and asymptotic guarantees for both the server-agent and\nclient-agents in an almost sure sense. Notably, our method does not rely on\nstandard assumptions in heterogeneous FL, such as the bounded gradient\ndissimilarity condition. We implement our method on image classification tasks\nand compare with other methods under different heterogeneous settings.","main_category":"math.OC","categories":"math.OC,cs.LG","published":"2025-04-02T15:44:59Z"}
{"aid":"http://arxiv.org/abs/2504.01888v1","title":"A novel gesture interaction control method for rehabilitation lower\n  extremity exoskeleton","summary":"With the rapid development of Rehabilitation Lower Extremity Robotic\nExoskeletons (RLEEX) technology, significant advancements have been made in\nHuman-Robot Interaction (HRI) methods. These include traditional physical HRI\nmethods that are easily recognizable and various bio-electrical signal-based\nHRI methods that can visualize and predict actions. However, most of these HRI\nmethods are contact-based, facing challenges such as operational complexity,\nsensitivity to interference, risks associated with implantable devices, and,\nmost importantly, limitations in comfort. These challenges render the\ninteraction less intuitive and natural, which can negatively impact patient\nmotivation for rehabilitation. To address these issues, this paper proposes a\nnovel non-contact gesture interaction control method for RLEEX, based on RGB\nmonocular camera depth estimation. This method integrates three key steps:\ndetecting keypoints, recognizing gestures, and assessing distance, thereby\napplying gesture information and augmented reality triggering technology to\ncontrol gait movements of RLEEX. Results indicate that this approach provides a\nfeasible solution to the problems of poor comfort, low reliability, and high\nlatency in HRI for RLEEX platforms. Specifically, it achieves a\ngesture-controlled exoskeleton motion accuracy of 94.11\\% and an average system\nresponse time of 0.615 seconds through non-contact HRI. The proposed\nnon-contact HRI method represents a pioneering advancement in control\ninteractions for RLEEX, paving the way for further exploration and development\nin this field.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.HC","published":"2025-04-02T16:46:01Z"}
{"aid":"http://arxiv.org/abs/2504.01891v1","title":"Multi-stream Physics Hybrid Networks for solving Navier-Stokes equations","summary":"Understanding and solving fluid dynamics equations efficiently remains a\nfundamental challenge in computational physics. Traditional numerical solvers\nand physics-informed neural networks struggle to capture the full range of\nfrequency components in partial differential equation solutions, limiting their\naccuracy and efficiency. Here, we propose the Multi-stream Physics Hybrid\nNetwork, a novel neural architecture that integrates quantum and classical\nlayers in parallel to improve the accuracy of solving fluid dynamics equations,\nnamely Kovasznay flow problem. This approach decomposes the solution into\nseparate frequency components, each predicted by independent Parallel Hybrid\nNetworks, simplifying the training process and enhancing performance. We\nevaluated the proposed model against a comparable classical neural network, the\nMulti-stream Physics Classical Network, in both data-driven and physics-driven\nscenarios. Our results show that the Multi-stream Physics Hybrid Network\nachieves a reduction in root mean square error by 36% for velocity components\nand 41% for pressure prediction compared to the classical model, while using\n24% fewer trainable parameters. These findings highlight the potential of\nhybrid quantum-classical architectures for advancing computational fluid\ndynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph,quant-ph","published":"2025-04-02T16:50:54Z"}
{"aid":"http://arxiv.org/abs/2504.01898v1","title":"Analysis of an Idealized Stochastic Polyak Method and its Application to\n  Black-Box Model Distillation","summary":"We provide a general convergence theorem of an idealized stochastic Polyak\nstep size called SPS$^*$. Besides convexity, we only assume a local expected\ngradient bound, that includes locally smooth and locally Lipschitz losses as\nspecial cases. We refer to SPS$^*$ as idealized because it requires access to\nthe loss for every training batch evaluated at a solution. It is also ideal, in\nthat it achieves the optimal lower bound for globally Lipschitz function, and\nis the first Polyak step size to have an $O(1/\\sqrt{t})$ anytime convergence in\nthe smooth setting. We show how to combine SPS$^*$ with momentum to achieve the\nsame favorable rates for the last iterate. We conclude with several experiments\nto validate our theory, and a more practical setting showing how we can distill\na teacher GPT-2 model into a smaller student model without any hyperparameter\ntuning.","main_category":"cs.LG","categories":"cs.LG,G.1.6","published":"2025-04-02T16:57:39Z"}
{"aid":"http://arxiv.org/abs/2504.01912v1","title":"Open cluster age calibration from colour-magnitude morphological indices\n  using Gaia DR3 data","summary":"Star clusters are crucial for understanding how stars evolve. Their\ncolour-magnitude diagrams show the effects of stellar evolution of\napproximately coeval objects with the same chemical composition. Furthermore,\nthe determination of their astrophysical parameters (age, distance, colour\nexcess and metallicity) together with their spatial distribution provides\ninformation about the structure and the evolution of the Galaxy itself. Using\ndata from the \\textit{Gaia} DR3 and 2MASS catalogues, we develop methodologies\nfor characterizing open clusters. Precise membership lists, mean astrometric\nparameters and radii are obtained. Using photometric data from both data\nsources, we carried out new age calibrations that rely on morphological indices\nbased on colour ($\\Delta BR$) and magnitude ($\\Delta G$) differences between\nthe red clump and the turnoff for a sample of 34 open clusters with ages\ncovering the interval $8.3 < \\log[t({\\rm yr})] < 9.9$. A set of age calibration\nfunctions based on \\textit{Gaia} morphological age indices are determined for\nthe first time. We demonstrate their accuracy, obtaining a mean residual of\n0.06 dex in $\\log[t(yr)]$. Our results also show that stellar evolution models\ntend to predict the difference $\\Delta G$. However, they typically overestimate\nthe difference $\\Delta BR$ for objects younger than $\\log[t({\\rm yr})] = 8.8$.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-02T17:13:23Z"}
{"aid":"http://arxiv.org/abs/2504.01919v1","title":"Bridging the Linguistic Divide: A Survey on Leveraging Large Language\n  Models for Machine Translation","summary":"The advent of Large Language Models (LLMs) has significantly reshaped the\nlandscape of machine translation (MT), particularly for low-resource languages\nand domains that lack sufficient parallel corpora, linguistic tools, and\ncomputational infrastructure. This survey presents a comprehensive overview of\nrecent progress in leveraging LLMs for MT. We analyze techniques such as\nfew-shot prompting, cross-lingual transfer, and parameter-efficient fine-tuning\nthat enable effective adaptation to under-resourced settings. The paper also\nexplores synthetic data generation strategies using LLMs, including\nback-translation and lexical augmentation. Additionally, we compare LLM-based\ntranslation with traditional encoder-decoder models across diverse language\npairs, highlighting the strengths and limitations of each. We discuss\npersistent challenges such as hallucinations, evaluation inconsistencies, and\ninherited biases while also evaluating emerging LLM-driven metrics for\ntranslation quality. This survey offers practical insights and outlines future\ndirections for building robust, inclusive, and scalable MT systems in the era\nof large-scale generative models.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T17:26:40Z"}
{"aid":"http://arxiv.org/abs/2504.01921v1","title":"Client Selection in Federated Learning with Data Heterogeneity and\n  Network Latencies","summary":"Federated learning (FL) is a distributed machine learning paradigm where\nmultiple clients conduct local training based on their private data, then the\nupdated models are sent to a central server for global aggregation. The\npractical convergence of FL is challenged by multiple factors, with the primary\nhurdle being the heterogeneity among clients. This heterogeneity manifests as\ndata heterogeneity concerning local data distribution and latency heterogeneity\nduring model transmission to the server. While prior research has introduced\nvarious efficient client selection methods to alleviate the negative impacts of\neither of these heterogeneities individually, efficient methods to handle\nreal-world settings where both these heterogeneities exist simultaneously do\nnot exist. In this paper, we propose two novel theoretically optimal client\nselection schemes that can handle both these heterogeneities. Our methods\ninvolve solving simple optimization problems every round obtained by minimizing\nthe theoretical runtime to convergence. Empirical evaluations on 9 datasets\nwith non-iid data distributions, 2 practical delay distributions, and\nnon-convex neural network models demonstrate that our algorithms are at least\ncompetitive to and at most 20 times better than best existing baselines.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-02T17:31:15Z"}
{"aid":"http://arxiv.org/abs/2504.01928v1","title":"Is the Reversal Curse a Binding Problem? Uncovering Limitations of\n  Transformers from a Basic Generalization Failure","summary":"Despite their impressive capabilities, LLMs exhibit a basic generalization\nfailure known as the Reversal Curse, where they struggle to learn reversible\nfactual associations. Understanding why this occurs could help identify\nweaknesses in current models and advance their generalization and robustness.\nIn this paper, we conjecture that the Reversal Curse in LLMs is a manifestation\nof the long-standing binding problem in cognitive science, neuroscience and AI.\nSpecifically, we identify two primary causes of the Reversal Curse stemming\nfrom transformers' limitations in conceptual binding: the inconsistency and\nentanglements of concept representations. We perform a series of experiments\nthat support these conjectures. Our exploration leads to a model design based\non JEPA (Joint-Embedding Predictive Architecture) that for the first time\nbreaks the Reversal Curse without side-stepping it with specialized data\naugmentation or non-causal masking, and moreover, generalization could be\nfurther improved by incorporating special memory layers that support\ndisentangled concept representations. We demonstrate that the skill of reversal\nunlocks a new kind of memory integration that enables models to solve\nlarge-scale arithmetic reasoning problems via parametric forward-chaining,\noutperforming frontier LLMs based on non-parametric memory and prolonged\nexplicit reasoning.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-02T17:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.01939v1","title":"Laboratory evaluation of a wearable instrumented headband for rotational\n  head kinematics measurement","summary":"Mild traumatic brain injuries (mTBI) are a highly prevalent condition with\nheterogeneous outcomes between individuals. A key factor governing brain tissue\ndeformation and the risk of mTBI is the rotational kinematics of the head.\nInstrumented mouthguards are a widely accepted method for measuring rotational\nhead motions, owing to their robust sensor-skull coupling. However, wearing\nmouthguards is not feasible in all situations, especially for long-term data\ncollection. Therefore, alternative wearable devices are needed. In this study,\nwe present an improved design and data processing scheme for an instrumented\nheadband. Our instrumented headband utilizes an array of inertial measurement\nunits (IMUs) and a new data-processing scheme based on continuous wavelet\ntransforms to address sources of error in the IMU measurements. The headband\nperformance was evaluated in the laboratory on an anthropomorphic test device,\nwhich was impacted with a soccer ball to replicate soccer heading. When\ncomparing the measured peak rotational velocities (PRV) and peak rotational\naccelerations (PRA) between the reference sensors and the headband for impacts\nto the front of the head, the correlation coefficients (r) were 0.80 and 0.63,\nand the normalized root mean square error (NRMSE) values were 0.20 and 0.28,\nrespectively. However, when considering all impact locations, r dropped to 0.42\nand 0.34 and NRMSE increased to 0.5 and 0.41 for PRV and PRA, respectively.\nThis new instrumented headband improves upon previous headband designs in\nreconstructing the rotational head kinematics resulting from frontal soccer\nball impacts, providing a potential alternative to instrumented mouthguards.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T17:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.02212v1","title":"Decidabilities of local unitary equivalence for entanglement witnesses\n  and states","summary":"The problem of determining whether two states are equivalent by local unitary\n(LU) operations is important for quantum information processing. In this paper\nwe propose an alternative perspective to study this problem by comparing the\ndecidabilities of LU equivalence (also known as LU decidabilities for short)\nbetween entanglement witnesses and states. We introduce a relation between sets\nof Hermitian operators in terms of the LU decidability. Then we compare the LU\ndecidability for the set of entanglement witness to those decidabilities for\nseveral sets of states, and establish a hierarchy on LU decidabilities for\nthese sets. Moreover, we realize that the simultaneous LU (SLU) equivalence\nbetween tuples of mutually orthogonal projectors is crucial to LU equivalent\noperators. We reveal by examples that for two tuples of projectors, the partial\nSLU equivalence cannot ensure the overall SLU equivalence. Generally, we\npresent a necessary and sufficient condition such that two tuples of states are\nSLU equivalent.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T02:05:53Z"}
{"aid":"http://arxiv.org/abs/2504.02237v1","title":"Super diffusive length dependent thermal conductivity in one-dimensional\n  materials with structural defects: longitudinal to transverse phonon\n  scattering leads to $Îº\\propto L^{1/3}$ law","summary":"Structural defects in one-dimensional heat conductors couple longitudinal\n(stretching) and transverse (bending) vibrations. This coupling results in the\nscattering of longitudinal phonons to transverse phonons and backwards. We show\nthat the decay rate of longitudinal phonons due to this scattering scales with\ntheir frequencies as $\\omega^{3/2}$ within the long wavelength limit ($\\omega\n\\rightarrow 0$), which is more efficient scattering compared to the\ntraditionally considered Rayleigh scattering within the longitudinal band\n($\\omega^2$). This scattering results in temperature independent thermal\nconductivity depending on the size as $\\kappa \\propto L^{1/3}$ for sufficiently\nlong materials. This predicted length dependence is observed in nanowires,\nthough the temperature dependence is seen there possibly because of deviations\nfrom pure one-dimensional behavior. The significant effect of interaction of\nlongitudinal phonons with transverse phonons is consistent with the earlier\nobservations of a substantial suppression of thermal energy transport by kinks,\nobviously leading to such interaction, though anharmonic interaction can also\nbe significant.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.dis-nn","published":"2025-04-03T03:08:54Z"}
{"aid":"http://arxiv.org/abs/2504.02241v1","title":"Quantum Deep Sets and Sequences","summary":"This paper introduces the quantum deep sets model, expanding the quantum\nmachine learning tool-box by enabling the possibility of learning variadic\nfunctions using quantum systems. A couple of variants are presented for this\nmodel. The first one focuses on mapping sets to quantum systems through state\nvector averaging: each element of the set is mapped to a quantum state, and the\nquantum state of the set is the average of the corresponding quantum states of\nits elements. This approach allows the definition of a permutation-invariant\nvariadic model. The second variant is useful for ordered sets, i.e., sequences,\nand relies on optimal coherification of tristochastic tensors that implement\nproducts of mixed states: each element of the set is mapped to a density\nmatrix, and the quantum state of the set is the product of the corresponding\ndensity matrices of its elements. Such variant can be relevant in tasks such as\nnatural language processing. The resulting quantum state in any of the variants\nis then processed to realise a function that solves a machine learning task\nsuch as classification, regression or density estimation. Through synthetic\nproblem examples, the efficacy and versatility of quantum deep sets and\nsequences (QDSs) is demonstrated.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-04-03T03:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.02252v1","title":"Adapting World Models with Latent-State Dynamics Residuals","summary":"Simulation-to-reality reinforcement learning (RL) faces the critical\nchallenge of reconciling discrepancies between simulated and real-world\ndynamics, which can severely degrade agent performance. A promising approach\ninvolves learning corrections to simulator forward dynamics represented as a\nresidual error function, however this operation is impractical with\nhigh-dimensional states such as images. To overcome this, we propose ReDRAW, a\nlatent-state autoregressive world model pretrained in simulation and calibrated\nto target environments through residual corrections of latent-state dynamics\nrather than of explicit observed states. Using this adapted world model, ReDRAW\nenables RL agents to be optimized with imagined rollouts under corrected\ndynamics and then deployed in the real world. In multiple vision-based MuJoCo\ndomains and a physical robot visual lane-following task, ReDRAW effectively\nmodels changes to dynamics and avoids overfitting in low data regimes where\ntraditional transfer methods fail.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.RO","published":"2025-04-03T03:41:30Z"}
{"aid":"http://arxiv.org/abs/2504.02255v1","title":"Bipedal Robust Walking on Uneven Footholds: Piecewise Slope LIPM with\n  Discrete Model Predictive Control","summary":"This study presents an enhanced theoretical formulation for bipedal\nhierarchical control frameworks under uneven terrain conditions. Specifically,\nowing to the inherent limitations of the Linear Inverted Pendulum Model (LIPM)\nin handling terrain elevation variations, we develop a Piecewise Slope LIPM\n(PS-LIPM). This innovative model enables dynamic adjustment of the Center of\nMass (CoM) height to align with topographical undulations during single-step\ncycles. Another contribution is proposed a generalized Angular Momentum-based\nLIPM (G-ALIP) for CoM velocity compensation using Centroidal Angular Momentum\n(CAM) regulation. Building upon these advancements, we derive the DCM\nstep-to-step dynamics for Model Predictive Control MPC formulation, enabling\nsimultaneous optimization of step position and step duration. A hierarchical\ncontrol framework integrating MPC with a Whole-Body Controller (WBC) is\nimplemented for bipedal locomotion across uneven stepping stones. The results\nvalidate the efficacy of the proposed hierarchical control framework and the\ntheoretical formulation.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-03T03:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.02261v1","title":"WonderTurbo: Generating Interactive 3D World in 0.72 Seconds","summary":"Interactive 3D generation is gaining momentum and capturing extensive\nattention for its potential to create immersive virtual experiences. However, a\ncritical challenge in current 3D generation technologies lies in achieving\nreal-time interactivity. To address this issue, we introduce WonderTurbo, the\nfirst real-time interactive 3D scene generation framework capable of generating\nnovel perspectives of 3D scenes within 0.72 seconds. Specifically, WonderTurbo\naccelerates both geometric and appearance modeling in 3D scene generation. In\nterms of geometry, we propose StepSplat, an innovative method that constructs\nefficient 3D geometric representations through dynamic updates, each taking\nonly 0.26 seconds. Additionally, we design QuickDepth, a lightweight depth\ncompletion module that provides consistent depth input for StepSplat, further\nenhancing geometric accuracy. For appearance modeling, we develop FastPaint, a\n2-steps diffusion model tailored for instant inpainting, which focuses on\nmaintaining spatial appearance consistency. Experimental results demonstrate\nthat WonderTurbo achieves a remarkable 15X speedup compared to baseline\nmethods, while preserving excellent spatial consistency and delivering\nhigh-quality output.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T04:10:47Z"}
{"aid":"http://arxiv.org/abs/2504.02263v1","title":"MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated\n  Expert Parallelism","summary":"Mixture-of-Experts (MoE) showcases tremendous potential to scale large\nlanguage models (LLMs) with enhanced performance and reduced computational\ncomplexity. However, its sparsely activated architecture shifts feed-forward\nnetworks (FFNs) from being compute-intensive to memory-intensive during\ninference, leading to substantially lower GPU utilization and increased\noperational costs. We present MegaScale-Infer, an efficient and cost-effective\nsystem for serving large-scale MoE models. MegaScale-Infer disaggregates\nattention and FFN modules within each model layer, enabling independent\nscaling, tailored parallelism strategies, and heterogeneous deployment for both\nmodules. To fully exploit disaggregation in the presence of MoE's sparsity,\nMegaScale-Infer introduces ping-pong pipeline parallelism, which partitions a\nrequest batch into micro-batches and shuttles them between attention and FFNs\nfor inference. Combined with distinct model parallelism for each module,\nMegaScale-Infer effectively hides communication overhead and maximizes GPU\nutilization. To adapt to disaggregated attention and FFN modules and minimize\ndata transmission overhead (e.g., token dispatch), MegaScale-Infer provides a\nhigh-performance M2N communication library that eliminates unnecessary\nGPU-to-CPU data copies, group initialization overhead, and GPU synchronization.\nExperimental results indicate that MegaScale-Infer achieves up to 1.90x higher\nper-GPU throughput than state-of-the-art solutions.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-03T04:20:44Z"}
{"aid":"http://arxiv.org/abs/2504.02288v1","title":"FEASE: Shallow AutoEncoding Recommender with Cold Start Handling via\n  Side Features","summary":"User and item cold starts present significant challenges in industrial\napplications of recommendation systems. Supplementing user-item interaction\ndata with metadata is a common solution-but often at the cost of introducing\nadditional biases. In this work, we introduce an augmented EASE model, i.e.\nFEASE, that seamlessly integrates both user and item side information to\naddress these cold start issues. Our straightforward, autoencoder-based method\nproduces a closed-form solution that leverages rich content signals for cold\nitems while refining user representations in data-sparse environments.\nImportantly, our method strikes a balance by effectively recommending cold\nstart items and handling cold start users without incurring extra bias, and it\nmaintains strong performance in warm settings. Experimental results demonstrate\nimproved recommendation accuracy and robustness compared to previous\ncollaborative filtering approaches. Moreover, our model serves as a strong\nbaseline for future comparative studies.","main_category":"cs.IR","categories":"cs.IR,cs.LG","published":"2025-04-03T05:27:55Z"}
{"aid":"http://arxiv.org/abs/2504.02293v1","title":"State-of-the-Art Translation of Text-to-Gloss using mBART : A case study\n  of Bangla","summary":"Despite a large deaf and dumb population of 1.7 million, Bangla Sign Language\n(BdSL) remains a understudied domain. Specifically, there are no works on\nBangla text-to-gloss translation task. To address this gap, we begin by\naddressing the dataset problem. We take inspiration from grammatical rule based\ngloss generation used in Germany and American sign langauage (ASL) and adapt it\nfor BdSL. We also leverage LLM to generate synthetic data and use\nback-translation, text generation for data augmentation. With dataset prepared,\nwe started experimentation. We fine-tuned pretrained mBART-50 and\nmBERT-multiclass-uncased model on our dataset. We also trained GRU, RNN and a\nnovel seq-to-seq model with multi-head attention. We observe significant high\nperformance (ScareBLEU=79.53) with fine-tuning pretrained mBART-50 multilingual\nmodel from Facebook. We then explored why we observe such high performance with\nmBART. We soon notice an interesting property of mBART -- it was trained on\nshuffled and masked text data. And as we know, gloss form has shuffling\nproperty. So we hypothesize that mBART is inherently good at text-to-gloss\ntasks. To find support against this hypothesis, we trained mBART-50 on\nPHOENIX-14T benchmark and evaluated it with existing literature. Our mBART-50\nfinetune demonstrated State-of-the-Art performance on PHOENIX-14T benchmark,\nfar outperforming existing models in all 6 metrics (ScareBLEU = 63.89, BLEU-1 =\n55.14, BLEU-2 = 38.07, BLEU-3 = 27.13, BLEU-4 = 20.68, COMET = 0.624). Based on\nthe results, this study proposes a new paradigm for text-to-gloss task using\nmBART models. Additionally, our results show that BdSL text-to-gloss task can\ngreatly benefit from rule-based synthetic dataset.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T05:47:51Z"}
{"aid":"http://arxiv.org/abs/2504.02304v1","title":"Measurement of LLM's Philosophies of Human Nature","summary":"The widespread application of artificial intelligence (AI) in various tasks,\nalong with frequent reports of conflicts or violations involving AI, has\nsparked societal concerns about interactions with AI systems. Based on\nWrightsman's Philosophies of Human Nature Scale (PHNS), a scale empirically\nvalidated over decades to effectively assess individuals' attitudes toward\nhuman nature, we design the standardized psychological scale specifically\ntargeting large language models (LLM), named the Machine-based Philosophies of\nHuman Nature Scale (M-PHNS). By evaluating LLMs' attitudes toward human nature\nacross six dimensions, we reveal that current LLMs exhibit a systemic lack of\ntrust in humans, and there is a significant negative correlation between the\nmodel's intelligence level and its trust in humans. Furthermore, we propose a\nmental loop learning framework, which enables LLM to continuously optimize its\nvalue system during virtual interactions by constructing moral scenarios,\nthereby improving its attitude toward human nature. Experiments demonstrate\nthat mental loop learning significantly enhances their trust in humans compared\nto persona or instruction prompts. This finding highlights the potential of\nhuman-based psychological assessments for LLM, which can not only diagnose\ncognitive biases but also provide a potential solution for ethical learning in\nartificial intelligence. We release the M-PHNS evaluation code and data at\nhttps://github.com/kodenii/M-PHNS.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:22:19Z"}
{"aid":"http://arxiv.org/abs/2504.02342v1","title":"On the twin-width of near-regular graphs","summary":"Twin-width is a recently introduced graph parameter based on the repeated\ncontraction of near-twins. It has shown remarkable utility in algorithmic and\nstructural graph theory, as well as in finite model theory -- particularly\nsince first-order model checking is fixed-parameter tractable when a witness\ncertifying small twin-width is provided. However, the behavior of twin-width in\nspecific graph classes, particularly cubic graphs, remains poorly understood.\nWhile cubic graphs are known to have unbounded twin-width, no explicit cubic\ngraph of twin-width greater than 4 is known.\n  This paper explores this phenomenon in regular and near-regular graph\nclasses. We show that extremal graphs of bounded degree and high twin-width are\nasymmetric, partly explaining their elusiveness. Additionally, we establish\nbounds for circulant and d-degenerate graphs, and examine strongly regular\ngraphs, which exhibit similar behavior to cubic graphs. Our results include\ndetermining the twin-width of Johnson graphs over 2-sets, and cyclic Latin\nsquare graphs.","main_category":"math.CO","categories":"math.CO,cs.DS","published":"2025-04-03T07:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.02344v1","title":"Boosting End-to-End Database Isolation Checking via Mini-Transactions\n  (Extended Version)","summary":"Transactional isolation guarantees are crucial for database correctness.\nHowever, recent studies have uncovered numerous isolation bugs in production\ndatabases. The common black-box approach to isolation checking stresses\ndatabases with large, concurrent, randomized transaction workloads and verifies\nwhether the resulting execution histories satisfy specified isolation levels.\nFor strong isolation levels such as strict serializability, serializability,\nand snapshot isolation, this approach often incurs significant end-to-end\nchecking overhead during both history generation and verification.\n  We address these inefficiencies through the novel design of Mini-Transactions\n(MTs). MTs are compact, short transactions that execute much faster than\ngeneral workloads, reducing overhead during history generation by minimizing\ndatabase blocking and transaction retries. By leveraging MTs' read-modify-write\npattern, we develop highly efficient algorithms to verify strong isolation\nlevels in linear or quadratic time. Despite their simplicity, MTs are\nsemantically rich and effectively capture common isolation anomalies described\nin the literature.\n  We implement our verification algorithms and an MT workload generator in a\ntool called MTC. Experimental results show that MTC outperforms\nstate-of-the-art tools in both history generation and verification. Moreover,\nMTC can detect bugs across various isolation levels in production databases\nwhile maintaining the effectiveness of randomized testing with general\nworkloads, making it a cost-effective solution for black-box isolation\nchecking.","main_category":"cs.DB","categories":"cs.DB,cs.SE","published":"2025-04-03T07:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.02353v1","title":"Interval Graphs are Reconstructible","summary":"A graph is reconstructible if it is determined up to isomorphism by the\nmultiset of its proper induced subgraphs. The reconstruction conjecture\npostulates that every graph of order at least 3 is reconstructible. We show\nthat interval graphs with at least three vertices are reconstructible. For this\npurpose we develop a technique to handle separations in the context of\nreconstruction. This resolves a major roadblock to using graph structure theory\nin the context of reconstruction. To apply our novel technique, we also develop\na resilient combinatorial structure theory for interval graphs. A consequence\nof our result is that interval graphs can be reconstructed in polynomial time.","main_category":"math.CO","categories":"math.CO,cs.DM,cs.DS","published":"2025-04-03T07:42:05Z"}
{"aid":"http://arxiv.org/abs/2504.02383v1","title":"Reinforcement Learning for Solving the Pricing Problem in Column\n  Generation: Applications to Vehicle Routing","summary":"In this paper, we address the problem of Column Generation (CG) using\nReinforcement Learning (RL). Specifically, we use a RL model based on the\nattention-mechanism architecture to find the columns with most negative reduced\ncost in the Pricing Problem (PP). Unlike previous Machine Learning (ML)\napplications for CG, our model deploys an end-to-end mechanism as it\nindependently solves the pricing problem without the help of any heuristic. We\nconsider a variant of Vehicle Routing Problem (VRP) as a case study for our\nmethod. Through a set of experiments where our method is compared against a\nDynamic Programming (DP)-based heuristic for solving the PP, we show that our\nmethod solves the linear relaxation up to a reasonable objective gap within 9%\nin significantly shorter running times, up to over 300 times faster for\ninstances with 100 customers.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T08:22:19Z"}
{"aid":"http://arxiv.org/abs/2504.02386v1","title":"VoiceCraft-Dub: Automated Video Dubbing with Neural Codec Language\n  Models","summary":"We present VoiceCraft-Dub, a novel approach for automated video dubbing that\nsynthesizes high-quality speech from text and facial cues. This task has broad\napplications in filmmaking, multimedia creation, and assisting voice-impaired\nindividuals. Building on the success of Neural Codec Language Models (NCLMs)\nfor speech synthesis, our method extends their capabilities by incorporating\nvideo features, ensuring that synthesized speech is time-synchronized and\nexpressively aligned with facial movements while preserving natural prosody. To\ninject visual cues, we design adapters to align facial features with the NCLM\ntoken space and introduce audio-visual fusion layers to merge audio-visual\ninformation within the NCLM framework. Additionally, we curate CelebV-Dub, a\nnew dataset of expressive, real-world videos specifically designed for\nautomated video dubbing. Extensive experiments show that our model achieves\nhigh-quality, intelligible, and natural speech synthesis with accurate lip\nsynchronization, outperforming existing methods in human perception and\nperforming favorably in objective evaluations. We also adapt VoiceCraft-Dub for\nthe video-to-speech task, demonstrating its versatility for various\napplications.","main_category":"cs.CV","categories":"cs.CV,eess.AS","published":"2025-04-03T08:24:47Z"}
{"aid":"http://arxiv.org/abs/2504.02399v1","title":"Bayesian eco-evolutionary game dynamics","summary":"The symbiotic relationship between the frameworks of classical game theory\nand evolutionary game theory is well-established. However, evolutionary game\ntheorists have mostly tapped into the classical game of complete information\nwhere players are completely informed of all other players' payoffs. Of late,\nthere is a surge of interest in eco-evolutionary interactions where the\nenvironment's state is changed by the players' actions which, in turn, are\ninfluenced by the changing environment. However, in real life, the information\nabout the true environmental state must pass through some noisy channel (like\nusually imperfect sensory apparatus of the players) before it is perceived by\nthe players: The players naturally are prone to sometimes perceive the true\nstate erroneously. Given the uncertain perceived environment, the players may\nadopt bet-hedging kind of strategies in which they play different actions in\ndifferent perceptions. In a population of such ill-informed players, a player\nwould be confused about the information state of her opponent, and an\nincomplete information situation akin to a Bayesian game surfaces. In short, we\ncontemplate possibility of natural emergence of symbiotic relationship between\nthe frameworks of Bayesian games and eco-evolutionary games when the players\nare equipped with inefficient sensory apparatus. Herein, we illustrate this\nconnection using a setup of infinitely large, well-mixed population of players\nequipped with two actions for exploiting a resource (the environment) at two\ndifferent rates so that the resource state evolves accordingly. The state of\nthe resource impacts every player's decision of playing particular action. We\ninvestigate continuous state environment in the presence of a Gaussian noisy\nchannel. Employing the formalism of replicator dynamics, we find that noisy\ninformation can be effective in preventing resource from going extinct.","main_category":"q-bio.PE","categories":"q-bio.PE,econ.TH,nlin.CD,physics.bio-ph","published":"2025-04-03T08:47:18Z"}
{"aid":"http://arxiv.org/abs/2504.02414v1","title":"Effective field theory of Plasmas in Podolsky corrected Photonic field","summary":"A theory for abelian plasma permeated by photons has been developed\nconsidering QED (quantum electrodynamics) generalized in Podolsky\nelectrodynamics framework for consideration of higher order terms in\nelectromagnetic theory. The theory traces out photonic degrees of freedom in\nplasma and accounts for plasma dynamics mediated by photons by calculated\neffective Hamiltonian. New modes of propagation have been predicted along with\nsuppression of fields and collective behaviour. Non-Markovian behaviour is also\ndiscovered for plasma states and interactions in finite plasma system. This\nfinds applicability in solid-state plasma, plasma confinement of magnetic and\ninertial nature, and laser-plasma interaction when theory is reduced to local\ninteractions.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T09:10:19Z"}
{"aid":"http://arxiv.org/abs/2504.02432v1","title":"Robust Randomized Low-Rank Approximation with Row-Wise Outlier Detection","summary":"Robust low-rank approximation under row-wise adversarial corruption can be\nachieved with a single pass, randomized procedure that detects and removes\noutlier rows by thresholding their projected norms. We propose a scalable,\nnon-iterative algorithm that efficiently recovers the underlying low-rank\nstructure in the presence of row-wise adversarial corruption. By first\ncompressing the data with a Johnson Lindenstrauss projection, our approach\npreserves the geometry of clean rows while dramatically reducing\ndimensionality. Robust statistical techniques based on the median and median\nabsolute deviation then enable precise identification and removal of outlier\nrows with abnormally high norms. The subsequent rank-k approximation achieves\nnear-optimal error bounds with a one pass procedure that scales linearly with\nthe number of observations. Empirical results confirm that combining random\nsketches with robust statistics yields efficient, accurate decompositions even\nin the presence of large fractions of corrupted rows.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-03T09:43:27Z"}
{"aid":"http://arxiv.org/abs/2504.02444v1","title":"Isospectral oscillators as a resource for quantum information processing","summary":"We address quantum systems isospectral to the harmonic oscillator, as those\nfound within the framework of supersymmetric quantum mechanics, as potential\nresources for continuous variable quantum information. These deformed\noscillator potentials share the equally spaced energy levels of the shifted\nharmonic oscillator but differ significantly in that they are non-harmonic.\nConsequently, their ground states and thermal equilibrium states are no longer\nGaussian and exhibit non-classical properties. We quantify their\nnon-Gaussianity and evaluate their non-classicality using various measures,\nincluding quadrature squeezing, photon number squeezing, Wigner function\nnegativity, and quadrature coherence scale. Additionally, we employ quantum\nestimation theory to identify optimal measurement strategies and establish\nultimate precision bounds for inferring the deformation parameter. Our findings\nprove that quantum systems isospectral to the harmonic oscillator may represent\npromising platforms for quantum information with continuous variables. In turn,\nnon-Gaussian and non-classical stationary states may be obtained and these\nfeatures persist at non-zero temperature.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T10:00:01Z"}
{"aid":"http://arxiv.org/abs/2504.02450v1","title":"CHARMS: Cognitive Hierarchical Agent with Reasoning and Motion Styles","summary":"To address the current challenges of low intelligence and simplistic vehicle\nbehavior modeling in autonomous driving simulation scenarios, this paper\nproposes the Cognitive Hierarchical Agent with Reasoning and Motion Styles\n(CHARMS). The model can reason about the behavior of other vehicles like a\nhuman driver and respond with different decision-making styles, thereby\nimproving the intelligence and diversity of the surrounding vehicles in the\ndriving scenario. By introducing the Level-k behavioral game theory, the paper\nmodels the decision-making process of human drivers and employs deep\nreinforcement learning to train the models with diverse decision styles,\nsimulating different reasoning approaches and behavioral characteristics.\nBuilding on the Poisson cognitive hierarchy theory, this paper also presents a\nnovel driving scenario generation method. The method controls the proportion of\nvehicles with different driving styles in the scenario using Poisson and\nbinomial distributions, thus generating controllable and diverse driving\nenvironments. Experimental results demonstrate that CHARMS not only exhibits\nsuperior decision-making capabilities as ego vehicles, but also generates more\ncomplex and diverse driving scenarios as surrounding vehicles. We will release\ncode for CHARMS at https://github.com/WUTAD-Wjy/CHARMS.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-03T10:15:19Z"}
{"aid":"http://arxiv.org/abs/2504.02459v1","title":"A Physics-Informed Meta-Learning Framework for the Continuous Solution\n  of Parametric PDEs on Arbitrary Geometries","summary":"In this work, we introduce implicit Finite Operator Learning (iFOL) for the\ncontinuous and parametric solution of partial differential equations (PDEs) on\narbitrary geometries. We propose a physics-informed encoder-decoder network to\nestablish the mapping between continuous parameter and solution spaces. The\ndecoder constructs the parametric solution field by leveraging an implicit\nneural field network conditioned on a latent or feature code. Instance-specific\ncodes are derived through a PDE encoding process based on the second-order\nmeta-learning technique. In training and inference, a physics-informed loss\nfunction is minimized during the PDE encoding and decoding. iFOL expresses the\nloss function in an energy or weighted residual form and evaluates it using\ndiscrete residuals derived from standard numerical PDE methods. This approach\nresults in the backpropagation of discrete residuals during both training and\ninference.\n  iFOL features several key properties: (1) its unique loss formulation\neliminates the need for the conventional encode-process-decode pipeline\npreviously used in operator learning with conditional neural fields for PDEs;\n(2) it not only provides accurate parametric and continuous fields but also\ndelivers solution-to-parameter gradients without requiring additional loss\nterms or sensitivity analysis; (3) it can effectively capture sharp\ndiscontinuities in the solution; and (4) it removes constraints on the geometry\nand mesh, making it applicable to arbitrary geometries and spatial sampling\n(zero-shot super-resolution capability). We critically assess these features\nand analyze the network's ability to generalize to unseen samples across both\nstationary and transient PDEs. The overall performance of the proposed method\nis promising, demonstrating its applicability to a range of challenging\nproblems in computational mechanics.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T10:24:00Z"}
{"aid":"http://arxiv.org/abs/2504.02483v1","title":"Robust direction-dependent gain-calibration of beam-modelling errors far\n  from the target field","summary":"Many astronomical questions require deep, wide-field observations at low\nradio frequencies. Phased arrays like LOFAR and SKA-low are designed for this,\nbut have inherently unstable element gains, leading to time, frequency and\ndirection-dependent gain errors. Precise direction-dependent calibration of\nobservations is therefore key to reaching the highest possible dynamic range.\nMany tools for direction-dependent calibration utilise sky and beam models to\ninfer gains. However, these calibration tools struggle with precision\ncalibration for relatively bright (e.g. A-team) sources far from the beam\ncentre. Therefore, the point-spread-function of these sources can potentially\nobscure a faint signal of interest. We show that, and why, the assumption of a\nsmooth gain solution per station fails for realistic radio interferometers, and\nhow this affects gain-calibration results. Subsequently, we introduce an\nimprovement for smooth spectral gain constraints for direction-dependent\ngain-calibration algorithms, in which the level of regularisation is weighted\nby the expected station response to the sky model. We test this method using\ndirection-dependent calibration method DDECal and physically-motivated beam\nmodelling errors for LOFAR-HBA stations. The new method outperforms the\nstandard method for various calibration settings near nulls in the beam, and\nmatches the standard inverse-variance-weighted method's performance for the\nremainder of the data. The proposed method is especially effective for short\nbaselines, both in visibility and image space. Improved direction-dependent\ngain-calibration is critical for future high-precision SKA-low observations,\nwhere higher sensitivity, increased antenna beam complexity, and mutual\ncoupling call for better off-axis source subtraction, which may not be achieved\nthrough improved beam models alone.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO","published":"2025-04-03T11:07:25Z"}
{"aid":"http://arxiv.org/abs/2504.02484v1","title":"Bochner-Riesz commutators on MÃ©tivier groups: boundedness and\n  compactness","summary":"In this paper, we prove the boundedness and compactness properties of\nBochner-Riesz commutator associated to the sub-Laplacians on M\\'etivier groups.\nWe show that the smoothness parameter can be expressed in terms of the\ntopological dimension rather than the homogeneous dimension of the M\\'etivier\ngroups.","main_category":"math.CA","categories":"math.CA","published":"2025-04-03T11:07:30Z"}
{"aid":"http://arxiv.org/abs/2504.02510v1","title":"A complimentary impedance spectroscopy biosensing method with graphene","summary":"We present a method where a bioactive functional layer on an electrically\nconductive thin film with high sheet resistance can be effectively used for\ncomplementary electrochemical impedance spectroscopy biosensing. The functional\nlayer's properties, such as double-layer capacitance and charge-transfer\nresistance, influence the complex impedance of the thin film in direct contact\nwith the layer. These measurements can be performed using a simple\nlow-frequency setup with a lock-in amplifier. When graphene is used as the\nresistive thin film, the signal may also include contributions from graphene's\nquantum capacitance, which is sensitive to charge transfer to and from the\ngraphene. Unlike in traditional graphene biosensors, changes in electrolyte\nproperties over time, such as those caused by the dissolution of ambient gases,\ndo not significantly affect AC measurements. This technique supports biosensor\nminiaturization, ensures stable operation, and provides reliable biomarker\ndetection with a high signal-to-noise ratio.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph,physics.bio-ph","published":"2025-04-03T11:52:55Z"}
{"aid":"http://arxiv.org/abs/2504.02513v1","title":"Adaptive Bivariate Quarklet Tree Approximation via Anisotropic Tensor\n  Quarklets","summary":"This paper deals with near-best approximation of a given bivariate function\nusing elements of quarkonial tensor frames. For that purpose we apply\nanisotropic tensor products of the univariate B-spline quarklets introduced\naround 2017 by Dahlke, Keding and Raasch. We introduce the concept of bivariate\nquarklet trees and develop an adaptive algorithm which allows for generalized\nhp-approximation of a given bivariate function by selected frame elements. It\nis proved that this algorithm is near-best, which means that as long as some\nstandard conditions concerning local errors are fulfilled it provides an\napproximation with an error close to that one of the best possible quarklet\ntree approximation. For this algorithm the complexity is investigated.\nMoreover, we use our techniques to approximate a bivariate test function with\ninverse-exponential rates of convergence. It can be expected that the results\npresented in this paper serve as important building block for the design of\nadaptive wavelet-hp-methods for solving PDEs in the bivariate setting with very\ngood convergence properties.","main_category":"math.NA","categories":"math.NA,cs.NA,math.FA","published":"2025-04-03T11:55:32Z"}
{"aid":"http://arxiv.org/abs/2504.02524v1","title":"SelfMedHPM: Self Pre-training With Hard Patches Mining Masked\n  Autoencoders For Medical Image Segmentation","summary":"In recent years, deep learning methods such as convolutional neural network\n(CNN) and transformers have made significant progress in CT multi-organ\nsegmentation. However, CT multi-organ segmentation methods based on masked\nimage modeling (MIM) are very limited. There are already methods using MAE for\nCT multi-organ segmentation task, we believe that the existing methods do not\nidentify the most difficult areas to reconstruct. To this end, we propose a MIM\nself-training framework with hard patches mining masked autoencoders for CT\nmulti-organ segmentation tasks (selfMedHPM). The method performs ViT\nself-pretraining on the training set of the target data and introduces an\nauxiliary loss predictor, which first predicts the patch loss and determines\nthe location of the next mask. SelfMedHPM implementation is better than various\ncompetitive methods in abdominal CT multi-organ segmentation and body CT\nmulti-organ segmentation. We have validated the performance of our method on\nthe Multi Atlas Labeling Beyond The Cranial Vault (BTCV) dataset for abdomen\nmult-organ segmentation and the SinoMed Whole Body (SMWB) dataset for body\nmulti-organ segmentation tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:28:21Z"}
{"aid":"http://arxiv.org/abs/2504.02542v1","title":"Audio-visual Controlled Video Diffusion with Masked Selective State\n  Spaces Modeling for Natural Talking Head Generation","summary":"Talking head synthesis is vital for virtual avatars and human-computer\ninteraction. However, most existing methods are typically limited to accepting\ncontrol from a single primary modality, restricting their practical utility. To\nthis end, we introduce \\textbf{ACTalker}, an end-to-end video diffusion\nframework that supports both multi-signals control and single-signal control\nfor talking head video generation. For multiple control, we design a parallel\nmamba structure with multiple branches, each utilizing a separate driving\nsignal to control specific facial regions. A gate mechanism is applied across\nall branches, providing flexible control over video generation. To ensure\nnatural coordination of the controlled video both temporally and spatially, we\nemploy the mamba structure, which enables driving signals to manipulate feature\ntokens across both dimensions in each branch. Additionally, we introduce a\nmask-drop strategy that allows each driving signal to independently control its\ncorresponding facial region within the mamba structure, preventing control\nconflicts. Experimental results demonstrate that our method produces\nnatural-looking facial videos driven by diverse signals and that the mamba\nlayer seamlessly integrates multiple driving modalities without conflict.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T12:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.02556v1","title":"Superconductivity in the Medium-Entropy/High-Entropy Re-based Alloys\n  with a Non-Centrosymmetric $Î±$-Mn Lattice","summary":"Medium or high-entropy alloys (MEAs-HEAs) and rhenium-based compounds with a\nnon-centrosymmetric (NC) structure have received a lot of attention for\noffering a fertile soil in search for unconventional superconductivity. Here,\nfive previously unreported NC Re-based MEA-HEA superconductors with an\n$\\alpha$-Mn lattice are successfully synthesized, with their superconducting\ntransition temperatures (Tcs) ranging from 4 to 5 K. An increase in the\nsuperconducting transition temperature (Tc) can be achieved by modulating the\nvalence electron count (VEC) through compositional adjustments. Magnetization\nmeasurements confirm that all the synthesized Re-based MEA-HEAs are bulk\ntype-II superconductors. Specific heat analysis reveals that the\nsuperconducting state of these HEAs can be well described by a single-gap\ns-wave model. Our results show that the Kadowaki-Woods ratio of these\n$\\alpha$-Mn MEA/HEA superconductors are close to the typical value of heavy\nfermion compounds, suggesting the existence of strong electronic correlation.\nThese findings provide promising material platforms to study the role of high\ndisorder in the origin of superconductivity in the NC MEAs-HEAs.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-03T13:12:45Z"}
{"aid":"http://arxiv.org/abs/2504.02559v1","title":"Leveraging LLM For Synchronizing Information Across Multilingual Tables","summary":"The vast amount of online information today poses challenges for non-English\nspeakers, as much of it is concentrated in high-resource languages such as\nEnglish and French. Wikipedia reflects this imbalance, with content in\nlow-resource languages frequently outdated or incomplete. Recent research has\nsought to improve cross-language synchronization of Wikipedia tables using\nrule-based methods. These approaches can be effective, but they struggle with\ncomplexity and generalization. This paper explores large language models (LLMs)\nfor multilingual information synchronization, using zero-shot prompting as a\nscalable solution. We introduce the Information Updation dataset, simulating\nthe real-world process of updating outdated Wikipedia tables, and evaluate LLM\nperformance. Our findings reveal that single-prompt approaches often produce\nsuboptimal results, prompting us to introduce a task decomposition strategy\nthat enhances coherence and accuracy. Our proposed method outperforms existing\nbaselines, particularly in Information Updation (1.79%) and Information\nAddition (20.58%), highlighting the model strength in dynamically updating and\nenriching data across architectures","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T13:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.02629v1","title":"An efficient and energy-stable IMEX splitting scheme for dispersed\n  multiphase flows","summary":"Volume-averaged Navier--Stokes equations are used in various applications to\nmodel systems with two or more interpenetrating phases. Each fluid obeys its\nown momentum and mass equations, and the phases are typically coupled via drag\nforces and a shared pressure. Monolithic solvers can therefore be very\nexpensive and difficult to implement. On the other hand, designing robust\nsplitting schemes requires making both pressure and drag forces explicit\nwithout sacrificing temporal stability. In this context, we derive a new\nfirst-order pressure-correction method based on the incompressibility of the\nmean velocity field, combined with an explicit treatment of the drag forces.\nFurthermore, the convective terms are linearised using extrapolated velocities,\nwhile the viscous terms are treated semi-implicitly. This gives us an\nimplicit-explicit (IMEX) method that is very robust not only due to its\nunconditional energy stability, but also because it does not require any type\nof fixed-point iterations. Each time step involves only linear, scalar\ntransport equations and a single Poisson problem as building blocks, thereby\noffering both efficiency and simplicity. We rigorously prove temporal stability\nwithout any time-step size restrictions, and the theory is confirmed through\ntwo-phase numerical examples.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-03T14:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.02630v1","title":"Grammar-based Ordinary Differential Equation Discovery","summary":"The understanding and modeling of complex physical phenomena through\ndynamical systems has historically driven scientific progress, as it provides\nthe tools for predicting the behavior of different systems under diverse\nconditions through time. The discovery of dynamical systems has been\nindispensable in engineering, as it allows for the analysis and prediction of\ncomplex behaviors for computational modeling, diagnostics, prognostics, and\ncontrol of engineered systems. Joining recent efforts that harness the power of\nsymbolic regression in this domain, we propose a novel framework for the\nend-to-end discovery of ordinary differential equations (ODEs), termed\nGrammar-based ODE Discovery Engine (GODE). The proposed methodology combines\nformal grammars with dimensionality reduction and stochastic search for\nefficiently navigating high-dimensional combinatorial spaces. Grammars allow us\nto seed domain knowledge and structure for both constraining, as well as,\nexploring the space of candidate expressions. GODE proves to be more sample-\nand parameter-efficient than state-of-the-art transformer-based models and to\ndiscover more accurate and parsimonious ODE expressions than both genetic\nprogramming- and other grammar-based methods for more complex inference tasks,\nsuch as the discovery of structural dynamics. Thus, we introduce a tool that\ncould play a catalytic role in dynamics discovery tasks, including modeling,\nsystem identification, and monitoring tasks.","main_category":"cs.LG","categories":"cs.LG,cs.CE,cs.SC","published":"2025-04-03T14:28:13Z"}
{"aid":"http://arxiv.org/abs/2504.02675v1","title":"Cybersickness Assessment Framework(TestBed): Towards a Standardization\n  of Experiments","summary":"Investigating cybersickness (CS) in virtual reality (VR) often requires\nsignificant resources to create the VR environment and manage other\nexperiment-related aspects. Additionally, slight differences in VR content\nacross studies can lead to conflicting results. To address these challenges, we\npropose a standardized assessment framework to facilitate cybersickness\nresearch. The main goal is to enable consistent and comparable CS-related\nexperiments. By establishing this common foundation, researchers can better\nevaluate and compare the impact of various factors on cybersickness. We provide\na comprehensive explanation of the conceptual designs, detail the technical\nimplementation, and offer instructions for using the proposed framework.\nLastly, we conclude by discussing the limitations and potential avenues for\nfuture development.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:15:10Z"}
{"aid":"http://arxiv.org/abs/2504.02683v1","title":"Probing patchy reionisation with JWST: IGM opacity constraints from the\n  Lyman-$Î±$ forest of galaxies in legacy extragalactic fields","summary":"We present the first characterization of the Gunn-Peterson trough in\nhigh-redshift galaxies using public JWST NIRSpec spectroscopy. This enables us\nto derive the first galaxy-based IGM opacity measurements at the end of\nreionisation. Using galaxy spectra has several advantages over quasar spectra:\nit enables measurements of the IGM opacity in any extragalactic field over a\ncontinuous redshift range $4\\lesssim z\\lesssim 7$, as well as measurements of\nthe intrinsic Lyman-$\\beta$ opacity. Our novel constraints are in good\nagreement with state-of-the-art ground-based quasar Lyman-$\\alpha$ forest\nobservations, and will become competitive as the number of JWST $z>5$ galaxy\nspectra rapidly increases. We also provide the first constraints on the\nuncontaminated Lyman-$\\beta$ opacity at $5<z<6$. Finally, we demonstrate the\npower of JWST to connect the ionisation state of the IGM to the sources of\nreionisation in a single extragalactic field. We show that a previously\nreported galaxy overdensity and an excess of Lyman-$\\alpha$ emitters detected\nwith JWST in GOODS-South at $z=5.8-5.9$ coincides with an anomalously low IGM\nopacity to Lyman-$\\alpha$ at this redshift. The local photo-ionisation rate\nexcess can be fully accounted for by the cumulative ionising output of\n$M_{\\rm{UV}}\\lesssim -10$ galaxies in the overdensity, provided they have\n$\\log_{10}\\langle \\xi_{\\rm{ion}} f_{\\rm{esc}} / \\ [\\rm{erg}^{-1}\\rm{Hz}]\\rangle\n= 24.7$ (or equivalently $\\log_{10}\\xi_{\\rm{ion}} / \\\n[\\rm{erg}^{-1}\\rm{Hz}]=25.4$ and $f_{\\rm{esc}}=20\\%$). Overall, this\nbreakthrough offers a new way to connect the galaxy large-scale structure to\nthe state of the IGM, potentially enabling us to precisely identify the sources\nof reionisation.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-03T15:24:01Z"}
{"aid":"http://arxiv.org/abs/2504.02698v1","title":"SCMPPI: Supervised Contrastive Multimodal Framework for Predicting\n  Protein-Protein Interactions","summary":"Protein-Protein Interaction (PPI) prediction is a key task in uncovering\ncellular functional networks and disease mechanisms. However, traditional\nexperimental methods are time-consuming and costly, and existing computational\nmodels face challenges in cross-modal feature fusion, robustness, and\nfalse-negative suppression. In this paper, we propose a novel supervised\ncontrastive multimodal framework, SCMPPI, for PPI prediction. By integrating\nprotein sequence features (AAC, DPC, CKSAAP-ESMC) with PPI network topology\ninformation (Node2Vec graph embedding), and combining an improved supervised\ncontrastive learning strategy, SCMPPI significantly enhances PPI prediction\nperformance. For the PPI task, SCMPPI introduces a negative sample filtering\nmechanism and modifies the contrastive loss function, effectively optimizing\nmultimodal features. Experiments on eight benchmark datasets, including yeast,\nhuman, and H.pylori, show that SCMPPI outperforms existing state-of-the-art\nmethods (such as DF-PPI and TAGPPI) in key metrics such as accuracy ( 98.01%)\nand AUC (99.62%), and demonstrates strong generalization in cross-species\nprediction (AUC > 99% on multi-species datasets). Furthermore, SCMPPI has been\nsuccessfully applied to CD9 networks, the Wnt pathway, and cancer-specific\nnetworks, providing a reliable tool for disease target discovery. This\nframework also offers a new paradigm for multimodal biological information\nfusion and contrastive learning in collaborative optimization for various\ncombined predictions.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.QM","published":"2025-04-03T15:34:02Z"}
{"aid":"http://arxiv.org/abs/2504.02702v1","title":"Background-Enhanced Axion Force by Axion Dark Matter","summary":"We investigate the influence of axion dark matter as a background on the\nspin-independent axion forces between nucleons. Notably, we find that the\npotential for axion forces scales from $1/r^3$ in a vacuum-only context to\n$1/r$ when the background effect is considered. Also, the magnitude of the\naxion force is substantially amplified in proportion to the number density of\naxion DM particles. These enhancements significantly improve the constraints on\nthe axion decay constant by several orders of magnitude, across a broad range\nof axion masses, based on the fifth-force experiments such as the Casimir-less\nand torsion balance tests. This suggests that such experiments are more\neffective than previously understood in detecting axions.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T15:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.02707v1","title":"Symplectic techniques for stochastic differential equations on reductive\n  Lie groups with applications to Langevin diffusions","summary":"We show how Langevin diffusions can be interpreted in the context of\nstochastic Hamiltonian systems with structure-preserving noise and dissipation\non reductive Lie groups. Reductive Lie groups provide the setting in which the\nLie group structure is compatible with Riemannian structures, via the existence\nof bi-invariant metrics. This structure allows for the explicit construction of\nRiemannian Brownian motion via symplectic techniques, which permits the study\nof Langevin diffusions with noise in the position coordinate as well as\nLangevin diffusions with noise in both momentum and position.","main_category":"math.PR","categories":"math.PR","published":"2025-04-03T15:44:05Z"}
{"aid":"http://arxiv.org/abs/2504.02734v1","title":"Monitored Fluctuating Hydrodynamics","summary":"We introduce a hydrodynamic framework for describing monitored classical\nstochastic processes. We study the conditional ensembles for these monitored\nprocesses -- i.e., we compute spacetime correlation functions conditioned on a\nfixed, typical measurement record. In the presence of global symmetries we show\nthat these conditional ensembles can undergo measurement-induced ``sharpening''\nphase transitions as a function of the monitoring rate; moreover, even weak\nmonitoring can give rise to novel critical phases, derived entirely from a\nclassical perspective. We give a simple hydrodynamic derivation of the known\ncharge-sharpening transition for diffusive many-body quantum systems. We show\nthat although the unmonitored symmetric and asymmetric exclusion processes are\nin different universality classes of transport, their conditional ensembles\nflow to the same fixed point with emergent relativistic invariance under\nmonitoring. On the other hand, weakly monitored systems with non-Abelian\nsymmetries enter a novel strongly coupled fixed point with non-trivial\ndynamical exponent, which we characterize. Our formalism naturally accounts for\nmonitoring general observables, such as currents or density gradients, and\nallows for a direct calculation of information-theoretic diagnostics of\nsharpening transitions, including the Shannon entropy of the measurement\nrecord.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,quant-ph","published":"2025-04-03T16:19:18Z"}
{"aid":"http://arxiv.org/abs/2504.02759v1","title":"Production of protons, deuterons and tritons in argon-nucleus\n  interactions at 3.2 AGeV","summary":"Results of the BM@N experiment at the Nuclotron/NICA complex on the\nproduction of protons, deuterons and tritons in interactions of an argon beam\nof 3.2 AGeV with fixed targets of C, Al, Cu, Sn and Pb are presented.\nTransverse mass spectra, rapidity distributions and multiplicities of protons,\ndeuterons and tritons are measured. The results are treated within a\ncoalescence approach and compared with predictions of theoretical models and\nwith other measurements","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-03T16:54:26Z"}
{"aid":"http://arxiv.org/abs/2504.02767v1","title":"How Deep Do Large Language Models Internalize Scientific Literature and\n  Citation Practices?","summary":"The spread of scientific knowledge depends on how researchers discover and\ncite previous work. The adoption of large language models (LLMs) in the\nscientific research process introduces a new layer to these citation practices.\nHowever, it remains unclear to what extent LLMs align with human citation\npractices, how they perform across domains, and may influence citation\ndynamics. Here, we show that LLMs systematically reinforce the Matthew effect\nin citations by consistently favoring highly cited papers when generating\nreferences. This pattern persists across scientific domains despite significant\nfield-specific variations in existence rates, which refer to the proportion of\ngenerated references that match existing records in external bibliometric\ndatabases. Analyzing 274,951 references generated by GPT-4o for 10,000 papers,\nwe find that LLM recommendations diverge from traditional citation patterns by\npreferring more recent references with shorter titles and fewer authors.\nEmphasizing their content-level relevance, the generated references are\nsemantically aligned with the content of each paper at levels comparable to the\nground truth references and display similar network effects while reducing\nauthor self-citations. These findings illustrate how LLMs may reshape citation\npractices and influence the trajectory of scientific discovery by reflecting\nand amplifying established trends. As LLMs become more integrated into the\nscientific research process, it is important to understand their role in\nshaping how scientific communities discover and build upon prior work.","main_category":"cs.DL","categories":"cs.DL,cs.AI,cs.LG,cs.SI","published":"2025-04-03T17:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.02787v1","title":"A 3D view of dwarf galaxies with Gaia and VLT/FLAMES II. The Sextans\n  dwarf spheroidal","summary":"The Sextans dwarf spheroidal galaxy has been challenging to study in a\ncomprehensive way as it is highly extended on the sky, with an uncertain but\nlarge tidal radius of between 80-160 arcminutes (or 3-4kpc), and an extremely\nlow central surface brightness of SigmaV = 26.2 mag/arcsec2. Here we present a\nnew homogeneous survey of 41 VLT/FLAMES multi-fibre spectroscopic pointings\nthat contain 2108 individual spectra, and combined with Gaia DR3 photometry and\nastrometry we present v-los measurements for 333 individual Red Giant Branch\nstars that are consistent with membership in the Sextans dwarf spheroidal\ngalaxy. In addition, we provide the metallicity, [Fe/H], determined from the\ntwo strongest CaII triplet lines, for 312 of these stars. We look again at the\nglobal characteristics of Sextans, deriving a mean line-of-sight velocity of\n<v-los> = +227.1km/s and a mean metallicity of <[Fe/H]> = -2.37. The\nmetallicity distribution is clearly double peaked, with the highest peak at\n[Fe/H]= -2.81 and another broader peak at [Fe/H]= -2.09. Thus it appears that\nSextans hosts two populations and the superposition leads to a radial variation\nin the mean metallicity, with the more metal rich population being centrally\nconcentrated. In addition there is an intriguing group of 9 probable members in\nthe outer region of Sextans at higher [Fe/H] than the mean in this region. If\nthis group could be confirmed as members they would eliminate the metallicity\ngradient. We also look again at the Colour-Magnitude Diagram of the resolved\nstellar population in Sextans. We also look again at the relation between\nSextans and the intriguingly nearby globular cluster, Pal3. The global\nproperties of Sextans have not changed significantly compared to previous\nstudies, but they are now more precise, and the sample of known members in the\nouter regions is now more complete.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T17:31:23Z"}
{"aid":"http://arxiv.org/abs/2504.02789v1","title":"A Framework for Robust Cognitive Evaluation of LLMs","summary":"Emergent cognitive abilities in large language models (LLMs) have been widely\nobserved, but their nature and underlying mechanisms remain poorly understood.\nA growing body of research draws on cognitive science to investigate LLM\ncognition, but standard methodologies and experimen-tal pipelines have not yet\nbeen established. To address this gap we develop CognitivEval, a framework for\nsystematically evaluating the artificial cognitive capabilities of LLMs, with a\nparticular emphasis on robustness in response collection. The key features of\nCognitivEval include: (i) automatic prompt permutations, and (ii) testing that\ngathers both generations and model probability estimates. Our experiments\ndemonstrate that these features lead to more robust experimental outcomes.\nUsing CognitivEval, we replicate five classic experiments in cognitive science,\nillustrating the framework's generalizability across various experimental tasks\nand obtaining a cognitive profile of several state of the art LLMs.\nCognitivEval will be released publicly to foster broader collaboration within\nthe cognitive science community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T17:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.02806v1","title":"Vertex-Based Localization of TurÃ¡n's Theorem","summary":"For a simple graph $G$, let $n$ and $m$ denote the number of vertices and\nedges in $G$, respectively. Tur\\'{a}n's theorem states that in a simple\n$K_{r+1}$ free graph, $m \\leq \\frac{n^2(r-1)}{2r}$. In this paper, we\ngeneralize this result as follows: For each $v \\in V(G)$, let $c(v)$ be the\norder of the largest clique that contains $v$. We show that \\[ m \\leq\n\\frac{n}{2}\\sum_{v\\in V(G)}\\frac{c(v)-1}{c(v)}\\] Furthermore, we characterize\nthe class of extremal graphs that attain equality in this bound.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-03T17:51:50Z"}
{"aid":"http://arxiv.org/abs/2504.04724v1","title":"Three-dimensional abruptly autofocusing by counter-propagating Airy\n  pulses with radial Airy beam profile","summary":"We report the experimental observation of a three-dimensional abruptly\nautofocusing effect by synthesizing a radially distributed Airy beam with two\ncounter-propagating Airy pulses in time. As the wave packet propagates in a\ndispersive medium, the radially distributed Airy beam converges inward to the\ncenter point. Two Airy pulses counter-propagate toward each other to merge to\nform a high peak power pulse. As the result, the high intensity emerges\nabruptly as the wave packet achieves three-dimensional focusing. This\nautofocusing effect is believed to have potential applications such as material\nmodification, plasma physics, nanoparticle manipulations, etc.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T04:26:51Z"}
{"aid":"http://arxiv.org/abs/2504.04745v1","title":"Can LLMs Interpret and Leverage Structured Linguistic Representations? A\n  Case Study with AMRs","summary":"This paper evaluates the ability of Large Language Models (LLMs) to leverage\ncontextual information in the form of structured linguistic representations.\nSpecifically, we examine the impact of encoding both short and long contexts\nusing Abstract Meaning Representation (AMR) structures across a diverse set of\nlanguage tasks. We perform our analysis using 8-bit quantized and\ninstruction-tuned versions of Llama 3.1 (8B), Phi-3, and Mistral 7B. Our\nresults indicate that, for tasks involving short contexts, augmenting the\nprompt with the AMR of the original language context often degrades the\nperformance of the underlying LLM. However, for tasks that involve long\ncontexts, such as dialogue summarization in the SAMSum dataset, this\nenhancement improves LLM performance, for example, by increasing the zero-shot\ncosine similarity score of Llama 3.1 from 66.2% to 76%. This improvement is\nmore evident in the newer and larger LLMs, but does not extend to the older or\nsmaller ones. In addition, we observe that LLMs can effectively reconstruct the\noriginal text from a linearized AMR, achieving a cosine similarity of 81.3% in\nthe best-case scenario.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T05:38:40Z"}
{"aid":"http://arxiv.org/abs/2504.04752v1","title":"Investigating Popularity Bias Amplification in Recommender Systems\n  Employed in the Entertainment Domain","summary":"Recommender systems have become an integral part of our daily online\nexperience by analyzing past user behavior to suggest relevant content in\nentertainment domains such as music, movies, and books. Today, they are among\nthe most widely used applications of AI and machine learning. Consequently,\nregulations and guidelines for trustworthy AI, such as the European AI Act,\nwhich addresses issues like bias and fairness, are highly relevant to the\ndesign, development, and evaluation of recommender systems. One particularly\nimportant type of bias in this context is popularity bias, which results in the\nunfair underrepresentation of less popular content in recommendation lists.\nThis work summarizes our research on investigating the amplification of\npopularity bias in recommender systems within the entertainment sector.\nAnalyzing datasets from three entertainment domains, music, movies, and anime,\nwe demonstrate that an item's recommendation frequency is positively correlated\nwith its popularity. As a result, user groups with little interest in popular\ncontent receive less accurate recommendations compared to those who prefer\nwidely popular items. Furthermore, we aim to better understand the connection\nbetween recommendation accuracy, calibration quality of algorithms, and\npopularity bias amplification.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T05:58:01Z"}
{"aid":"http://arxiv.org/abs/2504.04763v1","title":"Broad-band noises in GX 339-4 during the 2021 outburst observed with\n  Insight-HXMT and NICER","summary":"Rapid X-ray variability of GX 339$-$4 including the low-frequency\nquasi-periodic oscillations (LFQPOs) and broad-band noises have been observed\nwith the Hard X-ray Modulation Telescope (\\textit{Insight}-HXMT) and Neutron\nstar Interior Composition Explorer (\\textit {NICER}) during the 2021 outburst.\nHere we present a systematic study of the evolution and energy dependence\nproperties of such broad-band noises (BBN). The outburst from February to March\nof 2021 can be divided into three stages: the low hard state (LHS), the hard\nintermediate state (HIMS) and soft intermediate state (SIMS). In the PDSs of\nthe LHS and HIMS, the broad-band noises are well fitted with three Lorentzian\ncomponents: a low-frequency component $L_1$, a middle-frequency component $L_2$\nand a high-frequency component $L_3$. The increasing trend of the\ncharacteristic frequencies for $L_1$ and $L_2$ and the relation between the QPO\nfrequency and characteristic BBN frequency are reported. We found that the\nenergies corresponding to the peaks and shapes of the rms spectra for three BBN\ncomponents are different. The comparison among three BBN components indicates\nthat energy-dominant bands of these BBN components are distinct. Our results\ncan be explained with the truncated disc/hot flow model with a large variable\ndisc and a small hot inner flow. A possible description of the accretion\nstructure and its evolution from the LHS to the SIMS is proposed. Further\nresearch is still required to probe such accretion structure in GX 339--4.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T06:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.04781v1","title":"OCC-MLLM-CoT-Alpha: Towards Multi-stage Occlusion Recognition Based on\n  Large Language Models via 3D-Aware Supervision and Chain-of-Thoughts Guidance","summary":"Comprehending occluded objects are not well studied in existing large-scale\nvisual-language multi-modal models. Current state-of-the-art multi-modal large\nmodels struggles to provide satisfactory results in understanding occluded\nobjects through universal visual encoders and supervised learning strategies.\nTherefore, we propose OCC-MLLM-CoT-Alpha, a multi-modal large vision language\nframework that integrates 3D-aware supervision and Chain-of-Thoughts guidance.\nParticularly, (1) we build a multi-modal large vision-language model framework\nwhich is consisted of a large multi-modal vision-language model and a 3D\nreconstruction expert model. (2) the corresponding multi-modal\nChain-of-Thoughts is learned through a combination of supervised and\nreinforcement training strategies, allowing the multi-modal vision-language\nmodel to enhance the recognition ability with learned multi-modal\nchain-of-thoughts guidance. (3) A large-scale multi-modal chain-of-thoughts\nreasoning dataset, consisting of $110k$ samples of occluded objects held in\nhand, is built. In the evaluation, the proposed methods demonstrate decision\nscore improvement of 15.75%,15.30%,16.98%,14.62%, and 4.42%,3.63%,6.94%,10.70%\nfor two settings of a variety of state-of-the-art models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:15:26Z"}
{"aid":"http://arxiv.org/abs/2504.04782v1","title":"I only read it for the plot! Maturity Ratings Affect Fanfiction Style\n  and Community Engagement","summary":"We consider the textual profiles of different fanfiction maturity ratings,\nhow they vary across fan groups, and how this relates to reader engagement\nmetrics. Previous studies have shown that fanfiction writing is motivated by a\ncombination of admiration for and frustration with the fan object. These\nfindings emerge when looking at fanfiction as a whole, as well as when it is\ndivided into subgroups, also called fandoms. However, maturity ratings are used\nto indicate the intended audience of the fanfiction, as well as whether the\nstory includes mature themes and explicit scenes. Since these ratings can be\nused to filter readers and writers, they can also be seen as a proxy for\ndifferent reader/writer motivations and desires. We find that explicit\nfanfiction in particular has a distinct textual profile when compared to other\nmaturity ratings. These findings thus nuance our understanding of reader/writer\nmotivations in fanfiction communities, and also highlights the influence of the\ncommunity norms and fan behavior more generally on these cultural products.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T07:20:59Z"}
{"aid":"http://arxiv.org/abs/2504.04785v1","title":"Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors","summary":"Efficiently leveraging of the capabilities of contemporary large language\nmodels (LLMs) is increasingly challenging, particularly when direct fine-tuning\nis expensive and often impractical. Existing training-free methods, including\nmanually or automated designed workflows, typically demand substantial human\neffort or yield suboptimal results. This paper proposes Weak-for-Strong\nHarnessing (W4S), a novel framework that customizes smaller, cost-efficient\nlanguage models to design and optimize workflows for harnessing stronger\nmodels. W4S formulates workflow design as a multi-turn markov decision process\nand introduces reinforcement learning for agentic workflow optimization (RLAO)\nto train a weak meta-agent. Through iterative interaction with the environment,\nthe meta-agent learns to design increasingly effective workflows without manual\nintervention. Empirical results demonstrate the superiority of W4S that our 7B\nmeta-agent, trained with just one GPU hour, outperforms the strongest baseline\nby 2.9% ~ 24.6% across eleven benchmarks, successfully elevating the\nperformance of state-of-the-art models such as GPT-3.5-Turbo and GPT-4o.\nNotably, W4S exhibits strong generalization capabilities across both seen and\nunseen tasks, offering an efficient, high-performing alternative to directly\nfine-tuning strong models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T07:27:31Z"}
{"aid":"http://arxiv.org/abs/2504.04859v1","title":"Block BDDC/FETI-DP Preconditioners for Three-Field mixed finite element\n  Discretizations of Biot's consolidation model","summary":"In this paper, we construct and analyze a block dual-primal preconditioner\nfor Biot's consolidation model approximated by three-field mixed finite\nelements based on a displacement, pressure, and total pressure formulation. The\ndomain is decomposed into nonoverlapping subdomains, and the continuity of the\ndisplacement component across the subdomain interface is enforced by\nintroducing a Lagrange multiplier. After eliminating all displacement variables\nand the independent subdomain interior components of pressure and total\npressure, the problem is reduced to a symmetric positive definite linear system\nfor the subdomain interface pressure, total pressure, and the Lagrange\nmultiplier. This reduced system is solved by a preconditioned conjugate\ngradient method, with a block dual-primal preconditioner using a Balancing\nDomain Decomposition by Constraints (BDDC) preconditioner for both the\ninterface total pressure block and the interface pressure blocks, as well as a\nFinite Element Tearing and Interconnecting-Dual Primal (FETI-DP) preconditioner\nfor the Lagrange multiplier block. By analyzing the conditioning of the\npreconditioned subsystem associated with the interface pressure and total\npressure components, we obtain a condition number bound of the preconditioned\nsystem, which is scalable in the number of subdomains, poly-logarithmic in the\nratio of subdomain and mesh sizes, and robust with respect to the parameters of\nthe model. Extensive numerical experiments confirm the theoretical result of\nthe proposed algorithm.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T09:17:37Z"}
{"aid":"http://arxiv.org/abs/2504.04868v1","title":"On Scenario Formalisms for Automated Driving","summary":"The concept of scenario and its many qualifications -- specifically logical\nand abstract scenarios -- have emerged as a foundational element in\nsafeguarding automated driving systems. However, the original linguistic\ndefinitions of the different scenario qualifications were often applied\nambiguously, leading to a divergence between scenario description languages\nproposed or standardized in practice and their terminological foundation. This\nresulted in confusion about the unique features as well as strengths and\nweaknesses of logical and abstract scenarios. To alleviate this, we give clear\nlinguistic definitions for the scenario qualifications concrete, logical, and\nabstract scenario and propose generic, unifying formalisms using curves,\nmappings to sets of curves, and temporal logics, respectively. We demonstrate\nthat these formalisms allow pinpointing strengths and weaknesses precisely by\ncomparing expressiveness, specification complexity, sampling, and monitoring of\nlogical and abstract scenarios. Our work hence enables the practitioner to\ncomprehend the different scenario qualifications and identify a suitable\nformalism.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T09:23:46Z"}
{"aid":"http://arxiv.org/abs/2504.04869v1","title":"Content-Aware Transformer for All-in-one Image Restoration","summary":"Image restoration has witnessed significant advancements with the development\nof deep learning models. Although Transformer architectures have progressed\nconsiderably in recent years, challenges remain, particularly the limited\nreceptive field in window-based self-attention. In this work, we propose\nDSwinIR, a Deformable Sliding window Transformer for Image Restoration. DSwinIR\nintroduces a novel deformable sliding window self-attention that adaptively\nadjusts receptive fields based on image content, enabling the attention\nmechanism to focus on important regions and enhance feature extraction aligned\nwith salient features. Additionally, we introduce a central ensemble pattern to\nreduce the inclusion of irrelevant content within attention windows. In this\nway, the proposed DSwinIR model integrates the deformable sliding window\nTransformer and central ensemble pattern to amplify the strengths of both CNNs\nand Transformers while mitigating their limitations. Extensive experiments on\nvarious image restoration tasks demonstrate that DSwinIR achieves\nstate-of-the-art performance. For example, in image deraining, compared to\nDRSformer on the SPA dataset, DSwinIR achieves a 0.66 dB PSNR improvement. In\nall-in-one image restoration, compared to PromptIR, DSwinIR achieves over a\n0.66 dB and 1.04 dB improvement on three-task and five-task settings,\nrespectively. Pretrained models and code are available at our project\nhttps://github.com/Aitical/DSwinIR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T09:24:41Z"}
{"aid":"http://arxiv.org/abs/2504.04895v1","title":"Asymmetric 4.77 Three-Way Unequal Filtering Power Divider/Combiner for\n  Communication Systems Application","summary":"This study presents a novel three-way unequal filtering power\ndivider/combiner, addressing challenges in unequal power distribution while\nincorporating filtering functions in communication systems. Wilkinson power\ndivider (WPD) is the traditional power division approach using\nquarter-wavelength transmission lines [1]. This type of power divider is\npopularly used in communication systems due to its good electrical isolation\nand simple structure. The problem with WPD is that its operation requires the\nuse of an externally connected bandpass filter (BPF) to achieve filtering\nfunctionality. This leads to increased footprint and increased loss\ncoefficients in a system. In contrast to the traditional design approach\ninvolving a BPF, a matching transmission line, and a Wilkinson power divider as\nseparate components, the proposed integrated filtering power divider (FPD)\nconsolidates all three components into a single device, leading to lower\nfootprint and lower loss coefficient in a system. Circuit modelling and\nelectromagnetic (EM) simulations were conducted to ensure alignment between\ntheoretical and practical results. The design demonstrates effective unequal\npower division at the three output ports while maintaining very good filtering\nperformance. Results show a return loss better than 15 dB and a minimum\ninsertion loss of 1.2 dB. The overall size of the device is 32.2 x 50.0 mm.\nThis paper contributes to advancements in power divider design by addressing\nunequal power division challenges and integrating filtering functions. The\nfindings offer a foundation for future developments in advanced power\ndivider/combiner systems, with insights into potential challenges and areas for\nfurther improvements.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP","published":"2025-04-07T10:06:59Z"}
{"aid":"http://arxiv.org/abs/2504.04901v1","title":"Design of a compact low loss 2-way millimetre wave power divider for\n  future communication","summary":"In this paper, a rectangular-shaped power divider has been presented\noperating at 27.9 GHz. The power divider has achieved acceptable results for\nimportant parameters such as S11, S12, S21, and S22. The substrate employed for\nthe power divider is Roger 3003 which has a thickness of 1.6 mm. This power\ndivider provides a reflection coefficient of -12.2 dB and an insertion loss of\n3.1 dB at 28 GHz. This ka-band T-junction power divider covers 68% of the\nbandwidth. Dimensions of the ka-band T-junction power divider are 50x80 mm. Due\nto its dimensions and bandwidth this power divider is more suitable for\nmillimetre wave applications like RADAR, beamforming, and 5G applications.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP","published":"2025-04-07T10:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.04905v1","title":"Null geodesics around a magnetized Kiselev black hole","summary":"A new magnetically charged Kiselev black hole solution is used to study the\nnull geodesics in this spacetime. We derive the equations of motion for the\nnull geodesics and analyze their properties, including the gravitational\nlensing effect. The 3D and equatorial plane orbits are discussed, with\nparticular attention given to the effect of quintessence. The deviations from\nthe Ernst black hole provide insights into the potential observational\nconsequences of dark energy in strong gravitational fields.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T10:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.04960v1","title":"Sign-changing multi-peak standing waves of the NLSE with a point\n  interaction","summary":"Consider the following semilinear problem with a point interaction in\n$\\mathbb{R}^N$: \\[- \\Delta_\\alpha u + \\omega u = u |u|^{p - 2},\\] where $N \\in\n\\{2, 3\\}$; $\\omega > 0$; $- \\Delta_\\alpha$ denotes the Hamiltonian of point\ninteraction with inverse $s$-wave scattering length $- (4 \\pi \\alpha)^{- 1}$\nand we want to solve for $u \\colon \\mathbb{R}^N \\to \\mathbb{R}$. By means of\nLyapunov--Schmidt reduction, we prove that this problem has sign-changing\nmulti-peak solutions when either (1) $N = 2$, $\\alpha \\in \\mathbb{R}$, $p_* < p\n\\leq 3$ and $\\omega$ is sufficiently large or (2) $N = 3$, $0 < \\alpha <\n\\infty$, $p_* < p < 3$ and $\\omega$ is sufficiently small, where $2.45 < p_* :=\n\\frac{9 + \\sqrt{113}}{8} < 2.46$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T11:48:47Z"}
{"aid":"http://arxiv.org/abs/2504.04963v1","title":"Constraint Multi-class Positive and Unlabeled Learning for Distantly\n  Supervised Named Entity Recognition","summary":"Distantly supervised named entity recognition (DS-NER) has been proposed to\nexploit the automatically labeled training data by external knowledge bases\ninstead of human annotations. However, it tends to suffer from a high false\nnegative rate due to the inherent incompleteness. To address this issue, we\npresent a novel approach called \\textbf{C}onstraint \\textbf{M}ulti-class\n\\textbf{P}ositive and \\textbf{U}nlabeled Learning (CMPU), which introduces a\nconstraint factor on the risk estimator of multiple positive classes. It\nsuggests that the constraint non-negative risk estimator is more robust against\noverfitting than previous PU learning methods with limited positive data. Solid\ntheoretical analysis on CMPU is provided to prove the validity of our approach.\nExtensive experiments on two benchmark datasets that were labeled using diverse\nexternal knowledge sources serve to demonstrate the superior performance of\nCMPU in comparison to existing DS-NER methods.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T11:51:41Z"}
{"aid":"http://arxiv.org/abs/2504.05006v1","title":"Enhancing Smart Contract Vulnerability Detection in DApps Leveraging\n  Fine-Tuned LLM","summary":"Decentralized applications (DApps) face significant security risks due to\nvulnerabilities in smart contracts, with traditional detection methods\nstruggling to address emerging and machine-unauditable flaws. This paper\nproposes a novel approach leveraging fine-tuned Large Language Models (LLMs) to\nenhance smart contract vulnerability detection. We introduce a comprehensive\ndataset of 215 real-world DApp projects (4,998 contracts), including\nhard-to-detect logical errors like token price manipulation, addressing the\nlimitations of existing simplified benchmarks. By fine-tuning LLMs (Llama3-8B\nand Qwen2-7B) with Full-Parameter Fine-Tuning (FFT) and Low-Rank Adaptation\n(LoRA), our method achieves superior performance, attaining an F1-score of 0.83\nwith FFT and data augmentation via Random Over Sampling (ROS). Comparative\nexperiments demonstrate significant improvements over prompt-based LLMs and\nstate-of-the-art tools. Notably, the approach excels in detecting\nnon-machine-auditable vulnerabilities, achieving 0.97 precision and 0.68 recall\nfor price manipulation flaws. The results underscore the effectiveness of\ndomain-specific LLM fine-tuning and data augmentation in addressing real-world\nDApp security challenges, offering a robust solution for blockchain ecosystem\nprotection.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T12:32:14Z"}
{"aid":"http://arxiv.org/abs/2504.05016v1","title":"Radio frequency single electron transmission spectroscopy of a\n  semiconductor Si/SiGe quantum dot","summary":"Rapid single shot spin readout is a key ingredient for fault tolerant quantum\ncomputing with spin qubits. An RF-SET (radio-frequency single electron\ntransistor) is predominantly used as its the readout timescale is far shorter\nthan the spin decoherence time. In this work, we experimentally demonstrate a\ntransmission-based RF-SET using a multi-module semiconductor-superconductor\nassembly. A monolithically integrated SET placed next to a double quantum dot\nin a Si/SiGe heterostructure is wire-bonded to a superconducting niobium\ninductor forming the impedance-transforming network. Compared to RF\nreflectometry, the proposed set-up is experimentally simpler without the need\nfor directional couplers. Read-out performance is benchmarked by the\nsignal-to-noise (SNR) of a dot-reservoir transition (DRT) and an interdot\ncharge transition (ICT) in the double quantum dot near the SET as a function of\nRF power and integration time. The minimum integration time for unitary SNR is\nfound to be 100 ns for ICT and 300 ns for DRT. The obtained minimum integration\ntimes are comparable to the state of the art in conventional RF reflectometry\nset-ups. Furthermore, we study the turn-on properties of the RF-SET to\ninvestigate capacitive shifts and RF losses. Understanding these effects are\ncrucial for further optimisations of the impedance transforming network as well\nas the device design to assist RF read-out. This new RF read-out scheme also\nshows promise for multiplexing spin-qubit readout and further studies on rapid\ncharge dynamics in quantum dots.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.app-ph","published":"2025-04-07T12:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.05031v1","title":"Analog phase-sensitive time-reversal of optically-carried radiofrequency\n  signals","summary":"Achieving low-latency time-reversal of broadband radiofrequency signals is\ncrucial for reliable communications in dynamic, uncontrolled environments.\nHowever, existing approaches are either digitally assisted -- making broadband\nextension challenging -- or limited to amplitude modulation. In this work, we\nreport the very first experimental realization of a fully analog,\nphase-preserving time-reversal architecture for optically-carried\nradiofrequency signals. The method exploits the exceptional coherence\nproperties of rare-earth ion-doped materials, and leverages the\nwell-established photon echo mechanism, widely used in quantum technologies.\nWhile our demonstration is conducted with a modest bandwidth, we identify the\nfundamental cause of this limitation and propose solutions for future\nscalability.","main_category":"physics.optics","categories":"physics.optics,physics.atom-ph,quant-ph","published":"2025-04-07T12:52:41Z"}
{"aid":"http://arxiv.org/abs/2504.05054v1","title":"Small-mass solutions in a two-dimensional logarithmic\n  chemotaxis-Navier-Stokes system with indirect nutrient consumption","summary":"This paper is concerned with the singular chemotaxis-fluid system with\nindirect nutrient consumption: $\n  n_{t}+u\\cdot\\nabla n=\\Delta n-\\nabla\\cdot(n S(x,n,v)\\cdot \\nabla v);\\\n  v_{t}+u\\cdot\\nabla v=\\Delta v-vw;\\\n  w_{t}+u\\cdot\\nabla w=\\Delta w-w+n;\\\n  u_t+(u\\cdot\\nabla) u=\\Delta u-\\nabla P+n\\nabla\\Phi;\\ \\nabla\\cdot u=0\\ $\n  in a smooth bounded domain $\\Omega\\subset\\mathbb{R}^2$\n  under no-flux/Neumann/Neumann/Dirichlet boundary conditions, where $\\Phi\\in\nW^{2,\\infty}(\\Omega)$, and $S: \\overline{\\Omega}\\times [0,\\infty) \\times\n(0,\\infty)\\rightarrow\\mathbb{R}^{2\\times 2}$ is a suitably smooth function that\nsatisfies $|S(x,n,v)|\\leq S_0(v) /v $ for all $(x,n,v) \\in \\Omega\\times\n(0,\\infty)^2$ with some nondecreasing $S_0: (0,\\infty)\\rightarrow(0,\\infty)$.\n  For all reasonably regular initial data with a smallness assumption merely\ninvolving the quantity $\\int_\\Omega n_0$,\n  it is shown that the problem possesses a globally bounded classical solution,\nwhich, inter alia, exponentially stabilizes\n  toward the spatially homogeneous state $(\n\\frac{1}{|\\Omega|}\\int_{\\Omega}n_0,0,\\frac{1}{|\\Omega|}\\int_{\\Omega}n_0,0)$\nwith respect to the norm in $L^\\infty(\\Omega)$.\n  This rigorously confirms that, at least in the two-dimensional setting, in\ncomparison to the direct mechanism of nutrient consumption, an indirect\nmechanism can induce much more regularity of solutions to the chemotaxis--fluid\nsystem even with a singular tensor-valued sensitivity.","main_category":"math.AP","categories":"math.AP","published":"2025-04-07T13:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.05061v1","title":"Topology of circular orbits of charged particles in black holes with\n  multiple horizons","summary":"The study of the topological properties of circular orbits is opening up new\nperspectives for exploring the spacetime structure around black holes. In this\nwork, we investigate how the charged properties of particles affect the\ntopological characteristics of circular orbits for charged test particles in\nasymptotically flat, AdS, and dS black holes. Our findings demonstrate that the\ncharged properties not only influence the topological properties of timelike\ncircular orbits but also impact those of null circular orbits. Additionally, we\nexplore scenarios involving multiple horizons and find that for a multi-horizon\nblack hole, if a circular orbit can exist between two neighboring horizons,\nthere will always be both a null circular orbit and a timelike circular orbit.\nWhether these orbits are stable or unstable depends on the potential function.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T13:33:31Z"}
{"aid":"http://arxiv.org/abs/2504.05064v1","title":"Wild generalised truncation of infinite matroids","summary":"For ${n \\in \\mathbb{N}}$, the $n$-truncation of a matroid $M$ of rank at\nleast $n$ is the matroid whose bases are the $n$-element independent sets of\n$M$. One can extend this definition to negative integers by letting the\n$(-n)$-truncation be the matroid whose bases are all the sets that can be\nobtained by deleting $n$ elements of a base of $M$. If $M$ has infinite rank,\nthen for distinct ${m,n \\in \\mathbb{Z}}$ the $m$-truncation and the\n$n$-truncation are distinct matroids.\n  Inspired by the work of Bowler and Geschke on infinite uniform matroids, we\nprovide a natural definition of generalised truncations that encompasses the\nnotions mentioned above. We call a generalised truncation wild if it is not an\n$n$-truncation for any ${n \\in \\mathbb{Z}}$ and we prove that, under Martin's\nAxiom, any finitary matroid of infinite rank and size of less than continuum\nadmits ${2^{2^{\\aleph_0}}}$ wild generalised truncations.","main_category":"math.CO","categories":"math.CO,math.LO","published":"2025-04-07T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.05083v1","title":"X-ray variability of VHE detected FSRQs: A comparative study","summary":"Flat Spectrum Radio Quasars (FSRQs) are weak sources of very high energy\n(VHE; E>100 GeV) emission, despite exhibiting strong MeV-GeV emissions that\ndominate their radiative output. To date, only ten FSRQs have been detected at\nVHEs, primarily during bright optical phases. In this study, we perform a\ndetailed and systematic, temporal, and spectral analysis of the nine\nVHE-detected FSRQs, using the Swift X-ray Telescope (XRT) data. Our findings\nshow no correlation between VHE activity and the X-ray flux or spectral state\nof the sources. However, investigation of spectral properties with X-ray\nbrightness shows anti-correlation between flux and spectral index. The X-ray,\ngenerally with a different spectral shape lies at the farther end of the\noptical-UV synchrotron spectrum which typically shows a declining power-law\nspectrum, and thus, the X-ray spectrum is generally explained by Synchrotron\nSelf-Compton (SSC) process. However, if optical-UV synchrotron emission extends\ninto the X-ray band, it can soften the X-ray spectrum. While most sources in\nour sample exhibit rising X-ray SEDs, indicative of non-synchrotron origins or\nminimal synchrotron contributions, many display softer or flat X-ray spectra,\nmainly during low X-ray flux states (e.g., 4C +21.35, 3C 279, TON 0599, PKS\n1441+25, and PKS 0346-27) suggesting potential synchrotron contributions. These\nsynchrotron continuations influence the gamma-ray spectrum, implying extension\ninto the VHE range for inverse Compton (IC) scattering in the Thomson\nscattering limit. If the extended component corresponds to an underlying\nlow-level emission, these FSRQs could represent potential candidates for\npersistent VHE activity.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T13:53:57Z"}
{"aid":"http://arxiv.org/abs/2504.05143v1","title":"Taming Double-Spending in Offline Payments with Reputation-Weighted Loan\n  Networks","summary":"Blockchain solutions typically assume a synchronous network to ensure\nconsistency and achieve consensus. In contrast, offline transaction systems aim\nto enable users to agree on and execute transactions without assuming bounded\ncommunication delays when interacting with the blockchain. Most existing\noffline payment schemes depend on trusted hardware wallets that are assumed to\nbe secure and tamper-proof. While this work introduces Overdraft, a novel\noffline payment system that shifts the reliance from hardware to users\nthemselves. Overdraft allows potential payment receivers to assess the\nlikelihood of being paid, allowing them to accept transactions with confidence\nor deny them. Overdraft achieves this by maintaining a loan network that is\nweighted by online reputation. This loan network contains time-limited\nagreements where users pledge to cover another user's payment if necessary. For\nexample, when a payer lacks sufficient funds at the moment of commitment.\nOffline users rely on the last known view of the loan network -- which they had\naccess to when last online -- to determine whether to participate in an offline\ntransaction. This view is used to estimate the probability of eventual payment,\npossibly using multiple loans. Once online again, users commit their\ntransactions to the blockchain with any conflicts being resolved\ndeterministically. Overdraft incorporates incentives for users and is designed\nto be resilient against Sybil attacks. As a proof of concept, we implemented\nOverdraft as an Ethereum Solidity smart contract and deployed it on the Sepolia\ntestnet to evaluate its performance.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-07T14:48:19Z"}
{"aid":"http://arxiv.org/abs/2504.05186v1","title":"Training state-of-the-art pathology foundation models with orders of\n  magnitude less data","summary":"The field of computational pathology has recently seen rapid advances driven\nby the development of modern vision foundation models (FMs), typically trained\non vast collections of pathology images. Recent studies demonstrate that\nincreasing the training data set and model size and integrating domain-specific\nimage processing techniques can significantly enhance the model's performance\non downstream tasks. Building on these insights, our work incorporates several\nrecent modifications to the standard DINOv2 framework from the literature to\noptimize the training of pathology FMs. We also apply a post-training procedure\nfor fine-tuning models on higher-resolution images to further enrich the\ninformation encoded in the embeddings. We present three novel pathology FMs\ntrained on up to two orders of magnitude fewer WSIs than those used to train\nother state-of-the-art FMs while demonstrating a comparable or superior\nperformance on downstream tasks. Even the model trained on TCGA alone (12k\nWSIs) outperforms most existing FMs and, on average, matches Virchow2, the\nsecond-best FM published to date. This suggests that there still remains a\nsignificant potential for further improving the models and algorithms used to\ntrain pathology FMs to take full advantage of the vast data collections.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T15:38:12Z"}
{"aid":"http://arxiv.org/abs/2504.05188v1","title":"Breakdown of Bulk-Radiation Correspondence in Radiative Photonic\n  Lattices","summary":"The topological characteristics of energy bands in crystalline systems are\nencapsulated in the Berry curvature of the bulk Bloch states. In photonic\ncrystal slabs, far-field emission from guided resonances naturally provides a\nnon-invasive way to probe the embedded wavefunctions, raising the question of\nhow the information carried by escaping photons relates to the band topology.\nWe develop a non-Hermitian model to describe the guided and leaky modes of\nphotonic crystal slabs with long-range couplings and non-local responses.\nWithin this framework, radiation Berry curvature is defined from the far-field\npolarization and compared to the conventional bulk Berry curvature of the\ncrystal Bloch modes. We investigate this bulk-radiation correspondence in the\nvicinity of the $\\Gamma$-point of the square lattice and the $K$-point of the\nhoneycomb lattice. The results show that the comparability between the bulk\ntopology and the radiation topology is not universal; the validity is\ncontingent upon the specific bulk Bloch states. Notably, the correspondence\ncompletely breaks down surrounding the far-field singularities, while it can\nhold in smooth regions under special symmetry conditions, e.g., rotational\nsymmetry. Besides, net Berry curvature concentration is captured at the valleys\nof the non-local honeycomb lattice, facilitating further exploration on\ngeneralized topological phases in photonic lattices beyond the regimes with\nlocalized couplings and Hermiticity.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-07T15:40:02Z"}
{"aid":"http://arxiv.org/abs/2504.05229v1","title":"FinGrAct: A Framework for FINe-GRrained Evaluation of ACTionability in\n  Explainable Automatic Fact-Checking","summary":"The field of explainable Automatic Fact-Checking (AFC) aims to enhance the\ntransparency and trustworthiness of automated fact-verification systems by\nproviding clear and comprehensible explanations. However, the effectiveness of\nthese explanations depends on their actionability --their ability to empower\nusers to make informed decisions and mitigate misinformation. Despite\nactionability being a critical property of high-quality explanations, no prior\nresearch has proposed a dedicated method to evaluate it. This paper introduces\nFinGrAct, a fine-grained evaluation framework that can access the web, and it\nis designed to assess actionability in AFC explanations through well-defined\ncriteria and an evaluation dataset. FinGrAct surpasses state-of-the-art (SOTA)\nevaluators, achieving the highest Pearson and Kendall correlation with human\njudgments while demonstrating the lowest ego-centric bias, making it a more\nrobust evaluation approach for actionability evaluation in AFC.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T16:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.05245v1","title":"Embedded Federated Feature Selection with Dynamic Sparse Training:\n  Balancing Accuracy-Cost Tradeoffs","summary":"Federated Learning (FL) enables multiple resource-constrained edge devices\nwith varying levels of heterogeneity to collaboratively train a global model.\nHowever, devices with limited capacity can create bottlenecks and slow down\nmodel convergence. One effective approach to addressing this issue is to use an\nefficient feature selection method, which reduces overall resource demands by\nminimizing communication and computation costs, thereby mitigating the impact\nof struggling nodes. Existing federated feature selection (FFS) methods are\neither considered as a separate step from FL or rely on a third party. These\napproaches increase computation and communication overhead, making them\nimpractical for real-world high-dimensional datasets. To address this, we\npresent \\textit{Dynamic Sparse Federated Feature Selection} (DSFFS), the first\ninnovative embedded FFS that is efficient in both communication and\ncomputation. In the proposed method, feature selection occurs simultaneously\nwith model training. During training, input-layer neurons, their connections,\nand hidden-layer connections are dynamically pruned and regrown, eliminating\nuninformative features. This process enhances computational efficiency on\ndevices, improves network communication efficiency, and boosts global model\nperformance. Several experiments are conducted on nine real-world datasets of\nvarying dimensionality from diverse domains, including biology, image, speech,\nand text. The results under a realistic non-iid data distribution setting show\nthat our approach achieves a better trade-off between accuracy, computation,\nand communication costs by selecting more informative features compared to\nother state-of-the-art FFS methods.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T16:33:05Z"}
{"aid":"http://arxiv.org/abs/2504.05251v1","title":"Rationalizing dynamic choices","summary":"An analyst observes an agent take a sequence of actions. The analyst does not\nhave access to the agent's information and ponders whether the observed actions\ncould be justified through a rational Bayesian model with a known utility\nfunction. We show that the observed actions cannot be justified if and only if\nthere is a single deviation argument that leaves the agent better off,\nregardless of the information. The result is then extended to allow for\ndistributions over possible action sequences. Four applications are presented:\nmonotonicity of rationalization with risk aversion, a potential rejection of\nthe Bayesian model with observable data, feasible outcomes in dynamic\ninformation design, and partial identification of preferences without\nassumptions on information.","main_category":"econ.TH","categories":"econ.TH,econ.EM","published":"2025-04-07T16:43:26Z"}
{"aid":"http://arxiv.org/abs/2504.05269v1","title":"A model-based analysis of the AggregateEU mechanism: Implications of\n  overbidding and non-commitment","summary":"AggregateEU is a new centralised mechanism that provides a no-commitment\nplatform to trade natural gas in the European Union. Throughout the\nconsultation process, AggregateEU has been mocked as `Tinder of the European\ngas markets' as it helps consumers and suppliers to find partners, but leaves\nit up to the matched partners to decide whether or not to contract on the\npossible trade. The non-commitment nature leads to substantial overbidding and\nmany non-realised matches.\n  We propose a quantitative modelling framework to study the effect of\noverbidding in the AggergateEU demand aggregation or joint purchasing\nmechanism. We conclude that the mechanism is prone to overbidding and that\noverbidding has ambiguous effects on trade. Depending on the parameters,\noverbidding may facilitate trade, but may also result in highly inefficient\noutcomes when overbidding is combined with a miscoordination over the delivery\npoints.\n  Suggested remedies include allowing for convex bids, restrictions on\noverbidding, or giving up part of the non-binding character of the market.\n%Ideally, the traditional mechanisms of gas exchanges should be augmented by\nfeatures of AggregateEU. Our results sugge","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-07T17:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.05293v1","title":"A BLE and UWB Beacon-Assist Framework for Multiuser Augmented Reality\n  Synchronization Across Multiple Devices in Shared Environments","summary":"The challenge to synchronize augmented reality (AR) across sessions/devices\nhas been solved by relying solely on vision-feature mapping, which is\nsuboptimal in scaling workable space and flaws under visual changes in\nsurroundings. This study implemented AR synchronization solutions utilizing\nlocation beacon technology, namely Bluetooth Low Energy (BLE) and\nUltra-Wideband (UWB), to discourse scalability issues and inconsistencies in\nthe existing AR system. The framework is bifurcated into two approaches:\nBLE-assist and UWB-assist AR synchronization. The BLE-assist method utilizes\niBeacon technology for room context recognition, integrating with Apple's ARKit\nARWorldMap and Google's ARCore Cloud Anchors. The UWB-assist solution employs\nprecise beacon ranging capabilities fusion with the device's azimuth to\nestablish fixed spatial reference in AR across sessions/devices. Comparative\nevaluations show that the UWB-assist approach outperforms the BLE-assist\napproach in reliability across environmental variations, as it always\nsuccessfully resolves virtual anchors with a near-constant latency average at\n25 seconds, regardless of the physical setting changes. Conversely, the\nBLE-assist implementation tends to be more accurate in resolving virtual\nanchors with a mean of 0.02 metres in position error and within 0.03 radian in\norientation error. In the UWB-assist approach, computed fixed spatial\nreferences have an average disparity of 0.04 metres and 0.11 radians in pose.\nThe UWB-assist approach is ideal for scenarios requiring consistently\nsuccessful localization with acceptable accuracy. In contrast, the BLE-assist\napproach is more suitable when demanding finer precision in virtual anchor\nposes with the performance tradeoffs when the surroundings are altered, such as\nfor destinated short-lived AR sessions.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-07T17:47:49Z"}
{"aid":"http://arxiv.org/abs/2504.05295v1","title":"Dion: A Communication-Efficient Optimizer for Large Models","summary":"Training large AI models efficiently requires distributing computation across\nmultiple accelerators, but this often incurs significant communication overhead\n-- especially during gradient synchronization. We introduce Dion, a\ncommunication-efficient optimizer that retains the synchronous semantics of\nstandard distributed training (e.g., DDP, FSDP) while substantially reducing\nI/O costs. Unlike conventional optimizers that synchronize full gradient\nmatrices, Dion leverages orthonormalized updates with device-local momentum\nbuffers, eliminating the need for full gradient exchange. It further supports\nan efficient sharding strategy that avoids reconstructing large matrices during\ntraining.","main_category":"cs.LG","categories":"cs.LG,cs.AI,math.OC","published":"2025-04-07T17:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.05626v1","title":"Remarks on the locality of generalized global symmetries","summary":"We examine generalized global symmetries as a kind of compactly supported\ncohomology, and so are led to revisit questions about the locality of quantum\nfield theory, following Segal. Physics naturally suggests a generalization of\nfactorization algebras, aimed at capturing nonperturbative information, and we\nexplain how higher group symmetries offer examples of this generalization,\nproviding an extension of the nonabelian Poincar\\'e duality of Salvatore and\nLurie. Finally, we explore how continuous generalized symmetries and anomalies\ncan be cast in this framework.","main_category":"math-ph","categories":"math-ph,hep-th,math.AT,math.MP","published":"2025-04-08T03:02:00Z"}
{"aid":"http://arxiv.org/abs/2504.05647v1","title":"Phase transitions of the ErdÅs-GyÃ¡rfÃ¡s function","summary":"Given positive integers $p,q$. For any integer $k\\ge2$, an edge coloring of\nthe complete $k$-graph $K_n^{(k)}$ is said to be a $(p,q)$-coloring if every\ncopy of $K_p^{(k)}$ receives at least $q$ colors. The Erd\\H{o}s-Gy\\'{a}rf\\'{a}s\nfunction $f_k(n,p,q)$ is the minimum number of colors that are needed for\n$K_n^{(k)}$ to have a $(p,q)$-coloring.\n  Conlon, Fox, Lee and Sudakov (\\emph{IMRN, 2015}) conjectured that for any\npositive integers $p, k$ and $i$ with $k\\ge3$ and $1\\le i<k$,\n$f_k(n,p,{{p-i}\\choose{k-i}})=(\\log_{(i-1)}n)^{o(1)}$, where $\\log_{(i)}n$ is\nan iterated $i$-fold logarithm in $n$. It has been verified to be true for\n$k=3, p=4, i=1$ by Conlon et. al (\\emph{IMRN, 2015}), for $k=3, p=5, i=2$ by\nMubayi (\\emph{JGT, 2016}), and for all $k\\ge 4, p=k+1,i=1$ by B. Janzer and O.\nJanzer (\\emph{JCTB, 2024}). In this paper, we give new constructions and show\nthat this conjecture holds for infinitely many new cases, i.e., it holds for\nall $k\\ge4$, $p=k+2$ and $i=k-1$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T03:49:05Z"}
{"aid":"http://arxiv.org/abs/2504.05673v1","title":"VC-LLM: Automated Advertisement Video Creation from Raw Footage using\n  Multi-modal LLMs","summary":"As short videos have risen in popularity, the role of video content in\nadvertising has become increasingly significant. Typically, advertisers record\na large amount of raw footage about the product and then create numerous\ndifferent short-form advertisement videos based on this raw footage. Creating\nsuch videos mainly involves editing raw footage and writing advertisement\nscripts, which requires a certain level of creative ability. It is usually\nchallenging to create many different video contents for the same product, and\nmanual efficiency is often low. In this paper, we present VC-LLM, a framework\npowered by Large Language Models for the automatic creation of high-quality\nshort-form advertisement videos. Our approach leverages high-resolution spatial\ninput and low-resolution temporal input to represent video clips more\neffectively, capturing both fine-grained visual details and broader temporal\ndynamics. In addition, during training, we incorporate supplementary\ninformation generated by rewriting the ground truth text, ensuring that all key\noutput information can be directly traced back to the input, thereby reducing\nmodel hallucinations. We also designed a benchmark to evaluate the quality of\nthe created videos. Experiments show that VC-LLM based on GPT-4o can produce\nvideos comparable to those created by humans. Furthermore, we collected\nnumerous high-quality short advertisement videos to create a pre-training\ndataset and manually cleaned a portion of the data to construct a high-quality\nfine-tuning dataset. Experiments indicate that, on the benchmark, the VC-LLM\nbased on fine-tuned LLM can produce videos with superior narrative logic\ncompared to those created by the VC-LLM based on GPT-4o.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T04:35:23Z"}
{"aid":"http://arxiv.org/abs/2504.05684v1","title":"TARO: Timestep-Adaptive Representation Alignment with Onset-Aware\n  Conditioning for Synchronized Video-to-Audio Synthesis","summary":"This paper introduces Timestep-Adaptive Representation Alignment with\nOnset-Aware Conditioning (TARO), a novel framework for high-fidelity and\ntemporally coherent video-to-audio synthesis. Built upon flow-based\ntransformers, which offer stable training and continuous transformations for\nenhanced synchronization and audio quality, TARO introduces two key\ninnovations: (1) Timestep-Adaptive Representation Alignment (TRA), which\ndynamically aligns latent representations by adjusting alignment strength based\non the noise schedule, ensuring smooth evolution and improved fidelity, and (2)\nOnset-Aware Conditioning (OAC), which integrates onset cues that serve as sharp\nevent-driven markers of audio-relevant visual moments to enhance\nsynchronization with dynamic visual events. Extensive experiments on the\nVGGSound and Landscape datasets demonstrate that TARO outperforms prior\nmethods, achieving relatively 53\\% lower Frechet Distance (FD), 29% lower\nFrechet Audio Distance (FAD), and a 97.19% Alignment Accuracy, highlighting its\nsuperior audio quality and synchronization precision.","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.CV","published":"2025-04-08T04:49:36Z"}
{"aid":"http://arxiv.org/abs/2504.05690v1","title":"STAGE: Stemmed Accompaniment Generation through Prefix-Based\n  Conditioning","summary":"Recent advances in generative models have made it possible to create\nhigh-quality, coherent music, with some systems delivering production-level\noutput.Yet, most existing models focus solely on generating music from scratch,\nlimiting their usefulness for musicians who want to integrate such models into\na human, iterative composition workflow.In this paper we introduce STAGE, our\nSTemmed Accompaniment GEneration model, fine-tuned from the state-of-the-art\nMusicGen to generate single-stem instrumental accompaniments conditioned on a\ngiven mixture. Inspired by instruction-tuning methods for language models, we\nextend the transformer's embedding matrix with a context token, enabling the\nmodel to attend to a musical context through prefix-based conditioning.Compared\nto the baselines, STAGE yields accompaniments that exhibit stronger coherence\nwith the input mixture, higher audio quality, and closer alignment with textual\nprompts.Moreover, by conditioning on a metronome-like track, our framework\nnaturally supports tempo-constrained generation, achieving state-of-the-art\nalignment with the target rhythmic structure--all without requiring any\nadditional tempo-specific module.As a result, STAGE offers a practical,\nversatile tool for interactive music creation that can be readily adopted by\nmusicians in real-world workflows.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-08T05:24:11Z"}
{"aid":"http://arxiv.org/abs/2504.05699v1","title":"Spacetime Models for Cosmology","summary":"I revisit Roberto Torretti's \"Spacetime Models for the World\" [SHPMP 31\n(2):171-186 (2000)] in the light of more recent work in (philosophy of)\ncosmology. I discuss the motivations for FLRW spacetimes as a natural starting\npoint for inquiry, and I suggest contemporary cosmologists can avoid the\nrationalism that Torretti attributes to Einstein's early work in relativistic\ncosmology. I then discuss the senses in which FLRW models are idealized, and I\nshow how those idealizations (and partial de-idealizations) have contributed to\nour understanding of the universe.","main_category":"physics.hist-ph","categories":"physics.hist-ph,gr-qc","published":"2025-04-08T05:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.05717v1","title":"Rainbow gravity effects on Klein-Gordon particles in a quantized\n  nonuniform external magnetic field in the Bonnor-Melvin domain walls\n  background","summary":"We investigate the effect of rainbow gravity on Klein-Gordon (KG) bosons in a\nquantized nonuniform magnetic field in the background of Bonnor-Melvin (BM)\nspacetime with a cosmological constant. In the process, we show that the BM\nspacetime introduces domain walls (i.e., infinitely impenetrable hard walls) at\n\\(r = 0\\) and \\(r = \\pi/\\sqrt{2\\Lambda}\\), as a consequence of the effective\ngravitational potential field generated by such a magnetized BM spacetime. As a\nresult, the motion of KG particles/antiparticles is restricted indefinitely\nwithin the range \\(r \\in [0, \\pi/\\sqrt{2\\Lambda}]\\), and the particles and\nantiparticles cannot be found elsewhere. Next, we provide a conditionally exact\nsolution in the form of the general Heun function \\(H_G(a, q, \\alpha, \\beta,\n\\gamma, \\delta, z)\\). Within the BM domain walls and under the condition of\nexact solvability, we study the effects of rainbow gravity on KG bosonic fields\nin a quantized nonuniform external magnetic field in the BM spacetime\nbackground. We use three pairs of rainbow functions: \\( f(u) = (1 -\n\\tilde{\\beta} |E|)^{-1}, \\, h(u) = 1 \\); and \\( f(u) = 1, \\, h(u) = \\sqrt{1 -\n\\tilde{\\beta} |E|^\\upsilon} \\), with \\(\\upsilon = 1,2\\), where \\(u = |E| /\nE_p\\), \\(\\tilde{\\beta} = \\beta / E_p\\), and \\(\\beta\\) is the rainbow parameter.\nWe find that such pairs of rainbow functions, \\((f(u), h(u))\\), fully comply\nwith the theory of rainbow gravity, ensuring that \\(E_p\\) is the maximum\npossible energy for particles and antiparticles alike. Moreover, we show that\nthe corresponding bosonic states form magnetized, rotating vortices, as\nintriguing consequences of such a magnetized BM spacetime background.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-08T06:36:54Z"}
{"aid":"http://arxiv.org/abs/2504.05735v1","title":"Anomalous Maxwell-Garnett theory for photonic time crystals","summary":"Maxwell-Garnett theory, dating back to James Clerk Maxwell-Garnett's\nfoundational work in 1904, provides a simple yet powerful framework to describe\nthe inhomogeneous structure as an effective homogeneous medium, which\nsignificantly reduces the overall complexity of analysis, calculation, and\ndesign. As such, the Maxwell-Garnett theory enables many practical applications\nin diverse realms, ranging from photonics, acoustics, mechanics,\nthermodynamics, to material science. It has long been thought that the\nMaxwell-Garnett theory of light in impedance-mismatched periodic structures is\nvalid only within the long-wavelength limit, necessitating either the temporal\nor spatial period of light to be much larger than that of structures. Here, we\nbreak this long-held belief by revealing an anomalous Maxwell-Garnett theory\nfor impedance-mismatched photonic time crystals beyond this long-wavelength\nlimit. The key to this anomaly lies in the Fabry-Perot resonance. We discover\nthat under the Fabry-P\\'erot resonance, the impedance-mismatched photonic time\ncrystal could be essentially equivalent to a homogeneous temporal slab\nsimultaneously at specific discrete wavelengths, despite the temporal period of\nthese light being comparable to or even much smaller than that of photonic time\ncrystals.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T07:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.05739v1","title":"PRACH Preamble Detection as a Multi-Class Classification Problem: A\n  Machine Learning Approach Using SVM","summary":"This study addresses the preamble detection problem in the Random Access\nprocedure of LTE/5G networks by formulating it as a multi-class classification\ntask and evaluating the effectiveness of machine learning techniques. A Support\nVector Machine (SVM) model is implemented and compared against conventional\ndetection methods. The proposed approach improves preamble index assignment,\nenhancing detection efficiency for User Equipment (UE) accessing the network.\nPerformance analysis demonstrates that the SVM-based solution increases\ndetection accuracy while reducing missed detections. These findings underscore\nthe potential of machine learning in optimizing the Random Access procedure and\nimproving network accessibility.","main_category":"eess.SP","categories":"eess.SP,40-06","published":"2025-04-08T07:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.05740v1","title":"Micro-splatting: Maximizing Isotropic Constraints for Refined\n  Optimization in 3D Gaussian Splatting","summary":"Recent advancements in 3D Gaussian Splatting have achieved impressive\nscalability and real-time rendering for large-scale scenes but often fall short\nin capturing fine-grained details. Conventional approaches that rely on\nrelatively large covariance parameters tend to produce blurred representations,\nwhile directly reducing covariance sizes leads to sparsity. In this work, we\nintroduce Micro-splatting (Maximizing Isotropic Constraints for Refined\nOptimization in 3D Gaussian Splatting), a novel framework designed to overcome\nthese limitations. Our approach leverages a covariance regularization term to\npenalize excessively large Gaussians to ensure each splat remains compact and\nisotropic. This work implements an adaptive densification strategy that\ndynamically refines regions with high image gradients by lowering the splitting\nthreshold, followed by loss function enhancement. This strategy results in a\ndenser and more detailed gaussian means where needed, without sacrificing\nrendering efficiency. Quantitative evaluations using metrics such as L1, L2,\nPSNR, SSIM, and LPIPS, alongside qualitative comparisons demonstrate that our\nmethod significantly enhances fine-details in 3D reconstructions.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-08T07:15:58Z"}
{"aid":"http://arxiv.org/abs/2504.05747v1","title":"SEA-LION: Southeast Asian Languages in One Network","summary":"Recently, Large Language Models (LLMs) have dominated much of the artificial\nintelligence scene with their ability to process and generate natural\nlanguages. However, the majority of LLM research and development remains\nEnglish-centric, leaving low-resource languages such as those in the Southeast\nAsian (SEA) region under-represented. To address this representation gap, we\nintroduce Llama-SEA-LION-v3-8B-IT and Gemma-SEA-LION-v3-9B-IT, two cutting-edge\nmultilingual LLMs designed for SEA languages. The SEA-LION family of LLMs\nsupports 11 SEA languages, namely English, Chinese, Indonesian, Vietnamese,\nMalay, Thai, Burmese, Lao, Filipino, Tamil, and Khmer. Our work leverages\nlarge-scale multilingual continued pre-training with a comprehensive\npost-training regime involving multiple stages of instruction fine-tuning,\nalignment, and model merging. Evaluation results on multilingual benchmarks\nindicate that our models achieve state-of-the-art performance across LLMs\nsupporting SEA languages. We open-source the models to benefit the wider SEA\ncommunity.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T07:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.05756v1","title":"Interpretable Non-linear Survival Analysis with Evolutionary Symbolic\n  Regression","summary":"Survival Regression (SuR) is a key technique for modeling time to event in\nimportant applications such as clinical trials and semiconductor manufacturing.\nCurrently, SuR algorithms belong to one of three classes: non-linear black-box\n-- allowing adaptability to many datasets but offering limited interpretability\n(e.g., tree ensembles); linear glass-box -- being easier to interpret but\nlimited to modeling only linear interactions (e.g., Cox proportional hazards);\nand non-linear glass-box -- allowing adaptability and interpretability, but\nempirically found to have several limitations (e.g., explainable boosting\nmachines, survival trees). In this work, we investigate whether Symbolic\nRegression (SR), i.e., the automated search of mathematical expressions from\ndata, can lead to non-linear glass-box survival models that are interpretable\nand accurate. We propose an evolutionary, multi-objective, and multi-expression\nimplementation of SR adapted to SuR. Our empirical results on five real-world\ndatasets show that SR consistently outperforms traditional glass-box methods\nfor SuR in terms of accuracy per number of dimensions in the model, while\nexhibiting comparable accuracy with black-box methods. Furthermore, we offer\nqualitative examples to assess the interpretability potential of SR models for\nSuR. Code at: https://github.com/lurovi/SurvivalMultiTree-pyNSGP.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-08T07:37:37Z"}
{"aid":"http://arxiv.org/abs/2504.05781v1","title":"Building Proactive and Instant-Reactive Safety Designs to Address\n  Harassment in Social Virtual Reality","summary":"Social Virtual Reality (VR) games offer immersive socialization experiences\nbut pose significant challenges of harassment. Common solutions, such as\nreporting and moderation, address harassment after it happens but fail to\nprevent or stop harassment in the moment. In this study, we explore and design\nproactive and instant-reactive safety designs to mitigate harassment in social\nVR. Proactive designs prevent harassment from occurring, while instant-reactive\ndesigns minimize harm during incidents. We explore three directions for design:\nuser-initiated personal bubbles, clarifying social norms, and encouraging\nbystander intervention. Through an iterative process, we first conducted a\nformative interview study to determine design goals for making these features\neffective, fit user needs, and robust to manipulation. We then implemented\nPuffer, an integrated safety system that includes a suite of proactive and\ninstant-reactive features, as a social VR prototype. From an evaluation using\nsimulated scenarios with participants, we find evidence that Puffer can help\nprotect players during emergencies, foster prosocial norms, and create more\npositive social interactions. We conclude by discussing how system safety\nfeatures can be designed to complement existing proactive and instant-reactive\nstrategies, particularly for people with marginalized identities.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-08T08:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.05789v1","title":"Leveraging Synthetic Adult Datasets for Unsupervised Infant Pose\n  Estimation","summary":"Human pose estimation is a critical tool across a variety of healthcare\napplications. Despite significant progress in pose estimation algorithms\ntargeting adults, such developments for infants remain limited. Existing\nalgorithms for infant pose estimation, despite achieving commendable\nperformance, depend on fully supervised approaches that require large amounts\nof labeled data. These algorithms also struggle with poor generalizability\nunder distribution shifts. To address these challenges, we introduce SHIFT:\nLeveraging SyntHetic Adult Datasets for Unsupervised InFanT Pose Estimation,\nwhich leverages the pseudo-labeling-based Mean-Teacher framework to compensate\nfor the lack of labeled data and addresses distribution shifts by enforcing\nconsistency between the student and the teacher pseudo-labels. Additionally, to\npenalize implausible predictions obtained from the mean-teacher framework, we\nincorporate an infant manifold pose prior. To enhance SHIFT's self-occlusion\nperception ability, we propose a novel visibility consistency module for\nimproved alignment of the predicted poses with the original image. Extensive\nexperiments on multiple benchmarks show that SHIFT significantly outperforms\nexisting state-of-the-art unsupervised domain adaptation (UDA) pose estimation\nmethods by 5% and supervised infant pose estimation methods by a margin of 16%.\nThe project page is available at: https://sarosijbose.github.io/SHIFT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:13:38Z"}
{"aid":"http://arxiv.org/abs/2504.05810v1","title":"PaMi-VDPO: Mitigating Video Hallucinations by Prompt-Aware\n  Multi-Instance Video Preference Learning","summary":"Direct Preference Optimization (DPO) helps reduce hallucinations in Video\nMultimodal Large Language Models (VLLMs), but its reliance on offline\npreference data limits adaptability and fails to capture true video-response\nmisalignment. We propose Video Direct Preference Optimization (VDPO), an online\npreference learning framework that eliminates the need for preference\nannotation by leveraging video augmentations to generate rejected samples while\nkeeping responses fixed. However, selecting effective augmentations is\nnon-trivial, as some clips may be semantically identical to the original under\nspecific prompts, leading to false rejections and disrupting alignment. To\naddress this, we introduce Prompt-aware Multi-instance Learning VDPO\n(PaMi-VDPO), which selects augmentations based on prompt context. Instead of a\nsingle rejection, we construct a candidate set of augmented clips and apply a\nclose-to-far selection strategy, initially ensuring all clips are semantically\nrelevant while then prioritizing the most prompt-aware distinct clip. This\nallows the model to better capture meaningful visual differences, mitigating\nhallucinations, while avoiding false rejections, and improving alignment.\nPaMi-VDPOseamlessly integrates into existing VLLMs without additional\nparameters, GPT-4/human supervision. With only 10k SFT data, it improves the\nbase model by 5.3% on VideoHallucer, surpassing GPT-4o, while maintaining\nstable performance on general video benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:41:41Z"}
{"aid":"http://arxiv.org/abs/2504.05826v1","title":"Work statistics and thermal phase transitions","summary":"The investigation of nonequilibrium thermodynamics in quantum many-body\nsystems underscores the importance of quantum work, which differs from its\nclassical counterpart due to its statistical nature. Recent studies have shown\nthat quantum work can serve as an effective indicator of quantum phase\ntransitions in systems subjected to sudden quenches. However, the potential of\nquantum work to identify thermal phase transitions remains largely unexplored.\nIn this paper, we examine several types of thermal phase transitions in a\nsudden-quench hard-core boson model, including Ising, three-state Potts, and\nBerezinskii-Kosterlitz-Thouless transitions. Through finite-size scaling\nanalysis, we conclude that work statistics can also characterize the critical\nbehaviors of thermal phase transitions in generic many-body systems. Our\ninvestigation paves the way for applying work statistics to characterize\ncritical behavior in many-body systems, with implications that may extend to\nbroader contexts.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T09:08:01Z"}
{"aid":"http://arxiv.org/abs/2504.05838v1","title":"Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and\n  Deceptive Jailbreaking","summary":"Recently, the Image Prompt Adapter (IP-Adapter) has been increasingly\nintegrated into text-to-image diffusion models (T2I-DMs) to improve\ncontrollability. However, in this paper, we reveal that T2I-DMs equipped with\nthe IP-Adapter (T2I-IP-DMs) enable a new jailbreak attack named the hijacking\nattack. We demonstrate that, by uploading imperceptible image-space adversarial\nexamples (AEs), the adversary can hijack massive benign users to jailbreak an\nImage Generation Service (IGS) driven by T2I-IP-DMs and mislead the public to\ndiscredit the service provider. Worse still, the IP-Adapter's dependency on\nopen-source image encoders reduces the knowledge required to craft AEs.\nExtensive experiments verify the technical feasibility of the hijacking attack.\nIn light of the revealed threat, we investigate several existing defenses and\nexplore combining the IP-Adapter with adversarially trained models to overcome\nexisting defenses' limitations. Our code is available at\nhttps://github.com/fhdnskfbeuv/attackIPA.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-08T09:20:29Z"}
{"aid":"http://arxiv.org/abs/2504.05852v1","title":"Physics-aware generative models for turbulent fluid flows through\n  energy-consistent stochastic interpolants","summary":"Generative models have demonstrated remarkable success in domains such as\ntext, image, and video synthesis. In this work, we explore the application of\ngenerative models to fluid dynamics, specifically for turbulence simulation,\nwhere classical numerical solvers are computationally expensive. We propose a\nnovel stochastic generative model based on stochastic interpolants, which\nenables probabilistic forecasting while incorporating physical constraints such\nas energy stability and divergence-freeness. Unlike conventional stochastic\ngenerative models, which are often agnostic to underlying physical laws, our\napproach embeds energy consistency by making the parameters of the stochastic\ninterpolant learnable coefficients. We evaluate our method on a benchmark\nturbulence problem - Kolmogorov flow - demonstrating superior accuracy and\nstability over state-of-the-art alternatives such as autoregressive conditional\ndiffusion models (ACDMs) and PDE-Refiner. Furthermore, we achieve stable\nresults for significantly longer roll-outs than standard stochastic\ninterpolants. Our results highlight the potential of physics-aware generative\nmodels in accelerating and enhancing turbulence simulations while preserving\nfundamental conservation properties.","main_category":"cs.CE","categories":"cs.CE,cs.AI,cs.NA,math.NA","published":"2025-04-08T09:29:01Z"}
{"aid":"http://arxiv.org/abs/2504.05912v1","title":"Financial resilience of agricultural and food production companies in\n  Spain: A compositional cluster analysis of the impact of the Ukraine-Russia\n  war (2021-2023)","summary":"This study analyzes the financial resilience of agricultural and food\nproduction companies in Spain amid the Ukraine-Russia war using cluster\nanalysis based on financial ratios. This research utilizes centered log-ratios\nto transform financial ratios for compositional data analysis. The dataset\ncomprises financial information from 1197 firms in Spain's agricultural and\nfood sectors over the period 2021-2023. The analysis reveals distinct clusters\nof firms with varying financial performance, characterized by metrics of\nsolvency and profitability. The results highlight an increase in resilient\nfirms by 2023, underscoring sectoral adaptation to the conflict's economic\nchallenges. These findings together provide insights for stakeholders and\npolicymakers to improve sectorial stability and strategic planning.","main_category":"q-fin.ST","categories":"q-fin.ST,stat.AP","published":"2025-04-08T11:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.05932v1","title":"The complete trans-series for conserved charges in the Lieb-Liniger\n  model","summary":"We determine the complete trans-series solution for the (non-relativistic)\nmoments of the rapidity density in the Lieb-Liniger model. The trans-series is\nwritten explicitly in terms of a perturbative basis, which can be obtained from\nthe already known perturbative expansion of the density by solving several\nordinary differential equations. Unknown integration constants are fixed from\nVolin's method. We have checked that our solution satisfies the analytical\nconsistency requirements including the newly derived resurgence relations and\nagrees with the high precision numerical solution. Our results also provides\nthe full analytic trans-series for the capacitance of the coaxial circular\nplate capacitor.","main_category":"hep-th","categories":"hep-th,cond-mat.quant-gas,cond-mat.stat-mech","published":"2025-04-08T11:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.05939v1","title":"Collision-free landing of multiple UAVs on moving ground vehicles using\n  time-varying control barrier functions","summary":"In this article, we present a centralized approach for the control of\nmultiple unmanned aerial vehicles (UAVs) for landing on moving unmanned ground\nvehicles (UGVs) using control barrier functions (CBFs). The proposed control\nframework employs two kinds of CBFs to impose safety constraints on the UAVs'\nmotion. The first class of CBFs (LCBF) is a three-dimensional exponentially\ndecaying function centered above the landing platform, designed to safely and\nprecisely land UAVs on the UGVs. The second set is a spherical CBF (SCBF),\ndefined between every pair of UAVs, which avoids collisions between them. The\nLCBF is time-varying and adapts to the motions of the UGVs. In the proposed CBF\napproach, the control input from the UAV's nominal tracking controller designed\nto reach the landing platform is filtered to choose a minimally-deviating\ncontrol input that ensures safety (as defined by the CBFs). As the control\ninputs of every UAV are shared in establishing multiple CBF constraints, we\nprove that the control inputs are shared without conflict in rendering the safe\nsets forward invariant. The performance of the control framework is validated\nthrough a simulated scenario involving three UAVs landing on three moving\ntargets.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T11:54:45Z"}
{"aid":"http://arxiv.org/abs/2504.05943v1","title":"New inequalities for the extended Euler-PoincarÃ© theorem","summary":"In [Acta Math. 161 (3--4) (1988) 279--303], Bj\\\"{o}rner and Kalai extended\nthe classic Euler-Poincar\\'{e} theorem by introducing certain nonlinear\nrelations between the $f$-vector and the Betti sequence of simplicial\ncomplexes. In this paper, we present an equivalent characterization of\nBj\\\"{o}rner and Kalai's nonlinear relations using a number-theoretic approach.\nMoreover, we strengthen a result of Bj\\\"{o}rner and Kalai concerning the\nmaximal element of Betti sequences with respect to a fixed $f$-vector and the\nminimal element of $f$-vectors with respect to a fixed Betti sequence.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T11:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.05945v1","title":"CKGAN: Training Generative Adversarial Networks Using Characteristic\n  Kernel Integral Probability Metrics","summary":"In this paper, we propose CKGAN, a novel generative adversarial network (GAN)\nvariant based on an integral probability metrics framework with characteristic\nkernel (CKIPM). CKIPM, as a distance between two probability distributions, is\ndesigned to optimize the lowerbound of the maximum mean discrepancy (MMD) in a\nreproducing kernel Hilbert space, and thus can be used to train GANs. CKGAN\nmitigates the notorious problem of mode collapse by mapping the generated\nimages back to random noise. To save the effort of selecting the kernel\nfunction manually, we propose a soft selection method to automatically learn a\ncharacteristic kernel function. The experimental evaluation conducted on a set\nof synthetic and real image benchmarks (MNIST, CelebA, etc.) demonstrates that\nCKGAN generally outperforms other MMD-based GANs. The results also show that at\nthe cost of moderately more training time, the automatically selected kernel\nfunction delivers very close performance to the best of manually fine-tuned one\non real image benchmarks and is able to improve the performances of other\nMMD-based GANs.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-08T11:58:56Z"}
{"aid":"http://arxiv.org/abs/2504.05982v1","title":"Have you tried turning it off and on again? Stochastic resetting for\n  enhanced sampling","summary":"Molecular dynamics simulations are widely used across chemistry, physics, and\nbiology, providing quantitative insight into complex processes with atomic\ndetail. However, their limited timescale of a few microseconds is a significant\nobstacle in describing phenomena such as conformational transitions of\nbiomolecules and polymorphism in molecular crystals. Recently, stochastic\nresetting, i.e., randomly stopping and restarting the simulations, emerged as a\npowerful enhanced sampling approach, which is collective variable-free, highly\nparallelized, and easily implemented in existing molecular dynamics codes.\nResetting expedites sampling rare events while enabling the inference of\nkinetic observables of the underlying process. It can be employed as a\nstandalone tool or in combination with other enhanced sampling methods, such as\nMetadynamics, with each technique compensating for the drawbacks of the other.\nHere, we comprehensively describe resetting and its theoretical background,\nreview recent developments in stochastic resetting for enhanced sampling, and\nprovide instructive guidelines for practitioners.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-08T12:39:14Z"}
{"aid":"http://arxiv.org/abs/2504.05986v1","title":"Nehari's Theorem for Schatten class Hankel operators for convex domains","summary":"Recently it was proven that for a convex subset of $\\mathbb{R}^{n}$ that has\ninfinitely many extreme vectors, the Nehari theorem fails, that is, there\nexists a bounded Hankel operator $H_{\\phi}$ on the Paley--Wiener space\n$PW(\\Omega)$ that does not admit a bounded symbol. In this paper we examine\nwhether Nehari's theorem can hold under the stronger assumption that the Hankel\noperator $H_{\\phi}$ is in the Schatten class $S^{p}(PW(\\Omega))$. We prove that\nthis fails for $p>4$ for any convex subset of $\\mathbb{R}^{n}$, $n\\geq2$, of\nboundary with a $C^{2}$ neighborhood of nonzero curvature. Furthermore we prove\nthat for a simple polytope $P$ in $\\mathbb{R}^{n}$, the inequality\n$$\\int_{\\mathbb{R}^{n}}\\dfrac{|\\widehat{f}(x)|^{2}}{m(P\\cap (x-P))}dx\\leq\nC\\|f\\|_{L^{1}}^{2},$$ holds for all $f\\in PW^{1}(2P)$, and consequently any\nHilbert--Schmidt Hankel operator on a Paley--Wiener space of a simple polytope\nis generated by a bounded function.","main_category":"math.FA","categories":"math.FA","published":"2025-04-08T12:48:16Z"}
{"aid":"http://arxiv.org/abs/2504.05992v1","title":"Under-Sampled High-Dimensional Data Recovery via Symbiotic Multi-Prior\n  Tensor Reconstruction","summary":"The advancement of sensing technology has driven the widespread application\nof high-dimensional data. However, issues such as missing entries during\nacquisition and transmission negatively impact the accuracy of subsequent\ntasks. Tensor reconstruction aims to recover the underlying complete data from\nunder-sampled observed data by exploring prior information in high-dimensional\ndata. However, due to insufficient exploration, reconstruction methods still\nface challenges when sampling rate is extremely low. This work proposes a\ntensor reconstruction method integrating multiple priors to comprehensively\nexploit the inherent structure of the data. Specifically, the method combines\nlearnable tensor decomposition to enforce low-rank constraints of the\nreconstructed data, a pre-trained convolutional neural network for smoothing\nand denoising, and block-matching and 3D filtering regularization to enhance\nthe non-local similarity in the reconstructed data. An alternating direction\nmethod of the multipliers algorithm is designed to decompose the resulting\noptimization problem into three subproblems for efficient resolution. Extensive\nexperiments on color images, hyperspectral images, and grayscale videos\ndatasets demonstrate the superiority of our method in extreme cases as compared\nwith state-of-the-art methods.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T12:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.06035v1","title":"Cosmic inflation in non-perturbative quantum gravity","summary":"String field theory motivated infinite-derivative models lead to non-local\ngravity modifications which form a promising class of quantum gravity\ncandidates. In this paper we investigate effects of non-locality on the\nthree-point function (the bi-spectrum) during cosmic inflation. The study is\ndone in an Einstein frame with an infinite-derivative scalar field Lagrangian\nminimally coupled to the Einstein-Hilbert term. A non-local generalization of\nthe Mukhanov-Sasaki equation is derived. Infinite-derivative operators present\nin this equation lead to an appearance of infinitely many new background\ninduced states in the perturbation spectrum during inflation with complex\nmasses on top of a usual nearly massless inflaton. On contrary to a flat\nbackground such states can be classically stable in a de Sitter space-time.\nThis helps preserving observational constraints on the scalar power-spectrum.\nWe proceed by studying a particular configuration assuming that the generalized\nMukhanov-Sasaki equation gives rise to an inflaton and one pair of new states\nwith complex conjugate masses as perturbative degrees of freedom. The\ncorresponding scalar bi-spectrum is computed numerically in squeezed and\nequilateral limits. We use the latest observational constraints on amplitude of\nthe bi-spectrum $f_{NL}$ from Planck 2018 dataset as a guideline for possible\nvalues of masses of new emerging states. We find that $f_{NL}$ is non-trivially\nsensitive to the values of complex masses and this can reduce the parameter\nspace of gravity modifications. In particular we find that the amplitude of the\nsqueezed limit gets easily enhanced while of the equilateral limit can stay\nlike in a local single-field model of inflation. We end up discussing open\nquestions relevant for this class of models of inflation.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-04-08T13:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.06072v1","title":"Black hole quasinormal mode resonances","summary":"Black hole quasinormal mode frequencies can be very close to each other\n(\"avoided crossings\") or even completely degenerate (\"exceptional points\") when\nthe system is characterized by more than one parameter. We investigate this\nresonant behavior and demonstrate that near exceptional points, the two modes\nare just different covers of the same complex function on a Riemann surface. We\nalso study the characteristic time domain signal due to the resonance in the\nfrequency domain, illustrating the analogy between black hole signals at\nresonance and harmonic oscillators driven by a resonant external force. We\ncarry out a numerical study of resonances between the fundamental mode and the\nfirst overtone in a specific toy model. We find that quasinormal mode\nfrequencies will not be accurately constrained unless we take into account the\neffect of resonances.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-08T14:12:04Z"}
{"aid":"http://arxiv.org/abs/2504.06119v1","title":"Variational discretizations of viscous and resistive\n  magnetohydrodynamics using structure-preserving finite elements","summary":"We propose a novel structure preserving discretization for viscous and\nresistive magnetohydrodynamics. We follow the recent line of work on discrete\nleast action principle for fluid and plasma equation, incorporating the recent\nadvances to model dissipative phenomena through a generalized Lagrange-d\nAlembert constrained variational principle. We prove that our semi-discrete\nscheme is equivalent to a metriplectic system and use this property to propose\na Poisson splitting time integration. The resulting approximation preserves\nmass, energy and the divergence constraint of the magnetic field. We then show\nsome numerical results obtained with our approach. We first test our scheme on\nsimple academic test to compare the results with established methodologies, and\nthen focus specifically on the simulation of plasma instabilities, with some\ntests on non Cartesian geometries to validate our discretization in the scope\nof tokamak instabilities.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T15:12:32Z"}
{"aid":"http://arxiv.org/abs/2504.06128v1","title":"Singularity and regularity of the critical 2D Stochastic Heat Flow","summary":"The Critical 2D Stochastic Heat Flow (SHF) provides a natural candidate\nsolution to the ill-posed 2D Stochastic Heat Equation with multiplicative\nspace-time white noise. In this paper, we initiate the investigation of the\nspatial properties of the SHF. We prove that, as a random measure on\n$\\mathbb{R}^2$, it is a.s. singular w.r.t. the Lebesgue measure. This is\nobtained by probing a \"quasi-critical\" regime and showing the asymptotic\nlog-normality of the mass assigned to vanishing balls, as the disorder strength\nis sent to zero at a suitable rate, accompanied by similar results for critical\n2D directed polymers. We also describe the regularity of the SHF, showing that\nit is a.s. H\\\"older $C^{-\\epsilon}$ for any $\\epsilon>0$, implying the absence\nof atoms, and we establish local convergence to zero in the long time limit.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-08T15:21:44Z"}
{"aid":"http://arxiv.org/abs/2504.06156v1","title":"ViTaMIn: Learning Contact-Rich Tasks Through Robot-Free Visuo-Tactile\n  Manipulation Interface","summary":"Tactile information plays a crucial role for humans and robots to interact\neffectively with their environment, particularly for tasks requiring the\nunderstanding of contact properties. Solving such dexterous manipulation tasks\noften relies on imitation learning from demonstration datasets, which are\ntypically collected via teleoperation systems and often demand substantial time\nand effort. To address these challenges, we present ViTaMIn, an embodiment-free\nmanipulation interface that seamlessly integrates visual and tactile sensing\ninto a hand-held gripper, enabling data collection without the need for\nteleoperation. Our design employs a compliant Fin Ray gripper with tactile\nsensing, allowing operators to perceive force feedback during manipulation for\nmore intuitive operation. Additionally, we propose a multimodal representation\nlearning strategy to obtain pre-trained tactile representations, improving data\nefficiency and policy robustness. Experiments on seven contact-rich\nmanipulation tasks demonstrate that ViTaMIn significantly outperforms baseline\nmethods, demonstrating its effectiveness for complex manipulation tasks.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T15:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.06189v1","title":"Accessible and Pedagogically-Grounded Explainability for Human-Robot\n  Interaction: A Framework Based on UDL and Symbolic Interfaces","summary":"This paper presents a novel framework for accessible and\npedagogically-grounded robot explainability, designed to support human-robot\ninteraction (HRI) with users who have diverse cognitive, communicative, or\nlearning needs. We combine principles from Universal Design for Learning (UDL)\nand Universal Design (UD) with symbolic communication strategies to facilitate\nthe alignment of mental models between humans and robots. Our approach employs\nAsterics Grid and ARASAAC pictograms as a multimodal, interpretable front-end,\nintegrated with a lightweight HTTP-to-ROS 2 bridge that enables real-time\ninteraction and explanation triggering. We emphasize that explainability is not\na one-way function but a bidirectional process, where human understanding and\nrobot transparency must co-evolve. We further argue that in educational or\nassistive contexts, the role of a human mediator (e.g., a teacher) may be\nessential to support shared understanding. We validate our framework with\nexamples of multimodal explanation boards and discuss how it can be extended to\ndifferent scenarios in education, assistive robotics, and inclusive AI.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-08T16:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.06191v1","title":"Impact of MvdW Equation of State and Neutrino Mass on r and s Process\n  Heavy Element Nucleosynthesis in Spiral, Elliptical and Dwarf Galactic\n  Environments and Kilonovae Events","summary":"We present an analysis of heavy element production with massive neutrinos in\ngalaxies of varying types (spiral, elliptical, and dwarf) and kilonovae events\nby incorporating a Multicomponent van der Waals (MvdW) equation of state (EoS)\nfor the opacity functions. This EoS is applied to derive opacities and\ncalculate the yields of isotopes formed in r-process and s-process\nnucleosynthesis, with and without the influence of neutrino masses or\noscillations. We look at both the lanthanide and actinide sequences using the\nMvdW parameters that involve the interaction strength and excluded volume\neffects. Our results reflect the characteristic differences found in r and s\nprocesses in the synthesis and long-term evolution of isotopes from the U, Th,\nand Sr chain across galactic environments. The inclusion of neutrino masses\nenhances the neutron-to-proton ratio, favoring heavier r-process isotopes and\naltering the overall galactic yields by cross section suppression. These\nfindings offer insights into the interplay of nuclear physics and astrophysical\nenvironments, highlighting the sensitivity of nucleosynthetic pathways to EoS\nmodifications and neutrino physics. We compare these results to metallicity\nprofiles of similar models: the Galactic Leaky Box, the Galactic Inflow, and\nthe Galactic Closed Box models and to the kilonova event GW170781.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-08T16:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.06200v1","title":"Day algebras","summary":"In this paper we show that the Day monoidal product generalises in a\nstraightforward way to other algebraic constructions and partial algebraic\nconstructions on categories. This generalisation was motivated by its\napplications in logic, for example in hybrid and separation logic. We use the\ndescription of the Day monoidal product using profunctors to show that the\ndefinition generalises to an extension of an arbitrary algebraic structure on a\ncategory to a pseudo-algebraic structure on a functor category. We provide two\nfurther extensions. First we consider the case where some of the operations on\nthe category are partial, and second we show that the resulting operations on\nthe functor category have adjoints (they are residuated).","main_category":"math.CT","categories":"math.CT","published":"2025-04-08T16:42:54Z"}
{"aid":"http://arxiv.org/abs/2504.06202v1","title":"Up-to-constants estimates on four-arm events for simple conformal loop\n  ensemble","summary":"We prove up-to-constants estimates for a general class of four-arm events in\nsimple conformal loop ensembles, i.e. CLE$_\\kappa$ for $\\kappa\\in (8/3,4]$. The\nfour-arm events that we consider can be created by either one or two loops,\nwith no constraint on the topology of the crossings. Our result is a key input\nin our series of works arxiv:2409.16230 and arxiv:2409.16273 on percolation of\nthe two-sided level sets in the discrete Gaussian free field (and level sets in\nthe occupation field of the random walk loop soup).\n  In order to get rid of all constraints on the topology of the crossings, we\nrely on the Brownian loop-soup representation of simple CLE [Ann. Math. 176\n(2012) 1827-1917], and a \"cluster version\" of a separation lemma for the\nBrownian loop soup. As a corollary, we also obtain up-to-constants estimates\nfor a general version of four-arm events for SLE$_\\kappa$ for $\\kappa\\in\n(8/3,4]$. This fixes (in the case of four arms and $\\kappa\\in(8/3,4]$) an\nessential gap in [Ann. Probab. 46 (2018) 2863-2907] and improves some estimates\ntherein.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-08T16:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.06221v1","title":"Quantum-stabilized states in magnetic dipolar quantum gases","summary":"A decade ago, a universal stabilization mechanism driven by quantum\nfluctuations was discovered in ultracold Bose gases of highly magnetic atoms.\nThis mechanism prevents these systems from collapsing and instead allows exotic\nstates of matter to arise, including ultradilute quantum droplets, crystallized\nquantum states, and specifically supersolids. We review the experimental and\ntheoretical progress in understanding these quantum-stabilized states, their\nemergence, and intriguing properties.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.stat-mech,physics.atom-ph,quant-ph","published":"2025-04-08T17:10:11Z"}
{"aid":"http://arxiv.org/abs/2504.06257v1","title":"PainNet: Statistical Relation Network with Episode-Based Training for\n  Pain Estimation","summary":"Despite the span in estimating pain from facial expressions, limited works\nhave focused on estimating the sequence-level pain, which is reported by\npatients and used commonly in clinics. In this paper, we introduce a novel\nStatistical Relation Network, referred to as PainNet, designed for the\nestimation of the sequence-level pain. PainNet employs two key modules, the\nembedding and the relation modules, for comparing pairs of pain videos, and\nproducing relation scores indicating if each pair belongs to the same pain\ncategory or not. At the core of the embedding module is a statistical layer\nmounted on the top of a RNN for extracting compact video-level features. The\nstatistical layer is implemented as part of the deep architecture. Doing so,\nallows combining multiple training stages used in previous research, into a\nsingle end-to-end training stage. PainNet is trained using the episode-based\ntraining scheme, which involves comparing a query video with a set of videos\nrepresenting the different pain categories. Experimental results show the\nbenefit of using the statistical layer and the episode-based training in the\nproposed model. Furthermore, PainNet outperforms the state-of-the-art results\non self-reported pain estimation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:58:52Z"}
{"aid":"http://arxiv.org/abs/2504.06262v1","title":"Paraxial fluids of light","summary":"Paraxial fluids of light are a promising platform for exploring collective\nphenomena in a highly tunable environment. These systems, which map the\npropagation of light through nonlinear media onto the wavefunction of effective\n2D quantum fluids, offer a complementary approach to traditional platforms such\nas cold atomic gases or superfluid helium. In this review, we present a\ndetailed overview of the theoretical framework underlying paraxial fluids of\nlight, including the nonlinear Schr\\\"odinger equation (NLSE) and its mapping to\nthe 2D+1 Gross-Pitaevskii equation (GPE). We explore the hydrodynamic\nformulation of these systems and we provide a comparative analysis of fluids of\nlight and cold atomic gases, examining key parameters and figures of merit.\n  We then review the recent experimental advances and the experimental\nplatforms currently used to realize paraxial fluids of light, including hot\natomic vapors, photorefractive crystals, and thermo-optic media. Additionally,\nwe question the geometry of the system extending the analogy from 2D+1 to lower\nor higher dimensions.\n  Looking forward, we outline the potential future directions for the field,\nincluding the use of laser cooled atoms as nonlinear media, the study of\ntwo-component mixtures, and the exploration of quantum effects beyond the\nmean-field approximation. These developments promise to deepen our\nunderstanding of quantum fluids and potentially contribute to advances in\nquantum technologies.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,quant-ph","published":"2025-04-08T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.06553v1","title":"ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis","summary":"While recent work in scene reconstruction and understanding has made strides\nin grounding natural language to physical 3D environments, it is still\nchallenging to ground abstract, high-level instructions to a 3D scene.\nHigh-level instructions might not explicitly invoke semantic elements in the\nscene, and even the process of breaking a high-level task into a set of more\nconcrete subtasks, a process called hierarchical task analysis, is\nenvironment-dependent. In this work, we propose ASHiTA, the first framework\nthat generates a task hierarchy grounded to a 3D scene graph by breaking down\nhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assisted\nhierarchical task analysis, to generate the task breakdown, with task-driven 3D\nscene graph construction to generate a suitable representation of the\nenvironment. Our experiments show that ASHiTA performs significantly better\nthan LLM baselines in breaking down high-level tasks into environment-dependent\nsubtasks and is additionally able to achieve grounding performance comparable\nto state-of-the-art methods.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-09T03:22:52Z"}
{"aid":"http://arxiv.org/abs/2504.06570v1","title":"Data quality or data quantity? Prioritizing data collection under\n  distribution shift with the data usefulness coefficient","summary":"Researchers often have access to multiple data sources of varying quality.\nFor example, in psychology, a researcher may decide between running an\nexperiment on an online platform or on a representative sample of the\npopulation of interest. Collecting a representative sample will result in\nhigher quality data but is often more expensive. This raises the question of\nhow to optimally prioritize data collection under resource constraints. We\nstudy this question in a setting where the distribution shift arises through\nmany independent random changes in the population. We introduce a \"data\nusefulness coefficient\" (DUC) and show that it allows us to predict how much\nthe risk of empirical risk minimization would decrease if a specific data set\nwere added to the training data. An advantage of our procedure is that it does\nnot require access to any outcome data $Y$. Instead, we rely on a random shift\nassumption, which implies that the strength of covariate ($X$) shift is\npredictive of the shift in $Y \\mid X$. We also derive methods for sampling\nunder budget and size constraints. We demonstrate the benefits of data\ncollection based on DUC and our optimal sampling strategy in several numerical\nexperiments.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T04:11:22Z"}
{"aid":"http://arxiv.org/abs/2504.06585v1","title":"Sim-to-Real of Humanoid Locomotion Policies via Joint Torque Space\n  Perturbation Injection","summary":"This paper proposes a novel alternative to existing sim-to-real methods for\ntraining control policies with simulated experiences. Prior sim-to-real methods\nfor legged robots mostly rely on the domain randomization approach, where a\nfixed finite set of simulation parameters is randomized during training.\nInstead, our method adds state-dependent perturbations to the input joint\ntorque used for forward simulation during the training phase. These\nstate-dependent perturbations are designed to simulate a broader range of\nreality gaps than those captured by randomizing a fixed set of simulation\nparameters. Experimental results show that our method enables humanoid\nlocomotion policies that achieve greater robustness against complex reality\ngaps unseen in the training domain.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T05:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.06586v1","title":"Diversity-aware Dual-promotion Poisoning Attack on Sequential\n  Recommendation","summary":"Sequential recommender systems (SRSs) excel in capturing users' dynamic\ninterests, thus playing a key role in various industrial applications. The\npopularity of SRSs has also driven emerging research on their security aspects,\nwhere data poisoning attack for targeted item promotion is a typical example.\nExisting attack mechanisms primarily focus on increasing the ranks of target\nitems in the recommendation list by injecting carefully crafted interactions\n(i.e., poisoning sequences), which comes at the cost of demoting users' real\npreferences. Consequently, noticeable recommendation accuracy drops are\nobserved, restricting the stealthiness of the attack. Additionally, the\ngenerated poisoning sequences are prone to substantial repetition of target\nitems, which is a result of the unitary objective of boosting their overall\nexposure and lack of effective diversity regularizations. Such homogeneity not\nonly compromises the authenticity of these sequences, but also limits the\nattack effectiveness, as it ignores the opportunity to establish sequential\ndependencies between the target and many more items in the SRS. To address the\nissues outlined, we propose a Diversity-aware Dual-promotion Sequential\nPoisoning attack method named DDSP for SRSs. Specifically, by theoretically\nrevealing the conflict between recommendation and existing attack objectives,\nwe design a revamped attack objective that promotes the target item while\nmaintaining the relevance of preferred items in a user's ranking list. We\nfurther develop a diversity-aware, auto-regressive poisoning sequence\ngenerator, where a re-ranking method is in place to sequentially pick the\noptimal items by integrating diversity constraints.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T05:28:41Z"}
{"aid":"http://arxiv.org/abs/2504.06588v1","title":"A Digital Twin of an Electrical Distribution Grid: SoCal 28-Bus Dataset","summary":"We provide an open-access dataset of phasor & waveform measurement units\n(PMUs/WMUs) of a real-world electrical distribution network. The network\nconsists of diverse sets of generation resources (including solar panels, fuel\ncells, natural gas generators, and utility interconnections), loads (including\nlarge-scale electric vehicle charging, data centers, central cooling, offices),\ntopology changes (such as line outages and load transfers), as well as a\nmixture of single- and three-phase networks. We describe a densely deployed PMU\nsensor network in a distribution grid, in which all buses with non-zero power\ninjections are measured. This approach enables a range of applications such as\nstate estimation, system identification, power flow optimization, and feedback\ncontrol, several of which are discussed in this paper. Additionally, we provide\na synchronized waveform dataset which allows the analysis of harmonics,\ntransient events, dynamic grid impedance, and stability. Data collection\nstarted in 2023 while new data is generated continuously and made available\nonline. A characterization of measurement error is provided. Finally, we\nprovide circuit topology and parameters as a part of the dataset. Together, the\ncircuit and timeseries data offer an opportunity for researchers to develop and\ntest algorithms on a real-world system.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T05:35:07Z"}
{"aid":"http://arxiv.org/abs/2504.06601v1","title":"Rounding of discrete variables","summary":"Let $X$ be a random variable that takes its values in\n$\\frac{1}{q}\\mathbb{Z}$, for some integer $q\\ge2$, and consider $X$ rounded to\nan integer, either downwards or upwards or to the nearest integer. We give\ngeneral formulas for the characteristic function and moments of the rounded\nvariable. These formulas complement the related but different formulas in the\ncase that $X$ has a continuous distribution, which was studied by Janson\n(2006).","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T05:59:14Z"}
{"aid":"http://arxiv.org/abs/2504.06608v1","title":"A Cross-Domain Few-Shot Learning Method Based on Domain Knowledge\n  Mapping","summary":"In task-based few-shot learning paradigms, it is commonly assumed that\ndifferent tasks are independently and identically distributed (i.i.d.).\nHowever, in real-world scenarios, the distribution encountered in few-shot\nlearning can significantly differ from the distribution of existing data. Thus,\nhow to effectively leverage existing data knowledge to enable models to quickly\nadapt to class variations under non-i.i.d. assumptions has emerged as a key\nresearch challenge. To address this challenge, this paper proposes a new\ncross-domain few-shot learning approach based on domain knowledge mapping,\napplied consistently throughout the pre-training, training, and testing phases.\nIn the pre-training phase, our method integrates self-supervised and supervised\nlosses by maximizing mutual information, thereby mitigating mode collapse.\nDuring the training phase, the domain knowledge mapping layer collaborates with\na domain classifier to learn both domain mapping capabilities and the ability\nto assess domain adaptation difficulty. Finally, this approach is applied\nduring the testing phase, rapidly adapting to domain variations through\nmeta-training tasks on support sets, consequently enhancing the model's\ncapability to transfer domain knowledge effectively. Experimental validation\nconducted across six datasets from diverse domains demonstrates the\neffectiveness of the proposed method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T06:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.06630v1","title":"Two-Axis planar Hall magnetic field sensors with sub nanoTesla\n  resolution","summary":"Planar Hall effect (PHE) magnetic sensors are attractive for various\napplications where the field resolution is required in the range of sub-nano\nTesla or in Pico Tesla. Here we present a detailed noise study of the PHE\nsensors consisting of two or three intersecting ellipses. It can be used to\nmeasure two axes of the magnetic field in the sensor plane in particular along\nthe two perpendicular easy axes in the overlapping region for two intersecting\nellipses and three easy axes at an angle of 60 degrees for three crossing\nellipses. Thus, for each remanent magnetic state in the overlap area, the\nsensor can measure the vector component of the magnetic field perpendicular to\nthe direction of the remanent magnetization. The two field components are\nmeasured with a field resolution less than 200 pT/sqrt(Hz) at 10 Hz and 350\npT/sqrt(Hz) at 1 Hz in the same region, while maintaining a similar size and\nnoise level of a single-axis sensor. Furthermore, we discuss here the possible\nroute for future improvement of the field resolution","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-09T07:07:27Z"}
{"aid":"http://arxiv.org/abs/2504.06648v1","title":"Semiclassical concentration estimates for Berezin-Toeplitz quasimodes\n  for regular energies","summary":"The purpose of this article is to prove sharp $L^p$ bounds for quasimodes of\nBerezin-Toeplitz operators. We consider examples with explicit computations and\na general situation on compact spaces and $\\Cm^n$. In both cases the eigenvalue\nis a regular value of the operator symbol. We then use the link between\npseudodifferential and Berezin-Toeplitz operators to obtain an $L^p$ bound of\nthe FBI transform of quasimodes of pseudodifferential operators.","main_category":"math.CV","categories":"math.CV,math.SG,math.SP","published":"2025-04-09T07:36:30Z"}
{"aid":"http://arxiv.org/abs/2504.06667v1","title":"Toward Holistic Evaluation of Recommender Systems Powered by Generative\n  Models","summary":"Recommender systems powered by generative models (Gen-RecSys) extend beyond\nclassical item ranking by producing open-ended content, which simultaneously\nunlocks richer user experiences and introduces new risks. On one hand, these\nsystems can enhance personalization and appeal through dynamic explanations and\nmulti-turn dialogues. On the other hand, they might venture into unknown\nterritory-hallucinating nonexistent items, amplifying bias, or leaking private\ninformation. Traditional accuracy metrics cannot fully capture these\nchallenges, as they fail to measure factual correctness, content safety, or\nalignment with user intent.\n  This paper makes two main contributions. First, we categorize the evaluation\nchallenges of Gen-RecSys into two groups: (i) existing concerns that are\nexacerbated by generative outputs (e.g., bias, privacy) and (ii) entirely new\nrisks (e.g., item hallucinations, contradictory explanations). Second, we\npropose a holistic evaluation approach that includes scenario-based assessments\nand multi-metric checks-incorporating relevance, factual grounding, bias\ndetection, and policy compliance. Our goal is to provide a guiding framework so\nresearchers and practitioners can thoroughly assess Gen-RecSys, ensuring\neffective personalization and responsible deployment.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T08:08:16Z"}
{"aid":"http://arxiv.org/abs/2504.06673v1","title":"Are Molecules Magical? Non-Stabilizerness in Molecular Bonding","summary":"Isolated atoms as well as molecules at equilibrium are presumed to be simple\nfrom the point of view of quantum computational complexity. Here we show that\nthe process of chemical bond formation is accompanied by a marked increase in\nthe quantum complexity of the electronic ground state. By studying the hydrogen\ndimer H$_{2}$ as a prototypical example, we demonstrate that when two hydrogen\natoms form a bond, a specific measure of quantum complexity exhibits a\npronounced peak that closely follows the behavior of the binding energy. This\nmeasure of quantum complexity, known as magic in the quantum information\nliterature, reflects how difficult it is to simulate the state using classical\nmethods. This observation suggests that regions of strong bonding formation or\nbreaking are also regions of enhanced intrinsic quantum complexity. This\ninsight suggests a connection of quantum information measures to chemical\nreactivity and advocates the use of stretched molecules as a quantum\ncomputational resource.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph","published":"2025-04-09T08:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.06678v1","title":"Geometric Quantum Gates of Non-closed Paths Under Counterdiabatic\n  Driving","summary":"Non-adiabatic and non-closed evolutionary paths play a significant role in\nthe fidelity of quantum gates. We propose a high-fidelity quantum control\nframework based on the quasi-topological number ($\\nu_{\\text{qua}}$), which\nextends the traditional Chern number to characterize geometric responses in\nnon-closed paths. By introducing a counterdiabatic gauge potential (AGP) that\ndynamically suppresses non-adiabatic transitions and reconstructs path\ncurvature, we demonstrate that $\\nu_{\\text{qua}}$ -a relative homotopy\ninvariant of compact manifolds in parameter space-quantifies the robustness of\ngeometric phases during open-path quantum evolution. This integer invariant\nensures gauge-invariant suppression of decoherence errors arising from\ndynamical phase coupling. By introducing nonlinear parametric ring paths, we\naddress the defects caused by intermediate states in the Rydberg atomic system.\nNumerical simulations in the Kitaev superconducting chain and 2D\ntransverse-field Ising model confirm that our protocol achieves quantum gate\nfidelity exceeding $\\mathcal{F} > 0.9999$. We bridges geometric quantum control\nwith topological protection, offering a universal approach to noise-resistant\nquantum computing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T08:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.06687v1","title":"Response to an external field of a generalized Langevin equation with\n  stochastic resetting of the memory kernel","summary":"We study a generalized Langevin equation (GLE) framework that incorporates\nstochastic resetting of a truncation power-law memory kernel. The inclusion of\nstochastic resetting enables the emergence of resonance phenomena even in\nparameter regimes where conventional settings (without resetting) do not\nexhibit such behavior. Specifically, we explore the response of the system to\nan external field under three scenarios: (i) a free particle, (ii) a particle\nin a harmonic potential, and (iii) the effect of truncation in the memory\nkernel. In each case, the primary focus is on understanding how the resetting\nmechanism interacts with standard parameters to induce stochastic resonance. In\naddition, we explore the effect of resetting on the dielectric loss.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-09T08:48:11Z"}
{"aid":"http://arxiv.org/abs/2504.06697v1","title":"\"Sorry for bugging you so much.\" Exploring Developers' Behavior Towards\n  Privacy-Compliant Implementation","summary":"While protecting user data is essential, software developers often fail to\nfulfill privacy requirements. However, the reasons why they struggle with\nprivacy-compliant implementation remain unclear. Is it due to a lack of\nknowledge, or is it because of insufficient support? To provide foundational\ninsights in this field, we conducted a qualitative 5-hour programming study\nwith 30 professional software developers implementing 3 privacy-sensitive\nprogramming tasks that were designed with GDPR compliance in mind. To explore\nif and how developers implement privacy requirements, participants were divided\ninto 3 groups: control, privacy prompted, and privacy expert-supported. After\ntask completion, we conducted follow-up interviews. Alarmingly, almost all\nparticipants submitted non-GDPR-compliant solutions (79/90). In particular,\nnone of the 3 tasks were solved privacy-compliant by all 30 participants, with\nthe non-prompted group having the lowest number of 3 out of 30\nprivacy-compliant solution attempts. Privacy prompting and expert support only\nslightly improved participants' submissions, with 6/30 and 8/30\nprivacy-compliant attempts, respectively. In fact, all participants reported\nsevere issues addressing common privacy requirements such as purpose\nlimitation, user consent, or data minimization. Counterintuitively, although\nmost developers exhibited minimal confidence in their solutions, they rarely\nsought online assistance or contacted the privacy expert, with only 4 out of 10\nexpert-supported participants explicitly asking for compliance confirmation.\nInstead, participants often relied on existing implementations and focused on\nimplementing functionality and security first.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T08:59:17Z"}
{"aid":"http://arxiv.org/abs/2504.06699v1","title":"Benchmarking Convolutional Neural Network and Graph Neural Network based\n  Surrogate Models on a Real-World Car External Aerodynamics Dataset","summary":"Aerodynamic optimization is crucial for developing eco-friendly, aerodynamic,\nand stylish cars, which requires close collaboration between aerodynamicists\nand stylists, a collaboration impaired by the time-consuming nature of\naerodynamic simulations. Surrogate models offer a viable solution to reduce\nthis overhead, but they are untested in real-world aerodynamic datasets. We\npresent a comparative evaluation of two surrogate modeling approaches for\npredicting drag on a real-world dataset: a Convolutional Neural Network (CNN)\nmodel that uses a signed distance field as input and a commercial tool based on\nGraph Neural Networks (GNN) that directly processes a surface mesh. In contrast\nto previous studies based on datasets created from parameterized geometries,\nour dataset comprises 343 geometries derived from 32 baseline vehicle\ngeometries across five distinct car projects, reflecting the diverse, free-form\nmodifications encountered in the typical vehicle development process. Our\nresults show that the CNN-based method achieves a mean absolute error of 2.3\ndrag counts, while the GNN-based method achieves 3.8. Both methods achieve\napproximately 77% accuracy in predicting the direction of drag change relative\nto the baseline geometry. While both methods effectively capture the broader\ntrends between baseline groups (set of samples derived from a single baseline\ngeometry), they struggle to varying extents in capturing the finer\nintra-baseline group variations. In summary, our findings suggest that\naerodynamicists can effectively use both methods to predict drag in under two\nminutes, which is at least 600 times faster than performing a simulation.\nHowever, there remains room for improvement in capturing the finer details of\nthe geometry.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T09:04:59Z"}
{"aid":"http://arxiv.org/abs/2504.06726v1","title":"On the Vinogradov bound by the Diophantine type","summary":"In this article, we give an asymptotic bound for the exponential sum of the\nM\\\"obius function $\\sum_{n \\le x} \\mu(n) e(\\alpha n)$ for a fixed irrational\nnumber $\\alpha\\in\\mathbb{R}$. This exponential sum was originally studied by\nDavenport and he obtained an asymptotic bound of $x(\\log x)^{-A}$ for any\n$A\\ge0$. Our bound depends on the irrationality exponent $\\eta$ of $\\alpha$. If\n$\\eta \\le 5/2$, we obtain a bound of $x^{4/5 + \\varepsilon}$ and, when $\\eta\n\\ge 5/2$, then our bound becomes $x^{(2\\eta-1)/2\\eta + \\varepsilon}$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T09:31:12Z"}
{"aid":"http://arxiv.org/abs/2504.06736v1","title":"On a weighted version of the BBM formula","summary":"We prove a weighted version of the Bourgain-Brezis-Mironescu (BBM) formula,\nboth in the pointwise and $\\Gamma$-convergence sense, together with a\ncompactness criterion for energy-bounded sequences. The non-negative weights\nneed only be $L^\\infty$ convergent to a bounded and uniformly continuous limit.\nWe apply the BBM formula to show a Poincar\\'e-type inequality and the stability\nof the first eigenvalues relative to the energies. Finally, we discuss a\nnon-local analogue of the weighted BBM formula.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-09T09:48:20Z"}
{"aid":"http://arxiv.org/abs/2504.06743v1","title":"Kinematic formulas in convex geometry for non-compact groups","summary":"We generalize classical kinematic formulas for convex bodies in a real vector\nspace $V$ to the setting of non-compact Lie groups admitting a Cartan\ndecomposition. Specifically, let $G$ be a closed linear group with Cartan\ndecomposition $G \\cong K \\times \\exp(\\mathfrak{p}_0)$, where $K$ is a maximal\ncompact subgroup acting transitively on the unit sphere. For $K$-invariant\ncontinuous valuations on convex bodies, we establish an integral geometric-type\nformula for $\\overline{G} = G \\ltimes V$. Key to our approach is the\nintroduction of a Gaussian measure on $\\mathfrak{p}_0$, which ensures\nconvergence of the non-compact part of the integral. In the special case $K =\nO(n)$, we recover a Hadwiger-type formula involving intrinsic volumes, with\nexplicit constants $c_j$ computed via a Weyl integration formula.","main_category":"math.MG","categories":"math.MG","published":"2025-04-09T09:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.06747v1","title":"An introduction to memory competitions, records and techniques","summary":"This article provides an overview of memory competitions, analyzes\ndifferences between disciplines and explains current state-of-the-art\ntechniques. Performances have increased dramatically over the past three\ndecades. Nowadays, information processing reaches up to 42 bit/s in short\ndisciplines with most of the time spent on reading, suggesting that mental\nassociations are formed even faster. Records show a remarkable concordance\nacross all time scales: the processing speed depends on memorization time as a\npower law.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-09T10:07:46Z"}
{"aid":"http://arxiv.org/abs/2504.06759v1","title":"Rhombohedral graphite junctions as a platform for continuous tuning\n  between topologically trivial and non-trivial electronic phases","summary":"Manipulating the topological properties of quantum states can provide a way\nto protect them against disorder. However, typically, changing the topology of\nelectronic states in a crystalline material is challenging because their nature\nis underpinned by chemical composition and lattice symmetry that are difficult\nto modify. We propose junctions between rhombohedral graphite crystals as a\nplatform that enables smooth transition between topologically trivial and\nnon-trivial regimes distinguished by the absence or presence of topological\njunction states. By invoking an analogy with the Su-Schrieffer-Heeger model,\nthe appearance of topological states is related to the symmetry of the atomic\nstacking at the interface between the crystals. The possibility to explore both\nthe topological and non-topological phases is provided by sliding the crystals\nwith respect to each other.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.other","published":"2025-04-09T10:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.06769v1","title":"Evolutionary dynamics of continuous public goods games in structured\n  populations","summary":"Over the past few decades, many works have studied the evolutionary dynamics\nof continuous games. However, previous works have primarily focused on\ntwo-player games with pairwise interactions. Indeed, group interactions rather\nthan pairwise interactions are usually found in real situations. The public\ngoods game serves as a paradigm of multi-player interactions. Notably, various\ntypes of benefit functions are typically considered in public goods games,\nincluding linear, saturating, and sigmoid functions. Thus far, the evolutionary\ndynamics of cooperation in continuous public goods games with these benefit\nfunctions remain unknown in structured populations. In this paper, we consider\nthe continuous public goods game in structured populations. By employing the\npair approximation approach, we derive the analytical expressions for invasion\nfitness. Furthermore, we explore the adaptive dynamics of cooperative\ninvestments in the game with various benefit functions. First, for the linear\npublic goods game, we find that there is no singular strategy, and the\ncooperative investments evolve to either the maximum or minimum depending on\nthe benefit-to-cost ratio. Subsequently, we examine the game with saturating\nbenefit functions and demonstrate the potential existence of an evolutionarily\nstable strategy (ESS). Additionally, for the game with the sigmoid benefit\nfunction, we observe that the evolutionary outcomes are closely related to the\nthreshold value. When the threshold is small, a unique ESS emerges. For\nintermediate threshold values, both the ESS and repellor singular strategies\ncan coexist. When the threshold value is large, a unique repellor displays.\nFinally, we perform individual-based simulations to validate our theoretical\nresults.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-09T10:47:05Z"}
{"aid":"http://arxiv.org/abs/2504.06775v1","title":"Variational Quantum Machine Learning with Quantum Error Detection","summary":"Quantum machine learning (QML) is an emerging field that promises advantages\nsuch as faster training, improved reliability and superior feature extraction\nover classical counterparts. However, its implementation on quantum hardware is\nchallenging due to the noise inherent in these systems, necessitating the use\nof quantum error correction (QEC) codes. Current QML research remains primarily\ntheoretical, often assuming noise-free environments and offering little insight\ninto the integration of QEC with QML implementations. To address this, we\ninvestigate the performance of a simple, parity-classifying Variational Quantum\nClassifier (VQC) implemented with the [[4,2,2]] error-detecting stabiliser code\nin a simulated noisy environment, marking the first study into the\nimplementation of a QML algorithm with a QEC code. We invoke ancilla qubits to\nlogically encode rotation gates, and classically simulate the logically-encoded\nVQC under two simple noise models representing gate noise and environmental\nnoise. We demonstrate that the stabiliser code improves the training accuracy\nat convergence compared to noisy implementations without QEC. However, we find\nthat the effectiveness and reliability of error detection is contingent upon\nkeeping the ancilla qubit error rates below a specific threshold, due to the\npropagation of ancilla errors to the physical qubits. Our results provide an\nimportant insight: for QML implementations with QEC codes that both require\nancilla qubits for logical rotations and cannot fully correct errors propagated\nbetween ancilla and physical qubits, the maximum achievable accuracy of the QML\nmodel is limited. This highlights the need for additional error correction or\nmitigation strategies to support the practical implementation of QML algorithms\nwith QEC on quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T10:56:21Z"}
{"aid":"http://arxiv.org/abs/2504.06782v1","title":"Probabilistic Grading and Classification System for End-of-Life Building\n  Components Toward Circular Economy Loop","summary":"The longevity and viability of construction components in a circular economy\ndemand a robust, data-informed framework for reuse decision-making. This paper\nintroduces a multi-level grading and classification system that combines\nBayesian probabilistic modeling with scenario-based performance thresholds to\nassess the reusability of end-of-life modular components. By grading components\nacross a five-tier scale, the system supports strategic decisions for reuse,\nup-use, or down-use, ensuring alignment with engineering standards and\nsustainability objectives. The model's development is grounded in empirical\ndata from precast concrete wall panels, and its explainability is enhanced\nthrough decision tree logic and Sankey visualizations that trace the influence\nof contextual scenarios on classification outcomes. MGCS addresses the\nenvironmental, economic, and operational challenges of EoL management--reducing\nmaterial waste, optimizing value recovery, and improving workflow efficiency.\nThrough dynamic feature weighting and transparent reasoning, the system offers\na practical yet rigorous pathway to embed circular thinking into construction\nindustry practices.","main_category":"econ.GN","categories":"econ.GN,cs.NA,math.NA,q-fin.EC","published":"2025-04-09T11:14:02Z"}
{"aid":"http://arxiv.org/abs/2504.06783v1","title":"Organization of Historical Oceanic Overturnings on Cross-Sphere Climate\n  Signals","summary":"The global ocean meridional overturning circulation (GMOC) is central for\nocean transport and climate variations. However, a comprehensive picture of its\nhistorical mean state and variability remains vague due to limitations in\nmodelling and observing systems. Incorporating observations into models offers\na viable approach to reconstructing climate history, yet achieving coherent\nestimates of GMOC has proven challenging due to difficulties in harmonizing\nocean stratification. Here, we demonstrate that applying multiscale data\nassimilation scheme that integrates atmospheric and oceanic observations into\nmultiple coupled models in a dynamically consistent way, the global ocean\ncurrents and GMOC over the past 80 years are retrieved. While the major\nhistoric events are printed in variability of the rebuilt GMOC, the timeseries\nof multisphere 3-dimensional physical variables representing the realistic\nhistorical evolution enable us to advance understanding of mechanisms of\nclimate signal propagation cross spheres and give birth to Artificial\nIntelligence coupled big models, thus advancing the Earth science.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-09T11:15:03Z"}
{"aid":"http://arxiv.org/abs/2504.06786v1","title":"Axion production from electron-nucleon scattering in chiral effective\n  theory","summary":"In this work we study the axion production from the electron-nucleon\nscattering, i.e., the $eN\\to e N a$ processes, being $N$ the proton and\nneutron. We simultaneously include three different types of axion interaction\ncouplings within the chiral effective field theory, namely the\naxion-nucleon-nucleon couplings $g_{aNN}$, axion-photon-photon coupling\n$g_{a\\gamma\\gamma}$ and axion-photon-vector meson resonances couplings $g_{\\rho\na\\gamma}$ and $g_{\\omega a\\gamma}$. Vast inputs from the lattice QCD and hadron\nphenomenological studies are used to fix the unknown couplings. The relative\nstrengths of different axion interactions in the $eN\\to e N a$ processes are\nthen revealed. We provide detailed predictions for the differential cross\nsections with respect to various angles and axion energy, as well as the total\ncross sections, both for the Kim-Shifman-Vainstein-Zakharov (KSVZ) and\nDine-Fischler-Srednicki-Zhitnitsky (DFSZ) axion models.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T11:19:20Z"}
{"aid":"http://arxiv.org/abs/2504.06794v1","title":"A new model for all $C$-sequences are trivial","summary":"We construct a model in which all $C$-sequences are trivial, yet there exists\na $\\kappa$-Souslin tree with full vanishing levels. This answers a question of\nLambie-Hanson and Rinot, and provides an optimal combination of compactness and\nincompactness. It is obtained by incorporating a so-called mutually exclusive\nascent path to Kunen's original forcing construction.","main_category":"math.LO","categories":"math.LO","published":"2025-04-09T11:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.06800v1","title":"A Meaningful Perturbation Metric for Evaluating Explainability Methods","summary":"Deep neural networks (DNNs) have demonstrated remarkable success, yet their\nwide adoption is often hindered by their opaque decision-making. To address\nthis, attribution methods have been proposed to assign relevance values to each\npart of the input. However, different methods often produce entirely different\nrelevance maps, necessitating the development of standardized metrics to\nevaluate them. Typically, such evaluation is performed through perturbation,\nwherein high- or low-relevance regions of the input image are manipulated to\nexamine the change in prediction. In this work, we introduce a novel approach,\nwhich harnesses image generation models to perform targeted perturbation.\nSpecifically, we focus on inpainting only the high-relevance pixels of an input\nimage to modify the model's predictions while preserving image fidelity. This\nis in contrast to existing approaches, which often produce out-of-distribution\nmodifications, leading to unreliable results. Through extensive experiments, we\ndemonstrate the effectiveness of our approach in generating meaningful rankings\nacross a wide range of models and attribution methods. Crucially, we establish\nthat the ranking produced by our metric exhibits significantly higher\ncorrelation with human preferences compared to existing approaches,\nunderscoring its potential for enhancing interpretability in DNNs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T11:46:41Z"}
{"aid":"http://arxiv.org/abs/2504.06814v1","title":"Revisit Gradient Descent for Geodesically Convex Optimization","summary":"In a seminal work of Zhang and Sra, gradient descent methods for geodesically\nconvex optimization were comprehensively studied. In particular, based on a\nrefined use of the triangle comparison theorem of Toponogov, Zhang and Sra\nderived a comparison inequality that relates the current iterate, the next\niterate and the optimum point. Since their seminal work, numerous follow-ups\nhave studied different downstream usages of their comparison lemma. However,\nall results along this line relies on strong assumptions, such as bounded\ndomain assumption or curvature bounded below assumption.\n  In this work, we introduce the concept of quasilinearization to optimization,\npresenting a novel framework for analyzing geodesically convex optimization. By\nleveraging this technique, we establish state-of-the-art convergence rates --\nfor both deterministic and stochastic settings -- under substantially weaker\nassumptions than previously required.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T12:08:43Z"}
{"aid":"http://arxiv.org/abs/2504.06851v1","title":"Mixing trichotomy for random walks on directed stochastic block models","summary":"We consider a directed version of the classical Stochastic Block Model with\n$m\\ge 2$ communities and a parameter $\\alpha$ controlling the inter-community\nconnectivity. We show that, depending on the scaling of $\\alpha$, the mixing\ntime of the random walk on this graph can exhibit three different behaviors,\nwhich we refer to as subcritical, critical and supercritical. In the\nsubcritical regime, the total variation distance to equilibrium decays\nabruptly, providing the occurrence of the so-called cutoff phenomenon. In the\nsupercritical regime, the mixing is governed by the inter-community jumps, and\nthe random walk exhibits a metastable behavior: at first it collapses to a\nlocal equilibrium, then, on a larger timescale, it can be effectively described\nas a mean-field process on the $m$ communities, with a decay to equilibrium\nwhich is asymptotically smooth and exponential. Finally, for the critical\nregime, we show a sort of interpolation of the two above-mentioned behaviors.\nAlthough the metastable behavior shown in the supercritical regime appears\nnatural from a heuristic standpoint, a substantial part of our analysis can be\nread as a control on the homogenization of the underlying random environment.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T13:05:55Z"}
{"aid":"http://arxiv.org/abs/2504.06908v1","title":"UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image\n  Segmentation","summary":"In medical imaging, the primary challenge is collecting large-scale labeled\ndata due to privacy concerns, logistics, and high labeling costs. In this work,\nwe present the UK Biobank Organs and Bones (UKBOB), the largest labeled dataset\nof body organs, comprising 51,761 MRI 3D samples (equivalent to 17.9 million 2D\nimages) and more than 1.37 billion 2D segmentation masks of 72 organs, all\nbased on the UK Biobank MRI dataset. We utilize automatic labeling, introduce\nan automated label cleaning pipeline with organ-specific filters, and manually\nannotate a subset of 300 MRIs with 11 abdominal classes to validate the quality\n(referred to as UKBOB-manual). This approach allows for scaling up the dataset\ncollection while maintaining confidence in the labels. We further confirm the\nvalidity of the labels by demonstrating zero-shot generalization of trained\nmodels on the filtered UKBOB to other small labeled datasets from similar\ndomains (e.g., abdominal MRI). To further mitigate the effect of noisy labels,\nwe propose a novel method called Entropy Test-time Adaptation (ETTA) to refine\nthe segmentation output. We use UKBOB to train a foundation model, Swin-BOB,\nfor 3D medical image segmentation based on the Swin-UNetr architecture,\nachieving state-of-the-art results in several benchmarks in 3D medical imaging,\nincluding the BRATS brain MRI tumor challenge (with a 0.4% improvement) and the\nBTCV abdominal CT scan benchmark (with a 1.3% improvement). The pre-trained\nmodels and the code are available at https://emmanuelleb985.github.io/ukbob ,\nand the filtered labels will be made available with the UK Biobank.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T14:10:51Z"}
{"aid":"http://arxiv.org/abs/2504.07001v1","title":"Leveraging GCN-based Action Recognition for Teleoperation in Daily\n  Activity Assistance","summary":"Caregiving of older adults is an urgent global challenge, with many older\nadults preferring to age in place rather than enter residential care. However,\nproviding adequate home-based assistance remains difficult, particularly in\ngeographically vast regions. Teleoperated robots offer a promising solution,\nbut conventional motion-mapping teleoperation imposes unnatural movement\nconstraints on operators, leading to muscle fatigue and reduced usability. This\npaper presents a novel teleoperation framework that leverages action\nrecognition to enable intuitive remote robot control. Using our simplified\nSpatio-Temporal Graph Convolutional Network (S-ST-GCN), the system recognizes\nhuman actions and executes corresponding preset robot trajectories, eliminating\nthe need for direct motion synchronization. A finite-state machine (FSM) is\nintegrated to enhance reliability by filtering out misclassified actions. Our\nexperiments demonstrate that the proposed framework enables effortless operator\nmovement while ensuring accurate robot execution. This proof-of-concept study\nhighlights the potential of teleoperation with action recognition for enabling\ncaregivers to remotely assist older adults during activities of daily living\n(ADLs). Future work will focus on improving the S-ST-GCN's recognition accuracy\nand generalization, integrating advanced motion planning techniques to further\nenhance robotic autonomy in older adult care, and conducting a user study to\nevaluate the system's telepresence and ease of control.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-09T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.07006v1","title":"Quasipolynomial bounds for the corners theorem","summary":"Let $G$ be a finite abelian group and $A$ be a subset of $G \\times G$ which\nis corner-free, meaning that there are no $x, y \\in G$ and $d \\in G \\setminus\n\\{0\\}$ such that $(x, y)$, $(x+d, y)$, $(x, y+d) \\in A$. We prove that \\[|A|\n\\le |G|^2 \\cdot \\exp(-(\\log |G|)^{\\Omega(1)}).\\] As a consequence, we obtain\npolynomial (in the input length) lower bounds on the non-deterministic\ncommunication complexity of Exactly-N in the 3-player Number-on-Forehead model.\nWe also obtain the first \"reasonable'' lower bounds on the coloring version of\nthe $3$-dimensional corners problem and equivalently the deterministic\ncommunication complexity of Exactly-N in the 4-player Number-on-Forehead model.","main_category":"math.CO","categories":"math.CO,cs.CC,math.NT","published":"2025-04-09T16:26:06Z"}
{"aid":"http://arxiv.org/abs/2504.07034v1","title":"Low Regularity of Self-Similar Solutions of Two-Dimensional Riemann\n  problems with Shocks for the Isentropic Euler system","summary":"We are concerned with the low regularity of self-similar solutions of\ntwo-dimensional Riemann problems for the isentropic Euler system. We establish\na general framework for the analysis of the local regularity of such solutions\nfor a class of two-dimensional Riemann problems for the isentropic Euler\nsystem, which includes the regular shock reflection problem, the Prandtl\nreflection problem, the Lighthill diffraction problem, and the four-shock\nRiemann problem. We prove that it is not possible that both the density and the\nvelocity are in $H^1$ in the subsonic domain for the self-similar solutions of\nthese problems in general. This indicates that the self-similar solutions of\nthe Riemann problems with shocks for the isentropic Euler system are of much\nmore complicated structure than those for the Euler system for potential flow;\nin particular, the density and the velocity are not necessarily continuous in\nthe subsonic domain. The proof is based on a regularization of the isentropic\nEuler system to derive the transport equation for the vorticity, a\nrenormalization argument extended to the case of domains with boundary, and\nDiPerna-Lions-type commutator estimates.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,nlin.PS,physics.flu-dyn","published":"2025-04-09T16:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.07037v1","title":"VQE calculations on a NISQ era trapped ion quantum computer using a\n  multireference unitary coupled cluster ansatz: application to the BeH$_2$\n  insertion problem","summary":"In this study, we employ the variational quantum eigensolver algorithm with a\nmultireference unitary coupled cluster ansatz to report the ground state energy\nof the BeH$_2$ molecule in a geometry where strong correlation effects are\nsignificant. We consider the two most important determinants in the\nconstruction of the reference state for our ansatz. Furthermore, in order to\ncarry out our intended 12-qubit computation on a noisy intermediate scale\nquantum era trapped ion hardware (the commercially available IonQ Forte-I), we\nperform a series of resource reduction techniques to a. decrease the number of\ntwo-qubit gates by 99.84% (from 12515 to 20 two-qubit gates) relative to the\nunoptimized circuit, and b. reduce the number of measurements via the idea of\nsupercliques, while losing 2.69% in the obtained ground state energy (with\nerror mitigation and post-selection) relative to that computed classically for\nthe same resource-optimized problem setting.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.atom-ph,quant-ph","published":"2025-04-09T16:52:37Z"}
{"aid":"http://arxiv.org/abs/2504.07081v1","title":"Self-Steering Language Models","summary":"While test-time reasoning enables language models to tackle complex tasks,\nsearching or planning in natural language can be slow, costly, and error-prone.\nBut even when LMs struggle to emulate the precise reasoning steps needed to\nsolve a problem, they often excel at describing its abstract structure--both\nhow to verify solutions and how to search for them. This paper introduces\nDisCIPL, a method for \"self-steering\" LMs where a Planner model generates a\ntask-specific inference program that is executed by a population of Follower\nmodels. Our approach equips LMs with the ability to write recursive search\nprocedures that guide LM inference, enabling new forms of verifiable and\nefficient reasoning. When instantiated with a small Follower (e.g.,\nLlama-3.2-1B), DisCIPL matches (and sometimes outperforms) much larger models,\nincluding GPT-4o and o1, on challenging constrained generation tasks. In\ndecoupling planning from execution, our work opens up a design space of\nhighly-parallelized Monte Carlo inference strategies that outperform standard\nbest-of-N sampling, require no finetuning, and can be implemented automatically\nby existing LMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T17:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.07409v1","title":"RLibm-MultiRound: Correctly Rounded Math Libraries Without Worrying\n  about the Application's Rounding Mode","summary":"Our RLibm project generates a single implementation for an elementary\nfunction that produces correctly rounded results for multiple rounding modes\nand representations with up to 32-bits. They are appealing for developing fast\nreference libraries without double rounding issues. The key insight is to build\npolynomials that produce the correctly rounded result for a representation with\ntwo additional bits when compared to the largest target representation and with\nthe \"non-standard\" round-to-odd rounding mode, which makes double rounding the\nRLibm math library result to any smaller target representation innocuous. The\nresulting approximations generated by the RLibm approach are implemented with\nmachine supported floating-point operations with the round-to-nearest rounding\nmode. When an application uses a rounding mode other than the round-to-nearest\nmode, the RLibm math library saves the application's rounding mode, changes the\nsystem's rounding mode to round-to-nearest, computes the correctly rounded\nresult, and restores the application's rounding mode. This frequent change of\nrounding modes has a performance cost.\n  This paper proposes two new methods, which we call rounding-invariant outputs\nand rounding-invariant input bounds, to avoid the frequent changes to the\nrounding mode and the dependence on the round-to-nearest mode. First, our new\nrounding-invariant outputs method proposes using the round-to-zero rounding\nmode to implement RLibm's polynomial approximations. We propose fast,\nerror-free transformations to emulate a round-to-zero result from any standard\nrounding mode without changing the rounding mode. Second, our\nrounding-invariant input bounds method factors any rounding error due to\ndifferent rounding modes using interval bounds in the RLibm pipeline. Both\nmethods make a different set of trade-offs and improve the performance of\nresulting libraries by more than 2X.","main_category":"cs.MS","categories":"cs.MS","published":"2025-04-10T03:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.07412v1","title":"Toda-type presentations for the quantum K theory of partial flag\n  varieties","summary":"We prove a determinantal, Toda-type, presentation for the equivariant K\ntheory of a partial flag variety $\\mathrm{Fl}(r_1, \\ldots, r_k;n)$. The proof\nrelies on pushing forward the Toda presentation obtained by Maeno, Naito and\nSagaki for the complete flag variety $\\mathrm{Fl}(n)$, via Kato's\n$\\mathrm{K}_T(\\mathrm{pt})$-algebra homomorphism from the quantum K ring of\n$\\mathrm{Fl}(n)$ to that of $\\mathrm{Fl}(r_1, \\ldots, r_k;n)$. Starting instead\nfrom the Whitney presentation for $\\mathrm{Fl}(n)$, we show that the same\npush-forward technique gives a recursive formula for polynomial representatives\nof quantum K Schubert classes in any partial flag variety which do not depend\non quantum parameters. In an appendix, we include another proof of the Toda\npresentation for the equivariant quantum K ring of $\\mathrm{Fl}(n)$, following\nAnderson, Chen, and Tseng, which is based on the fact that the $\\mathrm{K}$\ntheoretic $J$-function is an eigenfunction of the finite difference Toda\nHamiltonians.","main_category":"math.AG","categories":"math.AG,math.CO,math.RT","published":"2025-04-10T03:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.07464v1","title":"Stable and Efficient Charging of Superconducting C-shunt Flux Quantum\n  Batteries","summary":"Quantum batteries, as miniature energy storage devices, have sparked\nsignificant research interest in recent years. However, achieving rapid and\nstable energy transfer in quantum batteries while obeying quantum speed limits\nremains a critical challenge. In this work, we experimentally optimize the\ncharging process by leveraging the unique energy level structure of a\nsuperconducting capacitively-shunted flux qubit, using counterdiabatic pulses\nin the stimulated Raman adiabatic passage. Compared to previous studies, we\nimpose two different norm constraints on the driving Hamiltonian, achieving\noptimal charging without exceeding the overall driving strength. Furthermore,\nwe experimentally demonstrate a charging process that achieves the quantum\nspeed limit. In addition, we introduce a dimensionless parameter $\\mathcal{S}$\nto unify charging speed and stability, offering a universal metric for\nperformance optimization. In contrast to metrics such as charging power and\nthermodynamic efficiency, the $\\mathcal{S}$ criterion quantitatively captures\nthe stability of ergentropy while also considering the charging speed. Our\nresults highlight the potential of the capacitively-shunted qubit platform as\nan ideal candidate for realizing three-level quantum batteries and deliver\nnovel strategies for optimizing energy transfer protocols.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T05:26:49Z"}
{"aid":"http://arxiv.org/abs/2504.07476v1","title":"CMEdataset Advancing China Map Detection and Standardization with\n  Digital Image Resources","summary":"Digital images of Chinas maps play a crucial role in map detection,\nparticularly in ensuring national sovereignty, territorial integrity, and map\ncompliance. However, there is currently no publicly available dataset\nspecifically dedicated to problematic maps the CME dataset. Existing datasets\nprimarily focus on general map data and are insufficient for effectively\nidentifying complex issues such as national boundary misrepresentations,\nmissing elements, and blurred boundaries. Therefore, this study creates a\nProblematic Map dataset that covers five key problem areas, aiming to provide\ndiverse samples for problematic map detection technologies, support\nhigh-precision map compliance detection, and enhance map data quality and\ntimeliness. This dataset not only provides essential resources for map\ncompliance, national security monitoring, and map updates, but also fosters\ninnovation and application of related technologies.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T06:04:16Z"}
{"aid":"http://arxiv.org/abs/2504.07485v1","title":"Rendering Large Volume Datasets in Unreal Engine 5: A Survey","summary":"In this technical report, we discuss several approaches to in-core rendering\nof large volumetric datasets in Unreal Engine 5 (UE5). We explore the following\nmethods: the TBRayMarcher Plugin, the Niagara Fluids Plugin , and various\napproaches using Sparse Volume Textures (SVT), with a particular focus on\nHeterogeneous Volumes (HV). We found the HV approach to be the most promising.\nThe biggest challenge we encountered with other approaches was the need to\nchunk datasets so that each fits into volume textures smaller than one\ngigavoxel. While this enables display of the entire dataset at reasonable frame\nrates, it introduces noticeable artifacts at chunk borders due to incorrect\nlighting, as each chunk lacks information about its neighbors. After addressing\nsome (signed) int32 overflows in the Engine's SVT-related source code by\nconverting them to to (unsigned) uint32 or int64, the SVT-based HV system\nallows us to render sparse datasets up to 32k x 32k x 16k voxels, provided the\ncompressed tile data (including MIP data and padding for correct interpolation)\ndoes not exceed 4 gigavoxels. In the future, we intend to extend the existing\nSVT streaming functionality to support out-of-core rendering, in order to\neventually overcome VRAM limitations, graphics API constraints, and the\nperformance issues associated with 64-bit arithmetic in GPU shaders.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-10T06:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.07489v1","title":"Constraining the 3HDM Parameter Space","summary":"One of the standard ways to study scenarios beyond the Standard Model\ninvolves extending the Higgs Sector. This work examines the Three Higgs Doublet\nModel (3HDM) in a Type-Z or democratic setup, where each Higgs doublet couples\nexclusively to a specific type of fermion. The particle spectrum of the 3HDM\nincludes four charged Higgs bosons, two CP-odd scalars, and three CP-even\nscalars. This work investigates the allowed mass and coupling parameter space\nin the Type-Z 3HDM after imposing all theoretical and experimental constraints.\nWe extract the allowed parameter space under three distinct alignment-limit\nconditions or mass hierarchies leveraging machine learning techniques.\nSpecifically, we analyze scenarios where the 125 GeV Higgs is the lightest, an\nintermediary, or the heaviest CP-even Higgs boson. Our findings indicate that\nwhile a single lighter CP-even Higgs boson below 125 GeV still remains a\npossibility, the presence of two lighter Higgses is ruled out.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T06:46:09Z"}
{"aid":"http://arxiv.org/abs/2504.07545v1","title":"Convexity Helps Iterated Search in 3D","summary":"Inspired by the classical fractional cascading technique, we introduce new\ntechniques to speed up the following type of iterated search in 3D: The input\nis a graph $\\mathbf{G}$ with bounded degree together with a set $H_v$ of 3D\nhyperplanes associated with every vertex of $v$ of $\\mathbf{G}$. The goal is to\nstore the input such that given a query point $q\\in \\mathbb{R}^3$ and a\nconnected subgraph $\\mathbf{H}\\subset \\mathbf{G}$, we can decide if $q$ is\nbelow or above the lower envelope of $H_v$ for every $v\\in \\mathbf{H}$. We show\nthat using linear space, it is possible to answer queries in roughly $O(\\log n\n+ |\\mathbf{H}|\\sqrt{\\log n})$ time which improves trivial bound of\n$O(|\\mathbf{H}|\\log n)$ obtained by using planar point location data\nstructures. Our data structure can in fact answer more general queries (it\ncombines with shallow cuttings) and it even works when $\\mathbf{H}$ is given\none vertex at a time. We show that this has a number of new applications and in\nparticular, we give improved solutions to a set of natural data structure\nproblems that up to our knowledge had not seen any improvements.\n  We believe this is a very surprising result because obtaining similar results\nfor the planar point location problem was known to be impossible.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-10T08:20:36Z"}
{"aid":"http://arxiv.org/abs/2504.07548v1","title":"On the variety of solutions of 1-dimensional nonlinear eigenvalue\n  problems","summary":"Second order nonlinear eigenvalue problems are considered for which the\nspectrum is an interval. The boundary conditions are of Robin and Dirichlet\ntype. The shape and the number of solutions are discussed by means of a phase\nplane analysis. A new type of asymmetric solutions are discovered. Some\nnumerical illustrations are given.","main_category":"math.DS","categories":"math.DS","published":"2025-04-10T08:23:38Z"}
{"aid":"http://arxiv.org/abs/2504.07549v1","title":"STeP: A General and Scalable Framework for Solving Video Inverse\n  Problems with Spatiotemporal Diffusion Priors","summary":"We study how to solve general Bayesian inverse problems involving videos\nusing diffusion model priors. While it is desirable to use a video diffusion\nprior to effectively capture complex temporal relationships, due to the\ncomputational and data requirements of training such a model, prior work has\ninstead relied on image diffusion priors on single frames combined with\nheuristics to enforce temporal consistency. However, these approaches struggle\nwith faithfully recovering the underlying temporal relationships, particularly\nfor tasks with high temporal uncertainty. In this paper, we demonstrate the\nfeasibility of practical and accessible spatiotemporal diffusion priors by\nfine-tuning latent video diffusion models from pretrained image diffusion\nmodels using limited videos in specific domains. Leveraging this plug-and-play\nspatiotemporal diffusion prior, we introduce a general and scalable framework\nfor solving video inverse problems. We then apply our framework to two\nchallenging scientific video inverse problems--black hole imaging and dynamic\nMRI. Our framework enables the generation of diverse, high-fidelity video\nreconstructions that not only fit observations but also recover multi-modal\nsolutions. By incorporating a spatiotemporal diffusion prior, we significantly\nimprove our ability to capture complex temporal relationships in the data while\nalso enhancing spatial fidelity.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T08:24:26Z"}
{"aid":"http://arxiv.org/abs/2504.07577v1","title":"Optimization Of The Survival Threshold For Anisotropic Logistic\n  Equations With Mixed Boundary Conditions","summary":"In this paper we study a reaction diffusion problem with anisotropic\ndiffusion and mixed Dirichlet-Neumann boundary conditions on the boundary of\nthe domain. First, we prove that the parabolic problem has a unique positive,\nbounded solution. Then, we show that this solution converges as t tends to\ninfinity to the unique nonnegative solution of the elliptic associated problem.\nThe existence of the unique positive solution to this problem depends on a\nprincipal eigenvalue of a suitable linearized problem with a sign-changing\nweights. Next, we study the minimization of such eigenvalue with respect to the\nsign-changing weight, showing that there exists an optimal bang-bang weight,\nnamely a piece-wise constant weight that takes only two values. Finally, we\ncompletely solve the problem in dimension one.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T09:20:34Z"}
{"aid":"http://arxiv.org/abs/2504.07600v1","title":"System Concept and Demonstration of Bistatic MIMO-OFDM-based ISAC","summary":"In future sixth-generation (6G) mobile networks, radar sensing is expected to\nbe offered as an additional service to its original purpose of communication.\nMerging these two functions results in integrated sensing and communication\n(ISAC) systems. In this context, bistatic ISAC appears as a possibility to\nexploit the distributed nature of cellular networks while avoiding highly\ndemanding hardware requirements such as full-duplex operation. Recent studies\nhave introduced strategies to perform required synchronization and data\nexchange between nodes for bistatic ISAC operation, based on orthogonal\nfrequency-division multiplexing (OFDM), however, only for single-input\nsingle-output architectures. In this article, a system concept for a bistatic\nmultiple-input multiple-output (MIMO)-OFDM-based ISAC system with beamforming\nat both transmitter and receiver is proposed, and a distribution\nsynchronization concept to ensure coherence among the different receive\nchannels for direction-of-arrival estimation is presented. After a discussion\non the ISAC processing chain, including relevant aspects for practical\ndeployments such as transmitter digital pre-distortion and receiver\ncalibration, a 4x8 MIMO measurement setup at 27.5 GHz and results are presented\nto validate the proposed system and distribution synchronization concepts.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T09:54:15Z"}
{"aid":"http://arxiv.org/abs/2504.07603v1","title":"RASMD: RGB And SWIR Multispectral Driving Dataset for Robust Perception\n  in Adverse Conditions","summary":"Current autonomous driving algorithms heavily rely on the visible spectrum,\nwhich is prone to performance degradation in adverse conditions like fog, rain,\nsnow, glare, and high contrast. Although other spectral bands like\nnear-infrared (NIR) and long-wave infrared (LWIR) can enhance vision perception\nin such situations, they have limitations and lack large-scale datasets and\nbenchmarks. Short-wave infrared (SWIR) imaging offers several advantages over\nNIR and LWIR. However, no publicly available large-scale datasets currently\nincorporate SWIR data for autonomous driving. To address this gap, we introduce\nthe RGB and SWIR Multispectral Driving (RASMD) dataset, which comprises 100,000\nsynchronized and spatially aligned RGB-SWIR image pairs collected across\ndiverse locations, lighting, and weather conditions. In addition, we provide a\nsubset for RGB-SWIR translation and object detection annotations for a subset\nof challenging traffic scenarios to demonstrate the utility of SWIR imaging\nthrough experiments on both object detection and RGB-to-SWIR image translation.\nOur experiments show that combining RGB and SWIR data in an ensemble framework\nsignificantly improves detection accuracy compared to RGB-only approaches,\nparticularly in conditions where visible-spectrum sensors struggle. We\nanticipate that the RASMD dataset will advance research in multispectral\nimaging for autonomous driving and robust perception systems.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T09:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.07663v1","title":"Multiplicative assignment with upgrades","summary":"We study a problem related to submodular function optimization and the exact\nmatching problem for which we show a rather peculiar status: its natural\nLP-relaxation can have fractional optimal vertices, but there is always also an\noptimal integral vertex, which we can also compute in polynomial time.\n  More specifically, we consider the multiplicative assignment problem with\nupgrades in which we are given a set of customers and suppliers and we seek to\nassign each customer to a different supplier. Each customer has a demand and\neach supplier has a regular and an upgraded cost for each unit demand provided\nto the respective assigned client. Our goal is to upgrade at most $k$ suppliers\nand to compute an assignment in order to minimize the total resulting cost.\nThis can be cast as the problem to compute an optimal matching in a bipartite\ngraph with the additional constraint that we must select $k$ edges from a\ncertain group of edges, similar to selecting $k$ red edges in the exact\nmatching problem. Also, selecting the suppliers to be upgraded corresponds to\nmaximizing a submodular set function under a cardinality constraint.\n  Our result yields an efficient LP-based algorithm to solve our problem\noptimally. In addition, we provide also a purely strongly polynomial-time\nalgorithm for it. As an application, we obtain exact algorithms for the\nupgrading variant of the problem to schedule jobs on identical or uniformly\nrelated machines in order to minimize their sum of completion times, i.e.,\nwhere we may upgrade up to $k$ jobs to reduce their respective processing\ntimes.","main_category":"cs.DS","categories":"cs.DS,cs.DM,math.OC","published":"2025-04-10T11:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.07680v1","title":"Synthetic Fluency: Hallucinations, Confabulations, and the Creation of\n  Irish Words in LLM-Generated Translations","summary":"This study examines hallucinations in Large Language Model (LLM) translations\ninto Irish, specifically focusing on instances where the models generate novel,\nnon-existent words. We classify these hallucinations within verb and noun\ncategories, identifying six distinct patterns among the latter. Additionally,\nwe analyse whether these hallucinations adhere to Irish morphological rules and\nwhat linguistic tendencies they exhibit. Our findings show that while both\nGPT-4.o and GPT-4.o Mini produce similar types of hallucinations, the Mini\nmodel generates them at a significantly higher frequency. Beyond\nclassification, the discussion raises speculative questions about the\nimplications of these hallucinations for the Irish language. Rather than\nseeking definitive answers, we offer food for thought regarding the increasing\nuse of LLMs and their potential role in shaping Irish vocabulary and linguistic\nevolution. We aim to prompt discussion on how such technologies might influence\nlanguage over time, particularly in the context of low-resource,\nmorphologically rich languages.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T12:08:47Z"}
{"aid":"http://arxiv.org/abs/2504.07687v1","title":"FMNV: A Dataset of Media-Published News Videos for Fake News Detection","summary":"News media, particularly video-based platforms, have become deeply embedded\nin daily life, concurrently amplifying risks of misinformation dissemination.\nConsequently, multimodal fake news detection has garnered significant research\nattention. However, existing datasets predominantly comprise user-generated\nvideos characterized by crude editing and limited public engagement, whereas\nprofessionally crafted fake news videos disseminated by media outlets often\npolitically or virally motivated pose substantially greater societal harm. To\naddress this gap, we construct FMNV, a novel dataset exclusively composed of\nnews videos published by media organizations. Through empirical analysis of\nexisting datasets and our curated collection, we categorize fake news videos\ninto four distinct types. Building upon this taxonomy, we employ Large Language\nModels (LLMs) to automatically generate deceptive content by manipulating\nauthentic media-published news videos. Furthermore, we propose FMNVD, a\nbaseline model featuring a dual-stream architecture integrating CLIP and Faster\nR-CNN for video feature extraction, enhanced by co-attention mechanisms for\nfeature refinement and multimodal aggregation. Comparative experiments\ndemonstrate both the generalization capability of FMNV across multiple\nbaselines and the superior detection efficacy of FMNVD. This work establishes\ncritical benchmarks for detecting high-impact fake news in media ecosystems\nwhile advancing methodologies for cross-modal inconsistency analysis.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-10T12:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.07723v1","title":"Low-Thrust Many-Revolution Transfer between Near Rectilinear Halo Orbit\n  and Low Lunar Orbit Using Hybrid Differential Dynamic Programming","summary":"Low-thrust, many-revolution transfers between near-rectilinear halo orbits\nand low lunar orbits are challenging due to the many-revolutions and is further\ncomplicated by three-body perturbation. To address these challenges, we extend\nhybrid differential dynamic programming by enhancing with a continuation of\ndynamical system. The optimization begins with the Sundman-transformed two-body\nproblem and gradually transitions to the Sundman-transformed circular\nrestricted three-body problem expressed in the moon-centered inertial frame.\nNumerical examples demonstrate the robust convergence of our method, where\noptimal transfers from low lunar orbit to near-rectilinear halo orbit are\nobtained with a poor initial guess of low lunar orbit.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,math.OC","published":"2025-04-10T13:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.07801v1","title":"FairEval: Evaluating Fairness in LLM-Based Recommendations with\n  Personality Awareness","summary":"Recent advances in Large Language Models (LLMs) have enabled their\napplication to recommender systems (RecLLMs), yet concerns remain regarding\nfairness across demographic and psychological user dimensions. We introduce\nFairEval, a novel evaluation framework to systematically assess fairness in\nLLM-based recommendations. FairEval integrates personality traits with eight\nsensitive demographic attributes,including gender, race, and age, enabling a\ncomprehensive assessment of user-level bias. We evaluate models, including\nChatGPT 4o and Gemini 1.5 Flash, on music and movie recommendations. FairEval's\nfairness metric, PAFS, achieves scores up to 0.9969 for ChatGPT 4o and 0.9997\nfor Gemini 1.5 Flash, with disparities reaching 34.79 percent. These results\nhighlight the importance of robustness in prompt sensitivity and support more\ninclusive recommendation systems.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.HC","published":"2025-04-10T14:38:15Z"}
{"aid":"http://arxiv.org/abs/2504.07832v1","title":"A character theoretic formula for base size II","summary":"A base for a permutation group $G$ acting on a set $\\Omega$ is a sequence\n$\\mathcal{B}$ of points of $\\Omega$ such that the pointwise stabiliser\n$G_{\\mathcal{B}}$ is trivial. The base size of $G$ is the size of a smallest\nbase for $G$. Extending the results of a recent paper of the author, we prove a\n2013 conjecture of Fritzsche, K\\\"ulshammer, and Reiche. Moreover, we generalise\nthis conjecture and derive an alternative character theoretic formula for the\nbase size of a certain class of permutation groups. As a consequence of our\nwork, a third formula for the base size of the symmetric group of degree $n$\nacting on the subsets of $\\{1,2,\\dots, n\\}$ is obtained.","main_category":"math.GR","categories":"math.GR,math.RT","published":"2025-04-10T15:09:00Z"}
{"aid":"http://arxiv.org/abs/2504.07838v1","title":"Large anisotropies in the gravitational wave background from\n  baryogenesis","summary":"Affleck-Dine (AD) baryogenesis can produce the baryon asymmetry of the\nUniverse through the $CP$-violating dynamics of AD field. The field generally\nfragments into Q-balls, whose rapid decay induces enhanced gravitational waves.\nIn this Letter, we investigate the anisotropies in this gravitational wave\nbackground as a new essential observable for AD baryogenesis. The evolution of\nAD field causes non-Gaussian baryonic isocurvature perturbations, and the\nnon-Gaussianity modulates the spatial distribution of Q-balls on large scales,\nresulting in large-scale anisotropies in the Q-ball-induced gravitational wave\nbackground. We present that the anisotropies can be significantly large with a\nreduced angular power spectrum $\\sim 10^{-2}$, and can be detected by future\nexperiments like LISA. Moreover, these anisotropies universally reveal the\n$CP$-violating dynamics of AD field, opening a novel road to explore the\nlongstanding baryon asymmetry puzzle.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-10T15:18:29Z"}
{"aid":"http://arxiv.org/abs/2504.07886v1","title":"Conformal product structures on compact Einstein manifolds","summary":"In this note we generalize our previous result, stating that if $(M_1,g_1)$\nand $(M_2,g_2)$ are compact Riemannian manifolds, then any Einstein metric on\nthe product $M:=M_1\\times M_2$ of the form $g=e^{2f_1}g_1+e^{2f_2}g_2$, with\n$f_1\\in C^\\infty(M_2)$ and $f_2\\in C^\\infty(M_1\\times M_2)$, is a warped\nproduct metric. Namely, we show that the same conclusion holds if we replace\nthe assumption that the manifold $M$ is globally the product of two compact\nmanifolds by the weaker assumption that $M$ is compact and carries a conformal\nproduct structure.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T15:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.07916v1","title":"Semantically Encoding Activity Labels for Context-Aware Human Activity\n  Recognition","summary":"Prior work has primarily formulated CA-HAR as a multi-label classification\nproblem, where model inputs are time-series sensor data and target labels are\nbinary encodings representing whether a given activity or context occurs. These\nCA-HAR methods either predicted each label independently or manually imposed\nrelationships using graphs. However, both strategies often neglect an essential\naspect: activity labels have rich semantic relationships. For instance,\nwalking, jogging, and running activities share similar movement patterns but\ndiffer in pace and intensity, indicating that they are semantically related.\nConsequently, prior CA-HAR methods often struggled to accurately capture these\ninherent and nuanced relationships, particularly on datasets with noisy labels\ntypically used for CA-HAR or situations where the ideal sensor type is\nunavailable (e.g., recognizing speech without audio sensors). To address this\nlimitation, we propose SEAL, which leverage LMs to encode CA-HAR activity\nlabels to capture semantic relationships. LMs generate vector embeddings that\npreserve rich semantic information from natural language. Our SEAL approach\nencodes input-time series sensor data from smart devices and their associated\nactivity and context labels (text) as vector embeddings. During training, SEAL\naligns the sensor data representations with their corresponding\nactivity/context label embeddings in a shared embedding space. At inference\ntime, SEAL performs a similarity search, returning the CA-HAR label with the\nembedding representation closest to the input data. Although LMs have been\nwidely explored in other domains, surprisingly, their potential in CA-HAR has\nbeen underexplored, making our approach a novel contribution to the field. Our\nresearch opens up new possibilities for integrating more advanced LMs into\nCA-HAR tasks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T17:30:07Z"}
{"aid":"http://arxiv.org/abs/2504.07917v1","title":"SKK groups of manifolds and non-unitary invertible TQFTs","summary":"This work considers the computation of controllable cut-and-paste groups\n$\\mathrm{SKK}^{\\xi}_n$ of manifolds with tangential structure $\\xi:B_n\\to\nBO_n$. To this end, we apply the work of Galatius-Madsen-Tillman-Weiss, Genauer\nand Schommer-Pries, who showed that for a wide range of structures $\\xi$ these\ngroups fit into a short exact sequence that relates them to bordism groups of\n$\\xi$-manifolds with kernel generated by the disc-bounding $\\xi$-sphere. The\norder of this sphere can be computed by knowing the possible values of the\nEuler characteristic of $\\xi$-manifolds. We are thus led to address two key\nquestions: the existence of $\\xi$-manifolds with odd Euler characteristic of a\ngiven dimension and conditions for the exact sequence to admit a splitting. We\nresolve these questions in a wide range of cases.\n  $\\mathrm{SKK}$ groups are of interest in physics as they play a role in the\nclassification of non-unitary invertible topological quantum field theories,\nwhich classify anomalies and symmetry protected topological (SPT) phases of\nmatter. Applying our topological results, we give a complete classification of\nnon-unitary invertible topological quantum field theories in the tenfold way in\ndimensions 1-5.","main_category":"math.AT","categories":"math.AT,math-ph,math.GT,math.MP","published":"2025-04-10T17:32:26Z"}
{"aid":"http://arxiv.org/abs/2504.07933v1","title":"Geometric and Dosimetric Validation of Deformable Image Registration for\n  Prostate MR-guided Adaptive Radiotherapy","summary":"Objective: Quantify geometric and dosimetric accuracy of a novel prostate\nMR-to-MR deformable image registration (DIR) approach to support MR-guided\nadaptive radiation therapy dose accumulation.\n  Approach: We evaluated DIR accuracy in 25 patients treated with 30 Gy in 5\nfractions on a 1.5 T MR-linac using an adaptive workflow. A reference MR was\nused for planning, with three images collected at each fraction: adapt MR for\nadaptive planning, verify MR for pretreatment position verification and beam-on\nfor capturing anatomy during radiation delivery. We assessed three DIR\napproaches: intensity-based, intensity-based with controlling structures (CS)\nand novel intensity based with controlling structures and points of interest\n(CS+P). DIRs were performed between the reference and fraction images and\nwithin fractions. We propagated CTV, bladder, and rectum contours using the\nDIRs and compared to manual contours using Dice similarity coefficient, mean\ndistance to agreement (DTAmean), and dose-volume metrics.\n  Results: CS and CS+P improved geometric agreement between contours over\nintensity-only DIR. DTAmean for reference-to-beam-on intensity-only DIR was\n0.131+/-0.009cm (CTV), 0.46+/-0.08cm (bladder), and 0.154+/-0.013cm (rectum).\nFor the CS, the values were 0.018+/-0.002cm, 0.388+/-0.14cm, and\n0.036+/-0.013cm. For CS+P these values were 0.015+/-0.001cm, 0.025+/-0.004cm,\nand 0.021+/-0.002cm. Dosimetrically, comparing CS and CS+P for reference to\nbeam-on DIRs resulted in a change of CTV D98% from [-29cGy, 19cGy] to [-18cGy,\n26cGy], rectum D1cc from [-106cGy, 72cGy] to [-52cGy, 74cGy], and bladder D5cc\nfrom [-51cGy, 544cGy] to [-79cGy, 36cGy].\n  Significance: CS improved geometric and dosimetric accuracy over\nintensity-only DIR, with CS+P providing the most consistent performance.\nHowever, session image segmentation remains a challenge, which may be addressed\nwith automated contouring.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-10T17:47:47Z"}
{"aid":"http://arxiv.org/abs/2504.07937v1","title":"Baryon asymmetry constraints on magnetic field from the Electroweak\n  epoch","summary":"Decay of helical (hyper)magnetic fields that may have been present in the\nUniverse during the Electroweak epoch can contribute to generation of the\nbaryon asymmetry of the Universe. We revise constraints on the strength and\ncorrelation length of such fields from the requirement that their decay does\nnot lead to over-production of the baryon asymmetry. We show that the helical\nfields with strength down to 1e-5 of the maximal possible strength during the\nElectroweak epoch should have had their correlation at least ~1e-6 of the\nHubble radius during this epoch. For weaker fields this lower bound on the\ncorrelation length relaxes proportionally to the square of magnetic field\nstrength. A field with parameters saturating the bound may actually be\nresponsible for the baryon asymmetry observed today. We show that relic of such\na field, surviving in the present day Universe in the form of intergalactic\nmagnetic field detectable with Cherenkov Telescope Array Observatory, may have\nthe strength up to 10-100 pG and can have parameters needed to affect the\ncosmological recombination and relax the Hubble tension. We also show that\nthere is no constraint on the parameters of helical or non-helical magnetic\nfields stemming from the requirement that the baryon isocurvature perturbations\nproduced by such fields during the Electroweak epoch are within the\nobservational limits.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.HE","published":"2025-04-10T17:50:47Z"}
{"aid":"http://arxiv.org/abs/2504.07962v1","title":"GLUS: Global-Local Reasoning Unified into A Single Large Language Model\n  for Video Segmentation","summary":"This paper proposes a novel framework utilizing multi-modal large language\nmodels (MLLMs) for referring video object segmentation (RefVOS). Previous\nMLLM-based methods commonly struggle with the dilemma between \"Ref\" and \"VOS\":\nthey either specialize in understanding a few key frames (global reasoning) or\ntracking objects on continuous frames (local reasoning), and rely on external\nVOS or frame selectors to mitigate the other end of the challenge. However, our\nframework GLUS shows that global and local consistency can be unified into a\nsingle video segmentation MLLM: a set of sparse \"context frames\" provides\nglobal information, while a stream of continuous \"query frames\" conducts local\nobject tracking. This is further supported by jointly training the MLLM with a\npre-trained VOS memory bank to simultaneously digest short-range and long-range\ntemporal information. To improve the information efficiency within the limited\ncontext window of MLLMs, we introduce object contrastive learning to\ndistinguish hard false-positive objects and a self-refined framework to\nidentify crucial frames and perform propagation. By collectively integrating\nthese insights, our GLUS delivers a simple yet effective baseline, achieving\nnew state-of-the-art for MLLMs on the MeViS and Ref-Youtube-VOS benchmark. Our\nproject page is at https://glus-video.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.07966v1","title":"What it takes to solve the Hubble tension through scale-dependent\n  modifications of the primordial power spectrum","summary":"We investigate scale-dependent modifications to the primordial scalar power\nspectrum as potential solutions to the Hubble tension. We use the Fisher-bias\nformalism, recently adapted to examine perturbed recombination solutions to the\nHubble tension, and extend its range of validity with an iterative method. We\nfirst analyze the Planck cosmic microwave background (CMB) anisotropy data,\ndemonstrating the existence of modifications to the primordial power spectrum\ncapable of fully resolving the tension between Planck and SH0ES. As a proof of\nconcept, we interpret these solutions in terms of small, time-dependent\nvariations in the first slow roll parameter or in the sound speed of curvature\nperturbations during a stage of primordial inflation. However, these solutions\nare associated with a low total matter density $\\Omega_m$, which makes them\ninconsistent with baryon acoustic oscillations (BAO) and uncalibrated\nsupernovae (SNIa) data. When incorporating additional BOSS and PantheonPlus\ndata, the solutions that reduce the Hubble tension tend to overfit Planck CMB\ndata to compensate for the worsened fit to BAO and SNIa data, making them less\ncompelling. These findings suggest that modifying the primordial power spectrum\nalone is unlikely to provide a robust resolution to the tension and highlight\nhow the viability of such data-driven solutions depends on the specific\ndatasets considered, emphasizing the role of future high-precision observations\nin further constraining possible resolutions to the tension.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.09894v1","title":"A mechanical approach to facilitate the formation of dodecagonal\n  quasicrystals and their approximants","summary":"The conditions for forming quasicrystals and their approximants are\nstringent, normally requiring multiple length scales to stabilize the\nquasicrystalline order. Here we report an unexpected finding that the\napproximants and motifs of dodecagonal quasicrystals can be spontaneously\nformed in the simplest system of identical hard disks, utilizing the unstable\nfeature of the initial square packing subject to mechanical perturbations.\nBecause there is only one length scale involved, this finding challenges\nexisting theories of quasicrystals and their approximants. By applying the same\napproach to a system known to form a dodecagonal quasicrystal, we develop\ndecent quasicrystalline order in a purely mechanical manner. With the aid of\nthermal treatment, we achieve a significantly better quasicrystalline order\nthan that from the direct self-assembly of the liquid state within the same\nperiod of time. In sufficiently low temperatures where the self-assembly of a\nliquid is significantly hindered, our approach still promotes the formation of\nquasicrystals. Our study thus opens a venue for high-efficiency search and\nformation of quasicrystals, and may have broader implications for the design\nand synthesis of quasicrystalline materials.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T05:39:23Z"}
{"aid":"http://arxiv.org/abs/2504.09904v1","title":"LiteTracker: Leveraging Temporal Causality for Accurate Low-latency\n  Tissue Tracking","summary":"Tissue tracking plays a critical role in various surgical navigation and\nextended reality (XR) applications. While current methods trained on large\nsynthetic datasets achieve high tracking accuracy and generalize well to\nendoscopic scenes, their runtime performances fail to meet the low-latency\nrequirements necessary for real-time surgical applications. To address this\nlimitation, we propose LiteTracker, a low-latency method for tissue tracking in\nendoscopic video streams. LiteTracker builds on a state-of-the-art long-term\npoint tracking method, and introduces a set of training-free runtime\noptimizations. These optimizations enable online, frame-by-frame tracking by\nleveraging a temporal memory buffer for efficient feature reuse and utilizing\nprior motion for accurate track initialization. LiteTracker demonstrates\nsignificant runtime improvements being around 7x faster than its predecessor\nand 2x than the state-of-the-art. Beyond its primary focus on efficiency,\nLiteTracker delivers high-accuracy tracking and occlusion prediction,\nperforming competitively on both the STIR and SuPer datasets. We believe\nLiteTracker is an important step toward low-latency tissue tracking for\nreal-time surgical applications in the operating room.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T05:53:57Z"}
{"aid":"http://arxiv.org/abs/2504.09905v1","title":"Fusing Bluetooth with Pedestrian Dead Reckoning: A Floor Plan-Assisted\n  Positioning Approach","summary":"Floor plans can provide valuable prior information that helps enhance the\naccuracy of indoor positioning systems. However, existing research typically\nfaces challenges in efficiently leveraging floor plan information and applying\nit to complex indoor layouts. To fully exploit information from floor plans for\npositioning, we propose a floor plan-assisted fusion positioning algorithm\n(FP-BP) using Bluetooth low energy (BLE) and pedestrian dead reckoning (PDR).\nIn the considered system, a user holding a smartphone walks through a\npositioning area with BLE beacons installed on the ceiling, and can locate\nhimself in real time. In particular, FP-BP consists of two phases. In the\noffline phase, FP-BP programmatically extracts map features from a stylized\nfloor plan based on their binary masks, and constructs a mapping function to\nidentify the corresponding map feature of any given position on the map. In the\nonline phase, FP-BP continuously computes BLE positions and PDR results from\nBLE signals and smartphone sensors, where a novel grid-based maximum likelihood\nestimation (GML) algorithm is introduced to enhance BLE positioning. Then, a\nparticle filter is used to fuse them and obtain an initial estimate. Finally,\nFP-BP performs post-position correction to obtain the final position based on\nits specific map feature. Experimental results show that FP-BP can achieve a\nreal-time mean positioning accuracy of 1.19 m, representing an improvement of\nover 28% compared to existing floor plan-fused baseline algorithms.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T06:00:39Z"}
{"aid":"http://arxiv.org/abs/2504.09908v1","title":"Laser-induced spectral diffusion and excited-state mixing of silicon T\n  centres","summary":"To find practical application as photon sources for entangled optical\nresource states or as spin-photon interfaces in entangled networks,\nsemiconductor emitters must produce indistinguishable photons with high\nefficiency and spectral stability. Nanophotonic cavity integration increases\nefficiency and bandwidth, but it also introduces environmental charge\ninstability and spectral diffusion. Among various candidates, silicon colour\ncentres have emerged as compelling platforms for integrated-emitter quantum\ntechnologies. Here we investigate the dynamics of spectral wandering in\nnanophotonics-coupled, individual silicon T centres using spectral correlation\nmeasurements. We observe that spectral fluctuations are driven predominantly by\nthe near-infrared excitation laser, consistent with a power-dependent\nOrnstein-Uhlenbeck process, and show that the spectrum is stable for up to 1.5\nms in the dark. We demonstrate a 35x narrowing of the emitter linewidth to 110\nMHz using a resonance-check scheme and discuss the advantage for pairwise\nentanglement rates and optical resource state generators. Finally, we report\nlaser-induced spin-mixing in the excited state and discuss potential mechanisms\ncommon to both phenomena. These effects must be considered in calibrating T\ncentre devices for high-performance entanglement generation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T06:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.09915v1","title":"StePO-Rec: Towards Personalized Outfit Styling Assistant via\n  Knowledge-Guided Multi-Step Reasoning","summary":"Advancements in Generative AI offers new opportunities for FashionAI,\nsurpassing traditional recommendation systems that often lack transparency and\nstruggle to integrate expert knowledge, leaving the potential for personalized\nfashion styling remain untapped. To address these challenges, we present PAFA\n(Principle-Aware Fashion), a multi-granular knowledge base that organizes\nprofessional styling expertise into three levels of metadata, domain\nprinciples, and semantic relationships. Using PAFA, we develop StePO-Rec, a\nknowledge-guided method for multi-step outfit recommendation. StePO-Rec\nprovides structured suggestions using a scenario-dimension-attribute framework,\nemploying recursive tree construction to align recommendations with both\nprofessional principles and individual preferences. A preference-trend\nre-ranking system further adapts to fashion trends while maintaining the\nconsistency of the user's original style. Experiments on the widely used\npersonalized outfit dataset IQON show a 28% increase in Recall@1 and 32.8% in\nMAP. Furthermore, case studies highlight improved explainability, traceability,\nresult reliability, and the seamless integration of expertise and\npersonalization.","main_category":"cs.IR","categories":"cs.IR,cs.MM","published":"2025-04-14T06:24:56Z"}
{"aid":"http://arxiv.org/abs/2504.09930v1","title":"Multi-objective Bayesian Optimization With Mixed-categorical Design\n  Variables for Expensive-to-evaluate Aeronautical Applications","summary":"This work aims at developing new methodologies to optimize computational\ncostly complex systems (e.g., aeronautical engineering systems). The proposed\nsurrogate-based method (often called Bayesian optimization) uses adaptive\nsampling to promote a trade-off between exploration and exploitation. Our\nin-house implementation, called SEGOMOE, handles a high number of design\nvariables (continuous, discrete or categorical) and nonlinearities by combining\nmixtures of experts for the objective and/or the constraints. Additionally, the\nmethod handles multi-objective optimization settings, as it allows the\nconstruction of accurate Pareto fronts with a minimal number of function\nevaluations. Different infill criteria have been implemented to handle multiple\nobjectives with or without constraints. The effectiveness of the proposed\nmethod was tested on practical aeronautical applications within the context of\nthe European Project AGILE 4.0 and demonstrated favorable results. A first\nexample concerns a retrofitting problem where a comparison between two\noptimizers have been made. A second example introduces hierarchical variables\nto deal with architecture system in order to design an aircraft family. The\nthird example increases drastically the number of categorical variables as it\ncombines aircraft design, supply chain and manufacturing process. In this\narticle, we show, on three different realistic problems, various aspects of our\noptimization codes thanks to the diversity of the treated aircraft problems.","main_category":"cs.LG","categories":"cs.LG,math.OC,stat.AP","published":"2025-04-14T06:44:13Z"}
{"aid":"http://arxiv.org/abs/2504.09933v1","title":"On the $N$th $2$-adic complexity of binary sequences identified with\n  algebraic $2$-adic integers","summary":"We identify a binary sequence $\\mathcal{S}=(s_n)_{n=0}^\\infty$ with the\n$2$-adic integer $G_\\mathcal{S}(2)=\\sum\\limits_{n=0}^\\infty s_n2^n$. In the\ncase that $G_\\mathcal{S}(2)$ is algebraic over $\\mathbb{Q}$ of degree $d\\ge 2$,\nwe prove that the $N$th $2$-adic complexity of $\\mathcal{S}$ is at least\n$\\frac{N}{d}+O(1)$, where the implied constant depends only on the minimal\npolynomial of $G_\\mathcal{S}(2)$. This result is an analog of the bound of\nM\\'erai and the second author on the linear complexity of automatic sequences,\nthat is, sequences with algebraic $G_\\mathcal{S}(X)$ over the rational function\nfield $\\mathbb{F}_2(X)$. We further discuss the most important case $d=2$ in\nboth settings and explain that the intersection of the set of $2$-adic\nalgebraic sequences and the set of automatic sequences is the set of\n(eventually) periodic sequences. Finally, we provide some experimental results\nsupporting the conjecture that $2$-adic algebraic sequences can have also a\ndesirable $N$th linear complexity and automatic sequences a desirable $N$th\n$2$-adic complexity, respectively.","main_category":"math.NT","categories":"math.NT,cs.IT,math.IT","published":"2025-04-14T06:52:47Z"}
{"aid":"http://arxiv.org/abs/2504.09949v1","title":"Pseudo-Label Guided Real-World Image De-weathering: A Learning Framework\n  with Imperfect Supervision","summary":"Real-world image de-weathering aims at removingvarious undesirable\nweather-related artifacts, e.g., rain, snow,and fog. To this end, acquiring\nideal training pairs is crucial.Existing real-world datasets are typically\nconstructed paired databy extracting clean and degraded images from live\nstreamsof landscape scene on the Internet. Despite the use of strictfiltering\nmechanisms during collection, training pairs inevitablyencounter inconsistency\nin terms of lighting, object position, scenedetails, etc, making de-weathering\nmodels possibly suffer fromdeformation artifacts under non-ideal supervision.\nIn this work,we propose a unified solution for real-world image\nde-weatheringwith non-ideal supervision, i.e., a pseudo-label guided\nlearningframework, to address various inconsistencies within the realworld\npaired dataset. Generally, it consists of a de-weatheringmodel (De-W) and a\nConsistent Label Constructor (CLC), bywhich restoration result can be\nadaptively supervised by originalground-truth image to recover sharp textures\nwhile maintainingconsistency with the degraded inputs in non-weather\ncontentthrough the supervision of pseudo-labels. Particularly, a Crossframe\nSimilarity Aggregation (CSA) module is deployed withinCLC to enhance the\nquality of pseudo-labels by exploring thepotential complementary information of\nmulti-frames throughgraph model. Moreover, we introduce an Information\nAllocationStrategy (IAS) to integrate the original ground-truth imagesand\npseudo-labels, thereby facilitating the joint supervision forthe training of\nde-weathering model. Extensive experimentsdemonstrate that our method exhibits\nsignificant advantageswhen trained on imperfectly aligned de-weathering\ndatasets incomparison with other approaches.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-14T07:24:03Z"}
{"aid":"http://arxiv.org/abs/2504.09988v1","title":"Equivariant bordism classification of five-dimensional\n  $(\\mathbb{Z}_2)^3$-manifolds with isolated fixed points","summary":"Denote by $\\mathcal{Z}_5((\\mathbb{Z}_2)^3)$ the group, which is also a vector\nspace over $\\mathbb{Z}_2$, generated by equivariant unoriented bordism classes\nof all five-dimensional closed smooth manifolds with effective smooth\n$(\\mathbb{Z}_2)^3$-actions fixing isolated points. We show that\n$\\dim_{\\mathbb{Z}_2} \\mathcal{Z}_5((\\mathbb{Z}_2)^3) = 77$ and determine a\nbasis of $\\mathcal{Z}_5((\\mathbb{Z}_2)^3)$, each of which is explicitly chosen\nas the projectivization of a real vector bundle. Thus this gives a complete\nclassification up to equivariant unoriented bordism of all five-dimensional\nclosed smooth manifolds with effective smooth $(\\mathbb{Z}_2)^3$-actions with\nisolated fixed points.","main_category":"math.AT","categories":"math.AT","published":"2025-04-14T08:52:27Z"}
{"aid":"http://arxiv.org/abs/2504.09993v1","title":"AimTS: Augmented Series and Image Contrastive Learning for Time Series\n  Classification","summary":"Time series classification (TSC) is an important task in time series\nanalysis. Existing TSC methods mainly train on each single domain separately,\nsuffering from a degradation in accuracy when the samples for training are\ninsufficient in certain domains. The pre-training and fine-tuning paradigm\nprovides a promising direction for solving this problem. However, time series\nfrom different domains are substantially divergent, which challenges the\neffective pre-training on multi-source data and the generalization ability of\npre-trained models. To handle this issue, we introduce Augmented Series and\nImage Contrastive Learning for Time Series Classification (AimTS), a\npre-training framework that learns generalizable representations from\nmulti-source time series data. We propose a two-level prototype-based\ncontrastive learning method to effectively utilize various augmentations in\nmulti-source pre-training, which learns representations for TSC that can be\ngeneralized to different domains. In addition, considering augmentations within\nthe single time series modality are insufficient to fully address\nclassification problems with distribution shift, we introduce the image\nmodality to supplement structural information and establish a series-image\ncontrastive learning to improve the generalization of the learned\nrepresentations for TSC tasks. Extensive experiments show that after\nmulti-source pre-training, AimTS achieves good generalization performance,\nenabling efficient learning and even few-shot learning on various downstream\nTSC datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T08:55:16Z"}
{"aid":"http://arxiv.org/abs/2504.10033v1","title":"The law of large numbers for discrete generalized quantum channels","summary":"We consider random linear operators $\\Omega \\to \\mathcal{L}(\\mathcal{T}_p,\n\\mathcal{T}_p)$ acting in a $p$-th Schatten class $\\mathcal{T}_p$ in a\nseparable Hilbert space $\\mathcal{H}$ for some $1 \\leqslant p < \\infty$. Such a\nsuperoperator is called a pre-channel since it is an extension of a quantum\nchannel to a wider class of operators without requirements of trace-preserving\nand positivity. Instead of the sum of i.i.d. variables there may be considered\nthe composition of random semigroups $e^{A_i t/n}$ in the Banach space\n$\\mathcal{T}_p$. The law of large numbers is known in the case $p=2$ in the\nform of the usual law of large numbers for random operators in a Hilbert space.\nWe obtain the law of large numbers for the case $1\\leqslant p \\leqslant 2$.","main_category":"math.FA","categories":"math.FA,math.PR","published":"2025-04-14T09:35:48Z"}
{"aid":"http://arxiv.org/abs/2504.10042v1","title":"Search for $B^0 \\to K^{\\ast 0} Ï^+ Ï^-$ decays at the Belle II\n  experiment","summary":"We present a search for the rare flavor-changing neutral-current decay $B^0\n\\to K^{\\ast 0} \\tau^+ \\tau^-$ with data collected by the Belle II experiment at\nthe SuperKEKB electron-positron collider. The analysis uses a 365 fb$^{-1}$\ndata sample recorded at the center-of-mass energy of the $\\Upsilon(4S)$\nresonance. One of the $B$ mesons produced in the $\\Upsilon(4S)\\to B^0\n\\bar{B}^0$ process is fully reconstructed in a hadronic decay mode, while its\ncompanion $B$ meson is required to decay into a $K^{\\ast 0}$ and two $\\tau$\nleptons of opposite charge. The $\\tau$ leptons are reconstructed in final\nstates with a single electron, muon, charged pion or charged $\\rho$ meson, and\nadditional neutrinos. We set an upper limit on the branching ratio of $BR(B^0\n\\to K^{\\ast 0} \\tau^+ \\tau^-) < 1.8 \\times 10^{-3}$ at the 90% confidence\nlevel, which is the most stringent constraint reported to date.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-14T09:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.10055v1","title":"Joint Action Language Modelling for Transparent Policy Execution","summary":"An agent's intention often remains hidden behind the black-box nature of\nembodied policies. Communication using natural language statements that\ndescribe the next action can provide transparency towards the agent's behavior.\nWe aim to insert transparent behavior directly into the learning process, by\ntransforming the problem of policy learning into a language generation problem\nand combining it with traditional autoregressive modelling. The resulting model\nproduces transparent natural language statements followed by tokens\nrepresenting the specific actions to solve long-horizon tasks in the\nLanguage-Table environment. Following previous work, the model is able to learn\nto produce a policy represented by special discretized tokens in an\nautoregressive manner. We place special emphasis on investigating the\nrelationship between predicting actions and producing high-quality language for\na transparent agent. We find that in many cases both the quality of the action\ntrajectory and the transparent statement increase when they are generated\nsimultaneously.","main_category":"cs.RO","categories":"cs.RO,cs.CL","published":"2025-04-14T09:57:37Z"}
{"aid":"http://arxiv.org/abs/2504.10069v1","title":"Relativistic Quantum Simulation of Hydrogen Sulfide for Hydrogen Energy\n  via Hybrid Quantum-Classical Algorithms","summary":"We present a relativistic quantum simulation framework for modeling hydrogen\nsulfide (H2S) decomposition relevant to hydrogen energy applications. The\napproach integrates Dirac-Coulomb relativistic quantum chemistry with the\nvariational quantum eigensolver (VQE), implemented on a hybrid\nquantum-classical architecture. Using quantum algorithms based on Jordan-Wigner\nencoding and relativistic integrals, we simulate ground-state energies and\npotential energy surfaces for H2, H2O, and H2S molecules. Results demonstrate\nthat the relativistic VQE correctly reproduces known energy shifts and\nmolecular trends. Optimizer performance, energy variance, and Pauli term\ncomplexity are also evaluated. The findings offer insight into scalable quantum\nsimulations of chemically and physically significant systems involving heavy\natoms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T10:15:02Z"}
{"aid":"http://arxiv.org/abs/2504.10076v1","title":"Towards Scalable Bayesian Optimization via Gradient-Informed Bayesian\n  Neural Networks","summary":"Bayesian optimization (BO) is a widely used method for data-driven\noptimization that generally relies on zeroth-order data of objective function\nto construct probabilistic surrogate models. These surrogates guide the\nexploration-exploitation process toward finding global optimum. While Gaussian\nprocesses (GPs) are commonly employed as surrogates of the unknown objective\nfunction, recent studies have highlighted the potential of Bayesian neural\nnetworks (BNNs) as scalable and flexible alternatives. Moreover, incorporating\ngradient observations into GPs, when available, has been shown to improve BO\nperformance. However, the use of gradients within BNN surrogates remains\nunexplored. By leveraging automatic differentiation, gradient information can\nbe seamlessly integrated into BNN training, resulting in more informative\nsurrogates for BO. We propose a gradient-informed loss function for BNN\ntraining, effectively augmenting function observations with local gradient\ninformation. The effectiveness of this approach is demonstrated on well-known\nbenchmarks in terms of improved BNN predictions and faster BO convergence as\nthe number of decision variables increases.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-14T10:21:08Z"}
{"aid":"http://arxiv.org/abs/2504.10101v1","title":"The Human Visual System Can Inspire New Interaction Paradigms for LLMs","summary":"The dominant metaphor of LLMs-as-minds leads to misleading conceptions of\nmachine agency and is limited in its ability to help both users and developers\nbuild the right degree of trust and understanding for outputs from LLMs. It\nmakes it harder to disentangle hallucinations from useful model interactions.\nThis position paper argues that there are fundamental similarities between\nvisual perception and the way LLMs process and present language. These\nsimilarities inspire a metaphor for LLMs which could open new avenues for\nresearch into interaction paradigms and shared representations. Our visual\nsystem metaphor introduces possibilities for addressing these challenges by\nunderstanding the information landscape assimilated by LLMs. In this paper we\nmotivate our proposal, introduce the interrelating theories from the fields\nthat inspired this view and discuss research directions that stem from this\nabstraction.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T11:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.10114v1","title":"$t$-$J$ model for strongly correlated two-orbital systems: Application\n  to bilayer nickelate superconductors","summary":"We derive a $t$-$J$ model applicable to strongly correlated two-orbital\nsystems including bilayer nickelate superconductors. Using the Schrieffer-Wolff\ntransformation, we exclude the doubly occupied states raising the on-site\nCoulomb energy and derive resulting spin interactions from the two-orbital\nHubbard model. We also introduce effective interactions attributed to the\ninterorbital Coulomb interaction. To adapt the effective model to bilayer\nnickelates that exhibit high-temperature superconductivity, we quantitatively\nevaluate the strengths of the spin interactions based on the hopping parameters\nin La$_3$Ni$_2$O$_7$. Considering the evaluated effective interactions, we\npropose a simplified $t$-$J$ model for bilayer nickelate superconductors.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-14T11:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.10147v1","title":"A Survey of Personalization: From RAG to Agent","summary":"Personalization has become an essential capability in modern AI systems,\nenabling customized interactions that align with individual user preferences,\ncontexts, and goals. Recent research has increasingly concentrated on\nRetrieval-Augmented Generation (RAG) frameworks and their evolution into more\nadvanced agent-based architectures within personalized settings to enhance user\nsatisfaction. Building on this foundation, this survey systematically examines\npersonalization across the three core stages of RAG: pre-retrieval, retrieval,\nand generation. Beyond RAG, we further extend its capabilities into the realm\nof Personalized LLM-based Agents, which enhance traditional RAG systems with\nagentic functionalities, including user understanding, personalized planning\nand execution, and dynamic generation. For both personalization in RAG and\nagent-based personalization, we provide formal definitions, conduct a\ncomprehensive review of recent literature, and summarize key datasets and\nevaluation metrics. Additionally, we discuss fundamental challenges,\nlimitations, and promising research directions in this evolving field. Relevant\npapers and resources are continuously updated at\nhttps://github.com/Applied-Machine-Learning-Lab/Awesome-Personalized-RAG-Agent.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T11:57:52Z"}
{"aid":"http://arxiv.org/abs/2504.10153v1","title":"Searching for quasi-periodicities in short transients: the curious case\n  of GRB 230307A","summary":"Gamma-ray bursts (GRBs) are the most powerful explosions in the Universe;\ntheir energy release reache s us from the end of the re-ionization era, making\nthem invaluable cosmological probes. GRB 230307A i s the second-brightest GRB\never observed in the 56 years of observations since the discovery of the\nphenomenon in 1967. Follow-up observations of the event at longer wavelengths\nrevealed a lanthanide-ri ch kilonova with long-lasting X-ray emission\nimmediately following the prompt gamma-rays. Moreover, t he gamma-ray light\ncurve of GRB 230307A collected with INTEGRAL's SPectrometer of INTEGRAL\nAntiCoincidence Shield (SPI-ACS) and Fermi's Gamma-Ray Burst Monitor (GBM). We\nuse Fourier analysis, wavelets and Gaussian Processes to search for periodic\nand quasi-periodic oscillations (QPOs) in the prompt gamma-ray emission of GRB\n230307A. We critically assess all three methods in terms of their robustness\nfor detections of QPOs in fast transients such as GRBs. Our analyses reveal\nQPOs at a frequency of $\\sim 1.2$ Hz (0.82s period) near the burst's peak\nemission phase, consistent across instruments and detection methods. We also\nidentify a second, less significant QPO at $\\sim 2.9$ Hz (0.34s) nearly\nsimultaneously. We hypothesise that the two QPOs originate from the transition\nepoch at the end of the jet acceleration phase. These QPOs re present plasma\ncirculation periods in vorticity about the jet axis carried outwards to the\nprompt radiation zone at much larger radii. They are sampled by colliding\nstructures (e.g., shocks) in the spinning jet, possibly marking the evolution\nof plasma rotation during the final stages of the progenitor neutron star\ncoalescence event.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T12:07:18Z"}
{"aid":"http://arxiv.org/abs/2504.10155v1","title":"A Buium--Coleman bound for the Mordell--Lang conjecture","summary":"For $X$ a hyperbolic curve of genus $g$ with good reduction at $p\\geq 2g$, we\ngive an explicit bound on the Mordell--Lang locus $X(\\mathbb{C})\\cap \\Gamma $,\nwhen $\\Gamma \\subset J(\\mathbb{C})$ is the divisible hull of a subgroup of\n$J(\\mathbb{Q} _p ^{\\mathrm{nr}})$ of rank less than $g$. Without any\nassumptions on the rank (but with all the other assumptions) we show that\n$X(\\mathbb{C})\\cap \\Gamma $ is unramified at $p$, and bound the size of its\nimage in $X(\\overline{\\mathbb{F} }_p )$. As a corollary, we show that Mordell\nimplies Mordell--Lang for curves.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-14T12:11:22Z"}
{"aid":"http://arxiv.org/abs/2504.10184v1","title":"Dispatching Odyssey: Exploring Performance in Computing Clusters under\n  Real-world Workloads","summary":"Recent workload measurements in Google data centers provide an opportunity to\nchallenge existing models and, more broadly, to enhance the understanding of\ndispatching policies in computing clusters. Through extensive data-driven\nsimulations, we aim to highlight the key features of workload traffic traces\nthat influence response time performance under simple yet representative\ndispatching policies. For a given computational power budget, we vary the\ncluster size, i.e., the number of available servers. A job-level analysis\nreveals that Join Idle Queue (JIQ) and Least Work Left (LWL) exhibit an optimal\nworking point for a fixed utilization coefficient as the number of servers is\nvaried, whereas Round Robin (RR) demonstrates monotonously worsening\nperformance. Additionally, we explore the accuracy of simple G/G queue\napproximations. When decomposing jobs into tasks, interesting results emerge;\nnotably, the simpler, non-size-based policy JIQ appears to outperform the more\n\"powerful\" size-based LWL policy. Complementing these findings, we present\npreliminary results on a two-stage scheduling approach that partitions tasks\nbased on service thresholds, illustrating that modest architectural\nmodifications can further enhance performance under realistic workload\nconditions. We provide insights into these results and suggest promising\ndirections for fully explaining the observed phenomena.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T12:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.10190v1","title":"Differentially Private 2D Human Pose Estimation","summary":"Human pose estimation (HPE) has become essential in numerous applications\nincluding healthcare, activity recognition, and human-computer interaction.\nHowever, the privacy implications of processing sensitive visual data present\nsignificant deployment barriers in critical domains. While traditional\nanonymization techniques offer limited protection and often compromise data\nutility for broader motion analysis, Differential Privacy (DP) provides formal\nprivacy guarantees but typically degrades model performance when applied\nnaively. In this work, we present the first differentially private 2D human\npose estimation (2D-HPE) by applying Differentially Private Stochastic Gradient\nDescent (DP-SGD) to this task. To effectively balance privacy with performance,\nwe adopt Projected DP-SGD (PDP-SGD), which projects the noisy gradients to a\nlow-dimensional subspace. Additionally, we adapt TinyViT, a compact and\nefficient vision transformer for coordinate classification in HPE, providing a\nlightweight yet powerful backbone that enhances privacy-preserving deployment\nfeasibility on resource-limited devices. Our approach is particularly valuable\nfor multimedia interpretation tasks, enabling privacy-safe analysis and\nunderstanding of human motion across diverse visual media while preserving the\nsemantic meaning required for downstream applications. Comprehensive\nexperiments on the MPII Human Pose Dataset demonstrate significant performance\nenhancement with PDP-SGD achieving 78.48% PCKh@0.5 at a strict privacy budget\n($\\epsilon=0.2$), compared to 63.85% for standard DP-SGD. This work lays\nfoundation for privacy-preserving human pose estimation in real-world,\nsensitive applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T12:50:37Z"}
{"aid":"http://arxiv.org/abs/2504.10230v1","title":"Extracting cosmological information from the abundance of galaxy\n  clusters with simulation-based inference","summary":"The abundance of galaxy clusters as a function of mass and redshift is a\nwell-established and powerful cosmological probe. Cosmological analyses based\non galaxy cluster number counts have traditionally relied on explicitly\ncomputed likelihoods, which are often challenging to develop with the required\naccuracy and expensive to evaluate. In this work, we implement an alternative\napproach based on simulation-based inference (SBI) methods that relies solely\non synthetic galaxy cluster catalogues generated under a given model. These\ncatalogues are much easier to produce than it is to develop and validate a\nlikelihood. We validate this approach in the context of the galaxy cluster\nsurvey of the upcoming Simons Observatory for a setup in which we can also\nevaluate an exact explicit likelihood. We find that our SBI-based approach\nyields cosmological parameter posterior means that are within $0.2\\,\\sigma$ of\nthose obtained with the explicit likelihood and with biases smaller than\n$0.1\\,\\sigma$. We also introduce and validate a procedure to assess the\ngoodness of fit using only synthetic catalogues similar to those used for\ntraining. This demonstrates, for the first time, that a galaxy cluster number\ncount cosmological analysis can be performed fully without resorting to a\nlikelihood at any stage. Finally, we apply our SBI-based approach to the real\nPlanck MMF3 cosmology sample, obtaining cosmological parameter constraints that\nare within $0.1\\,\\sigma$ of their likelihood-based counterparts. This\nconstitutes the first SBI-based number count cosmological analysis of a real\ngalaxy cluster catalogue.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-14T13:51:55Z"}
{"aid":"http://arxiv.org/abs/2504.10238v1","title":"Highly Hydrogenated Monolayer Graphene with Wide Band Gap Opening","summary":"A thorough spectroscopic characterisation of highly hydrogenated monolayer\ngraphene trasferred on TEM grids is herein reported. The graphene hydrogenation\nhas the effect to distort the $sp^2$ arrangement of carbon atoms in the lattice\ntoward a $sp^3$-like coordination, through the breaking of the $\\pi$-bonds, as\ndetermined by X ray photoelectron spectroscopy of the C 1s core level. The\nhydrogen bonding was found to be favoured for a more distorted graphene\nlattice. Indeed, a 100$\\%$ $sp^3$-saturation - the highest ever achieved - was\nobserved after the hydrogenation of a sample with more pristine $sp^3$-like\ndeformed bonds, while the flatter, more $sp^2$-arranged, sample reached a\n59$\\%$ $sp^3$-saturation. Electron energy loss spectroscopy confirmed the\nphotoemission result showing the $\\pi$-plasmon excitation quenching, in the\ntotally hydrogenated sample, and significant reduction, for the other one. High\nloading levels of hydrogenation were also witnessed by the opening of a wide\noptical band gap (6.3 and 6.2 eV). The observation of the C-H stretching\nvibrational mode is also reported, as a direct footprint of graphene\nhydrogenation. Finally, valence band measurements of the 59$\\%$ saturated\nsample suggest the coexistence of one-side and two-side hydrogenation\nmorphologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T14:01:40Z"}
{"aid":"http://arxiv.org/abs/2504.10243v1","title":"A parton shower consistent with parton densities at LO and NLO: PDF2ISR","summary":"We present a method for obtaining an initial-state parton shower model where\nthe (backward) evolution fully consistent with the (forward) evolution of the\ncollinear parton density used. As a proof-of-concept we use parton densities\nobtained with the Parton Branching (PB) approach, and modify the default\ninitial-state shower in PYTHIA8 with this method to be consistent with them. PB\nis ideally suited for checking the validity of our method since, in addition to\nproducing collinear parton densities, it also produces the corresponding\ntransverse-dependent (TMD) ones, and these can then be directly compared to the\ntransverse momentum distribution obtained from the parton shower. We show that\nTMD distributions which we in this way obtain from our modified PYTHIA8 shower\nusing leading order (LO) parton densities and splitting functions are fully\nconsistent with the corresponding leading order TMD densities. At\nnext-to-leading order (NLO) it is not possible to achieve the same consistency\nusing the built-in LO splitting functions in the shower, but we show that by\nintroducing NLO splitting functions using a reweighting procedure, we can\nachieve consistency also at NLO. The method presented here, which we have named\nPDF2ISR, can be easily extended to any collinear parton densities, as long as\nthe exact conditions for the evolution are known. With the PDF2ISR method we\nobtain an initial-state parton shower which in principle has no free\nparameters, and is fully consistent with collinear parton densities at LO and\nNLO.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-th","published":"2025-04-14T14:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.10247v1","title":"Exponentially Decaying Quantum Simulation Error with Noisy Devices","summary":"Quantum simulation is a promising way toward practical quantum advantage, but\nnoise in current quantum hardware poses a significant obstacle. We\ntheoretically and numerically revealed that not only the physical error but\nalso the algorithmic error in a single Trotter step decreases exponentially\nwith the circuit depth. In particular, according to our results, we derive the\noptimal number of Trotter steps and the noise requirement to guarantee total\nsimulation precision. At last, we demonstrate that our improved error analysis\nleads to significant resource-saving for fault-tolerant Trotter simulation. By\naddressing these aspects, this work systematically characterizes the robustness\nof Trotter simulation errors in noisy quantum devices and paves the way toward\npractical quantum advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T14:10:24Z"}
{"aid":"http://arxiv.org/abs/2504.10254v1","title":"MASSeg : 2nd Technical Report for 4th PVUW MOSE Track","summary":"Complex video object segmentation continues to face significant challenges in\nsmall object recognition, occlusion handling, and dynamic scene modeling. This\nreport presents our solution, which ranked second in the MOSE track of CVPR\n2025 PVUW Challenge. Based on an existing segmentation framework, we propose an\nimproved model named MASSeg for complex video object segmentation, and\nconstruct an enhanced dataset, MOSE+, which includes typical scenarios with\nocclusions, cluttered backgrounds, and small target instances. During training,\nwe incorporate a combination of inter-frame consistent and inconsistent data\naugmentation strategies to improve robustness and generalization. During\ninference, we design a mask output scaling strategy to better adapt to varying\nobject sizes and occlusion levels. As a result, MASSeg achieves a J score of\n0.8250, F score of 0.9007, and a J&F score of 0.8628 on the MOSE test set.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T14:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.10264v1","title":"Multidimensional non-uniform hyperbolicity, robust exponential mixing\n  and the basin problem","summary":"We show that the ergodic, topological and geometric basins coincide for\nhyperbolic dominated ergodic $cu$-Gibbs states, solving the ``basin problem''\nfor a wide class of non-uniformly hyperbolic systems.\n  We obtain robust examples of exponential mixing physical measures for systems\nwith multidimensional nonuniform hyperbolic dominated splitting, without\nuniformly expanding or contracting subbundles.\n  Both results are a consequence of extending the construction of\nGibbs-Markov-Young structures from partial hyperbolic systems to systems with\nonly a dominated splitting, using the existence of an ``improved hyperbolic\nblock'', with respect to Pesin's Nonuniform Hyperbolic Theory, for hyperbolic\ndominated measures of smooth maps, obtained through hyperbolic times and\nassociated ``coherent schedules'' introduced by one of the coauthors.","main_category":"math.DS","categories":"math.DS","published":"2025-04-14T14:29:23Z"}
{"aid":"http://arxiv.org/abs/2504.10289v1","title":"Optimal Graph Stretching for Distributed Averaging","summary":"The performance of distributed averaging depends heavily on the underlying\ntopology. In various fields, including compressed sensing, multi-party\ncomputation, and abstract graph theory, graphs may be expected to be free of\nshort cycles, i.e. to have high girth. Though extensive analyses and heuristics\nexist for optimising the performance of distributed averaging in general\nnetworks, these studies do not consider girth. As such, it is not clear what\nhappens to convergence time when a graph is stretched to a higher girth.\n  In this work, we introduce the optimal graph stretching problem, wherein we\nare interested in finding the set of edges for a particular graph that ensures\noptimal convergence time under constraint of a minimal girth. We compare\nvarious methods for choosing which edges to remove, and use various convergence\nheuristics to speed up the searching process. We generate many graphs with\nvarying parameters, stretch and optimise them, and measure the duration of\ndistributed averaging. We find that stretching by itself significantly\nincreases convergence time. This decrease can be counteracted with a subsequent\nrepair phase, guided by a convergence time heuristic. Existing heuristics are\ncapable, but may be suboptimal.","main_category":"cs.DC","categories":"cs.DC,cs.DM","published":"2025-04-14T15:01:24Z"}
{"aid":"http://arxiv.org/abs/2504.10304v1","title":"Extended-BMS Anomalies and Flat Space Holography","summary":"We classify the Lagrangians and anomalies of an extended BMS field theory\nusing BRST methods. To do so, we establish an intrinsic gauge-fixing procedure\nfor the geometric data, which allows us to derive the extended BMS symmetries\nand the correct transformation law of the shear, encoded in the connection. Our\nanalysis reveals that the invariant Lagrangians are always topological, thereby\nreducing the 4d bulk to a 2d boundary theory. Moreover, we find that\nsupertranslations are anomaly-free, while superrotations exhibit independent\ncentral charges. This BMS field theory is dual to Einstein gravity in\nasymptotically flat spacetimes when the superrotation anomalies coincide and\nare dictated by the bulk. Meanwhile, the absence of supertranslation anomalies\naligns with Weinberg's soft graviton theorem being tree-level exact. This work\nprovides a first-principle derivation of the structure of the null boundary\nfield theory, intrinsic and independent of bulk considerations, offering\nfurther evidence for the holographic principle in flat space, and its\ndimensional reduction.","main_category":"hep-th","categories":"hep-th,gr-qc,math-ph,math.MP","published":"2025-04-14T15:12:30Z"}
{"aid":"http://arxiv.org/abs/2504.10312v1","title":"Investigating two-zero texture in the light of gauged Type-II seesaw","summary":"Neutrino oscillation, discovered over two decades ago, confirmed that\nneutrinos have nonzero masses. Since then, two mass-squared differences have\nbeen measured with unprecedented precision, yet the absolute neutrino mass\nscale remains unknown. Additionally, the fundamental symmetry governing the\nneutrino mixing pattern is still undetermined. Among various theoretical\npossibilities, the two-zero texture in the neutrino mass matrix ($m_\\nu$)\nstands out as an attractive framework due to its reduced number of free\nparameters, enabling definite predictions for the unknown parameters of the\nPMNS matrix. In this work, we present a comprehensive analysis of the two-zero\ntexture, focusing on its implications for the Dirac CP phase ($\\delta$) and the\neffective Majorana mass ($m_{\\beta\\beta}$), the latter being crucial for\nneutrinoless double beta decay. We find that for certain two-zero textures,\n$m_{\\beta\\beta}$ reaches a few tens of meV, placing it within the sensitivity\nrange of KamLAND-Zen. Furthermore, we demonstrate how a two-zero texture can\nnaturally emerge in a well-motivated neutrino mass model, specifically the\ngauged Type-II seesaw mechanism, which requires multiple scalar triplets.\nNotably, some two-zero patterns cannot be realized in this framework, as more\nthan two independent zeros can appear in $m_\\nu$. Finally, we discuss key\nphenomenological consequences of the gauged Type-II seesaw model.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-14T15:20:13Z"}
{"aid":"http://arxiv.org/abs/2504.10322v1","title":"Efficient Prompt Tuning for Hierarchical Ingredient Recognition","summary":"Fine-grained ingredient recognition presents a significant challenge due to\nthe diverse appearances of ingredients, resulting from different cutting and\ncooking methods. While existing approaches have shown promising results, they\nstill require extensive training costs and focus solely on fine-grained\ningredient recognition. In this paper, we address these limitations by\nintroducing an efficient prompt-tuning framework that adapts pretrained\nvisual-language models (VLMs), such as CLIP, to the ingredient recognition task\nwithout requiring full model finetuning. Additionally, we introduce three-level\ningredient hierarchies to enhance both training performance and evaluation\nrobustness. Specifically, we propose a hierarchical ingredient recognition\ntask, designed to evaluate model performance across different hierarchical\nlevels (e.g., chicken chunks, chicken, meat), capturing recognition\ncapabilities from coarse- to fine-grained categories. Our method leverages\nhierarchical labels, training prompt-tuned models with both fine-grained and\ncorresponding coarse-grained labels. Experimental results on the VireoFood172\ndataset demonstrate the effectiveness of prompt-tuning with hierarchical\nlabels, achieving superior performance. Moreover, the hierarchical ingredient\nrecognition task provides valuable insights into the model's ability to\ngeneralize across different levels of ingredient granularity.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T15:30:49Z"}
{"aid":"http://arxiv.org/abs/2504.10326v1","title":"AlayaDB: The Data Foundation for Efficient and Effective Long-context\n  LLM Inference","summary":"AlayaDB is a cutting-edge vector database system natively architected for\nefficient and effective long-context inference for Large Language Models (LLMs)\nat AlayaDB AI. Specifically, it decouples the KV cache and attention\ncomputation from the LLM inference systems, and encapsulates them into a novel\nvector database system. For the Model as a Service providers (MaaS), AlayaDB\nconsumes fewer hardware resources and offers higher generation quality for\nvarious workloads with different kinds of Service Level Objectives (SLOs), when\ncomparing with the existing alternative solutions (e.g., KV cache\ndisaggregation, retrieval-based sparse attention). The crux of AlayaDB is that\nit abstracts the attention computation and cache management for LLM inference\ninto a query processing procedure, and optimizes the performance via a native\nquery optimizer. In this work, we demonstrate the effectiveness of AlayaDB via\n(i) three use cases from our industry partners, and (ii) extensive experimental\nresults on LLM inference benchmarks.","main_category":"cs.AI","categories":"cs.AI,cs.DB,cs.IR","published":"2025-04-14T15:34:26Z"}
{"aid":"http://arxiv.org/abs/2504.10343v1","title":"Domain-Adversarial Neural Network and Explainable AI for Reducing\n  Tissue-of-Origin Signal in Pan-cancer Mortality Classification","summary":"Tissue-of-origin signals dominate pan-cancer gene expression, often obscuring\nmolecular features linked to patient survival. This hampers the discovery of\ngeneralizable biomarkers, as models tend to overfit tissue-specific patterns\nrather than capture survival-relevant signals. To address this, we propose a\nDomain-Adversarial Neural Network (DANN) trained on TCGA RNA-seq data to learn\nrepresentations less biased by tissue and more focused on survival. Identifying\ntissue-independent genetic profiles is key to revealing core cancer programs.\nWe assess the DANN using: (1) Standard SHAP, based on the original input space\nand DANN's mortality classifier; (2) A layer-aware strategy applied to hidden\nactivations, including an unsupervised manifold from raw activations and a\nsupervised manifold from mortality-specific SHAP values. Standard SHAP remains\nconfounded by tissue signals due to biases inherent in its computation. The raw\nactivation manifold was dominated by high-magnitude activations, which masked\nsubtle tissue and mortality-related signals. In contrast, the layer-aware SHAP\nmanifold offers improved low-dimensional representations of both tissue and\nmortality signals, independent of activation strength, enabling subpopulation\nstratification and pan-cancer identification of survival-associated genes.","main_category":"cs.LG","categories":"cs.LG,q-bio.QM","published":"2025-04-14T15:51:39Z"}
{"aid":"http://arxiv.org/abs/2504.10362v1","title":"Proteinoid spikes: from protocognitive to universal approximating agents","summary":"Proteinoids, as soft matter fluidic systems, are computational substrates\nthat have been recently proposed for their analog computing capabilities. Such\nsystems exhibit oscillatory electrical activity because of cationic and anionic\nexchange inside and outside such gels. It has also been recently shown that\nthis (analog) electrical activity, when sampled at fixed time intervals, can be\nused to reveal their underlying information-theoretic, computational code. This\ncode, for instance, can be expressed in the (digital) language of Boolean gates\nand QR codes. Though, this might seem as a good evidence that proteinoid\nsubstrates have computing abilities when subjected to analog-to-digital\ntransition, the leap from their underlying computational code to computing\nabilities is not well explained yet. How can the electrical activity inside\nproteinoids, whilst of chemical origin, be able them to perform computational\ntasks at the first place? In addition, proteinoids are also hypothesised to be\nthe chemical manifestation of the primordial soup, i.e., as potential entities\nwith proto-cognitive abilities. In this work, we show that the proteinoid\nsubstrate, owing to its chemical makeup and proto-cognitive abilities, can be\ninterpreted as an universal approximator, thanks to a novel equivalence between\nthe electrical activity exhibited by the substrate and a deep Rectified Linear\nUnit (deep ReLU) network. We exemplify this equivalence by constructing a\nprediction algorithm which acts as a binary classification model and extract\n16-dimensional vector data from the proteinoid spike, in order to perform\npredictions with 70.41\\% accuracy. We conclude by drawing an equivalence\nbetween the the deep ReLU network and the Kolmogorov-Arnold representation\ntheorem, whose origin can be traced back to Hilbert's thirteenth problem.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.chem-ph","published":"2025-04-14T16:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.10367v1","title":"On the universality of the split monopole black hole magnetosphere","summary":"Black holes can acquire magnetic flux from their magnetized progenitor or via\nprolonged accretion. We study the evolution of black hole magnetospheres by\nmeans of axisymmetric general relativistic magnetohydrodynamic simulations. We\nshow that all simulated initial magnetic field geometries of varying complexity\nultimately evolve into a split monopole magnetosphere. The magnetospheric\nevolution consists of two phases. In the first phase, the magnetosphere evolves\ntoward pressure equilibrium accompanied by a large magnetic flux decrease on\nthe event horizon on a fast Alfv\\'enic timescale of $\\sim 60$ light-crossing\ntimes of the gravitational radius. The second phase proceeds in a pressure\nbalance in which the magnetic flux decays and current sheets shift in polar\nangle over the event horizon on slower resistive timescales. We present an\nanalytic model for the second phase. Furthermore, we show that in a split\nmonopole magnetosphere the magnetic flux on the event horizon decays\nexponentially with a timescale that depends on the black hole spin, where\nhigher spin results in slower decay. Our results can have an implications for\nthe timescales of reconnection-powered flares and for multimessenger\ncounterparts to gravitational wave events.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T16:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.10377v1","title":"Groups with finitely many long commutators of maximal order","summary":"Given a group $G$ and elements $x_1,x_2,\\dots, x_\\ell\\in G$, the commutator\nof the form $[x_1,x_2,\\dots, x_\\ell]$ is called a commutator of length $\\ell$.\nThe present paper deals with groups having only finitely many commutators of\nlength $\\ell$ of maximal order. We establish the following results.\n  Let $G$ be a residually finite group with finitely many commutators of length\n$\\ell$ of maximal order. Then $G$ contains a subgroup $M$ of finite index such\nthat $\\gamma_\\ell(M)=1$. Moreover, if $G$ is finitely generated, then\n$\\gamma_\\ell(G)$ is finite.\n  Let $\\ell,m,n,r$ be positive integers and $G$ an $r$-generator group with at\nmost $m$ commutators of length $\\ell$ of maximal order $n$. Suppose that either\n$n$ is a prime power, or $n=p^{\\alpha}q^{\\beta}$, where $p$ and $q$ are odd\nprimes, or $G$ is nilpotent. Then $\\gamma_\\ell(G)$ is finite of\n$(m,\\ell,r)$-bounded order and there is a subgroup $M\\le G$ of\n$(m,\\ell,r)$-bounded index such that $\\gamma_\\ell(M)=1$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-14T16:24:40Z"}
{"aid":"http://arxiv.org/abs/2504.10393v1","title":"Quantum Liouvillian Tomography","summary":"Characterization of near-term quantum computing platforms requires the\nability to capture and quantify dissipative effects. This is an inherently\nchallenging task, as these effects are multifaceted, spanning a broad spectrum\nfrom Markovian to strongly non-Markovian dynamics. We introduce Quantum\nLiouvillian Tomography (QLT), a protocol to capture and quantify non-Markovian\neffects in time-continuous quantum dynamics. The protocol leverages\ngradient-based quantum process tomography to reconstruct dynamical maps and\nutilizes regression over the derivatives of Pauli string probability\ndistributions to extract the Liouvillian governing the dynamics. We benchmark\nthe protocol using synthetic data and quantify its accuracy in recovering\nHamiltonians, jump operators, and dissipation rates for two-qubit systems.\nFinally, we apply QLT to analyze the evolution of an idling two-qubit system\nimplemented on a superconducting quantum platform to extract characteristics of\nHamiltonian and dissipative components and, as a result, detect inherently\nnon-Markovian dynamics. Our work introduces the first protocol capable of\nretrieving generators of generic open quantum evolution from experimental data,\nthus enabling more precise characterization of many-body non-Markovian effects\nin near-term quantum computing platforms.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other","published":"2025-04-14T16:42:17Z"}
{"aid":"http://arxiv.org/abs/2504.10407v1","title":"Enhancing DESI DR1 Full-Shape analyses using HOD-informed priors","summary":"We present an analysis of DESI Data Release 1 (DR1) that incorporates Halo\nOccupation Distribution (HOD)-informed priors into Full-Shape (FS) modeling of\nthe power spectrum based on cosmological perturbation theory (PT). By\nleveraging physical insights from the galaxy-halo connection, these\nHOD-informed priors on nuisance parameters substantially mitigate projection\neffects in extended cosmological models that allow for dynamical dark energy.\nThe resulting credible intervals now encompass the posterior maximum from the\nbaseline analysis using gaussian priors, eliminating a significant posterior\nshift observed in baseline studies. In the $\\Lambda$CDM framework, a combined\nDESI DR1 FS information and constraints from the DESI DR1 baryon acoustic\noscillations (BAO)-including Big Bang Nucleosynthesis (BBN) constraints and a\nweak prior on the scalar spectral index-yields $\\Omega_{\\rm m} = 0.2994\\pm\n0.0090$ and $\\sigma_8 = 0.836^{+0.024}_{-0.027}$, representing improvements of\napproximately 4% and 23% over the baseline analysis, respectively. For the\n$w_0w_a$CDM model, our results from various data combinations are highly\nconsistent, with all configurations converging to a region with $w_0 > -1$ and\n$w_a < 0$. This convergence not only suggests intriguing hints of dynamical\ndark energy but also underscores the robustness of our HOD-informed prior\napproach in delivering reliable cosmological constraints.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-14T16:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.10436v1","title":"Capacities of highly Markovian divisible quantum channels","summary":"We analyze information transmission capacities of quantum channels acting on\n$d$-dimensional quantum systems that are highly Markovian divisible, i.e.,\nchannels of the form \\begin{equation*}\n  \\Phi = \\underbrace{\\Psi\\circ \\Psi \\circ \\ldots \\circ \\Psi}_{l\n\\,\\operatorname{times}} \\end{equation*} with $l \\geq \\gamma d^2 \\log d$ for\nsome constant $\\gamma=\\gamma(\\Psi)$ that depends on the spectral gap of the\ndividing channel $\\Psi$. We prove that capacities of such channels are\napproximately strongly additive and can be efficiently approximated in terms of\nthe structure of their peripheral spaces. Furthermore, the quantum and private\nclassical capacities of such channels approximately coincide and approximately\nsatisfy the strong converse property. We show that these approximate results\nbecome exact for the corresponding zero-error capacities when $l \\geq d^2$. To\nprove these results, we show that for any channel $\\Psi$, the classical,\nprivate classical, and quantum capacities of $\\Psi_\\infty$, which is its\nso-called asymptotic part, satisfy the strong converse property and are\nstrongly additive. In the zero-error case, we introduce the notion of the\nstabilized non-commutative confusability graph of a quantum channel and\ncharacterize its structure for any given channel.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT","published":"2025-04-14T17:27:43Z"}
{"aid":"http://arxiv.org/abs/2504.10437v1","title":"Model Order Reduction of Linear Systems via $(Î³,Î´)$-Similarity","summary":"Model order reduction aims to determine a low-order approximation of\nhigh-order models with least possible approximation errors. For application to\nphysical systems, it is crucial that the reduced order model (ROM) is robust to\nany disturbance that acts on the full order model (FOM) -- in the sense that\nthe output of the ROM remains a good approximation of that of the FOM, even in\nthe presence of such disturbances. In this work, we present a framework for\nmodel order reduction for a class of continuous-time linear systems that\nensures this property for any $L_2$ disturbance. Apart from robustness to\ndisturbances in this sense, the proposed framework also displays other\ndesirable properties for model order reduction: (1) a provable bound on the\nerror defined as the $L_2$ norm of the difference between the output of the ROM\nand FOM, (2) preservation of stability, (3) compositionality properties and a\nprovable error bound for arbitrary interconnected systems, (4) a provable bound\non the output of the FOM when the controller designed for the ROM is used with\nthe FOM, and finally, (5) compatibility with existing approaches such as\nbalanced truncation and moment matching. Property (4) does not require\ncomputation of any gap metric and property (5) is beneficial as existing\napproaches can also be equipped with some of the preceding properties. The\ntheoretical results are corroborated on numerical case studies, including on a\nbuilding model.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:28:54Z"}
{"aid":"http://arxiv.org/abs/2504.10443v1","title":"Multimodal Long Video Modeling Based on Temporal Dynamic Context","summary":"Recent advances in Large Language Models (LLMs) have led to significant\nbreakthroughs in video understanding. However, existing models still struggle\nwith long video processing due to the context length constraint of LLMs and the\nvast amount of information within the video. Although some recent methods are\ndesigned for long video understanding, they often lose crucial information\nduring token compression and struggle with additional modality like audio. In\nthis work, we propose a dynamic long video encoding method utilizing the\ntemporal relationship between frames, named Temporal Dynamic Context (TDC).\nFirstly, we segment the video into semantically consistent scenes based on\ninter-frame similarities, then encode each frame into tokens using visual-audio\nencoders. Secondly, we propose a novel temporal context compressor to reduce\nthe number of tokens within each segment. Specifically, we employ a query-based\nTransformer to aggregate video, audio, and instruction text tokens into a\nlimited set of temporal context tokens. Finally, we feed the static frame\ntokens and the temporal context tokens into the LLM for video understanding.\nFurthermore, to handle extremely long videos, we propose a training-free\nchain-of-thought strategy that progressively extracts answers from multiple\nvideo segments. These intermediate answers serve as part of the reasoning\nprocess and contribute to the final answer. We conduct extensive experiments on\ngeneral video understanding and audio-video understanding benchmarks, where our\nmethod demonstrates strong performance. The code and models are available at\nhttps://github.com/Hoar012/TDC-Video.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG,cs.MM","published":"2025-04-14T17:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.10453v1","title":"Anchors no more: Using peculiar velocities to constrain $H_0$ and the\n  primordial Universe without calibrators","summary":"We develop a novel approach to constrain the Hubble parameter $H_0$ and the\nprimordial power spectrum amplitude $A_\\mathrm{s}$ using supernovae type Ia\n(SNIa) data. By considering SNIa as tracers of the peculiar velocity field, we\ncan model their distance and their covariance as a function of cosmological\nparameters without the need of calibrators like Cepheids; this yields a new\nindependent probe of the large-scale structure based on SNIa data without\ndistance anchors. Crucially, we implement a differentiable pipeline in JAX,\nincluding efficient emulators and affine sampling, reducing inference time from\nyears to hours on a single GPU. We first validate our method on mock datasets,\ndemonstrating that we can constrain $H_0$ and $\\log 10^{10}A_\\mathrm{s}$ within\n$\\sim10\\%$ using $\\sim10^3$ SNIa. We then test our pipeline with SNIa from an\n$N$-body simulation, obtaining $7\\%$-level unbiased constraints on $H_0$ with a\nmoderate noise level. We finally apply our method to Pantheon+ data,\nconstraining $H_0$ at the $10\\%$ level without Cepheids when fixing\n$A_\\mathrm{s}$ to its $\\it{Planck}$ value. On the other hand, we obtain\n$15\\%$-level constraints on $\\log 10^{10}A_\\mathrm{s}$ in agreement with\n$\\it{Planck}$ when including Cepheids in the analysis. In light of upcoming\nobservations of low redshift SNIa from the Zwicky Transient Facility and the\nVera Rubin Legacy Survey of Space and Time, surveys for which our method will\ndevelop its full potential, we make our code publicly available.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM,cs.LG,gr-qc","published":"2025-04-14T17:40:18Z"}
{"aid":"http://arxiv.org/abs/2504.10482v1","title":"Cosmology with the angular cross-correlation of gravitational-wave and\n  galaxy catalogs: forecasts for next-generation interferometers and the Euclid\n  survey","summary":"We study the angular power spectrum of gravitational-wave and galaxy catalogs\nin tomographic redshift and distance bins as a probe of late-time cosmology,\nfocusing specifically on next-generation ground-based interferometers in\ncombination with the Euclid photometric survey. We assess the potential of this\ntechnique to constrain the Hubble constant and the matter energy density. Our\nanalysis incorporates realistic gravitational-wave source populations, error\nmodelling calibrated on recent detector designs, and accounts for nuisance\nparameters. We show that the tomographic angular cross-correlation could\ndetermine the Hubble constant to percent or sub-percent precision depending on\nthe binning choice, configuration and operation time of gravitational-wave\nobservatories. This conclusion holds even when marginalising over the unknown\ntracer biases, primordial power-spectrum parameters and baryon density. In\nparticular, we show that the combination of the galaxy auto-correlation spectra\nand the cross-correlation of gravitational waves and galaxy surveys can lead to\nan improvement of up to a factor ${{\\sim}}10$ in constraining power over either\nof the two probes taken individually. However, this prospect crucially relies\non the presence of multiple gravitational-wave interferometers able to yield\nprecise sky localisation. We also discuss the use of a spectroscopic redshift\ncatalog, as well as the detectability of the clustering bias of\ngravitational-wave sources.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-14T17:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.10839v1","title":"Rethinking Theory of Mind Benchmarks for LLMs: Towards A User-Centered\n  Perspective","summary":"The last couple of years have witnessed emerging research that appropriates\nTheory-of-Mind (ToM) tasks designed for humans to benchmark LLM's ToM\ncapabilities as an indication of LLM's social intelligence. However, this\napproach has a number of limitations. Drawing on existing psychology and AI\nliterature, we summarize the theoretical, methodological, and evaluation\nlimitations by pointing out that certain issues are inherently present in the\noriginal ToM tasks used to evaluate human's ToM, which continues to persist and\nexacerbated when appropriated to benchmark LLM's ToM. Taking a human-computer\ninteraction (HCI) perspective, these limitations prompt us to rethink the\ndefinition and criteria of ToM in ToM benchmarks in a more dynamic,\ninteractional approach that accounts for user preferences, needs, and\nexperiences with LLMs in such evaluations. We conclude by outlining potential\nopportunities and challenges towards this direction.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-15T03:44:43Z"}
{"aid":"http://arxiv.org/abs/2504.10842v1","title":"A comprehensive review of remote sensing in wetland classification and\n  mapping","summary":"Wetlands constitute critical ecosystems that support both biodiversity and\nhuman well-being; however, they have experienced a significant decline since\nthe 20th century. Back in the 1970s, researchers began to employ remote sensing\ntechnologies for wetland classification and mapping to elucidate the extent and\nvariations of wetlands. Although some review articles summarized the\ndevelopment of this field, there is a lack of a thorough and in-depth\nunderstanding of wetland classification and mapping: (1) the scientific\nimportance of wetlands, (2) major data, methods used in wetland classification\nand mapping, (3) driving factors of wetland changes, (4) current research\nparadigm and limitations, (5) challenges and opportunities in wetland\nclassification and mapping under the context of technological innovation and\nglobal environmental change. In this review, we aim to provide a comprehensive\nperspective and new insights into wetland classification and mapping for\nreaders to answer these questions. First, we conduct a meta-analysis of over\n1,200 papers, encompassing wetland types, methods, sensor types, and study\nsites, examining prevailing trends in wetland classification and mapping. Next,\nwe review and synthesize the wetland features and existing data and methods in\nwetland classification and mapping. We also summarize typical wetland mapping\nproducts and explore the intrinsic driving factors of wetland changes across\nmultiple spatial and temporal scales. Finally, we discuss current limitations\nand propose future directions in response to global environmental change and\ntechnological innovation. This review consolidates our understanding of wetland\nremote sensing and offers scientific recommendations that foster transformative\nprogress in wetland science.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-15T03:59:36Z"}
{"aid":"http://arxiv.org/abs/2504.10848v1","title":"Ichiyo: Fragile and Transient Interaction in Neighborhood","summary":"As the Internet develops, social networking and other communication tools\nhave transformed people's relationships into something fast, visible, and\ngeographically huge. However, these communication tools have not expanded\nopportunities for acquainting oneself with neighbors outside one's social\nnetwork; rather, they have comparatively diminished occasions for interacting\nwith unfamiliar neighbors by prioritizing communication with existing friends.\nTherefore, we invented the medium Ichiyo to increase the opportunities to think\nof neighbors walking along the same street or in the same neighborhood and to\nexpand the imagination of those who pass by and those who used to be there.\nThus, users can engage in indirect interaction. We used commercially available\nlaser cutters to engrave QR codes on leaves that are naturally found in our\nliving space to prevent environmental invasion. The QR codes lead to a communal\nspace on the web where users can freely leave messages. By engraving QR codes,\ninformation can be virtually expanded to be presented. To get the feedback of\nIchiyo, we let a total of several thousand people experience a new way of\ncommunication as a part of the exhibition ''iii Exhibition 2022'', an art\nexhibition at the University of Tokyo. A total of more than 1,000 leaves\nengraved with QR codes were prepared and scattered at the exhibition site and\nalong the road from the nearest station to the venue.","main_category":"cs.HC","categories":"cs.HC,cs.MM","published":"2025-04-15T04:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.10863v1","title":"Intertwined fluctuations and isotope effects in the Hubbard-Holstein\n  model on the square lattice from functional renormalization","summary":"Electron-electron and electron-phonon interactions are responsible for the\nformation of spin, charge, and superconducting correlations in layered quantum\nmaterials. A paradigmatic model for such materials that captures both kinds of\ninteractions is the two-dimensional Hubbard-Holstein model with a\ndispersionless Einstein phonon. In this work, we provide a detailed analysis of\nthe magnetic, density, and superconducting fluctuations at and away from\nhalf-filling. To that end, we employ the functional renormalization group using\nthe recently introduced extension of the single-boson exchange formulation.\nMore precisely, we go beyond previous approaches to the model by resolving the\nfull frequency dependence of the two-particle vertex and taking into account\nthe feedback from the electronic self-energy. We perform broad parameter scans\nin the space of Hubbard repulsion, electron-phonon coupling strength, and\nphonon frequency to explore the leading magnetic, density, and superconducting\nsusceptibilities from the adiabatic to the anti-adiabatic regime. Our numerical\ndata reveal that self-energy effects lead to an enhancement of the $d$-wave\nsuperconducting susceptibility towards larger phonon frequencies, in contrast\nto earlier isotope-effect studies. At small phonon frequencies, large density\ncontributions to the $s$-wave superconducting susceptibility change sign and\neventually lead to a reduction of $s$-wave superconductivity with increasing\nelectron-phonon coupling, signaling the breakdown of Migdal-Eliashberg theory.\nWe analyze our findings systematically, employing detailed diagnostics of the\nintertwined fluctuations and pinning down the various positive and negative\nisotope effects of the physical susceptibilities.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-15T04:49:50Z"}
{"aid":"http://arxiv.org/abs/2504.10876v1","title":"Non-Minimal RT Coupling and its Impact on Inflationary Evolution in f(R,\n  T) Gravity","summary":"We examine inflationary models in the $f(R, T)$ gravity framework where we\nhave a conformal constant and an $RT$-mixing term apart from an R term. The\nRT-mixing term introduces non-minimal coupling between gravity and matter. We\nconsider the exponential SUSY potential $V(\\p)=M^4 \\lt(1-e^{-\\l \\p/\\mp}\\rt)$\nand a novel potential $V(\\p)=\\l \\mp^{4-2\\a} \\p^{2\\a} \\sin^2\\lt(\\frac{\\b\n\\mp^\\a}{\\p^\\a}\\rt)$. With the help of COBE normalization, we constrain values\nof different parameters and extract the field value at the time of Hubble\ncrossing. The end of inflation is marked by $\\tep(\\p_i)=1$ where $\\p_i$ is the\nfield value at the end of inflation. Equipped with these values, we then move\non to calculate values of spectral index $n_s$ and tensor-to-scalar ratio $r$.\nOur predicted values of $n_s$ and $r$ fall within their observed values from\nthe Planck 2018 survey and BICEP/Keck array measurement for both potential,\nmaking them plausible candidates for the inflationary model. We also display\nthe variation of the tensor-to-scalar ratio and spectral index with the\ncoefficient of RT-mixing term for fixed values of e-fold number. There, we find\nthe existence of two local maxima of $n_s$, which occur at a negative and a\npositive value of $\\x$, the coefficient of $RT$-mixing term. Our analysis finds\na significant impact of $\\x$ on values of observables","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-15T05:09:10Z"}
{"aid":"http://arxiv.org/abs/2504.10881v1","title":"A Nonparametric Bayesian Local-Global Model for Enhanced Adverse Event\n  Signal Detection in Spontaneous Reporting System Data","summary":"Spontaneous reporting system databases are key resources for post-marketing\nsurveillance, providing real-world evidence (RWE) on the adverse events (AEs)\nof regulated drugs or other medical products. Various statistical methods have\nbeen proposed for AE signal detection in these databases, flagging\ndrug-specific AEs with disproportionately high observed counts compared to\nexpected counts under independence. However, signal detection remains\nchallenging for rare AEs or newer drugs, which receive small observed and\nexpected counts and thus suffer from reduced statistical power. Principled\ninformation sharing on signal strengths across drugs/AEs is crucial in such\ncases to enhance signal detection. However, existing methods typically ignore\ncomplex between-drug associations on AE signal strengths, limiting their\nability to detect signals. We propose novel local-global mixture Dirichlet\nprocess (DP) prior-based nonparametric Bayesian models to capture these\nassociations, enabling principled information sharing between drugs while\nbalancing flexibility and shrinkage for each drug, thereby enhancing\nstatistical power. We develop efficient Markov chain Monte Carlo algorithms for\nimplementation and employ a false discovery rate (FDR)-controlled, false\nnegative rate (FNR)-optimized hypothesis testing framework for AE signal\ndetection. Extensive simulations demonstrate our methods' superior sensitivity\n-- often surpassing existing approaches by a twofold or greater margin -- while\nstrictly controlling the FDR. An application to FDA FAERS data on statin drugs\nfurther highlights our methods' effectiveness in real-world AE signal\ndetection. Software implementing our methods is provided as supplementary\nmaterial.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO","published":"2025-04-15T05:22:01Z"}
{"aid":"http://arxiv.org/abs/2504.10929v1","title":"Cross-Frequency Implicit Neural Representation with Self-Evolving\n  Parameters","summary":"Implicit neural representation (INR) has emerged as a powerful paradigm for\nvisual data representation. However, classical INR methods represent data in\nthe original space mixed with different frequency components, and several\nfeature encoding parameters (e.g., the frequency parameter $\\omega$ or the rank\n$R$) need manual configurations. In this work, we propose a self-evolving\ncross-frequency INR using the Haar wavelet transform (termed CF-INR), which\ndecouples data into four frequency components and employs INRs in the wavelet\nspace. CF-INR allows the characterization of different frequency components\nseparately, thus enabling higher accuracy for data representation. To more\nprecisely characterize cross-frequency components, we propose a cross-frequency\ntensor decomposition paradigm for CF-INR with self-evolving parameters, which\nautomatically updates the rank parameter $R$ and the frequency parameter\n$\\omega$ for each frequency component through self-evolving optimization. This\nself-evolution paradigm eliminates the laborious manual tuning of these\nparameters, and learns a customized cross-frequency feature encoding\nconfiguration for each dataset. We evaluate CF-INR on a variety of visual data\nrepresentation and recovery tasks, including image regression, inpainting,\ndenoising, and cloud removal. Extensive experiments demonstrate that CF-INR\noutperforms state-of-the-art methods in each case.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T07:14:35Z"}
{"aid":"http://arxiv.org/abs/2504.10956v1","title":"The effects of asymptotically flat $R^2$ spacetime on black hole image\n  of Sagittarius A*","summary":"A new class of analytically expressible vacuum solutions has recently been\ndiscovered for pure ${R}^2$ gravity, building upon Buchdahl's seminal work from\n1962. These solutions, inspired by Buchdahl's framework, offer a promising\navenue for testing ${R}^2$ gravity against astrophysical observations. Within a\nsubset of asymptotically flat Buchdahl-inspired vacuum spacetimes, we introduce\na free parameter $\\epsilon$ to characterize deviations from the Schwarzschild\nmetric, which is recovered in the limit $\\epsilon = 0$. In this study, we\nemploy the publicly available code \\textit{ipole} to simulate black hole images\nunder the Buchdahl-inspired metric, with a focus on the black hole at the\ncenter of the Milky Way, Sagittarius A* (Sgr A*). Our simulations show that\nboth the shadow size and photon ring diameter decrease monotonically with\nincreasing $\\epsilon$. By exploring a range of observational inclination\nangles, we find that the photon ring diameter being a direct observable is only\nweakly sensitive to the inclination angle. We further constrain the parameter\n$\\epsilon$ by comparing our simulation results with the Event Horizon Telescope\n(EHT) observations of Sgr A*. The obtained bounds are consistent with those\npreviously derived from the orbital motion of the S2 star, but provide tighter\nconstraints. In addition, we analyze the influence of the Buchdahl-inspired\nspacetime on the polarization patterns near the black hole and find its impact\nto be minimal. In contrast, the observational inclination angle has a\nsubstantial effect on the observed polarization structure, highlighting the\ndominant role of viewing geometry in shaping polarization features.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-15T08:02:35Z"}
{"aid":"http://arxiv.org/abs/2504.10960v1","title":"A Linear Push-Pull Average Consensus Algorithm for Delay-Prone Networks","summary":"In this paper, we address the average consensus problem of multi-agent\nsystems for possibly unbalanced and delay-prone networks with directional\ninformation flow. We propose a linear distributed algorithm (referred to as\nRPPAC) that handles asynchronous updates and time-varying heterogeneous\ninformation delays. Our proposed distributed algorithm utilizes a\nsurplus-consensus mechanism and information regarding the number of incoming\nand outgoing links to guarantee state averaging, despite the imbalanced and\ndelayed information flow in directional networks. The convergence of the RPPAC\nalgorithm is examined using key properties of the backward product of\ntime-varying matrices that correspond to different snapshots of the directional\naugmented network.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T08:05:36Z"}
{"aid":"http://arxiv.org/abs/2504.10962v1","title":"$Ï$-MPPI: A Projection-based Model Predictive Path Integral Scheme for\n  Smooth Optimal Control of Fixed-Wing Aerial Vehicles","summary":"Model Predictive Path Integral (MPPI) is a popular sampling-based Model\nPredictive Control (MPC) algorithm for nonlinear systems. It optimizes\ntrajectories by sampling control sequences and averaging them. However, a key\nissue with MPPI is the non-smoothness of the optimal control sequence, leading\nto oscillations in systems like fixed-wing aerial vehicles (FWVs). Existing\nsolutions use post-hoc smoothing, which fails to bound control derivatives.\nThis paper introduces a new approach: we add a projection filter $\\pi$ to\nminimally correct control samples, ensuring bounds on control magnitude and\nhigher-order derivatives. The filtered samples are then averaged using MPPI,\nleading to our $\\pi$-MPPI approach. We minimize computational overhead by using\na neural accelerated custom optimizer for the projection filter. $\\pi$-MPPI\noffers a simple way to achieve arbitrary smoothness in control sequences. While\nwe focus on FWVs, this projection filter can be integrated into any MPPI\npipeline. Applied to FWVs, $\\pi$-MPPI is easier to tune than the baseline,\nresulting in smoother, more robust performance.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-15T08:11:02Z"}
{"aid":"http://arxiv.org/abs/2504.10977v1","title":"Phonon-polaritons in Zn(1-x)MgxTe (x<0.09): A Raman scattering study","summary":"Phonon-polaritons (PP) are phonon-photon coupled modes. Using near-forward\nRaman scattering, the PP of the cubic Zn(1-x)MgxTe (x<0.09) semiconductor alloy\ncould be measured. While the PP-coupling hardly develops in pure ZnTe, minor\nMg-alloying suffices to stabilize a long-lifetime PP strongly bound to the\nlattice, i.e., with a pronounced phonon character, and yet a fast one\noriginating from the highly dispersive photon-like bottleneck of the\nPP-dispersion. By combining the advantages of a phonon and of a photon, the\nlong-lifetime PP generated by minor Mg-alloying of ZnTe marks an improvement\nover the PP of pristine ZnTe, that, from the Raman cross section calculation,\ncan only achieve a balanced compromise between the two kinds of advantages,\nintensity and speed. The discussion of the PP-related lattice dynamics of\nZn(1-x)MgxTe (x<0.09) is grounded in a preliminary study of the lattice macro-\nand microstructure using X-ray diffraction and solid-state nuclear magnetic\nresonance, respectively, and further relies on ab initio calculations of the\nnative phonon modes behind the PP in the Mg-dilute limit of Zn(1-x)MgxTe (x~0),\nconsidering various Mg-isotopes.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,J.2","published":"2025-04-15T08:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.10984v1","title":"Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera","summary":"Cephalopods exhibit unique colour discrimination capabilities despite having\none type of photoreceptor, relying instead on chromatic aberration induced by\ntheir ocular optics and pupil shapes to perceive spectral information. We took\ninspiration from this biological mechanism to design a spectral imaging system\nthat combines a ball lens with an event-based camera. Our approach relies on a\nmotorised system that shifts the focal position, mirroring the adaptive lens\nmotion in cephalopods. This approach has enabled us to achieve\nwavelength-dependent focusing across the visible light and near-infrared\nspectrum, making the event a spectral sensor. We characterise chromatic\naberration effects, using both event-based and conventional frame-based\nsensors, validating the effectiveness of bio-inspired spectral discrimination\nboth in simulation and in a real setup as well as assessing the spectral\ndiscrimination performance. Our proposed approach provides a robust spectral\nsensing capability without conventional colour filters or computational\ndemosaicing. This approach opens new pathways toward new spectral sensing\nsystems inspired by nature's evolutionary solutions. Code and analysis are\navailable at: https://samiarja.github.io/neuromorphic_octopus_eye/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.11002v1","title":"Dopamine Audiobook: A Training-free MLLM Agent for Emotional and\n  Human-like Audiobook Generation","summary":"Audiobook generation, which creates vivid and emotion-rich audio works, faces\nchallenges in conveying complex emotions, achieving human-like qualities, and\naligning evaluations with human preferences. Existing text-to-speech (TTS)\nmethods are often limited to specific scenarios, struggle with emotional\ntransitions, and lack automatic human-aligned evaluation benchmarks, instead\nrelying on either misaligned automated metrics or costly human assessments. To\naddress these issues, we propose Dopamine Audiobook, a new unified\ntraining-free system leveraging a multimodal large language model (MLLM) as an\nAI agent for emotional and human-like audiobook generation and evaluation.\nSpecifically, we first design a flow-based emotion-enhanced framework that\ndecomposes complex emotional speech synthesis into controllable sub-tasks.\nThen, we propose an adaptive model selection module that dynamically selects\nthe most suitable TTS methods from a set of existing state-of-the-art (SOTA)\nTTS methods for diverse scenarios. We further enhance emotional expressiveness\nthrough paralinguistic augmentation and prosody retrieval at word and utterance\nlevels. For evaluation, we propose a novel GPT-based evaluation framework\nincorporating self-critique, perspective-taking, and psychological MagicEmo\nprompts to ensure human-aligned and self-aligned assessments. Experiments show\nthat our method generates long speech with superior emotional expression to\nSOTA TTS models in various metrics. Importantly, our evaluation framework\ndemonstrates better alignment with human preferences and transferability across\naudio tasks. Project website with audio samples can be found at\nhttps://dopamine-audiobook.github.io.","main_category":"cs.SD","categories":"cs.SD,cs.MM,eess.AS","published":"2025-04-15T09:19:44Z"}
{"aid":"http://arxiv.org/abs/2504.11019v1","title":"DRIFT open dataset: A drone-derived intelligence for traffic analysis in\n  urban environmen","summary":"Reliable traffic data are essential for understanding urban mobility and\ndeveloping effective traffic management strategies. This study introduces the\nDRone-derived Intelligence For Traffic analysis (DRIFT) dataset, a large-scale\nurban traffic dataset collected systematically from synchronized drone videos\nat approximately 250 meters altitude, covering nine interconnected\nintersections in Daejeon, South Korea. DRIFT provides high-resolution vehicle\ntrajectories that include directional information, processed through video\nsynchronization and orthomap alignment, resulting in a comprehensive dataset of\n81,699 vehicle trajectories. Through our DRIFT dataset, researchers can\nsimultaneously analyze traffic at multiple scales - from individual vehicle\nmaneuvers like lane-changes and safety metrics such as time-to-collision to\naggregate network flow dynamics across interconnected urban intersections. The\nDRIFT dataset is structured to enable immediate use without additional\npreprocessing, complemented by open-source models for object detection and\ntrajectory extraction, as well as associated analytical tools. DRIFT is\nexpected to significantly contribute to academic research and practical\napplications, such as traffic flow analysis and simulation studies. The dataset\nand related resources are publicly accessible at\nhttps://github.com/AIxMobility/The-DRIFT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:43:13Z"}
{"aid":"http://arxiv.org/abs/2504.11020v1","title":"\"Even explanations will not help in trusting [this] fundamentally biased\n  system\": A Predictive Policing Case-Study","summary":"In today's society, where Artificial Intelligence (AI) has gained a vital\nrole, concerns regarding user's trust have garnered significant attention. The\nuse of AI systems in high-risk domains have often led users to either\nunder-trust it, potentially causing inadequate reliance or over-trust it,\nresulting in over-compliance. Therefore, users must maintain an appropriate\nlevel of trust. Past research has indicated that explanations provided by AI\nsystems can enhance user understanding of when to trust or not trust the\nsystem. However, the utility of presentation of different explanations forms\nstill remains to be explored especially in high-risk domains. Therefore, this\nstudy explores the impact of different explanation types (text, visual, and\nhybrid) and user expertise (retired police officers and lay users) on\nestablishing appropriate trust in AI-based predictive policing. While we\nobserved that the hybrid form of explanations increased the subjective trust in\nAI for expert users, it did not led to better decision-making. Furthermore, no\nform of explanations helped build appropriate trust. The findings of our study\nemphasize the importance of re-evaluating the use of explanations to build\n[appropriate] trust in AI based systems especially when the system's use is\nquestionable. Finally, we synthesize potential challenges and policy\nrecommendations based on our results to design for appropriate trust in\nhigh-risk based AI-based systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-15T09:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.11042v1","title":"LazyReview A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews","summary":"Peer review is a cornerstone of quality control in scientific publishing.\nWith the increasing workload, the unintended use of `quick' heuristics,\nreferred to as lazy thinking, has emerged as a recurring issue compromising\nreview quality. Automated methods to detect such heuristics can help improve\nthe peer-reviewing process. However, there is limited NLP research on this\nissue, and no real-world dataset exists to support the development of detection\ntools. This work introduces LazyReview, a dataset of peer-review sentences\nannotated with fine-grained lazy thinking categories. Our analysis reveals that\nLarge Language Models (LLMs) struggle to detect these instances in a zero-shot\nsetting. However, instruction-based fine-tuning on our dataset significantly\nboosts performance by 10-20 performance points, highlighting the importance of\nhigh-quality training data. Furthermore, a controlled experiment demonstrates\nthat reviews revised with lazy thinking feedback are more comprehensive and\nactionable than those written without such feedback. We will release our\ndataset and the enhanced guidelines that can be used to train junior reviewers\nin the community. (Code available here:\nhttps://github.com/UKPLab/arxiv2025-lazy-review)","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T10:07:33Z"}
{"aid":"http://arxiv.org/abs/2504.11053v1","title":"QualiTagger: Automating software quality detection in issue trackers","summary":"A systems quality is a major concern for development teams when it evolve.\nUnderstanding the effects of a loss of quality in the codebase is crucial to\navoid side effects like the appearance of technical debt. Although the\nidentification of these qualities in software requirements described in natural\nlanguage has been investigated, most of the results are often not applicable in\npractice, and rely on having been validated on small datasets and limited\namount of projects. For many years, machine learning (ML) techniques have been\nproved as a valid technique to identify and tag terms described in natural\nlanguage. In order to advance previous works, in this research we use cutting\nedge models like Transformers, together with a vast dataset mined and curated\nfrom GitHub, to identify what text is usually associated with different quality\nproperties. We also study the distribution of such qualities in issue trackers\nfrom openly accessible software repositories, and we evaluate our approach both\nwith students from a software engineering course and with its application to\nrecognize security labels in industry.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-15T10:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.11068v1","title":"Uma extensÃ£o de Raft com propagaÃ§Ã£o epidÃ©mica","summary":"The Raft agreement algorithm is recognized for its ease of understanding and\npractical implementation, and is currently adopted in systems such as\nKubernetes. However, it has some limitations in terms of scalability and\nperformance as it concentrates effort on the leader. In this paper we present a\nnew algorithm that expands Raft by incorporating epidemic propagation\nmechanisms to decentralize the replication effort. Our proposal is evaluated\nexperimentally with a Go implementation and tested with a significant number of\nprocesses. -- --\n  O algoritmo de acordo Raft \\'e reconhecido pela sua facilidade de\ncompreens\\~ao e implementa\\c{c}\\~ao pr\\'atica, sendo atualmente adotado em\nsistemas como o Kubernetes. No entanto, tem algumas limita\\c{c}\\~oes em termos\nde escalabilidade e desempenho por concentrar o esfor\\c{c}o no l\\'ider. Neste\ntrabalho apresentamos um novo algoritmo que expande o Raft com a\nincorpora\\c{c}\\~ao de mecanismos de propaga\\c{c}\\~ao epid\\'emica para\ndescentralizar o esfor\\c{c}o da replica\\c{c}\\~ao. A nossa proposta \\'e avaliada\nexperimentalmente com uma implementa\\c{c}\\~ao em Go e testada com um n\\'umero\nsignificativo de processos.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-15T11:05:25Z"}
{"aid":"http://arxiv.org/abs/2504.11079v1","title":"Scalability and Maintainability Challenges and Solutions in Machine\n  Learning: Systematic Literature Review","summary":"This systematic literature review examines the critical challenges and\nsolutions related to scalability and maintainability in Machine Learning (ML)\nsystems. As ML applications become increasingly complex and widespread across\nindustries, the need to balance system scalability with long-term\nmaintainability has emerged as a significant concern. This review synthesizes\ncurrent research and practices addressing these dual challenges across the\nentire ML life-cycle, from data engineering to model deployment in production.\nWe analyzed 124 papers to identify and categorize 41 maintainability challenges\nand 13 scalability challenges, along with their corresponding solutions. Our\nfindings reveal intricate inter dependencies between scalability and\nmaintainability, where improvements in one often impact the other.\n  The review is structured around six primary research questions, examining\nmaintainability and scalability challenges in data engineering, model\nengineering, and ML system development. We explore how these challenges\nmanifest differently across various stages of the ML life-cycle.\n  This comprehensive overview offers valuable insights for both researchers and\npractitioners in the field of ML systems. It aims to guide future research\ndirections, inform best practices, and contribute to the development of more\nrobust, efficient, and sustainable ML applications across various domains.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-15T11:24:43Z"}
{"aid":"http://arxiv.org/abs/2504.11080v1","title":"Change State Space Models for Remote Sensing Change Detection","summary":"Despite their frequent use for change detection, both ConvNets and Vision\ntransformers (ViT) exhibit well-known limitations, namely the former struggle\nto model long-range dependencies while the latter are computationally\ninefficient, rendering them challenging to train on large-scale datasets.\nVision Mamba, an architecture based on State Space Models has emerged as an\nalternative addressing the aforementioned deficiencies and has been already\napplied to remote sensing change detection, though mostly as a feature\nextracting backbone. In this article the Change State Space Model is\nintroduced, that has been specifically designed for change detection by\nfocusing on the relevant changes between bi-temporal images, effectively\nfiltering out irrelevant information. By concentrating solely on the changed\nfeatures, the number of network parameters is reduced, enhancing significantly\ncomputational efficiency while maintaining high detection performance and\nrobustness against input degradation. The proposed model has been evaluated via\nthree benchmark datasets, where it outperformed ConvNets, ViTs, and Mamba-based\ncounterparts at a fraction of their computational complexity. The\nimplementation will be made available at https://github.com/Elman295/CSSM upon\nacceptance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:25:10Z"}
{"aid":"http://arxiv.org/abs/2504.11082v1","title":"DeepMLF: Multimodal language model with learnable tokens for deep fusion\n  in sentiment analysis","summary":"While multimodal fusion has been extensively studied in Multimodal Sentiment\nAnalysis (MSA), the role of fusion depth and multimodal capacity allocation\nremains underexplored. In this work, we position fusion depth, scalability, and\ndedicated multimodal capacity as primary factors for effective fusion. We\nintroduce DeepMLF, a novel multimodal language model (LM) with learnable tokens\ntailored toward deep fusion. DeepMLF leverages an audiovisual encoder and a\npretrained decoder LM augmented with multimodal information across its layers.\nWe append learnable tokens to the LM that: 1) capture modality interactions in\na controlled fashion and 2) preserve independent information flow for each\nmodality. These fusion tokens gather linguistic information via causal\nself-attention in LM Blocks and integrate with audiovisual information through\ncross-attention MM Blocks. Serving as dedicated multimodal capacity, this\ndesign enables progressive fusion across multiple layers, providing depth in\nthe fusion process. Our training recipe combines modality-specific losses and\nlanguage modelling loss, with the decoder LM tasked to predict ground truth\npolarity. Across three MSA benchmarks with varying dataset characteristics,\nDeepMLF achieves state-of-the-art performance. Our results confirm that deeper\nfusion leads to better performance, with optimal fusion depths (5-7) exceeding\nthose of existing approaches. Additionally, our analysis on the number of\nfusion tokens reveals that small token sets ($\\sim$20) achieve optimal\nperformance. We examine the importance of representation learning order (fusion\ncurriculum) through audiovisual encoder initialization experiments. Our\nablation studies demonstrate the superiority of the proposed fusion design and\ngating while providing a holistic examination of DeepMLF's scalability to LLMs,\nand the impact of each training objective and embedding regularization.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T11:28:02Z"}
{"aid":"http://arxiv.org/abs/2504.11089v1","title":"InfoClus: Informative Clustering of High-dimensional Data Embeddings","summary":"Developing an understanding of high-dimensional data can be facilitated by\nvisualizing that data using dimensionality reduction. However, the\nlow-dimensional embeddings are often difficult to interpret. To facilitate the\nexploration and interpretation of low-dimensional embeddings, we introduce a\nnew concept named partitioning with explanations. The idea is to partition the\ndata shown through the embedding into groups, each of which is given a sparse\nexplanation using the original high-dimensional attributes. We introduce an\nobjective function that quantifies how much we can learn through observing the\nexplanations of the data partitioning, using information theory, and also how\ncomplex the explanations are. Through parameterization of the complexity, we\ncan tune the solutions towards the desired granularity. We propose InfoClus,\nwhich optimizes the partitioning and explanations jointly, through greedy\nsearch constrained over a hierarchical clustering. We conduct a qualitative and\nquantitative analysis of InfoClus on three data sets. We contrast the results\non the Cytometry data with published manual analysis results, and compare with\ntwo other recent methods for explaining embeddings (RVX and VERA). These\ncomparisons highlight that InfoClus has distinct advantages over existing\nprocedures and methods. We find that InfoClus can automatically create good\nstarting points for the analysis of dimensionality-reduction-based scatter\nplots.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T11:34:03Z"}
{"aid":"http://arxiv.org/abs/2504.11137v1","title":"Asymmetric Resonant Ferroelectric Tunnel Junctions for Simultaneous High\n  Tunnel Electroresistance and Low Resistance-Area Product","summary":"Ferroelectric tunnel junctions offer potential for non-volatile memory with\nlow power, fast switching, and scalability, but their performance is limited by\na high resistance-area product and a low tunnel electroresistance ratio. To\naddress these challenges, we propose a doped HfO2-based, silicon-compatible\nasymmetric resonant ferroelectric tunnel junction design with a quantum well\nembedded between two ferroelectric layers, replacing the conventional\nmetal-ferroelectric-metal structure. Using a self-consistent coupling of the\nnon-equilibrium Green's function method with a Preisach-based model, we\ndemonstrate that the quantum well enhances resonant tunneling effects, leading\nto a simultaneous reduction in the resistance-area product and a boost in the\ntunnel electroresistance ratio. The low-resistance state becomes more robust,\nwhile the high-resistance state is suppressed, improving readout speed and\nreducing power usage. We observed that incorporating a 2 nm quantum well\nsignificantly enhances the tunnel electroresistance ratio, achieving a peak\nvalue of approximately 6.15 x 10^4 percent, while simultaneously minimizing the\nresistance-area product to 47.1 Ohm-cm^2 at 0.175 V. Additionally, the device\nexhibits negative differential resistance, further enhancing its functionality.\nOur results confirm that this design enables scalable, energy-efficient, and\nhigh-performance non-volatile memory, making it a strong candidate for future\nmemory technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T12:39:54Z"}
{"aid":"http://arxiv.org/abs/2504.11140v1","title":"An Unsupervised Network Architecture Search Method for Solving Partial\n  Differential Equations","summary":"Solving partial differential equations (PDEs) has been indispensable in\nscientific and engineering applications. Recently, deep learning methods have\nbeen widely used to solve high-dimensional problems, one of which is the\nphysics-informed neural network (PINN). Typically, a deep learning method has\nthree main components: a neural network, a loss function, and an optimizer.\nWhile the construction of the loss function is rooted in the definition of\nsolution space, how to choose a optimal neural network is somewhat ad hoc,\nleaving much room for improvement. In the framework of PINN, we propose an\nunsupervised network architecture search method for solving PDEs, termed\nPINN-DARTS, which applies the differentiable architecture search (DARTS) to\nfind the optimal network architecture structure in a given set of neural\nnetworks. In this set, the number of layers and the number of neurons in each\nlayer can change. In the searching phase, both network and architecture\nparameters are updated simultaneously, so the running time is close to that of\nPINN with a pre-determined network structure. Unlike available works, our\napproach is unsupervised and purely based on the PDE residual without any prior\nusage of solutions. PINN-DARTS outputs the optimal network structure as well as\nthe associated numerical solution. The performance of PINN-DARTS is verified on\nseveral benchmark PDEs, including elliptic, parabolic, wave, and Burgers'\nequations. Compared to traditional architecture search methods, PINN-DARTS\nachieves significantly higher architectural accuracy. Another interesting\nobservation is that both the solution complexity and the PDE type have a\nprominent impact on the optimal network architecture. Our study suggests that\narchitectures with uneven widths from layer to layer may have superior\nperformance across different solution complexities and different PDE types.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T12:42:32Z"}
{"aid":"http://arxiv.org/abs/2504.11155v1","title":"There are no exotic compact moduli of sheaves on a curve","summary":"We study moduli of coherent sheaves of some given degree and positive rank on\na curve. We show that there is only one nonempty open condition on families of\nsheaves that yields a universally closed adequate moduli space, namely, the one\nthat recovers the classical moduli of slope semistable vector bundles.","main_category":"math.AG","categories":"math.AG","published":"2025-04-15T12:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.11160v1","title":"DMAGaze: Gaze Estimation Based on Feature Disentanglement and\n  Multi-Scale Attention","summary":"Gaze estimation, which predicts gaze direction, commonly faces the challenge\nof interference from complex gaze-irrelevant information in face images. In\nthis work, we propose DMAGaze, a novel gaze estimation framework that exploits\ninformation from facial images in three aspects: gaze-relevant global features\n(disentangled from facial image), local eye features (extracted from cropped\neye patch), and head pose estimation features, to improve overall performance.\nFirstly, we design a new continuous mask-based Disentangler to accurately\ndisentangle gaze-relevant and gaze-irrelevant information in facial images by\nachieving the dual-branch disentanglement goal through separately\nreconstructing the eye and non-eye regions. Furthermore, we introduce a new\ncascaded attention module named Multi-Scale Global Local Attention Module\n(MS-GLAM). Through a customized cascaded attention structure, it effectively\nfocuses on global and local information at multiple scales, further enhancing\nthe information from the Disentangler. Finally, the global gaze-relevant\nfeatures disentangled by the upper face branch, combined with head pose and\nlocal eye features, are passed through the detection head for high-precision\ngaze estimation. Our proposed DMAGaze has been extensively validated on two\nmainstream public datasets, achieving state-of-the-art performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T13:08:43Z"}
{"aid":"http://arxiv.org/abs/2504.11176v1","title":"Wonderful Blow-Ups of Weighted Building Sets and Configuration Spaces of\n  Filtered Manifolds","summary":"Fulton and MacPherson famously constructed a configuration space that encodes\ninfinitesimal collision data by blowing up the diagonals. We observe that when\ngeneralizing their approach to configuration spaces of filtered manifolds (e.g.\njet spaces or sub-Riemannian manifolds), these blow-ups have to be modified\nwith weights in order for the collisions to be compatible with higher-order\ndata.\n  In the present article, we provide a general framework for blowing up\narrangements of submanifolds that are equipped with a weighting in the sense of\nLoizides and Meinrenken. We prove in particular smoothness of the blow-up under\nreasonable assumptions, extending a result of Li to the weighted setting. Our\ndiscussion covers both spherical and projective blow-ups, as well as the\n(restricted) functoriality of the construction.\n  Alongside a self-contained introduction to weightings, we also give a new\ncharacterization thereof in terms of their vanishing ideals and prove that\ncleanly intersecting weightings locally yield a weighting.\n  As our main application, we construct configuration spaces of filtered\nmanifolds, including convenient local models. We also discuss a variation of\nthe construction tailored to certain fiber bundles equipped with a filtration.\nThis is necessary for the special case of jet configuration spaces, which we\ninvestigate in a future article.","main_category":"math.DG","categories":"math.DG,math.GT","published":"2025-04-15T13:31:47Z"}
{"aid":"http://arxiv.org/abs/2504.11179v1","title":"Semistable reduction of plane quartics at $p=3$","summary":"We explain how to compute the semistable reduction of plane quartic curves\nover local fields of residue characteristic $p=3$. Our approach is based on\nfinding suitable degree-$3$ coverings of the projective line by such plane\nquartics and on the different function of Cohen, Temkin, and Trushin associated\nto the analytifications of these coverings. In particular, we give an explicit\nformula for computing the different function on a given interval. The resulting\nalgorithm for computing the semistable reduction of plane quartics is\nimplemented in SageMath, and we illustrate it by determining the semistable\nreduction of a particular plane quartic at $p=3$ that arises as a quotient of\nthe non-split Cartan modular curve $X^+_{ns}(27)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-15T13:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.11221v1","title":"Global asymptotic behavior of solutions to the generalized derivative\n  nonlinear SchrÃ¶dinger equation","summary":"This article is concerned with the global asymptotic behavior for the\ngeneralized derivative nonlinear Schr\\\"odinger (gDNLS) equation. When the\nnonlinear effect is not strong, we show pointwise-in-time dispersive decay for\nsolutions to the gDNLS equation with small initial data in\n$H^{\\frac{1}{2}+}(\\mathbb{R})$ utilizing crucially Lorentz-space improvements\nof the traditional Strichartz inequality. When the nonlinear effect is\nespecially dominant, there exists a sequence of solitary waves that are\narbitrary small in the energy space, which means the small data scattering is\nnot true. However, there is evidence that it is not possible for the solitons\nto be localized in $L^{2}(\\mathbb{R})$ and small in $H^{1}(\\mathbb{R})$. With\nsmall and localized data assumption, we obtain global asymptotic behavior for\nsolutions to the gDNLS equation by using vector field methods combined with the\ntesting by wave packets method.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T14:23:12Z"}
{"aid":"http://arxiv.org/abs/2504.11248v1","title":"Probing Lorentz Invariance Violation in Z Boson Mass Measurements at\n  High-Energy Colliders","summary":"We propose a minimal extension to the Standard Model by introducing a Lorentz\nInvariance Violation (LIV) term into the Z boson's dispersion relation,\nexpressed as $p_\\mu p^\\mu = M_Z^2 + \\delta_{LIV} (p_\\mu n^\\mu)^2$, where\n$\\delta_{LIV}$ defines the violation scale and $n^\\mu$ is a unit Lorentz vector\nspecifying the direction. This modification alters the Z boson propagator and\ndecay rate, impacting the Drell-Yan process cross-section at high-energy\ncolliders. Observable effects are most pronounced near the resonance region at\nhigh rapidities ($|Y| > 4$), potentially shifting the perceived Z boson mass\nand inducing sidereal-time modulations for spacelike and lightlike LIV due to\nEarth's rotation. We outline a targeted search strategy for ATLAS and CMS,\nachieving sensitivity to LIV signatures down to $|\\delta_{LIV}| \\approx\n10^{-8}$ (or $10^{-9}$ optimistically), offering new insights into historical\nand future collider data. Our model predicts systematic shifts in weak boson\nmasses at higher collision energies, relevant to past Tevatron and LHC\ndiscrepancies, though current data are now consistent.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-th","published":"2025-04-15T14:46:22Z"}
{"aid":"http://arxiv.org/abs/2504.11261v1","title":"Robust MPC for Uncertain Linear Systems -- Combining Model Adaptation\n  and Iterative Learning","summary":"This paper presents a robust adaptive learning Model Predictive Control (MPC)\nframework for linear systems with parametric uncertainties and additive\ndisturbances performing iterative tasks. The approach iteratively refines the\nparameter estimates using set membership estimation. Performance enhancement\nover iterations is achieved by learning the terminal cost from data. Safety is\nenforced using a terminal set, which is also learned iteratively. The proposed\nmethod guarantees recursive feasibility, constraint satisfaction, and a robust\nbound on the closed-loop cost. Numerical simulations on a mass-spring-damper\nsystem demonstrate improved computational efficiency and control performance\ncompared to an existing robust adaptive MPC approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T15:00:34Z"}
{"aid":"http://arxiv.org/abs/2504.11264v1","title":"DeepSelective: Feature Gating and Representation Matching for\n  Interpretable Clinical Prediction","summary":"The rapid accumulation of Electronic Health Records (EHRs) has transformed\nhealthcare by providing valuable data that enhance clinical predictions and\ndiagnoses. While conventional machine learning models have proven effective,\nthey often lack robust representation learning and depend heavily on\nexpert-crafted features. Although deep learning offers powerful solutions, it\nis often criticized for its lack of interpretability. To address these\nchallenges, we propose DeepSelective, a novel end to end deep learning\nframework for predicting patient prognosis using EHR data, with a strong\nemphasis on enhancing model interpretability. DeepSelective combines data\ncompression techniques with an innovative feature selection approach,\nintegrating custom-designed modules that work together to improve both accuracy\nand interpretability. Our experiments demonstrate that DeepSelective not only\nenhances predictive accuracy but also significantly improves interpretability,\nmaking it a valuable tool for clinical decision-making. The source code is\nfreely available at http://www.healthinformaticslab.org/supp/resources.php .","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T15:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.11337v1","title":"REWARD CONSISTENCY: Improving Multi-Objective Alignment from a\n  Data-Centric Perspective","summary":"Multi-objective preference alignment in language models often encounters a\nchallenging trade-off: optimizing for one human preference (e.g., helpfulness)\nfrequently compromises others (e.g., harmlessness) due to the inherent\nconflicts between competing objectives. While prior work mainly focuses on\nalgorithmic solutions, we explore a novel data-driven approach to uncover the\ntypes of data that can effectively mitigate these conflicts. Specifically, we\npropose the concept of Reward Consistency (RC), which identifies samples that\nalign with multiple preference objectives, thereby reducing conflicts during\ntraining. Through gradient-based analysis, we demonstrate that RC-compliant\nsamples inherently constrain performance degradation during multi-objective\noptimization. Building on these insights, we further develop Reward Consistency\nSampling, a framework that automatically constructs preference datasets that\neffectively mitigate conflicts during multi-objective alignment. Our generated\ndata achieves an average improvement of 13.37% in both the harmless rate and\nhelpfulness win rate when optimizing harmlessness and helpfulness, and can\nconsistently resolve conflicts in varying multi-objective scenarios.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T16:09:19Z"}
{"aid":"http://arxiv.org/abs/2504.11345v1","title":"Erzeugunsgrad, VC-Dimension and Neural Networks with rational activation\n  function","summary":"The notion of Erzeugungsgrad was introduced by Joos Heintz in 1983 to bound\nthe number of non-empty cells occurring after a process of quantifier\nelimination. We extend this notion and the combinatorial bounds of Theorem 2 in\nHeintz (1983) using the degree for constructible sets defined in\nPardo-Sebasti\\'an (2022). We show that the Erzeugungsgrad is the key ingredient\nto connect affine Intersection Theory over algebraically closed fields and the\nVC-Theory of Computational Learning Theory for families of classifiers given by\nparameterized families of constructible sets. In particular, we prove that the\nVC-dimension and the Krull dimension are linearly related up to logarithmic\nfactors based on Intersection Theory. Using this relation, we study the density\nof correct test sequences in evasive varieties. We apply these ideas to analyze\nparameterized families of neural networks with rational activation function.","main_category":"cs.LG","categories":"cs.LG,math.AG","published":"2025-04-15T16:16:38Z"}
{"aid":"http://arxiv.org/abs/2504.11359v1","title":"Deciphering the Structure of Push-Pull Conjugated Polymer Aggregates in\n  Solution and Film","summary":"The morphology of conjugated polymer films is highly tunable, influencing\ntheir performance in organic electronics. Specifically, molecular packing or\ncrystal structure strongly influence electronic processes such as light\nabsorption and charge transfer. However, the unit cells of high-performance\nelectron donor polymers remain unknown, limiting the understanding of how\nprocessing affects structure and device performance. This study characterizes\nthe aggregate structure of PM6-type push-pull polymers using X-ray scattering,\ncryogenic electron microscopy, and molecular dynamics (MD) simulations. A novel\nforward simulation approach linking grazing-incidence wide-angle X-ray\nscattering (GIWAXS) with MD resolves a monoclinic unit cell that accurately\ndescribes PM6-type polymer aggregates in both thin films and casting solutions.\nIntimate pi-pi stacking between donor and acceptor units emerges from this unit\ncell. Analysis of experimental GIWAXS using this unit cell quantifies sliding\ndisorder in these aggregates, which may impact device performance. The shape\nand internal structure of solution aggregates are also identified in\nchlorobenzene. These findings enhance our understanding of PM6-type polymer\npacking, outline a strategy for elucidating the crystal structure of weakly\nordered materials, and provide an opportunity to control optoelectronic\nperformance through aggregate formation in PM6 and other push-pull conjugated\npolymers.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.soft","published":"2025-04-15T16:26:28Z"}
{"aid":"http://arxiv.org/abs/2504.11361v1","title":"Dynamical Casimir effect in superconducting cavities: from photon\n  generation to universal quantum gates","summary":"This chapter explores various aspects of the Dynamical Casimir Effect (DCE)\nand its implications in the context of circuit quantum electrodynamics (cQED).\nWe begin by reviewing the origin and fundamental properties of the DCE,\nincluding three equivalent mathematical frameworks that offer complementary\nperspectives on the phenomenon. These formulations will serve as a foundation\nfor the subsequent analyses. We then turn our attention to the practical\nrealization of the DCE in cQED-based architectures, discussing how modern\nsuperconducting circuits can be engineered to exhibit this inherently quantum\neffect. Building on this, we examine how the presence of the DCE influences the\nperformance of a quantum thermal machine operating with a quantum field,\nshedding light on the interplay between quantum fluctuations and thermodynamic\nprocesses. Further, we demonstrate how the DCE can be harnessed to implement a\ncontrolled-squeeze gate within a cQED platform, opening a path toward advanced\nquantum control and quantum information processing. The chapter concludes with\na synthesis of the main results and a discussion of potential future\ndirections.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other","published":"2025-04-15T16:28:00Z"}
{"aid":"http://arxiv.org/abs/2504.11364v1","title":"Teaching Large Language Models to Reason through Learning and Forgetting","summary":"Leveraging inference-time search in large language models has proven\neffective in further enhancing a trained model's capability to solve complex\nmathematical and reasoning problems. However, this approach significantly\nincreases computational costs and inference time, as the model must generate\nand evaluate multiple candidate solutions to identify a viable reasoning path.\nTo address this, we propose an effective approach that integrates search\ncapabilities directly into the model by fine-tuning it using both successful\n(learning) and failed reasoning paths (forgetting) derived from diverse search\nmethods. While fine-tuning the model with these data might seem\nstraightforward, we identify a critical issue: the model's search capability\ntends to degrade rapidly if fine-tuning is performed naively. We show that this\ndegradation can be substantially mitigated by employing a smaller learning\nrate. Extensive experiments on the challenging Game-of-24 and Countdown\nmathematical reasoning benchmarks show that our approach not only outperforms\nboth standard fine-tuning and inference-time search baselines but also\nsignificantly reduces inference time by 180$\\times$.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-15T16:30:02Z"}
{"aid":"http://arxiv.org/abs/2504.11366v1","title":"A Decade of Wheat Mapping for Lebanon","summary":"Wheat accounts for approximately 20% of the world's caloric intake, making it\na vital component of global food security. Given this importance, mapping wheat\nfields plays a crucial role in enabling various stakeholders, including policy\nmakers, researchers, and agricultural organizations, to make informed decisions\nregarding food security, supply chain management, and resource allocation. In\nthis paper, we tackle the problem of accurately mapping wheat fields out of\nsatellite images by introducing an improved pipeline for winter wheat\nsegmentation, as well as presenting a case study on a decade-long analysis of\nwheat mapping in Lebanon. We integrate a Temporal Spatial Vision Transformer\n(TSViT) with Parameter-Efficient Fine Tuning (PEFT) and a novel post-processing\npipeline based on the Fields of The World (FTW) framework. Our proposed\npipeline addresses key challenges encountered in existing approaches, such as\nthe clustering of small agricultural parcels in a single large field. By\nmerging wheat segmentation with precise field boundary extraction, our method\nproduces geometrically coherent and semantically rich maps that enable us to\nperform in-depth analysis such as tracking crop rotation pattern over years.\nExtensive evaluations demonstrate improved boundary delineation and field-level\nprecision, establishing the potential of the proposed framework in operational\nagricultural monitoring and historical trend analysis. By allowing for accurate\nmapping of wheat fields, this work lays the foundation for a range of critical\nstudies and future advances, including crop monitoring and yield estimation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T16:31:54Z"}
{"aid":"http://arxiv.org/abs/2504.11377v1","title":"Improving Swimming Performance in Soft Robotic Fish with Distributed\n  Muscles and Embedded Kinematic Sensing","summary":"Bio-inspired underwater vehicles could yield improved efficiency,\nmaneuverability, and environmental compatibility over conventional\npropeller-driven underwater vehicles. However, to realize the swimming\nperformance of biology, there is a need for soft robotic swimmers with both\ndistributed muscles and kinematic feedback. This study presents the design and\nswimming performance of a soft robotic fish with independently controllable\nmuscles and embedded kinematic sensing distributed along the body. The soft\nswimming robot consists of an interior flexible spine, three axially\ndistributed sets of HASEL artificial muscles, embedded strain gauges, a\nstreamlined silicone body, and off-board electronics. In a fixed configuration,\nthe soft robot generates a maximum thrust of 7.9 mN when excited near its first\nresonant frequency (2 Hz) with synchronized antagonistic actuation of all\nmuscles. When excited near its second resonant frequency (8 Hz), synchronized\nmuscle actuation generates 5.0 mN of thrust. By introducing a sequential phase\noffset into the muscle actuation, the thrust at the second resonant frequency\nincreases to 7.2 mN, a 44% increase from simple antagonistic activation. The\nsequential muscle activation improves the thrust by increasing 1) the tail-beat\nvelocity and 2) traveling wave content in the swimming kinematics by four\ntimes. Further, the second resonant frequency (8 Hz) generates nearly as much\nthrust as the first resonance (2 Hz) while requiring only $\\approx25$% of the\ntail displacement, indicating that higher resonant frequencies have benefits\nfor swimming in confined environments where a smaller kinematic envelope is\nnecessary. These results demonstrate the performance benefits of independently\ncontrollable muscles and distributed kinematic sensing, and this type of soft\nrobotic swimmer provides a platform to address the open challenge of\nsensorimotor control.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T16:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.11379v1","title":"Omni$^2$: Unifying Omnidirectional Image Generation and Editing in an\n  Omni Model","summary":"$360^{\\circ}$ omnidirectional images (ODIs) have gained considerable\nattention recently, and are widely used in various virtual reality (VR) and\naugmented reality (AR) applications. However, capturing such images is\nexpensive and requires specialized equipment, making ODI synthesis increasingly\nimportant. While common 2D image generation and editing methods are rapidly\nadvancing, these models struggle to deliver satisfactory results when\ngenerating or editing ODIs due to the unique format and broad 360$^{\\circ}$\nField-of-View (FoV) of ODIs. To bridge this gap, we construct\n\\textbf{\\textit{Any2Omni}}, the first comprehensive ODI generation-editing\ndataset comprises 60,000+ training data covering diverse input conditions and\nup to 9 ODI generation and editing tasks. Built upon Any2Omni, we propose an\n\\textbf{\\underline{Omni}} model for \\textbf{\\underline{Omni}}-directional image\ngeneration and editing (\\textbf{\\textit{Omni$^2$}}), with the capability of\nhandling various ODI generation and editing tasks under diverse input\nconditions using one model. Extensive experiments demonstrate the superiority\nand effectiveness of the proposed Omni$^2$ model for both the ODI generation\nand editing tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T16:53:11Z"}
{"aid":"http://arxiv.org/abs/2504.11383v1","title":"Accelerating Multiscale Modeling with Hybrid Solvers: Coupling FEM and\n  Neural Operators with Domain Decomposition","summary":"Numerical solvers for partial differential equations (PDEs) face challenges\nbalancing computational cost and accuracy, especially in multiscale and dynamic\nsystems. Neural operators can significantly speed up simulations; however, they\noften face challenges such as error accumulation and limited generalization in\nmultiphysics problems. This work introduces a novel hybrid framework that\nintegrates physics-informed DeepONet with FEM through domain decomposition. The\ncore innovation lies in adaptively coupling FEM and DeepONet subdomains via a\nSchwarz alternating method. This methodology strategically allocates\ncomputationally demanding regions to a pre-trained Deep Operator Network, while\nthe remaining computational domain is solved through FEM. To address dynamic\nsystems, we integrate the Newmark time-stepping scheme directly into the\nDeepONet, significantly mitigating error accumulation in long-term simulations.\nFurthermore, an adaptive subdomain evolution enables the ML-resolved region to\nexpand dynamically, capturing emerging fine-scale features without remeshing.\nThe framework's efficacy has been validated across a range of solid mechanics\nproblems, including static, quasi-static, and dynamic regimes, demonstrating\naccelerated convergence rates (up to 20% improvement compared to FE-FE\napproaches), while preserving solution fidelity with error < 1%. Our case\nstudies show that our proposed hybrid solver: (1) maintains solution continuity\nacross subdomain interfaces, (2) reduces computational costs by eliminating\nfine mesh requirements, (3) mitigates error accumulation in time-dependent\nsimulations, and (4) enables automatic adaptation to evolving physical\nphenomena. This work bridges the gap between numerical methods and AI-driven\nsurrogates, offering a scalable pathway for high-fidelity simulations in\nengineering and scientific applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T16:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.11403v1","title":"Counting irreducible representations of general linear groups and\n  unitary groups","summary":"Let $G$ be a general linear group over $\\BR$, $\\BC$, or $\\BH$, or a real\nunitary group. In this paper, we precisely describe the number of isomorphism\nclasses of irreducible Casselman-Wallach representations of $G$ with a given\ninfinitesimal character and a given associated variety, expressed in terms of\ncertain combinatorial data called painted Young diagrams and assigned Young\ndiagrams.","main_category":"math.RT","categories":"math.RT","published":"2025-04-15T17:18:20Z"}
{"aid":"http://arxiv.org/abs/2504.11411v1","title":"Breaking the TDD Flow for Over-the-Air Phase Synchronization in\n  Distributed Antenna Systems","summary":"Phase synchronization between distributed antenna arrays requires\nmeasurements that break the standard time-division duplex (TDD) operation. We\npresent a feasibility study on implementing such synchronization and analyze\nits impact on the quality of service. Considering two antenna arrays with\nindependent local oscillators (LOs), we propose a modified TDD flow to\naccommodate the transmission of phase synchronization signals, formulate the\nphase estimation and compensation problem, and derive the achievable downlink\nspectral efficiency (SE). Numerical results show that frequent re-estimation of\nthe interarray phase disparity is essential for maximizing SE in systems with\nlow-quality LOs. Furthermore, applying a Kalman filter for phase tracking\nsubstantially improves the SE, especially if phase estimation errors are large\ncompared to LOs phase drifts.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T17:26:42Z"}
{"aid":"http://arxiv.org/abs/2504.11415v1","title":"Robustness and sex differences in skin cancer detection: logistic\n  regression vs CNNs","summary":"Deep learning has been reported to achieve high performances in the detection\nof skin cancer, yet many challenges regarding the reproducibility of results\nand biases remain. This study is a replication (different data, same analysis)\nof a study on Alzheimer's disease [28] which studied robustness of logistic\nregression (LR) and convolutional neural networks (CNN) across patient sexes.\nWe explore sex bias in skin cancer detection, using the PAD-UFES-20 dataset\nwith LR trained on handcrafted features reflecting dermatological guidelines\n(ABCDE and the 7-point checklist), and a pre-trained ResNet-50 model. We\nevaluate these models in alignment with [28]: across multiple training datasets\nwith varied sex composition to determine their robustness. Our results show\nthat both the LR and the CNN were robust to the sex distributions, but the\nresults also revealed that the CNN had a significantly higher accuracy (ACC)\nand area under the receiver operating characteristics (AUROC) for male patients\nthan for female patients. We hope these findings to contribute to the growing\nfield of investigating potential bias in popular medical machine learning\nmethods. The data and relevant scripts to reproduce our results can be found in\nour Github.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-15T17:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.11420v1","title":"Reinforcing Compositional Retrieval: Retrieving Step-by-Step for\n  Composing Informative Contexts","summary":"Large Language Models (LLMs) have demonstrated remarkable capabilities across\nnumerous tasks, yet they often rely on external context to handle complex\ntasks. While retrieval-augmented frameworks traditionally focus on selecting\ntop-ranked documents in a single pass, many real-world scenarios demand\ncompositional retrieval, where multiple sources must be combined in a\ncoordinated manner. In this work, we propose a tri-encoder sequential retriever\nthat models this process as a Markov Decision Process (MDP), decomposing the\nprobability of retrieving a set of elements into a sequence of conditional\nprobabilities and allowing each retrieval step to be conditioned on previously\nselected examples. We train the retriever in two stages: first, we efficiently\nconstruct supervised sequential data for initial policy training; we then\nrefine the policy to align with the LLM's preferences using a reward grounded\nin the structural correspondence of generated programs. Experimental results\nshow that our method consistently and significantly outperforms baselines,\nunderscoring the importance of explicitly modeling inter-example dependencies.\nThese findings highlight the potential of compositional retrieval for tasks\nrequiring multiple pieces of evidence or examples.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T17:35:56Z"}
{"aid":"http://arxiv.org/abs/2504.11434v1","title":"Enhancing Out-of-Distribution Detection with Extended Logit\n  Normalization","summary":"Out-of-distribution (OOD) detection is essential for the safe deployment of\nmachine learning models. Recent advances have explored improved classification\nlosses and representation learning strategies to enhance OOD detection.\nHowever, these methods are often tailored to specific post-hoc detection\ntechniques, limiting their generalizability. In this work, we identify a\ncritical issue in Logit Normalization (LogitNorm), which inhibits its\neffectiveness in improving certain post-hoc OOD detection methods. To address\nthis, we propose Extended Logit Normalization ($\\textbf{ELogitNorm}$), a novel\nhyperparameter-free formulation that significantly benefits a wide range of\npost-hoc detection methods. By incorporating feature distance-awareness to\nLogitNorm, $\\textbf{ELogitNorm}$ shows more robust OOD separability and\nin-distribution (ID) confidence calibration than its predecessor. Extensive\nexperiments across standard benchmarks demonstrate that our approach\noutperforms state-of-the-art training-time methods in OOD detection while\nmaintaining strong ID classification accuracy.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.11455v1","title":"SimpleAR: Pushing the Frontier of Autoregressive Visual Generation\n  through Pretraining, SFT, and RL","summary":"This work presents SimpleAR, a vanilla autoregressive visual generation\nframework without complex architecure modifications. Through careful\nexploration of training and inference optimization, we demonstrate that: 1)\nwith only 0.5B parameters, our model can generate 1024x1024 resolution images\nwith high fidelity, and achieve competitive results on challenging\ntext-to-image benchmarks, e.g., 0.59 on GenEval and 79.66 on DPG; 2) both\nsupervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO)\ntraining could lead to significant improvements on generation aesthectics and\nprompt alignment; and 3) when optimized with inference acceleraton techniques\nlike vLLM, the time for SimpleAR to generate an 1024x1024 image could be\nreduced to around 14 seconds. By sharing these findings and open-sourcing the\ncode, we hope to reveal the potential of autoregressive visual generation and\nencourage more participation in this research field. Code is available at\nhttps://github.com/wdrink/SimpleAR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.11458v1","title":"Intermediate phases in $Î±$-RuCl$_3$ under in-plane magnetic field\n  via interlayer spin interactions","summary":"$\\alpha$-RuCl$_3$ has attracted significant attention as a prime candidate\nfor the spin-1/2 Kitaev spin liquid in two-dimensional honeycomb lattices.\nAlthough its ground state is magnetically ordered, the order is suppressed\nunder a moderate in-plane magnetic field. The intermediate regime of the field\nhas exotic behaviours, some of which are claimed to originate from a Kitaev\nspin liquid. In resolving debates surrounding these behaviours, the interlayer\ninteractions in $\\alpha$-RuCl$_3$ have been largely overlooked due to their\nperceived weakness in van der Waals materials. However, near the transition,\nthey may become significant as the field energy approaches the interlayer\ncoupling scale. Here we investigate the effects of interlayer couplings in\n$\\alpha$-RuCl$_3$ with $R\\bar{3}$ and $C2/m$ structures. We first examine their\neffects on the transition temperature ($T_N$) using classical Monte Carlo\nsimulations. We found that the interlayer couplings have minimal effects on\n$T_N$, and the different $T_N$ between the two structures are mainly due to the\nanisotropy in the intralayer interactions. Focusing on the $R{\\bar 3}$\nstructure, we show that the nearest neighbour interlayer interaction is\nXXZ-type due to the symmetry, and the next nearest neighbor interaction of the\nKitaev-type is crucial for the transition between two zigzag orders under an\nin-plane field. Furthermore, an intermediate phase with a large unit cell\nemerges due to the interlayer interactions. Our findings provide new insights\ninto the exotic behaviours and sample dependence reported in $\\alpha$-RuCl$_3$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.11776v1","title":"ALMASOP. Detection of Turbulence-induced Mass Assembly Shocks in\n  Starless Cores","summary":"Star formation is a series of mass assembly processes and starless cores,\nthose cold and dense condensations in molecular clouds, play a pivotal role as\ninitial seeds of stars. With only a limited sample of known starless cores,\nhowever, the origin and growth of such stellar precursors had not been well\ncharacterized previously. Meanwhile, the recent discovery of CH$_3$OH emission,\nwhich is generally associated with desorbed icy mantle in warm regions,\nparticularly at the periphery of starless cores also remains puzzling. We\npresent sensitive ALMA (Band~3) observations (at 3~mm) toward a sample of newly\nidentified starless cores in the Orion Molecular Cloud. The spatially resolved\nimages distinctly indicate that the observed CH$_3$OH and N$_2$H$^+$ emission\nassociated with these cores are morphologically anti-correlated and\nkinematically offset from each other. We postulate that the CH$_3$OH emission\nhighlights the desorption of icy mantle by shocks resulting from gas piling\nonto dense cores in the filaments traced by N$_2$H$^+$. Our magnetohydrodynamic\n(MHD) simulations of star formation in turbulent clouds combined with radiative\ntransfer calculations and imaging simulations successfully reproduced the\nobserved signatures and reaffirmed the above scenario at work. Our result\nserves as an intriguing and exemplary illustration, a snapshot in time, of the\ndynamic star-forming processes in turbulent clouds. The results offer\ncompelling insights into the mechanisms governing the growth of starless cores\nand the presence of gas-phase complex organic molecules associated with these\ncores.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-16T05:31:03Z"}
{"aid":"http://arxiv.org/abs/2504.11783v1","title":"The Digital Cybersecurity Expert: How Far Have We Come?","summary":"The increasing deployment of large language models (LLMs) in the\ncybersecurity domain underscores the need for effective model selection and\nevaluation. However, traditional evaluation methods often overlook specific\ncybersecurity knowledge gaps that contribute to performance limitations. To\naddress this, we develop CSEBenchmark, a fine-grained cybersecurity evaluation\nframework based on 345 knowledge points expected of cybersecurity experts.\nDrawing from cognitive science, these points are categorized into factual,\nconceptual, and procedural types, enabling the design of 11,050 tailored\nmultiple-choice questions. We evaluate 12 popular LLMs on CSEBenchmark and find\nthat even the best-performing model achieves only 85.42% overall accuracy, with\nparticular knowledge gaps in the use of specialized tools and uncommon\ncommands. Different LLMs have unique knowledge gaps. Even large models from the\nsame family may perform poorly on knowledge points where smaller models excel.\nBy identifying and addressing specific knowledge gaps in each LLM, we achieve\nup to an 84% improvement in correcting previously incorrect predictions across\nthree existing benchmarks for two cybersecurity tasks. Furthermore, our\nassessment of each LLM's knowledge alignment with specific cybersecurity roles\nreveals that different models align better with different roles, such as GPT-4o\nfor the Google Senior Intelligence Analyst and Deepseek-V3 for the Amazon\nPrivacy Engineer. These findings underscore the importance of aligning LLM\nselection with the specific knowledge requirements of different cybersecurity\nroles for optimal performance.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-16T05:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.11789v1","title":"The vanishing discount problem for nonlocal Hamilton-Jacobi equations","summary":"We establish a convergence result for the vanishing discount problem in the\ncontext of nonlocal HJ equations. We consider a fairly general class of\ndiscounted first-order and convex HJ equations which incorporate an\nintegro-differential operator posed on the $d$-dimensional torus, and we show\nthat the solutions converge to a specific critical solution as the discount\nfactor tends to zero. Our approach relies on duality techniques for nonlocal\nconvex HJ equations, building upon Hahn-Banach separation theorems to develop a\ngeneralized notion of Mather measure. The results are applied to a specific\nclass of convex and superlinear Hamiltonians.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-16T05:42:24Z"}
{"aid":"http://arxiv.org/abs/2504.11807v1","title":"Entropy bounds from quantum thermodynamics","summary":"Within an inherently classical perspective, there is always an unavoidable\nenergy cost associated with the information deletion and this common lore is at\nthe heart of the Landauer's conjecture that does not impose, per se, any\nrelevant limit on the information acquisition. Although such a mindset should\ngenerally apply to systems of any size, its quantum mechanical implications are\nparticularly intriguing and, for this reason, we examine here a minimal\nphysical structure where the system and the environment are described,\nrespectively, by a pair of quantum oscillators coupled by an appropriate\nHermitian interaction able to amplify the entropy of the initial state. Since\nat the onset of the dynamical evolution the system is originally in a pure\nstate, its entropy variation is always positive semidefinite and the Landauer's\nconjecture should not impose any constraint. Nonetheless, provided the quantum\namplification is effective, it turns out that the entropy variation of the\nsystem always undershoots the heat transferred to the environment. When the\ninitial thermal state of the environment is characterized by a chemical\npotential, the entropy growth is bounded both by the particles and by the heat\nflowing to the environment. The limits deduced in the quantum thermodynamical\nframework are also scrutinized from a field theory standpoint where species of\ndifferent spins are copiously produced (especially in a cosmological context)\nthanks to the rapid variation of the space-time curvature.","main_category":"quant-ph","categories":"quant-ph,astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-16T06:41:50Z"}
{"aid":"http://arxiv.org/abs/2504.11829v1","title":"DÃ©jÃ  Vu: Multilingual LLM Evaluation through the Lens of Machine\n  Translation Evaluation","summary":"Generation capabilities and language coverage of multilingual large language\nmodels (mLLMs) are advancing rapidly. However, evaluation practices for\ngenerative abilities of mLLMs are still lacking comprehensiveness, scientific\nrigor, and consistent adoption across research labs, which undermines their\npotential to meaningfully guide mLLM development. We draw parallels with\nmachine translation (MT) evaluation, a field that faced similar challenges and\nhas, over decades, developed transparent reporting standards and reliable\nevaluations for multilingual generative models. Through targeted experiments\nacross key stages of the generative evaluation pipeline, we demonstrate how\nbest practices from MT evaluation can deepen the understanding of quality\ndifferences between models. Additionally, we identify essential components for\nrobust meta-evaluation of mLLMs, ensuring the evaluation methods themselves are\nrigorously assessed. We distill these insights into a checklist of actionable\nrecommendations for mLLM research and development.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T07:38:19Z"}
{"aid":"http://arxiv.org/abs/2504.11836v1","title":"Non-centering for discrete-valued state transition models: an\n  application to ESBL-producing E. coli transmission in Malawi","summary":"Infectious disease transmission is often modelled by discrete-valued\nstochastic state-transition processes. Due to a lack of complete data, Bayesian\ninference for these models often relies on data-augmentation techniques. These\ntechniques are often inefficient or time consuming to implement. We introduce a\nnovel data-augmentation Markov chain Monte Carlo method for discrete-time\nindividual-based epidemic models, which we call the Rippler algorithm. This\nmethod uses the transmission model in the proposal step of the\nMetropolis-Hastings algorithm, rather than in the accept-reject step. We test\nthe Rippler algorithm on simulated data and apply it to data on\nextended-spectrum beta-lactamase (ESBL)-producing E. coli collected in\nBlantyre, Malawi. We compare the Rippler algorithm to two other commonly used\nBayesian inference methods for partially observed epidemic data, and find that\nit has a good balance between mixing speed and computational complexity.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T07:46:46Z"}
{"aid":"http://arxiv.org/abs/2504.11837v1","title":"FiSMiness: A Finite State Machine Based Paradigm for Emotional Support\n  Conversations","summary":"Emotional support conversation (ESC) aims to alleviate the emotional distress\nof individuals through effective conversations. Although large language models\n(LLMs) have obtained remarkable progress on ESC, most of these studies might\nnot define the diagram from the state model perspective, therefore providing a\nsuboptimal solution for long-term satisfaction. To address such an issue, we\nleverage the Finite State Machine (FSM) on LLMs, and propose a framework called\nFiSMiness. Our framework allows a single LLM to bootstrap the planning during\nESC, and self-reason the seeker's emotion, support strategy and the final\nresponse upon each conversational turn. Substantial experiments on ESC datasets\nsuggest that FiSMiness outperforms many baselines, including direct inference,\nself-refine, chain of thought, finetuning, and external-assisted methods, even\nthose with many more parameters.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T07:52:06Z"}
{"aid":"http://arxiv.org/abs/2504.11838v1","title":"A Visual RAG Pipeline for Few-Shot Fine-Grained Product Classification","summary":"Despite the rapid evolution of learning and computer vision algorithms,\nFine-Grained Classification (FGC) still poses an open problem in many\npractically relevant applications. In the retail domain, for example, the\nidentification of fast changing and visually highly similar products and their\nproperties are key to automated price-monitoring and product recommendation.\nThis paper presents a novel Visual RAG pipeline that combines the Retrieval\nAugmented Generation (RAG) approach and Vision Language Models (VLMs) for\nfew-shot FGC. This Visual RAG pipeline extracts product and promotion data in\nadvertisement leaflets from various retailers and simultaneously predicts\nfine-grained product ids along with price and discount information. Compared to\nprevious approaches, the key characteristic of the Visual RAG pipeline is that\nit allows the prediction of novel products without re-training, simply by\nadding a few class samples to the RAG database. Comparing several VLM back-ends\nlike GPT-4o [23], GPT-4o-mini [24], and Gemini 2.0 Flash [10], our approach\nachieves 86.8% accuracy on a diverse dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T07:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.11847v1","title":"Ultra-Efficient Kidney Stone Fragment Removal via Spinner-Induced\n  Synergistic Circulation and Spiral Flow","summary":"Kidney stones can cause severe pain and complications such as chronic kidney\ndisease or kidney failure. Retrograde intrarenal surgery (RIRS), which uses\nlaser lithotripsy to fragment stones for removal via a ureteroscope, is widely\nadopted due to its safety and effectiveness. However, conventional fragment\nremoval methods using basketing and vacuum-assisted aspiration are inefficient,\nas they can capture only 1 to 3 fragments (1--3\\,mm in size) per pass, often\nrequiring dozens to hundreds of ureteroscope passes during a single procedure\nto completely remove the fragments. These limitations lead to prolonged\nprocedures and residual fragments that contribute to high recurrence rates. To\naddress these limitations, we present a novel spinner device that enables\nultra-efficient fragment removal through spinning-induced localized suction.\nThe spinner generates a three-dimensional spiral and circulating flow field\nthat dislodges and draws fragments into its cavity even from distances over\n20\\,mm, eliminating the need to chase fragments. It can capture over 60\nfragments (0.5--2\\,mm) or over 15 larger fragments (2--3\\,mm) in a single pass,\nsignificantly improving removal efficiency. In this work, the spinner design is\noptimized via computational fluid dynamics to maximize suction performance.\n\\textit{In vitro} testing demonstrates near 100\\% capture rates for up to 60\nfragments in a single operation and superior large-distance capture efficacy\ncompared to vacuum-assisted methods. \\textit{Ex vivo} testing of the integrated\nspinner-ureteroscope system in a porcine kidney confirmed its high performance\nby capturing 45 fragments in just 4 seconds during a single pass and achieving\ncomplete fragment clearance within a few passes.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.med-ph","published":"2025-04-16T08:10:16Z"}
{"aid":"http://arxiv.org/abs/2504.11856v1","title":"Cross-Frequency Collaborative Training Network and Dataset for\n  Semi-supervised First Molar Root Canal Segmentation","summary":"Root canal (RC) treatment is a highly delicate and technically complex\nprocedure in clinical practice, heavily influenced by the clinicians'\nexperience and subjective judgment. Deep learning has made significant\nadvancements in the field of computer-aided diagnosis (CAD) because it can\nprovide more objective and accurate diagnostic results. However, its\napplication in RC treatment is still relatively rare, mainly due to the lack of\npublic datasets in this field. To address this issue, in this paper, we\nestablished a First Molar Root Canal segmentation dataset called FMRC-2025.\nAdditionally, to alleviate the workload of manual annotation for dentists and\nfully leverage the unlabeled data, we designed a Cross-Frequency Collaborative\ntraining semi-supervised learning (SSL) Network called CFC-Net. It consists of\ntwo components: (1) Cross-Frequency Collaborative Mean Teacher (CFC-MT), which\nintroduces two specialized students (SS) and one comprehensive teacher (CT) for\ncollaborative multi-frequency training. The CT and SS are trained on different\nfrequency components while fully integrating multi-frequency knowledge through\ncross and full frequency consistency supervisions. (2) Uncertainty-guided\nCross-Frequency Mix (UCF-Mix) mechanism enables the network to generate\nhigh-confidence pseudo-labels while learning to integrate multi-frequency\ninformation and maintaining the structural integrity of the targets. Extensive\nexperiments on FMRC-2025 and three public dental datasets demonstrate that\nCFC-MT is effective for RC segmentation and can also exhibit strong\ngeneralizability on other dental segmentation tasks, outperforming\nstate-of-the-art SSL medical image segmentation methods. Codes and dataset will\nbe released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T08:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.11863v1","title":"Understanding the evolution of the magnetic ground state in\n  Ba$_4$NaRu$_3$O$_{12}$","summary":"We report a comprehensive investigation of the quadruple perovskite\nBa$_4$NaRu$_3$O$_{12}$, in which we discover a robust spin-lattice coupled\nground state characterized by a long-range antiferromagnetic ordering at $T_N\n\\sim$ 257 K. The system's unique structural motif of three symmetrically\ndistinct magnetic ions, including Ru dimers separated by non-magnetic layers,\nis intimately correlated with its magnetic behavior, as evidenced by\ntemperature-dependent diffraction measurements and specific heat data. The\npowder neutron diffraction patterns at 13 K showed that the spins within the\ndimers are antiparallel, leading to a net zero moment contribution and a\nstaggered arrangement of the triangular layers formed by the Ru moments within\nthe corner-shared octahedra along the $c$-axis. The low-temperature specific\nheat revealed an extra boson peak contribution from optical modes with a\nmaximum vibrational energy of $\\sim$55cm$^{-1}$. The charge transport exhibited\nvariable-range hopping (VRH) behaviour below $T_N$, with a stronger\nenergy-dependence than expected from the Efros-Shklovskii model, suggesting the\npresence of multiparticle correlation effects.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-16T08:37:28Z"}
{"aid":"http://arxiv.org/abs/2504.11873v1","title":"Transferable Deployment of Semantic Edge Inference Systems via\n  Unsupervised Domain Adaption","summary":"This paper investigates deploying semantic edge inference systems for\nperforming a common image clarification task. In particular, each system\nconsists of multiple Internet of Things (IoT) devices that first locally encode\nthe sensing data into semantic features and then transmit them to an edge\nserver for subsequent data fusion and task inference. The inference accuracy is\ndetermined by efficient training of the feature encoder/decoder using labeled\ndata samples. Due to the difference in sensing data and communication channel\ndistributions, deploying the system in a new environment may induce high costs\nin annotating data labels and re-training the encoder/decoder models. To\nachieve cost-effective transferable system deployment, we propose an efficient\nDomain Adaptation method for Semantic Edge INference systems (DASEIN) that can\nmaintain high inference accuracy in a new environment without the need for\nlabeled samples. Specifically, DASEIN exploits the task-relevant data\ncorrelation between different deployment scenarios by leveraging the techniques\nof unsupervised domain adaptation and knowledge distillation. It devises an\nefficient two-step adaptation procedure that sequentially aligns the data\ndistributions and adapts to the channel variations. Numerical results show\nthat, under a substantial change in sensing data distributions, the proposed\nDASEIN outperforms the best-performing benchmark method by 7.09% and 21.33% in\ninference accuracy when the new environment has similar or 25 dB lower channel\nsignal to noise power ratios (SNRs), respectively. This verifies the\neffectiveness of the proposed method in adapting both data and channel\ndistributions in practical transfer deployment applications.","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY","published":"2025-04-16T08:50:51Z"}
{"aid":"http://arxiv.org/abs/2504.11878v1","title":"A Novel Approach to Secure RSMA Networks","summary":"This letter introduces a novel data-dependent interleaving technique designed\nto enhance the security of rate-splitting multiple access (RSMA) networks by\nprotecting the common stream from eavesdropping threats. Specifically, we\nexploit the RSMA structure by interleaving the common bits of each user based\non a sequence derived from their private bits. By decoding its private stream,\nthe legitimate receiver reconstructs the interleaving sequence set by the\ntransmitter and successfully de-interleaves the common stream. Therefore, the\ncommon part is successfully prevented from being intercepted by an eavesdropper\nwho is unable to deduce the dynamic changing interleaving permutations. To\nensure dynamic interleaving sequences, a private bit selection approach that\nbalances the trade-off between security and system efficiency is proposed.\nSimulation findings confirm the effectiveness of the suggested method, showing\nnotable security improvements while maintaining robust overall system\nreliability.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-16T08:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.11886v1","title":"Detection of wave activity within a realistic 3D MHD quiet sun\n  simulation","summary":"Context. Tracing wave activity from the photosphere to the corona has\nimportant implications for coronal heating and prediction of the solar wind.\nDespite extensive theory and simulations, the detection of waves in realistic\nMHD simulations still presents a large challenge due to wave interaction, mode\nconversion, and damping mechanisms. Aims. We conducted this study to detect\nlocalised wave activity within a realistic MHD simulation of the solar\natmosphere by the Bifrost code. Methods. We present a new method of detecting\nthe most significant contributions of wave activity within localised areas of\nthe domain, aided by Discrete Fourier Transforms and frequency filtering. We\ncorrelate oscillations in the vertical & horizontal magnetic field, velocities\nparallel & perpendicular to the magnetic field, and pressure to infer the\nnature of the dominant wave modes. Results. Our method captures the most\npowerful frequencies and wavenumbers, as well as providing a new diagnostic for\ndamping processes. We infer the presence of magnetoacoustic waves in the\nboundaries of prominent chromospheric/coronal swirling features. We find these\nwaves are likely damped by viscous heating in the swirl boundaries,\ncontributing to heating in the upper atmosphere. Conclusions. Using the most\nsignificant frequencies decomposition, we highlight that energy can be\ntransported from the lower atmosphere to the upper atmosphere through waves and\nfluctuations along the swirl boundaries. Although further analysis is needed to\nconfirm these findings, our new method provides a path forward to investigate\nwave activity in the solar atmosphere","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-16T09:14:14Z"}
{"aid":"http://arxiv.org/abs/2504.11896v1","title":"Learning Physics-Informed Color-Aware Transforms for Low-Light Image\n  Enhancement","summary":"Image decomposition offers deep insights into the imaging factors of visual\ndata and significantly enhances various advanced computer vision tasks. In this\nwork, we introduce a novel approach to low-light image enhancement based on\ndecomposed physics-informed priors. Existing methods that directly map\nlow-light to normal-light images in the sRGB color space suffer from\ninconsistent color predictions and high sensitivity to spectral power\ndistribution (SPD) variations, resulting in unstable performance under diverse\nlighting conditions. To address these challenges, we introduce a\nPhysics-informed Color-aware Transform (PiCat), a learning-based framework that\nconverts low-light images from the sRGB color space into deep\nillumination-invariant descriptors via our proposed Color-aware Transform\n(CAT). This transformation enables robust handling of complex lighting and SPD\nvariations. Complementing this, we propose the Content-Noise Decomposition\nNetwork (CNDN), which refines the descriptor distributions to better align with\nwell-lit conditions by mitigating noise and other distortions, thereby\neffectively restoring content representations to low-light images. The CAT and\nthe CNDN collectively act as a physical prior, guiding the transformation\nprocess from low-light to normal-light domains. Our proposed PiCat framework\ndemonstrates superior performance compared to state-of-the-art methods across\nfive benchmark datasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-16T09:23:38Z"}
{"aid":"http://arxiv.org/abs/2504.11902v1","title":"The axial-vector form factor of the nucleon in a finite box","summary":"We consider the axial-vector form factor of the nucleon in a finite box.\nStarting from the chiral Lagrangian with nucleon and Delta-isobar degrees of\nfreedom, we address, at the one-loop level, the impact of two types of\nfinite-volume effects. On the one hand, there are the implicit effects from the\nin-box values of the nucleon and Delta-isobar masses. On the other hand, there\nare the explicit effects caused by computing the in-box loop integrals with the\nvalues of the nucleon and Delta-isobar masses obtained in the infinite-volume\nlimit. Selected numerical results are shown for three lattice ensembles. We\nshow that the implicit effects dominate the in-box form factor. Our results are\npresented in terms of a set of basis functions that generalize the\nPassarino-Veltman reduction scheme to the finite-box case, such that only\nscalar loop integrals have to be performed. The techniques we developed are\nmore generally relevant for lattice studies of hadronic quantities.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-16T09:26:30Z"}
{"aid":"http://arxiv.org/abs/2504.11920v1","title":"Lagrangian finite elements in Sobolev-like spaces of order $3/2$","summary":"This paper introduces a Sobolev-like space of order $3/2$, denoted as\n$\\widehat{H}^{3/2}$, for Lagrangian finite elements, especially for $C^0$\nelements. It is motivated by the limitations of current stability analysis of\nthe evolving surface finite element method (ESFEM), which relies exclusively on\nan energy estimate framework. To establish a PDE-based analysis framework for\nESFEM, we encounter a fundamental regularity mismatch: the ESFEM adopts the\n$C^0$ elements, while the PDE regularity theory requires $H^{3/2}$ regularity\nfor solutions. To overcome this difficulty, we first examine the properties of\nthe continuous $H^{3/2}$ space, then introduce a Dirichlet lift and Scott-Zhang\ntype interpolation operators to bridge to the discrete $\\widehat{H}^{3/2}$\nspace. Our new $\\widehat{H}^{3/2}$ space is shown to be compatible with the\nelliptic PDE regularity theory, the trace inequality, and the inverse\ninequality. Notably, we extend the critical domain deformation estimate in\nESFEM to the $\\widehat{H}^{3/2}$ setting. The $\\widehat{H}^{3/2}$ theory\nprovides a foundation for establishing a PDE-based convergence analysis\nframework of ESFEM.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-16T09:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.11928v1","title":"The Jade Gateway to Trust: Exploring How Socio-Cultural Perspectives\n  Shape Trust Within Chinese NFT Communities","summary":"Today's world is witnessing an unparalleled rate of technological\ntransformation. The emergence of non-fungible tokens (NFTs) has transformed how\nwe handle digital assets and value. Despite their initial popularity, NFTs face\ndeclining adoption influenced not only by cryptocurrency volatility but also by\ntrust dynamics within communities. From a social computing perspective,\nunderstanding these trust dynamics offers valuable insights for the development\nof both the NFT ecosystem and the broader digital economy. China presents a\ncompelling context for examining these dynamics, offering a unique intersection\nof technological innovation and traditional cultural values. Through a content\nanalysis of eight Chinese NFT-focused WeChat groups and 21 semi-structured\ninterviews, we examine how socio-cultural factors influence trust formation and\ndevelopment. We found that trust in Chinese NFT communities is significantly\nmolded by local cultural values. To be precise, Confucian virtues, such as\nbenevolence, propriety, and integrity, play a crucial role in shaping these\ntrust relationships. Our research identifies three critical trust dimensions in\nChina's NFT market: (1) technological, (2) institutional, and (3) social. We\nexamined the challenges in cultivating each dimension. Based on these insights,\nwe developed tailored trust-building guidelines for Chinese NFT stakeholders.\nThese guidelines address trust issues that factor into NFT's declining\npopularity and could offer valuable strategies for CSCW researchers,\ndevelopers, and designers aiming to enhance trust in global NFT communities.\nOur research urges CSCW scholars to take into account the unique socio-cultural\ncontexts when developing trust-enhancing strategies for digital innovations and\nonline interactions.","main_category":"cs.CY","categories":"cs.CY,cs.HC","published":"2025-04-16T10:03:30Z"}
{"aid":"http://arxiv.org/abs/2504.11939v1","title":"Assessing WGC Compatibility in ModMax Black Holes via Photon Spheres\n  Analysis and WCCC Validation","summary":"It seems that the regime of Hawking radiation and evaporation ultimately\ndrives charged black holes toward super-extremality of the charge parameter and\nthe dominance of extremal conditions. This progression, in turn, lays the\ngroundwork for satisfying the necessary conditions for the Weak Gravity\nConjecture (WGC). Preliminary studies indicate that black holes such as the\nReissner-Nordstr$\\\"o$m (RN) model, in their initial form, lack the capacity to\nsustain super-extremality of the charge parameter. If such conditions arise,\nthese black holes transition into naked singularities-a scenario that is highly\nundesirable due to the loss of causality and the breakdown of space-time\ngeometry. This raises whether the inability to sustain super-extremality is an\ninherent property of the model or a consequence of the approximations and\nprecision limitations employed in its construction. To address this, we turned\nto the ModMax model, which represents an extension of the RN model. Our\nanalysis revealed that the ModMax model not only accommodates super-extremality\nof the charge parameter but also, under certain conditions, emerges as a\npromising candidate for investigating the WGC. Furthermore, we independently\nobserved how the inclusion of the de Sitter radius ($\\ell$) in the AdS model\nand $f(R)$ gravitational corrections-both of which enhance and complicate the\nmodel-can have a direct impact on the range of super-extremal charge tolerance\nwhich, in turn, provides the realization of the conditions necessary for the\nWGC.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-16T10:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.11979v1","title":"On the Regularity of Random 2-SAT and 3-SAT","summary":"We consider the random $k$-SAT problem with $n$ variables, $m=m(n)$ clauses,\nand clause density $\\alpha=\\lim_{n\\to\\infty}m/n$ for $k=2,3$. It is known that\nif $\\alpha$ is small enough, then the random $k$-SAT problem admits a solution\nwith high probability, which we interpret as the problem being\nunder-constrained. In this paper, we quantify exactly how under-constrained the\nrandom $k$-SAT problems are by determining their degrees of freedom, which we\ndefine as the threshold for the number of variables we can fix to an arbitrary\nvalue before the problem no longer is solvable with high probability. We show\nthat the random $2$-SAT and $3$-SAT problems have $n/m^{1/2}$ and $n/m^{1/3}$\ndegrees of freedom, respectively. Our main result is an explicit computation of\nthe corresponding threshold functions. Our result shows that the threshold\nfunction for the random $2$-SAT problem is regular, while it is non-regular for\nthe random $3$-SAT problem. By regular, we mean continuous and analytic on the\ninterior of its support. This result shows that the random $3$-SAT problem is\nmore sensitive to small changes in the clause density $\\alpha$ than the random\n$2$-SAT problem.","main_category":"math.PR","categories":"math.PR,cs.DM","published":"2025-04-16T11:17:56Z"}
{"aid":"http://arxiv.org/abs/2504.11981v1","title":"Hardware-Friendly Delayed-Feedback Reservoir for Multivariate\n  Time-Series Classification","summary":"Reservoir computing (RC) is attracting attention as a machine-learning\ntechnique for edge computing. In time-series classification tasks, the number\nof features obtained using a reservoir depends on the length of the input\nseries. Therefore, the features must be converted to a constant-length\nintermediate representation (IR), such that they can be processed by an output\nlayer. Existing conversion methods involve computationally expensive matrix\ninversion that significantly increases the circuit size and requires processing\npower when implemented in hardware. In this article, we propose a simple but\neffective IR, namely, dot-product-based reservoir representation (DPRR), for RC\nbased on the dot product of data features. Additionally, we propose a\nhardware-friendly delayed-feedback reservoir (DFR) consisting of a nonlinear\nelement and delayed feedback loop with DPRR. The proposed DFR successfully\nclassified multivariate time series data that has been considered particularly\ndifficult to implement efficiently in hardware. In contrast to conventional DFR\nmodels that require analog circuits, the proposed model can be implemented in a\nfully digital manner suitable for high-level syntheses. A comparison with\nexisting machine-learning methods via field-programmable gate array\nimplementation using 12 multivariate time-series classification tasks confirmed\nthe superior accuracy and small circuit size of the proposed method.","main_category":"cs.LG","categories":"cs.LG,cs.AR","published":"2025-04-16T11:22:38Z"}
{"aid":"http://arxiv.org/abs/2504.12022v1","title":"Hardness and Approximation Schemes for Discrete Packing and Domination","summary":"We present polynomial-time approximation schemes based on local search}\ntechnique for both geometric (discrete) independent set (\\mdis) and geometric\n(discrete) dominating set (\\mdds) problems, where the objects are arbitrary\nradii disks and arbitrary side length axis-parallel squares. Further, we show\nthat the \\mdds~problem is \\apx-hard for various shapes in the plane. Finally,\nwe prove that both \\mdis~and \\mdds~problems are \\np-hard for unit disks\nintersecting a horizontal line and axis-parallel unit squares intersecting a\nstraight line with slope $-1$.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-16T12:28:34Z"}
{"aid":"http://arxiv.org/abs/2504.12034v1","title":"OpDiffer: LLM-Assisted Opcode-Level Differential Testing of Ethereum\n  Virtual Machine","summary":"As Ethereum continues to thrive, the Ethereum Virtual Machine (EVM) has\nbecome the cornerstone powering tens of millions of active smart contracts.\nIntuitively, security issues in EVMs could lead to inconsistent behaviors among\nsmart contracts or even denial-of-service of the entire blockchain network.\nHowever, to the best of our knowledge, only a limited number of studies focus\non the security of EVMs. Moreover, they suffer from 1) insufficient test input\ndiversity and invalid semantics; and 2) the inability to automatically identify\nbugs and locate root causes. To bridge this gap, we propose OpDiffer, a\ndifferential testing framework for EVM, which takes advantage of LLMs and\nstatic analysis methods to address the above two limitations. We conducted the\nlargest-scale evaluation, covering nine EVMs and uncovering 26 previously\nunknown bugs, 22 of which have been confirmed by developers and three have been\nassigned CNVD IDs. Compared to state-of-the-art baselines, OpDiffer can improve\ncode coverage by at most 71.06%, 148.40% and 655.56%, respectively. Through an\nanalysis of real-world deployed Ethereum contracts, we estimate that 7.21% of\nthe contracts could trigger our identified EVM bugs under certain environmental\nsettings, potentially resulting in severe negative impact on the Ethereum\necosystem.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-16T12:48:00Z"}
{"aid":"http://arxiv.org/abs/2504.12047v1","title":"Non-local Wasserstein Geometry, Gradient Flows, and Functional\n  Inequalities for Stationary Point Processes","summary":"We construct a non-local Benamou-Brenier-type transport distance on the space\nof stationary point processes and analyse the induced geometry. We show that\nour metric is a specific variant of the transport distance recently constructed\nin [DSHS24]. As a consequence, we show that the Ornstein-Uhlenbeck semigroup is\nthe gradient flow of the specific relative entropy w.r.t. the newly constructed\ndistance. Furthermore, we show the existence of stationary geodesics, establish\n$1$-geodesic convexity of the specific relative entropy, and derive stationary\nanalogues of functional inequalities such as a specific HWI inequality and a\nspecific Talagrand inequality. One of the key technical contributions is the\nexistence of solutions to the non-local continuity equation between arbitrary\npoint processes.","main_category":"math.PR","categories":"math.PR","published":"2025-04-16T13:03:48Z"}
{"aid":"http://arxiv.org/abs/2504.12057v1","title":"Pressure-tuned spin chains in brochantite, Cu$_4$SO$_4$(OH)$_6$","summary":"Using high-pressure single-crystal x-ray diffraction combined with\nthermodynamic measurements and density-functional calculations, we uncover the\nmicroscopic magnetic model of the mineral brochantite, Cu$_4$SO$_4$(OH)$_6$,\nand its evolution upon compression. The formation of antiferromagnetic spin\nchains with the effective intrachain coupling of $J\\simeq 100$\\,K is attributed\nto the occurrence of longer Cu--Cu distances and larger Cu--O--Cu bond angles\nbetween the structural chains within the layers of the brochantite structure.\nThese zigzag spin chains are additionally stabilized by ferromagnetic couplings\n$J_2$ between second neighbors and moderately frustrated by several\nantiferromagnetic couplings that manifest themselves in the reduced N\\'eel\ntemperature of the material. Pressure tuning of the brochantite structure keeps\nits monoclinic symmetry unchanged and leads to the growth of antiferromagnetic\n$J$ with the rate of 3.2\\,K/GPa, although this trend is primarily caused by the\nenhanced ferromagnetic couplings $J_2$. Our results show that the nature of\nmagnetic couplings in brochantite and in other layered Cu$^{2+}$ minerals is\ncontrolled by the size of the lattice translation along their structural chains\nand by the extent of the layer buckling.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.other","published":"2025-04-16T13:10:55Z"}
{"aid":"http://arxiv.org/abs/2504.12070v1","title":"A Light Lepton-flavor-violating Flavon: the Messenger of Neutrino Mixing\n  and Muon $g-2$","summary":"In neutrino physics, a class of models with local or global family symmetries\nmay be invoked, and then a flavon field is needed to realize the full neutrino\nmixing. This flavon may shed light on the long-standing muon $g-2$ puzzle. In\nthis work, we explore this idea in the $({B-L})_{13}$ gauge extension to the\nstandard model (SM), in which realistic neutrino mixing requires both a SM\nsinglet flavon $s$ and a vector-like lepton (VLL) doublet. The dominant\ncoupling between the flavon and leptons is in the manner of\nlepton-flavor-violation (LFV). Through an analytical analysis of the SM\nlepton-VLL mixing matrix, we find that the parameter space of the $s\\bar\\mu\ne$-type flavon to explain the muon $g-2$ has been completely excluded by the\nspecific LFV process, muonium-antimuonium oscillation. But the $s\\bar\\mu\n\\tau$-type flavon still has the opportunity; however, it confronts the strong\nconstraint from $\\tau\\to \\mu$ conservation and, in particular, the lepton\nflavor universality test of $Z$ boson decay, which arises due to our way to\nrealize the LFV flavon. The surviving flavon is highly predictable, with mass\nin the narrow window $m_\\tau\\lesssim m_s\\lesssim 1.5~ m_\\tau$ and LFV coupling\nstrength $\\sim 10^{-2}$. Besides, it leaves a TeV scale VLL with a multi-lepton\nsignature at the LHC.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T13:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.12077v1","title":"Coincident onset of charge order and pseudogap in a homogeneous\n  high-temperature superconductor","summary":"Understanding high-temperature superconductivity in cuprates requires\nknowledge of the metallic phase it evolves from, particularly the pseudogap\nprofoundly affecting the electronic properties at low carrier densities. A key\nquestion is the influence of chemical disorder, which is ubiquitous but\nexceedingly difficult to model. Using resonant x-ray scattering, we identified\ntwo-dimensional charge order in stoichiometric YBa$_2$Cu$_4$O$_8$ ($T_c$ = 80\nK), which is nearly free of chemical disorder. The charge order amplitude shows\na concave temperature dependence and vanishes sharply at $T^*$ = 200 K, the\nonset of a prominent pseudogap previously determined by spectroscopy,\nsuggesting a causal link between these phenomena. The gradual onset of charge\norder in other cuprates is thus likely attributable to an inhomogeneous\ndistribution of charge ordering temperatures due to disorder induced by\nchemical substitution. The relationship between the pseudogap and the\ndisorder-induced gradual freeze-out of charge carriers remains a central issue\nin research on high-$T_c$ superconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-16T13:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.12085v1","title":"Semiparametric Causal Discovery and Inference with Invalid Instruments","summary":"Learning causal relationships among a set of variables, as encoded by a\ndirected acyclic graph, from observational data is complicated by the presence\nof unobserved confounders. Instrumental variables (IVs) are a popular remedy\nfor this issue, but most existing methods either assume the validity of all IVs\nor postulate a specific form of relationship, such as a linear model, between\nthe primary variables and the IVs. To overcome these limitations, we introduce\na partially linear structural equation model for causal discovery and inference\nthat accommodates potentially invalid IVs and allows for general dependence of\nthe primary variables on the IVs. We establish identification under this\nsemiparametric model by constructing surrogate valid IVs, and develop a\nfinite-sample procedure for estimating the causal structures and effects.\nTheoretically, we show that our procedure consistently learns the causal\nstructures, yields asymptotically normal estimates, and effectively controls\nthe false discovery rate in edge recovery. Simulation studies demonstrate the\nsuperiority of our method over existing competitors, and an application to\ninferring gene regulatory networks in Alzheimer's disease illustrates its\nusefulness.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-16T13:46:45Z"}
{"aid":"http://arxiv.org/abs/2504.12119v1","title":"Weighted estimates for Multilinear Singular Integrals with Rough Kernels","summary":"We establish weighted norm inequalities for a class of multilinear singular\nintegral operators with rough kernels. Specifically, we consider the\nmultilinear singular integral operator $\\mathcal{L}_\\Omega$ associated with an\nintegrable function $\\Omega$ on the unit sphere $\\mathbb{S}^{mn-1}$ satisfying\nthe vanishing mean condition. Extending the classical results of Watson and\nDuoandikoetxea to the multilinear setting, we prove that $\\mathcal{L}_\\Omega$\nis bounded from $L^{p_1}(w_1)\\times\\cdots\\times L^{p_m}(w_m)$ to\n$L^p(v_{\\vec{\\boldsymbol{w}}})$ under the assumption that $\\Omega\\in\nL^q(\\mathbb{S}^{mn-1})$ and that the $m$ tuple of weights\n$\\vec{\\boldsymbol{w}}= (w_1,\\ldots,w_m)$ lies in the multiple weight class\n$A_{\\vec{\\boldsymbol{p}}/q'}((\\mathbb{R}^n)^m)$. Here, $q'$ denotes the\nH\\\"older conjugate of $q$, and we assume $q'\\le p_1,\\dots,p_m<\\infty$ with $1/p\n= 1/p_1 + \\cdots + 1/p_m$.","main_category":"math.CA","categories":"math.CA","published":"2025-04-16T14:33:04Z"}
{"aid":"http://arxiv.org/abs/2504.12132v1","title":"Weakly Semi-supervised Whole Slide Image Classification by Two-level\n  Cross Consistency Supervision","summary":"Computer-aided Whole Slide Image (WSI) classification has the potential to\nenhance the accuracy and efficiency of clinical pathological diagnosis. It is\ncommonly formulated as a Multiple Instance Learning (MIL) problem, where each\nWSI is treated as a bag and the small patches extracted from the WSI are\nconsidered instances within that bag. However, obtaining labels for a large\nnumber of bags is a costly and time-consuming process, particularly when\nutilizing existing WSIs for new classification tasks. This limitation renders\nmost existing WSI classification methods ineffective. To address this issue, we\npropose a novel WSI classification problem setting, more aligned with clinical\npractice, termed Weakly Semi-supervised Whole slide image Classification\n(WSWC). In WSWC, a small number of bags are labeled, while a significant number\nof bags remain unlabeled. The MIL nature of the WSWC problem, coupled with the\nabsence of patch labels, distinguishes it from typical semi-supervised image\nclassification problems, making existing algorithms for natural images\nunsuitable for directly solving the WSWC problem. In this paper, we present a\nconcise and efficient framework, named CroCo, to tackle the WSWC problem\nthrough two-level Cross Consistency supervision. CroCo comprises two\nheterogeneous classifier branches capable of performing both instance\nclassification and bag classification. The fundamental idea is to establish\ncross-consistency supervision at both the bag-level and instance-level between\nthe two branches during training. Extensive experiments conducted on four\ndatasets demonstrate that CroCo achieves superior bag classification and\ninstance classification performance compared to other comparative methods when\nlimited WSIs with bag labels are available. To the best of our knowledge, this\npaper presents for the first time the WSWC problem and gives a successful\nresolution.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T14:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.12162v1","title":"Spectral Analysis for Gaussian Quantum Markov Semigroups","summary":"We investigate the spectrum of the generator induced on the space of\nHilbert-Schmidt operators by a Gaussian quantum Markov semigroup with a\nfaithful normal invariant state in the general case, without any symmetry or\nquantum detailed balance assumptions. We prove that the eigenvalues are\nentirely determined by those of the drift matrix, similarly to classical\nOrnstein-Uhlenbeck semigroups. This result is established using a\nquasi-derivation property of the generator. Moreover, the same spectral\nproperty holds for the adjoint of the induced generator. Finally, we show that\nthese eigenvalues constitute the entire spectrum when the induced generator has\na spectral gap.","main_category":"math.FA","categories":"math.FA","published":"2025-04-16T15:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.12196v1","title":"Loose paths in random ordered hypergraphs","summary":"We consider the length of {\\em ordered loose paths} in the random $r$-uniform\nhypergraph $H=H^{(r)}(n, p)$. A ordered loose path is a sequence of edges\n$E_1,E_2,\\ldots,E_\\ell$ where $\\max\\{j\\in E_i\\}=\\min\\{j\\in E_{i+1}\\}$ for\n$1\\leq i<\\ell$. We establish fairly tight bounds on the length of the longest\nordered loose path in $H$ that hold with high probability.","main_category":"math.CO","categories":"math.CO","published":"2025-04-16T15:48:06Z"}
{"aid":"http://arxiv.org/abs/2504.12202v1","title":"Correlations as a resource in molecular switches","summary":"Photoisomerization, a photochemical process underlying many biological\nmechanisms, has been modeled recently within the quantum resource theory of\nthermodynamics. This approach has emerged as a promising tool for studying\nfundamental limitations to nanoscale processes independently of the microscopic\ndetails governing their dynamics. On the other hand, correlations between\nphysical systems have been shown to play a crucial role in quantum\nthermodynamics by lowering the work cost of certain operations. Here, we\nexplore quantitatively how correlations between multiple photoswitches can\nenhance the efficiency of photoisomerization beyond that attainable for single\nmolecules. Furthermore, our analysis provides insights into the interplay\nbetween quantum and classical correlations in these transformations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T15:52:59Z"}
{"aid":"http://arxiv.org/abs/2504.12230v1","title":"Suppression of composition g-modes in chemically-equilibrating warm\n  neutron stars","summary":"We investigate the impact of chemical equilibration and the resulting bulk\nviscosity on non-radial oscillation modes of warm neutron stars at temperatures\nup to T~5 MeV, relevant for protoneutron stars and neutron-star post-merger\nremnants. In this regime, the relaxation rate of weak interactions becomes\ncomparable to the characteristic frequencies of composition g-modes in the\ncore, resulting in resonant damping. To capture this effect, we introduce the\ndynamic sound speed, a complex, frequency-dependent generalization of the\nadiabatic sound speed that encodes both the restoring force and the dissipative\neffects of bulk compression. Using realistic weak reaction rates and three\nrepresentative equations of state, we compute the complex frequencies of\ncomposition g-modes with finite-temperature profiles. We find that bulk viscous\ndamping becomes increasingly significant with temperature and can completely\nsuppress composition g-modes. In contrast, the f-mode remains largely\nunaffected by bulk viscosity due to its nearly divergence-free character. Our\nresults highlight the sensitivity of g-mode behavior to thermal structure, weak\nreaction rates, and the equation of state, and establish the dynamic sound\nspeed as a valuable descriptor characterizing oscillation properties in\ndissipative neutron star matter.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,nucl-th","published":"2025-04-16T16:27:50Z"}
{"aid":"http://arxiv.org/abs/2504.12242v1","title":"On $p$-adic congruences involving $\\sqrt d$","summary":"Let $p$ be an odd prime and let $d$ be an integer not divisible by $p$. We\nprove that $$ \\prod_{1\\le m,n\\le p-1\\atop p\\nmid m^2-dn^2}\\ (x-(m+n\\sqrt{d}))\n\\equiv \\begin{cases}\\sum_{k=1}^{p-2}\\frac{k(k+1)}2x^{(k-1)(p-1)}\\pmod p\n&\\text{if}\\ (\\frac dp)=1,\\\\\\sum_{k=0}^{(p-1)/2}x^{2k(p-1)} \\pmod p&\\text {if}\\\n(\\frac dp)=-1, \\end{cases}$$ where $(\\frac dp)$ denotes the Legendre symbol.\nThis extends a recent conjecture of N. Kalinin. We also obtain the\nWolstenholme-type congruence $$\\sum_{1\\le m,n\\le p-1\\atop p\\nmid m^2-dn^2}\\ \\\n\\frac1{m+n\\sqrt d}\\equiv0\\pmod{p^2}.$$","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T16:47:10Z"}
{"aid":"http://arxiv.org/abs/2504.12258v1","title":"Experimental Analysis of Multipath Characteristics in Indoor Distributed\n  Massive MIMO Channels","summary":"Distributed massive multiple-input multiple-output (MIMO), also known as\ncell-free massive MIMO, has emerged as a promising technology for\nsixth-generation (6G) wireless networks. This letter introduces an indoor\nchannel measurement campaign designed to explore the behavior of multipath\ncomponents (MPCs) in distributed massive MIMO channels. Fully coherent channels\nwere measured between eight distributed uniform planar arrays (128 elements in\ntotal) and a 12-meter user equipment route. Furthermore, a method is introduced\nto determine the order (single- or multi-bounce) of MPC interaction by\nleveraging map information and MPC parameters. In addition, a Kalman\nfilter-based framework is used for identifying the MPC interaction mechanisms\n(reflection or scattering/diffraction/mixed). Finally, a comprehensive\nMPC-level characterization is performed based on the measured channels,\nincluding the significance of the single-bounce MPCs, the spherical wavefront\nfeatures, the birth-and-death processes of the MPCs, and the spatial\ndistribution of reflections. The findings serve as a valuable reference for\nunderstanding MPC propagation behavior, which is necessary for accurate\nmodeling of indoor distributed massive MIMO channels.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T17:08:12Z"}
{"aid":"http://arxiv.org/abs/2504.12273v1","title":"Beyond Reconstruction: A Physics Based Neural Deferred Shader for\n  Photo-realistic Rendering","summary":"Deep learning based rendering has demonstrated major improvements for\nphoto-realistic image synthesis, applicable to various applications including\nvisual effects in movies and photo-realistic scene building in video games.\nHowever, a significant limitation is the difficulty of decomposing the\nillumination and material parameters, which limits such methods to reconstruct\nan input scene, without any possibility to control these parameters. This paper\nintroduces a novel physics based neural deferred shading pipeline to decompose\nthe data-driven rendering process, learn a generalizable shading function to\nproduce photo-realistic results for shading and relighting tasks, we also\nprovide a shadow estimator to efficiently mimic shadowing effect. Our model\nachieves improved performance compared to classical models and a state-of-art\nneural shading model, and enables generalizable photo-realistic shading from\narbitrary illumination input.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T17:32:50Z"}
{"aid":"http://arxiv.org/abs/2504.12607v1","title":"Solving Constrained Combinatorial Optimization Problems with Variational\n  Quantum Imaginary Time Evolution","summary":"Solving combinatorial optimization problems using variational quantum\nalgorithms (VQAs) has emerged as a promising research direction. Since the\nintroduction of the Quantum Approximate Optimization Algorithm (QAOA), numerous\nvariants have been proposed to enhance its performance. QAOA was later extended\nto the Quantum Alternating Operator Ansatz (QAOA+), which generalizes the\ninitial state, phase-separation operator, and mixer to address constrained\nproblems without relying on the standard Quadratic Unconstrained Binary\nOptimization (QUBO) formulation. However, QAOA+ often requires additional\nancilla qubits and a large number of multi-controlled Toffoli gates to prepare\nthe superposition of feasible states, resulting in deep circuits that are\nchallenging for near-term quantum devices. Furthermore, VQAs are generally\nhindered by issues such as barren plateaus and suboptimal local minima.\nRecently, Quantum Imaginary Time Evolution (QITE), a ground-state preparation\nalgorithm, has been explored as an alternative to QAOA and its variants. QITE\nhas demonstrated improved performance in quantum chemistry problems and has\nbeen applied to unconstrained combinatorial problems such as Max-Cut. In this\nwork, we apply the variational form of QITE (VarQITE) to solve the Multiple\nKnapsack Problem (MKP), a constrained problem, using a Max-Cut-tailored ansatz.\nTo the best of our knowledge, this is the first attempt to address constrained\noptimization using VarQITE. We show that VarQITE achieves significantly lower\nmean optimality gaps compared to QAOA and other conventional methods. Moreover,\nwe demonstrate that scaling the Hamiltonian coefficients can further reduce\noptimization costs and accelerate convergence.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T03:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.12612v1","title":"The Chronicles of Foundation AI for Forensics of Multi-Agent Provenance","summary":"Provenance is the chronology of things, resonating with the fundamental\npursuit to uncover origins, trace connections, and situate entities within the\nflow of space and time. As artificial intelligence advances towards autonomous\nagents capable of interactive collaboration on complex tasks, the provenance of\ngenerated content becomes entangled in the interplay of collective creation,\nwhere contributions are continuously revised, extended or overwritten. In a\nmulti-agent generative chain, content undergoes successive transformations,\noften leaving little, if any, trace of prior contributions. In this study, we\ninvestigates the problem of tracking multi-agent provenance across the temporal\ndimension of generation. We propose a chronological system for post hoc\nattribution of generative history from content alone, without reliance on\ninternal memory states or external meta-information. At its core lies the\nnotion of symbolic chronicles, representing signed and time-stamped records, in\na form analogous to the chain of custody in forensic science. The system\noperates through a feedback loop, whereby each generative timestep updates the\nchronicle of prior interactions and synchronises it with the synthetic content\nin the very act of generation. This research seeks to develop an accountable\nform of collaborative artificial intelligence within evolving cyber ecosystems.","main_category":"cs.AI","categories":"cs.AI,cs.CR,cs.MA","published":"2025-04-17T03:23:17Z"}
{"aid":"http://arxiv.org/abs/2504.12643v1","title":"RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating\n  Enhanced Rotary Position Embedding","summary":"This technical report introduces a targeted improvement to the StreamPETR\nframework, specifically aimed at enhancing velocity estimation, a critical\nfactor influencing the overall NuScenes Detection Score. While StreamPETR\nexhibits strong 3D bounding box detection performance as reflected by its high\nmean Average Precision our analysis identified velocity estimation as a\nsubstantial bottleneck when evaluated on the NuScenes dataset. To overcome this\nlimitation, we propose a customized positional embedding strategy tailored to\nenhance temporal modeling capabilities. Experimental evaluations conducted on\nthe NuScenes test set demonstrate that our improved approach achieves a\nstate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a new\nbenchmark for camera-only 3D object detection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T05:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.12656v1","title":"Spherical collapse in DHOST theories and EFT of dark energy","summary":"We study the nonlinear evolution of matter overdensities using the spherical\ncollapse model in degenerate higher-order scalar-tensor (DHOST) theories beyond\nHorndeski, employing the effective field theory (EFT) of dark energy approach.\nWe investigate the impact of the EFT parameters characterising DHOST theories\non the formation of large-scale structure. We identify the parameter space in\nwhich the collapse of the spherical overdensity is prevented by the scalar\nfield turning imaginary at some moment, which allows us to place constraints on\nthe model parameters. We show how the collapse time and the critical density\ncontrast depend on the EFT parameters. To assess the observational\nimplications, we compute the halo mass function using the Press-Schechter\nformalism. We find that the number density of halos is suppressed compared to\nthe $\\Lambda$CDM model due to ``beyond Horndeski'' effects, upon imposing the\nstability of linear perturbations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-17T05:33:55Z"}
{"aid":"http://arxiv.org/abs/2504.12762v1","title":"Testing the Star-disk Collision Model for Quasi-periodic Eruptions","summary":"Quasi-periodic eruptions (QPEs), the repeated outbursts observed in soft\nX-ray bands, have attracted broad interest, but their physical origin is under\ndebate. One of the popular models, the star-disk collision model, suggests that\nQPEs can be produced through periodic collisions of an orbiting star with the\naccretion disk of a central black hole (BH). However, previous tests of the\nstar-disk collision model mainly focus on the timing analysis. Other observed\nproperties, such as peak luminosities $L_{\\rm{p}}$, durations $t_{\\rm{e}}$, and\nradiation temperatures $T_{\\rm{p}}$ of the eruptions, are not systematically\ninvestigated. For a sample of six QPE sources and two QPE-like sources, we test\nthe star-disk collision model by using these observables to derive the\nconstraints on the stellar radius $R_*$. We find that, except for two sources\n(eRo-QPE3 and eRo-QPE4), the rest of the sample either has no allowed $R_*$ to\nsimultaneously reproduce the observed $L_{\\rm{p}}$ and $t_{\\rm{e}}$, or the\nrequired $R_*$ is too large to avoid being disrupted by the central BH. For the\ntwo exceptions, a stellar radius of the order of $1\\ R_{\\rm{\\odot}}$ is\nnecessary to satisfy all the constraints. Another issue with the simplest\nversion of this model is that it predicts $k T_{\\rm{p}} \\sim 10\\ \\rm{eV}$, one\norder of magnitude lower than the observed value.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA,astro-ph.SR,hep-ph","published":"2025-04-17T09:00:00Z"}
{"aid":"http://arxiv.org/abs/2504.12771v1","title":"Classification-Based Analysis of Price Pattern Differences Between\n  Cryptocurrencies and Stocks","summary":"Cryptocurrencies are digital tokens built on blockchain technology, with\nthousands actively traded on centralized exchanges (CEXs). Unlike stocks, which\nare backed by real businesses, cryptocurrencies are recognized as a distinct\nclass of assets by researchers. How do investors treat this new category of\nasset in trading? Are they similar to stocks as an investment tool for\ninvestors? We answer these questions by investigating cryptocurrencies' and\nstocks' price time series which can reflect investors' attitudes towards the\ntargeted assets. Concretely, we use different machine learning models to\nclassify cryptocurrencies' and stocks' price time series in the same period and\nget an extremely high accuracy rate, which reflects that cryptocurrency\ninvestors behave differently in trading from stock investors. We then extract\nfeatures from these price time series to explain the price pattern difference,\nincluding mean, variance, maximum, minimum, kurtosis, skewness, and first to\nthird-order autocorrelation, etc., and then use machine learning methods\nincluding logistic regression (LR), random forest (RF), support vector machine\n(SVM), etc. for classification. The classification results show that these\nextracted features can help to explain the price time series pattern difference\nbetween cryptocurrencies and stocks.","main_category":"q-fin.ST","categories":"q-fin.ST","published":"2025-04-17T09:12:27Z"}
{"aid":"http://arxiv.org/abs/2504.12774v1","title":"Phase field model of Coulomb explosion damage in solid induced by\n  ultrashort laser","summary":"Much experimental evidence reveals that Coulomb explosion governs non-thermal\nmaterial removal under femtosecond or even shorter laser pulses, and\nnon-thermal laser damage has been a topic widely discussed. Nevertheless, there\nis still no continuum mechanical model capable of describing the evolution of\nsuch damage. In this study, we develop a model that characterizes solid damage\nthrough a phase field variable governed by Allen-Cahn dynamics. The parameter\nof the model is defined by a conceptual mechanism: during Coulomb explosion,\nelectron pressure surpasses the interatomic barrier potential, dissociates\nmaterial from the solid surface as small equivalent particles and resulting in\nlocalized damage. The numerical simulation validates the model's availability\nand demonstrate its ability to predict damage morphology under varying laser\nconditions. This work advances the understanding of non-thermal ablation and\nprovides a tool for optimizing ultrafast laser processing.","main_category":"physics.optics","categories":"physics.optics,cond-mat.other,physics.comp-ph","published":"2025-04-17T09:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.12775v1","title":"Linear ordinary differential equations constrained Gaussian Processes\n  for solving optimal control problems","summary":"This paper presents an intrinsic approach for addressing control problems\nwith systems governed by linear ordinary differential equations (ODEs). We use\ncomputer algebra to constrain a Gaussian Process on solutions of ODEs. We\nobtain control functions via conditioning on datapoints. Our approach thereby\nconnects Algebra, Functional Analysis, Machine Learning and Control theory. We\ndiscuss the optimality of the control functions generated by the posterior mean\nof the Gaussian Process. We present numerical examples which underline the\npracticability of our approach.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T09:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.12781v1","title":"Hexagonal and k-hexagonal graph's normalized Laplacian spectrum and\n  applications","summary":"Substituting each edge of a simple connected graph $G$ by a path of length 1\nand $k$ paths of length 5 generates the $k$-hexagonal graph $H^k(G)$. Iterative\ngraph $H^k_n(G)$ is produced when the preceding constructions are repeated $n$\ntimes. According to the graph structure, we obtain a set of linear equations,\nand derive the entirely normalized Laplacian spectrum of $H^k_n(G)$ when $k =\n1$ and $k \\geqslant 2$ respectively by analyzing the structure of the solutions\nof these linear equations. We find significant formulas to calculate the\nKemeny's constant, multiplicative degree-Kirchhoff index and number of spanning\ntrees of $H^k_n(G)$ as applications.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T09:27:36Z"}
{"aid":"http://arxiv.org/abs/2504.12797v1","title":"Status of the Proton EDM Experiment (pEDM)","summary":"The Proton EDM Experiment (pEDM) is the first direct search for the proton\nelectric dipole moment (EDM) with the aim of being the first experiment to\nprobe the Standard Model (SM) prediction of any particle EDM. Phase-I of pEDM\nwill achieve $10^{-29} e\\cdot$cm, improving current indirect limits by four\norders of magnitude. This will establish a new standard of precision in nucleon\nEDM searches and offer a unique sensitivity to better understand the Strong CP\nproblem. The experiment is ideally positioned to explore physics beyond the\nStandard Model (BSM), with sensitivity to axionic dark matter via the signal of\nan oscillating proton EDM and across a wide mass range of BSM models from\n$\\mathcal{O}(1\\text{GeV})$ to $\\mathcal{O}(10^3\\text{TeV})$. Utilizing the\nfrozen-spin technique in a highly symmetric storage ring that leverages\nexisting infrastructure at Brookhaven National Laboratory (BNL), pEDM builds\nupon the technological foundation and experimental expertise of the highly\nsuccessful Muon $g$$-$$2$ Experiments. With significant R\\&D and prototyping\nalready underway, pEDM is preparing a conceptual design report (CDR) to offer a\ncost-effective, high-impact path to discovering new sources of CP violation and\nadvancing our understanding of fundamental physics. It will play a vital role\nin complementing the physics goals of the next-generation collider while\nsimultaneously contributing to sustaining particle physics research and\ntraining early career researchers during gaps between major collider\noperations.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-17T09:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.12799v1","title":"TSGS: Improving Gaussian Splatting for Transparent Surface\n  Reconstruction via Normal and De-lighting Priors","summary":"Reconstructing transparent surfaces is essential for tasks such as robotic\nmanipulation in labs, yet it poses a significant challenge for 3D\nreconstruction techniques like 3D Gaussian Splatting (3DGS). These methods\noften encounter a transparency-depth dilemma, where the pursuit of\nphotorealistic rendering through standard $\\alpha$-blending undermines\ngeometric precision, resulting in considerable depth estimation errors for\ntransparent materials. To address this issue, we introduce Transparent Surface\nGaussian Splatting (TSGS), a new framework that separates geometry learning\nfrom appearance refinement. In the geometry learning stage, TSGS focuses on\ngeometry by using specular-suppressed inputs to accurately represent surfaces.\nIn the second stage, TSGS improves visual fidelity through anisotropic specular\nmodeling, crucially maintaining the established opacity to ensure geometric\naccuracy. To enhance depth inference, TSGS employs a first-surface depth\nextraction method. This technique uses a sliding window over $\\alpha$-blending\nweights to pinpoint the most likely surface location and calculates a robust\nweighted average depth. To evaluate the transparent surface reconstruction task\nunder realistic conditions, we collect a TransLab dataset that includes complex\ntransparent laboratory glassware. Extensive experiments on TransLab show that\nTSGS achieves accurate geometric reconstruction and realistic rendering of\ntransparent objects simultaneously within the efficient 3DGS framework.\nSpecifically, TSGS significantly surpasses current leading methods, achieving a\n37.3% reduction in chamfer distance and an 8.0% improvement in F1 score\ncompared to the top baseline. The code and dataset will be released at\nhttps://longxiang-ai.github.io/TSGS/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T10:00:09Z"}
{"aid":"http://arxiv.org/abs/2504.12807v1","title":"Hybrid Dense-UNet201 Optimization for Pap Smear Image Segmentation Using\n  Spider Monkey Optimization","summary":"Pap smear image segmentation is crucial for cervical cancer diagnosis.\nHowever, traditional segmentation models often struggle with complex cellular\nstructures and variations in pap smear images. This study proposes a hybrid\nDense-UNet201 optimization approach that integrates a pretrained DenseNet201 as\nthe encoder for the U-Net architecture and optimizes it using the spider monkey\noptimization (SMO) algorithm. The Dense-UNet201 model excelled at feature\nextraction. The SMO was modified to handle categorical and discrete parameters.\nThe SIPaKMeD dataset was used in this study and evaluated using key performance\nmetrics, including loss, accuracy, Intersection over Union (IoU), and Dice\ncoefficient. The experimental results showed that Dense-UNet201 outperformed\nU-Net, Res-UNet50, and Efficient-UNetB0. SMO Dense-UNet201 achieved a\nsegmentation accuracy of 96.16%, an IoU of 91.63%, and a Dice coefficient score\nof 95.63%. These findings underscore the effectiveness of image preprocessing,\npretrained models, and metaheuristic optimization in improving medical image\nanalysis and provide new insights into cervical cell segmentation methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T10:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.12809v1","title":"Saliency-Aware Diffusion Reconstruction for Effective Invisible\n  Watermark Removal","summary":"As digital content becomes increasingly ubiquitous, the need for robust\nwatermark removal techniques has grown due to the inadequacy of existing\nembedding techniques, which lack robustness. This paper introduces a novel\nSaliency-Aware Diffusion Reconstruction (SADRE) framework for watermark\nelimination on the web, combining adaptive noise injection, region-specific\nperturbations, and advanced diffusion-based reconstruction. SADRE disrupts\nembedded watermarks by injecting targeted noise into latent representations\nguided by saliency masks although preserving essential image features. A\nreverse diffusion process ensures high-fidelity image restoration, leveraging\nadaptive noise levels determined by watermark strength. Our framework is\ntheoretically grounded with stability guarantees and achieves robust watermark\nremoval across diverse scenarios. Empirical evaluations on state-of-the-art\n(SOTA) watermarking techniques demonstrate SADRE's superiority in balancing\nwatermark disruption and image quality. SADRE sets a new benchmark for\nwatermark elimination, offering a flexible and reliable solution for real-world\nweb content. Code is available\non~\\href{https://github.com/inzamamulDU/SADRE}{\\textbf{https://github.com/inzamamulDU/SADRE}}.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-17T10:15:10Z"}
{"aid":"http://arxiv.org/abs/2504.12836v1","title":"Inverse iteration method for higher eigenvalues of the $p$-Laplacian","summary":"We propose a characterization of a $p$-Laplace higher eigenvalue based on the\ninverse iteration method with balancing the Rayleigh quotients of the positive\nand negative parts of solutions to consecutive $p$-Poisson equations. The\napproach relies on the second eigenvalue's minimax properties, but the actual\nlimiting eigenvalue depends on the choice of initial function. The\nwell-posedness and convergence of the iterative scheme are proved. Moreover, we\nprovide the corresponding numerical computations. As auxiliary results, which\nalso have an independent interest, we provide several properties of certain\n$p$-Poisson problems.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA,math.SP","published":"2025-04-17T10:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.12872v1","title":"On perfect sampling: ROCFTP with Metropolis-multishift coupler","summary":"ROCFTP is a perfect sampling algorithm that employs various random\noperations, and requiring a specific Markov chain construction for each target.\nTo overcome this requirement, the Metropolis algorithm is incorporated as a\nrandom operation within ROCFTP. While the Metropolis sampler functions as a\nrandom operation, it isn't a coupler. However, by employing normal multishift\ncoupler as a symmetric proposal for Metropolis, we obtain ROCFTP with\nMetropolis-multishift. Initially designed for bounded state spaces, ROCFTP's\napplicability to targets with unbounded state spaces is extended through the\nintroduction of the Most Interest Range (MIR) for practical use. It was\ndemonstrated that selecting MIR decreases the likelihood of ROCFTP hitting\n$MIR^C$ by a factor of (1 - {\\epsilon}), which is beneficial for practical\nimplementation. The algorithm exhibits a convergence rate characterized by\nexponential decay. Its performance is rigorously evaluated across various\ntargets, and tests ensure its goodness of fit. Lastly, an R package is provided\nfor generating exact samples using ROCFTP Metropolis-multishift.","main_category":"stat.CO","categories":"stat.CO,math.ST,stat.ME,stat.TH","published":"2025-04-17T12:00:03Z"}
{"aid":"http://arxiv.org/abs/2504.12884v1","title":"TOI-3493 b: A planet with a Neptune-like density transiting a bright\n  G0-type star","summary":"We report the discovery of TOI-3493 b, a sub-Neptune-sized planet on an\n8.15-d orbit transiting the bright (V=9.3) G0 star HD 119355 (aka TIC\n203377303) initially identified by NASA's TESS space mission. With the aim of\nconfirming the planetary nature of the transit signal detected by TESS and\ndetermining the mass of the planet, we performed an intensive Doppler campaign\nwith the HARPS spectrograph, collecting radial velocity measurements. We found\nthat TOI-3493 b lies in a nearly circular orbit and has a mass of 9.0+/-1.2\nM_earth and a radius of 3.22+/-0.08 R_earth, implying a bulk density of\n1.47+/-0.23 g/cm^3, consistent with a composition comprising a small solid core\nsurrounded by a thick H/He dominated atmosphere.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-17T12:20:27Z"}
{"aid":"http://arxiv.org/abs/2504.12935v1","title":"Dynamical relationship between CAR algebras and determinantal point\n  processes: point processes at finite temperature and stochastically positive\n  KMS systems","summary":"The aim of this paper is threefold. Firstly, we develop the author's previous\nwork on the dynamical relationship between determinantal point processes and\nCAR algebras. Secondly, we present a novel application of the theory of\nstochastic processes associated with KMS states for CAR algebras and their\nquasi-free states. Lastly, we propose a unified theory of algebraic\nconstructions and analysis of stationary processes on point configuration\nspaces with respect to determinantal point processes. As a byproduct, we\nestablish an algebraic derivation of a determinantal formula for space-time\ncorrelations of stochastic processes, and we analyze several limiting behaviors\nof these processes.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP,math.OA","published":"2025-04-17T13:31:09Z"}
{"aid":"http://arxiv.org/abs/2504.12936v1","title":"Relative magnetic helicity under turbulent relaxation","summary":"Magnetic helicity is a quantity that underpins many theories of magnetic\nrelaxation in electrically conducting fluids, both laminar and turbulent.\nAlthough much theoretical effort has been expended on magnetic fields that are\neverywhere tangent to their domain boundaries, many applications, both in\nastrophysics and laboratories, actually involve magnetic fields that are\nline-tied to the boundary, i.e. with a non-trivial normal component on the\nboundary. This modification of the boundary condition requires a modification\nof magnetic helicity, whose suitable replacement is called relative magnetic\nhelicity. In this work, we investigate rigorously the behaviour of relative\nmagnetic helicity under turbulent relaxation. In particular, we specify the\nnormal component of the magnetic field on the boundary and consider the\n\\emph{ideal limit} of resistivity tending to zero in order to model the\nturbulent evolution in the sense of Onsager's theory of turbulence. We show\nthat relative magnetic helicity is conserved in this distinguished limit and\nthat, for constant viscosity, the magnetic field can relax asymptotically to a\nmagnetohydrostatic equilibrium.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,math.AP","published":"2025-04-17T13:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.12954v1","title":"Phenomenology of Inverse Seesaw Using $S_3$ Modular Symmetry","summary":"Describing neutrino masses using the inverse seesaw mechanism with discrete\nflavor symmetry imposed through modular forms provides a testable framework at\nTeV scales with fewer parameters. However, $S_3$, the smallest modular group,\nremains relatively underexplored. In this work, we construct the minimal\nsupersymmetric inverse seesaw model based on the modular $S_3$ flavor symmetry.\nIn our model, the light neutrino mass matrix depends on 6 real parameters: the\ncomplex modulus, an overall scale for light neutrino mass, a real ratio and a\ncomplex ratio of Yukawa coupling. Thanks to its minimality, our model offers\nvarious definite predictions: the lightest neutrino is massless, the neutrino\nmasses are inverted ordering, the sum of the three light neutrino masses\n($\\sum_i m_i$) is 100 meV, the effective mass for the end point of the beta\ndecay spectrum is 50 meV, the effective mass for neutrinoless double beta decay\n($m_{ee}$) is in the range $38-58$ meV. In particular, the predicted values for\n$\\sum_i m_i$ and $m_{ee}$ from our model are within reach of the next\ngeneration experiments. Our model also predicts radiative lepton flavor\nviolating decays $\\ell\\to\\ell'\\gamma$ which are compatible with experimental\nconstraints.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T13:58:43Z"}
{"aid":"http://arxiv.org/abs/2504.12957v1","title":"Cavity-enhanced spectroscopy of individual nuclear spins in a dense bath","summary":"Echo-based spectroscopy of the superhyperfine interaction of an electronic\nspin with nuclear spins in its surroundings enables detailed insights into the\nmicroscopic magnetic environment of spins in solids. Still, it is an\noutstanding challenge to resolve individual nuclear spins in a dense bath, in\nwhich many of them exhibit a comparable coupling strength. This simultaneously\nrequires a high spectral resolution and a large signal-to-noise ratio. However,\nwhen probing spin ensembles, dipolar interactions between the dopants can lead\nto a concentration-dependent trade-off between resolution and signal. Here, we\nfully eliminate this limitation of previous optical-echo-envelope-modulation\nspectroscopy experiments by integrating the emitters into a high-finesse\nresonator, which allows for strong optical echoes even at very low\nconcentrations. To demonstrate its potential, the technique is applied to\nerbium dopants in yttrium-orthosilicate (Er:YSO). Achieving an unprecedented\nspectral resolution enables precise measurements of the superhyperfine\ninteraction with four of the Y nuclear spins densely surrounding each emitter.\nThe achieved boost of the signal, enabled by the resonator, allows for\nextending the approach to the lowest concentration possible -- to the level of\nsingle dopants, thereby providing a tool for detecting and studying individual\nnuclear spins. Thus, our technique paves the way for an improved understanding\nof dense nuclear spin baths in solids.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other","published":"2025-04-17T14:03:10Z"}
{"aid":"http://arxiv.org/abs/2504.12962v1","title":"Astronomical Refutation of the New Chronology by Fomenko and Nosovsky:\n  The 1151-Year Planetary Cycle and Dating of the Almagest via Speed/Error\n  Correlation","summary":"This paper introduces two astronomical methods developed through\ncomputational simulation to evaluate the historical dating of ancient\nastronomical sources. The first identifies a 1151-year planetary cycle based on\nthe recurrence of visible configurations of Mercury to Saturn, including the\nSun and Moon, from a geocentric perspective. The second, called SESCC\n(Speed-Error Signals Cross Correlation), statistically estimates the epoch of\nstar catalogs by analyzing the correlation between positional error and proper\nmotion in ecliptic latitude. Both methods are reproducible, data-driven, and\nyield results that contradict key tenets of the New Chronology proposed by\nFomenko and Nosovsky, most notably the claim that the Anno Domini began in 1152\nCE. Open-source code and analysis tools are provided for independent\nverification.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,physics.hist-ph","published":"2025-04-17T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.12975v1","title":"Computing $n$-time correlation functions without ancilla qubits","summary":"The $n$-time correlation function is pivotal for establishing connections\nbetween theoretical predictions and experimental observations of a quantum\nsystem. Conventional methods for computing $n$-time correlation functions on\nquantum computers, such as the Hadamard test, generally require an ancilla\nqubit that controls the entire system -- an approach that poses challenges for\ndigital quantum devices with limited qubit connectivity, as well as for analog\nquantum platforms lacking controlled operations. Here, we introduce a method to\ncompute $n$-time correlation functions using only unitary evolutions on the\nsystem of interest, thereby eliminating the need for ancillas and the control\noperations. This approach substantially relaxes hardware connectivity\nrequirements for digital processors and enables more practical measurements of\n$n$-time correlation functions on analog platforms. We demonstrate our protocol\non IBM quantum hardware up to 12 qubits to measure fermionic and bosonic\nsingle-particle spectra of the Su-Schrieffer-Heeger model and the Schwinger\nmodel, respectively, and the out-of-time-order correlator in the\ntransverse-field Ising model. In the experiment, we further introduce a\nsignal-processing strategy that integrates signal filtering and correlation\nanalysis, and successfully reproduces the noiseless simulation results from the\nnoisy hardware. Our work highlights a route to exploring complex quantum\nmany-body correlation functions in practice, even in the presence of realistic\nhardware limitations and noise.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T14:27:23Z"}
{"aid":"http://arxiv.org/abs/2504.13003v1","title":"Towards Optimal Distributed Edge Coloring with Small Palettes","summary":"We design a deterministic distributed $\\mathcal{O}(\\log n)$-round reduction\nfrom the $(2\\Delta-2)$-edge coloring problem to the much easier\n$(2\\Delta-1)$-edge coloring problem. This is almost optimal, as the\n$(2\\Delta-2)$-edge coloring problem admits an $\\Omega(\\log_\\Delta n)$ lower\nbound. Further, we also obtain an optimal $\\mathcal{O}(\\log_\\Delta n)$-round\nreduction, albeit to the harder maximal independent set (MIS) problem.\n  The current state-of-the-art for $(2\\Delta - 1)$-edge coloring actually comes\nfrom an MIS algorithm by [Ghaffari \\& Grunau, FOCS'24], which runs in\n$\\widetilde{\\mathcal{O}}(\\log^{5/3} n)$ rounds. With our new reduction, this\nround complexity now carries over to the $(2\\Delta - 2)$-edge coloring problem\nas well. Alternatively, one can also plug in the $(\\mathrm{poly} \\log \\Delta +\n\\mathcal{O}(\\log^{\\ast} n))$-round $(2\\Delta - 1)$-edge coloring algorithm from\n[Balliu, Brandt, Kuhn \\& Olivetti, PODC'22], which yields an optimal runtime of\n$\\mathcal{O}(\\log n)$ rounds for $\\Delta \\leq \\mathrm{poly} \\log n$.\nPreviously, the fastest deterministic algorithm using less than $2\\Delta - 1$\ncolors for general graphs by [Brandt, Maus, Narayanan, Schager \\& Uitto,\nSODA'25] ran in $\\widetilde{\\mathcal{O}}(\\log^3 n)$ rounds. In addition, we\nalso obtain a $\\mathcal{O}(\\log \\log n)$-round randomized reduction of\n$(2\\Delta - 2)$-edge coloring to $(2\\Delta - 1)$-edge coloring. This improves\nupon the (very recent) best randomized algorithm using less than $2\\Delta - 1$\ncolors from [Bourreau, Brandt \\& Nolin, STOC'25] by reducing the round\ncomplexity from $\\widetilde{\\mathcal{O}}(\\log^{8/3}\\log n)$ down to\n$\\widetilde{\\mathcal{O}}(\\log^{5/3} \\log n)$.","main_category":"cs.DS","categories":"cs.DS,cs.DC","published":"2025-04-17T15:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.13063v1","title":"An exact approach for the multi-depot electric vehicle scheduling\n  problem","summary":"The \"avoid - shift - improve\" framework and the European Clean Vehicles\nDirective set the path for improving the efficiency and ultimately\ndecarbonizing the transport sector. While electric buses have already been\nadopted in several cities, regional bus lines may pose additional challenges\ndue to the potentially longer distances they have to travel. In this work, we\nmodel and solve the electric bus scheduling problem, lexicographically\nminimizing the size of the bus fleet, the number of charging stops, and the\ntotal energy consumed, to provide decision support for bus operators planning\nto replace their diesel-powered fleet with zero emission vehicles. We propose a\ngraph representation which allows partial charging without explicitly relying\non time variables and derive 3-index and 2-index mixed-integer linear\nprogramming formulations for the multi-depot electric vehicle scheduling\nproblem. While the 3-index model can be solved by an off-the-shelf solver\ndirectly, the 2-index model relies on an exponential number of constraints to\nensure the correct depot pairing. These are separated in a cutting plane\nfashion. We propose a set of instances with up to 80 service trips to compare\nthe two approaches, showing that, with a small number of depots, the compact\n3-index model performs very well. However, as the number of depots increases\nthe developed branch-and-cut algorithm proves to be of value. These findings\nnot only offer algorithmic insights but the developed approaches also provide\nactionable guidance for transit agencies and operators, allowing to quantify\ntrade-offs between fleet size, energy efficiency, and infrastructure needs\nunder realistic operational conditions.","main_category":"math.OC","categories":"math.OC,cs.DM","published":"2025-04-17T16:18:56Z"}
{"aid":"http://arxiv.org/abs/2504.13079v1","title":"Retrieval-Augmented Generation with Conflicting Evidence","summary":"Large language model (LLM) agents are increasingly employing\nretrieval-augmented generation (RAG) to improve the factuality of their\nresponses. However, in practice, these systems often need to handle ambiguous\nuser queries and potentially conflicting information from multiple sources\nwhile also suppressing inaccurate information from noisy or irrelevant\ndocuments. Prior work has generally studied and addressed these challenges in\nisolation, considering only one aspect at a time, such as handling ambiguity or\nrobustness to noise and misinformation. We instead consider multiple factors\nsimultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and\nMisinformation in Documents), a new dataset that simulates complex and\nrealistic scenarios for conflicting evidence for a user query, including\nambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent\napproach in which LLM agents debate over the merits of an answer over multiple\nrounds, allowing an aggregator to collate responses corresponding to\ndisambiguated entities while discarding misinformation and noise, thereby\nhandling diverse sources of conflict jointly. We demonstrate the effectiveness\nof MADAM-RAG using both closed and open-source models on AmbigDocs -- which\nrequires presenting all valid answers for ambiguous queries -- improving over\nstrong RAG baselines by up to 11.40% and on FaithEval -- which requires\nsuppressing misinformation -- where we improve by up to 15.80% (absolute) with\nLlama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for\nexisting RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match\nscore). While MADAM-RAG begins to address these conflicting factors, our\nanalysis indicates that a substantial gap remains especially when increasing\nthe level of imbalance in supporting evidence and misinformation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T16:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.13109v1","title":"UniEdit-Flow: Unleashing Inversion and Editing in the Era of Flow Models","summary":"Flow matching models have emerged as a strong alternative to diffusion\nmodels, but existing inversion and editing methods designed for diffusion are\noften ineffective or inapplicable to them. The straight-line, non-crossing\ntrajectories of flow models pose challenges for diffusion-based approaches but\nalso open avenues for novel solutions. In this paper, we introduce a\npredictor-corrector-based framework for inversion and editing in flow models.\nFirst, we propose Uni-Inv, an effective inversion method designed for accurate\nreconstruction. Building on this, we extend the concept of delayed injection to\nflow models and introduce Uni-Edit, a region-aware, robust image editing\napproach. Our methodology is tuning-free, model-agnostic, efficient, and\neffective, enabling diverse edits while ensuring strong preservation of\nedit-irrelevant regions. Extensive experiments across various generative models\ndemonstrate the superiority and generalizability of Uni-Inv and Uni-Edit, even\nunder low-cost settings. Project page: https://uniedit-flow.github.io/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.13122v1","title":"VistaDPO: Video Hierarchical Spatial-Temporal Direct Preference\n  Optimization for Large Video Models","summary":"Large Video Models (LVMs) built upon Large Language Models (LLMs) have shown\npromise in video understanding but often suffer from misalignment with human\nintuition and video hallucination issues. To address these challenges, we\nintroduce VistaDPO, a novel framework for Video Hierarchical Spatial-Temporal\nDirect Preference Optimization. VistaDPO enhances text-video preference\nalignment across three hierarchical levels: i) Instance Level, aligning overall\nvideo content with responses; ii) Temporal Level, aligning video temporal\nsemantics with event descriptions; and iii) Perceptive Level, aligning spatial\nobjects with language tokens. Given the lack of datasets for fine-grained\nvideo-language preference alignment, we construct VistaDPO-7k, a dataset of\n7.2K QA pairs annotated with chosen and rejected responses, along with\nspatial-temporal grounding information such as timestamps, keyframes, and\nbounding boxes. Extensive experiments on benchmarks such as Video\nHallucination, Video QA, and Captioning performance tasks demonstrate that\nVistaDPO significantly improves the performance of existing LVMs, effectively\nmitigating video-language misalignment and hallucination. The code and data are\navailable at https://github.com/HaroldChen19/VistaDPO.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-17T17:39:41Z"}
{"aid":"http://arxiv.org/abs/2504.13153v1","title":"Training-Free Hierarchical Scene Understanding for Gaussian Splatting\n  with Superpoint Graphs","summary":"Bridging natural language and 3D geometry is a crucial step toward flexible,\nlanguage-driven scene understanding. While recent advances in 3D Gaussian\nSplatting (3DGS) have enabled fast and high-quality scene reconstruction,\nresearch has also explored incorporating open-vocabulary understanding into\n3DGS. However, most existing methods require iterative optimization over\nper-view 2D semantic feature maps, which not only results in inefficiencies but\nalso leads to inconsistent 3D semantics across views. To address these\nlimitations, we introduce a training-free framework that constructs a\nsuperpoint graph directly from Gaussian primitives. The superpoint graph\npartitions the scene into spatially compact and semantically coherent regions,\nforming view-consistent 3D entities and providing a structured foundation for\nopen-vocabulary understanding. Based on the graph structure, we design an\nefficient reprojection strategy that lifts 2D semantic features onto the\nsuperpoints, avoiding costly multi-view iterative training. The resulting\nrepresentation ensures strong 3D semantic coherence and naturally supports\nhierarchical understanding, enabling both coarse- and fine-grained\nopen-vocabulary perception within a unified semantic field. Extensive\nexperiments demonstrate that our method achieves state-of-the-art\nopen-vocabulary segmentation performance, with semantic field reconstruction\ncompleted over $30\\times$ faster. Our code will be available at\nhttps://github.com/Atrovast/THGS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:56:07Z"}
{"aid":"http://arxiv.org/abs/2504.13158v1","title":"Testing for dice control at craps","summary":"Dice control involves \"setting\" the dice and then throwing them in a careful\nway, in the hope of influencing the outcomes and gaining an advantage at craps.\nHow does one test for this ability? To specify the alternative hypothesis, we\nneed a statistical model of dice control. Two have been suggested in the\ngambling literature, namely the Smith-Scott model and the Wong-Shackleford\nmodel. Both models are parameterized by $\\theta\\in[0,1]$, which measures the\nshooter's level of control. We propose and compare four test statistics: (a)\nthe sample proportion of 7s; (b) the sample proportion of pass-line wins; (c)\nthe sample mean of hand-length observations; and (d) the likelihood ratio\nstatistic for a hand-length sample. We want to test $H_0:\\theta = 0$ (no\ncontrol) versus $H_1:\\theta > 0$ (some control). We also want to test\n$H_0:\\theta\\le\\theta_0$ versus $H_1:\\theta>\\theta_0$, where $\\theta_0$ is the\n\"break-even point.\" For the tests considered we estimate the power, either by\nnormal approximation or by simulation.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T17:57:32Z"}
{"aid":"http://arxiv.org/abs/2504.13171v1","title":"Sleep-time Compute: Beyond Inference Scaling at Test-time","summary":"Scaling test-time compute has emerged as a key ingredient for enabling large\nlanguage models (LLMs) to solve difficult problems, but comes with high latency\nand inference cost. We introduce sleep-time compute, which allows models to\n\"think\" offline about contexts before queries are presented: by anticipating\nwhat queries users might ask and pre-computing useful quantities, we can\nsignificantly reduce the compute requirements at test-time. To demonstrate the\nefficacy of our method, we create modified versions of two reasoning tasks -\nStateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can\nreduce the amount of test-time compute needed to achieve the same accuracy by ~\n5x on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time\ncompute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic\nand 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic,\nwhich extends GSM-Symbolic by including multiple related queries per context.\nBy amortizing sleep-time compute across related queries about the same context\nusing Multi-Query GSM-Symbolic, we can decrease the average cost per query by\n2.5x. We then conduct additional analysis to understand when sleep-time compute\nis most effective, finding the predictability of the user query to be well\ncorrelated with the efficacy of sleep-time compute. Finally, we conduct a\ncase-study of applying sleep-time compute to a realistic agentic SWE task.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-17T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.13175v1","title":"Novel Demonstration Generation with Gaussian Splatting Enables Robust\n  One-Shot Manipulation","summary":"Visuomotor policies learned from teleoperated demonstrations face challenges\nsuch as lengthy data collection, high costs, and limited data diversity.\nExisting approaches address these issues by augmenting image observations in\nRGB space or employing Real-to-Sim-to-Real pipelines based on physical\nsimulators. However, the former is constrained to 2D data augmentation, while\nthe latter suffers from imprecise physical simulation caused by inaccurate\ngeometric reconstruction. This paper introduces RoboSplat, a novel method that\ngenerates diverse, visually realistic demonstrations by directly manipulating\n3D Gaussians. Specifically, we reconstruct the scene through 3D Gaussian\nSplatting (3DGS), directly edit the reconstructed scene, and augment data\nacross six types of generalization with five techniques: 3D Gaussian\nreplacement for varying object types, scene appearance, and robot embodiments;\nequivariant transformations for different object poses; visual attribute\nediting for various lighting conditions; novel view synthesis for new camera\nperspectives; and 3D content generation for diverse object types. Comprehensive\nreal-world experiments demonstrate that RoboSplat significantly enhances the\ngeneralization of visuomotor policies under diverse disturbances. Notably,\nwhile policies trained on hundreds of real-world demonstrations with additional\n2D data augmentation achieve an average success rate of 57.2%, RoboSplat\nattains 87.8% in one-shot settings across six types of generalization in the\nreal world.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T17:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.14831v1","title":"Supersymmetric Hybrid Inflation in light of Atacama Cosmology Telescope\n  Data Release 6, Planck 2018 and LB-BK18","summary":"Supersymmetry-based hybrid inflation models (referred to as `spontaneously\nbroken supersymmetry' by the Planck collaboration) are attractive for several\nreasons, including the appealing feature that inflation is associated with\nlocal gauge symmetry breaking in the early universe. Following the Planck\ncollaboration's notation, the inflationary potential with sub-Planckian\ninflaton field values is given by: $V = \\Lambda^4 [1 + \\alpha_h \\log(\\phi /\nM_{Pl})] - m_{3/2} \\Lambda^2 \\phi + \\Lambda^4 O((\\phi / M_{Pl})^4)$. Here,\n$\\Lambda = \\sqrt{\\kappa} M$ denotes the energy scale of inflation, $M$ is the\ngauge symmetry breaking scale, $\\kappa$ is a dimensionless parameter that sets\nthe inflaton mass ($\\sqrt{2} \\kappa M$), and $\\alpha_h$ is determined from\nquantum corrections in terms of $\\kappa$ and the underlying gauge group. A soft\nsupersymmetry-breaking term proportional to the gravitino mass $m_{3/2}$ (~10\nTeV) and linear in the inflaton field $\\phi$ is also present during inflation.\nThe final term in $V$ represents the leading-order supergravity correction.\n(Note that the last two terms were not taken into account in the Planck\nanalysis.) We provide estimates for the parameters $\\kappa$ (and $\\alpha_h$)\nthat yield a scalar spectral index $n_s$ in the range 0.96 to 0.98, which is\nfully consistent with recent P-ACT-LB measurements presented by the Atacama\nCosmology Telescope, as well as earlier measurements by Planck. We recall that\nin the absence of the soft SUSY-breaking term proportional to $m_{3/2}$ in $V$,\nthe spectral index $n_s = 1 - 1/N = 0.98$, where $N = 50$ denotes the number of\ne-foldings. The tensor-to-scalar ratio $r$ in this minimal model is tiny, but\nit can reach potentially observable values ($r \\lesssim 0.01$) in non-minimal\nmodels.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T03:18:43Z"}
{"aid":"http://arxiv.org/abs/2504.14880v1","title":"Stratification and Rectifiability of Harmonic Map Flows via Tangent\n  Measures","summary":"In this paper, we investigate the stratification theory for suitable\nsolutions of harmonic map flows based on the spatial symmetry of tangent\nmeasures. Generally, suitable solutions are a category of solutions that\nsatisfy both the localized energy inequality and the monotonicity formula.\nBuilding on the modifications and adjustments of quantitative stratifications\nand Reifenberg-rectifiable theory by Naber and Valtorta, we confirm that each\nstratum in our model is rectifiable. We also establish an estimate for the\nMinkowski content of the singular set at each time slice, demonstrating that\nthe singular set is rectifiable and that our results strengthen previous\nfindings, which were limited to almost every time slice. Furthermore, under\ncertain assumptions about the target manifolds that exclude specific tangent\nflows and measures, our analysis achieves substantial improvements in the\nregularity of suitable solutions for harmonic map flows.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-21T06:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.14898v1","title":"Expected Free Energy-based Planning as Variational Inference","summary":"We address the problem of planning under uncertainty, where an agent must\nchoose actions that not only achieve desired outcomes but also reduce\nuncertainty. Traditional methods often treat exploration and exploitation as\nseparate objectives, lacking a unified inferential foundation. Active\ninference, grounded in the Free Energy Principle, offers such a foundation by\nminimizing Expected Free Energy (EFE), a cost function that combines utility\nwith epistemic drives like ambiguity resolution and novelty seeking. However,\nthe computational burden of EFE minimization has remained a major obstacle to\nits scalability. In this paper, we show that EFE-based planning arises\nnaturally from minimizing a variational free energy functional on a generative\nmodel augmented with preference and epistemic priors. This result reinforces\ntheoretical consistency with the Free Energy Principle, by casting planning\nitself as variational inference. Our formulation yields optimal policies that\njointly support goal achievement and information gain, while incorporating a\ncomplexity term that accounts for bounded computational resources. This\nunifying framework connects and extends existing methods, enabling scalable,\nresource-aware implementations of active inference agents.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-21T07:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.14920v1","title":"DyFo: A Training-Free Dynamic Focus Visual Search for Enhancing LMMs in\n  Fine-Grained Visual Understanding","summary":"Humans can effortlessly locate desired objects in cluttered environments,\nrelying on a cognitive mechanism known as visual search to efficiently filter\nout irrelevant information and focus on task-related regions. Inspired by this\nprocess, we propose Dyfo (Dynamic Focus), a training-free dynamic focusing\nvisual search method that enhances fine-grained visual understanding in large\nmultimodal models (LMMs). Unlike existing approaches which require additional\nmodules or data collection, Dyfo leverages a bidirectional interaction between\nLMMs and visual experts, using a Monte Carlo Tree Search (MCTS) algorithm to\nsimulate human-like focus adjustments. This enables LMMs to focus on key visual\nregions while filtering out irrelevant content, without introducing additional\ntraining caused by vocabulary expansion or the integration of specialized\nlocalization modules. Experimental results demonstrate that Dyfo significantly\nimproves fine-grained visual understanding and reduces hallucination issues in\nLMMs, achieving superior performance across both fixed and dynamic resolution\nmodels. The code is available at https://github.com/PKU-ICST-MIPL/DyFo_CVPR2025","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:39:29Z"}
{"aid":"http://arxiv.org/abs/2504.14957v1","title":"Parallel Kac's Walk Generates PRU","summary":"Ma and Huang recently proved that the PFC construction, introduced by Metger,\nPoremba, Sinha and Yuen [MPSY24], gives an adaptive-secure pseudorandom unitary\nfamily PRU. Their proof developed a new path recording technique [MH24].\n  In this work, we show that a linear number of sequential repetitions of the\nparallel Kac's Walk, introduced by Lu, Qin, Song, Yao and Zhao [LQSY+24], also\nforms an adaptive-secure PRU, confirming a conjecture therein. Moreover, it\nadditionally satisfies strong security against adversaries making inverse\nqueries. This gives an alternative PRU construction, and provides another\ninstance demonstrating the power of the path recording technique. We also\ndiscuss some further simplifications and implications.","main_category":"quant-ph","categories":"quant-ph,cs.CC,cs.CR","published":"2025-04-21T08:32:14Z"}
{"aid":"http://arxiv.org/abs/2504.15000v1","title":"Quasilinear problems with mixed local-nonlocal operator and\n  concave-critical nonlinearities: Multiplicity of positive solutions","summary":"We study the existence and multiplicity of positive solutions for the\nfollowing concave-critical problem driven by an operator of mixed order\nobtained by the sum of the classical $p$-Laplacian and of the fractional\n$p$-Laplacian, \\begin{equation}\\tag{$\\mathcal{P}_{\\lambda,\\varepsilon}$}\n  -\\Delta_p u+\\varepsilon(-\\Delta_p)^s u=\\lambda|u|^{q-2}u+|u|^{p^*-2}u\n\\;\\text{ in }\\Omega,\\quad\n  u=0 \\; \\text{ in }\\mathbb{R}^N \\setminus \\Omega, \\end{equation} where\n$\\Omega\\subset\\mathbb{R}^N$ is a bounded open set, $\\epsilon\\in(0,1]$,\n$0<s<1<q<p<N$, and $p^*=\\frac{Np}{N-p}$, and $\\lambda \\in \\mathbb{R}$ is a\nparameter. For $\\lambda \\leq 0$, we show that\n(\\textcolor{blue}{$\\mathcal{P}_{\\lambda,\\varepsilon}$}) has no nontrivial\nsolution. For $\\lambda>0$, we prove Ambrosetti-Brezis-Cerami type results. In\nparticular, we prove the existence of $\\Lambda_\\varepsilon$ such that\n(\\textcolor{blue}{$\\mathcal{P}_{\\lambda,\\varepsilon}$}) has a positive minimal\nsolution for $0<\\lambda<\\Lambda_\\varepsilon$, a positive solution for\n$\\lambda=\\Lambda_\\varepsilon$ and no positive solution for\n$\\lambda>\\Lambda_\\varepsilon$. We also prove the existence of\n$0<\\lambda^\\#\\leq\\Lambda_\\varepsilon$ such that\n(\\textcolor{blue}{$\\mathcal{P}_{\\lambda,\\varepsilon}$}) has at least two\npositive solutions for $\\lambda\\in(0,\\lambda^\\#)$ provided $\\varepsilon$ small\nenough. This extends the recent result of Biagi and Vecchi (Nonlinear Anal. 256\n(2025),113795), Amundsen, et al. (Commun. Pure Appl. Anal., 22(10):3139-3164,\n2023) from $p=2$ to the general $1<p<N$. Additionally, it extends the classical\nresult of Azorero and Peral (Indiana Univ. Math. J., 43(3):947-957, 1994) to\nthe mixed local-nonlocal quasilinear problems. Moreover, our results\ncomplements the multiplicity results for nonnegative solutions in da Silva, et\nal. (J. Differential Equations, 408:494-536, 2024).","main_category":"math.AP","categories":"math.AP","published":"2025-04-21T10:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.15061v1","title":"Effective Starobinsky pre-inflation","summary":"We consider one-loop corrections to a recently obtained form of Starobinsky\ninflation in Jordan frame to extract information about the initial conditions\nof the universe leading to cosmological inflation. Integrating out graviton\nmodes, we find higher-derivative instabilities that are shown to decay into\nscalarons and causing an effective kinetic-domination stage where the universe\nbehaves as a stiff fluid. Through slow cosmological expansion, the kination\nstage leads to inflation. We find a natural cut-off for the scalaron magnitude\nensuring positivity of the modified kinetic term which matches Planck\nconstraints on inflaton energy density at the pivot scale. We, then, backtrack\nto find that even for arbitrary initial conditions, kination naturally leads to\nthe inflationary epoch without the need for fine-tuning. Modifications to the\nscalar power spectrum are also shown to potentially explain low-$l$ anomaly in\nCMB observations as well as the updated prediction of spectral index\n$\\approx0.9743$ accounting for data from Atacama Cosmology Telescope (ACT).","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-21T12:40:36Z"}
{"aid":"http://arxiv.org/abs/2504.15070v1","title":"Automated discovery and optimization of autonomous quantum error\n  correction codes for a general open quantum system","summary":"We develop a method to search for the optimal code space, induced decay rates\nand control Hamiltonian to implement autonomous quantum error correction (AQEC)\nfor a general open quantum system. The system is defined by a free-evolution\nLindbladian superoperator, which contains the free Hamiltonian and naturally\noccurring decoherence terms, as well as the control superoperators. The\nperformance metric for optimization is the fidelity between the projector onto\nthe code space and the same projector after Lindbladian evolution for a\nspecified time. We use a gradient-based search to update the code words,\ninduced decay matrix and control Hamiltonian matrix. We apply the method to\noptimize AQEC codes for a variety of few-level systems. The four-level system\nwith uniform decay rates offers a simple example for testing and illustrating\nthe operation of our approach. The algorithm reliably succeeds in finding the\noptimal code in this case, while success becomes probabilistic for more\ncomplicated cases. For a five-level system with photon loss decay, the\nalgorithm finds good AQEC codes, but these codes are not as good as the\nwell-known binomial code. We use the binomial code as a starting point to\nsearch for the optimal code for a perturbed five-level system. In this case,\nthe algorithm finds a code that is better than both the original binomial code\nand any other code obtained numerically when starting from a random initial\nguess.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T12:56:10Z"}
{"aid":"http://arxiv.org/abs/2504.15101v1","title":"NeuGaze: Reshaping the future BCI","summary":"Traditional brain-computer interfaces (BCIs), reliant on costly\nelectroencephalography or invasive implants, struggle with complex\nhuman-computer interactions due to setup complexity and limited precision. We\npresent NeuGaze, a novel webcam-based system that leverages eye gaze, head\nmovements, and facial expressions to enable intuitive, real-time control using\nonly a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal\ncalibration, NeuGaze achieves performance comparable to conventional inputs,\nsupporting precise cursor navigation, key triggering via an efficient skill\nwheel, and dynamic gaming interactions, such as defeating formidable opponents\nin first-person games. By harnessing preserved neck-up functionalities in\nmotor-impaired individuals, NeuGaze eliminates the need for specialized\nhardware, offering a low-cost, accessible alternative to BCIs. This paradigm\nempowers diverse applications, from assistive technology to entertainment,\nredefining human-computer interaction for motor-impaired users. Project is at\n\\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.ET","published":"2025-04-21T13:49:17Z"}
{"aid":"http://arxiv.org/abs/2504.15105v1","title":"A triple-branch network for latent fingerprint enhancement guided by\n  orientation fields and minutiae","summary":"Latent fingerprint enhancement is a critical step in the process of latent\nfingerprint identification. Existing deep learning-based enhancement methods\nstill fall short of practical application requirements, particularly in\nrestoring low-quality fingerprint regions. Recognizing that different regions\nof latent fingerprints require distinct enhancement strategies, we propose a\nTriple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances\ndifferent regions of the image using tailored strategies. Furthermore, to\nimprove the generalization capability of the network, we integrate orientation\nfield and minutiae-related modules into TBSFNet and introduce a Multi-Level\nFeature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST\ndatasets demonstrate that MLFGNet outperforms existing enhancement algorithms.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T13:54:33Z"}
{"aid":"http://arxiv.org/abs/2504.15106v1","title":"Optimizations of electronic stopping cross section measurements using\n  the backscattering method","summary":"The accurate determination of electronic stopping cross sections is essential\nfor advancing nuclear science and materials research. In this work, we present\nan optimized methodology for stopping power measurements using the\nbackscattering technique, with a focus on minimizing both random and systematic\nuncertainties. By systematically analyzing the sources of uncertainty and\nrefining the experimental geometry, we establish a robust framework for\nhigh-precision measurements. Our approach was applied to the stopping power of\nhelium ions in gold thin films, demonstrating excellent agreement with\nreference models such as SRIM and ICRU-49. The results reveal that carefully\nchosen measurement angles can effectively balance statistical precision and\nsystematic accuracy, achieving total uncertainties below 3% across a wide\nenergy range. This study provides a refined strategy for stopping power\ndetermination, offering valuable improvements for ion beam analysis and\nbenchmarking theoretical models.","main_category":"physics.ins-det","categories":"physics.ins-det,cond-mat.other,nucl-ex","published":"2025-04-21T13:58:01Z"}
{"aid":"http://arxiv.org/abs/2504.15115v1","title":"Deterministic $k$-Median Clustering in Near-Optimal Time","summary":"The metric $k$-median problem is a textbook clustering problem. As input, we\nare given a metric space $V$ of size $n$ and an integer $k$, and our task is to\nfind a subset $S \\subseteq V$ of at most $k$ `centers' that minimizes the total\ndistance from each point in $V$ to its nearest center in $S$.\n  Mettu and Plaxton [UAI'02] gave a randomized algorithm for $k$-median that\ncomputes a $O(1)$-approximation in $\\tilde O(nk)$ time. They also showed that\nany algorithm for this problem with a bounded approximation ratio must have a\nrunning time of $\\Omega(nk)$. Thus, the running time of their algorithm is\noptimal up to polylogarithmic factors.\n  For deterministic $k$-median, Guha et al.~[FOCS'00] gave an algorithm that\ncomputes a $\\text{poly}(\\log (n/k))$-approximation in $\\tilde O(nk)$ time,\nwhere the degree of the polynomial in the approximation is unspecified. To the\nbest of our knowledge, this remains the state-of-the-art approximation of any\ndeterministic $k$-median algorithm with this running time.\n  This leads us to the following natural question: What is the best\napproximation of a deterministic $k$-median algorithm with near-optimal running\ntime? We make progress in answering this question by giving a deterministic\nalgorithm that computes a $O(\\log(n/k))$-approximation in $\\tilde O(nk)$ time.\nWe also provide a lower bound showing that any deterministic algorithm with\nthis running time must have an approximation ratio of $\\Omega(\\log n/(\\log k +\n\\log \\log n))$, establishing a gap between the randomized and deterministic\nsettings for $k$-median.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-21T14:10:20Z"}
{"aid":"http://arxiv.org/abs/2504.15121v1","title":"Robust and Real-time Surface Normal Estimation from Stereo Disparities\n  using Affine Transformations","summary":"This work introduces a novel method for surface normal estimation from\nrectified stereo image pairs, leveraging affine transformations derived from\ndisparity values to achieve fast and accurate results. We demonstrate how the\nrectification of stereo image pairs simplifies the process of surface normal\nestimation by reducing computational complexity. To address noise reduction, we\ndevelop a custom algorithm inspired by convolutional operations, tailored to\nprocess disparity data efficiently. We also introduce adaptive heuristic\ntechniques for efficiently detecting connected surface components within the\nimages, further improving the robustness of the method. By integrating these\nmethods, we construct a surface normal estimator that is both fast and\naccurate, producing a dense, oriented point cloud as the final output. Our\nmethod is validated using both simulated environments and real-world stereo\nimages from the Middlebury and Cityscapes datasets, demonstrating significant\nimprovements in real-time performance and accuracy when implemented on a GPU.\nUpon acceptance, the shader source code will be made publicly available to\nfacilitate further research and reproducibility.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:19:00Z"}
{"aid":"http://arxiv.org/abs/2504.15134v1","title":"Instance-Adaptive Keypoint Learning with Local-to-Global Geometric\n  Aggregation for Category-Level Object Pose Estimation","summary":"Category-level object pose estimation aims to predict the 6D pose and size of\npreviously unseen instances from predefined categories, requiring strong\ngeneralization across diverse object instances. Although many previous methods\nattempt to mitigate intra-class variations, they often struggle with instances\nexhibiting complex geometries or significant deviations from canonical shapes.\nTo address this challenge, we propose INKL-Pose, a novel category-level object\npose estimation framework that enables INstance-adaptive Keypoint Learning with\nlocal-to-global geometric aggregation. Specifically, our approach first\npredicts semantically consistent and geometric informative keypoints through an\nInstance-Adaptive Keypoint Generator, then refines them with: (1) a Local\nKeypoint Feature Aggregator capturing fine-grained geometries, and (2) a Global\nKeypoint Feature Aggregator using bidirectional Mamba for structural\nconsistency. To enable bidirectional modeling in Mamba, we introduce a Feature\nSequence Flipping strategy that preserves spatial coherence while constructing\nbackward feature sequences. Additionally, we design a surface loss and a\nseparation loss to enforce uniform coverage and spatial diversity in keypoint\ndistribution. The generated keypoints are finally mapped to a canonical space\nfor regressing the object's 6D pose and size. Extensive experiments on\nCAMERA25, REAL275, and HouseCat6D demonstrate that INKL-Pose achieves\nstate-of-the-art performance and significantly outperforms existing methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:37:37Z"}
{"aid":"http://arxiv.org/abs/2504.15154v1","title":"Non-Hermitian Hopf insulators","summary":"Hopf insulators represent a unique class of topological insulators that exist\nexclusively in two-band systems and are inherently unstable upon the inclusion\nof additional bands. Meanwhile, recent studies have shown that non-Hermiticity\ngives rise to distinctive complex-energy gap structures, known as point gaps,\nand associated topological phases with no analogs in Hermitian systems.\nHowever, non-Hermitian counterparts of Hopf insulators have remained largely\nelusive. Here, we generally classify topological phases of two-band\nnon-Hermitian systems based on the homotopy theory and uncover Hopf-type\npoint-gap topology present only for two bands. Specifically, we reveal such\nHopf-type point-gap topology for three-dimensional systems with chiral symmetry\n(class AIII) and four-dimensional systems with no symmetry (class A).\nExplicitly constructing prototypical models from the Hermitian Hopf insulator,\nwe further demonstrate that these non-Hermitian topological phases lead to\nanomalous point-gapless boundary states spectrally detachable from the bulk\nbands.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,math-ph,math.MP,quant-ph","published":"2025-04-21T14:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.15156v1","title":"Advanced posterior analyses of hidden Markov models: finite Markov chain\n  imbedding and hybrid decoding","summary":"Two major tasks in applications of hidden Markov models are to (i) compute\ndistributions of summary statistics of the hidden state sequence, and (ii)\ndecode the hidden state sequence. We describe finite Markov chain imbedding\n(FMCI) and hybrid decoding to solve each of these two tasks. In the first part\nof our paper we use FMCI to compute posterior distributions of summary\nstatistics such as the number of visits to a hidden state, the total time spent\nin a hidden state, the dwell time in a hidden state, and the longest run\nlength. We use simulations from the hidden state sequence, conditional on the\nobserved sequence, to establish the FMCI framework. In the second part of our\npaper we apply hybrid segmentation for improved decoding of a HMM. We\ndemonstrate that hybrid decoding shows increased performance compared to\nViterbi or Posterior decoding (often also referred to as global or local\ndecoding), and we introduce a novel procedure for choosing the tuning parameter\nin the hybrid procedure. Furthermore, we provide an alternative derivation of\nthe hybrid loss function based on weighted geometric means. We demonstrate and\napply FMCI and hybrid decoding on various classical data sets, and supply\naccompanying code for reproducibility.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-21T14:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.15170v1","title":"HSANET: A Hybrid Self-Cross Attention Network For Remote Sensing Change\n  Detection","summary":"The remote sensing image change detection task is an essential method for\nlarge-scale monitoring. We propose HSANet, a network that uses hierarchical\nconvolution to extract multi-scale features. It incorporates hybrid\nself-attention and cross-attention mechanisms to learn and fuse global and\ncross-scale information. This enables HSANet to capture global context at\ndifferent scales and integrate cross-scale features, refining edge details and\nimproving detection performance. We will also open-source our model code:\nhttps://github.com/ChengxiHAN/HSANet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T15:23:59Z"}
{"aid":"http://arxiv.org/abs/2504.15178v1","title":"Time-Series Analysis on Edge-AI Hardware for Healthcare Monitoring","summary":"This project addresses the need for efficient, real-time analysis of\nbiomedical signals such as electrocardiograms (ECG) and electroencephalograms\n(EEG) for continuous health monitoring. Traditional methods rely on\nlong-duration data recording followed by offline analysis, which is\npower-intensive and delays responses to critical symptoms such as arrhythmia.\nTo overcome these limitations, a time-domain ECG analysis model based on a\nnovel dynamically-biased Long Short-Term Memory (DB-LSTM) neural network is\nproposed. This model supports simultaneous ECG forecasting and classification\nwith high performance-achieving over 98% accuracy and a normalized mean square\nerror below 1e-3 for forecasting, and over 97% accuracy with faster convergence\nand fewer training parameters for classification. To enable edge deployment,\nthe model is hardware-optimized by quantizing weights to INT4 or INT3 formats,\nresulting in only a 2% and 6% drop in classification accuracy during training\nand inference, respectively, while maintaining full accuracy for forecasting.\nExtensive simulations using multiple ECG datasets confirm the model's\nrobustness. Future work includes implementing the algorithm on FPGA and CMOS\ncircuits for practical cardiac monitoring, as well as developing a digital\nhardware platform that supports flexible neural network configurations and\non-chip online training for personalized healthcare applications.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T15:40:10Z"}
{"aid":"http://arxiv.org/abs/2504.15180v1","title":"Reaction-diffusion approximation of nonlocal interactions in\n  high-dimensional Euclidean space","summary":"In various phenomena such as pattern formation, neural firing in the brain\nand cell migration, interactions that can affect distant objects globally in\nspace can be observed. These interactions are referred to as nonlocal\ninteractions and are often modeled using spatial convolution with an\nappropriate integral kernel. Many evolution equations incorporating nonlocal\ninteractions have been proposed. In such equations, the behavior of the system\nand the patterns it generates can be controlled by modifying the shape of the\nintegral kernel. However, the presence of nonlocality poses challenges for\nmathematical analysis. To address these difficulties, we develop an\napproximation method that converts nonlocal effects into spatially local\ndynamics using reaction-diffusion systems. In this paper, we present an\napproximation method for nonlocal interactions in evolution equations based on\na linear sum of solutions to a reaction-diffusion system in high-dimensional\nEuclidean space up to three dimensions. The key aspect of this approach is\nidentifying a class of integral kernels that can be approximated by a linear\ncombination of specific Green functions in the case of high-dimensional spaces.\nThis enables us to demonstrate that any nonlocal interactions can be\napproximated by a linear sum of auxiliary diffusive substances. Our results\nestablish a connection between a broad class of nonlocal interactions and\ndiffusive chemical reactions in dynamical systems.","main_category":"math.AP","categories":"math.AP","published":"2025-04-21T15:41:18Z"}
{"aid":"http://arxiv.org/abs/2504.15193v1","title":"Automated Measurement of Eczema Severity with Self-Supervised Learning","summary":"Automated diagnosis of eczema using images acquired from digital camera can\nenable individuals to self-monitor their recovery. The process entails first\nsegmenting out the eczema region from the image and then measuring the severity\nof eczema in the segmented region. The state-of-the-art methods for automated\neczema diagnosis rely on deep neural networks such as convolutional neural\nnetwork (CNN) and have shown impressive performance in accurately measuring the\nseverity of eczema. However, these methods require massive volume of annotated\ndata to train which can be hard to obtain. In this paper, we propose a\nself-supervised learning framework for automated eczema diagnosis under limited\ntraining data regime. Our framework consists of two stages: i) Segmentation,\nwhere we use an in-context learning based algorithm called SegGPT for few-shot\nsegmentation of eczema region from the image; ii) Feature extraction and\nclassification, where we extract DINO features from the segmented regions and\nfeed it to a multi-layered perceptron (MLP) for 4-class classification of\neczema severity. When evaluated on a dataset of annotated \"in-the-wild\" eczema\nimages, we show that our method outperforms (Weighted F1: 0.67 $\\pm$ 0.01) the\nstate-of-the-art deep learning methods such as finetuned Resnet-18 (Weighted\nF1: 0.44 $\\pm$ 0.16) and Vision Transformer (Weighted F1: 0.40 $\\pm$ 0.22). Our\nresults show that self-supervised learning can be a viable solution for\nautomated skin diagnosis where labeled data is scarce.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-21T16:02:26Z"}
{"aid":"http://arxiv.org/abs/2504.15200v1","title":"On robust toric ideals of weighted oriented graphs","summary":"In this work, we study the equivalence of robustness, strongly robustness,\ngeneralized robustness, and weakly robustness properties of toric ideals of\nweighted oriented graphs. For any weighted oriented graph $D$, if its toric\nideal $I_D$ is generalized robust or weakly robust, then we show that $D$ has\nno subgraphs of certain structures.\n  We prove the equality of Graver basis, Universal Gr\\\"obner basis, reduced\nGr\\\"obner basis with respect to degree lexicographic order of the toric ideals\n$I_D$ of weighted oriented graphs $D=\\C_1\\cup_P \\cdots \\cup_P \\C_n$ consist of\ncycles $\\C_1\\ldots,\\C_n$ that share a path $P$. As a consequence, we show that\n(i) $I_{D}$ is robust iff $I_{D}$ is strongly robust; (ii) $I_{D}$ is\ngeneralized robust iff $I_{D}$ is weakly robust. If at most two of the cycles\n$\\C_i$ in $D$ are unbalanced, then the following statements are equivalent: (i)\n$I_{D}$ is strongly robust; (ii) $I_{D}$ is robust; (iii) $I_{D}$ is\ngeneralized robust; (iv) $I_{D}$ is weakly robust; (v) $D$ has no subgraphs of\ntypes $D_{1}$ and $D_{2}$, where $D_1$ is a weighted oriented graph consisting\nof two balanced cycles share an edge in $D$, and $D_2$ is a weighted oriented\ngraph consisting of three cycles that share an edge\\ such that one cycle is\nbalanced and the rest two are unbalanced cycles, as in figure \\ref{fig2}. We\nexplicitly determine the Graver basis of the toric ideal of two balanced cycles\nsharing a path.","main_category":"math.AC","categories":"math.AC","published":"2025-04-21T16:17:05Z"}
{"aid":"http://arxiv.org/abs/2504.15209v1","title":"A Causal Convolutional Low-rank Representation Model for Imputation of\n  Water Quality Data","summary":"The monitoring of water quality is a crucial part of environmental\nprotection, and a large number of monitors are widely deployed to monitor water\nquality. Due to unavoidable factors such as data acquisition breakdowns,\nsensors and communication failures, water quality monitoring data suffers from\nmissing values over time, resulting in High-Dimensional and Sparse (HDS) Water\nQuality Data (WQD). The simple and rough filling of the missing values leads to\ninaccurate results and affects the implementation of relevant measures.\nTherefore, this paper proposes a Causal convolutional Low-rank Representation\n(CLR) model for imputing missing WQD to improve the completeness of the WQD,\nwhich employs a two-fold idea: a) applying causal convolutional operation to\nconsider the temporal dependence of the low-rank representation, thus\nincorporating temporal information to improve the imputation accuracy; and b)\nimplementing a hyperparameters adaptation scheme to automatically adjust the\nbest hyperparameters during model training, thereby reducing the tedious manual\nadjustment of hyper-parameters. Experimental studies on three real-world water\nquality datasets demonstrate that the proposed CLR model is superior to some of\nthe existing state-of-the-art imputation models in terms of imputation accuracy\nand time cost, as well as indicating that the proposed model provides more\nreliable decision support for environmental monitoring.","main_category":"cs.LG","categories":"cs.LG,cs.AI,I.2.7","published":"2025-04-21T16:27:16Z"}
{"aid":"http://arxiv.org/abs/2504.15218v1","title":"Non-minimal coupling in light of ACT","summary":"The latest ACT data release disfavors the attractor $n_s=1-2/N$. In\ninflationary models with nonminimal coupling, such attractors typically arise\nin the strong coupling limit. To align with observational constraints, we focus\non nonminimal coupling models with small coupling constants. For the model with\nthe coupling function $\\Omega(\\phi) = 1 + \\xi f(\\phi)$ and the potential\n$V(\\phi) = \\lambda^2 f^2(\\phi)$, we find that observational data constrain the\nparameters as $0.1 \\lesssim \\xi \\lesssim 35$ and $0 \\lesssim k \\lesssim 1.5$\nfor $f(\\phi) = \\phi^k$ at the $1\\sigma$ confidence level. With the help of the\nnonmiminal coupling $\\Omega(\\phi) = 1 + \\xi \\phi^2$, the hilltop inflation and\npower-law inflation models with power indices $2/3$ and $1/3$ can be consistent\nwith observational data within the $1\\sigma$ range. We also give the viable\nparameter regions for $\\xi$ for these three models.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T16:43:18Z"}
{"aid":"http://arxiv.org/abs/2504.15245v1","title":"Probing the octupole deformation of $^{238}$U in high-energy nuclear\n  collisions","summary":"Some atomic nuclei exhibit ``pear\" shapes arising from octupole deformation\n($\\beta_3$), though direct experimental evidences for such exotic shapes\nremains scarce. Low-energy model studies suggest $^{238}$U may have a modest\noctupole deformation arising from collective vibrational degrees of freedom, in\naddition to a large prolate shape. We investigated the impact of this modest\noctupole shape on observables involving triangular flow ($v_3$) in high-energy\nnuclear collisions. Using a hydrodynamic framework, we show $v_3$ and its\ncorrelation with mean transverse momentum, $\\langle v_3^2 \\delta\\pT \\rangle$,\nexhibit strong sensitivity to $\\beta_3$. We found that $\\langle v_3^2\\rangle$\nfollows a linear increase with $\\beta_3^2$, while $\\langle v_3^2 \\delta\\pT\n\\rangle$ is suppressed in the presence of $\\beta_3$. Our findings show that the\ncollective-flow-assisted nuclear imaging method in high-energy nuclear\ncollisions, when compared with experimental data, can provide unique\nconstraints on higher-order deformations.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-21T17:17:33Z"}
{"aid":"http://arxiv.org/abs/2504.15246v1","title":"A Refreshment Stirred, Not Shaken (III): Can Swapping Be Differentially\n  Private?","summary":"The quest for a precise and contextually grounded answer to the question in\nthe present paper's title resulted in this stirred-not-shaken triptych, a\nphrase that reflects our desire to deepen the theoretical basis, broaden the\npractical applicability, and reduce the misperception of differential privacy\n(DP)$\\unicode{x2014}$all without shaking its core foundations. Indeed, given\nthe existence of more than 200 formulations of DP (and counting), before even\nattempting to answer the titular question one must first precisely specify what\nit actually means to be DP. Motivated by this observation, a theoretical\ninvestigation into DP's fundamental essence resulted in Part I of this trio,\nwhich introduces a five-building-block system explicating the who, where, what,\nhow and how much aspects of DP. Instantiating this system in the context of the\nUnited States Decennial Census, Part II then demonstrates the broader\napplicability and relevance of DP by comparing a swapping strategy like that\nused in 2010 with the TopDown Algorithm$\\unicode{x2014}$a DP method adopted in\nthe 2020 Census. This paper provides nontechnical summaries of the preceding\ntwo parts as well as new discussion$\\unicode{x2014}$for example, on how greater\nawareness of the five building blocks can thwart privacy theatrics; how our\nresults bridging traditional SDC and DP allow a data custodian to reap the\nbenefits of both these fields; how invariants impact disclosure risk; and how\nremoving the implicit reliance on aleatoric uncertainty could lead to new\ngeneralizations of DP.","main_category":"cs.CR","categories":"cs.CR,stat.OT","published":"2025-04-21T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.15250v1","title":"Tracer dynamics in an interacting active bath: fluctuations and energy\n  partition","summary":"We investigate the dynamics of a massive tracer particle coupled to an\ninteracting active bath, modeled as a harmonic chain of overdamped active\nparticles analytically, with an aim to understand the impact of bath\ninteractions and activity on the nonequilibrium fluctuations of the tracer.\nFrom the microscopic equations, we derive the tracer particle's effective\nLangevin equation, obtaining the dissipative and stochastic forces from the\nbath. We analyze the friction kernel, revealing power-law tails in the weak\ncoupling limit and exponential decay in the strong coupling regime. Due to the\ninterplay between bath interactions, probe-bath coupling, and activity, the\nmean squared displacement, velocity, and stationary velocity correlations\nexhibit different dynamical regimes, which we characterize analytically. Under\nharmonic confinement, we find that energy equipartition holds at low activity\nbut breaks down at higher activity, with the kinetic energy exhibiting a\nnon-monotonic dependence on the activity of the bath.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-21T17:27:41Z"}
{"aid":"http://arxiv.org/abs/2504.15253v1","title":"Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as\n  Test-Time Scaling Evaluators","summary":"Scaling test-time computation, or affording a generator large language model\n(LLM) extra compute during inference, typically employs the help of external\nnon-generative evaluators (i.e., reward models). Concurrently, LLM-judges,\nmodels trained to generate evaluations and critiques (explanations) in natural\nlanguage, are becoming increasingly popular in automatic evaluation. Despite\njudge empirical successes, their effectiveness as evaluators in test-time\nscaling settings is largely unknown. In this paper, we introduce the Judge\nEvaluation for Test-Time Scaling (JETTS) benchmark, which evaluates judge\nperformance in three domains (math reasoning, code generation, and instruction\nfollowing) under three task settings: response reranking, step-level beam\nsearch, and critique-based response refinement. We evaluate 10 different judge\nmodels (7B-70B parameters) for 8 different base generator models (6.7B-72B\nparameters). Our benchmark shows that while judges are competitive with outcome\nreward models in reranking, they are consistently worse than process reward\nmodels in beam search procedures. Furthermore, though unique to LLM-judges,\ntheir natural language critiques are currently ineffective in guiding the\ngenerator towards better responses.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-21T17:33:23Z"}
{"aid":"http://arxiv.org/abs/2504.15259v1","title":"Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset\n  Generation","summary":"Digital modeling and reconstruction of human faces serve various\napplications. However, its availability is often hindered by the requirements\nof data capturing devices, manual labor, and suitable actors. This situation\nrestricts the diversity, expressiveness, and control over the resulting models.\nThis work aims to demonstrate that a semantically controllable generative\nnetwork can provide enhanced control over the digital face modeling process. To\nenhance diversity beyond the limited human faces scanned in a controlled\nsetting, we introduce a novel data generation pipeline that creates a\nhigh-quality 3D face database using a pre-trained diffusion model. Our proposed\nnormalization module converts synthesized data from the diffusion model into\nhigh-quality scanned data. Using the 44,000 face models we obtained, we further\ndeveloped an efficient GAN-based generator. This generator accepts semantic\nattributes as input, and generates geometry and albedo. It also allows\ncontinuous post-editing of attributes in the latent space. Our asset refinement\ncomponent subsequently creates physically-based facial assets. We introduce a\ncomprehensive system designed for creating and editing high-quality face\nassets. Our proposed model has undergone extensive experiment, comparison and\nevaluation. We also integrate everything into a web-based interactive tool. We\naim to make this tool publicly available with the release of the paper.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T17:38:50Z"}
{"aid":"http://arxiv.org/abs/2504.15276v1","title":"Improved Algorithms for Quantum MaxCut via Partially Entangled Matchings","summary":"We introduce a $0.611$-approximation algorithm for Quantum MaxCut and a\n$\\frac{1+\\sqrt{5}}{4} \\approx 0.809$-approximation algorithm for the EPR\nHamiltonian of [arXiv:2209.02589]. A novel ingredient in both of these\nalgorithms is to partially entangle pairs of qubits associated to edges in a\nmatching, while preserving the direction of their single-qubit Bloch vectors.\nThis allows us to interpolate between product states and matching-based states\nwith a tunable parameter.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.15278v1","title":"DRAWER: Digital Reconstruction and Articulation With Environment Realism","summary":"Creating virtual digital replicas from real-world data unlocks significant\npotential across domains like gaming and robotics. In this paper, we present\nDRAWER, a novel framework that converts a video of a static indoor scene into a\nphotorealistic and interactive digital environment. Our approach centers on two\nmain contributions: (i) a reconstruction module based on a dual scene\nrepresentation that reconstructs the scene with fine-grained geometric details,\nand (ii) an articulation module that identifies articulation types and hinge\npositions, reconstructs simulatable shapes and appearances and integrates them\ninto the scene. The resulting virtual environment is photorealistic,\ninteractive, and runs in real time, with compatibility for game engines and\nrobotic simulation platforms. We demonstrate the potential of DRAWER by using\nit to automatically create an interactive game in Unreal Engine and to enable\nreal-to-sim-to-real transfer for robotics applications.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-21T17:59:49Z"}
{"aid":"http://arxiv.org/abs/2504.15553v1","title":"Evidence of Ultrashort Orbital Transport in Heavy Metals Revealed by\n  Terahertz Emission Spectroscopy","summary":"The orbital angular momentum of electrons offers a promising, yet largely\nunexplored, degree of freedom for ultrafast, energy-efficient information\nprocessing. As the foundation of orbitronics, understanding how orbital\ncurrents propagate and convert into charge currents is essential - but remains\nelusive due to the challenge in disentangling orbital and spin dynamics in\nultrathin films. Although orbital currents have been predicted to propagate\nover long distances in materials, recent theoretical studies argue that lattice\nsymmetry may constrain their mean free paths (MFPs) to the scale of a single\natomic layer. In this work, we provide the first direct experimental evidence\nfor ultrashort orbital MFPs in heavy metals (HMs) - W, Ta, Pt - revealed by\nfemtosecond terahertz emission spectroscopy. This is enabled by\nsub-nanometer-precision control of thin-film thickness using wedge-shaped HM|Ni\nheterostructures. By employing a multi-component terahertz-emission model, we\nquantitatively extract the orbital MFPs, consistently finding them shorter than\ntheir spin counterparts. Furthermore, control experiments rule out interfacial\norbital-to-charge conversion as the dominant mechanism, confirming that the\nprocess is governed by the bulk inverse orbital Hall effect. Our findings\nresolve a central controversy in orbitronics and provide key insights into\norbital transport and conversion mechanisms.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.optics","published":"2025-04-22T03:15:36Z"}
{"aid":"http://arxiv.org/abs/2504.15555v1","title":"Optimal Procurement Design: A Reduced Form Approach","summary":"Standard procurement models assume that the buyer knows the quality of the\ngood at the time of procurement; however, in many settings, the quality is\nlearned only long after the transaction. We study procurement problems in which\nthe buyer's valuation of the supplied good depends directly on its quality,\nwhich is unverifiable and unobservable to the buyer. For a broad class of\nprocurement problems, we identify procurement mechanisms maximizing any\nweighted average of the buyer's expected payoff and social surplus. The optimal\nmechanism can be implemented by an auction that restricts sellers to submit\nbids within specific intervals.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-22T03:19:02Z"}
{"aid":"http://arxiv.org/abs/2504.15572v1","title":"Global Solutions for 5D Quadratic Fourth-Order SchrÃ¶dinger Equations","summary":"We prove small data scattering for the fourth-order Schr\\\"odinger equation\nwith quadratic nonlinearity \\begin{equation*}\n  i\\partial_t u+\\Delta^2 u+\\alpha u^2 + \\beta \\bar{u}^2=0\\qquad\\text{in\n}\\mathbb{R}^5 \\end{equation*} for $\\alpha, \\beta \\in \\mathbb{R}$. We extend the\nspace-time resonance method, originally introduced by Germain, Masmoudi, and\nShatah, to the setting involving the bilaplacian. We show that under a\nsmallness condition on the initial data measured in a suitable norm, the\nsolution satisfies $\\|u\\|_{L^{\\infty}_x }\\lesssim t^{-\\frac{5}{4}} $ and\nscatters to the solution to the free equation. Although our work builds upon an\nestablished method, the fourth-order nature of the equation presents\nsubstantial challenges, requiring different techniques to overcome them.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T04:05:59Z"}
{"aid":"http://arxiv.org/abs/2504.15624v1","title":"FaceInsight: A Multimodal Large Language Model for Face Perception","summary":"Recent advances in multimodal large language models (MLLMs) have demonstrated\nstrong capabilities in understanding general visual content. However, these\ngeneral-domain MLLMs perform poorly in face perception tasks, often producing\ninaccurate or misleading responses to face-specific queries. To address this\ngap, we propose FaceInsight, the versatile face perception MLLM that provides\nfine-grained facial information. Our approach introduces visual-textual\nalignment of facial knowledge to model both uncertain dependencies and\ndeterministic relationships among facial information, mitigating the\nlimitations of language-driven reasoning. Additionally, we incorporate face\nsegmentation maps as an auxiliary perceptual modality, enriching the visual\ninput with localized structural cues to enhance semantic understanding.\nComprehensive experiments and analyses across three face perception tasks\ndemonstrate that FaceInsight consistently outperforms nine compared MLLMs under\nboth training-free and fine-tuned settings.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T06:31:57Z"}
{"aid":"http://arxiv.org/abs/2504.15652v1","title":"Designing cobalt-free face-centered cubic high-entropy alloys: A\n  strategy using d-orbital energy level","summary":"High-entropy alloys (HEAs) are promising materials for high-temperature\nstructural applications such as nuclear reactors due to their outstanding\nmechanical properties and thermal stability. Instead of the trial-and-error\nmethod, it is efficient to design and prepare single-phase face-centered cubic\n(FCC) structured HEAs using semi-empirical phase formation rules. However,\nalmost all of phase formation rules were proposed without taking into account\nthe cobalt-free situation. The HEAs containing cobalt are unsuitable for\nnuclear applications because of the long-term activation of cobalt. Here, six\nparameters, d-orbital energy level, valance electron concentration, entropy of\nmixing, enthalpy of mixing, atom size differences, and parameter of the entropy\nof mixing ({\\Omega}) were calculated to determine the solid solution phase,\nespecially the FCC phase formation rules in cobalt-free HEAs. HEAs of 4\ncomponents were arc melted to verify the newly developed phase formation rules.\nThe nanomechanical properties of produced HEAs were evaluated using\nnanoindentation. Among the six parameters, the d-orbital energy level and\nvalance electron concentration are the critical factors that determine the FCC\nphase stability in cobalt-free alloys. Interestingly, the d-orbital energy\nlevel can be alone used as a benchmark for developing mechanical properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T07:20:32Z"}
{"aid":"http://arxiv.org/abs/2504.15699v1","title":"Advancing Embodied Agent Security: From Safety Benchmarks to Input\n  Moderation","summary":"Embodied agents exhibit immense potential across a multitude of domains,\nmaking the assurance of their behavioral safety a fundamental prerequisite for\ntheir widespread deployment. However, existing research predominantly\nconcentrates on the security of general large language models, lacking\nspecialized methodologies for establishing safety benchmarks and input\nmoderation tailored to embodied agents. To bridge this gap, this paper\nintroduces a novel input moderation framework, meticulously designed to\nsafeguard embodied agents. This framework encompasses the entire pipeline,\nincluding taxonomy definition, dataset curation, moderator architecture, model\ntraining, and rigorous evaluation. Notably, we introduce EAsafetyBench, a\nmeticulously crafted safety benchmark engineered to facilitate both the\ntraining and stringent assessment of moderators specifically designed for\nembodied agents. Furthermore, we propose Pinpoint, an innovative\nprompt-decoupled input moderation scheme that harnesses a masked attention\nmechanism to effectively isolate and mitigate the influence of functional\nprompts on moderation tasks. Extensive experiments conducted on diverse\nbenchmark datasets and models validate the feasibility and efficacy of the\nproposed approach. The results demonstrate that our methodologies achieve an\nimpressive average detection accuracy of 94.58%, surpassing the performance of\nexisting state-of-the-art techniques, alongside an exceptional moderation\nprocessing time of merely 0.002 seconds per instance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T08:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.15701v1","title":"A systematic approach to $\\ell$-loop planar integrands from the\n  classical equation of motion","summary":"In this letter, we present a recursive method for $\\ell$-loop planar\nintegrands in colored quantum field theories. We start with the classical\nequation of motion and then pick out the comb component, which will help us to\ndefine the loop kernels. Then we construct the $\\ell$-loop integrands based on\nsome recursion rules for the $\\ell$-loop kernels. Finally, we reach a recursion\nformula for the $\\ell$-loop planar integrands. Our method can be easily\ngeneralized to general quantum field theories, even non-Lagrangian theories, to\nobtain the planar part of the whole $\\ell$-loop integrands.","main_category":"hep-th","categories":"hep-th","published":"2025-04-22T08:43:33Z"}
{"aid":"http://arxiv.org/abs/2504.15726v1","title":"Barter and Hierarchy: A Practical Perspective on Food, Society, and\n  Knowledge in the Inca Empire","summary":"The Inca Empire developed a sophisticated food production system, social\norganisation, and knowledge transmission without money or writing. The article\nintroduces the concept of a barter economy structured through hierarchical\ncooperation and examines the Inca model from a practice-based (heuristical)\nperspective.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-22T09:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.15735v1","title":"Local HÃ¶lder Regularity For Nonlocal Porous Media And Fast Diffusion\n  Equations With General Kernel","summary":"We show that locally bounded, local weak solutions to certain nonlocal,\nnonlinear diffusion equations modeled on the fractional porous media and fast\ndiffusion equations given by \\begin{align*} \\partial_t u +\n(-\\Delta)^s(|u|^{m-1}u) = 0 \\quad \\mbox{ for } \\quad 0<s<1 \\quad\\text{and}\\quad\nm>0 \\end{align*} are locally H\\\"older continuous. We work with bounded,\nmeasurable kernels and provide the corresponding $L^{\\infty}_{loc} \\rightarrow\nC^{0,\\alpha}_{loc}$ De Giorgi-Nash-Moser theory for the equation via a delicate\nanalysis of the set of singularity/degeneracy in a geometry dictated by the\nsolution itself and a careful analysis of far-off effects. In particular, our\nresults are in the spirit of interior regularity, requiring the equation to\nhold only locally, and thus are new even for positive solutions of the equation\nwith constant coefficients.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T09:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.15747v1","title":"Lattice surgery-based logical state teleportation via noisy links","summary":"For planar architectures surface code-based quantum error correction is one\nof the most promising approaches to fault-tolerant quantum computation. This is\npartially due to the variety of fault-tolerant logical protocols that can be\nimplemented in two dimensions using local operations. One such protocol is the\nlattice surgery-based logical state teleportation, which transfers a logical\nquantum state from an initial location on a quantum chip to a target location\nthrough a linking region of qubits. This protocol serves as a basis for\nhigher-level routines, such as the entangling CNOT gate or magic state\ninjection. In this work we investigate the correctability phase diagram of this\nprotocol for distinct error rates inside the surface code patches and within\nthe linking region. We adopt techniques from statistical physics to describe\nthe numerically observed crossover regime between correctable and uncorrectable\nquantum error correction phases, where the correctability depends on the\nseparation between the initial and target locations. We find that inside the\ncrossover regime the correctability-threshold lines decay as a power law with\nincreasing separation, which we explain accurately using a finite-size scaling\nanalysis. Our results indicate that the logical state teleportation protocol\ncan tolerate much higher noise rates in the linking region compared to the bulk\nof the surface code patches, provided the separation between the positions is\nrelatively small.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T09:49:03Z"}
{"aid":"http://arxiv.org/abs/2504.15767v1","title":"Is there a Birch Swinnerton-Dyer conjecture for Dedekind zeta functions?","summary":"A Birch Swinnerton-Dyer conjecture for number fields $K / \\mathbb{Q}$ would\nassert that $dim V_K = ord_{s = 1/2} \\zeta_K (s)$ for some vector space\nfunctorially attached to $K$. Presently there is no natural candidate for the\n$V_K$'s. However, assuming $V_K$ is of a cohomological nature and assuming a\nconjecture of Serre on the vanishing order of $\\zeta_K (s)$ at $s = 1/2$ we\nshow that such functors $K \\mapsto V_K$ (with natural extra structures) exist\nand are all isomorphic. Their common automorphism group is $2$-torsion and\nabelian.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T10:25:17Z"}
{"aid":"http://arxiv.org/abs/2504.15812v1","title":"Fusing Reward and Dueling Feedback in Stochastic Bandits","summary":"This paper investigates the fusion of absolute (reward) and relative\n(dueling) feedback in stochastic bandits, where both feedback types are\ngathered in each decision round. We derive a regret lower bound, demonstrating\nthat an efficient algorithm may incur only the smaller among the reward and\ndueling-based regret for each individual arm. We propose two fusion approaches:\n(1) a simple elimination fusion algorithm that leverages both feedback types to\nexplore all arms and unifies collected information by sharing a common\ncandidate arm set, and (2) a decomposition fusion algorithm that selects the\nmore effective feedback to explore the corresponding arms and randomly assigns\none feedback type for exploration and the other for exploitation in each round.\nThe elimination fusion experiences a suboptimal multiplicative term of the\nnumber of arms in regret due to the intrinsic suboptimality of dueling\nelimination. In contrast, the decomposition fusion achieves regret matching the\nlower bound up to a constant under a common assumption. Extensive experiments\nconfirm the efficacy of our algorithms and theoretical results.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T11:51:20Z"}
{"aid":"http://arxiv.org/abs/2504.15813v1","title":"Thermoelectric performance of quantum dots embedded in an Aharonov-Bohm\n  ring: a Pauli master equation approach","summary":"Within linear response theory using Pauli master equation approach, we have\ninvestigated the thermoelectric properties of quantum dots (QDs) embedded in an\nAharonov-Bohm (AB) ring weakly coupled to two metallic electrodes. This study\nexplores the impact of magnetic flux on thermoelectric transport, emphasizing\nthe role of quantum interference induced by the flux. When the magnetic flux is\nvaried from 0 to one quantum of flux $\\Phi = \\Phi_{0} = \\frac{h}{e}$, both the\nelectrical conductance and the thermoelectric figure of merit ($ZT$)\nsignificantly increase by two order of magnitude. Moreover, our investigation\ninto the effects of onsite and inter-site Coulomb interactions in this\nnanojunction indicates that an optimal $ZT$ is attained with moderate onsite\nCoulomb interaction and minimal inter-site Coulomb interaction. We briefly\ndiscussed the effects of asymmetric arrangements of triple QDs within an AB\nring. However, within our parameter regime, a symmetric arrangement offers\nsuperior thermoelectric performance compared to asymmetric configurations.\nFurthermore, we explored how increasing the number of QDs in the ring enhances\nthe thermoelectric properties, resulting in a potential $ZT$ value of around\n$0.43$. This study shows that arranging multiple QDs symmetrically in an AB\nring can result in significant thermoelectric performance in nanostructured\nsystem at low temperatures.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-22T11:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.15885v1","title":"Branch-and-Bound Algorithms as Polynomial-time Approximation Schemes","summary":"Branch-and-bound algorithms (B&B) and polynomial-time approximation schemes\n(PTAS) are two seemingly distant areas of combinatorial optimization. We intend\nto (partially) bridge the gap between them while expanding the boundary of\ntheoretical knowledge on the B&B framework. Branch-and-bound algorithms\ntypically guarantee that an optimal solution is eventually found. However, we\nshow that the standard implementation of branch-and-bound for certain knapsack\nand scheduling problems also exhibits PTAS-like behavior, yielding increasingly\nbetter solutions within polynomial time. Our findings are supported by\ncomputational experiments and comparisons with benchmark methods. This paper is\nan extended version of a paper accepted at ICALP 2025.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-04-22T13:30:01Z"}
{"aid":"http://arxiv.org/abs/2504.15918v1","title":"Ask2Loc: Learning to Locate Instructional Visual Answers by Asking\n  Questions","summary":"Locating specific segments within an instructional video is an efficient way\nto acquire guiding knowledge. Generally, the task of obtaining video segments\nfor both verbal explanations and visual demonstrations is known as visual\nanswer localization (VAL). However, users often need multiple interactions to\nobtain answers that align with their expectations when using the system. During\nthese interactions, humans deepen their understanding of the video content by\nasking themselves questions, thereby accurately identifying the location.\nTherefore, we propose a new task, named In-VAL, to simulate the multiple\ninteractions between humans and videos in the procedure of obtaining visual\nanswers. The In-VAL task requires interactively addressing several semantic gap\nissues, including 1) the ambiguity of user intent in the input questions, 2)\nthe incompleteness of language in video subtitles, and 3) the fragmentation of\ncontent in video segments. To address these issues, we propose Ask2Loc, a\nframework for resolving In-VAL by asking questions. It includes three key\nmodules: 1) a chatting module to refine initial questions and uncover clear\nintentions, 2) a rewriting module to generate fluent language and create\ncomplete descriptions, and 3) a searching module to broaden local context and\nprovide integrated content. We conduct extensive experiments on three\nreconstructed In-VAL datasets. Compared to traditional end-to-end and two-stage\nmethods, our proposed Ask2Loc can improve performance by up to 14.91 (mIoU) on\nthe In-VAL task. Our code and datasets can be accessed at\nhttps://github.com/changzong/Ask2Loc.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.HC","published":"2025-04-22T14:03:16Z"}
{"aid":"http://arxiv.org/abs/2504.15926v1","title":"ErMn$_6$Sn$_6$: A Promising Kagome Antiferromagnetic Candidate for\n  Room-Temperature Nernst Effect-based thermoelectrics","summary":"The Nernst effect, the generation of a transverse electric voltage in the\npresence of longitudinal thermal gradient, has garnered significant attention\nin the realm of magnetic topological materials due to its superior potential\nfor thermoelectric applications. In this work, we investigate electronic and\nthermoelectric transport properties of a Kagome magnet ErMn$_6$Sn$_6$, a\ncompound showing an incommensurate antiferromagnetic phase followed by a\nferrimagnetic phase transition upon cooling. We show that in the\nantiferromagnetic phase ErMn$_6$Sn$_6$ exhibits both topological Nernst effect\nand anomalous Nernst effect, analogous to the electric Hall effects, with the\nNernst coefficient reaching 1.71 uV/K at 300 K and 3 T. This value surpasses\nthat of most of previously reported state-of-the-art canted antiferromagnetic\nmaterials and is comparable to recently reported other members of RMn$_6$Sn$_6$\n(R = rare-earth, Y, Lu, Sc) compounds, which makes ErMn$_6$Sn$_6$ a promising\ncandidate for advancing the development of Nernst effect-based thermoelectric\ndevices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-22T14:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.15939v1","title":"Full Crystallographic Imaging of Hexagonal Boron Nitride Monolayers with\n  Phonon-Enhanced Sum-Frequency Microscopy","summary":"Hexagonal boron nitride (hBN) is an important 2D material for van der Waals\nheterostructures, single photon emitters, and infrared nanophotonics. The\noptical characterization of mono- and few-layer samples of hBN however remains\na challenge as the material is almost invisible optically. Here we introduce\nphase-resolved sum-frequency microscopy as a technique for imaging monolayers\nof hBN grown by chemical vapor deposition (CVD) and visualize their crystal\norientation. A combination of femtosecond mid-infrared (IR) and visible laser\npulses is used for sum-frequency generation (SFG), which is imaged in a\nwide-field optical microscope. The IR laser resonantly excites a phonon of hBN\nthat leads to an ~800-fold enhancement of the SFG intensity, making it possible\nto image large 100x100 {\\mu}m2 sample areas in less than 1 s. Implementing\nheterodyne detection in combination with azimuthal rotation of the sample\nfurther provides full crystallographic information. Through combined knowledge\nof topography and crystal orientation, we find that triangular domains of\nCVD-grown monolayer hBN have nitrogen-terminated zigzag edges. Overall, SFG\nmicroscopy can be used as an ultra-sensitive tool to image crystal structure,\nstrain, stacking sequences, and twist angles, and is applicable to the wide\nrange of van der Waals structures, where location and identification of\nmonolayer regions and interfaces with broken inversion symmetry is of paramount\nimportance.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.optics","published":"2025-04-22T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.15942v1","title":"Adversarial Observations in Weather Forecasting","summary":"AI-based systems, such as Google's GenCast, have recently redefined the state\nof the art in weather forecasting, offering more accurate and timely\npredictions of both everyday weather and extreme events. While these systems\nare on the verge of replacing traditional meteorological methods, they also\nintroduce new vulnerabilities into the forecasting process. In this paper, we\ninvestigate this threat and present a novel attack on autoregressive diffusion\nmodels, such as those used in GenCast, capable of manipulating weather\nforecasts and fabricating extreme events, including hurricanes, heat waves, and\nintense rainfall. The attack introduces subtle perturbations into weather\nobservations that are statistically indistinguishable from natural noise and\nchange less than 0.1% of the measurements - comparable to tampering with data\nfrom a single meteorological satellite. As modern forecasting integrates data\nfrom nearly a hundred satellites and many other sources operated by different\ncountries, our findings highlight a critical security risk with the potential\nto cause large-scale disruptions and undermine public trust in weather\nprediction.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-22T14:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.15950v1","title":"Detector of microwave photon pairs based on a Josephson photomultiplier","summary":"We propose a viable design of a microwave two-photon threshold detector. In\nessence, the considered scheme is an extension of the existing single-photon\ndetector - a Josephson photomultiplier (JPM) - an absorbing microwave detector\nbased on a capacitively-shunted rf SQUID. To implement a two-photon threshold\ndetector, we utilize a dimer of resonators - two lumped-element resonators\ninteracting via an asymmetric dc SQUID, with one of the resonators capacitively\ncoupled to the JPM. By specific tuning of the resonator frequencies and the\nexternal flux through the dc SQUID coupler, we engineer a non-perturbative\ntwo-photon coupling between the resonators. This coupling results in the\ncoherent conversion of a photon pair from one resonator into a single photon in\nanother resonator, enabling selective response to quantum states with at least\ntwo photons. We also consider an extended coupler design that allows on-demand\n\\textit{in situ} switching of two-photon coupling. In addition, we propose the\nmodified JPM design to improve its performance. Our calculations demonstrate\nthat, for realistic circuit parameters, we can achieve more than $99\\%$\nfidelity of photon pair detection in less than 50 ns. The considered scheme may\nserve as a building block for the implementation of efficient\nphoton-number-resolving detectors in circuit QED architecture.","main_category":"quant-ph","categories":"quant-ph,cond-mat.supr-con","published":"2025-04-22T14:47:20Z"}
{"aid":"http://arxiv.org/abs/2504.15965v1","title":"From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era\n  of LLMs","summary":"Memory is the process of encoding, storing, and retrieving information,\nallowing humans to retain experiences, knowledge, skills, and facts over time,\nand serving as the foundation for growth and effective interaction with the\nworld. It plays a crucial role in shaping our identity, making decisions,\nlearning from past experiences, building relationships, and adapting to\nchanges. In the era of large language models (LLMs), memory refers to the\nability of an AI system to retain, recall, and use information from past\ninteractions to improve future responses and interactions. Although previous\nresearch and reviews have provided detailed descriptions of memory mechanisms,\nthere is still a lack of a systematic review that summarizes and analyzes the\nrelationship between the memory of LLM-driven AI systems and human memory, as\nwell as how we can be inspired by human memory to construct more powerful\nmemory systems. To achieve this, in this paper, we propose a comprehensive\nsurvey on the memory of LLM-driven AI systems. In particular, we first conduct\na detailed analysis of the categories of human memory and relate them to the\nmemory of AI systems. Second, we systematically organize existing\nmemory-related work and propose a categorization method based on three\ndimensions (object, form, and time) and eight quadrants. Finally, we illustrate\nsome open problems regarding the memory of current AI systems and outline\npossible future directions for memory in the era of large language models.","main_category":"cs.IR","categories":"cs.IR,H.0","published":"2025-04-22T15:05:04Z"}
{"aid":"http://arxiv.org/abs/2504.15982v1","title":"The effects of transport processes on the bulk composition of the first\n  generation of planetesimals interior to the water iceline","summary":"The CHNOS elemental budgets of rocky planets are crucial for their structure,\nevolution and potential chemical habitability. It is unclear how the nonlocal\ndisk processes affecting dust in planet-forming disks affect the CHNOS\nelemental budgets of nascent planets both inside and outside the Solar System.\nWe aim to quantify the coupled effect of dynamical and collisional processes on\nthe initial refractory CHNOS budgets of planetesimals, forming interior to the\nwater ice line for a Solar and non-Solar composition consistent with the star\nHIP 43393. Methods. We utilize the SHAMPOO code to track the effects of\ndynamical and collisional processes on 16000 individual dust monomers. Each\nmonomer is here assigned a refractory chemical composition and mineralogy\ninformed by the equilibrium condensation code GGCHEM given the P-T conditions\nat the initial position of the monomer. Monomers travel embedded in aggregates\nthrough a young class I disk, whose structure is calculated with the ProDiMo\ncode. Furthermore, monomers are allowed to undergo dehydration and\ndesulfurization. We find that solid material becomes well-mixed both radially\nand vertically. For both the Solar and HIP43393 compositions, the solid phase\nin the disk midplane regions interior to r~0.7AU can become enriched in\nhydrogen and sulfur by up to 10at% relative to predictions from purely local\ncalculations. This originates from the inward radial transport of hydrated and\nsulfur-bearing minerals such as lizardite and iron sulfide. Nonlocal disk\nprocessing in a young turbulent, massive disk can lead to significant\ncompositional homogenization of the midplane dust and by extension of the\ninitial composition of planetesimals. Planetesimals forming at r<0.7AU may\nbecome enriched in hydrated minerals and sulfur, which could result in more\nwidespread aqueous alteration interior to the water iceline compared to\nplanetesimals that emerge...","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-22T15:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.15989v1","title":"Token-Aware Coding Flow: A Study with Nano Surge in Reasoning Model","summary":"With the widespread application of large-scale language models (LLMs) in\nsoftware engineering, the Chain of Thought (CoT) approach has emerged as a\ncrucial tool for driving automated code generation and optimization. However,\ndespite the significant success of CoT methods in generating high-quality code,\nthe issue of token inflation during the reasoning process remains a formidable\nchallenge to model performance and efficiency, particularly when dealing with\ncomplex code smells. Code smells not only affect the maintainability and\nscalability of code but also significantly increase the computational burden\nduring LLM inference, leading to excessive token consumption and, consequently,\nreduced reasoning efficiency. This paper introduces an innovative Token-Aware\nCoding Flow method, aimed at addressing the token inflation problem caused by\nsmelly code in the CoT process. Through experimentation, we validate the\nsynergistic effect of code refactoring and prompt engineering strategies,\ndemonstrating that after eliminating code smells, token consumption during\nmodel inference is significantly reduced. The experimental results show that\nrefactored code, while maintaining functional consistency, can reduce token\nconsumption by up to 50\\%. Additionally, by explicitly prompting the type of\ncode smells in the prompt and incorporating strategies such as context\nawareness and role constraints, we further optimize the reasoning process,\nachieving a 24.5\\% to 30\\% reduction in token consumption. These optimizations\nnot only significantly enhance the model's reasoning efficiency and improve\ncode generation quality but also provide new insights for addressing\nperformance bottlenecks in complex code generation tasks.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-22T15:51:00Z"}
{"aid":"http://arxiv.org/abs/2504.15994v1","title":"The Excess Zero Graph of a Coxeter Group","summary":"For a Coxeter group $W$ with length function $\\ell$, the excess zero graph\n$\\mathcal{E}_0(W)$ has vertex set the non-identity involutions of $W$, with two\ninvolutions $x$ and $y$ adjacent whenever $\\ell(xy)=\\ell(x)+\\ell(y)$.\nProperties of this graph such as connectivity, diameter and valencies of\ncertain vertices of $\\mathcal{E}_0(W)$ are explored.","main_category":"math.GR","categories":"math.GR","published":"2025-04-22T15:57:08Z"}
{"aid":"http://arxiv.org/abs/2504.15995v1","title":"OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical\n  Federated Learning","summary":"Vertical Federated Learning (VFL) enables organizations with disjoint feature\nspaces but shared user bases to collaboratively train models without sharing\nraw data. However, existing VFL systems face critical limitations: they often\nlack effective incentive mechanisms, struggle to balance privacy-utility\ntradeoffs, and fail to accommodate clients with heterogeneous resource\ncapabilities. These challenges hinder meaningful participation, degrade model\nperformance, and limit practical deployment. To address these issues, we\npropose OPUS-VFL, an Optimal Privacy-Utility tradeoff Strategy for VFL.\nOPUS-VFL introduces a novel, privacy-aware incentive mechanism that rewards\nclients based on a principled combination of model contribution, privacy\npreservation, and resource investment. It employs a lightweight leave-one-out\n(LOO) strategy to quantify feature importance per client, and integrates an\nadaptive differential privacy mechanism that enables clients to dynamically\ncalibrate noise levels to optimize their individual utility. Our framework is\ndesigned to be scalable, budget-balanced, and robust to inference and poisoning\nattacks. Extensive experiments on benchmark datasets (MNIST, CIFAR-10, and\nCIFAR-100) demonstrate that OPUS-VFL significantly outperforms state-of-the-art\nVFL baselines in both efficiency and robustness. It reduces label inference\nattack success rates by up to 20%, increases feature inference reconstruction\nerror (MSE) by over 30%, and achieves up to 25% higher incentives for clients\nthat contribute meaningfully while respecting privacy and cost constraints.\nThese results highlight the practicality and innovation of OPUS-VFL as a\nsecure, fair, and performance-driven solution for real-world VFL.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T16:00:11Z"}
{"aid":"http://arxiv.org/abs/2504.16006v1","title":"Full dynamics of two-membrane cavity optomechanics","summary":"In a two-membrane cavity optomechanical setup, two semi-transparent membranes\nplaced within an optical Fabry-P\\'erot cavity yield a nontrivial dependence of\nthe frequency of a mode of the optical cavity on the membranes' positions,\nwhich is due to interference. However, the system dynamics is typically\ndescribed by a radiation pressure force treatment in which the frequency shift\nis expanded stopping at first order in the membrane displacements. In this\npaper, we study the full dynamics of the system obtained by considering the\nexact nonlinear dependence of the optomechanical interaction between two\nmembranes' vibrational modes and the driven cavity mode. We then compare this\ndynamics with the standard treatment based on the Hamiltonian linear\ninteraction, and we find the conditions under which the two dynamics may\nsignificantly depart from each other. In particular, we see that a parameter\nregime exists in which the customary first-order treatment provides distinct\nand incorrect predictions for the synchronization of two self-sustained\nmechanical limit-cycles, and for Gaussian entanglement of the two membranes in\nthe case of two-tone driving.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-22T16:15:04Z"}
{"aid":"http://arxiv.org/abs/2504.16071v1","title":"A Markov Chain Monte Carlo Method for Efficient Finite-Length LDPC Code\n  Design","summary":"Low-density parity-check (LDPC) codes are among the most prominent\nerror-correction schemes. They find application to fortify various modern\nstorage, communication, and computing systems. Protograph-based (PB) LDPC codes\noffer many degrees of freedom in the code design and enable fast encoding and\ndecoding. In particular, spatially-coupled (SC) and multi-dimensional (MD)\ncirculant-based codes are PB-LDPC codes with excellent performance. Efficient\nfinite-length (FL) algorithms are required in order to effectively exploit the\navailable degrees of freedom offered by SC partitioning, lifting, and MD\nrelocations. In this paper, we propose a novel Markov chain Monte Carlo (MCMC\nor MC$^2$) method to perform this FL optimization, addressing the removal of\nshort cycles. While iterating, we draw samples from a defined distribution\nwhere the probability decreases as the number of short cycles from the previous\niteration increases. We analyze our MC$^2$ method theoretically as we prove the\ninvariance of the Markov chain where each state represents a possible\npartitioning or lifting arrangement. Via our simulations, we then fit the\ndistribution of the number of cycles resulting from a given arrangement on a\nGaussian distribution. We derive estimates for cycle counts that are close to\nthe actual counts. Furthermore, we derive the order of the expected number of\niterations required by our approach to reach a local minimum as well as the\nsize of the Markov chain recurrent class. Our approach is compatible with code\ndesign techniques based on gradient-descent. Numerical results show that our\nMC$^2$ method generates SC codes with remarkably less number of short cycles\ncompared with the current state-of-the-art. Moreover, to reach the same number\nof cycles, our method requires orders of magnitude less overall time compared\nwith the available literature methods.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-22T17:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.16072v1","title":"Describe Anything: Detailed Localized Image and Video Captioning","summary":"Generating detailed and accurate descriptions for specific regions in images\nand videos remains a fundamental challenge for vision-language models. We\nintroduce the Describe Anything Model (DAM), a model designed for detailed\nlocalized captioning (DLC). DAM preserves both local details and global context\nthrough two key innovations: a focal prompt, which ensures high-resolution\nencoding of targeted regions, and a localized vision backbone, which integrates\nprecise localization with its broader context. To tackle the scarcity of\nhigh-quality DLC data, we propose a Semi-supervised learning (SSL)-based Data\nPipeline (DLC-SDP). DLC-SDP starts with existing segmentation datasets and\nexpands to unlabeled web images using SSL. We introduce DLC-Bench, a benchmark\ndesigned to evaluate DLC without relying on reference captions. DAM sets new\nstate-of-the-art on 7 benchmarks spanning keyword-level, phrase-level, and\ndetailed multi-sentence localized image and video captioning.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T17:51:41Z"}
{"aid":"http://arxiv.org/abs/2504.16083v1","title":"MMInference: Accelerating Pre-filling for Long-Context VLMs via\n  Modality-Aware Permutation Sparse Attention","summary":"The integration of long-context capabilities with visual understanding\nunlocks unprecedented potential for Vision Language Models (VLMs). However, the\nquadratic attention complexity during the pre-filling phase remains a\nsignificant obstacle to real-world deployment. To overcome this limitation, we\nintroduce MMInference (Multimodality Million tokens Inference), a dynamic\nsparse attention method that accelerates the prefilling stage for long-context\nmulti-modal inputs. First, our analysis reveals that the temporal and spatial\nlocality of video input leads to a unique sparse pattern, the Grid pattern.\nSimultaneously, VLMs exhibit markedly different sparse distributions across\ndifferent modalities. We introduce a permutation-based method to leverage the\nunique Grid pattern and handle modality boundary issues. By offline search the\noptimal sparse patterns for each head, MMInference constructs the sparse\ndistribution dynamically based on the input. We also provide optimized GPU\nkernels for efficient sparse computations. Notably, MMInference integrates\nseamlessly into existing VLM pipelines without any model modifications or\nfine-tuning. Experiments on multi-modal benchmarks-including Video QA,\nCaptioning, VisionNIAH, and Mixed-Modality NIAH-with state-of-the-art\nlong-context VLMs (LongVila, LlavaVideo, VideoChat-Flash, Qwen2.5-VL) show that\nMMInference accelerates the pre-filling stage by up to 8.3x at 1M tokens while\nmaintaining accuracy. Our code is available at https://aka.ms/MMInference.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-22T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.16422v1","title":"Cooperative-Memory Photonic Reservoir using Modulation Nonlinearity:\n  Circumventing the Speed Constraints of Nonlinear Silicon Microring Resonators","summary":"Complex dynamics of silicon microring resonators loaded by delayed feedback\nelements enable high-speed photonic reservoir computing. Implementing feedback\nis especially challenging when the required delay should match the time scales\nof silicon's nonlinearities. To increase the computation speed and preclude any\nneed for very long delay lines, we avoid relying on silicon's nonlinearity and\nmerely employ either amplitude or phase modulation along with direct detection.\nBy supplementing its memory with that of the electronic output layer, the\nproposed photonic reservoir composed of a Mach-Zehnder interferometer and a\nmicroring resonator is predicted to perform computations one order of magnitude\nfaster than those based on silicon's nonlinearity with its speed only limited\nby the modulation/detection bandwidth. This reservoir performs accurately in\nNARMA-10, Mackey-Glass, and Santa-Fe prediction tasks, and enables signal\nequalization in optical communication systems.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-23T05:13:08Z"}
{"aid":"http://arxiv.org/abs/2504.16423v1","title":"Advancing Radar Hand Gesture Recognition: A Hybrid Spectrum Synthetic\n  Framework Merging Simulation with Neural Networks","summary":"Millimeter wave (mmWave) radar sensors play a vital role in hand gesture\nrecognition (HGR) by detecting subtle motions while preserving user privacy.\nHowever, the limited scale of radar datasets hinders the performance. Existing\nsynthetic data generation methods fall short in two key areas. On the one hand,\nmodeling-based approaches fail to accurately simulate the wave propagation and\nreflection at the hand-gesture level, facing unique complexities such as\ndiffraction and occlusion. On the other hand, generative model-based methods\nare hard to converge while radar data is limited, lacking interpretability, and\nsometimes fail to produce kinematically plausible results. To overcome these\nlimitations, we propose a novel hybrid spectrum synthetic framework leveraging\nvisual hand gesture data. It combines a cylinder mesh-based hand reflection\nmodel with a small-scale neural network called RadarWeightNet, which focuses on\nassigning weights to simulated signals. Our framework addresses two key\nchallenges: achieving accurate simulation of complex hand geometry and bridging\nthe simulation-to-real gap in a data-driven manner while preserving\ninterpretability, which balances physical accuracy with machine learning\nadaptability. We tested our framework under extreme scenarios where radar data\nis scarce. The results demonstrate the effectiveness of our hybrid framework,\nachieving up to 63% SSIM in synthetic performance and up to 30% improvement in\nclassification performance in few-shot learning.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T05:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.16433v1","title":"FrogDogNet: Fourier frequency Retained visual prompt Output Guidance for\n  Domain Generalization of CLIP in Remote Sensing","summary":"In recent years, large-scale vision-language models (VLMs) like CLIP have\ngained attention for their zero-shot inference using instructional text\nprompts. While these models excel in general computer vision, their potential\nfor domain generalization in remote sensing (RS) remains underexplored.\nExisting approaches enhance prompt learning by generating visual prompt tokens\nbut rely on full-image features, introducing noise and background artifacts\nthat vary within a class, causing misclassification. To address this, we\npropose FrogDogNet, a novel prompt learning framework integrating Fourier\nfrequency filtering and self-attention to improve RS scene classification and\ndomain generalization. FrogDogNet selectively retains invariant low-frequency\ncomponents while eliminating noise and irrelevant backgrounds, ensuring robust\nfeature representation across domains. The model first extracts significant\nfeatures via projection and self-attention, then applies frequency-based\nfiltering to preserve essential structural information for prompt learning.\nExtensive experiments on four RS datasets and three domain generalization tasks\nshow that FrogDogNet consistently outperforms state-of-the-art prompt learning\nmethods, demonstrating superior adaptability across domain shifts. Our findings\nhighlight the effectiveness of frequency-based invariant feature retention in\ngeneralization, paving the way for broader applications. Our code is available\nat https://github.com/HariseetharamG/FrogDogNet","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T05:35:59Z"}
{"aid":"http://arxiv.org/abs/2504.16435v1","title":"Toward a Principled Workflow for Prevalence Mapping Using Household\n  Survey Data","summary":"Understanding the prevalence of key demographic and health indicators in\nsmall geographic areas and domains is of global interest, especially in low-\nand middle-income countries (LMICs), where vital registration data is sparse\nand household surveys are the primary source of information. Recent advances in\ncomputation and the increasing availability of spatially detailed datasets have\nled to much progress in sophisticated statistical modeling of prevalence. As a\nresult, high-resolution prevalence maps for many indicators are routinely\nproduced in the literature. However, statistical and practical guidance for\nproducing prevalence maps in LMICs has been largely lacking. In particular,\nadvice in choosing and evaluating models and interpreting results is needed,\nespecially when data is limited. Software and analysis tools are also usually\ninaccessible to researchers in low-resource settings to conduct their own\nanalysis or reproduce findings in the literature. In this paper, we propose a\ngeneral workflow for prevalence mapping using household survey data. We\nconsider all stages of the analysis pipeline, with particular emphasis on model\nchoice and interpretation. We illustrate the proposed workflow using a case\nstudy mapping the proportion of pregnant women who had at least four antenatal\ncare visits in Kenya. Reproducible code is provided in the Supplementary\nMaterials and can be readily extended to a broad collection of indicators.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-23T05:37:31Z"}
{"aid":"http://arxiv.org/abs/2504.16450v1","title":"An Effective Gram Matrix Characterizes Generalization in Deep Networks","summary":"We derive a differential equation that governs the evolution of the\ngeneralization gap when a deep network is trained by gradient descent. This\ndifferential equation is controlled by two quantities, a contraction factor\nthat brings together trajectories corresponding to slightly different datasets,\nand a perturbation factor that accounts for them training on different\ndatasets. We analyze this differential equation to compute an ``effective Gram\nmatrix'' that characterizes the generalization gap after training in terms of\nthe alignment between this Gram matrix and a certain initial ``residual''.\nEmpirical evaluations on image classification datasets indicate that this\nanalysis can predict the test loss accurately. Further, at any point during\ntraining, the residual predominantly lies in the subspace of the effective Gram\nmatrix with the smallest eigenvalues. This indicates that the training process\nis benign, i.e., it does not lead to significant deterioration of the\ngeneralization gap (which is zero at initialization). The alignment between the\neffective Gram matrix and the residual is different for different datasets and\narchitectures. The match/mismatch of the data and the architecture is primarily\nresponsible for good/bad generalization.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-23T06:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.16465v1","title":"Octonions, complex structures and Standard Model fermions","summary":"This article is a write-up of the talk given in one of the mini-symposia of\nthe 2024 European Congress of Mathematicians. I will explain some basics of the\nrepresentation theory underlying Spin(10) and SU(5) Grand Unified Theories. I\nwill also explain the characterisation of the Standard Model gauge group G_SM\nas a subgroup of Spin(10) that was developed in [1]. Thus, the symmetry\nbreaking required to obtain G_SM can be seen to rely on two suitably aligned\ncommuting complex structures on R10. The required complex structures can in\nturn be encoded in a pair of pure spinors of Spin(10). The condition that the\ncomplex structures are commuting and suitably aligned translates into the\nrequirement that the respective pure spinors are orthogonal and that their sum\nis again a pure spinor. The most efficient description of spinors, and in\nparticular pure spinors of Spin(10) is via the octonionic model of the latter,\nand this is how octonions enter the story.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T07:23:58Z"}
{"aid":"http://arxiv.org/abs/2504.16477v1","title":"Distributed Optimization with Efficient Communication, Event-Triggered\n  Solution Enhancement, and Operation Stopping","summary":"In modern large-scale systems with sensor networks and IoT devices it is\nessential to collaboratively solve complex problems while utilizing network\nresources efficiently. In our paper we present three distributed optimization\nalgorithms that exhibit efficient communication among nodes. Our first\nalgorithm presents a simple quantized averaged gradient procedure for\ndistributed optimization, which is shown to converge to a neighborhood of the\noptimal solution. Our second algorithm incorporates a novel event-triggered\nrefinement mechanism, which refines the utilized quantization level to enhance\nthe precision of the estimated optimal solution. It enables nodes to terminate\ntheir operation according to predefined performance guarantees. Our third\nalgorithm is tailored to operate in environments where each message consists of\nonly a few bits. It incorporates a novel event-triggered mechanism for\nadjusting the quantizer basis and quantization level, allowing nodes to\ncollaboratively decide operation termination based on predefined performance\ncriteria. We analyze the three algorithms and establish their linear\nconvergence. Finally, an application on distributed sensor fusion for target\nlocalization is used to demonstrate their favorable performance compared to\nexisting algorithms in the literature.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-23T07:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.16503v1","title":"Neuro-Evolutionary Approach to Physics-Aware Symbolic Regression","summary":"Symbolic regression is a technique that can automatically derive analytic\nmodels from data. Traditionally, symbolic regression has been implemented\nprimarily through genetic programming that evolves populations of candidate\nsolutions sampled by genetic operators, crossover and mutation. More recently,\nneural networks have been employed to learn the entire analytical model, i.e.,\nits structure and coefficients, using regularized gradient-based optimization.\nAlthough this approach tunes the model's coefficients better, it is prone to\npremature convergence to suboptimal model structures. Here, we propose a\nneuro-evolutionary symbolic regression method that combines the strengths of\nevolutionary-based search for optimal neural network (NN) topologies with\ngradient-based tuning of the network's parameters. Due to the inherent high\ncomputational demand of evolutionary algorithms, it is not feasible to learn\nthe parameters of every candidate NN topology to full convergence. Thus, our\nmethod employs a memory-based strategy and population perturbations to enhance\nexploitation and reduce the risk of being trapped in suboptimal NNs. In this\nway, each NN topology can be trained using only a short sequence of\nbackpropagation iterations. The proposed method was experimentally evaluated on\nthree real-world test problems and has been shown to outperform other NN-based\napproaches regarding the quality of the models obtained.","main_category":"cs.NE","categories":"cs.NE,cs.LG","published":"2025-04-23T08:29:53Z"}
{"aid":"http://arxiv.org/abs/2504.16507v1","title":"Streaming algorithms for products of probabilities","summary":"We consider streaming algorithms for approximating a product of input\nprobabilities up to multiplicative error of $1-\\epsilon$. It is shown that\nevery randomized streaming algorithm for this problem needs space $\\Omega(\\log\nn + \\log b - \\log \\epsilon) - \\mathcal{O}(1)$, where $n$ is length of the input\nstream and $b$ is the bit length of the input numbers. This matches an upper\nbound from Alur et al.~up to a constant multiplicative factor. Moreover, we\nconsider the threshold problem, where it is asked whether the product of the\ninput probabilities is below a given threshold. It is shown that every\nrandomized streaming algorithm for this problem needs space $\\Omega(n \\cdot\nb)$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T08:34:04Z"}
{"aid":"http://arxiv.org/abs/2504.16519v1","title":"Exciton Basis Description of Ultrafast Triplet Separation in\n  Pentacene-(Tetracene)2-Pentacene Intramolecular Singlet Fission Chromophore","summary":"Precise understanding of the electronic structures of optically dark\ntriplet-triplet multiexcitons that are the intermediate states in singlet\nfission (SF) continues to be a challenge. This is particularly true for\nintramolecular singlet fission (iSF) chromophores, that are oligomers of large\nmonomer molecules. We have performed quantum many-body calculations of the\ncomplete set of excited states relevant to iSF in\nPentacene-(Tetracene)2-Pentacene oligomers, consisting of two terminal\npentacene monomers linked by two tetracene monomers. Our computations use an\nexciton basis that gives physical pictorial descriptions of all eigenstates,\nand are performed over an active space of twenty-eight monomer molecular\norbitals, including configuration interaction with all relevant quadruple\nexcitations within the active space, thereby ensuring very high precision. We\ndiscuss the many-electron structures of the optical predominantly intramonomer\nspin-singlets, intermonomer charge-transfer excitations, and most importantly,\nthe complete set of low energy covalent triplet-triplet multiexcitons. We are\nable to explain the weak binding energy of the pentacene-tetracene\ntriplet-triplet eigenstate that is generated following photoexcitation. We\nexplain the increase in lifetime with increasing numbers of tetracene monomers\nof the transient absorption associated with contiguous pentacene-tetracene\ntriplet-triplet in this family of oligomers. We are consequently able to give a\npictorial description of the triplet separation following generation of the\ninitial triplet-triplet, leading to a state with individual triplets occupying\nonly the two pentacene monomers. We expect many applications of our theoretical\napproach to triplet separation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T08:44:23Z"}
{"aid":"http://arxiv.org/abs/2504.16527v1","title":"Brownian motion and generalized Lifson-Jackson formula in quasi-periodic\n  systems","summary":"Brownian motion in periodic potentials has been widely investigated in\nstatistical physics and related interdisciplinary fields. In the overdamped\nregime, it has been well-known that the diffusion constant $D^*$ is given by\nthe Lifson-Jackson (LJ) formula. With a tilted potential, this model can\nexhibit giant diffusion. In this work, we start from the basic argument that\nsince any quasi-periodic potential can be approximated accurately using a\nperiodic potential, this formula and the associated physics should also apply\nto the quasi-periodic potential after some proper redefinition. We derive $D^*$\nfrom the Smoluchowski equation using the fact that its asymptotic solution is a\nproduct of a Boltzmann weight and a Gaussian envelope function. Then we\nanalytically calculate $D^*$ in terms of Bessel functions. Finally, we study\nthe giant diffusion with quasi-periodic potentials, generalize the\ncorresponding formula to the condition with tilted potential under the same\nargument, and calculate $D^*$ analytically. This work generalizes the Brownian\nmotion from periodic potentials to the much broader quasi-periodic potentials,\nwhich should have applications in interdisciplinary fields in physics,\nchemistry, engineering, and life sciences.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-23T08:50:59Z"}
{"aid":"http://arxiv.org/abs/2504.16535v1","title":"Decentralized Quantile Regression for Feature-Distributed Massive\n  Datasets with Privacy Guarantees","summary":"In this paper, we introduce a novel decentralized surrogate gradient-based\nalgorithm for quantile regression in a feature-distributed setting, where\nglobal features are dispersed across multiple machines within a decentralized\nnetwork. The proposed algorithm, \\texttt{DSG-cqr}, utilizes a convolution-type\nsmoothing approach to address the non-smooth nature of the quantile loss\nfunction. \\texttt{DSG-cqr} is fully decentralized, conjugate-free, easy to\nimplement, and achieves linear convergence up to statistical precision. To\nensure privacy, we adopt the Gaussian mechanism to provide\n$(\\epsilon,\\delta)$-differential privacy. To overcome the exact residual\ncalculation problem, we estimate residuals using auxiliary variables and\ndevelop a confidence interval construction method based on Wald statistics.\nTheoretical properties are established, and the practical utility of the\nmethods is also demonstrated through extensive simulations and a real-world\ndata application.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-23T09:04:21Z"}
{"aid":"http://arxiv.org/abs/2504.16563v1","title":"Enhancing LLM-Based Agents via Global Planning and Hierarchical\n  Execution","summary":"Intelligent agent systems based on Large Language Models (LLMs) have shown\ngreat potential in real-world applications. However, existing agent frameworks\nstill face critical limitations in task planning and execution, restricting\ntheir effectiveness and generalizability. Specifically, current planning\nmethods often lack clear global goals, leading agents to get stuck in local\nbranches, or produce non-executable plans. Meanwhile, existing execution\nmechanisms struggle to balance complexity and stability, and their limited\naction space restricts their ability to handle diverse real-world tasks. To\naddress these limitations, we propose GoalAct, a novel agent framework that\nintroduces a continuously updated global planning mechanism and integrates a\nhierarchical execution strategy. GoalAct decomposes task execution into\nhigh-level skills, including searching, coding, writing and more, thereby\nreducing planning complexity while enhancing the agents' adaptability across\ndiverse task scenarios. We evaluate GoalAct on LegalAgentBench, a benchmark\nwith multiple types of legal tasks that require the use of multiple types of\ntools. Experimental results demonstrate that GoalAct achieves state-of-the-art\n(SOTA) performance, with an average improvement of 12.22% in success rate.\nThese findings highlight GoalAct's potential to drive the development of more\nadvanced intelligent agent systems, making them more effective across complex\nreal-world applications. Our code can be found at\nhttps://github.com/cjj826/GoalAct.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-23T09:43:40Z"}
{"aid":"http://arxiv.org/abs/2504.16581v1","title":"Revisiting Regret Benchmarks in Online Non-Stochastic Control","summary":"In the online non-stochastic control problem, an agent sequentially selects\ncontrol inputs for a linear dynamical system when facing unknown and\nadversarially selected convex costs and disturbances. A common metric for\nevaluating control policies in this setting is policy regret, defined relative\nto the best-in-hindsight linear feedback controller. However, for general\nconvex costs, this benchmark may be less meaningful since linear controllers\ncan be highly suboptimal. To address this, we introduce an alternative, more\nsuitable benchmark--the performance of the best fixed input. We show that this\nbenchmark can be viewed as a natural extension of the standard benchmark used\nin online convex optimization and propose a novel online control algorithm that\nachieves sublinear regret with respect to this new benchmark. We also discuss\nthe connections between our method and the original one proposed by Agarwal et\nal. in their seminal work introducing the online non-stochastic control\nproblem, and compare the performance of both approaches through numerical\nsimulations.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-23T10:01:34Z"}
{"aid":"http://arxiv.org/abs/2504.16590v1","title":"Testing the Gallium anomaly using Electron-Neutrino Scattering","summary":"The Gallium anomaly is an unexplained deficit in the neutrinos observed\nduring the calibration of GALLEX and SAGE using a $^{51}$Cr radioactive source\nand recently confirmed by BEST. The possible explanations for this deficit\ninclude an overestimation of the neutrino absorption cross section in Ga, an\nincorrect measurement of the source activity or the existence of sterile\nneutrinos. However, as this deficit has only been observed in Ga detectors, it\nhas not been possible to distinguish among various proposals. Therefore, we\npropose an experiment using the same radioactive source but with a different\ndetection method, electron-neutrino scattering. We discuss potential locations\nfor such an experiment, estimating the main backgrounds and expected event\nrates, considering various target masses and source positions. Even if the\nanomaly does not result from the detection method, such an experiment can\nprovide an independent determination of the branching ratio of the $^{51}$Cr\ndecay by using the spectral information or observing the scattering angle. It\nis also sensitive to an eventual baseline dependence of the anomaly, as is\npredicted in sterile neutrino models.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T10:14:32Z"}
{"aid":"http://arxiv.org/abs/2504.16639v1","title":"DAPLSR: Data Augmentation Partial Least Squares Regression Model via\n  Manifold Optimization","summary":"Traditional Partial Least Squares Regression (PLSR) models frequently\nunderperform when handling data characterized by uneven categories. To address\nthe issue, this paper proposes a Data Augmentation Partial Least Squares\nRegression (DAPLSR) model via manifold optimization. The DAPLSR model\nintroduces the Synthetic Minority Over-sampling Technique (SMOTE) to increase\nthe number of samples and utilizes the Value Difference Metric (VDM) to select\nthe nearest neighbor samples that closely resemble the original samples for\ngenerating synthetic samples. In solving the model, in order to obtain a more\naccurate numerical solution for PLSR, this paper proposes a manifold\noptimization method that uses the geometric properties of the constraint space\nto improve model degradation and optimization. Comprehensive experiments show\nthat the proposed DAPLSR model achieves superior classification performance and\noutstanding evaluation metrics on various datasets, significantly outperforming\nexisting methods.","main_category":"cs.LG","categories":"cs.LG,cs.IR","published":"2025-04-23T11:58:28Z"}
{"aid":"http://arxiv.org/abs/2504.16696v1","title":"Evaluating Meta-Regression Techniques: A Simulation Study on\n  Heterogeneity in Location and Time","summary":"In this paper, we conduct a simulation study to evaluate conventional\nmeta-regression approaches (study-level random, fixed, and mixed effects)\nagainst seven methodology specifications new to meta-regressions that control\njoint heterogeneity in location and time (including a new one that we\nintroduce). We systematically vary heterogeneity levels to assess statistical\npower, estimator bias and model robustness for each methodology specification.\nThis assessment focuses on three aspects: performance under joint heterogeneity\nin location and time, the effectiveness of our proposed settings incorporating\nlocation fixed effects and study-level fixed effects with a time trend, as well\nas guidelines for model selection. The results show that jointly modeling\nheterogeneity when heterogeneity is in both dimensions improves performance\ncompared to modeling only one type of heterogeneity.","main_category":"econ.EM","categories":"econ.EM","published":"2025-04-23T13:27:52Z"}
{"aid":"http://arxiv.org/abs/2504.16705v1","title":"Hawking-RÃ©nyi black hole thermodynamics, Kiselev solution, and cosmic\n  censorship","summary":"Explicit example, where the Hawking temperature of a black hole horizon is\ncompatible with the black hole's R\\'enyi entropy thermodynamic description, is\nconstructed. It is shown that for every static, spherically symmetric, vacuum\nblack hole space-time, a corresponding black hole solution can be derived,\nwhere the Hawking temperature is identical with the R\\'enyi temperature, i.e.\nthe one obtained from the R\\'enyi entropy of the black hole via the 1st law of\nthermodynamics. In order to have this Hawking-R\\'enyi type thermodynamic\nproperty, the black holes must be surrounded by an anisotropic fluid in the\nform of a Kiselev metric, where the properties of the fluid are uniquely\ndetermined by the mass of the black hole, $M$, and the R\\'enyi parameter,\n{\\lambda}. In the simplest Schwarzschild scenario, the system is found to be\nthermodynamically unstable, and the 3rd law of thermodynamics seems to play the\nrole of a cosmic censor via placing an upper bound on the black hole's mass, by\nwhich preventing the black hole from loosing its horizon(s).","main_category":"gr-qc","categories":"gr-qc,cond-mat.stat-mech,hep-ph,hep-th","published":"2025-04-23T13:37:41Z"}
{"aid":"http://arxiv.org/abs/2504.16723v1","title":"Detecting and Understanding Hateful Contents in Memes Through Captioning\n  and Visual Question-Answering","summary":"Memes are widely used for humor and cultural commentary, but they are\nincreasingly exploited to spread hateful content. Due to their multimodal\nnature, hateful memes often evade traditional text-only or image-only detection\nsystems, particularly when they employ subtle or coded references. To address\nthese challenges, we propose a multimodal hate detection framework that\nintegrates key components: OCR to extract embedded text, captioning to describe\nvisual content neutrally, sub-label classification for granular categorization\nof hateful content, RAG for contextually relevant retrieval, and VQA for\niterative analysis of symbolic and contextual cues. This enables the framework\nto uncover latent signals that simpler pipelines fail to detect. Experimental\nresults on the Facebook Hateful Memes dataset reveal that the proposed\nframework exceeds the performance of unimodal and conventional multimodal\nmodels in both accuracy and AUC-ROC.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T13:52:14Z"}
{"aid":"http://arxiv.org/abs/2504.16742v1","title":"Can Automated Feedback Turn Students into Happy Prologians?","summary":"Giving personalized feedback to students is very important to the learning\nprocess. However, doing so in a timely manner can be difficult to accomplish in\nvery large courses. Recent work has explored different types of automated\nfeedback adapted to different languages and programming paradigms, particularly\nlogic programming. In ProHelp, we implemented several of these types of\nfeedback so that they could be used by students enrolled in a logic programming\nclass. Then, we surveyed those students to find if the feedback was useful and\nwhich types of feedback they preferred. Results show that students found all\ntypes of feedback helpful, with automatic testing, in particular, being the\nmost helpful type. We also explore student preferences for which types of\nfeedback they would most like to see implemented in the future.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:11:54Z"}
{"aid":"http://arxiv.org/abs/2504.16749v1","title":"Feature Mixing Approach for Detecting Intraoperative Adverse Events in\n  Laparoscopic Roux-en-Y Gastric Bypass Surgery","summary":"Intraoperative adverse events (IAEs), such as bleeding or thermal injury, can\nlead to severe postoperative complications if undetected. However, their rarity\nresults in highly imbalanced datasets, posing challenges for AI-based detection\nand severity quantification. We propose BetaMixer, a novel deep learning model\nthat addresses these challenges through a Beta distribution-based mixing\napproach, converting discrete IAE severity scores into continuous values for\nprecise severity regression (0-5 scale). BetaMixer employs Beta\ndistribution-based sampling to enhance underrepresented classes and regularizes\nintermediate embeddings to maintain a structured feature space. A generative\napproach aligns the feature space with sampled IAE severity, enabling robust\nclassification and severity regression via a transformer. Evaluated on the\nMultiBypass140 dataset, which we extended with IAE labels, BetaMixer achieves a\nweighted F1 score of 0.76, recall of 0.81, PPV of 0.73, and NPV of 0.84,\ndemonstrating strong performance on imbalanced data. By integrating Beta\ndistribution-based sampling, feature mixing, and generative modeling, BetaMixer\noffers a robust solution for IAE detection and quantification in clinical\nsettings.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T14:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.16751v1","title":"Matter-antimatter asymmetry in generalized coupling theories","summary":"We explore the gravitational baryogenesis paradigm in the homogeneous and\nisotropic cosmology of generalized coupling gravity and, in particular, of the\nso-called Minimal Exponential Measure Model (MEMe). We show that, also in this\ntheory, the time derivative of the Ricci scalar couples with matter currents\nand can preserve an unbalance in the baryon-antibaryon number beyond thermal\nequilibrium. Using the current bounds on the ratio of baryon number to entropy\ndensity, we can considerably improve the known constraints on the parameter q\nthat characterizes the MEMe model. This estimate also allows us to draw\nstringent constraints on the spatial curvature of the cosmological model.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-23T14:22:19Z"}
{"aid":"http://arxiv.org/abs/2504.16754v1","title":"HEMA : A Hippocampus-Inspired Extended Memory Architecture for\n  Long-Context AI Conversations","summary":"Large language models (LLMs) struggle with maintaining coherence in extended\nconversations spanning hundreds of turns, despite performing well within their\ncontext windows. This paper introduces HEMA (Hippocampus-Inspired Extended\nMemory Architecture), a dual-memory system inspired by human cognitive\nprocesses. HEMA combines Compact Memory - a continuously updated one-sentence\nsummary preserving global narrative coherence, and Vector Memory - an episodic\nstore of chunk embeddings queried via cosine similarity. When integrated with a\n6B-parameter transformer, HEMA maintains coherent dialogues beyond 300 turns\nwhile keeping prompt length under 3,500 tokens. Experimental results show\nsubstantial improvements: factual recall accuracy increases from 41% to 87%,\nand human-rated coherence improves from 2.7 to 4.3 on a 5-point scale. With 10K\nindexed chunks, Vector Memory achieves P@5 >= 0.80 and R@50 >= 0.74, doubling\nthe area under the precision-recall curve compared to summarization-only\napproaches. Ablation studies reveal two key insights: semantic forgetting\nthrough age-weighted pruning reduces retrieval latency by 34% with minimal\nrecall loss, and a two-level summary hierarchy prevents cascade errors in\nultra-long conversations exceeding 1,000 turns. HEMA demonstrates that\ncombining verbatim recall with semantic continuity provides a practical\nsolution for privacy-aware conversational AI capable of month-long dialogues\nwithout model retraining.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T14:27:12Z"}
{"aid":"http://arxiv.org/abs/2504.16757v1","title":"Constant-Roll Inflation","summary":"Constant-roll inflation is a distinctive class of phenomenological\ninflationary models in which the inflaton's rate of roll remains constant. It\nprovides an exact solution that is compatible with the latest observational\nconstraints and offers a natural framework for enhancing the curvature power\nspectrum, which is relevant to the formation of primordial black holes. In this\npaper, I review constant-roll inflation in memory of Alexei Starobinsky.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-23T14:30:06Z"}
{"aid":"http://arxiv.org/abs/2504.16768v1","title":"How Effective are Generative Large Language Models in Performing\n  Requirements Classification?","summary":"In recent years, transformer-based large language models (LLMs) have\nrevolutionised natural language processing (NLP), with generative models\nopening new possibilities for tasks that require context-aware text generation.\nRequirements engineering (RE) has also seen a surge in the experimentation of\nLLMs for different tasks, including trace-link detection, regulatory\ncompliance, and others. Requirements classification is a common task in RE.\nWhile non-generative LLMs like BERT have been successfully applied to this\ntask, there has been limited exploration of generative LLMs. This gap raises an\nimportant question: how well can generative LLMs, which produce context-aware\noutputs, perform in requirements classification? In this study, we explore the\neffectiveness of three generative LLMs-Bloom, Gemma, and Llama-in performing\nboth binary and multi-class requirements classification. We design an extensive\nexperimental study involving over 400 experiments across three widely used\ndatasets (PROMISE NFR, Functional-Quality, and SecReq). Our study concludes\nthat while factors like prompt design and LLM architecture are universally\nimportant, others-such as dataset variations-have a more situational impact,\ndepending on the complexity of the classification task. This insight can guide\nfuture model development and deployment strategies, focusing on optimising\nprompt structures and aligning model architectures with task-specific needs for\nimproved performance.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.SE","published":"2025-04-23T14:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.16807v1","title":"Lattice QCD determination of the radiative decay rates $h_{c}\\to\n  Î·_{c}\\, Î³$ and $h_{b}\\to Î·_{b}\\, Î³$","summary":"We present the results of our lattice QCD computation of the hadronic matrix\nelements relevant to the $h_{c}\\to \\eta_{c}\\gamma$ and $h_{b}\\to\n\\eta_{b}\\gamma$ decays by using the gauge configurations produced by the\nExtended Twisted Mass Collaboration with $N_{f}=2+1+1$ dynamical Wilson-Clover\ntwisted mass fermions at five different lattice spacings with physical\ndynamical $u$ , $d$, $s$ and $c$ quark masses (except for the the coarsest\nlattice for which the lightest sea quark corresponds to a pion with\n$m_{\\pi}\\simeq 175~\\mathrm{MeV}$). While the hadronic matrix element for\n$h_{c}\\to \\eta_{c}\\gamma$ is obtained directly, the one relevant to\n$h_{b}\\to\\eta_{b}\\gamma$ is reached by working with heavy quark masses\n$m^{(n)}_{H} = \\lambda^{n-1} m_{c}$, with $\\lambda \\sim 1.24$ and $n=1,2,\n\\ldots ,6$, and then extrapolated to $m_{b}$ by several judicious ans\\\"atze. In\nthe continuum limit we obtain $\\Gamma( h_{c}\\to \\eta_{c} \\gamma ) =\n0.604(24)~\\mathrm{MeV}$, which is by a factor of $2.3$ more accurate than the\nprevious lattice estimates, and in good agreement with the experimental\nmeasurement. In the $b$-quark case we obtain $\\Gamma( h_{b}\\to \\eta_{b} \\gamma)\n=46.0(4.8)~\\mathrm{keV}$.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-23T15:26:36Z"}
{"aid":"http://arxiv.org/abs/2504.16813v1","title":"LLM-assisted Graph-RAG Information Extraction from IFC Data","summary":"IFC data has become the general building information standard for\ncollaborative work in the construction industry. However, IFC data can be very\ncomplicated because it allows for multiple ways to represent the same product\ninformation. In this research, we utilise the capabilities of LLMs to parse the\nIFC data with Graph Retrieval-Augmented Generation (Graph-RAG) technique to\nretrieve building object properties and their relations. We will show that,\ndespite limitations due to the complex hierarchy of the IFC data, the Graph-RAG\nparsing enhances generative LLMs like GPT-4o with graph-based knowledge,\nenabling natural language query-response retrieval without the need for a\ncomplex pipeline.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T15:31:11Z"}
{"aid":"http://arxiv.org/abs/2504.16840v1","title":"A Low-Cost Photogrammetry System for 3D Plant Modeling and Phenotyping","summary":"We present an open-source, low-cost photogrammetry system for 3D plant\nmodeling and phenotyping. The system uses a structure-from-motion approach to\nreconstruct 3D representations of the plants via point clouds. Using wheat as\nan example, we demonstrate how various phenotypic traits can be computed easily\nfrom the point clouds. These include standard measurements such as plant height\nand radius, as well as features that would be more cumbersome to measure by\nhand, such as leaf angles and convex hull. We further demonstrate the utility\nof the system through the investigation of specific metrics that may yield\nobjective classifications of erectophile versus planophile wheat canopy\narchitectures.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T16:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.16858v1","title":"Planning with Diffusion Models for Target-Oriented Dialogue Systems","summary":"Target-Oriented Dialogue (TOD) remains a significant challenge in the LLM\nera, where strategic dialogue planning is crucial for directing conversations\ntoward specific targets. However, existing dialogue planning methods generate\ndialogue plans in a step-by-step sequential manner, and may suffer from\ncompounding errors and myopic actions. To address these limitations, we\nintroduce a novel dialogue planning framework, DiffTOD, which leverages\ndiffusion models to enable non-sequential dialogue planning. DiffTOD formulates\ndialogue planning as a trajectory generation problem with conditional guidance,\nand leverages a diffusion language model to estimate the likelihood of the\ndialogue trajectory. To optimize the dialogue action strategies, DiffTOD\nintroduces three tailored guidance mechanisms for different target types,\noffering flexible guidance towards diverse TOD targets at test time. Extensive\nexperiments across three diverse TOD settings show that DiffTOD can effectively\nperform non-myopic lookahead exploration and optimize action strategies over a\nlong horizon through non-sequential dialogue planning, and demonstrates strong\nflexibility across complex and diverse dialogue scenarios. Our code and data\nare accessible through https://anonymous.4open.science/r/DiffTOD.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T16:27:15Z"}
{"aid":"http://arxiv.org/abs/2504.16863v1","title":"On graphs with a simple structure of maximal cliques","summary":"We say that a hereditary graph class $\\mathcal{G}$ is \\emph{clique-sparse} if\nthere is a constant $k=k(\\mathcal{G})$ such that for every graph\n$G\\in\\mathcal{G}$, every vertex of $G$ belongs to at most $k$ maximal cliques,\nand any maximal clique of $G$ can be intersected in at most $k$ different ways\nby other maximal cliques.\n  We provide various characterisations of clique-sparse graph classes,\nincluding a list of five parametric forbidden induced subgraphs. We show that\nrecent techniques for proving induced analogues of Menger's Theorem and the\nGrid Theorem of Robertson and Seymour can be lifted to prove induced variants\nin clique-sparse graph classes when replacing ``treewidth'' by\n''tree-independence number''.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-23T16:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.16891v1","title":"AIMO-2 Winning Solution: Building State-of-the-Art Mathematical\n  Reasoning Models with OpenMathReasoning dataset","summary":"This paper presents our winning submission to the AI Mathematical Olympiad -\nProgress Prize 2 (AIMO-2) competition. Our recipe for building state-of-the-art\nmathematical reasoning models relies on three key pillars. First, we create a\nlarge-scale dataset comprising 540K unique high-quality math problems,\nincluding olympiad-level problems, and their 3.2M long-reasoning solutions.\nSecond, we develop a novel method to integrate code execution with long\nreasoning models through iterative training, generation, and quality filtering,\nresulting in 1.7M high-quality Tool-Integrated Reasoning solutions. Third, we\ncreate a pipeline to train models to select the most promising solution from\nmany candidates. We show that such generative solution selection (GenSelect)\ncan significantly improve upon majority voting baseline. Combining these ideas,\nwe train a series of models that achieve state-of-the-art results on\nmathematical reasoning benchmarks. To facilitate further research, we release\nour code, models, and the complete OpenMathReasoning dataset under a\ncommercially permissive license.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG","published":"2025-04-23T17:13:04Z"}
{"aid":"http://arxiv.org/abs/2504.16903v1","title":"Collinear Corrections to the Cachazo-Strominger Soft Theorem","summary":"Soft theorems describe the behavior of scattering amplitudes when one or\nseveral external particles are taken to be energetically soft. In tree-level\ngravity there are universal soft theorems for the three leading orders in the\nsoft expansion, and they can be shown to be equivalent to Ward identities of\nasymptotic symmetries. While the leading and subleading symmetries are\nunderstood as supertranslations and superrotations respectively, the precise\nsymmetry interpretation of the sub-subleading soft theorem is still a matter of\ninvestigation. The form of the sub-subleading soft graviton theorem was\nelucidated by Cachazo and Strominger using a BCFW expansion of graviton\namplitudes. In this work we show that consistency with results based on\nasymptotic charges requires a careful treatment of collinear singularities in\nthe amplitude, giving rise to collinear corrections to the usual\nCachazo-Strominger soft theorem.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T17:27:52Z"}
{"aid":"http://arxiv.org/abs/2504.16908v1","title":"Axiomatic Equilibrium Selection: The Case of Generic Extensive Form\n  Games","summary":"A solution concept that is a refinement of Nash equilibria selects for each\nfinite game a nonempty collection of closed and connected subsets of Nash\nequilibria as solutions. We impose three axioms for such solution concepts. The\naxiom of backward induction requires each solution to contain a quasi-perfect\nequilibrium. Two invariance axioms posit that solutions of a game are the same\nas those of a game obtained by the addition of strategically irrelevant\nstrategies and players. Stability satisfies these axioms; and any solution\nconcept that satisfies them must, for generic extensive-form games, select from\namong its stable outcomes. A strengthening of the two invariance axioms\nprovides an analogous axiomatization of components of equilibria with a nonzero\nindex.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-23T17:35:47Z"}
{"aid":"http://arxiv.org/abs/2504.16924v1","title":"Ultradense Sphere Packings Derived From Disordered Stealthy Hyperuniform\n  Ground States","summary":"Disordered stealthy hyperuniform (SHU) packings are an emerging class of\nexotic amorphous two-phase materials endowed with novel physical properties.\nSuch packings of identical spheres have been created from SHU point patterns\nvia a modified collective-coordinate optimization scheme that includes a\nsoft-core repulsion, besides the standard `stealthy' pair potential. Using the\ndistributions of minimum pair distances and nearest-neighbor distances, we find\nthat when the stealthiness parameter $\\chi$ is lower than 0.5, the maximal\nvalues of $\\phi$, denoted by $\\phi_{\\max}$, decrease to zero on average as the\nparticle number $N$ increases if there are no soft-core repulsions. By\ncontrast, the inclusion of soft-core repulsions results in very large\n$\\phi_{\\max}$ independent of $N$, reaching up to $\\phi_{\\max}=1.0, 0.86, 0.63$\nin the zero-$\\chi$ limit and decreasing to $\\phi_{\\max}=1.0, 0.67, 0.47$ at\n$\\chi=0.45$ for $d=1,2,3$, respectively. We obtain explicit formulas for\n$\\phi_{\\max}$ as functions of $\\chi$ and $N$ for a given $d$. For $d=2,3$, our\nsoft-core SHU packings for small $\\chi$ become configurationally very close to\nthe jammed hard-particle packings created by fast compression algorithms, as\nmeasured by the pair statistics. As $\\chi$ increases beyond $0.20$, the\npackings form fewer contacts and linear polymer-like chains. The resulting\nstructure factors $S(k)$ and pair correlation functions $g_2(r)$ reveal that\nsoft-core repulsions significantly alter the short- and intermediate-range\ncorrelations in the SHU ground states. We also compute the spectral density\n$\\tilde{\\chi}_{_V}(k)$, which can be used to estimate various physical\nproperties (e.g., electromagnetic properties, fluid permeability, and mean\nsurvival time) of SHU two-phase dispersions. Our results offer a new route for\ndiscovering novel disordered hyperuniform two-phase materials with\nunprecedentedly high density.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.dis-nn,physics.comp-ph","published":"2025-04-23T17:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.16932v1","title":"Dispu$Ï$able: the high cost of a low optical depth","summary":"Recent Baryonic Acoustic Oscillation (BAO) measurements from the Dark Energy\nSpectroscopic Instrument (DESI) are mildly discrepant ($2.2\\sigma$) with the\nCosmic Microwave Background (CMB) when interpreted within $\\Lambda$CDM. When\nanalyzing these data with extended cosmologies this inconsistency manifests as\na $\\simeq3\\sigma$ preference for sub-minimal neutrino mass or evolving dark\nenergy. It is known that the preference for sub-minimal neutrino mass from the\nsuppression of structure growth could be alleviated by increasing the optical\ndepth to reionization $\\tau$. We show that, because the CMB-inferred $\\tau$ is\nnegatively correlated with the matter fraction, a larger optical depth resolves\na similar preference from geometric constraints. Optical depths large enough to\nresolve the neutrino mass tension ($\\tau\\sim0.09)$ also reduce the preference\nfor evolving dark energy from $\\simeq3\\sigma$ to $\\simeq1.5\\sigma$. Conversely,\nwithin $\\Lambda$CDM the combination of DESI BAO, high-$\\ell$ CMB and CMB\nlensing yields $\\tau = 0.090 \\pm 0.012$. The required increase in $\\tau$ is in\n$\\simeq3-5\\sigma$ tension with Planck low-$\\ell$ polarization data when taken\nat face value. While there is no evidence for systematics in the large-scale\nPlanck data, $\\tau$ remains the least well-constrained $\\Lambda$CDM parameter\nand is far from its cosmic variance limit. The importance of $\\tau$ for several\ncosmological measurements strengthens the case for future large-scale CMB\nexperiments as well as direct probes of the epoch of reionization.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-23T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.17233v1","title":"An Adaptive Finite Element DtN Method for the Acoustic-Elastic\n  Interaction Problem in Periodic Structures","summary":"Consider a time-harmonic acoustic plane wave incident onto an elastic body\nwith an unbounded periodic surface. The medium above the surface is supposed to\nbe filled with a homogeneous compressible inviscid air/fluid of constant mass\ndensity, while the elastic body is assumed to be isotropic and linear. By\nintroducing the Dirichlet-to-Neumann (DtN) operators for acoustic and elastic\nwaves simultaneously, the model is formulated as an acoustic-elastic\ninteraction problem in periodic structures. Based on a duality argument, an a\nposteriori error estimate is derived for the associated truncated finite\nelement approximation. The a posteriori error estimate consists of the finite\nelement approximation error and the truncation error of two different DtN\noperators, where the latter decays exponentially with respect to the truncation\nparameter. Based on the a posteriori error, an adaptive finite element\nalgorithm is proposed for solving the acoustic-elastic interaction problem in\nperiodic structures. Numerical experiments are presented to demonstrate the\neffectiveness of the proposed algorithm.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-24T04:01:09Z"}
{"aid":"http://arxiv.org/abs/2504.17249v1","title":"Demonstrating Berkeley Humanoid Lite: An Open-source, Accessible, and\n  Customizable 3D-printed Humanoid Robot","summary":"Despite significant interest and advancements in humanoid robotics, most\nexisting commercially available hardware remains high-cost, closed-source, and\nnon-transparent within the robotics community. This lack of accessibility and\ncustomization hinders the growth of the field and the broader development of\nhumanoid technologies. To address these challenges and promote democratization\nin humanoid robotics, we demonstrate Berkeley Humanoid Lite, an open-source\nhumanoid robot designed to be accessible, customizable, and beneficial for the\nentire community. The core of this design is a modular 3D-printed gearbox for\nthe actuators and robot body. All components can be sourced from widely\navailable e-commerce platforms and fabricated using standard desktop 3D\nprinters, keeping the total hardware cost under $5,000 (based on U.S. market\nprices). The design emphasizes modularity and ease of fabrication. To address\nthe inherent limitations of 3D-printed gearboxes, such as reduced strength and\ndurability compared to metal alternatives, we adopted a cycloidal gear design,\nwhich provides an optimal form factor in this context. Extensive testing was\nconducted on the 3D-printed actuators to validate their durability and\nalleviate concerns about the reliability of plastic components. To demonstrate\nthe capabilities of Berkeley Humanoid Lite, we conducted a series of\nexperiments, including the development of a locomotion controller using\nreinforcement learning. These experiments successfully showcased zero-shot\npolicy transfer from simulation to hardware, highlighting the platform's\nsuitability for research validation. By fully open-sourcing the hardware\ndesign, embedded code, and training and deployment frameworks, we aim for\nBerkeley Humanoid Lite to serve as a pivotal step toward democratizing the\ndevelopment of humanoid robotics. All resources are available at\nhttps://lite.berkeley-humanoid.org.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-24T04:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.17255v1","title":"3D Deep-learning-based Segmentation of Human Skin Sweat Glands and Their\n  3D Morphological Response to Temperature Variations","summary":"Skin, the primary regulator of heat exchange, relies on sweat glands for\nthermoregulation. Alterations in sweat gland morphology play a crucial role in\nvarious pathological conditions and clinical diagnoses. Current methods for\nobserving sweat gland morphology are limited by their two-dimensional, in\nvitro, and destructive nature, underscoring the urgent need for real-time,\nnon-invasive, quantifiable technologies. We proposed a novel three-dimensional\n(3D) transformer-based multi-object segmentation framework, integrating a\nsliding window approach, joint spatial-channel attention mechanism, and\narchitectural heterogeneity between shallow and deep layers. Our proposed\nnetwork enables precise 3D sweat gland segmentation from skin volume data\ncaptured by optical coherence tomography (OCT). For the first time, subtle\nvariations of sweat gland 3D morphology in response to temperature changes,\nhave been visualized and quantified. Our approach establishes a benchmark for\nnormal sweat gland morphology and provides a real-time, non-invasive tool for\nquantifying 3D structural parameters. This enables the study of individual\nvariability and pathological changes in sweat gland structure, advancing\ndermatological research and clinical applications, including thermoregulation\nand bromhidrosis treatment.","main_category":"eess.IV","categories":"eess.IV,cs.AI,physics.optics","published":"2025-04-24T05:19:47Z"}
{"aid":"http://arxiv.org/abs/2504.17257v1","title":"Electrohydrodynamic drift of a drop away from an insulating wall","summary":"An isolated charge-neutral drop suspended in an unbounded medium does not\nmigrate in a uniform DC electric field.\n  A nearby wall breaks the symmetry and causes the drop to drift towards or\naway from the boundary, depending on the electric properties of the fluids and\nthe wall. In the case of an electrically insulating wall and an electric field\napplied tangentially to the wall, the interaction of the drop with its\nelectrostatic image gives rise to repulsion by the wall. However, the\nelectrohydrodynamic flow causes either repulsion for a drop with\n$\\mathrm{R/P}<1$, where $\\mathrm{R}$ and $\\mathrm{P}$ are the drop-to-medium\nratios of conductivity and permittivity, respectively, or attraction for\n$\\mathrm{R/P}>1$. We experimentally measure droplet trajectories and quantify\nthe wall-induced electrohydrodynamic lift in the case $\\mathrm{R/P}<1$.\nNumerical simulations using the boundary integral method agree well with the\nexperiment and also explore the $\\mathrm{R/P}>1$ case. The results show that\nthe lateral migration of a drop in a uniform electric field applied parallel to\nan insulating wall is dominated by the long-range flow due to the image\nstresslet.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-24T05:28:44Z"}
{"aid":"http://arxiv.org/abs/2504.17270v1","title":"Thermally quenched metastable phase in the Ising model with competing\n  interactions","summary":"Thermal quenching has been used to find metastable materials such as hard\nsteels and metallic glasses. More recently, quenching-based phase control has\nbeen applied to correlated electron systems that exhibit metal--insulator,\nmagnetic or superconducting transitions. Despite the discovery of metastable\nelectronic phases, however, how metastability is achieved through the degrees\nof freedom, which can vary even at low temperatures such as those of an\nelectron, is unclear. Here, we show a thermally quenched metastable phase in\nthe Ising model without conservation of magnetization by Monte Carlo\nsimulations. When multiple types of interactions that stabilize different\nlong-range orders are introduced, the ordering kinetics divergently slow toward\nlow temperatures, meaning that the system will reach a low temperature without\nordering if the cooling rate is high enough. Quantitative analysis of the\ndivergent behavior suggests that the energy barrier for eliminating the local\nstructure of competing orders is the origin of this metastability. Thus, the\npresent simulations show that competing interactions play a key role in\nrealizing metastability.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.stat-mech","published":"2025-04-24T05:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.17271v1","title":"Contrastive Learning for Continuous Touch-Based Authentication","summary":"Smart mobile devices have become indispensable in modern daily life, where\nsensitive information is frequently processed, stored, and transmitted-posing\ncritical demands for robust security controls. Given that touchscreens are the\nprimary medium for human-device interaction, continuous user authentication\nbased on touch behavior presents a natural and seamless security solution.\nWhile existing methods predominantly adopt binary classification under\nsingle-modal learning settings, we propose a unified contrastive learning\nframework for continuous authentication in a non-disruptive manner.\nSpecifically, the proposed method leverages a Temporal Masked Autoencoder to\nextract temporal patterns from raw multi-sensor data streams, capturing\ncontinuous motion and gesture dynamics. The pre-trained TMAE is subsequently\nintegrated into a Siamese Temporal-Attentive Convolutional Network within a\ncontrastive learning paradigm to model both sequential and cross-modal\npatterns. To further enhance performance, we incorporate multi-head attention\nand channel attention mechanisms to capture long-range dependencies and\noptimize inter-channel feature integration. Extensive experiments on public\nbenchmarks and a self-collected dataset demonstrate that our approach\noutperforms state-of-the-art methods, offering a reliable and effective\nsolution for user authentication on mobile devices.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T05:58:12Z"}
{"aid":"http://arxiv.org/abs/2504.17272v1","title":"Development and Explainability of Models for Machine-Learning-Based\n  Reconstruction of Signals in Particle Detectors","summary":"Machine learning methods are being introduced at all stages of data\nreconstruction and analysis in various high-energy physics experiments. We\npresent the development and application of convolutional neural networks with\nmodified autoencoder architecture for the reconstruction of the pulse arrival\ntime and amplitude in individual scintillating crystals in electromagnetic\ncalorimeters and other detectors. The network performance is discussed as well\nas the application of xAI methods for further investigation of the algorithm\nand improvement of the output accuracy.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex,physics.comp-ph","published":"2025-04-24T06:01:11Z"}
{"aid":"http://arxiv.org/abs/2504.17282v1","title":"Cracking the Code of Action: a Generative Approach to Affordances for\n  Reinforcement Learning","summary":"Agents that can autonomously navigate the web through a graphical user\ninterface (GUI) using a unified action space (e.g., mouse and keyboard actions)\ncan require very large amounts of domain-specific expert demonstrations to\nachieve good performance. Low sample efficiency is often exacerbated in\nsparse-reward and large-action-space environments, such as a web GUI, where\nonly a few actions are relevant in any given situation. In this work, we\nconsider the low-data regime, with limited or no access to expert behavior. To\nenable sample-efficient learning, we explore the effect of constraining the\naction space through $\\textit{intent-based affordances}$ -- i.e., considering\nin any situation only the subset of actions that achieve a desired outcome. We\npropose $\\textbf{Code as Generative Affordances}$ $(\\textbf{$\\texttt{CoGA}$})$,\na method that leverages pre-trained vision-language models (VLMs) to generate\ncode that determines affordable actions through implicit intent-completion\nfunctions and using a fully-automated program generation and verification\npipeline. These programs are then used in-the-loop of a reinforcement learning\nagent to return a set of affordances given a pixel observation. By greatly\nreducing the number of actions that an agent must consider, we demonstrate on a\nwide range of tasks in the MiniWob++ benchmark that: $\\textbf{1)}$\n$\\texttt{CoGA}$ is orders of magnitude more sample efficient than its RL agent,\n$\\textbf{2)}$ $\\texttt{CoGA}$'s programs can generalize within a family of\ntasks, and $\\textbf{3)}$ $\\texttt{CoGA}$ performs better or on par compared\nwith behavior cloning when a small number of expert demonstrations is\navailable.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T06:20:08Z"}
{"aid":"http://arxiv.org/abs/2504.17308v1","title":"Physics-based super-resolved simulation of 3D elastic wave propagation\n  adopting scalable Diffusion Transformer","summary":"In this study, we develop a Diffusion Transformer (referred as to DiT1D) for\nsynthesizing realistic earthquake time histories. The DiT1D generates realistic\nbroadband accelerograms (0-30 Hz resolution), constrained at low frequency by\n3-dimensional (3D) elastodynamics numerical simulations, ensuring the\nfulfillment of the minimum observable physics. The DiT1D architecture,\nsuccessfully adopted in super-resolution image generation, is trained on\nrecorded single-station 3-components (3C) accelerograms. Thanks to Multi-Head\nCross-Attention (MHCA) layers, we guide the DiT1D inference by enforcing the\nlow-frequency part of the accelerogram spectrum into it. The DiT1D learns the\nlow-to-high frequency map from the recorded accelerograms, duly normalized, and\nsuccessfully transfer it to synthetic time histories. The latter are\nlow-frequency by nature, because of the lack of knowledge on the underground\nstructure of the Earth, demanded to fully calibrate the numerical model. We\ndeveloped a CNN-LSTM lightweight network in conjunction with the DiT1D, so to\npredict the peak amplitude of the broadband signal from its low-pass-filtered\ncounterpart, and rescale the normalized accelerograms rendered by the DiT1D.\nDespite the DiT1D being agnostic to any earthquake event peculiarities\n(magnitude, site conditions, etc.), it showcases remarkable zero-shot\nprediction realism when applied to the output of validated earthquake\nsimulations. The generated time histories are viable input accelerograms for\nearthquake-resistant structural design and the pre-trained DiT1D holds a huge\npotential to integrate full-scale fault-to-structure digital twins of\nearthquake-prone regions.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-24T07:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.17327v1","title":"Simple Universally Optimal Dijkstra","summary":"Let G be a weighted (directed) graph with n vertices and m edges. Given a\nsource vertex s, Dijkstra's algorithm computes the shortest path lengths from s\nto all other vertices in O(m + n log n) time. This bound is known to be\nworst-case optimal via a reduction to sorting. Theoretical computer science has\ndeveloped numerous fine-grained frameworks for analyzing algorithmic\nperformance beyond standard worst-case analysis, such as instance optimality\nand output sensitivity. Haeupler et al. [FOCS '24] consider the notion of\nuniversal optimality, a refined complexity measure that accounts for both the\ngraph topology and the edge weights. For a fixed graph topology, the universal\nrunning time of a weighted graph algorithm is defined as its worst-case running\ntime over all possible edge weightings of G. An algorithm is universally\noptimal if no other algorithm achieves a better asymptotic universal running\ntime on any particular graph topology. They show that Dijkstra's algorithm can\nbe made universally optimal by replacing the heap with a custom data structure.\n  We revisit their result. We introduce a simple heap property called timestamp\noptimality, where the cost of popping an element x is logarithmic in the number\nof elements inserted between pushing and popping x. We show that timestamp\noptimal heaps are not only easier to define but also easier to implement. Using\nthese timestamps, we provide a significantly simpler proof that Dijkstra's\nalgorithm, with the right kind of heap, is universally optimal.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T07:40:44Z"}
{"aid":"http://arxiv.org/abs/2504.17337v1","title":"Error Exponents for DNA Storage Codes with a Variable Number of Reads","summary":"In this paper, we study error exponents for a concatataned coding based class\nof DNA storage codes in which the number of reads performed can be variable.\nThat is, the decoder can sequentially perform reads and choose whether to\noutput the final decision or take more reads, and we are interested in\nminimizing the average number of reads performed rather than a fixed\npre-specified value. We show that this flexibility leads to a considerable\nreduction in the error probability compared to a fixed number of reads, not\nonly in terms of constants in the error exponent but also in the scaling laws.\nThis is shown via an achievability result for a suitably-designed protocol, and\nin certain parameter regimes we additionally establish a matching converse that\nholds for all protocols within a broader concatenated coding based class.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T07:56:21Z"}
{"aid":"http://arxiv.org/abs/2504.17338v1","title":"Dynamic Approximate Maximum Matching in the Distributed Vertex Partition\n  Model","summary":"We initiate the study of approximate maximum matching in the vertex partition\nmodel, for graphs subject to dynamic changes. We assume that the $n$ vertices\nof the graph are partitioned among $k$ players, who execute a distributed\nalgorithm and communicate via message passing. An adaptive adversary may\nperform dynamic updates to the graph topology by inserting or removing edges\nbetween the nodes, and the algorithm needs to respond to these changes by\nadapting the output of the players, with the goal of maintaining an approximate\nmaximum matching. The main performance metric in this setting is the\nalgorithm's update time, which corresponds to the number of rounds required for\nupdating the solution upon an adversarial change. For the standard setting of\nsingle-edge insertions and deletions, we obtain the following results:\n  We give a randomized Las Vegas algorithm with an expected update time of $O(\n\\frac{\\sqrt{m}}{\\beta k} )$ rounds that maintains a $\\frac{2}{3}$-approximate\nmaximum matching that is also maximal, where $m$ is the number of edges of the\ngraph. We also show that any algorithm has a worst case update time of $\\Omega(\n\\frac{n}{\\beta k^2\\log n} )$, assuming a link bandwidth of $O(\\beta\\log n)$\nbits per round, if it maintains a matching that is maximal and does not have\nany 3-augmenting paths. For batch-dynamic updates, where the adversary may\nmodify up to $\\ell\\ge 1$ edges at once, we prove the following: There is a\nrandomized algorithm that succeeds with high probability in maintaining a\n$\\frac{2}{3}$-approximate maximum matching and has a worst case update time of\n$\\Omega( \\frac{\\ell\\log n}{\\sqrt{\\beta k}} )$ rounds. We show that $\\Omega(\n\\frac{\\ell}{\\beta k \\log n} )$ poses a lower bound for maintaining a maximal\nmatching without 3-augmenting paths.","main_category":"cs.DC","categories":"cs.DC,cs.DS","published":"2025-04-24T07:56:21Z"}
{"aid":"http://arxiv.org/abs/2504.17349v1","title":"DRC: Enhancing Personalized Image Generation via Disentangled\n  Representation Composition","summary":"Personalized image generation has emerged as a promising direction in\nmultimodal content creation. It aims to synthesize images tailored to\nindividual style preferences (e.g., color schemes, character appearances,\nlayout) and semantic intentions (e.g., emotion, action, scene contexts) by\nleveraging user-interacted history images and multimodal instructions. Despite\nnotable progress, existing methods -- whether based on diffusion models, large\nlanguage models, or Large Multimodal Models (LMMs) -- struggle to accurately\ncapture and fuse user style preferences and semantic intentions. In particular,\nthe state-of-the-art LMM-based method suffers from the entanglement of visual\nfeatures, leading to Guidance Collapse, where the generated images fail to\npreserve user-preferred styles or reflect the specified semantics.\n  To address these limitations, we introduce DRC, a novel personalized image\ngeneration framework that enhances LMMs through Disentangled Representation\nComposition. DRC explicitly extracts user style preferences and semantic\nintentions from history images and the reference image, respectively, to form\nuser-specific latent instructions that guide image generation within LMMs.\nSpecifically, it involves two critical learning stages: 1) Disentanglement\nlearning, which employs a dual-tower disentangler to explicitly separate style\nand semantic features, optimized via a reconstruction-driven paradigm with\ndifficulty-aware importance sampling; and 2) Personalized modeling, which\napplies semantic-preserving augmentations to effectively adapt the disentangled\nrepresentations for robust personalized generation. Extensive experiments on\ntwo benchmarks demonstrate that DRC shows competitive performance while\neffectively mitigating the guidance collapse issue, underscoring the importance\nof disentangled representation learning for controllable and effective\npersonalized image generation.","main_category":"cs.CV","categories":"cs.CV,cs.IR","published":"2025-04-24T08:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.17350v1","title":"First-order store and visibility in name-passing calculi","summary":"The $\\pi$-calculus is the paradigmatical name-passing calculus. While being\npurely name-passing, it allows the representation of higher-order functions and\nstore. We study how $\\pi$-calculus processes can be controlled so that\ncomputations can only involve storage of first-order values. The discipline is\nenforced by a type system that is based on the notion of visibility, coming\nfrom game semantics. We discuss the impact of visibility on the behavioural\ntheory. We propose characterisations of may-testing and barbed equivalence,\nbased on (variants of) trace equivalence and labelled bisimilarity, in the case\nwhere computation is sequential, and in the case where computation is\nwell-bracketed.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-24T08:11:02Z"}
{"aid":"http://arxiv.org/abs/2504.17371v1","title":"Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D\n  Dataset","summary":"Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet,\ntraditional datasets are usually captured by fixed sensors mounted on a car and\nare susceptible to occlusion. Additionally, such an approach can precisely\nreconstruct the dynamic environment in the close vicinity of the measurement\nvehicle only, while neglecting objects that are further away. In this paper, we\nintroduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality,\nocclusion-free dataset of 6 degrees of freedom bounding box trajectories\nacquired through a novel monocular camera drone tracking pipeline. Our dataset\nincludes more than 175,000 trajectories of 14 types of traffic participants and\nsignificantly exceeds existing datasets in terms of diversity and scale,\ncontaining many unprecedented scenarios such as complex vehicle-pedestrian\ninteraction on highly populated urban streets and comprehensive parking\nmaneuvers from entry to exit. DSC3D dataset was captured in five various\nlocations in Europe and the United States and include: a parking lot, a crowded\ninner-city, a steep urban intersection, a federal highway, and a suburban\nintersection. Our 3D trajectory dataset aims to enhance autonomous driving\nsystems by providing detailed environmental 3D representations, which could\nlead to improved obstacle interactions and safety. We demonstrate its utility\nacross multiple applications including motion prediction, motion planning,\nscenario mining, and generative reactive traffic agents. Our interactive online\nvisualization platform and the complete dataset are publicly available at\napp.deepscenario.com, facilitating research in motion prediction, behavior\nmodeling, and safety validation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T08:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.17384v1","title":"On the workflow, opportunities and challenges of developing foundation\n  model in geophysics","summary":"Foundation models, as a mainstream technology in artificial intelligence,\nhave demonstrated immense potential across various domains in recent years,\nparticularly in handling complex tasks and multimodal data. In the field of\ngeophysics, although the application of foundation models is gradually\nexpanding, there is currently a lack of comprehensive reviews discussing the\nfull workflow of integrating foundation models with geophysical data. To\naddress this gap, this paper presents a complete framework that systematically\nexplores the entire process of developing foundation models in conjunction with\ngeophysical data. From data collection and preprocessing to model architecture\nselection, pre-training strategies, and model deployment, we provide a detailed\nanalysis of the key techniques and methodologies at each stage. In particular,\nconsidering the diversity, complexity, and physical consistency constraints of\ngeophysical data, we discuss targeted solutions to address these challenges.\nFurthermore, we discuss how to leverage the transfer learning capabilities of\nfoundation models to reduce reliance on labeled data, enhance computational\nefficiency, and incorporate physical constraints into model training, thereby\nimproving physical consistency and interpretability. Through a comprehensive\nsummary and analysis of the current technological landscape, this paper not\nonly fills the gap in the geophysics domain regarding a full-process review of\nfoundation models but also offers valuable practical guidance for their\napplication in geophysical data analysis, driving innovation and advancement in\nthe field.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.AI","published":"2025-04-24T09:08:24Z"}
{"aid":"http://arxiv.org/abs/2504.17392v1","title":"Edge-weighted Online Stochastic Matching Under Jaillet-Lu LP","summary":"The online stochastic matching problem was introduced by [FMMM09], together\nwith the $(1-\\frac1e)$-competitive Suggested Matching algorithm. In the most\ngeneral edge-weighted setting, this ratio has not been improved for more than\none decade, until recently [Yan24] beat the $1-\\frac1e$ bound and [QFZW23]\nfurther improved the ratio to $0.650$. Both of these works measure the online\ncompetitiveness against the offline LP relaxation introduced by [JL14]. This LP\nhas also played an important role in other settings since it is a natural\nchoice for two-choices online algorithms.\n  In this paper, we propose an upper bound of $0.663$ and a lower bound of\n$0.662$ for edge-weighted online stochastic matching under Jaillet-Lu LP.\nFirst, we propose a hard instance and prove that the optimal online algorithm\nfor this instance only has a competitive ratio $<0.663$. Then, we show that a\nnear-optimal algorithm for this instance can be generalized to work on all\ninstances and achieve a competitive ratio $>0.662$. It indicates that more\npowerful LPs are necessary if we want to further improve the ratio by $0.001$.","main_category":"cs.DS","categories":"cs.DS,cs.GT","published":"2025-04-24T09:19:30Z"}
{"aid":"http://arxiv.org/abs/2504.17408v1","title":"Introducing Combined Effects of Filtering and ASE Noise in Optical Links\n  Supposing Different Equalization Algorithms","summary":"This paper presents a comprehensive analytical framework for evaluating\nfiltering penalties in ASE-noise-limited coherent optical links. The model\naccounts for the cumulative effects of cascaded optical filters,\namplifier-induced ASE noise, and transceiver noise, alongside digital\nequalization at the receiver. By developing a generalized channel\nrepresentation, we derive closed-form expressions for signal-to-noise ratio\ndegradation under various equalization strategies, including Zero-Forcing\nEqualizer, Minimum Mean Square Error Equalizer, and Fractionally Spaced\nEqualizer. These models capture the impact of colored noise resulting from\nlinear filtering and provide both time and frequency-domain insights. The\nproposed framework is validated through experimental comparisons using\naccurately modeled optical filters, demonstrating close agreement between\ntheory and practice and offering a robust foundation for system-level\nperformance evaluation in metro-access networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-24T10:01:02Z"}
{"aid":"http://arxiv.org/abs/2504.17415v1","title":"Structural design and multiple magnetic orderings of the intergrowth\n  compound Eu$_2$CuMn$_2$P$_3$","summary":"We report the design, synthesis, crystal structure, and physical properties\nof a layered intergrowth compound, Eu$_2$CuMn$_2$P$_3$. The structure of\nEu$_2$CuMn$_2$P$_3$ features an alternating arrangement of hexagonal EuCuP\nblock layers and trigonal EuMn$_2$P$_2$ block layers, interconnected through\nshared Eu planes. This structural hybridization leads to multiple magnetic\norderings in Eu$_2$CuMn$_2$P$_3$: weak antiferromagnetic (AFM) ordering of Mn\nat $T_\\mathrm{N}^\\mathrm{Mn}$ = 80 K, AFM ordering of Eu at\n$T_\\mathrm{N}^\\mathrm{Eu}$ = 29 K, a spin-reorientation transition at\n$T_\\mathrm{SR}$ = 14.5 K, and weak ferromagnetism below\n$T_\\mathrm{N}^\\mathrm{Mn}$. The spin configurations at different temperature\nregions were discussed based on the calculations of magnetic energies for\nvarious collinear arrangements. Resistivity measurements reveal a pronounced\ntransition peak at $T_\\mathrm{N}^\\mathrm{Eu}$, which is suppressed in the\npresence of a magnetic field, resulting in a significant negative\nmagnetoresistance effect. The computed semimetallic band structure,\ncharacterized by a small density of states at the Fermi level, aligns well with\nexperimental observations. The successful synthesis of Eu$_2$CuMn$_2$P$_3$ and\nits fascinating magnetic properties highlight the effectiveness of our\nblock-layer design strategy. By assembling magnetic block layers of compounds\nwith compatible crystal symmetries and closely matched lattice parameters, this\napproach opens exciting avenues for discovering layered materials with unique\nmagnetic behaviors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-24T10:15:40Z"}
{"aid":"http://arxiv.org/abs/2504.17421v1","title":"Towards Harnessing the Collaborative Power of Large and Small Models for\n  Domain Tasks","summary":"Large language models (LLMs) have demonstrated remarkable capabilities, but\nthey require vast amounts of data and computational resources. In contrast,\nsmaller models (SMs), while less powerful, can be more efficient and tailored\nto specific domains. In this position paper, we argue that taking a\ncollaborative approach, where large and small models work synergistically, can\naccelerate the adaptation of LLMs to private domains and unlock new potential\nin AI. We explore various strategies for model collaboration and identify\npotential challenges and opportunities. Building upon this, we advocate for\nindustry-driven research that prioritizes multi-objective benchmarks on\nreal-world private datasets and applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T10:24:35Z"}
{"aid":"http://arxiv.org/abs/2504.17438v1","title":"Storing and Querying Evolving Graphs in NoSQL Storage Models","summary":"This paper investigates advanced storage models for evolving graphs, focusing\non the efficient management of historical data and the optimization of global\nquery performance. Evolving graphs, which represent dynamic relationships\nbetween entities over time, present unique challenges in preserving their\ncomplete history while supporting complex analytical queries. We first do a\nfast review of the current state of the art focusing mainly on distributed\nhistorical graph databases to provide the context of our proposals. We\ninvestigate the im- plementation of an enhanced vertex-centric storage model in\nMongoDB that prioritizes space efficiency by leveraging in-database query\nmechanisms to minimize redundant data and reduce storage costs. To ensure broad\napplicability, we employ datasets, some of which are generated with the LDBC\nSNB generator, appropriately post-processed to utilize both snapshot- and\ninterval-based representations. Our experimental results both in centralized\nand distributed infrastructures, demonstrate significant improvements in query\nperformance, particularly for resource-intensive global queries that\ntraditionally suffer from inefficiencies in entity-centric frameworks. The\nproposed model achieves these gains by optimizing memory usage, reducing client\ninvolvement, and exploiting the computational capabilities of MongoDB. By\naddressing key bottlenecks in the storage and processing of evolving graphs,\nthis study demonstrates a step toward a robust and scalable framework for\nmanaging dynamic graph data. This work contributes to the growing field of\ntemporal graph analytics by enabling more efficient ex- ploration of historical\ndata and facilitating real-time insights into the evolution of complex\nnetworks.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-24T10:57:27Z"}
{"aid":"http://arxiv.org/abs/2504.17447v1","title":"FRAG: Frame Selection Augmented Generation for Long Video and Long\n  Document Understanding","summary":"There has been impressive progress in Large Multimodal Models (LMMs). Recent\nworks extend these models to long inputs, including multi-page documents and\nlong videos. However, the model size and performance of these long context\nmodels are still limited due to the computational cost in both training and\ninference. In this work, we explore an orthogonal direction and process long\ninputs without long context LMMs. We propose Frame Selection Augmented\nGeneration (FRAG), where the model first selects relevant frames within the\ninput, and then only generates the final outputs based on the selected frames.\nThe core of the selection process is done by scoring each frame independently,\nwhich does not require long context processing. The frames with the highest\nscores are then selected by a simple Top-K selection. We show that this\nfrustratingly simple framework is applicable to both long videos and multi-page\ndocuments using existing LMMs without any fine-tuning. We consider two models,\nLLaVA-OneVision and InternVL2, in our experiments and show that FRAG\nconsistently improves the performance and achieves state-of-the-art\nperformances for both long video and long document understanding. For videos,\nFRAG substantially improves InternVL2-76B by 5.8% on MLVU and 3.7% on\nVideo-MME. For documents, FRAG achieves over 20% improvements on MP-DocVQA\ncompared with recent LMMs specialized in long document understanding. Code is\navailable at: https://github.com/NVlabs/FRAG","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-24T11:19:18Z"}
{"aid":"http://arxiv.org/abs/2504.17456v1","title":"Thermodynamics and Holographic RG Flow in 3D C-metric","summary":"In this paper, we investigate the microscopic derivation of the entropy and\nthe holographic RG flow in 3D C-metric. We first discuss the case of a sector\nin BTZ (Banados-Teitelboim-Zanelli) black hole. By rescaling the Newton's\nconstant we recover the area law of entropy of this sector by microstate\ncounting. Then we apply this technique to all accelerating BTZ phases in 3D\nC-metric. Finally, for the boundary entropy in 3D C-metric, we study the\nmonotonicity of the $g$-function of 3D C-metric in small acceleration limit and\nfind that the $g$-theorem is satisfied only in $\\rm I_{2}$.","main_category":"hep-th","categories":"hep-th","published":"2025-04-24T11:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.17460v1","title":"A Lightweight Method for Generating Multi-Tier JIT Compilation Virtual\n  Machine in a Meta-Tracing Compiler Framework","summary":"Meta-compiler frameworks, such as RPython and Graal/Truffle, generate\nhigh-performance virtual machines (VMs) from interpreter definitions. Although\nthey generate VMs with high-quality just-in-time (JIT) compilers, they still\nlack an important feature that dedicated VMs (i.e., VMs that are developed for\nspecific languages) have, namely \\emph{multi-tier compilation}. Multi-tier\ncompilation uses light-weight compilers at early stages and highly-optimizing\ncompilers at later stages in order to balance between compilation overheads and\ncode quality.\n  We propose a novel approach to enabling multi-tier compilation in the VMs\ngenerated by a meta-compiler framework. Instead of extending the JIT compiler\nbackend of the framework, our approach drives an existing (heavyweight)\ncompiler backend in the framework to quickly generate unoptimized native code\nby merely embedding directives and compile-time operations into interpreter\ndefinitions.\n  As a validation of the approach, we developed 2SOM, a Simple Object Machine\nwith a two-tier JIT compiler based on RPython. 2SOM first applies the tier-1\nthreaded code generator that is generated by our proposed technique, then, to\nthe loops that exceed a threshold, applies the tier-2 tracing JIT compiler that\nis generated by the original RPython framework. Our performance evaluation that\nruns a program with a realistic workload showed that 2SOM improved, when\ncompared against an RPython-based VM, warm-up performance by 15\\%, with merely\na 5\\% reduction in peak performance.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-24T11:51:28Z"}
{"aid":"http://arxiv.org/abs/2504.17461v1","title":"Evaluating Time Series Models for Urban Wastewater Management:\n  Predictive Performance, Model Complexity and Resilience","summary":"Climate change increases the frequency of extreme rainfall, placing a\nsignificant strain on urban infrastructures, especially Combined Sewer Systems\n(CSS). Overflows from overburdened CSS release untreated wastewater into\nsurface waters, posing environmental and public health risks. Although\ntraditional physics-based models are effective, they are costly to maintain and\ndifficult to adapt to evolving system dynamics. Machine Learning (ML)\napproaches offer cost-efficient alternatives with greater adaptability. To\nsystematically assess the potential of ML for modeling urban infrastructure\nsystems, we propose a protocol for evaluating Neural Network architectures for\nCSS time series forecasting with respect to predictive performance, model\ncomplexity, and robustness to perturbations. In addition, we assess model\nperformance on peak events and critical fluctuations, as these are the key\nregimes for urban wastewater management. To investigate the feasibility of\nlightweight models suitable for IoT deployment, we compare global models, which\nhave access to all information, with local models, which rely solely on nearby\nsensor readings. Additionally, to explore the security risks posed by network\noutages or adversarial attacks on urban infrastructure, we introduce error\nmodels that assess the resilience of models. Our results demonstrate that while\nglobal models achieve higher predictive performance, local models provide\nsufficient resilience in decentralized scenarios, ensuring robust modeling of\nurban infrastructure. Furthermore, models with longer native forecast horizons\nexhibit greater robustness to data perturbations. These findings contribute to\nthe development of interpretable and reliable ML solutions for sustainable\nurban wastewater management. The implementation is available in our GitHub\nrepository.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T11:52:13Z"}
{"aid":"http://arxiv.org/abs/2504.17465v1","title":"On soliton resolution to Cauchy problem of the spin-1 Gross-Pitaevskii\n  equation","summary":"We investigate the Cauchy problem for the spin-1 Gross-Pitaevskii(GP)\nequation, which is a model instrumental in characterizing the soliton dynamics\nwithin spinor Bose-Einstein condensates. Recently, Geng $etal.$ (Commun. Math.\nPhys. 382, 585-611 (2021)) reported the long-time asymptotic result with error\n$\\mathcal{O}(\\frac{\\log t}t)$ for the spin-1 GP equation that only exists in\nthe continuous spectrum. The main purpose of our work is to further generalize\nand improve Geng's work. Compared with the previous work, our asymptotic error\naccuracy has been improved from $\\mathcal{O}(\\frac{\\log t}t)$ to\n$\\mathcal{O}(t^{-3/4})$. More importantly, by establishing two matrix valued\nfunctions, we obtained effective asymptotic errors and successfully constructed\nasymptotic analysis of the spin-1 GP equation based on the characteristics of\nthe spectral problem, including two cases: (i)coexistence of discrete and\ncontinuous spectrum; (ii)only continuous spectrum which considered by Geng's\nwork with error $\\mathcal{O}(\\frac{\\log t}t)$. For the case (i), the\ncorresponding asymptotic approximations can be characterized with an\n$N$-soliton as well as an interaction term between soliton solutions and the\ndispersion term with diverse residual error order $\\mathcal{O}(t^{-3/4})$. For\nthe case (ii), the corresponding asymptotic approximations can be characterized\nwith the leading term on the continuous spectrum and the residual error order\n$\\mathcal{O}(t^{-3/4})$. Finally, our results confirm the soliton resolution\nconjecture for the spin-1 GP equation.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,nlin.SI","published":"2025-04-24T11:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.17466v1","title":"From Single Particles to Clinical Beam Rates: A Wide Dynamic Range Beam\n  Monitor","summary":"Access to high-energy particle beams is key for testing high-energy physics\n(HEP) instruments. Accelerators for cancer treatment can serve as such a\ntesting ground. However, HEP instrument tests typically require particle fluxes\nsignificantly lower than for cancer treatment. Thus, facilities need\nadaptations to fulfill both the requirements for cancer treatment and the\nrequirements for HEP instrument testing. We report on the progress made in\ndeveloping a beam monitor with a sufficient dynamic range to allow for the\ndetection of single particles, while still being able to act as a monitor at\nthe clinical particle rates of the MedAustron treatment facility. The beam\nmonitor is designed for integration into existing accelerators.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex","published":"2025-04-24T12:00:09Z"}
{"aid":"http://arxiv.org/abs/2504.17498v1","title":"Hausdorff dimension of shrinking targets on Przytycki-UrbaÅski\n  fractals","summary":"Shrinking target problems in the context of iterated function systems have\nreceived an increasing amount of interest in the past few years. The classical\nshrinking target problem concerns points returning infinitely many times to a\nsequence of shrinking balls. In the iterated function system context, the\nshrinking balls problem is only well tractable in the case of similarity maps,\nbut the case of affine maps is more elusive due to many geometric-dynamical\ncomplications.\n  In the current work, we push through these complications and compute the\nHausdorff dimension of a set recurring to a shrinking target of geometric balls\nin some affine iterated function systems. For these results, we have pinpointed\na representative class of affine iterated function systems, consisting of a\npair of diagonal affine maps, that was introduced by Przytycki and Urba\\'nski.\nThe analysis splits into many sub-cases according to the type of the centre\npoint of the targets, and the relative sizes of the targets and the\ncontractions of the maps, illustrating the array of challenges of going beyond\naffine maps with nice projections. The proofs require heavy machinery from, and\nexpand, the theory of Bernoulli convolutions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-24T12:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.17499v1","title":"New self-organized benzo[b]thiophene-based materials for GHz\n  applications","summary":"This research delves into the synthesis and characterization of novel liquid\ncrystal compounds derived from benzo[b]Ithiophene cores, focusing on their\npotential applications in microwave technology. Two synthetic strategies were\ndeveloped to construct rigid cores, resulting in the successful synthesis of\nten compounds with varied terminal groups and lateral substituents.\nCorrelations between molecular structure and mesomorphic properties were\nelucidated through extensive comparative analysis. Birefringence measurements\nand quantum chemical calculations further provided insights into the optical\nproperties and polarizability anisotropy of the synthesized compounds. The\nresults highlight the influence of structural diversity on the compounds'\nsuitability for microwave applications. Specifically, compounds featuring\ncarbon-carbon triple bonds and polar terminal groups demonstrated enhanced\nbirefringence and polarizability values, indicating their potential in\nmicrowave device fabrication. This study underscores the importance of\nmolecular design in optimizing liquid crystal materials for advanced\ntechnological applications.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-04-24T12:39:12Z"}
{"aid":"http://arxiv.org/abs/2504.17511v1","title":"Subcode Ensemble Decoding of Polar Codes","summary":"In the short block length regime, pre-transformed polar codes together with\nsuccessive cancellation list (SCL) decoding possess excellent error correction\ncapabilities. However, in practice, the list size is limited due to the\nsuboptimal scaling of the required area in hardware implementations.\nAutomorphism ensemble decoding (AED) can improve performance for a fixed list\nsize by running multiple parallel SCL decodings on permuted received words,\nyielding a list of estimates from which the final estimate is selected. Yet,\nAED is limited to appropriately designed polar codes. Subcode ensemble decoding\n(ScED) was recently proposed for low-density parity-check codes and does not\nimpose such design constraints. It uses multiple decodings in different\nsubcodes, ensuring that the selected subcodes jointly cover the original code.\nWe extend ScED to polar codes by expressing polar subcodes through suitable\npre-transformations (PTs). To this end, we describe a framework classifying\npre-transformations for pre-transformed polar codes based on their role in\nencoding and decoding. Within this framework, we propose a new type of PT\nenabling ScED for polar codes, analyze its properties, and discuss how to\nconstruct an efficient ensemble.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T12:55:23Z"}
{"aid":"http://arxiv.org/abs/2504.17535v1","title":"Two gluing methods for string C-group representations of the symmetric\n  groups","summary":"The study of string C-group representations of rank at least $n/2$ for the\nsymmetric group $S_n$ has gained a lot of attention in the last fifteen years.\nIn a recent paper, Cameron et al. gave a list of permutation representation\ngraphs of rank $r\\geq n/2$ for $S_n$, having a fracture graph and a non-perfect\nsplit. They conjecture that these graphs are permutation representation graphs\nof string C-groups. In trying to prove this conjecture, we discovered two new\ntechniques to glue two CPR graphs for symmetric groups together. We discuss the\ncases in which they yield new CPR graphs. By doing so, we invalidate the\nconjecture of Cameron et al. We believe our gluing techniques will be useful in\nthe study of string C-group representations of high ranks for the symmetric\ngroups.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-24T13:24:12Z"}
{"aid":"http://arxiv.org/abs/2504.17554v1","title":"Rethinking PM Crash Consistency in the CXL Era","summary":"Persistent Memory (PM) introduces new opportunities for designing\ncrash-consistent applications without the traditional storage overheads.\nHowever, ensuring crash consistency in PM demands intricate knowledge of CPU,\ncache, and memory interactions. Hardware and software mechanisms have been\nproposed to ease this burden, but neither proved sufficient, prompting a\nvariety of bug detection tools.\n  With the sunset of Intel Optane comes the rise of Compute Express Link (CXL)\nfor PM. In this position paper, we discuss the impact of CXL's disaggregated\nand heterogeneous nature in the development of crash-consistent PM\napplications, and outline three research directions: hardware primitives,\npersistency frameworks, and bug detection tools.","main_category":"cs.ET","categories":"cs.ET","published":"2025-04-24T13:47:35Z"}
{"aid":"http://arxiv.org/abs/2504.17559v1","title":"Concentration inequalities and cut-off phenomena for penalized model\n  selection within a basic Rademacher framework","summary":"This article exists first and foremost to contribute to a tribute to Patrick\nCattiaux. One of the two authors has known Patrick Cattiaux for a very long\ntime, and owes him a great deal. If we are to illustrate the adage that life is\nmade up of chance, then what could be better than the meeting of two young\npeople in the 80s, both of whom fell in love with the mathematics of\nrandomness, and one of whom changed the other's life by letting him in on a\nsecret: if you really believe in it, you can turn this passion into a\nprofession. By another happy coincidence, this tribute comes at just the right\ntime, as Michel Talagrand has been awarded the Abel prize. The temptation was\ntherefore great to do a double. Following one of the many galleries opened up\nby mathematics, we shall first draw a link between the mathematics of Patrick\nCattiaux and that of Michel Talagrand. Then we shall show how the abstract\nprobabilistic material on the concentration of product measures thus revisited\ncan be used to shed light on cut-off phenomena in our field of expertise,\nmathematical statistics. Nothing revolutionary here, as everyone knows the\nimpact that Talagrand's work has had on the development of mathematical\nstatistics since the late 90s, but we've chosen a very simple framework in\nwhich everything can be explained with minimal technicality, leaving the main\nideas to the fore.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-24T13:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.17569v1","title":"Flying through cluttered and dynamic environments with LiDAR","summary":"Navigating unmanned aerial vehicles (UAVs) through cluttered and dynamic\nenvironments remains a significant challenge, particularly when dealing with\nfast-moving or sudden-appearing obstacles. This paper introduces a complete\nLiDAR-based system designed to enable UAVs to avoid various moving obstacles in\ncomplex environments. Benefiting the high computational efficiency of\nperception and planning, the system can operate in real time using onboard\ncomputing resources with low latency. For dynamic environment perception, we\nhave integrated our previous work, M-detector, into the system. M-detector\nensures that moving objects of different sizes, colors, and types are reliably\ndetected. For dynamic environment planning, we incorporate dynamic object\npredictions into the integrated planning and control (IPC) framework, namely\nDynIPC. This integration allows the UAV to utilize predictions about dynamic\nobstacles to effectively evade them. We validate our proposed system through\nboth simulations and real-world experiments. In simulation tests, our system\noutperforms state-of-the-art baselines across several metrics, including\nsuccess rate, time consumption, average flight time, and maximum velocity. In\nreal-world trials, our system successfully navigates through forests, avoiding\nmoving obstacles along its path.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-24T13:59:06Z"}
{"aid":"http://arxiv.org/abs/2504.17579v1","title":"THz Emission from Spintronic Microstructure","summary":"Recent advancements in spintronics have opened a new avenue in terahertz\n(THz) radiation sources that may outperform the traditional contact-based\nmetallic counterparts. Inspired by the generation of broadband spintronic THz\nsignals at the interface of a ferromagnet and ultrawide bandgap semiconductors,\nhere we investigated the generation of THz radiation from micro-structured\nheterostructures of a metallic ferromagnet (Ni80Fe20) and an ultrawide bandgap\nsemiconductor (AlGaN/GaN) that contains a layer of 2D electron gas. By\nprecisely tailoring the dimension of the subwavelength pillars of a THz device,\nthe micro-structured spintronic THz emitter can achieve up to more than three\ntimes higher emission intensity compared to that of the un-patterned\ncounterpart. Our study advances the development of the next generation of\nspintronic THz sources that allow a tailored emission frequency and intensity\ncontrol and, further, are compatible with existing integrated wide-bandgap\nsemiconductor circuits.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-24T14:09:43Z"}
{"aid":"http://arxiv.org/abs/2504.17593v1","title":"The stellar corona-chromosphere connection. A comprehensive study of\n  X-ray and Ca II IRT fluxes from eROSITA and Gaia","summary":"Stellar activity can be observed at different wavelengths in a variety of\ndifferent activity indicators. We investigated the correlation between coronal\nand chromospheric emissions by combining X-ray data from stars detected in the\neROSITA all-sky surveys (eRASS1 and eRASS:5) with Ca II infrared triplet (IRT)\nactivity indices as published in the third Gaia data release (Gaia DR3). We\nspecifically studied 24 300 and 43 200 stellar sources with reliable Ca II IRT\nmeasurement and X-ray detection in eRASS1 and eRASS:5, which is by far the\nlargest stellar sample available so far. The largest detection fraction is\nobtained for highly active sources and stars of a late spectral type, while\nF-type and less active stars (as measured in the Ca II IRT) remain mostly\nundetected in X-rays. Also, the correlation is the strongest for late-type\nsources, while F-type stars show a rather weak correlation between the X-ray to\nbolometric flux ratio and the Ca II IRT activity index. The relation between\nthe X-ray and Ca II IRT surface fluxes changes with the fractional X-ray flux\nwithout showing two separated branches as described in previous studies. For\nfast rotators, both activity indicators saturate at a similar Rossby number and\nthe X-ray to bolometric flux ratio decreases faster than the IRT index for\nslower rotating stars. As a consequence, the ratio between X-ray and IRT fluxes\nis constant in the saturation regime and decreases for slow rotators.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-04-24T14:21:56Z"}
{"aid":"http://arxiv.org/abs/2504.17598v1","title":"TSUE: A Two-Stage Data Update Method for an Erasure Coded Cluster File\n  System","summary":"Compared to replication-based storage systems, erasure-coded storage incurs\nsignificantly higher overhead during data updates. To address this issue,\nvarious parity logging methods have been pro- posed. Nevertheless, due to the\nlong update path and substantial amount of random I/O involved in erasure code\nupdate processes, the resulting long latency and low throughput often fail to\nmeet the requirements of high performance applications. To this end, we propose\na two-stage data update method called TSUE. TSUE divides the update process\ninto a synchronous stage that records updates in a data log, and an\nasynchronous stage that recycles the log in real-time. TSUE effectively reduces\nupdate latency by transforming random I/O into sequential I/O, and it\nsignificantly reduces recycle overhead by utilizing a three-layer log and the\nspatio-temporal locality of access patterns. In SSDs cluster, TSUE\nsignificantly im- proves update performance, achieving improvements of 7.6X\nunder Ali-Cloud trace, 5X under Ten-Cloud trace, while it also extends the\nSSD's lifespan by up to 13X through reducing the frequencies of reads/writes\nand of erase operations.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-24T14:24:16Z"}
{"aid":"http://arxiv.org/abs/2504.17606v1","title":"From surface roughness to crater formation in a 2D multi-scale\n  simulation of ultrashort pulse laser ablation","summary":"Surface roughness plays a critical role in ultrashort pulse laser ablation,\nparticularly for industrial applications using burst mode operations,\nmulti-pulse laser processing, and the generation of laser-induced periodic\nsurface structures. Hence, we address the impact of surface roughness on the\nresulting laser ablation topography predicted by a simulation model and\ncompared to experimental results. We present a comprehensive multi-scale\nsimulation framework that first employs finite-difference-time-domain\nsimulations for calculating the surface fluence distribution on a rough surface\nmeasured by an atomic-force-microscope followed by the two-temperature model\ncoupled with hydrodynamic/solid mechanics simulation for the initial material\nheating. Lastly, a computational fluid dynamics model for material relaxation\nand fluid flow is developed and employed. Final state results of aluminum and\nAISI 304 stainless steel simulations demonstrated alignment with established\nablation models and crater dimension prediction. Notably, Al exhibited\nsignificant optical scattering effects due to initial surface roughness of 15\nnm - being 70 times below the laser wavelength, leading to localized, selective\nablation processes and substantially altered crater topography compared to\nidealized conditions. Contrary, AISI 304 with RMS roughness of 2 nm showed no\ndifference. Hence, we highlight the necessity of incorporating realistic,\nmaterial-specific surface roughness values into large-scale ablation\nsimulations. Furthermore, the induced local fluence variations demonstrated the\ninadequacy of neglecting lateral heat transport effects in this context.","main_category":"hep-ex","categories":"hep-ex,cond-mat.mtrl-sci","published":"2025-04-24T14:29:33Z"}
{"aid":"http://arxiv.org/abs/2504.17629v1","title":"Integrated Sensing and Communications for Unsourced Random Access: A\n  Spectrum Sharing Compressive Sensing Approach","summary":"This paper addresses the unsourced/uncoordinated random access problem in an\nintegrated sensing and communications (ISAC) system, with a focus on uplink\nmultiple access code design. Recent theoretical advancements highlight that an\nISAC system will be overwhelmed by the increasing number of active devices,\ndriven by the growth of massive machine-type communication (mMTC). To meet the\ndemands of future mMTC network, fundamental solutions are required that ensure\nrobust capacity while maintaining favorable energy and spectral efficiency. One\npromising approach to support emerging massive connectivity is the development\nof systems based on the unsourced ISAC (UNISAC) framework. This paper proposes\na spectrum-sharing compressive sensing-based UNISAC (SSCS-UNISAC) and offers\ninsights into the practical design of UNISAC multiple access codes. In this\nframework, both communication signals (data transmission) and sensing signals\n(e.g., radar echoes) overlap within finite channel uses and are transmitted via\nthe proposed UNISAC protocol. The proposed decoder exhibits robust performance,\nproviding 20-30 dB capacity gains compared to conventional protocols such as\nTDMA and ALOHA. Numerical results validate the promising performance of the\nproposed scheme.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T14:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.17636v1","title":"A Guide to Structureless Visual Localization","summary":"Visual localization algorithms, i.e., methods that estimate the camera pose\nof a query image in a known scene, are core components of many applications,\nincluding self-driving cars and augmented / mixed reality systems.\nState-of-the-art visual localization algorithms are structure-based, i.e., they\nstore a 3D model of the scene and use 2D-3D correspondences between the query\nimage and 3D points in the model for camera pose estimation. While such\napproaches are highly accurate, they are also rather inflexible when it comes\nto adjusting the underlying 3D model after changes in the scene. Structureless\nlocalization approaches represent the scene as a database of images with known\nposes and thus offer a much more flexible representation that can be easily\nupdated by adding or removing images. Although there is a large amount of\nliterature on structure-based approaches, there is significantly less work on\nstructureless methods. Hence, this paper is dedicated to providing the, to the\nbest of our knowledge, first comprehensive discussion and comparison of\nstructureless methods. Extensive experiments show that approaches that use a\nhigher degree of classical geometric reasoning generally achieve higher pose\naccuracy. In particular, approaches based on classical absolute or\nsemi-generalized relative pose estimation outperform very recent methods based\non pose regression by a wide margin. Compared with state-of-the-art\nstructure-based approaches, the flexibility of structureless methods comes at\nthe cost of (slightly) lower pose accuracy, indicating an interesting direction\nfor future work.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T15:08:36Z"}
{"aid":"http://arxiv.org/abs/2504.17646v1","title":"Portability of Optimizations from SC to TSO","summary":"It is well recognized that the safety of compiler optimizations is at risk in\na concurrent context. Existing approaches primarily rely on context-free\nthread-local guarantees, and prohibit optimizations that introduce a data-race.\nHowever, compilers utilize global context-specific information, exposing safe\noptimizations that may violate such guarantees as well as introduce a race.\nSuch optimizations need to individually be proven safe for each language model.\nAn alternate approach to this would be proving them safe for an intuitive model\n(like interleaving semantics), and then determine their portability across\nother concurrent models. In this paper, we address this problem of porting\nacross models of concurrency. We first identify a global guarantee on\noptimizations portable from Sequential Consistency (SC) to Total Store Order\n(TSO). Our guarantee is in the form of constraints specifying the syntactic\nchanges an optimization must not incur. We then show these constraints\ncorrelate to prohibiting the introduction of triangular races, a subset of\ndata-race relevant to TSO. We conclude by showing how such race inducing\noptimizations relate to porting across Strong Release Acquire (SRA), a known\ncausally consistent memory model.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-24T15:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.17650v1","title":"Near-Term Pseudorandom and Pseudoresource Quantum States","summary":"A pseudorandom quantum state (PRS) is an ensemble of quantum states\nindistinguishable from Haar-random states to observers with efficient quantum\ncomputers. It allows one to substitute the costly Haar-random state with\nefficiently preparable PRS as a resource for cryptographic protocols, while\nalso finding applications in quantum learning theory, black hole physics,\nmany-body thermalization, quantum foundations, and quantum chaos. All existing\nconstructions of PRS equate the notion of efficiency to quantum computers which\nruntime is bounded by a polynomial in its input size. In this work, we relax\nthe notion of efficiency for PRS with respect to observers with near-term\nquantum computers implementing algorithms with runtime that scales slower than\npolynomial-time. We introduce the $\\mathbf{T}$-PRS which is indistinguishable\nto quantum algorithms with runtime $\\mathbf{T}(n)$ that grows slower than\npolynomials in the input size $n$. We give a set of reasonable conditions that\na $\\mathbf{T}$-PRS must satisfy and give two constructions by using\nquantum-secure pseudorandom functions and pseudorandom functions. For\n$\\mathbf{T}(n)$ being linearithmic, linear, polylogarithmic, and logarithmic\nfunction, we characterize the amount of quantum resources a $\\mathbf{T}$-PRS\nmust possess, particularly on its coherence, entanglement, and magic. Our\nquantum resource characterization applies generally to any two state ensembles\nthat are indistinguishable to observers with computational power\n$\\mathbf{T}(n)$, giving a general necessary condition of whether a low-resource\nensemble can mimic a high-resource ensemble, forming a\n$\\mathbf{T}$-pseudoresource pair. We demonstate how the necessary amount of\nresource decreases as the observer's computational power is more restricted,\ngiving a $\\mathbf{T}$-pseudoresource pair with larger resource gap for more\ncomputationally limited observers.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-24T15:21:29Z"}
{"aid":"http://arxiv.org/abs/2504.17676v1","title":"UNILoc: Unified Localization Combining Model-Based Geometry and\n  Unsupervised Learning","summary":"Accurate mobile device localization is critical for emerging 5G/6G\napplications such as autonomous vehicles and augmented reality. In this paper,\nwe propose a unified localization method that integrates model-based and\nmachine learning (ML)-based methods to reap their respective advantages by\nexploiting available map information. In order to avoid supervised learning, we\ngenerate training labels automatically via optimal transport (OT) by fusing\ngeometric estimates with building layouts. Ray-tracing based simulations are\ncarried out to demonstrate that the proposed method significantly improves\npositioning accuracy for both line-of-sight (LoS) users (compared to ML-based\nmethods) and non-line-of-sight (NLoS) users (compared to model-based methods).\nRemarkably, the unified method is able to achieve competitive overall\nperformance with the fully-supervised fingerprinting, while eliminating the\nneed for cumbersome labeled data measurement and collection.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-24T15:45:54Z"}
{"aid":"http://arxiv.org/abs/2504.17683v1","title":"On the locally analytic $\\text{Ext}^1$-conjecture in the\n  $\\text{GL}_2(L)$ case","summary":"Let $L$ be a finite extension of $\\mathbb{Q}_p$. We calculate the dimension\nof $\\text{Ext}^1$-groups of certain locally analytic representations of\n$\\text{GL}_2(L)$ defined using coherent cohomology of Drinfeld curves.\nFurthermore, let $\\rho_p$ be a $2$-dimensional continuous representation of\n$\\text{Gal}(\\bar L/L)$, which is de Rham with parallel Hodge-Tate weights $0,1$\nand whose underlying Weil-Deligne representation is irreducible. We prove\nBreuil's locally analytic $\\text{Ext}^1$ conjecture for such $\\rho_p$. As an\napplication, we show that the isomorphism class of the multiplicity space\n$\\Pi^{\\text{an}}_{\\text{geo}}(\\rho_p)$ of $\\rho_p$ in the pro-\\'etale\ncohomology of Drinfeld curves uniquely determines the isomorphism class of\n$\\rho_p$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-24T15:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.17696v1","title":"Hierarchical and Multimodal Data for Daily Activity Understanding","summary":"Daily Activity Recordings for Artificial Intelligence (DARai, pronounced\n\"Dahr-ree\") is a multimodal, hierarchically annotated dataset constructed to\nunderstand human activities in real-world settings. DARai consists of\ncontinuous scripted and unscripted recordings of 50 participants in 10\ndifferent environments, totaling over 200 hours of data from 20 sensors\nincluding multiple camera views, depth and radar sensors, wearable inertial\nmeasurement units (IMUs), electromyography (EMG), insole pressure sensors,\nbiomonitor sensors, and gaze tracker.\n  To capture the complexity in human activities, DARai is annotated at three\nlevels of hierarchy: (i) high-level activities (L1) that are independent tasks,\n(ii) lower-level actions (L2) that are patterns shared between activities, and\n(iii) fine-grained procedures (L3) that detail the exact execution steps for\nactions. The dataset annotations and recordings are designed so that 22.7% of\nL2 actions are shared between L1 activities and 14.2% of L3 procedures are\nshared between L2 actions. The overlap and unscripted nature of DARai allows\ncounterfactual activities in the dataset.\n  Experiments with various machine learning models showcase the value of DARai\nin uncovering important challenges in human-centered applications.\nSpecifically, we conduct unimodal and multimodal sensor fusion experiments for\nrecognition, temporal localization, and future action anticipation across all\nhierarchical annotation levels. To highlight the limitations of individual\nsensors, we also conduct domain-variant experiments that are enabled by DARai's\nmulti-sensor and counterfactual activity design setup.\n  The code, documentation, and dataset are available at the dedicated DARai\nwebsite:\nhttps://alregib.ece.gatech.edu/software-and-datasets/darai-daily-activity-recordings-for-artificial-intelligence-and-machine-learning/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-24T16:04:00Z"}
{"aid":"http://arxiv.org/abs/2504.17710v1","title":"Plasma State Monitoring and Disruption Characterization using Multimodal\n  VAEs","summary":"When a plasma disrupts in a tokamak, significant heat and electromagnetic\nloads are deposited onto the surrounding device components. These forces scale\nwith plasma current and magnetic field strength, making disruptions one of the\nkey challenges for future devices. Unfortunately, disruptions are not fully\nunderstood, with many different underlying causes that are difficult to\nanticipate. Data-driven models have shown success in predicting them, but they\nonly provide limited interpretability. On the other hand, large-scale\nstatistical analyses have been a great asset to understanding disruptive\npatterns. In this paper, we leverage data-driven methods to find an\ninterpretable representation of the plasma state for disruption\ncharacterization. Specifically, we use a latent variable model to represent\ndiagnostic measurements as a low-dimensional, latent representation. We build\nupon the Variational Autoencoder (VAE) framework, and extend it for (1)\ncontinuous projections of plasma trajectories; (2) a multimodal structure to\nseparate operating regimes; and (3) separation with respect to disruptive\nregimes. Subsequently, we can identify continuous indicators for the disruption\nrate and the disruptivity based on statistical properties of measurement data.\nThe proposed method is demonstrated using a dataset of approximately 1600 TCV\ndischarges, selecting for flat-top disruptions or regular terminations. We\nevaluate the method with respect to (1) the identified disruption risk and its\ncorrelation with other plasma properties; (2) the ability to distinguish\ndifferent types of disruptions; and (3) downstream analyses. For the latter, we\nconduct a demonstrative study on identifying parameters connected to\ndisruptions using counterfactual-like analysis. Overall, the method can\nadequately identify distinct operating regimes characterized by varying\nproximity to disruptions in an interpretable manner.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,cs.CV,cs.LG","published":"2025-04-24T16:14:16Z"}
{"aid":"http://arxiv.org/abs/2504.17723v1","title":"Towards Robust LLMs: an Adversarial Robustness Measurement Framework","summary":"The rise of Large Language Models (LLMs) has revolutionized artificial\nintelligence, yet these models remain vulnerable to adversarial perturbations,\nundermining their reliability in high-stakes applications. While adversarial\nrobustness in vision-based neural networks has been extensively studied, LLM\nrobustness remains under-explored. We adapt the Robustness Measurement and\nAssessment (RoMA) framework to quantify LLM resilience against adversarial\ninputs without requiring access to model parameters. By comparing RoMA's\nestimates to those of formal verification methods, we demonstrate its accuracy\nwith minimal error margins while maintaining computational efficiency. Our\nempirical evaluation reveals that robustness varies significantly not only\nbetween different models but also across categories within the same task and\nbetween various types of perturbations. This non-uniformity underscores the\nneed for task-specific robustness evaluations, enabling practitioners to\ncompare and select models based on application-specific robustness\nrequirements. Our work provides a systematic methodology to assess LLM\nrobustness, advancing the development of more reliable language models for\nreal-world deployment.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T16:36:19Z"}
{"aid":"http://arxiv.org/abs/2504.17752v1","title":"Disaggregated Deep Learning via In-Physics Computing at Radio Frequency","summary":"Modern edge devices, such as cameras, drones, and Internet-of-Things nodes,\nrely on deep learning to enable a wide range of intelligent applications,\nincluding object recognition, environment perception, and autonomous\nnavigation. However, deploying deep learning models directly on the often\nresource-constrained edge devices demands significant memory footprints and\ncomputational power for real-time inference using traditional digital computing\narchitectures. In this paper, we present WISE, a novel computing architecture\nfor wireless edge networks designed to overcome energy constraints in deep\nlearning inference. WISE achieves this goal through two key innovations:\ndisaggregated model access via wireless broadcasting and in-physics computation\nof general complex-valued matrix-vector multiplications directly at radio\nfrequency. Using a software-defined radio platform with wirelessly broadcast\nmodel weights over the air, we demonstrate that WISE achieves 95.7% image\nclassification accuracy with ultra-low operation power of 6.0 fJ/MAC per\nclient, corresponding to a computation efficiency of 165.8 TOPS/W. This\napproach enables energy-efficient deep learning inference on wirelessly\nconnected edge devices, achieving more than two orders of magnitude improvement\nin efficiency compared to traditional digital computing.","main_category":"cs.LG","categories":"cs.LG,cs.ET,eess.SP,physics.app-ph","published":"2025-04-24T17:10:18Z"}
{"aid":"http://arxiv.org/abs/2504.17769v1","title":"Bringing light into the Landau-Lifshitz-Gilbert equation: Consequences\n  of its fractal non-Markovian memory kernel for optically induced magnetic\n  inertia and magnons","summary":"The Landau-Lisfhitz-Gilbert (LLG) equation has been the cornerstone of\nmodeling the dynamics of localized spins, viewed as classical vectors of fixed\nlength, within nonequilibrium magnets. When light is employed as the\nnonequilibrium drive, the LLG equation must be supplemented with additional\nterms that are usually conjectured using phenomenological arguments for direct\nopto-magnetic coupling between localized spins and (real or effective) magnetic\nfield of light. However, direct coupling of magnetic field to spins is 1/c\nsmaller than coupling of light and electrons; or both magnetic and electric\nfields are too fast for slow classical spins to be able to follow them. Here,\nwe displace the need for phenomenological arguments by rigorously deriving an\nextended LLG equation via Schwinger-Keldysh field theory (SKFT). Within such a\ntheory, light interacts with itinerant electrons, and then spin current carried\nby them exerts spin-transfer torque onto localized spins, so that when\nphotoexcited electrons are integrated out we arrive at a spin-only equation.\nUnlike the standard phenomenological LLG equation with local-in-time Gilbert\ndamping, our extended one contains a non-Markovian memory kernel whose plot\nwithin the plane of its two times variables exhibits fractal properties. By\napplying SKFT-derived extended LLG equation, as our central result, to a\nlight-driven ferromagnet as an example, we predict an optically induced\nmagnetic inertia term. Its magnitude is governed by spatially nonlocal and\ntime-dependent prefactor, leading to excitation of coherent magnons at sharp\nfrequencies in and outside of the band of incoherent (or thermal) magnons.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-24T17:41:17Z"}
{"aid":"http://arxiv.org/abs/2504.17786v1","title":"Emergent fractals in dirty topological crystals","summary":"Non-trivial geometry of electronic Bloch states gives birth to topological\ninsulators that are robust against sufficiently weak randomness, inevitably\npresent in any quantum material. However, increasing disorder triggers a\nquantum phase transition into a featureless normal insulator. As the underlying\nquantum critical point is approached from the topological side, small scattered\ndroplets of normal insulators start to develop in the system and their coherent\nnucleation causes ultimate condensation of a trivial insulation. Unless\ndisorder is too strong, the normal insulator accommodates disjoint tiny\ntopological puddles. Furthermore, in the close vicinity of such a transition\nthe emergent islands of topological and trivial insulators display spatial\nfractal structures, a feature that is revealed only by local topological\nmarkers. Here we showcase this (possibly) generic phenomenon that should be\napposite to dirty topological crystals of any symmetry class in any dimension\nfrom the Bott index and local Chern marker for a square lattice-based\ndisordered Chern insulator model.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.mtrl-sci,cond-mat.stat-mech","published":"2025-04-24T17:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.19483v1","title":"Improving Reasoning Performance in Large Language Models via\n  Representation Engineering","summary":"Recent advancements in large language models (LLMs) have resulted in\nincreasingly anthropomorphic language concerning the ability of LLMs to reason.\nWhether reasoning in LLMs should be understood to be inherently different is,\nhowever, widely debated. We propose utilizing a representation engineering\napproach wherein model activations are read from the residual stream of an LLM\nwhen processing a reasoning task. The activations are used to derive a control\nvector that is applied to the model as an inference-time intervention,\nmodulating the representational space of the model, to improve performance on\nthe specified task. We publish the code for deriving control vectors and\nanalyzing model representations. The method allows us to improve performance on\nreasoning benchmarks and assess how control vectors influence the final logit\ndistribution of a model via metrics such as KL divergence and entropy. We apply\ncontrol vectors to Mistral-7B-Instruct and a range of Pythia models on an\ninductive, a deductive and mathematical reasoning task. We show that an LLM\ncan, to a certain degree, be controlled to improve its perceived reasoning\nability by modulating activations. The intervention is dependent upon the\nability to reliably extract the model's typical state when correctly solving a\ntask. Our results suggest that reasoning performance can be modulated in the\nsame manner as other information-processing tasks performed by LLMs and\ndemonstrate that we are capable of improving performance on specific tasks via\na simple intervention on the residual stream with no additional training.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-28T04:58:43Z"}
{"aid":"http://arxiv.org/abs/2504.19536v1","title":"TeleScope: A Longitudinal Dataset for Investigating Online Discourse and\n  Information Interaction on Telegram","summary":"Telegram is a globally popular instant messaging platform known for its\nstrong emphasis on security, privacy, and unique social networking features. It\nhas recently emerged as the host for various cross-domain analysis and research\nworks, such as social media influence, propaganda studies, and extremism. This\npaper introduces TeleScope, an extensive dataset suite that, to our knowledge,\nis the largest of its kind. It comprises metadata for about 500K Telegram\nchannels and downloaded message metadata for about 71K public channels,\naccounting for around 120M crawled messages. We also release channel\nconnections and user interaction data built using Telegram's message-forwarding\nfeature to study multiple use cases, such as information spread and message\nforwarding patterns. In addition, we provide data enrichments, such as language\ndetection, active message posting periods for each channel, and Telegram\nentities extracted from messages, that enable online discourse analysis beyond\nwhat is possible with the original data alone. The dataset is designed for\ndiverse applications, independent of specific research objectives, and\nsufficiently versatile to facilitate the replication of social media studies\ncomparable to those conducted on platforms like X (formerly Twitter)","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-28T07:37:31Z"}
{"aid":"http://arxiv.org/abs/2504.19555v1","title":"Physical-Layer Security in Mixed Near-Field and Far-Field Communication\n  Systems","summary":"Extremely large-scale arrays (XL-arrays) have emerged as a promising\ntechnology to improve the spectrum efficiency and spatial resolution of future\nwireless systems. Different from existing works that mostly considered physical\nlayer security (PLS) in either the far-field or near-field, we consider in this\npaper a new and practical scenario, where legitimate users (Bobs) are located\nin the far-field of a base station (BS) while eavesdroppers (Eves) are located\nin the near-field for intercepting confidential information at short distance,\nreferred to as the mixed near-field and far-field PLS. Specifically, we\nformulate an optimization problem to maximize the sum-secrecy-rate of all Bobs\nby optimizing the power allocation of the BS, subject to the constraint on the\ntotal BS transmit power. To shed useful insights, we first consider a\none-Bob-one-Eve system and characterize the insecure-transmission region of the\nBob in closed form. Interestingly, we show that the insecure-transmission\nregion is significantly \\emph{expanded} as compared to that in conventional\nfar-field PLS systems, due to the energy-spread effect in the mixed-field\nscenario. Then, we further extend the analysis to a two-Bob-one-Eve system. It\nis revealed that as compared to the one-Bob system, the interferences from the\nother Bob can be effectively used to weaken the capability of Eve for\nintercepting signals of target Bobs, thus leading to enhanced secrecy rates.\nFurthermore, we propose an efficient algorithm to obtain a high-quality\nsolution to the formulated non-convex problem by leveraging the successive\nconvex approximation (SCA) technique. Finally, numerical results demonstrate\nthat our proposed algorithm achieves a higher sum-secrecy-rate than the\nbenchmark scheme where the power allocation is designed based on the\n(simplified) far-field channel model.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T08:00:36Z"}
{"aid":"http://arxiv.org/abs/2504.19573v1","title":"Existence of Friedrich-Wintgen bound states in the continuum: system of\n  SchrÃ¶dinger equations","summary":"A bound state in the continuum (BIC) is an eigenmode with the corresponding\neigenvalue embedded in the continuous spectrum. There is currently a\nsignificant research interest on BICs in the photonics community, because they\ncan be used to induce strong resonances that are useful for lasing, sensing,\nharmonic generation, etc. The existence of BICs in classical or quantum wave\nsystems has only been established for some relatively simple cases such as BICs\nprotected by symmetry. In 1985, Friedrich and Wintgen (Physical Review A, Vol.\n32, pp. 3232-3242, 1985) suggested that BICs may appear from the destructive\ninterference of two resonances coupled to a single radiation channel. They used\na system of three one-dimensional Schr\\\"{o}dinger equations to illustrate this\nprocess. Many BICs in classical wave systems seem to follow this mechanism and\nare now called Friedrich-Wintgen BICs. However, Friedrich and Wintgen did not\nshow the existence of BICs in their system of three Schr\\\"{o}dinger equations.\nInstead, they approximated the original system by a model with one\nSchr\\\"{o}dinger equation and two algebraic equations, and only analyzed BICs in\nthe approximate model. In this paper, we give a rigorous justification for the\nexistence of BICs in the original system of three 1D Schr\\\"{o}dinger equations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-28T08:33:04Z"}
{"aid":"http://arxiv.org/abs/2504.19574v1","title":"DG-DETR: Toward Domain Generalized Detection Transformer","summary":"End-to-end Transformer-based detectors (DETRs) have demonstrated strong\ndetection performance. However, domain generalization (DG) research has\nprimarily focused on convolutional neural network (CNN)-based detectors, while\npaying little attention to enhancing the robustness of DETRs. In this letter,\nwe introduce a Domain Generalized DEtection TRansformer (DG-DETR), a simple,\neffective, and plug-and-play method that improves out-of-distribution (OOD)\nrobustness for DETRs. Specifically, we propose a novel domain-agnostic query\nselection strategy that removes domain-induced biases from object queries via\northogonal projection onto the instance-specific style space. Additionally, we\nleverage a wavelet decomposition to disentangle features into domain-invariant\nand domain-specific components, enabling synthesis of diverse latent styles\nwhile preserving the semantic features of objects. Experimental results\nvalidate the effectiveness of DG-DETR. Our code is available at\nhttps://github.com/sminhwang/DG-DETR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T08:33:10Z"}
{"aid":"http://arxiv.org/abs/2504.19590v1","title":"Arabic Metaphor Sentiment Classification Using Semantic Information","summary":"In this paper, I discuss the testing of the Arabic Metaphor Corpus (AMC) [1]\nusing newly designed automatic tools for sentiment classification for AMC based\non semantic tags. The tool incorporates semantic emotional tags for sentiment\nclassification. I evaluate the tool using standard methods, which are F-score,\nrecall, and precision. The method is to show the impact of Arabic online\nmetaphors on sentiment through the newly designed tools. To the best of our\nknowledge, this is the first approach to conduct sentiment classification for\nArabic metaphors using semantic tags to find the impact of the metaphor.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-28T08:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.19623v1","title":"Multi-Horizon Echo State Network Prediction of Intraday Stock Returns","summary":"Stock return prediction is a problem that has received much attention in the\nfinance literature. In recent years, sophisticated machine learning methods\nhave been shown to perform significantly better than ''classical'' prediction\ntechniques. One downside of these approaches is that they are often very\nexpensive to implement, for both training and inference, because of their high\ncomplexity. We propose a return prediction framework for intraday returns at\nmultiple horizons based on Echo State Network (ESN) models, wherein a large\nportion of parameters are drawn at random and never trained. We show that this\napproach enjoys the benefits of recurrent neural network expressivity,\ninherently efficient implementation, and strong forecasting performance.","main_category":"q-fin.CP","categories":"q-fin.CP,q-fin.ST","published":"2025-04-28T09:32:10Z"}
{"aid":"http://arxiv.org/abs/2504.19632v1","title":"QFDNN: A Resource-Efficient Variational Quantum Feature Deep Neural\n  Networks for Fraud Detection and Loan Prediction","summary":"Social financial technology focuses on trust, sustainability, and social\nresponsibility, which require advanced technologies to address complex\nfinancial tasks in the digital era. With the rapid growth in online\ntransactions, automating credit card fraud detection and loan eligibility\nprediction has become increasingly challenging. Classical machine learning (ML)\nmodels have been used to solve these challenges; however, these approaches\noften encounter scalability, overfitting, and high computational costs due to\ncomplexity and high-dimensional financial data. Quantum computing (QC) and\nquantum machine learning (QML) provide a promising solution to efficiently\nprocessing high-dimensional datasets and enabling real-time identification of\nsubtle fraud patterns. However, existing quantum algorithms lack robustness in\nnoisy environments and fail to optimize performance with reduced feature sets.\nTo address these limitations, we propose a quantum feature deep neural network\n(QFDNN), a novel, resource efficient, and noise-resilient quantum model that\noptimizes feature representation while requiring fewer qubits and simpler\nvariational circuits. The model is evaluated using credit card fraud detection\nand loan eligibility prediction datasets, achieving competitive accuracies of\n82.2% and 74.4%, respectively, with reduced computational overhead.\nFurthermore, we test QFDNN against six noise models, demonstrating its\nrobustness across various error conditions. Our findings highlight QFDNN\npotential to enhance trust and security in social financial technology by\naccurately detecting fraudulent transactions while supporting sustainability\nthrough its resource-efficient design and minimal computational overhead.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-04-28T09:47:28Z"}
{"aid":"http://arxiv.org/abs/2504.19710v1","title":"PhyloProfile v2 -- Exploring multi-layered phylogenetic profiles at\n  scale","summary":"Phylogenetic profiles visualize the presence-absence pattern of genes across\ntaxa and are essential for delineating the evolutionary fate of genes and gene\nfamilies. Integrating phylogenetic profiles across many genes and taxa reveals\npatterns of coevolution, aiding the predictions of gene functions and\ninteractions. The surge of genome sequences generated by biodiversity genomics\nprojects allows to compile phylogenetic profiles at an unprecedented scale.\nPhyloProfile v2 was designed to cope with the novel challenges of visualizing\nand analyzing phylogenetic profiles comprising millions of pairwise orthology\nrelationships. By providing the ability to interact with the visualization and\ndynamically filter the data, PhyloProfile v2 facilitates a seamless transition\nfrom survey analyses across thousands of genes and taxa down to the feature\narchitecture comparison of two ortholog pairs within the same analysis. As one\nkey innovation, PhyloProfile v2 allows the display of phylogenetic profiles in\n2D or 3D using dimensionality reduction techniques. This novel perspective\neases, for example, the identification of taxa with similar presence/absence\npatterns of genes irrespective of their phylogenetic relationships.\nPhyloProfile v2 is available as an R package at Bioconductor\nhttps://doi.org/doi:10.18129/B9.bioc.PhyloProfile. The open-source code and\ndocumentation are provided under MIT license at\nhttps://github.com/BIONF/PhyloProfile","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-28T12:04:33Z"}
{"aid":"http://arxiv.org/abs/2504.19729v1","title":"Faster Dynamic $(Î+1)$-Coloring Against Adaptive Adversaries","summary":"We consider the problem of maintaining a proper $(\\Delta + 1)$-vertex\ncoloring in a graph on $n$-vertices and maximum degree $\\Delta$ undergoing edge\ninsertions and deletions. We give a randomized algorithm with amortized update\ntime $\\widetilde{O}( n^{2/3} )$ against adaptive adversaries, meaning that\nupdates may depend on past decisions by the algorithm. This improves on the\nvery recent $\\widetilde{O}( n^{8/9} )$-update-time algorithm by Behnezhad,\nRajaraman, and Wasim (SODA 2025) and matches a natural barrier for dynamic\n$(\\Delta+1)$-coloring algorithms. The main improvements are in the densest\nregions of the graph, where we use structural hints from the study of\ndistributed graph algorithms.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-28T12:28:45Z"}
{"aid":"http://arxiv.org/abs/2504.19733v1","title":"Theory of Non-Linear Electron Relaxation in Thin Gold Films and Their\n  Signatures in Optical Observables","summary":"Based on the momentum-resolved Boltzmann equation, we provide self-consistent\nnumerical calculations of the dynamics of conduction electrons in thin noble\nmetal films after linear and non-linear optical excitations with infrared and\nterahertz frequencies. Focusing exclusively on electron-phonon interaction,\norientational relaxation is introduced and acts as dephasing of the optical\nexcitation on a scale of tens of fs. In the linear regime, our numerical\nresults agree with the experimental fits to a Drude model and predicts for\nnon-linear excitations a field strength dependency of the orientational\nrelaxation rate. In the THz regime, where the orientational relaxation proceeds\nfaster than the oscillation cycle of the excitation THz field, a new high order\ndissipative Kerr-type non-linearity is predicted. This non-linearity originates\nfrom the Pauli blocking included in the electron-phonon scattering and results\nin a non-linearly increasing transmission of the film, detectable in\nexperiments.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-28T12:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.19739v1","title":"Contrastive Language-Image Learning with Augmented Textual Prompts for\n  3D/4D FER Using Vision-Language Model","summary":"In this paper, we introduce AffectVLM, a vision-language model designed to\nintegrate multiviews for a semantically rich and visually comprehensive\nunderstanding of facial emotions from 3D/4D data. To effectively capture visual\nfeatures, we propose a joint representation learning framework paired with a\nnovel gradient-friendly loss function that accelerates model convergence\ntowards optimal feature representation. Additionally, we introduce augmented\ntextual prompts to enhance the model's linguistic capabilities and employ mixed\nview augmentation to expand the visual dataset. We also develop a Streamlit app\nfor a real-time interactive inference and enable the model for distributed\nlearning. Extensive experiments validate the superior performance of AffectVLM\nacross multiple benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T12:36:14Z"}
{"aid":"http://arxiv.org/abs/2504.19748v1","title":"The charge cycle of group IV vacancy centers in diamond: From DFT to\n  rate equations","summary":"The silicon vacancy center in diamond is a promising system for quantum\ntechnologies due to its exceptional optical and spin properties. This has led\nto great interest in the silicon-vacancy center as well as in the other group\nIV vacancy centers. In this work, we model the charge cycle of the group IV\nvacancy centers from the $-2$ to $0$ charge state. As a first step, we compute\nthe onset energies for all relevant one- and two-step ionization processes.\nBased on these results, we then derive the rate equations using Fermi's golden\nrule.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.atom-ph,physics.comp-ph,physics.optics,quant-ph","published":"2025-04-28T12:48:07Z"}
{"aid":"http://arxiv.org/abs/2504.19752v1","title":"Spectral Analysis of Approximated Capacity Fade Curvature for\n  Lithium-Ion Batteries","summary":"The techno-economic benefits of incorporating battery degradation into\nadvanced control strategies necessitate the development of degradation\ndiagnosis as an advanced function in battery management systems (BMSs). To\naddress this, a curvature-based knee identification method was proposed in our\nprevious work [1]. Here, we further validate its effectiveness on a new battery\naging dataset under a realistic driving profile and conduct spectral analysis\nof the approximated capacity fade curvature. The curvature-based method shows\nconsistent knee identification performance on this dataset and the approximated\ncurvature is found to correlate with underlying degradation modes and a shift\nof electrode material phase transition points. The method uses capacity data as\nthe only input, which is easy to acquire in the lab and it is applicable in\nbattery energy storage systems for grid applications.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-28T12:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.19757v1","title":"vMODB: Unifying event and data management for distributed asynchronous\n  applications","summary":"Event-driven architecture (EDA) has emerged as a crucial architectural\npattern for scalable cloud applications. However, its asynchronous and\ndecoupled nature introduces challenges for meeting transactional requirements.\nDatabase systems, relegated to serving as storage engines for individual\ncomponents, do not recognize transactions that span multiple components in\nEDAs. In contrast, messaging systems are unaware of the components' application\nstates. Weaving such asynchronous and independent EDA components forces\ndevelopers to relinquish transactional guarantees, resulting in data\nconsistency issues. To address this challenge, we design vMODB, a distributed\nframework that enables the implementation of highly consistent and scalable\ncloud applications without compromising the envisioned benefits of EDA. We\npropose Virtual Micro Service (VMS), a novel programming model that provides\nfamiliar constructs to enable developers to specify the data model,\nconstraints, and concurrency semantics of components, as well as transactions\nand data dependencies that span across components. vMODB leverages VMS\nsemantics to enforce ACID properties by transparently unifying event logs and\nstate management into a common event-driven execution framework. Our\nexperiments using two benchmarks show that vMODB outperforms a widely adopted\nstate-of-the-art competing framework that only offers eventual consistency by\nup to 3X. With its high performance, familiar programming constructs, and ACID\nproperties, vMODB will significantly simplify the development of highly\nconsistent and efficient EDAs.","main_category":"cs.DB","categories":"cs.DB,cs.SE","published":"2025-04-28T12:55:36Z"}
{"aid":"http://arxiv.org/abs/2504.19784v1","title":"Grain boundary complexion transitions in olivine with temperature","summary":"Olivine comprises approximately 70 $\\%$ by volume of the Earth's upper\nmantle, making it likely that it controls the mechanical, electrical and\nseismic properties of the upper mantle. All rocks are composed of crystals\nseparated by grain boundaries, which affect their overall conductivity,\nstrength and viscosity. Here, we present a study of forsterite\n(Mg$_{2}$SiO$_{4}$) polycrystals synthesised between 1150 $^{\\circ}$C and 1390\n$^{\\circ}$C to obtain samples with different grain sizes. The grain boundary\nplane distributions (GBPD) were analysed by SEM and EBSD. A reversible change\nin the GBPD is observed between 1290 $^{\\circ}$C and 1390 $^{\\circ}$C. The GBPD\nshows that the most commonly occurring grain boundary planes are {0kl}-type at\n1290 $^{\\circ}$C and below, while at 1390 $^{\\circ}$C, (010) grain boundary\nplanes dominate the average crystal habitus. The least common planes at all\ntemperatures are (100). This reversible transition in the dominant grain\nboundary plane type is evidence for a temperature-dependent complexion\ntransition occurring between 1290 $^{\\circ}$C and 1390 $^{\\circ}$C. It is well\nestablished that different grain boundary crystallographies are related to\ndifferent grain boundary properties. We relate the observed grain boundary\ncomplexion transition to differences in grain boundary properties observed in\nprevious studies and suggest their influence on bulk rock properties.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cond-mat.mtrl-sci","published":"2025-04-28T13:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.19792v1","title":"Contextures: The Mechanism of Representation Learning","summary":"This dissertation establishes the contexture theory to mathematically\ncharacterize the mechanism of representation learning, or pretraining. Despite\nthe remarkable empirical success of foundation models, it is not very clear\nwhat representations they learn, and why these representations are useful for\nvarious downstream tasks. A scientific understanding of representation learning\nis critical, especially at this point when scaling up the model size is\nproducing diminishing returns, and designing new pretraining methods is\nimperative for further progress.\n  Prior work treated different representation learning methods quite\ndifferently, whereas the contexture theory provides a unified framework for\nanalyzing these methods. The central argument is that a representation is\nlearned from the association between the input X and a context variable A. We\nprove that if an encoder captures the maximum information of this association,\nin which case we say that the encoder learns the contexture, then it will be\noptimal on the class of tasks that are compatible with the context. We also\nshow that a context is the most useful when the association between X and A is\nneither too strong nor too weak. The important implication of the contexture\ntheory is that increasing the model size alone will achieve diminishing\nreturns, and further advancements require better contexts.\n  We demonstrate that many pretraining objectives can learn the contexture,\nincluding supervised learning, self-supervised learning, generative models,\netc. Then, we introduce two general objectives -- SVME and KISE, for learning\nthe contexture. We also show how to mix multiple contexts together, an\neffortless way to create better contexts from existing ones. Then, we prove\nstatistical learning bounds for representation learning. Finally, we discuss\nthe effect of the data distribution shift from pretraining to the downstream\ntask.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-28T13:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.19798v1","title":"Stainless steel in an electronically excited state","summary":"Austenitic stainless steel\n(Fe$_{0.5875}$Cr$_{0.25}$Mn$_{0.09}$Ni$_{0.07}$C$_{0.0025}$) is modeled with\nthe XTANT-3 simulation toolkit to evaluate its properties in an electronically\nexcited state produced by ultrafast laser irradiation. The model relies on\ndensity-functional tight binding to obtain the electronic Hamiltonian,\nproducing the electronic energy levels and wave functions. They are used to\ncalculate the electron heat capacity, electron heat conductivity, and\nelectron-phonon coupling parameter at the electronic temperatures up to 25,000\nK. It is revealed that stainless steel nonthermally melts at sub-picosecond\ntimescales at the deposited dose of ~1.4 eV/atom (the electronic temperature\n$T_e \\sim 10,000$ K): the atomic lattice disorders due to modifications of the\ninteratomic potential induced by the excitation of electrons, even without\nelectron-phonon coupling (Born-Oppenheimer approximation). Including the\nelectron-phonon coupling (non-Born-Oppenheimer simulation) lowers the damage\nthreshold dose to ~0.45 eV/atom, triggering atomic disorder at picosecond\ntimescales via thermal melting, predicated on the atomic heating by electrons.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-28T13:40:21Z"}
{"aid":"http://arxiv.org/abs/2504.19823v1","title":"A nonlinear diffusion equation of the Gurtin-MacCamy type: existence,\n  uniqueness, and numerical simulations","summary":"This paper examines a nonlinear diffusion process that arises in the modeling\nof biological population dynamics and extends to applications in thermal\ndiffusion and material sciences. By investigating a power-law governed\ndiffusion mechanism coupled with a time-dependent growth rate, we establish the\nexistence and uniqueness of solutions to the associated boundary-value problem\nwithin a bounded domain. Our approach departs from traditional methods by\ntransforming the original problem into a simplified elliptic framework, which\nnot only facilitates rigorous theoretical analysis but also paves the way for\nefficient numerical simulations. In addition to the analytical results, we\ndevelop a numerical scheme implemented in Python to visualize the evolution of\nthe population density across time and space. These simulations confirm the\ntheoretical predictions and demonstrate the model's sensitivity to variations\nin the nonlinear exponent, growth rate, and other parameters. The\ninterdisciplinary nature of our work suggests that the insights gained from the\nstudy of nonlinear diffusion may have far-reaching implications, ranging from\nthe control of microbial populations in biomedical contexts to the analysis of\nenergy transport in advanced materials. Overall, our findings contribute to a\ndeeper understanding of complex diffusion phenomena and offer a novel\ncomputational framework that can be adapted to a wide range of scientific and\nengineering problems.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T14:23:24Z"}
{"aid":"http://arxiv.org/abs/2504.19832v1","title":"Identifying the Frontier Structural Function and Bounding Mean\n  Deviations","summary":"This paper analyzes a model in which an outcome variable equals the\ndifference between a frontier function of inputs and a nonnegative unobserved\ndeviation. If zero is in the support of the deviation at a given input value,\nthen the frontier function is identified by the maximum outcome there. This\nobviates the need for instrumental variables. Implementation requires allowing\nfor the distribution of deviations to depend on inputs, thus not ruling out\nendogenous inputs and ensuring the estimated frontier is not merely a constant\nshift of a biased conditional expectation. Including random errors results in a\nstochastic frontier analysis model generalized to allow the joint distribution\nof deviations and errors to depend on inputs. If the minimum deviation is a\nfunction of inputs, then we derive a lower bound for the mean deviation using\nvariance and skewness, without making parametric distributional assumptions. We\napply our results to a frontier production function, with deviations\nrepresenting inefficiencies.","main_category":"econ.EM","categories":"econ.EM,econ.GN,q-fin.EC","published":"2025-04-28T14:34:54Z"}
{"aid":"http://arxiv.org/abs/2504.19884v1","title":"Accretion and Recovery in Giant Eruptions of Massive Stars","summary":"Giant Eruptions (GEs) are episodic high-rate mass loss events that massive\nstars experience in the late stage of evolutions before exploding as a\ncore-collapse supernova. If it occurs in a binary system, the companion star\ncan accrete part of the mass. We use numerical simulations to analyze how the\ncompanion responds to accretion and how its structure and evolution are\naltered. We run a grid of massive stars with masses from $20~\\rm M_{\\odot}$ to\n$60~\\rm M_{\\odot}$, and accretion rates from $\\rm 10^{-4}$ to $\\rm\n0.1~M_{\\odot}~\\rm yr^{-1}$, over a duration of $20$ yrs. For accretion rates\n$\\rm \\lesssim 0.01~M_{\\odot}~\\rm yr^{-1}$ the star remains on the hotter side\nof the HR diagram with a minor increase in luminosity without expanding, as the\naccretion timescale exceeds the thermal time scale by a larger factor. Mass\nloss through stellar winds leads to a minor drop in luminosity shortly after\nthe accretion phase as the star enters the recovery phase. For $\\rm \\gtrsim\n0.01~M_{\\odot}~\\rm yr^{-1}$ the companion star experiences a sudden increase in\nluminosity by about one order of magnitude, inflates, and cools. Under the\naccreted gas layer the star retains its structure and continues to eject\nradiation-driven wind during the recovery phase, namely the time it takes to\nregain equilibrium. Eventually, the accreted material mixes with the inner\nlayers of the star, and the star continues to evolve as a more massive star.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.HE","published":"2025-04-28T15:14:36Z"}
{"aid":"http://arxiv.org/abs/2504.19907v1","title":"Vanishing of higher cohomology and cohomological rationality","summary":"Our work begins by studying the vanishing of higher cohomology for the\nderived pushforward of a torsion free sheaf along a modification of integral\nNoetherian schemes. Leveraging this, we establish a relatively simple recipe\nfor constructing varieties with (mild) rational or Du Bois singularities, some\nof which is applicable in both zero and nonzero characteristic. Furthermore, we\nexplore notions of singularities that lie in the same cohomological veins of\nrational singularities for varieties in characteristic zero, including Bhatt's\nderived splinters and Kov\\'{a}cs' birational derived splinters.","main_category":"math.AG","categories":"math.AG,math.AC","published":"2025-04-28T15:40:09Z"}
{"aid":"http://arxiv.org/abs/2504.19914v1","title":"Demographic Parity-aware Individualized Treatment Rules","summary":"There has been growing interest in developing optimal individualized\ntreatment rules (ITRs) in various fields, such as precision medicine, business\ndecision-making, and social welfare distribution. The application of ITRs\nwithin a societal context raises substantial concerns regarding potential\ndiscrimination over sensitive attributes such as age, gender, or race. To\naddress this concern directly, we introduce the concept of demographic parity\nin ITRs. However, estimating an optimal ITR that satisfies the demographic\nparity requires solving a non-convex constrained optimization problem. To\novercome these computational challenges, we employ tailored fairness proxies\ninspired by demographic parity and transform it into a convex quadratic\nprogramming problem. Additionally, we establish the consistency of the proposed\nestimator and the risk bound. The performance of the proposed method is\ndemonstrated through extensive simulation studies and real data analysis.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-28T15:43:24Z"}
{"aid":"http://arxiv.org/abs/2504.19930v1","title":"Accelerated 3D-3D rigid registration of echocardiographic images\n  obtained from apical window using particle filter","summary":"The perfect alignment of 3D echocardiographic images captured from various\nangles has improved image quality and broadened the field of view. This study\nproposes an accelerated sequential Monte Carlo (SMC) algorithm for 3D-3D rigid\nregistration of transthoracic echocardiographic images with significant and\nlimited overlap taken from apical window that is robust to the noise and\nintensity variation in ultrasound images. The algorithm estimates the\ntranslational and rotational components of the rigid transform through an\niterative process and requires an initial approximation of the rotation and\ntranslation limits. We perform registration in two ways: the image-based\nregistration computes the transform to align the end-diastolic frame of the\napical nonstandard image to the apical standard image and applies the same\ntransform to all frames of the cardiac cycle, whereas the mask-based\nregistration approach uses the binary masks of the left ventricle in the same\nway. The SMC and exhaustive search (EX) algorithms were evaluated for 4D\ntemporal sequences recorded from 7 volunteers who participated in a study\nconducted at the Mazankowski Alberta Heart Institute. The evaluations\ndemonstrate that the mask-based approach of the accelerated SMC yielded a Dice\nscore value of 0.819 +/- 0.045 for the left ventricle and gained 16.7x speedup\ncompared to the CPU version of the SMC algorithm.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-28T16:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.19935v1","title":"Enhancing Quality for VVC Compressed Videos with Omniscient Quality\n  Enhancement Model","summary":"The latest video coding standard H.266/VVC has shown its great improvement in\nterms of compression performance when compared to its predecessor HEVC\nstandard. Though VVC was implemented with many advanced techniques, it still\nmet the same challenges as its predecessor due to the need for even higher\nperceptual quality demand at the decoder side as well as the compression\nperformance at the encoder side. The advancement of Artificial Intelligence\n(AI) technology, notably the deep learning-based video quality enhancement\nmethods, was shown to be a promising approach to improving the perceptual\nquality experience. In this paper, we propose a novel Omniscient video quality\nenhancement Network for VVC compressed Videos. The Omniscient Network for\ncompressed video quality enhancement was originally designed for HEVC\ncompressed videos in which not only the spatial-temporal features but also\ncross-frequencies information were employed to augment the visual quality.\nInspired by this work, we propose a modification of the OVQE model and\nintegrate it into the lasted STD-VVC (Standard Versatile Video Coding) decoder\narchitecture. As assessed in a rich set of test conditions, the proposed\nOVQE-VVC solution is able to achieve significant PSNR improvement, notably\naround 0.74 dB and up to 1.2 dB with respect to the original STD-VVC codec.\nThis also corresponds to around 19.6% of bitrate saving while keeping a similar\nquality observation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T16:08:49Z"}
{"aid":"http://arxiv.org/abs/2504.19958v1","title":"Machine Learning Identification of Gravimentally Microlensed Gamma-Ray\n  Bursts","summary":"Gravitational microlensing of gamma-ray bursts (GRBs) provides a unique\nopportunity to probe compact dark matter and small-scale structures in the\nuniverse. However, identifying such microlensed GRBs within large datasets is a\nsignificant challenge. In this study, we develop a machine learning approach to\ndistinguish Lensed GRBs from their Non-lensed counterparts using simulated\nlight curves. A comprehensive dataset was generated, comprising labeled light\ncurves for both categories. Features were extracted using the Cesium package,\ncapturing critical temporal properties of the light curves. Multiple machine\nlearning models were trained on the extracted features, with Random Forest\nachieving the best performance, delivering an accuracy of 94\\% and an F1 score\nof 95\\% (94\\%) for Non-Lensed (Lensed) class. This approach successfully\ndemonstrates the potential of machine learning for identifying gravitational\nlensing in GRBs, paving the way for future observational applications.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-28T16:31:43Z"}
{"aid":"http://arxiv.org/abs/2504.19964v1","title":"XMM-Newton Observations of the High Temperature Plasma in the Large\n  Magellanic Cloud Supernova Remnant N132D","summary":"We present an analysis of the archival XMM-Newton observations of the Large\nMagellanic Cloud (LMC) supernova remnant N132D totaling more than 500ks. We\nfocus on the high temperature plasma ($kt\\sim 4.5$keV) that is responsible for\nthe high energy continuum and exciting the Fe K emission. An image analysis\nshows that the Fe K emission is mainly concentrated in the southern part of the\nremnant interior to the region defined by the forward shock. This Fe K\ndistribution would be consistent with an asymmetric distribution of the Fe\nejecta and/or an asymmetric interaction between the reverse shock and the Fe\nejecta. We compare the EPIC-pn and EPIC-MOS spectra in the 3.0 -- 12.0keV\nbandpass with a model based on RGS data plus a higher temperature component, in\ncollisional ionization equilibrium (CIE), or non-equilibrium (NEI) (both\nionizing and recombining). We find that the data are equally well-fitted by the\nCIE and ionizing models. Assuming the CIE and ionizing spectral models, the Fe\nin this high temperature component is significantly enhanced with respect to\ntypical LMC abundances. We can place only an upper limit on the neutral Fe K\nline. We conclude that the Fe~K emission is due to ejecta heated by the reverse\nshock given the spatial distribution, relatively high temperature, and enhanced\nabundance. We estimate the progenitor mass based on the Ca/Fe and Ni/Fe mass\nratios to be $13\\le M_P \\le 15 M_\\odot$.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-28T16:36:27Z"}
{"aid":"http://arxiv.org/abs/2504.19978v1","title":"On one generalization of stable allocations in a two-sided market","summary":"In the stable allocation problem on a two-sided market introduced and studied\nby Baiou and Balinski in the early 2000's, one is given a bipartite graph\n$G=(V,E)$ with capacities $b$ on the edges (``contracts'') and quotas $q$ on\nthe vertices (``agents''). Each vertex $v\\in V$ is endowed with a linear order\non the set $E_v$ of edges incident to $v$, which generates preference relations\namong functions (``contract intensities'') on $E_v$, giving rise to a model of\n\\it{stable allocations} for $G$. This is a special case of Alkan-Gale's\nstability model for a bipartite graph with edge capacities in which, instead of\nlinear orders, the preferences of each ``agent'' $v$ are given via a choice\nfunction that acts on the box $\\{z\\in{\\mathbb R}_+^{E_v}\\colon z(e)\\le b(e),\\,\ne\\in E_v\\}$ or a closed subset in it and obeys the (well motivated) axioms of\nconsistence, substitutability and cardinal monotonicity. By central results in\nAlkan-Gale's theory, the set of stable assignments generated by such choice\nfunctions is nonempty and forms a distributive lattice.\n  In this paper, being in frameworks of Alkan-Gale's model and generalizing the\nstable allocation one, we consider the situation when the preferences of\n``agents'' of one side (``workers'') are given via linear orders, whereas the\nones of the other side (``firms'') via integer-valued choice functions subject\nto the three axioms as above, thus introducing the model of \\it{generalized\nallocations}, or g-allocations for short. Our main aims are to characterize and\nefficiently construct rotations, functions on $E$ associated with immediately\npreceding relations in the lattice $(S,\\prec)$ of stable g-allocations, and to\nestimate the complexity of constructing a poset generated by rotations for\nwhich the lattice of closed functions is isomorphic to $(S,\\prec)$, obtaining a\n``compact'' representation of the latter.","main_category":"math.CO","categories":"math.CO","published":"2025-04-28T16:50:16Z"}
{"aid":"http://arxiv.org/abs/2504.19994v1","title":"Semi-parametric bulk and tail regression using spline-based neural\n  networks","summary":"Semi-parametric quantile regression (SPQR) is a flexible approach to density\nregression that learns a spline-based representation of conditional density\nfunctions using neural networks. As it makes no parametric assumptions about\nthe underlying density, SPQR performs well for in-sample testing and\ninterpolation. However, it can perform poorly when modelling heavy-tailed data\nor when asked to extrapolate beyond the range of observations, as it fails to\nsatisfy any of the asymptotic guarantees provided by extreme value theory\n(EVT). To build semi-parametric density regression models that can be used for\nreliable tail extrapolation, we create the blended generalised Pareto (GP)\ndistribution, which i) provides a model for the entire range of data and, via a\nsmooth and continuous transition, ii) benefits from exact GP upper-tails\nwithout the need for intermediate threshold selection. We combine SPQR with our\nblended GP to create extremal semi-parametric quantile regression (xSPQR),\nwhich provides a flexible semi-parametric approach to density regression that\nis compliant with traditional EVT. We handle interpretability of xSPQR through\nthe use of model-agnostic variable importance scores, which provide the\nrelative importance of a covariate for separately determining the bulk and tail\nof the conditional density. The efficacy of xSPQR is illustrated on simulated\ndata, and an application to U.S. wildfire burnt areas.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-28T17:15:03Z"}
{"aid":"http://arxiv.org/abs/2504.20015v1","title":"Interaction of Laguerre-Gaussian laser pulses with borane targets of\n  different hydrogen-boron ratio","summary":"We study the interaction of high-intensity Laguerre Gaussian laser pulses\nwith hydrogen-boron compounds targets using 3D particle-in-cell simulations.\nThe ratio of hydrogen to boron is varied throughout different simulation runs\nas a proxy model for various borane molecules that can be synthesized. We show\nthat the strength of the axial magnetic fields generated via the Inverse\nFaraday effect depends on the specific ratio of target components, making\nboranes and the option to tune their composition of interest for proton-boron\nfusion.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-28T17:35:05Z"}
{"aid":"http://arxiv.org/abs/2504.20018v1","title":"MINT: Multi-Vector Search Index Tuning","summary":"Vector search plays a crucial role in many real-world applications. In\naddition to single-vector search, multi-vector search becomes important for\nmulti-modal and multi-feature scenarios today. In a multi-vector database, each\nrow is an item, each column represents a feature of items, and each cell is a\nhigh-dimensional vector. In multi-vector databases, the choice of indexes can\nhave a significant impact on performance. Although index tuning for relational\ndatabases has been extensively studied, index tuning for multi-vector search\nremains unclear and challenging. In this paper, we define multi-vector search\nindex tuning and propose a framework to solve it. Specifically, given a\nmulti-vector search workload, we develop algorithms to find indexes that\nminimize latency and meet storage and recall constraints. Compared to the\nbaseline, our latency achieves 2.1X to 8.3X speedup.","main_category":"cs.DB","categories":"cs.DB,cs.AI","published":"2025-04-28T17:36:06Z"}
{"aid":"http://arxiv.org/abs/2504.20040v1","title":"MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion","summary":"While Structure-from-Motion (SfM) has seen much progress over the years,\nstate-of-the-art systems are prone to failure when facing extreme viewpoint\nchanges in low-overlap, low-parallax or high-symmetry scenarios. Because\ncapturing images that avoid these pitfalls is challenging, this severely limits\nthe wider use of SfM, especially by non-expert users. We overcome these\nlimitations by augmenting the classical SfM paradigm with monocular depth and\nnormal priors inferred by deep neural networks. Thanks to a tight integration\nof monocular and multi-view constraints, our approach significantly outperforms\nexisting ones under extreme viewpoint changes, while maintaining strong\nperformance in standard conditions. We also show that monocular priors can help\nreject faulty associations due to symmetries, which is a long-standing problem\nfor SfM. This makes our approach the first capable of reliably reconstructing\nchallenging indoor environments from few images. Through principled uncertainty\npropagation, it is robust to errors in the priors, can handle priors inferred\nby different models with little tuning, and will thus easily benefit from\nfuture progress in monocular depth and normal estimation. Our code is publicly\navailable at https://github.com/cvg/mpsfm.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-28T17:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.20386v1","title":"Safe and Optimal N-Spacecraft Swarm Reconfiguration in Non-Keplerian\n  Cislunar Orbits","summary":"This paper presents a novel fuel-optimal guidance and control methodology for\nspacecraft swarm reconfiguration in Restricted Multi-Body Problems (RMBPs) with\na guarantee of passive safety, maintaining miss distance even under abrupt loss\nof control authority. A new set of constraints exploits a quasi-periodic\nstructure of RMBPs to guarantee passive safety. Particularly, this can be\nexpressed as simple geometric constraints by solving optimal control in Local\nToroidal Coordinates, which is based on a local eigenspace of a quasi-periodic\nmotion around the corresponding periodic orbit. The proposed formulation\nenables a significant simplification of problem structure, which is highly\napplicable to large-scale swarm reconfiguration in cislunar orbits. The method\nis demonstrated in various models of RMBPs (Elliptical Restricted Three-Body\nProblem and Bi-Circular Restricted Four-Body Problem) and also validated in the\nfull-ephemeris dynamics. By extending and generalizing well-known concepts from\nthe two- to the three- and four-body problems, this paper lays the foundation\nfor the practical control schemes of relative motion in cislunar space.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY,math.DS","published":"2025-04-29T03:13:28Z"}
{"aid":"http://arxiv.org/abs/2504.20395v1","title":"Partial Answer of How Transformers Learn Automata","summary":"We introduce a novel framework for simulating finite automata using\nrepresentation-theoretic semidirect products and Fourier modules, achieving\nmore efficient Transformer-based implementations.","main_category":"cs.FL","categories":"cs.FL,cs.LG","published":"2025-04-29T03:35:40Z"}
{"aid":"http://arxiv.org/abs/2504.20415v1","title":"Undecidability of the Emptiness Problem of Deterministic Propositional\n  While Programs with Graph Loop: Hypothesis Elimination Using Loops","summary":"We show that the emptiness (unsatisfiability) problem is undecidable and\n$\\mathrm{\\Pi}^{0}_{1}$-complete for deterministic propositional while programs\nwith (graph) loop. To this end, we introduce a hypothesis elimination using\nloops. Using this, we give reductions from the complement of the periodic\ndomino problem.\n  Moreover, as a corollary via hypothesis eliminations, we also show that the\nequational theory is $\\mathrm{\\Pi}^{0}_{1}$-complete for the positive calculus\nof relations with transitive closure and difference. Additionally, we show that\nthe emptiness problem is PSPACE-complete for the existential calculus of\nrelations with transitive closure.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-29T04:24:36Z"}
{"aid":"http://arxiv.org/abs/2504.20426v1","title":"RV-Syn: Rational and Verifiable Mathematical Reasoning Data Synthesis\n  based on Structured Function Library","summary":"The advancement of reasoning capabilities in Large Language Models (LLMs)\nrequires substantial amounts of high-quality reasoning data, particularly in\nmathematics. Existing data synthesis methods, such as data augmentation from\nannotated training sets or direct question generation based on relevant\nknowledge points and documents, have expanded datasets but face challenges in\nmastering the inner logic of the problem during generation and ensuring the\nverifiability of the solutions. To address these issues, we propose RV-Syn, a\nnovel Rational and Verifiable mathematical Synthesis approach. RV-Syn\nconstructs a structured mathematical operation function library based on\ninitial seed problems and generates computational graphs as solutions by\ncombining Python-formatted functions from this library. These graphs are then\nback-translated into complex problems. Based on the constructed computation\ngraph, we achieve solution-guided logic-aware problem generation. Furthermore,\nthe executability of the computational graph ensures the verifiability of the\nsolving process. Experimental results show that RV-Syn surpasses existing\nsynthesis methods, including those involving human-generated problems,\nachieving greater efficient data scaling. This approach provides a scalable\nframework for generating high-quality reasoning datasets.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T04:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.20457v1","title":"Modular Channels, Thermal Filtering and the Spectral Emergence of\n  Spacetime","summary":"We investigate the information-theoretic structure underlying causal horizons\nthrough the formalism of modular quantum channels. By analyzing the singular\nvalue decomposition of the channel induced by the partial trace over\ninaccessible regions, we show that the Unruh effect and the Page curve can be\nunderstood as manifestations of a universal thermal filtering mechanism\ngoverned by the modular Hamiltonian. This structure leads to a Gibbs-weighted\nhierarchy of information transmission modes, with entanglement entropy\ncorresponding to spectral activation and thermal capacity.\n  We reinterpret the first law of entanglement as a Clausius relation for\nmodular flow and derive Einstein's equations by requiring its local validity\nacross Rindler horizons. In the case of black hole evaporation, we find that\nthe modular channel undergoes an informational phase transition at the Page\ntime, marked by a shift from entanglement preservation to recoverability,\nquantified through fidelity and channel capacity.\n  Based on these results, we propose the Modular Channels Flow Correspondence\n(MCFC): a minimal holographic principle whereby the area of a causal screen\nmeasures the storage of filtered quantum information. Our framework offers a\nunified operational account of holography, entropy, and curvature, grounded in\nthe spectral dynamics of modular channels.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-29T06:35:15Z"}
{"aid":"http://arxiv.org/abs/2504.20484v1","title":"Enhancing LLM Language Adaption through Cross-lingual In-Context\n  Pre-training","summary":"Large language models (LLMs) exhibit remarkable multilingual capabilities\ndespite English-dominated pre-training, attributed to cross-lingual mechanisms\nduring pre-training. Existing methods for enhancing cross-lingual transfer\nremain constrained by parallel resources, suffering from limited linguistic and\ndomain coverage. We propose Cross-lingual In-context Pre-training (CrossIC-PT),\na simple and scalable approach that enhances cross-lingual transfer by\nleveraging semantically related bilingual texts via simple next-word\nprediction. We construct CrossIC-PT samples by interleaving semantic-related\nbilingual Wikipedia documents into a single context window. To access window\nsize constraints, we implement a systematic segmentation policy to split long\nbilingual document pairs into chunks while adjusting the sliding window\nmechanism to preserve contextual coherence. We further extend data availability\nthrough a semantic retrieval framework to construct CrossIC-PT samples from\nweb-crawled corpus. Experimental results demonstrate that CrossIC-PT improves\nmultilingual performance on three models (Llama-3.1-8B, Qwen2.5-7B, and\nQwen2.5-1.5B) across six target languages, yielding performance gains of 3.79%,\n3.99%, and 1.95%, respectively, with additional improvements after data\naugmentation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T07:24:25Z"}
{"aid":"http://arxiv.org/abs/2504.20502v1","title":"Laser-induced modulation of the ferromagnetic-antiferromagnetic phase\n  fraction in FeRh films","summary":"With his huge entropy change and a strong interplay between magnetic order,\nstructural and electrical properties, the first-order\nantiferromagnetic/ferromagnetic phase transition is a paradigmatic example of\nthe multicaloric effect. The unraveling of the physics underlying the phase\ntransition needs a better understanding of the thermal hysteresis of FeRh\nwithin the AF-FM phase coexistence region. In this work, we compare the effect\nof two very different types of thermal cycling on the hysteresis of the\nmagnetic order: quasi-static heating, and cooling of the entire 195 nm thick\nfilm, and a f =100 kHz modulated heating driven by a laser focused down to a\nspot of about ten micron squared at the film surface. Taking advantage of the\nreflectivity difference between both phases to probe optically their respective\nfraction, we show that whereas only temperature-driven reflectivity variations\n(dR/dT , thermoreflectance) are detected in the pure phases, a huge modulation\nof the phase-dependent reflectance at the driving frequency f is detected in\nthe phase coexistence temperature range. This is quantitatively described as\nresulting from a substantial modulation of the FM fraction (up to 90%) with\nincreasing laser power. A simplified rate-independent hysteresis model with\nreturn-point-memory (RPM), represented in terms of bistable units that undergo\na temperature excursion corresponding to a given laser power, reproduces very\nwell the optically measured FM phase modulation characteristics for a broad\nrange of temperature excursions. This offers an insight into the leading role\nof quenched disorder in defining thermal hysteresis in FeRh under high\nexcitation frequency, when the material is periodically driven\nout-of-equilibrium.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-29T07:44:29Z"}
{"aid":"http://arxiv.org/abs/2504.20515v1","title":"Integrability of homogeneous exact magnetic flows on spheres","summary":"We consider motion of a material point placed in a constant homogeneous\nmagnetic field in $\\mathbb R^n$ and also motion restricted to the sphere\n$S^{n-1}$. While there is an obvious integrability of the magnetic system in\n$\\mathbb R^n$, the integrability of the system restricted to the sphere\n$S^{n-1}$ is highly non-trivial. We prove complete integrability of the\nobtained restricted magnetic systems for $n\\le 6$. The first integrals of\nmotion of the magnetic flows on the spheres $S^{n-1}$, for $n=5$ and $n=6$, are\npolynomials of the degree $1$, $2$, and $3$ in momenta. We prove noncommutative\nintegrability of the obtained magnetic flows for any $n\\ge 7$ when the systems\nallow a reduction to the cases with $n\\le 6$. We conjecture that the restricted\nmagnetic systems on $S^{n-1}$ are integrable for all $n$.","main_category":"math.DG","categories":"math.DG,nlin.SI","published":"2025-04-29T07:57:34Z"}
{"aid":"http://arxiv.org/abs/2504.20533v1","title":"Error bounds for the Floquet-Magnus expansion and their application to\n  the semiclassical quantum Rabi model","summary":"We present a general, nonperturbative method for deriving effective\nHamiltonians of arbitrary order for periodically driven systems, based on an\niterated integration by parts technique. The resulting family of effective\nHamiltonians reproduces the well-known Floquet-Magnus expansion, now enhanced\nwith explicit error bounds that quantify the distance between the exact and\napproximate dynamics at each order, even in cases where the Floquet-Magnus\nseries fails to converge. We apply the method to the semiclassical Rabi model\nand provide explicit error bounds for both the Bloch-Siegert Hamiltonian and\nits third-order refinement. Our analysis shows that, while the rotating-wave\napproximation more accurately captures the true dynamics than the Bloch-Siegert\nHamiltonian in most regimes, the third-order approximation ultimately\noutperforms both.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T08:27:21Z"}
{"aid":"http://arxiv.org/abs/2504.20534v1","title":"A polarized view of the young Pulsar Wind Nebula 3C 58 with IXPE","summary":"Pulsar Wind nebulae (PWNe), are among the most efficient particle\naccelerators in the Universe, however understanding the physical conditions and\nthe magnetic geometry in their inner region has always proved elusive. X-ray\npolarization provides now a unique opportunity to investigate the magnetic\nfield structure and turbulence properties close to where high energy particles\nare accelerated. Here we report on the recent X-ray polarization measurement of\nthe PWN 3C 58 by the International X-ray Polarimeter Explorer (IXPE). 3C 58 is\na young system displaying a characteristic jet-torus structure which, unlike\nother PWNe, is seen almost edge on. This nebula shows a high level of\nintegrated polarization ~ 22% at an angle ~ 97deg, with an implied magnetic\nfield oriented parallel to the major axis of the inner torus, suggesting a\ntoroidal magnetic geometry with little turbulence in the interior, and an\nintrinsic level of polarization possibly approaching the theoretical limit for\nsynchrotron emission. No significant detection of a polarized signal from the\nassociated pulsar was found. These results confirm that the internal structure\nof young PWNe is far less turbulent than previously predicted, and at odds with\nmultidimensional numerical simulations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-29T08:27:50Z"}
{"aid":"http://arxiv.org/abs/2504.20540v1","title":"Spin Wave Dispersion of the van der Waals Antiferromagnet NiPS$_3$","summary":"We calculate the magnon dispersion spectra of the two-dimensional zigzag van\nder Waals antiferromagnet NiPS$_3$ for monolayer, bilayer, and bulk systems as\na function of an external magnetic field. We calculate the exchange and\nanisotropy constants in our spin model by first principles. We can accurately\nexplain the transition from a collinear to a canted ground state for a magnetic\nfield applied normal to the (in-plane) easy-axis, and a spin-flop transition\nwhen the field is parallel to it. A topologically protected Dirac nodal line is\npresent and robust with respect to both external and anisotropy fields.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-29T08:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.20563v1","title":"Turing machines deciders, part I","summary":"The Busy Beaver Challenge (or bbchallenge) aims at collaboratively solving\nthe following conjecture: \"$S(5) = 47{,}176{,}870$\" [Rad\\'o, 1962], [Marxen and\nBuntrock, 1990], [Aaronson, 2020]. This conjecture says that if a 5-state\nTuring machine runs for more than 47,176,870 steps without halting, then it\nwill never halt -- starting from the all-0 tape. Proving this conjecture\namounts to deciding whether 181,385,789 Turing machines with 5 states halt or\nnot -- starting from the all-0 tape [bbchallenge, 2025]. To do so, we write\n$\\textit{deciders}$: programs that take as input a Turing machine and output\neither HALT, NONHALT, or UNKNOWN. Each decider is specialised in recognising a\nparticular type of non-halting behavior.\n  After two years of work, the Busy Beaver Challenge achieved its goal in July\n2024 by delivering a proof of \"$S(5) = 47{,}176{,}870$\" formalised in Coq\n[bbchallenge, 2025]. In this document, we present deciders that were developed\nbefore the Coq proof and which were mainly not used in the proof; nonetheless,\nthey are relevant techniques for analysing Turing machines. Part II of this\nwork is the decider section of our paper showing \"$S(5) = 47{,}176{,}870$\"\n[bbchallenge, 2025], presenting the deciders that were used in the Coq proof.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-29T09:08:11Z"}
{"aid":"http://arxiv.org/abs/2504.20630v1","title":"ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting","summary":"Multimodal immersive spatial drama generation focuses on creating continuous\nmulti-speaker binaural speech with dramatic prosody based on multimodal\nprompts, with potential applications in AR, VR, and others. This task requires\nsimultaneous modeling of spatial information and dramatic prosody based on\nmultimodal inputs, with high data collection costs. To the best of our\nknowledge, our work is the first attempt to address these challenges. We\nconstruct MRSDrama, the first multimodal recorded spatial drama dataset,\ncontaining binaural drama audios, scripts, videos, geometric poses, and textual\nprompts. Then, we propose ISDrama, the first immersive spatial drama generation\nmodel through multimodal prompting. ISDrama comprises these primary components:\n1) Multimodal Pose Encoder, based on contrastive learning, considering the\nDoppler effect caused by moving speakers to extract unified pose information\nfrom multimodal prompts. 2) Immersive Drama Transformer, a flow-based\nmamba-transformer model that generates high-quality drama, incorporating\nDrama-MOE to select proper experts for enhanced prosody and pose control. We\nalso design a context-consistent classifier-free guidance strategy to\ncoherently generate complete drama. Experimental results show that ISDrama\noutperforms baseline models on objective and subjective metrics. The demos and\ndataset are available at https://aaronz345.github.io/ISDramaDemo.","main_category":"eess.AS","categories":"eess.AS,cs.MM,cs.SD","published":"2025-04-29T10:56:44Z"}
{"aid":"http://arxiv.org/abs/2504.20644v1","title":"Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified\n  File Selection","summary":"Selecting high-quality pre-training data for large language models (LLMs) is\ncrucial for enhancing their overall performance under limited computation\nbudget, improving both training and sample efficiency. Recent advancements in\nfile selection primarily rely on using an existing or trained proxy model to\nassess the similarity of samples to a target domain, such as high quality\nsources BookCorpus and Wikipedia. However, upon revisiting these methods, the\ndomain-similarity selection criteria demonstrates a diversity dilemma,\ni.e.dimensional collapse in the feature space, improving performance on the\ndomain-related tasks but causing severe degradation on generic performance. To\nprevent collapse and enhance diversity, we propose a DiverSified File selection\nalgorithm (DiSF), which selects the most decorrelated text files in the feature\nspace. We approach this with a classical greedy algorithm to achieve more\nuniform eigenvalues in the feature covariance matrix of the selected texts,\nanalyzing its approximation to the optimal solution under a formulation of\n$\\gamma$-weakly submodular optimization problem. Empirically, we establish a\nbenchmark and conduct extensive experiments on the TinyLlama architecture with\nmodels from 120M to 1.1B parameters. Evaluating across nine tasks from the\nHarness framework, DiSF demonstrates a significant improvement on overall\nperformance. Specifically, DiSF saves 98.5% of 590M training files in\nSlimPajama, outperforming the full-data pre-training within a 50B training\nbudget, and achieving about 1.5x training efficiency and 5x data efficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T11:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.20652v1","title":"A DFT study on 18-crown-6-like-N$_8$ structure as a material for\n  metal-ions storage: stability and performance","summary":"Developing electrode materials with exceptional electrical conductivity,\nrobust chemical stability, rapid charge and discharge rates, and high storage\ncapacity is essential for advancing high-performance metal-ion batteries. This\nstudy explores the two-dimensional, 18-crown-6-like N8 structure (2D-N8) as a\npromising electrode material for next-generation rechargeable post-lithium\nbatteries. We thoroughly investigated the pristine N8 structures, focusing on\ntheir stability and performance metrics. Our analysis revealed remarkable\nstructural stability across the board. Additionally, electronic calculations\nindicated a small band gap of 0.54 eV for the N8 monolayer, suggesting\nfavorable electronic properties for battery applications. When we evaluated a\nseries of metal ions as adsorbates, we found that the pristine N8 monolayer\nachieved an impressive storage capacity of 1675 mAh/g for sodium (Na) and\nmagnesium (Mg) ions, highlighting its potential for effective ion storage. Our\nfindings suggest that the engineered 2D-N8 structure offers a unique\ncombination of stability and electrochemical performance that could\nsignificantly contribute to developing efficient and durable energy storage\ntechnologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-29T11:21:27Z"}
{"aid":"http://arxiv.org/abs/2504.20660v1","title":"Quantum-Enhanced Hybrid Reinforcement Learning Framework for Dynamic\n  Path Planning in Autonomous Systems","summary":"In this paper, a novel quantum classical hybrid framework is proposed that\nsynergizes quantum with Classical Reinforcement Learning. By leveraging the\ninherent parallelism of quantum computing, the proposed approach generates\nrobust Q tables and specialized turn cost estimations, which are then\nintegrated with a classical Reinforcement Learning pipeline. The Classical\nQuantum fusion results in rapid convergence of training, reducing the training\ntime significantly and improved adaptability in scenarios featuring static,\ndynamic, and moving obstacles. Simulator based evaluations demonstrate\nsignificant enhancements in path efficiency, trajectory smoothness, and mission\nsuccess rates, underscoring the potential of framework for real time,\nautonomous navigation in complex and unpredictable environments. Furthermore,\nthe proposed framework was tested beyond simulations on practical scenarios,\nincluding real world map data such as the IIT Delhi campus, reinforcing its\npotential for real time, autonomous navigation in complex and unpredictable\nenvironments.","main_category":"cs.LG","categories":"cs.LG,cs.ET,cs.IT,math.IT","published":"2025-04-29T11:36:08Z"}
{"aid":"http://arxiv.org/abs/2504.20670v1","title":"FBRT-YOLO: Faster and Better for Real-Time Aerial Image Detection","summary":"Embedded flight devices with visual capabilities have become essential for a\nwide range of applications. In aerial image detection, while many existing\nmethods have partially addressed the issue of small target detection,\nchallenges remain in optimizing small target detection and balancing detection\naccuracy with efficiency. These issues are key obstacles to the advancement of\nreal-time aerial image detection. In this paper, we propose a new family of\nreal-time detectors for aerial image detection, named FBRT-YOLO, to address the\nimbalance between detection accuracy and efficiency. Our method comprises two\nlightweight modules: Feature Complementary Mapping Module (FCM) and\nMulti-Kernel Perception Unit(MKP), designed to enhance object perception for\nsmall targets in aerial images. FCM focuses on alleviating the problem of\ninformation imbalance caused by the loss of small target information in deep\nnetworks. It aims to integrate spatial positional information of targets more\ndeeply into the network,better aligning with semantic information in the deeper\nlayers to improve the localization of small targets. We introduce MKP, which\nleverages convolutions with kernels of different sizes to enhance the\nrelationships between targets of various scales and improve the perception of\ntargets at different scales. Extensive experimental results on three major\naerial image datasets, including Visdrone, UAVDT, and AI-TOD,demonstrate that\nFBRT-YOLO outperforms various real-time detectors in terms of performance and\nspeed.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T11:53:54Z"}
{"aid":"http://arxiv.org/abs/2504.20679v1","title":"Are Information Retrieval Approaches Good at Harmonising Longitudinal\n  Survey Questions in Social Science?","summary":"Automated detection of semantically equivalent questions in longitudinal\nsocial science surveys is crucial for long-term studies informing empirical\nresearch in the social, economic, and health sciences. Retrieving equivalent\nquestions faces dual challenges: inconsistent representation of theoretical\nconstructs (i.e. concept/sub-concept) across studies as well as between\nquestion and response options, and the evolution of vocabulary and structure in\nlongitudinal text. To address these challenges, our multi-disciplinary\ncollaboration of computer scientists and survey specialists presents a new\ninformation retrieval (IR) task of identifying concept (e.g. Housing, Job,\netc.) equivalence across question and response options to harmonise\nlongitudinal population studies. This paper investigates multiple unsupervised\napproaches on a survey dataset spanning 1946-2020, including probabilistic\nmodels, linear probing of language models, and pre-trained neural networks\nspecialised for IR. We show that IR-specialised neural models achieve the\nhighest overall performance with other approaches performing comparably.\nAdditionally, the re-ranking of the probabilistic model's results with neural\nmodels only introduces modest improvements of 0.07 at most in F1-score.\nQualitative post-hoc evaluation by survey specialists shows that models\ngenerally have a low sensitivity to questions with high lexical overlap,\nparticularly in cases where sub-concepts are mismatched. Altogether, our\nanalysis serves to further research on harmonising longitudinal studies in\nsocial science.","main_category":"cs.CL","categories":"cs.CL,cs.IR","published":"2025-04-29T12:00:33Z"}
{"aid":"http://arxiv.org/abs/2504.20712v1","title":"On three-dimensional ${\\cal N}=4$ supersymmetry: maximally\n  supersymmetric backgrounds and massive deformations","summary":"Using the $SO ({\\cal N})$ superspace formulation for $\\cal N$-extended\nconformal supergravity in three dimensions, we derive all maximally\nsupersymmetric backgrounds in the ${\\cal N} =4$ case. The specific feature of\nthis choice is that the so-called super Cotton tensor $X^{IJKL} = X^{[IJKL]}$,\nwhich exists for ${\\cal N} \\geq 4$, is equivalent to the scalar $X$ defined by\n$X^{IJKL} = \\varepsilon^{IJKL} X$. This scalar may be used as a deformation\nparameter. In the family of $(p,q)$ anti-de Sitter (AdS) superspaces with\n$p+q=4$, it is known that $X\\neq 0$ exists only if $p=4$ and $q=0$. In general,\nthe $(4,0)$ AdS superspaces are characterised by the structure group\n$SL(2,{\\mathbb R}) \\times SO (4)$ and their geometry is determined by two\nconstant parameters, $S$ and $X$, of which the former determines the AdS\ncurvature, while the $R$-symmetry curvature is determined by the parameters\n$(X+2S)$ and $(X-2S)$ in the left and right sectors of $SU(2)_{\\rm L} \\times\nSU(2)_{\\rm R}$, respectively. Setting $S=0$ leads to the so-called deformed\n${\\cal N}=4$ Minkowski superspace ${\\mathbb M}^{3|8}_X$ introduced thirteen\nyears ago. We construct general interacting supersymmetric field theories in\n${\\mathbb M}^{3|8}_X$ and demonstrate that they originate as massive\ndeformations of the following two families of ${\\cal N} =4$ theories in\nstandard Minkowski superspace ${\\mathbb M}^{3|8}$: (i) ${\\cal N}=4$\nsuperconformal field theories; and (ii) ${\\cal N}=4$ supersymmetric gauge\ntheories in ${\\mathbb M}^{3|8}$ which are not superconformal but possess the\n$R$-symmetry group $SU(2)_{\\rm L} \\times SU(2)_{\\rm R}$. Extensions of the\ntheories in (ii) to ${\\mathbb M}^{3|8}_X$ necessarily contain Chern-Simons\nterms at the component level. We also demonstrate the generation of\ntopologically massive ${\\cal N}=4$ supersymmetric gauge theories from radiative\ncorrections in the hypermultiplet sector.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-29T12:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.20715v1","title":"Neural semi-Lagrangian method for high-dimensional advection-diffusion\n  problems","summary":"This work is devoted to the numerical approximation of high-dimensional\nadvection-diffusion equations. It is well-known that classical methods, such as\nthe finite volume method, suffer from the curse of dimensionality, and that\ntheir time step is constrained by a stability condition. The semi-Lagrangian\nmethod is known to overcome the stability issue, while recent time-discrete\nneural network-based approaches overcome the curse of dimensionality. In this\nwork, we propose a novel neural semi-Lagrangian method that combines these last\ntwo approaches. It relies on projecting the initial condition onto a\nfinite-dimensional neural space, and then solving an optimization problem,\ninvolving the backwards characteristic equation, at each time step. It is\nparticularly well-suited for implementation on GPUs, as it is fully\nparallelizable and does not require a mesh. We provide rough error estimates,\nand present several high-dimensional numerical experiments to assess the\nperformance of our approach, and compare it to other neural methods.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-29T12:52:55Z"}
{"aid":"http://arxiv.org/abs/2504.20717v1","title":"Timing analysis of the black-hole candidate Swift J1727.8-1613:\n  detection of a dip-like feature in the high-energy cross spectrum","summary":"We present a timing analysis of observations with the Hard X-ray Modulation\nTelescope of the black hole X-ray transient Swift J1727.8-1613 during its 2023\noutburst. We detect, for the first time in a black hole X-ray binary, a\nprominent dip at ~ 3-15 Hz in the real part of the cross spectrum between\nhigh-energy (>25 keV) and low-energy (<10 keV) photons in the Low Hard and Hard\nIntermediate States, during which the QPO frequency rapidly increases and then\nstabilizes at ~ 1.0-1.5 Hz. Remarkably, the real part of the cross spectrum\nreaches negative values at the frequencies around the minimum of the dip,\nindicative of a phase lag ranging between ${\\pi}/2$ and ${\\pi}$ in this\nfrequency range. We fit the power spectra and the real and imaginary parts of\nthe cross spectra simultaneously using a multi-Lorentzian model. Among the lag\nmodels, the Gaussian phase-lag model provides a slightly better reduced\n${\\chi}^2$ than the constant phase-lag and constant time-lag models, while it\nalso alleviates the degeneracy associated with those models. From the\nparameters of the Lorentzian that fits the dip, we estimate the size of the\naccretion flow, which consistently exceeds 10,000 km as the QPO frequency\nincreases from 0.13 Hz to 2.0 Hz. Furthermore, both the energy-dependent\nphase-lag and fractional-rms spectra of the dip exhibit a change in trend\naround 15 keV, with the phase lag dropping and rms reaching a local minimum.\nThese spectra closely resemble the shapes predicted by the time-dependent\nComptonization model, vKompth, for a low feedback factor, offering a pathway to\nexplain the radiative properties of the corona. Additionally, the coherence\nfunction suggests a diversity of variability components, potentially arising\nfrom different parts of the corona.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-29T12:56:14Z"}
{"aid":"http://arxiv.org/abs/2504.20728v1","title":"On optimal error rates for strong approximation of SDEs with a HÃ¶lder\n  continuous drift coefficient","summary":"In the present article we study strong approximation of solutions of scalar\nstochastic differential equations (SDEs) with bounded and $\\alpha$-H\\\"older\ncontinuous drift coefficient and constant diffusion coefficient at time point\n$1$. Recently, it was shown in [arXiv:1909.07961v4 (2021)] that for such SDEs\nthe equidistant Euler scheme achieves an $L^p$-error rate of at least\n$(1+\\alpha)/2$, up to an arbitrary small $\\varepsilon$, for all $p\\geq 1$ and\nall $\\alpha\\in(0, 1]$ in terms of the number of evaluations of the driving\nBrownian motion $W$. In this article we prove a matching lower error bound for\n$\\alpha\\in(0, 1)$. More precisely, we show that for every $\\alpha\\in(0, 1)$,\nthe $L^p$-error rate $(1+\\alpha)/2$ of the Euler scheme in [arXiv:1909.07961v4\n(2021)] can not be improved in general by no numerical method based on finitely\nmany evaluations of $W$ at fixed time points. Up to now, this result was known\nin the literature only for $\\alpha=1$.\n  Additionally, we extend a result from [arXiv:2402.13732v2 (2024)] on sharp\nlower errror bounds for strong approximation of SDEs with a bounded drift\ncoefficient of fractional Sobolev regularity $\\alpha\\in (0,1)$ and constant\ndiffusion coefficient at time point $1$. We prove that for every $\\alpha\\in\n(0,1)$, the $L^p$-error rate $ (1 + \\alpha)/2$ that was shown in\n[arXiv:2101.12185v2 (2022)] for the equidistant Euler scheme can, up to a\nlogarithmic term, not be improved in general by no numerical method based on\nfinitely many evaluations of W at fixed time points. This result was known from\n[arXiv:2402.13732v2 (2024)] only for $\\alpha\\in (1/2,1)$ and $p=2$.\n  For the proof of these lower bounds we use variants of the Weierstrass\nfunction as a drift coefficient and we employ the coupling of noise technique\nrecently introduced in [arXiv:2010.00915v1 (2020)].","main_category":"math.PR","categories":"math.PR,cs.NA,math.NA","published":"2025-04-29T13:11:46Z"}
{"aid":"http://arxiv.org/abs/2504.20756v1","title":"Graph-Based Fault Diagnosis for Rotating Machinery: Adaptive\n  Segmentation and Structural Feature Integration","summary":"This paper proposes a novel graph-based framework for robust and\ninterpretable multiclass fault diagnosis in rotating machinery. The method\nintegrates entropy-optimized signal segmentation, time-frequency feature\nextraction, and graph-theoretic modeling to transform vibration signals into\nstructured representations suitable for classification. Graph metrics, such as\naverage shortest path length, modularity, and spectral gap, are computed and\ncombined with local features to capture global and segment-level fault\ncharacteristics. The proposed method achieves high diagnostic accuracy when\nevaluated on two benchmark datasets, the CWRU bearing dataset (under 0-3 HP\nloads) and the SU gearbox and bearing datasets (under different speed-load\nconfigurations). Classification scores reach up to 99.8% accuracy on Case\nWestern Reserve University (CWRU) and 100% accuracy on the Southeast University\ndatasets using a logistic regression classifier. Furthermore, the model\nexhibits strong noise resilience, maintaining over 95.4% accuracy at high noise\nlevels (standard deviation = 0.5), and demonstrates excellent cross-domain\ntransferability with up to 99.7% F1-score in load-transfer scenarios. Compared\nto traditional techniques, this approach requires no deep learning\narchitecture, enabling lower complexity while ensuring interpretability. The\nresults confirm the method's scalability, reliability, and potential for\nreal-time deployment in industrial diagnostics.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T13:34:52Z"}
{"aid":"http://arxiv.org/abs/2504.20777v1","title":"Bayesian Deep End-to-End Learning for MIMO-OFDM System with Delay-Domain\n  Sparse Precoder","summary":"This paper introduces a novel precoder design aimed at reducing pilot\noverhead for effective channel estimation in multiple-input multiple-output\northogonal frequency division multiplexing (MIMO-OFDM) applications utilizing\nhigh-order modulation. We propose an innovative demodulation reference signal\nscheme that achieves up to an 8x reduction in overhead by implementing a\ndelay-domain sparsity constraint on the precoder. Furthermore, we present a\ndeep neural network (DNN)-based end-to-end architecture that integrates a\npropagation channel estimation module, a precoder design module, and an\neffective channel estimation module. Additionally, we propose a Bayesian\nmodel-assisted training framework that incorporates domain knowledge, resulting\nin an interpretable datapath design. Simulation results demonstrate that our\nproposed solution significantly outperforms various baseline schemes while\nexhibiting substantially lower computational complexity.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T13:54:19Z"}
{"aid":"http://arxiv.org/abs/2504.20801v1","title":"Unlocking User-oriented Pages: Intention-driven Black-box Scanner for\n  Real-world Web Applications","summary":"Black-box scanners have played a significant role in detecting\nvulnerabilities for web applications. A key focus in current black-box scanning\nis increasing test coverage (i.e., accessing more web pages). However, since\nmany web applications are user-oriented, some deep pages can only be accessed\nthrough complex user interactions, which are difficult to reach by existing\nblack-box scanners. To fill this gap, a key insight is that web pages contain a\nwealth of semantic information that can aid in understanding potential user\nintention. Based on this insight, we propose Hoyen, a black-box scanner that\nuses the Large Language Model to predict user intention and provide guidance\nfor expanding the scanning scope. Hoyen has been rigorously evaluated on 12\npopular open-source web applications and compared with 6 representative tools.\nThe results demonstrate that Hoyen performs a comprehensive exploration of web\napplications, expanding the attack surface while achieving about 2x than the\ncoverage of other scanners on average, with high request accuracy. Furthermore,\nHoyen detected over 90% of its requests towards the core functionality of the\napplication, detecting more vulnerabilities than other scanners, including\nunique vulnerabilities in well-known web applications. Our data/code is\navailable at https://hoyen.tjunsl.com/","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-04-29T14:14:30Z"}
{"aid":"http://arxiv.org/abs/2504.20806v1","title":"Geometric Function Theory on Uniformly Quasiconformally Homogeneous\n  Domains","summary":"Uniformly quasiconformally homogeneous domains in $\\mathbb{R}^n$ carry a\ntransitive collection of $K$-quasiconformal maps for a fixed $K\\geq 1.$ In this\npaper, we study two questions in this setting. The first is to show that\nquasiconformality and quasisymmetry with respect to the quasihyperbolic metric\nare equivalent. The second is to study normal quasiregular maps from such a\ndomain into $S^n$ or $\\mathbb{R}^n$ and show they enjoy geometric properties\nsuch as a uniform H\\\"{o}lder condition.","main_category":"math.CV","categories":"math.CV","published":"2025-04-29T14:19:34Z"}
{"aid":"http://arxiv.org/abs/2504.20819v1","title":"Quantum Signature of Anisotropic Singularities in Hydrogen Bond Breaking\n  of Water Dimer","summary":"In all standard force field-based simulations of organic, bio-molecules,\npolymers; the torsion angle based Hamiltonian has been an indispensable term to\nset up molecular simulation. Torsion often termed as a dihedral angle, the\ncoordinate assumes a continuous molecular geometry and energy changes for an\nangle range from 0 to 360 degrees. However, quantum mechanics-based results\npresented earlier and in this report show electronic energy will have\nsingularities due to molecular geometry criticality, and torsion based\nelectrotonic energy is not a smooth function of (r, theta) due to bond-breaking\ngeometry. Contrast to force field or molecular mechanics based results of\ngeometrical and energy continuity, continuum of geometry under torsion is not\nfeasible as per quantum mechanical electronic energy computations. This feature\nof electronic energy is readily observed for weakly H-bonded and VDW dimers.\n  Applying the ab initio methods of Hartree-Fock, Density Functional as well as\nMoller-Plesset, we have reconfirmed the previous general predictions of\nelectronic energy singularities with torsion angle variation around weak H-bond\nequilibrium and beyond for water dimer. Due to the quantum nature of the weak\nchemical bond breaking process leading to break-point conditions in molecules,\nthe singularities in electronic energy is observed contrast to molecular\nmechanics results. These overlooked results of quantum energy singularities can\nbe useful to improve the current bio-molecular force field and reaction\nchemistry dynamics involving bond-breaking process.\n  Hypothesis tested: https://zenodo.org/records/12730902","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-29T14:39:24Z"}
{"aid":"http://arxiv.org/abs/2504.20821v1","title":"The When and How of Target Variable Transformations","summary":"The machine learning pipeline typically involves the iterative process of (1)\ncollecting the data, (2) preparing the data, (3) learning a model, and (4)\nevaluating a model. Practitioners recognize the importance of the data\npreparation phase in terms of its impact on the ability to learn accurate\nmodels. In this regard, significant attention is often paid to manipulating the\nfeature set (e.g., selection, transformations, dimensionality reduction). A\npoint that is less well appreciated is that transformations on the target\nvariable can also have a large impact on whether it is possible to learn a\nsuitable model. These transformations may include accounting for\nsubject-specific biases (e.g., in how someone uses a rating scale), contexts\n(e.g., population size effects), and general trends (e.g., inflation). However,\nthis point has received a much more cursory treatment in the existing\nliterature. The goal of this paper is three-fold. First, we aim to highlight\nthe importance of this problem by showing when transforming the target variable\nhas been useful in practice. Second, we will provide a set of generic ``rules\nof thumb'' that indicate situations when transforming the target variable may\nbe needed. Third, we will discuss which transformations should be considered in\na given situation.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T14:40:21Z"}
{"aid":"http://arxiv.org/abs/2504.20897v1","title":"Elliptic leading singularities and canonical integrands","summary":"We propose a generalization of $\\mathrm{dlog}$ integrands with unit leading\nsingularities to the case covering integration of differential forms on\nelliptic curves. We first construct a special algebraic basis of integrands,\nincluding a differential one-form of the second kind, and match it to a Feynman\nintegral ansatz in a suitable parametrization. Integration over a preferred\nbasis cycle reveals their (elliptic) leading singularities. A simple\ntransformation that sets all but one of the elliptic leading singularities to\nzero and normalizes the remaining one to unity then defines the canonical\nintegrands. In several examples, we observe that the corresponding Feynman\nintegrals satisfy a special form of differential equation that has so far\nremained unnoticed. It factorizes component-wise either $\\epsilon$ or $1 -\nn\\,\\epsilon$ with integer $n$, and evaluates order-by-order in $\\epsilon$ to\npure functions. We conjecture that our integrand-level construction universally\nleads to such differential equations.","main_category":"hep-th","categories":"hep-th","published":"2025-04-29T16:14:03Z"}
{"aid":"http://arxiv.org/abs/2504.20902v1","title":"Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for\n  Visual Classifiers","summary":"A person downloading a pre-trained model from the web should be aware of its\nbiases. Existing approaches for bias identification rely on datasets containing\nlabels for the task of interest, something that a non-expert may not have\naccess to, or may not have the necessary resources to collect: this greatly\nlimits the number of tasks where model biases can be identified. In this work,\nwe present Classifier-to-Bias (C2B), the first bias discovery framework that\nworks without access to any labeled data: it only relies on a textual\ndescription of the classification task to identify biases in the target\nclassification model. This description is fed to a large language model to\ngenerate bias proposals and corresponding captions depicting biases together\nwith task-specific target labels. A retrieval model collects images for those\ncaptions, which are then used to assess the accuracy of the model w.r.t. the\ngiven biases. C2B is training-free, does not require any annotations, has no\nconstraints on the list of biases, and can be applied to any pre-trained model\non any classification task. Experiments on two publicly available datasets show\nthat C2B discovers biases beyond those of the original datasets and outperforms\na recent state-of-the-art bias detection baseline that relies on task-specific\nannotations, being a promising first step toward addressing task-agnostic\nunsupervised bias detection.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-29T16:19:38Z"}
{"aid":"http://arxiv.org/abs/2504.20904v1","title":"Dual Explanations via Subgraph Matching for Malware Detection","summary":"Interpretable malware detection is crucial for understanding harmful\nbehaviors and building trust in automated security systems. Traditional\nexplainable methods for Graph Neural Networks (GNNs) often highlight important\nregions within a graph but fail to associate them with known benign or\nmalicious behavioral patterns. This limitation reduces their utility in\nsecurity contexts, where alignment with verified prototypes is essential. In\nthis work, we introduce a novel dual prototype-driven explainable framework\nthat interprets GNN-based malware detection decisions. This dual explainable\nframework integrates a base explainer (a state-of-the-art explainer) with a\nnovel second-level explainer which is designed by subgraph matching technique,\ncalled SubMatch explainer. The proposed explainer assigns interpretable scores\nto nodes based on their association with matched subgraphs, offering a\nfine-grained distinction between benign and malicious regions. This\nprototype-guided scoring mechanism enables more interpretable, behavior-aligned\nexplanations. Experimental results demonstrate that our method preserves high\ndetection performance while significantly improving interpretability in malware\nanalysis.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-29T16:20:28Z"}
{"aid":"http://arxiv.org/abs/2504.20948v1","title":"DS_FusionNet: Dynamic Dual-Stream Fusion with Bidirectional Knowledge\n  Distillation for Plant Disease Recognition","summary":"Given the severe challenges confronting the global growth security of\neconomic crops, precise identification and prevention of plant diseases has\nemerged as a critical issue in artificial intelligence-enabled agricultural\ntechnology. To address the technical challenges in plant disease recognition,\nincluding small-sample learning, leaf occlusion, illumination variations, and\nhigh inter-class similarity, this study innovatively proposes a Dynamic\nDual-Stream Fusion Network (DS_FusionNet). The network integrates a\ndual-backbone architecture, deformable dynamic fusion modules, and\nbidirectional knowledge distillation strategy, significantly enhancing\nrecognition accuracy. Experimental results demonstrate that DS_FusionNet\nachieves classification accuracies exceeding 90% using only 10% of the\nPlantDisease and CIFAR-10 datasets, while maintaining 85% accuracy on the\ncomplex PlantWild dataset, exhibiting exceptional generalization capabilities.\nThis research not only provides novel technical insights for fine-grained image\nclassification but also establishes a robust foundation for precise\nidentification and management of agricultural diseases.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T17:15:02Z"}
{"aid":"http://arxiv.org/abs/2504.20964v1","title":"OSVBench: Benchmarking LLMs on Specification Generation Tasks for\n  Operating System Verification","summary":"We introduce OSVBench, a new benchmark for evaluating Large Language Models\n(LLMs) in generating complete specification code pertaining to operating system\nkernel verification tasks. The benchmark first defines the specification\ngeneration problem into a program synthesis problem within a confined scope of\nsyntax and semantics by providing LLMs with the programming model. The LLMs are\nrequired to understand the provided verification assumption and the potential\nsyntax and semantics space to search for, then generate the complete\nspecification for the potentially buggy operating system code implementation\nunder the guidance of the high-level functional description of the operating\nsystem. This benchmark is built upon a real-world operating system kernel,\nHyperkernel, and consists of 245 complex specification generation tasks in\ntotal, each is a long context task of about 20k-30k tokens. Our comprehensive\nevaluation of 12 LLMs exhibits the limited performance of the current LLMs on\nthe specification generation tasks for operating system verification.\nSignificant disparities in their performance on the benchmark highlight\ndifferences in their ability to handle long-context code generation tasks. The\nevaluation toolkit and benchmark are available at\nhttps://github.com/lishangyu-hkust/OSVBench.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.OS,cs.PL,cs.SE","published":"2025-04-29T17:34:49Z"}
{"aid":"http://arxiv.org/abs/2504.21257v1","title":"On the uniqueness of the quasi-geostrophic equation with the fractional\n  Laplacian","summary":"We consider the uniqueness of the solution of the surface quasi-geostrophic\nequation with fractional Laplacian. We show that the uniqueness holds in\nnon-homogeneous Besov spaces without any additional assumption which is\nsupposed to constract solutions. When the power of the fractional Laplacian is\nclose to 2, we prove that the uniqueness with the regularity index $s=-1/2$. We\nextract the least regularity $s=-1/2$ for the well-definedness of the nonlinear\nterm of the equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T02:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.21281v1","title":"Mamba Based Feature Extraction And Adaptive Multilevel Feature Fusion\n  For 3D Tumor Segmentation From Multi-modal Medical Image","summary":"Multi-modal 3D medical image segmentation aims to accurately identify tumor\nregions across different modalities, facing challenges from variations in image\nintensity and tumor morphology. Traditional convolutional neural network\n(CNN)-based methods struggle with capturing global features, while\nTransformers-based methods, despite effectively capturing global context,\nencounter high computational costs in 3D medical image segmentation. The Mamba\nmodel combines linear scalability with long-distance modeling, making it a\npromising approach for visual representation learning. However, Mamba-based 3D\nmulti-modal segmentation still struggles to leverage modality-specific features\nand fuse complementary information effectively. In this paper, we propose a\nMamba based feature extraction and adaptive multilevel feature fusion for 3D\ntumor segmentation using multi-modal medical image. We first develop the\nspecific modality Mamba encoder to efficiently extract long-range relevant\nfeatures that represent anatomical and pathological structures present in each\nmodality. Moreover, we design an bi-level synergistic integration block that\ndynamically merges multi-modal and multi-level complementary features by the\nmodality attention and channel attention learning. Lastly, the decoder combines\ndeep semantic information with fine-grained details to generate the tumor\nsegmentation map. Experimental results on medical image datasets (PET/CT and\nMRI multi-sequence) show that our approach achieve competitive performance\ncompared to the state-of-the-art CNN, Transformer, and Mamba-based approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T03:29:55Z"}
{"aid":"http://arxiv.org/abs/2504.21311v1","title":"Covert Prompt Transmission for Secure Large Language Model Services","summary":"This paper investigates covert prompt transmission for secure and efficient\nlarge language model (LLM) services over wireless networks. We formulate a\nlatency minimization problem under fidelity and detectability constraints to\nensure confidential and covert communication by jointly optimizing the transmit\npower and prompt compression ratio. To solve this problem, we first propose a\nprompt compression and encryption (PCAE) framework, performing surprisal-guided\ncompression followed by lightweight permutation-based encryption. Specifically,\nPCAE employs a locally deployed small language model (SLM) to estimate\ntoken-level surprisal scores, selectively retaining semantically critical\ntokens while discarding redundant ones. This significantly reduces\ncomputational overhead and transmission duration. To further enhance covert\nwireless transmission, we then develop a group-based proximal policy\noptimization (GPPO) method that samples multiple candidate actions for each\nstate, selecting the optimal one within each group and incorporating a\nKullback-Leibler (KL) divergence penalty to improve policy stability and\nexploration. Simulation results show that PCAE achieves comparable LLM response\nfidelity to baseline methods while reducing preprocessing latency by over five\norders of magnitude, enabling real-time edge deployment. We further validate\nPCAE effectiveness across diverse LLM backbones, including DeepSeek-32B,\nQwen-32B, and their smaller variants. Moreover, GPPO reduces covert\ntransmission latency by up to 38.6\\% compared to existing reinforcement\nlearning strategies, with further analysis showing that increased transmit\npower provides additional latency benefits.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-30T04:53:11Z"}
{"aid":"http://arxiv.org/abs/2504.21312v1","title":"Annotating and Auditing the Safety Properties of Unsafe Rust","summary":"Unsafe code is a critical topic in ensuring the security of system software\ndevelopment in Rust. It is the sole source of potential undefined behaviors,\nassuming the compiler is sound. To avoid the misuse of unsafe code, Rust\ndevelopers should provide clear safety property annotations for unsafe APIs.\nHowever, there is limited official guidance and few best practices for\nannotating unsafe code. Even the current best practices for safety property\nannotations in the Rust standard library are ad hoc and informal. In this\npaper, we design a domain-specific language to describe the safety properties\nof unsafe APIs, which may serve as a precursor for automated verification in\nthe future. Furthermore, to ensure that the caller of an unsafe API properly\ndelegates the safety property required by the callee, we propose a novel\nunsafety propagation graph to model the usage and propagation of unsafe code.\nBased on this graph, we further introduce a method to partition the graph into\nsmaller graphs, such that each graph serves as a self-contained audit unit for\nexamining the soundness of unsafe code encapsulation and safety property\nannotation. We applied our approach to the Rust standard library, and the\nexperimental results demonstrate that our method is both practical and\neffective. Additionally, we have fixed safety property description issues in 23\nAPIs.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-30T04:53:35Z"}
{"aid":"http://arxiv.org/abs/2504.21324v1","title":"Conditional inference for multi-omics data with right censored data","summary":"Recent advances in multi-omics technology highlight the need for statistical\nmethods that account for complex dependencies among biological layers. In this\npaper, we propose a novel Multi-Omics Factor-Adjusted Cox (MOFA-Cox) model to\nhandle multi-omics survival data, addressing the intricate correlation\nstructures across different omics layers. Building upon this model, we\nintroduce a decorrelated score test for the Cox model in high-dimensional\nsurvival analysis. We establish the theoretical properties of our test\nstatistic, which show that it admits a closed-form asymptotic distribution,\neliminating the need for resampling. We further analyze its local power under\nlocal alternatives. Importantly, our test statistic does not require a sparsity\nassumption on the covariates of interest, broadening its applicability.\nNumerical studies and an applaication to the TCGA breast cancer dataset\ndemonstrate the effectiveness of our method.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-30T05:20:36Z"}
{"aid":"http://arxiv.org/abs/2504.21333v1","title":"On the distribution of $Î±p^2$ modulo one over primes of the form\n  $[n^c]$","summary":"Let $[\\,\\cdot\\,]$ be the floor function and $\\|x\\|$ denotes the distance from\n$x$ to the nearest integer. In this paper we show that whenever $\\alpha$ is\nirrational and $\\beta$ is real then for any fixed $\\frac{13}{14}<\\gamma<1$,\nthere exist infinitely many prime numbers $p$ satisfying the inequality\n\\begin{equation*} \\|\\alpha p^2+\\beta\\|< p^{\\frac{13-14\\gamma}{29}+\\varepsilon}\\\n\\end{equation*} and such that $p=[n^{1/\\gamma}]$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T05:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.21339v1","title":"Note on elliptic equations on closed manifolds with singular\n  nonlinearities","summary":"We consider a general elliptic equation $$ -\\Delta_g u+V(x)u=f(x,u)+g(x,u^2)u\n$$ on a closed Riemannian manifold $(M, g)$ and utilize a recent variational\napproach by Hebey, Pacard, Pollack to show the existence of a nontrivial\nsolution under general assumptions on nonlinear terms $f$ and $g$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T05:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.21372v1","title":"Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction","summary":"Speech Event Extraction (SpeechEE) is a challenging task that lies at the\nintersection of Automatic Speech Recognition (ASR) and Natural Language\nProcessing (NLP), requiring the identification of structured event information\nfrom spoken language. In this work, we present a modular, pipeline-based\nSpeechEE framework that integrates high-performance ASR with semantic\nsearch-enhanced prompting of Large Language Models (LLMs). Our system first\nclassifies speech segments likely to contain events using a hybrid filtering\nmechanism including rule-based, BERT-based, and LLM-based models. It then\nemploys few-shot LLM prompting, dynamically enriched via semantic similarity\nretrieval, to identify event triggers and extract corresponding arguments. We\nevaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini)\nhighlighting significant performance gains with o1-mini, which achieves 63.3%\nF1 on trigger classification and 27.8% F1 on argument classification,\noutperforming prior benchmarks. Our results demonstrate that pipeline\napproaches, when empowered by retrieval-augmented LLMs, can rival or exceed\nend-to-end systems while maintaining interpretability and modularity. This work\nprovides practical insights into LLM-driven event extraction and opens pathways\nfor future hybrid models combining textual and acoustic features.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-30T07:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.21395v1","title":"On the magic positivity of Ehrhart polynomials of dilated polytopes","summary":"A polynomial $f(x)$ of degree $d$ is said to be magic positive if all the\ncoefficients are non-negative when $f(x)$ is expanded with respect to the basis\n$\\{x^i(x+1)^{d-i}\\}_{i=0}^d$. It is known that if $f(x)$ is magic positive,\nthen the polynomial appearing in the numerator of its generating function is\nreal-rooted. In this paper, we show that for a polynomial $f(x)$ with positive\nreal coefficients, there exists a positive real number $k$ such that $f(k'x)$\nis magic positive for any $k' \\geq k$. Furthermore, for any integer $d\\geq3$,\nwe show the existence of a $d$-dimensional polytope $P$ such that the Ehrhart\npolynomial of $kP$ is not magic positive for a given integer $k$. Finally, we\ninvestigate how much certain polytopes need to be dilated to make their Ehrhart\npolynomials magic positive.","main_category":"math.CO","categories":"math.CO","published":"2025-04-30T07:52:06Z"}
{"aid":"http://arxiv.org/abs/2504.21405v1","title":"Resonance in isochronous systems with decaying oscillatory and\n  stochastic perturbations","summary":"The combined influence of oscillatory excitations and multiplicative\nstochastic perturbations of white noise type on isochronous systems in the\nplane is investigated. It is assumed that the intensity of perturbations decays\nwith time and the excitation frequency satisfies a resonance condition. The\noccurrence and stochastic stability of solutions with an asymptotically\nconstant amplitude are discussed. By constructing an averaging transformation,\nwe derive a model truncated deterministic system that describes possible\nasymptotic regimes for perturbed solutions. The persistence of resonant\nsolutions in the phase locking and the phase drifting modes is justified by\nconstructing suitable Lyapunov functions for the complete stochastic system. In\nparticular, we show that decaying stochastic perturbations can shift the\nboundary of stability domain for resonant solutions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-30T08:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.21408v1","title":"The maximum mass and rotational kinetic energy of rapidly rotating\n  neutron stars","summary":"Rapid uniformly-rotating neutron stars are expected to be formed for instance\nin the collapse of some massive stars, the accretion of some compact object\nbinaries, and some double neutron star mergers. The huge amount of the\nrotational energy has been widely believed to be the source of some cosmic\ngamma-ray bursts and superluminous supernovae. Benefited from the tight\nconstraints on the equation of state of the neutron star matter set by the\nlatest multi-messenger data, the chiral effective field theory ($\\chi$EFT) and\nperturbative quantum chromodynamics (pQCD), here we present the maximum\ngravitational mass as well as the kinetic rotational energy for a neutron star\nat a given spin period. Our nonparametric EOS analysis reveals that the\ncritical Keplerian configurations ($\\Omega_{\\rm kep}^{\\rm\ncrit}=1.00\\pm0.07\\times 10^{4}~ {\\rm rad/s}$) can sustain maximum gravitational\nmasses of $M_{\\rm kep}^{\\rm crit}=2.76^{+0.11}_{-0.09} M_\\odot$ with\ncorresponding rotational energy reaching $E_{\\rm rot,kep}^{\\rm\ncrit}=2.38^{+0.25}_{-0.24}\\times 10^{53}$. However, the maximum rotational\nenergy that can be feasibly extracted from a neutron star is limited to\n$1.40^{+0.15}_{-0.13}\\times 10^{53}$ erg, which holds for a baryon mass of\n$2.68^{+0.10}_{-0.09}M_\\odot$. All these parameters, obtained via the\nnonparametric reconstruction of the equation of state, are at the $68.3\\%$\nconfidence level and the adoption of a quarkonic model yields rather similar\nresults. These findings are found to have already set some intriguing\nconstraints on the millisecond magnetar interpretation of some exciting data.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-30T08:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.21409v1","title":"Towards Intelligent Edge Sensing for ISCC Network: Joint Multi-Tier DNN\n  Partitioning and Beamforming Design","summary":"The combination of Integrated Sensing and Communication (ISAC) and Mobile\nEdge Computing (MEC) enables devices to simultaneously sense the environment\nand offload data to the base stations (BS) for intelligent processing, thereby\nreducing local computational burdens. However, transmitting raw sensing data\nfrom ISAC devices to the BS often incurs substantial fronthaul overhead and\nlatency. This paper investigates a three-tier collaborative inference framework\nenabled by Integrated Sensing, Communication, and Computing (ISCC), where cloud\nservers, MEC servers, and ISAC devices cooperatively execute different segments\nof a pre-trained deep neural network (DNN) for intelligent sensing. By\noffloading intermediate DNN features, the proposed framework can significantly\nreduce fronthaul transmission load. Furthermore, multiple-input multiple-output\n(MIMO) technology is employed to enhance both sensing quality and offloading\nefficiency. To minimize the overall sensing task inference latency across all\nISAC devices, we jointly optimize the DNN partitioning strategy, ISAC\nbeamforming, and computational resource allocation at the MEC servers and\ndevices, subject to sensing beampattern constraints. We also propose an\nefficient two-layer optimization algorithm. In the inner layer, we derive\nclosed-form solutions for computational resource allocation using the\nKarush-Kuhn-Tucker conditions. Moreover, we design the ISAC beamforming vectors\nvia an iterative method based on the majorization-minimization and weighted\nminimum mean square error techniques. In the outer layer, we develop a\ncross-entropy based probabilistic learning algorithm to determine an optimal\nDNN partitioning strategy. Simulation results demonstrate that the proposed\nframework substantially outperforms existing two-tier schemes in inference\nlatency.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-30T08:09:59Z"}
{"aid":"http://arxiv.org/abs/2504.21423v1","title":"Diff-Prompt: Diffusion-Driven Prompt Generator with Mask Supervision","summary":"Prompt learning has demonstrated promising results in fine-tuning pre-trained\nmultimodal models. However, the performance improvement is limited when applied\nto more complex and fine-grained tasks. The reason is that most existing\nmethods directly optimize the parameters involved in the prompt generation\nprocess through loss backpropagation, which constrains the richness and\nspecificity of the prompt representations. In this paper, we propose\nDiffusion-Driven Prompt Generator (Diff-Prompt), aiming to use the diffusion\nmodel to generate rich and fine-grained prompt information for complex\ndownstream tasks. Specifically, our approach consists of three stages. In the\nfirst stage, we train a Mask-VAE to compress the masks into latent space. In\nthe second stage, we leverage an improved Diffusion Transformer (DiT) to train\na prompt generator in the latent space, using the masks for supervision. In the\nthird stage, we align the denoising process of the prompt generator with the\npre-trained model in the semantic space, and use the generated prompts to\nfine-tune the model. We conduct experiments on a complex pixel-level downstream\ntask, referring expression comprehension, and compare our method with various\nparameter-efficient fine-tuning approaches. Diff-Prompt achieves a maximum\nimprovement of 8.87 in R@1 and 14.05 in R@5 compared to the foundation model\nand also outperforms other state-of-the-art methods across multiple metrics.\nThe experimental results validate the effectiveness of our approach and\nhighlight the potential of using generative models for prompt generation. Code\nis available at https://github.com/Kelvin-ywc/diff-prompt.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T08:28:38Z"}
{"aid":"http://arxiv.org/abs/2504.21470v1","title":"Gate-tunable polarity inversions and three-fold rotation symmetry of the\n  superconducting diode effect","summary":"The superconducting diode effect is an asymmetry in the critical current with\nrespect to the supercurrent polarity. One impetus driving recent interest in\nthe effect is its dependence on intrinsic or microscopic symmetry breaking\nmechanisms.\n  Here, we study the superconducting diode effect in gated planar Josephson\njunctions fabricated on a superconductor--semiconductor heterostructure under\nan in-plane magnetic field.\n  We observe two gate-driven inversions of the diode polarity in the vicinity\nof zero field, as well as a third-harmonic component in the dependence of the\ndiode efficiency on the in-plane field angle.\n  We analyze the Lifshitz invariant for an arbitrary spin--orbit coupling and\nshow that multiple polarity inversions are possible in the presence of both\nlinear and cubic Dresselhaus terms, where the Rashba parameter varies\nmonotonically with gate voltage.\n  Numerical calculations of the diode efficiency further reveal the presence of\nhigher harmonics in its field-angle dependence in the presence of spin--orbit\ncoupling.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-30T09:48:43Z"}
{"aid":"http://arxiv.org/abs/2504.21473v1","title":"Invariant Bridges Between Four Successive Points: A New Tool for Data\n  Coding","summary":"We introduce a simple yet powerful invariant relation connecting four\nsuccessive terms of a class of exponentially decaying alternating functions.\nSpecifically, for the sequence defined by f(n) = ((1/2)^n + (-1)^n) / n, we\nprove that the combination [(n-2)f(n-2) + (n-3)f(n-3)] / [n f(n) + (n-1)f(n-1)]\nis universally equal to 4 for all integers n >= 4. This invariant bridge across\nfour points opens new possibilities for predictive coding, data compression,\nand error detection. We demonstrate how the relation can be used to reconstruct\nmissing data, verify data integrity, and reduce redundancy in data streams with\nminimal computational overhead. The simplicity and universality of this\ninvariant make it a promising tool for a wide range of applications in\ninformation theory and coding systems.","main_category":"math.LO","categories":"math.LO,cs.IT,math.IT","published":"2025-04-30T09:52:25Z"}
{"aid":"http://arxiv.org/abs/2504.21484v1","title":"Chiral interactions between tropocollagen molecules determine the\n  collagen microfibril structure","summary":"Collagen is the most abundant structural protein in animals, forming\nhierarchically organised fibrils that provide mechanical support to tissues.\nDespite detailed structural studies, the physical principles that govern the\nformation of the characteristic axially-periodic collagen microfibril remain\npoorly understood. Here, we present a theoretical framework that links the\namino acid sequence of tropocollagen to its supramolecular organisation. By\ncombining statistical modeling of residue geometry with sequence-informed\ninteraction potentials, we show that the chiral arrangement of outward-facing\nresidues induces directional intermolecular interactions that drive molecular\nsupercoiling. These interactions favour the formation of right-handed,\npentameric microfibrils with a staggered axial periodicity of approximately 67\nnm. Our simulations reveal that this structure emerges across a wide range of\nmammalian collagen sequences as a global energy minimum robust to biochemical\nnoise. These findings provide a mechanistic explanation for collagen's\nsupramolecular chirality and offer design principles for engineering synthetic\ncollagen-mimetic materials.","main_category":"cond-mat.soft","categories":"cond-mat.soft,q-bio.BM","published":"2025-04-30T10:08:16Z"}
{"aid":"http://arxiv.org/abs/2504.21586v1","title":"One Net to Rule Them All: Domain Randomization in Quadcopter Racing\n  Across Different Platforms","summary":"In high-speed quadcopter racing, finding a single controller that works well\nacross different platforms remains challenging. This work presents the first\nneural network controller for drone racing that generalizes across physically\ndistinct quadcopters. We demonstrate that a single network, trained with domain\nrandomization, can robustly control various types of quadcopters. The network\nrelies solely on the current state to directly compute motor commands. The\neffectiveness of this generalized controller is validated through real-world\ntests on two substantially different crafts (3-inch and 5-inch race\nquadcopters). We further compare the performance of this generalized controller\nwith controllers specifically trained for the 3-inch and 5-inch drone, using\ntheir identified model parameters with varying levels of domain randomization\n(0%, 10%, 20%, 30%). While the generalized controller shows slightly slower\nspeeds compared to the fine-tuned models, it excels in adaptability across\ndifferent platforms. Our results show that no randomization fails sim-to-real\ntransfer while increasing randomization improves robustness but reduces speed.\nDespite this trade-off, our findings highlight the potential of domain\nrandomization for generalizing controllers, paving the way for universal AI\ncontrollers that can adapt to any platform.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.SY,eess.SY","published":"2025-04-30T12:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.21593v1","title":"Dark-technicolour at colliders","summary":"By employing the extended most attractive channel hypothesis, we show that\nQCD-like gauge dynamics is possible in the dark-technicolour paradigm. The\ndark-technicolour paradigm can produce the mass of the Higgs boson, and at the\nsame time, the $S$-parameter is also satisfied. Moreover, the dark-technicolour\nparadigm can provide a solution of the flavour problem by accommodating the\nstandard HVM or the Froggatt-Nielsen mechanism within its framework. We present\nthe inclusive collider signatures, such as $t\\bar{t}$ and $\\gamma \\gamma$, of\nthe lowest lying scalars and pseudoscalars of the dark-technicolour paradigm,\nfor the scenarios, when the standard HVM or the Froggatt-Nielsen mechanism are\nimplemented within its framework. The collider signatures are investigated at\nthe high-luminosity Large Hadron Collider, the high-energy Large Hadron\nCollider, and a 100 TeV future hadron collider. Several signatures are within\nthe reach of the high-luminosity Large Hadron Collider. Additionally, one of\nthe dark-Higgs of the model can address $95.4$ GeV excess reported by the ATLAS\nand CMS experiments. Furthermore, one of the dark-Higgs can act like a new\nclass of chirality-dependent dark-matter particles.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-30T12:51:17Z"}
{"aid":"http://arxiv.org/abs/2504.21594v1","title":"Switching Transients in Constrained Transformer-Line/Cable\n  Configurations","summary":"This paper investigates the transient phenomena that occur in two special\ncases in the Netherlands: (A) during the energization of a power transformer\nvia a cable feeder and (B) the energization of a power transformer together\nwith an overhead line (OHL). In Case A a 7 km long 150 kV cable and a 150/50 kV\ntransformer are connected and energized at the same time. In Case B a 150/50 kV\ntransformer and a short 50 kV OHL are connected and energized simultaneously.\nThe reason behind this kind of situations is related to space restrictions and\ncost efficiency.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-30T12:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.21598v1","title":"Cascade Detector Analysis and Application to Biomedical Microscopy","summary":"As both computer vision models and biomedical datasets grow in size, there is\nan increasing need for efficient inference algorithms. We utilize cascade\ndetectors to efficiently identify sparse objects in multiresolution images.\nGiven an object's prevalence and a set of detectors at different resolutions\nwith known accuracies, we derive the accuracy, and expected number of\nclassifier calls by a cascade detector. These results generalize across number\nof dimensions and number of cascade levels. Finally, we compare one- and\ntwo-level detectors in fluorescent cell detection, organelle segmentation, and\ntissue segmentation across various microscopy modalities. We show that the\nmulti-level detector achieves comparable performance in 30-75% less time. Our\nwork is compatible with a variety of computer vision models and data domains.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T12:58:30Z"}
{"aid":"http://arxiv.org/abs/2504.21620v1","title":"Deterministic Distributed DFS via Cycle Separators in Planar Graphs","summary":"One of the most basic techniques in algorithm design consists of breaking a\nproblem into subproblems and then proceeding recursively. In the case of graph\nalgorithms, one way to implement this approach is through separator sets. Given\na graph $G=(V,E)$, a subset of nodes $S \\subseteq V$ is called a separator set\nof $G$ if the size of each connected component of $G-S$ is at most $2/3 \\cdot\n|V|$. The most useful separator sets are those that satisfy certain\nrestrictions of cardinality or structure. For over 40 years, various efficient\nalgorithms have been developed for computing separators of different kinds,\nparticularly in planar graphs. Separator sets, combined with a divide and\nconquer approach, have been fundamental in the design of efficient algorithms\nin various settings.\n  In this work, we present the first deterministic algorithm in the distributed\nCONGEST model that recursively computes a cycle separator over planar graphs in\n$\\tilde{O}(D)$ rounds. This result, as in the centralized setting, has\nsignificant implications in the area of distributed planar algorithms. In fact,\nfrom this result, we can construct a deterministic algorithm that computes a\nDFS tree in ${\\tilde{O}}(D)$ rounds. This matches both the best-known\nrandomized algorithm of Ghaffari and Parter (DISC, 2017) and, up to\npolylogarithmic factors, the trivial lower bound of $\\Omega(D)$ rounds.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-30T13:21:12Z"}
{"aid":"http://arxiv.org/abs/2504.21631v1","title":"Skin Effect Induced Anomalous Dynamics from Charge-Fluctuating Initial\n  States","summary":"Non-equilibrium dynamics in non-Hermitian systems has attracted significant\ninterest, particularly due to the skin effect and its associated anomalous\nphenomena. Previous studies have primarily focused on initial states with a\ndefinite particle number. Here, we present a systematic study of non-reciprocal\nquench dynamics in the pairing states with indefinite particle number. Our\nstudy uncovers a range of novel behaviors. Firstly, we demonstrate a universal\ntendency towards half-filling of particle density at late times. At early times\nfor certain initial states, we observe a chiral wavefront in both particle\nnumber distribution and charge inflow, associated with a sharp decrease in\nparticle number. Furthermore, we find that non-Hermiticity could enhance the\ngrowth of entanglement in the initial stages of evolution. In the intermediate\ntime regime, the characteristic skin effect leads to particle accumulation on\none side, leading to a pronounced reduction in entanglement entropy. Moreover,\nour results reveal the presence of the quantum Mpemba effect during the\nrestoration of U(1) symmetry. Our findings open new avenues for exploring\nexotic dynamic phenomena in quantum many-body systems arising from the\ninterplay of symmetry breaking and non-Hermiticity.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.quant-gas,cond-mat.str-el","published":"2025-04-30T13:33:10Z"}
{"aid":"http://arxiv.org/abs/2504.21638v1","title":"A note on the quantum Wielandt inequality","summary":"In this note, we show how to extend operator algebraic methods introduced by\nRahaman to prove that the index of primitivity of any primitive Schwarz map is\nat most $2(D-1)^2$, where $D$ is the dimension of the underlying matrix\nalgebra. This inequality was first proved by Rahaman for Schwarz maps which\nwere both unital and trace preserving. We show here that the assumption of\nunitality is automatic (up to normalization) for primitive Schwarz maps, but,\nin general, not all primitive unital Schwarz maps are trace preserving.\nTherefore, the precise purpose of this note is to showcase how to apply the\nproof of Rahaman to arbitrary primitive Schwarz maps. As a corollary of this\ntheorem, we show that the index of primitivity of any primitive 2-positive map\nis at most $2(D-1)^2$, so in particular this bound holds for arbitrary\nprimitive completely positive maps. We briefly discuss of how this relates to a\nconjecture of Perez-Garcia, Verstraete, Wolf and Cirac concerning properties of\nparent Hamiltonians of matrix product states.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT,math.OA","published":"2025-04-30T13:40:53Z"}
{"aid":"http://arxiv.org/abs/2504.21662v1","title":"On Advancements of the Forward-Forward Algorithm","summary":"The Forward-Forward algorithm has evolved in machine learning research,\ntackling more complex tasks that mimic real-life applications. In the last\nyears, it has been improved by several techniques to perform better than its\noriginal version, handling a challenging dataset like CIFAR10 without losing\nits flexibility and low memory usage. We have shown in our results that\nimprovements are achieved through a combination of convolutional channel\ngrouping, learning rate schedules, and independent block structures during\ntraining that lead to a 20\\% decrease in test error percentage. Additionally,\nto approach further implementations on low-capacity hardware projects we have\npresented a series of lighter models that achieve low test error percentages\nwithin (21$\\pm$6)\\% and number of trainable parameters between 164,706 and\n754,386. This serving also as a basis for our future study on complete\nverification and validation of these kinds of neural networks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-30T14:03:52Z"}
{"aid":"http://arxiv.org/abs/2504.21671v1","title":"Broadband study of the SMC pulsar RX J0032.9-7348 during its X-ray\n  brightening in 2024","summary":"We present the results of the broadband timing and spectral analysis of the\npoorly understood SMC pulsar RX J0032.9-7348 (= SXP 7.02) using NuSTAR and\nNICER observations during its X-ray brightening in 2024. Our timing analysis\nrevealed a pulsation period of approximately 7.02 s in the X-ray light curve.\nThe pulse profile obtained in the broad energy range is double-peaked and\nasymmetric in nature and shows moderate variation with the energy. An absorbed\npower-law model describes the 0.5-8 keV NICER spectra well. The 3-50 keV NuSTAR\nspectrum is best described with an absorbed power-law modified with a\nhigh-energy cutoff model. We find no evidence of iron or cyclotron line\nfeatures in the energy spectrum. During our observation period, the 0.5-50 keV\nluminosity varies in the range of $\\sim 8\\times10^{36} - 4\\times10^{37}$ erg\ns$^{-1}$. We also discuss the dependence of spectral parameters on the\nrotational phase of the pulsar through phase-resolved spectroscopy.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-30T14:12:36Z"}
{"aid":"http://arxiv.org/abs/2504.21682v1","title":"Visual Text Processing: A Comprehensive Review and Unified Evaluation","summary":"Visual text is a crucial component in both document and scene images,\nconveying rich semantic information and attracting significant attention in the\ncomputer vision community. Beyond traditional tasks such as text detection and\nrecognition, visual text processing has witnessed rapid advancements driven by\nthe emergence of foundation models, including text image reconstruction and\ntext image manipulation. Despite significant progress, challenges remain due to\nthe unique properties that differentiate text from general objects. Effectively\ncapturing and leveraging these distinct textual characteristics is essential\nfor developing robust visual text processing models. In this survey, we present\na comprehensive, multi-perspective analysis of recent advancements in visual\ntext processing, focusing on two key questions: (1) What textual features are\nmost suitable for different visual text processing tasks? (2) How can these\ndistinctive text features be effectively incorporated into processing\nframeworks? Furthermore, we introduce VTPBench, a new benchmark that\nencompasses a broad range of visual text processing datasets. Leveraging the\nadvanced visual quality assessment capabilities of multimodal large language\nmodels (MLLMs), we propose VTPScore, a novel evaluation metric designed to\nensure fair and reliable evaluation. Our empirical study with more than 20\nspecific models reveals substantial room for improvement in the current\ntechniques. Our aim is to establish this work as a fundamental resource that\nfosters future exploration and innovation in the dynamic field of visual text\nprocessing. The relevant repository is available at\nhttps://github.com/shuyansy/Visual-Text-Processing-survey.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T14:19:29Z"}
{"aid":"http://arxiv.org/abs/2504.21706v1","title":"Vision Transformers in Precision Agriculture: A Comprehensive Survey","summary":"Detecting plant diseases is a crucial aspect of modern agriculture - it plays\na key role in maintaining crop health and increasing overall yield. Traditional\napproaches, though still valuable, often rely on manual inspection or\nconventional machine learning techniques, both of which face limitations in\nscalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as\na promising alternative, offering benefits such as improved handling of\nlong-range dependencies and better scalability for visual tasks. This survey\nexplores the application of ViTs in precision agriculture, covering tasks from\nclassification to detection and segmentation. We begin by introducing the\nfoundational architecture of ViTs and discuss their transition from Natural\nLanguage Processing (NLP) to computer vision. The discussion includes the\nconcept of inductive bias in traditional models like Convolutional Neural\nNetworks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive\nreview of recent literature, focusing on key methodologies, datasets, and\nperformance metrics. The survey also includes a comparative analysis of CNNs\nand ViTs, with a look at hybrid models and performance enhancements. Technical\nchallenges - such as data requirements, computational demands, and model\ninterpretability - are addressed alongside potential solutions. Finally, we\noutline potential research directions and technological advancements that could\nfurther support the integration of ViTs in real-world agricultural settings.\nOur goal with this study is to offer practitioners and researchers a deeper\nunderstanding of how ViTs are poised to transform smart and precision\nagriculture.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-30T14:50:02Z"}
{"aid":"http://arxiv.org/abs/2504.21707v1","title":"Recursive KL Divergence Optimization: A Dynamic Framework for\n  Representation Learning","summary":"We propose a generalization of modern representation learning objectives by\nreframing them as recursive divergence alignment processes over localized\nconditional distributions While recent frameworks like Information Contrastive\nLearning I-Con unify multiple learning paradigms through KL divergence between\nfixed neighborhood conditionals we argue this view underplays a crucial\nrecursive structure inherent in the learning process. We introduce Recursive KL\nDivergence Optimization RKDO a dynamic formalism where representation learning\nis framed as the evolution of KL divergences across data neighborhoods. This\nformulation captures contrastive clustering and dimensionality reduction\nmethods as static slices while offering a new path to model stability and local\nadaptation. Our experiments demonstrate that RKDO offers dual efficiency\nadvantages approximately 30 percent lower loss values compared to static\napproaches across three different datasets and 60 to 80 percent reduction in\ncomputational resources needed to achieve comparable results. This suggests\nthat RKDOs recursive updating mechanism provides a fundamentally more efficient\noptimization landscape for representation learning with significant\nimplications for resource constrained applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IT,math.IT","published":"2025-04-30T14:51:27Z"}
{"aid":"http://arxiv.org/abs/2504.21713v1","title":"N-body choreographies on a p-limacon curve","summary":"We consider an $N$--body problem under a harmonic potential of the form\n$\\frac{1}{2}\\sum \\kappa_{jl} |q_j-q_l|^2$. A $p$-lima\\c{c}on curve is a planar\ncurve parametrized by $t$ given by $a(\\cos t,\\sin t)+b(\\cos pt, \\sin pt)$,\nwhere $a,b\\in \\mathbb{R}$, $p \\in \\mathbb{Z}$, and $t \\in [0,2\\pi]$. We study\n$N$-body choreographic motions constrained to a $p$-lima\\c{c}on curve and\nestablish necessary and sufficient conditions for their existence.\nSpecifically, we prove that choreographic motions exist if and only if $p/N, (p\n\\pm 1)/N \\notin \\mathbb{Z}$. Under an additional symmetry assumption on the\nforce coefficients, we further refine these conditions. We also analyze the\noccurrence of collisions, showing that for given $p$ and $N$, at most $2(N-1)$\nchoices of $a/b$ lead to collisions. Furthermore, we find additional conserved\nquantities.","main_category":"math.DS","categories":"math.DS","published":"2025-04-30T14:55:21Z"}
{"aid":"http://arxiv.org/abs/2504.21724v1","title":"Higher derivative corrections to Kerr-AdS black hole thermodynamics","summary":"Instead of the much more involved covariant counterterm method, we apply the\nwell justified background subtraction method to calculate the first order\ncorrections to Kerr-AdS black hole thermodynamics induced by the higher\nderivative terms up to the cubic of Riemann tensor, where the computation is\nfurther simplified by the decomposition trick for the bulk action. The validity\nof our results is further substantiated by examining the corrections induced by\nthe Gauss-Bonnet term. Moreover, by comparing our results with those obtained\nvia the ADM and Wald formulas in the Lorentz signature, we can extract some\ngeneric information about the first order corrected black hole solutions\ninduced by each higher derivative term.","main_category":"hep-th","categories":"hep-th","published":"2025-04-30T15:10:26Z"}
{"aid":"http://arxiv.org/abs/2504.21728v1","title":"Asymptotic Analysis of Weighted Fair Division","summary":"Several resource allocation settings involve agents with unequal entitlements\nrepresented by weights. We analyze weighted fair division from an asymptotic\nperspective: if $m$ items are divided among $n$ agents whose utilities are\nindependently sampled from a probability distribution, when is it likely that a\nfair allocation exist? We show that if the ratio between the weights is\nbounded, a weighted envy-free allocation exists with high probability provided\nthat $m = \\Omega(n\\log n/\\log\\log n)$, generalizing a prior unweighted result.\nFor weighted proportionality, we establish a sharp threshold of $m = n/(1-\\mu)$\nfor the transition from non-existence to existence, where $\\mu\\in (0,1)$\ndenotes the mean of the distribution. In addition, we prove that for two\nagents, a weighted envy-free (and weighted proportional) allocation is likely\nto exist if $m = \\omega(\\sqrt{r})$, where $r$ denotes the ratio between the two\nweights.","main_category":"cs.GT","categories":"cs.GT,cs.DM,math.PR","published":"2025-04-30T15:20:10Z"}
{"aid":"http://arxiv.org/abs/2504.21776v1","title":"WebThinker: Empowering Large Reasoning Models with Deep Research\n  Capability","summary":"Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate\nimpressive long-horizon reasoning capabilities. However, their reliance on\nstatic internal knowledge limits their performance on complex,\nknowledge-intensive tasks and hinders their ability to produce comprehensive\nresearch reports requiring synthesis of diverse web information. To address\nthis, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs\nto autonomously search the web, navigate web pages, and draft research reports\nduring the reasoning process. WebThinker integrates a \\textbf{Deep Web\nExplorer} module, enabling LRMs to dynamically search, navigate, and extract\ninformation from the web when encountering knowledge gaps. It also employs an\n\\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to\nseamlessly interleave reasoning, information gathering, and report writing in\nreal time. To further enhance research tool utilization, we introduce an\n\\textbf{RL-based training strategy} via iterative online Direct Preference\nOptimization (DPO). Extensive experiments on complex reasoning benchmarks\n(GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive)\ndemonstrate that WebThinker significantly outperforms existing methods and\nstrong proprietary systems. Our approach enhances LRM reliability and\napplicability in complex scenarios, paving the way for more capable and\nversatile deep research systems. The code is available at\nhttps://github.com/RUC-NLPIR/WebThinker.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-04-30T16:25:25Z"}
{"aid":"http://arxiv.org/abs/2504.21846v1","title":"Active Light Modulation to Counter Manipulation of Speech Visual Content","summary":"High-profile speech videos are prime targets for falsification, owing to\ntheir accessibility and influence. This work proposes Spotlight, a low-overhead\nand unobtrusive system for protecting live speech videos from visual\nfalsification of speaker identity and lip and facial motion. Unlike predominant\nfalsification detection methods operating in the digital domain, Spotlight\ncreates dynamic physical signatures at the event site and embeds them into all\nvideo recordings via imperceptible modulated light. These physical signatures\nencode semantically-meaningful features unique to the speech event, including\nthe speaker's identity and facial motion, and are cryptographically-secured to\nprevent spoofing. The signatures can be extracted from any video downstream and\nvalidated against the portrayed speech content to check its integrity. Key\nelements of Spotlight include (1) a framework for generating extremely compact\n(i.e., 150-bit), pose-invariant speech video features, based on\nlocality-sensitive hashing; and (2) an optical modulation scheme that embeds\n>200 bps into video while remaining imperceptible both in video and live.\nPrototype experiments on extensive video datasets show Spotlight achieves AUCs\n$\\geq$ 0.99 and an overall true positive rate of 100% in detecting falsified\nvideos. Further, Spotlight is highly robust across recording conditions, video\npost-processing techniques, and white-box adversarial attacks on its video\nfeature extraction methodologies.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-30T17:55:24Z"}
{"aid":"http://arxiv.org/abs/2505.00254v1","title":"Empowering Agentic Video Analytics Systems with Video Language Models","summary":"AI-driven video analytics has become increasingly pivotal across diverse\ndomains. However, existing systems are often constrained to specific,\npredefined tasks, limiting their adaptability in open-ended analytical\nscenarios. The recent emergence of Video-Language Models (VLMs) as\ntransformative technologies offers significant potential for enabling\nopen-ended video understanding, reasoning, and analytics. Nevertheless, their\nlimited context windows present challenges when processing ultra-long video\ncontent, which is prevalent in real-world applications. To address this, we\nintroduce AVA, a VLM-powered system designed for open-ended, advanced video\nanalytics. AVA incorporates two key innovations: (1) the near real-time\nconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long or\ncontinuous video streams, and (2) an agentic retrieval-generation mechanism\nthat leverages EKGs to handle complex and diverse queries. Comprehensive\nevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that\nAVA achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,\nrespectively, significantly surpassing existing VLM and video\nRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video\nanalytics in ultra-long and open-world video scenarios, we introduce a new\nbenchmark, AVA-100. This benchmark comprises 8 videos, each exceeding 10 hours\nin duration, along with 120 manually annotated, diverse, and complex\nquestion-answer pairs. On AVA-100, AVA achieves top-tier performance with an\naccuracy of 75.8%.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-01T02:40:23Z"}
{"aid":"http://arxiv.org/abs/2505.00264v1","title":"Integrating VR tours in online language learning:A design-based research\n  study","summary":"This paper presents an investigation into the integration of virtual reality\n(VR) tours in online English lessons tailored for adult learners. The study\nutilised a design-based research approach to evaluate the effectiveness of VR\ntours in this context. It specifically examined the responses of adult learners\nto this instructional strategy by collecting data through surveys, observation\nnotes and interviews with four learners in Japan and five learners in France,\nmost of whom completed 10 lessons over 4 months. The research findings\nhighlight the effectiveness of VR tours in enhancing learner motivation.\nAdditionally, they demonstrate that perceived learning outcomes are influenced\nnot only by the immersive experience of spatial presence but also by the\nnovelty of technological and scenery-related aspects within the VR environment,\nas well as factors related to lesson design and individual learner\ncharacteristics.","main_category":"cs.CY","categories":"cs.CY,cs.ET","published":"2025-05-01T03:08:52Z"}
{"aid":"http://arxiv.org/abs/2505.00267v1","title":"Local classical solutions of a kinetic equation for three waves\n  interactions in presence of a Dirac measure at the origin","summary":"The existence of local, classical solutions is proved, for a system of two\ncoupled equations that describe, in the framework of the wave turbulence\ntheory, the fluctuations around an equilibrium, of a system of nonlinear waves\nsatisfying the 3-d cubic Schr\\\"odinger equation, weakly interacting in presence\nof a condensate. The function that describes the density of waves behaves like\na singular Rayleigh Jeans equilibria near the origin, and induces a strictly\nincreasing behavior in time of the function describing the condensate's\ndensity.","main_category":"math.AP","categories":"math.AP","published":"2025-05-01T03:25:12Z"}
{"aid":"http://arxiv.org/abs/2505.00268v1","title":"Consistency in Language Models: Current Landscape, Challenges, and\n  Future Directions","summary":"The hallmark of effective language use lies in consistency -- expressing\nsimilar meanings in similar contexts and avoiding contradictions. While human\ncommunication naturally demonstrates this principle, state-of-the-art language\nmodels struggle to maintain reliable consistency across different scenarios.\nThis paper examines the landscape of consistency research in AI language\nsystems, exploring both formal consistency (including logical rule adherence)\nand informal consistency (such as moral and factual coherence). We analyze\ncurrent approaches to measure aspects of consistency, identify critical\nresearch gaps in standardization of definitions, multilingual assessment, and\nmethods to improve consistency. Our findings point to an urgent need for robust\nbenchmarks to measure and interdisciplinary approaches to ensure consistency in\nthe application of language models on domain-specific tasks while preserving\nthe utility and adaptability.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T03:25:25Z"}
{"aid":"http://arxiv.org/abs/2505.00286v1","title":"A polytopal discrete de Rham scheme for the exterior calculus Einstein's\n  equations","summary":"In this work, based on the $3+1$ decomposition in [23, 32], we present a\nfully exterior calculus breakdown of spacetime and Einstein's equations. Links\nto the orthonormal frame approach [37] are drawn to help understand the\nvariables in this context. Two formulations are derived, discretised and tested\nusing the exterior calculus discrete de Rham complex [12], and some discrete\nquantities are shown to be conserved in one of the cases.","main_category":"gr-qc","categories":"gr-qc,cs.NA,math.NA","published":"2025-05-01T04:18:49Z"}
{"aid":"http://arxiv.org/abs/2505.00303v1","title":"Leveraging Surplus Electricity: Profitability of Bitcoin Mining as a\n  National Strategy in South Korea","summary":"This study examines the feasibility and profitability of utilizing surplus\nelectricity for Bitcoin mining. Surplus electricity refers to the remaining\nelectricity after net metering, which can be repurposed for Bitcoin mining to\nimprove Korea Electric Power Corporation's (KEPCO) energy resource efficiency\nand alleviate its debt challenges. Net metering (or net energy metering) is an\nelectricity billing mechanism that allows consumers who generate some or all of\ntheir own electricity to use that electricity when they want, rather than when\nit is produced. Using the latest Bitcoin miner, the Antminer S21 XP Hyd, the\nstudy evaluates daily Bitcoin mining when operating at 30,565 and 45,439 units,\nincorporating Bitcoin network hash rates to assess profitability. To examine\nprofitability, the Random Forest Regressor and Long Short-Term Memory models\nwere used to predict the Bitcoin price. The analysis shows that the use of\nexcess electricity for Bitcoin mining not only generates economic revenue, but\nalso minimizes energy loss, reduces debt, and resolves unsettled payment issues\nfor KEPCO. This study empirically investigates and analyzes the integration of\nelectricity surplus in South Korea with bitcoin mining for the first time. The\nfindings highlight the potential to strengthen the financial stability of KEPCO\nand demonstrate the feasibility of Bitcoin mining. In addition, this research\nserves as a foundational resource for future advancements in the Bitcoin mining\nindustry and the efficient use of energy resources.","main_category":"stat.AP","categories":"stat.AP,stat.ML","published":"2025-05-01T04:52:33Z"}
{"aid":"http://arxiv.org/abs/2505.00324v1","title":"Interactions of the scalaron dark matter in $f (R)$ gravity","summary":"In $f(R)$ gravity, the scalaron$\\unicode{x2014}$a scalar degree of freedom\narising from modification of General Relativity$\\unicode{x2014}$could account\nfor all dark matter if its mass lies in the meV$\\unicode{x2013}$MeV range. In\nthis work, we revisit the scalaron's interactions with Standard Model\nparticles, assuming their minimal coupling to gravity. In particular, we refine\nthe scalaron decay rate into photons. Assuming the scalaron constitutes all of\ndark matter, we calculate the average cosmological background radiation\nproduced by these decays. We also estimate the contribution of primordial\nthermal scalarons to the present dark matter density and find it to be\nnegligible. This supports the original scenario in which the scalaron dark\nmatter behaves as a coherently oscillating field.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-05-01T05:48:11Z"}
{"aid":"http://arxiv.org/abs/2505.00345v1","title":"Denoising weak lensing mass maps with diffusion model: systematic\n  comparison with generative adversarial network","summary":"(abridged) Weak gravitational lensing (WL) is the unique and powerful probe\ninto the large-scale structures of the Universe. Removing the shape noise from\nthe observed WL field, i.e., denoising, enhances the potential of WL by\naccessing information at small scales where the shape noise dominates without\ndenoising. We utilise two machine learning (ML) models for denosing: generative\nadversarial network (GAN) and diffusion model (DM). We evaluate the performance\nof denosing with GAN and DM utilising the large suite of mock WL observations,\nwhich serve as the training and test data sets. We apply denoising to 1,000\nmaps with GAN and DM models trained with 39,000 mock observations. Both models\ncan fairly well reproduce the true convergence map on large scales. Then, we\nmeasure cosmological statistics: power spectrum, bispectrum, one-point\nprobability distribution function, peak and minima counts, and scattering\ntransform coefficients. We find that DM outperforms GAN in almost all\nstatistics and recovers the correct statistics down to small scales within\nroughly $0.3 \\sigma$ level at the scales accessible from current and future WL\nsurveys. We also conduct the stress tests on the trained model; denoising the\nmaps with different characteristics, e.g., different source redshifts, from the\ndata used in training. The performance degrades at small scales, but the\nstatistics can still be recovered at large scales. Though the training of DM is\nmore computationally demanding compared with GAN, there are several advantages:\nnumerically stable training, higher performance in the reconstruction of\ncosmological statistics, and sampling multiple realisations once the model is\ntrained. It has been known that DM can generate higher-quality images in\nreal-world problems than GAN, the superiority has been confirmed as well in the\nWL denoising problem.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-01T06:45:50Z"}
{"aid":"http://arxiv.org/abs/2505.00358v1","title":"R&B: Domain Regrouping and Data Mixture Balancing for Efficient\n  Foundation Model Training","summary":"Data mixing strategies have successfully reduced the costs involved in\ntraining language models. While promising, such methods suffer from two flaws.\nFirst, they rely on predetermined data domains (e.g., data sources, task\ntypes), which may fail to capture critical semantic nuances, leaving\nperformance on the table. Second, these methods scale with the number of\ndomains in a computationally prohibitive way. We address these challenges via\nR&B, a framework that re-partitions training data based on semantic similarity\n(Regroup) to create finer-grained domains, and efficiently optimizes the data\ncomposition (Balance) by leveraging a Gram matrix induced by domain gradients\nobtained throughout training. Unlike prior works, it removes the need for\nadditional compute to obtain evaluation information such as losses or\ngradients. We analyze this technique under standard regularity conditions and\nprovide theoretical insights that justify R&B's effectiveness compared to\nnon-adaptive mixing approaches. Empirically, we demonstrate the effectiveness\nof R&B on five diverse datasets ranging from natural language to reasoning and\nmultimodal tasks. With as little as 0.01% additional compute overhead, R&B\nmatches or exceeds the performance of state-of-the-art data mixing strategies.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-05-01T07:08:19Z"}
{"aid":"http://arxiv.org/abs/2505.00364v1","title":"From GNNs to Trees: Multi-Granular Interpretability for Graph Neural\n  Networks","summary":"Interpretable Graph Neural Networks (GNNs) aim to reveal the underlying\nreasoning behind model predictions, attributing their decisions to specific\nsubgraphs that are informative. However, existing subgraph-based interpretable\nmethods suffer from an overemphasis on local structure, potentially overlooking\nlong-range dependencies within the entire graphs. Although recent efforts that\nrely on graph coarsening have proven beneficial for global interpretability,\nthey inevitably reduce the graphs to a fixed granularity. Such an inflexible\nway can only capture graph connectivity at a specific level, whereas real-world\ngraph tasks often exhibit relationships at varying granularities (e.g.,\nrelevant interactions in proteins span from functional groups, to amino acids,\nand up to protein domains). In this paper, we introduce a novel Tree-like\nInterpretable Framework (TIF) for graph classification, where plain GNNs are\ntransformed into hierarchical trees, with each level featuring coarsened graphs\nof different granularity as tree nodes. Specifically, TIF iteratively adopts a\ngraph coarsening module to compress original graphs (i.e., root nodes of trees)\ninto increasingly coarser ones (i.e., child nodes of trees), while preserving\ndiversity among tree nodes within different branches through a dedicated graph\nperturbation module. Finally, we propose an adaptive routing module to identify\nthe most informative root-to-leaf paths, providing not only the final\nprediction but also the multi-granular interpretability for the decision-making\nprocess. Extensive experiments on the graph classification benchmarks with both\nsynthetic and real-world datasets demonstrate the superiority of TIF in\ninterpretability, while also delivering a competitive prediction performance\nakin to the state-of-the-art counterparts.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T07:22:51Z"}
{"aid":"http://arxiv.org/abs/2505.00376v1","title":"Accurate Modeling of Interfacial Thermal Transport in van der Waals\n  Heterostructures via Hybrid Machine Learning and Registry-Dependent\n  Potentials","summary":"Two-dimensional transition metal dichalcogenides (TMDs) exhibit remarkable\nthermal anisotropy due to their strong intralayer covalent bonding and weak\ninterlayer van der Waals (vdW) interactions. However, accurately modeling their\nthermal transport properties remains a significant challenge, primarily due to\nthe computational limitations of density functional theory (DFT) and the\ninaccuracies of classical force fields in non-equilibrium regimes. To address\nthis, we use a recently developed hybrid computational framework that combines\nmachine learning potential (MLP) for intralayer interactions with\nregistry-dependent interlayer potential (ILP) for anisotropic vdW interlayer\ninteraction, achieving near quantum mechanical accuracy. This approach\ndemonstrates exceptional agreement with DFT calculations and experimental data\nfor TMD systems, accurately predicting key properties such as lattice\nconstants, bulk modulus, moir\\'e reconstruction, phonon spectra, and thermal\nconductivities. The scalability of this method enables accurate simulations of\nTMD heterostructures with large-scale moir\\'e superlattices, making it a\ntransformative tool for the design of TMD-based thermal metamaterials and\ndevices, bridging the gap between accuracy and computational efficiency.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-05-01T08:02:12Z"}
{"aid":"http://arxiv.org/abs/2505.00433v1","title":"Success probability in Shor's Algorithm","summary":"This paper aims to determine the exact success probability at each step of\nShor's algorithm. Although the literature usually provides a lower bound on\nthis probability, we present an improved bound. The derived formulas enable the\nidentification of all failure cases in Shor's algorithm, which correspond to a\nsuccess probability of zero. A simulation routine is provided to evaluate the\ntheoretical success probability for a given integer when its prime\nfactorization is known with potential applications in quantum resource\nestimation and algorithm benchmarking.","main_category":"quant-ph","categories":"quant-ph,cs.DS","published":"2025-05-01T10:08:58Z"}
{"aid":"http://arxiv.org/abs/2505.00471v1","title":"A General Model for Linearly Polarized Optical Vector Beams","summary":"We propose an approach for deriving a broad class of propagation models for\ninhomogeneously, linearly polarized ``vector'' beams. Our formulation leverages\na complex scalar potential along with an appropriately constructed Lagrangian\nenergy density. Importantly, we show that polarization inhomogeneities can be\nincluded by simple addition of a spatially dependent polarization angle to the\ncomplex potential phase. Thus, phase and polarization are seen to be equivalent\nfrom an energy perspective. As part of our development, we also show how the\ncomplex scalar potential arises naturally when considering polarization angle\nas a field symmetry during construction of the Lagrangian. We further show that\nthe definition of linear momentum density in terms of the complex potential\nholds a distinct advantage over the conventional definition for inhomogeneously\npolarized beams.","main_category":"physics.optics","categories":"physics.optics,math-ph,math.MP","published":"2025-05-01T11:50:05Z"}
{"aid":"http://arxiv.org/abs/2505.00481v1","title":"Stabilization by Controllers Having Integer Coefficients","summary":"The system property of ``having integer coefficients,'' that is, a transfer\nfunction has an integer monic polynomial as its denominator, is significant in\nthe field of encrypted control as it is required for a dynamic controller to be\nrealized over encrypted data. This paper shows that there always exists a\ncontroller with integer coefficients stabilizing a given discrete-time linear\ntime-invariant plant. A constructive algorithm to obtain such a controller is\nprovided, along with numerical examples. Furthermore, the proposed method is\napplied to converting a pre-designed controller to have integer coefficients,\nwhile the original performance is preserved in the sense that the transfer\nfunction of the closed-loop system remains unchanged.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-01T12:21:00Z"}
{"aid":"http://arxiv.org/abs/2505.00513v1","title":"Group class operations and homological conditions","summary":"Kropholler's operation ${\\scriptstyle{{\\bf LH}}}$ and Talelli's operation\n$\\Phi$ can be often used to formally enlarge the class of available examples of\ngroups that satisfy certain homological conditions. In this paper, we employ\nthis enlargement technique regarding two specific homological conditions. We\nthereby demonstrate the abundance of groups that (a) have virtually Gorenstein\ngroup algebras, as defined by Beligiannis and Reiten, and (b) satisfy Moore's\nconjecture on the relation between projectivity and relative projectivity, that\nwas studied by Aljadeff and Meir.","main_category":"math.GR","categories":"math.GR,math.KT","published":"2025-05-01T13:31:23Z"}
{"aid":"http://arxiv.org/abs/2505.00528v1","title":"An Analytic Zeta Function Ramp at the Black Hole Thouless Time","summary":"Black hole normal modes have intriguing connections to logarithmic spectra,\nand the spectral form factor (SFF) of $E_n = \\log n$ is the mod square of the\nRiemann zeta function (RZF). In this paper, we first provide an analytic\nunderstanding of the dip-ramp-plateau structure of RZF and show that the ramp\nat $\\beta \\equiv \\Re(s)=0$ has a slope precisely equal to 1. The $s=1$ pole of\nRZF can be viewed as due to a Hagedorn transition in this setting, and\nRiemann's analytic continuation to $\\Re(s)< 1$ provides the quantum\ncontribution to the truncated $\\log n$ partition function. This perspective\nyields a precise definition of RZF as the ''full ramp after removal of the\ndip'', and allows an unambiguous determination of the Thouless time. For black\nhole microstates, the Thouless time is expected to be\n$\\mathcal{O}(1)$--remarkably, the RZF also exhibits this behavior. To our\nknowledge, this is the first black hole-inspired toy model that has a\ndemonstrably $\\mathcal{O}(1)$ Thouless time. In contrast, it is\n$\\mathcal{O}(\\log N)$ in the SYK model and expected to be $\\mathcal{O}(N^{\\#})$\nin supergravity fuzzballs. We trace the origins of the ramp to a certain\nreflection property of the functional equation satisfied by RZF, and suggest\nthat it is a general feature of $L$-functions--we find evidence for ramps in\nlarge classes of $L$-functions. As an aside, we also provide an analytic\ndetermination of the slopes of (non-linear) ramps that arise in power law\nspectra using Poisson resummation techniques.","main_category":"hep-th","categories":"hep-th","published":"2025-05-01T13:54:37Z"}
{"aid":"http://arxiv.org/abs/2505.00590v1","title":"Unlocking the Potential of Linear Networks for Irregular Multivariate\n  Time Series Forecasting","summary":"Time series forecasting holds significant importance across various\nindustries, including finance, transportation, energy, healthcare, and climate.\nDespite the widespread use of linear networks due to their low computational\ncost and effectiveness in modeling temporal dependencies, most existing\nresearch has concentrated on regularly sampled and fully observed multivariate\ntime series. However, in practice, we frequently encounter irregular\nmultivariate time series characterized by variable sampling intervals and\nmissing values. The inherent intra-series inconsistency and inter-series\nasynchrony in such data hinder effective modeling and forecasting with\ntraditional linear networks relying on static weights. To tackle these\nchallenges, this paper introduces a novel model named AiT. AiT utilizes an\nadaptive linear network capable of dynamically adjusting weights according to\nobservation time points to address intra-series inconsistency, thereby\nenhancing the accuracy of temporal dependencies modeling. Furthermore, by\nincorporating the Transformer module on variable semantics embeddings, AiT\nefficiently captures variable correlations, avoiding the challenge of\ninter-series asynchrony. Comprehensive experiments across four benchmark\ndatasets demonstrate the superiority of AiT, improving prediction accuracy by\n11% and decreasing runtime by 52% compared to existing state-of-the-art\nmethods.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T15:24:48Z"}
{"aid":"http://arxiv.org/abs/2505.00607v1","title":"Nonparametric Estimation of Matching Efficiency and Elasticity in a\n  Marriage Agency Platform: 2014--2025","summary":"This paper examines monthly matching efficiency in the Japanese marriage\nmarket using novel data from IBJ, the country's largest structured matching\nplatform. Unlike administrative or dating app data, IBJ provides full search,\ndating, and matching logs based on verified profiles and confirmed engagements.\nUsers are highly selected into serious marriage search via costly screening.\nCovering 3.3% of national marriages annually, the data offer rare behavioral\ngranularity. Using a nonparametric approach, I estimate time-varying matching\nfunctions and elasticities. Efficiency rises fourfold over time, illustrating\nhow digital intermediation transforms partner search in modern marriage\nmarkets.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-05-01T15:36:50Z"}
{"aid":"http://arxiv.org/abs/2505.00663v1","title":"Wasserstein Policy Optimization","summary":"We introduce Wasserstein Policy Optimization (WPO), an actor-critic algorithm\nfor reinforcement learning in continuous action spaces. WPO can be derived as\nan approximation to Wasserstein gradient flow over the space of all policies\nprojected into a finite-dimensional parameter space (e.g., the weights of a\nneural network), leading to a simple and completely general closed-form update.\nThe resulting algorithm combines many properties of deterministic and classic\npolicy gradient methods. Like deterministic policy gradients, it exploits\nknowledge of the gradient of the action-value function with respect to the\naction. Like classic policy gradients, it can be applied to stochastic policies\nwith arbitrary distributions over actions -- without using the\nreparameterization trick. We show results on the DeepMind Control Suite and a\nmagnetic confinement fusion task which compare favorably with state-of-the-art\ncontinuous control methods.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-01T17:07:01Z"}
{"aid":"http://arxiv.org/abs/2505.00697v1","title":"Faster Quantum Algorithm for Multiple Observables Estimation in\n  Fermionic Problems","summary":"Achieving quantum advantage in efficiently estimating collective properties\nof quantum many-body systems remains a fundamental goal in quantum computing.\nWhile the quantum gradient estimation (QGE) algorithm has been shown to achieve\ndoubly quantum enhancement in the precision and the number of observables, it\nremains unclear whether one benefits in practical applications. In this work,\nwe present a generalized framework of adaptive QGE algorithm, and further\npropose two variants which enable us to estimate the collective properties of\nfermionic systems using the smallest cost among existing quantum algorithms.\nThe first method utilizes the symmetry inherent in the target state, and the\nsecond method enables estimation in a single-shot manner using the parallel\nscheme. We show that our proposal offers a quadratic speedup compared with\nprior QGE algorithms in the task of fermionic partial tomography for systems\nwith limited particle numbers. Furthermore, we provide the numerical\ndemonstration that, for a problem of estimating fermionic 2-RDMs, our proposals\nimprove the number of queries to the target state preparation oracle by a\nfactor of 100 for the nitrogenase FeMo cofactor and by a factor of 500 for\nFermi-Hubbard model of 100 sites.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T17:57:19Z"}
{"aid":"http://arxiv.org/abs/2505.00703v1","title":"T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level\n  and Token-level CoT","summary":"Recent advancements in large language models have demonstrated how\nchain-of-thought (CoT) and reinforcement learning (RL) can improve performance.\nHowever, applying such reasoning strategies to the visual generation domain\nremains largely unexplored. In this paper, we present T2I-R1, a novel\nreasoning-enhanced text-to-image generation model, powered by RL with a\nbi-level CoT reasoning process. Specifically, we identify two levels of CoT\nthat can be utilized to enhance different stages of generation: (1) the\nsemantic-level CoT for high-level planning of the prompt and (2) the\ntoken-level CoT for low-level pixel processing during patch-by-patch\ngeneration. To better coordinate these two levels of CoT, we introduce\nBiCoT-GRPO with an ensemble of generation rewards, which seamlessly optimizes\nboth generation CoTs within the same training step. By applying our reasoning\nstrategies to the baseline model, Janus-Pro, we achieve superior performance\nwith 13% improvement on T2I-CompBench and 19% improvement on the WISE\nbenchmark, even surpassing the state-of-the-art model FLUX.1. Code is available\nat: https://github.com/CaraJ7/T2I-R1","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-05-01T17:59:46Z"}
