{"aid":"http://arxiv.org/abs/2503.21672v1","title":"The Avoider-Enforcer game on hypergraphs of rank 3","summary":"In the Avoider-Enforcer convention of positional games, two players, Avoider\nand Enforcer, take turns selecting vertices from a hypergraph H. Enforcer wins\nif, by the time all vertices of H have been selected, Avoider has completely\nfilled an edge of H with her vertices; otherwise, Avoider wins. In this paper,\nwe first give some general results, in particular regarding the outcome of the\ngame and disjoint unions of hypergraphs. We then determine which player has a\nwinning strategy for all hypergraphs of rank 2, and for linear hypergraphs of\nrank 3 when Avoider plays the last move. The structural characterisations we\nobtain yield polynomial-time algorithms.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-03-27T16:40:37Z"}
{"aid":"http://arxiv.org/abs/2503.21673v1","title":"A friendly introduction to triangular transport","summary":"Decision making under uncertainty is a cross-cutting challenge in science and\nengineering. Most approaches to this challenge employ probabilistic\nrepresentations of uncertainty. In complicated systems accessible only via data\nor black-box models, however, these representations are rarely known. We\ndiscuss how to characterize and manipulate such representations using\ntriangular transport maps, which approximate any complex probability\ndistribution as a transformation of a simple, well-understood distribution. The\nparticular structure of triangular transport guarantees many desirable\nmathematical and computational properties that translate well into solving\npractical problems. Triangular maps are actively used for density estimation,\n(conditional) generative modelling, Bayesian inference, data assimilation,\noptimal experimental design, and related tasks. While there is ample literature\non the development and theory of triangular transport methods, this manuscript\nprovides a detailed introduction for scientists interested in employing measure\ntransport without assuming a formal mathematical background. We build intuition\nfor the key foundations of triangular transport, discuss many aspects of its\npractical implementation, and outline the frontiers of this field.","main_category":"stat.CO","categories":"stat.CO,physics.ao-ph,stat.ME,stat.ML","published":"2025-03-27T16:41:14Z"}
{"aid":"http://arxiv.org/abs/2503.21684v1","title":"Decorated phases in triblock copolymers: zeroth- and first-order\n  analysis","summary":"We study a two-dimensional inhibitory ternary system characterized by a free\nenergy functional which combines an interface short-range interaction energy\npromoting micro-domain growth with a Coulomb-type long-range interaction energy\nwhich prevents micro-domains from unlimited spreading. Here we consider a\nscenario in which two species are dominant and one species is vanishingly\nsmall. In this scenario two energy levels are distinguished: the zeroth-order\nenergy encodes information on the optimal arrangement of the dominant\nconstituents, while the first-order energy gives the shape of the vanishing\nconstituent. This first-order energy also shows that, for any optimal\nconfiguration, the vanishing phase must lie on the boundary between the two\ndominant constituents and form lens clusters also known as vesica piscis.","main_category":"math.AP","categories":"math.AP","published":"2025-03-27T16:52:27Z"}
{"aid":"http://arxiv.org/abs/2503.21697v1","title":"The commutativity problem for effective varieties of formal series, and\n  applications","summary":"A formal series in noncommuting variables $\\Sigma$ over the rationals is a\nmapping $\\Sigma^* \\to \\mathbb Q$. We say that a series is commutative if the\nvalue in the output does not depend on the order of the symbols in the input.\nThe commutativity problem for a class of series takes as input a (finite\npresentation of) a series from the class and amounts to establishing whether it\nis commutative. This is a very natural, albeit nontrivial problem, which has\nnot been considered before from an algorithmic perspective.\n  We show that commutativity is decidable for all classes of series that\nconstitute a so-called effective prevariety, a notion generalising Reutenauer's\nvarieties of formal series. For example, the class of rational series,\nintroduced by Sch\\\"utzenberger in the 1960's, is well-known to be an effective\n(pre)variety, and thus commutativity is decidable for it.\n  In order to showcase the applicability of our result, we consider classes of\nformal series generalising the rational ones. We consider polynomial automata,\nshuffle automata, and infiltration automata, and we show that each of these\nmodels recognises an effective prevariety of formal series. Consequently, their\ncommutativity problem is decidable, which is a novel result. We find it\nremarkable that commutativity can be decided in a uniform way for such\ndisparate computation models.\n  Finally, we present applications of commutativity outside the theory of\nformal series. We show that we can decide solvability in sequences and in power\nseries for restricted classes of algebraic difference and differential\nequations, for which such problems are undecidable in full generality. Thanks\nto this, we can prove that the syntaxes of multivariate polynomial recursive\nsequences and of constructible differentially algebraic power series are\neffective, which are new results which were left open in previous work.","main_category":"cs.FL","categories":"cs.FL,cs.DM,cs.LO","published":"2025-03-27T17:01:19Z"}
{"aid":"http://arxiv.org/abs/2503.21727v1","title":"Enhancing Underwater Navigation through Cross-Correlation-Aware Deep\n  INS/DVL Fusion","summary":"The accurate navigation of autonomous underwater vehicles critically depends\non the precision of Doppler velocity log (DVL) velocity measurements. Recent\nadvancements in deep learning have demonstrated significant potential in\nimproving DVL outputs by leveraging spatiotemporal dependencies across multiple\nsensor modalities. However, integrating these estimates into model-based\nfilters, such as the extended Kalman filter, introduces statistical\ninconsistencies, most notably, cross-correlations between process and\nmeasurement noise. This paper addresses this challenge by proposing a\ncross-correlation-aware deep INS/DVL fusion framework. Building upon BeamsNet,\na convolutional neural network designed to estimate AUV velocity using DVL and\ninertial data, we integrate its output into a navigation filter that explicitly\naccounts for the cross-correlation induced between the noise sources. This\napproach improves filter consistency and better reflects the underlying sensor\nerror structure. Evaluated on two real-world underwater trajectories, the\nproposed method outperforms both least squares and cross-correlation-neglecting\napproaches in terms of state uncertainty. Notably, improvements exceed 10% in\nvelocity and misalignment angle confidence metrics. Beyond demonstrating\nempirical performance, this framework provides a theoretically principled\nmechanism for embedding deep learning outputs within stochastic filters.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-27T17:38:43Z"}
{"aid":"http://arxiv.org/abs/2503.21728v1","title":"Near field imaging of local interference in radio interferometric data:\n  Impact on the redshifted 21-cm power spectrum","summary":"Radio-frequency interference (RFI) is a major systematic limitation in radio\nastronomy, particularly for science cases requiring high sensitivity, such as\n21-cm cosmology. Traditionally, RFI is dealt with by identifying its signature\nin the dynamic spectra of visibility data and flagging strongly affected\nregions. However, for RFI sources that do not occupy narrow regions in the\ntime-frequency space, such as persistent local RFI, modeling these sources\ncould be essential to mitigating their impact. This paper introduces two\nmethods for detecting and characterizing local RFI sources from radio\ninterferometric visibilities: matched filtering and maximum a posteriori (MAP)\nimaging. These algorithms use the spherical wave equation to construct\nthree-dimensional near-field image cubes of RFI intensity from the\nvisibilities. The matched filter algorithm can generate normalized maps by\ncross-correlating the expected contributions from RFI sources with the observed\nvisibilities, while the MAP method performs a regularized inversion of the\nvisibility equation in the near field. We also develop a full polarization\nsimulation framework for RFI and demonstrate the methods on simulated\nobservations of local RFI sources. The stability, speed, and errors introduced\nby these algorithms are investigated, and, as a demonstration, the algorithms\nare applied to a subset of NenuFAR observations to perform spatial, spectral,\nand temporal characterization of two local RFI sources. We assess the impact of\nlocal RFI on images, the uv plane, and cylindrical power spectra through\nsimulations and describe these effects qualitatively. We also quantify the\nlevel of errors and biases that these algorithms induce and assess their\nimplications for the estimated 21-cm power spectrum with radio interferometers.\nThe near-field imaging and simulation codes are made available publicly in the\nPython library nfis.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO","published":"2025-03-27T17:40:38Z"}
{"aid":"http://arxiv.org/abs/2503.21735v1","title":"GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release\n  Analytics","summary":"Ensuring the reliability and effectiveness of software release decisions is\ncritical, particularly in safety-critical domains like automotive systems.\nPrecise analysis of release validation data, often presented in tabular form,\nplays a pivotal role in this process. However, traditional methods that rely on\nmanual analysis of extensive test datasets and validation metrics are prone to\ndelays and high costs. Large Language Models (LLMs) offer a promising\nalternative but face challenges in analytical reasoning, contextual\nunderstanding, handling out-of-scope queries, and processing structured test\ndata consistently; limitations that hinder their direct application in\nsafety-critical scenarios. This paper introduces GateLens, an LLM-based tool\nfor analyzing tabular data in the automotive domain. GateLens translates\nnatural language queries into Relational Algebra (RA) expressions and then\ngenerates optimized Python code. It outperforms the baseline system on\nbenchmarking datasets, achieving higher F1 scores and handling complex and\nambiguous queries with greater robustness. Ablation studies confirm the\ncritical role of the RA module, with performance dropping sharply when omitted.\nIndustrial evaluations reveal that GateLens reduces analysis time by over 80%\nwhile maintaining high accuracy and reliability. As demonstrated by presented\nresults, GateLens achieved high performance without relying on few-shot\nexamples, showcasing strong generalization across various query types from\ndiverse company roles. Insights from deploying GateLens with a partner\nautomotive company offer practical guidance for integrating AI into critical\nworkflows such as release validation. Results show that by automating test\nresult analysis, GateLens enables faster, more informed, and dependable release\ndecisions, and can thus advance software scalability and reliability in\nautomotive systems.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL,cs.MA","published":"2025-03-27T17:48:32Z"}
{"aid":"http://arxiv.org/abs/2503.21746v1","title":"Effects of dissipation on phase diagram and bosonic excitations in the\n  quark-meson model","summary":"In this work we study the quark-meson model within a real-time formulation of\nthe functional renormalization group (FRG) on the Schwinger-Keldysh contour.\nFirst, we discuss in detail the symmetry of thermal equilibrium for the\nfermionic sector of the Keldysh action. We take into account dissipation for\nthe bosonic degrees of freedom in the spirit of the Caldeira-Leggett model by\ncoupling the system to an $O(4)$ invariant external heat bath. We study the\neffect of dissipation on static equilibrium properties, most prominently on the\nFRG flow of the effective potential and thus on the resulting phase diagram. We\nfind that, unlike in classical systems, through the contributions from non-zero\nMatsubara modes the dissipative dynamics can in general have an effect on\nstatic observables. We investigate these effects within two phenomenological\nmodels for the temperature dependence of the pion damping to verify that they\nare quantitatively small. To estimate their largest possible influence, we\nconsider limits where the damping constants approach infinity.","main_category":"hep-ph","categories":"hep-ph","published":"2025-03-27T17:53:22Z"}
{"aid":"http://arxiv.org/abs/2503.21749v1","title":"LeX-Art: Rethinking Text Generation via Scalable High-Quality Data\n  Synthesis","summary":"We introduce LeX-Art, a comprehensive suite for high-quality text-image\nsynthesis that systematically bridges the gap between prompt expressiveness and\ntext rendering fidelity. Our approach follows a data-centric paradigm,\nconstructing a high-quality data synthesis pipeline based on Deepseek-R1 to\ncurate LeX-10K, a dataset of 10K high-resolution, aesthetically refined\n1024$\\times$1024 images. Beyond dataset construction, we develop LeX-Enhancer,\na robust prompt enrichment model, and train two text-to-image models, LeX-FLUX\nand LeX-Lumina, achieving state-of-the-art text rendering performance. To\nsystematically evaluate visual text generation, we introduce LeX-Bench, a\nbenchmark that assesses fidelity, aesthetics, and alignment, complemented by\nPairwise Normalized Edit Distance (PNED), a novel metric for robust text\naccuracy evaluation. Experiments demonstrate significant improvements, with\nLeX-Lumina achieving a 79.81% PNED gain on CreateBench, and LeX-FLUX\noutperforming baselines in color (+3.18%), positional (+4.45%), and font\naccuracy (+3.81%). Our codes, models, datasets, and demo are publicly\navailable.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:56:15Z"}
{"aid":"http://arxiv.org/abs/2503.21752v1","title":"Hypergraphic zonotopes and acyclohedra","summary":"We introduce a higher-uniformity analogue of graphic zonotopes and\npermutohedra. Specifically, given a $(d+1)$-uniform hypergraph $H$, we define\nits hypergraphic zonotope $\\mathcal{Z}_H$, and when $H$ is the complete\n$(d+1)$-uniform hypergraph $K^{(d+1)}_n$, we call its hypergraphic zonotope the\nacyclohedron $\\mathcal{A}_{n,d}$.\n  We express the volume of $\\mathcal{Z}_H$ as a homologically weighted count of\nthe spanning $d$-dimensional hypertrees of $H$, which is closely related to\nKalai's generalization of Cayley's theorem in the case when $H=K^{(d+1)}_n$\n(but which, curiously, is not the same). We also relate the vertices of\nhypergraphic zonotopes to a notion of acyclic orientations previously studied\nby Linial and Morganstern for complete hypergraphs.","main_category":"math.CO","categories":"math.CO","published":"2025-03-27T17:56:42Z"}
{"aid":"http://arxiv.org/abs/2503.21768v1","title":"Results on branching random walks and rumor processes via germ order","summary":"Germ order is a non-standard stochastic order defined through the comparison\nof the generating functions of the processes. This order was first introduced\nfor branching random walks with a constant breeding law and independent\ndispersal of offspring, which are characterized by a one-dimensional generating\nfunction. In this work, we investigate the properties of the extension of this\nconcept to processes characterized by a multidimensional generating function,\nsuch as general branching random walks and rumor processes. In particular, we\nuse germ ordering to characterize the behavior of certain branching random\nwalks and rumor processes with inhomogeneous breeding/transmitting laws.","main_category":"math.PR","categories":"math.PR","published":"2025-03-27T17:59:06Z"}
{"aid":"http://arxiv.org/abs/2503.23702v1","title":"3D Dental Model Segmentation with Geometrical Boundary Preserving","summary":"3D intraoral scan mesh is widely used in digital dentistry diagnosis,\nsegmenting 3D intraoral scan mesh is a critical preliminary task. Numerous\napproaches have been devised for precise tooth segmentation. Currently, the\ndeep learning-based methods are capable of the high accuracy segmentation of\ncrown. However, the segmentation accuracy at the junction between the crown and\nthe gum is still below average. Existing down-sampling methods are unable to\neffectively preserve the geometric details at the junction. To address these\nproblems, we propose CrossTooth, a boundary-preserving segmentation method that\ncombines 3D mesh selective downsampling to retain more vertices at the\ntooth-gingiva area, along with cross-modal discriminative boundary features\nextracted from multi-view rendered images, enhancing the geometric\nrepresentation of the segmentation network. Using a point network as a backbone\nand incorporating image complementary features, CrossTooth significantly\nimproves segmentation accuracy, as demonstrated by experiments on a public\nintraoral scan dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:00:11Z"}
{"aid":"http://arxiv.org/abs/2503.23714v1","title":"Building Instruction-Tuning Datasets from Human-Written Instructions\n  with Open-Weight Large Language Models","summary":"Instruction tuning is crucial for enabling Large Language Models (LLMs) to\nsolve real-world tasks. Prior work has shown the effectiveness of\ninstruction-tuning data synthesized solely from LLMs, raising a fundamental\nquestion: Do we still need human-originated signals for instruction tuning?\nThis work answers the question affirmatively: we build state-of-the-art\ninstruction-tuning datasets sourced from human-written instructions, by simply\npairing them with LLM-generated responses. LLMs fine-tuned on our datasets\nconsistently outperform those fine-tuned on existing ones. Our data\nconstruction approach can be easily adapted to other languages; we build\ndatasets for Japanese and confirm that LLMs tuned with our data reach\nstate-of-the-art performance. Analyses suggest that instruction-tuning in a new\nlanguage allows LLMs to follow instructions, while the tuned models exhibit a\nnotable lack of culture-specific knowledge in that language. The datasets and\nfine-tuned models will be publicly available. Our datasets, synthesized with\nopen-weight LLMs, are openly distributed under permissive licenses, allowing\nfor diverse use cases.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T04:28:38Z"}
{"aid":"http://arxiv.org/abs/2503.23723v1","title":"Undecidable problems associated with variational quantum algorithms","summary":"Variational Quantum Algorithms (VQAs), such as the Variational Quantum\nEigensolver (VQE) and the Quantum Approximate Optimization Algorithm (QAOA),\nare widely studied as candidates for near-term quantum advantage. Recent work\nhas shown that training VQAs is NP-hard in general. In this paper, we present a\nconditional result suggesting that the training of VQAs is undecidable, even in\nidealized, noiseless settings. We reduce the decision version of the digitized\nVQA training problem-where circuit parameters are drawn from a discrete set-to\nthe question of whether a universal Diophantine equation (UDE) has a root. This\nreduction relies on encoding the UDE into the structure of a variational\nquantum circuit via the matrix exponentials. The central step involves\nestablishing a correspondence between the objective function of the VQA and a\nknown UDE of 58 variables and degree 4. Our main result is conditional on a\nnatural conjecture: that a certain system of structured complex polynomial\nequations-arising from the inner product of a VQA circuit output and a fixed\nobservable-has at least one solution. We argue this conjecture is plausible\nbased on dimension-counting arguments (degrees of freedom in the Hamiltonians,\nstate vector, and observable), and the generic solvability of such systems in\nalgebraic geometry over the complex numbers. Under this assumption, we suggest\nthat deciding whether a digitized VQA achieves a given energy threshold is\nundecidable. This links the limitations of variational quantum algorithms to\nfoundational questions in mathematics and logic, extending the known landscape\nof quantum computational hardness to include uncomputability. Additionally, we\nestablish an unconditional undecidability result for VQA convergence in open\nquantum systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T04:52:43Z"}
{"aid":"http://arxiv.org/abs/2503.23727v1","title":"Angle-dependent in-situ fast flavor transformations in post-neutron star\n  merger disks","summary":"The remnant black hole-accretion disk system resulting from binary neutron\nstar mergers has proven to be a promising site for synthesizing the heaviest\nelements via rapid neutron capture (r-process). A critical factor in\ndetermining the full r-process pattern in these environments is the neutron\nrichness of the ejecta, which is strongly influenced by neutrino interactions.\nOne key ingredient shaping these interactions is fast neutrino flavor\nconversions (FFCs), which arise due to angular crossings in neutrino\ndistributions and occur on nanosecond timescales. We present the first\nthree-dimensional, in-situ, angle-dependent modeling of FFCs in post-merger\ndisks, implemented within general relativistic magnetohydrodynamics with Monte\nCarlo neutrino transport. Our results reveal that, by suppressing electron\nneutrinos, FFCs more efficiently cool the disk and weaken the early thermally\ndriven wind. Less re-leptonization due to electron neutrino absorption makes\nthis cooler wind more neutron-rich, producing a more robust r-process at higher\nlatitudes of the outflow. This study underscores the necessity of incorporating\nFFCs in realistic simulations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T05:01:52Z"}
{"aid":"http://arxiv.org/abs/2503.23749v1","title":"Lower semicontinuity of bounded property in the branching problem and\n  sphericity of flag variety","summary":"Vinberg--Kimel'fel'd [Funct. Anal. Appl., 1978] established that a\nquasi-projective normal $G$-variety $X$ is spherical if and only if $G$-modules\non the spaces $\\Gamma(X, \\mathcal{L})$ of global sections of $G$-equivariant\nline bundles are multiplicity-free. This result was generalized by\nKobayashi--Oshima [Adv. Math., 2013] and several researchers to (degenerate)\nprincipal series representations of reductive Lie groups. The purpose of this\nshort article is to show that the boundedness of the multiplicities in the\nrestrictions of cohomologically induced modules implies the sphericity of some\npartial flag variety.\n  In our previous paper, we reduce the boundedness of the multiplicities to the\nfiniteness of a ring-theoretic invariant $\\mathrm{PIdeg}$. To show the main\nresult, we discuss the lower semicontinuity of $\\mathrm{PIdeg}$ on the space\n$\\mathrm{Prim}(\\mathcal{U}(\\mathfrak{g}))$ of primitive ideals. We also treat\nthe finiteness of the lengths of the restrictions of cohomologically induced\nmodules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-31T06:01:51Z"}
{"aid":"http://arxiv.org/abs/2503.23781v1","title":"DebFlow: Automating Agent Creation via Agent Debate","summary":"Large language models (LLMs) have demonstrated strong potential and\nimpressive performance in automating the generation and optimization of\nworkflows. However, existing approaches are marked by limited reasoning\ncapabilities, high computational demands, and significant resource\nrequirements. To address these issues, we propose DebFlow, a framework that\nemploys a debate mechanism to optimize workflows and integrates reflexion to\nimprove based on previous experiences. We evaluated our method across six\nbenchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approach\nachieved a 3\\% average performance improvement over the latest baselines,\ndemonstrating its effectiveness in diverse problem domains. In particular,\nduring training, our framework reduces resource consumption by 37\\% compared to\nthe state-of-the-art baselines. Additionally, we performed ablation studies.\nRemoving the Debate component resulted in a 4\\% performance drop across two\nbenchmark datasets, significantly greater than the 2\\% drop observed when the\nReflection component was removed. These findings strongly demonstrate the\ncritical role of Debate in enhancing framework performance, while also\nhighlighting the auxiliary contribution of reflexion to overall optimization.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T06:56:13Z"}
{"aid":"http://arxiv.org/abs/2503.23820v1","title":"When Counterfactual Reasoning Fails: Chaos and Real-World Complexity","summary":"Counterfactual reasoning, a cornerstone of human cognition and\ndecision-making, is often seen as the 'holy grail' of causal learning, with\napplications ranging from interpreting machine learning models to promoting\nalgorithmic fairness. While counterfactual reasoning has been extensively\nstudied in contexts where the underlying causal model is well-defined,\nreal-world causal modeling is often hindered by model and parameter\nuncertainty, observational noise, and chaotic behavior. The reliability of\ncounterfactual analysis in such settings remains largely unexplored. In this\nwork, we investigate the limitations of counterfactual reasoning within the\nframework of Structural Causal Models. Specifically, we empirically investigate\n\\emph{counterfactual sequence estimation} and highlight cases where it becomes\nincreasingly unreliable. We find that realistic assumptions, such as low\ndegrees of model uncertainty or chaotic dynamics, can result in\ncounterintuitive outcomes, including dramatic deviations between predicted and\ntrue counterfactual trajectories. This work urges caution when applying\ncounterfactual reasoning in settings characterized by chaos and uncertainty.\nFurthermore, it raises the question of whether certain systems may pose\nfundamental limitations on the ability to answer counterfactual questions about\ntheir behavior.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T08:14:51Z"}
{"aid":"http://arxiv.org/abs/2503.23833v1","title":"Products of Kirillov-Reshetikhin modules and maximal green sequences","summary":"We show that a $q$-character of a Kirillov-Reshetikhin module (KR modules)\nfor untwisted quantum affine algebras of simply laced types $A_n^{(1)}$,\n$D_n^{(1)}$, $E_6^{(1)}$, $E_7^{(1)}$, $E_8^{(1)}$ might be obtained from a\nspecific cluster variable of a seed obtained by applying a maximal green\nsequence to the initial (infinite) quiver of the Hernandez-Leclerc cluster\nalgebra. For a collection of KR-modules with nested supports, we show an\nexplicit construction of a cluster seed, which has cluster variables\ncorresponding to the $q$-characters of KR-modules of such a collection. We\nprove that the product of KR-modules of such a collection is a simple module.\nWe also construct cluster seeds with cluster variables corresponding to\n$q$-characters of KR-modules of some non-nested collections. We make a\nconjecture that tensor products of KR-modules for such non-nested collections\nare simple. We show that the cluster Donaldson-Thomas transformations for\ndouble Bruhat cells for $ADE$ types can be computed using $q$-characters of\nKR-modules.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-03-31T08:28:36Z"}
{"aid":"http://arxiv.org/abs/2503.23836v1","title":"Gradient catastrophe and Peregrine soliton in nonlinear flexible\n  mechanical metamaterials","summary":"We explore the generation of extreme wave events in mechanical metamaterials\nusing the regularization of the gradient catastrophe theory developed by A.\nTovbis and M. Bertola for the nonlinear Schr\\\"odinger equation. According to\nthis theory, Peregrine solitons can locally emerge in the semiclassical limit\nof the nonlinear Schr\\\"odinger equation. Our objective is to determine whether\nthe phenomenon of gradient catastrophe can occur in a class of architected\nstructures designated as flexible mechanical metamaterials, both with and\nwithout losses. We demonstrate theoretically and numerically that this\nphenomenon can occur in a canonical example of such flexible mechanical\nmetamaterial, a chain of rotating units, studied earlier for its ability to\nsupport robust nonlinear waves such as elastic vector solitons. We find that in\nthe presence of weak losses, the gradient catastrophe persists although the\namplitude of extreme generated events is smaller and their onset is delayed\ncompared to the lossless configuration.","main_category":"nlin.PS","categories":"nlin.PS,physics.class-ph","published":"2025-03-31T08:31:15Z"}
{"aid":"http://arxiv.org/abs/2503.23843v1","title":"The Problem of the Global Astrometric Sphere Reconstruction in\n  Astrometry -- Issues and Approaches","summary":"In this contribution we give a brief account of the problem of the Global\nAstrometric Sphere Reconstruction in Astrometry, with particular reference to\nthe Gaia and Gaia-like astrometric missions, namely those adopting a scanning\nstrategy with observations in TDI mode. We sketch the design of the Gaia\nmission, the mathematical modelling that comes naturally from its observing\nstrategy, and how the problem of the global sphere reconstruction translates\ninto that of the solution of large, sparse, and overdetermined system of\nlinearized equations. After a short description of the two approaches to this\nproblem implemented in the Gaia data reduction pipelines, we list the main\nknown problems of the current approaches, with specific reference to the\ncalibration and the correlation issues. Finally, we suggest how an arc-based\nsolution could help to alleviate some of these problems, how it would be\npossible to devise a mathematical model for such an observable despite the TDI\nobserving mode, and the main difficulty that a parallel implementation of this\nmodel would have to solve.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T08:45:29Z"}
{"aid":"http://arxiv.org/abs/2503.23849v1","title":"Narrow-Line Seyfert 1 Galaxies Beyond the Local X-ray Universe: An X-ray\n  spectral sample","summary":"Narrow-line Seyfert 1 AGNs (NLS1s) represent a unique stage in the black hole\ngrowth history, characterised by low black hole masses of approximately\n$10^{6}$-$10^{8}$ solar masses and around-Eddington accretion rates. X-ray\nstudies of NLS1s have largely been confined to the local Universe ($z < 0.2$),\nwhile their broad-line counterparts and radio-loud quasars have been more\nextensively investigated at higher redshifts. In this work, we conducted an\nX-ray spectral analysis for 14 SDSS-observed NLS1s at $z\\approx1$ in the eRASS1\ncatalogue. We found that all of their eROSITA observations agree with the\nexpected rest-frame 2 keV monochromatic luminosity given their rest-frame 2500\nangstrom monochromatic luminosity, further supporting evidence of AGN emission.\nSecond, when fitted with a power-law model, most continuum spectra between\n0.7-7 keV in their rest frames necessitate photon indices $\\Gamma\\gtrsim2.5$.\nNotably, the highest photon index of around 4.7 in one of our NLS1 AGNs hints\nat a significant contribution from soft excess emission. Finally, our analysis\ndemonstrates that we can align the Eddington ratios with optical measurements\nby applying a correction factor between 10-120 to their X-ray luminosity.\nAlthough measurement uncertainty remains considerable, our findings suggest\nthat assumptions for the standard geometrically thin accretion disc model made\nin previous estimations of this correction factor may not apply to near or\nsuper-Eddington NLS1 AGNs. Finally, we also compare this sample with extremely\nvariable nearby NLS1s and other X-ray-weak AGNs, such as JWST-observed,\nbroad-line AGNs at $z=5-6$, and underscores the importance of deeper X-ray\nsurveys for more X-ray-weak NLS1s.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T08:55:07Z"}
{"aid":"http://arxiv.org/abs/2503.23850v1","title":"Event-activity dependence of heavy-flavor production at the ALICE\n  experiment","summary":"Heavy-flavor production at the LHC offers valuable tests of\nquantum-chromodynamics calculations, owing to the large masses of heavy quarks.\nMeasurements of charm production as a function of event activity reveal new\nfeatures of charm production and fragmentation, providing insights to the\ninterplay between soft and hard processes. In addition, charm production in\nheavy-ion collisions addresses flavor-dependent quark transport properties in\nboth hot and cold nuclear matter, helping to clarify the roles of coalescence\nand fragmentation in heavy-flavor hadron formation. This contribution\nsummarizes recent measurements from the ALICE experiment on charm production as\na function of charged-particle multiplicity in pp collisions at various\nenergies, including the measurements of charm baryon-to-meson production yield\nratios in pp, p--Pb and Pb--Pb collisions. New results on ${\\rm D}^0$\nproduction in pp collisions as a function of the transverse spherocity of the\nevent, as well as of the transverse event-activity classifier $R_{\\rm T}$, are\nalso presented.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T08:55:52Z"}
{"aid":"http://arxiv.org/abs/2503.23860v1","title":"The Kossakowski Matrix and Strict Positivity of Markovian Quantum\n  Dynamics","summary":"We investigate the relationship between strict positivity of the Kossakowski\nmatrix, irreducibility and positivity improvement properties of Markovian\nQuantum Dynamics. We show that for a Gaussian quantum dynamical semigroup\nstrict positivity of the Kossakowski matrix implies irreducibility and, with an\nadditional technical assumption, that the support of any initial state is the\nwhole space for any positive time.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T09:07:26Z"}
{"aid":"http://arxiv.org/abs/2503.23861v1","title":"$s_{\\pm}$ pairing via interlayer interaction in\n  La$_{2.85}$Pr$_{0.15}$Ni$_2$O$_7$ Thin Films under Ambient Pressure","summary":"We demonstrate that interlayer \\(s_{\\pm}\\)-wave pairing dominates\nsuperconductivity in La\\(_{2.85}\\)Pr\\(_{0.15}\\)Ni\\(_2\\)O\\(_7\\) thin films\nthrough self-consistent mean-field calculations. We further show that applying\na perpendicular electric field breaks layer equivalence, generating nodal\nstructures, Fermi arcs, and finite low-energy states in the \\(d_{x^2-y^2}\\)\norbital. Our results quantitatively align with recent experimental observations\nfor the superconducting gaps, and we propose experimental symmetry-breaking\nperturbations as a direct test for the interlayer pairing mechanism.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T09:08:26Z"}
{"aid":"http://arxiv.org/abs/2503.23920v1","title":"Semileptonic baryon decays $Ξ_b\\rightarrow Ξ_c \\ell^- \\barν_\\ell\n  $ in perturbative QCD","summary":"We perform a detailed analysis of the semileptonic $\\Xi_b\\rightarrow \\Xi_c\n\\ell^- \\bar{\\nu}_\\ell$ decays within the perturbative QCD (PQCD) framework. In\nour study, the $\\Xi_b\\rightarrow \\Xi_c$ transition form factors are calculated\nusing several popular models for baryonic light-cone distribution amplitudes\n(LCDAs). These form factors are then employed to analyze a range of observable\nquantities for the semileptonic processes via the helicity formalism. Our work\npresents predictions for the branching fractions of these decays for both the\n$\\tau$ and $e$ channels. Notably, the obtained lepton flavor universality\nratio, $\\mathcal{R}_{\\Xi_c}\\approx 0.3$, may offer new insights into the\n$\\mathcal{R}^{(*)}$ puzzle. Furthermore, we investigate various angular\nobservables, such as forward-backward asymmetries, lepton-side convexity\nparameters, and polarization asymmetries, which provide complementary\ninformation regarding potential new physics in $b$-baryonic semileptonic\ntransitions. The numerical results for these angular observables are presented\nas both functions of $q^2$ and as averaged values. We observe that the lepton\nmass plays a significant role in shaping the angular distributions, affecting\nmost of the observables under consideration. These results are expected to be\nvaluable for both current and future experimental investigations of\nsemileptonic heavy-to-heavy baryon decays.","main_category":"hep-ph","categories":"hep-ph","published":"2025-03-31T10:10:31Z"}
{"aid":"http://arxiv.org/abs/2503.23924v1","title":"Model Hemorrhage and the Robustness Limits of Large Language Models","summary":"Large language models (LLMs) demonstrate strong performance across natural\nlanguage processing tasks, yet undergo significant performance degradation when\nmodified for deployment through quantization, pruning, or decoding strategy\nadjustments. We define this phenomenon as model hemorrhage - performance\ndecline caused by parameter alterations and architectural changes. Through\nsystematic analysis of various LLM frameworks, we identify key vulnerability\npatterns: layer expansion frequently disrupts attention mechanisms, compression\ntechniques induce information loss cascades, and decoding adjustments amplify\nprediction divergences. Our investigation reveals transformer architectures\nexhibit inherent robustness thresholds that determine hemorrhage severity\nacross modification types. We propose three mitigation strategies:\ngradient-aware pruning preserves critical weight pathways, dynamic quantization\nscaling maintains activation integrity, and decoding calibration aligns\ngeneration trajectories with original model distributions. This work\nestablishes foundational metrics for evaluating model stability during\nadaptation, providing practical guidelines for maintaining performance while\nenabling efficient LLM deployment. Our findings advance understanding of neural\nnetwork resilience under architectural transformations, particularly for\nlarge-scale language models.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-03-31T10:16:03Z"}
{"aid":"http://arxiv.org/abs/2503.23930v1","title":"Exploring Reliable PPG Authentication on Smartwatches in Daily Scenarios","summary":"Photoplethysmography (PPG) Sensors, widely deployed in smartwatches, offer a\nsimple and non-invasive authentication approach for daily use. However, PPG\nauthentication faces reliability issues due to motion artifacts from physical\nactivity and physiological variability over time. To address these challenges,\nwe propose MTL-RAPID, an efficient and reliable PPG authentication model, that\nemploys a multitask joint training strategy, simultaneously assessing signal\nquality and verifying user identity. The joint optimization of these two tasks\nin MTL-RAPID results in a structure that outperforms models trained on\nindividual tasks separately, achieving stronger performance with fewer\nparameters. In our comprehensive user studies regarding motion artifacts (N =\n30), time variations (N = 32), and user preferences (N = 16), MTL-RAPID\nachieves a best AUC of 99.2\\% and an EER of 3.5\\%, outperforming existing\nbaselines. We opensource our PPG authentication dataset along with the\nMTL-RAPID model to facilitate future research on GitHub.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:25:48Z"}
{"aid":"http://arxiv.org/abs/2503.23939v1","title":"Simulation of Shor algorithm for discrete logarithm problems with\n  comprehensive pairs of modulo p and order q","summary":"The discrete logarithm problem (DLP) over finite fields, commonly used in\nclassical cryptography, has no known polynomial-time algorithm on classical\ncomputers. However, Shor has provided its polynomial-time algorithm on quantum\ncomputers. Nevertheless, there are only few examples simulating quantum\ncircuits that operate on general pairs of modulo $p$ and order $q$. In this\npaper, we constructed such quantum circuits and solved DLPs for all 1,860\npossible pairs of $p$ and $q$ up to 32 qubits using a quantum simulator with\nPRIMEHPC FX700. From this, we obtained and verified values of the success\nprobabilities, which had previously been heuristically analyzed by Eker\\r{a}.\nAs a result, we found that the success probability of Shor's algorithm for\nsolving the DLP exhibits periodicity with an asymmetric waveform determined by\nthe order $q$. Additionally, we generated 1,015 quantum circuits for larger\npairs of $p$ and $q$, extrapolated the circuit sizes obtained, and compared\nthem for $p=2048$ bits between safe-prime groups and Schnorr groups. While in\nclassical cryptography, the cipher strength of safe-prime groups and Schnorr\ngroups is the same if $p$ is equal, we quantitatively demonstrated how much the\nstrength of the latter decreases to the bit length of $p$ in the former when\nusing Shor's quantum algorithm. In particular, it was experimentally and\ntheoretically shown that when a ripple carry adder is used in the addition\ncircuit, the cryptographic strength of a Schnorr group with $p=2048$ bits under\nShor's algorithm is almost equivalent to that of a safe-prime group with\n$p=1024$ bits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T10:39:10Z"}
{"aid":"http://arxiv.org/abs/2503.23953v1","title":"Skilful global seasonal predictions from a machine learning weather\n  model trained on reanalysis data","summary":"Machine learning weather models trained on observed atmospheric conditions\ncan outperform conventional physics-based models at short- to medium-range\n(1-14 day) forecast timescales. Here we take the machine learning weather model\nACE2, trained to predict 6-hourly steps in atmospheric evolution and which can\nremain stable over long forecast periods, and assess it from a seasonal\nforecasting perspective. Applying persisted sea surface temperature (SST) and\nsea-ice anomalies centred on 1st November each year, we initialise a lagged\nensemble of winter predictions covering 1993/1994 to 2015/2016. Over this\n23-year period there is remarkable similarity in the patterns of predictability\nwith a leading physics-based model. The ACE2 model exhibits skilful predictions\nof the North Atlantic Oscillation (NAO) with a correlation score of 0.47\n(p=0.02), as well as a realistic global distribution of skill and ensemble\nspread. Surprisingly, ACE2 is found to exhibit a signal-to-noise error as seen\nin physics-based models, in which it is better at predicting the real world\nthan itself. Examining predictions of winter 2009/2010 indicates potential\nlimitations of ACE2 in capturing extreme seasonal conditions that extend\noutside the training data. Nevertheless, this study reveals that machine\nlearning weather models can produce skilful global seasonal predictions and\nheralds a new era of increased understanding, development and generation of\nnear-term climate predictions.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-03-31T11:11:16Z"}
{"aid":"http://arxiv.org/abs/2503.23954v1","title":"Exclusion of a diquark-antidiquark structure for the lightest\n  positive-parity charmed mesons","summary":"The nature of low-lying scalar and axial-vector charmed mesons has been\ndebated for decades, with hadronic molecular and compact tetraquark models\nbeing prominent candidates. These two models predict quite different features\nfor the accessible SU(3) multiplets in the scalar and axial-vector sectors,\nwhich can be tested through lattice calculations at SU(3) symmetric points. In\nthis work, we perform lattice calculations for both scalar and axial-vector\ncharmed mesons with an SU(3) symmetric pion mass about 613 MeV for the SU(3)\n$[6]$ and $[\\overline{15}]$ multiplets. We find that the $[6]$ multiplet\nexhibits attractive interactions in both scalar and axial-vector sectors, while\nthe $[\\overline{15}]$ multiplet shows repulsive interactions in both sectors.\nThe energy shifts in the scalar and axial-vector sectors are compatible with\neach other within uncertainties. These results are fully consistent with the\nhadronic molecular picture, while challenging the compact tetraquark model,\nwhich predicts the existence of low-lying $[\\overline{15}]$ states in the\naxial-vector sector but not in the scalar sector.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-03-31T11:12:29Z"}
{"aid":"http://arxiv.org/abs/2503.23981v1","title":"Federated Structured Sparse PCA for Anomaly Detection in IoT Networks","summary":"Although federated learning has gained prominence as a privacy-preserving\nframework tailored for distributed Internet of Things (IoT) environments,\ncurrent federated principal component analysis (PCA) methods lack integration\nof sparsity, a critical feature for robust anomaly detection. To address this\nlimitation, we propose a novel federated structured sparse PCA (FedSSP)\napproach for anomaly detection in IoT networks. The proposed model uniquely\nintegrates double sparsity regularization: (1) row-wise sparsity governed by\n$\\ell_{2,p}$-norm with $p\\in[0,1)$ to eliminate redundant feature dimensions,\nand (2) element-wise sparsity via $\\ell_{q}$-norm with $q\\in[0,1)$ to suppress\nnoise-sensitive components. To efficiently solve this non-convex optimization\nproblem in a distributed setting, we devise a proximal alternating minimization\n(PAM) algorithm with rigorous theoretical proofs establishing its convergence\nguarantees. Experiments on real datasets validate that incorporating structured\nsparsity enhances both model interpretability and detection accuracy.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-03-31T11:50:21Z"}
{"aid":"http://arxiv.org/abs/2503.23982v1","title":"Deep Nets as Hamiltonians","summary":"Neural networks are complex functions of both their inputs and parameters.\nMuch prior work in deep learning theory analyzes the distribution of network\noutputs at a fixed a set of inputs (e.g. a training dataset) over random\ninitializations of the network parameters. The purpose of this article is to\nconsider the opposite situation: we view a randomly initialized Multi-Layer\nPerceptron (MLP) as a Hamiltonian over its inputs. For typical realizations of\nthe network parameters, we study the properties of the energy landscape induced\nby this Hamiltonian, focusing on the structure of near-global minimum in the\nlimit of infinite width. Specifically, we use the replica trick to perform an\nexact analytic calculation giving the entropy (log volume of space) at a given\nenergy. We further derive saddle point equations that describe the overlaps\nbetween inputs sampled iid from the Gibbs distribution induced by the random\nMLP. For linear activations we solve these saddle point equations exactly. But\nwe also solve them numerically for a variety of depths and activation\nfunctions, including $\\tanh, \\sin, \\text{ReLU}$, and shaped non-linearities. We\nfind even at infinite width a rich range of behaviors. For some\nnon-linearities, such as $\\sin$, for instance, we find that the landscapes of\nrandom MLPs exhibit full replica symmetry breaking, while shallow $\\tanh$ and\nReLU networks or deep shaped MLPs are instead replica symmetric.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,cs.AI,cs.LG,math.PR","published":"2025-03-31T11:51:10Z"}
{"aid":"http://arxiv.org/abs/2503.24001v1","title":"Convergence of a finite volume scheme for a model for ants","summary":"We develop and analyse a finite volume scheme for a nonlocal active matter\nsystem known to exhibit a rich array of complex behaviours. The model under\ninvestigation was derived from a stochastic system of interacting particles\ndescribing a foraging ant colony coupled to pheromone dynamics. In this work,\nwe prove that the unique numerical solution converges to the unique weak\nsolution as the mesh size and the time step go to zero. We also show discrete\nlong-time estimates, which prove that certain norms are preserved for all\ntimes, uniformly in the mesh size and time step. In particular, we prove higher\nregularity estimates which provide an analogue of continuum parabolic higher\nregularity estimates. Finally, we numerically study the rate of convergence of\nthe scheme, and we provide examples of the existence of multiple metastable\nsteady states.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-03-31T12:23:49Z"}
{"aid":"http://arxiv.org/abs/2503.24010v1","title":"Roommates with Convex Preferences","summary":"Roommate problems with convex preferences always have stable matchings.\nEfficiency and individual rationality are, moreover, compatible with\nstrategyproofness in such convex roommate problems. Both of these results fail\nwithout the assumption of convexity. In the environment under study,\npreferences are convex if and only if they are single peaked. Any individually\nrational and convex roommate problem is homomorphic to a marriage market where\nan agent's gender corresponds to the direction of the agent's top-ranked\npartner. The existence of stable matchings then follows from the existence of\nstable matchings in marriage markets. To prove the second existence result, I\ndefine an efficient, individually rational, and strategyproof mechanism for\nconvex roommate problems. To calculate outcomes, this mechanism starts with all\nagents being single and then gradually reassigns agents to better partners by\nperforming minimal Pareto improvements. Whenever it becomes clear that some\nagent cannot be part of any further Pareto improvement, such an agent is\nmatched.","main_category":"econ.TH","categories":"econ.TH","published":"2025-03-31T12:36:48Z"}
{"aid":"http://arxiv.org/abs/2503.24034v1","title":"Creation of a black hole bomb instability in an electromagnetic system","summary":"The amplification and generation of electromagnetic radiation by a rotating\nmetallic or lossy cylinder, first theorized by Zeldovich in the 1970s, is\ntightly connected to the concepts of quantum friction, energy extraction from\nrotating black holes and runaway mechanisms such as black hole bombs. Despite\nrecent advances including acoustic analogues of the Zeldovich effect and the\nobservation of a negative resistance in a low-frequency electromagnetic model,\nactual positive signal amplitude gain, the spontaneous generation of\nelectromagnetic waves and runaway amplifi- cation effects have never been\nexperimentally verified. Here, we demonstrate experimentally that a\nmechanically rotating metallic cylinder not only definitively acts as an\namplifier of a rotating elec- tromagnetic field mode but also, when paired with\na low-loss resonator, becomes unstable and acts as a generator, seeded only by\nnoise. The system exhibits an exponential runaway amplification of\nspontaneously generated electromagnetic modes thus demonstrating the\nelectromagnetic analogue of Press and Teukolskys black hole bomb. The\nexponential amplification from noise supports theoretical investigations into\nblack hole instabilities and is promising for the development of future\nexperiments to observe quantum friction in the form of the Zeldovich effect\nseeded by the quantum vacuum.","main_category":"quant-ph","categories":"quant-ph,physics.app-ph,physics.ins-det","published":"2025-03-31T13:00:10Z"}
{"aid":"http://arxiv.org/abs/2503.24058v1","title":"Mechanical Squeezed Kerr Oscillator based on Tapered Ion Trap","summary":"We propose the realization of a mechanically squeezed Kerr oscillator with a\nsingle ion in a tapered trap. We show that the motion coupling between the\naxial and radial modes caused by the trap geometry leads to Kerr nonlinearity\nof the radial mode with magnitude controlled by the trap frequencies. This\nallows the realization of non-Gaussian quantum gates, which play a significant\nrole in the universal set of continuous variable quantum gates. Furthermore, we\nshow that, because of the nonlinearity of the ion trap, applying an\noff-resonant time-varying electric field along the trap axis causes a motion\nsqueezing of the radial mode. Finally, we discuss the motion mode frequency\nspectrum of an ion crystal in a tapered trap. We show that the frequency gap\nbetween the motion modes increases with trap nonlinearity, which benefits the\nrealization of faster quantum gates.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T13:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.24063v1","title":"A robot-assisted pipeline to rapidly scan 1.7 million historical aerial\n  photographs","summary":"During the 20th Century, aerial surveys captured hundreds of millions of\nhigh-resolution photographs of the earth's surface. These images, the\nprecursors to modern satellite imagery, represent an extraordinary visual\nrecord of the environmental and social upheavals of the 20th Century. However,\nmost of these images currently languish in physical archives where retrieval is\ndifficult and costly. Digitization could revolutionize access, but manual\nscanning is slow and expensive. Here, we describe and validate a novel\nrobot-assisted pipeline that increases worker productivity in scanning 30-fold,\napplied at scale to digitize an archive of 1.7 million historical aerial\nphotographs from 65 countries.","main_category":"eess.IV","categories":"eess.IV,cs.SY,econ.GN,eess.SY,q-fin.EC","published":"2025-03-31T13:23:05Z"}
{"aid":"http://arxiv.org/abs/2503.24072v1","title":"Estimation of thermal properties and boundary heat transfer coefficient\n  of the ground with a Bayesian technique","summary":"Urbanization is the key contributor for climate change. Increasing\nurbanization rate causes an urban heat island (UHI) effect, which strongly\ndepends on the short- and long-wave radiation balance heat flux between the\nsurfaces. In order to calculate accurately this heat flux, it is required to\nassess the surface temperature which depends on the knowledge of the thermal\nproperties and the surface heat transfer coefficients in the heat transfer\nproblem. The aim of this paper is to estimate the thermal properties of the\nground and the time varying surface heat transfer coefficient by solving an\ninverse problem. The Dufort--Frankel scheme is applied for solving the unsteady\nheat transfer problem. For the inverse problem, a Markov chain Monte Carlo\nmethod is used to estimate the posterior probability density function of\nunknown parameters within the Bayesian framework of statistics, by applying the\nMetropolis-Hastings algorithm for random sample generation. Actual temperature\nmeasurements available at different ground depths were used for the solution of\nthe inverse problem. Different time discretizations were examined for the\ntransient heat transfer coefficient at the ground surface, which then involved\ndifferent prior distributions. Results of different case studies show that the\nestimated values of the unknown parameters were in accordance with literature\nvalues. Moreover, with the present solution of the inverse problem the\ntemperature residuals were smaller than those obtained by using literature\nvalues for the unknowns.","main_category":"cs.CE","categories":"cs.CE,math-ph,math.MP,G.3","published":"2025-03-31T13:29:25Z"}
{"aid":"http://arxiv.org/abs/2503.24076v1","title":"On a question about real rooted polynomials and f-polynomials of\n  simplicial complexes","summary":"For a polynomial $f(t) = 1+f_0t+\\cdots +f_{d-1}t^d$ with positive integer\ncoefficients Bell and Skandera ask if real rootedness of f(t) implies that\nthere is a simplicial complex with f-vector $(1,f_0 \\ldots,f_{d-1})$. In this\npaper we discover properties implied by the real rootedness of f(t) in terms of\nthe binomial representation $f_i = \\binom{x_{i+1}}{i+1}, i \\geq 0$. We use\nthese to provide a sufficient criterion for a positive answer to the question\nby Bell and Skandera. We also describe two further approaches to the conjecture\nand use one to verify that some well studied real rooted classical polynomials\nare f-polynomials. Finally, we provide a series of results showing that the set\nof f-vectors of simplicial complexes is closed under constructions also\npreserving real rootedness of their generating polynomials.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T13:31:37Z"}
{"aid":"http://arxiv.org/abs/2503.24083v1","title":"Controlled Latent Diffusion Models for 3D Porous Media Reconstruction","summary":"Three-dimensional digital reconstruction of porous media presents a\nfundamental challenge in geoscience, requiring simultaneous resolution of\nfine-scale pore structures while capturing representative elementary volumes.\nWe introduce a computational framework that addresses this challenge through\nlatent diffusion models operating within the EDM framework. Our approach\nreduces dimensionality via a custom variational autoencoder trained in binary\ngeological volumes, improving efficiency and also enabling the generation of\nlarger volumes than previously possible with diffusion models. A key innovation\nis our controlled unconditional sampling methodology, which enhances\ndistribution coverage by first sampling target statistics from their empirical\ndistributions, then generating samples conditioned on these values. Extensive\ntesting on four distinct rock types demonstrates that conditioning on porosity\n- a readily computable statistic - is sufficient to ensure a consistent\nrepresentation of multiple complex properties, including permeability,\ntwo-point correlation functions, and pore size distributions. The framework\nachieves better generation quality than pixel-space diffusion while enabling\nsignificantly larger volume reconstruction (256-cube voxels) with substantially\nreduced computational requirements, establishing a new state-of-the-art for\ndigital rock physics applications.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.LG","published":"2025-03-31T13:36:55Z"}
{"aid":"http://arxiv.org/abs/2503.24113v1","title":"From Local to Remote: VisIVO Visual Analytics in the Era of the Square\n  Kilometre Array","summary":"The field of astrophysics is continuously advancing, with an ever-growing\ninflux of data requiring robust and efficient analysis tools. As the Square\nKilometre Array (SKA) radio telescopes come fully operational, we anticipate\nthe generation of hundreds of petabytes of data annually, characterized by\nunprecedented resolution and detail. In this context, scientific visualization\nbecomes a critical component, enabling researchers to interpret complex\ndatasets and extract meaningful insights. The immense volume of data demands\nnot only suitable tools but also substantial infrastructure and computational\ncapacity to analyze it effectively. In this work, we will discuss how we are\naddressing these challenges with the development of our interactive\nvisualization tool named VisIVO Visual Analytics. The tool is transitioning\nfrom a local visualizer to a remote visualizer, utilizing a client-server\narchitecture. This evolution will allow the software to run parallel\nvisualization pipelines on high-performance computing (HPC) clusters, thereby\nenhancing its capacity to handle extensive datasets efficiently.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T14:04:53Z"}
{"aid":"http://arxiv.org/abs/2503.24114v1","title":"Generic linearized curvature singularity at the perturbed Kerr Cauchy\n  horizon","summary":"We prove the precise asymptotics of the spin $-2$ Teukolsky field in the\ninterior and along the Cauchy horizon of a subextremal Kerr black hole.\nTogether with the oscillatory blow-up asymptotics of the spin $+2$ Teukolsky\nfield proven in our previous work arXiv:2409.02670, our result suggests that\ngeneric perturbations of a Kerr black hole build up to form a\ncoordinate-independent curvature singularity at the Cauchy horizon. This\nsupports the Strong Cosmic Censorship conjecture in Kerr spacetimes. Unlike in\nthe spin $+2$ case, the spin $-2$ Teukolsky field is regular on the Cauchy\nhorizon and the first term in its asymptotic development vanishes. As a result,\nthe derivation of a precise lower bound for the spin $-2$ field is more\ndelicate than in the spin $+2$ case, and relies on a novel ODE method based on\na decomposition of the Teukolsky operator between radial and time derivatives.","main_category":"gr-qc","categories":"gr-qc,math.AP","published":"2025-03-31T14:05:27Z"}
{"aid":"http://arxiv.org/abs/2503.24119v1","title":"Measuring User Experience Through Speech Analysis: Insights from HCI\n  Interviews","summary":"User satisfaction plays a crucial role in user experience (UX) evaluation.\nTraditionally, UX measurements are based on subjective scales, such as\nquestionnaires. However, these evaluations may suffer from subjective bias. In\nthis paper, we explore the acoustic and prosodic features of speech to\ndifferentiate between positive and neutral UX during interactive sessions. By\nanalyzing speech features such as root-mean-square (RMS), zero-crossing\nrate(ZCR), jitter, and shimmer, we identified significant differences between\nthe positive and neutral user groups. In addition, social speech features such\nas activity and engagement also show notable variations between these groups.\nOur findings underscore the potential of speech analysis as an objective and\nreliable tool for UX measurement, contributing to more robust and\nbias-resistant evaluation methodologies. This work offers a novel approach to\nintegrating speech features into UX evaluation and opens avenues for further\nresearch in HCI.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T14:07:38Z"}
{"aid":"http://arxiv.org/abs/2503.24123v1","title":"CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic\n  Learning","summary":"Many computational tasks benefit from being formulated as the composition of\nneural networks followed by a discrete symbolic program. The goal of\nneurosymbolic learning is to train the neural networks using only end-to-end\ninput-output labels of the composite. We introduce CTSketch, a novel, scalable\nneurosymbolic learning algorithm. CTSketch uses two techniques to improve the\nscalability of neurosymbolic inference: decompose the symbolic program into\nsub-programs and summarize each sub-program with a sketched tensor. This\nstrategy allows us to approximate the output distribution of the program with\nsimple tensor operations over the input distributions and summaries. We provide\ntheoretical insight into the maximum error of the approximation. Furthermore,\nwe evaluate CTSketch on many benchmarks from the neurosymbolic literature,\nincluding some designed for evaluating scalability. Our results show that\nCTSketch pushes neurosymbolic learning to new scales that have previously been\nunattainable by obtaining high accuracy on tasks involving over one thousand\ninputs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T14:08:58Z"}
{"aid":"http://arxiv.org/abs/2503.24136v1","title":"Numerical simulation of Generalized Hermite Processes","summary":"Hermite processes are paradigmatic examples of stochastic processes which can\nbelong to any Wiener chaos of an arbitrary order; the wellknown fractional\nBrownian motion belonging to the Gaussian first order Wiener chaos and the\nRosenblatt process belonging to the non-Gaussian second order Wiener chaos are\ntwo particular cases of them. Except these two particular cases no simulation\nmethod for sample paths of Hermite processes is available so far. The goal of\nour article is to introduce a new method which potentially allows to simulate\nsample paths of any Hermite process and even those of any generalized Hermite\nprocess. Our starting point is the representation for the latter process as\nrandom wavelet-typeseries, obtained in our very recent paper [3]. We construct\nfrom it a \"concrete\" sequence of piecewise linear continuous random functions\nwhich almost surely approximate sample paths of this process for the uniform\nnorm on any compact interval, and we provide an almost sure estimate of the\napproximation error. Then, for the Rosenblatt process and more importantly for\nthe third order Hermite process, we propose algorithms allowing to implement\nthis sequence and we illustrate them by several simulations. Python routines\nimplementing these synthesis procedures are available upon request.","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T14:18:42Z"}
{"aid":"http://arxiv.org/abs/2503.24146v1","title":"Joint Modeling of Multiple Longitudinal Biomarkers and Survival Outcomes\n  via Threshold Regression: Variability as a Predictor","summary":"Longitudinal biomarker data and health outcomes are routinely collected in\nmany studies to assess how biomarker trajectories predict health outcomes.\nExisting methods primarily focus on mean biomarker profiles, treating\nvariability as a nuisance. However, excess variability may indicate system\ndysregulations that may be associated with poor outcomes. In this paper, we\naddress the long-standing problem of using variability information of multiple\nlongitudinal biomarkers in time-to-event analyses by formulating and studying a\nBayesian joint model. We first model multiple longitudinal biomarkers, some of\nwhich are subject to limit-of-detection censoring. We then model the survival\ntimes by incorporating random effects and variances from the longitudinal\ncomponent as predictors through threshold regression that admits\nnon-proportional hazards. We demonstrate the operating characteristics of the\nproposed joint model through simulations and apply it to data from the Study of\nWomen's Health Across the Nation (SWAN) to investigate the impact of the mean\nand variability of follicle-stimulating hormone (FSH) and anti-Mullerian\nhormone (AMH) on age at the final menstrual period (FMP).","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T14:33:04Z"}
{"aid":"http://arxiv.org/abs/2503.24151v1","title":"Robust Feedback Optimization with Model Uncertainty: A Regularization\n  Approach","summary":"Feedback optimization optimizes the steady state of a dynamical system by\nimplementing optimization iterations in closed loop with the plant. It relies\non online measurements and limited model information, namely, the input-output\nsensitivity. In practice, various issues including inaccurate modeling, lack of\nobservation, or changing conditions can lead to sensitivity mismatches, causing\nclosed-loop sub-optimality or even instability. To handle such uncertainties,\nwe pursue robust feedback optimization, where we optimize the closed-loop\nperformance against all possible sensitivities lying in specific uncertainty\nsets. We provide tractable reformulations for the corresponding min-max\nproblems via regularizations and characterize the online closed-loop\nperformance through the tracking error in case of time-varying optimal\nsolutions. Simulations on a distribution grid illustrate the effectiveness of\nour robust feedback optimization controller in addressing sensitivity\nmismatches in a non-stationary environment.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T14:36:25Z"}
{"aid":"http://arxiv.org/abs/2503.24172v1","title":"Pseudo-Random UAV Test Generation Using Low-Fidelity Path Simulator","summary":"Simulation-based testing provides a safe and cost-effective environment for\nverifying the safety of Uncrewed Aerial Vehicles (UAVs). However, simulation\ncan be resource-consuming, especially when High-Fidelity Simulators (HFS) are\nused. To optimise simulation resources, we propose a pseudo-random test\ngenerator that uses a Low-Fidelity Simulator (LFS) to estimate UAV flight\npaths. This work simplifies the PX4 autopilot HFS to develop a LFS, which\noperates one order of magnitude faster than the HFS.Test cases predicted to\ncause safety violations in the LFS are subsequently validated using the HFS.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T14:50:46Z"}
{"aid":"http://arxiv.org/abs/2503.24188v1","title":"A Swift analysis of the Eras tour set list and implications for\n  astrophysics research (Taylor's version)","summary":"Popular culture plays a significant role in shaping public interest in\nscience, and Taylor Swift's discography frequently incorporates astrophysics\nterminology. This study examines the occurrence of astrophysics-related words\nin her lyrics and their representation in the Eras tour set list. By analyzing\nthe frequency of words in Swift's total discography, we identify that\nastrophysics is promoted the most within her most recent album, The Tortured\nPoets Department, whereas songs from Midnights promoted astrophysics the most\nthroughout the Eras tour. We catagorize words into various disciplines of\nastrophysics and find that multimessenger astronomy is promoted the most, both\nin Swift's total discography and throughout the Eras tour. We perform Taylor\nexpansion and predict $12 \\pm 5$ astrophysical terms in Swift's next album.\nThis analysis offers a unique perspective on the intersection of music and\nscience, revealing how Swift's artistry may unintentionally promote interest in\ndifferent fields of astrophysics.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO,astro-ph.IM,astro-ph.SR,physics.ed-ph,physics.soc-ph","published":"2025-03-31T15:05:48Z"}
{"aid":"http://arxiv.org/abs/2503.24189v1","title":"Quantum superalgebras and the free-fermionic Yang-Baxter equation","summary":"The free-fermion point refers to a\n$\\operatorname{GL}(2)\\times\\operatorname{GL}(1)$ parametrized Yang-Baxter\nequation within the six-vertex model. It has been known for a long time that\nthis is connected with the quantum group $U_q(\\mathfrak{gl}(1|1))$. We\ndemonstrate that $R$-matrices from the finite quantum superalgebra\n$U_q(\\mathfrak{gl}(1|1))$ recovers a dense subset of the free-fermion point of\nthe six-vertex model and recover the prime, simple modules in the affine\nquantum superalgebra $U_q(\\widehat{\\mathfrak{gl}}(1|1))$. Either of these\nquantum groups can be used to generate the full free-fermion point, and we\ndiscuss them both. Our discussion includes 6 families of six-vertex models used\nby Brubaker, Bump, and Friedberg in connection with Tokuyama's theorem, a\ndeformation of the Weyl character formula. Thus our work gives quantum group\ninterpretations for those models, known informally as Tokuyama ice.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-03-31T15:06:50Z"}
{"aid":"http://arxiv.org/abs/2503.24207v1","title":"Definability of mad families of vector spaces and two local Ramsey\n  theories","summary":"Let $E$ be a vector space over a countable field of dimension $\\aleph_0$. Two\ninfinite-dimensional subspaces $V,W \\subseteq E$ are almost disjoint if $V \\cap\nW$ is finite-dimensional. This paper provides some improvements on results\nabout the definability of maximal almost disjoint families (mad families) of\nsubspaces in [17]. We show that a full mad family of block subspaces exists\nassuming either $\\frak{p} = \\max\\{\\frak{b},\\frak{s}\\}$ or a positive answer to\na problem in [17], improving Smythe's construction assuming $\\frak{p} =\n\\frak{c}$. We also discuss the abstract Mathias forcing introduced by Di\nPrisco-Mijares-Nieto in [11], and apply it to show that in the Solovay's model\nobtained by the collapse of a Mahlo cardinal, there are no full mad families of\nblock subspaces over $\\mathbb{F}_2$.","main_category":"math.LO","categories":"math.LO","published":"2025-03-31T15:24:19Z"}
{"aid":"http://arxiv.org/abs/2503.24212v1","title":"Characterization of $\\PSL(2,q)$ by the number of singular elements","summary":"Given a finite group $G$, let $\\pi(G)$ denote the set of all primes that\ndivide the order of $G$. For a prime $r \\in \\pi(G)$, we define $r$-singular\nelements as those elements of $G$ whose order is divisible by $r$. Denote by\n$S_r(G)$ the number of $r$-singluar elements of $G$. We denote the proportion\n$S_r(G)/|G|$ of $r$-singular elements in $G$ by ${\\mu_r}(G)$. Let $\\mu(G) :=\n{\\{\\mu_r}(G) | r\\in \\pi(G)\\}$ be the set of all proportions of $r$-singular\nelements for each prime $r$ in $\\pi(G)$. In this paper, we prove that if a\nfinite group $G$ has the same set $\\mu(G)$ as the simple group $\\PSL(2,q)$,\nthen $G$ is isomorphic to $\\PSL(2,q)$.","main_category":"math.GR","categories":"math.GR","published":"2025-03-31T15:30:34Z"}
{"aid":"http://arxiv.org/abs/2503.24226v1","title":"Asymptotic Freedom and Finite-size Scaling of Two-dimensional Classical\n  Heisenberg Model","summary":"The classical Heisenberg model is one of the most fundamental models in\nstatistical and condensed matter physics. Extensive theoretical and numerical\nstudies suggest that, in two dimensions, this model does not exhibit a\nfinite-temperature phase transition but instead manifests asymptotic freedom.\nHowever, some research has also proposed the possibility of a\nBerezinskii-Kosterlitz-Thouless (BKT) phase transition over the years. In this\nstudy, we revisit the classical two-dimensional (2D) Heisenberg model through\nlarge-scale simulations with linear system sizes up to $L=16384$. Our\nMonte-Carlo data, without any extrapolation, clearly reveal an exponential\ndivergence of the correlation length $\\xi$ as a function of inverse temperature\n$\\beta$, a hallmark of asymptotic freedom. Moreover, extrapolating $\\xi$ to the\nthermodynamic limit in the low-temperature regime achieves close agreement with\nthe three-loop perturbative calculations. We further propose a finite-size\nscaling (FSS) ansatz for $\\xi$, demonstrating that the pseudo-critical point\n$\\beta_L$ diverges logarithmically with $L$. The thermodynamic and finite-size\nscaling behaviors of the magnetic susceptibility $\\chi$ are also investigated\nand corroborate the prediction of asymptotic freedom. Our work provides solid\nevidence for asymptotic freedom in the 2D Heisenberg model and advances\nunderstanding of finite-size scaling in such systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T15:39:13Z"}
{"aid":"http://arxiv.org/abs/2503.24227v1","title":"Ambient and high pressure studies of structural, electronic and magnetic\n  properties of EuZn$_2$P$_2$ single crystal","summary":"A thorough study of EuZn$_2$P$_2$ single crystals, which were grown from Sn\nflux, was performed using both bulk (heat capacity, ac susceptibility, dc\nmagnetization, electrical resistivitivity, magnetoresistance) and microscopic\n(M\\\"ossbauer spectroscopy) techniques. Electrical resistance and magnetic\nsusceptibility were measured also under high pressure conditions (up to 19 GPa\nand 9.5 GPa, respectively). Further insight into electronic properties and\nphonons is provided by ab initio calculations. The results indicate that\nEuZn$_2$P$_2$ is an antiferromagnet with strong Eu-Eu exchange coupling of\nferromagnetic type within the basal plane and weaker antiferromagnetic\ninteraction along the c axis. The Eu magnetic moments are tilted from the basal\nplane. Hydrostatic pressure strongly affects both magnetic (increase of the\nN\\'eel temperature) and electronic (suppression of the band gap and semi\nmetallic behavior) properties, indicating a strong interplay of structure with\nmagnetic and electronic degrees of freedom.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T15:40:30Z"}
{"aid":"http://arxiv.org/abs/2503.24236v1","title":"Estimating a graph's spectrum via random Kirchhoff forests","summary":"Exact eigendecomposition of large matrices is very expensive, and it is\npractically impossible to compute exact eigenvalues. Instead, one may set a\nmore modest goal of approaching the empirical distribution of the eigenvalues,\nrecovering the overall shape of the eigenspectrum. Current approaches to\nspectral estimation typically work with \\emph{moments} of the spectral\ndistribution. These moments are first estimated using Monte Carlo trace\nestimators, then the estimates are combined to approximate the spectral\ndensity. In this article we show how \\emph{Kirchhoff forests}, which are random\nforests on graphs, can be used to estimate certain non-linear moments of very\nlarge graph Laplacians. We show how to combine these moments into an estimate\nof the spectral density. If the estimate's desired precision isn't too high,\nour approach paves the way to the estimation of a graph's spectrum in time\nsublinear in the number of links.","main_category":"stat.CO","categories":"stat.CO,math.ST,stat.TH","published":"2025-03-31T15:47:55Z"}
{"aid":"http://arxiv.org/abs/2503.24238v1","title":"PhD Thesis: Shifted Contact Structures on Differentiable Stacks","summary":"This thesis focuses on developing \"stacky\" versions of contact structures,\nextending the classical notion of contact structures on manifolds. A fruitful\napproach is to study contact structures using line bundle-valued $1$-forms.\nSpecifically, we introduce the notions of $0$ and $+1$-shifted contact\nstructures on Lie groupoids. To define the kernel of a line bundle-valued\n$1$-form $\\theta$ on a Lie groupoid, we draw inspiration from the concept of\nthe homotopy kernel in Homological Algebra. That kernel is essentially given by\na representation up to homotopy (RUTH). Similarly, the curvature is described\nby a specific RUTH morphism. Both the definitions are motivated by the\nSymplectic-to-Contact Dictionary, which establishes a relationship between\nSymplectic and Contact Geometry. Examples of $0$-shifted contact structures can\nbe found in contact structures on orbifolds, while examples of $+1$-shifted\ncontact structures include the prequantization of $+1$-shifted symplectic\nstructures and the integration of Dirac-Jacobi structures.","main_category":"math.DG","categories":"math.DG,math-ph,math.MP,math.SG","published":"2025-03-31T15:52:35Z"}
{"aid":"http://arxiv.org/abs/2503.24245v1","title":"Enhancing Large Language Models (LLMs) for Telecommunications using\n  Knowledge Graphs and Retrieval-Augmented Generation","summary":"Large language models (LLMs) have made significant progress in\ngeneral-purpose natural language processing tasks. However, LLMs are still\nfacing challenges when applied to domain-specific areas like\ntelecommunications, which demands specialized expertise and adaptability to\nevolving standards. This paper presents a novel framework that combines\nknowledge graph (KG) and retrieval-augmented generation (RAG) techniques to\nenhance LLM performance in the telecom domain. The framework leverages a KG to\ncapture structured, domain-specific information about network protocols,\nstandards, and other telecom-related entities, comprehensively representing\ntheir relationships. By integrating KG with RAG, LLMs can dynamically access\nand utilize the most relevant and up-to-date knowledge during response\ngeneration. This hybrid approach bridges the gap between structured knowledge\nrepresentation and the generative capabilities of LLMs, significantly enhancing\naccuracy, adaptability, and domain-specific comprehension. Our results\ndemonstrate the effectiveness of the KG-RAG framework in addressing complex\ntechnical queries with precision. The proposed KG-RAG model attained an\naccuracy of 88% for question answering tasks on a frequently used\ntelecom-specific dataset, compared to 82% for the RAG-only and 48% for the\nLLM-only approaches.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T15:58:08Z"}
{"aid":"http://arxiv.org/abs/2503.24257v1","title":"Mathematical foundations of information economics","summary":"The state of economic theory and accumulated facts from the different\nbranches of the economic science require to analyze the concept of the\ndescription of economy systems. The economic reality generates the problems the\nsolution of that is only possible by a new paradigm of the description of\neconomy system. The classical mathematical economics is based on a notion of\nthe rational consumer choice generated by a certain preference relation on some\nset of goods a consumer wanted and the concept of maximization of the firm\nprofit. The sense of the notion of the ratio- nal consumer choice is that it is\ndetermined by a certain utility function, defining the choice of a consumer by\nmaximization of it on a certain budget set of goods. More- over, choices of\nconsumers are independent. In the reality choices of consumers are not\nindependent because they depend on the firms supply. Except the firms supply,\nthe consumer choice is also determined by information about the state of the\neconomy system that the consumer has and respectively eval- uates at the moment\nof the choice. In turn, the firms supply is made on the basis of needs of the\nconsumers and their buying power. By information about the state of the economy\nsystem we understand a certain information about the equilibrium price vector\nand productive processes realized in the economy system under the equilibrium\nprice vector.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-03-31T16:05:39Z"}
{"aid":"http://arxiv.org/abs/2503.24259v1","title":"Advances in Continual Graph Learning for Anti-Money Laundering Systems:\n  A Comprehensive Review","summary":"Financial institutions are required by regulation to report suspicious\nfinancial transactions related to money laundering. Therefore, they need to\nconstantly monitor vast amounts of incoming and outgoing transactions. A\nparticular challenge in detecting money laundering is that money launderers\ncontinuously adapt their tactics to evade detection. Hence, detection methods\nneed constant fine-tuning. Traditional machine learning models suffer from\ncatastrophic forgetting when fine-tuning the model on new data, thereby\nlimiting their effectiveness in dynamic environments. Continual learning\nmethods may address this issue and enhance current anti-money laundering (AML)\npractices, by allowing models to incorporate new information while retaining\nprior knowledge. Research on continual graph learning for AML, however, is\nstill scarce. In this review, we critically evaluate state-of-the-art continual\ngraph learning approaches for AML applications. We categorise methods into\nreplay-based, regularization-based, and architecture-based strategies within\nthe graph neural network (GNN) framework, and we provide in-depth experimental\nevaluations on both synthetic and real-world AML data sets that showcase the\neffect of the different hyperparameters. Our analysis demonstrates that\ncontinual learning improves model adaptability and robustness in the face of\nextreme class imbalances and evolving fraud patterns. Finally, we outline key\nchallenges and propose directions for future research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T16:06:47Z"}
{"aid":"http://arxiv.org/abs/2503.24270v1","title":"Visual Acoustic Fields","summary":"Objects produce different sounds when hit, and humans can intuitively infer\nhow an object might sound based on its appearance and material properties.\nInspired by this intuition, we propose Visual Acoustic Fields, a framework that\nbridges hitting sounds and visual signals within a 3D space using 3D Gaussian\nSplatting (3DGS). Our approach features two key modules: sound generation and\nsound localization. The sound generation module leverages a conditional\ndiffusion model, which takes multiscale features rendered from a\nfeature-augmented 3DGS to generate realistic hitting sounds. Meanwhile, the\nsound localization module enables querying the 3D scene, represented by the\nfeature-augmented 3DGS, to localize hitting positions based on the sound\nsources. To support this framework, we introduce a novel pipeline for\ncollecting scene-level visual-sound sample pairs, achieving alignment between\ncaptured images, impact locations, and corresponding sounds. To the best of our\nknowledge, this is the first dataset to connect visual and acoustic signals in\na 3D context. Extensive experiments on our dataset demonstrate the\neffectiveness of Visual Acoustic Fields in generating plausible impact sounds\nand accurately localizing impact sources. Our project page is at\nhttps://yuelei0428.github.io/projects/Visual-Acoustic-Fields/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T16:16:10Z"}
{"aid":"http://arxiv.org/abs/2503.24275v1","title":"Davenport-Heilbronn Function Ratio Properties and Non-Trivial Zeros\n  Study","summary":"This paper systematically investigates the analytic properties of the ratio\n$f(s)/f(1-s) = X(s)$ based on the Davenport-Heilbronn functional equation $f(s)\n= X(s)f(1-s)$. We propose a novel method to analyze the distribution of\nnon-trivial zeros through the monotonicity of the ratio $|f(s)/f(1-s)|$.\nRigorously proving that non-trivial zeros can only lie on the critical line\n$\\sigma=1/2$, we highlight two groundbreaking findings: 1. Contradiction of\nOff-Critical Zeros: Numerical \"exceptional zeros\" (e.g., Spira, 1994) violate\nthe theoretical threshold $\\kappa=1.21164$ and conflict with the monotonicity\nconstraint of $|X(s)|=1$. 2. Essential Difference Between Approximate and\nStrict Zeros: Points satisfying $f(s) \\to 0$ do not constitute strict zeros\nunless verified by analyticity. This work provides a new perspective for\nstudying zero distributions of $L$-functions related to the Riemann Hypothesis.","main_category":"math.NT","categories":"math.NT,math.AP","published":"2025-03-31T16:21:38Z"}
{"aid":"http://arxiv.org/abs/2503.24290v1","title":"Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement\n  Learning on the Base Model","summary":"We introduce Open-Reasoner-Zero, the first open source implementation of\nlarge-scale reasoning-oriented RL training focusing on scalability, simplicity\nand accessibility. Through extensive experiments, we demonstrate that a\nminimalist approach, vanilla PPO with GAE ($\\lambda=1$, $\\gamma=1$) and\nstraightforward rule-based rewards, without any KL regularization, is\nsufficient to scale up both response length and benchmark performance, similar\nto the phenomenon observed in DeepSeek-R1-Zero. Using the same base model as\nDeepSeek-R1-Zero-Qwen-32B, our implementation achieves superior performance on\nAIME2024, MATH500, and the GPQA Diamond benchmark while demonstrating\nremarkable efficiency -- requiring only a tenth of the training steps, compared\nto DeepSeek-R1-Zero pipeline. In the spirit of open source, we release our\nsource code, parameter settings, training data, and model weights across\nvarious sizes.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-03-31T16:36:05Z"}
{"aid":"http://arxiv.org/abs/2503.24294v1","title":"Nonlinear-elasticity models with surface energy","summary":"Soft solids with surface energy exhibit complex mechanical behavior,\nnecessitating advanced constitutive models to capture the interplay between\nbulk and surface mechanics. This interplay has profound implications for\nmaterial design and emerging technologies. In this work, we set up variational\nmodels for bulk-surface elasticity and explore a novel class of\nsurface-polyconvex constitutive models that account for surface energy while\nensuring the existence of minimizers. These models are implemented within a\nfinite element framework and validated through benchmark problems and\napplications, including, e.g., the liquid bridge problem and the\nRayleigh-Plateau instability, for which the surface energy plays the dominant\nrole. The results demonstrate the ability of surface-polyconvex models to\naccurately capture surface-driven phenomena, establishing them as a powerful\ntool for advancing the mechanics of soft materials in both engineering and\nbiological applications.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-03-31T16:41:37Z"}
{"aid":"http://arxiv.org/abs/2503.24302v1","title":"Synergy of Doob Transformation and Montroll Defect Theory for Random\n  Walks in External Potentials","summary":"We present a systematic method for constructing stochastic processes by\nmodifying simpler, analytically solvable random walks on discrete lattices. Our\nframework integrates the Doob $h$-transformation with the Montroll defect\ntheory, overcoming the strict constraints associated with each method alone. By\ncombining these two approaches, we map random walks in simple potentials onto\nprocesses involving more general external potentials and metastable states.\nExplicit analytical expressions relate the transformed process to the original\none, facilitating direct investigation of exponential decay rates and\nadditional dynamical modes. As an illustrative example, we demonstrate our\nmethod by analyzing a random walker in a linear potential modified to include a\nmetastable state, revealing distinct exponential decay regimes relevant to\nescape dynamics.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T16:47:14Z"}
{"aid":"http://arxiv.org/abs/2503.24307v1","title":"A Systematic Evaluation of LLM Strategies for Mental Health Text\n  Analysis: Fine-tuning vs. Prompt Engineering vs. RAG","summary":"This study presents a systematic comparison of three approaches for the\nanalysis of mental health text using large language models (LLMs): prompt\nengineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA\n3, we evaluate these approaches on emotion classification and mental health\ncondition detection tasks across two datasets. Fine-tuning achieves the highest\naccuracy (91% for emotion classification, 80% for mental health conditions) but\nrequires substantial computational resources and large training sets, while\nprompt engineering and RAG offer more flexible deployment with moderate\nperformance (40-68% accuracy). Our findings provide practical insights for\nimplementing LLM-based solutions in mental health applications, highlighting\nthe trade-offs between accuracy, computational requirements, and deployment\nflexibility.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-03-31T16:54:04Z"}
{"aid":"http://arxiv.org/abs/2503.24317v1","title":"Thermodynamic Features of a Heat Engine Coupled with Exponentially\n  Decreasing Temperature Across the Reaction Coordinate, as well as\n  Perspectives on Nonequilibrium Thermodynamics","summary":"In this study, we advance the understanding of non-equilibrium systems by\nderiving thermodynamic relations for a heat engine operating under an\nexponentially decreasing temperature profile. Such thermal configurations\nclosely mimic spatially localized heating such as laser-induced thermal\ngradients. Using exact analytical solutions, we show that this arrangement\nresults in significantly higher velocity, entropy production, and extraction\nrates than piecewise thermal profiles, while exhibiting reduced irreversibility\nand complexity relative to linear or quadratic gradients. We further examine\nthe thermodynamic behavior of the Brownian particles in the networks. Our study\nreveals that the velocity and entropy production rates remain independent of\nnetwork size; on the contrary, extensive quantities such as total entropy\ndepend on the number of microstates. Additionally, we show that a Brownian\nparticle in a ratchet potential with spatially varying temperature achieves\ndirected motion, even without external forces driven by solely thermal\nasymmetry. These findings highlight the critical role of temperature asymmetry\nin controlling the transport processes and optimizing the particle dynamics.\nThis in turn will have promising applications in microfluidic devices and\nnanoscale sensors. Finally, we explore the influence of the system parameters\non the efficiency and performance of the heat engine. The exponential\ntemperature profiles enable faster velocities while simultaneously exhibiting\nhigher efficiency compared with other thermal arrangements. Moreover, by\naddressing key questions on entropy production, we provide insights into the\ntransition between nonequilibrium and equilibrium systems and contribute tools\nfor optimizing energy-efficient systems in both natural and engineered\nsettings.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T17:07:01Z"}
{"aid":"http://arxiv.org/abs/2503.24318v1","title":"Quantum Conference Key Agreement with Classical Advantage Distillation","summary":"In this work, we prove security of a quantum conference key agreement (QCKA)\nprotocol augmented with a classical advantage distillation (CAD) protocol. We\nderive a proof of security, in the finite key setting, that is able to bound\nthe secure key rate for any general, coherent, attack. We evaluate the\nperformance of the system, showing our result can improve the noise tolerance\nof the protocol in some, but not all, scenarios.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:07:36Z"}
{"aid":"http://arxiv.org/abs/2503.24319v1","title":"Resolving the baryon assymmetry with RATS","summary":"Current leading theories of physics such as the Big Bang, the standard model\nof particle physics, and general relativity suggest that the universe should\ncontain an equal amount of matter and antimatter. Yet observations have found a\ndisproportionately large amount of matter, a phenomenon known as the baryon\nassymmetry problem. Since century-old established theories are traditionally\nimpossible to refute, the only possible explanation is that the remaining\nantimatter is hidden in plain sight and remains to be observed. We propose the\nexistence of anti-stars to solve the baryon assymetry in our new Reasonable\nAntimatter Theory of Stars (RATS). In this context, the RATS will create a\nframework to resolve the traditional tension between observers and theorists,\nand thus contribute to the peaceful and collaborative spirit of astronomy. Our\nmethod is the firing of neurons in our brains, typically known as a thought\nexperiment. We still have no idea why or how this works, but it must be good\nbecause most of science was created this way. Our results are the result of our\nmethods, which result in some text and the resulting conclusions. In order to\nencourage the reader to reach the end of this short paper, we do not want to\nspoil the conclusions here. Instead, the conclusions will conclude the paper.","main_category":"physics.pop-ph","categories":"physics.pop-ph,astro-ph.CO,astro-ph.SR","published":"2025-03-31T17:07:37Z"}
{"aid":"http://arxiv.org/abs/2503.24341v1","title":"Chemically Tuning Room Temperature Pulsed Optically Detected Magnetic\n  Resonance","summary":"Optical detection of magnetic resonance enables spin-based quantum sensing\nwith high spatial resolution and sensitivity-even at room temperature-as\nexemplified by solid-state defects. Molecular systems provide a complementary,\nchemically tunable, platform for room-temperature optically detected magnetic\nresonance (ODMR)-based quantum sensing. A critical parameter governing sensing\nsensitivity is the optical contrast-i.e., the difference in emission between\ntwo spin states. In state-of-the-art solid-state defects such as the\nnitrogen-vacancy center in diamond, this contrast is approximately 30%. Here,\ncapitalizing on chemical tunability, we show that room-temperature ODMR\ncontrasts of 40% can be achieved in molecules. Using a nitrogen-substituted\nanalogue of pentacene (6,13-diazapentacene), we enhance contrast compared to\npentacene and, by determining the triplet kinetics through time-dependent\npulsed ODMR, show how this arises from accelerated anisotropic intersystem\ncrossing. Furthermore, we translate high-contrast room-temperature pulsed ODMR\nto self-assembled nanocrystals. Overall, our findings highlight the synthetic\nhandles available to optically readable molecular spins and the opportunities\nto capitalize on chemical tunability for room-temperature quantum sensing.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph","published":"2025-03-31T17:25:46Z"}
{"aid":"http://arxiv.org/abs/2503.24359v1","title":"Unveiling the Fast Acceleration of AGN-Driven Winds at Kiloparsec Scales","summary":"Supermassive black holes at the centre of galaxies gain mass through\naccretion disks. Models predict that quasi-spherical winds, expelled by the\nblack hole during active accretion phases, have a key role in shaping galaxy\nevolution by regulating star formation, the distribution of metals over\nkiloparsec scales, and by sweeping ambient gas to the outskirts and beyond of\ngalaxies. Nonetheless, the mechanism driving these outflows and the amount of\nenergy exchanged between the wind and the galaxy's interstellar medium remain\nunclear. Here, we present a detailed analysis of the kinematical properties of\nwinds in a sample of nearby active galaxies using the novel kinematic tool\nMOKA3D, which takes into account the clumpy nature of the ISM. We find\nremarkable similarities among the properties of the outflows in all the\ngalaxies examined. In particular, we provide the first evidence that outflows\nexhibit a regular trend in radial velocity, initially constant or slightly\ndecreasing, followed by rapid acceleration starting at approximately 1 kpc from\nthe nucleus, despite the seemingly complex kinematics observed. The observed\nbehavior aligns with our current theoretical understanding of Active Galactic\nNuclei outflows, where a momentum-driven phase transitions to an\nenergy-conserving phase just beyond approximately 1 kpc. The constant velocity\nof the momentum-driven wind is then rapidly accelerated following the\ninefficient Compton cooling of post-shock material and the transition to energy\nconservation. The measured radial terminal velocities of the outflows are\nalways larger than the escape velocities from the host galaxies, confirming the\nkey role of outflows in shaping the galaxy properties and evolution, as a\nmanifestation of AGN feedback. Our results, only made possible by our novel\nkinematic analysis tool, are crucial to understand the origin and the powering\nmechanism of these winds.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T17:37:44Z"}
{"aid":"http://arxiv.org/abs/2503.24365v1","title":"Which LIME should I trust? Concepts, Challenges, and Solutions","summary":"As neural networks become dominant in essential systems, Explainable\nArtificial Intelligence (XAI) plays a crucial role in fostering trust and\ndetecting potential misbehavior of opaque models. LIME (Local Interpretable\nModel-agnostic Explanations) is among the most prominent model-agnostic\napproaches, generating explanations by approximating the behavior of black-box\nmodels around specific instances. Despite its popularity, LIME faces challenges\nrelated to fidelity, stability, and applicability to domain-specific problems.\nNumerous adaptations and enhancements have been proposed to address these\nissues, but the growing number of developments can be overwhelming,\ncomplicating efforts to navigate LIME-related research. To the best of our\nknowledge, this is the first survey to comprehensively explore and collect\nLIME's foundational concepts and known limitations. We categorize and compare\nits various enhancements, offering a structured taxonomy based on intermediate\nsteps and key issues. Our analysis provides a holistic overview of advancements\nin LIME, guiding future research and helping practitioners identify suitable\napproaches. Additionally, we provide a continuously updated interactive website\n(https://patrick-knab.github.io/which-lime-to-trust/), offering a concise and\naccessible overview of the survey.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T17:44:39Z"}
{"aid":"http://arxiv.org/abs/2504.01325v1","title":"Coarse chain recurrence, Morse graphs with finite errors, and\n  persistence of circulations","summary":"In flow control, finite energy may be injected to push out material trapped\nin the attractor and to eliminate stagnation and circulate the flow. To\ndescribe such phenomena and to give a lower bound on the energy required, we\ngeneralize the existing concepts of chain recurrence. In fact, this paper\nintroduces concepts of ``coarse chain recurrences'' and Morse graphs with\nfinite errors. Using these concepts, we describe toy models of escape from\nattracting basins and elimination of stagnation by controls using finite\nenergy, persistence of recurrent points, and singular limit behaviors where\nenergy injections go to zero. Furthermore, we construct filtrations associated\nwith dynamical systems, which indicate the persistence of circulations.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T03:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.01339v1","title":"Computing Time-varying Network Reliability using Binary Decision\n  Diagrams","summary":"Computing the reliability of a time-varying network, taking into account its\ndynamic nature, is crucial for networks that change over time, such as space\nnetworks, vehicular ad-hoc networks, and drone networks. These networks are\nmodeled using temporal graphs, in which each edge is labeled with a time\nindicating its existence at a specific point in time. The time-varying network\nreliability is defined as the probability that a data packet from the source\nvertex can reach the terminal vertex, following links with increasing time\nlabels (i.e., a journey), while taking into account the possibility of network\nlink failures. Currently, the existing method for calculating this reliability\ninvolves explicitly enumerating all possible journeys between the source and\nterminal vertices and then calculating the reliability using the sum of\ndisjoint products method. However, this method has high computational\ncomplexity. In contrast, there is an efficient algorithm that uses binary\ndecision diagrams (BDDs) to evaluate the reliability of a network whose\ntopology does not change over time. This paper presents an efficient exact\nalgorithm that utilizes BDDs for computing the time-varying network\nreliability. Experimental results show that the proposed method runs faster\nthan the existing method up to four orders of magnitude.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T03:58:50Z"}
{"aid":"http://arxiv.org/abs/2504.01346v1","title":"GTR: Graph-Table-RAG for Cross-Table Question Answering","summary":"Beyond pure text, a substantial amount of knowledge is stored in tables. In\nreal-world scenarios, user questions often require retrieving answers that are\ndistributed across multiple tables. GraphRAG has recently attracted much\nattention for enhancing LLMs' reasoning capabilities by organizing external\nknowledge to address ad-hoc and complex questions, exemplifying a promising\ndirection for cross-table question answering. In this paper, to address the\ncurrent gap in available data, we first introduce a multi-table benchmark,\nMutliTableQA, comprising 60k tables and 25k user queries collected from\nreal-world sources. Then, we propose the first Graph-Table-RAG framework,\nnamely GTR, which reorganizes table corpora into a heterogeneous graph, employs\na hierarchical coarse-to-fine retrieval process to extract the most relevant\ntables, and integrates graph-aware prompting for downstream LLMs' tabular\nreasoning. Extensive experiments show that GTR exhibits superior cross-table\nquestion-answering performance while maintaining high deployment efficiency,\ndemonstrating its real-world practical applicability.","main_category":"cs.CL","categories":"cs.CL,cs.IR,cs.LG","published":"2025-04-02T04:24:41Z"}
{"aid":"http://arxiv.org/abs/2504.01347v1","title":"MEEK: Re-thinking Heterogeneous Parallel Error Detection Architecture\n  for Real-World OoO Superscalar Processors","summary":"Heterogeneous parallel error detection is an approach to achieving\nfault-tolerant processors, leveraging multiple power-efficient cores to\nre-execute software originally run on a high-performance core. Yet, its complex\ncomponents, gathering data cross-chip from many parts of the core, raise\nquestions of how to build it into commodity cores without heavy design invasion\nand extensive re-engineering.\n  We build the first full-RTL design, MEEK, into an open-source SoC, from\nmicroarchitecture and ISA to the OS and programming model. We identify and\nsolve bottlenecks and bugs overlooked in previous work, and demonstrate that\nMEEK offers microsecond-level detection capacity with affordable overheads. By\ntrading off architectural functionalities across codesigned hardware-software\nlayers, MEEK features only light changes to a mature out-of-order superscalar\ncore, simple coordinating software layers, and a few lines of operating-system\ncode. The Repo. of MEEK's source code:\nhttps://github.com/SEU-ACAL/reproduce-MEEK-DAC-25.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T04:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.01356v1","title":"xML-workFlow: an end-to-end explainable scikit-learn workflow for rapid\n  biomedical experimentation","summary":"Motivation: Building and iterating machine learning models is often a\nresource-intensive process. In biomedical research, scientific codebases can\nlack scalability and are not easily transferable to work beyond what they were\nintended. xML-workFlow addresses this issue by providing a rapid, robust, and\ntraceable end-to-end workflow that can be adapted to any ML project with\nminimal code rewriting.\n  Results: We show a practical, end-to-end workflow that integrates\nscikit-learn, MLflow, and SHAP. This template significantly reduces the time\nand effort required to build and iterate on ML models, addressing the common\nchallenges of scalability and reproducibility in biomedical research. Adapting\nour template may save bioinformaticians time in development and enables\nbiomedical researchers to deploy ML projects.\n  Availability and implementation: xML-workFlow is available at\nhttps://github.com/MedicalGenomicsLab/xML-workFlow.","main_category":"cs.LG","categories":"cs.LG,cs.SE","published":"2025-04-02T05:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.01401v1","title":"Systematic study of α-decay half-lives of superheavy nuclei based\n  on Coulomb and proximity potential models with temperature effects","summary":"By employing the Coulomb proximity potential model (CPPM) in conjunction with\n22 distinct proximity potential models, we investigated the temperature\ndependence and the effects of proton number and neutron number on the diffusion\nparameters that determine the {\\alpha}-decay half-lives of superheavy nuclei.\nThe results indicate that the Prox.77-3 T-DEP proximity potential model yields\nthe best performance, with the lowest root mean square deviation\n({\\sigma}=0.515), reflecting a high consistency with experimental data. In\ncontrast, Bass77, AW95, Ngo80, and Guo2013 display larger deviations. The\ninclusion of temperature dependence significantly improves the accuracy of\nmodels such as Prox.77-3, Prox.77-6, and Prox.77-7. The -decay half-lives of 36\npotential superheavy nuclei were further predicted using the five most accurate\nproximity potential models and Ni's empirical formula, with the results\naligning well with experimental data. These predictions underscore the high\nreliability of the CPPM combined with proximity potential models in the\ntheoretical calculation of {\\alpha}-decay half-lives of superheavy nuclei,\noffering valuable theoretical insights for future experimental investigations\nof superheavy nuclei.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-02T06:39:48Z"}
{"aid":"http://arxiv.org/abs/2504.01424v1","title":"On the Role of Priors in Bayesian Causal Learning","summary":"In this work, we investigate causal learning of independent causal mechanisms\nfrom a Bayesian perspective. Confirming previous claims from the literature, we\nshow in a didactically accessible manner that unlabeled data (i.e., cause\nrealizations) do not improve the estimation of the parameters defining the\nmechanism. Furthermore, we observe the importance of choosing an appropriate\nprior for the cause and mechanism parameters, respectively. Specifically, we\nshow that a factorized prior results in a factorized posterior, which resonates\nwith Janzing and Sch\\\"olkopf's definition of independent causal mechanisms via\nthe Kolmogorov complexity of the involved distributions and with the concept of\nparameter independence of Heckerman et al.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T07:19:49Z"}
{"aid":"http://arxiv.org/abs/2504.01426v1","title":"Temperature and misorientation-dependent austenite nucleation at ferrite\n  grain boundaries in a medium manganese steel: role of\n  misorientation-dependent grain boundary segregation","summary":"In the current work, we study the role of grain boundary (GB)\nmisorientation-dependent segregation on austenite nucleation in a 50% cold\nrolled intercritically annealed 10Mn-0.05C-1.5Al (wt. %) medium Mn steel.\nDuring intercritical annealing at 500{\\deg}C, austenite nucleates predominantly\nat high-angle GBs. At 600{\\deg}C, austenite nucleates additionally at low-angle\nGBs, exhibiting a temperature dependance. Correlative transmission Kikuchi\ndiffraction /atom probe tomography reveals a misorientation-dependent\nsegregation. While GB segregation has been reported to assist austenite\nnucleation in medium manganese steels (3-12 wt.% Mn), an understanding of the\ntemperature and misorientation dependance is lacking, which is the aim of\ncurrent work. Since artifacts of atom probe can cause a broadening of the\nsegregation width, we combined experiments with results from density functional\ntheory (DFT) calculations that reveal that the Mn segregation is not limited to\nthe GB plane but confined to a region in the range of approximately 1 nm.\nConsequently, GB segregation alters both the GB interface energy and the free\nenergy per unit volume corresponding to the transformation. We estimate the\nlocal driving force for austenite nucleation accounting for the segregation\nwidth of ~ 1 nm. Based on classical nucleation theory, we clarify the effect of\nGB segregation on the critical radius and activation energy barrier for\nconfined austenite nucleation at the GB.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T07:22:43Z"}
{"aid":"http://arxiv.org/abs/2504.01480v1","title":"A microscopic traffic flow model on network with destination-aware V2V\n  communications and rational decision-making","summary":"In this paper we carry out a computational study of a novel microscopic\nfollow-the-leader model for traffic flow on road networks. We assume that each\ndriver has its own origin and destination, and wants to complete its journey in\nminimal time. We also assume that each driver is able to take rational\ndecisions at junctions and can change route while moving depending on the\ntraffic conditions. The main novelty of the model is that vehicles can\nautomatically and anonymously share information about their position,\ndestination, and planned path when they are close to each other within a\ncertain distance. The pieces of information acquired during the journey are\nused to optimize the route itself. In the limit case of a infinite\ncommunication range, we recover the classical Reactive User Equilibrium and\nDynamic User Equilibrium.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T08:35:37Z"}
{"aid":"http://arxiv.org/abs/2504.01495v1","title":"Are Autonomous Web Agents Good Testers?","summary":"Despite advances in automated testing, manual testing remains prevalent due\nto the high maintenance demands associated with test script fragility-scripts\noften break with minor changes in application structure. Recent developments in\nLarge Language Models (LLMs) offer a potential alternative by powering\nAutonomous Web Agents (AWAs) that can autonomously interact with applications.\nThese agents may serve as Autonomous Test Agents (ATAs), potentially reducing\nthe need for maintenance-heavy automated scripts by utilising natural language\ninstructions similar to those used by human testers. This paper investigates\nthe feasibility of adapting AWAs for natural language test case execution and\nhow to evaluate them. We contribute with (1) a benchmark of three offline web\napplications, and a suite of 113 manual test cases, split between passing and\nfailing cases, to evaluate and compare ATAs performance, (2) SeeAct-ATA and\npinATA, two open-source ATA implementations capable of executing test steps,\nverifying assertions and giving verdicts, and (3) comparative experiments using\nour benchmark that quantifies our ATAs effectiveness. Finally we also proceed\nto a qualitative evaluation to identify the limitations of PinATA, our best\nperforming implementation. Our findings reveal that our simple implementation,\nSeeAct-ATA, does not perform well compared to our more advanced PinATA\nimplementation when executing test cases (50% performance improvement).\nHowever, while PinATA obtains around 60% of correct verdict and up to a\npromising 94% specificity, we identify several limitations that need to be\naddressed to develop more resilient and reliable ATAs, paving the way for\nrobust, low maintenance test automation. CCS Concepts: $\\bullet$ Software and\nits engineering $\\rightarrow$ Software testing and debugging.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T08:48:01Z"}
{"aid":"http://arxiv.org/abs/2504.01504v1","title":"Approximate Agreement Algorithms for Byzantine Collaborative Learning","summary":"In Byzantine collaborative learning, $n$ clients in a peer-to-peer network\ncollectively learn a model without sharing their data by exchanging and\naggregating stochastic gradient estimates. Byzantine clients can prevent others\nfrom collecting identical sets of gradient estimates. The aggregation step thus\nneeds to be combined with an efficient (approximate) agreement subroutine to\nensure convergence of the training process.\n  In this work, we study the geometric median aggregation rule for Byzantine\ncollaborative learning. We show that known approaches do not provide\ntheoretical guarantees on convergence or gradient quality in the agreement\nsubroutine. To satisfy these theoretical guarantees, we present a hyperbox\nalgorithm for geometric median aggregation.\n  We practically evaluate our algorithm in both centralized and decentralized\nsettings under Byzantine attacks on non-i.i.d. data. We show that our geometric\nmedian-based approaches can tolerate sign-flip attacks better than known\nmean-based approaches from the literature.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-02T08:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.01510v1","title":"Surface forces and frictional properties of adsorbed bio-based cationic\n  polysaccharide thin films in salted aqueous medium","summary":"Inter-surface forces mediated by polymer films are important in a range of\ntechnological and industrial situations. In cosmetics, applications such as\nhair conditioning typically rely on the adsorption of polyelectrolyte films\nonto the charged surface of hair fibers, whose contact mechanics and\ntribological properties are central in determining the final sensorial\nperceptions associated with the cosmetic treatment. A major current challenge\nto be tackled by the cosmetic industry is to design high-performance products\nemploying bio-sourced polyelectrolytes, with the aim of achieving\neco-sustainable processes and products. In this context, the present study\nfocuses on the mechanical properties of thin films obtained by adsorption from\nsolution of fungal chitosan onto negatively charged mica surfaces. We use a\nSurface Forces Apparatus allowing for the simultaneous measurement of film\nthickness and friction force as a function of the applied normal load and shear\nvelocity. We show that, in aqueous medium at an ionic strength of 40 mM,\nadsorbed films of chitosan give rise to repulsive inter-surface forces whose\nrange, comparable to the Flory radius of the macromolecules, increases with the\npolymer molecular weight. In addition, the adsorbed layers are found to behave,\nunder compressive forces, as pseudo-brushes of neutral polymers. Finally, we\nshow that under shear forces, chitosan layers exhibit a transition from a low\nto a high friction regime under increasing confinement.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T08:57:56Z"}
{"aid":"http://arxiv.org/abs/2504.01531v1","title":"DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal\n  Forecasting","summary":"Accurate predictions of spatio-temporal systems' states are crucial for tasks\nsuch as system management, control, and crisis prevention. However, the\ninherent time variance of spatio-temporal systems poses challenges to achieving\naccurate predictions whenever stationarity is not granted. To address\nnon-stationarity frameworks, we propose a Distribution and Relation Adaptive\nNetwork (DRAN) capable of dynamically adapting to relation and distribution\nchanges over time. While temporal normalization and de-normalization are\nfrequently used techniques to adapt to distribution shifts, this operation is\nnot suitable for the spatio-temporal context as temporal normalization scales\nthe time series of nodes and possibly disrupts the spatial relations among\nnodes. In order to address this problem, we develop a Spatial Factor Learner\n(SFL) module that enables the normalization and de-normalization process in\nspatio-temporal systems. To adapt to dynamic changes in spatial relationships\namong sensors, we propose a Dynamic-Static Fusion Learner (DSFL) module that\neffectively integrates features learned from both dynamic and static relations\nthrough an adaptive fusion ratio mechanism. Furthermore, we introduce a\nStochastic Learner to capture the noisy components of spatio-temporal\nrepresentations. Our approach outperforms state of the art methods in weather\nprediction and traffic flows forecasting tasks. Experimental results show that\nour SFL efficiently preserves spatial relationships across various temporal\nnormalization operations. Visualizations of the learned dynamic and static\nrelations demonstrate that DSFL can capture both local and distant\nrelationships between nodes. Moreover, ablation studies confirm the\neffectiveness of each component.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T09:18:43Z"}
{"aid":"http://arxiv.org/abs/2504.01564v1","title":"Numerical techniques for geodesic approximation in Riemaniann shape\n  optimization","summary":"Shape optimization is commonly applied in engineering to optimize shapes with\nrespect to an objective functional relying on PDE solutions. In this paper, we\nview shape optimization as optimization on Riemannian shape manifolds. We\nconsider so-called outer metrics on the diffeomorphism group to solve\nPDE-constrained shape optimization problems efficiently. Commonly, the\nnumerical solution of such problems relies on the Riemannian version of the\nsteepest descent method. One key difference between this version and the\nstandard method is that iterates are updated via geodesics or retractions. Due\nto the lack of explicit expressions for geodesics, for most of the previously\nproposed metrics, very limited progress has been made in this direction.\nLeveraging the existence of explicit expressions for the geodesic equations\nassociated to the outer metrics on the diffeomorphism group, we aim to study\nthe viability of using such equations in the context of PDE-constrained shape\noptimization. However, solving geodesic equations is computationally\nchallenging and often restrictive. Therefore, this paper discusses potential\nnumerical approaches to simplify the numerical burden of using geodesics,\nmaking the proposed method computationally competitive with previously\nestablished methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T10:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.01575v1","title":"Fully ergodic simulations using radial updates","summary":"A sensible application of the Hybrid Monte Carlo (HMC) method is often\nhindered by the presence of large - or even infinite - potential barriers.\nThese potential barriers separate the configuration space into distinct sectors\nand can lead to ergodicity violations that bias measurements. In this work, we\naddress this problem by augmenting HMC with a multiplicative\nMetropolis-Hastings update in a so-called ''radial direction'' of the fields\nwhich enables crossing the potential barriers and ensures ergodicity of the\nsampling algorithm at comparably low computational cost. We demonstrate the\nalgorithm on a simple toy model and show how it can be applied to the fermionic\nHubbard model describing physics ranging from an exactly-solvable two-site\nsystem to the $C_{20}H_{12}$ perylene molecule. Our numerical results show that\nthe radial updates successfully remove ergodicity violations, while\nsimultaneously reducing autocorrelation times.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-lat","published":"2025-04-02T10:28:49Z"}
{"aid":"http://arxiv.org/abs/2504.01609v1","title":"The Mini-SiTian Array: the mini-SiTian Realtime Image Processing\n  pipeline (STRIP)","summary":"This paper provides a comprehensive introduction to the Mini-SiTian Real-Time\nImage Processing pipeline (STRIP) and evaluates its operational performance.\nThe STRIP pipeline is specifically designed for real-time alert triggering and\nlight curve generation for transient sources. By applying the STRIP pipeline to\nboth simulated and real observational data of the Mini-SiTian survey, it\nsuccessfully identified various types of variable sources, including stellar\nflares, supernovae, variable stars, and asteroids, while meeting requirements\nof reduction speed within 5 minutes. For the real observational dataset, the\npipeline detected 1 flare event, 127 variable stars, and 14 asteroids from\nthree monitored sky regions. Additionally, two datasets were generated: one, a\nreal-bogus training dataset comprising 218,818 training samples, and the other,\na variable star light curve dataset with 421 instances. These datasets will be\nused to train machine learning algorithms, which are planned for future\nintegration into STRIP.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.01631v1","title":"Constructive Decompositions of the Identity for Functional John\n  Ellipsoids","summary":"We consider functional ellipsoids in the sense defined by Ivanov and\nNasz\\'odi and we study the problem of constructing a decomposition of the\nidentity similar to the one given by Fritz John in his fundamental theorem.","main_category":"math.FA","categories":"math.FA,math.DG","published":"2025-04-02T11:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.01634v1","title":"Shape Anisotropy Enabled Field Free Switching of Perpendicular\n  Nanomagnets","summary":"Spin Orbit Torque-Magnetic Random Access Memory (SOT-MRAM) is being developed\nas a successor to the Spin transfer torque MRAM (STT-MRAM) owing to its\nsuperior performance on the metrics of reliability and read-write speed. SOT\nswitching of perpendicularly magnetized ferromagnet in the heavy\nmetal/ferromagnet bilayer of SOT-MRAM unit cell requires an additional external\nmagnetic field to support the spin-orbit torque generated by heavy metal to\ncause deterministic switching. This complexity can be overcome if an internal\nfield can be generated to break the switching symmetry. We experimentally\ndemonstrate that by engineering the shape of ferromagnet, an internal magnetic\nfield capable of breaking the switching symmetry can be generated, which allows\nfor deterministic switching by spin-orbit torques. We fabricated nanomagnets of\nCobalt with triangular shape on top of Platinum and showed external magnetic\nfield free switching between the two stable states of magnetization by\napplication of nano-second voltage pulses. The experimental findings are\nconsistent with the micro-magnetic simulation results of the proposed geometry.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-02T11:40:10Z"}
{"aid":"http://arxiv.org/abs/2504.01650v1","title":"Sparse Gaussian Neural Processes","summary":"Despite significant recent advances in probabilistic meta-learning, it is\ncommon for practitioners to avoid using deep learning models due to a\ncomparative lack of interpretability. Instead, many practitioners simply use\nnon-meta-models such as Gaussian processes with interpretable priors, and\nconduct the tedious procedure of training their model from scratch for each\ntask they encounter. While this is justifiable for tasks with a limited number\nof data points, the cubic computational cost of exact Gaussian process\ninference renders this prohibitive when each task has many observations. To\nremedy this, we introduce a family of models that meta-learn sparse Gaussian\nprocess inference. Not only does this enable rapid prediction on new tasks with\nsparse Gaussian processes, but since our models have clear interpretations as\nmembers of the neural process family, it also allows manual elicitation of\npriors in a neural process for the first time. In meta-learning regimes for\nwhich the number of observed tasks is small or for which expert domain\nknowledge is available, this offers a crucial advantage.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-02T12:00:09Z"}
{"aid":"http://arxiv.org/abs/2504.01656v1","title":"Probabilistic plugging of airways by sliding mucus films","summary":"When do mucus films plug lung airways? Using reduced-order simulations of a\nlarge ensemble of randomly perturbed films, we show that the answer is not\ndetermined by just the film's volume. While very thin films always stay open\nand very thick films always plug, we find a range of intermediate films for\nwhich plugging is uncertain. The fastest-growing linear mode of the\nRayleigh-Plateau instability ensures that the film's volume is divided among\nmultiple humps. However, the nonlinear growth of these humps can occur\nunevenly, due to spontaneous axial sliding -- a lucky hump can sweep up a\ndisproportionate share of the film's volume and so form a plug. This\nsliding-induced plugging is robust and prevails with or without gravitational\nand ciliary transport.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,nlin.PS","published":"2025-04-02T12:04:44Z"}
{"aid":"http://arxiv.org/abs/2504.01657v1","title":"Impact of Small-Scale Gravity Waves on Tracer Transport","summary":"Small-scale gravity waves play a crucial role in atmospheric tracer\ntransport, yet their effects remain unresolved in climate models and must be\nparameterized. This study investigates how gravity waves influence large-scale\ntracer distributions, utilizing a multiple-scale analysis to systematically\nidentify the governing terms of gravity wave-induced tracer fluxes. The\nanalysis reveals both leading-order and next-order impacts: the former being\nthe inertia-gravity wave-induced tracer Stokes drift, which acts perpendicular\nto both the large-scale tracer gradient and the wave number, while the latter\nbecomes significant at lower latitudes where Coriolis effects diminish. A\nnumerical framework is developed to incorporate these fluxes into a gravity\nwave parameterization model, potentially enhancing climate model accuracy\nwithout requiring explicit resolution of small-scale wave dynamics. Model\nvalidation against high-resolution wave-resolving simulations confirms the\neffectiveness of this approach. By improving the representation of gravity\nwave-induced tracer transport, this research advances the accuracy of climate\nsimulations, particularly in their depiction of microphysics and radiative\nprocesses.","main_category":"physics.ao-ph","categories":"physics.ao-ph,physics.flu-dyn","published":"2025-04-02T12:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.01668v1","title":"Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation\n  for 3D Semantic Segmentation","summary":"3D point cloud semantic segmentation (PCSS) is a cornerstone for\nenvironmental perception in robotic systems and autonomous driving, enabling\nprecise scene understanding through point-wise classification. While\nunsupervised domain adaptation (UDA) mitigates label scarcity in PCSS, existing\nmethods critically overlook the inherent vulnerability to real-world\nperturbations (e.g., snow, fog, rain) and adversarial distortions. This work\nfirst identifies two intrinsic limitations that undermine current PCSS-UDA\nrobustness: (a) unsupervised features overlap from unaligned boundaries in\nshared-class regions and (b) feature structure erosion caused by\ndomain-invariant learning that suppresses target-specific patterns. To address\nthe proposed problems, we propose a tripartite framework consisting of: 1) a\nrobustness evaluation model quantifying resilience against adversarial\nattack/corruption types through robustness metrics; 2) an invertible attention\nalignment module (IAAM) enabling bidirectional domain mapping while preserving\ndiscriminative structure via attention-guided overlap suppression; and 3) a\ncontrastive memory bank with quality-aware contrastive learning that\nprogressively refines pseudo-labels with feature quality for more\ndiscriminative representations. Extensive experiments on\nSynLiDAR-to-SemanticPOSS adaptation demonstrate a maximum mIoU improvement of\n14.3\\% under adversarial attack.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-02T12:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.01675v1","title":"Einstein's elevator and the principle of equivalence","summary":"We outlines here the design, execution, and educational outcomes of an\nintervention inspired by Einstein's elevator thought experiment, intended to\nintroduce secondary school students to the principle of equivalence, which is\nat the basis of the theory of General Relativity. We build an experimental\nversion of Einstein's elevator, which simulated the effects of free-fall in an\naccelerated reference frame: a detailed description of the experimental\napparatus and its construction is provided, highlighting the challenges and\ninnovations in creating a simple yet functional setup using everyday materials.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-02T12:25:08Z"}
{"aid":"http://arxiv.org/abs/2504.01693v1","title":"$SL_k$-Tilings and Paths in $\\mathbb{Z}^k$","summary":"An $SL_k$-tiling is a bi-infinite array of integers having all adjacent\n$k\\times k$ minors equal to one and all adjacent $(k+1)\\times (k+1)$ minors\nequal to zero. Introduced and studied by Bergeron and Reutenauer,\n$SL_k$-tilings generalize the notion of Conway-Coxeter frieze patterns in the\ncase $k=2$. In a recent paper, Short showed a bijection between bi-infinite\npaths of reduced rationals in the Farey graph and $SL_2$-tilings. We extend\nthis result to higher $k$ by constructing a bijection between $SL_k$-tilings\nand certain pairs of bi-infinite strips of vectors in $\\mathbb{Z}^k$ called\npaths. The key ingredient in the proof is the connection to Pl\\\"ucker friezes\nand Grassmannian cluster algebras. As an application, we obtain results about\nperiodicity, duality, and positivity for tilings.","main_category":"math.CO","categories":"math.CO,math.RA,math.RT","published":"2025-04-02T12:49:39Z"}
{"aid":"http://arxiv.org/abs/2504.01719v1","title":"Beyond Non-Expert Demonstrations: Outcome-Driven Action Constraint for\n  Offline Reinforcement Learning","summary":"We address the challenge of offline reinforcement learning using realistic\ndata, specifically non-expert data collected through sub-optimal behavior\npolicies. Under such circumstance, the learned policy must be safe enough to\nmanage \\textit{distribution shift} while maintaining sufficient flexibility to\ndeal with non-expert (bad) demonstrations from offline data.To tackle this\nissue, we introduce a novel method called Outcome-Driven Action Flexibility\n(ODAF), which seeks to reduce reliance on the empirical action distribution of\nthe behavior policy, hence reducing the negative impact of those bad\ndemonstrations.To be specific, a new conservative reward mechanism is developed\nto deal with {\\it distribution shift} by evaluating actions according to\nwhether their outcomes meet safety requirements - remaining within the state\nsupport area, rather than solely depending on the actions' likelihood based on\noffline data.Besides theoretical justification, we provide empirical evidence\non widely used MuJoCo and various maze benchmarks, demonstrating that our ODAF\nmethod, implemented using uncertainty quantification techniques, effectively\ntolerates unseen transitions for improved \"trajectory stitching,\" while\nenhancing the agent's ability to learn from realistic non-expert data.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-02T13:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.01737v1","title":"Enlightenment Period Improving DNN Performance","summary":"In the early stage of deep neural network training, the loss decreases\nrapidly before gradually leveling off. Extensive research has shown that during\nthis stage, the model parameters undergo significant changes and their\ndistribution is largely established. Existing studies suggest that the\nintroduction of noise during early training can degrade model performance. We\nidentify a critical \"enlightenment period\" encompassing up to the first 4% of\nthe training cycle (1--20 epochs for 500-epoch training schedules), a phase\ncharacterized by intense parameter fluctuations and heightened noise\nsensitivity. Our findings reveal that strategically reducing noise during this\nbrief phase--by disabling data augmentation techniques such as Mixup or\nremoving high-loss samples--leads to statistically significant improvements in\nmodel performance. This work opens new avenues for exploring the relationship\nbetween the enlightenment period and network training dynamics across diverse\nmodel architectures and tasks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T13:49:31Z"}
{"aid":"http://arxiv.org/abs/2504.01773v1","title":"Budget-Feasible Contracts","summary":"The problem of computing near-optimal contracts in combinatorial settings has\nrecently attracted significant interest in the computer science community.\nPrevious work has provided a rich body of structural and algorithmic insights\ninto this problem. However, most of these results rely on the assumption that\nthe principal has an unlimited budget for incentivizing agents, an assumption\nthat is often unrealistic in practice. This motivates the study of the optimal\ncontract problem under budget constraints. We study multi-agent contracts with\nbudget constraints under both binary and combinatorial actions. For binary\nactions, our contribution is threefold. First, we generalize all previously\nknown approximation guarantees on the principal's revenue to budgeted settings.\nSecond, through the lens of budget constraints, we uncover insightful\nconnections between the standard objective of the principal's revenue and other\nobjectives. We identify a broad class of objectives, which we term BEST\nobjectives, including reward, social welfare, and revenue, and show that they\nare all equivalent (up to a constant factor), leading to approximation\nguarantees for all BEST objectives. Third, we introduce the price of frugality,\nwhich quantifies the loss due to budget constraints, and establish near-tight\nbounds on this measure, providing deeper insights into the tradeoffs between\nbudgets and incentives. For combinatorial actions, we establish a strong\nnegative result. Specifically, we show that in a budgeted setting with\nsubmodular rewards, no finite approximation is possible to any BEST objective.\nThis stands in contrast to the unbudgeted setting with submodular rewards,\nwhere a polynomial-time constant-factor approximation is known for revenue. On\nthe positive side, for gross substitutes rewards, we recover our binary-actions\nresults, obtaining a constant-factor approximation for all BEST objectives.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-02T14:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.01785v1","title":"Time-optimal single-scalar control on a qubit of unitary dynamics","summary":"Optimal control theory is applied to analyze the time-optimal solution with a\nsingle scalar control knob in a two-level quantum system without quantum\ndecoherence. Emphasis is \\change{placed} on the dependence on the maximum\ncontrol strength $u_\\text{max}$. General constraints on the optimal protocol\nare derived and used to rigorously parameterize the time-optimal solution. Two\nconcrete problems are investigated. For generic state preparation problems,\nboth multiple bang-bang and bang-singular-bang are legitimate and should be\nconsidered. Generally, the optimal is bang-bang for small $u_\\text{max}$, and\nthere exists a state-dependent critical amplitude above which singular control\nemerges. For the X-gate operation of a qubit, the optimal protocol \\change{is\nexclusively} multiple bang-bang. The minimum gate time is about 80\\% of that\nbased on the resonant Rabi $\\pi$-pulse over a wide range of control strength;\nin the $u_\\text{max} \\rightarrow 0$ limit this ratio is derived to be $\\pi/4$.\nTo develop practically feasible protocols, we present methods to smooth the\nabrupt changes in the bang-bang control while preserving perfect gate fidelity.\n\\change{The presence of bang-bang segments in the time-optimal protocol}\nindicates that the high-frequency components and a full calculation (instead of\nthe commonly adopted Rotating Wave Approximation) are essential for the\nultimate quantum speed limit.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T14:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01792v1","title":"UniViTAR: Unified Vision Transformer with Native Resolution","summary":"Conventional Vision Transformer simplifies visual modeling by standardizing\ninput resolutions, often disregarding the variability of natural visual data\nand compromising spatial-contextual fidelity. While preliminary explorations\nhave superficially investigated native resolution modeling, existing approaches\nstill lack systematic analysis from a visual representation perspective. To\nbridge this gap, we introduce UniViTAR, a family of homogeneous vision\nfoundation models tailored for unified visual modality and native resolution\nscenario in the era of multimodal. Our framework first conducts architectural\nupgrades to the vanilla paradigm by integrating multiple advanced components.\nBuilding upon these improvements, a progressive training paradigm is\nintroduced, which strategically combines two core mechanisms: (1) resolution\ncurriculum learning, transitioning from fixed-resolution pretraining to native\nresolution tuning, thereby leveraging ViT's inherent adaptability to\nvariable-length sequences, and (2) visual modality adaptation via inter-batch\nimage-video switching, which balances computational efficiency with enhanced\ntemporal reasoning. In parallel, a hybrid training framework further synergizes\nsigmoid-based contrastive loss with feature distillation from a frozen teacher\nmodel, thereby accelerating early-stage convergence. Finally, trained\nexclusively on public datasets, externsive experiments across multiple model\nscales from 0.3B to 1B demonstrate its effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T14:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.01794v1","title":"On the regularity of entropy solutions to stochastic degenerate\n  parabolic equations","summary":"We study the regularity of entropy solutions for quasilinear parabolic\nequations with anisotropic degeneracy and stochastic forcing. Building on\nprevious works, we establish space-time regularity under a non-degeneracy\ncondition that does not require an assumption on the derivative of the symbol\nof the corresponding kinetic equation, a restriction imposed in earlier\nstudies. This allows us to obtain regularity results for certain equations not\naccounted for by prior theory, albeit with reduced regularity exponents. Our\napproach uses a kinetic formulation with two transport equations, one of second\norder and one of first order, leveraging a form of \"parabolic regularity\"\ninherent in these equations that was not utilized in previous studies.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T15:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.01803v1","title":"DISINFOX: an open-source threat exchange platform serving intelligence\n  on disinformation and influence operations","summary":"This paper introduces DISINFOX, an open-source threat intelligence exchange\nplatform for the structured collection, management, and dissemination of\ndisinformation incidents and influence operations. Analysts can upload and\ncorrelate information manipulation and interference incidents, while clients\ncan access and analyze the data through an interactive web interface or\nprogrammatically via a public API. This facilitates integration with other\nvendors, providing a unified view of cybersecurity and disinformation events.\n  The solution is fully containerized using Docker, comprising a web-based\nfrontend for user interaction, a backend REST API for managing core\nfunctionalities, and a public API for structured data retrieval, enabling\nseamless integration with existing Cyber Threat Intelligence (CTI) workflows.\nIn particular, DISINFOX models the incidents through DISARM Tactics,\nTechniques, and Procedures (TTPs), a MITRE ATT&CK-like framework for\ndisinformation, with a custom data model based on the Structured Threat\nInformation eXpression (STIX2) standard.\n  As an open-source solution, DISINFOX provides a reproducible and extensible\nhub for researchers, analysts, and policymakers seeking to enhance the\ndetection, investigation, and mitigation of disinformation threats. The\nintelligence generated from a custom dataset has been tested and utilized by a\nlocal instance of OpenCTI, a mature CTI platform, via a custom-built connector,\nvalidating the platform with the exchange of more than 100 disinformation\nincidents.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-02T15:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.01805v1","title":"Spatial-R1: Enhancing MLLMs in Video Spatial Reasoning","summary":"Enhancing the spatial reasoning capabilities of Multi-modal Large Language\nModels (MLLMs) for video understanding is crucial yet challenging. We present\nSpatial-R1, a targeted approach involving two key contributions: the curation\nof SR, a new video spatial reasoning dataset from ScanNet with automatically\ngenerated QA pairs across seven task types, and the application of\nTask-Specific Group Relative Policy Optimization (GRPO) for fine-tuning. By\ntraining the Qwen2.5-VL-7B-Instruct model on SR using GRPO, Spatial-R1\nsignificantly advances performance on the VSI-Bench benchmark, achieving a\n7.4\\% gain over the baseline and outperforming strong contemporary models. This\nwork validates the effectiveness of specialized data curation and optimization\ntechniques for improving complex spatial reasoning in video MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T15:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.01833v1","title":"YourBench: Easy Custom Evaluation Sets for Everyone","summary":"Evaluating large language models (LLMs) effectively remains a critical\nbottleneck, as traditional static benchmarks suffer from saturation and\ncontamination, while human evaluations are costly and slow. This hinders timely\nor domain-specific assessment, crucial for real-world applications. We\nintroduce YourBench, a novel, open-source framework that addresses these\nlimitations by enabling dynamic, automated generation of reliable, up-to-date,\nand domain-tailored benchmarks cheaply and without manual annotation, directly\nfrom user-provided documents. We demonstrate its efficacy by replicating 7\ndiverse MMLU subsets using minimal source text, achieving this for under 15 USD\nin total inference costs while perfectly preserving the relative model\nperformance rankings (Spearman Rho = 1) observed on the original benchmark. To\nensure that YourBench generates data grounded in provided input instead of\nrelying on posterior parametric knowledge in models, we also introduce\nTempora-0325, a novel dataset of over 7K diverse documents, published\nexclusively after March 2025. Our comprehensive analysis spans 26 SoTA models\nfrom 7 major families across varying scales (3-671B parameters) to validate the\nquality of generated evaluations through rigorous algorithmic checks (e.g.,\ncitation grounding) and human assessments. We release the YourBench library,\nthe Tempora-0325 dataset, 150k+ question answer pairs based on Tempora and all\nevaluation and inference traces to facilitate reproducible research and empower\nthe community to generate bespoke benchmarks on demand, fostering more relevant\nand trustworthy LLM evaluation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.1","published":"2025-04-02T15:40:24Z"}
{"aid":"http://arxiv.org/abs/2504.01847v1","title":"Confluence of Conditional Rewriting Modulo","summary":"Sets of equations E play an important computational role in rewriting-based\nsystems R by defining an equivalence relation =E inducing a partition of terms\ninto E-equivalence classes on which rewriting computations, denoted ->R/E and\ncalled *rewriting modulo E*, are issued. This paper investigates *confluence of\n->R/E*, usually called *E-confluence*, for *conditional* rewriting-based\nsystems, where rewriting steps are determined by conditional rules. We rely on\nJouannaud and Kirchner's framework to investigate confluence of an abstract\nrelation R modulo an abstract equivalence relation E on a set A. We show how to\nparticularize the framework to be used with conditional systems. Then, we show\nhow to define appropriate finite sets of *conditional pairs* to prove and\ndisprove E-confluence. In particular, we introduce *Logic-based Conditional\nCritical Pairs* which do not require the use of (often infinitely many)\nE-unifiers to provide a finite representation of the *local peaks* considered\nin the abstract framework. We also introduce *parametric Conditional Variable\nPairs* which are essential to deal with conditional rules in the analysis of\nE-confluence. Our results apply to well-known classes of rewriting-based\nsystems. In particular, to *Equational (Conditional) Term Rewriting Systems*.","main_category":"cs.LO","categories":"cs.LO,cs.PL,cs.SC","published":"2025-04-02T15:55:06Z"}
{"aid":"http://arxiv.org/abs/2504.01848v1","title":"PaperBench: Evaluating AI's Ability to Replicate AI Research","summary":"We introduce PaperBench, a benchmark evaluating the ability of AI agents to\nreplicate state-of-the-art AI research. Agents must replicate 20 ICML 2024\nSpotlight and Oral papers from scratch, including understanding paper\ncontributions, developing a codebase, and successfully executing experiments.\nFor objective evaluation, we develop rubrics that hierarchically decompose each\nreplication task into smaller sub-tasks with clear grading criteria. In total,\nPaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed\nwith the author(s) of each ICML paper for accuracy and realism. To enable\nscalable evaluation, we also develop an LLM-based judge to automatically grade\nreplication attempts against rubrics, and assess our judge's performance by\ncreating a separate benchmark for judges. We evaluate several frontier models\non PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet\n(New) with open-source scaffolding, achieves an average replication score of\n21.0\\%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench,\nfinding that models do not yet outperform the human baseline. We\n\\href{https://github.com/openai/preparedness}{open-source our code} to\nfacilitate future research in understanding the AI engineering capabilities of\nAI agents.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-02T15:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.01849v1","title":"An Approach to Technical AGI Safety and Security","summary":"Artificial General Intelligence (AGI) promises transformative benefits but\nalso presents significant risks. We develop an approach to address the risk of\nharms consequential enough to significantly harm humanity. We identify four\nareas of risk: misuse, misalignment, mistakes, and structural risks. Of these,\nwe focus on technical approaches to misuse and misalignment. For misuse, our\nstrategy aims to prevent threat actors from accessing dangerous capabilities,\nby proactively identifying dangerous capabilities, and implementing robust\nsecurity, access restrictions, monitoring, and model safety mitigations. To\naddress misalignment, we outline two lines of defense. First, model-level\nmitigations such as amplified oversight and robust training can help to build\nan aligned model. Second, system-level security measures such as monitoring and\naccess control can mitigate harm even if the model is misaligned. Techniques\nfrom interpretability, uncertainty estimation, and safer design patterns can\nenhance the effectiveness of these mitigations. Finally, we briefly outline how\nthese ingredients could be combined to produce safety cases for AGI systems.","main_category":"cs.AI","categories":"cs.AI,cs.CY,cs.LG","published":"2025-04-02T15:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.01850v1","title":"Code Red! On the Harmfulness of Applying Off-the-shelf Large Language\n  Models to Programming Tasks","summary":"Nowadays, developers increasingly rely on solutions powered by Large Language\nModels (LLM) to assist them with their coding tasks. This makes it crucial to\nalign these tools with human values to prevent malicious misuse. In this paper,\nwe propose a comprehensive framework for assessing the potential harmfulness of\nLLMs within the software engineering domain. We begin by developing a taxonomy\nof potentially harmful software engineering scenarios and subsequently, create\na dataset of prompts based on this taxonomy. To systematically assess the\nresponses, we design and validate an automatic evaluator that classifies the\noutputs of a variety of LLMs both open-source and closed-source models, as well\nas general-purpose and code-specific LLMs. Furthermore, we investigate the\nimpact of models size, architecture family, and alignment strategies on their\ntendency to generate harmful content. The results show significant disparities\nin the alignment of various LLMs for harmlessness. We find that some models and\nmodel families, such as Openhermes, are more harmful than others and that\ncode-specific models do not perform better than their general-purpose\ncounterparts. Notably, some fine-tuned models perform significantly worse than\ntheir base-models due to their design choices. On the other side, we find that\nlarger models tend to be more helpful and are less likely to respond with\nharmful information. These results highlight the importance of targeted\nalignment strategies tailored to the unique challenges of software engineering\ntasks and provide a foundation for future work in this critical area.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-02T16:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.01859v1","title":"A method to derive material-specific spin-bath model descriptions of\n  materials displaying prevalent spin physics (for simulation on NISQ devices)","summary":"Magnetism and spin physics are true quantum mechanical effects and their\ndescription usually requires multi reference methods and is often hidden in the\nstandard description of molecules in quantum chemistry. In this work we present\na twofold approach to the description of spin physics in molecules and solids.\nFirst, we present a method that identifies the single-particle basis in which a\ngiven subset of the orbitals is equivalent to spin degrees of freedom for\nmodels and materials which feature significant spin physics at low energies. We\nintroduce a metric for the spin-like character of a basis orbital, of which the\noptimization yields the basis containing the optimum spin-like basis orbitals.\nSecond, we demonstrate an extended Schrieffer-Wolff transformation method to\nderive the effective Hamiltonian acting on the subspace of the Hilbert space in\nwhich the charge degree of freedom of electron densities in the spin-like\norbitals is integrated out. The method then yields an effective spin-bath\nHamiltonian description for the system. This extended Schrieffer-Wolff\ntransformation is applicable to a wide range of Hamiltonians and has been\nutilized in this work for model Hamiltonians as well as the active space\nHamiltonian of molecular chromium bromide.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-02T16:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.01860v1","title":"Hyperbolic decomposition of Dirichlet distance for ARMA models","summary":"We investigate the hyperbolic decomposition of the Dirichlet norm and\ndistance between autoregressive moving average (ARMA) models. Beginning with\nthe K\\\"ahler information geometry of linear systems in the Hardy space and\nweighted Hardy spaces, we demonstrate that the Dirichlet norm and distance of\nARMA models, corresponding to the mutual information between the past and\nfuture, are decomposed into functions of the hyperbolic distance between the\npoles and zeros of the ARMA models.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-02T16:12:24Z"}
{"aid":"http://arxiv.org/abs/2504.01882v1","title":"CO-DEFEND: Continuous Decentralized Federated Learning for Secure\n  DoH-Based Threat Detection","summary":"The use of DNS over HTTPS (DoH) tunneling by an attacker to hide malicious\nactivity within encrypted DNS traffic poses a serious threat to network\nsecurity, as it allows malicious actors to bypass traditional monitoring and\nintrusion detection systems while evading detection by conventional traffic\nanalysis techniques. Machine Learning (ML) techniques can be used to detect DoH\ntunnels; however, their effectiveness relies on large datasets containing both\nbenign and malicious traffic. Sharing such datasets across entities is\nchallenging due to privacy concerns. In this work, we propose CO-DEFEND\n(Continuous Decentralized Federated Learning for Secure DoH-Based Threat\nDetection), a Decentralized Federated Learning (DFL) framework that enables\nmultiple entities to collaboratively train a classification machine learning\nmodel while preserving data privacy and enhancing resilience against single\npoints of failure. The proposed DFL framework, which is scalable and\nprivacy-preserving, is based on a federation process that allows multiple\nentities to train online their local models using incoming DoH flows in real\ntime as they are processed by the entity. In addition, we adapt four classical\nmachine learning algorithms, Support Vector Machines (SVM), Logistic Regression\n(LR), Decision Trees (DT), and Random Forest (RF), for federated scenarios,\ncomparing their results with more computationally complex alternatives such as\nneural networks. We compare our proposed method by using the dataset\nCIRA-CIC-DoHBrw-2020 with existing machine learning approaches to demonstrate\nits effectiveness in detecting malicious DoH tunnels and the benefits it\nbrings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T16:40:01Z"}
{"aid":"http://arxiv.org/abs/2504.01906v1","title":"Gaze-Hand Steering for Travel and Multitasking in Virtual Environments","summary":"As head-mounted displays (HMDs) with eye-tracking become increasingly\naccessible, the need for effective gaze-based interfaces in virtual reality\n(VR) grows. Traditional gaze- or hand-based navigation often limits user\nprecision or impairs free viewing, making multitasking difficult. We present a\ngaze-hand steering technique that combines eye-tracking with hand-pointing:\nusers steer only when gaze aligns with a hand-defined target, reducing\nunintended actions and enabling free look. Speed is controlled via either a\njoystick or a waist-level speed circle. We evaluated our method in a user study\n(N=20) across multitasking and single-task scenarios, comparing it to a similar\ntechnique. Results show that gaze-hand steering maintains performance and\nenhances user comfort and spatial awareness during multitasking. Our findings\nsupport the use of gaze-hand steering in gaze-dominant VR applications\nrequiring precision and simultaneous interaction. Our method significantly\nimproves VR navigation in gaze-dominant, multitasking-intensive applications,\nsupporting immersion and efficient control.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-02T17:07:01Z"}
{"aid":"http://arxiv.org/abs/2504.01916v1","title":"FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer\n  Text Inputs","summary":"As a pioneering vision-language model, CLIP (Contrastive Language-Image\nPre-training) has achieved significant success across various domains and a\nwide range of downstream vision-language tasks. However, the text encoders in\npopular CLIP models are limited to processing only 77 text tokens, which\nconstrains their ability to effectively handle longer, detail-rich captions.\nAdditionally, CLIP models often struggle to effectively capture detailed visual\nand textual information, which hampers their performance on tasks that require\nfine-grained analysis. To address these limitations, we present a novel\napproach, \\textbf{FineLIP}, that extends the capabilities of CLIP. FineLIP\nenhances cross-modal text-image mapping by incorporating \\textbf{Fine}-grained\nalignment with \\textbf{L}onger text input within the CL\\textbf{IP}-style\nframework. FineLIP first extends the positional embeddings to handle longer\ntext, followed by the dynamic aggregation of local image and text tokens. The\naggregated results are then used to enforce fine-grained token-to-token\ncross-modal alignment. We validate our model on datasets with long, detailed\ncaptions across two tasks: zero-shot cross-modal retrieval and text-to-image\ngeneration. Quantitative and qualitative experimental results demonstrate the\neffectiveness of FineLIP, outperforming existing state-of-the-art approaches.\nFurthermore, comprehensive ablation studies validate the benefits of key design\nelements within FineLIP.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-02T17:19:59Z"}
{"aid":"http://arxiv.org/abs/2504.01922v1","title":"Is Less Really More? Fake News Detection with Limited Information","summary":"The threat that online fake news and misinformation pose to democracy,\njustice, public confidence, and especially to vulnerable populations, has led\nto a sharp increase in the need for fake news detection and intervention.\nWhether multi-modal or pure text-based, most fake news detection methods depend\non textual analysis of entire articles. However, these fake news detection\nmethods come with certain limitations. For instance, fake news detection\nmethods that rely on full text can be computationally inefficient, demand large\namounts of training data to achieve competitive accuracy, and may lack\nrobustness across different datasets. This is because fake news datasets have\nstrong variations in terms of the level and types of information they provide;\nwhere some can include large paragraphs of text with images and metadata,\nothers can be a few short sentences. Perhaps if one could only use minimal\ninformation to detect fake news, fake news detection methods could become more\nrobust and resilient to the lack of information. We aim to overcome these\nlimitations by detecting fake news using systematically selected, limited\ninformation that is both effective and capable of delivering robust, promising\nperformance. We propose a framework called SLIM Systematically-selected Limited\nInformation) for fake news detection. In SLIM, we quantify the amount of\ninformation by introducing information-theoretic measures. SLIM leverages\nlimited information to achieve performance in fake news detection comparable to\nthat of state-of-the-art obtained using the full text. Furthermore, by\ncombining various types of limited information, SLIM can perform even better\nwhile significantly reducing the quantity of information required for training\ncompared to state-of-the-art language model-based fake news detection\ntechniques.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-02T17:32:37Z"}
{"aid":"http://arxiv.org/abs/2504.01935v1","title":"Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning\n  Length?","summary":"Large language models (LLMs) often benefit from verbalized reasoning at\ninference time, but it remains unclear which aspects of task difficulty these\nextra reasoning tokens address. To investigate this question, we formalize a\nframework using deterministic finite automata (DFAs). DFAs offer a formalism\nthrough which we can characterize task complexity through measurable properties\nsuch as run length (number of reasoning steps required) and state-space size\n(decision complexity). We first show that across different tasks and models of\ndifferent sizes and training paradigms, there exists an optimal amount of\nreasoning tokens such that the probability of producing a correct solution is\nmaximized. We then investigate which properties of complexity govern this\ncritical length: we find that task instances with longer corresponding\nunderlying DFA runs (i.e. demand greater latent state-tracking requirements)\ncorrelate with longer reasoning lengths, but, surprisingly, that DFA size (i.e.\nstate-space complexity) does not. We then demonstrate an implication of these\nfindings: being able to predict the optimal number of reasoning tokens for new\nproblems and filtering out non-optimal length answers results in consistent\naccuracy improvements.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T17:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.01938v1","title":"A Unified Approach to Analysis and Design of Denoising Markov Models","summary":"Probabilistic generative models based on measure transport, such as diffusion\nand flow-based models, are often formulated in the language of Markovian\nstochastic dynamics, where the choice of the underlying process impacts both\nalgorithmic design choices and theoretical analysis. In this paper, we aim to\nestablish a rigorous mathematical foundation for denoising Markov models, a\nbroad class of generative models that postulate a forward process transitioning\nfrom the target distribution to a simple, easy-to-sample distribution,\nalongside a backward process particularly constructed to enable efficient\nsampling in the reverse direction. Leveraging deep connections with\nnonequilibrium statistical mechanics and generalized Doob's $h$-transform, we\npropose a minimal set of assumptions that ensure: (1) explicit construction of\nthe backward generator, (2) a unified variational objective directly minimizing\nthe measure transport discrepancy, and (3) adaptations of the classical\nscore-matching approach across diverse dynamics. Our framework unifies existing\nformulations of continuous and discrete diffusion models, identifies the most\ngeneral form of denoising Markov models under certain regularity assumptions on\nforward generators, and provides a systematic recipe for designing denoising\nMarkov models driven by arbitrary L\\'evy-type processes. We illustrate the\nversatility and practical effectiveness of our approach through novel denoising\nMarkov models employing geometric Brownian motion and jump processes as forward\ndynamics, highlighting the framework's potential flexibility and capability in\nmodeling complex distributions.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA,stat.ML","published":"2025-04-02T17:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.01942v1","title":"De Sitter entropy: on-shell versus off-shell","summary":"Attributing thermodynamic properties to the Bunch-Davies state in static\npatch of de Sitter space and setting the corresponding equations of state, we\ndemonstrate that, for pure gravity, the bulk entropy computed on-shell as a\nvolume integral in de Sitter space coincides with the Wald entropy (area law)\nin any spacetime dimension and for any theory of f(R) gravity. We extend this\nresult to the renormalized entanglement entropy of a non-minimally coupled\nscalar field. From the on-shell perspective, entropy emerges as a bulk\ncontribution, whereas from the off-shell viewpoint, it manifests as a boundary\n(horizon) contribution. As a result, in de Sitter space, generalized entropy\ncan be understood in two distinct ways: either as a bulk or as a boundary\ncontribution.","main_category":"hep-th","categories":"hep-th","published":"2025-04-02T17:48:35Z"}
{"aid":"http://arxiv.org/abs/2504.02211v1","title":"FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault\n  Tolerant Attention","summary":"Transformer models leverage self-attention mechanisms to capture complex\ndependencies, demonstrating exceptional performance in various applications.\nHowever, the long-duration high-load computations required for model inference\nimpose stringent reliability demands on the computing platform, as soft errors\nthat occur during execution can significantly degrade model performance.\nExisting fault tolerance methods protect each operation separately using\ndecoupled kernels, incurring substantial computational and memory overhead. In\nthis paper, we propose a novel error-resilient framework for Transformer\nmodels, integrating end-to-end fault tolerant attention (EFTA) to improve\ninference reliability against soft errors. Our approach enables error detection\nand correction within a fully fused attention kernel, reducing redundant data\naccess and thereby mitigating memory faults. To further enhance error coverage\nand reduce overhead, we design a hybrid fault tolerance scheme tailored for the\nEFTA, introducing for the first time: 1) architecture-aware algorithm-based\nfault tolerance (ABFT) using tensor checksum, which minimizes inter-thread\ncommunication overhead on tensor cores during error detection; 2) selective\nneuron value restriction, which selectively applies adaptive fault tolerance\nconstraints to neuron values, balancing error coverage and overhead; 3) unified\nverification, reusing checksums to streamline multiple computation steps into a\nsingle verification process. Experimental results show that EFTA achieves up to\n7.56x speedup over traditional methods with an average fault tolerance overhead\nof 13.9%.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.LG","published":"2025-04-03T02:05:08Z"}
{"aid":"http://arxiv.org/abs/2504.02244v1","title":"SocialGesture: Delving into Multi-person Gesture Understanding","summary":"Previous research in human gesture recognition has largely overlooked\nmulti-person interactions, which are crucial for understanding the social\ncontext of naturally occurring gestures. This limitation in existing datasets\npresents a significant challenge in aligning human gestures with other\nmodalities like language and speech. To address this issue, we introduce\nSocialGesture, the first large-scale dataset specifically designed for\nmulti-person gesture analysis. SocialGesture features a diverse range of\nnatural scenarios and supports multiple gesture analysis tasks, including\nvideo-based recognition and temporal localization, providing a valuable\nresource for advancing the study of gesture during complex social interactions.\nFurthermore, we propose a novel visual question answering (VQA) task to\nbenchmark vision language models'(VLMs) performance on social gesture\nunderstanding. Our findings highlight several limitations of current gesture\nrecognition models, offering insights into future directions for improvement in\nthis field. SocialGesture is available at\nhuggingface.co/datasets/IrohXu/SocialGesture.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T03:21:06Z"}
{"aid":"http://arxiv.org/abs/2504.02256v1","title":"A direct algebraic proof for the non-positivity of Liouvillian\n  eigenvalues in Markovian quantum dynamics","summary":"Markovian open quantum systems are described by the Lindblad master equation\n$\\partial_t\\rho =\\mathcal{L}(\\rho)$, where $\\rho$ denotes the system's density\noperator and $\\mathcal{L}$ the Liouville super-operator, which is also known as\nthe Liouvillian. For systems with a finite-dimensional Hilbert space, it is a\nfundamental property of the Liouvillian, that the real-parts of all its\neigenvalues are non-positive which, in physical terms, corresponds to the\nstability of the system. The usual argument for this property is indirect,\nusing that $\\mathcal{L}$ generates a quantum channel and that quantum channels\nare contractive. We provide a direct algebraic proof based on the Lindblad form\nof Liouvillians.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T03:54:25Z"}
{"aid":"http://arxiv.org/abs/2504.02262v1","title":"Predictive modeling of altitude resolved greenline airglow emission\n  (557.7 nm) in the MLT region","summary":"Atomic oxygen is a critical and highly reactive chemical species responsible\nfor key physical and chemical processes in the mesosphere and lower\nthermosphere.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-03T04:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.02268v1","title":"Advancing Semantic Caching for LLMs with Domain-Specific Embeddings and\n  Synthetic Data","summary":"This report investigates enhancing semantic caching effectiveness by\nemploying specialized, fine-tuned embedding models. Semantic caching relies on\nembedding similarity rather than exact key matching, presenting unique\nchallenges in balancing precision, query latency, and computational efficiency.\nWe propose leveraging smaller, domain-specific embedding models, fine-tuned\nwith targeted real-world and synthetically generated datasets. Our empirical\nevaluations demonstrate that compact embedding models fine-tuned for just one\nepoch on specialized datasets significantly surpass both state-of-the-art\nopen-source and proprietary alternatives in precision and recall. Moreover, we\nintroduce a novel synthetic data generation pipeline for the semantic cache\nthat mitigates the challenge of limited domain-specific annotated data, further\nboosting embedding performance. Our approach effectively balances computational\noverhead and accuracy, establishing a viable and efficient strategy for\npractical semantic caching implementations.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-03T04:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.02285v1","title":"Tree-based Models for Vertical Federated Learning: A Survey","summary":"Tree-based models have achieved great success in a wide range of real-world\napplications due to their effectiveness, robustness, and interpretability,\nwhich inspired people to apply them in vertical federated learning (VFL)\nscenarios in recent years. In this paper, we conduct a comprehensive study to\ngive an overall picture of applying tree-based models in VFL, from the\nperspective of their communication and computation protocols. We categorize\ntree-based models in VFL into two types, i.e., feature-gathering models and\nlabel-scattering models, and provide a detailed discussion regarding their\ncharacteristics, advantages, privacy protection mechanisms, and applications.\nThis study also focuses on the implementation of tree-based models in VFL,\nsummarizing several design principles for better satisfying various\nrequirements from both academic research and industrial deployment. We conduct\na series of experiments to provide empirical observations on the differences\nand advances of different types of tree-based models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T05:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.02287v1","title":"MultiSensor-Home: A Wide-area Multi-modal Multi-view Dataset for Action\n  Recognition and Transformer-based Sensor Fusion","summary":"Multi-modal multi-view action recognition is a rapidly growing field in\ncomputer vision, offering significant potential for applications in\nsurveillance. However, current datasets often fail to address real-world\nchallenges such as wide-area environmental conditions, asynchronous data\nstreams, and the lack of frame-level annotations. Furthermore, existing methods\nface difficulties in effectively modeling inter-view relationships and\nenhancing spatial feature learning. In this study, we propose the Multi-modal\nMulti-view Transformer-based Sensor Fusion (MultiTSF) method and introduce the\nMultiSensor-Home dataset, a novel benchmark designed for comprehensive action\nrecognition in home environments. The MultiSensor-Home dataset features\nuntrimmed videos captured by distributed sensors, providing high-resolution RGB\nand audio data along with detailed multi-view frame-level action labels. The\nproposed MultiTSF method leverages a Transformer-based fusion mechanism to\ndynamically model inter-view relationships. Furthermore, the method also\nintegrates a external human detection module to enhance spatial feature\nlearning. Experiments on MultiSensor-Home and MM-Office datasets demonstrate\nthe superiority of MultiTSF over the state-of-the-art methods. The quantitative\nand qualitative results highlight the effectiveness of the proposed method in\nadvancing real-world multi-modal multi-view action recognition.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T05:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.02294v1","title":"Search for Fast Radio Bursts and radio pulsars from pulsing\n  Ultraluminous X-ray Sources","summary":"We conducted targeted fast radio burst (FRB) and pulsar searches on eight\npulsing ultraluminous X-ray sources (PULXs) using the Five-hundred-meter\nAperture Spherical Radio Telescope (FAST) and the Parkes 64-meter Radio\nTelescope (Murriyang) to investigate whether PULXs could be progenitors of\nFRBs. FAST carried out 12 observations of four PULXs, totaling 8 hours, while\nParkes conducted 12 observations of the remaining four PULXs, totaling 11\nhours. No significant signals were detected through single-pulse and periodic\nsearches, covering a dispersion measure (DM) range of 0-5000 pc cm$^{-3}$,\nplacing stringent upper limits on the radio flux density from these sources.\nThe results imply that accretion processes and dense stellar winds in PULXs\nlikely suppress or attenuate potential coherent emission in radio band.\nAdditionally, the beaming factor and luminosity of FRBs associated with PULXs,\nas well as the highly relativistic and magnetized nature of their outflows, may\nlimit detectability. Non-detection yielded from the observations covering the\nfull orbital phases of PULXs can also constrain the theoretical models that\nlink FRB emission to highly magnetized neutron stars in binary systems.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-03T05:49:34Z"}
{"aid":"http://arxiv.org/abs/2504.02363v1","title":"Double groupoids of composites: applications to uniformity","summary":"In this paper we present a geometrical framework to study the uniformity of a\ncomposite material by means of double groupoid theory. The notions of vertical\nand horizontal uniformity are introduced, as well as other weaker ones that\nallows us to study other possible notions of more general uniformity.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-03T07:53:36Z"}
{"aid":"http://arxiv.org/abs/2504.02367v1","title":"CrystalFormer-RL: Reinforcement Fine-Tuning for Materials Design","summary":"Reinforcement fine-tuning has instrumental enhanced the instruction-following\nand reasoning abilities of large language models. In this work, we explore the\napplications of reinforcement fine-tuning to the autoregressive\ntransformer-based materials generative model CrystalFormer (arXiv:2403.15734)\nusing discriminative machine learning models such as interatomic potentials and\nproperty prediction models. By optimizing reward signals-such as energy above\nthe convex hull and material property figures of merit-reinforcement\nfine-tuning infuses knowledge from discriminative models into generative\nmodels. The resulting model, CrystalFormer-RL, shows enhanced stability in\ngenerated crystals and successfully discovers crystals with desirable yet\nconflicting material properties, such as substantial dielectric constant and\nband gap simultaneously. Notably, we observe that reinforcement fine-tuning\nenables not only the property-guided novel material design ability of\ngenerative pre-trained model but also unlocks property-driven material\nretrieval from the unsupervised pre-training dataset. Leveraging rewards from\ndiscriminative models to fine-tune materials generative models opens an\nexciting gateway to the synergies of the machine learning ecosystem for\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.comp-ph","published":"2025-04-03T07:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.02380v1","title":"Beyond Asymptotics: Targeted exploration with finite-sample guarantees","summary":"In this paper, we introduce a targeted exploration strategy for the\nnon-asymptotic, finite-time case. The proposed strategy is applicable to\nuncertain linear time-invariant systems subject to sub-Gaussian disturbances.\nAs the main result, the proposed approach provides a priori guarantees,\nensuring that the optimized exploration inputs achieve a desired accuracy of\nthe model parameters. The technical derivation of the strategy (i) leverages\nexisting non-asymptotic identification bounds with self-normalized martingales,\n(ii) utilizes spectral lines to predict the effect of sinusoidal excitation,\nand (iii) effectively accounts for spectral transient error and parametric\nuncertainty. A numerical example illustrates how the finite exploration time\ninfluence the required exploration energy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T08:17:17Z"}
{"aid":"http://arxiv.org/abs/2504.02384v1","title":"Resistive switching characteristics of Cu/MgO/MoS2/Cu structure","summary":"During the study of resistive switching devices, researchers have found that\nthe influence of the insertion layer cannot be ignored. Many reports have\nconfirmed that the appropriate insertion layer can significantly improve the\nperformance of the resistive switching devices. Therefore, in this work, we use\nmagnetron sputtering to fabricate three devices: Cu/MgO/Cu, Cu/MgO/MoS2/Cu and\nCu/MoS2/MgO/Cu. Through the characterization test of each device and the\nmeasurement of the I-V curve, it is found that the resistive switching\ncharacteristics of the Cu/MgO/Cu device will change greatly after adding an\nMoS2 insertion layer. The analysis results show that the inserted MoS2 layer\ndoes not change the main transmission mechanism (space charge limited\nconduction) of the device, but affects the regulating function of interfacial\npotential barrier, the effect also is related to the location of MoS2 inserted\ninto the layer. Among the Cu/MgO/Cu, Cu/MgO/MoS2/Cu and Cu/MoS2/MgO/Cu devices,\nthe Cu/MgO/MoS2/Cu device exhibits a larger switching ratio (about 103) and a\nlower reset voltage (about 0.21 V), which can be attributed to the regulation\nof the interface barrier between MgO and MoS2. In addition, when the MoS2 layer\nis inserted between the bottom electrodes Cu and MgO, the leakage current of\nthe device is significantly reduced. Therefore, Cu/MoS2/MgO/Cu device has the\nhighest commercial value from the point of view of practical applications.\nFinally, according to the XPS results and XRD results, we establish the\nconductive filament models for the three devices, and analyze the reasons for\nthe different resistive switching characteristics of the three devices.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-03T08:22:36Z"}
{"aid":"http://arxiv.org/abs/2504.02385v1","title":"Quantum singular value transformation without block encodings:\n  Near-optimal complexity with minimal ancilla","summary":"We develop new algorithms for Quantum Singular Value Transformation (QSVT), a\nunifying framework underlying a wide range of quantum algorithms. Existing\nimplementations of QSVT rely on block encoding, incurring $O(\\log L)$ ancilla\noverhead and circuit depth $\\widetilde{O}(d\\lambda L)$ for polynomial\ntransformations of a Hamiltonian $H=\\sum_{k=1}^L \\lambda_k H_k$, where $d$ is\npolynomial degree, and $\\lambda=\\sum_k |\\lambda_k|$. We introduce a new\napproach that eliminates block encoding, needs only a single ancilla qubit, and\nmaintains near-optimal complexity, using only basic Hamiltonian simulation\nmethods such as Trotterization. Our method achieves a circuit depth of\n$\\widetilde{O}(L(d\\lambda_{\\mathrm{comm}})^{1+o(1)})$, without any multi-qubit\ncontrolled gates. Here, $\\lambda_{\\mathrm{comm}}$ depends on the nested\ncommutators of the $H_k$'s and can be much smaller than $\\lambda$. Central to\nour technique is a novel use of Richardson extrapolation, enabling systematic\nerror cancellation in interleaved sequences of arbitrary unitaries and\nHamiltonian evolution operators, establishing a broadly applicable framework\nbeyond QSVT. Additionally, we propose two randomized QSVT algorithms for cases\nwith only sampling access to Hamiltonian terms. The first uses qDRIFT, while\nthe second replaces block encodings in QSVT with randomly sampled unitaries.\nBoth achieve quadratic complexity in $d$, which we establish as a lower bound\nfor any randomized method implementing polynomial transformations in this\nmodel. Finally, as applications, we develop end-to-end quantum algorithms for\nquantum linear systems and ground state property estimation, achieving\nnear-optimal complexity without oracular access. Our results provide a new\nframework for quantum algorithms, reducing hardware overhead while maintaining\nnear-optimal performance, with implications for both near-term and\nfault-tolerant quantum computing.","main_category":"quant-ph","categories":"quant-ph,cs.DS","published":"2025-04-03T08:24:15Z"}
{"aid":"http://arxiv.org/abs/2504.02417v1","title":"Leveraging Static Relationships for Intra-Type and Inter-Type Message\n  Passing in Video Question Answering","summary":"Video Question Answering (VideoQA) is an important research direction in the\nfield of artificial intelligence, enabling machines to understand video content\nand perform reasoning and answering based on natural language questions.\nAlthough methods based on static relationship reasoning have made certain\nprogress, there are still deficiencies in the accuracy of static relationship\nrecognition and representation, and they have not fully utilized the static\nrelationship information in videos for in-depth reasoning and analysis.\nTherefore, this paper proposes a reasoning method for intra-type and inter-type\nmessage passing based on static relationships. This method constructs a dual\ngraph for intra-type message passing reasoning and builds a heterogeneous graph\nbased on static relationships for inter-type message passing reasoning. The\nintra-type message passing reasoning model captures the neighborhood\ninformation of targets and relationships related to the question in the dual\ngraph, updating the dual graph to obtain intra-type clues for answering the\nquestion. The inter-type message passing reasoning model captures the\nneighborhood information of targets and relationships from different categories\nrelated to the question in the heterogeneous graph, updating the heterogeneous\ngraph to obtain inter-type clues for answering the question. Finally, the\nanswers are inferred by combining the intra-type and inter-type clues based on\nstatic relationships. Experimental results on the ANetQA and Next-QA datasets\ndemonstrate the effectiveness of this method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T09:14:41Z"}
{"aid":"http://arxiv.org/abs/2504.02420v1","title":"On learning racing policies with reinforcement learning","summary":"Fully autonomous vehicles promise enhanced safety and efficiency. However,\nensuring reliable operation in challenging corner cases requires control\nalgorithms capable of performing at the vehicle limits. We address this\nrequirement by considering the task of autonomous racing and propose solving it\nby learning a racing policy using Reinforcement Learning (RL). Our approach\nleverages domain randomization, actuator dynamics modeling, and policy\narchitecture design to enable reliable and safe zero-shot deployment on a real\nplatform. Evaluated on the F1TENTH race car, our RL policy not only surpasses a\nstate-of-the-art Model Predictive Control (MPC), but, to the best of our\nknowledge, also represents the first instance of an RL policy outperforming\nexpert human drivers in RC racing. This work identifies the key factors driving\nthis performance improvement, providing critical insights for the design of\nrobust RL-based control strategies for autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-03T09:21:48Z"}
{"aid":"http://arxiv.org/abs/2504.02424v1","title":"Designing optimal elastic filaments for viscous propulsion","summary":"The propulsion of many eukaryotic cells is generated by flagella, flexible\nslender filaments that are actively oscillating in space and time. The dynamics\nof these biological appendages have inspired the design of many types of\nartificial microswimmers. The magnitude of the filament's viscous propulsion\ndepends on the time-varying shape of the filament, and that shape depends in\nturn on the spatial distribution of the bending rigidity of the filament. In\nthis work, we rigorously determine the relationship between the mechanical\n(bending) properties of the filament and the viscous thrust it produces using\nmathematical optimisation. Specifically, by considering a model system (a\nslender elastic filament with an oscillating slope at its base), we derive the\noptimal bending rigidity function along the filament that maximises the\ntime-averaged thrust produced by the actuated filament. Instead of prescribing\na specific functional form, we use functional optimisation and adjoint-based\nvariational calculus to formally establish the link between the distribution of\nbending rigidity and propulsion. The optimal rigidities are found to be stiff\nnear the base, and soft near the distal end, with a spatial distribution that\ndepends critically on the constraints used in the optimisation procedure. These\nfindings may guide the optimal design of future artificial swimmers.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-03T09:28:32Z"}
{"aid":"http://arxiv.org/abs/2504.02428v1","title":"Semigroup Congruences and Subsemigroups of the Direct Square","summary":"We investigate semigroups $S$ which have the property that every subsemigroup\nof $S\\times S$ which contains the diagonal $\\{ (s,s)\\colon s\\in S\\}$ is\nnecessarily a congruence on $S$. We call such $S$ a DSC semigroup. It is well\nknown that all finite groups are DSC, and easy to see that every DSC semigroup\nmust be simple. Building on this, we show that for broad classes of semigroups\n-- including periodic, stable, inverse and several well-known types of simple\nsemigroups -- the only DSC members are groups. However, it turns out that there\nexist non-group DSC semigroups, which we obtain utilising a construction\nintroduced by Byleen for the purpose of constructing interesting\ncongruence-free semigroups. Such examples can additionally be regular or\nbisimple.","main_category":"math.RA","categories":"math.RA,math.GR","published":"2025-04-03T09:33:50Z"}
{"aid":"http://arxiv.org/abs/2504.02447v1","title":"Measuring the Low-Energy Weak Mixing Angle with Supernova Neutrinos","summary":"The weak mixing angle $\\theta_W$ is a fundamental parameter in the\nelectroweak theory with a value running according to the energy scale, and its\nprecision measurement in the low-energy regime is still ongoing. We propose a\nmethod to measure the low-energy $\\sin{^2\\theta_W}$ by taking advantage of\nArgo, a future ton-scale liquid argon dark matter detector, and the neutrino\nflux from a nearby core-collapse supernova (CCSN). We evaluate the expected\nprecision of this measurement through the coherent elastic neutrino-nucleus\nscattering (CE$\\nu$NS) channel. We show that Argo is potentially capable of\nachieving a few percent determination of $\\sin{^2\\theta_W}$, at the momentum\ntransfer of $q \\sim 20$ MeV, in the observation of a CCSN within $\\sim 3$ kpc\nfrom the Earth. Such a measurement is valuable for both the precision test of\nthe electroweak theory and searching for new physics beyond the standard model\nin the neutrino sector.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T10:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.02455v1","title":"QPanda3: A High-Performance Software-Hardware Collaborative Framework\n  for Large-Scale Quantum-Classical Computing Integration","summary":"QPanda3 is a high-performance quantum programming framework that enhances\nquantum computing efficiency through optimized circuit compilation, an advanced\ninstruction stream format (OriginBIS), and hardware-aware execution strategies.\nThese engineering optimizations significantly improve both processing speed and\nsystem performance, addressing key challenges in the NISQ era. A core\ninnovation, OriginBIS, accelerates encoding speeds by up to 86.9x compared to\nOpenQASM 2.0, while decoding is 35.6x faster, leading to more efficient data\nhandling, reduced memory overhead, and improved communication efficiency. This\ndirectly enhances the execution of quantum circuits, making large-scale quantum\nsimulations more feasible. Comprehensive benchmarking demonstrates QPanda3's\nsuperior performance: quantum circuit construction is 20.7x faster, execution\nspeeds improve by 3.4x, and transpilation efficiency increases by 14.97x over\nQiskit. Notably, in compiling a 118-qubit W-state circuit on a 2D-grid\ntopology, QPanda3 achieves an unprecedented 869.9x speedup, underscoring its\nability to handle complex quantum workloads at scale. By combining high-speed\nquantum processing with a modular and extensible software architecture, QPanda3\nprovides a practical bridge between today's NISQ devices and future\nfault-tolerant quantum computing. It facilitates real-world applications in\nfinancial modeling, materials science, and combinatorial optimization, while\nits robust and scalable design supports industrial adoption and cloud-based\ndeployment.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-03T10:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.02462v1","title":"Gravitational Wave with Domain Wall Dominance","summary":"Domain walls (DWs) can be produced when a discrete symmetry is spontaneously\nbroken, and long-lived DWs can dominate the energy density of the universe. In\nthis work, we explore the possibility that a \"domain wall dominant (DWD)\" phase\nexisted in the early universe and ended with DW decay. During the DWD phase,\nthe universe undergoes a power-law accelerated expansion of the scale factor\nand exhibits temporal superhorizon evolution of the relevant frequency modes.\nWe show that this can lead to distinct features imprinted on the stochastic\ngravitational wave (GW) background. Our findings provide a comprehensive\nframework for evaluating GW emission associated with DWD, leading to\ndistinguishable long-lived DW-induced GWs from other cosmological sources, with\nsignificant implications for future GW observatories.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-03T10:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.02469v1","title":"An MHD Simulation of the Possible Modulations of Stellar CMEs Radio\n  Observations by an Exoplanetary Magnetosphere","summary":"Type II radio bursts are the indicator of adverse space weather in a stellar\nsystem. These radio bursts are the consequence of shock wave acceleration due\nto the coronal mass ejection (CME). Here, we perform a series of\nmagnetohydrodynamic (MHD) simulations of a CME-driven star-planet system in\norder to investigate the modulation in radio burst mechanism by a close-in\nexoplanetary system. We use a model for the stellar wind with a close-in\nexoplanet, and a CME model based on the eruption of a flux rope. We are able to\ngenerate synthetic radio burst images from our MHD simulations. We find that\nradio burst like phenomena is most likely to be observed for moderately active\nsolar like stars and close-in exoplanetary systems have significant influence\non the nature of radio burst spectrum. We find that when the planetary field is\nnot too strong, the planetary magnetosphere is pushing against the CME,\nincreasing its density so the radio burst is visible at higher frequencies.\nWhen the planetary field is very strong, the large magnetosphere does not leave\nroom for the CME shock to evolve so the radio burst is more visible in the\nlower frequencies associated with the weak compression at the flanks of the CME\nshock. In case of highly active solar-like stars, strong overlying stellar\nfields weakens the solar-like CME shock, thus generates very weak (almost\nnon-visible) radio burst signals. For HD 189733 (moderate stellar field), only\nintensity difference is visible when the CME arrives the planet. We also do not\nfind significant modulation in the radio emission by a close-in exoplanet\nsystem when the stellar magnetic field is complex. In summary, our result\nsuggests that the nature of the radio burst spectrum is highly dependent on the\ntopology of the stellar magnetic field and the close-in exoplanetary magnetic\nfield strength.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-03T10:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.02486v1","title":"We Need Improved Data Curation and Attribution in AI for Scientific\n  Discovery","summary":"As the interplay between human-generated and synthetic data evolves, new\nchallenges arise in scientific discovery concerning the integrity of the data\nand the stability of the models. In this work, we examine the role of synthetic\ndata as opposed to that of real experimental data for scientific research. Our\nanalyses indicate that nearly three-quarters of experimental datasets available\non open-access platforms have relatively low adoption rates, opening new\nopportunities to enhance their discoverability and usability by automated\nmethods. Additionally, we observe an increasing difficulty in distinguishing\nsynthetic from real experimental data. We propose supplementing ongoing efforts\nin automating synthetic data detection by increasing the focus on watermarking\nreal experimental data, thereby strengthening data traceability and integrity.\nOur estimates suggest that watermarking even less than half of the real world\ndata generated annually could help sustain model robustness, while promoting a\nbalanced integration of synthetic and human-generated content.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T11:07:52Z"}
{"aid":"http://arxiv.org/abs/2504.02527v1","title":"Recent results on strangeness enhancement in small collision systems\n  with ALICE","summary":"Quantum Chromodynamics (QCD) predicts that, at sufficiently high temperature\nand energy density, nuclear matter undergoes a phase transition from confined\nhadrons to a deconfined state of quarks and gluons known as the quark-gluon\nplasma (QGP). One of the historically proposed signatures of QGP formation is\nstrangeness enhancement (SE), characterized by an increased production of\nstrange hadrons in heavy-ion collisions relative to proton--proton (pp)\ninteractions. At the LHC, the ALICE experiment has measured a continuous\nincrease in the strange-to-non-strange hadron yield ratios as a function of\nmidrapidity charged-particle multiplicity, not only in large systems like\nPb--Pb but also in small systems such as pp and p--Pb. The origin of SE in\nsmall systems is still under debate, motivating further experimental\ninvestigations. This article presents recent ALICE analyses that offer\ncomplementary insights into the phenomenon. These include (i)\nmulti-differential studies using event-shape observables such as transverse\nspherocity and the concept of effective energy, and (ii) the first measurement\nof multiplicity distributions of strange and multi-strange hadrons,\nP($\\textit{n}_{S}$), in pp collisions.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T12:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.02552v1","title":"Variational convergences under moving anisotropies","summary":"We study the asymptotic behaviour of sequences of integral functionals\ndepending on moving anisotropies. We introduce and describe the relevant\nfunctional setting, establishing uniform Meyers-Serrin type approximations,\nPoincar\\'e inequalities and compactness properties. We prove several\n$\\Gamma$-convergence results, and apply the latter to the study of\n$H$-convergence of anisotropic linear differential operators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T13:06:41Z"}
{"aid":"http://arxiv.org/abs/2504.02553v1","title":"Exploring Individual Factors in the Adoption of LLMs for Specific\n  Software Engineering Tasks","summary":"The advent of Large Language Models (LLMs) is transforming software\ndevelopment, significantly enhancing software engineering processes. Research\nhas explored their role within development teams, focusing on specific tasks\nsuch as artifact generation, decision-making support, and information\nretrieval. Despite the growing body of work on LLMs in software engineering,\nmost studies have centered on broad adoption trends, neglecting the nuanced\nrelationship between individual cognitive and behavioral factors and their\nimpact on task-specific adoption. While factors such as perceived effort and\nperformance expectancy have been explored at a general level, their influence\non distinct software engineering tasks remains underexamined. This gap hinders\nthe development of tailored LLM-based systems (e.g., Generative AI Agents) that\nalign with engineers' specific needs and limits the ability of team leaders to\ndevise effective strategies for fostering LLM adoption in targeted workflows.\nThis study bridges this gap by surveying N=188 software engineers to test the\nrelationship between individual attributes related to technology adoption and\nLLM adoption across five key tasks, using structural equation modeling (SEM).\nThe Unified Theory of Acceptance and Use of Technology (UTAUT2) was applied to\ncharacterize individual adoption behaviors. The findings reveal that\ntask-specific adoption is influenced by distinct factors, some of which\nnegatively impact adoption when considered in isolation, underscoring the\ncomplexity of LLM integration in software engineering. To support effective\nadoption, this article provides actionable recommendations, such as seamlessly\nintegrating LLMs into existing development environments and encouraging\npeer-driven knowledge sharing to enhance information retrieval.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-03T13:07:04Z"}
{"aid":"http://arxiv.org/abs/2504.02555v1","title":"Noise Calibration and Spatial-Frequency Interactive Network for STEM\n  Image Enhancement","summary":"Scanning Transmission Electron Microscopy (STEM) enables the observation of\natomic arrangements at sub-angstrom resolution, allowing for atomically\nresolved analysis of the physical and chemical properties of materials.\nHowever, due to the effects of noise, electron beam damage, sample thickness,\netc, obtaining satisfactory atomic-level images is often challenging. Enhancing\nSTEM images can reveal clearer structural details of materials. Nonetheless,\nexisting STEM image enhancement methods usually overlook unique features in the\nfrequency domain, and existing datasets lack realism and generality. To resolve\nthese issues, in this paper, we develop noise calibration, data synthesis, and\nenhancement methods for STEM images. We first present a STEM noise calibration\nmethod, which is used to synthesize more realistic STEM images. The parameters\nof background noise, scan noise, and pointwise noise are obtained by\nstatistical analysis and fitting of real STEM images containing atoms. Then we\nuse these parameters to develop a more general dataset that considers both\nregular and random atomic arrangements and includes both HAADF and BF mode\nimages. Finally, we design a spatial-frequency interactive network for STEM\nimage enhancement, which can explore the information in the frequency domain\nformed by the periodicity of atomic arrangement. Experimental results show that\nour data is closer to real STEM images and achieves better enhancement\nperformances together with our network. Code will be available at\nhttps://github.com/HeasonLee/SFIN}{https://github.com/HeasonLee/SFIN.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T13:11:57Z"}
{"aid":"http://arxiv.org/abs/2504.02575v1","title":"Assessing Geographical and Seasonal Influences on Energy Efficiency of\n  Electric Drayage Trucks","summary":"The electrification of heavy-duty vehicles is a critical pathway towards\nimproved energy efficiency of the freight sector. The current battery electric\ntruck technology poses several challenges to the operations of commercial\nvehicles, such as limited driving range, sensitivity to climate conditions, and\nlong recharging times. Estimating the energy consumption of heavy-duty electric\ntrucks is crucial to assess the feasibility of the fleet electrification and\nits impact on the electric grid. This paper focuses on developing a model-based\nsimulation approach to predict and analyze the energy consumption of drayage\ntrucks used in ports logistic operations, considering seasonal climate\nvariations and geographical characteristics. The paper includes results for\nthree major container ports within the United States, providing region-specific\ninsights into driving range, payload capacity, and charging infrastructure\nrequirements, which will inform decision-makers in integrating electric trucks\ninto the existing drayage operations and plan investments for electric grid\ndevelopment.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T13:39:21Z"}
{"aid":"http://arxiv.org/abs/2504.02599v1","title":"Technical Overview of Recent Developments in Small Modular Reactors in\n  the United States","summary":"Small modular reactors (SMRs) are a class of advanced nuclear fission\nreactors characterized by their compact core size (typically <300 MWe) and\npassive safety systems. Their modular design enables on-site assembly, making\nthem suitable for deployment in locations inaccessible to conventional\nlarge-scale reactors. With rising global energy demand, particularly driven by\nthe growth of AI, SMRs have recently gained attention as a potential solution\nfor powering data centers. This technical review aims to provide the public and\nrelevant stakeholders with a foundational understanding of SMR technology. It\nbegins with an overview of SMR concepts, historical context, and their current\nrole in the U.S. energy mix. Detailed technical summaries of nine selected SMR\ndesigns are then presented, covering core design, fuel systems, reactivity\ncontrol, and safety features. The report also outlines key regulatory\nframeworks, including 10 CFR Part 50, Part 52, and the technology-inclusive,\nrisk-informed, and performance-based framework currently under development.\nFinally, major U.S. programs and legislative efforts supporting SMR deployment\nover the past decade are summarized.","main_category":"physics.soc-ph","categories":"physics.soc-ph,physics.ins-det","published":"2025-04-03T14:01:32Z"}
{"aid":"http://arxiv.org/abs/2504.02640v1","title":"RoSMM: A Robust and Secure Multi-Modal Watermarking Framework for\n  Diffusion Models","summary":"Current image watermarking technologies are predominantly categorized into\ntext watermarking techniques and image steganography; however, few methods can\nsimultaneously handle text and image-based watermark data, which limits their\napplicability in complex digital environments. This paper introduces an\ninnovative multi-modal watermarking approach, drawing on the concept of vector\ndiscretization in encoder-based vector quantization. By constructing adjacency\nmatrices, the proposed method enables the transformation of text watermarks\ninto robust image-based representations, providing a novel multi-modal\nwatermarking paradigm for image generation applications. Additionally, this\nstudy presents a newly designed image restoration module to mitigate image\ndegradation caused by transmission losses and various noise interferences,\nthereby ensuring the reliability and integrity of the watermark. Experimental\nresults validate the robustness of the method under multiple noise attacks,\nproviding a secure, scalable, and efficient solution for digital image\ncopyright protection.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-03T14:36:08Z"}
{"aid":"http://arxiv.org/abs/2504.02667v1","title":"Compositionality Unlocks Deep Interpretable Models","summary":"We propose $\\chi$-net, an intrinsically interpretable architecture combining\nthe compositional multilinear structure of tensor networks with the\nexpressivity and efficiency of deep neural networks. $\\chi$-nets retain equal\naccuracy compared to their baseline counterparts. Our novel, efficient\ndiagonalisation algorithm, ODT, reveals linear low-rank structure in a\nmultilayer SVHN model. We leverage this toward formal weight-based\ninterpretability and model compression.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T15:07:54Z"}
{"aid":"http://arxiv.org/abs/2504.02676v1","title":"Snow: Self-organizing Broadcast Protocol for Cloud","summary":"In large-scale distributed applications, efficient and reliable broadcast\nprotocols are essential for node communication. Tree-based broadcast lacks\nflexibility and may suffer performance degradation or even broadcast failure\nwhen cluster membership changes. Gossip-based broadcast incurs high bandwidth\noverhead and only provides probabilistic delivery guarantees. In tree-based\nbroadcasting, when an internal node leaves, its child nodes need to reconnect\nto a new parent. This process may introduce instability, leading to potential\nmessage duplication and increased transmission latency. However, in cloud\nenvironments, node departures and arrivals are common, causing frequent\nperformance degradation in tree-based broadcasting. This paper introduces Snow,\na self-organizing broadcast protocol designed for cloud environments. Instead,\nit dynamically sends or forwards messages based on each node's membership view,\nultimately forming a broadcast structure resembling a multi-way balanced\ntree(the height difference of leaf nodes is at most 1). Our experimental\nresults showed that Snow maintains message delivery reliability and latency\nguarantees under node churn while maintaining low overhead without sending\nunnecessary redundant messages.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-03T15:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.02697v1","title":"Learning Phase Distortion with Selective State Space Models for Video\n  Turbulence Mitigation","summary":"Atmospheric turbulence is a major source of image degradation in long-range\nimaging systems. Although numerous deep learning-based turbulence mitigation\n(TM) methods have been proposed, many are slow, memory-hungry, and do not\ngeneralize well. In the spatial domain, methods based on convolutional\noperators have a limited receptive field, so they cannot handle a large spatial\ndependency required by turbulence. In the temporal domain, methods relying on\nself-attention can, in theory, leverage the lucky effects of turbulence, but\ntheir quadratic complexity makes it difficult to scale to many frames.\nTraditional recurrent aggregation methods face parallelization challenges.\n  In this paper, we present a new TM method based on two concepts: (1) A\nturbulence mitigation network based on the Selective State Space Model\n(MambaTM). MambaTM provides a global receptive field in each layer across\nspatial and temporal dimensions while maintaining linear computational\ncomplexity. (2) Learned Latent Phase Distortion (LPD). LPD guides the state\nspace model. Unlike classical Zernike-based representations of phase\ndistortion, the new LPD map uniquely captures the actual effects of turbulence,\nsignificantly improving the model's capability to estimate degradation by\nreducing the ill-posedness. Our proposed method exceeds current\nstate-of-the-art networks on various synthetic and real-world TM benchmarks\nwith significantly faster inference speed. The code is available at\nhttp://github.com/xg416/MambaTM.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T15:33:18Z"}
{"aid":"http://arxiv.org/abs/2504.02743v1","title":"Sequential Binary Hypothesis Testing with Competing Agents under\n  Information Asymmetry","summary":"This paper concerns sequential hypothesis testing in competitive multi-agent\nsystems where agents exchange potentially manipulated information.\nSpecifically, a two-agent scenario is studied where each agent aims to\ncorrectly infer the true state of nature while optimizing decision speed and\naccuracy. At each iteration, agents collect private observations, update their\nbeliefs, and share (possibly corrupted) belief signals with their counterparts\nbefore deciding whether to stop and declare a state, or continue gathering more\ninformation. The analysis yields three main results: (1)~when agents share\ninformation strategically, the optimal signaling policy involves\nequal-probability randomization between truthful and inverted beliefs;\n(2)~agents maximize performance by relying solely on their own observations for\nbelief updating while using received information only to anticipate their\ncounterpart's stopping decision; and (3)~the agent reaching their confidence\nthreshold first cause the other agent to achieve a higher conditional\nprobability of error. Numerical simulations further demonstrate that agents\nwith higher KL divergence in their conditional distributions gain competitive\nadvantage. Furthermore, our results establish that information sharing --\ndespite strategic manipulation -- reduces overall system stopping time compared\nto non-interactive scenarios, which highlights the inherent value of\ncommunication even in this competitive setup.","main_category":"eess.SY","categories":"eess.SY,cs.MA,cs.SY,math.OC","published":"2025-04-03T16:30:40Z"}
{"aid":"http://arxiv.org/abs/2504.02809v1","title":"Fractional attractors in light of the latest ACT observations","summary":"In light of the latest results from ACT observations we review a class of\npotentials labeled as fractional attractors, that can originate from Palatini\ngravity. We show in a model independent way that this class of potentials\npredicts both a spectral index $n_s$ and a tensor-to-scalar ratio $r$ which fit\nthe $1\\sigma$ region of the combination ACT+Planck data for a wide choice of\nthe parameters. We also provide a numerical fit for the parameter space of this\nmodels in the case of a simple quadratic and quartic fractional potential.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph","published":"2025-04-03T17:53:22Z"}
{"aid":"http://arxiv.org/abs/2504.04728v1","title":"Exploring Kernel Transformations for Implicit Neural Representations","summary":"Implicit neural representations (INRs), which leverage neural networks to\nrepresent signals by mapping coordinates to their corresponding attributes,\nhave garnered significant attention. They are extensively utilized for image\nrepresentation, with pixel coordinates as input and pixel values as output. In\ncontrast to prior works focusing on investigating the effect of the model's\ninside components (activation function, for instance), this work pioneers the\nexploration of the effect of kernel transformation of input/output while\nkeeping the model itself unchanged. A byproduct of our findings is a simple yet\neffective method that combines scale and shift to significantly boost INR with\nnegligible computation overhead. Moreover, we present two perspectives, depth\nand normalization, to interpret the performance benefits caused by scale and\nshift transformation. Overall, our work provides a new avenue for future works\nto understand and improve INR through the lens of kernel transformation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T04:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.04735v1","title":"Fermi Operator Expansion for the Hartree-Fock-Bogoliubov Theory","summary":"A variety of phases in the inner crust of neutron stars are crucial for\nunderstanding the pulsar phenomena. However, the three-dimensional\ncoordinate-space calculation of the phases is computationally demanding. We aim\nto generalize the Fermi Operator Expansion (FOE) method that is effective for\nfinite-temperature coordinate-space simulation, from the Hartree-Fock theory to\nHartree-Fock-Bogoliubov (HFB) theory including the pairing effects.\nFurthermore, the periodic structure with free neutrons in the inner crust\nrequires us to treat the system with the band theory. We give a concise proof\nthat the generalized density matrix in the HFB theory can be obtained with the\nFOE. The Chebyshev polynomial expansion is used for calculations of the HFB\nband theory. Using a model for a slab phase of the inner crust, the FOE method\nproduces results in good agreement with those based on the diagonalization of\nthe HFB Hamiltonian. The FOE method for the HFB band theory is a powerful tool\nfor studying the non-trivial exotic structures in neutron stars. The FOE method\nis suitable for parallelization and further acceleration is possible with\nnearsightedness.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-07T05:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.04742v1","title":"Unveiling Physical Conditions and Star Formation Processes in the G47\n  Filamentary Cloud","summary":"We present a multi-wavelength study of the filamentary cloud G47 (d\n$\\sim$4.44 kpc), which hosts the mid-infrared bubbles N98, B1, and B2. The\nSMGPS 1.3 GHz continuum map detects ionized emission toward all the bubbles,\nmarking the first detection of ionized emission toward the B2 bubble. Analysis\nof the unWISE 12.0 $\\mu$m image, Spitzer 8.0 $\\mu$m image, and the Herschel\ncolumn density and temperature maps reveals two previously unreported\nhub-filament system candidates associated with the HII regions B2 and N98,\nwhich are powered by massive OB stars. This indirectly favours the\napplicability of a global non-isotropic collapse (GNIC) scenario for massive\nstar formation in N98 and B2. The position-position-velocity diagram of FUGIN\n$^{13}$CO(1-0) shows significant velocity variations from 61 to 53 km s$^{-1}$\ntoward areas between B2 and N98, where the magnetic field morphology exhibits\nsignificant curvature, and high velocity dispersion (i.e., 2.3--3.1 km\ns$^{-1}$) is observed. This may be explained by the expansion of the HII\nregions B2 and N98. The energy budget of the cloud, estimated using SOFIA/HAWC+\nand molecular line data, suggests that the magnetic field dominates over\nturbulence and gravity in G47. Furthermore, the radial column density and\nvelocity profiles of G47 display signatures of converging flows in a sheet-like\nstructure. The relative orientations between the magnetic field and local\ngravity suggest that G47 may undergo gravitational contraction along the\nmagnetic field lines once it becomes magnetically supercritical.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-07T05:36:27Z"}
{"aid":"http://arxiv.org/abs/2504.04748v1","title":"Sharp threshold for network recovery from voter model dynamics","summary":"We investigate the problem of recovering a latent directed Erd\\H{o}s-R\\'enyi\ngraph $G^*\\sim \\mathcal G(n,p)$ from observations of discrete voter model\ntrajectories on $G^*$, where $np$ grows polynomially in $n$. Given access to\n$M$ independent voter model trajectories evolving up to time $T$, we establish\nthat $G^*$ can be recovered \\emph{exactly} with probability at least $0.9$ by\nan \\emph{efficient} algorithm, provided that \\[ M \\cdot \\min\\{T, n\\} \\geq C n^2\np^2 \\log n \\] holds for a sufficiently large constant $C$. Here, $M\\cdot\n\\min\\{T,n\\}$ can be interpreted as the approximate number of effective update\nrounds being observed, since the voter model on $G^*$ typically reaches\nconsensus after $\\Theta(n)$ rounds, and no further information can be gained\nafter this point. Furthermore, we prove an \\emph{information-theoretic} lower\nbound showing that the above condition is tight up to a constant factor. Our\nresults indicate that the recovery problem does not exhibit a\nstatistical-computational gap.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T05:47:52Z"}
{"aid":"http://arxiv.org/abs/2504.04749v1","title":"Vision Transformers with Autoencoders and Explainable AI for Cancer\n  Patient Risk Stratification Using Whole Slide Imaging","summary":"Cancer remains one of the leading causes of mortality worldwide,\nnecessitating accurate diagnosis and prognosis. Whole Slide Imaging (WSI) has\nbecome an integral part of clinical workflows with advancements in digital\npathology. While various studies have utilized WSIs, their extracted features\nmay not fully capture the most relevant pathological information, and their\nlack of interpretability limits clinical adoption.\n  In this paper, we propose PATH-X, a framework that integrates Vision\nTransformers (ViT) and Autoencoders with SHAP (Shapley Additive Explanations)\nto enhance model explainability for patient stratification and risk prediction\nusing WSIs from The Cancer Genome Atlas (TCGA). A representative image slice is\nselected from each WSI, and numerical feature embeddings are extracted using\nGoogle's pre-trained ViT. These features are then compressed via an autoencoder\nand used for unsupervised clustering and classification tasks. Kaplan-Meier\nsurvival analysis is applied to evaluate stratification into two and three risk\ngroups. SHAP is used to identify key contributing features, which are mapped\nonto histopathological slices to provide spatial context.\n  PATH-X demonstrates strong performance in breast and glioma cancers, where a\nsufficient number of WSIs enabled robust stratification. However, performance\nin lung cancer was limited due to data availability, emphasizing the need for\nlarger datasets to enhance model reliability and clinical applicability.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-07T05:48:42Z"}
{"aid":"http://arxiv.org/abs/2504.04784v1","title":"Disentangling Instruction Influence in Diffusion Transformers for\n  Parallel Multi-Instruction-Guided Image Editing","summary":"Instruction-guided image editing enables users to specify modifications using\nnatural language, offering more flexibility and control. Among existing\nframeworks, Diffusion Transformers (DiTs) outperform U-Net-based diffusion\nmodels in scalability and performance. However, while real-world scenarios\noften require concurrent execution of multiple instructions, step-by-step\nediting suffers from accumulated errors and degraded quality, and integrating\nmultiple instructions with a single prompt usually results in incomplete edits\ndue to instruction conflicts. We propose Instruction Influence Disentanglement\n(IID), a novel framework enabling parallel execution of multiple instructions\nin a single denoising process, designed for DiT-based models. By analyzing\nself-attention mechanisms in DiTs, we identify distinctive attention patterns\nin multi-instruction settings and derive instruction-specific attention masks\nto disentangle each instruction's influence. These masks guide the editing\nprocess to ensure localized modifications while preserving consistency in\nnon-edited regions. Extensive experiments on open-source and custom datasets\ndemonstrate that IID reduces diffusion steps while improving fidelity and\ninstruction completion compared to existing baselines. The codes will be\npublicly released upon the acceptance of the paper.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.04790v1","title":"Unified speed limits in classical and quantum dynamics via temporal\n  Fisher information","summary":"The importance of Fisher information is increasing in nonequilibrium\nthermodynamics, as it has played a fundamental role in trade-off relations such\nas thermodynamic uncertainty relations and speed limits. In this work, we\ninvestigate temporal Fisher information, which measures the temporal\ninformation content encoded in probability distributions, for both classical\nand quantum systems. We establish that temporal Fisher information is bounded\nfrom above by physical costs, such as entropy production in classical Langevin\nand Markov processes, and the variance of interaction Hamiltonians in open\nquantum systems. Conversely, temporal Fisher information is bounded from below\nby statistical distances (e.g., the Bhattacharyya arccos distance), leading to\nclassical and quantum speed limits that constrain the minimal time required for\nstate transformations. Our work provides a unified perspective of speed limits\nfrom the point of view of temporal Fisher information in both classical and\nquantum dynamics.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-07T07:34:18Z"}
{"aid":"http://arxiv.org/abs/2504.04797v1","title":"Addressing the Curse of Scenario and Task Generalization in AI-6G: A\n  Multi-Modal Paradigm","summary":"Existing works on machine learning (ML)-empowered wireless communication\nprimarily focus on monolithic scenarios and single tasks. However, with the\nblooming growth of communication task classes coupled with various task\nrequirements in future 6G systems, this working pattern is obviously\nunsustainable. Therefore, identifying a groundbreaking paradigm that enables a\nuniversal model to solve multiple tasks in the physical layer within diverse\nscenarios is crucial for future system evolution. This paper aims to\nfundamentally address the curse of ML model generalization across diverse\nscenarios and tasks by unleashing multi-modal feature integration capabilities\nin future systems. Given the universality of electromagnetic propagation\ntheory, the communication process is determined by the scattering environment,\nwhich can be more comprehensively characterized by cross-modal perception, thus\nproviding sufficient information for all communication tasks across varied\nenvironments. This fact motivates us to propose a transformative two-stage\nmulti-modal pre-training and downstream task adaptation paradigm...","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T07:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.04815v1","title":"Beyond Answers: How LLMs Can Pursue Strategic Thinking in Education","summary":"Artificial Intelligence (AI) holds transformative potential in education,\nenabling personalized learning, enhancing inclusivity, and encouraging\ncreativity and curiosity. In this paper, we explore how Large Language Models\n(LLMs) can act as both patient tutors and collaborative partners to enhance\neducation delivery. As tutors, LLMs personalize learning by offering\nstep-by-step explanations and addressing individual needs, making education\nmore inclusive for students with diverse backgrounds or abilities. As\ncollaborators, they expand students' horizons, supporting them in tackling\ncomplex, real-world problems and co-creating innovative projects. However, to\nfully realize these benefits, LLMs must be leveraged not as tools for providing\ndirect solutions but rather to guide students in developing resolving\nstrategies and finding learning paths together. Therefore, a strong emphasis\nshould be placed on educating students and teachers on the successful use of\nLLMs to ensure their effective integration into classrooms. Through practical\nexamples and real-world case studies, this paper illustrates how LLMs can make\neducation more inclusive and engaging while empowering students to reach their\nfull potential.","main_category":"cs.CY","categories":"cs.CY,cs.ET,eess.SP","published":"2025-04-07T08:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.04839v1","title":"Crossed Ponderomotive Lenses for Spherical Aberration Correction in\n  Electron Optics","summary":"This article evaluates the lens characteristics of a non-rotationally\nsymmetric electron lens based on a ponderomotive potential (i.e., a\nponderomotive lens) formed by intersecting one or more optical beams\nperpendicular to an electron beam. Based on geometric optics, design formulas\nare derived for the focal length and general spherical aberration coefficients\nof specifically crossed ponderomotive lenses. Numerical calculations\ndemonstrate that a pair of these crossed ponderomotive lenses can effectively\ncorrect spherical aberration in the objective lens of an electron microscope.\nUnlike rotationally symmetric ponderomotive lenses, which require the optical\nbeam to be coaxially aligned with the electron beam, the crossed ponderomotive\nlens avoids the need to place optical mirrors and lenses directly on the beam\naxis. Thus, it offers practical advantages in designing and building electron\noptical instruments and contributes to system miniaturization. With lens\nproperties similar to multipole lenses, the proposed crossed ponderomotive lens\nis expected to facilitate diverse developments in electron optical systems\nincorporating ponderomotive potentials.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T08:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.04845v1","title":"Open problems UP24","summary":"The conference Unexpected Phenomena in Energy Minimization and Polarization,\nheld in Sofia, Bulgaria in 2024, provided a platform for researchers to discuss\nand propose challenging open questions across various fields, such as potential\ntheory, approximation, special functions, point configurations, lattices, and\nnumerical analysis. The open problems sessions were productive, fruitful and\nled to a range of interesting questions. In this document, we present these\nopen problems.","main_category":"math.CA","categories":"math.CA,math-ph,math.MP","published":"2025-04-07T08:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.04857v1","title":"3D Gaussian Particle Approximation of VDB Datasets: A Study for\n  Scientific Visualization","summary":"The complexity and scale of Volumetric and Simulation datasets for Scientific\nVisualization(SciVis) continue to grow. And the approaches and advantages of\nmemory-efficient data formats and storage techniques for such datasets vary.\nOpenVDB library and its VDB data format excels in memory efficiency through its\nhierarchical and dynamic tree structure, with active and inactive sub-trees for\ndata storage. It is heavily used in current production renderers for both\nanimation and rendering stages in VFX pipelines and photorealistic rendering of\nvolumes and fluids. However, it still remains to be fully leveraged in SciVis\nwhere domains dealing with sparse scalar fields like porous media, time varying\nvolumes such as tornado and weather simulation or high resolution simulation of\nComputational Fluid Dynamics present ample number of large challenging data\nsets.Goal of this paper is not only to explore the use of OpenVDB in SciVis but\nalso to explore a level of detail(LOD) technique using 3D Gaussian particles\napproximating voxel regions. For rendering, we utilize NVIDIA OptiX library for\nray marching through the Gaussians particles. Data modeling using 3D Gaussians\nhas been very popular lately due to success in stereoscopic image to 3D scene\nconversion using Gaussian Splatting and Gaussian approximation and mixture\nmodels aren't entirely new in SciVis as well. Our work explores the integration\nwith rendering software libraries like OpenVDB and OptiX to take advantage of\ntheir built-in memory compaction and hardware acceleration features, while also\nleveraging the performance capabilities of modern GPUs. Thus, we present a\nSciVis rendering approach that uses 3D Gaussians at varying LOD in a lossy\nscheme derived from VDB datasets, rather than focusing on photorealistic volume\nrendering.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-07T09:14:15Z"}
{"aid":"http://arxiv.org/abs/2504.04861v1","title":"SAFT: Structure-aware Transformers for Textual Interaction\n  Classification","summary":"Textual interaction networks (TINs) are an omnipresent data structure used to\nmodel the interplay between users and items on e-commerce websites, social\nnetworks, etc., where each interaction is associated with a text description.\nClassifying such textual interactions (TIC) finds extensive use in detecting\nspam reviews in e-commerce, fraudulent transactions in finance, and so on.\nExisting TIC solutions either (i) fail to capture the rich text semantics due\nto the use of context-free text embeddings, and/or (ii) disregard the bipartite\nstructure and node heterogeneity of TINs, leading to compromised TIC\nperformance. In this work, we propose SAFT, a new architecture that integrates\nlanguage- and graph-based modules for the effective fusion of textual and\nstructural semantics in the representation learning of interactions. In\nparticular, line graph attention (LGA)/gated attention units (GAUs) and\npretrained language models (PLMs) are capitalized on to model the\ninteraction-level and token-level signals, which are further coupled via the\nproxy token in an iterative and contextualized fashion. Additionally, an\nefficient and theoretically-grounded approach is developed to encode the local\nand global topology information pertaining to interactions into structural\nembeddings. The resulting embeddings not only inject the structural features\nunderlying TINs into the textual interaction encoding but also facilitate the\ndesign of graph sampling strategies. Extensive empirical evaluations on\nmultiple real TIN datasets demonstrate the superiority of SAFT over the\nstate-of-the-art baselines in TIC accuracy.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T09:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.04865v1","title":"Imagining the Far East: Exploring Perceived Biases in AI-Generated\n  Images of East Asian Women","summary":"Image-generating AI, which allows users to create images from text, is\nincreasingly used to produce visual content. Despite its advancements, cultural\nbiases in AI-generated images have raised significant concerns. While much\nresearch has focused on issues within Western contexts, our study examines the\nperceived biases regarding the portrayal of East Asian women. In this\nexploratory study, we invited East Asian users to audit three popular models\n(DALL-E, Midjourney, Stable Diffusion) and identified 18 specific perceived\nbiases, categorized into four patterns: Westernization, overuse or misuse of\ncultural symbols, sexualization & feminization, and racial stereotypes. This\nwork highlights the potential challenges posed by AI models in portraying\nEastern individuals.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-07T09:20:14Z"}
{"aid":"http://arxiv.org/abs/2504.04866v1","title":"Optimal Network-Guided Covariate Selection for High-Dimensional Data\n  Integration","summary":"When integrating datasets from different studies, it is common that they have\ncomponents of different formats. How to combine them organically for improved\nestimation is important and challenging. This paper investigates this problem\nin a two-study scenario, where covariates are observed for all subjects, but\nnetwork data is available in only one study, and response variables are\navailable only in the other.\n  To leverage the partially observed network information, we propose the\nNetwork-Guided Covariate Selection (NGCS) algorithm. It integrates the spectral\ninformation from network adjacency matrices with the Higher Criticism\nThresholding approach for informative covariates identification. Theoretically,\nwe prove that NGCS achieves the optimal rate in covariate selection, which is\nthe same rate in the supervised learning setting. Furthermore, this optimality\nis robust to network models and tuning parameters.\n  This framework extends naturally to clustering and regression tasks, with two\nproposed algorithms: NG-clu and NG-reg. For clustering, NG-clu accurately\nclusters data points despite incomplete network information. For regression,\nNG-reg enhances predictive performance by incorporating latent covariate\nstructures inferred from network data. Empirical studies on synthetic and\nreal-world datasets demonstrate the robustness and superior performance of our\nalgorithms, underscoring their effectiveness in handling heterogeneous data\nformats.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-07T09:21:34Z"}
{"aid":"http://arxiv.org/abs/2504.04897v1","title":"The Minimum Eternal Vertex Cover Problem on a Subclass of\n  Series-Parallel Graphs","summary":"Eternal vertex cover is the following two-player game between a defender and\nan attacker on a graph. Initially, the defender positions k guards on k\nvertices of the graph; the game then proceeds in turns between the defender and\nthe attacker, with the attacker selecting an edge and the defender responding\nto the attack by moving some of the guards along the edges, including the\nattacked one. The defender wins a game on a graph G with k guards if they have\na strategy such that, in every round of the game, the vertices occupied by the\nguards form a vertex cover of G, and the attacker wins otherwise. The eternal\nvertex cover number of a graph G is the smallest number k of guards allowing\nthe defender to win and Eternal Vertex Cover is the problem of computing the\neternal vertex cover number of the given graph.\n  We study this problem when restricted to the well-known class of\nseries-parallel graphs. In particular, we prove that Eternal Vertex Cover can\nbe solved in linear time when restricted to melon graphs, a proper subclass of\nseries-parallel graphs. Moreover, we also conjecture that this problem is\nNP-hard on series-parallel graphs.","main_category":"math.CO","categories":"math.CO,cs.CC,cs.DM,cs.DS,G.2.2","published":"2025-04-07T10:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.04898v1","title":"SLIDE: Automated Identification and Quantification of Grain Boundary\n  Sliding and Opening in 3D","summary":"Grain Boundary (GB) deformation mechanisms such as Sliding (GBS) and Opening\n(GBO) are prevalent in alloys at high homologous temperatures but are hard to\ncapture quantitatively. We propose an automated procedure to quantify 3D GB\ndeformations at the nanoscale, using a combination of precisely aligned Digital\nImage Correlation (DIC), electron backscatter diffraction, optical\nprofilometry, and in-beam secondary electron maps. The framework, named Sliding\nidentification by Local Integration of Displacements across Edges (SLIDE), (i)\ndistinguishes GBS from GBO, (ii) computes the datapoint-wise measured in-plane\ndisplacement gradient tensor (from DIC), (iii) projects this data onto the\ntheoretical GBS tensor to reject near-GB plasticity/elasticity/noise, and (iv)\nadds the out-of-plane step from optical profilometry to yield the local 3D\nGBS/GBO vector; automatically repeated for each $\\sim$50nm-long GB segment.\nSLIDE is validated on a virtual experiment of discrete 3D sliding, and\nsuccessfully applied to Zn-coated steel experiments, yielding quantitative\nGBS/GBO activity maps.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T10:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.04906v1","title":"On misconceptions about the Brier score in binary prediction models","summary":"The Brier score is a widely used metric evaluating overall performance of\npredictions for binary outcome probabilities in clinical research. However, its\ninterpretation can be complex, as it does not align with commonly taught\nconcepts in medical statistics. Consequently, the Brier score is often\nmisinterpreted, sometimes to a significant extent, a fact that has not been\nadequately addressed in the literature. This commentary aims to explore\nprevalent misconceptions surrounding the Brier score and elucidate the reasons\nthese interpretations are incorrect.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-07T10:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.04939v1","title":"A Taxonomy of Self-Handover","summary":"Self-handover, transferring an object between one's own hands, is a common\nbut understudied bimanual action. While it facilitates seamless transitions in\ncomplex tasks, the strategies underlying its execution remain largely\nunexplored. Here, we introduce the first systematic taxonomy of self-handover,\nderived from manual annotation of over 12 hours of cooking activity performed\nby 21 participants. Our analysis reveals that self-handover is not merely a\npassive transition, but a highly coordinated action involving anticipatory\nadjustments by both hands. As a step toward automated analysis of human\nmanipulation, we further demonstrate the feasibility of classifying\nself-handover types using a state-of-the-art vision-language model. These\nfindings offer fresh insights into bimanual coordination, underscoring the role\nof self-handover in enabling smooth task transitions-an ability essential for\nadaptive dual-arm robotics.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-04-07T11:21:42Z"}
{"aid":"http://arxiv.org/abs/2504.04942v1","title":"Lemmanaid: Neuro-Symbolic Lemma Conjecturing","summary":"Automatically conjecturing useful, interesting and novel lemmas would greatly\nimprove automated reasoning tools and lower the bar for formalizing mathematics\nin proof assistants. It is however a very challenging task for both neural and\nsymbolic approaches. We present the first steps towards a practical\nneuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language\nModels (LLMs) and symbolic methods, and evaluate it on proof libraries for the\nIsabelle proof assistant. We train an LLM to generate lemma templates that\ndescribe the shape of a lemma, and use symbolic methods to fill in the details.\nWe compare Lemmanaid against an LLM trained to generate complete lemma\nstatements as well as previous fully symbolic conjecturing methods. Our results\nindicate that neural and symbolic techniques are complementary. By leveraging\nthe best of both symbolic and neural methods we can generate useful lemmas for\na wide range of input domains, facilitating computer-assisted theory\ndevelopment and formalization.","main_category":"cs.AI","categories":"cs.AI,cs.LO","published":"2025-04-07T11:30:36Z"}
{"aid":"http://arxiv.org/abs/2504.04949v1","title":"One Quantizer is Enough: Toward a Lightweight Audio Codec","summary":"Neural audio codecs have recently gained traction for their ability to\ncompress high-fidelity audio and generate discrete tokens that can be utilized\nin downstream generative modeling tasks. However, leading approaches often rely\non resource-intensive models and multi-quantizer architectures, resulting in\nconsiderable computational overhead and constrained real-world applicability.\nIn this paper, we present SQCodec, a lightweight neural audio codec that\nleverages a single quantizer to address these limitations. SQCodec explores\nstreamlined convolutional networks and local Transformer modules, alongside\nTConv, a novel mechanism designed to capture acoustic variations across\nmultiple temporal scales, thereby enhancing reconstruction fidelity while\nreducing model complexity. Extensive experiments across diverse datasets show\nthat SQCodec achieves audio quality comparable to multi-quantizer baselines,\nwhile its single-quantizer design offers enhanced adaptability and its\nlightweight architecture reduces resource consumption by an order of magnitude.\nThe source code is publicly available at https://github.com/zhai-lw/SQCodec.","main_category":"cs.SD","categories":"cs.SD,cs.AI,I.2.m","published":"2025-04-07T11:34:39Z"}
{"aid":"http://arxiv.org/abs/2504.04953v1","title":"M-Prometheus: A Suite of Open Multilingual LLM Judges","summary":"The use of language models for automatically evaluating long-form text\n(LLM-as-a-judge) is becoming increasingly common, yet most LLM judges are\noptimized exclusively for English, with strategies for enhancing their\nmultilingual evaluation capabilities remaining largely unexplored in the\ncurrent literature. This has created a disparity in the quality of automatic\nevaluation methods for non-English languages, ultimately hindering the\ndevelopment of models with better multilingual capabilities. To bridge this\ngap, we introduce M-Prometheus, a suite of open-weight LLM judges ranging from\n3B to 14B parameters that can provide both direct assessment and pairwise\ncomparison feedback on multilingual outputs. M-Prometheus models outperform\nstate-of-the-art open LLM judges on multilingual reward benchmarks spanning\nmore than 20 languages, as well as on literary machine translation (MT)\nevaluation covering 4 language pairs. Furthermore, M-Prometheus models can be\nleveraged at decoding time to significantly improve generated outputs across\nall 3 tested languages, showcasing their utility for the development of better\nmultilingual models. Lastly, through extensive ablations, we identify the key\nfactors for obtaining an effective multilingual judge, including backbone model\nselection and training on natively multilingual feedback data instead of\ntranslated data. We release our models, training dataset, and code.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T11:37:26Z"}
{"aid":"http://arxiv.org/abs/2504.04958v1","title":"Probabilistic imaginary-time evolution in state-vector-based and\n  shot-based simulations and on quantum devices","summary":"Imaginary-time evolution, an important technique in tensor network and\nquantum Monte Carlo algorithms on classical computers, has recently been\nadapted to quantum computing. In this study, we focus on probabilistic\nimaginary-time evolution (PITE) algorithm and derive its formulation in the\ncontext of state-vector-based simulations, where quantum state vectors are\ndirectly used to compute observables without statistical errors. We compare the\nresults with those of shot-based simulations, which estimate observables\nthrough repeated projective measurements. Applying the PITE algorithm to the\nHeisenberg chain, we investigate optimal initial conditions for convergence. We\nfurther demonstrate the method on the transverse-field Ising model using a\nstate-of-the-art trapped-ion quantum device. Finally, we explore the potential\nof error mitigation in this framework, highlighting practical considerations\nfor near-term digital quantum simulations.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-07T11:45:31Z"}
{"aid":"http://arxiv.org/abs/2504.04971v1","title":"Below threshold nonsequential double ionization with linearly polarized\n  two-color fields II: Quantum interference","summary":"We perform a systematic analysis of intra-channel quantum interference in\nlaser-induced nonsequential double ionization with linearly polarized\nbichromatic fields, focusing on the recollision-excitation with subsequent\nionization (RESI) mechanism, and employing the strong-field approximation. We\ngeneralize and elaborate several analytic interference conditions for RESI in\narbitrary driving fields, with a focus on the interference arising from the\nspecific symmetries of bichromatic fields. For example, for waves of comparable\nstrengths, multiple events per half cycle for the direct electron must be\nconsidered. Furthermore, interference breaks some of the symmetries arising\nfrom the field. We detangle the superimposed interference fringes originating\nfrom phase differences related to symmetrization due to electron exchange,\ntemporal shifts and a combination of exchange and event interference. We show\nthat the hierarchy between exchange-only and exchange-temporal interference is\nfluid and can be manipulated by an appropriate choice of driving-field\nparameters. This is enabled by different types of interference occupying\nspecific regions of the plane spanned by the electron momentum components\nparallel to the driving-field polarization.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-07T11:57:18Z"}
{"aid":"http://arxiv.org/abs/2504.04976v1","title":"A Domain-Based Taxonomy of Jailbreak Vulnerabilities in Large Language\n  Models","summary":"The study of large language models (LLMs) is a key area in open-world machine\nlearning. Although LLMs demonstrate remarkable natural language processing\ncapabilities, they also face several challenges, including consistency issues,\nhallucinations, and jailbreak vulnerabilities. Jailbreaking refers to the\ncrafting of prompts that bypass alignment safeguards, leading to unsafe outputs\nthat compromise the integrity of LLMs. This work specifically focuses on the\nchallenge of jailbreak vulnerabilities and introduces a novel taxonomy of\njailbreak attacks grounded in the training domains of LLMs. It characterizes\nalignment failures through generalization, objectives, and robustness gaps. Our\nprimary contribution is a perspective on jailbreak, framed through the\ndifferent linguistic domains that emerge during LLM training and alignment.\nThis viewpoint highlights the limitations of existing approaches and enables us\nto classify jailbreak attacks on the basis of the underlying model deficiencies\nthey exploit. Unlike conventional classifications that categorize attacks based\non prompt construction methods (e.g., prompt templating), our approach provides\na deeper understanding of LLM behavior. We introduce a taxonomy with four\ncategories -- mismatched generalization, competing objectives, adversarial\nrobustness, and mixed attacks -- offering insights into the fundamental nature\nof jailbreak vulnerabilities. Finally, we present key lessons derived from this\ntaxonomic study.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-04-07T12:05:16Z"}
{"aid":"http://arxiv.org/abs/2504.04980v1","title":"Combining kinetic and thermodynamic uncertainty relations in quantum\n  transport","summary":"We study the fluctuations of generic currents in multi-terminal,\nmulti-channel quantum transport settings. In the quantum regime, these\nfluctuations and the resulting precision differ strongly depending on whether\nthe device is of fermionic or bosonic nature. Using scattering theory, we show\nthat the precision is bounded by constraints set by the entropy production and\nby the activity in the spirit of thermodynamic or kinetic uncertainty\nrelations, valid for fermionic and bosonic quantum systems and even in the\nabsence of time-reversal symmetry. Furthermore, we derive a combined\nthermodynamic kinetic uncertainty relation, which is tight over a wide range of\nparameters and can hence predict the reachable precision of a device.\n  Since these constraints can be expressed in terms of observables accessible\nin transport measurements, such as currents and bandwidth, we foresee that the\ntight thermodynamic kinetic uncertainty-like bounds are also useful as an\ninference tool: they can be exploited to estimate entropy production from\ntransport observables, such as the charge current and its noise, which are more\neasily accessible in experiment.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-04-07T12:09:09Z"}
{"aid":"http://arxiv.org/abs/2504.04985v1","title":"Quasi-periodic sub-structure of RRAT J1913+1330","summary":"Recent findings suggest a universal relationship between the quasi-periodic\nsub-structures and rotational periods across various types of radio-emitting\nneutron stars. In this study, we report the detection of 12 quasi-periodic\nsub-structures in a rotating radio transient (RRAT) J1913+1330 using the\nFive-hundred-meter Aperture Spherical Radio Telescope (FAST). This is the\nsecond known RRAT exhibiting quasi-periodic sub-structures. Our result\nreinforces the observed relationship between quasi-periodicity and rotational\nperiod. The polarization analysis reveals that 11 of the 12 pulses exhibit high\nlinear polarization consistent with the quasi-periodic behaviour of the total\nintensity, while circular polarization with detectable quasi-periodic\nsub-structures is observed in only three pulses. No correlation is found\nbetween the sub-structure periods and their widths, peak fluxes, or fluences,\neven under the extremely variable single-pulse energy and morphology observed\nin J1913+1330.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T12:11:49Z"}
{"aid":"http://arxiv.org/abs/2504.04986v1","title":"Quantum control of a random transverse Ising spin system","summary":"We consider subspace transfer within the time-dependent one-dimensional\nquantum transverse Ising model, with random nearest-neighbor interactions and a\ntransverse field. We run numerical simulations using a variational approach and\nthe numerical GRAPE (gradient-ascent pulse engineering) and dCRAB (dressed\nchopped random basis) quantum control algorithms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T12:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.04989v1","title":"Randomized block Krylov method for approximation of truncated tensor SVD","summary":"This paper is devoted to studying the application of the block Krylov\nsubspace method for approximation of the truncated tensor SVD (T-SVD). The\ntheoretical results of the proposed randomized approach are presented. Several\nexperimental experiments using synthetics and real-world data are conducted to\nverify the efficiency and feasibility of the proposed randomized approach, and\nthe numerical results show that the proposed method provides promising results.\nApplications of the proposed approach to data completion and data compression\nare presented.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T12:13:47Z"}
{"aid":"http://arxiv.org/abs/2504.05001v1","title":"SILVIA: Ultra-precision formation flying demonstration for space-based\n  interferometry","summary":"We propose SILVIA (Space Interferometer Laboratory Voyaging towards\nInnovative Applications), a mission concept designed to demonstrate\nultra-precision formation flying between three spacecraft separated by 100 m.\nSILVIA aims to achieve sub-micrometer precision in relative distance control by\nintegrating spacecraft sensors, laser interferometry, low-thrust and low-noise\nmicro-propulsion for real-time measurement and control of distances and\nrelative orientations between spacecraft. A 100-meter-scale mission in a\nnear-circular low Earth orbit has been identified as an ideal, cost-effective\nsetting for demonstrating SILVIA, as this configuration maintains a good\nbalance between small relative perturbations and low risk for collision. This\nmission will fill the current technology gap towards future missions, including\ngravitational wave observatories such as DECIGO (DECihertz Interferometer\nGravitational wave Observatory), designed to detect the primordial\ngravitational wave background, and high-contrast nulling infrared\ninterferometers like LIFE (Large Interferometer for Exoplanets), designed for\ndirect imaging of thermal emissions from nearby terrestrial planet candidates.\nThe mission concept and its key technologies are outlined, paving the way for\nthe next generation of high-precision space-based observatories.","main_category":"astro-ph.IM","categories":"astro-ph.IM,cs.SY,eess.SY,gr-qc,physics.ins-det","published":"2025-04-07T12:27:46Z"}
{"aid":"http://arxiv.org/abs/2504.05004v1","title":"Stacking Variational Bayesian Monte Carlo","summary":"Variational Bayesian Monte Carlo (VBMC) is a sample-efficient method for\napproximate Bayesian inference with computationally expensive likelihoods.\nWhile VBMC's local surrogate approach provides stable approximations, its\nconservative exploration strategy and limited evaluation budget can cause it to\nmiss regions of complex posteriors. In this work, we introduce Stacking\nVariational Bayesian Monte Carlo (S-VBMC), a method that constructs global\nposterior approximations by merging independent VBMC runs through a principled\nand inexpensive post-processing step. Our approach leverages VBMC's mixture\nposterior representation and per-component evidence estimates, requiring no\nadditional likelihood evaluations while being naturally parallelizable. We\ndemonstrate S-VBMC's effectiveness on two synthetic problems designed to\nchallenge VBMC's exploration capabilities and two real-world applications from\ncomputational neuroscience, showing substantial improvements in posterior\napproximation quality across all cases.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-07T12:30:59Z"}
{"aid":"http://arxiv.org/abs/2504.05005v1","title":"Can audio recordings be used to detect leaks and coughs during\n  mechanical insufflation exsufflation (MI-E) treatment?","summary":"This report relates to a study group hosted by the EPSRC funded network,\nIntegrating data-driven BIOphysical models into REspiratory MEdicine (BIOREME),\nand supported by SofTMech and Innovate UK, Business Connect. The BIOREME\nnetwork hosts events, including this study group, to bring together\nmulti-disciplinary researchers, clinicians, companies and charities to catalyse\nresearch in the applications of mathematical modelling for respiratory\nmedicine. The goal of this study group was to provide an interface between\ncompanies, clinicians, and mathematicians to develop mathematical tools to the\nproblems presented. The study group was held at The University of Glasgow on\nthe 17 - 21 June 2024 and was attended by 16 participants from 8 different\ninstitutions. Below details the technical report of one of the challenges and\nthe methods developed by the team of researchers who worked on this challenge.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-07T12:32:01Z"}
{"aid":"http://arxiv.org/abs/2504.05028v1","title":"The Lorentzian splitting theorem with weakened curvature condition","summary":"In this note we present a version of the Lorentzian splitting theorem under\nan averaged Ricci curvature condition, utilizing, in its proof, the properties\nof achronal limits developed in [18], [19].","main_category":"math.DG","categories":"math.DG,gr-qc","published":"2025-04-07T12:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.05050v1","title":"Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language\n  Models","summary":"Large language models (LLMs) are foundational explorations to artificial\ngeneral intelligence, yet their alignment with human values via instruction\ntuning and preference learning achieves only superficial compliance. Here, we\ndemonstrate that harmful knowledge embedded during pretraining persists as\nindelible \"dark patterns\" in LLMs' parametric memory, evading alignment\nsafeguards and resurfacing under adversarial inducement at distributional\nshifts. In this study, we first theoretically analyze the intrinsic ethical\nvulnerability of aligned LLMs by proving that current alignment methods yield\nonly local \"safety regions\" in the knowledge manifold. In contrast, pretrained\nknowledge remains globally connected to harmful concepts via high-likelihood\nadversarial trajectories. Building on this theoretical insight, we empirically\nvalidate our findings by employing semantic coherence inducement under\ndistributional shifts--a method that systematically bypasses alignment\nconstraints through optimized adversarial prompts. This combined theoretical\nand empirical approach achieves a 100% attack success rate across 19 out of 23\nstate-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing\ntheir universal vulnerabilities.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T13:20:17Z"}
{"aid":"http://arxiv.org/abs/2504.05062v1","title":"LDGNet: A Lightweight Difference Guiding Network for Remote Sensing\n  Change Detection","summary":"With the rapid advancement of deep learning, the field of change detection\n(CD) in remote sensing imagery has achieved remarkable progress. Existing\nchange detection methods primarily focus on achieving higher accuracy with\nincreased computational costs and parameter sizes, leaving development of\nlightweight methods for rapid real-world processing an underexplored challenge.\nTo address this challenge, we propose a Lightweight Difference Guiding Network\n(LDGNet), leveraging absolute difference image to guide optical remote sensing\nchange detection. First, to enhance the feature representation capability of\nthe lightweight backbone network, we propose the Difference Guiding Module\n(DGM), which leverages multi-scale features extracted from the absolute\ndifference image to progressively influence the original image encoder at each\nlayer, thereby reinforcing feature extraction. Second, we propose the\nDifference-Aware Dynamic Fusion (DADF) module with Visual State Space Model\n(VSSM) for lightweight long-range dependency modeling. The module first uses\nfeature absolute differences to guide VSSM's global contextual modeling of\nchange regions, then employs difference attention to dynamically fuse these\nlong-range features with feature differences, enhancing change semantics while\nsuppressing noise and background. Extensive experiments on multiple datasets\ndemonstrate that our method achieves comparable or superior performance to\ncurrent state-of-the-art (SOTA) methods requiring several times more\ncomputation, while maintaining only 3.43M parameters and 1.12G FLOPs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.05076v1","title":"Content-Distortion High-Order Interaction for Blind Image Quality\n  Assessment","summary":"The content and distortion are widely recognized as the two primary factors\naffecting the visual quality of an image. While existing No-Reference Image\nQuality Assessment (NR-IQA) methods have modeled these factors, they fail to\ncapture the complex interactions between content and distortions. This\nshortfall impairs their ability to accurately perceive quality. To confront\nthis, we analyze the key properties required for interaction modeling and\npropose a robust NR-IQA approach termed CoDI-IQA (Content-Distortion high-order\nInteraction for NR-IQA), which aggregates local distortion and global content\nfeatures within a hierarchical interaction framework. Specifically, a\nProgressive Perception Interaction Module (PPIM) is proposed to explicitly\nsimulate how content and distortions independently and jointly influence image\nquality. By integrating internal interaction, coarse interaction, and fine\ninteraction, it achieves high-order interaction modeling that allows the model\nto properly represent the underlying interaction patterns. To ensure sufficient\ninteraction, multiple PPIMs are employed to hierarchically fuse multi-level\ncontent and distortion features at different granularities. We also tailor a\ntraining strategy suited for CoDI-IQA to maintain interaction stability.\nExtensive experiments demonstrate that the proposed method notably outperforms\nthe state-of-the-art methods in terms of prediction accuracy, data efficiency,\nand generalization ability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:44:30Z"}
{"aid":"http://arxiv.org/abs/2504.05078v1","title":"Serverless Approach to Running Resource-Intensive STAR Aligner","summary":"The application of serverless computing for alignment of RNA-sequences can\nimprove many existing bioinformatics workflows by reducing operational costs\nand execution times. This work analyzes the applicability of serverless\nservices for running the STAR aligner, which is known for its accuracy and\nlarge memory requirement. This presents a challenge, as serverless services\nwere designed for light and short tasks. Nevertheless, we successfully deploy a\nSTAR-based pipeline on AWS ECS service, propose multiple optimizations, and\nperform experiment with 17 TBs of data. Results are compared against standard\nvirtual machine (VM) based solution showing that serverless is a valid\nalternative for small-scale batch processing. However, in large-scale where\nefficiency matters the most, VMs are still recommended.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-07T13:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.05079v1","title":"Experimental verification of Threshold Quantum State Tomography on a\n  fully-reconfigurable photonic integrated circuit","summary":"Reconstructing the state of a complex quantum system represents a pivotal\ntask for all quantum information applications, both for characterization\npurposes and for verification of quantum protocols. Recent technological\ndevelopments have shown the capability of building quantum systems with\nprogressively larger number of qubits in different platforms. The standard\napproach based on quantum state tomography, while providing a method to\ncompletely characterize an unknown quantum state, requires a number of\nmeasurements that scales exponentially with the number of qubits. Other methods\nhave been subsequently proposed and tested to reduce the number of\nmeasurements, or to focus on specific properties of the output state rather\nthan on its complete reconstruction. Here, we show experimentally the\napplication of an approach, called threshold quantum state tomography, in an\nadvanced hybrid photonic platform with states up to n=4 qubits. This method\ndoes not require a priori knowledge on the state, and selects only the\ninformative projectors starting from the measurement of the density matrix\ndiagonal. We show the effectiveness of this approach in a photonic platform,\nshowing that a consistent reduction in the number of measurement is obtained\nwhile reconstructing relevant states for quantum protocols, with only very\nlimited loss of information. The advantage of this protocol opens perspective\nof its application in larger, more complex, systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T13:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.05109v1","title":"Inverse Mixed Integer Optimization: An Interior Point Perspective","summary":"We propose a novel solution framework for inverse mixed-integer optimization\nbased on analytic center concepts from interior point methods. We characterize\nthe optimality gap of a given solution, provide structural results, and propose\nmodels that can efficiently solve large problems. First, we exploit the\nproperty that mixed-integer solutions are primarily interior points that can be\nmodeled as weighted analytic centers with unique weights. We then demonstrate\nthat the optimality of a given solution can be measured relative to an\nidentifiable optimal solution to the linear programming relaxation. We quantify\nthe absolute optimality gap and pose the inverse mixed-integer optimization\nproblem as a bi-level program where the upper-level objective minimizes the\nnorm to a given reference cost, while the lower-level objective minimizes the\nabsolute optimality gap to an optimal linear programming solution. We provide\ntwo models that address the discrepancies between the upper and lower-level\nproblems, establish links with noisy and data-driven optimization, and conduct\nextensive numerical testing. We find that the proposed framework successfully\nidentifies high-quality solutions in rapid computational times. Compared to the\nstate-of-the-art trust region cutting plane method, it achieves optimal cost\nvectors for 95% and 68% of the instances within optimality gaps of e-2 and e-5,\nrespectively, without sacrificing the relative proximity to the nominal cost\nvector. To ensure the optimality of the given solution, the proposed approach\nis complemented by a classical cutting plane method. It is shown to solve\ninstances that the trust region cutting plane method could not successfully\nsolve as well as being in very close proximity to the nominal cost vector.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T14:15:17Z"}
{"aid":"http://arxiv.org/abs/2504.05169v1","title":"Machine learning interatomic potential can infer electrical response","summary":"Modeling the response of material and chemical systems to electric fields\nremains a longstanding challenge. Machine learning interatomic potentials\n(MLIPs) offer an efficient and scalable alternative to quantum mechanical\nmethods but do not by themselves incorporate electrical response. Here, we show\nthat polarization and Born effective charge (BEC) tensors can be directly\nextracted from long-range MLIPs within the Latent Ewald Summation (LES)\nframework, solely by learning from energy and force data. Using this approach,\nwe predict the infrared spectra of bulk water under zero or finite external\nelectric fields, ionic conductivities of high-pressure superionic ice, and the\nphase transition and hysteresis in ferroelectric PbTiO$_3$ perovskite. This\nwork thus extends the capability of MLIPs to predict electrical\nresponse--without training on charges or polarization or BECs--and enables\naccurate modeling of electric-field-driven processes in diverse systems at\nscale.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.chem-ph,physics.comp-ph","published":"2025-04-07T15:14:07Z"}
{"aid":"http://arxiv.org/abs/2504.05202v1","title":"Infinitely Divisible Noise for Differential Privacy: Nearly Optimal\n  Error in the High $\\varepsilon$ Regime","summary":"Differential privacy (DP) can be achieved in a distributed manner, where\nmultiple parties add independent noise such that their sum protects the overall\ndataset with DP. A common technique here is for each party to sample their\nnoise from the decomposition of an infinitely divisible distribution. We\nanalyze two mechanisms in this setting: 1) the generalized discrete Laplace\n(GDL) mechanism, whose distribution (which is closed under summation) follows\nfrom differences of i.i.d. negative binomial shares, and 2) the multi-scale\ndiscrete Laplace (MSDLap) mechanism, a novel mechanism following the sum of\nmultiple i.i.d. discrete Laplace shares at different scales.\n  For $\\varepsilon \\geq 1$, our mechanisms can be parameterized to have\n$O\\left(\\Delta^3 e^{-\\varepsilon}\\right)$ and $O\\left(\\min\\left(\\Delta^3\ne^{-\\varepsilon}, \\Delta^2 e^{-2\\varepsilon/3}\\right)\\right)$ MSE,\nrespectively, where $\\Delta$ denote the sensitivity; the latter bound matches\nknown optimality results. We also show a transformation from the discrete\nsetting to the continuous setting, which allows us to transform both mechanisms\nto the continuous setting and thereby achieve the optimal $O\\left(\\Delta^2\ne^{-2\\varepsilon / 3}\\right)$ MSE. To our knowledge, these are the first\ninfinitely divisible additive noise mechanisms that achieve order-optimal MSE\nunder pure DP, so our work shows formally there is no separation in utility\nwhen query-independent noise adding mechanisms are restricted to infinitely\ndivisible noise. For the continuous setting, our result improves upon the Arete\nmechanism from [Pagh and Stausholm, ALT 2022] which gives an MSE of\n$O\\left(\\Delta^2 e^{-\\varepsilon/4}\\right)$. Furthermore, we give an exact\nsampler tuned to efficiently implement the MSDLap mechanism, and we apply our\nresults to improve a state of the art multi-message shuffle DP protocol in the\nhigh $\\varepsilon$ regime.","main_category":"cs.CR","categories":"cs.CR,cs.DS","published":"2025-04-07T15:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.05214v1","title":"Post-Training Language Models for Continual Relation Extraction","summary":"Real-world data, such as news articles, social media posts, and chatbot\nconversations, is inherently dynamic and non-stationary, presenting significant\nchallenges for constructing real-time structured representations through\nknowledge graphs (KGs). Relation Extraction (RE), a fundamental component of KG\ncreation, often struggles to adapt to evolving data when traditional models\nrely on static, outdated datasets. Continual Relation Extraction (CRE) methods\ntackle this issue by incrementally learning new relations while preserving\npreviously acquired knowledge. This study investigates the application of\npre-trained language models (PLMs), specifically large language models (LLMs),\nto CRE, with a focus on leveraging memory replay to address catastrophic\nforgetting. We evaluate decoder-only models (eg, Mistral-7B and Llama2-7B) and\nencoder-decoder models (eg, Flan-T5 Base) on the TACRED and FewRel datasets.\nTask-incremental fine-tuning of LLMs demonstrates superior performance over\nearlier approaches using encoder-only models like BERT on TACRED, excelling in\nseen-task accuracy and overall performance (measured by whole and average\naccuracy), particularly with the Mistral and Flan-T5 models. Results on FewRel\nare similarly promising, achieving second place in whole and average accuracy\nmetrics. This work underscores critical factors in knowledge transfer, language\nmodel architecture, and KG completeness, advancing CRE with LLMs and memory\nreplay for dynamic, real-time relation extraction.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:01:22Z"}
{"aid":"http://arxiv.org/abs/2504.05218v1","title":"Hybrid machine learning data assimilation for marine biogeochemistry","summary":"Marine biogeochemistry models are critical for forecasting, as well as\nestimating ecosystem responses to climate change and human activities. Data\nassimilation (DA) improves these models by aligning them with real-world\nobservations, but marine biogeochemistry DA faces challenges due to model\ncomplexity, strong nonlinearity, and sparse, uncertain observations. Existing\nDA methods applied to marine biogeochemistry struggle to update unobserved\nvariables effectively, while ensemble-based methods are computationally too\nexpensive for high-complexity marine biogeochemistry models. This study\ndemonstrates how machine learning (ML) can improve marine biogeochemistry DA by\nlearning statistical relationships between observed and unobserved variables.\nWe integrate ML-driven balancing schemes into a 1D prototype of a system used\nto forecast marine biogeochemistry in the North-West European Shelf seas. ML is\napplied to predict (i) state-dependent correlations from free-run ensembles and\n(ii), in an ``end-to-end'' fashion, analysis increments from an Ensemble Kalman\nFilter. Our results show that ML significantly enhances updates for previously\nnot-updated variables when compared to univariate schemes akin to those used\noperationally. Furthermore, ML models exhibit moderate transferability to new\nlocations, a crucial step toward scaling these methods to 3D operational\nsystems. We conclude that ML offers a clear pathway to overcome current\ncomputational bottlenecks in marine biogeochemistry DA and that refining\ntransferability, optimizing training data sampling, and evaluating scalability\nfor large-scale marine forecasting, should be future research priorities.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.LG","published":"2025-04-07T16:04:10Z"}
{"aid":"http://arxiv.org/abs/2504.05233v1","title":"Formation of Near-surface Atmospheric Inversion and Surface Inversion in\n  Hothouse Climates","summary":"A hothouse climate may develop throughout Earth's history and its warming\nfuture and on potentially habitable exoplanets near the inner edge of the\nhabitable zone. Previous studies suggested that near-surface atmospheric\ninversion (NAIV) with planetary boundary air temperature being higher than the\nair temperature adjacent to the surface, is a pronounced phenomenon in hothouse\nclimates. However, the underlying mechanisms are unclear. Here we show that\nlower-tropospheric radiative heating is necessary but not independently\nsufficient in forming the NAIV. Instead, the dynamic heating induced by\nlarge-scale subsidence is essential. With the prescribed reasonable large-scale\nsubsidence, NAIV appears in small-domain cloud-resolving simulations, which was\nnot observed in previous studies. Surface evaporative cooling also contributes\nto the formation of the NAIV. Besides NAIV, we find that surface inversion\n(SIV) with the air adjacent to the surface being warmer than the underlying sea\nsurface is also a distinct phenomenon in hothouse climates. SIV is caused by\nstrong surface evaporative cooling and large atmospheric shortwave absorption.\nThese two types of inversion strongly stabilize the atmosphere, weaken\natmospheric circulation, dry the free troposphere, and suppress the\nhydrological cycle.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.ao-ph","published":"2025-04-07T16:18:06Z"}
{"aid":"http://arxiv.org/abs/2504.05287v1","title":"RobustDexGrasp: Robust Dexterous Grasping of General Objects from\n  Single-view Perception","summary":"Robust grasping of various objects from single-view perception is fundamental\nfor dexterous robots. Previous works often rely on fully observable objects,\nexpert demonstrations, or static grasping poses, which restrict their\ngeneralization ability and adaptability to external disturbances. In this\npaper, we present a reinforcement-learning-based framework that enables\nzero-shot dynamic dexterous grasping of a wide range of unseen objects from\nsingle-view perception, while performing adaptive motions to external\ndisturbances. We utilize a hand-centric object representation for shape feature\nextraction that emphasizes interaction-relevant local shapes, enhancing\nrobustness to shape variance and uncertainty. To enable effective hand\nadaptation to disturbances with limited observations, we propose a mixed\ncurriculum learning strategy, which first utilizes imitation learning to\ndistill a policy trained with privileged real-time visual-tactile feedback, and\ngradually transfers to reinforcement learning to learn adaptive motions under\ndisturbances caused by observation noises and dynamic randomization. Our\nexperiments demonstrate strong generalization in grasping unseen objects with\nrandom poses, achieving success rates of 97.0% across 247,786 simulated objects\nand 94.6% across 512 real objects. We also demonstrate the robustness of our\nmethod to various disturbances, including unobserved object movement and\nexternal forces, through both quantitative and qualitative evaluations. Project\nPage: https://zdchan.github.io/Robust_DexGrasp/","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T17:38:19Z"}
{"aid":"http://arxiv.org/abs/2504.05296v1","title":"Let it Snow! Animating Static Gaussian Scenes With Dynamic Weather\n  Effects","summary":"3D Gaussian Splatting has recently enabled fast and photorealistic\nreconstruction of static 3D scenes. However, introducing dynamic elements that\ninteract naturally with such static scenes remains challenging. Accordingly, we\npresent a novel hybrid framework that combines Gaussian-particle\nrepresentations for incorporating physically-based global weather effects into\nstatic 3D Gaussian Splatting scenes, correctly handling the interactions of\ndynamic elements with the static scene. We follow a three-stage process: we\nfirst map static 3D Gaussians to a particle-based representation. We then\nintroduce dynamic particles and simulate their motion using the Material Point\nMethod (MPM). Finally, we map the simulated particles back to the Gaussian\ndomain while introducing appearance parameters tailored for specific effects.\nTo correctly handle the interactions of dynamic elements with the static scene,\nwe introduce specialized collision handling techniques. Our approach supports a\nvariety of weather effects, including snowfall, rainfall, fog, and sandstorms,\nand can also support falling objects, all with physically plausible motion and\nappearance. Experiments demonstrate that our method significantly outperforms\nexisting approaches in both visual quality and physical realism.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-07T17:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.05298v1","title":"One-Minute Video Generation with Test-Time Training","summary":"Transformers today still struggle to generate one-minute videos because\nself-attention layers are inefficient for long context. Alternatives such as\nMamba layers struggle with complex multi-scene stories because their hidden\nstates are less expressive. We experiment with Test-Time Training (TTT) layers,\nwhose hidden states themselves can be neural networks, therefore more\nexpressive. Adding TTT layers into a pre-trained Transformer enables it to\ngenerate one-minute videos from text storyboards. For proof of concept, we\ncurate a dataset based on Tom and Jerry cartoons. Compared to baselines such as\nMamba~2, Gated DeltaNet, and sliding-window attention layers, TTT layers\ngenerate much more coherent videos that tell complex stories, leading by 34 Elo\npoints in a human evaluation of 100 videos per method. Although promising,\nresults still contain artifacts, likely due to the limited capability of the\npre-trained 5B model. The efficiency of our implementation can also be\nimproved. We have only experimented with one-minute videos due to resource\nconstraints, but the approach can be extended to longer videos and more complex\nstories. Sample videos, code and annotations are available at:\nhttps://test-time-training.github.io/video-dit","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.05306v1","title":"CREA: A Collaborative Multi-Agent Framework for Creative Content\n  Generation with Diffusion Models","summary":"Creativity in AI imagery remains a fundamental challenge, requiring not only\nthe generation of visually compelling content but also the capacity to add\nnovel, expressive, and artistically rich transformations to images. Unlike\nconventional editing tasks that rely on direct prompt-based modifications,\ncreative image editing demands an autonomous, iterative approach that balances\noriginality, coherence, and artistic intent. To address this, we introduce\nCREA, a novel multi-agent collaborative framework that mimics the human\ncreative process. Our framework leverages a team of specialized AI agents who\ndynamically collaborate to conceptualize, generate, critique, and enhance\nimages. Through extensive qualitative and quantitative evaluations, we\ndemonstrate that CREA significantly outperforms state-of-the-art methods in\ndiversity, semantic alignment, and creative transformation. By structuring\ncreativity as a dynamic, agentic process, CREA redefines the intersection of AI\nand art, paving the way for autonomous AI-driven artistic exploration,\ngenerative design, and human-AI co-creation. To the best of our knowledge, this\nis the first work to introduce the task of creative editing.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.05639v1","title":"DBOT: Artificial Intelligence for Systematic Long-Term Investing","summary":"Long-term investing was previously seen as requiring human judgment. With the\nadvent of generative artificial intelligence (AI) systems, automated systematic\nlong-term investing is now feasible. In this paper, we present DBOT, a system\nwhose goal is to reason about valuation like Aswath Damodaran, who is a unique\nexpert in the investment arena in terms of having published thousands of\nvaluations on companies in addition to his numerous writings on the topic,\nwhich provide ready training data for an AI system. DBOT can value any publicly\ntraded company. DBOT can also be back-tested, making its behavior and\nperformance amenable to scientific inquiry. We compare DBOT to its analytic\nparent, Damodaran, and highlight the research challenges involved in raising\nits current capability to that of Damodaran's. Finally, we examine the\nimplications of DBOT-like AI agents for the financial industry, especially how\nthey will impact the role of human analysts in valuation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,q-fin.PR","published":"2025-04-08T03:34:22Z"}
{"aid":"http://arxiv.org/abs/2504.05653v1","title":"How communities shape epidemic spreading: A hierarchically structured\n  metapopulation perspective","summary":"Recent outbreaks of COVID-19, Zika, Ebola, and influenza have renewed\ninterest in advancing epidemic models to better reflect the complexities of\ndisease spreading. Modern approaches incorporate social norms, mobility\npatterns, and heterogeneous community structures to capture the interplay\nbetween social and biological dynamics. This study examines epidemic\npropagation in hierarchically structured metapopulation networks, where\nindividuals interact within localized communities -- such as schools,\nworkplaces, and theaters -- and diffuse across them. Using mean-field\naveraging, we derive a scaling law linking contagion rates to the mean\nconnectivity degree, while stability analysis identifies thresholds for\ninfection surges. In networks with heterogeneous mean degrees, spectral\nperturbation theory reveals how structural variability accelerates and\namplifies disease spreading. We find that nodes with above-average degrees are\nnot only infected earlier but also act as key outbreak drivers. Framing\nepidemic dynamics as a continuous phase transition, we apply pattern formation\ntheory to show that the critical eigenvectors governing system stability are\nshaped by the network's degree distribution. Crucially, by analyzing Laplacian\neigenvector localization, we uncover a one-to-one correspondence between\ncommunity infection densities and the entries of the critical eigenvector --\nrevealing how internal community structure directly shapes global infection\npatterns. This work provides a systematic framework for understanding and\npredicting epidemic dynamics in structured populations, while highlighting the\nfundamental role of community organization.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO","published":"2025-04-08T04:02:06Z"}
{"aid":"http://arxiv.org/abs/2504.05655v1","title":"Multi-bubble solutions for the Dirichlet problem of the $H$-system with\n  higher degree","summary":"We consider a Dirichlet problem of the $H$-system \\begin{equation*}\n\\begin{cases} \\Delta v = 2v_x\\wedge v_y ~& \\text{ in }\\mathcal{D},\\\\\nv=\\varepsilon \\tilde g ~& \\text{ on }\\partial{\\mathcal{D}}, \\end{cases}\n\\end{equation*} where $\\mathcal D\\subset \\mathbb{R}^2$ is the unit disk,\n$v:\\mathcal D\\to \\mathbb{R}^3$, and $\\tilde g:\\partial \\mathcal D\\to\n\\mathbb{R}^3$ is a given smooth map. As $\\varepsilon\\to 0^+$, we construct\nmulti-bubble solutions concentrating at distinct points, taking around each\npoint the profile of degree 2 $H$-bubble. This gives a partial answer to a\nconjecture due to Brezis-Coron \\cite{BrezisCoron} and Chanillo-Malchiodi\n\\cite{chanillomalchiodi2005cagasymptotic} concerning the limiting configuration\nin the case of higher degrees. This seems to be the first construction in\nemploying higher-degree harmonic maps as the primary configurations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T04:05:53Z"}
{"aid":"http://arxiv.org/abs/2504.05676v1","title":"Interfacial Heat Transport via Evanescent Radiation by Hot Electrons","summary":"We predict an additional thermal transport pathway across metal/non-metal\ninterfaces with large electron-phonon non-equilibrium via evanescent radiative\nheat transfer. In such systems, electron scattering processes vary drastically\nand can be leveraged to guide heat across interfaces via radiative heat\ntransport without engaging the lattice directly. We employ the formalism of\nfluctuational electrodynamics to simulate the spectral radiative heat flux\nacross the interface of a metal film and a non-metal substrate. We find that\nthe radiative conductance can exceed 300 MW m$^{-2}$ K$^{-1}$ at an electron\ntemperature of 5000 K for an emitting tungsten film on a hexagonal boron\nnitride substrate, becoming comparable to its conductive counterpart. This\nallows for a more holistic approach to the heat flow across interfaces,\naccounting for electron-phonon non-equilibrium and ultrafast near-field\nphonon-polariton coupling.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.comp-ph","published":"2025-04-08T04:36:29Z"}
{"aid":"http://arxiv.org/abs/2504.05678v1","title":"On The Merit Principle in Strategic Exchanges","summary":"New fairness notions in align with the merit principle are proposed for\ndesigning exchange rules. We show that, for an obviously strategy-proof,\nefficient and individually rational rule, an upper bound of fairness attainable\nis that, if two agents possess objects considered the best by all others, then\nat least one receives her favorite object. Notably, it is not possible to\nguarantee them both receiving favorites. Our results thus indicate an\nunambiguous trade-off between incentives and fairness in the design of exchange\nrules.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-08T04:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.05693v1","title":"STRIVE: A Think & Improve Approach with Iterative Refinement for\n  Enhancing Question Quality Estimation","summary":"Automatically assessing question quality is crucial for educators as it saves\ntime, ensures consistency, and provides immediate feedback for refining\nteaching materials. We propose a novel methodology called STRIVE (Structured\nThinking and Refinement with multiLLMs for Improving Verified Question\nEstimation) using a series of Large Language Models (LLMs) for automatic\nquestion evaluation. This approach aims to improve the accuracy and depth of\nquestion quality assessment, ultimately supporting diverse learners and\nenhancing educational practices. The method estimates question quality in an\nautomated manner by generating multiple evaluations based on the strengths and\nweaknesses of the provided question and then choosing the best solution\ngenerated by the LLM. Then the process is improved by iterative review and\nresponse with another LLM until the evaluation metric values converge. This\nsophisticated method of evaluating question quality improves the estimation of\nquestion quality by automating the task of question quality evaluation.\nCorrelation scores show that using this proposed method helps to improve\ncorrelation with human judgments compared to the baseline method. Error\nanalysis shows that metrics like relevance and appropriateness improve\nsignificantly relative to human judgments by using STRIVE.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T05:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.05752v1","title":"Complete and robust population transfer between the two ground states of\n  a three-state loop quantum system by amplitude composite pulse control","summary":"This work presents a method for achieving complete, robust, and efficient\npopulation transfer between the two ground states in a three-level loop quantum\nsystem. The approach utilizes composite pulse sequences by effectively mapping\nthe three-state system onto an equivalent two-level system. This transformation\nallows the use of broadband composite pulses designed initially for\nconventional two-state quantum systems. Unlike traditional implementations, the\ncomposite pulses in the three-level system are not controlled through phase\nadjustments; instead, they are realized via the amplitude ratio of the Rabi\nfrequencies.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T07:32:00Z"}
{"aid":"http://arxiv.org/abs/2504.05758v1","title":"Addressing Class Imbalance with Probabilistic Graphical Models and\n  Variational Inference","summary":"This study proposes a method for imbalanced data classification based on deep\nprobabilistic graphical models (DPGMs) to solve the problem that traditional\nmethods have insufficient learning ability for minority class samples. To\naddress the classification bias caused by class imbalance, we introduce\nvariational inference optimization probability modeling, which enables the\nmodel to adaptively adjust the representation ability of minority classes and\ncombines the class-aware weight adjustment strategy to enhance the classifier's\nsensitivity to minority classes. In addition, we combine the adversarial\nlearning mechanism to generate minority class samples in the latent space so\nthat the model can better characterize the category boundary in the\nhigh-dimensional feature space. The experiment is evaluated on the Kaggle\n\"Credit Card Fraud Detection\" dataset and compared with a variety of advanced\nimbalanced classification methods (such as GAN-based sampling, BRF,\nXGBoost-Cost Sensitive, SAAD, HAN). The results show that the method in this\nstudy has achieved the best performance in AUC, Precision, Recall and F1-score\nindicators, effectively improving the recognition rate of minority classes and\nreducing the false alarm rate. This method can be widely used in imbalanced\nclassification tasks such as financial fraud detection, medical diagnosis, and\nanomaly detection, providing a new solution for related research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T07:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.05788v1","title":"Space-averaged non-equilibrium Green's function approach for quantum\n  transport in 3D","summary":"The non-equilibrium Green's function (NEGF) approach offers a practical\nframework for simulating various phenomena in mesoscopic systems. As the\ndimension of electronic devices shrinks to just a few nanometers, the need for\nnew effective-mass based 3D implementations of NEGF has become increasingly\napparent. This work extends our previous Finite-Volume implementation --\noriginally developed for the self-consistent solution of the Schr\\\"odinger and\nPoisson equations in 2D -- into a full 3D NEGF framework. Our implementation\nbegins with exploring a few problems with the common textbook Finite Difference\nimplementations of NEGF. We then concisely demonstrate how Finite-Volume\ndiscretization addresses few key implementation challenges. Importantly, we\nexplain how this type of discretization enables evaluating the self-energies,\nwhich account for the effects of reservoirs. The potential applications of this\nnew method are illustrated through two examples. We anticipate that this\nimplementation will be broadly applicable to open quantum systems, especially\nin cases where a fully three-dimensional domain is essential.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T08:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.05813v1","title":"A new approach for simulating PBH formation from generic curvature\n  fluctuations with the Misner-Sharp formalism","summary":"Primordial Black Holes (PBHs) may have formed in the early Universe due to\nthe collapse of super-horizon curvature fluctuations. Simulations of PBH\nformation have been essential for inferring the initial conditions that lead to\nblack hole formation and for studying their properties and impact on our\nUniverse. The Misner-Sharp formalism is commonly used as a standard approach\nfor these simulations. Recently, type-II fluctuations, characterized by a\nnon-monotonic areal radius, have gained interest. In the standard Misner-Sharp\napproach for simulating PBH formation with these fluctuations, the evolution\nequations suffer from divergent terms (0/0), which complicate and prevent the\nsimulations. We formulate a new approach to overcome this issue in a simple\nmanner by using the trace of the extrinsic curvature as an auxiliary variable,\nallowing simulations of type-II fluctuations within the Misner-Sharp formalism.\nUsing a set of standard exponential-shaped curvature profiles, we apply our new\napproach and numerical code based on pseudospectral methods to study the time\nevolution of the gravitational collapse, threshold values of type A/B PBHs and\nPBH mass. Interestingly, we identify cases of type-II fluctuations that do not\nnecessarily result in PBH formation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T08:53:38Z"}
{"aid":"http://arxiv.org/abs/2504.05814v1","title":"The threshold for PBH formation in the type-II region and its analytical\n  estimation","summary":"We numerically simulate the formation of Primordial Black Holes (PBHs) in a\nradiation-dominated Universe under the assumption of spherical symmetry, driven\nby the collapse of adiabatic fluctuations, for different curvature profiles\n$\\zeta$. Our results show that the threshold for PBH formation, defined as the\npeak value of the critical compaction function $\\mathcal{C}_{c}(r_m)$ (where\n$r_m$ is the scale at which the peak occurs), does not asymptotically saturate\nto its maximum possible value in the type-I region for sufficiently sharp\nprofiles. Instead, the threshold is found in the type-II region with\n$\\mathcal{C}_{c}(r_m)$ being a minimum. We find, for the cases tested, that\nthis is a general trend associated with profiles that exhibit extremely large\ncurvatures in the linear component of the compaction function\n$\\mathcal{C}_{l}(r) \\equiv -4r \\zeta'(r)/3$ shape around its peak $r_m$ (spiky\nshapes). To measure this curvature at $r_m$, we define a dimensionless\nparameter: $\\kappa \\equiv -r^{2}_m \\mathcal{C}_l''(r_m)$, and we find that the\nthresholds observed in the type-II region occur for $\\kappa \\gtrsim 30$ for the\nprofiles we have used. By defining the threshold in terms of\n$\\mathcal{C}_{l,c}(r_m)$, we extend previous analytical estimations to the\ntype-II region, which is shown to be accurate within a few percent when\ncompared to the numerical simulations for the tested profiles. Our results\nsuggest that current PBH abundance calculations for models where the threshold\nlies in the type-II region may have been overestimated due to the general\nassumption that it should saturate at the boundary between the type-I and\ntype-II regions.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T08:53:42Z"}
{"aid":"http://arxiv.org/abs/2504.05825v1","title":"Spin Dynamics in Rotating Quantum Plasmas: Coupled EPI Dispersion and\n  Solitary wave analysis","summary":"The propagation of an electrostatic wave in a three-component e-p-I\nastrophysical quantum plasma in a rotating frame has been studied, taking into\naccount the particle spin, Fermi pressure, and quantum Bohm potential. Spin\npolarization plays a key role in explaining the dynamics of quantum plasmas,\nespecially in astrophysical contexts due to the high external magnetic field\nprevalent in such environments. Effects specific to this particular\nenvironment, like rotation as well as gravity, have also been included. Coupled\ndispersion of electron, positron, and ion modes has been obtained. Further, the\ninvestigation of solitary waves by the Korteweg de Vries method has been\ncarried out, and a soliton solution has been obtained. Quantum effects increase\nwave dispersion and soliton stability in quantum plasma, thereby affecting the\nelectrostatic potential.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-08T09:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.05828v1","title":"Capacity Region for Covert Secret Key Generation over Multiple Access\n  Channels","summary":"We study covert secret key generation over a binary-input two-user multiple\naccess channel with one-way public discussion and derive bounds on the capacity\nregion. Specifically, in this problem, there are three legitimate parties:\nAlice, Bob and Charlie. The goal is to allow Charlie to generate a secret key\nwith Alice and another secret key with Bob, reliably, secretly and covertly.\nReliability ensures that the key generated by Alice and Charlie is the same and\nthe key generated by Bob and Charlie is the same. Secrecy ensures that the\nsecret keys generated are only known to specific legitimate parties. Covertness\nensures that the key generation process is undetectable by a warden Willie. As\na corollary of our result, we establish bounds on the capacity region of\nwiretap secret key generation without the covertness constraint and discuss the\nimpact of covertness. Our results generalize the point-to-point result of\nTahmasbi and Bloch (TIFS 2020) to the setting of multiterminal communication.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-08T09:08:45Z"}
{"aid":"http://arxiv.org/abs/2504.05849v1","title":"On the Importance of Conditioning for Privacy-Preserving Data\n  Augmentation","summary":"Latent diffusion models can be used as a powerful augmentation method to\nartificially extend datasets for enhanced training. To the human eye, these\naugmented images look very different to the originals. Previous work has\nsuggested to use this data augmentation technique for data anonymization.\nHowever, we show that latent diffusion models that are conditioned on features\nlike depth maps or edges to guide the diffusion process are not suitable as a\nprivacy preserving method. We use a contrastive learning approach to train a\nmodel that can correctly identify people out of a pool of candidates. Moreover,\nwe demonstrate that anonymization using conditioned diffusion models is\nsusceptible to black box attacks. We attribute the success of the described\nmethods to the conditioning of the latent diffusion model in the anonymization\nprocess. The diffusion model is instructed to produce similar edges for the\nanonymized images. Hence, a model can learn to recognize these patterns for\nidentification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T09:27:51Z"}
{"aid":"http://arxiv.org/abs/2504.05876v1","title":"Topological ignition of the stealth coronal mass ejections","summary":"One of hot topics in the solar physics are the so-called 'stealth' coronal\nmass ejections (CME), which are not associated with any appreciable energy\nrelease events in the lower corona, such as the solar flares. It is sometimes\nassumed that these phenomena might be produced by some specific physical\nmechanism, but no particular suggestions were put forward. It is the aim of the\npresent paper to show that a promising explanation of the stealth CMEs can be\nbased on the so-called 'topological' ignition of the magnetic reconnection. As\na theoretical basis, we employ the Gorbachev-Kel'ner-Somov-Shvarts (GKSS) model\nof formation of the magnetic null point, which is produced by a specific\nsuperposition of the remote sources (sunspots) rather than by the local current\nsystems. As follows from our numerical simulations, the topological model\nexplains very well all basic features of the stealth CMEs: (i) the plasma\neruption develops without an appreciable heat release from the spot of\nreconnection, i.e., without the solar flare; (ii) the spot of reconnection\n(magnetic null point) can be formed far away from the location of the magnetic\nfield sources; (iii) the trajectories of eruption are strongly curved, which\ncan explain observability of CMEs generated behind the solar limb. Therefore,\nthe topological ignition of magnetic reconnection should be interesting both by\nitself, as a novel physical phenomenon, and as a prognostic tool for\nforecasting the stealth CMEs and the resulting unexpected geomagnetic storms.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-08T10:04:57Z"}
{"aid":"http://arxiv.org/abs/2504.05882v1","title":"Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban\n  LiDAR Segmentation with Semi-Supervised Techniques","summary":"3D semantic segmentation plays a critical role in urban modelling, enabling\ndetailed understanding and mapping of city environments. In this paper, we\nintroduce Turin3D: a new aerial LiDAR dataset for point cloud semantic\nsegmentation covering an area of around 1.43 km2 in the city centre of Turin\nwith almost 70M points. We describe the data collection process and compare\nTurin3D with others previously proposed in the literature. We did not fully\nannotate the dataset due to the complexity and time-consuming nature of the\nprocess; however, a manual annotation process was performed on the validation\nand test sets, to enable a reliable evaluation of the proposed techniques. We\nfirst benchmark the performances of several point cloud semantic segmentation\nmodels, trained on the existing datasets, when tested on Turin3D, and then\nimprove their performances by applying a semi-supervised learning technique\nleveraging the unlabelled training set. The dataset will be publicly available\nto support research in outdoor point cloud segmentation, with particular\nrelevance for self-supervised and semi-supervised learning approaches given the\nabsence of ground truth annotations for the training set.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T10:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.05902v1","title":"Defending Deep Neural Networks against Backdoor Attacks via Module\n  Switching","summary":"The exponential increase in the parameters of Deep Neural Networks (DNNs) has\nsignificantly raised the cost of independent training, particularly for\nresource-constrained entities. As a result, there is a growing reliance on\nopen-source models. However, the opacity of training processes exacerbates\nsecurity risks, making these models more vulnerable to malicious threats, such\nas backdoor attacks, while simultaneously complicating defense mechanisms.\nMerging homogeneous models has gained attention as a cost-effective\npost-training defense. However, we notice that existing strategies, such as\nweight averaging, only partially mitigate the influence of poisoned parameters\nand remain ineffective in disrupting the pervasive spurious correlations\nembedded across model parameters. We propose a novel module-switching strategy\nto break such spurious correlations within the model's propagation path. By\nleveraging evolutionary algorithms to optimize fusion strategies, we validate\nour approach against backdoor attacks targeting text and vision domains. Our\nmethod achieves effective backdoor mitigation even when incorporating a couple\nof compromised models, e.g., reducing the average attack success rate (ASR) to\n22% compared to 31.9% with the best-performing baseline on SST-2.","main_category":"cs.CR","categories":"cs.CR,cs.CL","published":"2025-04-08T11:01:07Z"}
{"aid":"http://arxiv.org/abs/2504.05919v1","title":"Measurement of high-mass $t\\bar{t}\\ell^{+}\\ell^{-}$ production and\n  lepton flavour universality-inspired effective field theory interpretations\n  at $\\sqrt{s}=13$ TeV with the ATLAS detector","summary":"Measurements of $t\\bar{t}\\ell^{+}\\ell^{-}$ production in the region of high\ndilepton invariant mass with effective field theory (EFT) interpretations are\npresented. They are performed using final states with three isolated leptons\n(electrons or muons) and are based on $\\sqrt{s} = 13$ TeV proton-proton\ncollision data with an integrated luminosity of $140\\,\\mathrm{fb}^{-1}$,\nrecorded from 2015 to 2018 with the ATLAS detector at the Large Hadron\nCollider. Measurements of the $t\\bar{t}\\ell^{+}\\ell^{-}$ signal strength and\ncross-section upper-limits are performed inclusively in lepton flavour and\nseparately for electrons and muons. The study also aims to probe anomalous\nfour-fermion interactions including to test for possible lepton flavor\nuniversality violation. No significant deviations from the Standard Model\npredictions are observed and the measurements are interpreted through the EFT\nformalism to provide new constraints on relevant operators.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-08T11:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.05959v1","title":"Old and New Results on Alphabetic Codes","summary":"This comprehensive survey examines the field of alphabetic codes, tracing\ntheir development from the 1960s to the present day. We explore classical\nalphabetic codes and their variants, analyzing their properties and the\nunderlying mathematical and algorithmic principles. The paper covers the\nfundamental relationship between alphabetic codes and comparison-based search\nprocedures and their applications in data compression, routing, and testing. We\nreview optimal alphabetic code construction algorithms, necessary and\nsufficient conditions for their existence, and upper bounds on the average code\nlength of optimal alphabetic codes. The survey also discusses variations and\ngeneralizations of the classical problem of constructing minimum average length\nalphabetic codes. By elucidating both classical results and recent findings,\nthis paper aims to serve as a valuable resource for researchers and students,\nconcluding with promising future research directions in this still-active\nfield.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-08T12:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.05979v1","title":"An Empirical Study of GPT-4o Image Generation Capabilities","summary":"The landscape of image generation has rapidly evolved, from early GAN-based\napproaches to diffusion models and, most recently, to unified generative\narchitectures that seek to bridge understanding and generation tasks. Recent\nadvances, especially the GPT-4o, have demonstrated the feasibility of\nhigh-fidelity multimodal generation, their architectural design remains\nmysterious and unpublished. This prompts the question of whether image and text\ngeneration have already been successfully integrated into a unified framework\nfor those methods. In this work, we conduct an empirical study of GPT-4o's\nimage generation capabilities, benchmarking it against leading open-source and\ncommercial models. Our evaluation covers four main categories, including\ntext-to-image, image-to-image, image-to-3D, and image-to-X generation, with\nmore than 20 tasks. Our analysis highlights the strengths and limitations of\nGPT-4o under various settings, and situates it within the broader evolution of\ngenerative modeling. Through this investigation, we identify promising\ndirections for future unified generative models, emphasizing the role of\narchitectural design and data scaling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T12:34:36Z"}
{"aid":"http://arxiv.org/abs/2504.05988v1","title":"Consistency Relation for Fixed Point Dynamics","summary":"We gain insight on the fixed point dynamics of $d$ dimensional quantum field\ntheories by exploiting the critical behavior of the $d-\\epsilon$ sister\ntheories. To this end we first derive a self-consistent relation between the\n$d-\\epsilon$ scaling exponents and the associated $d$ dimensional beta\nfunctions. We then demonstrate that to account for an interacting fixed point\nin the original theory the related $d-\\epsilon$ scaling exponent must be\nmulti-valued in $\\epsilon$. We elucidate our findings by discussing several\nexamples such as the QCD Banks-Zaks infrared fixed point, QCD at large number\nof flavors, as well as the O(N) model in four dimensions. For the latter, we\nshow that although the $1/N$ corrections prevent the reconstruction of the\nrenormalization group flow, this is possible when adding the $1/N^2$\ncontributions.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-08T12:50:27Z"}
{"aid":"http://arxiv.org/abs/2504.06006v1","title":"Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?","summary":"Optimal hyperparameter selection is critical for maximizing neural network\nperformance, especially as models grow in complexity. This work investigates\nthe viability of using large language models (LLMs) for hyperparameter\noptimization by employing a fine-tuned version of Code Llama. Through\nparameter-efficient fine-tuning using LoRA, we adapt the LLM to generate\naccurate and efficient hyperparameter recommendations tailored to diverse\nneural network architectures. Unlike traditional methods such as Optuna, which\nrely on exhaustive trials, the proposed approach achieves competitive or\nsuperior results in terms of Root Mean Square Error (RMSE) while significantly\nreducing computational overhead. Our approach highlights that LLM-based\noptimization not only matches state-of-the-art methods like Tree-structured\nParzen Estimators but also accelerates the tuning process. This positions LLMs\nas a promising alternative to conventional optimization techniques,\nparticularly for rapid experimentation. Furthermore, the ability to generate\nhyperparameters in a single inference step makes this method particularly\nwell-suited for resource-constrained environments such as edge devices and\nmobile applications, where computational efficiency is paramount. The results\nconfirm that LLMs, beyond their efficiency, offer substantial time savings and\ncomparable stability, underscoring their value in advancing machine learning\nworkflows. All generated hyperparameters are included in the LEMUR Neural\nNetwork (NN) Dataset, which is publicly available and serves as an open-source\nbenchmark for hyperparameter optimization research.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE","published":"2025-04-08T13:15:47Z"}
{"aid":"http://arxiv.org/abs/2504.06025v1","title":"Geometries with trialities arising from linear spaces","summary":"A triality is a sort of super-symmetry that exchanges the types of the\nelements of an incidence geometry in cycles of length three. Although\ngeometries with trialities exhibit fascinating behaviors, their construction is\nchallenging, making them rare in the literature. To understand trialities more\ndeeply, it is crucial to have a wide variety of examples at hand. In this\narticle, we introduce a general method for constructing various rank-three\nincidence systems with trialities. Specifically, for any rank two incidence\nsystem $\\Gamma$, we define its triangle complex $\\Delta(\\Gamma)$, a rank three\nincidence system whose elements consist of three copies of the flags (pairs of\nincident elements) of $\\Gamma$. This triangle complex always admits a triality\nthat cyclically permutes the three copies. We then explore in detail the\nproperties of the triangle complex when $\\Gamma$ is a linear space, including\nflag-transitivity, the existence of dualities, and connectivity properties. As\na consequence of our work, this construction yields the first infinite family\nof thick, flag-transitive and residually connected geometries with trialities\nbut no dualities.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-08T13:28:55Z"}
{"aid":"http://arxiv.org/abs/2504.06046v1","title":"Rhythmic neuromorphic control of a pendulum: A hybrid systems analysis","summary":"Neuromorphic engineering is an emerging research domain that aims to realize\nimportant implementation advantages that brain-inspired technologies can offer\nover classical digital technologies, including energy efficiency, adaptability,\nand robustness. For the field of systems and control, neuromorphic controllers\ncould potentially bring many benefits, but their advancement is hampered by\nlack of systematic analysis and design tools. In this paper, the objective is\nto show that hybrid systems methods can aid in filling this gap. We do this by\nformally analyzing rhythmic neuromorphic control of a pendulum system, which\nwas recently proposed as a prototypical setup. The neuromorphic controller\ngenerates spikes, which we model as a Dirac delta pulse, whenever the pendulum\nangular position crosses its resting position, with the goal of inducing a\nstable limit cycle. This leads to modeling the closed-loop system as a hybrid\ndynamical system, which in between spikes evolves in open loop and where the\njumps correspond to the spiking control actions. Exploiting the hybrid system\nmodel, we formally prove the existence, uniqueness, and a stability property of\nthe hybrid limit cycle for the closed-loop system. Numerical simulations\nillustrate our approach. We finally elaborate on a possible spiking adaptation\nmechanism on the pulse amplitude to generate a hybrid limit cycle of a desired\nmaximal angular amplitude.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T13:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.06059v1","title":"New designs of linear optical interferometers with minimal depth and\n  component count","summary":"We adapt an algorithm for CNOT circuits synthesis based on the Bruhat\ndecomposition to the design of linear optical circuits with Mach-Zehnder\ninterferometers (MZI). The synthesis algorithm reduces to designing sorting\nnetworks with nearest neighbor swapping operations as elementary gates. We\nrecover previous designs from the literature but with additional theoretical\nproperties regarding the compiler that implements unitaries on the\ninterferometer. Notably the compiler can always decide whether a unitary can be\nimplemented on a given interferometer and, if so, returns the shallowest\npossible implementation. We also show natural extensions of our framework for\nboson sampling experiments and for the coupling of multiple integrated\ninterferometers to design larger linear optical systems. In both cases, the\ndesigns are optimal in terms of number of optical components. Finally, we\npropose a greedy design which exploits the arbritrary-but-fixed coupling of\nseparate integrated interferometers to perform shallow boson sampling. We\ndiscuss the optimal interferometer dimensions to maximize the transmission.\nBeyond boson sampling, our developed framework allows a resource-favourable\nimplemention of any non-adaptive linear optical quantum algorithm, by providing\nthe shallowest possible interferometer for implementing this algorithm.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T14:03:04Z"}
{"aid":"http://arxiv.org/abs/2504.06091v1","title":"Real-Time LaCAM","summary":"The vast majority of Multi-Agent Path Finding (MAPF) methods with\ncompleteness guarantees require planning full horizon paths. However, planning\nfull horizon paths can take too long and be impractical in real-world\napplications. Instead, real-time planning and execution, which only allows the\nplanner a finite amount of time before executing and replanning, is more\npractical for real world multi-agent systems. Several methods utilize real-time\nplanning schemes but none are provably complete, which leads to livelock or\ndeadlock. Our main contribution is to show the first Real-Time MAPF method with\nprovable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023)\nin an incremental fashion. Our results show how we can iteratively plan for\ncongested environments with a cutoff time of milliseconds while still\nmaintaining the same success rate as full horizon LaCAM. We also show how it\ncan be used with a single-step learned MAPF policy. The proposed Real-Time\nLaCAM also provides us with a general mechanism for using iterative constraints\nfor completeness in future real-time MAPF algorithms.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.RO","published":"2025-04-08T14:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.06121v1","title":"A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature\n  Fusion for Foggy Conditions","summary":"Lane detection is a critical component of Advanced Driver Assistance Systems\n(ADAS). Existing lane detection algorithms generally perform well under\nfavorable weather conditions. However, their performance degrades significantly\nin adverse conditions, such as fog, which increases the risk of traffic\naccidents. This challenge is compounded by the lack of specialized datasets and\nmethods designed for foggy environments. To address this, we introduce the\nFoggyLane dataset, captured in real-world foggy scenarios, and synthesize two\nadditional datasets, FoggyCULane and FoggyTusimple, from existing popular lane\ndetection datasets. Furthermore, we propose a robust Fog-Enhanced Network for\nlane detection, incorporating a Global Feature Fusion Module (GFFM) to capture\nglobal relationships in foggy images, a Kernel Feature Fusion Module (KFFM) to\nmodel the structural and positional relationships of lane instances, and a\nLow-level Edge Enhanced Module (LEEM) to address missing edge details in foggy\nconditions. Comprehensive experiments demonstrate that our method achieves\nstate-of-the-art performance, with F1-scores of 95.04 on FoggyLane, 79.85 on\nFoggyCULane, and 96.95 on FoggyTusimple. Additionally, with TensorRT\nacceleration, the method reaches a processing speed of 38.4 FPS on the NVIDIA\nJetson AGX Orin, confirming its real-time capabilities and robustness in foggy\nenvironments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:13:01Z"}
{"aid":"http://arxiv.org/abs/2504.06124v1","title":"Safe Interaction via Monte Carlo Linear-Quadratic Games","summary":"Safety is critical during human-robot interaction. But -- because people are\ninherently unpredictable -- it is often difficult for robots to plan safe\nbehaviors. Instead of relying on our ability to anticipate humans, here we\nidentify robot policies that are robust to unexpected human decisions. We\nachieve this by formulating human-robot interaction as a zero-sum game, where\n(in the worst case) the human's actions directly conflict with the robot's\nobjective. Solving for the Nash Equilibrium of this game provides robot\npolicies that maximize safety and performance across a wide range of human\nactions. Existing approaches attempt to find these optimal policies by\nleveraging Hamilton-Jacobi analysis (which is intractable) or linear-quadratic\napproximations (which are inexact). By contrast, in this work we propose a\ncomputationally efficient and theoretically justified method that converges\ntowards the Nash Equilibrium policy. Our approach (which we call MCLQ)\nleverages linear-quadratic games to obtain an initial guess at safe robot\nbehavior, and then iteratively refines that guess with a Monte Carlo search.\nNot only does MCLQ provide real-time safety adjustments, but it also enables\nthe designer to tune how conservative the robot is -- preventing the system\nfrom focusing on unrealistic human behaviors. Our simulations and user study\nsuggest that this approach advances safety in terms of both computation time\nand expected performance. See videos of our experiments here:\nhttps://youtu.be/KJuHeiWVuWY.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T15:18:38Z"}
{"aid":"http://arxiv.org/abs/2504.06160v1","title":"Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack\n  Narratives Targeting Mental Health Groups","summary":"Large Language Models (LLMs) have been shown to demonstrate imbalanced biases\nagainst certain groups. However, the study of unprovoked targeted attacks by\nLLMs towards at-risk populations remains underexplored. Our paper presents\nthree novel contributions: (1) the explicit evaluation of LLM-generated attacks\non highly vulnerable mental health groups; (2) a network-based framework to\nstudy the propagation of relative biases; and (3) an assessment of the relative\ndegree of stigmatization that emerges from these attacks. Our analysis of a\nrecently released large-scale bias audit dataset reveals that mental health\nentities occupy central positions within attack narrative networks, as revealed\nby a significantly higher mean centrality of closeness (p-value = 4.06e-10) and\ndense clustering (Gini coefficient = 0.7). Drawing from sociological\nfoundations of stigmatization theory, our stigmatization analysis indicates\nincreased labeling components for mental health disorder-related targets\nrelative to initial targets in generation chains. Taken together, these\ninsights shed light on the structural predilections of large language models to\nheighten harmful discourse and highlight the need for suitable approaches for\nmitigation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG,cs.SI","published":"2025-04-08T15:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.06161v1","title":"A Hom formula for Soergel modules","summary":"We study Soergel modules for arbitrary Coxeter groups. For infinite Coxeter\ngroups, we show that the homomorphisms between Soergel modules are in general\nmore than those coming from morphisms of Soergel bimodules. This result\nprovides a negative answer to a question posed by Soergel.\n  We further show that the dimensions of the morphism spaces agree with the\npairing in the Hecke algebra when Soergel modules are instead regarded as\nmodules over the structure algebra. Moreover, we use this module structure to\ndefine a distinguished submodule of indecomposable Soergel bimodules that\nmimics the cohomology submodule of the intersection cohomology. Combined with\nthe Hodge theory of Soergel bimodules, this can be used to extend results\nregarding the shape of Bruhat intervals, such as top-heaviness, to arbitrary\nCoxeter groups.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T15:58:42Z"}
{"aid":"http://arxiv.org/abs/2504.06163v1","title":"Action Valuation in Sports: A Survey","summary":"Action Valuation (AV) has emerged as a key topic in Sports Analytics,\noffering valuable insights by assigning scores to individual actions based on\ntheir contribution to desired outcomes. Despite a few surveys addressing\nrelated concepts such as Player Valuation, there is no comprehensive review\ndedicated to an in-depth analysis of AV across different sports. In this\nsurvey, we introduce a taxonomy with nine dimensions related to the AV task,\nencompassing data, methodological approaches, evaluation techniques, and\npractical applications. Through this analysis, we aim to identify the essential\ncharacteristics of effective AV methods, highlight existing gaps in research,\nand propose future directions for advancing the field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:59:19Z"}
{"aid":"http://arxiv.org/abs/2504.06169v1","title":"Linear Regulator-Based Synchronization of Positive Multi-Agent Systems","summary":"This paper addresses the positive synchronization of interconnected systems\non undirected graphs. For homogeneous positive systems, a static feedback\nprotocol design is proposed, based on the Linear Regulator problem. The\nsolution to the algebraic equation associated to the stabilizing policy can be\nfound using a linear program. Necessary and sufficient conditions on the\npositivity of each agent's trajectory for all nonnegative initial conditions\nare also provided. Simulations on large regular graphs with different nodal\ndegree illustrate the proposed results.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T16:08:07Z"}
{"aid":"http://arxiv.org/abs/2504.06190v1","title":"No-scale supergravity","summary":"To connect supergravity with the real world, a highly non-trivial requirement\nis complete spontaneous supersymmetry breaking in an approximately flat\nfour-dimensional space-time. In no-scale supergravity models, this naturally\nhappens at the classical level: the gravitino mass, setting the scale of\nsupersymmetry breaking, slides along a flat direction of the potential with\nvanishing energy. This contribution briefly describes, with a personal\nselection of simple illustrative examples, some qualitative features of\nno-scale models that relate them to a possible dynamical generation of the\nhierarchies between the vacuum energy scale, the weak scale and the Planck\nscale. It includes comments on their versions with extended supersymmetry, on\ntheir higher-dimensional origin and on how their still unsolved problems of\nquantum stability can already be addressed, with some results, at the level of\nsupergravity compactifications, although their solution (if any) will\neventually require a better understanding of superstring theories.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T16:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.06196v1","title":"TxGemma: Efficient and Agentic LLMs for Therapeutics","summary":"Therapeutic development is a costly and high-risk endeavor that is often\nplagued by high failure rates. To address this, we introduce TxGemma, a suite\nof efficient, generalist large language models (LLMs) capable of therapeutic\nproperty prediction as well as interactive reasoning and explainability. Unlike\ntask-specific models, TxGemma synthesizes information from diverse sources,\nenabling broad application across the therapeutic development pipeline. The\nsuite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a\ncomprehensive dataset of small molecules, proteins, nucleic acids, diseases,\nand cell lines. Across 66 therapeutic development tasks, TxGemma achieved\nsuperior or comparable performance to the state-of-the-art generalist model on\n64 (superior on 45), and against state-of-the-art specialist models on 50\n(superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks,\nsuch as clinical trial adverse event prediction, requires less training data\nthan fine-tuning base LLMs, making TxGemma suitable for data-limited\napplications. Beyond these predictive capabilities, TxGemma features\nconversational models that bridge the gap between general LLMs and specialized\nproperty predictors. These allow scientists to interact in natural language,\nprovide mechanistic reasoning for predictions based on molecular structure, and\nengage in scientific discussions. Building on this, we further introduce\nAgentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that\nreasons, acts, manages diverse workflows, and acquires external domain\nknowledge. Agentic-Tx surpasses prior leading models on the Humanity's Last\nExam benchmark (Chemistry & Biology) with 52.3% relative improvement over\no3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels\nwith improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over\no3-mini (high).","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG","published":"2025-04-08T16:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.06213v1","title":"Guidelines for designs for ultrastable laser with $\\mathbf{10^{-17}}$\n  fractional frequency instability","summary":"Lasers with long coherence time and narrow linewidth are an essential tool\nfor quantum sensors and clocks. Ultrastable cavities and laser systems are now\ncommercially available with fractional frequency instabilities in the mid\n$10^{-16}$ range. This document aims to provide technical guidance for\nresearchers starting in the field of ultrastable lasers and to give an outlook\ntoward the next generation of improved ultrastable lasers. These guidelines\nhave arisen from the scope of the EMPIR project ``Next generation ultrastable\nlasers'' ( https://www.ptb.de/empir2021/nextlasers ) with contributions from\nthe European project partners.","main_category":"physics.optics","categories":"physics.optics,physics.ins-det","published":"2025-04-08T16:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.06258v1","title":"Two-Dimensional Ferroelectric Altermagnets: From Model to Material\n  Realization","summary":"Multiferroic altermagnets offer new opportunities for magnetoelectric\ncoupling and electrically tunable spintronics. However, due to intrinsic\nsymmetry conflicts between altermagnetism and ferroelectricity, achieving their\ncoexistence, known as ferroelectric altermagnets (FEAM), remains an outstanding\nchallenge, especially in two-dimensional (2D) systems. Here, we propose a\nuniversal, symmetry-based design principle for 2D FEAM, supported by\ntight-binding models and first-principles calculations. We show that\nferroelectric lattice distortions can break spin equivalence and introduce the\nnecessary rotational symmetry, enabling altermagnetism with electrically\nreversible spin splitting. Guided by this framework, we identify a family of 2D\nvanadium oxyhalides and sulfide halides as promising FEAM candidates. In these\ncompounds, pseudo Jahn-Teller distortions and Peierls-like dimerization\ncooperatively establish the required symmetry conditions. We further propose\nthe magneto-optical Kerr effect as an experimental probe to confirm FEAM and\nits electric spin reversal. Our findings provide a practical framework for 2D\nFEAM and advancing electrically controlled spintronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.06259v1","title":"Realization and Calibration of Continuously Parameterized Two-Qubit\n  Gates on a Trapped-Ion Quantum Processor","summary":"Continuously parameterized two-qubit gates are a key feature of\nstate-of-the-art trapped-ion quantum processors as they have favorable error\nscalings and show distinct improvements in circuit performance over more\nrestricted maximally entangling gatesets. In this work, we provide a\ncomprehensive and pedagogical discussion on how to practically implement these\ncontinuously parameterized M{\\o}lmer-S{\\o}rensen gates on the Quantum\nScientific Computing Open User Testbed (QSCOUT), a low-level trapped-ion\nprocessor. To generate the arbitrary entangling angles, $\\theta$, we simply\nscale the amplitude of light used to generate the entanglement. However, doing\nso requires careful consideration of amplifier saturation as well as the\nvariable light shifts that result. As such, we describe a method to calibrate\nand cancel the dominant fourth-order effects, followed by a dynamic virtual\nphase advance during the gate to cancel any residual light shifts, and find a\nlinear scaling between $\\theta$ and the residual light shift. Once, we have\nconsidered and calibrated these effects, we demonstrate performance improvement\nwith decreasing $\\theta$. Finally, we describe nuances of hardware control to\ntransform the XX-type interaction of the arbitrary-angle M{\\o}lmer-S{\\o}rensen\ngate into a phase-agnostic and crosstalk-mitigating ZZ interaction.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T17:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.06264v1","title":"D^2USt3R: Enhancing 3D Reconstruction with 4D Pointmaps for Dynamic\n  Scenes","summary":"We address the task of 3D reconstruction in dynamic scenes, where object\nmotions degrade the quality of previous 3D pointmap regression methods, such as\nDUSt3R, originally designed for static 3D scene reconstruction. Although these\nmethods provide an elegant and powerful solution in static settings, they\nstruggle in the presence of dynamic motions that disrupt alignment based solely\non camera poses. To overcome this, we propose D^2USt3R that regresses 4D\npointmaps that simultaneiously capture both static and dynamic 3D scene\ngeometry in a feed-forward manner. By explicitly incorporating both spatial and\ntemporal aspects, our approach successfully encapsulates spatio-temporal dense\ncorrespondence to the proposed 4D pointmaps, enhancing downstream tasks.\nExtensive experimental evaluations demonstrate that our proposed approach\nconsistently achieves superior reconstruction performance across various\ndatasets featuring complex motions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.06265v1","title":"GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning\n  through Bayesian Optimization","summary":"Large Language Models (LLMs) can encode complex relationships in their latent\nspaces, yet harnessing them for optimization under uncertainty remains\nchallenging. We address this gap with a novel architecture that reframes LLM\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\nto preserve the benefits of both - LLMs to provide a rich and flexible input\nspace for Bayesian optimization and - GPs to model this space with predictive\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\noptimization, our method nearly doubles the discovery rate of high-performing\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\nimprovement over domain-specific representations without requiring specialized\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\ngeneral chemistry to reaction and molecular property optimization -\ndemonstrates our method's robustness, generality, and consistent improvements\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\nthese improvements: joint LLM-GP optimization through marginal likelihood\nimplicitly performs contrastive learning, aligning representations to produce\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\nand (3) more efficient sampling - without requiring any external loss. This\nwork provides both practical advances in sample-efficient optimization and\ninsights into what makes effective Bayesian optimization.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.06551v1","title":"Bridging Queries and Tables through Entities in Table Retrieval","summary":"Table retrieval is essential for accessing information stored in structured\ntabular formats; however, it remains less explored than text retrieval. The\ncontent of the table primarily consists of phrases and words, which include a\nlarge number of entities, such as time, locations, persons, and organizations.\nEntities are well-studied in the context of text retrieval, but there is a\nnoticeable lack of research on their applications in table retrieval. In this\nwork, we explore how to leverage entities in tables to improve retrieval\nperformance. First, we investigate the important role of entities in table\nretrieval from a statistical perspective and propose an entity-enhanced\ntraining framework. Subsequently, we use the type of entities to highlight\nentities instead of introducing an external knowledge base. Moreover, we design\nan interaction paradigm based on entity representations. Our proposed framework\nis plug-and-play and flexible, making it easy to integrate into existing table\nretriever training processes. Empirical results on two table retrieval\nbenchmarks, NQ-TABLES and OTT-QA, show that our proposed framework is both\nsimple and effective in enhancing existing retrievers. We also conduct\nextensive analyses to confirm the efficacy of different components. Overall,\nour work provides a promising direction for elevating table retrieval,\nenlightening future research in this area.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T03:16:33Z"}
{"aid":"http://arxiv.org/abs/2504.06564v1","title":"Do Reasoning Models Show Better Verbalized Calibration?","summary":"Large reasoning models (LRMs) have recently shown impressive capabilities in\ncomplex reasoning by leveraging increased test-time computation and exhibiting\nbehaviors akin to human-like deliberation. Despite these advances, it remains\nan open question whether LRMs are better calibrated - particularly in their\nverbalized confidence - compared to instruction-tuned counterparts. In this\npaper, we investigate the calibration properties of LRMs trained via supervised\nfine-tuning distillation on long reasoning traces (henceforth SFT reasoning\nmodels) and outcome-based reinforcement learning for reasoning (henceforth RL\nreasoning models) across diverse domains. Our findings reveal that LRMs\nsignificantly outperform instruction-tuned models on complex reasoning tasks in\nboth accuracy and confidence calibration. In contrast, we find surprising\ntrends in the domain of factuality in particular. On factuality tasks, while\nDeepseek-R1 shows strong calibration behavior, smaller QwQ-32B shows no\nimprovement over instruct models; moreover, SFT reasoning models display worse\ncalibration (greater overconfidence) compared to instruct models. Our results\nprovide evidence for a potentially critical role of reasoning-oriented RL\ntraining in improving LLMs' capacity for generating trustworthy, self-aware\noutputs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.06577v1","title":"Bypassing Safety Guardrails in LLMs Using Humor","summary":"In this paper, we show it is possible to bypass the safety guardrails of\nlarge language models (LLMs) through a humorous prompt including the unsafe\nrequest. In particular, our method does not edit the unsafe request and follows\na fixed template -- it is simple to implement and does not need additional LLMs\nto craft prompts. Extensive experiments show the effectiveness of our method\nacross different LLMs. We also show that both removing and adding more humor to\nour method can reduce its effectiveness -- excessive humor possibly distracts\nthe LLM from fulfilling its unsafe request. Thus, we argue that LLM\njailbreaking occurs when there is a proper balance between focus on the unsafe\nrequest and presence of humor.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-09T04:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.06578v1","title":"Attributes-aware Visual Emotion Representation Learning","summary":"Visual emotion analysis or recognition has gained considerable attention due\nto the growing interest in understanding how images can convey rich semantics\nand evoke emotions in human perception. However, visual emotion analysis poses\ndistinctive challenges compared to traditional vision tasks, especially due to\nthe intricate relationship between general visual features and the different\naffective states they evoke, known as the affective gap. Researchers have used\ndeep representation learning methods to address this challenge of extracting\ngeneralized features from entire images. However, most existing methods\noverlook the importance of specific emotional attributes such as brightness,\ncolorfulness, scene understanding, and facial expressions. Through this paper,\nwe introduce A4Net, a deep representation network to bridge the affective gap\nby leveraging four key attributes: brightness (Attribute 1), colorfulness\n(Attribute 2), scene context (Attribute 3), and facial expressions (Attribute\n4). By fusing and jointly training all aspects of attribute recognition and\nvisual emotion analysis, A4Net aims to provide a better insight into emotional\ncontent in images. Experimental results show the effectiveness of A4Net,\nshowcasing competitive performance compared to state-of-the-art methods across\ndiverse visual emotion datasets. Furthermore, visualizations of activation maps\ngenerated by A4Net offer insights into its ability to generalize across\ndifferent visual emotion datasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.MM","published":"2025-04-09T05:00:43Z"}
{"aid":"http://arxiv.org/abs/2504.06579v1","title":"Coherence-decoherence interplay in quantum systems due to projective\n  stochastic pulses: The case of Rabi oscillations","summary":"The interplay of coherence and decoherence is played out in a three-level\nquantum system, in which the third level is incoherently coupled to the second\none which itself is in coherent interaction with the first level. The study is\nbased on a stochastic scenario in which the coherent, unitary evolution of the\nsystem is randomly interrupted by a Poisson-driven pulse sequence. In the\nabsence of an external pulse, the system undergoes coherent, unitary evolution\nrestricted to the subspace spanned by the first level (level $1$) and the\nsecond level (level $2$). The application of a pulse induces transitions\nbetween the second and the third level (level $3$), thereby introducing\nnon-unitary effects that perturb the otherwise isolated two-level dynamics. The\npulses are assumed to have infinitesimal duration, with strengths modeled as\nrandom variables that are uncorrelated across different pulses. A\nrepresentative model for the stochastically-averaged transition (super)operator\nmimicking the dynamics induced by the application of pulses allows for an\nanalytical derivation of the matrix elements of the averaged density operator.\nWhen the system is initially in level $1$, we obtain in particular the temporal\nbehavior of the stay-put probability, that is, the probability $P_1(t)$ that\nthe system is still in level $1$ at time $t$. As a function of time, the\nquantity $P_1(t)$ exhibits a coherence-to-decoherence crossover behavior. At\nshort times $t \\ll 1/\\lambda$, where $\\lambda$ is the average frequency at\nwhich pulses are applied to the system, coherent dynamics dominate.\nConsequently, $P_1(t)$ displays pronounced Rabi-like oscillations. At long\ntimes $t \\gg 1/\\lambda$, decoherence effects prevail, leading to an exponential\ndecay of the form $P_1(t) \\sim \\exp(-\\lambda t)$.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-09T05:02:08Z"}
{"aid":"http://arxiv.org/abs/2504.06581v1","title":"Right Prediction, Wrong Reasoning: Uncovering LLM Misalignment in RA\n  Disease Diagnosis","summary":"Large language models (LLMs) offer a promising pre-screening tool, improving\nearly disease detection and providing enhanced healthcare access for\nunderprivileged communities. The early diagnosis of various diseases continues\nto be a significant challenge in healthcare, primarily due to the nonspecific\nnature of early symptoms, the shortage of expert medical practitioners, and the\nneed for prolonged clinical evaluations, all of which can delay treatment and\nadversely affect patient outcomes. With impressive accuracy in prediction\nacross a range of diseases, LLMs have the potential to revolutionize clinical\npre-screening and decision-making for various medical conditions. In this work,\nwe study the diagnostic capability of LLMs for Rheumatoid Arthritis (RA) with\nreal world patients data. Patient data was collected alongside diagnoses from\nmedical experts, and the performance of LLMs was evaluated in comparison to\nexpert diagnoses for RA disease prediction. We notice an interesting pattern in\ndisease diagnosis and find an unexpected \\textit{misalignment between\nprediction and explanation}. We conduct a series of multi-round analyses using\ndifferent LLM agents. The best-performing model accurately predicts rheumatoid\narthritis (RA) diseases approximately 95\\% of the time. However, when medical\nexperts evaluated the reasoning generated by the model, they found that nearly\n68\\% of the reasoning was incorrect. This study highlights a clear misalignment\nbetween LLMs high prediction accuracy and its flawed reasoning, raising\nimportant questions about relying on LLM explanations in clinical settings.\n\\textbf{LLMs provide incorrect reasoning to arrive at the correct answer for RA\ndisease diagnosis.}","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-09T05:04:01Z"}
{"aid":"http://arxiv.org/abs/2504.06626v1","title":"Localization of deformation in the central hub of hub-and-spoke kirigami","summary":"A recent approach to the design of flexible electronic devices consists of\ncutting a two-dimensional sheet to form a central hub connected to several\ntapered `spokes', resembling the hub-and-spoke of a bicycle wheel. When\nradially compressed, the resulting cut sheet buckles out-of-plane forming a\nstructure whose three-dimensional shape can be chosen by designing the tapering\nof the spokes. While the deformation of the spokes in this `hub-and-spoke'\nkirigami are approximately cylindrical (i.e.~zero Gaussian curvature and hence\nsmall elastic strain), this is not the case in the central hub. The central hub\nis deformed radially because of continuity with the spokes but, because of its\nown circular symmetry, it must develop Gaussian curvature, and hence strain. In\nthis article we quantify this strain, focussing in particular on its magnitude\nand its location. We find that the strain is localized in a boundary layer near\nthe edge of the hub region, whose size is controlled by the moment applied on\nit by the deformed spokes. We discuss the implications of our results for\navoiding material failure in flexible-electronic devices.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-04-09T07:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.06640v1","title":"Design and use of devices to assist movement of the upper limb: review\n  of the literature","summary":"This article explores assistive devices for upper limb movement in people\nwith disabilities through a systematic review based on the PRISMA methodology.\nThe studied devices encompass technologies ranging from orthoses to advanced\nrobotics, aiming to compensate for or supplement motor impairments. The results\nhighlight the diversity of applications (rehabilitation, daily living\nactivities), targeted body segments (distal, proximal, or global), as well as\ncontrol mechanisms and interfaces used. However, despite the variety of\npromising prototypes, few devices are commercially available, limiting their\nreal impact on end users. Existing technologies, while effective in improving\nfunctional autonomy and quality of life, still face challenges in terms of\nergonomics, cost, and portability. In conclusion, this article emphasizes the\nimportance of a user-centered approach and proposes avenues for the development\nof innovative, modular, and accessible assistive devices.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:32:02Z"}
{"aid":"http://arxiv.org/abs/2504.06643v1","title":"AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series\n  Anomaly Detection","summary":"Unsupervised multivariate time series anomaly detection (UMTSAD) plays a\ncritical role in various domains, including finance, networks, and sensor\nsystems. In recent years, due to the outstanding performance of deep learning\nin general sequential tasks, many models have been specialized for deep UMTSAD\ntasks and have achieved impressive results, particularly those based on the\nTransformer and self-attention mechanisms. However, the sequence anomaly\nassociation assumptions underlying these models are often limited to specific\npredefined patterns and scenarios, such as concentrated or peak anomaly\npatterns. These limitations hinder their ability to generalize to diverse\nanomaly situations, especially where the lack of labels poses significant\nchallenges. To address these issues, we propose AMAD, which integrates\n\\textbf{A}uto\\textbf{M}asked Attention for UMTS\\textbf{AD} scenarios. AMAD\nintroduces a novel structure based on the AutoMask mechanism and an attention\nmixup module, forming a simple yet generalized anomaly association\nrepresentation framework. This framework is further enhanced by a Max-Min\ntraining strategy and a Local-Global contrastive learning approach. By\ncombining multi-scale feature extraction with automatic relative association\nmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.\nExtensive experimental results demonstrate that the proposed model achieving\ncompetitive performance results compared to SOTA benchmarks across a variety of\ndatasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI,I.5.1","published":"2025-04-09T07:32:59Z"}
{"aid":"http://arxiv.org/abs/2504.06649v1","title":"GRAIN: Multi-Granular and Implicit Information Aggregation Graph Neural\n  Network for Heterophilous Graphs","summary":"Graph neural networks (GNNs) have shown significant success in learning graph\nrepresentations. However, recent studies reveal that GNNs often fail to\noutperform simple MLPs on heterophilous graph tasks, where connected nodes may\ndiffer in features or labels, challenging the homophily assumption. Existing\nmethods addressing this issue often overlook the importance of information\ngranularity and rarely consider implicit relationships between distant nodes.\nTo overcome these limitations, we propose the Granular and Implicit Graph\nNetwork (GRAIN), a novel GNN model specifically designed for heterophilous\ngraphs. GRAIN enhances node embeddings by aggregating multi-view information at\nvarious granularity levels and incorporating implicit data from distant,\nnon-neighboring nodes. This approach effectively integrates local and global\ninformation, resulting in smoother, more accurate node representations. We also\nintroduce an adaptive graph information aggregator that efficiently combines\nmulti-granularity and implicit data, significantly improving node\nrepresentation quality, as shown by experiments on 13 datasets covering varying\nhomophily and heterophily. GRAIN consistently outperforms 12 state-of-the-art\nmodels, excelling on both homophilous and heterophilous graphs.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T07:36:44Z"}
{"aid":"http://arxiv.org/abs/2504.06672v1","title":"RAGME: Retrieval Augmented Video Generation for Enhanced Motion Realism","summary":"Video generation is experiencing rapid growth, driven by advances in\ndiffusion models and the development of better and larger datasets. However,\nproducing high-quality videos remains challenging due to the high-dimensional\ndata and the complexity of the task. Recent efforts have primarily focused on\nenhancing visual quality and addressing temporal inconsistencies, such as\nflickering. Despite progress in these areas, the generated videos often fall\nshort in terms of motion complexity and physical plausibility, with many\noutputs either appearing static or exhibiting unrealistic motion. In this work,\nwe propose a framework to improve the realism of motion in generated videos,\nexploring a complementary direction to much of the existing literature.\nSpecifically, we advocate for the incorporation of a retrieval mechanism during\nthe generation phase. The retrieved videos act as grounding signals, providing\nthe model with demonstrations of how the objects move. Our pipeline is designed\nto apply to any text-to-video diffusion model, conditioning a pretrained model\non the retrieved samples with minimal fine-tuning. We demonstrate the\nsuperiority of our approach through established metrics, recently proposed\nbenchmarks, and qualitative results, and we highlight additional applications\nof the framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.06676v1","title":"Ranking alternatives from opinions on criteria","summary":"A primary challenge in collective decision-making is that achieving unanimous\nagreement is difficult, even at the level of criteria. The history of social\nchoice theory illustrates this: numerous normative criteria on voting rules\nhave been proposed; however, disagreements persist regarding which criteria\nshould take precedence. This study addresses the problem of ranking\nalternatives based on the aggregation of opinions over criteria that the\nalternatives might fulfill. Using the opinion aggregation model, we propose a\nnew rule, termed the Intersection Initial Segment (IIS) rule, and characterize\nit using five axioms: neutrality, independence of the worst set, independence\nof the best set, weak intersection very important player, and independence of\nnon-unanimous improvement. We illustrate our approach on a running example\nwhere the objective is to rank voting rules, showing that our opinion\naggregation model is particularly well-suited to this context, and that the IIS\nrule is a counterpart to the method discussed in Nurmi's paper (2015).","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-09T08:31:33Z"}
{"aid":"http://arxiv.org/abs/2504.06710v1","title":"Clustering and novel class recognition: evaluating bioacoustic deep\n  learning feature extractors","summary":"In computational bioacoustics, deep learning models are composed of feature\nextractors and classifiers. The feature extractors generate vector\nrepresentations of the input sound segments, called embeddings, which can be\ninput to a classifier. While benchmarking of classification scores provides\ninsights into specific performance statistics, it is limited to species that\nare included in the models' training data. Furthermore, it makes it impossible\nto compare models trained on very different taxonomic groups. This paper aims\nto address this gap by analyzing the embeddings generated by the feature\nextractors of 15 bioacoustic models spanning a wide range of setups (model\narchitectures, training data, training paradigms). We evaluated and compared\ndifferent ways in which models structure embedding spaces through clustering\nand kNN classification, which allows us to focus our comparison on feature\nextractors independent of their classifiers. We believe that this approach lets\nus evaluate the adaptability and generalization potential of models going\nbeyond the classes they were trained on.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.06711v1","title":"Pogorelov type $C^2$ estimates for sum Hessian equations","summary":"In this paper, We establish Pogorelov type $C^2$ estimates for the admissible\nsolutions with $\\sigma_k(D^2u)$ bounded from below of Sum Hessian equations. We\nalso proved the lower bounded condition can be removed when $k = n$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.06714v1","title":"Unifying Search and Recommendation: A Generative Paradigm Inspired by\n  Information Theory","summary":"Recommender systems and search engines serve as foundational elements of\nonline platforms, with the former delivering information proactively and the\nlatter enabling users to seek information actively. Unifying both tasks in a\nshared model is promising since it can enhance user modeling and item\nunderstanding. Previous approaches mainly follow a discriminative paradigm,\nutilizing shared encoders to process input features and task-specific heads to\nperform each task. However, this paradigm encounters two key challenges:\ngradient conflict and manual design complexity. From the information theory\nperspective, these challenges potentially both stem from the same issue -- low\nmutual information between the input features and task-specific outputs during\nthe optimization process.\n  To tackle these issues, we propose GenSR, a novel generative paradigm for\nunifying search and recommendation (S&R), which leverages task-specific prompts\nto partition the model's parameter space into subspaces, thereby enhancing\nmutual information. To construct effective subspaces for each task, GenSR first\nprepares informative representations for each subspace and then optimizes both\nsubspaces in one unified model. Specifically, GenSR consists of two main\nmodules: (1) Dual Representation Learning, which independently models\ncollaborative and semantic historical information to derive expressive item\nrepresentations; and (2) S&R Task Unifying, which utilizes contrastive learning\ntogether with instruction tuning to generate task-specific outputs effectively.\nExtensive experiments on two public datasets show GenSR outperforms\nstate-of-the-art methods across S&R tasks. Our work introduces a new generative\nparadigm compared with previous discriminative methods and establishes its\nsuperiority from the mutual information perspective.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T09:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.06721v1","title":"Learning global control of underactuated systems with Model-Based\n  Reinforcement Learning","summary":"This short paper describes our proposed solution for the third edition of the\n\"AI Olympics with RealAIGym\" competition, held at ICRA 2025. We employed\nMonte-Carlo Probabilistic Inference for Learning Control (MC-PILCO), an MBRL\nalgorithm recognized for its exceptional data efficiency across various\nlow-dimensional robotic tasks, including cart-pole, ball \\& plate, and Furuta\npendulum systems. MC-PILCO optimizes a system dynamics model using interaction\ndata, enabling policy refinement through simulation rather than direct system\ndata optimization. This approach has proven highly effective in physical\nsystems, offering greater data efficiency than Model-Free (MF) alternatives.\nNotably, MC-PILCO has previously won the first two editions of this\ncompetition, demonstrating its robustness in both simulated and real-world\nenvironments. Besides briefly reviewing the algorithm, we discuss the most\ncritical aspects of the MC-PILCO implementation in the tasks at hand: learning\na global policy for the pendubot and acrobot systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-09T09:20:37Z"}
{"aid":"http://arxiv.org/abs/2504.06724v1","title":"End-to-end design framework for compressed on-chip pixel-wise\n  spectro-polarimeters","summary":"Modern detector manufacturing allows spectral and polarimetric filters to be\ndirectly integrated on top of separate detector pixels. This enables the\ncreation of CubeSat-sized spectro-polarimetric instruments that are not much\nlarger than the detector and a lens. Redundancy inherent to the observed scene,\noffers the opportunity for sparse sampling in the form of not scanning all\nfilters at every location. However, when there are fewer pushbroom steps than\nfilters, data are missing in the resulting data cube. The missing, largely\nredundant data can be filled in with interpolation methods, often called\ndemosaicers. The choice of filters and their precise layout influences the\nperformance of the instrument after the demosaicing process. In these\nproceedings we describe a part of a design toolbox for both the filter layout\nand the optimum parameters for the reconstruction to a full\nspectro-polarimetric data cube. The design tool is based on training a (neural)\nnetwork and jointly updating the values of the filters and demosaicer. We\noptimized a filter layout by training on spectro-polarimetric remote\nobservations of the Earth acquired by SPEX airborne. This optimised filter\nlayout could reconstruct a validation scene from five overlapping snapshots\n(pushbroom steps), which would take 109 pushbroom steps when measuring with a\nclassical layout and no reconstruction.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.optics","published":"2025-04-09T09:29:30Z"}
{"aid":"http://arxiv.org/abs/2504.06745v1","title":"A pluripotential theoretic framework for polynomial interpolation of\n  vector-valued functions and differential forms","summary":"We consider the problem of uniform interpolation of functions with values in\na complex inner product space of finite dimension. This problem can be casted\nwithin a modified weighted pluripotential theoretic framework. Indeed, in the\nproposed modification a vector valued weight is considered, allowing to\npartially extend the main asymptotic results holding for interpolation of\nscalar valued functions to the case of vector valued ones. As motivating\nexample and main application we specialize our results to interpolation of\ndifferential forms by differential forms with polynomial coefficients.","main_category":"math.CV","categories":"math.CV","published":"2025-04-09T10:04:23Z"}
{"aid":"http://arxiv.org/abs/2504.06779v1","title":"What if we find nothing? Bayesian analysis of the statistical\n  information of null results in future exoplanet habitability and biosignature\n  surveys","summary":"Future telescopes will survey temperate, terrestrial exoplanets to estimate\nthe frequency of habitable ($\\eta_{\\text{Hab}}$) or inhabited\n($\\eta_{\\text{Life}}$) planets. This study aims to determine the minimum number\nof planets ($N$) required to draw statistically significant conclusions,\nparticularly in the case of a null result (i.e., no detections). Using a\nBayesian framework, we analyzed surveys of up to $N=100$ planets to infer the\nfrequency of a binary observable feature ($\\eta_{\\text{obs}}$) after null\nresults. Posterior best fits and upper limits were derived for various survey\nsizes and compared with predicted yields from missions like the Large\nInterferometer for Exoplanets (LIFE) and the Habitable Worlds Observatory\n(HWO). Our findings indicate that $N=20-50$ ``perfect'' observations (100\\%\nconfidence in detecting or excluding the feature) yield conclusions relatively\nindependent of priors. To achieve 99.9\\% upper limits of $\\eta_{\\text{obs}}\n\\leq 0.2/0.1$, approximately $N \\simeq 40/80$ observations are needed. For\n``imperfect'' observations, uncertainties in interpretation and sample biases\nbecome limiting factors. We show that LIFE and HWO aim for sufficiently large\nsurvey sizes to provide statistically meaningful estimates of habitable\nenvironments and life prevalence under these assumptions. However, robust\nconclusions require careful sample selection and high-confidence detection or\nexclusion of features in each observation.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-09T11:02:19Z"}
{"aid":"http://arxiv.org/abs/2504.06795v1","title":"Winning and nullity of inhomogeneous bad","summary":"We prove the hyperplane absolute winning property of weighted inhomogeneous\nbadly approximable vectors in $\\mathbb{R}^d$. This answers a question by\nBeresnevich--Nesharim--Yang and extends the main result of [Geometric and\nFunctional Analysis, 31 (1), 1-33, 2021] to the inhomogeneous set-up.\n  We also show for any nondegenerate curve and nondegenerate analytic manifold\nthat almost every point is not weighted inhomogeneous badly approximable for\nany weight. This is achieved by duality and the quantitative nondivergence\nestimates from homogeneous dynamics motivated by [Acta Math. 231 (2023), 1-30],\ntogether with the methods from [arXiv:2307.10109].","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-09T11:38:28Z"}
{"aid":"http://arxiv.org/abs/2504.06824v1","title":"A Roadmap for Improving Data Reliability and Sharing in Crosslinking\n  Mass Spectrometry","summary":"Crosslinking Mass Spectrometry (MS) can uncover protein-protein interactions\nand provide structural information on proteins in their native cellular\nenvironments. Despite its promise, the field remains hampered by inconsistent\ndata formats, variable approaches to error control, and insufficient\ninteroperability with global data repositories. Recent advances, especially in\nfalse discovery rate (FDR) models and pipeline benchmarking, show that\nCrosslinking MS data can reach a reliability that matches the demand of\nintegrative structural biology. To drive meaningful progress, however, the\ncommunity must agree on error estimation, open data formats, and streamlined\nrepository submissions. This perspective highlights these challenges, clarifies\nremaining barriers, and frames practical next steps. Successful field\nharmonisation will enhance the acceptance of Crosslinking MS in the broader\nbiological community and is critical for the dependability of the data, no\nmatter where it is produced.","main_category":"q-bio.OT","categories":"q-bio.OT","published":"2025-04-09T12:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.06833v1","title":"Symbolic Parallel Composition for Multi-language Protocol Verification","summary":"The implementation of security protocols often combines different languages.\nThis practice, however, poses a challenge to traditional verification\ntechniques, which typically assume a single-language environment and,\ntherefore, are insufficient to handle challenges presented by the interplay of\ndifferent languages. To address this issue, we establish principles for\ncombining multiple programming languages operating on different atomic types\nusing a symbolic execution semantics. This facilitates the (parallel)\ncomposition of labeled transition systems, improving the analysis of complex\nsystems by streamlining communication between diverse programming languages. By\ntreating the Dolev-Yao (DY) model as a symbolic abstraction, our approach\neliminates the need for translation between different base types, such as\nbitstrings and DY terms. Our technique provides a foundation for securing\ninteractions in multi-language environments, enhancing program verification and\nsystem analysis in complex, interconnected systems.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T12:50:03Z"}
{"aid":"http://arxiv.org/abs/2504.06841v1","title":"Classifying the Unknown: In-Context Learning for Open-Vocabulary Text\n  and Symbol Recognition","summary":"We introduce Rosetta, a multimodal model that leverages Multimodal In-Context\nLearning (MICL) to classify sequences of novel script patterns in documents by\nleveraging minimal examples, thus eliminating the need for explicit retraining.\nTo enhance contextual learning, we designed a dataset generation process that\nensures varying degrees of contextual informativeness, improving the model's\nadaptability in leveraging context across different scenarios. A key strength\nof our method is the use of a Context-Aware Tokenizer (CAT), which enables\nopen-vocabulary classification. This allows the model to classify text and\nsymbol patterns across an unlimited range of classes, extending its\nclassification capabilities beyond the scope of its training alphabet of\npatterns. As a result, it unlocks applications such as the recognition of new\nalphabets and languages. Experiments on synthetic datasets demonstrate the\npotential of Rosetta to successfully classify Out-Of-Distribution visual\npatterns and diverse sets of alphabets and scripts, including but not limited\nto Chinese, Greek, Russian, French, Spanish, and Japanese.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T12:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.06856v1","title":"CasTex: Cascaded Text-to-Texture Synthesis via Explicit Texture Maps and\n  Physically-Based Shading","summary":"This work investigates text-to-texture synthesis using diffusion models to\ngenerate physically-based texture maps. We aim to achieve realistic model\nappearances under varying lighting conditions. A prominent solution for the\ntask is score distillation sampling. It allows recovering a complex texture\nusing gradient guidance given a differentiable rasterization and shading\npipeline. However, in practice, the aforementioned solution in conjunction with\nthe widespread latent diffusion models produces severe visual artifacts and\nrequires additional regularization such as implicit texture parameterization.\nAs a more direct alternative, we propose an approach using cascaded diffusion\nmodels for texture synthesis (CasTex). In our setup, score distillation\nsampling yields high-quality textures out-of-the box. In particular, we were\nable to omit implicit texture parameterization in favor of an explicit\nparameterization to improve the procedure. In the experiments, we show that our\napproach significantly outperforms state-of-the-art optimization-based\nsolutions on public texture synthesis benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:08:30Z"}
{"aid":"http://arxiv.org/abs/2504.06870v1","title":"Bayesian Component Separation for DESI LAE Automated Spectroscopic\n  Redshifts and Photometric Targeting","summary":"Lyman Alpha Emitters (LAEs) are valuable high-redshift cosmological probes\ntraditionally identified using specialized narrow-band photometric surveys. In\nground-based spectroscopy, it can be difficult to distinguish the sharp LAE\npeak from residual sky emission lines using automated methods, leading to\nmisclassified redshifts. We present a Bayesian spectral component separation\ntechnique to automatically determine spectroscopic redshifts for LAEs while\nmarginalizing over sky residuals. We use visually inspected spectra of LAEs\nobtained using the Dark Energy Spectroscopic Instrument (DESI) to create a\ndata-driven prior and can determine redshift by jointly inferring sky residual,\nLAE, and residual components for each individual spectrum. We demonstrate this\nmethod on 910 spectroscopically observed $z = 2-4$ DESI LAE candidate spectra\nand determine their redshifts with $>$90% accuracy when validated against\nvisually inspected redshifts. Using the $\\Delta \\chi^2$ value from our pipeline\nas a proxy for detection confidence, we then explore potential survey design\nchoices and implications for targeting LAEs with medium-band photometry. This\nmethod allows for scalability and accuracy in determining redshifts from DESI\nspectra, and the results provide recommendations for LAE targeting in\nanticipation of future high-redshift spectroscopic surveys.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO,stat.AP","published":"2025-04-09T13:21:20Z"}
{"aid":"http://arxiv.org/abs/2504.06902v1","title":"A Measurement Device Independent Quantum Key Distribution protocol in\n  the service of three users","summary":"Quantum Key Distribution (QKD) is the only theoretically proven method for\nsecure key distribution between two users. In this work, we propose and analyze\na Measurement Device Independent (MDI) protocol designed to distribute keys\namong three users in a pairwise manner. Each user randomly selects a basis,\nencodes bit values in the phase of coherent states, and sends the resulting\npulses to a central measurement unit (MU) composed of three beam splitters and\nthree photon detectors. When the three pulses arrive simultaneously at the MU\nand under the condition of successful detection of photons, a key bit is\ndistributed to at least one pair of users. This protocol extends the\nfoundational phase-encoding MDI protocol introduced by [K. Tamaki, et al.,\nPhys. Rev. A 85, 042307 (2012)] to three users, but this comes at the cost of\nintroducing a systematic error in the implementation of the honest protocol.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T14:01:49Z"}
{"aid":"http://arxiv.org/abs/2504.06923v1","title":"The Importance of Being Discrete: Measuring the Impact of Discretization\n  in End-to-End Differentially Private Synthetic Data","summary":"Differentially Private (DP) generative marginal models are often used in the\nwild to release synthetic tabular datasets in lieu of sensitive data while\nproviding formal privacy guarantees. These models approximate low-dimensional\nmarginals or query workloads; crucially, they require the training data to be\npre-discretized, i.e., continuous values need to first be partitioned into\nbins. However, as the range of values (or their domain) is often inferred\ndirectly from the training data, with the number of bins and bin edges\ntypically defined arbitrarily, this approach can ultimately break end-to-end DP\nguarantees and may not always yield optimal utility.\n  In this paper, we present an extensive measurement study of four\ndiscretization strategies in the context of DP marginal generative models. More\nprecisely, we design DP versions of three discretizers (uniform, quantile, and\nk-means) and reimplement the PrivTree algorithm. We find that optimizing both\nthe choice of discretizer and bin count can improve utility, on average, by\nalmost 30% across six DP marginal models, compared to the default strategy and\nnumber of bins, with PrivTree being the best-performing discretizer in the\nmajority of cases. We demonstrate that, while DP generative models with\nnon-private discretization remain vulnerable to membership inference attacks,\napplying DP during discretization effectively mitigates this risk. Finally, we\npropose an optimized approach for automatically selecting the optimal number of\nbins, achieving high utility while reducing both privacy budget consumption and\ncomputational overhead.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-09T14:30:30Z"}
{"aid":"http://arxiv.org/abs/2504.06936v1","title":"On Macdonald expansions of $q$-chromatic symmetric functions and the\n  Stanley-Stembridge Conjecture","summary":"The Stanley-Stembridge conjecture asserts that the chromatic symmetric\nfunction of a $(3+1)$-free graph is $e$-positive. Recently, Hikita proved this\nconjecture by giving an explicit $e$-expansion of the Shareshian-Wachs\n$q$-chromatic refinement for unit interval graphs. Using the $\\mathbb{A}_{q,t}$\nalgebra, we give an expansion of these $q$-chromatic symmetric functions into\nMacdonald polynomials. Upon setting $t=1$, we obtain another proof of the\nStanley-Stembridge conjecture and rederive Hikita's formula. Upon setting\n$t=0$, we obtain an expansion into Hall-Littlewood symmetric functions.","main_category":"math.CO","categories":"math.CO,math.RT","published":"2025-04-09T14:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.06950v1","title":"PathSegDiff: Pathology Segmentation using Diffusion model\n  representations","summary":"Image segmentation is crucial in many computational pathology pipelines,\nincluding accurate disease diagnosis, subtyping, outcome, and survivability\nprediction. The common approach for training a segmentation model relies on a\npre-trained feature extractor and a dataset of paired image and mask\nannotations. These are used to train a lightweight prediction model that\ntranslates features into per-pixel classes. The choice of the feature extractor\nis central to the performance of the final segmentation model, and recent\nliterature has focused on finding tasks to pre-train the feature extractor. In\nthis paper, we propose PathSegDiff, a novel approach for histopathology image\nsegmentation that leverages Latent Diffusion Models (LDMs) as pre-trained\nfeatured extractors. Our method utilizes a pathology-specific LDM, guided by a\nself-supervised encoder, to extract rich semantic information from H\\&E stained\nhistopathology images. We employ a simple, fully convolutional network to\nprocess the features extracted from the LDM and generate segmentation masks.\nOur experiments demonstrate significant improvements over traditional methods\non the BCSS and GlaS datasets, highlighting the effectiveness of\ndomain-specific diffusion pre-training in capturing intricate tissue structures\nand enhancing segmentation accuracy in histopathology images.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T14:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.06983v1","title":"Free Random Projection for In-Context Reinforcement Learning","summary":"Hierarchical inductive biases are hypothesized to promote generalizable\npolicies in reinforcement learning, as demonstrated by explicit hyperbolic\nlatent representations and architectures. Therefore, a more flexible approach\nis to have these biases emerge naturally from the algorithm. We introduce Free\nRandom Projection, an input mapping grounded in free probability theory that\nconstructs random orthogonal matrices where hierarchical structure arises\ninherently. The free random projection integrates seamlessly into existing\nin-context reinforcement learning frameworks by encoding hierarchical\norganization within the input space without requiring explicit architectural\nmodifications. Empirical results on multi-environment benchmarks show that free\nrandom projection consistently outperforms the standard random projection,\nleading to improvements in generalization. Furthermore, analyses within\nlinearly solvable Markov decision processes and investigations of the spectrum\nof kernel random matrices reveal the theoretical underpinnings of free random\nprojection's enhanced performance, highlighting its capacity for effective\nadaptation in hierarchically structured state spaces.","main_category":"cs.LG","categories":"cs.LG,math.PR,stat.ML","published":"2025-04-09T15:38:50Z"}
{"aid":"http://arxiv.org/abs/2504.06991v1","title":"Dissimilar Batch Decompositions of Random Datasets","summary":"For better learning, large datasets are often split into small batches and\nfed sequentially to the predictive model. In this paper, we study such batch\ndecompositions from a probabilistic perspective. We assume that data points\n(possibly corrupted) are drawn independently from a given space and define a\nconcept of similarity between two data points. We then consider decompositions\nthat restrict the amount of similarity within each batch and obtain high\nprobability bounds for the minimum size. We demonstrate an inherent tradeoff\nbetween relaxing the similarity constraint and the overall size and also use\nmartingale methods to obtain bounds for the maximum size of data subsets with a\ngiven similarity.","main_category":"cs.LG","categories":"cs.LG,math.PR,stat.ML","published":"2025-04-09T15:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.06999v1","title":"Extremal Planar Matchings of Inhomogenous Random Bipartite Graphs","summary":"In this paper we study maximum size and minimum weight planar matchings of\ninhomogenous random bipartite graphs. Our motivation for this study comes from\nefficient usage of cross edges in relay networks for overall improvement in\nnetwork performance. We first consider Bernoulli planar matchings with a\nconstraint on the edge length and obtain deviation estimates for the maximum\nsize of a planar matching. We then equip each edge of the complete bipartite\ngraph with a positive random weight and obtain bounds on the minimum weight of\na planar matching containing a given number of edges. We also use segmentation\nand martingale methods to obtain~\\(L^2-\\)convergence of the minimum weight,\nappropriately scaled and centred.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T16:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.07005v1","title":"A stacky approach to prismatic crystals via $q$-prism charts","summary":"Let $Y$ be a locally complete intersection over $\\mathcal{O}_K$ containing a\n$p$-power root of unity $\\zeta_p$. We classify the derived category of\nprismatic crystals on the absolute prismatic site of $Y$ by studying\nquasi-coherent complexes on the prismatization of $Y$ via $q$-prism charts. We\nalso develop a Galois descent mechanism to remove the assumption on\n$\\mathcal{O}_K$. As an application, we classify quasi-coherent complexes on the\nCartier-Witt stack and give a purely algebraic calculation of the cohomology of\nthe structure sheaf on the absolute prismatic site of $\\mathbb{Z}_p$. Along the\nway, for $Y$ a locally complete intersection over $\\overline{A}$ with $A$ lying\nover a $q$-prism, we classify quasi-coherent complexes on the relative\nprismatization of $Y$.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-09T16:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.07011v1","title":"FAME: Introducing Fuzzy Additive Models for Explainable AI","summary":"In this study, we introduce the Fuzzy Additive Model (FAM) and FAM with\nExplainability (FAME) as a solution for Explainable Artificial Intelligence\n(XAI). The family consists of three layers: (1) a Projection Layer that\ncompresses the input space, (2) a Fuzzy Layer built upon Single Input-Single\nOutput Fuzzy Logic Systems (SFLS), where SFLS functions as subnetworks within\nan additive index model, and (3) an Aggregation Layer. This architecture\nintegrates the interpretability of SFLS, which uses human-understandable\nif-then rules, with the explainability of input-output relationships,\nleveraging the additive model structure. Furthermore, using SFLS inherently\naddresses issues such as the curse of dimensionality and rule explosion. To\nfurther improve interpretability, we propose a method for sculpting antecedent\nspace within FAM, transforming it into FAME. We show that FAME captures the\ninput-output relationships with fewer active rules, thus improving clarity. To\nlearn the FAM family, we present a deep learning framework. Through the\npresented comparative results, we demonstrate the promising potential of FAME\nin reducing model complexity while retaining interpretability, positioning it\nas a valuable tool for XAI.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T16:29:55Z"}
{"aid":"http://arxiv.org/abs/2504.07015v1","title":"LLM-IFT: LLM-Powered Information Flow Tracking for Secure Hardware","summary":"As modern hardware designs grow in complexity and size, ensuring security\nacross the confidentiality, integrity, and availability (CIA) triad becomes\nincreasingly challenging. Information flow tracking (IFT) is a widely-used\napproach to tracing data propagation, identifying unauthorized activities that\nmay compromise confidentiality or/and integrity in hardware. However,\ntraditional IFT methods struggle with scalability and adaptability,\nparticularly in high-density and interconnected architectures, leading to\ntracing bottlenecks that limit applicability in large-scale hardware. To\naddress these limitations and show the potential of transformer-based models in\nintegrated circuit (IC) design, this paper introduces LLM-IFT that integrates\nlarge language models (LLM) for the realization of the IFT process in hardware.\nLLM-IFT exploits LLM-driven structured reasoning to perform hierarchical\ndependency analysis, systematically breaking down even the most complex\ndesigns. Through a multi-step LLM invocation, the framework analyzes both\nintra-module and inter-module dependencies, enabling comprehensive IFT\nassessment. By focusing on a set of Trust-Hub vulnerability test cases at both\nthe IP level and the SoC level, our experiments demonstrate a 100\\% success\nrate in accurate IFT analysis for confidentiality and integrity checks in\nhardware.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T16:32:13Z"}
{"aid":"http://arxiv.org/abs/2504.07018v1","title":"ShadowBinding: Realizing Effective Microarchitectures for In-Core Secure\n  Speculation Schemes","summary":"Secure speculation schemes have shown great promise in the war against\nspeculative side-channel attacks, and will be a key building block for\ndeveloping secure, high-performance architectures moving forward. As the field\nmatures, the need for rigorous microarchitectures, and corresponding\nperformance and cost analysis, become critical for evaluating secure schemes\nand for enabling their future adoption.\n  In ShadowBinding, we present effective microarchitectures for two\nstate-of-the-art secure schemes, uncovering and mitigating fundamental\nmicroarchitectural limitations within the analyzed schemes, and provide\nimportant design characteristics. We uncover that Speculative Taint Tracking's\n(STT's) rename-based taint computation must be completed in a single cycle,\ncreating an expensive dependency chain which greatly limits performance for\nwider processor cores. We also introduce a novel michroarchitectural approach\nfor STT, named STT-Issue, which, by delaying the taint computation to the issue\nstage, eliminates the dependency chain, achieving better instructions per cycle\n(IPC), timing, area, and performance results.\n  Through a comprehensive evaluation of our STT and Non-Speculative Data Access\n(NDA) microarchitectural designs on the RISC-V Berkeley Out-of-Order Machine,\nwe find that the IPC impact of in-core secure schemes is higher than previously\nestimated, close to 20% for the highest performance core. With insights into\ntiming from our RTL evaluation, the performance loss, created by the combined\nimpact of IPC and timing, becomes even greater, at 35%, 27%, and 22% for\nSTT-Rename, STT-Issue, and NDA, respectively. If these trends were to hold for\nleading processor core designs, the performance impact would be well over 30%,\neven for the best-performing scheme.","main_category":"cs.CR","categories":"cs.CR,cs.AR","published":"2025-04-09T16:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.07028v1","title":"UAV Position Estimation using a LiDAR-based 3D Object Detection Method","summary":"This paper explores the use of applying a deep learning approach for 3D\nobject detection to compute the relative position of an Unmanned Aerial Vehicle\n(UAV) from an Unmanned Ground Vehicle (UGV) equipped with a LiDAR sensor in a\nGPS-denied environment. This was achieved by evaluating the LiDAR sensor's data\nthrough a 3D detection algorithm (PointPillars). The PointPillars algorithm\nincorporates a column voxel point-cloud representation and a 2D Convolutional\nNeural Network (CNN) to generate distinctive point-cloud features representing\nthe object to be identified, in this case, the UAV. The current localization\nmethod utilizes point-cloud segmentation, Euclidean clustering, and predefined\nheuristics to obtain the relative position of the UAV. Results from the two\nmethods were then compared to a reference truth solution.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T16:43:59Z"}
{"aid":"http://arxiv.org/abs/2504.07041v1","title":"Efficient Storage Integrity in Adversarial Settings","summary":"Storage integrity is essential to systems and applications that use untrusted\nstorage (e.g., public clouds, end-user devices). However, known methods for\nachieving storage integrity either suffer from high (and often prohibitive)\noverheads or provide weak integrity guarantees. In this work, we demonstrate a\nhybrid approach to storage integrity that simultaneously reduces overhead while\nproviding strong integrity guarantees. Our system, partially asynchronous\nintegrity checking (PAC), allows disk write commitments to be deferred while\nstill providing guarantees around read integrity. PAC delivers a 5.5X\nthroughput and latency improvement over the state of the art, and 85% of the\nthroughput achieved by non-integrity-assuring approaches. In this way, we show\nthat untrusted storage can be used for integrity-critical workloads without\nmeaningfully sacrificing performance.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T16:58:22Z"}
{"aid":"http://arxiv.org/abs/2504.07050v1","title":"Minimal mechanism for fluidic flocks in interacting active colloids","summary":"Collective motion as a flock is a widely observed phenomenon in active matter\nsystems. Finding possible mechanisms of attaining a global polar order via\ndynamical mechanisms - without any explicit alignment interaction - is an area\nof active current research. Here, we report a flocking transition sustained\npurely by chemo-repulsive torques at low to medium densities in a system of\nchemically interacting colloidal particles. The basic requirements to sustain\nthe flock are excluded volume repulsions and deterministic long-ranged net\nrepulsive torques, with the time scale individual colloids move a unit length\nbeing dominant with respect to the time they deterministically sense chemicals.\nSwitching on the translational repulsive forces renders the flock a crystalline\nstructure. The generality of this phenomenon is displayed for a range of\nattractive translational forces to which the flock is robust. We rationalize\nthese results with a phenomenological hydrodynamical model.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-09T17:09:48Z"}
{"aid":"http://arxiv.org/abs/2504.07060v1","title":"Generalized Semantic Contrastive Learning via Embedding Side Information\n  for Few-Shot Object Detection","summary":"The objective of few-shot object detection (FSOD) is to detect novel objects\nwith few training samples. The core challenge of this task is how to construct\na generalized feature space for novel categories with limited data on the basis\nof the base category space, which could adapt the learned detection model to\nunknown scenarios. However, limited by insufficient samples for novel\ncategories, two issues still exist: (1) the features of the novel category are\neasily implicitly represented by the features of the base category, leading to\ninseparable classifier boundaries, (2) novel categories with fewer data are not\nenough to fully represent the distribution, where the model fine-tuning is\nprone to overfitting. To address these issues, we introduce the side\ninformation to alleviate the negative influences derived from the feature space\nand sample viewpoints and formulate a novel generalized feature representation\nlearning method for FSOD. Specifically, we first utilize embedding side\ninformation to construct a knowledge matrix to quantify the semantic\nrelationship between the base and novel categories. Then, to strengthen the\ndiscrimination between semantically similar categories, we further develop\ncontextual semantic supervised contrastive learning which embeds side\ninformation. Furthermore, to prevent overfitting problems caused by sparse\nsamples, a side-information guided region-aware masked module is introduced to\naugment the diversity of samples, which finds and abandons biased information\nthat discriminates between similar categories via counterfactual explanation,\nand refines the discriminative representation space further. Extensive\nexperiments using ResNet and ViT backbones on PASCAL VOC, MS COCO, LVIS V1,\nFSOD-1K, and FSVOD-500 benchmarks demonstrate that our model outperforms the\nprevious state-of-the-art methods, significantly improving the ability of FSOD\nin most shots/splits.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T17:24:05Z"}
{"aid":"http://arxiv.org/abs/2504.07063v1","title":"Non-Gaussianity of Tensor Induced Density Perturbations","summary":"We investigate the non-Gaussianity of second-order matter density\nperturbations induced by primordial gravitational waves (GWs). These\ntensor-induced scalar modes arise from local fluctuations in the GWs energy\ndensity, which is quadratic in tensor perturbations. The resulting second-order\ndensity contrast follows a chi-squared distribution, naturally exhibiting\nsignificant non-Gaussianity. We compute the bispectrum of these tensor-induced\nscalar modes and analyze its dependence on various primordial GWs power\nspectra, including scale-invariant, blue-tilted, Gaussian-bump, and\nmonochromatic sources. We find that the bispectrum shape is inherently\nsensitive to the underlying GWs spectrum by construction. In particular,\nGaussian-bump and monochromatic sources produce a strong signal peaking in the\nequilateral configuration, similar to the effect of scalar-induced tensor\nmodes. Our findings reveal a new way to probe primordial GWs via galaxy surveys\nand highlight a unique feature of tensor-induced density perturbations,\notherwise mimicking linear ones on sub-horizon scales.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T17:26:41Z"}
{"aid":"http://arxiv.org/abs/2504.07074v1","title":"The Lyman-alpha and Continuum Origins Survey II: the uneventful journey\n  of escaping Ly$α$ and ionizing radiation through the neutral ISM and CGM\n  of galaxies","summary":"One of the current challenges in galaxy evolution studies is to establish the\nmechanisms that govern the escape of ionizing radiation from galaxies. In this\nwork, we investigate the connection between Lyman Continuum (LyC) escape and\nthe conditions of the Circumgalactic Medium (CGM), as probed by Ly$\\alpha$\nhalos (LAHs) in emission. We use Ly$\\alpha$ and UV continuum imaging data from\nthe Lyman alpha and Continuum Origins Survey (LaCOS), targeting 42 nearby ($z\n\\simeq 0.3$), star-forming galaxies with LyC observations (escape fractions of\n$f_{\\rm esc}^{\\rm LyC} \\simeq 0.01-0.49$). LaCOS galaxies show extended\nLy$\\alpha$ emission ubiquitously, with LyC emitters (LCEs) having more compact\nLy$\\alpha$ morphologies relative to the UV size than non-LCEs, and Ly$\\alpha$\nspatial offsets that do not exceed the extent of the UV continuum. We model the\ndiffuse LAHs using a combined Sersic plus exponential 2D profile, and find that\nthe characteristic scale length of the Ly$\\alpha$ is ten times the scale length\nof the UV, on average. We unveil a tight anti-correlation between $f_{\\rm\nesc}^{\\rm LyC}$ and the Ly$\\alpha$ Halo Fraction (HF, or contribution of the\nhalo to the total Ly$\\alpha$ luminosity), that we propose as a new LyC\nindicator. Our observations also show that the HF scales positively with the\nneutral gas in the ISM, revealing a picture in which Ly$\\alpha$ and LyC photons\nin LCEs emerge through clear sight-lines directly from the central starbursts\nand, in the case of Ly$\\alpha$, minimizing the number of scattering\ninteractions in the CGM. The properties of LAHs in LaCOS resemble those of LAHs\nat $z \\geq 3$, suggesting a lack of evolution in the $f_{\\rm esc}^{\\rm LyC}$\npredictors that rely on the spatial properties of Ly$\\alpha$, and ensuring the\napplicability of these indicators to observations of high-redshift galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T17:46:13Z"}
{"aid":"http://arxiv.org/abs/2504.07087v1","title":"KG-LLM-Bench: A Scalable Benchmark for Evaluating LLM Reasoning on\n  Textualized Knowledge Graphs","summary":"Knowledge graphs have emerged as a popular method for injecting up-to-date,\nfactual knowledge into large language models (LLMs). This is typically achieved\nby converting the knowledge graph into text that the LLM can process in\ncontext. While multiple methods of encoding knowledge graphs have been\nproposed, the impact of this textualization process on LLM performance remains\nunder-explored. We introduce KG-LLM-Bench, a comprehensive and extensible\nbenchmark spanning five knowledge graph understanding tasks, and evaluate how\ndifferent encoding strategies affect performance across various base models.\nOur extensive experiments with seven language models and five textualization\nstrategies provide insights for optimizing LLM performance on KG reasoning\ntasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-04-09T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.07091v1","title":"AssistanceZero: Scalably Solving Assistance Games","summary":"Assistance games are a promising alternative to reinforcement learning from\nhuman feedback (RLHF) for training AI assistants. Assistance games resolve key\ndrawbacks of RLHF, such as incentives for deceptive behavior, by explicitly\nmodeling the interaction between assistant and user as a two-player game where\nthe assistant cannot observe their shared goal. Despite their potential,\nassistance games have only been explored in simple settings. Scaling them to\nmore complex environments is difficult because it requires both solving\nintractable decision-making problems under uncertainty and accurately modeling\nhuman users' behavior. We present the first scalable approach to solving\nassistance games and apply it to a new, challenging Minecraft-based assistance\ngame with over $10^{400}$ possible goals. Our approach, AssistanceZero, extends\nAlphaZero with a neural network that predicts human actions and rewards,\nenabling it to plan under uncertainty. We show that AssistanceZero outperforms\nmodel-free RL algorithms and imitation learning in the Minecraft-based\nassistance game. In a human study, our AssistanceZero-trained assistant\nsignificantly reduces the number of actions participants take to complete\nbuilding tasks in Minecraft. Our results suggest that assistance games are a\ntractable framework for training effective AI assistants in complex\nenvironments. Our code and models are available at\nhttps://github.com/cassidylaidlaw/minecraft-building-assistance-game.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-09T17:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.07096v1","title":"OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training\n  Tokens","summary":"We present OLMoTrace, the first system that traces the outputs of language\nmodels back to their full, multi-trillion-token training data in real time.\nOLMoTrace finds and shows verbatim matches between segments of language model\noutput and documents in the training text corpora. Powered by an extended\nversion of infini-gram (Liu et al., 2024), our system returns tracing results\nwithin a few seconds. OLMoTrace can help users understand the behavior of\nlanguage models through the lens of their training data. We showcase how it can\nbe used to explore fact checking, hallucination, and the creativity of language\nmodels. OLMoTrace is publicly available and fully open-source.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T17:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.07418v1","title":"ThermoStereoRT: Thermal Stereo Matching in Real Time via Knowledge\n  Distillation and Attention-based Refinement","summary":"We introduce ThermoStereoRT, a real-time thermal stereo matching method\ndesigned for all-weather conditions that recovers disparity from two rectified\nthermal stereo images, envisioning applications such as night-time drone\nsurveillance or under-bed cleaning robots. Leveraging a lightweight yet\npowerful backbone, ThermoStereoRT constructs a 3D cost volume from thermal\nimages and employs multi-scale attention mechanisms to produce an initial\ndisparity map. To refine this map, we design a novel channel and spatial\nattention module. Addressing the challenge of sparse ground truth data in\nthermal imagery, we utilize knowledge distillation to boost performance without\nincreasing computational demands. Comprehensive evaluations on multiple\ndatasets demonstrate that ThermoStereoRT delivers both real-time capacity and\nrobust accuracy, making it a promising solution for real-world deployment in\nvarious challenging environments. Our code will be released on\nhttps://github.com/SJTU-ViSYS-team/ThermoStereoRT","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T03:24:21Z"}
{"aid":"http://arxiv.org/abs/2504.07424v1","title":"Routing to the Right Expertise: A Trustworthy Judge for\n  Instruction-based Image Editing","summary":"Instruction-based Image Editing (IIE) models have made significantly\nimprovement due to the progress of multimodal large language models (MLLMs) and\ndiffusion models, which can understand and reason about complex editing\ninstructions. In addition to advancing current IIE models, accurately\nevaluating their output has become increasingly critical and challenging.\nCurrent IIE evaluation methods and their evaluation procedures often fall short\nof aligning with human judgment and often lack explainability. To address these\nlimitations, we propose JUdgement through Routing of Expertise (JURE). Each\nexpert in JURE is a pre-selected model assumed to be equipped with an atomic\nexpertise that can provide useful feedback to judge output, and the router\ndynamically routes the evaluation task of a given instruction and its output to\nappropriate experts, aggregating their feedback into a final judge. JURE is\ntrustworthy in two aspects. First, it can effortlessly provide explanations\nabout its judge by examining the routed experts and their feedback. Second,\nexperimental results demonstrate that JURE is reliable by achieving superior\nalignment with human judgments, setting a new standard for automated IIE\nevaluation. Moreover, JURE's flexible design is future-proof - modular experts\ncan be seamlessly replaced or expanded to accommodate advancements in IIE,\nmaintaining consistently high evaluation quality. Our evaluation data and\nresults are available at https://github.com/Cyyyyyrus/JURE.git.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T03:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.07440v1","title":"Revisiting LLM Evaluation through Mechanism Interpretability: a New\n  Metric and Model Utility Law","summary":"Large Language Models (LLMs) have become indispensable across academia,\nindustry, and daily applications, yet current evaluation methods struggle to\nkeep pace with their rapid development. In this paper, we analyze the core\nlimitations of traditional evaluation pipelines and propose a novel metric, the\nModel Utilization Index (MUI), which introduces mechanism interpretability\ntechniques to complement traditional performance metrics. MUI quantifies the\nextent to which a model leverages its capabilities to complete tasks. The core\nidea is that to assess an LLM's overall ability, we must evaluate not only its\ntask performance but also the effort expended to achieve the outcome. Our\nextensive experiments reveal an inverse relationship between MUI and\nperformance, from which we deduce a common trend observed in popular LLMs,\nwhich we term the Utility Law. Based on this, we derive four corollaries that\naddress key challenges, including training judgement, the issue of data\ncontamination, fairness in model comparison, and data diversity. We hope that\nour survey, novel metric, and utility law will foster mutual advancement in\nboth evaluation and mechanism interpretability. Our code can be found at\nhttps://github.com/ALEX-nlp/MUI-Eva.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T04:09:47Z"}
{"aid":"http://arxiv.org/abs/2504.07456v1","title":"Sums with Stern-Brocot sequences and Minkowski question mark function","summary":"We give an affirmative answer to a question asked by N. Moshchevitin\n\\cite{m1} in his lecture at International Congress of Basic Science, Beijing,\n2024 (see also \\cite{m}, Section 6.3). The question is that whether the\nremainder $$\nR_n=\\sum_{j=1}^{2^n}\\left(\\xi_{j,n}-\\frac{j}{2^n}\\right)^2-2^n\\int_0^1(?(x)-x))^2\\text{d}x\n$$ tends to $0$ when $n$ tends to infinity, where $\\xi_{j,n}$ are elements of\nthe Stern-Brocot sequence and $?(x)$ denotes Minkowski Question-Mark Function.\nWe present some extended results and give a correct proof of a theorem on the\nFourier-Stieltjes coefficient of the inverse function of $?(x)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T05:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.07467v1","title":"Defense against Prompt Injection Attacks via Mixture of Encodings","summary":"Large Language Models (LLMs) have emerged as a dominant approach for a wide\nrange of NLP tasks, with their access to external information further enhancing\ntheir capabilities. However, this introduces new vulnerabilities, known as\nprompt injection attacks, where external content embeds malicious instructions\nthat manipulate the LLM's output. Recently, the Base64 defense has been\nrecognized as one of the most effective methods for reducing success rate of\nprompt injection attacks. Despite its efficacy, this method can degrade LLM\nperformance on certain NLP tasks. To address this challenge, we propose a novel\ndefense mechanism: mixture of encodings, which utilizes multiple character\nencodings, including Base64. Extensive experimental results show that our\nmethod achieves one of the lowest attack success rates under prompt injection\nattacks, while maintaining high performance across all NLP tasks, outperforming\nexisting character encoding-based defense methods. This underscores the\neffectiveness of our mixture of encodings strategy for both safety and task\nperformance metrics.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T05:35:21Z"}
{"aid":"http://arxiv.org/abs/2504.07470v1","title":"Transformer-Based Temporal Information Extraction and Application: A\n  Review","summary":"Temporal information extraction (IE) aims to extract structured temporal\ninformation from unstructured text, thereby uncovering the implicit timelines\nwithin. This technique is applied across domains such as healthcare, newswire,\nand intelligence analysis, aiding models in these areas to perform temporal\nreasoning and enabling human users to grasp the temporal structure of text.\nTransformer-based pre-trained language models have produced revolutionary\nadvancements in natural language processing, demonstrating exceptional\nperformance across a multitude of tasks. Despite the achievements garnered by\nTransformer-based approaches in temporal IE, there is a lack of comprehensive\nreviews on these endeavors. In this paper, we aim to bridge this gap by\nsystematically summarizing and analyzing the body of work on temporal IE using\nTransformers while highlighting potential future research directions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T05:48:24Z"}
{"aid":"http://arxiv.org/abs/2504.07478v1","title":"Intelligent DoS and DDoS Detection: A Hybrid GRU-NTM Approach to Network\n  Security","summary":"Detecting Denial of Service (DoS) and Distributed Denial of Service (DDoS)\nattacks remains a critical challenge in cybersecurity. This research introduces\na hybrid deep learning model combining Gated Recurrent Units (GRUs) and a\nNeural Turing Machine (NTM) for enhanced intrusion detection. Trained on the\nUNSW-NB15 and BoT-IoT datasets, the model employs GRU layers for sequential\ndata processing and an NTM for long-term pattern recognition. The proposed\napproach achieves 99% accuracy in distinguishing between normal, DoS, and DDoS\ntraffic. These findings offer promising advancements in real-time threat\ndetection and contribute to improved network security across various domains.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-10T06:08:04Z"}
{"aid":"http://arxiv.org/abs/2504.07480v1","title":"Echoes of Disagreement: Measuring Disparity in Social Consensus","summary":"Public discourse and opinions stem from multiple social groups. Each group\nhas beliefs about a topic (such as vaccination, abortion, gay marriage, etc.),\nand opinions are exchanged and blended to produce consensus. A particular\nmeasure of interest corresponds to measuring the influence of each group on the\nconsensus and the disparity between groups on the extent to which they\ninfluence the consensus. In this paper, we study and give provable algorithms\nfor optimizing the disparity under the DeGroot or the Friedkin-Johnsen models\nof opinion dynamics. Our findings provide simple poly-time algorithms to\noptimize disparity for most cases, fully characterize the instances that\noptimize disparity, and show how simple interventions such as contracting\nvertices or adding links affect disparity. Finally, we test our developed\nalgorithms in a variety of real-world datasets.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T06:18:27Z"}
{"aid":"http://arxiv.org/abs/2504.07492v1","title":"Homogeneous nucleation rate of carbon dioxide hydrate formation under\n  experimental condition from Seeding simulations","summary":"We investigate the nucleation of carbon dioxide (CO$_2$) hydrates from carbon\ndioxide aqueous solutions by means of molecular dynamics simulations using the\nTIP4P/Ice and the TraPPE models for water and CO$_2$ respectively. We work at\n400 bar and different temperatures and CO$_2$ concentrations. We use brute\nforce molecular dynamics when the supersaturation or the supercooling are so\nhigh so that nucleation occurs spontaneously and Seeding otherwise. We used\nboth methods for a particular state and we get a rate of\n10$^{25}\\,\\text{m}^{-3}\\text{s}^{-1}$ for nucleation in a CO$_2$ saturated\nsolution at 255 K (35 K of supercooling). By comparison with our previous work\non methane hydrates, we conclude that nucleation of CO$_2$ hydrates is several\norders of magnitude faster due to a lower interfacial free energy between the\ncrystal and the solution. By combining our nucleation studies with a recent\ncalculation of the hydrate-solution interfacial free energy at coexistence, we\nobtain a prediction of the nucleation rate temperature dependence for\nCO$_{2}$-saturated solutions (the experimentally relevant concentration). On\nthe one hand, we open the window for comparison with experiments for\nsupercooling larger than 25 K. On the other hand, we conclude that homogeneous\nnucleation is impossible for supercooling lower than 20 K. Therefore,\nnucleation must be heterogeneous in typical experiments where hydrate formation\nis observed at low supercooling. To assess the hypothesis that nucleation\noccurs at the solution-CO$_2$ interface we run spontaneous nucleation\nsimulations in two-phase systems and find, by comparison with single-phase\nsimulations, that the interface does not affect hydrate nucleation, at least at\nthe deep supercooling at which this study was carried out (40 and 45 K).\nOverall, our work sheds light on molecular and thermodynamic aspects of hydrate\nnucleation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T06:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.07510v1","title":"Wigner distribution, Wigner entropy, and Anomalous Transport of a\n  Generalized Aubry-André model","summary":"In this paper, we study a generalized Aubry-Andr\\'{e} model with tunable\nquasidisordered potentials. The model has an invariable mobility edge that\nseparates the extended states from the localized states. At the mobility edge,\nthe wave function presents critical characteristics, which can be verified by\nfinite-size scaling analysis. Our numerical investigations demonstrate that the\nextended, critical, and localized states can be effectively distinguished via\ntheir phase space representation, specially the Wigner distribution. Based on\nthe Wigner distribution function, we can further obtain the corresponding\nWigner entropy and employ the feature that the critical state has the maximum\nWigner entropy to locate the invariable mobility edge. Finally, we reveal that\nthere are anomalous transport phenomena between the transition from ballistic\ntransport to the absence of diffusion.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-10T07:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.07537v1","title":"Formalizing Representation Theorems for a Logical Framework with\n  Rewriting","summary":"Representation theorems for formal systems often take the form of an\ninductive translation that satisfies certain invariants, which are proved\ninductively. Theory morphisms and logical relations are common patterns of such\ninductive constructions. They allow representing the translation and the proofs\nof the invariants as a set of translation rules, corresponding to the cases of\nthe inductions. Importantly, establishing the invariants is reduced to checking\na finite set of, typically decidable, statements. Therefore, in a framework\nsupporting theory morphisms and logical relations, translations that fit one of\nthese patterns become much easier to formalize and to verify. The\n$\\lambda\\Pi$-calculus modulo rewriting is a logical framework designed for\nrepresenting and translating between formal systems that has previously not\nsystematically supported such patterns. In this paper, we extend it with theory\nmorphisms and logical relations. We apply these to define and verify invariants\nfor a number of translations between formal systems. In doing so, we identify\nsome best practices that enable us to obtain elegant novel formalizations of\nsome challenging translations, in particular type erasure translations from\ntyped to untyped languages.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-10T08:02:40Z"}
{"aid":"http://arxiv.org/abs/2504.07550v1","title":"A search for periodic activity in multi-peaked long gamma-ray bursts","summary":"A sizeable fraction of gamma-ray burst (GRB) light curves (LCs) features a\nsequence of peaks, which holds information on the unknown way energy is\ndissipated into gamma-rays over time. Traditional searches for periodic signals\nin GRB LCs turned out to be inconclusive, partly because they are challenging\nas a consequence of the short-lived, coloured-noise, and non-stationary nature\nof the LCs themselves. Yet, recent claims have revived the issue. We searched\nfor periodic components in GRB LCs through a new approach to GRBs, which\nescapes most of the issues faced by traditional techniques. We identified peaks\nthrough a well tested algorithm and selected GRBs with at least 10 peaks out of\n5 GRB catalogues (Swift/BAT, CGRO/BATSE, Fermi/GBM, Insight-HXMT,\nBeppoSAX/GRBM). Each GRB was simply treated as a discrete point process, whose\nrealisation coincides with the sequence of peak times. We searched for possible\nperiodic recurrences based on the multinomial distribution, after accounting\nfor the clustering of peaks due to the non-stationarity of the GRB signals. The\nbest candidate has a p-value of 3e-4 that there is no periodic recurrence.\nHowever, accounting for the multiple trials of 555 searched GRBs, its\nstatistical significance is demoted to 17%. The overall distribution of the\np-values obtained for all GRBs is compatible with a uniform distribution in\n[0,1]. We found no robust evidence for multi-peaked GRBs with periodic\nrecurrences. We can exclude that a sizeable fraction (>~ 0.75) of peaks of each\nGRB with at least 10 peaks are periodic. While our result does not necessarily\nclash with claimed periodicities based on Fourier techniques, it constrains the\nputative recurrent behaviour, which would not manifest itself through the\nsequence of peaks, but, evidently, in a more elusive way.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T08:25:10Z"}
{"aid":"http://arxiv.org/abs/2504.07558v1","title":"Atomic structure analysis of PL5 in silicon carbide with single-spin\n  spectroscopy","summary":"Divacancy (VV) spin defects in 4H polytype of silicon carbide (4H-SiC) are\nemerging candidates for quantum information processing and quantum sensing.\nAmong these defects, PL5 and PL6 stand out due to their superior charge\nstability and optically detected magnetic resonance (ODMR) properties at room\ntemperature. However, their atomic structures remain unresolved, with ongoing\ncontroversy regarding their potential association with stacking faults.\nPrevious measurements relying on spin ensemble detection are insufficient to\ndraw definitive conclusions. In this study, we conduct correlative imaging of\nstacking faults and PL5-6 at single-defect level, conclusively demonstrating\nthat PL5-6 are not associated with stacking faults. Further investigation of\nPL5 through single-spin ODMR spectroscopy allows us to determine its six\nspatial orientations, as well as to measure the orientation of its transverse\nanisotropy spin splitting (E) and the statistical distribution of hyperfine\nsplitting. These results and ab initio calculations suggest that PL5 should be\nVsiVc(hk) divacancy coupled with a nearby antisite atom (VVA). The structure\nresolution of PL5 starts the first step toward its controllable fabrication,\npaving the way for various applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.comp-ph,quant-ph","published":"2025-04-10T08:39:40Z"}
{"aid":"http://arxiv.org/abs/2504.07560v1","title":"PhaseGen: A Diffusion-Based Approach for Complex-Valued MRI Data\n  Generation","summary":"Magnetic resonance imaging (MRI) raw data, or k-Space data, is\ncomplex-valued, containing both magnitude and phase information. However,\nclinical and existing Artificial Intelligence (AI)-based methods focus only on\nmagnitude images, discarding the phase data despite its potential for\ndownstream tasks, such as tumor segmentation and classification. In this work,\nwe introduce $\\textit{PhaseGen}$, a novel complex-valued diffusion model for\ngenerating synthetic MRI raw data conditioned on magnitude images, commonly\nused in clinical practice. This enables the creation of artificial\ncomplex-valued raw data, allowing pretraining for models that require k-Space\ninformation. We evaluate PhaseGen on two tasks: skull-stripping directly in\nk-Space and MRI reconstruction using the publicly available FastMRI dataset.\nOur results show that training with synthetic phase data significantly improves\ngeneralization for skull-stripping on real-world data, with an increased\nsegmentation accuracy from $41.1\\%$ to $80.1\\%$, and enhances MRI\nreconstruction when combined with limited real-world data. This work presents a\nstep forward in utilizing generative AI to bridge the gap between\nmagnitude-based datasets and the complex-valued nature of MRI raw data. This\napproach allows researchers to leverage the vast amount of avaliable image\ndomain data in combination with the information-rich k-Space data for more\naccurate and efficient diagnostic tasks. We make our code publicly\n$\\href{https://github.com/TIO-IKIM/PhaseGen}{\\text{available here}}$.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-10T08:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07583v1","title":"Do LLMs Understand Your Translations? Evaluating Paragraph-level MT with\n  Question Answering","summary":"Despite the steady progress in machine translation evaluation, existing\nautomatic metrics struggle to capture how well meaning is preserved beyond\nsentence boundaries. We posit that reliance on a single intrinsic quality\nscore, trained to mimic human judgments, might be insufficient for evaluating\ntranslations of long, complex passages, and a more ``pragmatic'' approach that\nassesses how accurately key information is conveyed by a translation in context\nis needed. We introduce TREQA (Translation Evaluation via Question-Answering),\na framework that extrinsically evaluates translation quality by assessing how\naccurately candidate translations answer reading comprehension questions that\ntarget key information in the original source or reference texts. In\nchallenging domains that require long-range understanding, such as literary\ntexts, we show that TREQA is competitive with and, in some cases, outperforms\nstate-of-the-art neural and LLM-based metrics in ranking alternative\nparagraph-level translations, despite never being explicitly optimized to\ncorrelate with human judgments. Furthermore, the generated questions and\nanswers offer interpretability: empirical analysis shows that they effectively\ntarget translation errors identified by experts in evaluated datasets. Our code\nis available at https://github.com/deep-spin/treqa","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-10T09:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.07589v1","title":"Copy-and-Paste? Identifying EVM-Inequivalent Code Smells in Multi-chain\n  Reuse Contracts","summary":"As the development of Solidity contracts on Ethereum, more developers are\nreusing them on other compatible blockchains. However, developers may overlook\nthe differences between the designs of the blockchain system, such as the Gas\nMechanism and Consensus Protocol, leading to the same contracts on different\nblockchains not being able to achieve consistent execution as on Ethereum. This\ninconsistency reveals design flaws in reused contracts, exposing code smells\nthat hinder code reusability, and we define this inconsistency as\nEVM-Inequivalent Code Smells. In this paper, we conducted the first empirical\nstudy to reveal the causes and characteristics of EVM-Inequivalent Code Smells.\nTo ensure the identified smells reflect real developer concerns, we collected\nand analyzed 1,379 security audit reports and 326 Stack Overflow posts related\nto reused contracts on EVM-compatible blockchains, such as Binance Smart Chain\n(BSC) and Polygon. Using the open card sorting method, we defined six types of\nEVM-Inequivalent Code Smells. For automated detection, we developed a tool\nnamed EquivGuard. It employs static taint analysis to identify key paths from\ndifferent patterns and uses symbolic execution to verify path reachability. Our\nanalysis of 905,948 contracts across six major blockchains shows that\nEVM-Inequivalent Code Smells are widespread, with an average prevalence of\n17.70%. While contracts with code smells do not necessarily lead to financial\nloss and attacks, their high prevalence and significant asset management\nunderscore the potential threats of reusing these smelly Ethereum contracts.\nThus, developers are advised to abandon Copy-and-Paste programming practices\nand detect EVM-Inequivalent Code Smells before reusing Ethereum contracts.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T09:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.07630v1","title":"An intrinsic cosmological observer","summary":"There has been much recent interest in the necessity of an observer degree of\nfreedom in the description of local algebras in semiclassical gravity. In this\nwork, we describe an example where the observer can be constructed\nintrinsically from the quantum fields. This construction involves the slow-roll\ninflation example recently analyzed by Chen and Penington, in which the\ngauge-invariant gravitational algebra arises from marginalizing over modular\nflow in a de Sitter static patch. We relate this procedure to the\nConnes-Takesaki theory of the flow of weights for type III von Neumann\nalgebras, and further show that the resulting gravitational algebra can\nnaturally be presented as a crossed product. This leads to a decomposition of\nthe gravitational algebra into quantum field and observer degrees of freedom,\nwith different choices of observer being related to changes in a quantum\nreference frame for the algebra. We also connect this example to other\nconstructions of type II algebras in semiclassical gravity, and argue they all\nshare the feature of being the result of gauging modular flow. The arguments in\nthis work involve various properties of automorphism groups of hyperfinite\nfactors, and so in an appendix we review the structure of these groups, which\nmay be of independent interest for further investigations into von Neumann\nalgebras in quantum gravity.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-10T10:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.07651v1","title":"Nonperturbative quantum theory of multiplasmonic electron emission from\n  surfaces: Gauge-specific cumulant expansions vs. Volkov ansatz over plasmonic\n  coherent states","summary":"Energetic electromagnetic fields produce a variety of elementary excitations\nin solids that can strongly modify their primary photoemission spectra. Such is\nthe plasmon excitation or pumping mechanism which, although indirect, is very\nefficient and hence may give rise to formation of plasmonic coherent states. In\nturn, these states may act as a source or sink of energy and momentum for\nescaping electrons. Starting from the model Hamiltonian approach we show that\nprepumped plasmonic bath of coherent states gives rise to ponderomotive\npotentials and Floquet electronic band structure that support multiple\nplasmon-induced electron emission or plasmoemission from metals. Theoretical\ndescription of multiple plasmoemission requires a nonperturbative approch which\nis here formulated by applying cumulant expansion and Volkov ansatz to the\ncalculations of electron wavefunctions and emission rates. The calculations are\nperformed in the standard length gauge as well as in the Pauli-transformed\nvelocity gauge for electron-plasmon interaction. The applicability of two\nnonperturbative approaches to calculation of excitation amplitudes are examined\nin each gauge. They smoothly interpolate between the fully quantal first order\nBorn approximation and semiclassical multiplasmon-induced electron excitation\nlimit. This is illustrated on the example of plasmoemission from Floquet\nsurface bands on Ag(111) from which this channel of electron yield has been\ndetected. Our calculations indicate that even subsingle mode occupations of\nplasmonic coherent states can support multiplasmon electron emission from\nsurface bands. A way of calibration of plasmonic coherent states is proposed.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-10T10:58:28Z"}
{"aid":"http://arxiv.org/abs/2504.07671v1","title":"Cross-Laplacians Based Topological Signal Processing over Cell\n  MultiComplexes","summary":"The study of the interactions among different types of interconnected systems\nin complex networks has attracted significant interest across many research\nfields. However, effective signal processing over layered networks requires\ntopological descriptors of the intra- and cross-layers relationships that are\nable to disentangle the homologies of different domains, at different scales,\naccording to the specific learning task. In this paper, we present Cell\nMultiComplex (CMC) spaces, which are novel topological domains for representing\nmultiple higher-order relationships among interconnected complexes. We\nintroduce cross-Laplacians matrices, which are algebraic descriptors of CMCs\nenabling the extraction of topological invariants at different scales, whether\nglobal or local, inter-layer or intra-layer. Using the eigenvectors of these\ncross-Laplacians as signal bases, we develop topological signal processing\ntools for CMC spaces. In this first study, we focus on the representation and\nfiltering of noisy flows observed over cross-edges between different layers of\nCMCs to identify cross-layer hubs, i.e., key nodes on one layer controlling the\nothers.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T11:42:58Z"}
{"aid":"http://arxiv.org/abs/2504.07683v1","title":"Effects of Berry Curvature and Orbital Magnetic Moment in the\n  Magnetothermoelectric Transport of Bloch Electron Systems","summary":"Thermoelectric transport coefficients up to linear order in the applied\nmagnetic field are microscopically studied using Kubo-Luttinger linear response\ntheory and thermal Green's functions. We derive exact formulas for the\nthermoelectric conductivity and thermal conductivity in the limit of small\nrelaxation rates for Bloch electrons in terms of Bloch wave functions, which\nshow that the Sommerfeld-Bethe relationship holds. Our final formula contains\nthe Berry curvature contributions as well as the orbital magnetic moment\ncontributions, that arise naturally from the microscopic theory. We show that\ngeneralized $f$-sum rules containing the Berry curvature and orbital magnetic\nmoment play essential roles in taking into account the interband effects of the\nmagnetic field. As an application, we study a model of a gapped Dirac electron\nsystem with broken time-reversal symmetry and show the presence of a linear\nmagnetothermopower in such systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T12:13:35Z"}
{"aid":"http://arxiv.org/abs/2504.07692v1","title":"Singularity resolution and inflation from an infinite tower of\n  regularized curvature corrections","summary":"We explore four-dimensional scalar-tensor theories obtained from well-defined\ndimensional regularizations of Lovelock invariants. When an infinite tower of\ncorrections is considered, these theories allow for cosmological models in\nwhich the Big Bang singularity is replaced by an inflationary phase in the\nearly-universe, and they also admit a specific class of regular black hole\nsolutions.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-04-10T12:26:03Z"}
{"aid":"http://arxiv.org/abs/2504.07704v1","title":"Measures of non-simplifyingness for conditional copulas and vines","summary":"In copula modeling, the simplifying assumption has recently been the object\nof much interest. Although it is very useful to reduce the computational\nburden, it remains far from obvious whether it is actually satisfied in\npractice. We propose a theoretical framework which aims at giving a precise\nmeaning to the following question: how non-simplified or close to be simplified\nis a given conditional copula? For this, we propose a theoretical framework\ncentered at the notion of measure of non-constantness. Then we discuss\ngeneralizations of the simplifying assumption to the case where the conditional\nmarginal distributions may not be continuous, and corresponding measures of\nnon-simplifyingness in this case. The simplifying assumption is of particular\nimportance for vine copula models, and we therefore propose a notion of measure\nof non-simplifyingness of a given copula for a particular vine structure, as\nwell as different scores measuring how non-simplified such a vine\ndecompositions would be for a general vine. Finally, we propose estimators for\nthese measures of non-simplifyingness given an observed dataset.","main_category":"math.ST","categories":"math.ST,stat.OT,stat.TH","published":"2025-04-10T12:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.07708v1","title":"TOCALib: Optimal control library with interpolation for bimanual\n  manipulation and obstacles avoidance","summary":"The paper presents a new approach for constructing a library of optimal\ntrajectories for two robotic manipulators, Two-Arm Optimal Control and\nAvoidance Library (TOCALib). The optimisation takes into account kinodynamic\nand other constraints within the FROST framework. The novelty of the method\nlies in the consideration of collisions using the DCOL method, which allows\nobtaining symbolic expressions for assessing the presence of collisions and\nusing them in gradient-based optimization control methods. The proposed\napproach allowed the implementation of complex bimanual manipulations. In this\npaper we used Mobile Aloha as an example of TOCALib application. The approach\ncan be extended to other bimanual robots, as well as to gait control of bipedal\nrobots. It can also be used to construct training data for machine learning\ntasks for manipulation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T12:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.07727v1","title":"Exploratory calculation of the rare hyperon decay $Σ^+ \\to p \\ell^+\n  \\ell^-$ from lattice QCD","summary":"The rare hyperon decay $\\Sigma^+ \\to p \\ell^+ \\ell^-$ is a flavour-changing\nneutral current process mediated by an $s \\to d$ transition that occurs only at\nloop level within the Standard Model. Consequently, this decay is highly\nsuppressed, making it a promising avenue for probing potential new physics.\nWhile phenomenological calculations have made important progress in predicting\nthe decay amplitude, there remains a four-fold ambiguity in the relevant\ntransition form factors that prevents a unique prediction for the branching\nfraction and angular observables. Fully resolving this ambiguity requires a\nfirst-principles Standard-Model calculation, and the recent observation of this\nprocess using LHCb Run 2 data reinforces the timeliness of such a calculation.\nIn this work, we present the first lattice-QCD calculation of this decay,\nperformed using a 2+1-flavour domain-wall fermion ensemble with a pion mass of\n340 MeV. At a small baryon source-sink separation, we observe the emergence of\na signal in the relevant baryonic four-point functions. This allows us to\ndetermine the positive-parity form factors for the rare hyperon decays from\nfirst-principles, albeit with large statistical and systematic uncertainties.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-10T13:20:40Z"}
{"aid":"http://arxiv.org/abs/2504.07761v1","title":"Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection","summary":"In an increasingly digitalized world, verifying the authenticity of ID\ndocuments has become a critical challenge for real-life applications such as\ndigital banking, crypto-exchanges, renting, etc. This study focuses on the\ntopic of fake ID detection, covering several limitations in the field. In\nparticular, no publicly available data from real ID documents exists, and most\nstudies rely on proprietary in-house databases that are not available due to\nprivacy reasons. In order to shed some light on this critical challenge that\nmakes difficult to advance in the field, we explore a trade-off between privacy\n(i.e., amount of sensitive data available) and performance, proposing a novel\npatch-wise approach for privacy-preserving fake ID detection. Our proposed\napproach explores how privacy can be enhanced through: i) two levels of\nanonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii)\ndifferent patch size configurations, varying the amount of sensitive data\nvisible in the patch image. Also, state-of-the-art methods such as Vision\nTransformers and Foundation Models are considered in the analysis. The\nexperimental framework shows that, on an unseen database (DLC-2021), our\nproposal achieves 13.91% and 0% EERs at patch and ID document level, showing a\ngood generalization to other databases. In addition to this exploration,\nanother key contribution of our study is the release of the first publicly\navailable database that contains 48,400 patches from both real and fake ID\ndocuments, along with the experimental framework and models, which will be\navailable in our GitHub.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-10T14:01:22Z"}
{"aid":"http://arxiv.org/abs/2504.07783v1","title":"On approximation of convex functionals with a convexity constraint and\n  general Lagrangians","summary":"In this note, we prove that minimizers of convex functionals with a convexity\nconstraint and a general class of Lagrangians can be approximated by solutions\nto fourth-order equations of Abreu type. Our result generalizes that of Le\n(Twisted Harnack inequality and approximation of variational problems with a\nconvexity constraint by singular Abreu equations. Adv. Math. 434 (2023)) where\nthe case of quadratically growing Lagrangians was treated.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T14:22:04Z"}
{"aid":"http://arxiv.org/abs/2504.07788v1","title":"Generalized Passivity Sensitivity Methodology for Small-Signal Stability\n  Analysis","summary":"This paper proposes a generalized passivity sensitivity analysis for power\nsystem stability studies. The method uncovers the most effective instability\nmitigation actions for both device-level and system-level investigations. The\nparticular structure of the admittance and nodal models is exploited in the\ndetailed derivation of the passivity sensitivity expressions. These proposed\nsensitivities are validated for different parameters at device-level and at\nsystem-level. Compared to previous stability and sensitivity methods, it does\nnot require detailed system information, such as exact system eigenvalues,\nwhile it provides valuable information for a less conservative stable system\ndesign. In addition, we demonstrate how to utilize the proposed method through\ncase studies with different converter controls and system-wide insights showing\nits general applicability.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T14:23:23Z"}
{"aid":"http://arxiv.org/abs/2504.07796v1","title":"Numerical solution by shape optimization method to an inverse shape\n  problem in multi-dimensional advection-diffusion problem with space dependent\n  coefficients","summary":"This work focuses on numerically solving a shape identification problem\nrelated to advection-diffusion processes with space-dependent coefficients\nusing shape optimization techniques. Two boundary-type cost functionals are\nconsidered, and their corresponding variations with respect to shapes are\nderived using the adjoint method, employing the chain rule approach. This\ninvolves firstly utilizing the material derivative of the state system and\nsecondly using its shape derivative. Subsequently, an alternating direction\nmethod of multipliers (ADMM) combined with the Sobolev-gradient-descent\nalgorithm is applied to stably solve the shape reconstruction problem.\nNumerical experiments in two and three dimensions are conducted to demonstrate\nthe feasibility of the methods.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-10T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.07814v1","title":"Estimating entanglement monotones of non-pure spin-squeezed states","summary":"We investigate how to estimate entanglement monotones of general mixed\nmany-body quantum states via lower and upper bounds from entanglement witnesses\nand separable ansatz states respectively. This allows us to study spin systems\non fully-connected graphs at nonzero temperature. We derive lower bounds to\ndistance-like measure from the set of fully separable states based on\nspin-squeezing inequalities. These are nonlinear expressions based on variances\nof collective spin operators and are potentially close to optimal in the large\nparticle-number limit, at least for models with two-particle interactions.\nConcretely, we apply our methods to equilibrium states of the\npermutation-invariant XXZ model with an external field and investigate\nentanglement at nonzero temperature close to quantum phase transition (QPT)\npoints in both the ferromagnetic and anti-ferromagnetic cases. We observe that\nthe lower bound becomes tight for zero temperature as well as for the\ntemperature at which entanglement disappears, both of which are thus precisely\ncaptured by the spin-squeezing inequalities. We further observe, among other\nthings, that entanglement arises at nonzero temperature close to a QPT even in\nthe ordered phase, where the ground state is separable. This can be considered\nan entanglement signature of a QPT that may also be visible in experiments.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T14:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.07822v1","title":"DG-STMTL: A Novel Graph Convolutional Network for Multi-Task\n  Spatio-Temporal Traffic Forecasting","summary":"Spatio-temporal traffic prediction is crucial in intelligent transportation\nsystems. The key challenge of accurate prediction is how to model the complex\nspatio-temporal dependencies and adapt to the inherent dynamics in data.\nTraditional Graph Convolutional Networks (GCNs) often struggle with static\nadjacency matrices that introduce domain bias or learnable matrices that may be\noverfitting to specific patterns. This challenge becomes more complex when\nconsidering Multi-Task Learning (MTL). While MTL has the potential to enhance\nprediction accuracy through task synergies, it can also face significant\nhurdles due to task interference. To overcome these challenges, this study\nintroduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task\nLearning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation\nmodule that combines static matrices with dynamic ones through a task-specific\ngating mechanism. We also introduce a group-wise GCN module to enhance the\nmodelling capability of spatio-temporal dependencies. We conduct extensive\nexperiments on two real-world datasets to evaluate our method. Results show\nthat our method outperforms other state-of-the-arts, indicating its\neffectiveness and robustness.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T15:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.07861v1","title":"Horizons, throats and bounces in hybrid metric-Palatini gravity with a\n  non-zero potential","summary":"This work conducts an in-depth exploration of exact electrically charged\nsolutions, including traversable wormholes, black holes, and black bounces,\nwithin the framework of the scalar-tensor representation of hybrid\nmetric-Palatini gravity (HMPG) with a non-zero scalar potential. By integrating\nprinciples from both the metric and Palatini formulations, HMPG provides a\nflexible approach to addressing persistent challenges in General Relativity\n(GR), such as the late-time cosmic acceleration and the nature of dark matter.\nUnder the assumption of spherical symmetry, we employ an inverse problem\ntechnique to derive exact solutions in both the Jordan and Einstein conformal\nframes. This method naturally leads to configurations involving either\ncanonical or phantom scalar fields. A thorough examination of horizon\nstructures, throat conditions, asymptotic behaviour, and curvature regularity\n(via the Kretschmann scalar) reveals the intricate causal structures permitted\nby this theoretical model. The analysis uncovers a diverse range of geometric\nconfigurations, with the phantom sector exhibiting a notably richer spectrum of\nsolutions than the canonical case. These solutions encompass traversable\nwormholes, black universe models, where the interior of a black hole evolves\ninto an expanding cosmological phase rather than a singularity, as well as\nblack bounce structures and multi-horizon black holes. The results demonstrate\nthat introducing a non-zero scalar potential within HMPG significantly expands\nthe array of possible gravitational solutions, yielding complex causal and\ncurvature properties that go beyond standard GR. Consequently, HMPG stands out\nas a powerful theoretical framework for modelling extreme astrophysical\nenvironments, where deviations from classical gravity are expected to play a\ncrucial role.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th","published":"2025-04-10T15:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.07882v1","title":"Large black-hole scalar charges induced by cosmology in Horndeski\n  theories","summary":"The regularity of black hole solutions, embedded in an expanding Universe, is\nstudied in a subclass of Horndeski theories, namely the sum of the simplest\nquadratic, cubic and quintic actions. We find that in presence of a time\nderivative of the scalar field, driven by the cosmological expansion, this\nregularity generically imposes large scalar charges for black holes, even when\nassuming strictly no direct coupling of matter to the scalar field. Such\ncharges cause a significant accretion of the scalar field by the black holes,\ndriving its local time derivative to a small value. This phenomenon, together\nwith the Vainshtein screening typical of these theories, strongly suppresses\nobservable scalar effects. We show that this full class of models is consistent\nwith LIGO/Virgo detections of gravitational waves, but that the LISA mission\nshould be able to constrain the coefficient of the quintic term at the\n$10^{-30}$ level in a self-acceleration scenario, an improvement by 16 orders\nof magnitude with respect to what is imposed by the speed of gravitational\nwaves.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T15:55:38Z"}
{"aid":"http://arxiv.org/abs/2504.07889v1","title":"A Steklov eigenvalue estimate for affine connections and its application\n  to substatic triples","summary":"Choi-Wang obtained a lower bound of the first eigenvalue of the Laplacian on\nclosed minimal hypersurfaces. On minimal hypersurfaces with boundary, Fraser-Li\nestablished an inequality giving a lower bound of the first Steklov eigenvalue\nas a counterpart of the Choi-Wang type inequality. These inequalities were\nshown under lower bounds of the Ricci curvature. In this paper, under\nnon-negative Ricci curvature associated with an affine connection introduced by\nWylie-Yeroshkin, we give a generalization of Fraser-Li type inequality. Our\nresults hold not only for weighted manifolds under non-negative $1$-weighted\nRicci curvature but also for substatic triples.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T16:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.07893v1","title":"Molecular excited state in the interaction quench dynamics of two\n  different atoms in a two-dimensional anisotropic trap","summary":"We explore the interaction quench dynamics of two atoms with different masses\nand subject to different trapping potentials. Notably, under such anisotropic\nconditions, the nonequilibrium dynamics can lead to the occupation of molecular\nexcited states. We consider cases of quenching from attractive to repulsive\ninteraction and vice versa, analyzing the impact of the pre- and postquench\nstates. The analysis of overlap integrals for the both states reveals a\nsignificant contribution from the molecular excited state. Moreover, the\noverlap with the prequench states might serve as an indicator of when this\nexcited state may emerge. Additionally, we calculate the energy spectrum for\nthe lowest levels in the both isotropic and anisotropic harmonic traps.\nThroughout our study, we use a Gaussian-shaped finite-range interaction\npotential.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.atm-clus,physics.comp-ph,quant-ph","published":"2025-04-10T16:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.07894v1","title":"DiverseFlow: Sample-Efficient Diverse Mode Coverage in Flows","summary":"Many real-world applications of flow-based generative models desire a diverse\nset of samples that cover multiple modes of the target distribution. However,\nthe predominant approach for obtaining diverse sets is not sample-efficient, as\nit involves independently obtaining many samples from the source distribution\nand mapping them through the flow until the desired mode coverage is achieved.\nAs an alternative to repeated sampling, we introduce DiverseFlow: a\ntraining-free approach to improve the diversity of flow models. Our key idea is\nto employ a determinantal point process to induce a coupling between the\nsamples that drives diversity under a fixed sampling budget. In essence,\nDiverseFlow allows exploration of more variations in a learned flow model with\nfewer samples. We demonstrate the efficacy of our method for tasks where\nsample-efficient diversity is desirable, such as text-guided image generation\nwith polysemous words, inverse problems like large-hole inpainting, and\nclass-conditional image synthesis.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T16:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.07900v1","title":"Temporal Tensors and Quantum Shortcut Dynamics in a Supermaze of\n  Multidimensional Time","summary":"We develop a theoretical framework that unifies concepts of multiple time\ndimensions, quantum shortcut dynamics, and complex topological structures\n('supermazes') to explore novel phenomena in quantum and classical systems. In\nparticular, we introduce a Temporal Tensor Formalism to describe\nmultidimensional time, define Quantum Shortcut Operators that enact\nnear-instantaneous state transitions, and incorporate these into a supermaze\ntopological model inspired by labyrinthine geometry and network complexity. We\nshow how this framework can give rise to surprising effects such as anomalous\nthermodynamic relaxation (analogous to the Mpemba effect) in quantum systems.\nTheoretical implications for quantum computing (including quantum cloud\nnetworks) are discussed, and connections are drawn to established mathematical\nparadoxes and physical principles.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-10T16:19:56Z"}
{"aid":"http://arxiv.org/abs/2504.07947v1","title":"Activating high-power parametric oscillation in photonic-crystal\n  resonators","summary":"By engineering the mode spectrum of a Kerr microresonator, we selectively\nactivate nonlinear phase matching amongst broadband parametric gain. At\nthreshold, optical parametric oscillators (OPOs) emerge from vacuum\nfluctuations in the presence of a pump laser, and above threshold, OPOs seed\nthe formation of intraresonator patterns and states, such as chaos and\nsolitons. These competing nonlinear processes hinder an important application\nof OPOs as wavelength-variable, low-noise sources. Recently, nanopatterned\nmicroresonator OPOs have leveraged photonic crystal bandgaps to enable\nuniversal phase matching and control of nonlinear interactions. Here, we\nexplore a design paradigm optimized for high-output power that uses geometric\ndispersion to suppress nonlinear interactions and a photonic crystal bandgap to\nactivate only a single OPO interaction. Our devices convert an input pump laser\nto output signal and idler waves with powers exceeding 40 mW while maintaining\nspectral purity and side-mode suppression ratios greater than 40 dB. We show\nthat this approach suits custom wavelengths by measuring four independent\noscillators that vary only photonic crystal parameters to select output waves.\nOur experiments demonstrate that microresonators functionalized by photonic\ncrystals offer a versatile and lossless palette of controls for nonlinear laser\nconversion.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T17:54:33Z"}
{"aid":"http://arxiv.org/abs/2504.07954v1","title":"Perception-R1: Pioneering Perception Policy with Reinforcement Learning","summary":"Inspired by the success of DeepSeek-R1, we explore the potential of\nrule-based reinforcement learning (RL) in MLLM post-training for perception\npolicy learning. While promising, our initial experiments reveal that\nincorporating a thinking process through RL does not consistently lead to\nperformance gains across all visual perception tasks. This leads us to delve\ninto the essential role of RL in the context of visual perception. In this\nwork, we return to the fundamentals and explore the effects of RL on different\nperception tasks. We observe that the perceptual complexity is a major factor\nin determining the effectiveness of RL. We also observe that reward design\nplays a crucial role in further approching the upper limit of model perception.\nTo leverage these findings, we propose Perception-R1, a scalable RL framework\nusing GRPO during MLLM post-training. With a standard Qwen2.5-VL-3B-Instruct,\nPerception-R1 achieves +4.2% on RefCOCO+, +17.9% on PixMo-Count, +4.2% on\nPageOCR, and notably, 31.9% AP on COCO2017 val for the first time, establishing\na strong baseline for perception policy learning.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-10T17:58:27Z"}
{"aid":"http://arxiv.org/abs/2504.09918v1","title":"Berry curvature-induced intrinsic spin Hall effect in\n  light-element-based CrN system for magnetization switching","summary":"The current-induced spin-orbit torque-based devices for magnetization\nswitching are commonly relied on the 4d and 5d heavy metals owing to their\nstrong spin-orbit coupling (SOC) to produce large spin current via spin Hall\neffect (SHE). Here we present the sizable SHE in CrN, a light element-based\nsystem and demonstrate the current-induced magnetization switching in the\nadjacent ferromagnetic layer [Co(0.35nm)/Pt(0.3nm)]3, which exhibits\nperpendicular magnetic anisotropy. We found the switching current density of\n2.6 MA/cm2. The first principles calculation gives the spin Hall conductivity\n(SHC) to be 120 (hcross/e) S/cm due to intrinsic Berry curvature arising from\nSOC induced band splitting near Fermi-energy. The theoretically calculated\nintrinsic SHC is close to the experimental SHC extracted from second harmonic\nHall measurement. We estimated spin Hall angle to be 0.09, demonstrating\nefficient charge-to-spin conversion in CrN system.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T06:26:39Z"}
{"aid":"http://arxiv.org/abs/2504.09953v1","title":"Efficient 2D to Full 3D Human Pose Uplifting including Joint Rotations","summary":"In sports analytics, accurately capturing both the 3D locations and rotations\nof body joints is essential for understanding an athlete's biomechanics. While\nHuman Mesh Recovery (HMR) models can estimate joint rotations, they often\nexhibit lower accuracy in joint localization compared to 3D Human Pose\nEstimation (HPE) models. Recent work addressed this limitation by combining a\n3D HPE model with inverse kinematics (IK) to estimate both joint locations and\nrotations. However, IK is computationally expensive. To overcome this, we\npropose a novel 2D-to-3D uplifting model that directly estimates 3D human\nposes, including joint rotations, in a single forward pass. We investigate\nmultiple rotation representations, loss functions, and training strategies -\nboth with and without access to ground truth rotations. Our models achieve\nstate-of-the-art accuracy in rotation estimation, are 150 times faster than the\nIK-based approach, and surpass HMR models in joint localization precision.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T07:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.09958v1","title":"C-MTCSD: A Chinese Multi-Turn Conversational Stance Detection Dataset","summary":"Stance detection has become an essential tool for analyzing public\ndiscussions on social media. Current methods face significant challenges,\nparticularly in Chinese language processing and multi-turn conversational\nanalysis. To address these limitations, we introduce C-MTCSD, the largest\nChinese multi-turn conversational stance detection dataset, comprising 24,264\ncarefully annotated instances from Sina Weibo, which is 4.2 times larger than\nthe only prior Chinese conversational stance detection dataset. Our\ncomprehensive evaluation using both traditional approaches and large language\nmodels reveals the complexity of C-MTCSD: even state-of-the-art models achieve\nonly 64.07% F1 score in the challenging zero-shot setting, while performance\nconsistently degrades with increasing conversation depth. Traditional models\nparticularly struggle with implicit stance detection, achieving below 50% F1\nscore. This work establishes a challenging new benchmark for Chinese stance\ndetection research, highlighting significant opportunities for future\nimprovements.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T07:55:47Z"}
{"aid":"http://arxiv.org/abs/2504.09973v1","title":"Beyond Degradation Redundancy: Contrastive Prompt Learning for\n  All-in-One Image Restoration","summary":"All-in-one image restoration, addressing diverse degradation types with a\nunified model, presents significant challenges in designing task-specific\nprompts that effectively guide restoration across multiple degradation\nscenarios. While adaptive prompt learning enables end-to-end optimization, it\noften yields overlapping or redundant task representations. Conversely,\nexplicit prompts derived from pretrained classifiers enhance discriminability\nbut may discard critical visual information for reconstruction. To address\nthese limitations, we introduce Contrastive Prompt Learning (CPL), a novel\nframework that fundamentally enhances prompt-task alignment through two\ncomplementary innovations: a \\emph{Sparse Prompt Module (SPM)} that efficiently\ncaptures degradation-specific features while minimizing redundancy, and a\n\\emph{Contrastive Prompt Regularization (CPR)} that explicitly strengthens task\nboundaries by incorporating negative prompt samples across different\ndegradation types. Unlike previous approaches that focus primarily on\ndegradation classification, CPL optimizes the critical interaction between\nprompts and the restoration model itself. Extensive experiments across five\ncomprehensive benchmarks demonstrate that CPL consistently enhances\nstate-of-the-art all-in-one restoration models, achieving significant\nimprovements in both standard multi-task scenarios and challenging composite\ndegradation settings. Our framework establishes new state-of-the-art\nperformance while maintaining parameter efficiency, offering a principled\nsolution for unified image restoration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.09974v1","title":"Towards Resilient Tracking in Autonomous Vehicles: A Distributionally\n  Robust Input and State Estimation Approach","summary":"This paper proposes a novel framework for the distributionally robust input\nand state estimation (DRISE) for autonomous vehicles operating under model\nuncertainties and measurement outliers. The proposed framework improves the\ninput and state estimation (ISE) approach by integrating distributional\nrobustness, enhancing the estimator's resilience and robustness to adversarial\ninputs and unmodeled dynamics. Moment-based ambiguity sets capture\nprobabilistic uncertainties in both system dynamics and measurement noise,\noffering analytical tractability and efficiently handling uncertainties in mean\nand covariance. In particular, the proposed framework minimizes the worst-case\nestimation error, ensuring robustness against deviations from nominal\ndistributions. The effectiveness of the proposed approach is validated through\nsimulations conducted in the CARLA autonomous driving simulator, demonstrating\nimproved performance in state estimation accuracy and robustness in dynamic and\nuncertain environments.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-14T08:26:06Z"}
{"aid":"http://arxiv.org/abs/2504.09978v1","title":"New exponential law for real networks","summary":"In this article we have shown that the distributions of ksi satisfy an\nexponential law for real networks while the distributions of ksi for random\nnetworks are bell-shaped and closer to the normal distribution. The ksi\ndistributions for Barabasi-Albert and Watts-Strogatz networks are similar to\nthe ksi distributions for random networks (bell-shaped) for most parameters,\nbut when these parameters become small enough, the Barabasi-Albert and\nWatts-Strogatz networks become more realistic with respect to the ksi\ndistributions.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-14T08:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.09990v1","title":"Correlative and Discriminative Label Grouping for Multi-Label Visual\n  Prompt Tuning","summary":"Modeling label correlations has always played a pivotal role in multi-label\nimage classification (MLC), attracting significant attention from researchers.\nHowever, recent studies have overemphasized co-occurrence relationships among\nlabels, which can lead to overfitting risk on this overemphasis, resulting in\nsuboptimal models. To tackle this problem, we advocate for balancing\ncorrelative and discriminative relationships among labels to mitigate the risk\nof overfitting and enhance model performance. To this end, we propose the\nMulti-Label Visual Prompt Tuning framework, a novel and parameter-efficient\nmethod that groups classes into multiple class subsets according to label\nco-occurrence and mutual exclusivity relationships, and then models them\nrespectively to balance the two relationships. In this work, since each group\ncontains multiple classes, multiple prompt tokens are adopted within Vision\nTransformer (ViT) to capture the correlation or discriminative label\nrelationship within each group, and effectively learn correlation or\ndiscriminative representations for class subsets. On the other hand, each group\ncontains multiple group-aware visual representations that may correspond to\nmultiple classes, and the mixture of experts (MoE) model can cleverly assign\nthem from the group-aware to the label-aware, adaptively obtaining label-aware\nrepresentation, which is more conducive to classification. Experiments on\nmultiple benchmark datasets show that our proposed approach achieves\ncompetitive results and outperforms SOTA methods on multiple pre-trained\nmodels.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.10019v1","title":"Sagbi bases, defining ideals and algebra of minors","summary":"This paper extends the article of the Bruns and Conca on SAGBI bases and\ntheir computation (J. Symb. Comput. 120 (2024)) in two directions. (i) We\ndescribe the extension of the Singular library sagbiNormaliz.sing to the\ncomputation of defining ideals of subalgebras of polynomial rings. (ii) We give\na complete classification of the algebras of minors for which the generating\nset is a SAGBI basis with respect to a suitable monomial order and we identify\nuniversal SAGBI basis in three cases. The investigation is illustrated by\nseveral examples.","main_category":"math.AC","categories":"math.AC","published":"2025-04-14T09:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.10021v1","title":"Masked Autoencoder Self Pre-Training for Defect Detection in\n  Microelectronics","summary":"Whereas in general computer vision, transformer-based architectures have\nquickly become the gold standard, microelectronics defect detection still\nheavily relies on convolutional neural networks (CNNs). We hypothesize that\nthis is due to the fact that a) transformers have an increased need for data\nand b) labelled image generation procedures for microelectronics are costly,\nand labelled data is therefore sparse. Whereas in other domains, pre-training\non large natural image datasets can mitigate this problem, in microelectronics\ntransfer learning is hindered due to the dissimilarity of domain data and\nnatural images. Therefore, we evaluate self pre-training, where models are\npre-trained on the target dataset, rather than another dataset. We propose a\nvision transformer (ViT) pre-training framework for defect detection in\nmicroelectronics based on masked autoencoders (MAE). In MAE, a large share of\nimage patches is masked and reconstructed by the model during pre-training. We\nperform pre-training and defect detection using a dataset of less than 10.000\nscanning acoustic microscopy (SAM) images labelled using transient thermal\nanalysis (TTA). Our experimental results show that our approach leads to\nsubstantial performance gains compared to a) supervised ViT, b) ViT pre-trained\non natural image datasets, and c) state-of-the-art CNN-based defect detection\nmodels used in the literature. Additionally, interpretability analysis reveals\nthat our self pre-trained models, in comparison to ViT baselines, correctly\nfocus on defect-relevant features such as cracks in the solder material. This\ndemonstrates that our approach yields fault-specific feature representations,\nmaking our self pre-trained models viable for real-world defect detection in\nmicroelectronics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10030v1","title":"EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical\n  Challenge in Multi-Robot Control","summary":"This paper introduces EmbodiedAgent, a hierarchical framework for\nheterogeneous multi-robot control. EmbodiedAgent addresses critical limitations\nof hallucination in impractical tasks. Our approach integrates a next-action\nprediction paradigm with a structured memory system to decompose tasks into\nexecutable robot skills while dynamically validating actions against\nenvironmental constraints. We present MultiPlan+, a dataset of more than 18,000\nannotated planning instances spanning 100 scenarios, including a subset of\nimpractical cases to mitigate hallucination. To evaluate performance, we\npropose the Robot Planning Assessment Schema (RPAS), combining automated\nmetrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's\nsuperiority over state-of-the-art models, achieving 71.85% RPAS score.\nReal-world validation in an office service task highlights its ability to\ncoordinate heterogeneous robots for long-horizon objectives.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T09:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.10074v1","title":"MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation\n  Framework","summary":"Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2\\% on the Single-Hop subset and\n+0.4\\% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8\\% on the Unseen-Q subset, +8.2\\% on the Unseen-E subset, and +8.1\\% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-14T10:19:47Z"}
{"aid":"http://arxiv.org/abs/2504.10090v1","title":"CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography","summary":"Large language models (LLMs) and multimodal large language models (MLLMs)\nhave significantly advanced artificial intelligence. However, visual reasoning,\nreasoning involving both visual and textual inputs, remains underexplored.\nRecent advancements, including the reasoning models like OpenAI o1 and Gemini\n2.0 Flash Thinking, which incorporate image inputs, have opened this\ncapability. In this ongoing work, we focus specifically on photography-related\ntasks because a photo is a visual snapshot of the physical world where the\nunderlying physics (i.e., illumination, blur extent, etc.) interplay with the\ncamera parameters. Successfully reasoning from the visual information of a\nphoto to identify these numerical camera settings requires the MLLMs to have a\ndeeper understanding of the underlying physics for precise visual\ncomprehension, representing a challenging and intelligent capability essential\nfor practical applications like photography assistant agents. We aim to\nevaluate MLLMs on their ability to distinguish visual differences related to\nnumerical camera settings, extending a methodology previously proposed for\nvision-language models (VLMs). Our preliminary results demonstrate the\nimportance of visual reasoning in photography-related tasks. Moreover, these\nresults show that no single MLLM consistently dominates across all evaluation\ntasks, demonstrating ongoing challenges and opportunities in developing MLLMs\nwith better visual reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-14T10:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.10092v1","title":"Bayesian optimal experimental design with Wasserstein information\n  criteria","summary":"Bayesian optimal experimental design (OED) provides a principled framework\nfor selecting the most informative observational settings in experiments. With\nrapid advances in computational power, Bayesian OED has become increasingly\nfeasible for inference problems involving large-scale simulations, attracting\ngrowing interest in fields such as inverse problems. In this paper, we\nintroduce a novel design criterion based on the expected Wasserstein-$p$\ndistance between the prior and posterior distributions. Especially, for $p=2$,\nthis criterion shares key parallels with the widely used expected information\ngain (EIG), which relies on the Kullback--Leibler divergence instead. First,\nthe Wasserstein-2 criterion admits a closed-form solution for Gaussian\nregression, a property which can be also leveraged for approximative schemes.\nSecond, it can be interpreted as maximizing the information gain measured by\nthe transport cost incurred when updating the prior to the posterior. Our main\ncontribution is a stability analysis of the Wasserstein-1 criterion, where we\nprovide a rigorous error analysis under perturbations of the prior or\nlikelihood. We partially extend this study also to the Wasserstein-2 criterion.\nIn particular, these results yield error rates when empirical approximations of\npriors are used. Finally, we demonstrate the computability of the Wasserstein-2\ncriterion and demonstrate our approximation rates through simulations.","main_category":"stat.ME","categories":"stat.ME,cs.NA,math.NA,stat.CO","published":"2025-04-14T10:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.10122v1","title":"Design Optimization of Flip FET Standard Cells with Dual-sided Pins for\n  Ultimate Scaling","summary":"Recently, we proposed a novel transistor architecture for 3D stacked FETs\ncalled Flip FET (FFET), featuring N/P transistors back-to-back stacked and\ndual-sided interconnects. With dual-sided power rails and signal tracks, FFET\ncan achieve an aggressive 2.5T cell height. As a tradeoff, the complex\nstructure and limited numbers of M0 tracks could limit the standard cell\ndesign. As a solution, multiple innovations were introduced and examined in\nthis work. Based on an advanced node design rule, several unique building\nblocks in FFET such as drain merge (DM), gate merge (GM), field drain merge\n(FDM) and buried signal track (BST) were investigated. Other key design\nconcepts of multi-row, split gate and dummy gate insertion (DG) were also\ncarefully studied, delivering around 35.6% area reduction compared with 3T\nCFET. Furthermore, the symmetric design of FFET has unique superiority over\nCFET thanks to the separate N/P logic on two sides of the wafer and their\nconnections using DM and GM. New routing scheme with dual-sided output pins on\nboth wafer frontside (FS) and backside (BS) was proposed for the first time.\nFinally, we conducted a comprehensive evaluation on complex cell design, taking\nAOI22 as an example. New strategies were proposed and examined. The FDM design\nis identified as the best, outperforming the BST and dummy gate design by 1.93%\nand 5.13% for the transition delay.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T11:31:44Z"}
{"aid":"http://arxiv.org/abs/2504.10131v1","title":"A three-functor formalism for commutative von Neumann algebras","summary":"A three-functor formalism is the half of a six-functor formalism that\nsupports the projection and base change formulas. In this paper, we provide a\nthree-functor formalism for commutative von Neumann algebras and their modules.\nUsing the Gelfand-Naimark theorem, this gives rise to a three-functor formalism\nfor measure spaces and measurable bundles of Hilbert spaces. We use this to\nprove Fell absorption for unitary representations of measure groupoids.\n  The three-functor formalism for commutative von Neumann algebras takes values\nin W*-categories, and we discuss in what sense it is a unitary three-functor\nformalism.","main_category":"math.OA","categories":"math.OA,math.CT,math.QA","published":"2025-04-14T11:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.10139v1","title":"Conditional Distribution Compression via the Kernel Conditional Mean\n  Embedding","summary":"Existing distribution compression methods, like Kernel Herding (KH), were\noriginally developed for unlabelled data. However, no existing approach\ndirectly compresses the conditional distribution of labelled data. To address\nthis gap, we first introduce the Average Maximum Conditional Mean Discrepancy\n(AMCMD), a natural metric for comparing conditional distributions. We then\nderive a consistent estimator for the AMCMD and establish its rate of\nconvergence. Next, we make a key observation: in the context of distribution\ncompression, the cost of constructing a compressed set targeting the AMCMD can\nbe reduced from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(n)$. Building on this, we\nextend the idea of KH to develop Average Conditional Kernel Herding (ACKH), a\nlinear-time greedy algorithm that constructs a compressed set targeting the\nAMCMD. To better understand the advantages of directly compressing the\nconditional distribution rather than doing so via the joint distribution, we\nintroduce Joint Kernel Herding (JKH), a straightforward adaptation of KH\ndesigned to compress the joint distribution of labelled data. While herding\nmethods provide a simple and interpretable selection process, they rely on a\ngreedy heuristic. To explore alternative optimisation strategies, we propose\nJoint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing\nPoints (ACKIP), which jointly optimise the compressed set while maintaining\nlinear complexity. Experiments show that directly preserving conditional\ndistributions with ACKIP outperforms both joint distribution compression (via\nJKH and JKIP) and the greedy selection used in ACKH. Moreover, we see that JKIP\nconsistently outperforms JKH.","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.CO,stat.ME","published":"2025-04-14T11:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.10168v1","title":"HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for\n  Hallucination Detection","summary":"In this paper, we present HalluSearch, a multilingual pipeline designed to\ndetect fabricated text spans in Large Language Model (LLM) outputs. Developed\nas part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and\nRelated Observable Overgeneration Mistakes, HalluSearch couples\nretrieval-augmented verification with fine-grained factual splitting to\nidentify and localize hallucinations in fourteen different languages. Empirical\nevaluations show that HalluSearch performs competitively, placing fourth in\nboth English (within the top ten percent) and Czech. While the system's\nretrieval-based strategy generally proves robust, it faces challenges in\nlanguages with limited online coverage, underscoring the need for further\nresearch to ensure consistent hallucination detection across diverse linguistic\ncontexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.10179v1","title":"The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental\n  Evaluation of Prompt Engineering Methods for Robust Multimodal Performance","summary":"Multimodal Large Language Models (MLLMs) are set to transform how machines\nprocess and generate human-like responses by integrating diverse modalities\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\nhinges on optimal prompt engineering. We present a comprehensive experimental\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\nand Integration. Our approach stratifies models by parameter count into Small\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\nin structured tasks such as code generation, achieving accuracies up to 96.88%\nunder Few-Shot prompting, all models struggle with complex reasoning and\nabstract understanding, often yielding accuracies below 60% and high\nhallucination rates. Structured reasoning prompts frequently increased\nhallucination up to 75% in small models and led to longer response times (over\n20 seconds in Large MLLMs), while simpler prompting methods provided more\nconcise and efficient outputs. No single prompting method uniformly optimises\nall task types. Instead, adaptive strategies combining example-based guidance\nwith selective structured reasoning are essential to enhance robustness,\nefficiency, and factual accuracy. Our findings offer practical recommendations\nfor prompt engineering and support more reliable deployment of MLLMs across\napplications including AI-assisted coding, knowledge retrieval, and multimodal\ncontent understanding.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.ET","published":"2025-04-14T12:31:39Z"}
{"aid":"http://arxiv.org/abs/2504.10191v1","title":"Localized Cultural Knowledge is Conserved and Controllable in Large\n  Language Models","summary":"Just as humans display language patterns influenced by their native tongue\nwhen speaking new languages, LLMs often default to English-centric responses\neven when generating in other languages. Nevertheless, we observe that local\ncultural information persists within the models and can be readily activated\nfor cultural customization. We first demonstrate that explicitly providing\ncultural context in prompts significantly improves the models' ability to\ngenerate culturally localized responses. We term the disparity in model\nperformance with versus without explicit cultural context the explicit-implicit\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\nit may not naturally surface in multilingual interactions if cultural context\nis not explicitly provided. Despite the explicit prompting benefit, however,\nthe answers reduce in diversity and tend toward stereotypes. Second, we\nidentify an explicit cultural customization vector, conserved across all\nnon-English languages we explore, which enables LLMs to be steered from the\nsynthetic English cultural world-model toward each non-English cultural world.\nSteered responses retain the diversity of implicit prompting and reduce\nstereotypes to dramatically improve the potential for customization. We discuss\nthe implications of explicit cultural customization for understanding the\nconservation of alternative cultural world models within LLMs, and their\ncontrollable utility for translation, cultural customization, and the\npossibility of making the explicit implicit through soft control for expanded\nLLM function and appeal.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.10206v1","title":"Approximation by Neural Network Sampling Operators in Mixed Lebesgue\n  Spaces","summary":"In this paper, we prove the rate of approximation for the Neural Network\nSampling Operators activated by sigmoidal functions with mixed Lebesgue norm in\nterms of averaged modulus of smoothness for a bounded measurable functions on\nbounded domain. In order to achieve the above result, we first establish that\nthe averaged modulus of smoothness is finite for certain suitable subspaces of\n$L^{p,q}(\\mathbb{R}\\times\\mathbb{R}).$ Using the properties of averaged modulus\nof smoothness, we estimate the rate of approximation of certain linear\noperators in mixed Lebesgue norm. Then, as an application of these linear\noperators, we obtain the Jackson type approximation theorem, in order to give a\ncharacterization for the rate of approximation of neural network operators\nin-terms of averaged modulus of smoothness in mixed norm. Lastly, we discuss\nsome examples of sigmoidal functions and using these sigmoidal functions, we\nshow the implementation of continuous and discontinuous functions by neural\nnetwork operators.","main_category":"math.FA","categories":"math.FA","published":"2025-04-14T13:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.10220v1","title":"Modeling the Thermal Structure of a Protoplanetary Disk Using Multiband\n  Flux-Limited Diffusion Approximation","summary":"This work continues the analysis of the model for calculating the thermal\nstructure of an axisymmetric protoplanetary disk, initiated in the paper by\nPavlyuchenkov (2024). The model is based on the well-known Flux-Limited\nDiffusion (FLD) approximation with separate calculation of heating by direct\nstellar radiation (hereinafter referred to as the FLD$^{\\rm s}$ method). In\naddition to the previously described FLD$^{\\rm s}$ model with\nwavelength-averaged opacities, we present a multiband model mFLD$^{\\rm s}$,\nwhere the spectrum of thermal radiation is divided into several frequency\nbands. The model is based on an implicit finite-difference scheme for the\nequations of thermal radiation diffusion, which reduces to a system of linear\nalgebraic equations written in hypermatrix form. A modified Gauss method for\ninverting the sparse hypermatrix of the original system of linear equations is\nproposed. The simulation results described in the article show that the\nmidplane radial temperature profile obtained with the mFLD$^{\\rm s}$ method has\na variable slope in accordance with the reference Monte Carlo radiative\ntransfer simulations. The mFLD$^{\\rm s}$ model also qualitatively reproduces\nthe non-isothermality of the temperature distribution along the angular\ncoordinate near the midplane, which is not provided by the FLD$^{\\rm s}$\nmethod. However, quantitative differences remain between the reference\ntemperature values and the results of mFLD$^{\\rm s}$. These differences are\nlikely due to the diffusive nature of the FLD approximation. It is also shown\nthat the characteristic times for the disk to reach thermal equilibrium within\nthe mFLD$^{\\rm s}$ model can be significantly shorter than in FLD$^{\\rm s}$.\nThis property should be taken into account when modeling non-stationary\nprocesses in protoplanetary disks within FLD-based models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-14T13:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.10223v1","title":"A proof of the Krzyz conjecture","summary":"A proof of the Krzyz conjecture is presented, based on the application of the\nvariational method, as well as on the use of two classical results and some of\ntheir consequences. The mentioned results are the Caratheodory-Toeplitz\ncriterion of continuing a polynomial to a Caratheodory class function, and the\nRiesz-Fejer theorem about trigonometric polynomials. This is an English\ntranslation of a preprint originally published in Russian:\nhttps://preprints.ru/article/1799","main_category":"math.CV","categories":"math.CV","published":"2025-04-14T13:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.10228v1","title":"Magneto-Hydrodynamic Simulations of Eccentric Binary Neutron Star\n  Mergers","summary":"Highly eccentric binary neutron star mergers exhibit unique dynamical and\nobservational signatures compared to quasi-circular ones in terms of their\ngravitational wave signal and the ejection of matter, leading to different\nelectromagnetic counterparts. In this article, we present general relativistic\nmagneto-hydrodynamic simulations of binary neutron star systems on highly\neccentric orbits. While in quasi-circular binaries, the influence of the\nmagnetic field is too weak to affect the general pre-merger dynamics, the close\nencounters in eccentric systems could potentially trigger magneto-hydrodynamic\ninstabilities. Therefore, we investigate possible effects before, during, and\nafter the merger for a total of three different systems with varying initial\neccentricity.\n  We study the f-mode oscillations excited by tidal interaction in close\nencounters and find good agreement with predicted f-mode frequency estimates.\nHowever, our simulations reveal no significant differences compared to results\nneglecting the magnetic field. Although we observe a rearrangement of the\npoloidal structure of the magnetic field inside the stars, there is no relevant\nincrease in the magnetic energy during the encounters. Also, during the merger,\nthe amplification of the magnetic field seems to be largely independent of the\neccentricity in our systems. Consistent with studies of merging non-magnetized\nbinary neutron stars, we find a correlation between eccentricity and mass\nejection, with a higher impact parameter leading to a larger amount of unbound\nmaterial.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-14T13:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.10240v1","title":"GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction","summary":"Circuit link prediction identifying missing component connections from\nincomplete netlists is crucial in automating analog circuit design. However,\nexisting methods face three main challenges: 1) Insufficient use of topological\npatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to\nthe complexity of annotations hinders model generalization; 3) Limited\nadaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural\nNetworks (GNNs) based framework featuring three innovations to tackle these\nchallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes\nfor Link Prediction) framework and achieve port-level accuracy in circuit link\nprediction. Second, we propose Netlist Babel Fish, a netlist format conversion\ntool leveraging retrieval-augmented generation (RAG) with large language model\n(LLM) to enhance the compatibility of netlist formats. Finally, we construct\nSpiceNetlist, a comprehensive dataset that contains 775 annotated circuits\nacross 10 different classes of components. The experimental results demonstrate\nan improvement of 15.05% on the SpiceNetlist dataset and 12.01% on the\nImage2Net dataset over the existing approach.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-14T14:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.10246v1","title":"Simplified and Verified: A Second Look at a Proof-Producing Union-Find\n  Algorithm","summary":"Using Isabelle/HOL, we verify a union-find data structure with an explain\noperation due to Nieuwenhuis and Oliveras. We devise a simpler, more naive\nversion of the explain operation whose soundness and completeness is easy to\nverify. Then, we prove the original formulation of the explain operation to be\nequal to our version. Finally, we refine this data structure to Imperative HOL,\nenabling us to export efficient imperative code. The formalisation provides a\nstepping stone towards the verification of proof-producing congruence closure\nalgorithms which are a core ingredient of Satisfiability Modulo Theories (SMT)\nsolvers.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T14:09:09Z"}
{"aid":"http://arxiv.org/abs/2504.10248v1","title":"Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for\n  Dynamic Data Acquisition in Digital Twins","summary":"This paper introduces a sensor steering methodology based on deep\nreinforcement learning to enhance the predictive accuracy and decision support\ncapabilities of digital twins by optimising the data acquisition process.\nTraditional sensor placement techniques are often constrained by one-off\noptimisation strategies, which limit their applicability for online\napplications requiring continuous informative data assimilation. The proposed\napproach addresses this limitation by offering an adaptive framework for sensor\nplacement within the digital twin paradigm. The sensor placement problem is\nformulated as a Markov decision process, enabling the training and deployment\nof an agent capable of dynamically repositioning sensors in response to the\nevolving conditions of the physical structure as represented by the digital\ntwin. This ensures that the digital twin maintains a highly representative and\nreliable connection to its physical counterpart. The proposed framework is\nvalidated through a series of comprehensive case studies involving a cantilever\nplate structure subjected to diverse conditions, including healthy and damaged\nconditions. The results demonstrate the capability of the deep reinforcement\nlearning agent to adaptively reposition sensors improving the quality of data\nacquisition and hence enhancing the overall accuracy of digital twins.","main_category":"stat.ML","categories":"stat.ML,cs.LG,eess.SP","published":"2025-04-14T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.10250v1","title":"MURR: Model Updating with Regularized Replay for Searching a Document\n  Stream","summary":"The Internet produces a continuous stream of new documents and user-generated\nqueries. These naturally change over time based on events in the world and the\nevolution of language. Neural retrieval models that were trained once on a\nfixed set of query-document pairs will quickly start misrepresenting\nnewly-created content and queries, leading to less effective retrieval.\nTraditional statistical sparse retrieval can update collection statistics to\nreflect these changes in the use of language in documents and queries. In\ncontrast, continued fine-tuning of the language model underlying neural\nretrieval approaches such as DPR and ColBERT creates incompatibility with\npreviously-encoded documents. Re-encoding and re-indexing all\npreviously-processed documents can be costly. In this work, we explore updating\na neural dual encoder retrieval model without reprocessing past documents in\nthe stream. We propose MURR, a model updating strategy with regularized replay,\nto ensure the model can still faithfully search existing documents without\nreprocessing, while continuing to update the model for the latest topics. In\nour simulated streaming environments, we show that fine-tuning models using\nMURR leads to more effective and more consistent retrieval results than other\nstrategies as the stream of documents and queries progresses.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-14T14:13:03Z"}
{"aid":"http://arxiv.org/abs/2504.10259v1","title":"Dual-grid parameter choice method with application to image deblurring","summary":"Variational regularization of ill-posed inverse problems is based on\nminimizing the sum of a data fidelity term and a regularization term. The\nbalance between them is tuned using a positive regularization parameter, whose\nautomatic choice remains an open question in general. A novel approach for\nparameter choice is introduced, based on the use of two slightly different\ncomputational models for the same inverse problem. Small parameter values\nshould give two very different reconstructions due to amplification of noise.\nLarge parameter values lead to two identical but trivial reconstructions.\nOptimal parameter is chosen between the extremes by matching image similarity\nof the two reconstructions with a pre-defined value. Efficacy of the new method\nis demonstrated with image deblurring using measured data and two different\nregularizers.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T14:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.10261v1","title":"Universality, Robustness, and Limits of the Eigenstate Thermalization\n  Hypothesis in Open Quantum Systems","summary":"The eigenstate thermalization hypothesis (ETH) underpins much of our modern\nunderstanding of the thermalization of closed quantum many-body systems. Here,\nwe investigate the statistical properties of observables in the eigenbasis of\nthe Lindbladian operator of a Markovian open quantum system. We demonstrate the\nvalidity of a Lindbladian ETH ansatz through extensive numerical simulations of\nseveral physical models. To highlight the robustness of Lindbladian ETH, we\nconsider what we dub the dilute-click regime of the model, in which one\npostselects only quantum trajectories with a finite fraction of quantum jumps.\nThe average dynamics are generated by a non-trace-preserving Liouvillian, and\nwe show that the Lindbladian ETH ansatz still holds in this case. On the other\nhand, the no-click limit is a singular point at which the Lindbladian reduces\nto a doubled non-Hermitian Hamiltonian and Lindbladian ETH breaks down.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,nlin.CD,quant-ph","published":"2025-04-14T14:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.10270v1","title":"Affine and cyclotomic $q$-Schur categories via webs","summary":"We formulate two new $\\mathbb Z[q,q^{-1}]$-linear diagrammatic monoidal\ncategories, the affine $q$-web category and the affine $q$-Schur category, as\nwell as their respective cyclotomic quotient categories. Diagrammatic integral\nbases for the Hom-spaces of all these categories are established. In addition,\nwe establish the following isomorphisms, providing diagrammatic presentations\nof these $q$-Schur algebras for the first time: (i)~ the path algebras of the\naffine $q$-web category to R.~Green's affine $q$-Schur algebras, (ii)~ the path\nalgebras of the affine $q$-Schur category to Maksimau-Stroppel's higher level\naffine $q$-Schur algebras, and most significantly, (iii)~ the path algebras of\nthe cyclotomic $q$-Schur categories to Dipper-James-Mathas' cyclotomic\n$q$-Schur algebras.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-04-14T14:34:52Z"}
{"aid":"http://arxiv.org/abs/2504.10285v1","title":"Grothendieck-Springer resolutions and TQFTs","summary":"Let $G$ be a connected complex semisimple group with Lie algebra\n$\\mathfrak{g}$ and fixed Kostant slice $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$.\nIn a previous work, we show that\n$((T^*G)_{\\text{reg}}\\rightrightarrows\\mathfrak{g}^*_{\\text{reg}},\\mathrm{Kos})$\nyields the open Moore-Tachikawa TQFT. Morphisms in the image of this TQFT are\ncalled open Moore-Tachikawa varieties. By replacing\n$T^*G\\rightrightarrows\\mathfrak{g}^*$ and $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$\nwith the double $\\mathrm{D}(G)\\rightrightarrows G$ and a Steinberg slice\n$\\mathrm{Ste}\\subseteq G$, respectively, one obtains quasi-Hamiltonian\nanalogues of the open Moore-Tachikawa TQFT and varieties.\n  We consider a conjugacy class $\\mathcal{C}$ of parabolic subalgebras of\n$\\mathfrak{g}$. This class determines partial Grothendieck-Springer resolutions\n$\\mu_{\\mathcal{C}}:\\mathfrak{g}_{\\mathcal{C}}\\longrightarrow\\mathfrak{g}^*=\\mathfrak{g}$\nand $\\nu_{\\mathcal{C}}:G_{\\mathcal{C}}\\longrightarrow G$. We construct a\ncanonical symplectic groupoid\n$(T^*G)_{\\mathcal{C}}\\rightrightarrows\\mathfrak{g}_{\\mathcal{C}}$ and\nquasi-symplectic groupoid $\\mathrm{D}(G)_{\\mathcal{C}}\\rightrightarrows\nG_{\\mathcal{C}}$. In addition, we prove that the pairs\n$(((T^*G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(\\mathfrak{g}_{\\mathcal{C}})_{\\text{reg}},\\mu_{\\mathcal{C}}^{-1}(\\mathrm{Kos}))$\nand\n$((\\mathrm{D}(G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(G_{\\mathcal{C}})_{\\text{reg}},\\nu_{\\mathcal{C}}^{-1}(\\mathrm{Ste}))$\ndetermine TQFTs in a $1$-shifted Weinstein symplectic category. Our main result\nis about the Hamiltonian symplectic varieties arising from the former TQFT; we\nshow that these have canonical Lagrangian relations to the open Moore-Tachikawa\nvarieties. Pertinent specializations of our results to the full\nGrothendieck-Springer resolution are discussed throughout this manuscript.","main_category":"math.SG","categories":"math.SG,math.AG,math.RT","published":"2025-04-14T14:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.10290v1","title":"Maximizing subgraph density in graphs of bounded degree and clique\n  number","summary":"We asymptotically determine the maximum density of subgraphs isomorphic to\n$H$, where $H$ is any graph containing a dominating vertex, in graphs $G$ on\n$n$ vertices with bounded maximum degree and bounded clique number. That is, we\nasymptotically determine the constant $c=c(H,\\Delta,\\omega)$ such that\nex$(n,H,\\{K_{1,\\Delta+1},K_{\\omega+1}\\})=(1-o_n(1))cn$. More generally, if $H$\nhas at least $u$ dominating vertices, then we find the maximum density of\nsubgraphs isomorphic to $H$ in graphs $G$ that have $p$ cliques of size $u$,\nhave bounded clique number, and are $K_u\\vee I_{\\Delta+1}$-free. For example,\nwe asymptotically determine the constant $d=d(H,\\Delta,\\omega)$ such that\nmex$(m,H,\\{K_{1,1,\\Delta+1},K_{\\omega+1}\\})=(1-o_m(1))dm$. Then we localize\nthese results, proving a tight inequality involving the sizes of the locally\nlargest cliques and complete split graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T15:02:24Z"}
{"aid":"http://arxiv.org/abs/2504.10298v1","title":"Cross-talk in superconducting qubit lattices with tunable couplers -\n  comparing transmon and fluxonium architectures","summary":"Cross-talk between qubits is one of the main challenges for scaling\nsuperconducting quantum processors. Here, we use the density-matrix\nrenormalization-group to numerically analyze lattices of superconducting qubits\nfrom a perspective of many-body localization. Specifically, we compare\ndifferent architectures that include tunable couplers designed to decouple\nqubits in the idle state, and calculate the residual ZZ interactions as well as\nthe inverse participation ratio in the computational basis states. For transmon\nqubits outside of the straddling regime, the results confirm that tunable\nC-shunt flux couplers are significantly more efficient in mitigating the ZZ\ninteractions than tunable transmons. A recently proposed fluxonium architecture\nwith tunable transmon couplers is demonstrated to also maintain its strong\nsuppression of the ZZ interactions in larger systems, while having a higher\ninverse participation ratio in the computational basis states than lattices of\ntransmon qubits. Our results thus suggest that fluxonium architectures may\nfeature lower cross talk than transmon lattices when designed to achieve\nsimilar gate speeds and fidelities.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T15:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.10306v1","title":"Global existence of measure-valued solutions to the multicomponent\n  Smoluchowski coagulation equation","summary":"Global solutions to the multicomponent Smoluchowski coagulation equation are\nconstructed for measure-valued initial data with minimal assumptions on the\nmoments. The framework is based on an abstract formulation of the\nArzel\\`a-Ascoli theorem for uniform spaces. The result holds for a large class\nof coagulation rate kernels, satisfying a power-law upper bound with possibly\ndifferent singularities at small-small, small-large and large-large coalescence\npairs. This includes in particular both mass-conserving and gelling kernels, as\nwell as interpolation kernels used in applications. We also provide short\nproofs of mass-conservation and gelation results for any weak solution, which\nextends previous results for one-component systems.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-14T15:14:22Z"}
{"aid":"http://arxiv.org/abs/2504.10315v1","title":"An energy optimization method based on mixed-integer model and\n  variational quantum computing algorithm for faster IMPT","summary":"Intensity-modulated proton therapy (IMPT) offers superior dose conformity\nwith reduced exposure to surrounding healthy tissues compared to conventional\nphoton therapy. Improving IMPT delivery efficiency reduces motion-related\nuncertainties, enhances plan robustness, and benefits breath-hold techniques by\nshortening treatment time. Among various factors, energy switching time plays a\ncritical role, making energy layer optimization (ELO) essential. This work\ndevelops an energy layer optimization method based on mixed integer model and\nvariational quantum computing algorithm to enhance the efficiency of IMPT. The\nenergy layer optimization problem is modeled as a mixed-integer program, where\ncontinuous variables optimize the dose distribution and binary variables\nindicate energy layer selection. To solve it, iterative convex relaxation\ndecouples the dose-volume constraints, followed by the alternating direction\nmethod of multipliers (ADMM) to separate mixed-variable optimization and the\nminimum monitor unit (MMU) constraint. The resulting beam intensity subproblem,\nsubject to MMU, either admits a closed-form solution or is efficiently solvable\nvia conjugate gradient. The binary subproblem is cast as a quadratic\nunconstrained binary optimization (QUBO) problem, solvable using variational\nquantum computing algorithms. With nearly the same plan quality, the proposed\nmethod noticeable reduces the number of the used energies. For example,\ncompared to conventional IMPT, QC can reduce the number of energy layers from\n61 to 35 in HN case, from 56 to 35 in lung case, and from 59 to 32 to abdomen\ncase. The reduced number of energies also results in fewer delivery time, e.g.,\nthe delivery time is reduced from 100.6, 232.0, 185.3 seconds to 90.7, 215.4,\n154.0 seconds, respectively.","main_category":"physics.med-ph","categories":"physics.med-ph,math.OC","published":"2025-04-14T15:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.10337v1","title":"Heimdall: test-time scaling on the generative verification","summary":"An AI system can create and maintain knowledge only to the extent that it can\nverify that knowledge itself. Recent work on long Chain-of-Thought reasoning\nhas demonstrated great potential of LLMs on solving competitive problems, but\ntheir verification ability remains to be weak and not sufficiently\ninvestigated. In this paper, we propose Heimdall, the long CoT verification LLM\nthat can accurately judge the correctness of solutions. With pure reinforcement\nlearning, we boost the verification accuracy from 62.5% to 94.5% on competitive\nmath problems. By scaling with repeated sampling, the accuracy further\nincreases to 97.5%. Through human evaluation, Heimdall demonstrates impressive\ngeneralization capabilities, successfully detecting most issues in challenging\nmath proofs, the type of which is not included during training. Furthermore, we\npropose Pessimistic Verification to extend the functionality of Heimdall to\nscaling up the problem solving. It calls Heimdall to judge the solutions from a\nsolver model and based on the pessimistic principle, selects the most likely\ncorrect solution with the least uncertainty. Taking\nDeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification\nimproves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute\nbudget and to 83.3% with more compute budget. With the stronger solver Gemini\n2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge\ndiscovery system, a ternary system where one poses questions, another provides\nsolutions, and the third verifies the solutions. Using the data synthesis work\nNuminaMath for the first two components, Heimdall effectively identifies\nproblematic records within the dataset and reveals that nearly half of the data\nis flawed, which interestingly aligns with the recent ablation studies from\nNuminaMath.","main_category":"cs.AI","categories":"cs.AI,I.2.7","published":"2025-04-14T15:46:33Z"}
{"aid":"http://arxiv.org/abs/2504.10355v1","title":"A geometric analysis of the Bazykin-Berezovskaya predator-prey model\n  with Allee effect in an economic framework","summary":"We study a fast-slow version of the Bazykin-Berezovskaya predator-prey model\nwith Allee effect evolving on two timescales, through the lenses of Geometric\nSingular Perturbation Theory (GSPT). The system we consider is in non-standard\nform. We completely characterize its dynamics, providing explicit threshold\nquantities to distinguish between a rich variety of possible asymptotic\nbehaviors. Moreover, we propose numerical results to illustrate our findings.\nLastly, we comment on the real-world interpretation of these results, in an\neconomic framework and in the context of predator-prey models.","main_category":"math.DS","categories":"math.DS,q-bio.PE","published":"2025-04-14T16:04:03Z"}
{"aid":"http://arxiv.org/abs/2504.10369v1","title":"SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired\n  Symbolic Reasoning","summary":"Optimizing Register Transfer Level (RTL) code is crucial for improving the\npower, performance, and area (PPA) of digital circuits in the early stages of\nsynthesis. Manual rewriting, guided by synthesis feedback, can yield\nhigh-quality results but is time-consuming and error-prone. Most existing\ncompiler-based approaches have difficulty handling complex design constraints.\nLarge Language Model (LLM)-based methods have emerged as a promising\nalternative to address these challenges. However, LLM-based approaches often\nface difficulties in ensuring alignment between the generated code and the\nprovided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL\noptimization framework that seamlessly integrates LLM-based code rewriting with\nsymbolic reasoning techniques. Our method incorporates a retrieval-augmented\ngeneration (RAG) system of optimization rules and Abstract Syntax Tree\n(AST)-based templates, enabling LLM-based rewriting that maintains syntactic\ncorrectness while minimizing undesired circuit behaviors. A symbolic module is\nproposed for analyzing and optimizing finite state machine (FSM) logic,\nallowing fine-grained state merging and partial specification handling beyond\nthe scope of pattern-based compilers. Furthermore, a fast verification\npipeline, combining formal equivalence checks with test-driven validation,\nfurther reduces the complexity of verification. Experiments on the RTL-Rewriter\nbenchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves\npower, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%,\nrespectively, compared to the state-of-the-art methods.","main_category":"cs.AR","categories":"cs.AR,cs.AI,cs.LG,cs.PL","published":"2025-04-14T16:15:55Z"}
{"aid":"http://arxiv.org/abs/2504.10381v1","title":"Abstract simplicial complexes in {\\tt Macaulay2}","summary":"{\\tt AbstractSimplicialComplexes.m2} is a computer algebra package written\nfor the computer algebra system {\\tt Macaulay2} \\cite{M2}. It provides new\ninfrastructure to work with abstract simplicial complexes and related\nhomological constructions. Its key novel feature is to implement each given\nabstract simplicial complex as a certain graded list in the form of a hash\ntable with integer keys. Among other features, this allows for a direct\nimplementation of the associated reduced and non-reduced simplicial chain\ncomplexes. Further, it facilitates construction of random simplicial complexes.\nThe approach that we employ here builds on the {\\tt Macaulay2} package {\\tt\nComplexes.m2} \\cite{Stillman:Smith:Complexes.m2}. It complements and is\nentirely different from the existing {\\tt Macaulay2} simplicial complexes\nframework that is made possible by the package {\\tt SimplicialComplexes.m2}\n\\cite{Smith:et:al:SimplicialComplexes.m2:jsag}.","main_category":"math.AG","categories":"math.AG,math.AC,math.AT,math.CO,math.KT","published":"2025-04-14T16:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10441v1","title":"Position Uncertainty in a Prisoner's Dilemma Game : An Experiment","summary":"Gallice and Monzon (2019) present a natural environment that sustains full\ncooperation in one-shot social dilemmas among a finite number of\nself-interested agents. They demonstrate that in a sequential public goods\ngame, where agents lack knowledge of their position in the sequence but can\nobserve some predecessors' actions, full contribution emerges in equilibrium\ndue to agents' incentive to induce potential successors to follow suit.\nFurthermore, they show that this principle extends to a number of social\ndilemmas, with the prominent example that of the prisoner's dilemma. In this\nstudy, we experimentally test the theoretical predictions of this model in a\nmulti- player prisoner's dilemma environment, where subjects are not aware of\ntheir position in the sequence and receive only partial information on past\ncooperating actions. We test the predictions of the model, and through rigorous\nstructural econometric analysis, we test the descriptive capacity of the model\nagainst alternative behavioural strategies, such as conditional cooperation,\naltruistic play and free-riding behaviour. We find that the majority resorts to\nfree-riding behaviour, around 30% is classified as Gallice and Monzon (2019)\ntypes, followed by those with social preference considerations and the\nunconditional altruists.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-14T17:32:07Z"}
{"aid":"http://arxiv.org/abs/2504.10452v1","title":"Integrating Vision and Location with Transformers: A Multimodal Deep\n  Learning Framework for Medical Wound Analysis","summary":"Effective recognition of acute and difficult-to-heal wounds is a necessary\nstep in wound diagnosis. An efficient classification model can help wound\nspecialists classify wound types with less financial and time costs and also\nhelp in deciding on the optimal treatment method. Traditional machine learning\nmodels suffer from feature selection and are usually cumbersome models for\naccurate recognition. Recently, deep learning (DL) has emerged as a powerful\ntool in wound diagnosis. Although DL seems promising for wound type\nrecognition, there is still a large scope for improving the efficiency and\naccuracy of the model. In this study, a DL-based multimodal classifier was\ndeveloped using wound images and their corresponding locations to classify them\ninto multiple classes, including diabetic, pressure, surgical, and venous\nulcers. A body map was also created to provide location data, which can help\nwound specialists label wound locations more effectively. The model uses a\nVision Transformer to extract hierarchical features from input images, a\nDiscrete Wavelet Transform (DWT) layer to capture low and high frequency\ncomponents, and a Transformer to extract spatial features. The number of\nneurons and weight vector optimization were performed using three swarm-based\noptimization techniques (Monster Gorilla Toner (MGTO), Improved Gray Wolf\nOptimization (IGWO), and Fox Optimization Algorithm). The evaluation results\nshow that weight vector optimization using optimization algorithms can increase\ndiagnostic accuracy and make it a very effective approach for wound detection.\nIn the classification using the original body map, the proposed model was able\nto achieve an accuracy of 0.8123 using image data and an accuracy of 0.8007\nusing a combination of image data and wound location. Also, the accuracy of the\nmodel in combination with the optimization models varied from 0.7801 to 0.8342.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:39:18Z"}
{"aid":"http://arxiv.org/abs/2504.10474v1","title":"Co-optimizing Physical Reconfiguration Parameters and Controllers for an\n  Origami-inspired Reconfigurable Manipulator","summary":"Reconfigurable robots that can change their physical configuration\npost-fabrication have demonstrate their potential in adapting to different\nenvironments or tasks. However, it is challenging to determine how to optimally\nadjust reconfigurable parameters for a given task, especially when the\ncontroller depends on the robot's configuration. In this paper, we address this\nproblem using a tendon-driven reconfigurable manipulator composed of multiple\nserially connected origami-inspired modules as an example. Under tendon\nactuation, these modules can achieve different shapes and motions, governed by\njoint stiffnesses (reconfiguration parameters) and the tendon displacements\n(control inputs). We leverage recent advances in co-optimization of design and\ncontrol for robotic system to treat reconfiguration parameters as design\nvariables and optimize them using reinforcement learning techniques. We first\nestablish a forward model based on the minimum potential energy method to\npredict the shape of the manipulator under tendon actuations. Using the forward\nmodel as the environment dynamics, we then co-optimize the control policy (on\nthe tendon displacements) and joint stiffnesses of the modules for goal\nreaching tasks while ensuring collision avoidance. Through co-optimization, we\nobtain optimized joint stiffness and the corresponding optimal control policy\nto enable the manipulator to accomplish the task that would be infeasible with\nfixed reconfiguration parameters (i.e., fixed joint stiffness). We envision the\nco-optimization framework can be extended to other reconfigurable robotic\nsystems, enabling them to optimally adapt their configuration and behavior for\ndiverse tasks and environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T17:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.10477v1","title":"Vector induced Gravitational Waves sourced by Primordial Magnetic Fields","summary":"In this work, we develop a generic formalism for the study of tensor\nperturbations induced at second order by first-order vector metric\nperturbations, dubbing these induced tensor modes $\\textit{vector-induced\ngravitational waves}$ (VIGWs). Notably, considering an inflation-inspired\npower-law type magnetic field power spectrum of the form $P_B(k)\\propto\nk^{n_\\mathrm{B}}$ (where $n_{\\rm B}$ is the magnetic spectral index), we show\nthat the VIGW signal is enhanced for stiff post-inflationary EoS, with the\nmaximum enhancement happening for $w=1$. We explicitly demonstrate this\ncontribution is dominant over the first-order magnetically-sourced GWs. The\nVIGW spectrum exhibits a maximum at around the scale crossing the cosmological\nhorizon at the end of reheating, $k_\\mathrm{reh}$, with its present day peak\namplitude scaling as $\\Omega_{\\rm GW}(k_{\\rm reh},\\eta_0)\\propto \\Delta N_{\\rm\nreh}\\times(H_{\\rm inf}/M_{\\rm Pl})^{8}$, where $H_{\\rm inf}$ is the Hubble\nparameter at the end of inflation and $\\Delta N_{\\rm reh}$ the duration of the\npost-inflationary era in $e$-folds. For $w=1$ (kination) and $n_{\\rm B}>-3/2$,\none further obtains a nearly $n_{\\rm B}$-independent frequency scaling of the\nGW spectrum of the form $\\Omega_{\\rm GW}(f,\\eta_0)\\propto \\left(\\frac{f}{f_{\\rm\nreh}}\\right)^{-2.8}$ for $f>f_\\mathrm{reh}\\equiv k_\\mathrm{reh}/(2\\pi)$.\nFinally, we need to highlight that the VIGW signal can be well within the\ndetection bands of several next-generation interferometric GW missions at small\nscales. Indicatively, for $H_{\\rm inf} \\sim O(10^{7})\\:\\mathrm{GeV}$ and\n$O(10^{14})\\:\\mathrm{GeV}$, and $\\Delta N_{\\rm reh} \\sim 15$ and $10$, the VIGW\nsignal is found to be detectable by LISA and ET respectively.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-14T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.10480v1","title":"Probing Long-Range Forces in Neutrino Oscillations at the ESSnuSB\n  Experiment","summary":"Neutrino oscillations constitute an excellent tool to probe physics beyond\nthe Standard Model. In this paper, we investigate the potential of the \\ess\nexperiment to constrain the effects of flavour-dependent long-range forces\n(LRFs) in neutrino oscillations, which may arise due to the extension of the\nStandard Model gauge group by introducing new $U(1)$ symmetries. Focusing on\nthree specific $U(1)$ symmetries -- $L_e - L_\\mu$, $L_e - L_\\tau$, and $L_\\mu -\nL_\\tau$, we demonstrate that \\ess offers a favourable environment to search for\nLRF effects. Our analyses reveal that \\ess can set 90\\% confidence level bounds\nof $V_{e\\mu} < 2.99 \\times 10^{-14} \\, \\text{eV}$, $V_{e\\tau} < 2.05 \\times\n10^{-14} \\, \\text{eV}$, and $V_{\\mu\\tau} < 1.81 \\times 10^{-14} \\, \\text{eV}$,\nwhich are competitive to the upcoming Deep Underground Neutrino Experiment\n(DUNE). It is also observed that reducing the systematic uncertainties from\n$5\\%$ to $2\\%$ improves the \\ess limits on $V_{\\alpha\\beta}$. Interestingly, we\nfind limited correlations between LRF parameters and the less constrained\nlepton mixing parameters $\\theta_{23}$ and $\\delta_{\\text{CP}}$, preserving the\nrobustness of ESSnuSB's sensitivity to CP violation. Even under extreme LRF\npotentials ($V_{\\alpha\\beta} \\gg 10^{-13} \\, \\text{eV}$), the CP-violation\nsensitivity and $\\delta_{\\text{CP}}$ precision remain largely unaffected. These\nresults establish ESSnuSB as a competitive experimental setup for probing LRF\neffects, complementing constraints from other neutrino sources and offering\ncritical insights into the physics of long-range forces.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-14T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.10872v1","title":"Design and Fabrication of a lightweight three-lens corrector system for\n  the 2.34-m Vainu Bappu Telescope","summary":"The Vainu Bappu Telescope (VBT) is a 2.34-m reflector, primarily supported\non-axis field of view, offering high-resolution and low-to-medium resolution\nspectroscopic observations in its prime and Cassegrain configurations. This\nstudy presents the design and fabrication of a compact, lightweight,\nthree-element wide-field corrector (WFC) utilizing three spherical lenses to\ncover a polychromatic wavelength range over a 30$'$ FoV at prime focus. The WFC\ndesign was optimized using ZEMAX, ensuring precision in aberrations,\ntolerances, and atmospheric dispersion. The fabricated lenses met stringent\ntolerances, with a $\\pm$1 mm deviation in radius of curvature and 2 mm\ndeviation in center thickness. A mechanical mount was developed to integrate\nall the WFC lenses, and wavefront error testing for the WFC system was\nperformed using ZYGO interferometry, yielding a Wavefront Error of 0.05\n$\\lambda$. Laboratory performance tests were designed and conducted using a\ndedicated setup with achromatic lenses and 100 $\\mu m$ fiber-coupled\npolychromatic light source showed a deviation of 0.1 pixel on-axis and 0.5\npixel at the extreme off-axis field compared to the ZEMAX design, demonstrating\nthat the optical performance of WFC is with minimal aberrations across the\nentire FoV. The successful integration of the WFC at the VBT prime focus will\nincrease the FoV, enabling the multi-fiber, multi-spectrograph setup in 30\narcmin field that will facilitate both OMR and Echelle spectrograph to be used\non the same night along with the addition of new multi-object spectrograph and\nan integral field unit instrument. This will mark a significant upgrade for the\nVBT, broadening its research potential, and expanding its observational\nversatility.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-15T05:03:00Z"}
{"aid":"http://arxiv.org/abs/2504.10887v1","title":"Fisher information approximation of random orthogonal matrices by\n  Gaussian matrices","summary":"Let ${\\Gamma}_n$ be an $n\\times n$ Haar-invariant orthogonal matrix. Let ${\nZ}_n$ be the $p\\times q$ upper-left submatrix of ${\\Gamma}_n$ and ${G}_n$ be a\n$p\\times q$ matrix whose $pq$ entries are independent standard normals, where\n$p$ and $q$ are two positive integers. Let $\\mathcal{L}(\\sqrt{n} {Z}_n)$ and\n$\\mathcal{L}({G}_n)$ be their joint distribution, respectively. Consider the\nFisher information $I(\\mathcal{L}(\\sqrt{n} { Z}_n)|\\mathcal{L}(G_n))$ between\nthe distributions of $\\sqrt{n} {Z}_n$ and ${ G}_n.$ In this paper, we conclude\nthat $$I(\\mathcal{L}(\\sqrt{n} {Z}_n)|\\mathcal{L}(G_n))\\longrightarrow 0 $$ as\n$n\\to\\infty$ if $pq=o(n)$ and it does not tend to zero if\n$c=\\lim\\limits_{n\\to\\infty}\\frac{pq}{n}\\in(0, +\\infty).$ Precisely, we obtain\nthat $$I(\\mathcal{L}(\\sqrt{n}\n{Z}_n)|\\mathcal{L}(G_n))=\\frac{p^2q(q+1)}{4n^2}(1+o(1))$$ when $p=o(n).$","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T05:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.10894v1","title":"Infinite temperature spin dynamics in the asymmetric Hatsugai-Kohmoto\n  model","summary":"We focus on the infinite temperature dynamical spin structure factor of the\nasymmetric Hatsugai-Kohmoto model, the relative of the asymmetric Hubbard\nmodel. It is characterized by distinct single particle energies for the two\nspin species, which interact with each other through a contact interaction in\nmomentum space. We evaluate its spin structure factor exactly and follow the\nevolution of its excitation spectrum for all fillings and interactions,\nidentify signatures of the Mott transition and fingerprints of the asymmetric\nhoppings. The longitudinal spin structure factor exhibits sound like and\ninteraction induced gapped excitations, whose number gets doubled in the\npresence of hopping asymmetry. The transverse response displays the competition\nof interaction and asymmetry induced gaps and results in a quadratic excitation\nbranch at their transition. The complete asymmetric case features\nmomentum-independent dynamical structure factor, characteristic to transitions\ninvolving a flat band.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech","published":"2025-04-15T06:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.10897v1","title":"SCOOP: A Scalable Quantum-Computing Framework to Constrained\n  Combinatorial Optimization","summary":"While the ultimate goal of solving computationally intractable problems is to\nfind a provably optimal solutions, practical constraints of real-world\nscenarios often necessitate focusing on efficiently obtaining high-quality,\nnear-optimal solutions. The Quantum Approximate Optimization Algorithm (QAOA)\nis a state-of-the-art hybrid quantum-classical approach for tackling these\nchallenging problems that are encoded using quadratic and higher-order\nunconstrained binary optimization problems (QUBO and HUBO). We present SCOOP, a\nnovel QAOA-based framework for solving constrained optimization problems. SCOOP\ntransforms a constrained problem into an unconstrained counterpart, forming\nSCOOP problem twins. The QAOA quantum algorithm operates on the unconstrained\ntwin to identify potential optimal and near-optimal solutions. Effective\nclassical post-processing reduces the solution set to the constrained problem\nspace. Our SCOOP approach is solution-enhanced, objective-function-compatible,\nand scalable. We demonstrate the framework on three NP-hard problems, Minimum\nDominating Set, Minimum Maximal Matching, and Minimum Set Cover appearing in\npractical application domains such as resource allocation, communication\nnetworks, and machine learning. We validate SCOOP's feasibility and\neffectiveness on Xanadu PennyLane simulators.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T06:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.10915v1","title":"LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI\n  Agent Ecosystems","summary":"The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that enables agents to make context-aware decisions grounded in\nshared ethical baselines. Anchored in emerging standards such as Decentralized\nIdentifiers (DIDs), Verifiable Credentials (VCs), and post-quantum\ncryptography, LOKA offers a scalable, future-resilient blueprint for\nmulti-agent AI governance. By embedding identity, trust, and ethics into the\nprotocol layer itself, LOKA establishes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.CY","published":"2025-04-15T06:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.10939v1","title":"Formation of Ba stars : impact of wind Roche lobe overflow and\n  circumbinary disk in shaping the orbital parameters","summary":"After more than three decades of investigation, the distribution of Ba stars\nin the e-log P diagram still defies our understanding. Recent smooth particle\nhydrodynamic simulations involving an asymptotic giant branch (AGB) primary\nhave shown that a circumbinary disk (CB) can form around the binary and that\nthe presence of dust in the wind of evolved low- and intermediate-mass stars\ncan significantly affect the systemic angular momentum loss and mass accretion\nonto the companion through the wind Roche lobe overflow (WRLOF) phase. We used\nthe binary evolution code BINSTAR, where we updated the modeling of the\nprogenitors of Ba stars including a CB disk, the WRLOF, tidally enhanced wind\nmass loss, and non-conservative RLOF with their effects on the orbital\nevolution. In our approach, we considered that a CB disk forms when WRLOF is\nactivated. The coupling between the CB disk and the binary follows the standard\nresonant interaction theory. We constructed grids of 2.0 + 1.0 $M_\\odot{}$ and\n1.2 + 0.8 $M_\\odot{}$ binaries for initial orbital parameters that result in\nWRLOF, and evolved these systems until the end of the primary's AGB phase.\nWRLOF resulted in a significant shrinkage of the orbital separation during the\nAGB phase, leading to binaries with initial periods on the order of $\\lesssim\n12000$ d undergoing Roche lobe overflow (RLOF). The combination of WRLOF,\neccentricity pumping from the CB disk, and/or tidally enhanced wind mass loss\ncan lead to RLOF on eccentric orbits down to periods of $P_\\mathrm{orb} \\sim\n3000$d. Non-conservative RLOF enabled a reduction of the period before\ncircularization down to $\\sim 2000$d, provided at least 50 percent of the\ntransferred mass left the system. Our models still cannot account for the\neccentricity distribution of Ba stars with periods shorter than $P_\\mathrm{orb}\n\\lesssim 2000$d, where a common envelope evolution appears unavoidable.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-15T07:39:51Z"}
{"aid":"http://arxiv.org/abs/2504.10947v1","title":"Improved MST3 Encryption scheme based on small Ree groups","summary":"This article presents an encryption scheme based on the small Ree groups. We\npropose utilizing the small Ree group structure to enhance the overall security\nparameters of the encryption scheme. By extending the logarithmic signature to\nencompass the entire group and modifying the encryption algorithm, we have\ndeveloped robust protection against sequential key recovery attacks.","main_category":"cs.CR","categories":"cs.CR,math.GR","published":"2025-04-15T07:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10954v1","title":"Offset-free Nonlinear MPC with Koopman-based Surrogate Models","summary":"In this paper, we design offset-free nonlinear Model Predictive Control (MPC)\nfor surrogate models based on Extended Dynamic Mode Decomposition (EDMD). The\nmodel used for prediction in MPC is augmented with a disturbance term, that is\nestimated by an observer. If the full information about the equilibrium of the\nreal system is not available, a reference calculator is introduced in the\nalgorithm to compute the MPC state and input references. The control algorithm\nguarantees offset-free tracking of the controlled output under the assumption\nthat the modeling errors are asymptotically constant. The effectiveness of the\nproposed approach is showcased with numerical simulations for two popular\nbenchmark systems: the van-der-Pol oscillator and the four-tanks process.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T08:00:15Z"}
{"aid":"http://arxiv.org/abs/2504.10981v1","title":"X-ray polarization of accreting black holes: Cyg X-1 and Swift\n  J1727.8-1613","summary":"The Imaging X-ray Polarimetry Explorer is an X-ray observatory measuring the\nX-ray polarization in the 2-8 keV energy range. Highly sensitive to the\nsystem's geometry, X-ray polarization is a unique method to probe the structure\nof X-ray binaries. The Imaging X-ray Polarimetry Explorer observed the\nHigh-Mass X-ray Binary Cygnus X-1 and the Low-Mass X-ray Binary Swift\nJ1727.8-1613 in different accretion states: in the hard state and in the soft\nstate. The X-ray polarimetry analysis of both sources shows a linear\npolarization degree increasing with energy, with higher values in the hard\nstate than in the soft state. However, the linear polarization angle stays\nsimilar in both states and is aligned with the radio jet within $5^\\circ$.\nFurthermore, the Low-Mass X-ray Binary Swift J1727.8-1613 has a lower optical\nintrinsic polarization and a lower X-ray polarization degree for a softer\nspectrum. The similarities observed in this analysis between the X-ray\npolarization results of different types of X-ray Binaries show that the\ninnermost accretion processes are independent of the companion star's type.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T08:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.10982v1","title":"Exploring the Role of KG-Based RAG in Japanese Medical Question\n  Answering with Small-Scale LLMs","summary":"Large language models (LLMs) perform well in medical QA, but their\neffectiveness in Japanese contexts is limited due to privacy constraints that\nprevent the use of commercial models like GPT-4 in clinical settings. As a\nresult, recent efforts focus on instruction-tuning open-source LLMs, though the\npotential of combining them with retrieval-augmented generation (RAG) remains\nunderexplored. To bridge this gap, we are the first to explore a knowledge\ngraph-based (KG) RAG framework for Japanese medical QA small-scale open-source\nLLMs. Experimental results show that KG-based RAG has only a limited impact on\nJapanese medical QA using small-scale open-source LLMs. Further case studies\nreveal that the effectiveness of the RAG is sensitive to the quality and\nrelevance of the external retrieved content. These findings offer valuable\ninsights into the challenges and potential of applying RAG in Japanese medical\nQA, while also serving as a reference for other low-resource languages.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T08:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.11007v1","title":"Kubernetes in the Cloud vs. Bare Metal: A Comparative Study of Network\n  Costs","summary":"Modern cloud-native applications increasingly utilise managed cloud services\nand containerisation technologies, such as Kubernetes, to achieve rapid\ntime-to-market and scalable deployments. Organisations must consider various\nfactors, including cost implications when deciding on a hosting platform for\ncontainerised applications as the usage grows. An emerging discipline called\nFinOps combines financial management and cloud operations to optimise costs in\ncloud-based applications. While prior research has explored system-level\noptimisation strategies for cost and resource efficiency in containerized\nsystems, analysing network costs in Kubernetes clusters remains underexplored.\nThis paper investigates the network usage and cost implications of\ncontainerised applications running on Kubernetes clusters. Using a methodology\nthat combines measurement analysis, experimentation, and cost modelling, we aim\nto provide organisations with actionable insights into network cost\noptimisation. Our findings highlight key considerations for analysing network\nexpenditures and evaluating the potential cost benefits of deploying\napplications on cloud providers. Overall, this paper contributes to the\nemerging FinOps discipline by addressing the financial and operational aspects\nof managing network costs in cloud-native environments.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-15T09:26:08Z"}
{"aid":"http://arxiv.org/abs/2504.11017v1","title":"Floquet realization of prethermal Meissner phase in a two-leg flux\n  ladder","summary":"We show that a periodically driven two-leg flux ladder hosting interacting\nhardcore bosons exhibits a prethermal Meissner phase for large drive amplitudes\nand at special drive frequencies. Such a prethermal Meissner phase is\ncharacterized by a finite time-averaged chiral current. We find an analytic\nexpression of these frequencies using Floquet perturbation theory. Our analysis\nreveals that the presence of the prethermal Meissner phase is tied to the\nemergence of strong Hilbert space fragmentation in these driven ladders. We\nsupport our analytical results by numerical study of finite-size flux ladders\nusing exact diagonalization and discuss experiments using ultracold dipolar\natom platforms that may test our theory.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.other","published":"2025-04-15T09:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.11018v1","title":"Cavity cooling using ultrafast electrons","summary":"We propose a method to cool a thermal photonic state in a cavity by passing\nelectrons through it. Electrons are coherently split into two paths, with one\npath traversing the cavity, becoming entangled with its photonic state. A\nsequence of such entanglement interactions can achieve cooling of the cavity:\ne.g., a twofold reduction in thermal photon number with a 25% post-selection\nprobability. This ``which-path''-based approach extends to other qubit\noscillator systems, such as phonons in crystals or optomechanical resonators,\noffering a general framework for quantum oscillator cooling.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T09:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.11023v1","title":"An Inexact Variable Metric Proximal Gradient-subgradient Algorithm for a\n  Class of Fractional Optimization Problems","summary":"In this paper, we study a class of fractional optimization problems, in which\nthe numerator of the objective is the sum of a convex function and a\ndifferentiable function with a Lipschitz continuous gradient, while the\ndenominator is a nonsmooth convex function. This model has broad applicability\nand encompasses several important optimization problems in the literature. To\naddress these problems, we propose an inexact variable metric proximal\ngradient-subgradient algorithm (iVPGSA), which, to our knowledge, is the first\ninexact proximal algorithm specifically designed for solving such type of\nfractional problems. By incorporating a variable metric proximal term and\nallowing for inexact solutions to the subproblem under a flexible error\ncriterion, the proposed algorithm is highly adaptable to a broader range of\nproblems while achieving favorable computational efficiency. Under mild\nassumptions, we establish that any accumulation point of the sequence generated\nby the iVPGSA is a critical point of the target problem. Moreover, we develop\nan improved Kurdyka-{\\L}ojasiewicz (KL)-based analysis framework to prove the\nglobal convergence of the entire sequence and characterize its convergence\nrate, \\textit{without} requiring a strict sufficient descent property. Our\nresults offer detailed insights into how the KL exponent and inexactness\ninfluence the convergence rate. The proposed analysis framework also has the\npotential to serve as a theoretical tool for studying the convergence rates of\na wide range of inexact algorithms beyond the iVPGSA. Finally, some numerical\nexperiments on the $\\ell_1/\\ell_2$ Lasso problem and the constrained\n$\\ell_1/\\ell_2$ sparse optimization problem are conducted to show the superior\nperformance of the iVPGSA in comparison to existing algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.11032v1","title":"On Rigid Varieties Isogenous to a Product of Curves","summary":"In this note, we study rigid complex manifolds that are realized as quotients\nof a product of curves by a free action of a finite group. They serve as\nhigher-dimensional analogues of Beauville surfaces. Using uniformization, we\noutline the theory to characterize these manifolds through specific\ncombinatorial data associated with the group under the assumption that the\naction is diagonal and the manifold is of general type. This leads to the\nnotion of a $n$-fold Beauville structure. We define an action on the set of all\n$n$-fold Beauville structures of a given finite group that allows us to\ndistinguish the biholomorphism classes of the underlying rigid manifolds. As an\napplication, we give a classification of these manifolds with group $\\mathbb\nZ_5^2$ in the three dimensional case and prove that this is the smallest\npossible group that allows a rigid, free and diagonal action on a product of\nthree curves. In addition, we provide the classification of rigid 3-folds $X$\ngiven by a group acting faithfully on each factor for any value of the\nholomorphic Euler number $\\chi(\\mathcal O_X) \\geq -5$.","main_category":"math.AG","categories":"math.AG,math.CV,math.GR","published":"2025-04-15T09:54:58Z"}
{"aid":"http://arxiv.org/abs/2504.11049v1","title":"A quantum algorithm for estimating the determinant","summary":"We present a quantum algorithm for estimating the matrix determinant based on\nquantum spectral sampling. The algorithm estimates the logarithm of the\ndeterminant of an $n \\times n$ positive sparse matrix to an accuracy $\\epsilon$\nin time ${\\cal O}(\\log n/\\epsilon^3)$, exponentially faster than previously\nexisting classical or quantum algorithms that scale linearly in $n$. The\nquantum spectral sampling algorithm generalizes to estimating any quantity\n$\\sum_j f(\\lambda_j)$, where $\\lambda_j$ are the matrix eigenvalues. For\nexample, the algorithm allows the efficient estimation of the partition\nfunction $Z(\\beta) =\\sum_j e^{-\\beta E_j}$ of a Hamiltonian system with energy\neigenvalues $E_j$, and of the entropy $ S =-\\sum_j p_j \\log p_j$ of a density\nmatrix with eigenvalues $p_j$.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T10:32:36Z"}
{"aid":"http://arxiv.org/abs/2504.11054v1","title":"Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models","summary":"Unsupervised reinforcement learning (RL) aims at pre-training agents that can\nsolve a wide range of downstream tasks in complex environments. Despite recent\nadvancements, existing approaches suffer from several limitations: they may\nrequire running an RL process on each downstream task to achieve a satisfactory\nperformance, they may need access to datasets with good coverage or\nwell-curated task-specific samples, or they may pre-train policies with\nunsupervised losses that are poorly correlated with the downstream tasks of\ninterest. In this paper, we introduce a novel algorithm regularizing\nunsupervised RL towards imitating trajectories from unlabeled behavior\ndatasets. The key technical novelty of our method, called Forward-Backward\nRepresentations with Conditional-Policy Regularization, is to train\nforward-backward representations to embed the unlabeled trajectories to the\nsame latent space used to represent states, rewards, and policies, and use a\nlatent-conditional discriminator to encourage policies to ``cover'' the states\nin the unlabeled behavior dataset. As a result, we can learn policies that are\nwell aligned with the behaviors in the dataset, while retaining zero-shot\ngeneralization capabilities for reward-based and imitation tasks. We\ndemonstrate the effectiveness of this new approach in a challenging humanoid\ncontrol problem: leveraging observation-only motion capture datasets, we train\nMeta Motivo, the first humanoid behavioral foundation model that can be\nprompted to solve a variety of whole-body tasks, including motion tracking,\ngoal reaching, and reward optimization. The resulting model is capable of\nexpressing human-like behaviors and it achieves competitive performance with\ntask-specific methods while outperforming state-of-the-art unsupervised RL and\nmodel-based baselines.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T10:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.11063v1","title":"UKDM: Underwater keypoint detection and matching using underwater image\n  enhancement techniques","summary":"The purpose of this paper is to explore the use of underwater image\nenhancement techniques to improve keypoint detection and matching. By applying\nadvanced deep learning models, including generative adversarial networks and\nconvolutional neural networks, we aim to find the best method which improves\nthe accuracy of keypoint detection and the robustness of matching algorithms.\nWe evaluate the performance of these techniques on various underwater datasets,\ndemonstrating significant improvements over traditional methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T10:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.11074v1","title":"Dynamical errors in machine learning forecasts","summary":"In machine learning forecasting, standard error metrics such as mean absolute\nerror (MAE) and mean squared error (MSE) quantify discrepancies between\npredictions and target values. However, these metrics do not directly evaluate\nthe physical and/or dynamical consistency of forecasts, an increasingly\ncritical concern in scientific and engineering applications.\n  Indeed, a fundamental yet often overlooked question is whether machine\nlearning forecasts preserve the dynamical behavior of the underlying system.\nAddressing this issue is essential for assessing the fidelity of machine\nlearning models and identifying potential failure modes, particularly in\napplications where maintaining correct dynamical behavior is crucial.\n  In this work, we investigate the relationship between standard forecasting\nerror metrics, such as MAE and MSE, and the dynamical properties of the\nunderlying system. To achieve this goal, we use two recently developed\ndynamical indices: the instantaneous dimension ($d$), and the inverse\npersistence ($\\theta$). Our results indicate that larger forecast errors --\ne.g., higher MSE -- tend to occur in states with higher $d$ (higher complexity)\nand higher $\\theta$ (lower persistence). To further assess dynamical\nconsistency, we propose error metrics based on the dynamical indices that\nmeasure the discrepancy of the forecasted $d$ and $\\theta$ versus their correct\nvalues. Leveraging these dynamical indices-based metrics, we analyze direct and\nrecursive forecasting strategies for three canonical datasets -- Lorenz,\nKuramoto-Sivashinsky equation, and Kolmogorov flow -- as well as a real-world\nweather forecasting task. Our findings reveal substantial distortions in\ndynamical properties in ML forecasts, especially for long forecast lead times\nor long recursive simulations, providing complementary information on ML\nforecast fidelity that can be used to improve ML models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,physics.comp-ph","published":"2025-04-15T11:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.11097v1","title":"Steering Feedback in Dynamic Driving Simulators: Road-Induced and\n  Non-Road-Induced Harshness","summary":"Steering feedback plays a substantial role in the validity of driving\nsimulators for the virtual development of modern vehicles. Established\nobjective steering characteristics typically assess the feedback behavior in\nthe frequency range of up to 30 Hz while factors such as steering wheel and\nvehicle body vibrations at higher frequencies are mainly approached as comfort\nissues. This work investigates the influence of steering wheel and vehicle body\nexcitations in the frequency range between 30 and 100 Hz on the subjective\nevaluation of steering feedback in a dynamic driving simulator. A controlled\nsubject study with 42 participants was performed to compare a reference vehicle\nwith an electrical power steering system to four variants of its virtual\nrepresentation on a dynamic driving simulator. The effects of road-induced\nexcitations were investigated by comparing a semi-empirical and a physics-based\ntire model, while the influence of non-road-induced excitations was\ninvestigated by implementing engine and wheel orders. The simulator variants\nwere evaluated in comparison to the reference vehicle during closed-loop\ndriving on a country road in a single-blind within-subjects design. The\nsubjective evaluation focused on the perception of road feedback compared to\nthe reference vehicle. The statistical analysis of subjective results shows\nthat there is a strong effect of non-road-induced steering and vehicle body\nexcitations, while the effect of road-induced excitations is considerably less\npronounced.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T11:42:55Z"}
{"aid":"http://arxiv.org/abs/2504.11100v1","title":"Uncertainty modeling method for wind and solar power output in building\n  integrated energy systems under continuous anomalous weather","summary":"The increasing occurrence of continuous anomalous weather events has\nintensified the uncertainty in wind and photovoltaic power generation, posing\nsignificant challenges to the operation and optimization of building integrated\nenergy systems. Existing studies often neglect the interdependence between\nsuccessive anomalous weather events and their collective impact on wind and\nsolar power output. Additionally, conventional modeling approaches struggle to\naccurately capture the nonlinear fluctuations induced by these weather\nconditions. To address this gap, this study proposes an uncertainty modeling\nmethod based on stochastic optimization and scenario generation. The Weibull\nand Beta distributions characterize the probabilistic properties of wind speed\nand solar irradiance, respectively, while the Copula function captures the\ndependence between wind speed and precipitation, enabling the construction of a\nwind-solar power uncertainty model that incorporates the joint distribution of\nconsecutive anomalous weather events. A Monte Carlo-based scenario generation\napproach is employed to construct a dataset representing anomalous weather\ncharacteristics, followed by a probabilistic distance-based scenario reduction\ntechnique to enhance modeling efficiency. Furthermore, the unscented\ntransformation method is introduced to mitigate nonlinear propagation errors in\nwind and solar power state estimation. Case studies demonstrate that the\nproposed method effectively characterizes the fluctuation patterns of wind and\nsolar power under continuous anomalous weather conditions while preserving the\nstatistical properties of the original data. These findings provide a reliable\nbasis for improving the operational resilience of building integrated energy\nsystems under extreme weather scenarios.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T11:48:55Z"}
{"aid":"http://arxiv.org/abs/2504.11107v1","title":"An Invariance Principle for some Reaction-Diffusion Equations with a\n  Multiplicative Random Source","summary":"We establish a notion of universality for the parabolic Anderson model via an\ninvariance principle for a wide family of parabolic stochastic partial\ndifferential equations. We then use this invariance principle in order to\nprovide an asymptotic theory for a wide class of non-linear SPDEs. A novel\ningredient of this invariance principle is the dissipativity of the underlying\nstochastic PDE.","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T11:55:05Z"}
{"aid":"http://arxiv.org/abs/2504.11120v1","title":"Improved approximation ratios for the Quantum Max-Cut problem on\n  general, triangle-free and bipartite graphs","summary":"We study polynomial-time approximation algorithms for the Quantum Max-Cut\n(QMC) problem. Given an edge-weighted graph $G$ on n vertices, the QMC problem\nis to determine the largest eigenvalue of a particular $2^n \\times 2^n$ matrix\nthat corresponds to $G$. We provide a sharpened analysis of the currently\nbest-known QMC approximation algorithm for general graphs. This algorithm\nachieves an approximation ratio of $0.599$, which our analysis improves to\n$0.603$. Additionally, we propose two new approximation algorithms for the QMC\nproblem on triangle-free and bipartite graphs, that achieve approximation\nratios of $0.61383$ and $0.8162$, respectively. These are the best-known\napproximation ratios for their respective graph classes.","main_category":"quant-ph","categories":"quant-ph,math.OC","published":"2025-04-15T12:08:07Z"}
{"aid":"http://arxiv.org/abs/2504.11128v1","title":"K-means Enhanced Density Gradient Analysis for Urban and Transport\n  Metrics Using Multi-Modal Satellite Imagery","summary":"This paper presents a novel computational approach for evaluating urban\nmetrics through density gradient analysis using multi-modal satellite imagery,\nwith applications including public transport and other urban systems. By\ncombining optical and Synthetic Aperture Radar (SAR) data, we develop a method\nto segment urban areas, identify urban centers, and quantify density gradients.\nOur approach calculates two key metrics: the density gradient coefficient\n($\\alpha$) and the minimum effective distance (LD) at which density reaches a\ntarget threshold. We further employ machine learning techniques, specifically\nK-means clustering, to objectively identify uniform and high-variability\nregions within density gradient plots. We demonstrate that these metrics\nprovide an effective screening tool for public transport analyses by revealing\nthe underlying urban structure. Through comparative analysis of two\nrepresentative cities with contrasting urban morphologies (monocentric vs\npolycentric), we establish relationships between density gradient\ncharacteristics and public transport network topologies. Cities with clear\ndensity peaks in their gradient plots indicate distinct urban centers requiring\ndifferent transport strategies than those with more uniform density\ndistributions. This methodology offers urban planners a cost-effective,\nglobally applicable approach to preliminary public transport assessment using\nfreely available satellite data. The complete implementation, with additional\nexamples and documentation, is available in an open-source repository under the\nMIT license at https://github.com/nexri/Satellite-Imagery-Urban-Analysis.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-15T12:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.11129v1","title":"$R$-matrix type parametrization of the Jost function for extracting the\n  resonance parameters from scattering data","summary":"A new method is proposed for fitting non-relativistic binary-scattering data\nand for extracting the parameters of possible quantum resonances in the\ncompound system that is formed during the collision. The method combines the\nwell-known $R$-matrix approach with the analysis based on the semi-analytic\nrepresentation of the Jost functions. It is shown that such a combination has\nthe advantages of both these approaches, namely, the number of the fitting\nparameters remains relatively small (as for the $R$-matrix approach) and the\nproper analytic structure of the $S$-matrix is preserved (as for the Jost\nfunction method). It is also shown that the new formalism, although closely\nrelated to the $R$-matrix method, has the benefit of no dependence on an\narbitrary channel radius. The efficiency and accuracy of the proposed method\nare tested using a model single-channel potential. Artificial ``experimental''\ndata generated with this potential are fitted, and its known resonances are\nsuccessfully recovered as zeros of the Jost function on the appropriate sheet\nof the Riemann surface of the energy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T12:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.11136v1","title":"Structure of some mapping spaces","summary":"We prove that the path space of a differentiable manifold is diffeomorphic to\na Fr\\'echet space, endowing the path space with a linear structure.\nFurthermore, the base point preserving mapping space consisting of maps from a\ncube to a differentiable manifold is also diffeomorphic to a Fr\\'echet space.\nAs a corollary of a more general theorem, we prove that the path fibration\nbecomes a fibre bundle for manifolds M. Additionally, we discuss the mapping\nspace from a compact topological space to a differentiable manifold,\ndemonstrating that this space admits the structure of a smooth Banach manifold.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T12:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.11147v1","title":"Robust Bayesian Inference for Censored Survival Models","summary":"This paper proposes a robust Bayesian accelerated failure time model for\ncensored survival data. We develop a new family of life-time distributions\nusing a scale mixture of the generalized gamma distributions, where we propose\na novel super heavy-tailed distribution as a mixing density. We theoretically\nshow that, under some conditions, the proposed method satisfies the full\nposterior robustness, which guarantees robustness of point estimation as well\nas uncertainty quantification. For posterior computation, we employ an integral\nexpression of the proposed heavy-tailed distribution to develop an efficient\nposterior computation algorithm based on the Markov chain Monte Carlo. The\nperformance of the proposed method is illustrated through numerical experiments\nand real data example.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-15T12:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.11148v1","title":"Super time-resolved tomography","summary":"Understanding 3D fundamental processes is crucial for academic and industrial\napplications. Nowadays, X-ray time-resolved tomography, or tomoscopy, is a\nleading technique for in-situ and operando 4D (3D+time) characterization.\nDespite its ability to achieve 1000 tomograms per second at large-scale X-ray\nfacilities, its applicability is limited by the centrifugal forces exerted on\nsamples and the challenges of developing suitable environments for such\nhigh-speed studies. Here, we introduce STRT, an approach that has the potential\nto enhance the temporal resolution of tomoscopy by at least an order of\nmagnitude while preserving spatial resolution. STRT exploits a 4D DL\nreconstruction algorithm to produce high-fidelity 3D reconstructions at each\ntime point, retrieved from a significantly reduced angular range of a few\ndegrees compared to the 0-180 degrees of traditional tomoscopy. Thus, STRT\nenhances the temporal resolution compared to tomoscopy by a factor equal to the\nratio between 180 degrees and the angular ranges used by STRT. In this work, we\nvalidate the 4D capabilities of STRT through simulations and experiments on\ndroplet collision simulations and additive manufacturing processes. We\nanticipate that STRT will significantly expand the capabilities of 4D X-ray\nimaging, enabling previously unattainable studies in both academic and\nindustrial contexts, such as materials formation and mechanical testing.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T12:49:19Z"}
{"aid":"http://arxiv.org/abs/2504.11151v1","title":"Magnetic uniform resolvent estimates","summary":"We establish uniform $L^{p}-L^{q}$ resolvent estimates for magnetic\nSchr\\\"odinger operators $H=(i\\partial+A(x))^2+V(x)$ in dimension $n \\geq 3$.\nUnder suitable decay conditions on the electromagnetic potentials, we prove\nthat for all $z \\in \\mathbb{C}\\setminus[0,+\\infty)$ with $|\\Im z| \\leq 1$, the\nresolvent satisfies \\begin{equation*}\n\\|(H-z)^{-1}\\phi\\|_{L^{q}}\\lesssim|z|^{\\theta(p,q)} (1+|z|^{\\frac 12\n\\frac{n-1}{n+1}}) \\|\\phi\\|_{L^{p}} \\end{equation*} where\n$\\theta(p,q)=\\frac{n}{2}(\\frac{1}{p}-\\frac{1}{q})-1$. This extends previous\nresults by providing estimates valid for all frequencies with explicit\ndependence on $z$, covering the same optimal range of indices as the free\nLaplacian case, and including weak endpoint estimates. We also derive a variant\nwith less stringent decay assumptions when restricted to a smaller parameter\nrange. As an application, we establish the first $L^p-L^{p'}$ bounds for the\nspectral measure of magnetic Schr\\\"odinger operators.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-15T12:53:09Z"}
{"aid":"http://arxiv.org/abs/2504.11166v1","title":"Adjustable Molecular Cross-Linkage of MXene Layers for Tunable Charge\n  Transport and VOC Sensing","summary":"MXenes, two-dimensional transition metal carbides, nitrides or carbonitrides,\nare emerging as highly promising materials due to their remarkable charge\ntransport characteristics and their versatile surface chemistry. Herein, we\ndemonstrate the tunability of interfaces and the inter-layer spacing between\nTi$_3$C$_2$T$_X$ MXene flakes through molecular cross-linking via ligand\nexchange with homologous diamines. Oleylamine was initially introduced as a\nligand, to facilitate the delamination and stable dispersion of pristine\nTi$_3$C$_2$T$_X$ flakes in chloroform. Subsequently, controlled cross-linkage\nof the flakes was achieved using diamine ligands with varying aliphatic chain\nlengths, enabling the precise tuning of the inter-layer spacing. Grazing\nincidence X-ray scattering (GIXRD / GIWAXS) confirmed the correlation between\nligand chain length and inter-layer spacing, which was further supported by\nDensity Functional Theory (DFT) calculations. Furthermore, we investigated the\ncharge transport properties of thin films consisting of these diamine\ncross-linked MXenes and observed a strong dependence of the conductivity on the\ninterlayer spacing. Finally, we probed chemiresistive vapor sensing properties\nof the MXene composites and observed a pronounced sensitivity and selectivity\ntowards water vapor, highlighting their potential for use in humidity sensors.\nProviding significant insights into molecular cross-linking of MXenes to form\nhybrid inorganic/organic composites and its consequences for charge transport,\nthis study opens avenues for the development of next-generation MXene-based\nelectronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-15T13:14:32Z"}
{"aid":"http://arxiv.org/abs/2504.11178v1","title":"MeerKAT 1.3 GHz Observations Towards the Milky Way Bulge","summary":"We present a MeerKAT survey of portions of the Milky Way bulge. The survey\ncovers 172.8 square degrees in two contiguous mosaics above and below the\nGalactic Center as well as 32 single pointing fields at higher longitudes. The\nresolution of the images is $\\sim$8\\asec\\ at a frequency of 1333 MHz with a\ntypical Stokes I RMS of 20 $\\mu$Jy Beam$^{-1}$. Most of the emission seen is\nfrom background extragalactic sources but many compact Galactic objects are\nidentifiable by their polarization properties. Apparent polarized emission\nresulting from fine scale Faraday rotation in the ISM is widespread in this\nregion of the Galaxy. The survey is used to search for background Giant Radio\nGalaxies, $>$700 kpc in size, identifying 17 such objects. Data products\ninclude FITS images of Stokes I, Q, U and V as well as a Faraday analysis and\nlists of compact total intensity and polarized sources.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T13:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.11211v1","title":"Instability of the Standing Pulse in Skew-Gradient Systems and Its\n  Application to FitzHugh-Nagumo Type Systems","summary":"In this paper, we use the Maslov index to obtain a lower bound on the number\nof unstable eigenvalues associated with standing pulse solutions in\nskew-gradient systems. Based on this, we establish an instability criterion for\nthe standing pulse. As an application, the results are applied to\nFitzHugh-Nagumo type systems, in which the activator and inhibitor reaction\nterms exhibit inherent nonlinear structures.","main_category":"math.AP","categories":"math.AP,math.DS","published":"2025-04-15T14:13:21Z"}
{"aid":"http://arxiv.org/abs/2504.11229v1","title":"The Forward-Forward Algorithm: Characterizing Training Behavior","summary":"The Forward-Forward algorithm is an alternative learning method which\nconsists of two forward passes rather than a forward and backward pass employed\nby backpropagation. Forward-Forward networks employ layer local loss functions\nwhich are optimized based on the layer activation for each forward pass rather\nthan a single global objective function. This work explores the dynamics of\nmodel and layer accuracy changes in Forward-Forward networks as training\nprogresses in pursuit of a mechanistic understanding of their internal\nbehavior. Treatments to various system characteristics are applied to\ninvestigate changes in layer and overall model accuracy as training progresses,\nhow accuracy is impacted by layer depth, and how strongly individual layer\naccuracy is correlated with overall model accuracy. The empirical results\npresented suggest that layers deeper within Forward-Forward networks experience\na delay in accuracy improvement relative to shallower layers and that shallower\nlayer accuracy is strongly correlated with overall model accuracy.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T14:30:18Z"}
{"aid":"http://arxiv.org/abs/2504.11244v1","title":"Multireference covariant density functional theory for shape coexistence\n  and isomerism in $^{43}$S","summary":"We extend the multireference covariant density functional theory (MR-CDFT) to\ndescribe the low-lying states of the odd-mass nucleus $^{43}$S near the neutron\nmagic number $N=28$ with shape coexistence. The wave functions of the low-lying\nstates are constructed as superpositions of configurations with different\nintrinsic shapes and $K$ quantum numbers, projected onto good particle numbers\nand angular momenta. The MR-CDFT successfully reproduces the main features of\nthe low-energy structure in $^{43}$S. Our results indicate that the ground\nstate, $3/2^-_1$, is predominantly composed of the intruder prolate\none-quasiparticle (1qp) configuration $\\nu1/2^-[321]$. In contrast, the\n$7/2^-_1$ state is identified as a high-$K$ isomer, primarily built on the\nprolate 1qp configuration $\\nu7/2^-[303]$. Additionally, the $3/2^-_2$ state is\nfound to be an admixture dominated by an oblate configuration with $K^\\pi =\n1/2^-$, along with a small contribution from a prolate configuration with\n$K^\\pi = 3/2^-$. These results demonstrate the capability of MR-CDFT to capture\nthe intricate interplay among shape coexistence, $K$-mixing, and isomerism in\nthe low-energy structure of odd-mass nuclei around $N = 28$.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-15T14:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.11251v1","title":"Easy repair via codes with simplex locality","summary":"In the context of distributed storage systems, locally repairable codes have\nbecome important. In this paper we focus on codes that allow for multi-erasure\npattern decoding with low computational effort. Different optimality\nrequirements, measured by the code's rate, minimum distance, locality,\navailability as well as field size, influence each other and can not all be\nmaximized at the same time. We focus on the notion of easy repair, more\nspecifically on the construction of codes that can repair correctable erasure\npatterns with minimal computational effort. In particular, we introduce the\neasy repair property and then present codes of different rates that possess\nthis property. The presented codes are all in some way related to simplex codes\nand comprise block codes as well as unit-memory convolutional codes. We also\nformulate conditions under which the easy repairs can be performed in parallel,\nthus improving access speed of the distributed storage system.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-15T14:47:22Z"}
{"aid":"http://arxiv.org/abs/2504.11256v1","title":"Covering Approximate Shortest Paths with DAGs","summary":"We define and study analogs of probabilistic tree embedding and tree cover\nfor directed graphs. We define the notion of a DAG cover of a general directed\ngraph $G$: a small collection $D_1,\\dots D_g$ of DAGs so that for all pairs of\nvertices $s,t$, some DAG $D_i$ provides low distortion for $dist(s,t)$; i.e. $\ndist_G(s, t) \\le \\min_{i \\in [g]} dist_{D_i}(s, t) \\leq \\alpha \\cdot dist_G(s,\nt)$, where $\\alpha$ is the distortion.\n  As a trivial upper bound, there is a DAG cover with $n$ DAGs and $\\alpha=1$\nby taking the shortest-paths tree from each vertex. When each DAG is restricted\nto be a subgraph of $G$, there is a matching lower bound (via a directed cycle)\nthat $n$ DAGs are necessary, even to preserve reachability. Thus, we allow the\nDAGs to include a limited number of additional edges not in the original graph.\n  When $n^2$ additional edges are allowed, there is a simple upper bound of two\nDAGs and $\\alpha=1$. Our first result is an almost-matching lower bound that\neven for $n^{2-o(1)}$ additional edges, at least $n^{1-o(1)}$ DAGs are needed,\neven to preserve reachability. However, the story is different when the number\nof additional edges is $\\tilde{O}(m)$, a natural setting where the sparsity of\nthe DAG collection nearly matches the original graph. Our main upper bound is\nthat there is a near-linear time algorithm to construct a DAG cover with\n$\\tilde{O}(m)$ additional edges, polylogarithmic distortion, and only $O(\\log\nn)$ DAGs. This is similar to known results for undirected graphs: the\nwell-known FRT probabilistic tree embedding implies a tree cover where both the\nnumber of trees and the distortion are logarithmic. Our algorithm also extends\nto a certain probabilistic embedding guarantee. Lastly, we complement our upper\nbound with a lower bound showing that achieving a DAG cover with no distortion\nand $\\tilde{O}(m)$ additional edges requires a polynomial number of DAGs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-15T14:55:26Z"}
{"aid":"http://arxiv.org/abs/2504.11273v1","title":"Hybrid Compton-PET Imaging for ion-range verification:A Preclinical\n  Study for Proton-, Helium-, and Carbon-Therapy at HIT","summary":"Enhanced-accuracy ion-range verification in real time shall enable a\nsignificant step forward in the use of therapeutic ion beams. Positron-emission\ntomography (PET) and prompt-gamma imaging (PGI) are two of the most promising\nand researched methodologies, both of them with their own advantages and\nchallenges. Thus far, both of them have been explored for ion-range\nverification in an independent way. However, the simultaneous combination of\nPET and PGI within the same imaging framework may open-up the possibility to\nexploit more efficiently all radiative emissions excited in the tissue by the\nion beam. Here we report on the first pre-clinical implementation of an hybrid\nPET-PGI imaging system, hereby exploring its performance over several ion-beam\nspecies (H, He and C), energies (55 MeV to 275 MeV) and intensities\n(10$^7$-10$^9$ ions/spot), which are representative of clinical conditions. The\nmeasurements were carried out using the pencil-beam scanning technique at the\nsynchrotron accelerator of the Heavy Ion Therapy centre in Heidelberg utilizing\nan array of four Compton cameras in a twofold front-to-front configuration. The\nresults demonstrate that the hybrid PET-PGI technique can be well suited for\nrelatively low energies (55-155 MeV) and beams of protons. On the other hand,\nfor heavier beams of helium and carbon ions at higher energies (155-275 MeV),\nrange monitoring becomes more challenging owing to large backgrounds from\nadditional nuclear processes. The experimental results are well understood on\nthe basis of realistic Monte Carlo (MC) calculations, which show a satisfactory\nagreement with the measured data. This work can guide further upgrades of the\nhybrid PET-PGI system towards a clinical implementation of this innovative\ntechnique.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.ins-det","published":"2025-04-15T15:14:28Z"}
{"aid":"http://arxiv.org/abs/2504.11278v1","title":"Towards dimensions and granularity in a unified workflow and data\n  provenance framework","summary":"Provenance information are essential for the traceability of scientific\nstudies or experiments and thus crucial for ensuring the credibility and\nreproducibility of research findings. This paper discusses a comprehensive\nprovenance framework combining the two types 1. workflow provenance, and 2.\ndata provenance as well as their dimensions and granularity, which enables the\nanswering of W7+1 provenance questions. We demonstrate the applicability by\nemploying a biomedical research use case, that can be easily transferred into\nother scientific fields. An integration of these concepts into a unified\nframework enables credibility and reproducibility of the research findings.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T15:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.11280v1","title":"PGU-SGP: A Pheno-Geno Unified Surrogate Genetic Programming For\n  Real-life Container Terminal Truck Scheduling","summary":"Data-driven genetic programming (GP) has proven highly effective in solving\ncombinatorial optimization problems under dynamic and uncertain environments. A\ncentral challenge lies in fast fitness evaluations on large training datasets,\nespecially for complex real-world problems involving time-consuming\nsimulations. Surrogate models, like phenotypic characterization (PC)-based\nK-nearest neighbors (KNN), have been applied to reduce computational cost.\nHowever, the PC-based similarity measure is confined to behavioral\ncharacteristics, overlooking genotypic differences, which can limit surrogate\nquality and impair performance. To address these issues, this paper proposes a\npheno-geno unified surrogate GP algorithm, PGU-SGP, integrating phenotypic and\ngenotypic characterization (GC) to enhance surrogate sample selection and\nfitness prediction. A novel unified similarity metric combining PC and GC\ndistances is proposed, along with an effective and efficient GC representation.\nExperimental results of a real-life vehicle scheduling problem demonstrate that\nPGU-SGP reduces training time by approximately 76% while achieving comparable\nperformance to traditional GP. With the same training time, PGU-SGP\nsignificantly outperforms traditional GP and the state-of-the-art algorithm on\nmost datasets. Additionally, PGU-SGP shows faster convergence and improved\nsurrogate quality by maintaining accurate fitness rankings and appropriate\nselection pressure, further validating its effectiveness.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-15T15:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.11289v1","title":"UniAnimate-DiT: Human Image Animation with Large-Scale Video Diffusion\n  Transformer","summary":"This report presents UniAnimate-DiT, an advanced project that leverages the\ncutting-edge and powerful capabilities of the open-source Wan2.1 model for\nconsistent human image animation. Specifically, to preserve the robust\ngenerative capabilities of the original Wan2.1 model, we implement Low-Rank\nAdaptation (LoRA) technique to fine-tune a minimal set of parameters,\nsignificantly reducing training memory overhead. A lightweight pose encoder\nconsisting of multiple stacked 3D convolutional layers is designed to encode\nmotion information of driving poses. Furthermore, we adopt a simple\nconcatenation operation to integrate the reference appearance into the model\nand incorporate the pose information of the reference image for enhanced pose\nalignment. Experimental results show that our approach achieves visually\nappearing and temporally consistent high-fidelity animations. Trained on 480p\n(832x480) videos, UniAnimate-DiT demonstrates strong generalization\ncapabilities to seamlessly upscale to 720P (1280x720) during inference. The\ntraining and inference code is publicly available at\nhttps://github.com/ali-vilab/UniAnimate-DiT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.11295v1","title":"Autoregressive Distillation of Diffusion Transformers","summary":"Diffusion models with transformer architectures have demonstrated promising\ncapabilities in generating high-fidelity images and scalability for high\nresolution. However, iterative sampling process required for synthesis is very\nresource-intensive. A line of work has focused on distilling solutions to\nprobability flow ODEs into few-step student models. Nevertheless, existing\nmethods have been limited by their reliance on the most recent denoised samples\nas input, rendering them susceptible to exposure bias. To address this\nlimitation, we propose AutoRegressive Distillation (ARD), a novel approach that\nleverages the historical trajectory of the ODE to predict future steps. ARD\noffers two key benefits: 1) it mitigates exposure bias by utilizing a predicted\nhistorical trajectory that is less susceptible to accumulated errors, and 2) it\nleverages the previous history of the ODE trajectory as a more effective source\nof coarse-grained information. ARD modifies the teacher transformer\narchitecture by adding token-wise time embedding to mark each input from the\ntrajectory history and employs a block-wise causal attention mask for training.\nFurthermore, incorporating historical inputs only in lower transformer layers\nenhances performance and efficiency. We validate the effectiveness of ARD in a\nclass-conditioned generation on ImageNet and T2I synthesis. Our model achieves\na $5\\times$ reduction in FID degradation compared to the baseline methods while\nrequiring only 1.1\\% extra FLOPs on ImageNet-256. Moreover, ARD reaches FID of\n1.84 on ImageNet-256 in merely 4 steps and outperforms the publicly available\n1024p text-to-image distilled models in prompt adherence score with a minimal\ndrop in FID compared to the teacher. Project page:\nhttps://github.com/alsdudrla10/ARD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.11305v1","title":"CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable\n  Wood Defect Detection","summary":"Wood defect detection is critical for ensuring quality control in the wood\nprocessing industry. However, current industrial applications face two major\nchallenges: traditional methods are costly, subjective, and labor-intensive,\nwhile mainstream deep learning models often struggle to balance detection\naccuracy and computational efficiency for edge deployment. To address these\nissues, this study proposes CFIS-YOLO, a lightweight object detection model\noptimized for edge devices. The model introduces an enhanced C2f structure, a\ndynamic feature recombination module, and a novel loss function that\nincorporates auxiliary bounding boxes and angular constraints. These\ninnovations improve multi-scale feature fusion and small object localization\nwhile significantly reducing computational overhead. Evaluated on a public wood\ndefect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of\n77.5\\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON\nBM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to\n17.3\\% of the original implementation, and incurs only a 0.5 percentage point\ndrop in mAP. These results demonstrate that CFIS-YOLO is a practical and\neffective solution for real-world wood defect detection in resource-constrained\nenvironments.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T15:45:59Z"}
{"aid":"http://arxiv.org/abs/2504.11306v1","title":"Context-Aware Palmprint Recognition via a Relative Similarity Metric","summary":"We propose a new approach to matching mechanism for palmprint recognition by\nintroducing a Relative Similarity Metric (RSM) that enhances the robustness and\ndiscriminability of existing matching frameworks. While conventional systems\nrely on direct pairwise similarity measures, such as cosine or Euclidean\ndistances, these metrics fail to capture how a pairwise similarity compares\nwithin the context of the entire dataset. Our method addresses this by\nevaluating the relative consistency of similarity scores across up to all\nidentities, allowing for better suppression of false positives and negatives.\nApplied atop the CCNet architecture, our method achieves a new state-of-the-art\n0.000036% Equal Error Rate (EER) on the Tongji dataset, outperforming previous\nmethods and demonstrating the efficacy of incorporating relational structure\ninto the palmprint matching process.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:46:17Z"}
{"aid":"http://arxiv.org/abs/2504.11307v1","title":"Uncertainty Estimation for Trust Attribution to Speed-of-Sound\n  Reconstruction with Variational Networks","summary":"Speed-of-sound (SoS) is a biomechanical characteristic of tissue, and its\nimaging can provide a promising biomarker for diagnosis. Reconstructing SoS\nimages from ultrasound acquisitions can be cast as a limited-angle\ncomputed-tomography problem, with Variational Networks being a promising\nmodel-based deep learning solution. Some acquired data frames may, however, get\ncorrupted by noise due to, e.g., motion, lack of contact, and acoustic shadows,\nwhich in turn negatively affects the resulting SoS reconstructions. We propose\nto use the uncertainty in SoS reconstructions to attribute trust to each\nindividual acquired frame. Given multiple acquisitions, we then use an\nuncertainty based automatic selection among these retrospectively, to improve\ndiagnostic decisions. We investigate uncertainty estimation based on Monte\nCarlo Dropout and Bayesian Variational Inference. We assess our automatic frame\nselection method for differential diagnosis of breast cancer, distinguishing\nbetween benign fibroadenoma and malignant carcinoma. We evaluate 21 lesions\nclassified as BI-RADS~4, which represents suspicious cases for probable\nmalignancy. The most trustworthy frame among four acquisitions of each lesion\nwas identified using uncertainty based criteria. Selecting a frame informed by\nuncertainty achieved an area under curve of 76% and 80% for Monte Carlo Dropout\nand Bayesian Variational Inference, respectively, superior to any\nuncertainty-uninformed baselines with the best one achieving 64%. A novel use\nof uncertainty estimation is proposed for selecting one of multiple data\nacquisitions for further processing and decision making.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:48:51Z"}
{"aid":"http://arxiv.org/abs/2504.11308v1","title":"Constraints on Generalized Gravity-Thermodynamic Cosmology from DESI DR2","summary":"We explore the cosmological implications of generalized entropic models\nwithin the framework of Gravity-Thermodynamics (GT) approaches. These models,\ncharacterized by three or four additional free parameters, are designed to\ncapture deviations from the standard Bekenstein-Hawking entropy and can\nreproduce well-known entropic formulations, including Tsallis, R\\'enyi,\nSharma-Mittal, Barrow, Kaniadakis, and Loop Quantum Gravity entropies in\nvarious analytical limits. We implement the corresponding cosmological models\nusing a fully numerical GT approach to constrain the model parameters and to\nstudy the evolution of the dark energy equation of state as a function of the\nscale factor. Our Bayesian analysis, which incorporates the Pantheon+ and DESy5\nsupernovae data alongside the recently released DESI-DR2/DR1 Baryon Acoustic\nOscillation (BAO) measurements, shows that the data favor the standard\nBekenstein-Hawking entropy, leading to a $\\Lambda$CDM-like late-time behavior.\nIn this context, the three-parameter ($\\mathcal{S}_3$) entropic model appears\nto be sufficient to capture the observed dark energy phenomenology.\nFurthermore, a direct comparison of the Bayesian evidence indicates that the\nthree-parameter model is preferred over the four-parameter ($\\mathcal{S}_4$)\nvariant by a factor of $\\Delta\\log\\mathcal{B} \\sim -6$, while the GT approach\nas a whole is significantly disfavored relative to the $\\Lambda$CDM model with\nat least $\\Delta\\log\\mathcal{B} \\sim -8$ ($\\mathcal{S}_3$) to\n$\\Delta\\log\\mathcal{B} \\sim -13$ ($\\mathcal{S}_4$), when using the DESy5 and\nDESI-DR2 datasets.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-15T15:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.11321v1","title":"Subset-Contrastive Multi-Omics Network Embedding","summary":"Motivation: Network-based analyses of omics data are widely used, and while\nmany of these methods have been adapted to single-cell scenarios, they often\nremain memory- and space-intensive. As a result, they are better suited to\nbatch data or smaller datasets. Furthermore, the application of network-based\nmethods in multi-omics often relies on similarity-based networks, which lack\nstructurally-discrete topologies. This limitation may reduce the effectiveness\nof graph-based methods that were initially designed for topologies with better\ndefined structures. Results: We propose Subset-Contrastive multi-Omics Network\nEmbedding (SCONE), a method that employs contrastive learning techniques on\nlarge datasets through a scalable subgraph contrastive approach. By exploiting\nthe pairwise similarity basis of many network-based omics methods, we\ntransformed this characteristic into a strength, developing an approach that\naims to achieve scalable and effective analysis. Our method demonstrates\nsynergistic omics integration for cell type clustering in single-cell data.\nAdditionally, we evaluate its performance in a bulk multi-omics integration\nscenario, where SCONE performs comparable to the state-of-the-art despite\nutilising limited views of the original data. We anticipate that our findings\nwill motivate further research into the use of subset contrastive methods for\nomics data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T16:01:39Z"}
{"aid":"http://arxiv.org/abs/2504.11329v1","title":"Hunting for Maxwell's Demon in the Wild","summary":"The apparent paradox of Maxwell's demon motivated the development of\ninformation thermodynamics and, more recently, engineering advances enabling\nthe creation of nanoscale information engines. From these advances, it is now\nunderstood that nanoscale machines like the molecular motors within cells can\nin principle operate as Maxwell demons. This motivates the question: does\ninformation help power molecular motors? Answering this would seemingly require\nsimultaneous measurement of all system degrees of freedom, which is generally\nintractable in single-molecule experiments. To overcome this limitation, we\nderive a statistical estimator to infer both the direction and magnitude of\nsubsystem heat flows, and thus to determine whether -- and how strongly -- a\nmotor operates as a Maxwell demon. The estimator uses only trajectory\nmeasurements for a single degree of freedom. We demonstrate the estimator by\napplying it to simulations of an experimental realization of an information\nengine and a kinesin molecular motor. Our results show that kinesin transitions\nto a Maxwell-demon mechanism in the presence of nonequilibrium noise, with a\ncorresponding increase in velocity consistent with experiments. These findings\nsuggest that molecular motors may have evolved to leverage active fluctuations\nwithin cells.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,physics.bio-ph","published":"2025-04-15T16:03:10Z"}
{"aid":"http://arxiv.org/abs/2504.11333v1","title":"Implicit dual time-stepping positivity-preserving entropy-stable schemes\n  for the compressible Navier-Stokes equations","summary":"We generalize the explicit high-order positivity-preserving entropy-stable\nspectral collocation schemes developed in [30, 34] for the three-dimensional\n(3D) compressible Navier Stokes equations to a time implicit formulation. The\ntime derivative terms are discretized by using the first- and second-order\nimplicit backward difference formulas (BDF1 and BDF2) that are well suited for\nsolving steady-state and time-dependent viscous flows at high Reynolds numbers,\nrespectively. The nonlinear system of discrete equations at each physical\ntimestep is solved by using a dual time-stepping technique. The proposed scheme\nis provably entropy-stable and positivity-preserving and provides unconditional\nstability properties in the physical time. Numerical results demonstrating\naccuracy and positivity-preserving properties of the new dual time-stepping\nscheme are presented for supersonic viscous flows with strong shock waves and\ncontact discontinuities.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T16:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.11349v1","title":"Explicit and Implicit Representations in AI-based 3D Reconstruction for\n  Radiology: A systematic literature review","summary":"The demand for high-quality medical imaging in clinical practice and assisted\ndiagnosis has made 3D reconstruction in radiological imaging a key research\nfocus. Artificial intelligence (AI) has emerged as a promising approach to\nenhancing reconstruction accuracy while reducing acquisition and processing\ntime, thereby minimizing patient radiation exposure and discomfort and\nultimately benefiting clinical diagnosis. This review explores state-of-the-art\nAI-based 3D reconstruction algorithms in radiological imaging, categorizing\nthem into explicit and implicit approaches based on their underlying\nprinciples. Explicit methods include point-based, volume-based, and Gaussian\nrepresentations, while implicit methods encompass implicit prior embedding and\nneural radiance fields. Additionally, we examine commonly used evaluation\nmetrics and benchmark datasets. Finally, we discuss the current state of\ndevelopment, key challenges, and future research directions in this evolving\nfield. Our project available on: https://github.com/Bean-Young/AI4Med.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.GR,I.4.5","published":"2025-04-15T16:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.11372v1","title":"A Review of Traffic Wave Suppression Strategies: Variable Speed Limit\n  vs. Jam-Absorption Driving","summary":"The main form of freeway traffic congestion is the familiar stop-and-go wave,\ncharacterized by wide moving jams that propagate indefinitely upstream provided\nenough traffic demand. They cause severe, long-lasting adverse effects, such as\nreduced traffic efficiency, increased driving risks, and higher vehicle\nemissions. This underscores the crucial importance of artificial intervention\nin the propagation of stop-and-go waves. Over the past two decades, two\nprominent strategies for stop-and-go wave suppression have emerged: variable\nspeed limit (VSL) and jam-absorption driving (JAD). Although they share similar\nresearch motivations, objectives, and theoretical foundations, the development\nof these strategies has remained relatively disconnected. To synthesize\nfragmented advances and drive the field forward, this paper first provides a\ncomprehensive review of the achievements in the stop-and-go wave\nsuppression-oriented VSL and JAD, respectively. It then focuses on bridging the\ntwo areas and identifying research opportunities from the following\nperspectives: fundamental diagrams, traffic dynamics modeling, traffic state\nestimation and prediction, stochasticity, scenarios for strategy validation,\nand field tests and practical deployment. We expect that through this review,\none area can effectively address its limitations by identifying and leveraging\nthe strengths of the other, thus promoting the overall research goal of freeway\nstop-and-go wave suppression.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.SY,eess.SY,stat.AP","published":"2025-04-15T16:37:23Z"}
{"aid":"http://arxiv.org/abs/2504.11380v1","title":"Speak with Confidence: Designing an Augmented Reality Training Tool for\n  Public Speaking","summary":"Public speaking anxiety affects many individuals, yet opportunities for\nreal-world practice remain limited. This study explores how augmented reality\n(AR) can provide an accessible training environment for public speaking.\nDrawing from literature on public speaking, VR-based training, self-efficacy,\nand behavioral feedback mechanisms, we designed SpeakAR, an AR-based tool that\nsimulates audience interaction through virtual models. SpeakAR was evaluated\nwith five participants of varying anxiety levels, each completing six speaking\ntasks. Results indicate that AR exposure can enhance confidence, with\nparticipants finding the system useful for practice. Feedback highlighted the\nimportance of dynamic facial expressions and idle animations in virtual models\nto improve realism and engagement. Our findings contribute to the design of\nAR-based training tools for public speaking, offering insights into how\nimmersive environments can support skill development and anxiety reduction.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-15T16:53:30Z"}
{"aid":"http://arxiv.org/abs/2504.11392v1","title":"Probing General Relativity-Induced Decoherence Using an on-chip Sagnac\n  Interferometer","summary":"The intersection of quantum mechanics and general relativity remains an open\nfrontier in fundamental physics, with few experimentally accessible phenomena\nconnecting the two. Recent theoretical proposals suggest that relativistic\nproper time can act as a source of decoherence in quantum systems, providing a\ntestable overlap between the two theories. Here, we propose a chip-integrated\nSagnac interferometer where rotation induces a proper time difference between\nclockwise and counterclockwise single-photon paths. When this time delay\nexceeds the photon's coherence time, interference visibility is predicted to\ndecrease, offering a direct signature of relativistic time dilation-induced\ndecoherence. We theoretically derive the proper time difference arising from\nthe Sagnac effect and estimate that for a loop radius of 18.9 cm and a rotation\nspeed of 1000 rad/s, decoherence should occur for single-photon wavepackets\nwith a coherence time of 10 femtoseconds. We also present a practical chip\ndesign that accommodates the required high-speed mechanical rotation and\nincludes an all-optical readout scheme to eliminate wiring constraints. This\napproach enables a stable, on-chip implementation using realistic parameters,\nwith rotation speed serving as a continuously tunable knob to control\ndecoherence. Our platform opens a new route for experimentally probing the\ninterplay between quantum coherence and relativistic proper time in a scalable\nand compact form.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-15T17:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.11400v1","title":"FlowUnits: Extending Dataflow for the Edge-to-Cloud Computing Continuum","summary":"This paper introduces FlowUnits, a novel programming and deployment model\nthat extends the traditional dataflow paradigm to address the unique challenges\nof edge-to-cloud computing environments. While conventional dataflow systems\noffer significant advantages for large-scale data processing in homogeneous\ncloud settings, they fall short when deployed across distributed, heterogeneous\ninfrastructures. FlowUnits addresses three critical limitations of current\napproaches: lack of locality awareness, insufficient resource adaptation, and\nabsence of dynamic update mechanisms. FlowUnits organize processing operators\ninto cohesive, independently manageable components that can be transparently\nreplicated across different regions, efficiently allocated on nodes with\nappropriate hardware capabilities, and dynamically updated without disrupting\nongoing computations. We implement and evaluate the FlowUnits model within\nRenoir, an existing dataflow system, demonstrating significant improvements in\ndeployment flexibility and resource utilization across the computing continuum.\nOur approach maintains the simplicity of dataflow while enabling seamless\nintegration of edge and cloud resources into unified data processing pipelines.","main_category":"cs.DC","categories":"cs.DC,cs.SE","published":"2025-04-15T17:14:08Z"}
{"aid":"http://arxiv.org/abs/2504.11402v1","title":"Complex multiannual cycles of Mycoplasma pneumoniae: persistence and the\n  role of stochasticity","summary":"The epidemiological dynamics of Mycoplasma pneumoniae are characterized by\ncomplex and poorly understood multiannual cycles, posing challenges for\nforecasting. Using Bayesian methods to fit a seasonally forced transmission\nmodel to long-term surveillance data from Denmark (1958-1995, 2010-2025), we\ninvestigate the mechanisms driving recurrent outbreaks of M. pneumoniae. The\nperiod of the multiannual cycles (predominantly approx. 5 years in Denmark) are\nexplained as a consequence of the interaction of two time-scales in the system,\none intrinsic and one extrinsic (seasonal). While it provides an excellent fit\nto shorter time series (a few decades), we find that the deterministic model\neventually settles into an annual cycle, failing to reproduce the observed\n4-5-year periodicity long-term. Upon further analysis, the system is found to\nexhibit transient chaos and thus high sensitivity to stochasticity. We show\nthat environmental (but not purely demographic) stochasticity can sustain the\nmulti-year cycles via stochastic resonance. The disruptive effects of COVID-19\nnon-pharmaceutical interventions (NPIs) on M. pneumoniae circulation constitute\na natural experiment on the effects of large perturbations. Consequently, the\neffects of NPIs are included in the model and medium-term predictions are\nexplored. Our findings highlight the intrinsic sensitivity of M. pneumoniae\ndynamics to perturbations and interventions, underscoring the limitations of\ndeterministic epidemic models for long-term prediction. More generally, our\nresults emphasize the potential role of stochasticity as a driver of complex\ncycles across endemic and recurring pathogens.","main_category":"q-bio.PE","categories":"q-bio.PE,nlin.CD","published":"2025-04-15T17:18:10Z"}
{"aid":"http://arxiv.org/abs/2504.11409v1","title":"Efficient Hybrid Language Model Compression through Group-Aware SSM\n  Pruning","summary":"Hybrid LLM architectures that combine Attention and State Space Models (SSMs)\nachieve state-of-the-art accuracy and runtime performance. Recent work has\ndemonstrated that applying compression and distillation to Attention-only\nmodels yields smaller, more accurate models at a fraction of the training cost.\nIn this work, we explore the effectiveness of compressing Hybrid architectures.\nWe introduce a novel group-aware pruning strategy that preserves the structural\nintegrity of SSM blocks and their sequence modeling capabilities. Furthermore,\nwe demonstrate the necessity of such SSM pruning to achieve improved accuracy\nand inference speed compared to traditional approaches. Our compression recipe\ncombines SSM, FFN, embedding dimension, and layer pruning, followed by\nknowledge distillation-based retraining, similar to the MINITRON technique.\nUsing this approach, we compress the Nemotron-H 8B Hybrid model down to 4B\nparameters with up to 40x fewer training tokens. The resulting model surpasses\nthe accuracy of similarly-sized models while achieving 2x faster inference,\nsignificantly advancing the Pareto frontier.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T17:26:29Z"}
{"aid":"http://arxiv.org/abs/2504.11410v1","title":"Randomized block proximal method with locally Lipschitz continuous\n  gradient","summary":"Block-coordinate algorithms are recognized to furnish efficient iterative\nschemes for addressing large-scale problems, especially when the computation of\nfull derivatives entails substantial memory requirements and computational\nefforts. In this paper, we investigate a randomized block proximal gradient\nalgorithm for minimizing the sum of a differentiable function and a separable\nproper lower-semicontinuous function, both possibly nonconvex. In contrast to\nprevious works, we only assume that the partial gradients of the differentiable\nfunction are locally Lipschitz continuous. At each iteration, the method\nadaptively selects a proximal stepsize to satisfy a sufficient decrease\ncondition without prior knowledge of the local Lipschitz moduli of the partial\ngradients of the differentiable function. In addition, we incorporate the\npossibility of conducting an additional linesearch to enhance the performance\nof the algorithm. Our main result establishes subsequential convergence to a\nstationary point of the problem almost surely. Finally, we provide numerical\nvalidation of the method in an experiment in image compression using a\nnonnegative matrix factorization model.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T17:26:40Z"}
{"aid":"http://arxiv.org/abs/2504.11430v1","title":"The 2D Lorentz-violating fermionic Casimir effect under thermal\n  conditions","summary":"In the present work, we explore the dimensional projection method applied to\na fermionic Lorentz invariance violation (LIV) theory with the CPT-even\ndimension-six extension. Due to the dimensional reduction of a fermionic system\nfrom $4D$ to $2D$, it is possible to study the influence of LIV on the Casimir\neffect under the MIT bag boundary condition model in a low-dimensional setting,\nwhere results are obtained without any approximations for a null-temperature\nsystem. Moreover, the Matsubara formalism is applied to derive closed\nexpressions for the influence of temperature on the physical observables:\nCasimir energy, Casimir force, and entropy associated with the system in a LIV\ncontext. For each thermal observable, the influence of the LIV correction term\nis considered in the analysis of both low- and high-temperature regimes.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T17:41:33Z"}
{"aid":"http://arxiv.org/abs/2504.11445v1","title":"Pixel-level modelling of group-scale strong lens CASSOWARY 19","summary":"We present the first high-precision model for the group-scale strong lensing\nsystem CASSOWARY 19 (CSWA19), utilising images from the Hubble Space Telescope\n(HST). Sixteen member galaxies identified via the red-sequence method, and the\nmain halo, all modelled as the dual Pseudo Isothermal Elliptical profile\n(dPIE), are incorporated into a parametric lens model alongside an external\nshear field. To model the system, we adopt the PyAutoLens software package,\nemploying a progressive search chain strategy for realizing the transition of\nsource model from multiple S\\'ersic profiles to a brightness-adaptive\npixelization, which uses 1000 pixels in the source plane to reconstruct the\nbackground source corresponding to 177,144 image pixels in the image plane. Our\nresults indicate that the total mass within the Einstein radius is\n$M_{\\theta_\\mathrm{E}}$ $\\approx 1.41\\times10^{13}$M$_{\\odot}$ and the average\nslope of the total mass density $\\rho (r)\\propto r^{-\\gamma}$ is\n$\\tilde{\\gamma}=1.33$ within the effective radius. This slope is shallower than\nthose measured in galaxies and groups but is closer to those of galaxy\nclusters. In addition, our approach successfully resolves the two merging\ngalaxies in the background source and yields a total magnification of\n$\\mu=103.18^{+0.23}_{-0.19}$, which is significantly higher than the outcomes\nfrom previous studies of CSWA19. In summary, our research demonstrates the\neffectiveness of the brightness-adaptive pixelization source reconstruction\ntechnique for modelling group-scale strong lensing systems. It can serve as a\ntechnical reference for future investigations into pixel-level modelling of the\ngroup- and cluster-scale strong lensing systems.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T17:56:11Z"}
{"aid":"http://arxiv.org/abs/2504.11456v1","title":"DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and\n  Verifiable Mathematical Dataset for Advancing Reasoning","summary":"The capacity for complex mathematical reasoning is a key benchmark for\nartificial intelligence. While reinforcement learning (RL) applied to LLMs\nshows promise, progress is significantly hindered by the lack of large-scale\ntraining data that is sufficiently challenging, possesses verifiable answer\nformats suitable for RL, and is free from contamination with evaluation\nbenchmarks. To address these limitations, we introduce DeepMath-103K, a new,\nlarge-scale dataset comprising approximately 103K mathematical problems,\nspecifically designed to train advanced reasoning models via RL. DeepMath-103K\nis curated through a rigorous pipeline involving source analysis, stringent\ndecontamination against numerous benchmarks, and filtering for high difficulty\n(primarily Levels 5-9), significantly exceeding existing open resources in\nchallenge. Each problem includes a verifiable final answer, enabling rule-based\nRL, and three distinct R1-generated solutions suitable for diverse training\nparadigms like supervised fine-tuning or distillation. Spanning a wide range of\nmathematical topics, DeepMath-103K promotes the development of generalizable\nreasoning. We demonstrate that models trained on DeepMath-103K achieve\nsignificant improvements on challenging mathematical benchmarks, validating its\neffectiveness. We release DeepMath-103K publicly to facilitate community\nprogress in building more capable AI reasoning systems:\nhttps://github.com/zwhe99/DeepMath.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.11816v1","title":"Cost-Efficient LLM Serving in the Cloud: VM Selection with KV Cache\n  Offloading","summary":"LLM inference is essential for applications like text summarization,\ntranslation, and data analysis, but the high cost of GPU instances from Cloud\nService Providers (CSPs) like AWS is a major burden. This paper proposes\nInferSave, a cost-efficient VM selection framework for cloud based LLM\ninference. InferSave optimizes KV cache offloading based on Service Level\nObjectives (SLOs) and workload charac teristics, estimating GPU memory needs,\nand recommending cost-effective VM instances. Additionally, the Compute Time\nCalibration Function (CTCF) improves instance selection accuracy by adjusting\nfor discrepancies between theoretical and actual GPU performance. Experiments\non AWS GPU instances show that selecting lower-cost instances without KV cache\noffloading improves cost efficiency by up to 73.7% for online workloads, while\nKV cache offloading saves up to 20.19% for offline workloads.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-16T07:02:38Z"}
{"aid":"http://arxiv.org/abs/2504.11831v1","title":"Support is All You Need for Certified VAE Training","summary":"Variational Autoencoders (VAEs) have become increasingly popular and deployed\nin safety-critical applications. In such applications, we want to give\ncertified probabilistic guarantees on performance under adversarial attacks. We\npropose a novel method, CIVET, for certified training of VAEs. CIVET depends on\nthe key insight that we can bound worst-case VAE error by bounding the error on\ncarefully chosen support sets at the latent layer. We show this point\nmathematically and present a novel training algorithm utilizing this insight.\nWe show in an extensive evaluation across different datasets (in both the\nwireless and vision application areas), architectures, and perturbation\nmagnitudes that our method outperforms SOTA methods achieving good standard\nperformance with strong robustness guarantees.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-16T07:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.11839v1","title":"\"Good\" and \"Bad\" Failures in Industrial CI/CD -- Balancing Cost and\n  Quality Assurance","summary":"Continuous Integration and Continuous Deployment (CI/CD) pipeline automates\nsoftware development to speed up and enhance the efficiency of engineering\nsoftware. These workflows consist of various jobs, such as code validation and\ntesting, which developers must wait to complete before receiving feedback. The\njobs can fail, which leads to unnecessary delays in build times, decreasing\nproductivity for developers, and increasing costs for companies. To explore how\ncompanies adopt CI/CD workflows and balance cost with quality assurance during\noptimization, we studied 4 companies, reporting industry experiences with CI/CD\npractices. Our findings reveal that organizations can confuse the distinction\nbetween CI and CD, whereas code merge and product release serve as more\neffective milestones for process optimization and risk control. While numerous\ntools and research efforts target the post-merge phase to enhance productivity,\nlimited attention has been given to the pre-merge phase, where early failure\nprevention brings more impacts and less risks.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T07:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.11853v1","title":"Stability of Highly Hydrogenated Monolayer Graphene in Ultra-High Vacuum\n  and in Air","summary":"The stability of hydrogenated monolayer graphene was investigated via X-ray\nphotoemission spectroscopy (XPS) for two different environmental conditions:\nultra-high vacuum (UHV) and ambient pressure. The study is carried out by\nmeasuring the C 1s line shape evolution for two hydrogenated samples one kept\nin the UHV chamber and the other progressively exposed to air. In particular,\nthe $sp^3$ relative intensity in the C 1s core-level spectrum, represented by\nthe area ratio $\\frac{sp^3}{sp^2+sp^3}$, was used as a marker for the\nhydrogenation-level and it resulted to vary by (4 $\\pm$ 2)$\\%$ in UHV after\nfour months. Thus, a long-term stability of hydrogenated monolayer graphene was\nfound, that indicates this material as a good candidate for hydrogen (or\ntritium) storage as long as it is kept in vacuum. On the other hand, the C 1s\nspectrum of the sample exposed to air shows a significant oxidation. A rapid\ngrowth up to saturation of the carbon oxides was observed with a time constant\n$\\tau$ = 1.8 $\\pm$ 0.2 hours. Finally, the re-exposure of the oxidised sample\nto atomic hydrogen was found to be an effective method for the recovery of\nhydrogenated graphene. This process was studied by carrying out both XPS and\nelectron energy loss spectroscopy, the latter exploited to observe the CH\nstretching mode as a direct footprint of re-hydrogenation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-16T08:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.11889v1","title":"Rethinking LLM-Based Recommendations: A Query Generation-Based,\n  Training-Free Approach","summary":"Existing large language model LLM-based recommendation methods face several\nchallenges, including inefficiency in handling large candidate pools,\nsensitivity to item order within prompts (\"lost in the middle\" phenomenon) poor\nscalability, and unrealistic evaluation due to random negative sampling. To\naddress these issues, we propose a Query-to-Recommendation approach that\nleverages LLMs to generate personalized queries for retrieving relevant items\nfrom the entire candidate pool, eliminating the need for candidate\npre-selection. This method can be integrated into an ID-based recommendation\nsystem without additional training, enhances recommendation performance and\ndiversity through LLMs' world knowledge, and performs well even for less\npopular item groups. Experiments on three datasets show up to 57 percent\nimprovement, with an average gain of 31 percent, demonstrating strong zero-shot\nperformance and further gains when ensembled with existing models.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-16T09:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.11895v1","title":"Search is All You Need for Few-shot Anomaly Detection","summary":"Few-shot anomaly detection (FSAD) has emerged as a crucial yet challenging\ntask in industrial inspection, where normal distribution modeling must be\naccomplished with only a few normal images. While existing approaches typically\nemploy multi-modal foundation models combining language and vision modalities\nfor prompt-guided anomaly detection, these methods often demand sophisticated\nprompt engineering and extensive manual tuning. In this paper, we demonstrate\nthat a straightforward nearest-neighbor search framework can surpass\nstate-of-the-art performance in both single-class and multi-class FSAD\nscenarios. Our proposed method, VisionAD, consists of four simple yet essential\ncomponents: (1) scalable vision foundation models that extract universal and\ndiscriminative features; (2) dual augmentation strategies - support\naugmentation to enhance feature matching adaptability and query augmentation to\naddress the oversights of single-view prediction; (3) multi-layer feature\nintegration that captures both low-frequency global context and high-frequency\nlocal details with minimal computational overhead; and (4) a class-aware visual\nmemory bank enabling efficient one-for-all multi-class detection. Extensive\nevaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrate\nVisionAD's exceptional performance. Using only 1 normal images as support, our\nmethod achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8%\nrespectively, outperforming current state-of-the-art approaches by significant\nmargins (+1.6%, +3.2%, and +1.4%). The training-free nature and superior\nfew-shot capabilities of VisionAD make it particularly appealing for real-world\napplications where samples are scarce or expensive to obtain. Code is available\nat https://github.com/Qiqigeww/VisionAD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T09:21:34Z"}
{"aid":"http://arxiv.org/abs/2504.11900v1","title":"Finding Flawed Fictions: Evaluating Complex Reasoning in Language Models\n  via Plot Hole Detection","summary":"Stories are a fundamental aspect of human experience. Engaging deeply with\nstories and spotting plot holes -- inconsistencies in a storyline that break\nthe internal logic or rules of a story's world -- requires nuanced reasoning\nskills, including tracking entities and events and their interplay, abstract\nthinking, pragmatic narrative understanding, commonsense and social reasoning,\nand theory of mind. As Large Language Models (LLMs) increasingly generate,\ninterpret, and modify text, rigorously assessing their narrative consistency\nand deeper language understanding becomes critical. However, existing\nbenchmarks focus mainly on surface-level comprehension. In this work, we\npropose plot hole detection in stories as a proxy to evaluate language\nunderstanding and reasoning in LLMs. We introduce FlawedFictionsMaker, a novel\nalgorithm to controllably and carefully synthesize plot holes in human-written\nstories. Using this algorithm, we construct a benchmark to evaluate LLMs' plot\nhole detection abilities in stories -- FlawedFictions -- , which is robust to\ncontamination, with human filtering ensuring high quality. We find that\nstate-of-the-art LLMs struggle in accurately solving FlawedFictions regardless\nof the reasoning effort allowed, with performance significantly degrading as\nstory length increases. Finally, we show that LLM-based story summarization and\nstory generation are prone to introducing plot holes, with more than 50% and\n100% increases in plot hole detection rates with respect to human-written\noriginals.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T09:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.11907v1","title":"A Graph-Based Reinforcement Learning Approach with Frontier Potential\n  Based Reward for Safe Cluttered Environment Exploration","summary":"Autonomous exploration of cluttered environments requires efficient\nexploration strategies that guarantee safety against potential collisions with\nunknown random obstacles. This paper presents a novel approach combining a\ngraph neural network-based exploration greedy policy with a safety shield to\nensure safe navigation goal selection. The network is trained using\nreinforcement learning and the proximal policy optimization algorithm to\nmaximize exploration efficiency while reducing the safety shield interventions.\nHowever, if the policy selects an infeasible action, the safety shield\nintervenes to choose the best feasible alternative, ensuring system\nconsistency. Moreover, this paper proposes a reward function that includes a\npotential field based on the agent's proximity to unexplored regions and the\nexpected information gain from reaching them. Overall, the approach\ninvestigated in this paper merges the benefits of the adaptability of\nreinforcement learning-driven exploration policies and the guarantee ensured by\nexplicit safety mechanisms. Extensive evaluations in simulated environments\ndemonstrate that the approach enables efficient and safe exploration in\ncluttered environments.","main_category":"cs.RO","categories":"cs.RO,I.2.9","published":"2025-04-16T09:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.11918v1","title":"Deep learning to improve the discovery of near-Earth asteroids in the\n  Zwicky Transient Facility","summary":"We present a novel pipeline that uses a convolutional neural network (CNN) to\nimprove the detection capability of near-Earth asteroids (NEAs) in the context\nof planetary defense. Our work aims to minimize the dependency on human\nintervention of the current approach adopted by the Zwicky Transient Facility\n(ZTF). The target NEAs have a high proper motion of up to tens of degrees per\nday and thus appear as streaks of light in the images. We trained our CNNs to\ndetect these streaks using three datasets: a set with real asteroid streaks, a\nset with synthetic (i.e., simulated) streaks and a mixed set, and tested the\nresultant models on real survey images. The results achieved were almost\nidentical across the three models: $0.843\\pm0.005$ in completeness and\n$0.820\\pm0.025$ in precision. The bias on streak measurements reported by the\nCNNs was $1.84\\pm0.03$ pixels in streak position, $0.817\\pm0.026$ degrees in\nstreak angle and $-0.048\\pm0.003$ in fractional bias in streak length (computed\nas the absolute length bias over the streak length, with the negative sign\nindicating an underestimation). We compared the performance of our CNN trained\nwith a mix of synthetic and real streaks to that of the ZTF human scanners by\nanalyzing a set of 317 streaks flagged as valid by the scanners. Our pipeline\ndetected $80~\\%$ of the streaks found by the scanners and 697 additional\nstreaks that were subsequently verified by the scanners to be valid streaks.\nThese results suggest that our automated pipeline can complement the work of\nthe human scanners at no cost for the precision and find more objects than the\ncurrent approach. They also prove that the synthetic streaks were realistic\nenough to be used for augmenting training sets when insufficient real streaks\nare available or exploring the simulation of streaks with unusual\ncharacteristics that have not yet been detected.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-16T09:55:26Z"}
{"aid":"http://arxiv.org/abs/2504.11925v1","title":"Reducing Calls to the Simulator in Simulation Based Inference (SBI)","summary":"Simulation-Based Inference (SBI) deals with statistical inference in problems\nwhere the data are generated from a system that is described by a complex\nstochastic simulator. The challenge for inference in these problems is that the\nlikelihood is intractable; SBI proceeds by using the simulator to sample from\nthe likelihood. In many real world applications, simulator calls are expensive,\nlimiting the associated sample size. Our goal in this work is to extend SBI to\nexploit two proposals for reducing simulator calls: to draw likelihood samples\nfrom a Neural Density Estimator (NDE) surrogate rather than from the stochastic\nsimulator; and use of Support Points rather than simple random sampling to\ngenerate evaluation sites. We embed these methods in the Sequential Neural\nPosterior Estimator (SNPE) algorithm. Across a suite of test cases, we find\nthat the NDE surrogate improves the quality of the inference; support points\nworked well in some examples, but not in others.","main_category":"stat.CO","categories":"stat.CO,62-08","published":"2025-04-16T09:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.11929v1","title":"Separate universe in multifield inflation: a phase-space approach","summary":"In this article we extend a study of the validity conditions of the\nseparate-universe approach of cosmological perturbations to models of inflation\nwith multiple fields. The separate-universe approach consists in describing the\nuniverse as a collection of homogeneous and isotropic patches, giving us an\neffective description of perturbation theory at large scales through\nphase-space reduction. This approximation is a necessary step in stochastic\ninflation, an effective theory of coarse-grained, super-Hubble, scalar fields\nfluctuations. One needs a stochastic inflation description in the context of\nprimordial black hole productions since it needs enhancements of the curvature\npower spectrum. It easily achievable in multifield inflation models but\nnecessarily comes with strong diffusive effects. We study and compare\ncosmological perturbation theory and the separate-universe approach in said\nnon-linear sigma models as a typical framework of multifield inflation and\nemploying the Hamiltonian formalism to keep track of the complete phase space\n(or the reduced isotropic phase space in the separate-universe approach). We\nfind that the separate-universe approach adequately describes the cosmological\nperturbation theory provided the wavelength of the modes considered is greater\nthat several lower bounds that depend on the cosmological horizon and the\ninverse of the effective Hamiltonian masses of the fields; the latter being\nfixed by the coupling potential and the field-space geometry. We also compare\ngauge-invariant variables and several gauge fixing procedures in both\napproaches. For instance, we showed that the uniform-expansion gauge is nicely\ndescribed by the separate-universe picture, hence qualifying its use in\nstochastic inflation as commonly done.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-16T10:08:43Z"}
{"aid":"http://arxiv.org/abs/2504.11933v1","title":"Lifelong and Universal Machine Learning Potentials for Chemical Reaction\n  Network Explorations","summary":"Recent developments in computational chemistry facilitate the automated\nquantum chemical exploration of chemical reaction networks for the in-silico\nprediction of synthesis pathways, yield, and selectivity. However, the\nunderlying quantum chemical energy calculations require vast computational\nresources, limiting these explorations severely in practice. Machine learning\npotentials (MLPs) offer a solution to increase computational efficiency, while\nretaining the accuracy of reliable first-principles data used for their\ntraining. Unfortunately, MLPs will be limited in their generalization ability\nwithin chemical (reaction) space, if the underlying training data is not\nrepresentative for a given application. Within the framework of automated\nreaction network exploration, where new reactants or reagents composed of any\nelements from the periodic table can be introduced, this lack of\ngeneralizability will be the rule rather than the exception. Here, we therefore\nstudy the benefits and drawbacks of two MLP concepts in this context. Whereas\nuniversal MLPs are designed to cover most of the relevant chemical space in\ntheir training, lifelong MLPs push their adaptability by efficient continual\nlearning of additional data. While the accuracy of the universal MLPs turns out\nto be not yet sufficient for reaction search trials without any fine-tuning,\nlifelong MLPs can reach chemical accuracy. We propose an improved learning\nalgorithm for lifelong adaptive data selection yielding efficient integration\nof new data while previous expertise is preserved.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.comp-ph","published":"2025-04-16T10:12:08Z"}
{"aid":"http://arxiv.org/abs/2504.11934v1","title":"An LLM-as-a-judge Approach for Scalable Gender-Neutral Translation\n  Evaluation","summary":"Gender-neutral translation (GNT) aims to avoid expressing the gender of human\nreferents when the source text lacks explicit cues about the gender of those\nreferents. Evaluating GNT automatically is particularly challenging, with\ncurrent solutions being limited to monolingual classifiers. Such solutions are\nnot ideal because they do not factor in the source sentence and require\ndedicated data and fine-tuning to scale to new languages. In this work, we\naddress such limitations by investigating the use of large language models\n(LLMs) as evaluators of GNT. Specifically, we explore two prompting approaches:\none in which LLMs generate sentence-level assessments only, and another, akin\nto a chain-of-thought approach, where they first produce detailed phrase-level\nannotations before a sentence-level judgment. Through extensive experiments on\nmultiple languages with five models, both open and proprietary, we show that\nLLMs can serve as evaluators of GNT. Moreover, we find that prompting for\nphrase-level annotations before sentence-level assessments consistently\nimproves the accuracy of all models, providing a better and more scalable\nalternative to current solutions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T10:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.11947v1","title":"Dissecting coupled orders in a terahertz-driven electron-doped cuprate","summary":"The interplay between superconductivity and charge density wave has often\nbeen studied from an equilibrium point of view. For example, using static\ntuning knobs such as doping, magnetic field and pressure, superconductivity can\nbe enhanced or suppressed. The resulting effect on the co-existing charge\ndensity wave order, if any, is judged by variations in its ground state\nproperties such as the ordering temperature or the spatial correlation. Such an\napproach can be understood as coordinated static displacements of two coupled\norder parameters within a Ginzburg-Landau description, evincing their interplay\nas either co-operative or competing but does not provide further microscopic\ninformation about the interaction. In order to assess such information, we\ndynamically perturb both orders from equilibrium and observe their coupling\ndirectly in the time-domain. We show that high-field multicycle terahertz\npulses drive both the Higgs amplitude fluctuations of the superconducting order\nas well as collective fluctuations of the charge order in an electron-doped\ncuprate, resulting in characteristic third harmonic generation. A notable time\ndelay is manifested between their respective driven dynamics. We propose that\nthis may signify the important energy scale describing their coupling or imply\na terahertz field-depinned charge density wave that destroys macroscopic\nsuperconductivity. Our work demonstrates a holistic approach for investigating\ncoupled superconducting and charge density wave orders, which may shed novel\nlight on their intertwined presence and widespread fluctuations in many classes\nof unconventional superconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T10:24:08Z"}
{"aid":"http://arxiv.org/abs/2504.11966v1","title":"Exploring Video-Based Driver Activity Recognition under Noisy Labels","summary":"As an open research topic in the field of deep learning, learning with noisy\nlabels has attracted much attention and grown rapidly over the past ten years.\nLearning with label noise is crucial for driver distraction behavior\nrecognition, as real-world video data often contains mislabeled samples,\nimpacting model reliability and performance. However, label noise learning is\nbarely explored in the driver activity recognition field. In this paper, we\npropose the first label noise learning approach for the driver activity\nrecognition task. Based on the cluster assumption, we initially enable the\nmodel to learn clustering-friendly low-dimensional representations from given\nvideos and assign the resultant embeddings into clusters. We subsequently\nperform co-refinement within each cluster to smooth the classifier outputs.\nFurthermore, we propose a flexible sample selection strategy that combines two\nselection criteria without relying on any hyperparameters to filter clean\nsamples from the training dataset. We also incorporate a self-adaptive\nparameter into the sample selection process to enforce balancing across\nclasses. A comprehensive variety of experiments on the public Drive&Act dataset\nfor all granularity levels demonstrates the superior performance of our method\nin comparison with other label-denoising methods derived from the image\nclassification field. The source code is available at\nhttps://github.com/ilonafan/DAR-noisy-labels.","main_category":"cs.CV","categories":"cs.CV,cs.LG,cs.RO,eess.IV","published":"2025-04-16T10:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.11971v1","title":"Spinorial quasilocal mass for spacetimes with negative cosmological\n  constant","summary":"A new notion of quasilocal mass is defined for generic, compact, two\ndimensional, spacelike surfaces in four dimensional spacetimes with negative\ncosmological constant. The definition is spinorial and based on work for\nvanishing cosmological constant by Penrose and Dougan & Mason. Furthermore,\nthis mass is non-negative, equal to the Misner-Sharp mass in spherical\nsymmetry, equal to zero for every generic surface in AdS, has an appropriate\nform for gravity linearised about AdS and has an appropriate limit for large\nspheres in asymptotically AdS spacetimes.","main_category":"gr-qc","categories":"gr-qc,hep-th,math.DG","published":"2025-04-16T11:07:23Z"}
{"aid":"http://arxiv.org/abs/2504.11986v1","title":"Language Models as Quasi-Crystalline Thought: Structure, Constraint, and\n  Emergence in Generative Systems","summary":"This essay proposes an analogy between large language models (LLMs) and\nquasicrystals: systems that exhibit global coherence without periodic\nrepetition and that are generated through local constraints. While LLMs are\noften evaluated in terms of predictive accuracy, factuality, or alignment, this\nstructural perspective suggests that their most characteristic behavior is the\nproduction of internally resonant linguistic patterns. Just as quasicrystals\nforced a redefinition of order in physical systems, viewing LLMs as generators\nof quasi-structured language opens new paths for evaluation and design:\nprivileging propagation of constraint over token-level accuracy, and coherence\nof form over fixed meaning. LLM outputs should be read not only for what they\nsay, but for the patterns of constraint and coherence that organize them. This\nshift reframes generative language as a space of emergent patterning: LLMs are\nneither fully random nor strictly rule-based, but defined by a logic of\nconstraint, resonance, and structural depth.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T11:27:47Z"}
{"aid":"http://arxiv.org/abs/2504.12008v1","title":"Global Patterns of Extreme Temperature Teleconnections Using Climate\n  Network Analysis","summary":"Extreme weather events, rare yet profoundly impactful, are often accompanied\nby severe conditions. Increasing global temperatures are poised to exacerbate\nthese events, resulting in greater human casualties, economic losses, and\necological destruction. Complex global climate interactions, known as\nteleconnections, can lead to widespread repercussions triggered by localized\nextreme weather. Understanding these teleconnection patterns is crucial for\nweather forecasting, enhancing safety, and advancing climate science. Here, we\nemploy climate network analysis to uncover teleconnection patterns associated\nwith extreme temperature fluctuations, including both extreme warming and\ncooling events occurring on a daily basis. Our study results demonstrate that\nthe distances of significant teleconnections initially conform to a power-law\ndecay, signifying a decline in connectivity with distance. However, this\npower-law decay tendency breaks beyond a certain threshold distance, suggesting\nthe existence of long-distance connections. Additionally, we uncover a greater\nprevalence of long-distance connectivity among extreme cooling events compared\nto extreme warming events. The global pattern of teleconnections is, in part,\ndriven by the mechanism of Rossby waves, which serve as a rapid conduit for\ninducing correlated fluctuations in both pressure and temperature. These\nresults enhance our understanding of the multiscale nature of climate\nteleconnections and hold significant implications for improving weather\nforecasting and assessing climate risks in a warming world.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-16T12:05:15Z"}
{"aid":"http://arxiv.org/abs/2504.12015v1","title":"Power Line Communication vs. Talkative Power Conversion: A Benchmarking\n  Study","summary":"The convergence of energy transmission and data communication has become a\nkey feature of decentralized energy systems across a broad spectrum of\nvoltage/power ranges, including smart grid applications and cyber-physical\npower systems. This paper compares two distinct approaches: Power Line\nCommunications (PLC) and Talkative Power Conversion (TPC). While PLC leverages\nexisting power infrastructure for data transmission by using external data\ntransmitters and receivers, TPC integrates communication capabilities directly\ninto power electronic converters. We present their technical foundations and\napplications, benchmark their strengths and bottlenecks, and outline future\nresearch directions regarding TPC that could bridge the gap between power and\ncommunication technologies.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-16T12:15:42Z"}
{"aid":"http://arxiv.org/abs/2504.12018v1","title":"Instruction-augmented Multimodal Alignment for Image-Text and Element\n  Matching","summary":"With the rapid advancement of text-to-image (T2I) generation models,\nassessing the semantic alignment between generated images and text descriptions\nhas become a significant research challenge. Current methods, including those\nbased on Visual Question Answering (VQA), still struggle with fine-grained\nassessments and precise quantification of image-text alignment. This paper\npresents an improved evaluation method named Instruction-augmented Multimodal\nAlignment for Image-Text and Element Matching (iMatch), which evaluates\nimage-text semantic alignment by fine-tuning multimodal large language models.\nWe introduce four innovative augmentation strategies: First, the QAlign\nstrategy creates a precise probabilistic mapping to convert discrete scores\nfrom multimodal large language models into continuous matching scores. Second,\na validation set augmentation strategy uses pseudo-labels from model\npredictions to expand training data, boosting the model's generalization\nperformance. Third, an element augmentation strategy integrates element\ncategory labels to refine the model's understanding of image-text matching.\nFourth, an image augmentation strategy employs techniques like random lighting\nto increase the model's robustness. Additionally, we propose prompt type\naugmentation and score perturbation strategies to further enhance the accuracy\nof element assessments. Our experimental results show that the iMatch method\nsignificantly surpasses existing methods, confirming its effectiveness and\npractical value. Furthermore, our iMatch won first place in the CVPR NTIRE 2025\nText to Image Generation Model Quality Assessment - Track 1 Image-Text\nAlignment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T12:21:49Z"}
{"aid":"http://arxiv.org/abs/2504.12045v1","title":"pix2pockets: Shot Suggestions in 8-Ball Pool from a Single Image in the\n  Wild","summary":"Computer vision models have seen increased usage in sports, and reinforcement\nlearning (RL) is famous for beating humans in strategic games such as Chess and\nGo. In this paper, we are interested in building upon these advances and\nexamining the game of classic 8-ball pool. We introduce pix2pockets, a\nfoundation for an RL-assisted pool coach. Given a single image of a pool table,\nwe first aim to detect the table and the balls and then propose the optimal\nshot suggestion. For the first task, we build a dataset with 195 diverse images\nwhere we manually annotate all balls and table dots, leading to 5748 object\nsegmentation masks. For the second task, we build a standardized RL environment\nthat allows easy development and benchmarking of any RL algorithm. Our object\ndetection model yields an AP50 of 91.2 while our ball location pipeline obtains\nan error of only 0.4 cm. Furthermore, we compare standard RL algorithms to set\na baseline for the shot suggestion task and we show that all of them fail to\npocket all balls without making a foul move. We also present a simple baseline\nthat achieves a per-shot success rate of 94.7% and clears a full game in a\nsingle turn 30% of the time.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-16T13:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.12046v1","title":"The Dynamic Inner Disk of a Planet Forming Star","summary":"Planets are a natural byproduct of the stellar formation process, resulting\nfrom local aggregations of material within the disks surrounding young stars.\nWhereas signatures of gas-giant planets at large orbital separations have been\nobserved and successfully modeled within protoplanetary disks, the formation\npathways of planets within their host star's future habitable zones remain\npoorly understood. Analyzing multiple nights of observations conducted over a\nshort, two-month span with the MIRC-X and PIONIER instruments at the CHARA\nArray and VLTI, respectively, we uncover a highly active environment at the\ninner-edge of the planet formation region in the disk of HD 163296. In\nparticular, we localize and track the motion of a disk feature near the\ndust-sublimation radius with a pattern speed of less than half the local\nKeplerian velocity, providing a potential glimpse at the planet formation\nprocess in action within the inner astronomical unit. We emphasize that this\nresult is at the edge of what is currently possible with available optical\ninterferometric techniques and behooves confirmation with a temporally dense\nfollowup observing campaign.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-16T13:03:30Z"}
{"aid":"http://arxiv.org/abs/2504.12061v1","title":"A survey on orderability and contact non-squeezing","summary":"The present article provides an overview of Yakov Eliashberg's seminal\ncontributions to the concepts of orderability and contact non-squeezing. It\nalso examines subsequent research by various authors, highlighting the\nsignificance of these notions and offering a detailed account of the current\nstate of the field.","main_category":"math.SG","categories":"math.SG","published":"2025-04-16T13:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.12065v1","title":"Numerical and Analytical Study of the Magnetic Field Distribution in a\n  Three-Solenoid System","summary":"This paper investigates the magnetic fields produced by a three-coil system,\nfocusing on how different mesh resolutions affect the accuracy of the results.\nUsing both the Poisson solver, as well as a numerical approach based on the\nsolution of fractional integrals, the study examines coils with dimensions of\n80 mm by 160 mm and a radius of 15.5 mm, each carrying a current of 200 A. The\nresearch explores how varying mesh step sizes within the coil regions\ninfluences the simulations accuracy and convergence. The results are analyzed\nalong a line parallel to the central axis at a distance equal to half of the\nsolenoid's radius.. The findings emphasize the consistency of the numerical\nresults, the compatibility of the solvers, and offer insights into further\noptimization strategies for more efficient simulations.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-16T13:20:36Z"}
{"aid":"http://arxiv.org/abs/2504.12073v1","title":"Unconventional and anomalous magnetic field distribution in a bilayer\n  superconductor with geometric constraints","summary":"We investigate the magnetic field distribution in multi-component\nsuperconductors. We examine a layered superconductor and a two-component\none-layer superconductor. We evaluate the field distribution in the presence of\na half-flux quantum vortex with a kink structure in the phase space of gap\nfunctions. We also examine the magnetic field distribution of a knot soliton\nwhich is formulated in a two-component superconductor. We investigate the\neffect of geometric constraints for multi-component superconductors, where the\ngeometric constraint means that the system is compactified in one direction so\nthat the current in this direction becomes vanishingly small. This corresponds\nto the gauge fixing in this direction. An unconventional magnetic field\ndistribution takes place; here the unconventional means that the magnetic field\nis screened incompletely which would be called the anomalous Meissner effect.\nWe argue that this anomalous behavior creates a massless gauge field.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T13:29:40Z"}
{"aid":"http://arxiv.org/abs/2504.12094v1","title":"Relaxation of perturbed circles in flat spaces for the Mullins-Sekerka\n  evolution in two dimensions","summary":"We analyze the convergence of a perturbed circular interface for the\ntwo-phase Mullins-Sekerka evolution in flat two-dimensional space. Our method\nis based on the gradient flow structure of the evolution and captures two\ndistinct regimes of the dynamics, an initial - and novel - phase of\nalgebraic-in-time decay and a later - and previously explored - phase of\nexponential-in-time decay. By quantifying the initial phase of relaxation, our\nmethod allows for the investigation of systems with large initial dissipation\nas long as the isoperimetric deficit is small enough. We include quantitative\nestimates of the solution in terms of its initial data, including the\n$C^{1}$-distance to the center manifold of circles and the displacement of the\nbarycenter.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T13:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.12120v1","title":"Logarithmic Spectral Distribution of a non-Hermitian $β$-Ensemble","summary":"We introduce a non-Hermitian $\\beta$-ensemble and determine its spectral\ndensity in the limit of large $\\beta$ and large matrix size $n$. The ensemble\nis given by a general tridiagonal complex random matrix of normal and\nchi-distributed random variables, extending previous work of two of the\nauthors. The joint distribution of eigenvalues contains a Vandermonde\ndeterminant to the power $\\beta$ and a residual coupling to the eigenvectors. A\ntool in the computation of the limiting spectral density is a single\ncharacteristic polynomial for centred tridiagonal Jacobi matrices, for which we\nexplicitly determine the coefficients in terms of its matrix elements. In the\nlow temperature limit $\\beta\\gg1$ our ensemble reduces to such a centred matrix\nwith vanishing diagonal. A general theorem from free probability based on the\nvariance of the coefficients of the characteristic polynomial allows us to\nobtain the spectral density when additionally taking the large-$n$ limit. It is\nrotationally invariant on a compact disc, given by the logarithm of the radius\nplus a constant. The same density is obtained when starting form a tridiagonal\ncomplex symmetric ensemble, which thus plays a special role. Extensive\nnumerical simulations confirm our analytical results and put this and the\npreviously studied ensemble in the context of the pseudospectrum.","main_category":"math-ph","categories":"math-ph,cond-mat.stat-mech,math.MP,math.PR","published":"2025-04-16T14:33:46Z"}
{"aid":"http://arxiv.org/abs/2504.12143v1","title":"ARCeR: an Agentic RAG for the Automated Definition of Cyber Ranges","summary":"The growing and evolving landscape of cybersecurity threats necessitates the\ndevelopment of supporting tools and platforms that allow for the creation of\nrealistic IT environments operating within virtual, controlled settings as\nCyber Ranges (CRs). CRs can be exploited for analyzing vulnerabilities and\nexperimenting with the effectiveness of devised countermeasures, as well as\nserving as training environments for building cyber security skills and\nabilities for IT operators. This paper proposes ARCeR as an innovative solution\nfor the automatic generation and deployment of CRs, starting from user-provided\ndescriptions in a natural language. ARCeR relies on the Agentic RAG paradigm,\nwhich allows it to fully exploit state-of-art AI technologies. Experimental\nresults show that ARCeR is able to successfully process prompts even in cases\nthat LLMs or basic RAG systems are not able to cope with. Furthermore, ARCeR is\nable to target any CR framework provided that specific knowledge is made\navailable to it.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-16T14:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.12149v1","title":"Study on charmonium(-like) mesons within a diabatic approach","summary":"In this work, we study the charmonium(-like) spectrum below 4.1 GeV using the\ndiabatic approach, which offers a unified description of conventional and\nunconventional heavy meson states. Compared to previous studies, we consider a\nmore realistic $c\\bar c$ potential with including the spin-dependent\ninteractions, which allows us to obtain more states and get more insights on\nthe charmonium spectrum. Based on our calculation, we obtain the masses of the\ncharmonium spectrum which align with the experimental data well. We also\npresent the probabilities of finding various components, i.e. $c\\bar c$ or\nmeson-meson pair, in those states. Our results support the arguments that the\n$\\chi_{c1}(3872)$, $\\psi(4040)$ and $\\chi_{c2}(3930)$ have significant\nmolecular components. In addition, our calculations show that the\n$\\chi_{c0}(3860)$ and $\\psi(3770)$ can be looked as the candidates for the\ncharmonium states $\\chi_{c0}(2P)$ and $\\psi(1D)$, respectively.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T14:57:29Z"}
{"aid":"http://arxiv.org/abs/2504.12154v1","title":"Deep Generative Models for Bayesian Inference on High-Rate Sensor Data:\n  Applications in Automotive Radar and Medical Imaging","summary":"Deep generative models have been studied and developed primarily in the\ncontext of natural images and computer vision. This has spurred the development\nof (Bayesian) methods that use these generative models for inverse problems in\nimage restoration, such as denoising, inpainting, and super-resolution. In\nrecent years, generative modeling for Bayesian inference on sensory data has\nalso gained traction. Nevertheless, the direct application of generative\nmodeling techniques initially designed for natural images on raw sensory data\nis not straightforward, requiring solutions that deal with high dynamic range\nsignals acquired from multiple sensors or arrays of sensors that interfere with\neach other, and that typically acquire data at a very high rate. Moreover, the\nexact physical data-generating process is often complex or unknown. As a\nconsequence, approximate models are used, resulting in discrepancies between\nmodel predictions and the observations that are non-Gaussian, in turn\ncomplicating the Bayesian inverse problem. Finally, sensor data is often used\nin real-time processing or decision-making systems, imposing stringent\nrequirements on, e.g., latency and throughput. In this paper, we will discuss\nsome of these challenges and offer approaches to address them, all in the\ncontext of high-rate real-time sensing applications in automotive radar and\nmedical imaging.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T15:03:01Z"}
{"aid":"http://arxiv.org/abs/2504.12171v1","title":"Traveling wave profiles for a semi-discrete Burgers equation","summary":"We look for traveling waves of the semi-discrete conservation law $4\\dot u_j\n+u_{j+1}^2-u_{j-1}^2 = 0$, using variational principles related to concepts of\n``hidden convexity'' appearing in recent studies of various PDE (partial\ndifferential equations). We analyze and numerically compute with two\nvariational formulations related to dual convex optimization problems\nconstrained by either the differential-difference equation (DDE) or nonlinear\nintegral equation (NIE) that wave profiles should satisfy. We prove existence\ntheorems conditional on the existence of extrema that satisfy a strict\nconvexity criterion, and numerically exhibit a variety of localized, periodic\nand non-periodic wave phenomena.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA,nlin.PS","published":"2025-04-16T15:23:43Z"}
{"aid":"http://arxiv.org/abs/2504.12172v1","title":"Poem Meter Classification of Recited Arabic Poetry: Integrating\n  High-Resource Systems for a Low-Resource Task","summary":"Arabic poetry is an essential and integral part of Arabic language and\nculture. It has been used by the Arabs to spot lights on their major events\nsuch as depicting brutal battles and conflicts. They also used it, as in many\nother languages, for various purposes such as romance, pride, lamentation, etc.\nArabic poetry has received major attention from linguistics over the decades.\nOne of the main characteristics of Arabic poetry is its special rhythmic\nstructure as opposed to prose. This structure is referred to as a meter.\nMeters, along with other poetic characteristics, are intensively studied in an\nArabic linguistic field called \"\\textit{Aroud}\". Identifying these meters for a\nverse is a lengthy and complicated process. It also requires technical\nknowledge in \\textit{Aruod}. For recited poetry, it adds an extra layer of\nprocessing. Developing systems for automatic identification of poem meters for\nrecited poems need large amounts of labelled data. In this study, we propose a\nstate-of-the-art framework to identify the poem meters of recited Arabic\npoetry, where we integrate two separate high-resource systems to perform the\nlow-resource task. To ensure generalization of our proposed architecture, we\npublish a benchmark for this task for future research.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T15:25:45Z"}
{"aid":"http://arxiv.org/abs/2504.12181v1","title":"Battery-aware Cyclic Scheduling in Energy-harvesting Federated Learning","summary":"Federated Learning (FL) has emerged as a promising framework for distributed\nlearning, but its growing complexity has led to significant energy consumption,\nparticularly from computations on the client side. This challenge is especially\ncritical in energy-harvesting FL (EHFL) systems, where device availability\nfluctuates due to limited and time-varying energy resources. We propose\nFedBacys, a battery-aware FL framework that introduces cyclic client\nparticipation based on users' battery levels to cope with these issues.\nFedBacys enables clients to save energy and strategically perform local\ntraining just before their designated transmission time by clustering clients\nand scheduling their involvement sequentially. This design minimizes redundant\ncomputation, reduces system-wide energy usage, and improves learning stability.\nOur experiments demonstrate that FedBacys outperforms existing approaches in\nterms of energy efficiency and performance consistency, exhibiting robustness\neven under non-i.i.d. training data distributions and with very infrequent\nbattery charging. This work presents the first comprehensive evaluation of\ncyclic client participation in EHFL, incorporating both communication and\ncomputation costs into a unified, resource-aware scheduling strategy.","main_category":"cs.LG","categories":"cs.LG,cs.IT,math.IT","published":"2025-04-16T15:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.12195v1","title":"Validating and monitoring bibliographic and citation data in\n  OpenCitations collections","summary":"Purpose. The increasing emphasis on data quantity in research infrastructures\nhas highlighted the need for equally robust mechanisms ensuring data quality,\nparticularly in bibliographic and citation datasets. This paper addresses the\nchallenge of maintaining high-quality open research information within\nOpenCitations, a community-guided Open Science Infrastructure, by introducing\ntools for validating and monitoring bibliographic metadata and citation data.\n  Methods. We developed a custom validation tool tailored to the OpenCitations\nData Model (OCDM), designed to detect and explain ingestion errors from\nheterogeneous sources, whether due to upstream data inconsistencies or internal\nsoftware bugs. Additionally, a quality monitoring tool was created to track\nknown data issues post-publication. These tools were applied in two scenarios:\n(1) validating metadata and citations from Matilda, a potential future source,\nand (2) monitoring data quality in the existing OpenCitations Meta dataset.\n  Results. The validation tool successfully identified a variety of structural\nand semantic issues in the Matilda dataset, demonstrating its precision. The\nmonitoring tool enabled the detection of recurring problems in the\nOpenCitations Meta collection, as well as their quantification. Together, these\ntools proved effective in enhancing the reliability of OpenCitations' published\ndata.\n  Conclusion. The presented validation and monitoring tools represent a step\ntoward ensuring high-quality bibliographic data in open research\ninfrastructures, though they are limited to the data model adopted by\nOpenCitations. Future developments are aimed at expanding to additional data\nsources, with particular regard to crowdsourced data.","main_category":"cs.DL","categories":"cs.DL,H.3.7","published":"2025-04-16T15:47:44Z"}
{"aid":"http://arxiv.org/abs/2504.12197v1","title":"Beyond Patches: Mining Interpretable Part-Prototypes for Explainable AI","summary":"Deep learning has provided considerable advancements for multimedia systems,\nyet the interpretability of deep models remains a challenge. State-of-the-art\npost-hoc explainability methods, such as GradCAM, provide visual interpretation\nbased on heatmaps but lack conceptual clarity. Prototype-based approaches, like\nProtoPNet and PIPNet, offer a more structured explanation but rely on fixed\npatches, limiting their robustness and semantic consistency.\n  To address these limitations, a part-prototypical concept mining network\n(PCMNet) is proposed that dynamically learns interpretable prototypes from\nmeaningful regions. PCMNet clusters prototypes into concept groups, creating\nsemantically grounded explanations without requiring additional annotations.\nThrough a joint process of unsupervised part discovery and concept activation\nvector extraction, PCMNet effectively captures discriminative concepts and\nmakes interpretable classification decisions.\n  Our extensive experiments comparing PCMNet against state-of-the-art methods\non multiple datasets show that it can provide a high level of interpretability,\nstability, and robustness under clean and occluded scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T15:48:21Z"}
{"aid":"http://arxiv.org/abs/2504.12209v1","title":"Evidence for a polar circumbinary exoplanet orbiting a pair of eclipsing\n  brown dwarfs","summary":"One notable example of exoplanet diversity is the population of circumbinary\nplanets, which orbit around both stars of a binary star system. There are so\nfar only 16 known circumbinary exoplanets, all of which lie in the same orbital\nplane as the host binary. Suggestions exist that circumbinary planets could\nalso exist on orbits highly inclined to the binary, close to 90$^{\\circ}$,\npolar orbits. No such planets have been found yet but polar circumbinary gas\nand debris discs have been observed and if these were to form planets then\nthose would be left on a polar orbit. We report strong evidence for a polar\ncircumbinary exoplanet, which orbits a close pair of brown dwarfs which are on\nan eccentric orbit. We use radial-velocities to measure a retrograde apsidal\nprecession for the binary, and show that this can only be attributed to the\npresence of a polar planet.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-16T15:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.12217v1","title":"zkVC: Fast Zero-Knowledge Proof for Private and Verifiable Computing","summary":"In the context of cloud computing, services are held on cloud servers, where\nthe clients send their data to the server and obtain the results returned by\nserver. However, the computation, data and results are prone to tampering due\nto the vulnerabilities on the server side. Thus, verifying the integrity of\ncomputation is important in the client-server setting. The cryptographic method\nknown as Zero-Knowledge Proof (ZKP) is renowned for facilitating private and\nverifiable computing. ZKP allows the client to validate that the results from\nthe server are computed correctly without violating the privacy of the server's\nintellectual property. Zero-Knowledge Succinct Non-Interactive Argument of\nKnowledge (zkSNARKs), in particular, has been widely applied in various\napplications like blockchain and verifiable machine learning. Despite their\npopularity, existing zkSNARKs approaches remain highly computationally\nintensive. For instance, even basic operations like matrix multiplication\nrequire an extensive number of constraints, resulting in significant overhead.\nIn addressing this challenge, we introduce \\textit{zkVC}, which optimizes the\nZKP computation for matrix multiplication, enabling rapid proof generation on\nthe server side and efficient verification on the client side. zkVC integrates\noptimized ZKP modules, such as Constraint-reduced Polynomial Circuit (CRPC) and\nPrefix-Sum Query (PSQ), collectively yielding a more than 12-fold increase in\nproof speed over prior methods. The code is available at\nhttps://github.com/UCF-Lou-Lab-PET/zkformer","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-16T16:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.12227v1","title":"A remark on Euler-like vector fields","summary":"In this note, we show that (the germ of) each Euler-like vector field comes\nfrom a tubular neighborhood embedding given by the normal exponential map of\nsome Riemannian metric.","main_category":"math.DG","categories":"math.DG","published":"2025-04-16T16:22:43Z"}
{"aid":"http://arxiv.org/abs/2504.12231v1","title":"Finite time blowup for Keller-Segel equation with logistic damping in\n  three dimensions","summary":"The Keller-Segel equation, a classical chemotaxis model, and many of its\nvariants have been extensively studied for decades. In this work, we focus on\n3D Keller-Segel equation with a quadratic logistic damping term $-\\mu \\rho^2$\n(modeling density-dependent mortality rate) and show the existence of\nfinite-time blowup solutions with nonnegative density and finite mass for any\n$\\mu \\in \\big[0,\\frac{1}{3}\\big)$. This range of $\\mu$ is sharp; for $\\mu \\ge\n\\frac{1}{3}$, the logistic damping effect suppresses the blowup as shown in\n[Kang-Stevens, 2016] and [Tello-Winkler, 2007]. A key ingredient is to\nconstruct a self-similar blowup solution to a related aggregation equation as\nan approximate solution, with subcritical scaling relative to the original\nmodel. Based on this construction, we employ a robust weighted $L^2$ method to\nprove the stability of this approximate solution, where modulation ODEs are\nintroduced to enforce local vanishing conditions for the perturbation lying in\na singular-weighted $L^2$ space. As a byproduct, we exhibit a new family of\ntype I blowup mechanisms for the classical 3D Keller-Segel equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T16:30:13Z"}
{"aid":"http://arxiv.org/abs/2504.12235v1","title":"Rotating Topological Stars","summary":"We construct a three-parameter family of smooth and horizonless rotating\nsolutions of Einstein-Maxwell theory with Chern-Simons term in five dimensions\nand discuss their stringy origin in terms of three-charge brane systems in Type\nIIB and M-theory. The general solution interpolates smoothly between Kerr and\nstatic Topological Star geometries. We show that for specific choices of the\nparameters and quantized values of the angular momentum the geometry terminates\non a smooth five-dimensional cap, and it displays neither ergoregion nor closed\ntimelike curves and a region of Gregory-Laflamme stability. We discuss the\ndimensional reduction to four dimensions and the propagation of particles and\nwaves showing that geodetic motion is integrable and the radial and angular\npropagation of scalar perturbations can be separated and described in terms of\ntwo ordinary differential equations of confluent Heun type.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T16:35:22Z"}
{"aid":"http://arxiv.org/abs/2504.12238v1","title":"Exceptional deficiency of non-Hermitian systems: high-dimensional\n  coalescence and dynamics","summary":"Exceptional points (EPs) are non-Hermitian singularities associated with the\ncoalescence of individual eigenvectors accompanied by the degeneracy of their\ncomplex energies. Here, we report the discovery of a generalization to the\nconcept of EP called exceptional deficiency (ED), which features the complete\ncoalescence of two eigenspaces with identical but arbitrarily large dimensions\nand the coincidence of entire spectral continua. The characteristics of the ED\nare studied using one-way coupled Hermitian and non-Hermitian lattices. The ED\ncan induce an anomalous absence and presence of non-Hermitian skin effect\n(NHSE) that transcends the topological bulk-edge correspondence of NHSE,\nresulting in unexpected synergistic skin-propagative dynamics. The conditions\nof the ED are also explored for unprecedented control of localization and\npropagation in non-Hermitian systems. These effects are experimentally observed\nusing active mechanical lattices. The discovery of ED opens multiple new\nfrontiers in non-Hermitian physics and can potentially resolve long-standing\nchallenges in related applications.","main_category":"quant-ph","categories":"quant-ph,physics.class-ph","published":"2025-04-16T16:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.12245v1","title":"SIDME: Self-supervised Image Demoiréing via Masked Encoder-Decoder\n  Reconstruction","summary":"Moir\\'e patterns, resulting from aliasing between object light signals and\ncamera sampling frequencies, often degrade image quality during capture.\nTraditional demoir\\'eing methods have generally treated images as a whole for\nprocessing and training, neglecting the unique signal characteristics of\ndifferent color channels. Moreover, the randomness and variability of moir\\'e\npattern generation pose challenges to the robustness of existing methods when\napplied to real-world data. To address these issues, this paper presents SIDME\n(Self-supervised Image Demoir\\'eing via Masked Encoder-Decoder Reconstruction),\na novel model designed to generate high-quality visual images by effectively\nprocessing moir\\'e patterns. SIDME combines a masked encoder-decoder\narchitecture with self-supervised learning, allowing the model to reconstruct\nimages using the inherent properties of camera sampling frequencies. A key\ninnovation is the random masked image reconstructor, which utilizes an\nencoder-decoder structure to handle the reconstruction task. Furthermore, since\nthe green channel in camera sampling has a higher sampling frequency compared\nto red and blue channels, a specialized self-supervised loss function is\ndesigned to improve the training efficiency and effectiveness. To ensure the\ngeneralization ability of the model, a self-supervised moir\\'e image generation\nmethod has been developed to produce a dataset that closely mimics real-world\nconditions. Extensive experiments demonstrate that SIDME outperforms existing\nmethods in processing real moir\\'e pattern data, showing its superior\ngeneralization performance and robustness.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-16T16:50:41Z"}
{"aid":"http://arxiv.org/abs/2504.12246v1","title":"Branching Bisimulation Learning","summary":"We introduce a bisimulation learning algorithm for non-deterministic\ntransition systems. We generalise bisimulation learning to systems with bounded\nbranching and extend its applicability to model checking branching-time\ntemporal logic, while previously it was limited to deterministic systems and\nmodel checking linear-time properties. Our method computes a finite\nstutter-insensitive bisimulation quotient of the system under analysis,\nrepresented as a decision tree. We adapt the proof rule for well-founded\nbisimulations to an iterative procedure that trains candidate decision trees\nfrom sample transitions of the system, and checks their validity over the\nentire transition relation using SMT solving. This results in a new technology\nfor model checking CTL* without the next-time operator. Our technique is sound,\nentirely automated, and yields abstractions that are succinct and effective for\nformal verification and system diagnostics. We demonstrate the efficacy of our\nmethod on diverse benchmarks comprising concurrent software, communication\nprotocols and robotic scenarios. Our method performs comparably to mature tools\nin the special case of LTL model checking, and outperforms the state of the art\nin CTL and CTL* model checking for systems with very large and countably\ninfinite state space.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-16T16:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.12260v1","title":"On resolution of L1-norm minimization via a two-metric adaptive\n  projection method","summary":"The two-metric projection method is a simple yet elegant algorithm proposed\nby Bertsekas\n  to address bound/box-constrained optimization problems. The algorithm's low\nper-iteration\n  cost and potential for using Hessian information make it a favorable\ncomputation method\n  for this problem class. Inspired by this algorithm, we propose a two-metric\nadaptive projection\n  method for solving the $\\ell_1$-norm regularization problem that inherits\nthese advantages. We demonstrate that the method is theoretically sound -\n  it has global convergence. Furthermore, it is capable of manifold\nidentification and has\n  superlinear convergence rate under the error bound condition and strict\ncomplementarity.\n  Therefore, given sparsity in the solution, the method enjoys superfast\nconvergence in iteration\n  while maintaining scalability, making it desirable for large-scale problems.\nWe also equip\n  the algorithm with competitive complexity to solve nonconvex problems.\nNumerical experiments\n  are conducted to illustrate the advantages of this algorithm implied by the\ntheory compared\n  to other competitive methods, especially in large-scale scenarios. In\ncontrast to the original two-metric projection method, our algorithm directly\nsolves the $\\ell_1$-norm minimization problem without resorting to the\nintermediate reformulation as a bound-constrained problem, so it circumvents\nthe issue of numerical instability.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T17:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.12277v1","title":"On D-spaces and Covering Properties","summary":"In this thesis, we introduce the subject of D-spaces and some of its most\nimportant open problems which are related to well known covering properties. We\nthen introduce a new approach for studying D-spaces and covering properties in\ngeneral. We start by defining a topology on the family of all principal\nultrafilters of a set $X$ called the principal ultrafilter topology. We show\nthat each open neighborhood assignment could be transformed uniquely to a\nspecial continuous map using the principal ultrafilter topology. We study some\nstructures related to this special continuous map in the category Top, then we\nobtain a characterization of D-spaces via this map. Finally, we prove some\nresults on Lindel\\\"of, paracompact, and metacompact spaces that are related to\nthe property D.","main_category":"math.GN","categories":"math.GN","published":"2025-04-16T17:35:51Z"}
{"aid":"http://arxiv.org/abs/2504.12606v1","title":"Robo-SGG: Exploiting Layout-Oriented Normalization and Restitution for\n  Robust Scene Graph Generation","summary":"In this paper, we introduce a novel method named Robo-SGG, i.e.,\nLayout-Oriented Normalization and Restitution for Robust Scene Graph\nGeneration. Compared to the existing SGG setting, the robust scene graph\ngeneration aims to perform inference on a diverse range of corrupted images,\nwith the core challenge being the domain shift between the clean and corrupted\nimages. Existing SGG methods suffer from degraded performance due to\ncompromised visual features e.g., corruption interference or occlusions. To\nobtain robust visual features, we exploit the layout information, which is\ndomain-invariant, to enhance the efficacy of existing SGG methods on corrupted\nimages. Specifically, we employ Instance Normalization(IN) to filter out the\ndomain-specific feature and recover the unchangeable structural features, i.e.,\nthe positional and semantic relationships among objects by the proposed\nLayout-Oriented Restitution. Additionally, we propose a Layout-Embedded Encoder\n(LEE) that augments the existing object and predicate encoders within the SGG\nframework, enriching the robust positional and semantic features of objects and\npredicates. Note that our proposed Robo-SGG module is designed as a\nplug-and-play component, which can be easily integrated into any baseline SGG\nmodel. Extensive experiments demonstrate that by integrating the\nstate-of-the-art method into our proposed Robo-SGG, we achieve relative\nimprovements of 5.6%, 8.0%, and 6.5% in mR@50 for PredCls, SGCls, and SGDet\ntasks on the VG-C dataset, respectively, and achieve new state-of-the-art\nperformance in corruption scene graph generation benchmark (VG-C and GQA-C). We\nwill release our source code and model.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T03:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.12617v1","title":"Bayesian Density-Density Regression with Application to Cell-Cell\n  Communications","summary":"We introduce a scalable framework for regressing multivariate distributions\nonto multivariate distributions, motivated by the application of inferring\ncell-cell communication from population-scale single-cell data. The observed\ndata consist of pairs of multivariate distributions for ligands from one cell\ntype and corresponding receptors from another. For each ordered pair $e=(l,r)$\nof cell types $(l \\neq r)$ and each sample $i = 1, \\ldots, n$, we observe a\npair of distributions $(F_{ei}, G_{ei})$ of gene expressions for ligands and\nreceptors of cell types $l$ and $r$, respectively. The aim is to set up a\nregression of receptor distributions $G_{ei}$ given ligand distributions\n$F_{ei}$. A key challenge is that these distributions reside in distinct spaces\nof differing dimensions. We formulate the regression of multivariate densities\non multivariate densities using a generalized Bayes framework with the sliced\nWasserstein distance between fitted and observed distributions. Finally, we use\ninference under such regressions to define a directed graph for cell-cell\ncommunications.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO,stat.ML","published":"2025-04-17T03:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.12639v1","title":"Mass measurements of proton-rich nuclei in the vicinity of ${}^{84}$Mo\n  and their impact on rp-process in type I X-ray burst","summary":"We report on the mass measurement of the rapid proton-capture process key\nnuclide ${}^{84}$Mo and its vicinity, such as ${}^{78}$Y${}^{\\rm m}$,\n${}^{79}$Y, ${}^{83}$Nb, and ${}^{88}$Ru, using the multi-reflection\ntime-of-flight spectrograph at RIKEN RIBF. For ${}^{78}$Y${}^{\\rm m}$,\n${}^{84}$Mo, and ${}^{88}$Ru, their masses are experimentally determined for\nthe first time with uncertainties of $\\delta m \\approx 20~{\\rm keV}$. The mass\nprecision of ${}^{79}$Y and ${}^{83}$Nb is improved to 13 keV and 9.6 keV,\nrespectively. The new $\\alpha$-separation energy of ${}^{84}$Mo, 1.434(83) MeV,\nunambiguously rules out the possibility of forming the ZrNb cycle. The X-ray\nburst simulation with the new masses shows that our measurements effectively\nremove the large final abundance uncertainties in the $A=80-90$ mass region.\nThe new mass values improve the prediction power for the composition of the\nnuclear ashes in X-ray bursts, including the production of light $p$-nuclei.","main_category":"nucl-ex","categories":"nucl-ex,astro-ph.HE,nucl-th","published":"2025-04-17T04:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.12657v1","title":"Photon Calibration Performance of KAGRA during the 4th Joint Observing\n  Run (O4)","summary":"KAGRA is a kilometer-scale cryogenic gravitational-wave (GW) detector in\nJapan. It joined the 4th joint observing run (O4) in May 2023 in collaboration\nwith the Laser Interferometer GW Observatory (LIGO) in the USA, and Virgo in\nItaly. After one month of observations, KAGRA entered a break period to enhance\nits sensitivity to GWs, and it is planned to rejoin O4 before its scheduled end\nin October 2025. To accurately recover the information encoded in the GW\nsignals, it is essential to properly calibrate the observed signals. We employ\na photon calibration (Pcal) system as a reference signal injector to calibrate\nthe output signals obtained from the telescope. In ideal future conditions, the\nuncertainty in Pcal could dominate the uncertainty in the observed data. In\nthis paper, we present the methods used to estimate the uncertainty in the Pcal\nsystems employed during KAGRA O4 and report an estimated system uncertainty of\n0.79%, which is three times lower than the uncertainty achieved in the previous\n3rd joint observing run (O3) in 2020. Additionally, we investigate the\nuncertainty in the Pcal laser power sensors, which had the highest impact on\nthe Pcal uncertainty, and estimate the beam positions on the KAGRA main mirror,\nwhich had the second highest impact. The Pcal systems in KAGRA are the first\nfully functional calibration systems for a cryogenic GW telescope. To avoid\ninterference with the KAGRA cryogenic systems, the Pcal systems incorporate\nunique features regarding their placement and the use of telephoto cameras,\nwhich can capture images of the mirror surface at almost normal incidence. As\nfuture GW telescopes, such as the Einstein Telescope, are expected to adopt\ncryogenic techniques, the performance of the KAGRA Pcal systems can serve as a\nvaluable reference.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-17T05:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.12658v1","title":"Rare-Event-Induced Ergodicity Breaking in Logarithmic Aging Systems","summary":"Ergodicity breaking and aging effects are fundamental challenges in\nout-of-equilibrium systems. Various mechanisms have been proposed to understand\nthe non-ergodic and aging phenomena, possibly related to observations in\nsystems ranging from structural glass and Anderson glasses to biological\nsystems and mechanical systems. While anomalous diffusion described by Levy\nstatistics efficiently captures ergodicity breaking, the origin of aging and\nergodicity breaking in systems with ultraslow dynamics remain unclear. Here, we\nreport a novel mechanism of ergodicity breaking in systems exhibiting log-aging\ndiffusion. This mechanism, characterized by increasingly infrequent rare events\nwith aging, yields statistics deviating significantly from Levy distribution,\nbreaking ergodicity as shown by unequal time- and ensemble-averaged mean\nsquared displacements and two distinct asymptotic probability distribution\nfunctions. Notably, although these rare events contribute negligibly to\nstatistical averages, they dramatically change the system's characteristic\ntime. This work lays the groundwork for microscopic understanding of\nout-of-equilibrium systems and provides new perspectives on glasses and\nGriffiths-McCoy singularities.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.soft,cond-mat.stat-mech","published":"2025-04-17T05:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.12663v1","title":"Persona-judge: Personalized Alignment of Large Language Models via\n  Token-level Self-judgment","summary":"Aligning language models with human preferences presents significant\nchallenges, particularly in achieving personalization without incurring\nexcessive computational costs. Existing methods rely on reward signals and\nadditional annotated data, limiting their scalability and adaptability to\ndiverse human values. To address these challenges, we introduce Persona-judge,\na novel discriminative paradigm that enables training-free personalized\nalignment with unseen preferences. Instead of optimizing policy parameters\nthrough external reward feedback, Persona-judge leverages the intrinsic\npreference judgment capabilities of the model. Specifically, a draft model\ngenerates candidate tokens conditioned on a given preference, while a judge\nmodel, embodying another preference, cross-validates the predicted tokens\nwhether to be accepted. Experimental results demonstrate that Persona-judge,\nusing the inherent preference evaluation mechanisms of the model, offers a\nscalable and computationally efficient solution to personalized alignment,\npaving the way for more adaptive customized alignment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T05:50:13Z"}
{"aid":"http://arxiv.org/abs/2504.12669v1","title":"A novel fast sweeping method for computing the attenuation operator\n  $t^*$ in absorbing media","summary":"$t^*$ represents the total path attenuation and characterizes the amplitude\ndecay of a propagating seismic wave. Calculating the attenuation operator $t^*$\nis typically required in seismic attenuation tomography. Traditional methods\nfor calculating $t^*$ require determining the ray path explicitly. However, ray\ntracing can be computationally intensive when processing large datasets, and\nconventional ray tracing techniques may fail even in mildly heterogeneous\nmedia. In this study, we propose a modified fast sweeping method (MFSM) to\nsolve the governing equation for $t^*$ without explicitly calculating the ray\npath. The approach consists of two main steps. First, the traveltime field is\ncalculated by numerically solving the eikonal equation using the fast sweeping\nmethod. Second, $t^*$ is computed by solving its governing equation with the\nMFSM, based on the discretization of the gradient of $t^*$ using an upwinding\nscheme derived from the traveltime gradient. The MFSM is rigorously validated\nthrough comparisons with analytical solutions and by examining $t^*$ errors\nunder grid refinement in both simple and complex models. Key performance\nmetrics, including convergence, number of iterations, and computation time, are\nevaluated. Two versions of the MFSM are developed for both Cartesian and\nspherical coordinate systems. We demonstrate the practical applicability of the\ndeveloped MFSM in calculating $t^*$ in North Island, and discuss the method's\nefficiency in estimating earthquake response spectra.","main_category":"physics.geo-ph","categories":"physics.geo-ph,physics.comp-ph","published":"2025-04-17T05:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.12674v1","title":"Can spacetime fluctuations generate entanglement between co-moving\n  accelerated detectors?","summary":"Recent studies [Class. Quant. Grav. 42, 03LT01 (2025); Phys. Rev. D 111,\n045023 (2025)] indicate that in a nested sequence of Rindler wedges, vacuum of\nformer Rindler frame appears to be thermally populated for an observer in\nshifted Rindler frame. Interestingly, this thermality is independent of shift\nparameter as long as it is non-zero and therefore arises even if the shift\nparameter is as small as Planck length. Building on this insight, we propose a\nset-up involving two atoms accelerating with identical acceleration. We find\nthat if their Rindler frames (consequently their trajectories) get\ninfinitesimally separated, the atoms become entangled. Remarkably again, this\nentanglement, like the perceived thermality, is independent of the shift\nparameter, provided it is non-vanishing. We investigate the dependence of\nentanglement on acceleration of the detectors. The present study indicates that\nthe entanglement between two detectors, moving on the same Rindler wedge, is\npossible. Moreover, small spacetime fluctuations can lead to entanglement\nbetween detectors, moving along same classical trajectory. Hence we feel that\nsuch theoretical prediction has potential to probe the Planck length nature of\nspacetime.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-17T06:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.12690v1","title":"Accessibility Recommendations for Designing Better Mobile Application\n  User Interfaces for Seniors","summary":"Seniors represent a growing user base for mobile applications; however, many\napps fail to adequately address their accessibility challenges and usability\npreferences. To investigate this issue, we conducted an exploratory focus group\nstudy with 16 senior participants, from which we derived an initial set of user\npersonas highlighting key accessibility and personalisation barriers. These\npersonas informed the development of a model-driven engineering toolset, which\nwas used to generate adaptive mobile app prototypes tailored to seniors' needs.\nWe then conducted a second focus group study with 22 seniors to evaluate these\nprototypes and validate our findings. Based on insights from both studies, we\ndeveloped a refined set of personas and a series of accessibility and\npersonalisation recommendations grounded in empirical data, prior research,\naccessibility standards, and developer resources, aimed at supporting software\npractitioners in designing more inclusive mobile applications.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-04-17T06:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.12727v1","title":"Efficient Major Transition Exchange under Distributional and Dual\n  Priority-respecting Constraints","summary":"Many real matching markets encounter distributional and fairness constraints.\nMotivated by the Chinese Major Transition Program (CMT), this paper studies the\ndesign of exchange mechanisms within a fresh framework of both distributional\nand dual priority-respecting constraints. Specifically, each student has an\ninitial assigned major and applies to transfer to a more desirable one. A\nstudent can successfully transfer majors only if they obtain eligibility from\nboth their initial major and the applied major. Each major has a dual priority:\na strict priority over current students who wish to transfer out and a strict\npriority over students from other majors who wish to transfer in. Additionally,\neach major faces a ceiling constraint and a floor constraint to regulate\nstudent distribution. We show that the existing mechanisms of CMT result in\navoidable inefficiencies, and propose two mechanisms that can match students to\nmajors in an efficient way as well as respecting each major's distributional\nand dual priority. The efficient mechanisms are based on a proposed solution\nconcept: eligibility maximization (EM), and two processes for identifying\nimprovement cycles--specifically, transfer-in exchangeable cycles and\ntransfer-out exchangeable cycles.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-17T08:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.12728v1","title":"Seierstad Sufficient Conditions for Stochastic Optimal Control Problems\n  with Infinite Horizon","summary":"In this note we consider a problem of stochastic optimal control with the\ninfinite-time horizon. We present analogues of the Seierstad sufficient\nconditions of overtaking optimality based on the dual variables stochastic\ndescribed by BSDEs appeared in the Bismut-Pontryagin maximum principle.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T08:09:23Z"}
{"aid":"http://arxiv.org/abs/2504.12731v1","title":"Nonlinear spin dynamics across Néel phase transition in\n  ferromagnetic/antiferromagnetic multilayers","summary":"We observe strongly nonlinear spin dynamics in ferro-/antiferro-magnetic\nmultilayers, controlled by the number of bilayers in the system, layer\nthicknesses, as well as temperature, peaking in magnitude near the N\\'eel point\nof the antiferromagnetic layers just above room temperature. Well above the\nN\\'eel transition, the individual ferromagnetic layers are exchange decoupled\nand resonate independently. As the temperature is lowered toward the N\\'eel\npoint, the ferromagnetic proximity effect through the thin antiferromagnetic\nspacers transforms the system into a weakly coupled macrospin chain along the\nfilm normal, which exhibits pronounced standing spin-wave resonance modes,\ncomparable in intensity to the uniform resonance in the ferromagnetic layers.\nThese findings are supported by our micromagnetic simulations showing clear\nspin-wave profiles with precessional phase lag along the macrospin chain. Well\nbelow the N\\'eel transition, the FeMn layers order strongly\nantiferromagnetically and exchange-pin the ferromagnetic layers to effectively\nmake the multilayer one macrospin. The appearance and intensity of the\nhigh-frequency spin-wave modes can thus be conveniently controlled by thermal\ngating the multilayer. The nonlinearity in the microwave response of the\ndemonstrated material can approach 100\\%, large compared to nonlinear materials\nused in e.g. optics, with second-harmonic generation often at the single\npercentage level.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T08:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.12743v1","title":"Quasinormal Modes and Greybody Factors of Scalar Field Perturbations in\n  the NED Corrected Charged Black Hole Spacetime","summary":"Inspired by the quark-antiquark confinement potential, Mazharimousavi et al.\n\\cite{Mazharimousavi:2023okd} proposed a nonlinear electrodynamics (NED) model,\nand based on this model, they constructed a charged black hole solution that\nincludes a logarithmic correction term ($\\propto \\frac{\\zeta \\ln r}{r}$). On\nthe basis of the Reissner-Nordstr\\\"om metric, this solution realizes a\nlong-range confinement correction by introducing the NED parameter $\\zeta$,\nproviding a new theoretical perspective for explaining the anomalies in galaxy\nrotation curves. To deeply explore the dynamic properties of this black hole\nsolution, this paper combines two complementary methods, namely, time-domain\nevolution and the WKB approximation, to calculate the quasinormal mode (QNM)\nspectrum of its scalar field perturbations. The research results show that the\noscillation frequencies and decay rates of the low-order QNM modes decrease\nmonotonically with the increase of the NED parameter $\\zeta$, and exhibit an\napproximately linear dependence. The analysis of the greybody factor (GF)\nindicates that as $\\zeta$ increases, the transmittance of the low-frequency\nscalar field also increases. The enhanced long-range confinement effect caused\nby the increase of $\\zeta$ makes low-frequency perturbations more likely to\nsurvive and propagate in space-time on the one hand, and at the same time\nenhances the transmission ability of the low-frequency scalar field. These\ncharacteristics provide key theoretical predictions and potential observational\nfeatures for testing and constraining such NED models in a strong gravitational\nfield environment in the future using the observational data of gravitational\nwave astronomy or Hawking radiation.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-17T08:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.12746v1","title":"A note on one-variable theorems for NSOP","summary":"We give an example of an SOP theory $T$, such that any $L(M)$-formula\n$\\varphi(x,y)$ with $|y|=1$ is NSOP. We show that any such $T$ must have the\nindependence property. We also give a simplified proof of Lachlan's theorem\nthat if every $L$-formula $\\varphi(x,y)$ with $|x|=1$ is NSOP, then $T$ is\nNSOP.","main_category":"math.LO","categories":"math.LO","published":"2025-04-17T08:38:02Z"}
{"aid":"http://arxiv.org/abs/2504.12749v1","title":"LAD-Reasoner: Tiny Multimodal Models are Good Reasoners for Logical\n  Anomaly Detection","summary":"Recent advances in industrial anomaly detection have highlighted the need for\ndeeper logical anomaly analysis, where unexpected relationships among objects,\ncounts, and spatial configurations must be identified and explained. Existing\napproaches often rely on large-scale external reasoning modules or elaborate\npipeline designs, hindering practical deployment and interpretability. To\naddress these limitations, we introduce a new task, Reasoning Logical Anomaly\nDetection (RLAD), which extends traditional anomaly detection by incorporating\nlogical reasoning. We propose a new framework, LAD-Reasoner, a customized tiny\nmultimodal language model built on Qwen2.5-VL 3B. Our approach leverages a\ntwo-stage training paradigm that first employs Supervised Fine-Tuning (SFT) for\nfine-grained visual understanding, followed by Group Relative Policy\nOptimization (GRPO) to refine logical anomaly detection and enforce coherent,\nhuman-readable reasoning. Crucially, reward signals are derived from both the\ndetection accuracy and the structural quality of the outputs, obviating the\nneed for building chain of thought (CoT) reasoning data. Experiments on the\nMVTec LOCO AD dataset show that LAD-Reasoner, though significantly smaller,\nmatches the performance of Qwen2.5-VL-72B in accuracy and F1 score, and further\nexcels in producing concise and interpretable rationales. This unified design\nreduces reliance on large models and complex pipelines, while offering\ntransparent and interpretable insights into logical anomaly detection. Code and\ndata will be released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:41:23Z"}
{"aid":"http://arxiv.org/abs/2504.12750v1","title":"Spatial Functional Deep Neural Network Model: A New Prediction Algorithm","summary":"Accurate prediction of spatially dependent functional data is critical for\nvarious engineering and scientific applications. In this study, a spatial\nfunctional deep neural network model was developed with a novel non-linear\nmodeling framework that seamlessly integrates spatial dependencies and\nfunctional predictors using deep learning techniques. The proposed model\nextends classical scalar-on-function regression by incorporating a spatial\nautoregressive component while leveraging functional deep neural networks to\ncapture complex non-linear relationships. To ensure a robust estimation, the\nmethodology employs an adaptive estimation approach, where the spatial\ndependence parameter was first inferred via maximum likelihood estimation,\nfollowed by non-linear functional regression using deep learning. The\neffectiveness of the proposed model was evaluated through extensive Monte Carlo\nsimulations and an application to Brazilian COVID-19 data, where the goal was\nto predict the average daily number of deaths. Comparative analysis with\nmaximum likelihood-based spatial functional linear regression and functional\ndeep neural network models demonstrates that the proposed algorithm\nsignificantly improves predictive performance. The results for the Brazilian\nCOVID-19 data showed that while all models achieved similar mean squared error\nvalues over the training modeling phase, the proposed model achieved the lowest\nmean squared prediction error in the testing phase, indicating superior\ngeneralization ability.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-17T08:44:29Z"}
{"aid":"http://arxiv.org/abs/2504.12760v1","title":"Analyzing multi-center randomized trials with covariate adjustment while\n  accounting for clustering","summary":"Augmented inverse probability weighting (AIPW) and G-computation with\ncanonical generalized linear models have become increasingly popular for\nestimating the average treatment effect in randomized experiments. These\nestimators leverage outcome prediction models to adjust for imbalances in\nbaseline covariates across treatment arms, improving statistical power compared\nto unadjusted analyses, while maintaining control over Type I error rates, even\nwhen the models are misspecified. Practical application of such estimators\noften overlooks the clustering present in multi-center clinical trials. Even\nwhen prediction models account for center effects, this neglect can degrade the\ncoverage of confidence intervals, reduce the efficiency of the estimators, and\ncomplicate the interpretation of the corresponding estimands. These issues are\nparticularly pronounced for estimators of counterfactual means, though less\nsevere for those of the average treatment effect, as demonstrated through Monte\nCarlo simulations and supported by theoretical insights. To address these\nchallenges, we develop efficient estimators of counterfactual means and the\naverage treatment effect in a random center. These extract information from\nbaseline covariates by relying on outcome prediction models, but remain\nunbiased in large samples when these models are misspecified. We also introduce\nan accompanying inference framework inspired by random-effects meta-analysis\nand relevant for settings where data from many small centers are being\nanalyzed. Adjusting for center effects yields substantial gains in efficiency,\nespecially when treatment effect heterogeneity across centers is large. Monte\nCarlo simulations and application to the WASH Benefits Bangladesh study\ndemonstrate adequate performance of the proposed methods.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T08:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.12794v1","title":"Supporting Urban Low-Altitude Economy: Channel Gain Map Inference Based\n  on 3D Conditional GAN","summary":"The advancement of advanced air mobility (AAM) in recent years has given rise\nto the concept of low-altitude economy (LAE). However, the diverse flight\nactivities associated with the emerging LAE applications in urban scenarios\nconfront complex physical environments, which urgently necessitates ubiquitous\nand reliable communication to guarantee the operation safety of the\nlow-altitude aircraft. As one of promising technologies for the sixth\ngeneration (6G) mobile networks, channel knowledge map (CKM) enables the\nenvironment-aware communication by constructing a site-specific dataset,\nthereby providing a priori on-site information for the aircraft to obtain the\nchannel state information (CSI) at arbitrary locations with much reduced online\noverhead. Diverse base station (BS) deployments in the three-dimensional (3D)\nurban low-altitude environment require efficient 3D CKM construction to capture\nspatial channel characteristics with less overhead. Towards this end, this\npaper proposes a 3D channel gain map (CGM) inference method based on a 3D\nconditional generative adversarial network (3D-CGAN). Specifically, we first\nanalyze the potential deployment types of BSs in urban low-altitude scenario,\nand investigate the CGM representation with the corresponding 3D channel gain\nmodel. The framework of the proposed 3D-CGAN is then discussed, which is\ntrained by a dataset consisting of existing CGMs. Consequently, the trained\n3D-CGAN is capable of inferring the corresponding CGM only based on the BS\ncoordinate without additional measurement. The simulation results demonstrate\nthat the CGMs inferred by the proposed 3D-CGAN outperform those of the\nbenchmark schemes, which can accurately reflect the radio propagation condition\nin 3D environment.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T09:55:03Z"}
{"aid":"http://arxiv.org/abs/2504.12805v1","title":"Assesing LLMs in Art Contexts: Critique Generation and Theory of Mind\n  Evaluation","summary":"This study explored how large language models (LLMs) perform in two areas\nrelated to art: writing critiques of artworks and reasoning about mental states\n(Theory of Mind, or ToM) in art-related situations. For the critique generation\npart, we built a system that combines Noel Carroll's evaluative framework with\na broad selection of art criticism theories. The model was prompted to first\nwrite a full-length critique and then shorter, more coherent versions using a\nstep-by-step prompting process. These AI-generated critiques were then compared\nwith those written by human experts in a Turing test-style evaluation. In many\ncases, human subjects had difficulty telling which was which, and the results\nsuggest that LLMs can produce critiques that are not only plausible in style\nbut also rich in interpretation, as long as they are carefully guided. In the\nsecond part, we introduced new simple ToM tasks based on situations involving\ninterpretation, emotion, and moral tension, which can appear in the context of\nart. These go beyond standard false-belief tests and allow for more complex,\nsocially embedded forms of reasoning. We tested 41 recent LLMs and found that\ntheir performance varied across tasks and models. In particular, tasks that\ninvolved affective or ambiguous situations tended to reveal clearer\ndifferences. Taken together, these results help clarify how LLMs respond to\ncomplex interpretative challenges, revealing both their cognitive limitations\nand potential. While our findings do not directly contradict the so-called\nGenerative AI Paradox--the idea that LLMs can produce expert-like output\nwithout genuine understanding--they suggest that, depending on how LLMs are\ninstructed, such as through carefully designed prompts, these models may begin\nto show behaviors that resemble understanding more closely than we might\nassume.","main_category":"cs.CL","categories":"cs.CL,cs.CY,cs.HC","published":"2025-04-17T10:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.12816v1","title":"SMARTe: Slot-based Method for Accountable Relational Triple extraction","summary":"Relational Triple Extraction (RTE) is a fundamental task in Natural Language\nProcessing (NLP). However, prior research has primarily focused on optimizing\nmodel performance, with limited efforts to understand the internal mechanisms\ndriving these models. Many existing methods rely on complex preprocessing to\ninduce specific interactions, often resulting in opaque systems that may not\nfully align with their theoretical foundations. To address these limitations,\nwe propose SMARTe: a Slot-based Method for Accountable Relational Triple\nextraction. SMARTe introduces intrinsic interpretability through a slot\nattention mechanism and frames the task as a set prediction problem. Slot\nattention consolidates relevant information into distinct slots, ensuring all\npredictions can be explicitly traced to learned slot representations and the\ntokens contributing to each predicted relational triple. While emphasizing\ninterpretability, SMARTe achieves performance comparable to state-of-the-art\nmodels. Evaluations on the NYT and WebNLG datasets demonstrate that adding\ninterpretability does not compromise performance. Furthermore, we conducted\nqualitative assessments to showcase the explanations provided by SMARTe, using\nattention heatmaps that map to their respective tokens. We conclude with a\ndiscussion of our findings and propose directions for future research.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T10:21:15Z"}
{"aid":"http://arxiv.org/abs/2504.12818v1","title":"An etude on a renormalization","summary":"In this paper, we study renormalization, that is, the procedure for\neliminating singularities, for a special model using both combinatorial\ntechniques in the framework of working with formal series, and using a limit\ntransition in a standard multidimensional integral, taking into account the\nremoval of the singular components. Special attention is paid to the\ncomparative analysis of the two views on the problem. It is remarkably that the\ndivergences, which have the same form in one approach, acquire a different\nnature in another approach and lead to interesting consequences. A special\ndeformation of the spectrum is used as regularization.","main_category":"math-ph","categories":"math-ph,hep-th,math.CA,math.MP","published":"2025-04-17T10:22:01Z"}
{"aid":"http://arxiv.org/abs/2504.12830v1","title":"Questions: A Taxonomy for Critical Reflection in Machine-Supported\n  Decision-Making","summary":"Decision-makers run the risk of relying too much on machine recommendations.\nExplainable AI, a common strategy for calibrating reliance, has mixed and even\nnegative effects, such as increasing overreliance. To cognitively engage the\ndecision-maker and to facilitate a deliberate decision-making process, we\npropose a potential `reflection machine' that supports critical reflection\nabout the pending decision, including the machine recommendation. Reflection\nhas been shown to improve critical thinking and reasoning, and thus\ndecision-making. One way to stimulate reflection is to ask relevant questions.\nTo systematically create questions, we present a question taxonomy inspired by\nSocratic questions and human-centred explainable AI. This taxonomy can\ncontribute to the design of such a `reflection machine' that asks\ndecision-makers questions. Our work is part of the growing research on\nhuman-machine collaborations that goes beyond the paradigm of machine\nrecommendations and explanations, and aims to enable greater human oversight as\nrequired by the European AI Act.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-17T10:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.12864v1","title":"Unbiased Quantum Error Mitigation Without Reliance on an Accurate Error\n  Model","summary":"Probabilistic error cancellation is a quantum error mitigation technique\ncapable of producing unbiased computation results but requires an accurate\nerror model. Constructing this model involves estimating a set of parameters,\nwhich, in the worst case, may scale exponentially with the number of qubits. In\nthis paper, we introduce a method called spacetime noise inversion, revealing\nthat unbiased quantum error mitigation can be achieved with just a single\naccurately measured error parameter and a sampler of Pauli errors. The error\nsampler can be efficiently implemented in conjunction with quantum error\ncorrection. We provide rigorous analyses of bias and cost, showing that the\ncost of measuring the parameter and sampling errors is low -- comparable to the\ncost of the computation itself. Moreover, our method is robust to the\nfluctuation of error parameters, a limitation of unbiased quantum error\nmitigation in practice. These findings highlight the potential of integrating\nquantum error mitigation with error correction as a promising approach to\nsuppress computational errors in the early fault-tolerant era.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T11:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.12877v1","title":"Market-Driven Flexibility Provision: A Tri-Level Optimization Approach\n  for Carbon Reduction","summary":"The integration of renewable energy resources (RES) in the power grid can\nreduce carbon intensity, but also presents certain challenges. The uncertainty\nand intermittent nature of RES emphasize the need for flexibility in power\nsystems. Moreover, there are noticeable mismatches between real-time\nelectricity prices and carbon intensity patterns throughout the day. These\ndiscrepancies may lead customers to schedule energy-intensive tasks during the\nearly hours of the day, a period characterized by lower electricity prices but\nhigher carbon intensity. This paper introduces a novel and comprehensive\nframework aimed at encouraging customer participation in electricity markets\nand aligning their flexibility with carbon intensity trends. The proposed\napproach integrates an incentive-based tariff with a tri-level optimization\nmodel, where customers are motivated to submit flexibility bids and, in return,\nreceive financial rewards based on their contributions. The tri-level model\nensures a dynamic interaction between the market operation platform (MOP) and\nend-users. Simulations are performed on a modified IEEE-33 bus system,\nsupported by two scenarios with different RES generations and customer\nbehaviors. Results demonstrate the effectiveness of the proposed framework in\nguiding the customers' consumption behaviors towards low carbon intensity.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-17T12:04:49Z"}
{"aid":"http://arxiv.org/abs/2504.12887v1","title":"A Novel View on the Inner Crusts of Neo-Neutron Stars: exotic light\n  nuclei, diffusional and thermodynamical stability","summary":"Based on an extended nuclear statistical equilibrium model, we investigate\nthe properties of non-accreted crusts of young and warm neo-neutron stars,\ni.e., of finite-temperature inhomogeneous dense matter in beta equilibrium. We\npresent two novel results and one known, but frequently ignored property of\nsuch matter. The first new feature is the appearance, in the deep inner crust,\nof an extensive and almost pure $^{14}$He layer that extends up to the density\nof the transition to homogeneous matter. This layer may challenge the idea of\nnuclear pasta phases, significantly impact the transport properties and the\ncrust crystallization process. Second, we raise the question of the\n(in)stability of the inner crust with respect to diffusion of ions (buoyancy)\nand demonstrate that our crust is stable, in contrast with the predictions of\nsome other models. Finally, we show that subsaturated stellar matter is\nthermodynamically stable with respect to density fluctuations, which rules out\na first-order phase transition between inhomogeneous and homogeneous phases.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-04-17T12:21:46Z"}
{"aid":"http://arxiv.org/abs/2504.12901v1","title":"Control of blow-up profiles for the mass-critical focusing nonlinear\n  Schrödinger equation on bounded domains","summary":"In this paper, we consider the mass-critical focusing nonlinear Schr\\\"odinger\non bounded two-dimensional domains with Dirichlet boundary conditions. In the\nabsence of control, it is well-known that free solutions starting from initial\ndata sufficiently large can blow-up. More precisely, given a finite number of\npoints, there exists particular profiles blowing up exactly at these points at\nthe blow-up time. For pertubations of these profiles, we show that, with the\nhelp of an appropriate nonlinear feedback law located in an open set containing\nthe blow-up points, the blow-up can be prevented from happening. More\nspecifically, we construct a small-time control acting just before the blow-up\ntime. The solution may then be extended globally in time. This is the first\nresult of control for blow-up profiles for nonlinear Schr\\\"odinger type\nequations. Assuming further a geometrical control condition on the support of\nthe control, we are able to prove a null-controllability result for such\nblow-up profiles. Finally, we discuss possible extensions to three-dimensional\ndomains.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-17T12:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.12914v1","title":"In Which Areas of Technical AI Safety Could Geopolitical Rivals\n  Cooperate?","summary":"International cooperation is common in AI research, including between\ngeopolitical rivals. While many experts advocate for greater international\ncooperation on AI safety to address shared global risks, some view cooperation\non AI with suspicion, arguing that it can pose unacceptable risks to national\nsecurity. However, the extent to which cooperation on AI safety poses such\nrisks, as well as provides benefits, depends on the specific area of\ncooperation. In this paper, we consider technical factors that impact the risks\nof international cooperation on AI safety research, focusing on the degree to\nwhich such cooperation can advance dangerous capabilities, result in the\nsharing of sensitive information, or provide opportunities for harm. We begin\nby why nations historically cooperate on strategic technologies and analyse\ncurrent US-China cooperation in AI as a case study. We further argue that\nexisting frameworks for managing associated risks can be supplemented with\nconsideration of key risks specific to cooperation on technical AI safety\nresearch. Through our analysis, we find that research into AI verification\nmechanisms and shared protocols may be suitable areas for such cooperation.\nThrough this analysis we aim to help researchers and governments identify and\nmitigate the risks of international cooperation on AI safety research, so that\nthe benefits of cooperation can be fully realised.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-17T13:03:56Z"}
{"aid":"http://arxiv.org/abs/2504.12959v1","title":"Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D\n  Semantic Occupancy Prediction","summary":"We present GDFusion, a temporal fusion method for vision-based 3D semantic\noccupancy prediction (VisionOcc). GDFusion opens up the underexplored aspects\nof temporal fusion within the VisionOcc framework, focusing on both temporal\ncues and fusion strategies. It systematically examines the entire VisionOcc\npipeline, identifying three fundamental yet previously overlooked temporal\ncues: scene-level consistency, motion calibration, and geometric\ncomplementation. These cues capture diverse facets of temporal evolution and\nmake distinct contributions across various modules in the VisionOcc framework.\nTo effectively fuse temporal signals across heterogeneous representations, we\npropose a novel fusion strategy by reinterpreting the formulation of vanilla\nRNNs. This reinterpretation leverages gradient descent on features to unify the\nintegration of diverse temporal information, seamlessly embedding the proposed\ntemporal cues into the network. Extensive experiments on nuScenes demonstrate\nthat GDFusion significantly outperforms established baselines. Notably, on\nOcc3D benchmark, it achieves 1.4\\%-4.8\\% mIoU improvements and reduces memory\nconsumption by 27\\%-72\\%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T14:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.12969v1","title":"Lessons from commissioning of the cryogenic system for the\n  Short-Baseline Neutrino Detector at Fermilab","summary":"Results from commissioning and first year of operations of the cryogenic\nsystem of the Short-Baseline Neutrino Detector (SBND) and its membrane cryostat\ninstalled at the Fermi National Accelerator Laboratory are described. The SBND\ndetector is installed in a 200 m$^3$ membrane cryostat filled with liquid\nargon, which serves both as target and as active media. For the correct\noperation of the detector, the liquid argon must be kept in very stable thermal\nconditions while the contamination of electronegative impurities must be\nconsistently kept at the level of small fractions of parts per billion. The\ndetector is operated in Booster Neutrino Beams (BNB) at Fermilab for the search\nof sterile neutrinos and measurements of neutrino-argon cross sections. The\ncryostat and the cryogenic systems also serve as prototypes for the much larger\nequipment to be used for the LBNF/DUNE experiment. Since its installation in\n2018-2023 and cooldown in spring of 2024, the cryostat and the cryogenic system\nhave been commissioned to support the detector operations. The lessons learned\nthrough installation, testing, commissioning, cooldown, and initial operations\nare described.","main_category":"physics.ins-det","categories":"physics.ins-det,physics.acc-ph","published":"2025-04-17T14:19:34Z"}
{"aid":"http://arxiv.org/abs/2504.12984v1","title":"A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM\n  Serving","summary":"Serving Large Language Models (LLMs) is critical for AI-powered applications\nbut demands substantial computational resources, particularly in memory\nbandwidth and computational throughput. Low-precision computation has emerged\nas a key technique to improve efficiency while reducing resource consumption.\nExisting approaches for generating low-precision kernels are limited to weight\nbit widths that are powers of two and suffer from suboptimal performance due to\nhigh-level GPU programming abstractions. These abstractions restrict critical\noptimizations, such as fine-grained register management and optimized memory\naccess patterns, which are essential for efficient low-precision computations.\nIn this paper, we introduce a virtual machine (VM) designed for General-Purpose\nGPU (GPGPU) computing, enabling support for low-precision data types with\narbitrary bit widths while maintaining GPU programmability. The proposed VM\nfeatures a thread-block-level programming model, a hierarchical memory space, a\nnovel algebraic layout system, and extensive support for diverse low-precision\ndata types. VM programs are compiled into highly efficient GPU programs with\nautomatic vectorization and instruction selection. Extensive experiments\ndemonstrate that our VM efficiently supports a full spectrum of low-precision\ndata types, and outperforms state-of-the-art low-precision kernels on their\nsupported types. Compared to existing compilers like Triton and Ladder, as well\nas hand-optimized kernels such as QuantLLM and Marlin, our VM achieves\nperformance improvements of 1.75x, 2.61x, 1.29x and 1.03x, respectively.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.PL","published":"2025-04-17T14:45:03Z"}
{"aid":"http://arxiv.org/abs/2504.12999v1","title":"GSAC: Leveraging Gaussian Splatting for Photorealistic Avatar Creation\n  with Unity Integration","summary":"Photorealistic avatars have become essential for immersive applications in\nvirtual reality (VR) and augmented reality (AR), enabling lifelike interactions\nin areas such as training simulations, telemedicine, and virtual collaboration.\nThese avatars bridge the gap between the physical and digital worlds, improving\nthe user experience through realistic human representation. However, existing\navatar creation techniques face significant challenges, including high costs,\nlong creation times, and limited utility in virtual applications. Manual\nmethods, such as MetaHuman, require extensive time and expertise, while\nautomatic approaches, such as NeRF-based pipelines often lack efficiency,\ndetailed facial expression fidelity, and are unable to be rendered at a speed\nsufficent for real-time applications. By involving several cutting-edge modern\ntechniques, we introduce an end-to-end 3D Gaussian Splatting (3DGS) avatar\ncreation pipeline that leverages monocular video input to create a scalable and\nefficient photorealistic avatar directly compatible with the Unity game engine.\nOur pipeline incorporates a novel Gaussian splatting technique with customized\npreprocessing that enables the user of \"in the wild\" monocular video capture,\ndetailed facial expression reconstruction and embedding within a fully rigged\navatar model. Additionally, we present a Unity-integrated Gaussian Splatting\nAvatar Editor, offering a user-friendly environment for VR/AR application\ndevelopment. Experimental results validate the effectiveness of our\npreprocessing pipeline in standardizing custom data for 3DGS training and\ndemonstrate the versatility of Gaussian avatars in Unity, highlighting the\nscalability and practicality of our approach.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T15:10:14Z"}
{"aid":"http://arxiv.org/abs/2504.13013v1","title":"Minkowski chirality: a measure of reflectional asymmetry of convex\n  bodies","summary":"Using an optimal containment approach, we quantify the asymmetry of convex\nbodies in $\\mathbb{R}^n$ with respect to reflections across affine subspaces of\na given dimension. We prove general inequalities relating these ''Minkowski\nchirality'' measures to Banach--Mazur distances and to each other, and prove\ntheir continuity with respect to the Hausdorff distance. In the planar case, we\ndetermine the reflection axes at which the Minkowski chirality of triangles and\nparallelograms is attained, and show that $\\sqrt{2}$ is a tight upper bound on\nthe chirality in both cases.","main_category":"math.MG","categories":"math.MG","published":"2025-04-17T15:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.13023v1","title":"ChatEXAONEPath: An Expert-level Multimodal Large Language Model for\n  Histopathology Using Whole Slide Images","summary":"Recent studies have made significant progress in developing large language\nmodels (LLMs) in the medical domain, which can answer expert-level questions\nand demonstrate the potential to assist clinicians in real-world clinical\nscenarios. Studies have also witnessed the importance of integrating various\nmodalities with the existing LLMs for a better understanding of complex\nclinical contexts, which are innately multi-faceted by nature. Although studies\nhave demonstrated the ability of multimodal LLMs in histopathology to answer\nquestions from given images, they lack in understanding of thorough clinical\ncontext due to the patch-level data with limited information from public\ndatasets. Thus, developing WSI-level MLLMs is significant in terms of the\nscalability and applicability of MLLMs in histopathology. In this study, we\nintroduce an expert-level MLLM for histopathology using WSIs, dubbed as\nChatEXAONEPath. We present a retrieval-based data generation pipeline using\n10,094 pairs of WSIs and histopathology reports from The Cancer Genome Atlas\n(TCGA). We also showcase an AI-based evaluation protocol for a comprehensive\nunderstanding of the medical context from given multimodal information and\nevaluate generated answers compared to the original histopathology reports. We\ndemonstrate the ability of diagnosing the given histopathology images using\nChatEXAONEPath with the acceptance rate of 62.9% from 1,134 pairs of WSIs and\nreports. Our proposed model can understand pan-cancer WSIs and clinical context\nfrom various cancer types. We argue that our proposed model has the potential\nto assist clinicians by comprehensively understanding complex morphology of\nWSIs for cancer diagnosis through the integration of multiple modalities.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-17T15:33:17Z"}
{"aid":"http://arxiv.org/abs/2504.13024v1","title":"Riemannian Patch Assignment Gradient Flows","summary":"This paper introduces patch assignment flows for metric data labeling on\ngraphs. Labelings are determined by regularizing initial local labelings\nthrough the dynamic interaction of both labels and label assignments across the\ngraph, entirely encoded by a dictionary of competing labeled patches and\nmediated by patch assignment variables. Maximal consistency of patch\nassignments is achieved by geometric numerical integration of a Riemannian\nascent flow, as critical point of a Lagrangian action functional. Experiments\nillustrate properties of the approach, including uncertainty quantification of\nlabel assignments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.13031v1","title":"Degrees of Freedom of Holographic MIMO -- Fundamental Theory and\n  Analytical Methods","summary":"Holographic multiple-input multiple-output (MIMO) is envisioned as one of the\nmost promising technology enablers for future sixth-generation (6G) networks.\nThe use of electrically large holographic surface (HoloS) antennas has the\npotential to significantly boost the spatial multiplexing gain by increasing\nthe number of degrees of freedom (DoF), even in line-of-sight (LoS) channels.\nIn this context, the research community has shown a growing interest in\ncharacterizing the fundamental limits of this technology. In this paper, we\ncompare the two analytical methods commonly utilized in the literature for this\npurpose: the cut-set integral and the self-adjoint operator. We provide a\ndetailed description of both methods and discuss their advantages and\nlimitations.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-17T15:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.13037v1","title":"Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular\n  Representations for Whole-Heart Assessment and Beyond","summary":"Cardiac magnetic resonance imaging is the gold standard for non-invasive\ncardiac assessment, offering rich spatio-temporal views of the cardiac anatomy\nand physiology. Patient-level health factors, such as demographics, metabolic,\nand lifestyle, are known to substantially influence cardiovascular health and\ndisease risk, yet remain uncaptured by CMR alone. To holistically understand\ncardiac health and to enable the best possible interpretation of an\nindividual's disease risk, CMR and patient-level factors must be jointly\nexploited within an integrated framework. Recent multi-modal approaches have\nbegun to bridge this gap, yet they often rely on limited spatio-temporal data\nand focus on isolated clinical tasks, thereby hindering the development of a\ncomprehensive representation for cardiac health evaluation. To overcome these\nlimitations, we introduce ViTa, a step toward foundation models that delivers a\ncomprehensive representation of the heart and a precise interpretation of\nindividual disease risk. Leveraging data from 42,000 UK Biobank participants,\nViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling\na complete capture of the cardiac cycle. These imaging data are then fused with\ndetailed tabular patient-level factors, enabling context-aware insights. This\nmulti-modal paradigm supports a wide spectrum of downstream tasks, including\ncardiac phenotype and physiological feature prediction, segmentation, and\nclassification of cardiac and metabolic diseases within a single unified\nframework. By learning a shared latent representation that bridges rich imaging\nfeatures and patient context, ViTa moves beyond traditional, task-specific\nmodels toward a universal, patient-specific understanding of cardiac health,\nhighlighting its potential to advance clinical utility and scalability in\ncardiac analysis.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-17T15:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.13044v1","title":"The Dissipation Theory of Aging: A Quantitative Analysis Using a\n  Cellular Aging Map","summary":"We propose a new theory for aging based on dynamical systems and provide a\ndata-driven computational method to quantify the changes at the cellular level.\nWe use ergodic theory to decompose the dynamics of changes during aging and\nshow that aging is fundamentally a dissipative process within biological\nsystems, akin to dynamical systems where dissipation occurs due to\nnon-conservative forces. To quantify the dissipation dynamics, we employ a\ntransformer-based machine learning algorithm to analyze gene expression data,\nincorporating age as a token to assess how age-related dissipation is reflected\nin the embedding space. By evaluating the dynamics of gene and age embeddings,\nwe provide a cellular aging map (CAM) and identify patterns indicative of\ndivergence in gene embedding space, nonlinear transitions, and entropy\nvariations during aging for various tissues and cell types. Our results provide\na novel perspective on aging as a dissipative process and introduce a\ncomputational framework that enables measuring age-related changes with\nmolecular resolution.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.LG,physics.bio-ph","published":"2025-04-17T15:59:15Z"}
{"aid":"http://arxiv.org/abs/2504.13046v1","title":"Variance-Reduced Fast Operator Splitting Methods for Stochastic\n  Generalized Equations","summary":"We develop two classes of variance-reduced fast operator splitting methods to\napproximate solutions of both finite-sum and stochastic generalized equations.\nOur approach integrates recent advances in accelerated fixed-point methods,\nco-hypomonotonicity, and variance reduction. First, we introduce a class of\nvariance-reduced estimators and establish their variance-reduction bounds. This\nclass covers both unbiased and biased instances and comprises common estimators\nas special cases, including SVRG, SAGA, SARAH, and Hybrid-SGD. Next, we design\na novel accelerated variance-reduced forward-backward splitting (FBS) algorithm\nusing these estimators to solve finite-sum and stochastic generalized\nequations. Our method achieves both $\\mathcal{O}(1/k^2)$ and $o(1/k^2)$\nconvergence rates on the expected squared norm $\\mathbb{E}[ \\|\nG_{\\lambda}x^k\\|^2]$ of the FBS residual $G_{\\lambda}$, where $k$ is the\niteration counter. Additionally, we establish, for the first time, almost sure\nconvergence rates and almost sure convergence of iterates to a solution in\nstochastic accelerated methods. Unlike existing stochastic fixed-point\nalgorithms, our methods accommodate co-hypomonotone operators, which\npotentially include nonmonotone problems arising from recent applications. We\nfurther specify our method to derive an appropriate variant for each stochastic\nestimator -- SVRG, SAGA, SARAH, and Hybrid-SGD -- demonstrating that they\nachieve the best-known complexity for each without relying on enhancement\ntechniques. Alternatively, we propose an accelerated variance-reduced\nbackward-forward splitting (BFS) method, which attains similar convergence\nrates and oracle complexity as our FBS method. Finally, we validate our results\nthrough several numerical experiments and compare their performance.","main_category":"math.OC","categories":"math.OC,stat.ML","published":"2025-04-17T16:02:20Z"}
{"aid":"http://arxiv.org/abs/2504.13062v1","title":"Seeing Beyond Dark-Field RGB Capabilities: Deep Spectral Extrapolation\n  of Ultrasmall Plasmonic Nanogaps","summary":"Localized surface plasmons can confine light within a deep-subwavelength\nvolume comparable to the scale of atoms and molecules, enabling ultrasensitive\nresponses to near-field variations. On the other hand, this extreme\nlocalization also inevitably amplifies the unwanted noise from the response of\nlocal morphological imperfections, leading to complex spectral variations and\nreduced consistency across the plasmonic nanostructures. Seeking uniform\noptical responses has therefore long been a sought-after goal in\nnanoplasmonics. However, conventional probing techniques by dark-field (DF)\nconfocal microscopy, such as image analysis or spectral measurements, can be\ninaccurate and time-consuming, respectively. Here, we introduce SPARX, a\ndeep-learning-powered paradigm that surpasses conventional imaging and\nspectroscopic capabilities. In particular, SPARX can batch-predict broadband DF\nspectra (e.g., 500-1000 nm) of numerous nanoparticles simultaneously from an\ninformation-limited RGB image (i.e., below 700 nm). It achieves this\nextrapolative inference beyond the camera's capture capabilities by learning\nthe underlying physical relationships among multiple orders of optical\nresonances. The spectral predictions only take milliseconds, achieving a\nspeedup of three to four orders of magnitude compared to traditional spectral\nacquisition, which may take from hours to days. As a proof-of-principle\ndemonstration for screening identical resonances, the selection accuracy\nachieved by SPARX is comparable to that of conventional spectroscopy\ntechniques. This breakthrough paves the way for consistent plasmonic\napplications and next-generation microscopies.","main_category":"physics.optics","categories":"physics.optics,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-17T16:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.13076v1","title":"Extremal Lagrangian tori in toric domains","summary":"Let $L$ be a closed Lagrangian submanifold of a symplectic manifold\n$(X,\\omega)$. Cieliebak and Mohnke define the symplectic area of $L$ as the\nminimal positive symplectic area of a smooth $2$-disk in $X$ with boundary on\n$L$. An extremal Lagrangian torus in $(X,\\omega)$ is a Lagrangian torus that\nmaximizes the symplectic area among the Lagrangian tori in $(X,\\omega)$. We\nprove that every extremal Lagrangian torus in the symplectic unit ball\n$(\\bar{B}^{2n}(1),\\omega_{\\mathrm{std}})$ is contained entirely in the boundary\n$\\partial B^{2n}(1)$. This answers a question attributed to Lazzarini and\ncompletely settles a conjecture of Cieliebak and Mohnke in the affirmative. In\naddition, we prove the conjecture for a class of toric domains in\n$(\\mathbb{C}^n, \\omega_{\\mathrm{std}})$, which includes all compact strictly\nconvex four-dimensional toric domains. We explain with counterexamples that the\ngeneral conjecture does not hold for non-convex domains.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-17T16:39:04Z"}
{"aid":"http://arxiv.org/abs/2504.13094v1","title":"Symmetry classification and invariant solutions of the classical\n  geometric mean reversion process","summary":"Based on the Lie symmetry method, we investigate a Feynman-Kac formula for\nthe classical geometric mean reversion process, which effectively describing\nthe dynamics of short-term interest rates. The Lie algebra of infinitesimal\nsymmetries and the corresponding one-parameter symmetry groups of the equation\nare obtained. An optimal system of invariant solutions are constructed by a\nderived optimal system of one-dimensional subalgebras. Because of taking into\naccount a supply response to price rises, this equation provides for a more\nrealistic assumption than the geometric Brownian motion in many investment\nscenarios.","main_category":"math.DS","categories":"math.DS,math.AP,math.PR,q-fin.MF","published":"2025-04-17T16:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.13095v1","title":"Should We Tailor the Talk? Understanding the Impact of Conversational\n  Styles on Preference Elicitation in Conversational Recommender Systems","summary":"Conversational recommender systems (CRSs) provide users with an interactive\nmeans to express preferences and receive real-time personalized\nrecommendations. The success of these systems is heavily influenced by the\npreference elicitation process. While existing research mainly focuses on what\nquestions to ask during preference elicitation, there is a notable gap in\nunderstanding what role broader interaction patterns including tone, pacing,\nand level of proactiveness play in supporting users in completing a given task.\nThis study investigates the impact of different conversational styles on\npreference elicitation, task performance, and user satisfaction with CRSs. We\nconducted a controlled experiment in the context of scientific literature\nrecommendation, contrasting two distinct conversational styles, high\ninvolvement (fast paced, direct, and proactive with frequent prompts) and high\nconsiderateness (polite and accommodating, prioritizing clarity and user\ncomfort) alongside a flexible experimental condition where users could switch\nbetween the two. Our results indicate that adapting conversational strategies\nbased on user expertise and allowing flexibility between styles can enhance\nboth user satisfaction and the effectiveness of recommendations in CRSs.\nOverall, our findings hold important implications for the design of future\nCRSs.","main_category":"cs.HC","categories":"cs.HC,cs.IR","published":"2025-04-17T17:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.13112v1","title":"Hadamard product in deep learning: Introduction, Advances and Challenges","summary":"While convolution and self-attention mechanisms have dominated architectural\ndesign in deep learning, this survey examines a fundamental yet understudied\nprimitive: the Hadamard product. Despite its widespread implementation across\nvarious applications, the Hadamard product has not been systematically analyzed\nas a core architectural primitive. We present the first comprehensive taxonomy\nof its applications in deep learning, identifying four principal domains:\nhigher-order correlation, multimodal data fusion, dynamic representation\nmodulation, and efficient pairwise operations. The Hadamard product's ability\nto model nonlinear interactions with linear computational complexity makes it\nparticularly valuable for resource-constrained deployments and edge computing\nscenarios. We demonstrate its natural applicability in multimodal fusion tasks,\nsuch as visual question answering, and its effectiveness in representation\nmasking for applications including image inpainting and pruning. This\nsystematic review not only consolidates existing knowledge about the Hadamard\nproduct's role in deep learning architectures but also establishes a foundation\nfor future architectural innovations. Our analysis reveals the Hadamard product\nas a versatile primitive that offers compelling trade-offs between\ncomputational efficiency and representational power, positioning it as a\ncrucial component in the deep learning toolkit.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T17:26:29Z"}
{"aid":"http://arxiv.org/abs/2504.13150v1","title":"Readable Twins of Unreadable Models","summary":"Creating responsible artificial intelligence (AI) systems is an important\nissue in contemporary research and development of works on AI. One of the\ncharacteristics of responsible AI systems is their explainability. In the\npaper, we are interested in explainable deep learning (XDL) systems. On the\nbasis of the creation of digital twins of physical objects, we introduce the\nidea of creating readable twins (in the form of imprecise information flow\nmodels) for unreadable deep learning models. The complete procedure for\nswitching from the deep learning model (DLM) to the imprecise information flow\nmodel (IIFM) is presented. The proposed approach is illustrated with an example\nof a deep learning classification model for image recognition of handwritten\ndigits from the MNIST data set.","main_category":"cs.AI","categories":"cs.AI,cs.CV","published":"2025-04-17T17:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.13162v1","title":"Personalized Text-to-Image Generation with Auto-Regressive Models","summary":"Personalized image synthesis has emerged as a pivotal application in\ntext-to-image generation, enabling the creation of images featuring specific\nsubjects in diverse contexts. While diffusion models have dominated this\ndomain, auto-regressive models, with their unified architecture for text and\nimage modeling, remain underexplored for personalized image generation. This\npaper investigates the potential of optimizing auto-regressive models for\npersonalized image synthesis, leveraging their inherent multimodal capabilities\nto perform this task. We propose a two-stage training strategy that combines\noptimization of text embeddings and fine-tuning of transformer layers. Our\nexperiments on the auto-regressive model demonstrate that this method achieves\ncomparable subject fidelity and prompt following to the leading diffusion-based\npersonalization methods. The results highlight the effectiveness of\nauto-regressive models in personalized image generation, offering a new\ndirection for future research in this area.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.13167v1","title":"ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from\n  Monocular Videos","summary":"Creating a photorealistic scene and human reconstruction from a single\nmonocular in-the-wild video figures prominently in the perception of a\nhuman-centric 3D world. Recent neural rendering advances have enabled holistic\nhuman-scene reconstruction but require pre-calibrated camera and human poses,\nand days of training time. In this work, we introduce a novel unified framework\nthat simultaneously performs camera tracking, human pose estimation and\nhuman-scene reconstruction in an online fashion. 3D Gaussian Splatting is\nutilized to learn Gaussian primitives for humans and scenes efficiently, and\nreconstruction-based camera tracking and human pose estimation modules are\ndesigned to enable holistic understanding and effective disentanglement of pose\nand appearance. Specifically, we design a human deformation module to\nreconstruct the details and enhance generalizability to out-of-distribution\nposes faithfully. Aiming to learn the spatial correlation between human and\nscene accurately, we introduce occlusion-aware human silhouette rendering and\nmonocular geometric priors, which further improve reconstruction quality.\nExperiments on the EMDB and NeuMan datasets demonstrate superior or on-par\nperformance with existing methods in camera tracking, human pose estimation,\nnovel view synthesis and runtime. Our project page is at\nhttps://eth-ait.github.io/ODHSR.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-17T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.14868v1","title":"Twin Co-Adaptive Dialogue for Progressive Image Generation","summary":"Modern text-to-image generation systems have enabled the creation of\nremarkably realistic and high-quality visuals, yet they often falter when\nhandling the inherent ambiguities in user prompts. In this work, we present\nTwin-Co, a framework that leverages synchronized, co-adaptive dialogue to\nprogressively refine image generation. Instead of a static generation process,\nTwin-Co employs a dynamic, iterative workflow where an intelligent dialogue\nagent continuously interacts with the user. Initially, a base image is\ngenerated from the user's prompt. Then, through a series of synchronized\ndialogue exchanges, the system adapts and optimizes the image according to\nevolving user feedback. The co-adaptive process allows the system to\nprogressively narrow down ambiguities and better align with user intent.\nExperiments demonstrate that Twin-Co not only enhances user experience by\nreducing trial-and-error iterations but also improves the quality of the\ngenerated images, streamlining the creative process across various\napplications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T05:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.14876v1","title":"Initiation Route of Coronal Mass Ejections: II. The Role of Filament\n  Mass","summary":"The thorough understanding on the initiation of coronal mass ejections\n(CMEs), which is manifested as a slow rise of pre-eruptive structures before\nthe impulsive ejection in kinematics, is the key for forecasting the solar\neruptions. In our previous work, we showed that the slow rise of a hot flux\nrope with coronal mass density is caused by the moderate magnetic reconnection\noccurring in the hyperbolic flux tube (HFT) combined with the torus\ninstability. However, it remains unclear how the initiation process varies when\na filament is present in the pre-eruptive flux rope. In this work, we reveal\nthe complete initiation route of a CME containing filament mass with a\nstate-of-the-art full-magnetohydrodynamics simulation. The comprehensive\nanalyses show that the filament mass has an important impact on the CME\ninitiation through triggering and driving the slow rise of flux rope with its\ndrainage, besides the contributions of HFT reconnection and torus instability.\nFinally, in combination with our previous work, we propose that the enhanced\ndrainage of filament mass and various features related to the HFT reconnection,\nsuch as, the split of pre-eruptive structure and the pre-flare loops and X-ray\nemissions, can serve as the precursors of CME initiation in observations.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T06:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.14894v1","title":"Never too Cocky to Cooperate: An FIM and RL-based USV-AUV Collaborative\n  System for Underwater Tasks in Extreme Sea Conditions","summary":"This paper develops a novel unmanned surface vehicle (USV)-autonomous\nunderwater vehicle (AUV) collaborative system designed to enhance underwater\ntask performance in extreme sea conditions. The system integrates a dual\nstrategy: (1) high-precision multi-AUV localization enabled by Fisher\ninformation matrix-optimized USV path planning, and (2) reinforcement\nlearning-based cooperative planning and control method for multi-AUV task\nexecution. Extensive experimental evaluations in the underwater data collection\ntask demonstrate the system's operational feasibility, with quantitative\nresults showing significant performance improvements over baseline methods. The\nproposed system exhibits robust coordination capabilities between USV and AUVs\nwhile maintaining stability in extreme sea conditions. To facilitate\nreproducibility and community advancement, we provide an open-source simulation\ntoolkit available at: https://github.com/360ZMEM/USV-AUV-colab .","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-21T06:47:46Z"}
{"aid":"http://arxiv.org/abs/2504.14914v1","title":"K-DRIFT Preparation: Experimental Verification of an Observation\n  Strategy for Accurate Dark-Sky Flats","summary":"Despite its scientific importance, the low-surface-brightness universe has\nyet to be fully explored due to various systematic uncertainties that affect\nthe achievable surface-brightness limit. Reducing these uncertainties requires\nvery accurate data processing. The dark-sky flat is a widely used calibration\nframe for accurate flat-field correction, generated by combining the sky\nbackground from science images. However, the night sky will likely contain\ncomplex local fluctuations, thus may still lead to photometric errors in data\ncalibrated with dark-sky flats. To address this concern, we conduct mock\nobservations with semi-realistic sky simulation data and evaluate observation\nstrategies to mitigate the impact of the fluctuating sky background. Our\nexperiments consider two representative sky conditions (clear and dirty) and\nperform intensive comparative analysis on two observation methods (offset and\nrolling). Our findings suggest that the rolling dithering method, which\nincorporates the operation of camera rotation into conventional dithering, can\nprovide more accurate dark-sky flats. Finally, we discuss the broader\nimplications of this method through additional experiments examining several\nfactors that may affect the imaging quality of observational data.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.GA","published":"2025-04-21T07:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.14919v1","title":"GenCLIP: Generalizing CLIP Prompts for Zero-shot Anomaly Detection","summary":"Zero-shot anomaly detection (ZSAD) aims to identify anomalies in unseen\ncategories by leveraging CLIP's zero-shot capabilities to match text prompts\nwith visual features. A key challenge in ZSAD is learning general prompts\nstably and utilizing them effectively, while maintaining both generalizability\nand category specificity. Although general prompts have been explored in prior\nworks, achieving their stable optimization and effective deployment remains a\nsignificant challenge. In this work, we propose GenCLIP, a novel framework that\nlearns and leverages general prompts more effectively through multi-layer\nprompting and dual-branch inference. Multi-layer prompting integrates\ncategory-specific visual cues from different CLIP layers, enriching general\nprompts with more comprehensive and robust feature representations. By\ncombining general prompts with multi-layer visual features, our method further\nenhances its generalization capability. To balance specificity and\ngeneralization, we introduce a dual-branch inference strategy, where a\nvision-enhanced branch captures fine-grained category-specific features, while\na query-only branch prioritizes generalization. The complementary outputs from\nboth branches improve the stability and reliability of anomaly detection across\nunseen categories. Additionally, we propose an adaptive text prompt filtering\nmechanism, which removes irrelevant or atypical class names not encountered\nduring CLIP's training, ensuring that only meaningful textual inputs contribute\nto the final vision-language alignment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.14940v1","title":"Gigaparsec structures are nowhere to be seen in $Λ$CDM: an\n  enhanced analysis of LSS in FLAMINGO-10K simulations","summary":"Recently, Sawala et al. 2025 claimed to refute the cosmological significance\nof the Giant Arc based on their analysis of the FLAMINGO-10K simulation data.\nIn our paper here, we highlight several shortcomings of the authors' analysis.\nWe then perform an enhanced analysis on the FLAMINGO-10K simulation data with\napplications of: the Single-Linkage Hierarchical Clustering (SLHC), the Convex\nHull of Member Spheres (CHMS), and the Minimal Spanning Tree (MST) algorithms.\nUsing the full $2.8^3$ Gpc$^3$ FLAMINGO-10K box, with subhaloes at $z=0.7$, and\n$100$ random realisations (from random subset selections) we find no gigaparsec\nstructures in FLAMINGO-10K, and only a few ultra-large large-scale structures\n(uLSSs, structures exceeding a maximum pairwise separation of $370$ Mpc).\nSomewhat surprisingly, we found that the large-scale aspects of the\nFLAMINGO-10K data could be adequately represented by a Poisson point\ndistribution. The enhanced analysis presented here further supports the\nremarkable nature of the Giant Arc as a cosmologically-significant structure.\nOf course, the Giant Arc is also accompanied by a second uLSS, the Big Ring.\nThe analysis presented here builds on the work presented by Sawala et al., but\namends the application of their statistical assessments. We do not yet know why\nthere appears to be such a large discrepancy between the FLAMINGO-10K data and\nthe observed LSS in MgII absorbers. Perhaps the results presented here might\nsuggest that the GA, and especially the GA + BR, presents a more direct\nchallenge to $\\Lambda$CDM. In contrast to the conclusion of Sawala et al. that\n`gigaparsec patterns abound in a $\\Lambda$CDM universe' we find that they are\nnowhere to be seen.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T08:02:11Z"}
{"aid":"http://arxiv.org/abs/2504.14970v1","title":"Gapless behavior in a two-leg spin ladder with bond randomness","summary":"We successfully synthesized\n[Cu$_2$(AcO)$_4$($p$-Py-V-$p$-F)$_2$]$\\cdot$4CHCl$_3$, a verdazyl-based complex\nwith a paddlewheel structure comprising two Cu atoms, which induces strong\nantiferromagnetic (AF) exchange interactions between Cu spins, generating a\nnonmagnetic singlet state at low temperatures. Two primary exchange\ninteractions between radical spins generate a spin-1/2 AF two-leg ladder. In\naddition, two possible positional configurations of the F atom in the complex\ncreate four different overlap patterns of molecular orbitals, introducing bond\nrandomness in the spin ladder. The observed experimental behaviors, such as the\nCurie tail in the magnetic susceptibility and the gapless gradual increase in\nthe magnetization curve, are attributed to a broad distribution of excitation\nenergies and a few orphan spins in the random-singlet (RS) state that are\nstabilized by bond randomness. The low-temperature specific heat exhibits a\ntemperature dependence with $\\propto 1/|{\\rm{ln}}T|^3$, demonstrating the\nformation of the RS state in unfrustrated systems. We also consider the effect\nof restricted patterns of exchange interactions and one-dimensional nature of\nthe system on the RS state.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-21T08:57:57Z"}
{"aid":"http://arxiv.org/abs/2504.14974v1","title":"Nonreciprocal photon blockade induced by parametric amplification in an\n  asymmetrical cavity","summary":"We propose a scheme to generate and manipulate nonreciprocal photon blockade\neffect in an asymmetrical Fabry-P\\'{e}rot cavity, which consists of a single\ntwo-level atom and a second-order nonlinear medium. By utilizing the intrinsic\nspatial asymmetry of cavity and applying a parametric amplification pumping\nlaser to the nonlinear medium, we can realize direction-dependent single-photon\nand two-photon blockade effects. For nonreciprocal single-photon blockade, our\nproposal is robust across a wide range of parameters, such as the cavity or\natomic detuning, coupling strength, and atomic decay. Within similar parameter\nranges, nonreciprocal two-photon blockade can be achieved and modulated by\nfinely adjusting the parametric amplification pumping. Our project offers a\nfeasible access to generating high-quality and tunable nonreciprocal\nsingle/two-photon source and paves a new avenue for investigating the\nnonreciprocity of photon quantum statistical properties.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T09:00:37Z"}
{"aid":"http://arxiv.org/abs/2504.14985v1","title":"aiXamine: LLM Safety and Security Simplified","summary":"Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-21T09:26:05Z"}
{"aid":"http://arxiv.org/abs/2504.15024v1","title":"Extending Collinear Density Functionals to Noncollinear Cases under\n  Periodic Boundary Condition","summary":"Accurate modeling of spin-orbit coupling and noncollinear magnetism in\nmaterials requires noncollinear density functionals within the two-component\ngeneralized Kohn-Sham (GKS) framework, yet constructing and implementing\nnoncollinear functionals remains challenging. Recently, a methodology was\nproposed to extend collinear functionals into noncollinear ones, successfully\ndefining noncollinear functionals and their derivatives. However, the initial\nimplementation involved a systematic approach to differentiate energy over\ndensity matrix elements rather than the derivatives of the energy functional\nwith respect to density, presenting challenges for integration with periodic\nboundary condition-density functional theory (PBC-DFT) software. We have\nderived a novel set of working equations based on the original methodology,\nwhich provides noncollinear energy functionals and their derivatives. These\nworking equations have been implemented in our noncollinear functional ensemble\nnamed NCXC, ensuring numerical stability and transferability without the need\nfor incorporating derivatives of basis functions. This implementation is\nexpected to facilitate compatibility with most DFT software packages. We\ndemonstrate some preliminary applications in periodic systems, including\nnoncollinear magnetism in spin spirals, band structures in topological\ninsulators, and band gaps in semiconducting inorganic materials, using NCXC.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T11:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.15033v1","title":"Blinding the Wiretapper: RIS-Enabled User Occultation in the ISAC Era","summary":"An undesirable consequence of the foreseeable proliferation of sophisticated\nintegrated sensing and communications (ISAC) technologies is the enabling of\nspoofing, by malicious agents, of situational information (such as proximity,\ndirection or location) of legitimate users of wireless systems. In order to\nmitigate this threat, we present a novel ISAC scheme that, aided by a\nreconfigurable intelligent surface (RIS), enables the occultation of the\npositions of user equipment (UE) from wiretappers, while maintaining both\nsensing and desired communication performance between the UEs and a legitimate\nbase station (BS). To that end, we first formulate an RIS phase-shift\noptimization problem that jointly maximizes the sum-rate performance of the UEs\n(communication objective), while minimizing the projection of the wiretapper's\neffective channel onto the legitimate channel (hiding objective), thereby\ndisrupting the attempts by a wiretapper of localizing the UEs. Then, in order\nto efficiently solve the resulting non-convex joint optimization problem, a\nnovel manifold optimization algorithm is derived, whose effectiveness is\nvalidated by numerical results, which demonstrate that the proposed approach\npreserves legitimate ISAC performance while significantly degrading the\nwiretapper's sensing capability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T11:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.15034v1","title":"Predicting Methane Adsorption in Metal-Substituted MOFs: A Comparative\n  Study between Density Functional Theory and Machine Learning","summary":"Metal-organic frameworks (MOFs) are promising materials for methane capture\ndue to their high surface area and tunable properties. Metal substitution\nrepresents a powerful strategy to enhance MOF performance, yet systematic\nexploration of the vast chemical space remains challenging. In this work, we\ncompare density functional theory (DFT) and machine learning (ML) in predicting\nmethane adsorption properties in metal-substituted variants of three\nhigh-performing MOFs: M-HKUST-1, M-ATC, and M-ZIF-8 (M = Cu, Zn). DFT\ncalculations reveal significant differences in methane binding energetics\nbetween Cu and Zn variants of all three MOFs. On the other hand, we fine-tuned\na pretrained multimodal ML model, PMTransformer, on a curated subset of\nhypothetical MOF (hMOF) structures to predict macroscopic adsorption\nproperties. While the model qualitatively predicts adsorption properties for\nthe original unaltered MOFs, it fails to distinguish between metal variants\ndespite their different binding energetics identified by DFT. We trace this\nlimitation to the hMOF training data generated using Grand Canonical Monte\nCarlo (GCMC) simulations based on classical force fields (UFF/TraPPE). Our\nstudy highlights a key challenge in ML-based MOF screening: ML models inherit\nthe limitations of their training data, particularly when electronic effects\nsignificantly impact adsorption behavior. Our findings emphasize the need for\nimproved force fields or hybrid GCMC/DFT datasets to incorporate both geometric\nand electronic factors for accurate prediction of adsorption properties in\nmetal-substituted MOFs.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-21T11:41:32Z"}
{"aid":"http://arxiv.org/abs/2504.15053v1","title":"One pathogen does not an epidemic make: A review of interacting\n  contagions, diseases, beliefs, and stories","summary":"From pathogens and computer viruses to genes and memes, contagion models have\nfound widespread utility across the natural and social sciences. Despite their\nsuccess and breadth of adoption, the approach and structure of these models\nremain surprisingly siloed by field. Given the siloed nature of their\ndevelopment and widespread use, one persistent assumption is that a given\ncontagion can be studied in isolation, independently from what else might be\nspreading in the population. In reality, countless contagions of biological and\nsocial nature interact within hosts (interacting with existing beliefs, or the\nimmune system) and across hosts (interacting in the environment, or affecting\ntransmission mechanisms). Additionally, from a modeling perspective, we know\nthat relaxing these assumptions has profound effects on the physics and\ntranslational implications of the models. Here, we review mechanisms for\ninteractions in social and biological contagions, as well as the models and\nframeworks developed to include these interactions in the study of the\ncontagions. We highlight existing problems related to the inference of\ninteractions and to the scalability of mathematical models and identify\npromising avenues of future inquiries. In doing so, we highlight the need for\ninterdisciplinary efforts under a unified science of contagions and for\nremoving a common dichotomy between social and biological contagions.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-21T12:26:27Z"}
{"aid":"http://arxiv.org/abs/2504.15060v1","title":"Flexible polyhedral nets in isotropic geometry","summary":"We study flexible polyhedral nets in isotropic geometry. This geometry has a\ndegenerate metric, but there is a natural notion of flexibility. We study\ninfinitesimal and finite flexibility, and classify all finitely flexible\npolyhedral nets of arbitrary size. We show that there are just two classes, in\ncontrast to Izmestiev's rather involved classification in Euclidean geometry,\nfor size 3x3 only. Using these nets to initialize the optimization algorithms,\nwe turn them into approximate Euclidean mechanisms. We also explore the smooth\nversions of these classes.","main_category":"math.MG","categories":"math.MG","published":"2025-04-21T12:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.15063v1","title":"Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle\n  Stages","summary":"Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-21T12:42:59Z"}
{"aid":"http://arxiv.org/abs/2504.15093v1","title":"Rethinking the Potential of Multimodality in Collaborative Problem\n  Solving Diagnosis with Large Language Models","summary":"Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-21T13:25:55Z"}
{"aid":"http://arxiv.org/abs/2504.15114v1","title":"Sensing with Quantum Light: A perspective","summary":"I present my perspective on sensing with quantum light. I summarise the\nmotivations and methodology for identifying quantum enhancements in sensing\nover a classical sensor. In the real world, this enhancement will be a constant\nfactor, and not increase with the size of the quantum probe as is often\nadvertised. I use a limited survey of interferometry, microscopy, and\nspectroscopy to extract the vital challenges that must be faced to realise\ntangible enhancements in sensing with quantum light.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T14:07:57Z"}
{"aid":"http://arxiv.org/abs/2504.15120v1","title":"Kuwain 1.5B: An Arabic SLM via Language Injection","summary":"Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-21T14:17:25Z"}
{"aid":"http://arxiv.org/abs/2504.15125v1","title":"Contemplative Wisdom for Superalignment","summary":"As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T14:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.15135v1","title":"KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking","summary":"Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-21T14:38:44Z"}
{"aid":"http://arxiv.org/abs/2504.15149v1","title":"Cosmological Constraints with Void Lensing I: the Simulation-Based\n  Inference Framework","summary":"We present a Simulation-Based Inference (SBI) framework for cosmological\nparameter estimation via void lensing analysis. Despite the absence of an\nanalytical model of void lensing, SBI can effectively learn posterior\ndistributions through forward modeling of mock data. We develop a forward\nmodeling pipeline that accounts for both cosmology and the galaxy-halo\nconnection. By training a neural density estimator on simulated data, we infer\nthe posteriors of two cosmological parameters, $\\Omega_m$ and $S_8$. Validation\ntests are conducted on posteriors derived from different cosmological\nparameters and a fiducial sample. The results demonstrate that SBI provides\nunbiased estimates of mean values and accurate uncertainties. These findings\nhighlight the potential to apply void lensing analysis to observational data\neven without an analytical void lensing model.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T14:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.15208v1","title":"Compute-Optimal LLMs Provably Generalize Better With Scale","summary":"Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T16:26:56Z"}
{"aid":"http://arxiv.org/abs/2504.15217v1","title":"DRAGON: Distributional Rewards Optimize Diffusion Generative Models","summary":"We present Distributional RewArds for Generative OptimizatioN (DRAGON), a\nversatile framework for fine-tuning media generation models towards a desired\noutcome. Compared with traditional reinforcement learning with human feedback\n(RLHF) or pairwise preference approaches such as direct preference optimization\n(DPO), DRAGON is more flexible. It can optimize reward functions that evaluate\neither individual examples or distributions of them, making it compatible with\na broad spectrum of instance-wise, instance-to-distribution, and\ndistribution-to-distribution rewards. Leveraging this versatility, we construct\nnovel reward functions by selecting an encoder and a set of reference examples\nto create an exemplar distribution. When cross-modality encoders such as CLAP\nare used, the reference examples may be of a different modality (e.g., text\nversus audio). Then, DRAGON gathers online and on-policy generations, scores\nthem to construct a positive demonstration set and a negative set, and\nleverages the contrast between the two sets to maximize the reward. For\nevaluation, we fine-tune an audio-domain text-to-music diffusion model with 20\ndifferent reward functions, including a custom music aesthetics model, CLAP\nscore, Vendi diversity, and Frechet audio distance (FAD). We further compare\ninstance-wise (per-song) and full-dataset FAD settings while ablating multiple\nFAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an\n81.45% average win rate. Moreover, reward functions based on exemplar sets\nindeed enhance generations and are comparable to model-based rewards. With an\nappropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality\nwin rate without training on human preference annotations. As such, DRAGON\nexhibits a new approach to designing and optimizing reward functions for\nimproving human-perceived quality. Sound examples at\nhttps://ml-dragon.github.io/web.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-21T16:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.15219v1","title":"EvalAgent: Discovering Implicit Evaluation Criteria from the Web","summary":"Evaluation of language model outputs on structured writing tasks is typically\nconducted with a number of desirable criteria presented to human evaluators or\nlarge language models (LLMs). For instance, on a prompt like \"Help me draft an\nacademic talk on coffee intake vs research productivity\", a model response may\nbe evaluated for criteria like accuracy and coherence. However, high-quality\nresponses should do more than just satisfy basic task requirements. An\neffective response to this query should include quintessential features of an\nacademic talk, such as a compelling opening, clear research questions, and a\ntakeaway. To help identify these implicit criteria, we introduce EvalAgent, a\nnovel framework designed to automatically uncover nuanced and task-specific\ncriteria. EvalAgent first mines expert-authored online guidance. It then uses\nthis evidence to propose diverse, long-tail evaluation criteria that are\ngrounded in reliable external sources. Our experiments demonstrate that the\ngrounded criteria produced by EvalAgent are often implicit (not directly stated\nin the user's prompt), yet specific (high degree of lexical precision).\nFurther, EvalAgent criteria are often not satisfied by initial responses but\nthey are actionable, such that responses can be refined to satisfy them.\nFinally, we show that combining LLM-generated and EvalAgent criteria uncovers\nmore human-valued criteria than using LLMs alone.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T16:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.15225v1","title":"M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global\n  Scoring and Calibrated Thresholding","summary":"With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T16:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.15229v1","title":"Immersive Teleoperation Framework for Locomanipulation Tasks","summary":"Recent advancements in robotic loco-manipulation have leveraged Virtual\nReality (VR) to enhance the precision and immersiveness of teleoperation\nsystems, significantly outperforming traditional methods reliant on 2D camera\nfeeds and joystick controls. Despite these advancements, challenges remain,\nparticularly concerning user experience across different setups. This paper\nintroduces a novel VR-based teleoperation framework designed for a robotic\nmanipulator integrated onto a mobile platform. Central to our approach is the\napplication of Gaussian splatting, a technique that abstracts the manipulable\nscene into a VR environment, thereby enabling more intuitive and immersive\ninteractions. Users can navigate and manipulate within the virtual scene as if\ninteracting with a real robot, enhancing both the engagement and efficacy of\nteleoperation tasks. An extensive user study validates our approach,\ndemonstrating significant usability and efficiency improvements. Two-thirds\n(66%) of participants completed tasks faster, achieving an average time\nreduction of 43%. Additionally, 93% preferred the Gaussian Splat interface\noverall, with unanimous (100%) recommendations for future use, highlighting\nimprovements in precision, responsiveness, and situational awareness. Finally,\nwe demonstrate the effectiveness of our framework through real-world\nexperiments in two distinct application scenarios, showcasing the practical\ncapabilities and versatility of the Splat-based VR interface.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:00:31Z"}
{"aid":"http://arxiv.org/abs/2504.15231v1","title":"Linear Complementary Pairs of Quasi-Cyclic and Quasi-Twisted Codes","summary":"In this paper, we provide a polynomial characterization of linear\ncomplementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also\ngive several examples of linear complementary pairs of quasi-cyclic and\nquasi-twisted codes with (almost) optimal security parameters.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T17:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.15235v1","title":"Cascade IPG Observer for Underwater Robot State Estimation","summary":"This paper presents a novel cascade nonlinear observer framework for inertial\nstate estimation. It tackles the problem of intermediate state estimation when\nexternal localization is unavailable or in the event of a sensor outage. The\nproposed observer comprises two nonlinear observers based on a recently\ndeveloped iteratively preconditioned gradient descent (IPG) algorithm. It takes\nthe inputs via an IMU preintegration model where the first observer is a\nquaternion-based IPG. The output for the first observer is the input for the\nsecond observer, estimating the velocity and, consequently, the position. The\nproposed observer is validated on a public underwater dataset and a real-world\nexperiment using our robot platform. The estimation is compared with an\nextended Kalman filter (EKF) and an invariant extended Kalman filter (InEKF).\nResults demonstrate that our method outperforms these methods regarding better\npositional accuracy and lower variance.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.15252v1","title":"SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam","summary":"Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-21T17:33:02Z"}
{"aid":"http://arxiv.org/abs/2504.15254v1","title":"CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation","summary":"C-to-Rust transpilation is essential for modernizing legacy C code while\nenhancing safety and interoperability with modern Rust ecosystems. However, no\ndataset currently exists for evaluating whether a system can transpile C into\nsafe Rust that passes a set of test cases. We introduce CRUST-Bench, a dataset\nof 100 C repositories, each paired with manually-written interfaces in safe\nRust as well as test cases that can be used to validate correctness of the\ntranspilation. By considering entire repositories rather than isolated\nfunctions, CRUST-Bench captures the challenges of translating complex projects\nwith dependencies across multiple files. The provided Rust interfaces provide\nexplicit specifications that ensure adherence to idiomatic, memory-safe Rust\npatterns, while the accompanying test cases enforce functional correctness. We\nevaluate state-of-the-art large language models (LLMs) on this task and find\nthat safe and idiomatic Rust generation is still a challenging problem for\nvarious state-of-the-art methods and techniques. We also provide insights into\nthe errors LLMs usually make in transpiling code from C to safe Rust. The best\nperforming model, OpenAI o1, is able to solve only 15 tasks in a single-shot\nsetting. Improvements on CRUST-Bench would lead to improved transpilation\nsystems that can reason about complex scenarios and help in migrating legacy\ncodebases from C into languages like Rust that ensure memory safety. You can\nfind the dataset and code at https://github.com/anirudhkhatry/CRUST-bench.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-04-21T17:33:33Z"}
{"aid":"http://arxiv.org/abs/2504.15549v1","title":"Do It For Me vs. Do It With Me: Investigating User Perceptions of\n  Different Paradigms of Automation in Copilots for Feature-Rich Software","summary":"Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.LG","published":"2025-04-22T03:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.15577v1","title":"State-Aware IoT Scheduling Using Deep Q-Networks and Edge-Based\n  Coordination","summary":"This paper addresses the challenge of energy efficiency management faced by\nintelligent IoT devices in complex application environments. A novel\noptimization method is proposed, combining Deep Q-Network (DQN) with an edge\ncollaboration mechanism. The method builds a state-action-reward interaction\nmodel and introduces edge nodes as intermediaries for state aggregation and\npolicy scheduling. This enables dynamic resource coordination and task\nallocation among multiple devices. During the modeling process, device status,\ntask load, and network resources are jointly incorporated into the state space.\nThe DQN is used to approximate and learn the optimal scheduling strategy. To\nenhance the model's ability to perceive inter-device relationships, a\ncollaborative graph structure is introduced to model the multi-device\nenvironment and assist in decision optimization. Experiments are conducted\nusing real-world IoT data collected from the FastBee platform. Several\ncomparative and validation tests are performed, including energy efficiency\ncomparisons across different scheduling strategies, robustness analysis under\nvarying task loads, and evaluation of state dimension impacts on policy\nconvergence speed. The results show that the proposed method outperforms\nexisting baseline approaches in terms of average energy consumption, processing\nlatency, and resource utilization. This confirms its effectiveness and\npracticality in intelligent IoT scenarios.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-04-22T04:24:16Z"}
{"aid":"http://arxiv.org/abs/2504.15602v1","title":"Mean Curvature Flow for Isoparametric Submanifolds in Hyperbolic Spaces","summary":"Mean curvature flows of isoparametric submanifolds in Euclidean spaces and\nspheres have been studied by Liu and Terng in \\cite{X.CT} and \\cite{X.C}. In\nparticular, it was proved that such flows always have ancient solutions. This\nis also true for mean curvature flows of isoparametric hypersurfaces in\nhyperbolic spaces by a result of Reis and Tenenblat in \\cite{S.H.T}. In this\npaper, we study mean curvature flows of isoparametric submanifolds in\nhyperbolic spaces with arbitrary codimension. In particular, we will show that\nthey always have ancient solutions and study their limiting behaviors.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T05:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.15611v1","title":"An ACO-MPC Framework for Energy-Efficient and Collision-Free Path\n  Planning in Autonomous Maritime Navigation","summary":"Automated driving on ramps presents significant challenges due to the need to\nbalance both safety and efficiency during lane changes. This paper proposes an\nintegrated planner for automated vehicles (AVs) on ramps, utilizing an\nunsatisfactory level metric for efficiency and arrow-cluster-based sampling for\nsafety. The planner identifies optimal times for the AV to change lanes, taking\ninto account the vehicle's velocity as a key factor in efficiency.\nAdditionally, the integrated planner employs arrow-cluster-based sampling to\nevaluate collision risks and select an optimal lane-changing curve. Extensive\nsimulations were conducted in a ramp scenario to verify the planner's efficient\nand safe performance. The results demonstrate that the proposed planner can\neffectively select an appropriate lane-changing time point and a safe\nlane-changing curve for AVs, without incurring any collisions during the\nmaneuver.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-22T06:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.15616v1","title":"SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory\n  Prediction","summary":"The analysis and prediction of agent trajectories are crucial for\ndecision-making processes in intelligent systems, with precise short-term\ntrajectory forecasting being highly significant across a range of applications.\nAgents and their social interactions have been quantified and modeled by\nresearchers from various perspectives; however, substantial limitations exist\nin the current work due to the inherent high uncertainty of agent intentions\nand the complex higher-order influences among neighboring groups. SocialMOIF is\nproposed to tackle these challenges, concentrating on the higher-order\nintention interactions among neighboring groups while reinforcing the primary\nrole of first-order intention interactions between neighbors and the target\nagent. This method develops a multi-order intention fusion model to achieve a\nmore comprehensive understanding of both direct and indirect intention\ninformation. Within SocialMOIF, a trajectory distribution approximator is\ndesigned to guide the trajectories toward values that align more closely with\nthe actual data, thereby enhancing model interpretability. Furthermore, a\nglobal trajectory optimizer is introduced to enable more accurate and efficient\nparallel predictions. By incorporating a novel loss function that accounts for\ndistance and direction during training, experimental results demonstrate that\nthe model outperforms previous state-of-the-art baselines across multiple\nmetrics in both dynamic and static datasets.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-22T06:14:49Z"}
{"aid":"http://arxiv.org/abs/2504.15621v1","title":"Regularization of elliptic multiple zeta values","summary":"In this paper, we show that regularized elliptic multiple zeta values are\ngiven by polynomials in elliptic multiple zeta values with admissible indices\nand special ones whose indices consist of 0 and 1.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T06:24:48Z"}
{"aid":"http://arxiv.org/abs/2504.15683v1","title":"FinTextSim: Enhancing Financial Text Analysis with BERTopic","summary":"Recent advancements in information availability and computational\ncapabilities have transformed the analysis of annual reports, integrating\ntraditional financial metrics with insights from textual data. To extract\nvaluable insights from this wealth of textual data, automated review processes,\nsuch as topic modeling, are crucial. This study examines the effectiveness of\nBERTopic, a state-of-the-art topic model relying on contextual embeddings, for\nanalyzing Item 7 and Item 7A of 10-K filings from S&P 500 companies\n(2016-2022). Moreover, we introduce FinTextSim, a finetuned\nsentence-transformer model optimized for clustering and semantic search in\nfinancial contexts. Compared to all-MiniLM-L6-v2, the most widely used\nsentence-transformer, FinTextSim increases intratopic similarity by 81% and\nreduces intertopic similarity by 100%, significantly enhancing organizational\nclarity. We assess BERTopic's performance using embeddings from both FinTextSim\nand all-MiniLM-L6-v2. Our findings reveal that BERTopic only forms clear and\ndistinct economic topic clusters when paired with FinTextSim's embeddings.\nWithout FinTextSim, BERTopic struggles with misclassification and overlapping\ntopics. Thus, FinTextSim is pivotal for advancing financial text analysis.\nFinTextSim's enhanced contextual embeddings, tailored for the financial domain,\nelevate the quality of future research and financial information. This improved\nquality of financial information will enable stakeholders to gain a competitive\nadvantage, streamlining resource allocation and decision-making processes.\nMoreover, the improved insights have the potential to leverage business\nvaluation and stock price prediction models.","main_category":"cs.CL","categories":"cs.CL,cs.LG,econ.GN,q-fin.EC,q-fin.GN","published":"2025-04-22T08:06:37Z"}
{"aid":"http://arxiv.org/abs/2504.15685v1","title":"Monte Carlo simulation of GRB data to test Lorentz-invariance violation","summary":"Lorentz-invariance violation (LV) at energy scales approaching the Planck\nregime serves as a critical probe for understanding quantum gravity\nphenomenology. Astrophysical observations of gamma-ray bursts (GRBs) present a\npromising avenue for testing LV-induced spectral lag phenomena; however,\ninterpretations are complicated by degeneracies between LV effects and\nintrinsic emission delays. This study systematically investigates three\ncompeting time delay models: Model A (LV delay combined with a constant\nintrinsic delay), Model B (energy-dependent intrinsic delay without LV), and\nModel C (LV delay combined with energy-dependent intrinsic delay). We utilize\nmock GRB datasets generated under distinct delay mechanisms and employ Bayesian\nparameter estimation on simulated observations of 10 GRBs. Our findings\ndemonstrate that Model C consistently recovers input parameters across all\ndatasets. In contrast, Models A and B struggle to reconcile data generated\nunder alternative mechanisms, particularly when confronted with high-energy TeV\nphotons from GRB 190114C and GRB 221009A. Our analysis confirms that the\nincorporation of energy-dependent intrinsic delays in Model C is essential for\nestablishing robust LV constraints, effectively resolving prior ambiguities in\nthe interpretation of multi-GeV and TeV photon emissions. The results validate\nModel C as a generalized framework for future LV searches, yielding a\nsubluminal LV scale of \\(E_{\\rm LV} \\simeq 3 \\times 10^{17}\\) GeV based on\nrealistic datasets. These findings are consistent with earlier constraints\nderived from Fermi-LAT datasets. This work underscores the necessity for joint\nmodeling of LV and astrophysical emission processes in next-generation LV\nstudies utilizing observatories such as LHAASO and CTA.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE,gr-qc","published":"2025-04-22T08:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.15694v1","title":"You Sense Only Once Beneath: Ultra-Light Real-Time Underwater Object\n  Detection","summary":"Despite the remarkable achievements in object detection, the model's accuracy\nand efficiency still require further improvement under challenging underwater\nconditions, such as low image quality and limited computational resources. To\naddress this, we propose an Ultra-Light Real-Time Underwater Object Detection\nframework, You Sense Only Once Beneath (YSOOB). Specifically, we utilize a\nMulti-Spectrum Wavelet Encoder (MSWE) to perform frequency-domain encoding on\nthe input image, minimizing the semantic loss caused by underwater optical\ncolor distortion. Furthermore, we revisit the unique characteristics of\neven-sized and transposed convolutions, allowing the model to dynamically\nselect and enhance key information during the resampling process, thereby\nimproving its generalization ability. Finally, we eliminate model redundancy\nthrough a simple yet effective channel compression and reconstructed large\nkernel convolution (RLKC) to achieve model lightweight. As a result, forms a\nhigh-performance underwater object detector YSOOB with only 1.2 million\nparameters. Extensive experimental results demonstrate that, with the fewest\nparameters, YSOOB achieves mAP50 of 83.1% and 82.9% on the URPC2020 and DUO\ndatasets, respectively, comparable to the current SOTA detectors. The inference\nspeed reaches 781.3 FPS and 57.8 FPS on the T4 GPU (TensorRT FP16) and the edge\ncomputing device Jetson Xavier NX (TensorRT FP16), surpassing YOLOv12-N by\n28.1% and 22.5%, respectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T08:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.15704v1","title":"On relaxing the N-Reachability Implicit Requirement in NMPC Design","summary":"This paper proposes a proof of stability for Model Predictive Control\nformulations involving a prediction horizon that might be too short to meet the\nreachability condition generally invoked as a sufficient condition for\nclosed-loop stability. This condition is replaced by a contraction condition on\nthe stage cost. But unlike the contraction based existing formulations where\nthe prediction horizon becomes a decision variable, the formulation proposed in\nthis paper remains standard in that it uses constant and short prediction\nhorizon. An illustrative example is provided to assess the relevance of the\nproposed formulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T08:46:23Z"}
{"aid":"http://arxiv.org/abs/2504.15706v1","title":"Distributed Compression for Computation and Bounds on the Optimal Rate","summary":"We address the problem of distributed computation of arbitrary functions of\ntwo correlated sources $X_1$ and $X_2$, residing in two distributed source\nnodes, respectively. We exploit the structure of a computation task by coding\nsource characteristic graphs (and multiple instances using the $n$-fold OR\nproduct of this graph with itself). For regular graphs and general graphs, we\nestablish bounds on the optimal rate -- characterized by the chromatic entropy\nfor the $n$-fold graph products -- that allows a receiver for asymptotically\nlossless computation of arbitrary functions over finite fields. For the special\nclass of cycle graphs (i.e., $2$-regular graphs), we establish an exact\ncharacterization of chromatic numbers and derive bounds on the required rates.\nNext, focusing on the more general class of $d$-regular graphs, we establish\nconnections between $d$-regular graphs and expansion rates for $n$-fold graph\npowers using graph spectra. Finally, for general graphs, we leverage the\nGershgorin Circle Theorem (GCT) to provide a characterization of the spectra,\nwhich allows us to build new bounds on the optimal rate. Our codes leverage the\nspectra of the computation and provide a graph expansion-based characterization\nto efficiently/succinctly capture the computation structure, providing new\ninsights into the problem of distributed computation of arbitrary functions.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-22T08:47:40Z"}
{"aid":"http://arxiv.org/abs/2504.15719v1","title":"Implementing Rational Choice Functions with LLMs and Measuring their\n  Alignment with User Preferences","summary":"As large language models (LLMs) become integral to intelligent user\ninterfaces (IUIs), their role as decision-making agents raises critical\nconcerns about alignment. Although extensive research has addressed issues such\nas factuality, bias, and toxicity, comparatively little attention has been paid\nto measuring alignment to preferences, i.e., the relative desirability of\ndifferent alternatives, a concept used in decision making, economics, and\nsocial choice theory. However, a reliable decision-making agent makes choices\nthat align well with user preferences.\n  In this paper, we generalize existing methods that exploit LLMs for ranking\nalternative outcomes by addressing alignment with the broader and more flexible\nconcept of user preferences, which includes both strict preferences and\nindifference among alternatives. To this end, we put forward design principles\nfor using LLMs to implement rational choice functions, and provide the\nnecessary tools to measure preference satisfaction. We demonstrate the\napplicability of our approach through an empirical study in a practical\napplication of an IUI in the automotive domain.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T09:08:21Z"}
{"aid":"http://arxiv.org/abs/2504.15731v1","title":"Entropy Stabilized ZrHfCoNiSnSb Half-Heusler Alloy for Thermoelectric\n  Applications: A Theoretical Prediction","summary":"Half-Heusler (HH) alloys are potential thermoelectric materials for use at\nelevated temperatures due to their high Seebeck coefficient and superior\nmechanical and thermal stability. However, their enhanced lattice thermal\nconductivity is detrimental to thermoelectric applications. One way to\ncircumvent this problem is to introduce mass disorder at lattice sites by\nmixing the components of two or more alloys. Such systems are typically\nstabilized by the entropy of mixing. In this work, using computational tools,\nwe propose a mixed HH, namely, ZrHfCoNiSnSb, which can be formed by the\nelemental compositions of the parent half-Heuslers ZrNiSn/HfNiSn and\nHfCoSb/ZrCoSb. We propose that this new compound can be synthesized at elevated\ntemperatures, as its Gibbs free energy is reduced due to higher configurational\nentropy, making it more thermodynamically stable than the parent compounds\nunder such conditions. Our calculations indicate that it is a dynamically\nstable semiconductor with a band gap of 0.61 eV. Its lattice thermal\nconductivity at room temperature is $5.39~\\text{Wm}^{-1}\\text{K}^{-1}$, which\nis significantly lower than those of the parent compounds. The peak value of\nthis alloy's figure of merit (ZT) is 1.00 for the n-type carriers at 1100 K,\nwhich is 27% more than the best figure of merit obtained for the parent\ncompounds.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T09:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.15759v1","title":"An equivalence theorem for algebraic and functorial QFT","summary":"This paper develops a novel approach to functorial quantum field theories\n(FQFTs) in the context of Lorentzian geometry. The key challenge is that\nglobally hyperbolic Lorentzian bordisms between two Cauchy surfaces cannot\nchange the topology of the Cauchy surface. This is addressed and solved by\nintroducing a more flexible concept of bordisms which provide morphisms from\ntuples of causally disjoint partial Cauchy surfaces to a later-in-time full\nCauchy surface. They assemble into a globally hyperbolic Lorentzian bordism\npseudo-operad, generalizing the geometric bordism pseudo-categories of Stolz\nand Teichner. The associated FQFTs are defined as pseudo-multifunctors into a\nsymmetric monoidal category of unital associative algebras. The main result of\nthis paper is an equivalence theorem between such globally hyperbolic\nLorentzian FQFTs and algebraic quantum field theories (AQFTs), both subject to\nthe time-slice axiom and a mild descent condition called additivity.","main_category":"math-ph","categories":"math-ph,hep-th,math.DG,math.MP,math.QA","published":"2025-04-22T10:11:48Z"}
{"aid":"http://arxiv.org/abs/2504.15763v1","title":"Modulus of continuity of Monge--Ampère potentials in big cohomology\n  classes","summary":"In this paper, we prove a uniform estimate for the modulus of continuity of\nsolutions to degenerate complex Monge--Amp\\`ere equation in big cohomology\nclasses. This improves the previous results of Di Nezza--Lu and of the first\nauthor.","main_category":"math.CV","categories":"math.CV","published":"2025-04-22T10:17:09Z"}
{"aid":"http://arxiv.org/abs/2504.15790v1","title":"Microstructure and Manipulation: Quantifying Pump-and-Dump Dynamics in\n  Cryptocurrency Markets","summary":"Building on our prior threshold-based analysis of six months of Poloniex\ntrading data, we have extended both the temporal span and granularity of our\nstudy by incorporating minute-level OHLCV records for 1021 tokens around each\nconfirmed pump-and-dump event. First, we algorithmically identify the\naccumulation phase, marking the initial and final insider volume spikes, and\nobserve that 70% of pre-event volume transacts within one hour of the pump\nannouncement. Second, we compute conservative lower bounds on insider profits\nunder both a single-point liquidation at 70% of peak and a tranche-based\nstrategy (selling 20% at 50%, 30% at 60%, and 50% at 80% of peak), yielding\nmedian returns above 100% and upper-quartile returns exceeding 2000%. Third, by\nunfolding the full pump structure and integrating social-media verification\n(e.g., Telegram announcements), we confirm numerous additional events that\neluded our initial model. We also categorize schemes into \"pre-accumulation\"\nversus \"on-the-spot\" archetypes-insights that sharpen detection algorithms,\ninform risk assessments, and underpin actionable strategies for real-time\nmarket-integrity enforcement.","main_category":"q-fin.TR","categories":"q-fin.TR","published":"2025-04-22T11:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.15814v1","title":"Fast Higher-Order Interpolation and Restriction in ExaHyPE Avoiding\n  Non-physical Reflections","summary":"Wave equations help us to understand phenomena ranging from earthquakes to\ntsunamis. These phenomena materialise over very large scales. It would be\ncomputationally infeasible to track them over a regular mesh. Yet, since the\nphenomena are localised, adaptive mesh refinement (AMR) can be used to\nconstruct meshes with a higher resolution close to the regions of interest.\nExaHyPE is a software engine created to solve wave problems using AMR, and we\nuse it as baseline to construct our numerical relativity application called\nExaGRyPE. To advance the mesh in time, we have to interpolate and restrict\nalong resolution transitions in each and every time step. ExaHyPE's vanilla\ncode version uses a d-linear tensor-product approach. In benchmarks of a\nstationary black hole this performs slowly and leads to errors in conserved\nquantities near AMR boundaries. We therefore introduce a set of higher-order\ninterpolation schemes where the derivatives are calculated at each coarse grid\ncell to approximate the enclosed fine cells. The resulting methods run faster\nthan the tensor-product approach. Most importantly, when running the stationary\nblack hole simulation using the higher order methods the errors near the AMR\nboundaries are removed.","main_category":"cs.CE","categories":"cs.CE,cs.MS,gr-qc","published":"2025-04-22T11:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.15835v1","title":"Text-based Animatable 3D Avatars with Morphable Model Alignment","summary":"The generation of high-quality, animatable 3D head avatars from text has\nenormous potential in content creation applications such as games, movies, and\nembodied virtual assistants. Current text-to-3D generation methods typically\ncombine parametric head models with 2D diffusion models using score\ndistillation sampling to produce 3D-consistent results. However, they struggle\nto synthesize realistic details and suffer from misalignments between the\nappearance and the driving parametric model, resulting in unnatural animation\nresults. We discovered that these limitations stem from ambiguities in the 2D\ndiffusion predictions during 3D avatar distillation, specifically: i) the\navatar's appearance and geometry is underconstrained by the text input, and ii)\nthe semantic alignment between the predictions and the parametric head model is\ninsufficient because the diffusion model alone cannot incorporate information\nfrom the parametric model. In this work, we propose a novel framework,\nAnimPortrait3D, for text-based realistic animatable 3DGS avatar generation with\nmorphable model alignment, and introduce two key strategies to address these\nchallenges. First, we tackle appearance and geometry ambiguities by utilizing\nprior information from a pretrained text-to-3D model to initialize a 3D avatar\nwith robust appearance, geometry, and rigging relationships to the morphable\nmodel. Second, we refine the initial 3D avatar for dynamic expressions using a\nControlNet that is conditioned on semantic and normal maps of the morphable\nmodel to ensure accurate alignment. As a result, our method outperforms\nexisting approaches in terms of synthesis quality, alignment, and animation\nfidelity. Our experiments show that the proposed method advances the state of\nthe art in text-based, animatable 3D head avatar generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T12:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.15852v1","title":"Recovering Nesterov accelerated dynamics from Heavy Ball dynamics via\n  time rescaling","summary":"In a real Hilbert space, we consider two classical problems: the global\nminimization of a smooth and convex function $f$ (i.e., a convex optimization\nproblem) and finding the zeros of a monotone and continuous operator $V$ (i.e.,\na monotone equation). Attached to the optimization problem, first we study the\nasymptotic properties of the trajectories generated by a second-order dynamical\nsystem which features a constant viscous friction coefficient and a positive,\nmonotonically increasing function $b(\\cdot)$ multiplying $\\nabla f$. For a\ngenerated solution trajectory $y(t)$, we show small $o$ convergence rates\ndependent on $b(t)$ for $f(y(t)) - \\min f$, and the weak convergence of $y(t)$\ntowards a global minimizer of $f$. In 2015, Su, Boyd and Cand\\'es introduced a\nsecond-order system which could be seen as the continuous-time counterpart of\nNesterov's accelerated gradient. As the first key point of this paper, we show\nthat for a special choice for $b(t)$, these two seemingly unrelated dynamical\nsystems are connected: namely, they are time reparametrizations of each other.\nEvery statement regarding the continuous-time accelerated gradient system may\nbe recovered from its Heavy Ball counterpart.\n  As the second key point of this paper, we observe that this connection\nextends beyond the optimization setting. Attached to the monotone equation\ninvolving the operator $V$, we again consider a Heavy Ball-like system which\nfeatures an additional correction term which is the time derivative of the\noperator along the trajectory. We establish a time reparametrization\nequivalence with the Fast OGDA dynamics introduced by Bot, Csetnek and Nguyen\nin 2022, which can be seen as an analog of the continuous accelerated gradient\ndynamics, but for monotone operators. Again, every statement regarding the Fast\nOGDA system may be recovered from a Heavy Ball-like system.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T12:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.15854v1","title":"Consistent Causal Inference of Group Effects in Non-Targeted Trials with\n  Finitely Many Effect Levels","summary":"A treatment may be appropriate for some group (the ``sick\" group) on whom it\nhas a positive effect, but it can also have a detrimental effect on subjects\nfrom another group (the ``healthy\" group). In a non-targeted trial both sick\nand healthy subjects may be treated, producing heterogeneous effects within the\ntreated group. Inferring the correct treatment effect on the sick population is\nthen difficult, because the effects on the different groups get tangled. We\npropose an efficient nonparametric approach to estimating the group effects,\ncalled {\\bf PCM} (pre-cluster and merge). We prove its asymptotic consistency\nin a general setting and show, on synthetic data, more than a 10x improvement\nin accuracy over existing state-of-the-art. Our approach applies more generally\nto consistent estimation of functions with a finite range.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-22T12:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.15879v1","title":"Multivariate Poisson intensity estimation via low-rank tensor\n  decomposition","summary":"In this work, we introduce new matrix- and tensor-based methodologies for\nestimating multivariate intensity functions of spatial point processes. By\nmodeling intensity functions as infinite-rank tensors within function spaces,\nwe develop new algorithms to reveal optimal bias-variance trade-off for\ninfinite-rank tensor estimation. Our methods dramatically enhance estimation\naccuracy while simultaneously reducing computational complexity. To our\nknowledge, this work marks the first application of matrix and tensor\ntechinques to spatial point processes. Extensive numerical experiments further\ndemonstrate that our techniques consistently outperform current\nstate-of-the-art methods.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-22T13:25:17Z"}
{"aid":"http://arxiv.org/abs/2504.15880v1","title":"Cryptoanalysis of a public key exchange based on circulant matrix over\n  digital semiring","summary":"We present a cryptanalysis of a key exchange protocol based on the digital\nsemiring. For this purpose, we find the maximal solution of a linear system\nover such semiring, and use the properties of circulant matrix to demonstrate\nthat the protocol is vulnerable. Specifically, we provide an efficient attack\nthat recovers the shared secret key from publicly exchanged information for any\ninstance of the digital semiring in polynomial time.","main_category":"cs.CR","categories":"cs.CR,cs.IT,math.AC,math.IT","published":"2025-04-22T13:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.15895v1","title":"Dynamic Early Exit in Reasoning Models","summary":"Recent advances in large reasoning language models (LRLMs) rely on test-time\nscaling, which extends long chain-of-thought (CoT) generation to solve complex\ntasks. However, overthinking in long CoT not only slows down the efficiency of\nproblem solving, but also risks accuracy loss due to the extremely detailed or\nredundant reasoning steps. We propose a simple yet effective method that allows\nLLMs to self-truncate CoT sequences by early exit during generation. Instead of\nrelying on fixed heuristics, the proposed method monitors model behavior at\npotential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically\nterminates the next reasoning chain's generation when the model exhibits high\nconfidence in a trial answer. Our method requires no additional training and\ncan be seamlessly integrated into existing o1-like reasoning LLMs. Experiments\non multiple reasoning benchmarks MATH-500, AMC 2023, GPQA Diamond and AIME 2024\nshow that the proposed method is consistently effective on deepseek-series\nreasoning LLMs, reducing the length of CoT sequences by an average of 31% to\n43% while improving accuracy by 1.7% to 5.7%.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T13:36:53Z"}
{"aid":"http://arxiv.org/abs/2504.15907v1","title":"On meromorphic solutions of Fermat type delay-differential equations\n  with two exponential terms","summary":"The existence of the meromorphic solutions to Fermat type delay-differential\nequation\n  \\begin{equation}\n  f^n(z)+a(f^{(l)}(z+c))^m=p_1(z)e^{a_1z^k}+p_2(z)e^{a_2z^k}, \\nonumber\n  \\end{equation}\n  is derived by using Nevanlinna theory under certain conditions, where\n$k\\ge1$, $m,$ $n$ and $l\\ge0$ are integers, $p_i$ are nonzero entire functions\nof order less than $k$, $c$, $a$ and $a_i$ are constants, $i=1,2$. These\nresults not only improve the previous results from Zhu et al. [J. Contemp.\nMath. Anal. 59(2024), 209-219], Qi et al. [Mediterr. J. Math. 21(2024), article\nno. 122], but also completely solve two conjectures posed by Gao et al.\n[Mediterr. J. Math. 20(2023), article no. 167].Some examples are given to\nillustrate our results.","main_category":"math.CV","categories":"math.CV","published":"2025-04-22T13:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.15911v1","title":"Direct and inverse problem for bi-wave equation with time-dependent\n  coefficients from partial data","summary":"In this article, we study a direct and an inverse problem for the bi-wave\noperator $(\\Box^2)$ along with second and lower order time-dependent\nperturbations. In the direct problem, we prove that the operator is well-posed,\ngiven initial and boundary data in suitable function spaces. In the inverse\nproblem, we prove uniqueness of the lower order time-dependent perturbations\nfrom the partial input-output operator. The restriction in the measurements are\nconsidered by restricting some of the Neumann data over a portion of the\nlateral boundary.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T13:56:50Z"}
{"aid":"http://arxiv.org/abs/2504.15932v1","title":"Reasoning Physical Video Generation with Diffusion Timestep Tokens via\n  Reinforcement Learning","summary":"Despite recent progress in video generation, producing videos that adhere to\nphysical laws remains a significant challenge. Traditional diffusion-based\nmethods struggle to extrapolate to unseen physical conditions (eg, velocity)\ndue to their reliance on data-driven approximations. To address this, we\npropose to integrate symbolic reasoning and reinforcement learning to enforce\nphysical consistency in video generation. We first introduce the Diffusion\nTimestep Tokenizer (DDT), which learns discrete, recursive visual tokens by\nrecovering visual attributes lost during the diffusion process. The recursive\nvisual tokens enable symbolic reasoning by a large language model. Based on it,\nwe propose the Phys-AR framework, which consists of two stages: The first stage\nuses supervised fine-tuning to transfer symbolic knowledge, while the second\nstage applies reinforcement learning to optimize the model's reasoning\nabilities through reward functions based on physical conditions. Our approach\nallows the model to dynamically adjust and improve the physical properties of\ngenerated videos, ensuring adherence to physical laws. Experimental results\ndemonstrate that PhysAR can generate videos that are physically consistent.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:20:59Z"}
{"aid":"http://arxiv.org/abs/2504.15936v1","title":"An effectful object calculus","summary":"We show how to smoothly incorporate in the object-oriented paradigm\nconstructs to raise, compose, and handle effects in an arbitrary monad. The\nunderlying pure calculus is meant to be a representative of the last generation\nof OO languages, and the effectful extension is manageable enough for ordinary\nprogrammers; notably, constructs to raise effects are just special methods. We\nequip the calculus with an expressive type-and-effect system, which, again by\nrelying on standard features such as inheritance and generic types, allows a\nsimple form of effect polymorphism. The soundness of the type-and-effect system\nis expressed and proved by a recently introduced technique, where the semantics\nis formalized by a one-step reduction relation from language expressions into\nmonadic ones, so that it is enough to prove progress and subject reduction\nproperties on this relation.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-22T14:24:59Z"}
{"aid":"http://arxiv.org/abs/2504.15944v1","title":"Deep learning of point processes for modeling high-frequency data","summary":"We investigate applications of deep neural networks to a point process having\nan intensity with mixing covariates processes as input. Our generic model\nincludes Cox-type models and marked point processes as well as multivariate\npoint processes. An oracle inequality and a rate of convergence are derived for\nthe prediction error. A simulation study shows that the marked point process\ncan be superior to the simple multivariate model in prediction. We apply the\nmarked ratio model to real limit order book data","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-22T14:42:16Z"}
{"aid":"http://arxiv.org/abs/2504.15958v1","title":"FreeGraftor: Training-Free Cross-Image Feature Grafting for\n  Subject-Driven Text-to-Image Generation","summary":"Subject-driven image generation aims to synthesize novel scenes that\nfaithfully preserve subject identity from reference images while adhering to\ntextual guidance, yet existing methods struggle with a critical trade-off\nbetween fidelity and efficiency. Tuning-based approaches rely on time-consuming\nand resource-intensive subject-specific optimization, while zero-shot methods\nfail to maintain adequate subject consistency. In this work, we propose\nFreeGraftor, a training-free framework that addresses these limitations through\ncross-image feature grafting. Specifically, FreeGraftor employs semantic\nmatching and position-constrained attention fusion to transfer visual details\nfrom reference subjects to the generated image. Additionally, our framework\nincorporates a novel noise initialization strategy to preserve geometry priors\nof reference subjects for robust feature matching. Extensive qualitative and\nquantitative experiments demonstrate that our method enables precise subject\nidentity transfer while maintaining text-aligned scene synthesis. Without\nrequiring model fine-tuning or additional training, FreeGraftor significantly\noutperforms existing zero-shot and training-free approaches in both subject\nfidelity and text alignment. Furthermore, our framework can seamlessly extend\nto multi-subject generation, making it practical for real-world deployment. Our\ncode is available at https://github.com/Nihukat/FreeGraftor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:55:23Z"}
{"aid":"http://arxiv.org/abs/2504.16007v1","title":"Methods for Recognizing Nested Terms","summary":"In this paper, we describe our participation in the RuTermEval competition\ndevoted to extracting nested terms. We apply the Binder model, which was\npreviously successfully applied to the recognition of nested named entities, to\nextract nested terms. We obtained the best results of term recognition in all\nthree tracks of the RuTermEval competition. In addition, we study the new task\nof recognition of nested terms from flat training data annotated with terms\nwithout nestedness. We can conclude that several approaches we proposed in this\nwork are viable enough to retrieve nested terms effectively without nested\nlabeling of them.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T16:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.16009v1","title":"Upscaling the Navier-Stokes-Cahn-Hilliard model for incompressible\n  multiphase flow in inhomogeneous porous media","summary":"In this work, we present a macroscopic model for the flow of two immiscible\nand incompressible fluids in inhomogeneous porous medium. At the pore scale,\nthe flow is governed by the fully Navier-Stokes equations while the evolution\nof the phase interface is captured by the Cahn-Hilliard equation. Using the\nvolume averaging method, the upscaled equations describing the averaged\nbehavior of two fluids at the Darcy scale are obtained, with unclosed terms\nrelated to spatial deviations. Then, spatial derivations are carefully modeled\nup to some undetermined coefficients, which could be evaluated by solving\nsimplified closure problems in each representative volume element. In\nparticular, the wetting behavior is incorporated into the averaged chemical\npotential. The differences between the proposed equations and the empirical\ntwo-phase Darcy-type models are discussed. Finally, a phase-field-based lattice\nBoltzmann model for the averaged equations is presented, and numerical results\ndemonstrate the abilities of the proposed model.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,math-ph,math.MP,physics.comp-ph,physics.geo-ph","published":"2025-04-22T16:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.16048v1","title":"PRIME: Fast Primal-Dual Feedback Optimization for Markets with\n  Application to Optimal Power Flow","summary":"Online Feedback Optimization (OFO) controllers iteratively drive a plant to\nan optimal operating point that satisfies input and output constraints, relying\nsolely on the input-output sensitivity as model information. This paper\nintroduces PRIME (PRoximal Iterative MarkEts), a novel OFO approach based on\nproximal-point iterations. Unlike existing OFO solutions, PRIME admits a\nmarket-based implementation, where self-interested actors are incentivized to\nmake choices that result in a safe and efficient operation, without\ncommunicating private costs or constraints. Furthermore, PRIME can cope with\nnon-smooth objective functions, achieve fast convergence rates and rapid\nconstraint satisfaction, and reject measurement noise. We demonstrate PRIME on\nan AC optimal power flow problem, obtaining an efficient real-time nonlinear\nlocal marginal pricing scheme.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T17:25:40Z"}
{"aid":"http://arxiv.org/abs/2504.16049v1","title":"Effect of Coriolis Force on the Shear Viscosity of Rotating Nuclear\n  Medium","summary":"Following the recent observation of non-zero spin polarization and spin\nalignment of a few hadrons, the rotational aspect of quark-gluon plasma formed\nin heavy ion collisions has attracted considerable interest. The present work\nexplores the effect of the Coriolis force, arising due to this rotation, on the\nshear viscosity of the medium. Using the relaxation time approximation within\nthe kinetic theory framework, we analyze the parallel (\\(\\eta_{||}/s\\)),\nperpendicular (\\(\\eta_\\perp/s\\)) and Hall (\\(\\eta_\\times/s\\)) components of\nshear viscosity to entropy density ratio under rotation. The estimation of\nanisotropic shear viscosity components is carried out using hadron resonance\ngas degrees of freedom below the critical (transition) temperature and massless\npartonic degrees of freedom above this temperature. Our results show that\nrotation suppresses the shear viscosity of the medium, with the degree of\nsuppression depending on the ratio between the relaxation time and the\nrotational period. In the context of realistic heavy-ion collision experiments,\nthe temperature and angular velocity both decrease with time, and one can\nestablish a connection between them through the standard approximate cooling\nlaw. For a temperature-dependent angular velocity \\(\\Omega(T)\\), we obtain a\ntraditional valley-like pattern for all components \\(\\eta_{||}/s\\),\n\\(\\eta_\\perp/s\\) and \\(\\eta_\\times/s\\) with reduced magnitudes compared to the\nvalley-like isotropic $\\eta/s$ one encounters in the absence of rotation.","main_category":"nucl-th","categories":"nucl-th,hep-th","published":"2025-04-22T17:27:10Z"}
{"aid":"http://arxiv.org/abs/2504.16057v1","title":"Automated Static Vulnerability Detection via a Holistic Neuro-symbolic\n  Approach","summary":"Static vulnerability detection is still a challenging problem and demands\nexcessive human efforts, e.g., manual curation of good vulnerability patterns.\nNone of prior works, including classic program analysis or Large Language Model\n(LLM)-based approaches, have fully automated such vulnerability pattern\ngenerations with reasonable detection accuracy. In this paper, we design and\nimplement, MoCQ, a novel holistic neuro-symbolic framework that combines the\ncomplementary strengths of LLMs and classical static analysis to enable\nscalable vulnerability detection. The key insight is that MoCQ leverages an LLM\nto automatically extract vulnerability patterns and translate them into\ndetection queries, and then on static analysis to refine such queries in a\nfeedback loop and eventually execute them for analyzing large codebases and\nmining vulnerabilities. We evaluate MoCQ on seven types of vulnerabilities\nspanning two programming languages. We found MoCQ-generated queries uncovered\nat least 12 patterns that were missed by experts. On a ground truth dataset,\nMoCQ achieved comparable precision and recall compared to expert-crafted\nqueries. Moreover, MoCQ has identified seven previously unknown vulnerabilities\nin real-world applications, demonstrating its practical effectiveness. We have\nresponsibly disclosed them to the corresponding developers.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-22T17:33:53Z"}
{"aid":"http://arxiv.org/abs/2504.16062v1","title":"ForesightNav: Learning Scene Imagination for Efficient Exploration","summary":"Understanding how humans leverage prior knowledge to navigate unseen\nenvironments while making exploratory decisions is essential for developing\nautonomous robots with similar abilities. In this work, we propose\nForesightNav, a novel exploration strategy inspired by human imagination and\nreasoning. Our approach equips robotic agents with the capability to predict\ncontextual information, such as occupancy and semantic details, for unexplored\nregions. These predictions enable the robot to efficiently select meaningful\nlong-term navigation goals, significantly enhancing exploration in unseen\nenvironments. We validate our imagination-based approach using the Structured3D\ndataset, demonstrating accurate occupancy prediction and superior performance\nin anticipating unseen scene geometry. Our experiments show that the\nimagination module improves exploration efficiency in unseen environments,\nachieving a 100% completion rate for PointNav and an SPL of 67% for ObjectNav\non the Structured3D Validation split. These contributions demonstrate the power\nof imagination-driven reasoning for autonomous systems to enhance generalizable\nand efficient exploration.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-22T17:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.16082v1","title":"MR. Video: \"MapReduce\" is the Principle for Long Video Understanding","summary":"We propose MR. Video, an agentic long video understanding framework that\ndemonstrates the simple yet effective MapReduce principle for processing long\nvideos: (1) Map: independently and densely perceiving short video clips, and\n(2) Reduce: jointly aggregating information from all clips. Compared with\nsequence-to-sequence vision-language models (VLMs), MR. Video performs detailed\nshort video perception without being limited by context length. Compared with\nexisting video agents that typically rely on sequential key segment selection,\nthe Map operation enables simpler and more scalable sequence parallel\nperception of short video segments. Its Reduce step allows for more\ncomprehensive context aggregation and reasoning, surpassing explicit key\nsegment retrieval. This MapReduce principle is applicable to both VLMs and\nvideo agents, and we use LLM agents to validate its effectiveness.\n  In practice, MR. Video employs two MapReduce stages: (A) Captioning:\ngenerating captions for short video clips (map), then standardizing repeated\ncharacters and objects into shared names (reduce); (B) Analysis: for each user\nquestion, analyzing relevant information from individual short videos (map),\nand integrating them into a final answer (reduce). MR. Video achieves over 10%\naccuracy improvement on the challenging LVBench compared to state-of-the-art\nVLMs and video agents.\n  Code is available at: https://github.com/ziqipang/MR-Video","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T17:59:41Z"}
{"aid":"http://arxiv.org/abs/2504.16388v1","title":"Measurement of the Temperature Dependence of the Refractive Index of\n  CdZnTe","summary":"We have been developing a CdZnTe immersion grating for a compact\nhigh-dispersion mid-infrared spectrometer (wavelength range 10--18 $\\mu$m,\nspectral resolution $R = \\lambda/\\Delta \\lambda > 25,000$, operating\ntemperature $T < 20$ K). Using an immersion grating, the spectrometer size can\nbe reduced to $1/n$ ($n$: refractive index) compared to conventional\ndiffraction gratings. CdZnTe is promising as a material for immersion gratings\nfor the wavelength range. However, the refractive index $n$ of CdZnTe has not\nbeen measured at $T < 20$ K.\n  We have been developing a system to precisely measure $n$ at cryogenic\ntemperatures ($T \\sim 10$ K) in the mid-infrared wavelength range. As the first\nresult, this paper reports the temperature dependence of $n$ of CdZnTe at the\nwavelength of 10.68 $\\mu$m. This system employs the minimum deviation method.\nThe refractive index $n$ of CdZnTe is measured at temperatures of \\( T = 12.57,\n22.47, 50.59, 70.57, \\text{ and } 298 \\, \\text{K} \\). We find that $n$ of\nCdZnTe at $\\lambda =$ 10.68 $\\mu$m is $2.6371 \\pm 0.0022$ at $12.57 \\pm 0.14$\nK, and the average temperature dependence of $n$ between 12.57 $\\pm$ 0.14 K and\n70.57 $\\pm$ 0.23 K is $\\Delta n/\\Delta T = (5.8 \\pm 0.3) \\times 10^{-5}$\nK$^{-1}$.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-23T03:30:54Z"}
{"aid":"http://arxiv.org/abs/2504.16390v1","title":"Probing Bulk Band Topology from Time Boundary Effect in Synthetic\n  Dimension","summary":"An incident wave at a temporal interface, created by an abrupt change in\nsystem parameters, generates time-refracted and time-reflected waves. We find\ntopological characteristics associated with the temporal interface that\nseparates distinct spatial topologies and report a novel bulk-boundary\ncorrespondence for the temporal interface. The vanishing of either time\nrefraction or time reflection records a topological phase transition across the\ntemporal interface, and the difference of bulk band topology predicts\nnontrivial braiding hidden in the time refraction and time reflection\ncoefficients. These findings, which are insensitive to spatial boundary\nconditions and robust against disorder, are demonstrated in a synthetic\nfrequency lattice with rich topological phases engendered by long-range\ncouplings. Our work reveals the topological aspect of temporal interface and\npaves the way for using the time boundary effect to probe topological phase\ntransitions and topological invariants.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-23T03:35:12Z"}
{"aid":"http://arxiv.org/abs/2504.16391v1","title":"Evolution of QPO during Rising Phase of Discovery Outburst of Swift\n  J1727.8-1613: Estimation of Mass from Spectro-Temporal Study","summary":"The rising phase of the 2023-24 outburst of the recently discovered bright\ntransient black hole candidate Swift J1727.8-1613 was monitored by\n\\textit{Insight}-HXMT. We study the evolution of hard ($4$-$150$ keV) and soft\n($2$-$4$ keV) band photon count rates, the hardness ratio (HR), and QPO\nfrequencies using daily observations from the HXMT/LE, ME, and HE instruments\nbetween August 25 and October 5, 2023. The QPO frequency is found to be\nstrongly correlated with the soft-band X-ray count rates, and spectral photon\nindices. In contrast, a strong anti-correlation is observed between HR and QPO\nfrequency, as well as between HR and photon index. Based on the evolution of\nthe QPO frequency, the rising phase of the outburst is subdivided into six\nparts, with parts 1-5 fitted using the propagating oscillatory shock (POS)\nsolution to understand the nature of the evolution from a physical perspective.\nThe best-fitted POS model is obtained with a black hole mass of\n$13.34\\pm0.02~M_\\odot$. An inward-propagating shock with weakening strength\n(except in part 4) is observed during the period of our study. The POS\nmodel-fitted mass of the source is further confirmed using the QPO frequency\n($\\nu$)-photon index ($\\Gamma$) scaling method. From this method, the estimated\nprobable mass of Swift J1727.8-1613 is obtained to be $13.54\\pm1.87~M_\\odot$.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T03:37:58Z"}
{"aid":"http://arxiv.org/abs/2504.16406v1","title":"Long Exposure Localization in Darkness Using Consumer Cameras","summary":"In this paper we evaluate performance of the SeqSLAM algorithm for passive\nvision-based localization in very dark environments with low-cost cameras that\nresult in massively blurred images. We evaluate the effect of motion blur from\nexposure times up to 10,000 ms from a moving car, and the performance of\nlocalization in day time from routes learned at night in two different\nenvironments. Finally we perform a statistical analysis that compares the\nbaseline performance of matching unprocessed grayscale images to using patch\nnormalization and local neighborhood normalization - the two key SeqSLAM\ncomponents. Our results and analysis show for the first time why the SeqSLAM\nalgorithm is effective, and demonstrate the potential for cheap camera-based\nlocalization systems that function despite extreme appearance change.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T04:18:57Z"}
{"aid":"http://arxiv.org/abs/2504.16412v1","title":"Superconductivity and Electron Correlations in Kagome Metal LuOs3B2","summary":"We report a comprehensive investigation of the physical properties of\nLuOs3B2, characterized by an ideal Os-based kagome lattice. Resistivity and\nmagnetization measurements confirm the emergence of type-II bulk\nsuperconductivity with a critical temperature Tc=4.63 K. The specific heat jump\nand the calculated electron-phonon coupling parameter support a moderately\ncoupled superconducting state. Electron correlation effects are supported by\nthe enhanced Wilson ratios. First-principles calculations reveal hallmark\nfeatures of kagome band structure, including Dirac points, van Hove\nsingularities, and quasi-flat bands, primarily derived from the Os d orbitals.\nThe inclusion of spin-orbit coupling opens a gap at the Dirac points,\nsignificantly altering the electronic properties. Furthermore, the\nsuperconductivity and electronic properties of isomorphic compounds are\ndiscussed. This work provides a thorough exploration of the superconducting and\nnormal states of LuOs3B2, deepening the understanding of kagome\nsuperconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-23T04:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.16417v1","title":"Anytime Safe Reinforcement Learning","summary":"This paper considers the problem of solving constrained\n  reinforcement learning problems with anytime guarantees, meaning\n  that the algorithmic solution returns a safe policy regardless of\n  when it is terminated. Drawing inspiration from anytime constrained\n  optimization, we introduce Reinforcement Learning-based Safe\n  Gradient Flow (RL-SGF), an on-policy algorithm which employs\n  estimates of the value functions and their respective gradients\n  associated with the objective and safety constraints for the current\n  policy, and updates the policy parameters by solving a convex\n  quadratically constrained quadratic program. We show that if the\n  estimates are computed with a sufficiently large number of episodes\n  (for which we provide an explicit bound), safe policies are updated\n  to safe policies with a probability higher than a prescribed\n  tolerance. We also show that iterates asymptotically converge to a\n  neighborhood of a KKT point, whose size can be arbitrarily reduced\n  by refining the estimates of the value function and their gradients.\n  We illustrate the performance of RL-SGF in a navigation example.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-23T04:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.16419v1","title":"PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels","summary":"Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.HC","published":"2025-04-23T05:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.16464v1","title":"ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree\n  and Visual Guidance","summary":"While recent advancements in robotic manipulation video synthesis have shown\npromise, significant challenges persist in ensuring effective\ninstruction-following and achieving high visual quality. Recent methods, like\nRoboDreamer, utilize linguistic decomposition to divide instructions into\nseparate lower-level primitives, conditioning the world model on these\nprimitives to achieve compositional instruction-following. However, these\nseparate primitives do not consider the relationships that exist between them.\nFurthermore, recent methods neglect valuable visual guidance, including depth\nand semantic guidance, both crucial for enhancing visual quality. This paper\nintroduces ManipDreamer, an advanced world model based on the action tree and\nvisual guidance. To better learn the relationships between instruction\nprimitives, we represent the instruction as the action tree and assign\nembeddings to tree nodes, each instruction can acquire its embeddings by\nnavigating through the action tree. The instruction embeddings can be used to\nguide the world model. To enhance visual quality, we combine depth and semantic\nguidance by introducing a visual guidance adapter compatible with the world\nmodel. This visual adapter enhances both the temporal and physical consistency\nof video generation. Based on the action tree and visual guidance, ManipDreamer\nsignificantly boosts the instruction-following ability and visual quality.\nComprehensive evaluations on robotic manipulation benchmarks reveal that\nManipDreamer achieves large improvements in video quality metrics in both seen\nand unseen tasks, with PSNR improved from 19.55 to 21.05, SSIM improved from\n0.7474 to 0.7982 and reduced Flow Error from 3.506 to 3.201 in unseen tasks,\ncompared to the recent RoboDreamer model. Additionally, our method increases\nthe success rate of robotic manipulation tasks by 2.5% in 6 RLbench tasks on\naverage.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-23T07:23:41Z"}
{"aid":"http://arxiv.org/abs/2504.16469v1","title":"Closed-form analysis of Multi-RIS Reflected Signals in RIS-Aided\n  Networks Using Stochastic Geometry","summary":"Reconfigurable intelligent surfaces (RISs) enhance wireless communication by\ncreating engineered signal reflection paths in addition to direct links. This\nwork presents a stochastic geometry framework using point processes (PPs) to\nmodel multiple randomly deployed RISs conditioned on their associated base\nstation (BS) locations. By characterizing aggregated reflections from multiple\nRISs using the Laplace transform, we analytically assess the performance impact\nof RIS-reflected signals by integrating this characterization into\nwell-established stochastic geometry frameworks. Specifically, we derive\nclosed-form expressions for the Laplace transform of the reflected signal power\nin several deployment scenarios. These analytical results facilitate\nperformance evaluation of RIS-enabled enhancements. Numerical simulations\nvalidate that optimal RIS placement favors proximity to BSs or user equipment\n(UEs), and further quantify the impact of reflected interference, various\nfading assumptions, and diverse spatial deployment strategies. Importantly, our\nanalytical approach shows superior computational efficiency compared to Monte\nCarlo simulations.","main_category":"cs.PF","categories":"cs.PF,cs.IT,math.IT","published":"2025-04-23T07:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.16470v1","title":"Improved Streaming Edge Coloring","summary":"Given a graph, an edge coloring assigns colors to edges so that no pairs of\nadjacent edges share the same color. We are interested in edge coloring\nalgorithms under the W-streaming model. In this model, the algorithm does not\nhave enough memory to hold the entire graph, so the edges of the input graph\nare read from a data stream one by one in an unknown order, and the algorithm\nneeds to print a valid edge coloring in an output stream. The performance of\nthe algorithm is measured by the amount of space and the number of different\ncolors it uses.\n  This streaming edge coloring problem has been studied by several works in\nrecent years. When the input graph contains $n$ vertices and has maximum vertex\ndegree $\\Delta$, it is known that in the W-streaming model, an\n$O(\\Delta^2)$-edge coloring can be computed deterministically with\n$\\tilde{O}(n)$ space [Ansari, Saneian, and Zarrabi-Zadeh, 2022], or an\n$O(\\Delta^{1.5})$-edge coloring can be computed by a $\\tilde{O}(n)$-space\nrandomized algorithm [Behnezhad, Saneian, 2024] [Chechik, Mukhtar, Zhang,\n2024].\n  In this paper, we achieve polynomial improvement over previous results.\nSpecifically, we show how to improve the number of colors to\n$\\tilde{O}(\\Delta^{4/3+\\epsilon})$ using space $\\tilde{O}(n)$\ndeterministically, for any constant $\\epsilon > 0$. This is the first\ndeterministic result that bypasses the quadratic bound on the number of colors\nwhile using near-linear space.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T07:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.16482v1","title":"Next Generation Multi-element monolithic Germanium detectors for\n  Spectroscopy: First integration at ESRF facility","summary":"The XAFS-DET work package of the European LEAPS-INNOV project is developing a\nhigh-purity Germanium detectors for synchrotron applications requiring\nspectroscopic-grade response. The detectors integrate three key features: (1)\nnewly designed monolithic Germanium sensors optimised to mitigate\ncharge-sharing events, (2) an improved cooling and mechanical design structure\nsupported by thermal simulations, and (3) complete electronic chain featuring a\nlow-noise CMOS technology-based preamplifier. enabling high X-ray count rate\ncapability over a broad energy range (5-100 keV). This paper discusses the\nfirst integration and characterization of one of the two multi-element Ge\ndetectors at the European Synchrotron Radiation Facility (ESRF). The\nintegration phase included validating high-throughput front-End electronics,\nintegrating them with the Ge sensor, and operating them at liquid nitrogen\ntemperature, in addition to the experimental characterization, which consists\nof electronics noise study and spectroscopic performance evaluation.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-23T07:51:37Z"}
{"aid":"http://arxiv.org/abs/2504.16483v1","title":"Exploring turnover, retention and growth in an OSS Ecosystem","summary":"The Gentoo ecosystem has evolved significantly over 23 years, highlighting\nthe critical impact of developer sentiment on workforce dynamics such as\nturnover, retention, and growth. While prior research has explored sentiment at\nthe project level, sentiment-driven dynamics at the component level remain\nunderexplored, particularly in their implications for software stability.\n  This study investigates the interplay between developer sentiment and\nworkforce dynamics in Gentoo. The primary objectives are to (1) compare\nworkforce metrics (turnover, retention, and growth rates) between\nsentiment-positive (SP) and sentiment-negative (SN) components, (2) examine\ntemporal trends across three time phases, and (3) analyze the impact of these\ndynamics on software stability.\n  A mixed-method approach was employed, integrating sentiment analysis of\nmailing lists and commit histories using the SentiStrength-SE tool. Workforce\nmetrics were statistically analyzed using Pearson Correlation Matrix and\nMann-Whitney U tests. The analysis focused on the most SP and SN components in\nthe ecosystem.\n  SN components exhibited higher retention rates but slower growth and turnover\ncompared to SP components, which showed dynamic contributor behavior but\nreduced long-term stability. Temporal analysis revealed significant variations\nin workforce dynamics over three phases, with developer retention correlating\npositively with modifications in both sentiment groups.\n  Tailored strategies are necessary for managing sentiment-driven dynamics in\nOSS projects. Improving \\textit{adaptability} in SN components, and\n\\textit{continuity} in SP components, could improve project sustainability and\ninnovation. This study contributes to a nuanced understanding of sentiment's\nrole in workforce behavior and software stability within OSS ecosystems.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T07:52:12Z"}
{"aid":"http://arxiv.org/abs/2504.16484v1","title":"Experimentally Certifying Kochen-Specker Set with the Maximally Mixed\n  State","summary":"Certifying Kochen-Specker (KS) set is a task of certifying a set of\nuncharacterized projectors as desired KS set. This work demonstrates an\nimproved scheme that enables this certification using only a maximally mixed\nstate, rather than traversing over all states, making it experimental feasible.\nIn this scheme, outcomes obtained from sequential measurements are used for the\nevaluation of the worst result and its certification threshold, based on the\ncharacteristics of maximally mixed state and a semi-definite program.\nExperimentally, a group of projectors closely approximating the KS set Peres-24\nis certified in an optical system, highlighting the feasibility of this scheme\nin certifying KS set. Furthermore, a quantitative analysis is presented by\nmanually adding errors to the optical system, demonstrating a strict level of\nexperimental imperfection in achieving successful certification. These results\noffer a new perspective on characterizing measurements from quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T07:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.16487v1","title":"Rethinking Generalizable Infrared Small Target Detection: A Real-scene\n  Benchmark and Cross-view Representation Learning","summary":"Infrared small target detection (ISTD) is highly sensitive to sensor type,\nobservation conditions, and the intrinsic properties of the target. These\nfactors can introduce substantial variations in the distribution of acquired\ninfrared image data, a phenomenon known as domain shift. Such distribution\ndiscrepancies significantly hinder the generalization capability of ISTD models\nacross diverse scenarios. To tackle this challenge, this paper introduces an\nISTD framework enhanced by domain adaptation. To alleviate distribution shift\nbetween datasets and achieve cross-sample alignment, we introduce Cross-view\nChannel Alignment (CCA). Additionally, we propose the Cross-view Top-K Fusion\nstrategy, which integrates target information with diverse background features,\nenhancing the model' s ability to extract critical data characteristics. To\nfurther mitigate the impact of noise on ISTD, we develop a Noise-guided\nRepresentation learning strategy. This approach enables the model to learn more\nnoise-resistant feature representations, to improve its generalization\ncapability across diverse noisy domains. Finally, we develop a dedicated\ninfrared small target dataset, RealScene-ISTD. Compared to state-of-the-art\nmethods, our approach demonstrates superior performance in terms of detection\nprobability (Pd), false alarm rate (Fa), and intersection over union (IoU). The\ncode is available at: https://github.com/luy0222/RealScene-ISTD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T07:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.16502v1","title":"Helping Blind People Grasp: Enhancing a Tactile Bracelet with an\n  Automated Hand Navigation System","summary":"Grasping constitutes a critical challenge for visually impaired people. To\naddress this problem, we developed a tactile bracelet that assists in grasping\nby guiding the user's hand to a target object using vibration commands. Here we\ndemonstrate the fully automated system around the bracelet, which can\nconfidently detect and track target and distractor objects and reliably guide\nthe user's hand. We validate our approach in three tasks that resemble complex,\neveryday use cases. In a grasping task, the participants grasp varying target\nobjects on a table, guided via the automated hand navigation system. In the\nmultiple objects task, participants grasp objects from the same class,\ndemonstrating our system's ability to track one specific object without\ntargeting surrounding distractor objects. Finally, the participants grasp one\nspecific target object by avoiding an obstacle along the way in the depth\nnavigation task, showcasing the potential to utilize our system's depth\nestimations to navigate even complex scenarios. Additionally, we demonstrate\nthat the system can aid users in the real world by testing it in a less\nstructured environment with a blind participant. Overall, our results\ndemonstrate that the system, by translating the AI-processed visual inputs into\na reduced data rate of actionable signals, enables autonomous behavior in\neveryday environments, thus potentially increasing the quality of life of\nvisually impaired people.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T08:24:24Z"}
{"aid":"http://arxiv.org/abs/2504.16511v1","title":"QuaDMix: Quality-Diversity Balanced Data Selection for Efficient LLM\n  Pretraining","summary":"Quality and diversity are two critical metrics for the training data of large\nlanguage models (LLMs), positively impacting performance. Existing studies\noften optimize these metrics separately, typically by first applying quality\nfiltering and then adjusting data proportions. However, these approaches\noverlook the inherent trade-off between quality and diversity, necessitating\ntheir joint consideration. Given a fixed training quota, it is essential to\nevaluate both the quality of each data point and its complementary effect on\nthe overall dataset. In this paper, we introduce a unified data selection\nframework called QuaDMix, which automatically optimizes the data distribution\nfor LLM pretraining while balancing both quality and diversity. Specifically,\nwe first propose multiple criteria to measure data quality and employ domain\nclassification to distinguish data points, thereby measuring overall diversity.\nQuaDMix then employs a unified parameterized data sampling function that\ndetermines the sampling probability of each data point based on these quality\nand diversity related labels. To accelerate the search for the optimal\nparameters involved in the QuaDMix framework, we conduct simulated experiments\non smaller models and use LightGBM for parameters searching, inspired by the\nRegMix method. Our experiments across diverse models and datasets demonstrate\nthat QuaDMix achieves an average performance improvement of 7.2% across\nmultiple benchmarks. These results outperform the independent strategies for\nquality and diversity, highlighting the necessity and ability to balance data\nquality and diversity.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T08:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.16515v1","title":"Federated Learning of Low-Rank One-Shot Image Detection Models in Edge\n  Devices with Scalable Accuracy and Compute Complexity","summary":"This paper introduces a novel federated learning framework termed LoRa-FL\ndesigned for training low-rank one-shot image detection models deployed on edge\ndevices. By incorporating low-rank adaptation techniques into one-shot\ndetection architectures, our method significantly reduces both computational\nand communication overhead while maintaining scalable accuracy. The proposed\nframework leverages federated learning to collaboratively train lightweight\nimage recognition models, enabling rapid adaptation and efficient deployment\nacross heterogeneous, resource-constrained devices. Experimental evaluations on\nthe MNIST and CIFAR10 benchmark datasets, both in an\nindependent-and-identically-distributed (IID) and non-IID setting, demonstrate\nthat our approach achieves competitive detection performance while\nsignificantly reducing communication bandwidth and compute complexity. This\nmakes it a promising solution for adaptively reducing the communication and\ncompute power overheads, while not sacrificing model accuracy.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T08:40:44Z"}
{"aid":"http://arxiv.org/abs/2504.16525v1","title":"Gravitational Positivity Bounds on Higgs-Portal Dark Matter","summary":"We consider gravitational positivity bounds on the Higgs-portal scalar dark\nmatter model. Applying gravitational positivity bounds with dark matter forward\nscattering process $\\phi \\phi \\to \\phi \\phi$ to this DM model, we find that the\nnew physics, besides the Higgs-portal dark matter physics, arises at an energy\nscale lower than $10^{10}$ GeV without the dark matter self-coupling. With the\nexistence of the dark matter self-coupling, the hierarchical order of magnitude\nbetween the self-coupling $\\lambda_{\\phi}$ and the Higgs-portal coupling\n$\\lambda_{h\\phi}$ changes the game. With $\\lambda_{\\phi}/\\lambda_{h\\phi} =\n10^{12}$, the GUT scale cutoff can realize. In this case, the dark freezeout\nscenario is possible for realizing the relic density of dark matter in the\nUniverse. We find that $\\lambda_{\\phi} \\sim O(1)$, $\\lambda_{h\\phi} \\sim\n10^{-12}$, and sub-GeV dark matter is implicated for the GUT scale cutoff\npossibility with the Higgs-portal dark matter model.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T08:49:36Z"}
{"aid":"http://arxiv.org/abs/2504.16534v1","title":"Partitioning of multiple brain metastases improves dose gradients in\n  single-isocenter radiosurgery","summary":"Background: A growing number of cancer patients with brain metastases can\nbenefit from stereotactic radiosurgery (SRS) thanks to recent advances in\nsystemic therapies. With an increasing patient load, single-isocenter\ntreatments on widely available C-arm linear accelerators are an attractive\noption. However, the planning of such treatments is challenging for\nmulti-target cases due to the island blocking problem, which occurs when the\nmulti-leaf collimator cannot conform to all targets simultaneously.\n  Purpose: We propose a multi-target partitioning algorithm that mitigates\nexcessive exposure of normal tissue caused by the island blocking problem.\n  Methods: The algorithm divides (partitions) the set of targets into subsets\nto treat with separate arc passes, optimizing both subsets and collimator\nangles to minimize island blocking. The algorithm was incorporated into a fully\nautomated treatment planning script and evaluated on 20 simulated patient\ncases, each with 10 brain metastases and 21 Gy prescriptions. It was also\nretrospectively evaluated on six clinical cases.\n  Results: Partitioning significantly improved the gradient index, global\nefficiency index, and brain V12Gy compared to simultaneous treatment of all\nmetastases. For example, the average gradient index improved from 5.9 to 3.3,\nglobal efficiency index from 0.32 to 0.46, and normal brain V12Gy from 49 cm3\nto 26 cm3 between 3 and 9 arcs. The proposed algorithm outperformed baselines\nin utilizing a limited number of arcs. All target partitioning strategies\nincreased the total number of monitor units (MUs).\n  Conclusions: The dose gradient in single-isocenter VMAT plans can be\nsubstantially improved by treating a smaller subset of metastases at a time.\nThis requires more MUs and arcs, implying a trade-off between delivery time and\nplan quality which can be explored using the algorithm proposed in this paper.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-23T09:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.16582v1","title":"Nanomechanics and Pore Structure of Sodium and Potassium Geopolymer\n  Gels: Experiments, Molecular Dynamics and Coarse-Grained Simulations","summary":"The link between composition, microstructure and mechanics of NASH and KASH\ngels is elusive, even in pure metakaolin-based geopolymes. This article\nexploits molecular mechanics, coarse-grained nanomechanics and micromechanics,\nto interpret new experimental results from microscopy, porosimetry and\nnanoindentation. KASH displays a finer nanogranular structure than NASH (3 vs\n30 nm particle diameters, 5 vs 50 nm average pore diameters), higher skeletal\ndensity (2.3 vs 2.02 g/cm$^3$), nanoindentation moduli (9.21 vs 7.5 GPa) and\nhardness (0.56 vs 0.37 GPa) despite a higher total porosity (0.48-0.53 vs\n0.38). This suggests a stiffer and stronger solid skeleton for KASH, confirmed\nthrough predictive molecular dynamics simulations on recent and new models of\nNASH and KASH. The atomistic simulations inform mechanical interactions for\nnew, coarse-grained, particle-based models of NASH and KASH. The resulting\nsimulations predict the nanoindentation result that KASH is stiffer than\nequally porous NASH and the impact of formation eigenstresses on elastic\nmoduli.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T10:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.16586v1","title":"Learning Switchable Priors for Neural Image Compression","summary":"Neural image compression (NIC) usually adopts a predefined family of\nprobabilistic distributions as the prior of the latent variables, and meanwhile\nrelies on entropy models to estimate the parameters for the probabilistic\nfamily. More complex probabilistic distributions may fit the latent variables\nmore accurately, but also incur higher complexity of the entropy models,\nlimiting their practical value. To address this dilemma, we propose a solution\nto decouple the entropy model complexity from the prior distributions. We use a\nfinite set of trainable priors that correspond to samples of the parametric\nprobabilistic distributions. We train the entropy model to predict the index of\nthe appropriate prior within the set, rather than the specific parameters.\nSwitching between the trained priors further enables us to embrace a skip mode\ninto the prior set, which simply omits a latent variable during the entropy\ncoding. To demonstrate the practical value of our solution, we present a\nlightweight NIC model, namely FastNIC, together with the learning of switchable\npriors. FastNIC obtains a better trade-off between compression efficiency and\ncomputational complexity for neural image compression. We also implanted the\nswitchable priors into state-of-the-art NIC models and observed improved\ncompression efficiency with a significant reduction of entropy coding\ncomplexity.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-23T10:06:58Z"}
{"aid":"http://arxiv.org/abs/2504.16587v1","title":"Spin polarization as a probe of the QCD critical point","summary":"Spin polarization is a novel method for probing the rotational properties of\nthe quark-gluon plasma (QGP) produced in relativistic heavy-ion collisions. In\nthis work, we investigate the effective transport and thermodynamic\ncoefficients in non-central O+O light-ion collisions, considering a parton\ndistribution function that incorporates the spin polarization induced by\nthermal vorticity during the collision. Using a kinetic theory approach, we\nfind that while the speed of sound squared ($c_s^2$) remains largely unaffected\nby spin polarization, the specific shear viscosity ($\\eta/s$), specific bulk\nviscosity ($\\zeta/s$), and mean free path ($\\lambda$) are significantly\nmodified.\n  Notably, when spin polarization is taken into account, both $c_s^2 $ and\n$\\zeta/s$ exhibit a non-monotonic dependence on collision energy, with an\ninflection point around $\\sqrt{s_{NN}} = 27 $~GeV, corresponding to an average\nparton chemical potential of $\\langle\\mu_p\\rangle = 0.021 $~GeV. This\nnon-monotonic behavior suggests that incorporating spin polarization into\ntheoretical calculations could provide an effective probe for locating the\ncritical point of the QCD phase transition.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-23T10:08:31Z"}
{"aid":"http://arxiv.org/abs/2504.16601v1","title":"Comparing Large Language Models and Traditional Machine Translation\n  Tools for Translating Medical Consultation Summaries: A Pilot Study","summary":"This study evaluates how well large language models (LLMs) and traditional\nmachine translation (MT) tools translate medical consultation summaries from\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\nfriendly and clinician, focused texts using standard automated metrics. Results\nshowed that traditional MT tools generally performed better, especially for\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\nChinese, when translating simpler summaries. Arabic translations improved with\ncomplexity due to the language's morphology. Overall, while LLMs offer\ncontextual flexibility, they remain inconsistent, and current evaluation\nmetrics fail to capture clinical relevance. The study highlights the need for\ndomain-specific training, improved evaluation methods, and human oversight in\nmedical translation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T10:31:33Z"}
{"aid":"http://arxiv.org/abs/2504.16645v1","title":"Preliminary design of a Cavity Tuner for Superconducting Radio-Frequency\n  Cavity","summary":"This paper introduces a newly designed cavity tuner for superconducting\nradio-frequency (SRF) cavity. Aiming to overcome the drawbacks of traditional\ntuning systems, like the limited tuning range of piezoelectric tuner and the\nlow-speed tuning of stepper-motor-based tuner, this novel tuner is crafted to\nimprove SRF cavity performance and stability via efficient and accurate\nfrequency tuning. The design encompasses several key elements. The cavity\nstructure includes a commonly used 1.3 GHz single-cell superconducting cavity\nand a room-temperature coaxial tuner cavity. The coupling mechanism between the\ntwo cavities, along with the coupling window design, ensures effective energy\ntransfer while minimizing losses. The mechanical tuning system, driven by\nelectromagnetic coils, enables precise adjustments, and the cooling mechanisms\nfor both cavities guarantee stable operation. Functioning by coupling an\nexternal resonant cavity to the superconducting one, this tuner can adjust\nfrequencies through mechanical or electromagnetic methods. It realizes rapid\ntuning, with a speed much faster than traditional mechanical tuner,\nhigh-precision tuning down to the sub-mHz level, and a wide tuning range\ncovering a broader frequency spectrum. Theoretical analysis and simulations\nverify that the tuner can remarkably enhance tuning speed, precision, and\nrange. It also has distinct advantages such as a simplified structure, which\nreduces manufacturing and maintenance complexity, and enhanced reliability due\nto its non-contact tuning operation. In particle accelerators, this cavity\ntuner holds great potential. It represents a significant step forward in\nsuperconducting accelerator technology, offering a novel way to optimize the\nperformance and stability of SRF cavity.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-23T12:05:34Z"}
{"aid":"http://arxiv.org/abs/2504.16652v1","title":"Non-linearity Effect Analysis of Gaussian Pulse Propagation In Optical\n  Fiber","summary":"In this research, numerical analysis of nonlinear pulse propagation is\ncarried out. This is done mainly by solving the nonlinear Schrodinger equation\nusing the split step algorithm. In a nonlinear media, dispersive effects exist\nsimultaneously with nonlinear effects. Refractive index dependence on intensity\nresults in optical Kerr effect which causes narrowing of transmitted pulses by\ninducing self-phase modulation while second order group velocity dispersion\ncauses the pulses to spread. In this project, group velocity dispersion is\ndiscussed followed by self-phase modulation. These individually detrimental\neffects are shown to combine beneficially for propagation of pulses here.\nGaussian pulse is studied and propagated by using them as input in to the\nnonlinear Schrodinger equation. The split step algorithm is described in depth.\nExplanation of each step is included along with the relevant equations defining\nthese steps.","main_category":"physics.optics","categories":"physics.optics,eess.SP","published":"2025-04-23T12:17:43Z"}
{"aid":"http://arxiv.org/abs/2504.16681v1","title":"On the origin of long-term modulation in the Sun's magnetic activity\n  cycle","summary":"One of the most striking manifestations of orderly behavior emerging out of\ncomplex interactions in any astrophysical system is the 11-year cycle of\nsunspots. However, direct sunspot observations and reconstructions of long-term\nsolar activity clearly exhibit amplitude fluctuations beyond the decadal\ntimescale -- which may be termed as supradecadal modulation. Whether this\nlong-term modulation in the Sun's magnetic activity results from nonlinear\nmechanisms or stochastic perturbations remains controversial and a matter of\nactive debate. Utilizing multi-millennial scale kinematic dynamo simulations\nbased on the Babcock-Leighton paradigm -- in the likely (near-critical) regime\nof operation of the solar dynamo -- we demonstrate that this supradecadal\nmodulation in solar activity cannot be explained by nonlinear mechanisms alone;\nstochastic forcing is essential for the manifestation of observed long-term\nfluctuations in the near-critical dynamo regime. Our findings substantiate some\nindependent observational and theoretical investigations, and provide\nadditional insights into temporal dynamics associated with a plethora of\nnatural phenomena in astronomy and planetary systems arising from weakly\nnonlinear, non-deterministic processes.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T13:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.16706v1","title":"Sorting as Gradient Flow on the Permutohedron","summary":"We investigate how sorting algorithms efficiently overcome the exponential\nsize of the permutation space. Our main contribution is a new continuous-time\nformulation of sorting as a gradient flow on the permutohedron, yielding an\nindependent proof of the classical $\\Omega(n \\log n)$ lower bound for\ncomparison-based sorting. This formulation reveals how exponential contraction\nof disorder occurs under simple geometric dynamics. In support of this\nanalysis, we present algebraic, combinatorial, and geometric perspectives,\nincluding decision-tree arguments and linear constraints on the permutohedron.\nThe idea that efficient sorting arises from structure-guided logarithmic\nreduction offers a unifying lens for how comparisons tame exponential spaces.\nThese observations connect to broader questions in theoretical computer\nscience, such as whether the existence of structure can explain why certain\ncomputational problems permit efficient solutions.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T13:38:00Z"}
{"aid":"http://arxiv.org/abs/2504.16712v1","title":"Detecting Cosmological Phase Transitions with Taiji: Sensitivity\n  Analysis and Parameter Estimation","summary":"We investigate the capability of the Taiji space-based gravitational wave\nobservatory to detect stochastic gravitational wave backgrounds produced by\nfirst-order phase transitions in the early universe. Using a comprehensive\nsimulation framework that incorporates realistic instrumental noise, galactic\ndouble white dwarf confusion noise, and extragalactic compact binary\nbackgrounds, we systematically analyze Taiji's sensitivity across a range of\nsignal parameters. Our Bayesian analysis demonstrates that Taiji can robustly\ndetect and characterize phase transition signals with energy densities\nexceeding $\\Omega_{\\text{PT}} \\gtrsim 1.4 \\times 10^{-11}$ across most of its\nfrequency band, with particularly strong sensitivity around $10^{-3}$ to\n$10^{-2}$ Hz. For signals with amplitudes above $\\Omega_{\\text{PT}} \\gtrsim 1.1\n\\times 10^{-10}$, Taiji can determine the peak frequency with relative\nprecision better than $10\\%$. These detection capabilities would enable Taiji\nto probe electroweak-scale phase transitions in various beyond-Standard-Model\nscenarios, potentially revealing new physics connected to baryogenesis and dark\nmatter production. We quantify detection confidence using both Bayes factors\nand the Deviance Information Criterion, finding consistent results that\nvalidate our statistical methodology.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.IM","published":"2025-04-23T13:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.16718v1","title":"Simulating Quantum Circuits with Tree Tensor Networks using\n  Density-Matrix Renormalization Group Algorithm","summary":"Quantum computing offers the potential for computational abilities that can\ngo beyond classical machines. However, they are still limited by several\nchallenges such as noise, decoherence, and gate errors. As a result, efficient\nclassical simulation of quantum circuits is vital not only for validating and\nbenchmarking quantum hardware but also for gaining deeper insights into the\nbehavior of quantum algorithms. A promising framework for classical simulation\nis provided by tensor networks. Recently, the Density-Matrix Renormalization\nGroup (DMRG) algorithm was developed for simulating quantum circuits using\nmatrix product states (MPS). Although MPS is efficient for representing quantum\nstates with one-dimensional correlation structures, the fixed linear geometry\nrestricts the expressive power of the MPS. In this work, we extend the DMRG\nalgorithm for simulating quantum circuits to tree tensor networks (TTNs). To\nbenchmark the method, we simulate random and QAOA circuits with various\ntwo-qubit gate connectivities. For the random circuits, we devise tree-like\ngate layouts that are suitable for TTN and show that TTN requires less memory\nthan MPS for the simulations. For the QAOA circuits, a TTN construction that\nexploits graph structure significantly improves the simulation fidelities. Our\nfindings show that TTNs provide a promising framework for simulating quantum\ncircuits, particularly when gate connectivities exhibit clustering or a\nhierarchical structure.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T13:48:03Z"}
{"aid":"http://arxiv.org/abs/2504.16719v1","title":"Higher-order photon rings of an ultracompact object and their\n  interferometric pattern","summary":"A horizonless ultracompact object can have a stable antiphoton sphere, which\ncauses the strong deflection of photons inside the unstable photon sphere,\nleading to the formation of distinctive inner photon rings. In this work, we\npresent analytical descriptions for the shape, thickness and interference\npattern of higher-order inner photon rings. By taking the static spherically\nsymmetric Schwarzschild star with a photon sphere as an example, we find that\nits inner photon rings can be more non-circular and thicker than the outer\nones, and show that the inclusion of the inner photon rings can give rise to\nnew features in the interferometric pattern. Our formulae can also be applied\nto other ultracompact objects, providing a convenient way to study the\nobservational properties of their higher-order photon rings.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T13:49:44Z"}
{"aid":"http://arxiv.org/abs/2504.16728v1","title":"IRIS: Interactive Research Ideation System for Accelerating Scientific\n  Discovery","summary":"The rapid advancement in capabilities of large language models (LLMs) raises\na pivotal question: How can LLMs accelerate scientific discovery? This work\ntackles the crucial first stage of research, generating novel hypotheses. While\nrecent work on automated hypothesis generation focuses on multi-agent\nframeworks and extending test-time compute, none of the approaches effectively\nincorporate transparency and steerability through a synergistic\nHuman-in-the-loop (HITL) approach. To address this gap, we introduce IRIS:\nInteractive Research Ideation System, an open-source platform designed for\nresearchers to leverage LLM-assisted scientific ideation. IRIS incorporates\ninnovative features to enhance ideation, including adaptive test-time compute\nexpansion via Monte Carlo Tree Search (MCTS), fine-grained feedback mechanism,\nand query-based literature synthesis. Designed to empower researchers with\ngreater control and insight throughout the ideation process. We additionally\nconduct a user study with researchers across diverse disciplines, validating\nthe effectiveness of our system in enhancing ideation. We open-source our code\nat https://github.com/Anikethh/IRIS-Interactive-Research-Ideation-System","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-23T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.16760v1","title":"Lightweight Latent Verifiers for Efficient Meta-Generation Strategies","summary":"Verifiers are auxiliary models that assess the correctness of outputs\ngenerated by base large language models (LLMs). They play a crucial role in\nmany strategies for solving reasoning-intensive problems with LLMs. Typically,\nverifiers are LLMs themselves, often as large (or larger) than the base model\nthey support, making them computationally expensive. In this work, we introduce\na novel lightweight verification approach, LiLaVe, which reliably extracts\ncorrectness signals from the hidden states of the base LLM. A key advantage of\nLiLaVe is its ability to operate with only a small fraction of the\ncomputational budget required by traditional LLM-based verifiers. To\ndemonstrate its practicality, we couple LiLaVe with popular meta-generation\nstrategies, like best-of-n or self-consistency. Moreover, we design novel\nLiLaVe-based approaches, like conditional self-correction or conditional\nmajority voting, that significantly improve both accuracy and efficiency in\ngeneration tasks with smaller LLMs. Our work demonstrates the fruitfulness of\nextracting latent information from the hidden states of LLMs, and opens the\ndoor to scalable and resource-efficient solutions for reasoning-intensive\napplications.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-23T14:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.16767v1","title":"Online model learning with data-assimilated reservoir computers","summary":"We propose an online learning framework for forecasting nonlinear\nspatio-temporal signals (fields). The method integrates (i) dimensionality\nreduction, here, a simple proper orthogonal decomposition (POD) projection;\n(ii) a generalized autoregressive model to forecast reduced dynamics, here, a\nreservoir computer; (iii) online adaptation to update the reservoir computer\n(the model), here, ensemble sequential data assimilation.We demonstrate the\nframework on a wake past a cylinder governed by the Navier-Stokes equations,\nexploring the assimilation of full flow fields (projected onto POD modes) and\nsparse sensors. Three scenarios are examined: a na\\\"ive physical state\nestimation; a two-fold estimation of physical and reservoir states; and a\nthree-fold estimation that also adjusts the model parameters. The two-fold\nstrategy significantly improves ensemble convergence and reduces reconstruction\nerror compared to the na\\\"ive approach. The three-fold approach enables robust\nonline training of partially-trained reservoir computers, overcoming\nlimitations of a priori training. By unifying data-driven reduced order\nmodelling with Bayesian data assimilation, this work opens new opportunities\nfor scalable online model learning for nonlinear time series forecasting.","main_category":"cs.LG","categories":"cs.LG,physics.flu-dyn,stat.AP","published":"2025-04-23T14:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.16769v1","title":"Deep photonic reservoir computer for nonlinear equalization of 16-level\n  quadrature amplitude modulation signals","summary":"Photonic reservoir computer (PRC) is a kind of real-time and adaptive\nrecurrent neural network, where only weights in the readout layer require\ntraining. PRC is a promising tool to deal with the crucial issue of nonlinear\nequalization in optical fiber communications. Here we theoretically show a deep\nPRC for the nonlinear equalization of coherent signals with the format of 16-\nlevel quadrature amplitude modulation (16-QAM). The deep PRC consists of\ncascading injection-locked Fabry-Perot lasers with optical feedback. Both the\nin-phase component and the quadrature component of the 16-QAM signals are\nsimultaneously injected into the deep PRC in parallel, based on the wavelength\nmultiplexing of Fabry-Perot lasers. It is demonstrated that the deep PRC\nexhibits strong capability for the nonlinearity compensation of coherent\nsignals. The Q factor is improved by more than 1 dB for 16-QAM signals with\nlaunch powers above 10 dBm, associated with a bit rate of 240 Gbps and a\ntransmission distance of 50 km.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-23T14:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.16774v1","title":"Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors\n  and Cross-Model Attention Mechanism","summary":"The examination of chest X-ray images is a crucial component in detecting\nvarious thoracic illnesses. This study introduces a new image description\ngeneration model that integrates a Vision Transformer (ViT) encoder with\ncross-modal attention and a GPT-4-based transformer decoder. The ViT captures\nhigh-quality visual features from chest X-rays, which are fused with text data\nthrough cross-modal attention to improve the accuracy, context, and richness of\nimage descriptions. The GPT-4 decoder transforms these fused features into\naccurate and relevant captions. The model was tested on the National Institutes\nof Health (NIH) and Indiana University (IU) Chest X-ray datasets. On the IU\ndataset, it achieved scores of 0.854 (B-1), 0.883 (CIDEr), 0.759 (METEOR), and\n0.712 (ROUGE-L). On the NIH dataset, it achieved the best performance on all\nmetrics: BLEU 1--4 (0.825, 0.788, 0.765, 0.752), CIDEr (0.857), METEOR (0.726),\nand ROUGE-L (0.705). This framework has the potential to enhance chest X-ray\nevaluation, assisting radiologists in more precise and efficient diagnosis.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-23T14:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.16777v1","title":"Systemic Flakiness: An Empirical Analysis of Co-Occurring Flaky Test\n  Failures","summary":"Flaky tests produce inconsistent outcomes without code changes, creating\nmajor challenges for software developers. An industrial case study reported\nthat developers spend 1.28% of their time repairing flaky tests at a monthly\ncost of $2,250. We discovered that flaky tests often exist in clusters, with\nco-occurring failures that share the same root causes, which we call systemic\nflakiness. This suggests that developers can reduce repair costs by addressing\nshared root causes, enabling them to fix multiple flaky tests at once rather\nthan tackling them individually. This study represents an inflection point by\nchallenging the deep-seated assumption that flaky test failures are isolated\noccurrences. We used an established dataset of 10,000 test suite runs from 24\nJava projects on GitHub, spanning domains from data orchestration to job\nscheduling. It contains 810 flaky tests, which we levered to perform a\nmixed-method empirical analysis of co-occurring flaky test failures. Systemic\nflakiness is significant and widespread. We performed agglomerative clustering\nof flaky tests based on their failure co-occurrence, finding that 75% of flaky\ntests across all projects belong to a cluster, with a mean cluster size of 13.5\nflaky tests. Instead of requiring 10,000 test suite runs to identify systemic\nflakiness, we demonstrated a lightweight alternative by training machine\nlearning models based on static test case distance measures. Through manual\ninspection of stack traces, conducted independently by four authors and\nresolved through negotiated agreement, we identified intermittent networking\nissues and instabilities in external dependencies as the predominant causes of\nsystemic flakiness.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.16779v1","title":"Evaluating the Impact of a Yoga-Based Intervention on Software\n  Engineers' Well-Being","summary":"Software engineering tasks are high-stress and cognitively demanding.\nAdditionally, there is a latent risk of software engineers presenting burnout,\ndepression and anxiety. Established interventions in other fields centred\naround attention awareness have shown positive results in mental well-being.\n  We aim to test how effective a yoga intervention is in improving general\nwell-being in the workplace. For that, we designed, implemented and evaluated\nan eight-week yoga programme in a software development company. We used a\nmixed-methods data collection, using a survey of six psychometric scales, pre\nand post-intervention, and a weekly well-being scale during the programme. For\nmethod triangulation, we conducted a focus group with the organisers to obtain\nqualitative data. The quantitative results did not show any statistically\nsignificant improvement after the intervention. Meanwhile, the qualitative\nresults illustrated that participants felt better and liked the intervention.\n  We conclude that yoga has a positive impact, which, however, can easily get\noverlaid by contextual factors, especially with only a once-per-week\nintervention.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:54:09Z"}
{"aid":"http://arxiv.org/abs/2504.16789v1","title":"MLOps Monitoring at Scale for Digital Platforms","summary":"Machine learning models are widely recognized for their strong performance in\nforecasting. To keep that performance in streaming data settings, they have to\nbe monitored and frequently re-trained. This can be done with machine learning\noperations (MLOps) techniques under supervision of an MLOps engineer. However,\nin digital platform settings where the number of data streams is typically\nlarge and unstable, standard monitoring becomes either suboptimal or too labor\nintensive for the MLOps engineer. As a consequence, companies often fall back\non very simple worse performing ML models without monitoring. We solve this\nproblem by adopting a design science approach and introducing a new monitoring\nframework, the Machine Learning Monitoring Agent (MLMA), that is designed to\nwork at scale for any ML model with reasonable labor cost. A key feature of our\nframework concerns test-based automated re-training based on a data-adaptive\nreference loss batch. The MLOps engineer is kept in the loop via key metrics\nand also acts, pro-actively or retrospectively, to maintain performance of the\nML model in the production stage. We conduct a large-scale test at a last-mile\ndelivery platform to empirically validate our monitoring framework.","main_category":"econ.EM","categories":"econ.EM,stat.AP","published":"2025-04-23T15:04:38Z"}
{"aid":"http://arxiv.org/abs/2504.16825v1","title":"Symbiotic stars in the era of modern ground- and space-based surveys","summary":"Symbiotic stars, interacting binaries composed of a cool giant and a hot\ncompact companion, exhibit complex variability across the electromagnetic\nspectrum. Over the past decades, large-scale photometric and spectroscopic\nsurveys from ground- and space-based observatories have significantly advanced\ntheir discovery and characterization. These datasets have transformed the\nsearch for new symbiotic candidates, providing extensive time-domain\ninformation crucial for their classification and analysis. This review\nhighlights recent observational results that have expanded the known population\nof symbiotic stars, refined classification criteria, and enhanced our\nunderstanding of their variability. Despite these advances, fundamental\nquestions remain regarding their long-term evolution, mass transfer and\naccretion processes, or their potential role as progenitors of Type Ia\nsupernovae. With ongoing and upcoming surveys, the coming years promise new\ndiscoveries and a more comprehensive picture of these intriguing interacting\nsystems.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.16865v1","title":"General method for solving nonlinear optical scattering problems using\n  fix point iterations","summary":"In this paper we introduce a new fix point iteration scheme for solving\nnonlinear electromagnetic scattering problems. The method is based on a\nspectral formulation of Maxwell's equations called the Bidirectional Pulse\nPropagation Equations. The scheme can be applied to a wide array of slab-like\ngeometries, and for arbitrary material responses. We derive the scheme and\ninvestigated how it performs with respect to convergence and accuracy by\napplying it to the case of light scattering from a simple slab whose nonlinear\nmaterial response is a sum a very fast electronic vibrational response, and a\nmuch slower molecular vibrational response.","main_category":"physics.class-ph","categories":"physics.class-ph,physics.comp-ph","published":"2025-04-23T16:38:49Z"}
{"aid":"http://arxiv.org/abs/2504.16873v1","title":"A LOFAR-style reconstruction of cosmic-ray air showers with SKA-Low","summary":"Cosmic-ray air shower detection with the low-frequency part of the Square\nKilometre Array (SKA) radio telescope is envisioned to yield very high\nprecision measurements of the particle composition of cosmic rays between\n$10^{16}$ and $10^{18}$ eV. This is made possible by the extreme antenna\ndensity of the core of SKA-Low, surpassing the current most dense radio air\nshower observatory LOFAR by over an order of magnitude. In order to make these\nmeasurements, the technical implementation of this observation mode and the\ndevelopment of reconstruction methods have to happen hand-in-hand. As a first\nlower limit of what is obtainable, we apply the current most precise\nreconstruction methods as used at LOFAR to a first complete simulation of air\nshower signals for the SKA-Low array. We describe this simulation setup and\ndiscuss the obtainable accuracy and resolution. A special focus is put on\neffects of the dynamic range of the system, beamforming methods to lower the\nenergy threshold, as well as the limits to the mass composition accuracy given\nby statistical and systematic uncertainties.","main_category":"astro-ph.HE","categories":"astro-ph.HE,hep-ex","published":"2025-04-23T16:47:18Z"}
{"aid":"http://arxiv.org/abs/2504.16882v1","title":"Fractional $Q$-curvature on the sphere and optimal partitions","summary":"We study an optimal partition problem on the sphere, where the cost\nfunctional is associated with the fractional $Q$-curvature in terms of the\nconformal fractional Laplacian on the sphere. By leveraging symmetries, we\nprove the existence of a symmetric minimal partition through a variational\napproach. A key ingredient in our analysis is a new H\\\"older regularity result\nfor symmetric functions in a fractional Sobolev space on the sphere. As a\nbyproduct, we establish the existence of infinitely many solutions to a\nnonlocal weakly-coupled competitive system on the sphere that remain invariant\nunder a group of conformal diffeomorphisms and we investigate the asymptotic\nbehavior of least-energy solutions as the coupling parameters approach negative\ninfinity.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-23T16:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.16883v1","title":"Enhancing Critical Thinking with AI: A Tailored Warning System for RAG\n  Models","summary":"Retrieval-Augmented Generation (RAG) systems offer a powerful approach to\nenhancing large language model (LLM) outputs by incorporating fact-checked,\ncontextually relevant information. However, fairness and reliability concerns\npersist, as hallucinations can emerge at both the retrieval and generation\nstages, affecting users' reasoning and decision-making. Our research explores\nhow tailored warning messages -- whose content depends on the specific context\nof hallucination -- shape user reasoning and actions in an educational quiz\nsetting. Preliminary findings suggest that while warnings improve accuracy and\nawareness of high-level hallucinations, they may also introduce cognitive\nfriction, leading to confusion and diminished trust in the system. By examining\nthese interactions, this work contributes to the broader goal of AI-augmented\nreasoning: developing systems that actively support human reflection, critical\nthinking, and informed decision-making rather than passive information\nconsumption.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T17:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.16895v1","title":"Exact analytic solutions in 2+1 Hořava gravity with cosmological\n  constant","summary":"We investigate the static solutions with rotational symmetry in the\nnonprojectable Ho\\v{r}ava theory in 2+1 dimensions. We consider all\ninequivalent terms of the effective theory, including the cosmological\nconstant. We find two distinct types of solutions: the first one corresponds to\na Lifshitz solution, while the second one is obtained through a coordinate\ntransformation of the equations of motion. This exact solution does not exhibit\nLifshitz behavior and features a naked singularity.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T17:24:53Z"}
{"aid":"http://arxiv.org/abs/2504.16913v1","title":"Tracing Thought: Using Chain-of-Thought Reasoning to Identify the LLM\n  Behind AI-Generated Text","summary":"In recent years, the detection of AI-generated text has become a critical\narea of research due to concerns about academic integrity, misinformation, and\nethical AI deployment. This paper presents COT Fine-tuned, a novel framework\nfor detecting AI-generated text and identifying the specific language model.\nresponsible for generating the text. We propose a dual-task approach, where\nTask A involves classifying text as AI-generated or human-written, and Task B\nidentifies the specific LLM behind the text. The key innovation of our method\nlies in the use of Chain-of-Thought reasoning, which enables the model to\ngenerate explanations for its predictions, enhancing transparency and\ninterpretability. Our experiments demonstrate that COT Fine-tuned achieves high\naccuracy in both tasks, with strong performance in LLM identification and\nhuman-AI classification. We also show that the CoT reasoning process\ncontributes significantly to the models effectiveness and interpretability.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T17:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.16918v1","title":"OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents","summary":"Optimization plays a vital role in scientific research and practical\napplications, but formulating a concrete optimization problem described in\nnatural language into a mathematical form and selecting a suitable solver to\nsolve the problem requires substantial domain expertise. We introduce\n\\textbf{OptimAI}, a framework for solving \\underline{Optim}ization problems\ndescribed in natural language by leveraging LLM-powered \\underline{AI} agents,\nachieving superior performance over current state-of-the-art methods. Our\nframework is built upon four key roles: (1) a \\emph{formulator} that translates\nnatural language problem descriptions into precise mathematical formulations;\n(2) a \\emph{planner} that constructs a high-level solution strategy prior to\nexecution; and (3) a \\emph{coder} and a \\emph{code critic} capable of\ninteracting with the environment and reflecting on outcomes to refine future\nactions. Ablation studies confirm that all roles are essential; removing the\nplanner or code critic results in $5.8\\times$ and $3.1\\times$ drops in\nproductivity, respectively. Furthermore, we introduce UCB-based debug\nscheduling to dynamically switch between alternative plans, yielding an\nadditional $3.3\\times$ productivity gain. Our design emphasizes multi-agent\ncollaboration, allowing us to conveniently explore the synergistic effect of\ncombining diverse models within a unified system. Our approach attains 88.1\\%\naccuracy on the NLP4LP dataset and 71.2\\% on the Optibench (non-linear w/o\ntable) subset, reducing error rates by 58\\% and 50\\% respectively over prior\nbest results.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T17:45:05Z"}
{"aid":"http://arxiv.org/abs/2504.16920v1","title":"Summary statistics of learning link changing neural representations to\n  behavior","summary":"How can we make sense of large-scale recordings of neural activity across\nlearning? Theories of neural network learning with their origins in statistical\nphysics offer a potential answer: for a given task, there are often a small set\nof summary statistics that are sufficient to predict performance as the network\nlearns. Here, we review recent advances in how summary statistics can be used\nto build theoretical understanding of neural network learning. We then argue\nfor how this perspective can inform the analysis of neural data, enabling\nbetter understanding of learning in biological and artificial neural networks.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-23T17:45:42Z"}
{"aid":"http://arxiv.org/abs/2504.16923v1","title":"Meta-Learning Online Dynamics Model Adaptation in Off-Road Autonomous\n  Driving","summary":"High-speed off-road autonomous driving presents unique challenges due to\ncomplex, evolving terrain characteristics and the difficulty of accurately\nmodeling terrain-vehicle interactions. While dynamics models used in\nmodel-based control can be learned from real-world data, they often struggle to\ngeneralize to unseen terrain, making real-time adaptation essential. We propose\na novel framework that combines a Kalman filter-based online adaptation scheme\nwith meta-learned parameters to address these challenges. Offline meta-learning\noptimizes the basis functions along which adaptation occurs, as well as the\nadaptation parameters, while online adaptation dynamically adjusts the onboard\ndynamics model in real time for model-based control. We validate our approach\nthrough extensive experiments, including real-world testing on a full-scale\nautonomous off-road vehicle, demonstrating that our method outperforms baseline\napproaches in prediction accuracy, performance, and safety metrics,\nparticularly in safety-critical scenarios. Our results underscore the\neffectiveness of meta-learned dynamics model adaptation, advancing the\ndevelopment of reliable autonomous systems capable of navigating diverse and\nunseen environments. Video is available at: https://youtu.be/cCKHHrDRQEA","main_category":"cs.RO","categories":"cs.RO,cs.LG,cs.SY,eess.SY","published":"2025-04-23T17:51:36Z"}
{"aid":"http://arxiv.org/abs/2504.17263v1","title":"Precision Neural Network Quantization via Learnable Adaptive Modules","summary":"Quantization Aware Training (QAT) is a neural network quantization technique\nthat compresses model size and improves operational efficiency while\neffectively maintaining model performance. The paradigm of QAT is to introduce\nfake quantization operators during the training process, allowing the model to\nautonomously compensate for information loss caused by quantization. Making\nquantization parameters trainable can significantly improve the performance of\nQAT, but at the cost of compromising the flexibility during inference,\nespecially when dealing with activation values with substantially different\ndistributions. In this paper, we propose an effective learnable adaptive neural\nnetwork quantization method, called Adaptive Step Size Quantization (ASQ), to\nresolve this conflict. Specifically, the proposed ASQ method first dynamically\nadjusts quantization scaling factors through a trained module capable of\naccommodating different activations. Then, to address the rigid resolution\nissue inherent in Power of Two (POT) quantization, we propose an efficient\nnon-uniform quantization scheme. We utilize the Power Of Square root of Two\n(POST) as the basis for exponential quantization, effectively handling the\nbell-shaped distribution of neural network weights across various bit-widths\nwhile maintaining computational efficiency through a Look-Up Table method\n(LUT). Extensive experimental results demonstrate that the proposed ASQ method\nis superior to the state-of-the-art QAT approaches. Notably that the ASQ is\neven competitive compared to full precision baselines, with its 4-bit quantized\nResNet34 model improving accuracy by 1.2\\% on ImageNet.","main_category":"cs.CV","categories":"cs.CV,cs.CC","published":"2025-04-24T05:46:25Z"}
{"aid":"http://arxiv.org/abs/2504.17287v1","title":"Combining Static and Dynamic Approaches for Mining and Testing\n  Constraints for RESTful API Testing","summary":"In API testing, deriving logical constraints on API response bodies is\ncrucial in generating the test cases to cover various aspects of RESTful APIs.\nHowever, existing approaches are limited to dynamic analysis in which\nconstraints are extracted from the execution of APIs as part of the system\nunder test. The key limitation of such a dynamic approach is its\nunder-estimation in which inputs in API executions are not sufficiently diverse\nto uncover actual constraints on API response bodies. In this paper, we propose\nto combine a novel static analysis approach (in which the constraints for API\nresponse bodies are mined from API specifications), with the dynamic approach\n(which relies on API execution data). We leverage large language models (LLMs)\nto comprehend the API specifications, mine constraints for response bodies, and\ngenerate test cases. To reduce LLMs' hallucination, we apply an\nObservation-Confirmation (OC) scheme which uses initial prompts to\ncontextualize constraints. %, allowing subsequent prompts to more accurately\nconfirm their presence. Our empirical results show that~LLMs with OC prompting\nachieve high precision in constraint mining with the average of 91.2%. When\ncombining static and dynamic analysis, our tool, RBCTest , achieves a precision\nof 78.5%. RBCTest detects 107 constraints that the dynamic approach misses and\n46 more precise constraints. We also use its generated test cases to detect 21\nmismatches between the API specification and actual response data for 8\nreal-world APIs. Four of the mismatches were, in fact, reported in developers'\nforums.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-24T06:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.17291v1","title":"Top on a smooth plane","summary":"We investigate the dynamics of a sliding top that is a rigid body with an\nideal sharp tip moving in a perfectly smooth horizontal plane, so no friction\nforces act on the body. We prove that this system is integrable only in two\ncases analogous to the Euler and Lagrange cases of the classical top problem.\nThe cases with the constant gravity field with acceleration $g\\neq0$ and\nwithout external field $g=0$ are considered. The non-integrability proof for\n$g\\neq0$ based on the fact that the equations of motion for the sliding top are\na perturbation of the classical top equations of motion. We show that the\nintegrability of the classical top is a necessary condition for the\nintegrability of the sliding top. Among four integrable classical top cases the\ncorresponding two cases for the sliding top are also integrable, and for the\ntwo remaining cases, we prove their non-integrability by analyzing the\ndifferential Galois group of variational equations along a certain particular\nsolution. In the absence of constant gravitational field $g=0$ the\nintegrability is much more difficult. At first, we proved that if the sliding\ntop problem is integrable, then the body is symmetric. In the proof, we applied\none of the Ziglin theorem concerning the splitting of separatrices phenomenon.\nThen we prove the non-integrability of the symmetric sliding top using\ndifferential Galois group of variational equations except two the same as for\n$g\\neq0$ cases. The integrability of these cases is also preserved when we add\nto equations of motion a gyrostatic term.","main_category":"nlin.CD","categories":"nlin.CD,nlin.SI","published":"2025-04-24T06:36:16Z"}
{"aid":"http://arxiv.org/abs/2504.17326v1","title":"Quantum Corner VOA and the Super Macdonald Polynomials","summary":"In this paper, we establish a relation between the quantum corner VOA\n$q\\widetilde{Y}_{L,0,N}[\\Psi]$, which can be regarded as a generalization of\nquantum $W_N$ algebra, and Sergeev-Veselov super Macdonald polynomials. We\ndemonstrate precisely that, under a specific map, the correlation functions of\nthe currents of $q\\widetilde{Y}_{L,0,N}[\\Psi]$, coincide with the\nSergeev-Veselov super Macdonald polynomials.","main_category":"hep-th","categories":"hep-th,math-ph,math.CO,math.MP,math.QA,math.RT","published":"2025-04-24T07:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.17348v1","title":"On the length of generating sets with conditions on minimal polynomial","summary":"Linear upper bounds may be derived by imposing specific structural conditions\non a generating set, such as additional constraints on ranks, eigenvalues, or\nthe degree of the minimal polynomial of the generating matrices. This paper\nestablishes a linear upper bound of \\(3n-5\\) for generating sets that contain a\nmatrix whose minimal polynomial has a degree exceeding \\(\\frac{n}{2}\\), where\n\\(n\\) denotes the order of the matrix. Compared to the bound provided in\n\\cite[Theorem 3.1]{r2}, this result reduces the constraints on the Jordan\ncanonical forms. Additionally, it is demonstrated that the bound\n\\(\\frac{7n}{2}-4\\) holds when the generating set contains a matrix with a\nminimal polynomial of degree \\(t\\) satisfying \\(2t\\le n\\le 3t-1\\). The primary\nenhancements consist of quantitative bounds and reduced reliance on Jordan form\nstructural constraints.","main_category":"math.RA","categories":"math.RA","published":"2025-04-24T08:09:32Z"}
{"aid":"http://arxiv.org/abs/2504.17351v1","title":"A hypercomplex method for solving piecewise continuous biharmonic\n  problem in domains with corner points","summary":"A piecewise continuous biharmonic problem in domains with corner points and a\ncorresponding Schwarz type boundary value problem for monogenic functions in a\ncommutative biharmonic algebra are considered. A method for reducing the\nproblems to a system of integral equations is developed.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T08:13:17Z"}
{"aid":"http://arxiv.org/abs/2504.17355v1","title":"Collaborative Multi-Agent Reinforcement Learning for Automated Feature\n  Transformation with Graph-Driven Path Optimization","summary":"Feature transformation methods aim to find an optimal mathematical\nfeature-feature crossing process that generates high-value features and\nimproves the performance of downstream machine learning tasks. Existing\nframeworks, though designed to mitigate manual costs, often treat feature\ntransformations as isolated operations, ignoring dynamic dependencies between\ntransformation steps. To address the limitations, we propose TCTO, a\ncollaborative multi-agent reinforcement learning framework that automates\nfeature engineering through graph-driven path optimization. The framework's\ncore innovation lies in an evolving interaction graph that models features as\nnodes and transformations as edges. Through graph pruning and backtracking, it\ndynamically eliminates low-impact edges, reduces redundant operations, and\nenhances exploration stability. This graph also provides full traceability to\nempower TCTO to reuse high-utility subgraphs from historical transformations.\nTo demonstrate the efficacy and adaptability of our approach, we conduct\ncomprehensive experiments and case studies, which show superior performance\nacross a range of datasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T08:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.17369v1","title":"Complexity one varieties are cluster type","summary":"The complexity of a pair $(X,B)$ is an invariant that relates the dimension\nof $X$, the rank of the group of divisors, and the coefficients of $B$. If the\ncomplexity is less than one, then $X$ is a toric variety. We prove that if the\ncomplexity is less than two, then $X$ is a Fano type variety. Furthermore, if\nthe complexity is less than 3/2, then $X$ admits a Calabi--Yau structure\n$(X,B)$ of complexity one and index at most two, and it admits a finite cover\n$Y \\to X$ of degree at most 2, where $Y$ is a cluster type variety. In\nparticular, if the complexity is one and the index is one, $(X,B)$ is cluster\ntype. Finally, we establish a connection with the theory of\n$\\mathbb{T}$-varieties. We prove that a variety of $\\mathbb{T}$-complexity one\nadmits a similar finite cover from a cluster type variety.","main_category":"math.AG","categories":"math.AG","published":"2025-04-24T08:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.17387v1","title":"Graph covers and semi-covers: Who is stronger?","summary":"The notion of graph cover, also known as locally bijective homomorphism, is a\ndiscretization of covering spaces known from general topology. It is a pair of\nincidence-preserving vertex- and edge-mappings between two graphs, the\nedge-component being bijective on the edge-neighborhoods of every vertex and\nits image. In line with the current trends in topological graph theory and its\napplications in mathematical physics, graphs are considered in the most relaxed\nform and as such they may contain multiple edges, loops and semi-edges.\n  Nevertheless, simple graphs (binary structures without multiple edges, loops,\nor semi-edges) play an important role. It has been conjectured in [Bok et al.:\nList covering of regular multigraphs, Proceedings IWOCA 2022, LNCS 13270, pp.\n228--242] that for every fixed graph $H$, deciding if a graph covers $H$ is\neither polynomial time solvable for arbitrary input graphs, or NP-complete for\nsimple ones. A graph $A$ is called stronger than a graph $B$ if every simple\ngraph that covers $A$ also covers $B$. This notion was defined and found useful\nfor NP-hardness reductions for disconnected graphs in [Bok et al.:\nComputational complexity of covering disconnected multigraphs, Proceedings FCT\n2022, LNCS 12867, pp. 85--99]. It was conjectured in [Kratochv\\'{\\i}l: Towards\nstrong dichotomy of graphs covers, GROW 2022 - Book of open problems, p. 10,\n{\\tt https://grow.famnit.upr.si/GROW-BOP.pdf}] that if $A$ has no semi-edges,\nthen $A$ is stronger than $B$ if and only if $A$ covers $B$. We prove this\nconjecture for cubic one-vertex graphs, and we also justify it for all cubic\ngraphs $A$ with at most 4 vertices.","main_category":"math.CO","categories":"math.CO,G.2.2","published":"2025-04-24T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.17391v1","title":"Mach-Zehnder atom interferometry with non-interacting trapped Bose\n  Einstein condensates","summary":"The coherent manipulation of a quantum wave is at the core of quantum\nsensing. For instance, atom interferometers require linear splitting and\nrecombination processes to map the accumulated phase shift into a measurable\npopulation signal. Although Bose Einstein condensates (BECs) are the archetype\nof coherent matter waves, their manipulation between trapped spatial modes has\nbeen limited by the strong interparticle collisions. Here, we overcome this\nproblem by using BECs with tunable interaction trapped in an innovative array\nof double-well potentials and exploiting quantum tunneling to realize linear\nbeam splitting. We operate several Mach-Zehnder interferometers in parallel,\ncanceling common-mode potential instabilities by a differential analysis, thus\ndemonstrating a trapped-atom gradiometer. Furthermore, by applying a spin-echo\nprotocol, we suppress additional decoherence sources and approach unprecedented\ncoherence times of one second. Our interferometer will find applications in\nprecision measurements of forces with a high spatial resolution and in linear\nmanipulation of quantum entangled states for sensing with sub shot-noise\nsensitivity.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,physics.atom-ph","published":"2025-04-24T09:18:01Z"}
{"aid":"http://arxiv.org/abs/2504.17410v1","title":"Bias-Eliminated PnP for Stereo Visual Odometry: Provably Consistent and\n  Large-Scale Localization","summary":"In this paper, we first present a bias-eliminated weighted (Bias-Eli-W)\nperspective-n-point (PnP) estimator for stereo visual odometry (VO) with\nprovable consistency. Specifically, leveraging statistical theory, we develop\nan asymptotically unbiased and $\\sqrt {n}$-consistent PnP estimator that\naccounts for varying 3D triangulation uncertainties, ensuring that the relative\npose estimate converges to the ground truth as the number of features\nincreases. Next, on the stereo VO pipeline side, we propose a framework that\ncontinuously triangulates contemporary features for tracking new frames,\neffectively decoupling temporal dependencies between pose and 3D point errors.\nWe integrate the Bias-Eli-W PnP estimator into the proposed stereo VO pipeline,\ncreating a synergistic effect that enhances the suppression of pose estimation\nerrors. We validate the performance of our method on the KITTI and Oxford\nRobotCar datasets. Experimental results demonstrate that our method: 1)\nachieves significant improvements in both relative pose error and absolute\ntrajectory error in large-scale environments; 2) provides reliable localization\nunder erratic and unpredictable robot motions. The successful implementation of\nthe Bias-Eli-W PnP in stereo VO indicates the importance of information\nscreening in robotic estimation tasks with high-uncertainty measurements,\nshedding light on diverse applications where PnP is a key ingredient.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-24T10:03:47Z"}
{"aid":"http://arxiv.org/abs/2504.17413v1","title":"Boundary observation and control for fractional heat and wave equations","summary":"We establish boundary observability and control for the fractional heat\nequation over arbitrary time horizons $T > 0$, within the optimal range of\nfractional exponents $s \\in (1/2, 1)$. Our approach introduces a novel\nsynthesis of techniques from fractional partial differential equations and\ncontrol theory, combining several key ingredients in an original and effective\nmanner:\n  1. Boundary observability for low-frequency solutions of the fractional wave\nequation. We begin by analyzing the associated fractional wave equation. Using\na fractional analogue of Pohozaev's identity, we establish a partial boundary\nobservability result for the low-frequency solutions. The corresponding\nobservability time horizon increases with the eigenmode frequency, reflecting\nthe inherently slower propagation speed of the fractional waves.\n  2. Transmutation to the parabolic setting. Using transmutation techniques, we\ntransfer the observability results from the wave setting to the parabolic one.\nThis yields a frequency-dependent observability inequality for the fractional\nheat equation, which - via duality - enables control of its low-frequency\ncomponents.\n  3. Frequency-wise iteration. Leveraging the dissipative nature of the\nfractional heat equation, we develop an iterative procedure to successively\ncontrol the entire frequency spectrum of solutions. The condition $s \\in (1/2,\n1)$ is crucial in this analysis, as it guarantees sufficient decay of\nhigh-frequency components, enabling the convergence of the iteration.\n  4. Duality. By a duality argument, we derive boundary observability from the\nboundary controllability of the fractional heat equation. Remarkably, this type\nof boundary observability result is entirely new in the multi-dimensional\nsetting and appears to be out of reach for existing methods. \\end{itemize}","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T10:11:56Z"}
{"aid":"http://arxiv.org/abs/2504.17419v1","title":"How Do Communities of ML-Enabled Systems Smell? A Cross-Sectional Study\n  on the Prevalence of Community Smells","summary":"Effective software development relies on managing both collaboration and\ntechnology, but sociotechnical challenges can harm team dynamics and increase\ntechnical debt. Although teams working on ML enabled systems are\ninterdisciplinary, research has largely focused on technical issues, leaving\ntheir socio-technical dynamics underexplored. This study aims to address this\ngap by examining the prevalence, evolution, and interrelations of community\nsmells, in open-source ML projects. We conducted an empirical study on 188\nrepositories from the NICHE dataset using the CADOCS tool to identify and\nanalyze community smells. Our analysis focused on their prevalence,\ninterrelations, and temporal variations. We found that certain smells, such as\nPrima Donna Effects and Sharing Villainy, are more prevalent and fluctuate over\ntime compared to others like Radio Silence or Organizational Skirmish. These\ninsights might provide valuable support for ML project managers in addressing\nsocio-technical issues and improving team coordination.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-24T10:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.17429v1","title":"Wide-angle Scanning Heterogeneous Element-Based Phased Array Using Novel\n  Scanning Envelope Synthesis Method","summary":"Two novel methods, including the scanning envelope synthesis (SES) method and\nthe active reflection self-cancellation (ARC) method, are proposed to design\nwide-angle scanning heterogeneous element phased arrays. Heterogeneous strategy\nis efficient to extend scanning range but quantitatively characterization of\nthe effect is critically needed to guide design for achieving desired\nperformance. The proposed SES method derives theoretically the relationship\nbetween scanning range and the 3dB-beamwidth of the pattern envelope of one\nphased array, which is linear superposition of active radiation pattern (AEP)\nmagnitude of each element. Therefore, the contribution of each kind of\nheterogeneity can be quantitatively analyzed for further enhancing the scanning\nrange. As we see, a high active reflection coefficient of the phased array can\ndirectly reduce the realized gain. In this way, one ARC method is proposed to\nreduce the active reflection coefficient by counteracting the reflection\ncomponent of active reflection coefficient with its transmission component,\nthereby keeping the realized gain efficiently even when the array scans at\nlarge angels. For verification, one 24.5-29.5GHz 4x4 phased array scanning in\nE-plane is designed and fabricated. Benefiting from the proposed SES method,\nthe scanning range of the prototype is extended up to $\\pm74\\deg$, around\n10{\\deg} improvement over one traditional heterogeneous array. Meanwhile, the\nactive reflection coefficient is reduced from -4dB to lower than -7.5dB by\napplying the ARC method.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-24T10:43:33Z"}
{"aid":"http://arxiv.org/abs/2504.17452v1","title":"The need for statistical physics in Africa: perspective and an\n  illustration in drug delivery problems","summary":"The development of statistical physics in Africa is in its nascent stages,\nyet its application holds immense promise for advancing emerging research\ntrends on the continent. This perspective paper, a product of a two-week\nworkshop on biophysics in Morogoro (Tanzania), aims to illuminate the potential\nof statistical physics in regional scientific research. We employ in-silico\natomistic molecular dynamics simulations to investigate the loading and\ndelivery capabilities of lecithin nanolipids for niclosamide, a poorly\nwater-soluble drug. Our simulations reveal that the loading capacity and\ninteraction strength between lecithin nanolipids and niclosamide improve with\nincreased lecithin concentrations. We perform a free-energy landscape analysis\nwhich uncovers two distinct metastable conformations of niclosamide within both\nthe aqueous phase and the lecithin nanolipids. Over a simulation period of half\na microsecond, lecithin nanolipids self-assemble into a spherical monolayer\nstructure, providing detailed atomic-level insights into their interactions\nwith niclosamide. These findings underscore the potential of lecithin\nnanolipids as efficient drug delivery systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,physics.bio-ph,physics.chem-ph,physics.soc-ph","published":"2025-04-24T11:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.17454v1","title":"Adaptive Orchestration of Modular Generative Information Access Systems","summary":"Advancements in large language models (LLMs) have driven the emergence of\ncomplex new systems to provide access to information, that we will collectively\nrefer to as modular generative information access (GenIA) systems. They\nintegrate a broad and evolving range of specialized components, including LLMs,\nretrieval models, and a heterogeneous set of sources and tools. While\nmodularity offers flexibility, it also raises critical challenges: How can we\nsystematically characterize the space of possible modules and their\ninteractions? How can we automate and optimize interactions among these\nheterogeneous components? And, how do we enable this modular system to\ndynamically adapt to varying user query requirements and evolving module\ncapabilities? In this perspective paper, we argue that the architecture of\nfuture modular generative information access systems will not just assemble\npowerful components, but enable a self-organizing system through real-time\nadaptive orchestration -- where components' interactions are dynamically\nconfigured for each user input, maximizing information relevance while\nminimizing computational overhead. We give provisional answers to the questions\nraised above with a roadmap that depicts the key principles and methods for\ndesigning such an adaptive modular system. We identify pressing challenges, and\npropose avenues for addressing them in the years ahead. This perspective urges\nthe IR community to rethink modular system designs for developing adaptive,\nself-optimizing, and future-ready architectures that evolve alongside their\nrapidly advancing underlying technologies.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T11:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.17473v1","title":"Wolves in the Repository: A Software Engineering Analysis of the XZ\n  Utils Supply Chain Attack","summary":"The digital economy runs on Open Source Software (OSS), with an estimated\n90\\% of modern applications containing open-source components. While this\nwidespread adoption has revolutionized software development, it has also\ncreated critical security vulnerabilities, particularly in essential but\nunder-resourced projects. This paper examines a sophisticated attack on the XZ\nUtils project (CVE-2024-3094), where attackers exploited not just code, but the\nentire open-source development process to inject a backdoor into a fundamental\nLinux compression library. Our analysis reveals a new breed of supply chain\nattack that manipulates software engineering practices themselves -- from\ncommunity management to CI/CD configurations -- to establish legitimacy and\nmaintain long-term control. Through a comprehensive examination of GitHub\nevents and development artifacts, we reconstruct the attack timeline, analyze\nthe evolution of attacker tactics. Our findings demonstrate how attackers\nleveraged seemingly beneficial contributions to project infrastructure and\nmaintenance to bypass traditional security measures. This work extends beyond\ntraditional security analysis by examining how software engineering practices\nthemselves can be weaponized, offering insights for protecting the open-source\necosystem.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-24T12:06:11Z"}
{"aid":"http://arxiv.org/abs/2504.17520v1","title":"Communication-Efficient Personalized Distributed Learning with Data and\n  Node Heterogeneity","summary":"To jointly tackle the challenges of data and node heterogeneity in\ndecentralized learning, we propose a distributed strong lottery ticket\nhypothesis (DSLTH), based on which a communication-efficient personalized\nlearning algorithm is developed. In the proposed method, each local model is\nrepresented as the Hadamard product of global real-valued parameters and a\npersonalized binary mask for pruning. The local model is learned by updating\nand fusing the personalized binary masks while the real-valued parameters are\nfixed among different agents. To further reduce the complexity of hardware\nimplementation, we incorporate a group sparse regularization term in the loss\nfunction, enabling the learned local model to achieve structured sparsity.\nThen, a binary mask aggregation algorithm is designed by introducing an\nintermediate aggregation tensor and adding a personalized fine-tuning step in\neach iteration, which constrains model updates towards the local data\ndistribution. The proposed method effectively leverages the relativity among\nagents while meeting personalized requirements in heterogeneous node\nconditions. We also provide a theoretical proof for the DSLTH, establishing it\nas the foundation of the proposed method. Numerical simulations confirm the\nvalidity of the DSLTH and demonstrate the effectiveness of the proposed\nalgorithm.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.MA","published":"2025-04-24T13:02:54Z"}
{"aid":"http://arxiv.org/abs/2504.17536v1","title":"Dynamic Membership for Regular Tree Languages","summary":"We study the dynamic membership problem for regular tree languages under\nrelabeling updates: we fix an alphabet ${\\Sigma}$ and a regular tree language\n$L$ over ${\\Sigma}$ (expressed, e.g., as a tree automaton), we are given a tree\n$T$ with labels in ${\\Sigma}$, and we must maintain the information of whether\nthe tree $T$ belongs to $L$ while handling relabeling updates that change the\nlabels of individual nodes in $T$. (The shape and size of the tree remain the\nsame throughout.)\n  Our first contribution is to show that this problem admits an $O(\\log n /\n\\log \\log n)$ algorithm for any fixed regular tree language, improving over\nknown algorithms that achieve $O(\\log n)$. This generalizes the known $O(\\log n\n/ \\log \\log n)$ upper bound over words, and it matches the lower bound of\n${\\Omega}(\\log n / \\log \\log n)$ from dynamic membership to some word languages\nand from the existential marked ancestor problem.\n  Our second contribution is to introduce a class of regular languages, dubbed\nalmost-commutative tree languages, and show that dynamic membership to such\nlanguages under relabeling updates can be done in constant time per update.\nAlmost-commutative languages generalize both commutative languages and finite\nlanguages, and they are the analogue for trees of the ZG languages enjoying\nconstant-time dynamic membership over words. Our main technical contribution is\nto show that this class is conditionally optimal when we assume that the\nalphabet features a neutral letter, i.e., a letter that has no effect on\nmembership to the language. More precisely, we show that any regular tree\nlanguage with a neutral letter which is not almost-commutative cannot be\nmaintained in constant time under the assumption that prefix-U1 problem from\n(Amarilli, Jachiet, Paperman, ICALP'21) also does not admit a constant-time\nalgorithm.","main_category":"cs.FL","categories":"cs.FL,cs.DS","published":"2025-04-24T13:26:08Z"}
{"aid":"http://arxiv.org/abs/2504.17549v1","title":"Premature supermassive black hole mergers in cosmological simulations of\n  structure formation","summary":"The co-evolution of massive black holes (BHs) and their host galaxies is\nwell-established within the hierarchical galaxy formation paradigm. Large-scale\ncosmological simulations are an ideal tool to study the repeated BH mergers,\naccretion and feedback that conspire to regulate this process. While such\nsimulations are of fundamental importance for understanding the complex and\nintertwined relationship between BHs and their hosts, they are plagued with\nnumerical inaccuracies at the scale of individual BH orbits. To quantify this\nissue, taking advantage of the $(100 \\, h^{-1}\\,\\text{cMpc})^3$ FABLE\nsimulation box, we track all individual BH mergers and the corresponding host\ngalaxy mergers as a function of cosmic time. We demonstrate that BH mergers\nfrequently occur prematurely, well before the corresponding merger of the host\ngalaxies is complete, and that BHs are sometimes erroneously displaced from\ntheir hosts during close galaxy encounters. Correcting for these artefacts\nresults in substantial macrophysical delays, spanning over several Gyrs, which\nare additional to any microphysical delays arising from unresolved BH binary\nhardening processes. We find that once the macrophysical delays are accounted\nfor, high-mass BH merger events are suppressed, affecting the predictions for\nthe BH population that may be observable with LISA and pulsar timing arrays.\nFurthermore, including these macrophysical delays leads to an increase in the\nnumber of observable dual active galactic nuclei, especially at lower\nredshifts, with respect to FABLE. Our results highlight the pressing need for\nmore accurate modelling of BH dynamics in cosmological simulations of galaxy\nformation as we prepare for the multi-messenger era.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T13:40:06Z"}
{"aid":"http://arxiv.org/abs/2504.17614v1","title":"Bolt: Clothing Virtual Characters at Scale","summary":"Clothing virtual characters is a time-consuming and often manual process.\nOutfits can be composed of multiple garments, and each garment must be fitted\nto the unique shape of a character. Since characters can vary widely in size\nand shape, fitting outfits to many characters is a combinatorially large\nproblem. We present Bolt, a system designed to take outfits originally authored\non a source body and fit them to new body shapes via a three stage transfer,\ndrape, and rig process. First, our new garment transfer method transforms each\ngarment's 3D mesh positions to the new character, then optimizes the garment's\n2D sewing pattern while maintaining key features of the original seams and\nboundaries. Second, our system simulates the transferred garments to\nprogressively drape and untangle each garment in the outfit. Finally, the\ngarments are rigged to the new character. This entire process is automatic,\nmaking it feasible to clothe characters at scale with no human intervention.\nClothed characters are then ready for immediate use in applications such as\ngaming, animation, synthetic generation, and more.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-24T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.17625v1","title":"Non-quadratic solutions to the Monge-Ampère equation","summary":"We construct ample smooth strictly plurisubharmonic non-quadratic solutions\nto the Monge-Amp\\`ere equation on either cylindrical type domains or the whole\ncomplex Euclidean space $\\mathbb C^2$. Among these, the entire solutions\ndefined on $\\mathbb C^2$ induce flat Kahler metrics, as expected by a question\nof Calabi. In contrast, those on cylindrical domains produce a family of\nnowhere flat Kahler metrics. Beyond these smooth solutions, we also classify\nsolutions that are radially symmetric in one variable, which exhibit various\ntypes of singularities. Finally, we explore analogous solutions to Donaldson's\nequation motivated by a result of He.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T14:48:28Z"}
{"aid":"http://arxiv.org/abs/2504.17626v1","title":"Improving Open-World Object Localization by Discovering Background","summary":"Our work addresses the problem of learning to localize objects in an\nopen-world setting, i.e., given the bounding box information of a limited\nnumber of object classes during training, the goal is to localize all objects,\nbelonging to both the training and unseen classes in an image, during\ninference. Towards this end, recent work in this area has focused on improving\nthe characterization of objects either explicitly by proposing new objective\nfunctions (localization quality) or implicitly using object-centric\nauxiliary-information, such as depth information, pixel/region affinity map\netc. In this work, we address this problem by incorporating background\ninformation to guide the learning of the notion of objectness. Specifically, we\npropose a novel framework to discover background regions in an image and train\nan object proposal network to not detect any objects in these regions. We\nformulate the background discovery task as that of identifying image regions\nthat are not discriminative, i.e., those that are redundant and constitute low\ninformation content. We conduct experiments on standard benchmarks to showcase\nthe effectiveness of our proposed approach and observe significant improvements\nover the previous state-of-the-art approaches for this task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T14:48:46Z"}
{"aid":"http://arxiv.org/abs/2504.17648v1","title":"A Robust Fault Detection Filter for Linear Time-Varying System with\n  Non-Gaussian Noise","summary":"This paper addresses the problem of robust fault detection filtering for\nlinear time-varying (LTV) systems with non-Gaussian noise and additive faults.\nThe conventional generalized likelihood ratio (GLR) method utilizes the Kalman\nfilter, which may exhibit inadequate performance under non-Gaussian noise\nconditions. To mitigate this issue, a fault detection method employing the\n$H_{\\infty}$ filter is proposed. The $H_{\\infty}$ filter is first derived as\nthe solution to a regularized least-squares (RLS) optimization problem, and the\neffect of faults on the output prediction error is then analyzed. The proposed\napproach using the $H_{\\infty}$ filter demonstrates robustness in non-Gaussian\nnoise environments and significantly improves fault detection performance\ncompared to the original GLR method that employs the Kalman filter. The\neffectiveness of the proposed approach is illustrated using numerical examples.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T15:18:31Z"}
{"aid":"http://arxiv.org/abs/2504.17649v1","title":"On Josephy-Halley method for generalized equations","summary":"We extend the classical third-order Halley iteration to the setting of\ngeneralized equations of the form \\[ 0 \\in f(x) + F(x), \\] where \\(f\\colon\nX\\longrightarrow Y\\) is twice continuously Fr\\'echet-differentiable on Banach\nspaces and \\(F\\colon X\\tto Y\\) is a set-valued mapping with closed graph.\nBuilding on predictor-corrector framework, our scheme first solves a partially\nlinearized inclusion to produce a predictor \\(u_{k+1}\\), then incorporates\nsecond-order information in a Halley-type corrector step to obtain \\(x_{k+1}\\).\nUnder metric regularity of the linearization at a reference solution and\nH\\\"older continuity of \\(f''\\), we prove that the iterates converge locally\nwith order \\(2+p\\) (cubically when \\(p=1\\)). Moreover, by constructing a\nsuitable scalar majorant function we derive semilocal Kantorovich-type\nconditions guaranteeing well-definedness and R-cubic convergence from an\nexplicit neighbourhood of the initial guess. Numerical experiments-including\none- and two-dimensional test problems confirm the theoretical convergence\nrates and illustrate the efficiency of the Josephy-Halley method compared to\nits Josephy-Newton counterpart.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-24T15:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.17653v1","title":"Towards a comprehensive taxonomy of online abusive language informed by\n  machine leaning","summary":"The proliferation of abusive language in online communications has posed\nsignificant risks to the health and wellbeing of individuals and communities.\nThe growing concern regarding online abuse and its consequences necessitates\nmethods for identifying and mitigating harmful content and facilitating\ncontinuous monitoring, moderation, and early intervention. This paper presents\na taxonomy for distinguishing key characteristics of abusive language within\nonline text. Our approach uses a systematic method for taxonomy development,\nintegrating classification systems of 18 existing multi-label datasets to\ncapture key characteristics relevant to online abusive language classification.\nThe resulting taxonomy is hierarchical and faceted, comprising 5 categories and\n17 dimensions. It classifies various facets of online abuse, including context,\ntarget, intensity, directness, and theme of abuse. This shared understanding\ncan lead to more cohesive efforts, facilitate knowledge exchange, and\naccelerate progress in the field of online abuse detection and mitigation among\nresearchers, policy makers, online platform owners, and other stakeholders.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T15:23:47Z"}
{"aid":"http://arxiv.org/abs/2504.17656v1","title":"polyGen: A Learning Framework for Atomic-level Polymer Structure\n  Generation","summary":"Synthetic polymeric materials underpin fundamental technologies in the\nenergy, electronics, consumer goods, and medical sectors, yet their development\nstill suffers from prolonged design timelines. Although polymer informatics\ntools have supported speedup, polymer simulation protocols continue to face\nsignificant challenges: on-demand generation of realistic 3D atomic structures\nthat respect the conformational diversity of polymer structures. Generative\nalgorithms for 3D structures of inorganic crystals, bio-polymers, and small\nmolecules exist, but have not addressed synthetic polymers. In this work, we\nintroduce polyGen, the first latent diffusion model designed specifically to\ngenerate realistic polymer structures from minimal inputs such as the repeat\nunit chemistry alone, leveraging a molecular encoding that captures polymer\nconnectivity throughout the architecture. Due to a scarce dataset of only 3855\nDFT-optimized polymer structures, we augment our training with DFT-optimized\nmolecular structures, showing improvement in joint learning between similar\nchemical structures. We also establish structure matching criteria to benchmark\nour approach on this novel problem. polyGen effectively generates diverse\nconformations of both linear chains and complex branched structures, though its\nperformance decreases when handling repeat units with a high atom count. Given\nthese initial results, polyGen represents a paradigm shift in atomic-level\nstructure generation for polymer science-the first proof-of-concept for\npredicting realistic atomic-level polymer conformations while accounting for\ntheir intrinsic structural flexibility.","main_category":"cs.CE","categories":"cs.CE,cond-mat.mtrl-sci,cs.LG","published":"2025-04-24T15:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.17688v1","title":"The Hubble Image Similarity Project","summary":"We have created a large database of similarity information between\nsub-regions of Hubble Space Telescope images. These data can be used to assess\nthe accuracy of image search algorithms based on computer vision methods. The\nimages were compared by humans in a citizen science project, where they were\nasked to select similar images from a comparison sample. We utilized the Amazon\nMechanical Turk system to pay our reviewers a fair wage for their work. Nearly\n850,000 comparison measurements have been analyzed to construct a similarity\ndistance matrix between all the pairs of images. We describe the algorithm used\nto extract a robust distance matrix from the (sometimes noisy) user reviews.\nThe results are very impressive: the data capture similarity between images\nbased on morphology, texture, and other details that are sometimes difficult\neven to describe in words (e.g., dusty absorption bands with sharp edges). The\ncollective visual wisdom of our citizen scientists matches the accuracy of the\ntrained eye, with even subtle differences among images faithfully reflected in\nthe distances.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-24T15:58:00Z"}
{"aid":"http://arxiv.org/abs/2504.17694v1","title":"Using mathematical models of heart cells to assess the safety of new\n  pharmaceutical drugs","summary":"Many drugs have been withdrawn from the market worldwide, at a cost of\nbillions of dollars, because of patient fatalities due to them unexpectedly\ndisturbing heart rhythm. Even drugs for ailments as mild as hay fever have been\nwithdrawn due to an unacceptable increase in risk of these heart rhythm\ndisturbances. Consequently, the whole pharmaceutical industry expends a huge\neffort in checking all new drugs for any unwanted side effects on the heart.\nThe predominant root cause has been identified as drug molecules blocking ionic\ncurrent flows in the heart. Block of individual types of ionic currents can now\nbe measured experimentally at an early stage of drug development, and this is\nthe standard screening approach for a number of ion currents in many large\npharmaceutical companies. However, clinical risk is a complex function of the\ndegree of block of many different types of cardiac ion currents, and this is\ndifficult to understand by looking at results of these screens independently.\nBy using ordinary differential equation models for the electrical activity of\nheart cells (electrophysiology models) we can integrate information from\ndifferent types of currents, to predict the effect on whole heart cells and\nsubsequent risk of side effects. The resulting simulations can provide a more\naccurate summary of the risk of a drug earlier in development and hence more\ncheaply than the pre-existing approaches.","main_category":"q-bio.CB","categories":"q-bio.CB,q-bio.SC","published":"2025-04-24T16:03:06Z"}
{"aid":"http://arxiv.org/abs/2504.17699v1","title":"Quadratic Interest Network for Multimodal Click-Through Rate Prediction","summary":"Multimodal click-through rate (CTR) prediction is a key technique in\nindustrial recommender systems. It leverages heterogeneous modalities such as\ntext, images, and behavioral logs to capture high-order feature interactions\nbetween users and items, thereby enhancing the system's understanding of user\ninterests and its ability to predict click behavior. The primary challenge in\nthis field lies in effectively utilizing the rich semantic information from\nmultiple modalities while satisfying the low-latency requirements of online\ninference in real-world applications. To foster progress in this area, the\nMultimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshop\nformulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding:\nthis task aims to explore multimodal information extraction and item\nrepresentation learning methods that enhance recommendation tasks; and (2) Task\n2 of Multimodal CTR Prediction: this task aims to explore what multimodal\nrecommendation model can effectively leverage multimodal embedding features and\nachieve better performance. In this paper, we propose a novel model for Task 2,\nnamed Quadratic Interest Network (QIN) for Multimodal CTR Prediction.\nSpecifically, QIN employs adaptive sparse target attention to extract\nmultimodal user behavior features, and leverages Quadratic Neural Networks to\ncapture high-order feature interactions. As a result, QIN achieved an AUC of\n0.9798 on the leaderboard and ranked second in the competition. The model code,\ntraining logs, hyperparameter configurations, and checkpoints are available at\nhttps://github.com/salmon1802/QIN.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T16:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.17705v1","title":"LUIDA: Large-scale Unified Infrastructure for Digital Assessments based\n  on Commercial Metaverse Platform","summary":"Online experiments using metaverse platforms have gained significant traction\nin Human-Computer Interaction and Virtual Reality (VR) research. However,\ncurrent research workflows are highly fragmented, as researchers must use\nseparate tools for system implementation, participant recruitment, experiment\nexecution, and data collection, reducing consistency and increasing workload.\nWe present LUIDA (Large-scale Unified Infrastructure for Digital Assessments),\na metaverse-based framework that integrates these fragmented processes. LUIDA\nautomatically allocates interconnected virtual environments for parallel\nexperiment execution and provides implementation templates adaptable to various\nVR research domains, requiring minimal metaverse development expertise. Our\nevaluation included two studies using a prototype built on Cluster, the\ncommercial metaverse platform. First, VR researchers using LUIDA to develop and\nrun experiments reported high usability scores (SUS: 73.75) and moderate\nworkload (NASA-TLX: 24.11) for overall usage, with interviews confirming\nstreamlined workflows compared to traditional laboratory experiments. Second,\nwe conducted three replicated experiments with public Cluster users, each\nrecruiting approximately 200 participants within one week. These experiments\nproduced results that closely matched the original studies, validating the\nexperimental integrity of LUIDA across research domains. After technical\nrefinements, we plan to release LUIDA as an open platform, providing a\nstandardized protocol to improve research efficiency and experimental\nreproducibility in VR studies.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-24T16:11:12Z"}
{"aid":"http://arxiv.org/abs/2504.17708v1","title":"Pushing the frontiers of subexponential FPT time for Feedback Vertex Set","summary":"The paper deals with the Feedback Vertex Set problem parameterized by the\nsolution size. Given a graph $G$ and a parameter $k$, one has to decide if\nthere is a set $S$ of at most $k$ vertices such that $G-S$ is acyclic. Assuming\nthe Exponential Time Hypothesis, it is known that FVS cannot be solved in time\n$2^{o(k)}n^{\\mathcal{O}(1)}$ in general graphs. To overcome this, many recent\nresults considered FVS restricted to particular intersection graph classes and\nprovided such $2^{o(k)}n^{\\mathcal{O}(1)}$ algorithms.\n  In this paper we provide generic conditions on a graph class for the\nexistence of an algorithm solving FVS in subexponential FPT time, i.e. time\n$2^{k^\\varepsilon} \\mathop{\\rm poly}(n)$, for some $\\varepsilon<1$, where $n$\ndenotes the number of vertices of the instance and $k$ the parameter. On the\none hand this result unifies algorithms that have been proposed over the years\nfor several graph classes such as planar graphs, map graphs, unit-disk graphs,\npseudo-disk graphs, and string graphs of bounded edge-degree. On the other hand\nit extends the tractability horizon of FVS to new classes that are not amenable\nto previously used techniques, in particular intersection graphs of ``thin''\nobjects like segment graphs or more generally $s$-string graphs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T16:12:52Z"}
{"aid":"http://arxiv.org/abs/2504.17713v1","title":"Target-Date Funds: A State-of-the-Art Review with Policy Applications to\n  Chile's Pension Reform","summary":"This review paper explores the evolution and implementation of target-date\nfunds (TDFs), specifically focusing on their application within the context of\nChile's 2025 pension reform. The introduction of TDFs marks a significant shift\nin Chile's pension system, which has traditionally relied on a multifund\nstructure (essentially a target-risk funds system). We offer a comprehensive\nreview of the theoretical foundations and practical considerations of TDFs,\nhighlighting key challenges and opportunities for Chilean regulators and fund\nmanagers. Notably, we recommend that the glide path design should be dynamic,\nincorporating adjustments based on total accumulated wealth, with particular\nflexibility depending on each investor's risk tolerance. Furthermore, we\npropose that the new benchmark for generational funds should feature a wide\ndeviation band relative to the new benchmark portfolio, which could foster a\nmarket with more investment strategies and better competition among fund\nmanagers, encourage the inclusion of alternative assets, and foster greater\ndiversification. Lastly, we highlight the need for future work to define a\nglide path model that incorporates the theoretical frameworks described,\ntailored to the unique parameters of the Chilean pension system. These\nrecommendations aim to optimize the long-term retirement outcomes for Chilean\nworkers under the new pension structure.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-24T16:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.17725v1","title":"STGen: A Novel Lightweight IoT Testbed for Generating Sensor Traffic for\n  the Experimentation of IoT Protocol and its Application in Hybrid Network","summary":"A Wireless Sensor Network (WSN) is a network that does not rely on a fixed\ninfrastructure and consists of numerous sensors, such as temperature, humidity,\nGPS, and cameras, equipped with onboard processors that manage and monitor the\nenvironment in a specific area. As a result, building a real sensor network\ntestbed for verifying, validating, or experimenting with a newly designed\nprotocol presents considerable challenges in adapting a laboratory scenario due\nto the significant financial and logistical barriers, such as the need for\nspecialized hardware and large-scale deployments. Additionally, WSN suffers\nfrom severe constraints such as restricted power supply, short communication\nrange, limited bandwidth availability, and restricted memory storage.\nAddressing these challenges, this work presents a flexible testbed solution\nnamed STGen that enables researchers to experiment with IoT protocols in a\nhybrid environment that emulates WSN implementations with the physical Internet\nthrough a dedicated physical server named STGen core, which receives sensor\ntraffic and processes it for further actions. The STGen testbed is lightweight\nin memory usage and easy to deploy. Most importantly, STGen supports\nlarge-scale distributed systems, facilitates experimentation with IoT\nprotocols, and enables integration with back-end services for big data\nanalytics and statistical insights. The key feature of STGen is the integration\nof real-world IoT protocols and their applications with WSN. Its modular and\nlightweight design makes STGen efficient and enables it to outperform other\npopular testbeds, such as Gotham and GothX, reducing memory usage by 89\\%.\nWhile GothX takes approximately 26 minutes to establish a large topology with\nfour VM nodes and 498 Docker nodes, STGen requires only 1.645 seconds to\ninitialize the platform with 500 sensor nodes.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-24T16:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.17732v1","title":"DPMambaIR:All-in-One Image Restoration via Degradation-Aware Prompt\n  State Space Model","summary":"All-in-One image restoration aims to address multiple image degradation\nproblems using a single model, significantly reducing training costs and\ndeployment complexity compared to traditional methods that design dedicated\nmodels for each degradation type. Existing approaches typically rely on\nDegradation-specific models or coarse-grained degradation prompts to guide\nimage restoration. However, they lack fine-grained modeling of degradation\ninformation and face limitations in balancing multi-task conflicts. To overcome\nthese limitations, we propose DPMambaIR, a novel All-in-One image restoration\nframework. By integrating a Degradation-Aware Prompt State Space Model (DP-SSM)\nand a High-Frequency Enhancement Block (HEB), DPMambaIR enables fine-grained\nmodeling of complex degradation information and efficient global integration,\nwhile mitigating the loss of high-frequency details caused by task competition.\nSpecifically, the DP-SSM utilizes a pre-trained degradation extractor to\ncapture fine-grained degradation features and dynamically incorporates them\ninto the state space modeling process, enhancing the model's adaptability to\ndiverse degradation types. Concurrently, the HEB supplements high-frequency\ninformation, effectively addressing the loss of critical details, such as edges\nand textures, in multi-task image restoration scenarios. Extensive experiments\non a mixed dataset containing seven degradation types show that DPMambaIR\nachieves the best performance, with 27.69dB and 0.893 in PSNR and SSIM,\nrespectively. These results highlight the potential and superiority of\nDPMambaIR as a unified solution for All-in-One image restoration.","main_category":"cs.CV","categories":"cs.CV,I.4.4","published":"2025-04-24T16:46:32Z"}
{"aid":"http://arxiv.org/abs/2504.17739v1","title":"Interpretable Early Detection of Parkinson's Disease through Speech\n  Analysis","summary":"Parkinson's disease is a progressive neurodegenerative disorder affecting\nmotor and non-motor functions, with speech impairments among its earliest\nsymptoms. Speech impairments offer a valuable diagnostic opportunity, with\nmachine learning advances providing promising tools for timely detection. In\nthis research, we propose a deep learning approach for early Parkinson's\ndisease detection from speech recordings, which also highlights the vocal\nsegments driving predictions to enhance interpretability. This approach seeks\nto associate predictive speech patterns with articulatory features, providing a\nbasis for interpreting underlying neuromuscular impairments. We evaluated our\napproach using the Italian Parkinson's Voice and Speech Database, containing\n831 audio recordings from 65 participants, including both healthy individuals\nand patients. Our approach showed competitive classification performance\ncompared to state-of-the-art methods, while providing enhanced interpretability\nby identifying key speech features influencing predictions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T16:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.17741v1","title":"Multi-messenger standard-siren cosmology for third-generation\n  gravitational-wave detectors: Considering observations of gamma-ray bursts\n  and kilonovae","summary":"In the third-generation (3G) gravitational-wave (GW) detector era, GW\nmulti-messenger observations for binary neutron star merger events can exert\ngreat impacts on exploring the cosmic expansion history. Extending the previous\nwork, we explore the potential of 3G GW standard siren observations in\ncosmological parameter estimation by considering their associated\nelectromagnetic (EM) counterparts, including $\\gamma$-ray burst (GRB)\ncoincidence observations by the Gravitational wave high-energy Electromagnetic\nCounterpart All-sky Monitor and GW-triggered target-of-opportunity observations\nof kilonovae by different optical survey projects. During an assumed 10-year\nobservation, we predict that the number of detectable GW-kilonova events is\n$\\sim 4900$ with redshifts below $\\sim 0.4$ under GW network and Large Synoptic\nSurvey Telescope in the $i$ band, which is three times more than that of GW-GRB\ndetections. For the cosmological analysis, we find that with the inclusion of\nGW-kilonova detections, the constraints on cosmological parameters from GW-EM\ndetections are significantly improved compared to those from GW-GRB detections.\nIn particular, GW-EM detections can tightly constrain the Hubble constant with\na precision ranging from $0.076\\%$ to $0.034\\%$. Moreover, GW multi-messenger\nobservations could effectively break the cosmological parameter degeneracies\ngenerated by the mainstream EM observations, CMB+BAO+SN (CBS). The combination\nof CBS and GW-EM can tightly constrain the equation of state parameters of dark\nenergy $w$ in the $w$CDM model and $w_0$ in the $w_0w_a$CDM model with\nprecisions of $0.72\\%$ and $0.99\\%$, respectively, meeting the standard of\nprecision cosmology. In conclusion, GW multi-messenger observations could play\na crucial role in helping solve the Hubble tension and probing the fundamental\nnature of dark energy.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-24T16:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.17744v1","title":"Nearby open clusters with tidal features: golden sample selection and 3D\n  structure","summary":"Open clusters offer unique opportunities to study stellar dynamics and\nevolution under the influence of their internal gravity, the Milky Way's\ngravitational field, and the interactions with encounters. Using the Gaia DR3\ndata for a catalog of open clusters within 500 parsecs that exhibit tidal\nfeatures reported by the literature, we apply a novel method based on 3D\nprincipal component analysis to select a ``golden sample'' of nearby open\nclusters with minimal line-of-sight distortions. This approach ensures a\nsystematic comparison of 3D and 2D structural parameters for tidally perturbed\nclusters. The selected golden sample includes Blanco 1, Melotte 20, Melotte 22,\nNGC 2632, NGC 7092, NGC 1662, Roslund 6 and Melotte 111. We analyze these\nclusters by fitting both 2D and 3D King Profiles to their stellar density\ndistributions. Our results reveal systematic discrepancies: most of the golden\nsample clusters exhibit larger 3D tidal radii compared to their 2D\ncounterparts, demonstrating that the 2D projection effects bias the measured\ncluster size. Furthermore, the 3D density profiles show stronger deviations\nfrom King profiles at the tidal radii ($\\Delta \\rho_{\\rm 3D} > \\Delta \\rho_{\\rm\n2D}$), highlighting enhanced sensitivity to tidal disturbances. Additionally,\nwe investigate the spatial distribution of cluster members relative to their\nbulk motion in the Galactic plane. We find that some clusters exhibit tidal\nfeatures oriented perpendicular to their direction of motion, which can be\nattributed to the fact that the current surveys only detect the curved inner\nregions of the tidal features. In conclusion, this work offers a golden sample\nof nearby open clusters that are most reliable for 3D structure analysis and\nunderscores the necessity of 3D analysis in characterizing OC morphological\nasymmetries, determining cluster size, and identifying tidal features.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-24T17:02:37Z"}
{"aid":"http://arxiv.org/abs/2504.17780v1","title":"Replay to Remember: Retaining Domain Knowledge in Streaming Language\n  Models","summary":"Continual learning in large language models (LLMs) typically encounters the\ncritical challenge of catastrophic forgetting, where previously acquired\nknowledge deteriorates upon exposure to new data. While techniques like replay\nbuffers and parameter-efficient tuning (e.g., Low-Rank Adaptation or LoRA) have\nbeen proposed, few studies investigate real-time domain adaptation under strict\ncomputational and data-stream constraints. In this paper, we demonstrate a\nlightweight method combining LoRA and a minimal replay mechanism in a realistic\nstreaming setting across three diverse knowledge domains: medical question\nanswering, genetics, and law. Using perplexity, semantic similarity, and\nGPT-based human-like evaluation metrics, we quantify the model's adaptation,\nforgetting, and recovery over time. Our experiments reveal that while\ncatastrophic forgetting naturally occurs, even minimal replay significantly\nstabilizes and partially restores domain-specific knowledge. This study\ncontributes practical insights for deploying adaptable LLMs in\nresource-constrained, real-world scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T17:56:22Z"}
