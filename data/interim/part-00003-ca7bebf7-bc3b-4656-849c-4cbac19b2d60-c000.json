{"aid":"http://arxiv.org/abs/2503.21656v1","title":"Logging the conformal life of Ramanujan's $Ï€$","summary":"In 1914, Ramanujan presented 17 infinite series for $1/\\pi$. We examine the\nphysics origin of these remarkable formulae by connecting them to 2D\nlogarithmic conformal field theories (LCFTs) which arise in various contexts\nsuch as the fractional quantum hall effect, percolation and polymers. In light\nof the LCFT connection, we investigate such infinite series in terms of the\nphysics data, i.e., the operator spectrum and OPE coefficients of the CFT and\nthe conformal block expansion. These considerations lead to novel\napproximations for $1/\\pi$. The rapid convergence of the Ramanujan series\nmotivates us to take advantage of the crossing symmetry of the LCFT correlators\nto find new and efficient representations. To achieve this, we use the\nparametric crossing symmetric dispersion relation which was recently developed\nfor string amplitudes. Quite strikingly, we find remarkable simplifications in\nthe new representations, where, in the Legendre relation, the entire\ncontribution to $1/\\pi$ comes from the logarithmic identity operator, hinting\nat a universal property of LCFTs. Additionally, the dispersive representation\ngives us a new handle on the double-lightcone limit.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-03-27T16:21:08Z"}
{"aid":"http://arxiv.org/abs/2503.21665v1","title":"Non-quasicontinuous Newtonian functions and outer capacities based on\n  Banach function spaces","summary":"We construct various examples of Sobolev-type functions, defined via upper\ngradients in metric spaces, that fail to be quasicontinuous or weakly\nquasicontinuous. This is done with quasi-Banach function lattices $X$ as the\nfunction spaces defining the smoothness of the Sobolev-type functions. These\nresults are in contrast to the case $X=L^p$ with $1\\le p<\\infty$, where all\nSobolev-type functions in $N^p$ are known to be quasicontinuous, provided that\nthe underlying metric space $\\mathcal{P}$ is locally complete. In most of our\nexamples, $\\mathcal{P}$ is a compact subset of $\\mathbf{R}^2$ and $X=L^\\infty$.\nFour particular examples are the damped topologist's sine curve, the von Koch\nsnowflake curve, the Cantor ternary set and the Sierpi\\'nski carpet. We also\ndiscuss several related properties, such as whether the Sobolev capacity is an\nouter capacity, and how these properties are related. A fundamental role in\nthese considerations is played by the lack of the Vitali--Carath\\'eodory\nproperty.","main_category":"math.FA","categories":"math.FA","published":"2025-03-27T16:32:52Z"}
{"aid":"http://arxiv.org/abs/2503.21685v1","title":"Extracting Coupling-Mode Spectral Densities with Two-Dimensional\n  Electronic Spectroscopy","summary":"Methods for reconstructing the spectral density of a vibrational environment\nfrom experimental data can yield key insights into the impact of the\nenvironment on molecular function. Although such experimental methods exist,\nthey generally only access vibrational modes that couple diagonally to the\nelectron system. Here we present a method for extracting the spectral density\nof modes that couple to the transition between electronic states, using\ntwo-dimensional electronic spectroscopy. To demonstrate this, we use a\nprocess-tensor method that can simulate two-dimensional electronic spectroscopy\nmeasurements in a numerically exact way. To explain how the extraction works,\nwe also derive an approximate analytical solution, which illustrates that the\nnon-Markovianity of the environment plays an essential role in the existence of\nthe simulated signal.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.mes-hall,quant-ph","published":"2025-03-27T16:53:56Z"}
{"aid":"http://arxiv.org/abs/2503.21699v1","title":"MAVERIX: Multimodal Audio-Visual Evaluation Reasoning IndeX","summary":"Frontier models have either been language-only or have primarily focused on\nvision and language modalities. Although recent advancements in models with\nvision and audio understanding capabilities have shown substantial progress,\nthe field lacks a standardized evaluation framework for thoroughly assessing\ntheir cross-modality perception performance. We introduce MAVERIX~(Multimodal\nAudio-Visual Evaluation Reasoning IndeX), a novel benchmark with 700 videos and\n2,556 questions explicitly designed to evaluate multimodal models through tasks\nthat necessitate close integration of video and audio information. MAVERIX\nuniquely provides models with audiovisual tasks, closely mimicking the\nmultimodal perceptual experiences available to humans during inference and\ndecision-making processes. To our knowledge, MAVERIX is the first benchmark\naimed explicitly at assessing comprehensive audiovisual integration.\nExperiments with state-of-the-art models, including Gemini 1.5 Pro and o1, show\nperformance approaching human levels (around 70% accuracy), while human experts\nreach near-ceiling performance (95.1%). With standardized evaluation protocols,\na rigorously annotated pipeline, and a public toolkit, MAVERIX establishes a\nchallenging testbed for advancing audiovisual multimodal intelligence.","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.CV","published":"2025-03-27T17:04:33Z"}
{"aid":"http://arxiv.org/abs/2503.21701v1","title":"Machine Learning Assisted Modeling of Amorphous TiO$_2$-Doped GeO$_2$\n  for Advanced LIGO Mirror Coatings","summary":"The mechanical loss angle of amorphous TiO$_2$-doped GeO$_2$ can be lower\nthan 10$^{-4}$, making it a candidate for Laser Interferometer\nGravitational-wave Observatory (LIGO) mirror coatings. Amorphous oxides have\ncomplex atomic structures that are influenced by various factors, including\ndoping concentration, preparation, and thermal history, resulting in different\nmass densities and physical properties. Modeling at atomistic level enables\ncapturing these effects by generating atomic structure models according to\nexperimental conditions. In order to obtain reliable and physical amorphous\nmodels at an affordable cost, we develop classical and machine-learning\npotentials (MLP) to speed up simulations. First-principles calculations are\nused to train and validate MLP as well as validating structure models. To\nbetter reproduce properties such as elastic modulus, radial distribution\nfunction (RDF) and the variations in mass density of doped amorphous oxides,\ndensity functional theory (DFT) calculations are used to optimize the final\nmodels. We find that the mass densities of amorphous systems are correlated\nwith the total void volume. The experimental mass density matches the models\nwith the most symmetric potential energy wells under volume change. The elastic\nresponse of the metal-oxygen network is also studied. The 27\\% TiO$_2$ doped\nGeO$_2$ system shows the least number of large atom-atom distance changes,\nwhile for 44\\% TiO$_2$ doped GeO$_2$, a majority of Ti-O distances are\nsignificantly changed. In response to strains, the metal-oxygen network at low\nmass densities prefers to adjust bond angles, while at high mass densities, the\nadjustment is mainly done by changing atom-atom distance.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-27T17:05:07Z"}
{"aid":"http://arxiv.org/abs/2503.21713v1","title":"Investigating Experiential Effects in Online Chess using a Hierarchical\n  Bayesian Analysis","summary":"The presence or absence of winner-loser effects is a widely discussed\nphenomenon across both sports and psychology research. Investigation of such\neffects is often hampered by the limited availability of data. Online chess has\nexploded in popularity in recent years and provides vast amounts of data which\ncan be used to explore this question. With a hierarchical Bayesian regression\nmodel, we carefully investigate the presence of such experiential effects in\nonline chess. Using a large quantity of online chess data, we see little\nevidence for experiential effects that are consistent across all players, with\nsome individual players showing some evidence for such effects. Given the\nchallenging temporal nature of this data, we discuss several methods for\nassessing the suitability of our model and carefully check its validity.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-27T17:24:48Z"}
{"aid":"http://arxiv.org/abs/2503.21716v1","title":"Dynamics of Star Cluster Formation: The Effects of Ongoing Star\n  Formation and Stellar Feedback","summary":"We perform a high resolution zoom-in simulation of star cluster assembly\nincluding the merger of two sub-clusters with initial conditions taken from\nprevious large scale giant molecular cloud (GMC) simulations. We couple\nhydrodynamics to N-body dynamics to simulate the individual stars themselves,\nand the gas-rich environment in which they evolve. We include prescriptions for\nstar formation and stellar feedback and compare directly to previous\nsimulations of the same region without these prescriptions to determine their\nrole in shaping the dynamics inherited from the cluster assembly process. The\nstellar mass of the cluster grows through star formation within the cluster and\naccretion of new stars and star forming gas from a nearby filament. This growth\nresults in an enhancement in the cluster's rotation and anisotropic expansion\ncompared to simulations without star formation. We also analyze the internal\nkinematics of the cluster once it has lost most of its gas and find that the\nrotational velocity and the velocity anisotropy profiles are qualitatively\nsimilar to those expected of clusters that have undergone violent relaxation.\nAs well, rotation and anisotropic expansion are still present by the time of\ngas removal. This implies that evolution within the GMC was unable to\ncompletely erase the kinematics inherited by the merger.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:28:36Z"}
{"aid":"http://arxiv.org/abs/2503.21734v1","title":"Structure and Melting of Fe, MgO, SiO2, and MgSiO3 in Planets: Database,\n  Inversion, and Phase Diagram","summary":"We present globally inverted pressure-temperature (P-T) phase diagrams up to\n5,000 GPa for four fundamental planetary materials, Fe, MgO, SiO2, and MgSiO3,\nderived from logistic regression and supervised learning, together with an\nexperimental phase equilibria database. These new P-T phase diagrams provide a\nsolution to long-standing disputes about their melting curves. Their\nimplications extend to the melting and freezing of rocky materials in the\ninterior of giant planets and super-Earth exoplanets, contributing to the\nrefinement of their internal structure models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.data-an,physics.geo-ph","published":"2025-03-27T17:48:04Z"}
{"aid":"http://arxiv.org/abs/2503.21750v1","title":"Optical control of orbital magnetism in magic angle twisted bilayer\n  graphene","summary":"Flat bands in graphene-based moir\\'e structures host a wide range of emerging\nstrongly correlated and topological phenomena. Optically probing and\ncontrolling them can reveal important information such as symmetry and\ndynamics, but have so far been challenging due to the small energy gap compared\nto optical wavelengths. Here, we report near infrared optical control of\norbital magnetism and associated anomalous Hall effects (AHE) in a magic angle\ntwisted bilayer graphene (MATBG) on monolayer WSe$_2$ device. We show that the\nproperties of the AHE, such as hysteresis and amplitude, can be controlled by\nlight near integer moir\\'e fillings, where spontaneous ferromagnetism exists.\nBy modulating the light helicity, we observe periodic modulation of the\ntransverse resistance in a wide range of fillings, indicating light induced\norbital magnetization through a large inverse Faraday effect. At the transition\nbetween metallic and AHE regimes, we also reveal large and random switching of\nthe Hall resistivity, which are attributed to optical control of percolating\ncluster of magnetic domains. Our results open the door to optical manipulation\nof correlation and topology in MATBG and related structures.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-03-27T17:56:23Z"}
{"aid":"http://arxiv.org/abs/2503.21774v1","title":"Optimal Stepsize for Diffusion Sampling","summary":"Diffusion models achieve remarkable generation quality but suffer from\ncomputational intensive sampling due to suboptimal step discretization. While\nexisting works focus on optimizing denoising directions, we address the\nprincipled design of stepsize schedules. This paper proposes Optimal Stepsize\nDistillation, a dynamic programming framework that extracts theoretically\noptimal schedules by distilling knowledge from reference trajectories. By\nreformulating stepsize optimization as recursive error minimization, our method\nguarantees global discretization bounds through optimal substructure\nexploitation. Crucially, the distilled schedules demonstrate strong robustness\nacross architectures, ODE solvers, and noise schedules. Experiments show 10x\naccelerated text-to-image generation while preserving 99.4% performance on\nGenEval. Our code is available at https://github.com/bebebe666/OptimalSteps.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2503.23681v1","title":"Universality of Shell Effects in Fusion-Fission Mass Distributions","summary":"We present the results of a broad, systematic study of heavy-ion induced\nfission mass distributions for every even-Z compound nucleus ($Z_\\mathrm{CN}$)\nfrom $^{144}$Gd to $^{212}$Th. We find systematic evidence of shell-driven\nstructure in every fission mass distribution. The change in shape of the mass\ndistributions with $Z_\\mathrm{CN}$ is consistent with the results of\nquantitative simultaneous fitting in mass and total kinetic energy,\ndemonstrating that fragment proton shell gaps at $Z_\\mathrm{FF} = 34, 36$ and\n$Z_\\mathrm{FF} = 44, 46$ are \\textit{both} major drivers of fission mass\ndistributions below the actinide region. The mass distributions show enhanced\nyields at mass symmetry for values of $Z_\\mathrm{CN}$ equal to two times these\nfavoured $Z_\\mathrm{FF}$ values. Thus, the same shell gaps that are drivers of\nmass-asymmetric fission also affect mass distributions at and near\nmass-symmetry. For all systems a second, more mass-asymmetric, fission mode is\nrequired to fit the fission mass distributions. If driven by a single shell\ngap, it appears to be in the light fragment around $Z_\\mathrm{FF} = 28, 30$.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T03:02:02Z"}
{"aid":"http://arxiv.org/abs/2503.23686v1","title":"Data-Driven Forecasting of High-Dimensional Transient and Stationary\n  Processes via Space-Time Projection","summary":"Space-Time Projection (STP) is introduced as a data-driven forecasting\napproach for high-dimensional and time-resolved data. The method computes\nextended space-time proper orthogonal modes from training data spanning a\nprediction horizon comprising both hindcast and forecast intervals. Forecasts\nare then generated by projecting the hindcast portion of these modes onto new\ndata, simultaneously leveraging their orthogonality and optimal correlation\nwith the forecast extension. Rooted in Proper Orthogonal Decomposition (POD)\ntheory, dimensionality reduction and time-delay embedding are intrinsic to the\napproach. For a given ensemble and fixed prediction horizon, the only tunable\nparameter is the truncation rank--no additional hyperparameters are required.\nThe hindcast accuracy serves as a reliable indicator for short-term forecast\naccuracy and establishes a lower bound on forecast errors. The efficacy of the\nmethod is demonstrated using two datasets: transient, highly anisotropic\nsimulations of supernova explosions in a turbulent interstellar medium, and\nexperimental velocity fields of a turbulent high-subsonic engineering flow. In\na comparative study with standard Long Short-Term Memory (LSTM) neural\nnetworks--acknowledging that alternative architectures or training strategies\nmay yield different outcomes--the method consistently provided more accurate\nforecasts. Considering its simplicity and robust performance, STP offers an\ninterpretable and competitive benchmark for forecasting high-dimensional\ntransient and chaotic processes, relying purely on spatiotemporal correlation\ninformation.","main_category":"cs.LG","categories":"cs.LG,astro-ph.GA,nlin.CD,physics.comp-ph,physics.data-an,physics.flu-dyn","published":"2025-03-31T03:36:59Z"}
{"aid":"http://arxiv.org/abs/2503.23697v1","title":"A Low-complexity Structured Neural Network to Realize States of\n  Dynamical Systems","summary":"Data-driven learning is rapidly evolving and places a new perspective on\nrealizing state-space dynamical systems. However, dynamical systems derived\nfrom nonlinear ordinary differential equations (ODEs) suffer from limitations\nin computational efficiency. Thus, this paper stems from data-driven learning\nto advance states of dynamical systems utilizing a structured neural network\n(StNN). The proposed learning technique also seeks to identify an optimal,\nlow-complexity operator to solve dynamical systems, the so-called Hankel\noperator, derived from time-delay measurements. Thus, we utilize the StNN based\non the Hankel operator to solve dynamical systems as an alternative to existing\ndata-driven techniques. We show that the proposed StNN reduces the number of\nparameters and computational complexity compared with the conventional neural\nnetworks and also with the classical data-driven techniques, such as Sparse\nIdentification of Nonlinear Dynamics (SINDy) and Hankel Alternative view of\nKoopman (HAVOK), which is commonly known as delay-Dynamic Mode\nDecomposition(DMD) or Hankel-DMD. More specifically, we present numerical\nsimulations to solve dynamical systems utilizing the StNN based on the Hankel\noperator beginning from the fundamental Lotka-Volterra model, where we compare\nthe StNN with the LEarning Across Dynamical Systems (LEADS), and extend our\nanalysis to highly nonlinear and chaotic Lorenz systems, comparing the StNN\nwith conventional neural networks, SINDy, and HAVOK. Hence, we show that the\nproposed StNN paves the way for realizing state-space dynamical systems with a\nlow-complexity learning algorithm, enabling prediction and understanding of\nfuture states.","main_category":"cs.LG","categories":"cs.LG,math.DS","published":"2025-03-31T03:52:38Z"}
{"aid":"http://arxiv.org/abs/2503.23726v1","title":"PDSL: Privacy-Preserved Decentralized Stochastic Learning with\n  Heterogeneous Data Distribution","summary":"In the paradigm of decentralized learning, a group of agents collaborates to\nlearn a global model using distributed datasets without a central server.\nHowever, due to the heterogeneity of the local data across the different\nagents, learning a robust global model is rather challenging. Moreover, the\ncollaboration of the agents relies on their gradient information exchange,\nwhich poses a risk of privacy leakage. In this paper, to address these issues,\nwe propose PDSL, a novel privacy-preserved decentralized stochastic learning\nalgorithm with heterogeneous data distribution. On one hand, we innovate in\nutilizing the notion of Shapley values such that each agent can precisely\nmeasure the contributions of its heterogeneous neighbors to the global learning\ngoal; on the other hand, we leverage the notion of differential privacy to\nprevent each agent from suffering privacy leakage when it contributes gradient\ninformation to its neighbors. We conduct both solid theoretical analysis and\nextensive experiments to demonstrate the efficacy of our PDSL algorithm in\nterms of privacy preservation and convergence.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T04:58:05Z"}
{"aid":"http://arxiv.org/abs/2503.23750v1","title":"Float Lattice Gas Automata: A connection between Molecular Dynamics and\n  Lattice Boltzmann Method for quantum computers","summary":"Building upon the Integer Lattice Gas Automata framework of Blommel\n\\textit{et al.} \\cite{PhysRevE.97.023310}, we introduce a simplified,\nfluctuation-free variant. This approach relies on floating-point numbers and\nclosely mirrors the Lattice Boltzmann Method (LBM), with the key distinction\nbeing a novel collision operator. This operator, derived from the ensemble\naverage of transition probabilities, generates nonlinear terms. We propose this\nnew Float Lattice Gas Automata (FLGA) collision as a computationally efficient\nalternative to traditional and quantum LBM implementations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T06:02:16Z"}
{"aid":"http://arxiv.org/abs/2503.23764v1","title":"WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation\n  for Efficient Medical Image Segmentation","summary":"Transformer-based architectures have advanced medical image analysis by\neffectively modeling long-range dependencies, yet they often struggle in 3D\nsettings due to substantial memory overhead and insufficient capture of\nfine-grained local features. We address these limi- tations with WaveFormer, a\nnovel 3D-transformer that: i) leverages the fundamental frequency-domain\nproperties of features for contextual rep- resentation, and ii) is inspired by\nthe top-down mechanism of the human visual recognition system, making it a\nbiologically motivated architec- ture. By employing discrete wavelet\ntransformations (DWT) at multiple scales, WaveFormer preserves both global\ncontext and high-frequency de- tails while replacing heavy upsampling layers\nwith efficient wavelet-based summarization and reconstruction. This\nsignificantly reduces the number of parameters, which is critical for\nreal-world deployment where compu- tational resources and training times are\nconstrained. Furthermore, the model is generic and easily adaptable to diverse\napplications. Evaluations on BraTS2023, FLARE2021, and KiTS2023 demonstrate\nperformance on par with state-of-the-art methods while offering substantially\nlower computational complexity.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T06:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.23792v1","title":"When do firms sell high durability products? The case of light bulb\n  industry","summary":"This study empirically investigates firms' incentives on the choice of\nproduct durability, and its social optimality, by developing a dynamic\nstructural model of durable goods with forward-looking consumers and\noligopolistic multi-product firms. Based on the observations of the light bulb\nmarket, it specifies a model where firms produce multiple products with\ndifferent durability levels and set product prices based on dynamic incentives.\nIt proposes and applies novel estimation algorithms that alleviate the\ncomputational burden and data requirement for estimating demand and marginal\ncost parameters of dynamic demand models. Using light bulb market data in\nJapan, structural parameters are estimated. This study obtains the following\nresults. First, large firms have incentives to collude to eliminate high\ndurability incandescent lamps, though it is profitable to sell them for each\nfirm. In contrast, when they can collude on prices, they don't have incentives\nto eliminate high durability bulbs. Second, eliminating high durability\nincandescent lamps leads to larger producer and total surplus, though it leads\nto lower consumer surplus.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T07:13:44Z"}
{"aid":"http://arxiv.org/abs/2503.23802v1","title":"Herscovici Conjecture on Pebbling","summary":"Consider a configuration of pebbles on the vertices of a connected graph. A\npebbling move is to remove two pebbles from a vertex and to place one pebble at\nthe neighbouring vertex of the vertex from which the pebbles are removed.\n  For a positive integer $t$, with every configuration of $\\pi_t(G)$(least\npositive integer) pebbles, if we can transfer $t$ pebbles to any target through\na number of pebbling moves then $\\pi_t(G)$ is called the $t$-pebbling number of\n$G$.\n  We discuss the computation of the $t$-pebbling number, the $2t-$ pebbling\nproperty and Herscovici conjecture considering total graphs.\n  \\bigskip \\noindent Keywords: pebbling moves, $t$- pebbling number,\n$2t$-pebbling property, Herscovici conjecture, total graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T07:25:26Z"}
{"aid":"http://arxiv.org/abs/2503.23803v1","title":"Thinking Longer, Not Larger: Enhancing Software Engineering Agents via\n  Scaling Test-Time Compute","summary":"Recent advancements in software engineering agents have demonstrated\npromising capabilities in automating program improvements. However, their\nreliance on closed-source or resource-intensive models introduces significant\ndeployment challenges in private environments, prompting a critical question:\n\\textit{How can personally deployable open-source LLMs achieve comparable code\nreasoning performance?}\n  To this end, we propose a unified Test-Time Compute scaling framework that\nleverages increased inference-time computation instead of larger models. Our\nframework incorporates two complementary strategies: internal TTC and external\nTTC. Internally, we introduce a \\textit{development-contextualized trajectory\nsynthesis} method leveraging real-world software repositories to bootstrap\nmulti-stage reasoning processes, such as fault localization and patch\ngeneration. We further enhance trajectory quality through rejection sampling,\nrigorously evaluating trajectories along accuracy and complexity. Externally,\nwe propose a novel \\textit{development-process-based search} strategy guided by\nreward models and execution verification. This approach enables targeted\ncomputational allocation at critical development decision points, overcoming\nlimitations of existing \"end-point only\" verification methods.\n  Evaluations on SWE-bench Verified demonstrate our \\textbf{32B model achieves\na 46\\% issue resolution rate}, surpassing significantly larger models such as\nDeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical\nvalidation of the test-time scaling phenomenon within SWE agents, revealing\nthat \\textbf{models dynamically allocate more tokens to increasingly\nchallenging problems}, effectively enhancing reasoning capabilities. We\npublicly release all training data, models, and code to facilitate future\nresearch. https://github.com/yingweima2022/SWE-Reasoner","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-03-31T07:31:32Z"}
{"aid":"http://arxiv.org/abs/2503.23817v1","title":"MVDRAM: Enabling GeMV Execution in Unmodified DRAM for Low-Bit LLM\n  Acceleration","summary":"General matrix-vector multiplication (GeMV) remains a critical latency\nbottleneck in large language model (LLM) inference, even with quantized low-bit\nmodels. Processing-Using-DRAM (PUD), an analog in-DRAM computing technique, has\nthe potential to repurpose on-device DRAM as a GeMV engine, offering additional\nhigh-throughput processing capabilities to widespread consumer devices without\nDRAM modifications. However, applying PUD to GeMV operations in the LLM\ninference pipeline incurs significant overheads $\\textit{before}$ and\n$\\textit{after}$ in-DRAM computation, diminishing the benefits of its\nhigh-throughput processing capabilities.\n  This paper presents MVDRAM, the first practical system to accelerate GeMV\noperations for low-bit LLM inference using unmodified DRAM. By leveraging the\ndata sharing patterns and mathematical linearity in GeMV operations, MVDRAM\norchestrates the processor and DRAM to eliminate the costs associated with\npre-arranging inputs and bit-transposition of outputs required in conventional\nPUD approaches. Our experimental evaluation with four DDR4 DRAM modules shows\nthat MVDRAM achieves comparable or even better inference speed than the\nprocessor-based implementation for GeMV operations in low-bit (under 4-bit)\nLLM. In particular, MVDRAM achieves up to 7.29$\\times$ speedup and 30.5$\\times$\nenergy efficiency for low-bit GeMV operations. For end-to-end LLM inference,\nMVDRAM achieves 2.18$\\times$ and 1.31$\\times$ throughput improvements, along\nwith 3.04$\\times$ and 2.35$\\times$ energy efficiency, for 2-bit and 4-bit\nquantized low-bit models, respectively. MVDRAM has the potential to redefine\nthe AI hardware landscape by demonstrating the feasibility of standard DRAM as\nan LLM accelerator.","main_category":"cs.AR","categories":"cs.AR,cs.DC","published":"2025-03-31T07:54:59Z"}
{"aid":"http://arxiv.org/abs/2503.23881v1","title":"ExScene: Free-View 3D Scene Reconstruction with Gaussian Splatting from\n  a Single Image","summary":"The increasing demand for augmented and virtual reality applications has\nhighlighted the importance of crafting immersive 3D scenes from a simple\nsingle-view image. However, due to the partial priors provided by single-view\ninput, existing methods are often limited to reconstruct low-consistency 3D\nscenes with narrow fields of view from single-view input. These limitations\nmake them less capable of generalizing to reconstruct immersive scenes. To\naddress this problem, we propose ExScene, a two-stage pipeline to reconstruct\nan immersive 3D scene from any given single-view image. ExScene designs a novel\nmultimodal diffusion model to generate a high-fidelity and globally consistent\npanoramic image. We then develop a panoramic depth estimation approach to\ncalculate geometric information from panorama, and we combine geometric\ninformation with high-fidelity panoramic image to train an initial 3D Gaussian\nSplatting (3DGS) model. Following this, we introduce a GS refinement technique\nwith 2D stable video diffusion priors. We add camera trajectory consistency and\ncolor-geometric priors into the denoising process of diffusion to improve color\nand spatial consistency across image sequences. These refined sequences are\nthen used to fine-tune the initial 3DGS model, leading to better reconstruction\nquality. Experimental results demonstrate that our ExScene achieves consistent\nand immersive scene reconstruction using only single-view input, significantly\nsurpassing state-of-the-art baselines.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:33:22Z"}
{"aid":"http://arxiv.org/abs/2503.23897v1","title":"Training-Free Text-Guided Image Editing with Visual Autoregressive Model","summary":"Text-guided image editing is an essential task that enables users to modify\nimages through natural language descriptions. Recent advances in diffusion\nmodels and rectified flows have significantly improved editing quality,\nprimarily relying on inversion techniques to extract structured noise from\ninput images. However, inaccuracies in inversion can propagate errors, leading\nto unintended modifications and compromising fidelity. Moreover, even with\nperfect inversion, the entanglement between textual prompts and image features\noften results in global changes when only local edits are intended. To address\nthese challenges, we propose a novel text-guided image editing framework based\non VAR (Visual AutoRegressive modeling), which eliminates the need for explicit\ninversion while ensuring precise and controlled modifications. Our method\nintroduces a caching mechanism that stores token indices and probability\ndistributions from the original image, capturing the relationship between the\nsource prompt and the image. Using this cache, we design an adaptive\nfine-grained masking strategy that dynamically identifies and constrains\nmodifications to relevant regions, preventing unintended changes. A token\nreassembling approach further refines the editing process, enhancing diversity,\nfidelity, and control. Our framework operates in a training-free manner and\nachieves high-fidelity editing with faster inference speeds, processing a 1K\nresolution image in as fast as 1.2 seconds. Extensive experiments demonstrate\nthat our method achieves performance comparable to, or even surpassing,\nexisting diffusion- and rectified flow-based approaches in both quantitative\nmetrics and visual quality. The code will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:46:56Z"}
{"aid":"http://arxiv.org/abs/2503.23935v1","title":"Nonparametric function-on-scalar regression using deep neural networks","summary":"We focus on nonlinear Function-on-Scalar regression, where the predictors are\nscalar variables, and the responses are functional data. Most existing studies\napproximate the hidden nonlinear relationships using linear combinations of\nbasis functions, such as splines. However, in classical nonparametric\nregression, it is known that these approaches lack adaptivity, particularly\nwhen the true function exhibits high spatial inhomogeneity or anisotropic\nsmoothness. To capture the complex structure behind data adaptively, we propose\na simple adaptive estimator based on a deep neural network model. The proposed\nestimator is straightforward to implement using existing deep learning\nlibraries, making it accessible for practical applications. Moreover, we derive\nthe convergence rates of the proposed estimator for the anisotropic Besov\nspaces, which consist of functions with varying smoothness across dimensions.\nOur theoretical analysis shows that the proposed estimator mitigates the curse\nof dimensionality when the true function has high anisotropic smoothness, as\nshown in the classical nonparametric regression. Numerical experiments\ndemonstrate the superior adaptivity of the proposed estimator, outperforming\nexisting methods across various challenging settings. Moreover, the proposed\nmethod is applied to analyze ground reaction force data in the field of sports\nmedicine, demonstrating more efficient estimation compared to existing\napproaches.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T10:34:50Z"}
{"aid":"http://arxiv.org/abs/2503.23938v1","title":"New results about aggregation functions of quasi-pseudometric modulars","summary":"In recent studies, Bibiloni-Femenias, Mi\\~{n}ana and Valero characterized the\nfunctions that aggregate a family of (quasi-)(pseudo)metric modulars defined\nover a fixed set $X$ into a single one. In this paper, we adopt a related but\ndifferent approach to examine those functions that allow us to define a\n(quasi-)(pseudo)metric modular in the Cartesian product of\n(quasi-)(pseudo)metric modular spaces. We base our research on the recent\ndevelopment of a general theory of aggregation functions between quantales.\nThis enables to shed light between the two different ways of aggregation\n(quasi-)(pseudo)metric modulars.","main_category":"math.GN","categories":"math.GN","published":"2025-03-31T10:38:24Z"}
{"aid":"http://arxiv.org/abs/2503.23940v1","title":"Operator limit of Wigner matrices I","summary":"We consider the Wigner matrix $W_{n}$ of dimension $n \\times n$ as $n \\to\n\\infty$. The objective of this paper is two folds: first we construct an\noperator $\\mathcal{W}$ on a suitable Hilbert space $\\mathcal{H}$ and then\ndefine a suitable notion of convergence such that the matrices $W_{n}$ converge\nin that notion of convergence to $\\mathcal{W}$. We further investigate some\nproperties of $\\mathcal{W}$ and $\\mathcal{H}$. We show that $\\mathcal{H}$ is a\nnontrivial extension of $L^{2}[0,1]$ with respect to the Lebesgue measure and\nthe spectral measure of $\\mathcal{W}$ at any function $f \\in L^{2}[0,1]$ is\nalmost surely the semicircular law.","main_category":"math.PR","categories":"math.PR,math-ph,math.FA,math.MP,math.ST,stat.TH","published":"2025-03-31T10:45:01Z"}
{"aid":"http://arxiv.org/abs/2503.23947v1","title":"Spectral-Adaptive Modulation Networks for Visual Perception","summary":"Recent studies have shown that 2D convolution and self-attention exhibit\ndistinct spectral behaviors, and optimizing their spectral properties can\nenhance vision model performance. However, theoretical analyses remain limited\nin explaining why 2D convolution is more effective in high-pass filtering than\nself-attention and why larger kernels favor shape bias, akin to self-attention.\nIn this paper, we employ graph spectral analysis to theoretically simulate and\ncompare the frequency responses of 2D convolution and self-attention within a\nunified framework. Our results corroborate previous empirical findings and\nreveal that node connectivity, modulated by window size, is a key factor in\nshaping spectral functions. Leveraging this insight, we introduce a\n\\textit{spectral-adaptive modulation} (SPAM) mixer, which processes visual\nfeatures in a spectral-adaptive manner using multi-scale convolutional kernels\nand a spectral re-scaling mechanism to refine spectral components. Based on\nSPAM, we develop SPANetV2 as a novel vision backbone. Extensive experiments\ndemonstrate that SPANetV2 outperforms state-of-the-art models across multiple\nvision tasks, including ImageNet-1K classification, COCO object detection, and\nADE20K semantic segmentation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:53:42Z"}
{"aid":"http://arxiv.org/abs/2503.23948v1","title":"AI2Agent: An End-to-End Framework for Deploying AI Projects as\n  Autonomous Agents","summary":"As AI technology advances, it is driving innovation across industries,\nincreasing the demand for scalable AI project deployment. However, deployment\nremains a critical challenge due to complex environment configurations,\ndependency conflicts, cross-platform adaptation, and debugging difficulties,\nwhich hinder automation and adoption. This paper introduces AI2Agent, an\nend-to-end framework that automates AI project deployment through\nguideline-driven execution, self-adaptive debugging, and case \\& solution\naccumulation. AI2Agent dynamically analyzes deployment challenges, learns from\npast cases, and iteratively refines its approach, significantly reducing human\nintervention. To evaluate its effectiveness, we conducted experiments on 30 AI\ndeployment cases, covering TTS, text-to-image generation, image editing, and\nother AI applications. Results show that AI2Agent significantly reduces\ndeployment time and improves success rates. The code and demo video are now\npublicly accessible.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:58:34Z"}
{"aid":"http://arxiv.org/abs/2503.23958v1","title":"A Multi-Stage Auto-Context Deep Learning Framework for Tissue and Nuclei\n  Segmentation and Classification in H&E-Stained Histological Images of\n  Advanced Melanoma","summary":"Melanoma is the most lethal form of skin cancer, with an increasing incidence\nrate worldwide. Analyzing histological images of melanoma by localizing and\nclassifying tissues and cell nuclei is considered the gold standard method for\ndiagnosis and treatment options for patients. While many computerized\napproaches have been proposed for automatic analysis, most perform tissue-based\nanalysis and nuclei (cell)-based analysis as separate tasks, which might be\nsuboptimal.\n  In this work, using the PUMA challenge dataset, we proposed a novel\nmulti-stage deep learning approach by combining tissue and nuclei information\nin a unified framework based on the auto-context concept to perform\nsegmentation and classification in histological images of melanoma. Through\npre-training and further post-processing, our approach achieved second and\nfirst place rankings in the PUMA challenge, with average micro Dice tissue\nscore and summed nuclei F1-score of 73.40% for Track 1 and 63.48% for Track 2,\nrespectively. Our implementation for training and testing is available at:\nhttps://github.com/NimaTorbati/PumaSubmit","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:15:50Z"}
{"aid":"http://arxiv.org/abs/2503.23973v1","title":"Odd Cuts in Bipartite Grafts II: Structure and Universality of Decapital\n  Distance Components","summary":"This paper is the second in a series of papers characterizing the maximum\npacking of \\( T \\)-cuts in bipartite grafts, following the first paper\n(N.~Kita, ``Tight cuts in bipartite grafts~I: Capital distance components,''\n{arXiv:2202.00192v2}, 2022). Given a graft $(G, T)$, a minimum join $F$, and a\nspecified vertex $r$ called the root, the distance components of $(G, T)$ are\ndefined as subgraphs of $G$ determined by the distances induced by $F$. A\ndistance component is called {\\em capital} if it contains the root; otherwise,\nit is called {\\em decapital}. In our first paper, we investigated the canonical\nstructure of capital distance components in bipartite grafts, which can be\ndescribed using the graft analogue of the Kotzig--Lov\\'asz decomposition. In\nthis paper, we provide the counterpart structure for the decapital distance\ncomponents. We also establish a necessary and sufficient condition for two\nvertices $r$ and $r'$ under which a decapital distance component with respect\nto root $r$ is also a decapital distance component with respect to root $r'$.\nAs a consequence, we obtain that the total number of decapital distance\ncomponents in a bipartite graft, taken over all choices of root, is equal to\ntwice the number of edges in a minimum join of the graft.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T11:36:02Z"}
{"aid":"http://arxiv.org/abs/2503.23975v1","title":"A Reactive Framework for Whole-Body Motion Planning of Mobile\n  Manipulators Combining Reinforcement Learning and SDF-Constrained Quadratic\n  Programmi","summary":"As an important branch of embodied artificial intelligence, mobile\nmanipulators are increasingly applied in intelligent services, but their\nredundant degrees of freedom also limit efficient motion planning in cluttered\nenvironments. To address this issue, this paper proposes a hybrid learning and\noptimization framework for reactive whole-body motion planning of mobile\nmanipulators. We develop the Bayesian distributional soft actor-critic\n(Bayes-DSAC) algorithm to improve the quality of value estimation and the\nconvergence performance of the learning. Additionally, we introduce a quadratic\nprogramming method constrained by the signed distance field to enhance the\nsafety of the obstacle avoidance motion. We conduct experiments and make\ncomparison with standard benchmark. The experimental results verify that our\nproposed framework significantly improves the efficiency of reactive whole-body\nmotion planning, reduces the planning time, and improves the success rate of\nmotion planning. Additionally, the proposed reinforcement learning method\nensures a rapid learning process in the whole-body planning task. The novel\nframework allows mobile manipulators to adapt to complex environments more\nsafely and efficiently.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T11:37:02Z"}
{"aid":"http://arxiv.org/abs/2503.24002v1","title":"A Simple BER Expression for FSO Systems with Weak Turbulence and\n  Pointing Errors","summary":"We develop a simple approximation for the average BER for an FSO system\nimpacted by weak turbulence and pointing errors. Numerical results show that\nthe proposed expression accurately predicts the true BER.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T12:27:24Z"}
{"aid":"http://arxiv.org/abs/2503.24011v1","title":"Simulations in Statistical Workflows","summary":"Simulations play important and diverse roles in statistical workflows, for\nexample, in model specification, checking, validation, and even directly in\nmodel inference. Over the past decades, the application areas and overall\npotential of simulations in statistical workflows have expanded significantly,\ndriven by the development of new simulation-based algorithms and exponentially\nincreasing computational resources. In this paper, we examine past and current\ntrends in the field and offer perspectives on how simulations may shape the\nfuture of statistical practice.","main_category":"stat.CO","categories":"stat.CO","published":"2025-03-31T12:38:21Z"}
{"aid":"http://arxiv.org/abs/2503.24012v1","title":"Tree-Guided $L_1$-Convex Clustering","summary":"Convex clustering is a modern clustering framework that guarantees globally\noptimal solutions and performs comparably to other advanced clustering methods.\nHowever, obtaining a complete dendrogram (clusterpath) for large-scale datasets\nremains computationally challenging due to the extensive costs associated with\niterative optimization approaches. To address this limitation, we develop a\nnovel convex clustering algorithm called Tree-Guided $L_1$-Convex Clustering\n(TGCC). We first focus on the fact that the loss function of $L_1$-convex\nclustering with tree-structured weights can be efficiently optimized using a\ndynamic programming approach. We then develop an efficient cluster fusion\nalgorithm that utilizes the tree structure of the weights to accelerate the\noptimization process and eliminate the issue of cluster splits commonly\nobserved in convex clustering. By combining the dynamic programming approach\nwith the cluster fusion algorithm, the TGCC algorithm achieves superior\ncomputational efficiency without sacrificing clustering performance.\nRemarkably, our TGCC algorithm can construct a complete clusterpath for $10^6$\npoints in $\\mathbb{R}^2$ within 15 seconds on a standard laptop without the\nneed for parallel or distributed computing frameworks. Moreover, we extend the\nTGCC algorithm to develop biclustering and sparse convex clustering algorithms.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-03-31T12:39:48Z"}
{"aid":"http://arxiv.org/abs/2503.24021v1","title":"IntelliCircos: A Data-driven and AI-powered Authoring Tool for Circos\n  Plots","summary":"Genomics data is essential in biological and medical domains, and\nbioinformatics analysts often manually create circos plots to analyze the data\nand extract valuable insights. However, creating circos plots is complex, as it\nrequires careful design for multiple track attributes and positional\nrelationships between them. Typically, analysts often seek inspiration from\nexisting circos plots, and they have to iteratively adjust and refine the plot\nto achieve a satisfactory final design, making the process both tedious and\ntime-intensive. To address these challenges, we propose IntelliCircos, an\nAI-powered interactive authoring tool that streamlines the process from initial\nvisual design to the final implementation of circos plots. Specifically, we\nbuild a new dataset containing 4396 circos plots with corresponding annotations\nand configurations, which are extracted and labeled from published papers. With\nthe dataset, we further identify track combination patterns, and utilize Large\nLanguage Model (LLM) to provide domain-specific design recommendations and\nconfiguration references to navigate the design of circos plots. We conduct a\nuser study with 8 bioinformatics analysts to evaluate IntelliCircos, and the\nresults demonstrate its usability and effectiveness in authoring circos plots.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T12:48:39Z"}
{"aid":"http://arxiv.org/abs/2503.24038v1","title":"Giant counter-rotating oscillations on the attosecond timescale","summary":"We predict an unexplored type of ultrastrong coupling between atoms and\nintense ultraviolet light that leads to giant population oscillations on the\nattosecond timescale. These counter-rotating oscillations can be of similar\namplitude as the elementary femtosecond Rabi oscillations between the two\nstrongly coupled states. The effect, which is beyond the two-level atom, is\nnon-reciprocal: It only affects the excited state, while the ground state is\nunaffected. We propose that two-photon Rabi oscillations (1s$^2$-1s3d) in\nhelium is suitable for the generation of this type of ultrastrong coupling with\nrealistic pulses. We use a combination of Floquet theory and effective\nHamiltonian theory to test our predictions against ab initio simulations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T13:01:32Z"}
{"aid":"http://arxiv.org/abs/2503.24078v1","title":"A Complete Epistemic Temporal Logic for Intelligent Agent","summary":"In this paper, we present a complete epistemic temporal logic, called BPICTL,\nwhich generalizes CTL by introducing epistemic modalities. A sound and complete\ninference system of BPICTL is given. We prove the finite model property of\nBPICTL. Furthermore, we present a model checking algorithm for BPICTL.","main_category":"cs.LO","categories":"cs.LO","published":"2025-03-31T13:33:30Z"}
{"aid":"http://arxiv.org/abs/2503.24086v1","title":"Distributed AC Optimal Power Flow: A Scalable Solution for Large-Scale\n  Problems","summary":"This paper introduces a novel distributed optimization framework for\nlarge-scale AC Optimal Power Flow (OPF) problems, offering both theoretical\nconvergence guarantees and rapid convergence in practice. By integrating\nsmoothing techniques and the Schur complement, the proposed approach addresses\nthe scalability challenges and reduces communication overhead in distributed AC\nOPF. Additionally, optimal network decomposition enables efficient parallel\nprocessing under the single program multiple data (SPMD) paradigm. Extensive\nsimulations on large-scale benchmarks across various operating scenarios\nindicate that the proposed framework outperforms the state-of-the-art\ncentralized solver IPOPT on modest hardware. This paves the way for more\nscalable and efficient distributed optimization in future power system\napplications.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T13:40:12Z"}
{"aid":"http://arxiv.org/abs/2503.24103v1","title":"Constructing Chayet-Garibaldi algebras from affine vertex algebras\n  (including the 3876-dimensional algebra for $E_8$)","summary":"In 2021, Maurice Chayet and Skip Garibaldi provided an explicit construction\nof a commutative non-associative algebra on the second smallest representation\nof $E_8$ (of dimension $3875$) adjoined with a unit. In fact, they define such\nan algebra $A(\\mathfrak{g})$ for each simple Lie algebra $\\mathfrak{g}$, in\nterms of explicit but ad-hoc formulas.\n  We discovered that their algebras $A(\\mathfrak{g})$ have a natural\ninterpretation in terms of affine vertex algebras, and their ad-hoc formulas\ntake an extremely simple form in this new interpretation. It is our hope that\nthis point of view will lead to a better understanding of this interesting\nclass of algebras.","main_category":"math.RA","categories":"math.RA,math.GR,math.RT","published":"2025-03-31T13:56:23Z"}
{"aid":"http://arxiv.org/abs/2503.24149v1","title":"Enhancing Trust in Inter-Organisational Data Sharing: Levels of\n  Assurance for Data Trustworthiness","summary":"As data is increasingly acknowledged as a highly valuable asset, much effort\nhas been put into investigating inter-organisational data sharing, aiming at\nutilising the value of formerly unused data. Moreover, most researchers agree,\nthat trust between actors is key for successful data sharing activities.\nHowever, existing research oftentimes focus on trust from a data provider\nperspective. Therefore, our work highlights the unbalanced view of trust,\naddressing it from a data consumer perspective. More specifically, our aim is\nto investigate trust enhancing measures on a data level, that is data\ntrustworthiness. We found, that existing data trustworthiness enhancing\nsolutions do not meet the requirements of the domain of inter-organisational\ndata sharing. Therefore, our study addresses this gap. Conducting a rigorous\ndesign science research approach, this work proposes a new Levels of Assurance\nfor Data Trustworthiness artifact. Built on existing artifacts, we demonstrate,\nhow it addresses the identified challenges within the domain appropriately. We\nfound that our novel approach requires more work to be suitable for adoption.\nStill, we are confident that our solution can increase consumer trust. We\nconclude by contributing to the body of design knowledge and emphasise the need\nfor more attention to be put into consumer trust.","main_category":"cs.SI","categories":"cs.SI,cs.CY,econ.GN,q-fin.EC","published":"2025-03-31T14:35:23Z"}
{"aid":"http://arxiv.org/abs/2503.24157v1","title":"LLM4FS: Leveraging Large Language Models for Feature Selection and How\n  to Improve It","summary":"Recent advances in large language models (LLMs) have provided new\nopportunities for decision-making, particularly in the task of automated\nfeature selection. In this paper, we first comprehensively evaluate LLM-based\nfeature selection methods, covering the state-of-the-art DeepSeek-R1,\nGPT-o3-mini, and GPT-4.5. Then, we propose a novel hybrid strategy called\nLLM4FS that integrates LLMs with traditional data-driven methods. Specifically,\ninput data samples into LLMs, and directly call traditional data-driven\ntechniques such as random forest and forward sequential selection. Notably, our\nanalysis reveals that the hybrid strategy leverages the contextual\nunderstanding of LLMs and the high statistical reliability of traditional\ndata-driven methods to achieve excellent feature selection performance, even\nsurpassing LLMs and traditional data-driven methods. Finally, we point out the\nlimitations of its application in decision-making.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T14:40:31Z"}
{"aid":"http://arxiv.org/abs/2503.24196v1","title":"Fermilab's Transition to Token Authentication","summary":"Fermilab is the first High Energy Physics institution to transition from\nX.509 user certificates to authentication tokens in production systems. All the\nexperiments that Fermilab hosts are now using JSON Web Token (JWT) access\ntokens in their grid jobs. Many software components have been either updated or\ncreated for this transition, and most of the software is available to others as\nopen source. The tokens are defined using the WLCG Common JWT Profile. Token\nattributes for all the tokens are stored in the Fermilab FERRY system which\ngenerates the configuration for the CILogon token issuer. High security-value\nrefresh tokens are stored in Hashicorp Vault configured by htvault-config, and\nJWT access tokens are requested by the htgettoken client through its\nintegration with HTCondor. The Fermilab job submission system jobsub was\nredesigned to be a lightweight wrapper around HTCondor. The grid workload\nmanagement system GlideinWMS which is also based on HTCondor was updated to use\ntokens for pilot job submission. For automated job submissions a managed tokens\nservice was created to reduce duplication of effort and knowledge of how to\nsecurely keep tokens active. The existing Fermilab file transfer tool ifdh was\nupdated to work seamlessly with tokens, as well as the Fermilab POMS\n(Production Operations Management System) which is used to manage automatic job\nsubmission and the RCDS (Rapid Code Distribution System) which is used to\ndistribute analysis code via the CernVM FileSystem. The dCache storage system\nwas reconfigured to accept tokens for authentication in place of X.509 proxy\ncertificates. As some services and sites have not yet implemented token\nsupport, proxy certificates are still sent with jobs for backwards\ncompatibility, but some experiments are beginning to transition to stop using\nthem.","main_category":"cs.DC","categories":"cs.DC","published":"2025-03-31T15:14:29Z"}
{"aid":"http://arxiv.org/abs/2503.24224v1","title":"Simplified Cofactor Conditions for Cubic to Tetragonal, Orthorhombic,\n  and Monoclinic Phase Transformations","summary":"Cofactor Conditions (CCs) are geometric compatibility conditions\nmathematically derived from the crystallographic theory of martensitic phase\ntransformation. The CCs guarantee compatible interfaces between the austenite\nand the parallelled twin of the martensite with any volume fraction, yielding a\nwide range of microstructures during phase transformation. In recent times, CCs\nhave demonstrated tremendous applications in the rational design of low\nhysteresis/fatigue shape memory alloys and shape memory ceramics. In this\npaper, we present a simplified form of the CCs for Type I/II twins using the\neigenspace of transformation stretch tensor and twin axes. We further show the\nexplicit forms and visualizations of the simplified CCs for Cubic to\nTetragonal, Cubic to Orthorhombic, and Cubic to Monoclinic I/II phase\ntransformations. The simplified form has revealed a more straightforward\ncorrelation between the lattice parameters and the CCs, and thus provides a\nmore convenient tool for the rational design of phase-transforming materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T15:38:23Z"}
{"aid":"http://arxiv.org/abs/2503.24234v1","title":"Beyond Gaussian Assumptions: A Nonlinear Generalization of Linear\n  Inverse Modeling","summary":"The Linear Inverse Model (LIM) is a class of data-driven methods that\nconstruct approximate linear stochastic models to represent complex\nobservational data. The stochastic forcing can be modeled using either Gaussian\nwhite noise or Ornstein-Uhlenbeck colored noise; the corresponding models are\ncalled White-LIM and Colored-LIM, respectively. Although LIMs are widely\napplied in climate sciences, they inherently approximate observed distributions\nas Gaussian, limiting their ability to capture asymmetries.\n  In this study, we extend LIMs to incorporate nonlinear dynamics, introducing\nWhite-nLIM and Colored-nLIM which allow for a more flexible and accurate\nrepresentation of complex dynamics from observations. The proposed methods not\nonly account for the nonlinear nature of the underlying system but also\neffectively capture the skewness of the observed distribution. Moreover, we\napply these methods to a lower-dimensional representation of ENSO and\ndemonstrate that both White-nLIM and Colored-nLIM successfully capture its\nnonlinear characteristic.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-03-31T15:46:06Z"}
{"aid":"http://arxiv.org/abs/2503.24235v1","title":"What, How, Where, and How Well? A Survey on Test-Time Scaling in Large\n  Language Models","summary":"As enthusiasm for scaling computation (data and parameters) in the\npretraining era gradually diminished, test-time scaling (TTS), also referred to\nas ``test-time computing'' has emerged as a prominent research focus. Recent\nstudies demonstrate that TTS can further elicit the problem-solving\ncapabilities of large language models (LLMs), enabling significant\nbreakthroughs not only in specialized reasoning tasks, such as mathematics and\ncoding, but also in general tasks like open-ended Q&A. However, despite the\nexplosion of recent efforts in this area, there remains an urgent need for a\ncomprehensive survey offering a systemic understanding. To fill this gap, we\npropose a unified, multidimensional framework structured along four core\ndimensions of TTS research: what to scale, how to scale, where to scale, and\nhow well to scale. Building upon this taxonomy, we conduct an extensive review\nof methods, application scenarios, and assessment aspects, and present an\norganized decomposition that highlights the unique functional roles of\nindividual techniques within the broader TTS landscape. From this analysis, we\ndistill the major developmental trajectories of TTS to date and offer hands-on\nguidelines for practical deployment. Furthermore, we identify several open\nchallenges and offer insights into promising future directions, including\nfurther scaling, clarifying the functional essence of techniques, generalizing\nto more tasks, and more attributions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T15:46:15Z"}
{"aid":"http://arxiv.org/abs/2503.24247v1","title":"Unitary and non-unitary operators leverage perfect and imperfect single\n  qutrit teleportation","summary":"Teleportation, a novel scheme, initially posited by Bennett \\textit{et.al},\nhas been studied here in the context of sending a single qutrit from Alice to\nBob using two qutrit entangled channels as resources. In this paper we have\nconsidered two special two qutrit entangled states, which belong to $SU(3)$\ngroup, as useful resources for teleportation. For the successful teleportation,\nthese entangled states have been chosen as quantum channels shared between\nAlice and Bob. Another entangled basis of two qutrit states have been used as\nauxiliary states, which would help Alice to manipulate with her channel so that\nthe single qutrit she holds can be successfully teleported to Bob. Bob's\nchoices of measurement operators influence the retrieval of Alice's single\nqutrit.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T15:58:23Z"}
{"aid":"http://arxiv.org/abs/2503.24263v1","title":"The Physics of Conformal Cyclic Cosmology","summary":"According to conformal cyclic cosmology (CCC), the currently conventional\ndescription of the entire history of the universe (but without an initial\ninflationary phase) provides but one cosmic aeon of an unending sequence of\nsuch aeons, where the future conformal infinity of each aeon joins essentially\nsmoothly to the conformally stretched big bang of the next, across a spacelike\n3-surface, referred to as a crossover 3-surface. Whereas in previous accounts\nof CCC a detailed description of the physics of crossover had been somewhat\nproblematic, a novel idea is introduced here to show how crossover takes place\nnaturally during a temporal period of the universe that is dominated by\ngravitational waves referred to here as a gravitational wave epoch (GWE).\nAccordingly, the geometry at the crossover surface is conformally smooth,\nexcept at a discrete set of points, referred to as Hawking points, each\nrepresenting the final Hawking evaporation of the dominant black hole of a\ngalactic cluster in the earlier aeon. It is shown here (using 2-spinor and\ntwistor techniques) that there is a mass-energy conservation law that holds\nacross the crossover surface, showing that the rise of temperature within such\nHawking spots should be effectively determined by the total mass of the\npre-crossover galactic cluster involved. This rise of temperature on the CMB\nmap within Hawking spots is found to be in quantitative agreement with the\nmasses of the largest galactic clusters observed in our own aeon what suggests\nthat the physics in the previous aeon was, at least in the gravitational\nsector, similar to ours. A second observational feature, the actual angular\ndiameter of the Hawking spots seen in our CMB, which is about twice what should\nhave been expected, is associated to the presence of GWE just after the\ncrossover and before the start of the usual cosmological epochs.","main_category":"gr-qc","categories":"gr-qc","published":"2025-03-31T16:10:05Z"}
{"aid":"http://arxiv.org/abs/2503.24264v1","title":"Extended signatures and link concordance","summary":"The Levine-Tristram signature admits an n-variable extension for n-component\nlinks: it was first defined as an integer valued function on\n$(S^1\\setminus\\{1\\})^n$, and recently extended to the full torus $T^n$. The aim\nof the present article is to study and use this extended signature. First, we\nshow that it is constant on the connected components of the complement of the\nzero-locus of some renormalized Alexander polynomial. Then, we prove that the\nextended signature is a concordance invariant on an explicit dense subset of\n$T^n$. Finally, as an application, we present an infinite family of 3-component\nlinks with the following property: these links are not concordant to their\nmirror image, a fact that can be detected neither by the non-extended\nsignatures, nor by the multivariable Alexander polynomial, nor by the Milnor\ntriple linking number.","main_category":"math.GT","categories":"math.GT","published":"2025-03-31T16:10:21Z"}
{"aid":"http://arxiv.org/abs/2503.24267v1","title":"FakeScope: Large Multimodal Expert Model for Transparent AI-Generated\n  Image Forensics","summary":"The rapid and unrestrained advancement of generative artificial intelligence\n(AI) presents a double-edged sword: while enabling unprecedented creativity, it\nalso facilitates the generation of highly convincing deceptive content,\nundermining societal trust. As image generation techniques become increasingly\nsophisticated, detecting synthetic images is no longer just a binary task: it\nnecessitates interpretable, context-aware methodologies that enhance\ntrustworthiness and transparency. However, existing detection models primarily\nfocus on classification, offering limited explanatory insights into image\nauthenticity. In this work, we propose FakeScope, an expert multimodal model\n(LMM) tailored for AI-generated image forensics, which not only identifies\nAI-synthetic images with high accuracy but also provides rich, interpretable,\nand query-driven forensic insights. We first construct FakeChain dataset that\ncontains linguistic authenticity reasoning based on visual trace evidence,\ndeveloped through a novel human-machine collaborative framework. Building upon\nit, we further present FakeInstruct, the largest multimodal instruction tuning\ndataset containing 2 million visual instructions tailored to enhance forensic\nawareness in LMMs. FakeScope achieves state-of-the-art performance in both\nclosed-ended and open-ended forensic scenarios. It can distinguish synthetic\nimages with high accuracy while offering coherent and insightful explanations,\nfree-form discussions on fine-grained forgery attributes, and actionable\nenhancement strategies. Notably, despite being trained exclusively on\nqualitative hard labels, FakeScope demonstrates remarkable zero-shot\nquantitative capability on detection, enabled by our proposed token-based\nprobability estimation strategy. Furthermore, FakeScope exhibits strong\ngeneralization and in-the-wild ability, ensuring its applicability in\nreal-world scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:12:48Z"}
{"aid":"http://arxiv.org/abs/2503.24271v1","title":"Enhancing Image Resolution of Solar Magnetograms: A Latent Diffusion\n  Model Approach","summary":"The spatial properties of the solar magnetic field are crucial to decoding\nthe physical processes in the solar interior and their interplanetary effects.\nHowever, observations from older instruments, such as the Michelson Doppler\nImager (MDI), have limited spatial or temporal resolution, which hinders the\nability to study small-scale solar features in detail. Super resolving these\nolder datasets is essential for uniform analysis across different solar cycles,\nenabling better characterization of solar flares, active regions, and magnetic\nnetwork dynamics. In this work, we introduce a novel diffusion model approach\nfor Super-Resolution and we apply it to MDI magnetograms to match the\nhigher-resolution capabilities of the Helioseismic and Magnetic Imager (HMI).\nBy training a Latent Diffusion Model (LDM) with residuals on downscaled HMI\ndata and fine-tuning it with paired MDI/HMI data, we can enhance the resolution\nof MDI observations from 2\"/pixel to 0.5\"/pixel. We evaluate the quality of the\nreconstructed images by means of classical metrics (e.g., PSNR, SSIM, FID and\nLPIPS) and we check if physical properties, such as the unsigned magnetic flux\nor the size of an active region, are preserved. We compare our model with\ndifferent variations of LDM and Denoising Diffusion Probabilistic models\n(DDPMs), but also with two deterministic architectures already used in the past\nfor performing the Super-Resolution task. Furthermore, we show with an analysis\nin the Fourier domain that the LDM with residuals can resolve features smaller\nthan 2\", and due to the probabilistic nature of the LDM, we can asses their\nreliability, in contrast with the deterministic models. Future studies aim to\nsuper-resolve the temporal scale of the solar MDI instrument so that we can\nalso have a better overview of the dynamics of the old events.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM,cs.LG","published":"2025-03-31T16:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.24328v1","title":"Contextual Preference Collaborative Measure Framework Based on Belief\n  System","summary":"To reduce the human intervention in the preference measure process,this\narticle proposes a preference collaborative measure framework based on an\nupdated belief system,which is also capable of improving the accuracy and\nefficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\nthe average internal distance of rulesets are proposed for specifying the\nrelationship between the rules.For discovering the most representative\npreferences that are common in all users,namely common preference,a algorithm\nbased on average internal distance of ruleset,PRA algorithm,is proposed,which\naims to finish the discoveryprocess with minimum information loss\nrate.Furthermore,the concept of Common belief is proposed to update the belief\nsystem,and the common preferences are the evidences of updated belief\nsystem.Then,under the belief system,the proposed belief degree and deviation\ndegree are used to determine whether a rule confirms the belief system or not\nand classify the preference rules into two kinds(generalized or\npersonalized),and eventually filters out Top-K interesting rules relying on\nbelief degree and deviation degree.Based on above,a scalable interestingness\ncalculation framework that can apply various formulas is proposed for\naccurately calculating interestingness in different conditions.At last,IMCos\nalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\nand efficiency of the framework by using weighted cosine similarity and\ncorrelation coefficients as belief degree.In experiments,the proposed\nalgorithms are compared to two state-of-the-art algorithms and the results show\nthat IMCos and IMCov outperform than the other two in most aspects.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-03-31T17:17:45Z"}
{"aid":"http://arxiv.org/abs/2503.24333v1","title":"Mean field model of contagion processes in urban traffic networks","summary":"Theoretical arguments and empirical evidence for the emergence of macroscopic\nepidemic type behavior, in the form of Susceptible-Infected-Susceptible (SIS)\nor Susceptible-Infected-Recovered (SIR) processes in urban traffic congestion\nfrom microscopic network flows is given. Moreover, it's shown that the\nemergence of SIS/SIR implies a relationship between traffic flow and density,\nwhich is consistent with observations of the so called Fundamental Diagram of\nTraffic, which is a characteristic signature of vehicle movement phenomena that\nspans multiple scales. Our results provide a plausible explanation for this\nscale-spanning signature and put in more firm grounds recent findings that\nindicate that traffic congestion at the aggregate level can be modeled by\nsimple contagion dynamics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cond-mat.dis-nn","published":"2025-03-31T17:22:10Z"}
{"aid":"http://arxiv.org/abs/2503.24334v1","title":"Augmenting Expert Cognition in the Age of Generative AI: Insights from\n  Document-Centric Knowledge Work","summary":"As Generative AI (GenAI) capabilities expand, understanding how to preserve\nand develop human expertise while leveraging AI's benefits becomes increasingly\ncritical. Through empirical studies in two contexts -- survey article authoring\nin scholarly research and business document sensemaking -- we examine how\ndomain expertise shapes patterns of AI delegation and information processing\namong knowledge workers. Our findings reveal that while experts welcome AI\nassistance with repetitive information foraging tasks, they prefer to retain\ncontrol over complex synthesis and interpretation activities that require\nnuanced domain understanding. We identify implications for designing GenAI\nsystems that support expert cognition. These include enabling selective\ndelegation aligned with expertise levels, preserving expert agency over\ncritical analytical tasks, considering varying levels of domain expertise in\nsystem design, and supporting verification mechanisms that help users calibrate\ntheir reliance while deepening expertise. We discuss the inherent tension\nbetween reducing cognitive load through automation and maintaining the\ndeliberate practice necessary for expertise development. Lastly, we suggest\napproaches for designing systems that provide metacognitive support, moving\nbeyond simple task automation toward actively supporting expertise development.\nThis work contributes to our understanding of how to design AI systems that\naugment rather than diminish human expertise in document-centric workflows.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T17:22:20Z"}
{"aid":"http://arxiv.org/abs/2503.24347v1","title":"Entanglement Distribution in Lossy Quantum Networks","summary":"Entanglement distribution is essential for unlocking the potential of\ndistributed quantum information processing. We consider an $N$-partite network\nwhere entanglement is distributed via a central source over lossy channels, and\nnetwork participants cooperate to establish entanglement between any two chosen\nparties under local operations and classical communication (LOCC) constraints.\nWe develop a general mathematical framework to assess the optimal average\nbipartite entanglement shared in a lossy distribution, and introduce a\ntractable lower bound by optimizing over a subset of single-parameter LOCC\ntransformations. Our results show that probabilistically extracting Bell pairs\nfrom W states is more advantageous than deterministically extracting them from\nGHZ-like states in lossy networks, with this advantage increasing with network\nsize. We further extend our analysis analytically, proving that W states remain\nmore effective in large-scale networks. These findings offer valuable insights\ninto the practical deployment of near-term networks, revealing a fundamental\ntrade-off between deterministic entanglement distribution protocols and\nloss-sensitive resources.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:32:18Z"}
{"aid":"http://arxiv.org/abs/2503.24361v1","title":"Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic\n  Manipulation","summary":"Large real-world robot datasets hold great potential to train generalist\nrobot models, but scaling real-world human data collection is time-consuming\nand resource-intensive. Simulation has great potential in supplementing\nlarge-scale data, especially with recent advances in generative AI and\nautomated data generation tools that enable scalable creation of robot behavior\ndatasets. However, training a policy solely in simulation and transferring it\nto the real world often demands substantial human effort to bridge the reality\ngap. A compelling alternative is to co-train the policy on a mixture of\nsimulation and real-world datasets. Preliminary studies have recently shown\nthis strategy to substantially improve the performance of a policy over one\ntrained on a limited amount of real-world data. Nonetheless, the community\nlacks a systematic understanding of sim-and-real co-training and what it takes\nto reap the benefits of simulation data for real-robot learning. This work\npresents a simple yet effective recipe for utilizing simulation data to solve\nvision-based robotic manipulation tasks. We derive this recipe from\ncomprehensive experiments that validate the co-training strategy on various\nsimulation and real-world datasets. Using two domains--a robot arm and a\nhumanoid--across diverse tasks, we demonstrate that simulation data can enhance\nreal-world task performance by an average of 38%, even with notable differences\nbetween the simulation and real-world data. Videos and additional results can\nbe found at https://co-training.github.io/","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-03-31T17:39:38Z"}
{"aid":"http://arxiv.org/abs/2503.24372v1","title":"A criterion on the free energy for log-Sobolev inequalities in\n  mean-field particle systems","summary":"For a class of mean-field particle systems, we formulate a criterion in terms\nof the free energy that implies uniform bounds on the log-Sobolev constant of\nthe associated Langevin dynamics. For certain double-well potentials with\nquadratic interaction, the criterion holds up to the critical temperature of\nthe model, and we also obtain precise asymptotics on the decay of the\nlog-Sobolev constant when approaching the critical point. The criterion also\napplies to ``diluted'' mean-field models defined on sufficiently dense,\npossibly random graphs. We further generalize the criterion to non-quadratic\ninteractions that admit a mode decomposition. The mode decomposition is\ndifferent from the scale decomposition of the Polchinski flow we used for\nshort-range spin systems.","main_category":"math.PR","categories":"math.PR,math-ph,math.FA,math.MP","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24374v1","title":"ERUPT: Efficient Rendering with Unposed Patch Transformer","summary":"This work addresses the problem of novel view synthesis in diverse scenes\nfrom small collections of RGB images. We propose ERUPT (Efficient Rendering\nwith Unposed Patch Transformer) a state-of-the-art scene reconstruction model\ncapable of efficient scene rendering using unposed imagery. We introduce\npatch-based querying, in contrast to existing pixel-based queries, to reduce\nthe compute required to render a target view. This makes our model highly\nefficient both during training and at inference, capable of rendering at 600\nfps on commercial hardware. Notably, our model is designed to use a learned\nlatent camera pose which allows for training using unposed targets in datasets\nwith sparse or inaccurate ground truth camera pose. We show that our approach\ncan generalize on large real-world data and introduce a new benchmark dataset\n(MSVS-1M) for latent view synthesis using street-view imagery collected from\nMapillary. In contrast to NeRF and Gaussian Splatting, which require dense\nimagery and precise metadata, ERUPT can render novel views of arbitrary scenes\nwith as few as five unposed input images. ERUPT achieves better rendered image\nquality than current state-of-the-art methods for unposed image synthesis\ntasks, reduces labeled data requirements by ~95\\% and decreases computational\nrequirements by an order of magnitude, providing efficient novel view synthesis\nfor diverse real-world scenes.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:53:05Z"}
{"aid":"http://arxiv.org/abs/2503.24380v1","title":"The fundamental localization phases in quasiperiodic systems: A unified\n  framework and exact results","summary":"The disordered quantum systems host three types of quantum states, the\nextended, localized, and critical, which bring up various distinct fundamental\nphases, including the pure phases and coexisting ones with mobility edges. The\nquantum phases involving critical states are of particular importance, but are\nless understood compared with the other ones, and the different phases have\nbeen separately studied in different quasiperiodic models. Here we propose a\nunified framework based on a spinful quasiperiodic system which unifies the\nrealizations of all the fundamental Anderson phases, %with or without mobility\nedges, with the exact and universal results being obtained for these distinct\nphases. Through the duality transformation and renormalization group method, we\nshow that the pure phases are obtained when the (emergent) chiral symmetry\npreserves in the proposed spin-1/2 quasiperiodic model, which provides a\ncriteria for the emergence of the pure phases or the coexisting ones with\nmobility edges. Further, we uncover a new universal mechanism for the critical\nstates that the emergence of such states is protected by the generalized\nincommensurate matrix element zeros in the spinful quasiperiodic model, as a\nnovel generalization of the quasiperiodic hopping zeros in the spinless\nsystems. We also show with the Avila's global theory the criteria of exact\nsolvability for the present unified quasiperiodic system, with which we\nidentify several new quasiperiodic models derived from the spinful system\nhosting exactly solvable Anderson phases. In particular, we reach a single\nmodel that hosts all the seven fundamental phases of Anderson localization.\nFinally, an experimental scheme is proposed to realize these models using\nquasiperiodic optical Raman lattices.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-03-31T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.01328v1","title":"Slow-Fast Architecture for Video Multi-Modal Large Language Models","summary":"Balancing temporal resolution and spatial detail under limited compute budget\nremains a key challenge for video-based multi-modal large language models\n(MLLMs). Existing methods typically compress video representations using\npredefined rules before feeding them into the LLM, resulting in irreversible\ninformation loss and often ignoring input instructions. To address this, we\npropose a novel slow-fast architecture that naturally circumvents this\ntrade-off, enabling the use of more input frames while preserving spatial\ndetails. Inspired by how humans first skim a video before focusing on relevant\nparts, our slow-fast design employs a dual-token strategy: 1) \"fast\" visual\ntokens -- a compact set of compressed video features -- are fed into the LLM\nalongside text embeddings to provide a quick overview; 2) \"slow\" visual tokens\n-- uncompressed video features -- are cross-attended by text embeddings through\nspecially designed hybrid decoder layers, enabling instruction-aware extraction\nof relevant visual details with linear complexity. We conduct systematic\nexploration to optimize both the overall architecture and key components.\nExperiments show that our model significantly outperforms self-attention-only\nbaselines, extending the input capacity from 16 to 128 frames with just a 3%\nincrease in computation, and achieving a 16% average performance improvement\nacross five video understanding benchmarks. Our 7B model achieves\nstate-of-the-art performance among models of similar size. Furthermore, our\nslow-fast architecture is a plug-and-play design that can be integrated into\nother video MLLMs to improve efficiency and scalability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T03:24:58Z"}
{"aid":"http://arxiv.org/abs/2504.01338v1","title":"FlowMotion: Target-Predictive Flow Matching for Realistic Text-Driven\n  Human Motion Generation","summary":"Achieving highly diverse and perceptually consistent 3D character animations\nwith natural motion and low computational costs remains a challenge in computer\nanimation. Existing methods often struggle to provide the nuanced complexity of\nhuman movement, resulting in perceptual inconsistencies and motion artifacts.\nTo tackle these issues, we introduce FlowMotion, a novel approach that\nleverages Conditional Flow Matching (CFM) for improved motion synthesis.\nFlowMotion incorporates an innovative training objective that more accurately\npredicts target motion, reducing the inherent jitter associated with CFM while\nenhancing stability, realism, and computational efficiency in generating\nanimations. This direct prediction approach enhances the perceptual quality of\nanimations by reducing erratic motion and aligning the training more closely\nwith the dynamic characteristics of human movement. Our experimental results\ndemonstrate that FlowMotion achieves higher balance between motion smoothness\nand generalization capability while maintaining the computational efficiency\ninherent in flow matching compared to state-of-the-art methods.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T03:55:21Z"}
{"aid":"http://arxiv.org/abs/2504.01340v1","title":"Local conformal symmetry and anomalies with antisymmetric tensor field","summary":"We consider the trace anomaly, which results from the integration of the\nmassless conformal fermion field with the background of metric and\nantisymmetric tensor fields. The non-local terms in the anomaly-induced\neffective action do not depend on the scheme of quantum calculations. On the\nother hand, total derivative terms in the anomaly and the corresponding local\npart of the induced action manifest scheme dependence and multiplicative\nanomaly.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-02T04:10:12Z"}
{"aid":"http://arxiv.org/abs/2504.01363v1","title":"Embedding Higman-Thompson groups of unfolding trees into the Leavitt\n  path algebras","summary":"The isomorphism problem of regular Higman-Thompson groups was solved in\narXiv:1006.1759, via embedding it into the Leavitt algebra. In this paper, we\nwill expand these results to embed the Higman-Thompson groups of unfolding\ntrees of directed graphs into the Leavitt path algebra. This embedding allows\nus to show that any isomorphism of rooted Leavitt path algebras induces an\nisomorphism between Higman-Thompson groups.","main_category":"math.RA","categories":"math.RA,math.GR","published":"2025-04-02T05:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.01383v1","title":"v-CLR: View-Consistent Learning for Open-World Instance Segmentation","summary":"In this paper, we address the challenging problem of open-world instance\nsegmentation. Existing works have shown that vanilla visual networks are biased\ntoward learning appearance information, \\eg texture, to recognize objects. This\nimplicit bias causes the model to fail in detecting novel objects with unseen\ntextures in the open-world setting. To address this challenge, we propose a\nlearning framework, called view-Consistent LeaRning (v-CLR), which aims to\nenforce the model to learn appearance-invariant representations for robust\ninstance segmentation. In v-CLR, we first introduce additional views for each\nimage, where the texture undergoes significant alterations while preserving the\nimage's underlying structure. We then encourage the model to learn the\nappearance-invariant representation by enforcing the consistency between object\nfeatures across different views, for which we obtain class-agnostic object\nproposals using off-the-shelf unsupervised models that possess strong\nobject-awareness. These proposals enable cross-view object feature matching,\ngreatly reducing the appearance dependency while enhancing the\nobject-awareness. We thoroughly evaluate our method on public benchmarks under\nboth cross-class and cross-dataset settings, achieving state-of-the-art\nperformance. Project page: https://visual-ai.github.io/vclr","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T05:52:30Z"}
{"aid":"http://arxiv.org/abs/2504.01410v1","title":"The Interstellar Medium","summary":"The interstellar medium (ISM) is the material that fills the space between\nthe stars in all galaxies; it is a multi-phase medium in pressure equilibrium,\nwith densities and temperatures covering over 6 orders of magnitude. Although\naccounting for only a small fraction of the mass of any given galaxy, it is a\nvital component, since it holds the material responsible for galaxy growth\nthrough star formation. Studying the ISM requires careful observations at all\nwavelengths of the electromagnetic spectrum. This article describes the\nmulti-phase nature of the ISM, and then puts it in the context of galaxy\nevolution models, emphasising the importance of the cycling of baryons in and\nout of galaxies. Within this framework, the ISM plays a central role: it\nconnects the physical processes operating on very large physical- and\ntime-scales which control the accretion of gas onto galaxies, and the small\nscale processes that regulate star formation.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T06:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.01425v1","title":"Asymptotic stability and exponential stability for a class of impulsive\n  neutral differential equations with discrete and distributed delays","summary":"In this paper, we present sufficient conditions for asymptotic stability and\nexponential stability of a class of impulsive neutral differential equations\nwith discrete and distributed delays. Our approaches are based on the method\nusing fixed point theory, which do not resort to any Lyapunov functions or\nLyapunov functionals. Our conditions do not require the differentiability of\ndelays, nor do they ask for a fixed sign on the coefficient functions. Our\nresults improve some previous ones in the literature. Examples are given to\nillustrate our main results.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T07:22:03Z"}
{"aid":"http://arxiv.org/abs/2504.01442v1","title":"Coarse-to-Fine Semantic Communication Systems for Text Transmission","summary":"Achieving more powerful semantic representations and semantic understanding\nis one of the key problems in improving the performance of semantic\ncommunication systems. This work focuses on enhancing the semantic\nunderstanding of the text data to improve the effectiveness of semantic\nexchange. We propose a novel semantic communication system for text\ntransmission, in which the semantic understanding is enhanced by coarse-to-fine\nprocessing. Especially, a dual attention mechanism is proposed to capture both\nthe coarse and fine semantic information. Numerical experiments show the\nproposed system outperforms the benchmarks in terms of bilingual evaluation,\nsentence similarity, and robustness under various channel conditions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T07:50:35Z"}
{"aid":"http://arxiv.org/abs/2504.01476v1","title":"Enhanced Cross-modal 3D Retrieval via Tri-modal Reconstruction","summary":"Cross-modal 3D retrieval is a critical yet challenging task, aiming to\nachieve bi-directional retrieval between 3D and text modalities. Current\nmethods predominantly rely on a certain 3D representation (e.g., point cloud),\nwith few exploiting the 2D-3D consistency and complementary relationships,\nwhich constrains their performance. To bridge this gap, we propose to adopt\nmulti-view images and point clouds to jointly represent 3D shapes, facilitating\ntri-modal alignment (i.e., image, point, text) for enhanced cross-modal 3D\nretrieval. Notably, we introduce tri-modal reconstruction to improve the\ngeneralization ability of encoders. Given point features, we reconstruct image\nfeatures under the guidance of text features, and vice versa. With well-aligned\npoint cloud and multi-view image features, we aggregate them as multimodal\nembeddings through fine-grained 2D-3D fusion to enhance geometric and semantic\nunderstanding. Recognizing the significant noise in current datasets where many\n3D shapes and texts share similar semantics, we employ hard negative\ncontrastive training to emphasize harder negatives with greater significance,\nleading to robust discriminative embeddings. Extensive experiments on the\nText2Shape dataset demonstrate that our method significantly outperforms\nprevious state-of-the-art methods in both shape-to-text and text-to-shape\nretrieval tasks by a substantial margin.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:29:42Z"}
{"aid":"http://arxiv.org/abs/2504.01535v1","title":"On Robust Empirical Likelihood for Nonparametric Regression with\n  Application to Regression Discontinuity Designs","summary":"Empirical likelihood serves as a powerful tool for constructing confidence\nintervals in nonparametric regression and regression discontinuity designs\n(RDD). The original empirical likelihood framework can be naturally extended to\nthese settings using local linear smoothers, with Wilks' theorem holding only\nwhen an undersmoothed bandwidth is selected. However, the generalization of\nbias-corrected versions of empirical likelihood under more realistic conditions\nis non-trivial and has remained an open challenge in the literature. This paper\nprovides a satisfactory solution by proposing a novel approach, referred to as\nrobust empirical likelihood, designed for nonparametric regression and RDD. The\ncore idea is to construct robust weights which simultaneously achieve bias\ncorrection and account for the additional variability introduced by the\nestimated bias, thereby enabling valid confidence interval construction without\nextra estimation steps involved. We demonstrate that the Wilks' phenomenon\nstill holds under weaker conditions in nonparametric regression, sharp and\nfuzzy RDD settings. Extensive simulation studies confirm the effectiveness of\nour proposed approach, showing superior performance over existing methods in\nterms of coverage probabilities and interval lengths. Moreover, the proposed\nprocedure exhibits robustness to bandwidth selection, making it a flexible and\nreliable tool for empirical analyses. The practical usefulness is further\nillustrated through applications to two real datasets.","main_category":"math.ST","categories":"math.ST,econ.EM,stat.ME,stat.TH","published":"2025-04-02T09:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.01546v1","title":"From indirect to direct taxis by fast reaction limit","summary":"Many ecological population models consider taxis as the directed movement of\nanimals in response to a stimulus. The taxis is named direct if the animals are\nguided by the density gradient of some other population or indirect if they are\nguided by the density of a chemical secreted by individuals of the other\npopulation. Let $u$ and $v$ denote the densities of two populations and $w$ the\ndensity of the chemical secreted by individuals in the $v$ population. We\nconsider a bounded, open set $\\Omega \\subset \\mathbb{R}^N$ with regular\nboundary and prove that for the space dimension $N\\leq 2$ the solution to the\nLotka-Volterra competition model with repulsive indirect taxis and homogeneous\nNeumann boundary conditions\n  $$u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla w +\\mu_1u(1-u-a_1v)\\,,$$\n  $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,,$$\n  $$\\varepsilon ( w_t - d_w\\Delta w )= v- w\\, , $$ converges to the solution of\nrepulsive direct-taxis model: $$ u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla\nv +\\mu_1u(1-u-a_1v)\\,,$$ $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,$$ when\n$\\varepsilon\\longrightarrow 0$. For space dimension $N\\geq 3$ we use the\ncompactness argument to show that the result holds in some weak sense. A\nsimilar result is also proved for a typical prey-predator model with prey taxis\nand logistic growth of predators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T09:40:34Z"}
{"aid":"http://arxiv.org/abs/2504.01571v1","title":"Pro-DG: Procedural Diffusion Guidance for Architectural Facade\n  Generation","summary":"We present Pro-DG, a framework for procedurally controllable photo-realistic\nfacade generation that combines a procedural shape grammar with diffusion-based\nimage synthesis. Starting from a single input image, we reconstruct its facade\nlayout using grammar rules, then edit that structure through user-defined\ntransformations. As facades are inherently multi-hierarchical structures, we\nintroduce hierarchical matching procedure that aligns facade structures at\ndifferent levels which is used to introduce control maps to guide a generative\ndiffusion pipeline. This approach retains local appearance fidelity while\naccommodating large-scale edits such as floor duplication or window\nrearrangement. We provide a thorough evaluation, comparing Pro-DG against\ninpainting-based baselines and synthetic ground truths. Our user study and\nquantitative measurements indicate improved preservation of architectural\nidentity and higher edit accuracy. Our novel method is the first to integrate\nneuro-symbolically derived shape-grammars for modeling with modern generative\nmodel and highlights the broader potential of such approaches for precise and\ncontrollable image manipulation.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG","published":"2025-04-02T10:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.01595v1","title":"JWST MIRI reveals the diversity of nuclear mid-infrared spectra of\n  nearby type-2 quasars","summary":"Type-2 quasars (QSO2s) are active galactic nuclei (AGN) seen through a\nsignificant amount of dust and gas that obscures the central supermassive black\nhole and the broad line region. Here we present new mid-infrared spectra of the\ncentral kiloparsec of five optically-selected QSO2s at redshift z~0.1 obtained\nwith JWST/MIRI/MRS. These QSO2s belong to the QSOFEED sample and they have log\nLbol=45.5-46.0 erg/s, global SFRs that place them above the main sequence, and\npractically identical optical spectral shape and [OIII] luminosity, but their\nnuclear mid-infrared spectra exhibit an unexpected diversity of both continua\nand features. They show: 1) 9.7 micron silicate features going from emission\n(strength of S9.7=0.5) to relatively strong absorption (S9.7=-1.0) and 18 and\n23 micron silicates either in emission or flat. In addition, two of the QSO2s\nshow absorption bands of CO, H2O, and aliphatic grains, indicating different\nlevels of nuclear obscuration across the sample. 2) [NeV]/[NeII] ratios ranging\nfrom 0.1 to 2.1 and [NeIII]/[NeII] from 1.0 to 3.5, indicating different\ncoronal line and ionizing continuum strengths. 3) Warm molecular gas masses of\n1-4x10^7 Msun and warm-to-cold gas mass ratios of 1-2%, with molecular gas\nexcitation likely due to jet-induced shocks in J1430+1339, and to UV heating\nand/or turbulence in J1509+0434. 4) PAH emission features with equivalent\nwidths ranging from <0.002 to 0.075 micron, from which we measure a larger\ncontribution from neutral molecules (PAH 11.3/6.2=1.3-3.4) and SFRs<3-7\nMsun/yr. This unprecedented dataset allowed us to start exploring the role of\nvarious AGN and galaxy properties including ionizing continuum, obscuration,\nelectron density, and jet-ISM interactions on some of the spectral differences\nlisted above, but larger samples are now required to fully understand the\ndiversity of QSO2s' nuclear mid-infrared spectra.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T11:02:01Z"}
{"aid":"http://arxiv.org/abs/2504.01630v1","title":"On the performance of the Euler-Maruyama scheme for multidimensional\n  SDEs with discontinuous drift coefficient","summary":"We study strong approximation of $d$-dimensional stochastic differential\nequations (SDEs) with a discontinuous drift coefficient. More precisely, we\nessentially assume that the drift coefficient is piecewise Lipschitz continuous\nwith an exceptional set $\\Theta\\subset \\mathbb{R}^d$ that is an orientable\n$C^4$-hypersurface of positive reach, the diffusion coefficient is assumed to\nbe Lipschitz continuous and, in a neighborhood of $\\Theta$, both coefficients\nare bounded and the diffusion coefficient has a non-degenerate portion\northogonal to $\\Theta$.\n  In recent years, a number of results have been proven in the literature for\nstrong approximation of such SDEs and, in particular, the performance of the\nEuler-Maruyama scheme was studied. For $d=1$ and finite $\\Theta$ it was shown\nthat the Euler-Maruyama scheme achieves an $L_p$-error rate of at least $1/2$\nfor all $p\\geq 1$ as in the classical case of Lipschitz continuous\ncoefficients. For $d>1$, it was only known so far, that the Euler-Maruyama\nscheme achieves an $L_2$-error rate of at least $1/4-$ if, additionally, the\ncoefficients $\\mu$ and $\\sigma$ are globally bounded.\n  In this article, we prove that in the above setting the Euler-Maruyama scheme\nin fact achieves an $L_{p}$-error rate of at least $1/2-$ for all\n$d\\in\\mathbb{N}$ and all $p\\geq 1$. The proof of this result is based on the\nwell-known approach of transforming such an SDE into an SDE with globally\nLipschitz continuous coefficients, a new It\\^{o} formula for a class of\nfunctions which are not globally $C^2$ and a detailed analysis of the expected\ntotal time that the actual position of the time-continuous Euler-Maruyama\nscheme and its position at the preceding time point on the underlying grid are\non 'different sides' of the hypersurface $\\Theta$.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR","published":"2025-04-02T11:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.01636v1","title":"Dataset and Methodology for Material Identification and virtual s-SNOM\n  Using AFM Phase Approach Curves","summary":"Atomic force microscopy (AFM) phase approach-curves have significant\npotential for nanoscale material characterization, however, the availability of\nrobust datasets and automated analysis tools has been limited. In this paper,\nwe introduce a novel methodology for material identification using a\nhigh-dimensional dataset consisting of AFM phase approach-curves collected from\nfive distinct materials: silicon, silicon dioxide, platinum, silver, and gold.\nEach measurement comprises 50 phase values obtained at progressively increasing\ntip-sample distances, resulting in 50x50x50 voxel images that represent phase\nvariations at different depths. Using this dataset, we compare k-nearest\nneighbors (KNN), random forest (RF), and feedforward neural network (FNN)\nmethods for material segmentation. Our results indicate that the FNN provides\nthe highest accuracy and F1 score, outperforming more traditional approaches.\nFinally, we demonstrate the practical value of these segmented maps by\ngenerating virtual scattering-type scanning near-field optical microscopy\n(s-SNOM) images, highlighting how AFM phase approach-curves can be leveraged to\nproduce detailed, predictive tools for nanoscale optical analysis.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-02T11:42:03Z"}
{"aid":"http://arxiv.org/abs/2504.01645v1","title":"How to write competitive proposals and job applications","summary":"Writing proposals and job applications is arguably one of the most important\ntasks in the career of a scientist. The proposed ideas must be scientifically\ncompelling, but how a proposal is planned, written, and presented can make an\nenormous difference. This Perspective is the third in a series aimed at\ntraining the writing skills of professional astronomers. In the first two\npapers we concentrated on the writing of papers, here we concentrate on how\nproposals and job applications can be optimally written and presented. We\ndiscuss how to select where to propose or apply, how to optimise your writing,\nand add notes on the potential use of artificial intelligence tools. This guide\nis aimed primarily at more junior researchers, but we hope that our\nobservations and suggestions may also be helpful for more experienced\napplicants, as well as for reviewers and funding agencies.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.ed-ph","published":"2025-04-02T11:53:45Z"}
{"aid":"http://arxiv.org/abs/2504.01651v1","title":"Nonlinear electrodynamic black holes and their role in testing modified\n  theories of gravity","summary":"The nature of black holes (BHs) and potential deviations from General\nRelativity (GR) remain key questions in astrophysics. Nonlinear electrodynamics\n(NED) offers a mechanism for constructing regular BHs that evade singularities.\nWe perform a geometrical and observational analysis of NED-inspired BHs,\nconstraining the magnetic parameter via Bayesian inference using EHT data,\nobtaining \\( q = 0.98^{+0.09}_{-0.08} \\) for M87* and \\( q = 1.10\\pm0.10 \\) for\nSgr A*. Deviations from Schwarzschild BHs manifest in horizon structure, shadow\nproperties, and lensing effects. We analyze BH shadows under plasma conditions,\nidentifying imprints of NED on strong-field processes. Future observations from\nLISA, next-generation X-ray telescopes, and EHT will further constrain these\ndeviations and provide tests for alternative gravity theories.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T12:00:35Z"}
{"aid":"http://arxiv.org/abs/2504.01655v1","title":"Q-Adapt: Adapting LMM for Visual Quality Assessment with Progressive\n  Instruction Tuning","summary":"The rapid advancement of Large Multi-modal Foundation Models (LMM) has paved\nthe way for the possible Explainable Image Quality Assessment (EIQA) with\ninstruction tuning from two perspectives: overall quality explanation, and\nattribute-wise perception answering. However, existing works usually overlooked\nthe conflicts between these two types of perception explanations during joint\ninstruction tuning, leading to insufficient perception understanding. To\nmitigate this, we propose a new paradigm for perception-oriented instruction\ntuning, i.e., Q-Adapt, which aims to eliminate the conflicts and achieve the\nsynergy between these two EIQA tasks when adapting LMM, resulting in enhanced\nmulti-faceted explanations of IQA. Particularly, we propose a progressive\ninstruction tuning strategy by dividing the adaption process of LMM for EIQA\ninto two stages, where the first stage empowers the LMM with universal\nperception knowledge tailored for two tasks using an efficient transfer\nlearning strategy, i.e., LoRA, and the second stage introduces the\ninstruction-adaptive visual prompt tuning to dynamically adapt visual features\nfor the different instructions from two tasks. In this way, our proposed\nQ-Adapt can achieve a lightweight visual quality evaluator, demonstrating\ncomparable performance and, in some instances, superior results across\nperceptual-related benchmarks and commonly-used IQA databases. The source code\nis publicly available at https://github.com/yeppp27/Q-Adapt.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-02T12:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.01670v1","title":"Introduction to dimensional reduction of fermions","summary":"We present a comprehensive pedagogical introduction to the dimensional\nreduction protocol (DRP), a versatile framework for analyzing instabilities and\ncritical points in interacting fermionic systems. The DRP simplifies the study\nof many-body problems by systematically reducing their effective spatial\ndimension while retaining essential physics. This method works for electron\ngases in a diverse array of settings: in any number of spatial dimensions, in\nthe presence of Zeeman fields, with spin-orbit coupling, including repulsive or\nattractive interactions. Focusing on two-point correlation functions, the DRP\nidentifies a minimal subspace relevant for capturing analytic properties,\nfacilitating efficient computation of critical phenomena in electronic systems.\nThis work outlines the assumptions, proof, and applications of the DRP,\nemphasizing its simplicity and broad applicability for future studies in\ncorrelated electron physics.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-02T12:17:49Z"}
{"aid":"http://arxiv.org/abs/2504.01689v1","title":"InvFussion: Bridging Supervised and Zero-shot Diffusion for Inverse\n  Problems","summary":"Diffusion Models have demonstrated remarkable capabilities in handling\ninverse problems, offering high-quality posterior-sampling-based solutions.\nDespite significant advances, a fundamental trade-off persists, regarding the\nway the conditioned synthesis is employed: Training-based methods achieve high\nquality results, while zero-shot approaches trade this with flexibility. This\nwork introduces a framework that combines the best of both worlds -- the strong\nperformance of supervised approaches and the flexibility of zero-shot methods.\nThis is achieved through a novel architectural design that seamlessly\nintegrates the degradation operator directly into the denoiser. In each block,\nour proposed architecture applies the degradation operator on the network\nactivations and conditions the output using the attention mechanism, enabling\nadaptation to diverse degradation scenarios while maintaining high performance.\nOur work demonstrates the versatility of the proposed architecture, operating\nas a general MMSE estimator, a posterior sampler, or a Neural Posterior\nPrincipal Component estimator. This flexibility enables a wide range of\ndownstream tasks, highlighting the broad applicability of our framework. The\nproposed modification of the denoiser network offers a versatile, accurate, and\ncomputationally efficient solution, demonstrating the advantages of dedicated\nnetwork architectures for complex inverse problems. Experimental results on the\nFFHQ and ImageNet datasets demonstrate state-of-the-art posterior-sampling\nperformance, surpassing both training-based and zero-shot alternatives.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.01722v1","title":"{GSR4B}: Biomass Map Super-Resolution with Sentinel-1/2 Guidance","summary":"Accurate Above-Ground Biomass (AGB) mapping at both large scale and high\nspatio-temporal resolution is essential for applications ranging from climate\nmodeling to biodiversity assessment, and sustainable supply chain monitoring.\nAt present, fine-grained AGB mapping relies on costly airborne laser scanning\nacquisition campaigns usually limited to regional scales. Initiatives such as\nthe ESA CCI map attempt to generate global biomass products from diverse\nspaceborne sensors but at a coarser resolution. To enable global,\nhigh-resolution (HR) mapping, several works propose to regress AGB from HR\nsatellite observations such as ESA Sentinel-1/2 images. We propose a novel way\nto address HR AGB estimation, by leveraging both HR satellite observations and\nexisting low-resolution (LR) biomass products. We cast this problem as Guided\nSuper-Resolution (GSR), aiming at upsampling LR biomass maps (sources) from\n$100$ to $10$ m resolution, using auxiliary HR co-registered satellite images\n(guides). We compare super-resolving AGB maps with and without guidance,\nagainst direct regression from satellite images, on the public BioMassters\ndataset. We observe that Multi-Scale Guidance (MSG) outperforms direct\nregression both for regression ($-780$ t/ha RMSE) and perception ($+2.0$ dB\nPSNR) metrics, and better captures high-biomass values, without significant\ncomputational overhead. Interestingly, unlike the RGB+Depth setting they were\noriginally designed for, our best-performing AGB GSR approaches are those that\nmost preserve the guide image texture. Our results make a strong case for\nadopting the GSR framework for accurate HR biomass mapping at scale. Our code\nand model weights are made publicly available\n(https://github.com/kaankaramanofficial/GSR4B).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.01741v1","title":"Quantum Quintom Cosmology","summary":"This work applies the principles of quantum cosmology to examine models\nincorporating a quintom field. Specifically, three distinct models are\nanalyzed: a simplified toy model, a model featuring an exponential quintom\npotential, and one where the quintom field is coupled with a negative\ncosmological constant. For each case, we study the classical trajectories\nwithin the configuration space, present solutions to the Wheeler-DeWitt\nequation in quantum cosmology, and discuss physical interpretations and\nconsequences. A key focus is the behavior of wave packets in the minisuperspace\nframework. Notably, the correspondence principle (connection between classical\nand quantum solutions) is also demonstrated.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T13:52:26Z"}
{"aid":"http://arxiv.org/abs/2504.01746v1","title":"Spans of quantum-inequality projections","summary":"A hereditarily atomic von Neumann algebra $A$ is a $W^*$ product of matrix\nalgebras, regarded as the underlying function algebra of a quantum set.\nProjections in $A\\overline{\\otimes}A^{\\circ}$ are interpreted as quantum binary\nrelations on $A$, with the supremum of all $p\\otimes (1-p)$ representing\nquantum inequality. We prove that the symmetrized weak$^*$-closed linear span\nof all such quantum-inequality projections is precisely the symmetric summand\nof the joint kernel of multiplication and opposite multiplication, a result\nvalid without the symmetrization qualification for plain matrix algebras. The\nproof exploits the symmetries of the spaces involved under the compact unitary\ngroup of $A$, and related results include a classification of those von Neumann\nalgebras (hereditarily atomic or not) for which the unitary group operates\njointly continuously with respect to the weak$^*$ topology.","main_category":"math.OA","categories":"math.OA,math.FA,math.QA,math.RA,math.RT","published":"2025-04-02T13:57:34Z"}
{"aid":"http://arxiv.org/abs/2504.01750v1","title":"Probing the Distance Duality Relation with Machine Learning and Recent\n  Data","summary":"The distance duality relation (DDR) relates two independent ways of measuring\ncosmological distances, namely the angular diameter distance and the luminosity\ndistance. These can be measured with baryon acoustic oscillations (BAO) and\nType Ia supernovae (SNe Ia), respectively. Here, we use recent DESI DR1,\nPantheon+, SH0ES and DES-SN5YR data to test this fundamental relation. We\nemploy a parametrised approach and also use model-independent Generic\nAlgorithms (GA), which are a machine learning method where functions evolve\nloosely based on biological evolution. When we use DESI and Pantheon+ data\nwithout Cepheid calibration or big bang nucleosynthesis (BBN), there is a\n$2\\sigma$ violation of the DDR in the parametrised approach. Then, we add\nhigh-redshift BBN data and the low-redshift SH0ES Cepheid calibration. This\nreflects the Hubble tension since both data sets are in tension in the standard\ncosmological model $\\Lambda$CDM. In this case, we find a significant violation\nof the DDR in the parametrised case at $6\\sigma$. Replacing the Pantheon+ SNe\nIa data by DES-SN5YR, we find similar results. For the model-independent\napproach, we find no deviation in the uncalibrated case and a small deviation\nwith BBN and Cepheids which remains at 1$\\sigma$. This shows the importance of\nconsidering model-independent approaches for the DDR.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T14:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.01759v1","title":"Hidden Markov Model Filtering with Equal Exit Probabilities","summary":"Hidden Markov Models (HMMs) provide a rigorous framework for inference in\ndynamic environments. In this work, we study the alpha-HMM algorithm motivated\nby the optimal online filtering formulation in settings where the true state\nevolves as a Markov chain with equal exit probabilities. We quantify the\ndynamics of the algorithm in stationary environments, revealing a trade-off\nbetween inference and adaptation, showing how key parameters and the quality of\nobservations affect performance. Comprehensive theoretical analysis on the\nnonlinear dynamical system that governs the evolution of the log-belief ratio\nover time and numerical experiments demonstrate that the proposed approach\neffectively balances adaptation and inference performance.","main_category":"eess.SY","categories":"eess.SY,cs.SY,stat.AP","published":"2025-04-02T14:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.01761v1","title":"Non-parametric Quantile Regression and Uniform Inference with Unknown\n  Error Distribution","summary":"This paper studies the non-parametric estimation and uniform inference for\nthe conditional quantile regression function (CQRF) with covariates exposed to\nmeasurement errors. We consider the case that the distribution of the\nmeasurement error is unknown and allowed to be either ordinary or super smooth.\nWe estimate the density of the measurement error by the repeated measurements\nand propose the deconvolution kernel estimator for the CQRF. We derive the\nuniform Bahadur representation of the proposed estimator and construct the\nuniform confidence bands for the CQRF, uniformly in the sense for all\ncovariates and a set of quantile indices, and establish the theoretical\nvalidity of the proposed inference. A data-driven approach for selecting the\ntuning parameter is also included. Monte Carlo simulations and a real data\napplication demonstrate the usefulness of the proposed method.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-02T14:16:39Z"}
{"aid":"http://arxiv.org/abs/2504.01770v1","title":"$\\mathbf{Î³^{(*)} + N(940)\\frac{1}{2}^+ \\to N(1520)\\frac{3}{2}^{-}}$\n  helicity amplitudes and transition form factors","summary":"We recently reported new results on the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+\n\\to \\Delta(1700)\\frac{3}{2}^{-}$ transition form factors using a\nsymmetry-preserving treatment of a vector$\\,\\otimes\\,$vector contact\ninteraction (SCI) within a coupled formalism based on the Dyson-Schwinger,\nBethe-Salpeter, and Faddeev equations. In this work, we extend our\ninvestigation to the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+ \\to\nN(1520)\\frac{3}{2}^{-}$ transition. Our computed transition form factors show\nreasonable agreement with experimental data at large photon virtualities.\nHowever, deviations emerge at low $Q^2$, where experimental results exhibit a\nsharper variation than theoretical predictions. This discrepancy is expected,\nas these continuum QCD analyses account only for the quark-core of baryons,\nwhile low photon virtualities are dominated by meson cloud effects. We\nanticipate that these analytical predictions, based on the simplified SCI\nframework, will serve as a valuable benchmark for more refined studies and\nQCD-based truncations that incorporate quark angular momentum and the\ncontributions of scalar and vector diquarks.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat,hep-th,nucl-th","published":"2025-04-02T14:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.01780v1","title":"Finiteness and duality of cohomology of $(\\varphi,Î“)$-modules and\n  the 6-functor formalism of locally analytic representations","summary":"Finiteness and duality of cohomology of families of\n$(\\varphi,\\Gamma)$-modules were proved by Kedlaya-Pottharst-Xiao. In this\npaper, we study solid locally analytic representations introduced by Rodrigues\nJacinto-Rodr\\'iguez Camargo in terms of analytic stacks and 6-functor\nformalisms, which are developed by Clausen-Scholze, Heyer-Mann, respectively.\nBy using this, we will provide a generalization of the result of\nKedlaya-Pottharst-Xiao, giving a new proof for cases already proved there.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T14:45:45Z"}
{"aid":"http://arxiv.org/abs/2504.01786v1","title":"BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing","summary":"3D graphics editing is crucial in applications like movie production and game\ndesign, yet it remains a time-consuming process that demands highly specialized\ndomain expertise. Automating this process is challenging because graphical\nediting requires performing a variety of tasks, each requiring distinct skill\nsets. Recently, vision-language models (VLMs) have emerged as a powerful\nframework for automating the editing process, but their development and\nevaluation are bottlenecked by the lack of a comprehensive benchmark that\nrequires human-level perception and presents real-world editing complexity. In\nthis work, we present BlenderGym, the first comprehensive VLM system benchmark\nfor 3D graphics editing. BlenderGym evaluates VLM systems through code-based 3D\nreconstruction tasks. We evaluate closed- and open-source VLM systems and\nobserve that even the state-of-the-art VLM system struggles with tasks\nrelatively easy for human Blender users. Enabled by BlenderGym, we study how\ninference scaling techniques impact VLM's performance on graphics editing\ntasks. Notably, our findings reveal that the verifier used to guide the scaling\nof generation can itself be improved through inference scaling, complementing\nrecent insights on inference scaling of LLM generation in coding and math\ntasks. We further show that inference compute is not uniformly effective and\ncan be optimized by strategically distributing it between generation and\nverification.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T14:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.01809v1","title":"Detector Response to Gravitational Wave Polarizations in Gravitational\n  Quantum Field Theory","summary":"We present an analysis of gravitational wave polarization modes within\nGravitational Quantum Field Theory (GQFT), a unified theoretical framework\nreconciling general relativity and quantum field theory. Our study focuses on\nfive fundamental polarization states predicted in GQFT: two tensor ($+,\n\\times$), two vector (x, y), and one scalar (breathing) mode, focusing on their\ndistinctive detection signatures in space-based interferometers like LISA and\nTaiji. Using first-order orbital dynamics in the Solar System Barycenter frame,\nwe identify three novel observational features: (1) characteristic interference\npatterns between polarization modes, (2) distinctive null-point signatures\nenabling mode discrimination, and (3) sky-position-dependent optimal detection\nwindows. Our approach provides complete sky coverage through polarization\nmapping while remaining fully compatible with existing mission designs, notably\navoiding the need for challenging direct breathing-mode measurements. The\nresults are presented through comprehensive sky maps, offering both theoretical\ninsights into gravitational wave polarization and practical tools for future\ndetector networks. This work establishes a new paradigm for testing fundamental\ngravity theories through their unique polarization fingerprints, with\nparticular relevance for upcoming multi-messenger gravitational wave astronomy.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-02T15:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.01841v1","title":"Garbage Collection for Rust: The Finalizer Frontier","summary":"Rust is a non-Garbage Collected (GCed) language, but the lack of GC makes\nexpressing data-structures that require shared ownership awkward, inefficient,\nor both. In this paper we explore a new design for, and implementation of, GC\nin Rust, called Alloy. Unlike previous approaches to GC in Rust, Alloy maps\nexisting Rust destructors to finalizers: this makes GC in Rust natural to use\nbut introduces surprising soundness, performance, and ergonomic problems. Alloy\nprovides solutions for each of these problems.","main_category":"cs.PL","categories":"cs.PL,D.3","published":"2025-04-02T15:46:58Z"}
{"aid":"http://arxiv.org/abs/2504.01858v1","title":"Investigating the Variable Continuum Lags in PG 2130+099","summary":"Broadband photometric reverberation mapping (RM) provides a measure of the\nsize of the continuum-emitting region in active galactic nuclei (AGN). Previous\nmonitoring campaigns of PG 2130+099 disagree as to whether the continuum\nemitting region size is consistent with that predicted for a standard optically\nthick geometrically thin accretion disk. We present $\\sim$6 months of\nobservations from several robotic telescopes, providing the highest cadence and\nwidest wavelength coverage photometric RM study of PG 2130+099 to date. Our\nresults indicate that inferred size of the continuum-emitting region in PG\n2130+099, like many recently observed AGN, is larger than the simplest\npredictions for an irradiated geometrically thin, optically thick accretion\ndisk. We also perform a flux-flux analysis, finding a variable spectrum broadly\nconsistent with a disk, and a constant component with enhanced\n$\\textit{i}$-band emission, potentially due to H$\\alpha$. We find some evidence\nof increasing lag with luminosity, but previous lag measurements are too\nuncertain to be definitive.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-02T16:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.01864v1","title":"On the $W$-entropy and Shannon entropy power on RCD$(K, N)$ and RCD$(K,\n  n, N)$ spaces","summary":"In this paper, we prove the $W$-entropy formula and its monotonicity for the\nheat flow on RCD$(K, N)$ and RCD$(K, n, N)$ spaces $(X, d, \\mu)$, where $K\\in\n\\mathbb{R}$, $n$ is the geometric dimension of $(X, d, \\mu)$ and $N\\geq n$. We\nalso prove the $K$-concavity of the Shannon entropy power on RCD$(K, N)$\nspaces. As an application, we derive the Shannon entropy isoperimetric\ninequality and the Stam logarithmic Sobolev inequality on RCD$(0, N)$ spaces\nwith maximal volume growth condition. Finally, we prove the rigidity theorem\nfor the Stam logarithmic Sobolev inequality with sharp constant on\nnoncollapsing RCD$(0, N)$ spaces.","main_category":"math.FA","categories":"math.FA,math.MG,math.PR","published":"2025-04-02T16:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.01876v1","title":"The TELOS Collaboration Approach to Reproducibility and Open Science","summary":"The TELOS Collaboration is committed to producing and analysing lattice data\nreproducibly, and sharing its research openly. In this document, we set out the\nways that we make this happen, where there is scope for improvement, and how we\nplan to achieve this. This is intended to work both as a statement of policy,\nand a guide to practice for those beginning to work with us. Some details and\nrecommendations are specific to the context in which the Collaboration works\n(such as references to requirements imposed by funders in the United Kingdom);\nhowever, most recommendations may serve as a template for other collaborations\nlooking to make their own work reproducible. Full tutorials on every aspect of\nreproducibility are beyond the scope of this document, but we refer to other\nresources for further information.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-02T16:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.01897v1","title":"Threshold for Fault-tolerant Quantum Advantage with the Quantum\n  Approximate Optimization Algorithm","summary":"Optimization is often cited as a promising application of quantum computers.\nHowever, the low degree of provable quantum speedups has led prior rigorous\nend-to-end resource analyses to conclude that a quantum computer is unlikely to\nsurpass classical state-of-the-art on optimization problems under realistic\nassumptions. In this work, we compile and analyze the Quantum Approximate\nOptimization Algorithm (QAOA) combined with Amplitude Amplification (AA)\napplied to random 8-SAT at the satisfiability threshold. Our compilation\ninvolves careful optimization of circuits for Hamiltonian simulation, which may\nbe of independent interest. We use the analytical scaling of the\ntime-to-solution for QAOA identified by PRX Quantum 5, 030348 (2024) and find\nthat with QAOA depth $p=623$, QAOA+AA achieves a crossover with\nstate-of-the-art classical heuristics at 179 variables and 14.99 hours of\nruntime when executed on a surface-code-based fault-tolerant quantum computer\nwith 73.91 million physical qubits, a physical error rate of $10^{-3}$, and a\n$1~\\mu$s code cycle time. Notably, we allow the classical solver to be\nparallelized as long as its total energy consumption is equal to that required\nfor decoding in the surface code. We further show that this restriction on\nclassical solver energy consumption can be relaxed given optimistic but\nplausible reductions in physical error rates and fault-tolerance overheads,\nenabling a crossover of 2.94 hours using 8.88 million physical qubits against a\nclassical solver running on a supercomputer with $725,760$ CPU cores. These\nfindings support the hypothesis that large-scale fault-tolerant quantum\ncomputers will be useful for optimization.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T16:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.01913v1","title":"Representing Flow Fields with Divergence-Free Kernels for Reconstruction","summary":"Accurately reconstructing continuous flow fields from sparse or indirect\nmeasurements remains an open challenge, as existing techniques often suffer\nfrom oversmoothing artifacts, reliance on heterogeneous architectures, and the\ncomputational burden of enforcing physics-informed losses in implicit neural\nrepresentations (INRs). In this paper, we introduce a novel flow field\nreconstruction framework based on divergence-free kernels (DFKs), which\ninherently enforce incompressibility while capturing fine structures without\nrelying on hierarchical or heterogeneous representations. Through qualitative\nanalysis and quantitative ablation studies, we identify the matrix-valued\nradial basis functions derived from Wendland's $\\mathcal{C}^4$ polynomial\n(DFKs-Wen4) as the optimal form of analytically divergence-free approximation\nfor velocity fields, owing to their favorable numerical properties, including\ncompact support, positive definiteness, and second-order differentiablility.\nExperiments across various reconstruction tasks, spanning data compression,\ninpainting, super-resolution, and time-continuous flow inference, has\ndemonstrated that DFKs-Wen4 outperform INRs and other divergence-free\nrepresentations in both reconstruction accuracy and computational efficiency\nwhile requiring the fewest trainable parameters.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T17:13:59Z"}
{"aid":"http://arxiv.org/abs/2504.01926v1","title":"Pairing Anderson motives via formal residues in the Frobenius\n  endomorphism","summary":"Anderson modules form a generalization of Drinfeld modules and are commonly\nunderstood as the counterpart of abelian varieties but with function field\ncoefficients. In an attempt to study their ``motivic theory'', two objects of\nsemilinear algebra are attached to an Anderson module: its motive and its dual\nmotive. While the former is better suited to follow the analogy with\nGrothendieck motives, the latter has proven much useful in the study of\ntranscendence questions in positive characteristic. Despite sharing similar\ndefinitions, the relationship between motives and dual motives has remained\nnebulous. Over perfect fields, it was only proved recently by the second author\nthat the finite generation of the motive is equivalent to the finite generation\nof the dual motive, answering a long-standing open question in function field\narithmetic (the ``abelian equals $A$-finite'' theorem). This work constructs a\nperfect pairing among the motive and the dual motive of an Anderson module,\nwith values in a module of differentials, thus answering a question raised by\nHartl and Juschka. Our construction involves taking the residue of certain\nformal power series in the Frobenius endomorphism. Although it may seem\npeculiar, this pairing is natural and compatible with base change. It also\ncomes with several new consequences in function field arithmetic; for example,\nwe generalize the ``abelian equals A-finite'' theorem to a large class of\nalgebras, including fields, perfect algebras and noetherian regular domains.","main_category":"math.AG","categories":"math.AG","published":"2025-04-02T17:37:05Z"}
{"aid":"http://arxiv.org/abs/2504.01947v1","title":"Efficient Federated Learning Tiny Language Models for Mobile Network\n  Feature Prediction","summary":"In telecommunications, Autonomous Networks (ANs) automatically adjust\nconfigurations based on specific requirements (e.g., bandwidth) and available\nresources. These networks rely on continuous monitoring and intelligent\nmechanisms for self-optimization, self-repair, and self-protection, nowadays\nenhanced by Neural Networks (NNs) to enable predictive modeling and pattern\nrecognition. Here, Federated Learning (FL) allows multiple AN cells - each\nequipped with NNs - to collaboratively train models while preserving data\nprivacy. However, FL requires frequent transmission of large neural data and\nthus an efficient, standardized compression strategy for reliable\ncommunication. To address this, we investigate NNCodec, a Fraunhofer\nimplementation of the ISO/IEC Neural Network Coding (NNC) standard, within a\nnovel FL framework that integrates tiny language models (TLMs) for various\nmobile network feature prediction (e.g., ping, SNR or band frequency). Our\nexperimental results on the Berlin V2X dataset demonstrate that NNCodec\nachieves transparent compression (i.e., negligible performance loss) while\nreducing communication overhead to below 1%, showing the effectiveness of\ncombining NNC with FL in collaboratively learned autonomous mobile networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC,eess.SP","published":"2025-04-02T17:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.01957v1","title":"GaussianLSS -- Toward Real-world BEV Perception: Depth Uncertainty\n  Estimation via Gaussian Splatting","summary":"Bird's-eye view (BEV) perception has gained significant attention because it\nprovides a unified representation to fuse multiple view images and enables a\nwide range of down-stream autonomous driving tasks, such as forecasting and\nplanning. Recent state-of-the-art models utilize projection-based methods which\nformulate BEV perception as query learning to bypass explicit depth estimation.\nWhile we observe promising advancements in this paradigm, they still fall short\nof real-world applications because of the lack of uncertainty modeling and\nexpensive computational requirement. In this work, we introduce GaussianLSS, a\nnovel uncertainty-aware BEV perception framework that revisits\nunprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm,\nand enhances them with depth un-certainty modeling. GaussianLSS represents\nspatial dispersion by learning a soft depth mean and computing the variance of\nthe depth distribution, which implicitly captures object extents. We then\ntransform the depth distribution into 3D Gaussians and rasterize them to\nconstruct uncertainty-aware BEV features. We evaluate GaussianLSS on the\nnuScenes dataset, achieving state-of-the-art performance compared to\nunprojection-based methods. In particular, it provides significant advantages\nin speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory\ncompared to projection-based methods, while achieving competitive performance\nwith only a 0.4% IoU difference.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:59:38Z"}
{"aid":"http://arxiv.org/abs/2504.02225v1","title":"Twisted second moment of modular $L$-functions to a fixed modulus","summary":"We study asymptotically the twisted second moment of the family of modular\n$L$-functions to a fixed modulus. As an application, we establish sharp lower\nbounds for all real $k \\geq 0$ and sharp upper bounds for $k$ in the range $0\n\\leq k \\leq 1$ for the $2k$-th moment of these $L$-functions on the critical\nline.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T02:46:48Z"}
{"aid":"http://arxiv.org/abs/2504.02227v1","title":"VEGAS: Towards Visually Explainable and Grounded Artificial Social\n  Intelligence","summary":"Social Intelligence Queries (Social-IQ) serve as the primary multimodal\nbenchmark for evaluating a model's social intelligence level. While impressive\nmultiple-choice question(MCQ) accuracy is achieved by current solutions,\nincreasing evidence shows that they are largely, and in some cases entirely,\ndependent on language modality, overlooking visual context. Additionally, the\nclosed-set nature further prevents the exploration of whether and to what\nextent the reasoning path behind selection is correct. To address these\nlimitations, we propose the Visually Explainable and Grounded Artificial Social\nIntelligence (VEGAS) model. As a generative multimodal model, VEGAS leverages\nopen-ended answering to provide explainable responses, which enhances the\nclarity and evaluation of reasoning paths. To enable visually grounded\nanswering, we propose a novel sampling strategy to provide the model with more\nrelevant visual frames. We then enhance the model's interpretation of these\nframes through Generalist Instruction Fine-Tuning (GIFT), which aims to: i)\nlearn multimodal-language transformations for fundamental emotional social\ntraits, and ii) establish multimodal joint reasoning capabilities. Extensive\nexperiments, comprising modality ablation, open-ended assessments, and\nsupervised MCQ evaluations, consistently show that VEGAS effectively utilizes\nvisual information in reasoning to produce correct and also credible answers.\nWe expect this work to of fer a new perspective on Social-IQ and advance the\ndevelopment of human-like social AI.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T02:48:21Z"}
{"aid":"http://arxiv.org/abs/2504.02250v1","title":"Designing Effective Human-Swarm Interaction Interfaces: Insights from a\n  User Study on Task Performance","summary":"In this paper, we present a systematic method of design for human-swarm\ninteraction interfaces, combining theoretical insights with empirical\nevaluation. We first derive ten design principles from existing literature,\napply them to key information dimensions identified through goal-directed task\nanalysis and developed a tablet-based interface for a target search task. We\nthen conducted a user study with 31 participants where humans were required to\nguide a robotic swarm to a target in the presence of three types of hazards\nthat pose a risk to the robots: Distributed, Moving, and Spreading. Performance\nwas measured based on the proximity of the robots to the target and the number\nof deactivated robots at the end of the task. Results indicate that at least\none robot was bought closer to the target in 98% of tasks, demonstrating the\ninterface's success fulfilling the primary objective of the task. Additionally,\nin nearly 67% of tasks, more than 50% of the robots reached the target.\nMoreover, particularly better performance was noted in moving hazards.\nAdditionally, the interface appeared to help minimize robot deactivation, as\nevidenced by nearly 94% of tasks where participants managed to keep more than\n50% of the robots active, ensuring that most of the swarm remained operational.\nHowever, its effectiveness varied across hazards, with robot deactivation being\nlowest in distributed hazard scenarios, suggesting that the interface provided\nthe most support in these conditions.","main_category":"cs.HC","categories":"cs.HC,cs.RO","published":"2025-04-03T03:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.02253v1","title":"On energy-momentum tensor for gravitational waves in $f(R)$ gravity","summary":"The classical Isaacson's procedure for describing back-reaction of the\naveraged energy-momentum for high frequency gravitational waves is generalized\nto $f(R)$ gravity case. From the beginning it is assumed that an initial\nbackground could be arbitrary one. By next steps it is restricted to de Sitter\nspace that is a novelty for the study of a back-reaction in $f(R)$ gravity.\nConsideration of the de Sitter space as a background spacetime allows us to\nprovide the averaging procedure completely. Using the results on the de Sitter\nspace and generalizing the Isaacson procedure, we construct the averaged\nenergy-momentum on an additionally curved (averaged) background. Relations of\nparameters, which preserve the de Sitter picture, and which disturb it are\ngiven. Our results generalize results of previous authors who use flat\n(Minkowski) spacetime as the beginning background in $f(R)$ gravity.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-03T03:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.02275v1","title":"Enhancing Customer Contact Efficiency with Graph Neural Networks in\n  Credit Card Fraud Detection Workflow","summary":"Credit card fraud has been a persistent issue since the last century, causing\nsignificant financial losses to the industry. The most effective way to prevent\nfraud is by contacting customers to verify suspicious transactions. However,\nwhile these systems are designed to detect fraudulent activity, they often\nmistakenly flag legitimate transactions, leading to unnecessary declines that\ndisrupt the user experience and erode customer trust. Frequent false positives\ncan frustrate customers, resulting in dissatisfaction, increased complaints,\nand a diminished sense of security. To address these limitations, we propose a\nfraud detection framework incorporating Relational Graph Convolutional Networks\n(RGCN) to enhance the accuracy and efficiency of identifying fraudulent\ntransactions. By leveraging the relational structure of transaction data, our\nmodel reduces the need for direct customer confirmation while maintaining high\ndetection performance. Our experiments are conducted using the IBM credit card\ntransaction dataset to evaluate the effectiveness of this approach.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T04:50:45Z"}
{"aid":"http://arxiv.org/abs/2504.02292v1","title":"Unifying Different Theories of Conformal Prediction","summary":"This paper presents a unified framework for understanding the methodology and\ntheory behind several different methods in the conformal prediction literature,\nwhich includes standard conformal prediction (CP), weighted conformal\nprediction (WCP), nonexchangeable conformal prediction (NexCP), and\nrandomly-localized conformal prediction (RLCP), among others. At the crux of\nour framework is the idea that conformal methods are based on revealing partial\ninformation about the data at hand, and positing a conditional distribution for\nthe data given the partial information. Different methods arise from different\nchoices of partial information, and of the corresponding (approximate)\nconditional distribution. In addition to recovering and unifying existing\nresults, our framework leads to both new theoretical guarantees for existing\nmethods, and new extensions of the conformal methodology.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-03T05:46:26Z"}
{"aid":"http://arxiv.org/abs/2504.02299v1","title":"Asymmetric graph alignment and the phase transition for asymmetric tree\n  correlation testing","summary":"Graph alignment - identifying node correspondences between two graphs - is a\nfundamental problem with applications in network analysis, biology, and privacy\nresearch. While substantial progress has been made in aligning correlated\nErd\\H{o}s-R\\'enyi graphs under symmetric settings, real-world networks often\nexhibit asymmetry in both node numbers and edge densities. In this work, we\nintroduce a novel framework for asymmetric correlated Erd\\H{o}s-R\\'enyi graphs,\ngeneralizing existing models to account for these asymmetries. We conduct a\nrigorous theoretical analysis of graph alignment in the sparse regime, where\nlocal neighborhoods exhibit tree-like structures. Our approach leverages tree\ncorrelation testing as the central tool in our polynomial-time algorithm,\nMPAlign, which achieves one-sided partial alignment under certain conditions.\n  A key contribution of our work is characterizing these conditions under which\nasymmetric tree correlation testing is feasible: If two correlated graphs $G$\nand $G'$ have average degrees $\\lambda s$ and $\\lambda s'$ respectively, where\n$\\lambda$ is their common density and $s,s'$ are marginal correlation\nparameters, their tree neighborhoods can be aligned if $ss' > \\alpha$, where\n$\\alpha$ denotes Otter's constant and $\\lambda$ is supposed large enough. The\nfeasibility of this tree comparison problem undergoes a sharp phase transition\nsince $ss' \\leq \\alpha$ implies its impossibility. These new results on tree\ncorrelation testing allow us to solve a class of random subgraph isomorphism\nproblems, resolving an open problem in the field.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-03T06:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.02338v1","title":"Coronal and chromospheric activity of Teegarden's star","summary":"Teegarden's star is a late-type M-dwarf planet host, typically showing only\nrather low levels of activity. In this paper we present an extensive\ncharacterisation of this activity at photospheric, chromospheric, and coronal\nlevels. We specifically investigated TESS observations of Teegarden's star,\nwhich showed two very large flares with an estimated flare fluence between\n10$^{29}$ and 10$^{32}$\\,erg comparable to the largest solar flares. We\nfurthermore analysed nearly 300 CARMENES spectra and 11 ESPRESSO spectra\ncovering all the usually used chromospheric lines in the optical from the\n\\ion{Ca}{ii} H \\& K lines at 3930\\,\\AA\\, to the \\ion{He}{i} infrared triplet at\n10830\\,\\AA. These lines show different behaviour: The \\ion{He}{i} infrared\ntriplet is the only one absent in all spectra, some lines show up only during\nflares, and others are always present and highly variable. Specifically, the\nH$\\alpha$ line is more or less filled in during quiescence; however, the higher\nBalmer lines are still observed in emission. Many chromospheric lines show a\ncorrelation with H$\\alpha$ variability, which, in addition to stochastic\nbehaviour, also shows systematic behaviour on different timescales including\nthe rotation period. Moreover, we found several flares and also report hints of\nan erupting prominence, which may have led to a coronal mass ejection. Finally,\nwe present X-ray observations of Teegarden's star (i.e. a discovery pointing\nobtained with the \\emph{Chandra} observatory) and an extensive study with the\n\\emph{XMM-Newton} observatory; when these two large flares were observed, one\nof them showed clear signatures of the Neupert effect, suggesting the\nproduction of hard X-rays in the system.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-03T07:18:54Z"}
{"aid":"http://arxiv.org/abs/2504.02341v1","title":"Bergman spaces on algebraic curves","summary":"A theorem of Wiegerinck asserts that the Bergman space of an open subset of\nthe complex numbers is either infinite-dimensional or trivial. Recently, this\nhas been generalized to holomorphic vector bundles over the projective line by\nthe third author and later to vector bundles over any compact Riemann surface\nby Gallagher, Gupta and Vivas.\n  In the present paper we extend the above results to the case of certain\nsingular metrics associated to divisors on a Riemann surface. As corollaries we\nobtain versions of Wiegerinck's theorem for both projective and affine\nalgebraic curves.","main_category":"math.CV","categories":"math.CV","published":"2025-04-03T07:20:23Z"}
{"aid":"http://arxiv.org/abs/2504.02346v1","title":"Repositioning, Ride-matching, and Abandonment in On-demand Ride-hailing\n  Platforms: A Mean Field Game Approach","summary":"The on-demand ride-hailing industry has experienced rapid growth,\ntransforming transportation norms worldwide. Despite improvements in efficiency\nover traditional taxi services, significant challenges remain, including\ndrivers' strategic repositioning behavior, customer abandonment, and\ninefficiencies in dispatch algorithms. To address these issues, we introduce a\ncomprehensive mean field game model that systematically analyzes the dynamics\nof ride-hailing platforms by incorporating driver repositioning across multiple\nregions, customer abandonment behavior, and platform dispatch algorithms. Using\nthis framework, we identify all possible mean field equilibria as the\nKarush-Kuhn-Tucker (KKT) points of an associated optimization problem. Our\nanalysis reveals the emergence of multiple equilibria, including the\ninefficient \"Wild Goose Chase\" one, characterized by drivers pursuing distant\nrequests, leading to suboptimal system performance. To mitigate these\ninefficiencies, we propose a novel two-matching-radius nearest-neighbor\ndispatch algorithm that eliminates undesirable equilibria and ensures a unique\nmean field equilibrium for multi-region systems. The algorithm dynamically\nadjusts matching radii based on driver supply rates, optimizing pick-up times\nand waiting times for drivers while maximizing request completion rates.\nNumerical experiments and simulation results show that our proposed algorithm\nreduces customer abandonment, minimizes waiting times for both customers and\ndrivers, and improves overall platform efficiency.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-03T07:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.02361v1","title":"MG-Gen: Single Image to Motion Graphics Generation with Layer\n  Decomposition","summary":"General image-to-video generation methods often produce suboptimal animations\nthat do not meet the requirements of animated graphics, as they lack active\ntext motion and exhibit object distortion. Also, code-based animation\ngeneration methods typically require layer-structured vector data which are\noften not readily available for motion graphic generation. To address these\nchallenges, we propose a novel framework named MG-Gen that reconstructs data in\nvector format from a single raster image to extend the capabilities of\ncode-based methods to enable motion graphics generation from a raster image in\nthe framework of general image-to-video generation. MG-Gen first decomposes the\ninput image into layer-wise elements, reconstructs them as HTML format data and\nthen generates executable JavaScript code for the reconstructed HTML data. We\nexperimentally confirm that \\ours{} generates motion graphics while preserving\ntext readability and input consistency. These successful results indicate that\ncombining layer decomposition and animation code generation is an effective\nstrategy for motion graphics generation.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-03T07:52:12Z"}
{"aid":"http://arxiv.org/abs/2504.02371v1","title":"Schur roots and tilting modules of acyclic quivers over commutative\n  rings","summary":"Let $Q$ be a finite acyclic quiver and $A_Q$ the cluster algebra of $Q$. It\nis well-known that for each field $k$, the additive equivalence classes of\nsupport tilting $kQ$-modules correspond bijectively with the clusters of $A_Q$.\nThe aim of this paper is to generalize this result to any ring indecomposable\ncommutative Noetherian ring $R$, that is, the additive equivalence classes of\n2-term silting complexes of $RQ$ correspond bijectively with the clusters of\n$A_Q$. As an application, for a Dynkin quiver $Q$, we prove that the torsion\nclasses of $\\mathrm{mod} RQ$ corresponds bijectively with the order preserving\nmaps from $\\mathrm{Spec} R$ to the set of clusters.","main_category":"math.RT","categories":"math.RT,math.AC,math.RA","published":"2025-04-03T08:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.02375v1","title":"A Comparative Study of MINLP and MPVC Formulations for Solving Complex\n  Nonlinear Decision-Making Problems in Aerospace Applications","summary":"High-level decision-making for dynamical systems often involves performance\nand safety specifications that are activated or deactivated depending on\nconditions related to the system state and commands. Such decision-making\nproblems can be naturally formulated as optimization problems where these\nconditional activations are regulated by discrete variables. However, solving\nthese problems can be challenging numerically, even on powerful computing\nplatforms, especially when the dynamics are nonlinear. In this work, we\nconsider decision-making for nonlinear systems where certain constraints, as\nwell as possible terms in the cost function, are activated or deactivated\ndepending on the system state and commands. We show that these problems can be\nformulated either as mixed-integer nonlinear programs (MINLPs) or as\nmathematical programs with vanishing constraints (MPVCs), where the former\nformulation involves discrete decision variables, whereas the latter relies on\ncontinuous variables subject to structured nonconvex constraints. We discuss\nthe different solution methods available for both formulations and demonstrate\nthem on optimal trajectory planning problems in various aerospace applications.\nFinally, we compare the strengths and weaknesses of the MINLP and MPVC\napproaches through a focused case study on powered descent guidance with\ndivert-feasible regions.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-03T08:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.02393v1","title":"Revealing the microscopic mechanism of deuteron formation at the LHC","summary":"The formation of light (anti)nuclei with mass number A of a few units (e.g.,\nd, $^3$He, and $^4$He) in high-energy hadronic collisions presents a\nlongstanding mystery in nuclear physics [1,2]. It is not clear how nuclei bound\nby a few MeV can emerge in environments characterized by temperatures above 100\nMeV [3-5], about 100,000 times hotter than the center of the Sun. Despite\nextensive studies, this question remained unanswered. The ALICE Collaboration\nnow addresses it with a novel approach using deuteron-pion momentum\ncorrelations in proton-proton (pp) collisions at the Large Hadron Collider\n(LHC). Our results provide model-independent evidence that about 80% of the\nobserved (anti)deuterons are produced in nuclear fusion reactions [6] following\nthe decay of short-lived resonances, such as the $\\Delta (1232)$. These\nfindings resolve a crucial gap in our understanding of nucleosynthesis in\nhadronic collisions. Beyond answering the fundamental question on how nuclei\nare formed in hadronic collisions, the results can be employed in the modeling\nof the production of light and heavy nuclei in cosmic rays [7] and dark matter\ndecays [8,9].","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T08:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.02412v1","title":"Bridging the Theoretical Gap in Randomized Smoothing","summary":"Randomized smoothing has become a leading approach for certifying adversarial\nrobustness in machine learning models. However, a persistent gap remains\nbetween theoretical certified robustness and empirical robustness accuracy.\nThis paper introduces a new framework that bridges this gap by leveraging\nLipschitz continuity for certification and proposing a novel, less conservative\nmethod for computing confidence intervals in randomized smoothing. Our approach\ntightens the bounds of certified robustness, offering a more accurate\nreflection of model robustness in practice. Through rigorous experimentation we\nshow that our method improves the robust accuracy, compressing the gap between\nempirical findings and previous theoretical results. We argue that\ninvestigating local Lipschitz constants and designing ad-hoc confidence\nintervals can further enhance the performance of randomized smoothing. These\nresults pave the way for a deeper understanding of the relationship between\nLipschitz continuity and certified robustness.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-03T09:05:49Z"}
{"aid":"http://arxiv.org/abs/2504.02429v1","title":"A Multi-Level Sentiment Analysis Framework for Financial Texts","summary":"Existing financial sentiment analysis methods often fail to capture the\nmulti-faceted nature of risk in bond markets due to their single-level approach\nand neglect of temporal dynamics. We propose Multi-Level Sentiment Analysis\nbased on pre-trained language models (PLMs) and large language models (LLMs), a\nnovel framework that systematically integrates firm-specific micro-level\nsentiment, industry-specific meso-level sentiment, and duration-aware smoothing\nto model the latency and persistence of textual impact. Applying our framework\nto the comprehensive Chinese bond market corpus constructed by us (2013-2023,\n1.39M texts), we extracted a daily composite sentiment index. Empirical results\nshow statistically measurable improvements in credit spread forecasting when\nincorporating sentiment (3.25% MAE and 10.96% MAPE reduction), with sentiment\nshifts closely correlating with major social risk events and firm-specific\ncrises. This framework provides a more nuanced understanding of sentiment\nacross different market levels while accounting for the temporal evolution of\nsentiment effects.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T09:35:07Z"}
{"aid":"http://arxiv.org/abs/2504.02470v1","title":"Impact of Global Warming on Extreme Rainfall in Taiwan","summary":"The relationship between global warming and extreme rainfalls in Taiwan was\nexamined in this study. Taiwan rainfall data from TCCIP, a project led by MOST,\nwere analyzed. North Hemisphere reference temperature data from NCEI led by\nNOAA. The yearly maximum of daily rainfall was focused on and the PGEV model,\nas proposed by Olafsdottir et al. \\citep{olafsdottir2021extreme}, was used to\nfit the extreme values and make inferences. The PGEV model integrates the\nGeneral Extreme Value (GEV) and Peak over Threshold (PoT) approaches, which are\ncommonly used to analyze extreme data. Relative intensity and return value were\nused to show the connection between temperature and extreme rainfall.\n  Results indicated that the intensity of extreme rainfall in Taiwan increases\nas the temperature rises. However, the effects of global warming on the\nfrequency and intensity of extreme rainfalls varied by region. In the north and\nsouth regions, the frequency of extreme rainfalls changed, while in the center\nand east regions, the intensity of extreme rainfalls changed. Furthermore,\naccording to the return value analysis, extreme rainfalls are likely to occur\nmore frequently in the future.\n  To account for differences between locations, Gaussian Process was used to\nsmooth the results obtained using the PGEV model. In addition, simulations\nusing the Gaussian copula and Gaussian Process were conducted to determine the\nquantile confidence intervals for each PGEV model. The simulations showed that\nall tests comparing with models with and without covariates are significant.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-03T10:44:32Z"}
{"aid":"http://arxiv.org/abs/2504.02478v1","title":"MG-MotionLLM: A Unified Framework for Motion Comprehension and\n  Generation across Multiple Granularities","summary":"Recent motion-aware large language models have demonstrated promising\npotential in unifying motion comprehension and generation. However, existing\napproaches primarily focus on coarse-grained motion-text modeling, where text\ndescribes the overall semantics of an entire motion sequence in just a few\nwords. This limits their ability to handle fine-grained motion-relevant tasks,\nsuch as understanding and controlling the movements of specific body parts. To\novercome this limitation, we pioneer MG-MotionLLM, a unified motion-language\nmodel for multi-granular motion comprehension and generation. We further\nintroduce a comprehensive multi-granularity training scheme by incorporating a\nset of novel auxiliary tasks, such as localizing temporal boundaries of motion\nsegments via detailed text as well as motion detailed captioning, to facilitate\nmutual reinforcement for motion-text modeling across various levels of\ngranularity. Extensive experiments show that our MG-MotionLLM achieves superior\nperformance on classical text-to-motion and motion-to-text tasks, and exhibits\npotential in novel fine-grained motion comprehension and editing tasks. Project\npage: CVI-SZU/MG-MotionLLM","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:53:41Z"}
{"aid":"http://arxiv.org/abs/2504.02494v1","title":"Semiconductor Wafer Map Defect Classification with Tiny Vision\n  Transformers","summary":"Semiconductor wafer defect classification is critical for ensuring high\nprecision and yield in manufacturing. Traditional CNN-based models often\nstruggle with class imbalances and recognition of the multiple overlapping\ndefect types in wafer maps. To address these challenges, we propose ViT-Tiny, a\nlightweight Vision Transformer (ViT) framework optimized for wafer defect\nclassification. Trained on the WM-38k dataset. ViT-Tiny outperforms its\nViT-Base counterpart and state-of-the-art (SOTA) models, such as MSF-Trans and\nCNN-based architectures. Through extensive ablation studies, we determine that\na patch size of 16 provides optimal performance. ViT-Tiny achieves an F1-score\nof 98.4%, surpassing MSF-Trans by 2.94% in four-defect classification,\nimproving recall by 2.86% in two-defect classification, and increasing\nprecision by 3.13% in three-defect classification. Additionally, it\ndemonstrates enhanced robustness under limited labeled data conditions, making\nit a computationally efficient and reliable solution for real-world\nsemiconductor defect detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T11:18:00Z"}
{"aid":"http://arxiv.org/abs/2504.02506v1","title":"Secrecy Performance of a Keyhole-based Multi-user System with Multiple\n  Eavesdroppers","summary":"This paper investigates the secrecy performance of a keyhole-aided multi-user\ncommunication network in the presence of multiple eavesdroppers. The\ncommunication happens through the same keyhole for legitimate users and\neavesdroppers. In this context, the secrecy performance is evaluated for a user\nscheduling technique by obtaining the exact closed-form expression of secrecy\noutage probability (SOP). Further, a simplified asymptotic SOP expression is\nderived assuming high signal-to-noise ratio (SNR) scenario for a better\nunderstanding of the impact of system parameters. The effect of the keyhole\nparameters, number of users, number of eavesdroppers, and threshold secrecy\nrate on the SOP performance are also investigated for the considered system\nmodel. In the high-SNR regime, the asymptotic SOP saturates to a constant value\nand does not depend on the keyhole parameter and the channel parameter of the\nsource-to-keyhole channel.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-03T11:38:08Z"}
{"aid":"http://arxiv.org/abs/2504.02526v1","title":"Improving User Experience with FAICO: Towards a Framework for AI\n  Communication in Human-AI Co-Creativity","summary":"How AI communicates with humans is crucial for effective human-AI\nco-creation. However, many existing co-creative AI tools cannot communicate\neffectively, limiting their potential as collaborators. This paper introduces\nour initial design of a Framework for designing AI Communication (FAICO) for\nco-creative AI based on a systematic review of 107 full-length papers. FAICO\npresents key aspects of AI communication and their impacts on user experience\nto guide the design of effective AI communication. We then show actionable ways\nto translate our framework into two practical tools: design cards for designers\nand a configuration tool for users. The design cards enable designers to\nconsider AI communication strategies that cater to a diverse range of users in\nco-creative contexts, while the configuration tool empowers users to customize\nAI communication based on their needs and creative workflows. This paper\ncontributes new insights within the literature on human-AI co-creativity and\nHuman-Computer Interaction, focusing on designing AI communication to enhance\nuser experience.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-03T12:29:53Z"}
{"aid":"http://arxiv.org/abs/2504.02530v1","title":"Statistical parameter identification of mixed-mode patterns from a\n  single experimental snapshot","summary":"Parameter identification in pattern formation models from a single\nexperimental snapshot is challenging, as traditional methods often require\nknowledge of initial conditions or transient dynamics -- data that are\nfrequently unavailable in experimental settings. In this study, we extend the\nrecently developed statistical approach, Correlation Integral Likelihood (CIL)\nmethod to enable robust parameter identification from a single snapshot of an\nexperimental pattern. Using the chlorite-iodite-malonic acid (CIMA) reaction --\na well-studied system that produces Turing patterns -- as a test case, we\naddress key experimental challenges such as measurement noise, model-data\ndiscrepancies, and the presence of mixed-mode patterns, where different spatial\nstructures (e.g., coexisting stripes and dots) emerge under the same\nconditions. Numerical experiments demonstrate that our method accurately\nestimates model parameters, even with incomplete or noisy data. This approach\nlays the groundwork for future applications in developmental biology, chemical\nreaction modelling, and other systems with heterogeneous output.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T12:33:56Z"}
{"aid":"http://arxiv.org/abs/2504.02537v1","title":"Blockchain and Distributed Ledger Technologies for Cyberthreat\n  Intelligence Sharing","summary":"Cyberthreat intelligence sharing is a critical aspect of cybersecurity, and\nit is essential to understand its definition, objectives, benefits, and impact\non society. Blockchain and Distributed Ledger Technology (DLT) are emerging\ntechnologies that have the potential to transform intelligence sharing. This\npaper aims to provide a comprehensive understanding of intelligence sharing and\nthe role of blockchain and DLT in enhancing it. The paper addresses questions\nrelated to the definition, objectives, benefits, and impact of intelligence\nsharing and provides a review of the existing literature. Additionally, the\npaper explores the challenges associated with blockchain and DLT and their\npotential impact on security and privacy. The paper also discusses the use of\nDLT and blockchain in security and intelligence sharing and highlights the\nassociated challenges and risks. Furthermore, the paper examines the potential\nimpact of a National Cybersecurity Strategy on addressing cybersecurity risks.\nFinally, the paper explores the experimental set up required for implementing\nblockchain and DLT for intelligence sharing and discusses the curricular\nramifications of intelligence sharing.","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-03T12:38:42Z"}
{"aid":"http://arxiv.org/abs/2504.02544v1","title":"Fourier Sliced-Wasserstein Embedding for Multisets and Measures","summary":"We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T12:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.02550v1","title":"Enhanced Permeability Estimation in Microporous Rocks Using a Hybrid\n  Macropore-Darcy Approach","summary":"This study presents a novel workflow for constructing hybrid macropore-Darcy\nmodels from micro-CT images of microporous rocks. In our approach, macropore\nnetworks are extracted using established methods, while the microporosity is\ncharacterised through segmented phase classification and incorporated into the\nmodel as Darcy cells. Effectively, Darcy cells capture the micro scale\nconnectivity variations that are missing in the macroscopic networks. This dual\nentity model thus incorporates both the conventional macroscopic pore structure\nand the critical flow pathways present in the under-resolved microporous\nregions. The proposed workflow is rigorously validated by comparing the\npermeability estimates with direct numerical simulation (DNS) results and\nexperimental measurements. Our findings demonstrate that this hybrid approach\nreliably reproduces fluid flow behaviour in complex porous media while\nsignificantly reducing computational demands, offering a promising tool for\nadvanced groundwater modelling and water resource management.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T13:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.02581v1","title":"Quantitative assessment of biological dynamics with aggregate data","summary":"We develop and apply a learning framework for parameter estimation in initial\nvalue problems that are assessed only indirectly via aggregate data such as\nsample means and/or variances. Our comprehensive framework follows Bayesian\nprinciples and consists of specialized Markov chain Monte Carlo computational\nschemes that rely on modified Hamiltonian Monte Carlo to align with summary\nstatistic constraints and a novel elliptical slice sampler adapted to the\nparameters of biological models. We benchmark our methods with synthetic data\non microbial growth in batch culture and test them on real growth curve data\nfrom laboratory replication experiments on $\\textit{Prochlorococcus}$ microbes.\nThe results indicate that our learning framework can utilize experimental or\nhistorical data and lead to robust parameter estimation and data assimilation\nin ODE models of biological dynamics that outperform least-squares fitting.","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-04-03T13:45:10Z"}
{"aid":"http://arxiv.org/abs/2504.02587v1","title":"Rethinking RL Scaling for Vision Language Models: A Transparent,\n  From-Scratch Framework and Comprehensive Evaluation Scheme","summary":"Reinforcement learning (RL) has recently shown strong potential in improving\nthe reasoning capabilities of large language models and is now being actively\nextended to vision-language models (VLMs). However, existing RL applications in\nVLMs often rely on heavily engineered frameworks that hinder reproducibility\nand accessibility, while lacking standardized evaluation protocols, making it\ndifficult to compare results or interpret training dynamics. This work\nintroduces a transparent, from-scratch framework for RL in VLMs, offering a\nminimal yet functional four-step pipeline validated across multiple models and\ndatasets. In addition, a standardized evaluation scheme is proposed to assess\ntraining dynamics and reflective behaviors. Extensive experiments on visual\nreasoning tasks uncover key empirical findings: response length is sensitive to\nrandom seeds, reflection correlates with output length, and RL consistently\noutperforms supervised fine-tuning (SFT) in generalization, even with\nhigh-quality data. These findings, together with the proposed framework, aim to\nestablish a reproducible baseline and support broader engagement in RL-based\nVLM research.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-03T13:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.02591v1","title":"State-Space Model Inspired Multiple-Input Multiple-Output Spiking\n  Neurons","summary":"In spiking neural networks (SNNs), the main unit of information processing is\nthe neuron with an internal state. The internal state generates an output spike\nbased on its component associated with the membrane potential. This spike is\nthen communicated to other neurons in the network. Here, we propose a general\nmultiple-input multiple-output (MIMO) spiking neuron model that goes beyond\nthis traditional single-input single-output (SISO) model in the SNN literature.\nOur proposed framework is based on interpreting the neurons as state-space\nmodels (SSMs) with linear state evolutions and non-linear spiking activation\nfunctions. We illustrate the trade-offs among various parameters of the\nproposed SSM-inspired neuron model, such as the number of hidden neuron states,\nthe number of input and output channels, including single-input multiple-output\n(SIMO) and multiple-input single-output (MISO) models. We show that for SNNs\nwith a small number of neurons with large internal state spaces, significant\nperformance gains may be obtained by increasing the number of output channels\nof a neuron. In particular, a network with spiking neurons with multiple-output\nchannels may achieve the same level of accuracy with the baseline with the\ncontinuous-valued communications on the same reference network architecture.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T13:55:11Z"}
{"aid":"http://arxiv.org/abs/2504.02612v1","title":"Fine-Tuning Visual Autoregressive Models for Subject-Driven Generation","summary":"Recent advances in text-to-image generative models have enabled numerous\npractical applications, including subject-driven generation, which fine-tunes\npretrained models to capture subject semantics from only a few examples. While\ndiffusion-based models produce high-quality images, their extensive denoising\nsteps result in significant computational overhead, limiting real-world\napplicability. Visual autoregressive~(VAR) models, which predict next-scale\ntokens rather than spatially adjacent ones, offer significantly faster\ninference suitable for practical deployment. In this paper, we propose the\nfirst VAR-based approach for subject-driven generation. However, na\\\"{\\i}ve\nfine-tuning VAR leads to computational overhead, language drift, and reduced\ndiversity. To address these challenges, we introduce selective layer tuning to\nreduce complexity and prior distillation to mitigate language drift.\nAdditionally, we found that the early stages have a greater influence on the\ngeneration of subject than the latter stages, which merely synthesize local\ndetails. Based on this finding, we propose scale-wise weighted tuning, which\nprioritizes coarser resolutions for promoting the model to focus on the\nsubject-relevant information instead of local details. Extensive experiments\nvalidate that our method significantly outperforms diffusion-based baselines\nacross various metrics and demonstrates its practical usage.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:12:55Z"}
{"aid":"http://arxiv.org/abs/2504.02628v1","title":"Towards Computation- and Communication-efficient Computational Pathology","summary":"Despite the impressive performance across a wide range of applications,\ncurrent computational pathology models face significant diagnostic efficiency\nchallenges due to their reliance on high-magnification whole-slide image\nanalysis. This limitation severely compromises their clinical utility,\nespecially in time-sensitive diagnostic scenarios and situations requiring\nefficient data transfer. To address these issues, we present a novel\ncomputation- and communication-efficient framework called Magnification-Aligned\nGlobal-Local Transformer (MAGA-GLTrans). Our approach significantly reduces\ncomputational time, file transfer requirements, and storage overhead by\nenabling effective analysis using low-magnification inputs rather than\nhigh-magnification ones. The key innovation lies in our proposed magnification\nalignment (MAGA) mechanism, which employs self-supervised learning to bridge\nthe information gap between low and high magnification levels by effectively\naligning their feature representations. Through extensive evaluation across\nvarious fundamental CPath tasks, MAGA-GLTrans demonstrates state-of-the-art\nclassification performance while achieving remarkable efficiency gains: up to\n10.7 times reduction in computational time and over 20 times reduction in file\ntransfer and storage requirements. Furthermore, we highlight the versatility of\nour MAGA framework through two significant extensions: (1) its applicability as\na feature extractor to enhance the efficiency of any CPath architecture, and\n(2) its compatibility with existing foundation models and\nhistopathology-specific encoders, enabling them to process low-magnification\ninputs with minimal information loss. These advancements position MAGA-GLTrans\nas a particularly promising solution for time-sensitive applications,\nespecially in the context of intraoperative frozen section diagnosis where both\naccuracy and efficiency are paramount.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T14:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.02659v1","title":"Spectropolarimetry for Discerning Geometry and Structure in\n  Circumstellar Media of Hot Massive Stars","summary":"Spectropolarimetric techniques are a mainstay of astrophysical inquiry,\nranging from Solar System objects to the Cosmic Background Radiation. This\nreview highlights applications of stellar polarimetry for massive hot stars,\nparticularly in the context of ultraviolet (UV) spaceborne missions. The\nprevalence of binarity in the massive star population and uncertainties\nregarding the degree of rotational criticality among hot stars raises important\nquestions about stellar interactions, interior structure, and even the\nlifetimes of evolutionary phases. These uncertainties have consequences for\nstellar population synthesis calculations. Spectropolarimetry is a key tool for\nextracting information about stellar and binary geometries. We review\nmethodologies involving electron scattering in circumstellar envelopes; gravity\ndarkening from rapid rotation; spectral line effects including the (a) \"line\neffect\", (b) Ohman effect, and (c) Hanle effect; and the imprint of\ninterstellar polarization on measurements. Finally, we describe the Polstar UV\nspectropolarimetric SMEX mission concept as one means for employing these\ndiagnostics to clarify the state of high rotation and its impacts for massive\nstars.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.IM","published":"2025-04-03T14:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.02663v1","title":"Development of Automated Data Quality Assessment and Evaluation Indices\n  by Analytical Experience","summary":"The societal need to leverage third-party data has driven the\ndata-distribution market and increased the importance of data quality\nassessment (DQA) in data transactions between organizations. However, DQA\nrequires expert knowledge of raw data and related data attributes, which\nhinders consensus-building in data purchasing. This study focused on the\ndifferences in DQAs between experienced and inexperienced data handlers. We\nperformed two experiments: The first was a questionnaire survey involving 41\nparticipants with varying levels of data-handling experience, who evaluated 12\ndata samples using 10 predefined indices with and without quality metadata\ngenerated by the automated tool. The second was an eye-tracking experiment to\nreveal the viewing behavior of participants during data evaluation. It was\nrevealed that using quality metadata generated by the automated tool can reduce\nmisrecognition in DQA. While experienced data handlers rated the quality\nmetadata highly, semi-experienced users gave it the lowest ratings. This study\ncontributes to enhancing data understanding within organizations and promoting\nthe distribution of valuable data by proposing an automated tool to support\nDQAs.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.02668v1","title":"Two-Stage nnU-Net for Automatic Multi-class Bi-Atrial Segmentation from\n  LGE-MRIs","summary":"Late gadolinium enhancement magnetic resonance imaging (LGE-MRI) is used to\nvisualise atrial fibrosis and scars, providing important information for\npersonalised atrial fibrillation (AF) treatments. Since manual analysis and\ndelineations of these images can be both labour-intensive and subject to\nvariability, we develop an automatic pipeline to perform segmentation of the\nleft atrial (LA) cavity, the right atrial (RA) cavity, and the wall of both\natria on LGE-MRI. Our method is based on a two-stage nnU-Net architecture,\ncombining 2D and 3D convolutional networks, and incorporates adaptive histogram\nequalisation to improve tissue contrast in the input images and morphological\noperations on the output segmentation maps. We achieve Dice similarity\ncoefficients of 0.92 +/- 0.03, 0.93 +/- 0.03, 0.71 +/- 0.05 and 95% Hausdorff\ndistances of (3.89 +/- 6.67) mm, (4.42 +/- 1.66) mm and (3.94 +/- 1.83) mm for\nLA, RA, and wall, respectively. The accurate delineation of the LA, RA and the\nmyocardial wall is the first step in analysing atrial structure in\ncardiovascular patients, especially those with AF. This can allow clinicians to\nprovide adequate and personalised treatment plans in a timely manner.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T15:08:33Z"}
{"aid":"http://arxiv.org/abs/2504.02670v1","title":"Affordable AI Assistants with Knowledge Graph of Thoughts","summary":"Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose the Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively. For example, KGoT achieves a 29%\nimprovement in task success rates on the GAIA benchmark compared to Hugging\nFace Agents with GPT-4o mini, while reducing costs by over 36x compared to\nGPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and\n37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a\nscalable, affordable, and high-performing solution for AI assistants.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-03T15:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.02703v1","title":"Uncovering shifts in the history of Physics education: a systematic,\n  NLP-based, thematic analysis of articles from The Physics Teacher and Physics\n  Education journals (1966-2019)","summary":"This study explores the thematic evolution of articles in The Physics Teacher\nand Physics Education journals, over a critical period in modern history, from\nthe Cold War era to the pre-pandemic world (1966 - 2019). Using an NLP-based\ninductive topic modeling approach, we identify recurring themes that have\nshaped the physics education literature, including content-based topics,\nteaching methodologies, laboratory practices, curriculum development, and the\ninfluence of Physics Education Research (PER). Our findings reveal both\noverarching trends and distinct thematic preferences between the journals.\nPhysics Education has historically emphasized curriculum structures, social\naspects of education, and interdisciplinary connections, whereas The Physics\nTeacher has focused more on pedagogical strategies, demonstrations, and\npractical teaching tools. Over the past three decades, both journals have\nincreasingly incorporated discussions on technology, computation, and\nPER-driven instructional practices. By tracing these developments over five\ndecades, this study provides a broader perspective on how physics education has\nresponded to changing educational priorities, technological advancements, and\nresearch developments.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-03T15:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.02727v1","title":"Effect of new healthy and live food supplement on Anemia disease in\n  Wistar rats","summary":"Anemia is a decrease in hemoglobin and red blood cells and due to a decrease\nin hemoglobin, oxygen carrying capacity reduce. In this disease, the red blood\ncell the amount and volume decrease. In this research, healthy and live food\npowder were synthesized by a green route. This organic biomaterial was named\nNBS. The NBS healthy and live food powder has various vitamins, macro and micro\nmolecules, and ingredients. Twenty Wistar rats were randomly divided into 4\nequal groups, including control and treatment groups 1, 2 and 3. Nutritional\nsupplements for healthy living were administered orally via gavage to rats in\ngroups 1, 2, and 3 at 12.5, 25, and 50 mg/ kg, respectively, and within a\nperiod of 20 days, one day in between. There was no intervention in the control\ngroup in order to reach baseline blood factors. At the end of the study, blood\nsamples were taken from the heart, including blood-red blood cells, hemoglobin,\nhematocrit and platelets using a fully automated blood cell counting machine.\nThe results showed that the new dietary supplement reduced the level of\nhematocrit and platelets in the studied rats. The healthy and live food\nsupplement at a concentration of 50 mg / kg increased blood levels compared to\nthe control group. The results of this study showed that the use of healthy and\nlive food supplement increased blood factors compared to the control group.","main_category":"q-bio.CB","categories":"q-bio.CB","published":"2025-04-03T16:11:14Z"}
{"aid":"http://arxiv.org/abs/2504.02735v1","title":"Pushing the Limit of PPG Sensing in Sedentary Conditions by Addressing\n  Poor Skin-sensor Contact","summary":"Photoplethysmography (PPG) is a widely used non-invasive technique for\nmonitoring cardiovascular health and various physiological parameters on\nconsumer and medical devices. While motion artifacts are well-known challenges\nin dynamic settings, suboptimal skin-sensor contact in sedentary conditions - a\ncritical issue often overlooked in existing literature - can distort PPG signal\nmorphology, leading to the loss or shift of essential waveform features and\ntherefore degrading sensing performance. In this work, we propose CP-PPG, a\nnovel approach that transforms Contact Pressure-distorted PPG signals into ones\nwith the ideal morphology. CP-PPG incorporates a novel data collection\napproach, a well-crafted signal processing pipeline, and an advanced deep\nadversarial model trained with a custom PPG-aware loss function. We validated\nCP-PPG through comprehensive evaluations, including 1) morphology\ntransformation performance on our self-collected dataset, 2) downstream\nphysiological monitoring performance on public datasets, and 3) in-the-wild\nperformance. Extensive experiments demonstrate substantial and consistent\nimprovements in signal fidelity (Mean Absolute Error: 0.09, 40% improvement\nover the original signal) as well as downstream performance across all\nevaluations in Heart Rate (HR), Heart Rate Variability (HRV), Respiration Rate\n(RR), and Blood Pressure (BP) estimation (on average, 21% improvement in HR;\n41-46% in HRV; 6% in RR; and 4-5% in BP). These findings highlight the critical\nimportance of addressing skin-sensor contact issues for accurate and dependable\nPPG-based physiological monitoring. Furthermore, CP-PPG can serve as a generic,\nplug-in API to enhance PPG signal quality.","main_category":"cs.HC","categories":"cs.HC,cs.LG","published":"2025-04-03T16:22:15Z"}
{"aid":"http://arxiv.org/abs/2504.02758v1","title":"ALMA uncovers optically thin and multi-component CO gas in the\n  outflowing circumnuclear disk of NGC1068","summary":"Active galactic nuclei (AGNs) influence their host galaxies through winds and\njets that can drive molecular outflows, traceable with CO line emissions using\nthe Atacama Large Millimeter Array (ALMA). Recent studies leveraging ALMA data\nhave proposed a three-dimensional outflow geometry in the nearby Seyfert II\ngalaxy NGC 1068, a key target for AGN unification theories. Using ALMA\nobservations of CO(2-1), CO(3-2), and CO(6-5) transitions at roughly 0.1\narcseconds (approximately 7 parsecs) resolution, we analyzed the temperature,\ndensity, and kinematics of NGC 1068's circumnuclear disk (CND), focusing on the\nmolecular outflow. Through local thermodynamic equilibrium (LTE) analysis, we\nderived column densities and rotational temperatures, indicating optically thin\ngas and CO-to-H2 (XCO) conversion factors between 4.8 and 9.6 times smaller\nthan the Milky Way value. The inferred molecular mass outflow rate is mostly\nbelow 5.5 solar masses per year, with the dominant contribution northeast of\nthe AGN. After subtracting the rotation curve of the CND, we modeled averaged\nline profiles in each region using single and multi-component Gaussian fits.\nSeveral profiles within or near the AGN wind bicone required multiple\ncomponents with significant velocity shifts, suggesting multi-component complex\noutflow kinematics. We observe lateral variation in CO kinematics along the AGN\nwind bicone and a misalignment between the molecular and ionized outflow\ndirections. These results imply that the dynamic impact of the ionized AGN wind\non the molecular gas in the CND may be limited. However, the molecular outflow\nshows a complex, asymmetric structure.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.02760v1","title":"Topological groupoids with involution and real algebraic stacks","summary":"To a topological groupoid endowed with an involution, we associate a\ntopological groupoid of fixed points, generalizing the fixed-point subspace of\na topological space with involution. We prove that when the topological\ngroupoid with involution arises from a Deligne-Mumford stack over $\\mathbb{R}$,\nthis fixed locus coincides with the real locus of the stack. This provides a\ntopological framework to study real algebraic stacks, and in particular real\nmoduli spaces. Finally, we propose a Smith-Thom type conjecture in this\nsetting, generalizing the Smith-Thom inequality for topological spaces endowed\nwith an involution.","main_category":"math.AG","categories":"math.AG,math.AT,math.GN","published":"2025-04-03T16:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.02766v1","title":"On Composable and Parametric Uncertainty in Systems Co-Design","summary":"Optimizing the design of complex systems requires navigating interdependent\ndecisions, heterogeneous components, and multiple objectives. Our monotone\ntheory of co-design offers a compositional framework for addressing this\nchallenge, modeling systems as Design Problems (DPs), representing trade-offs\nbetween functionalities and resources within partially ordered sets. While\ncurrent approaches model uncertainty using intervals, capturing worst- and\nbest-case bounds, they fail to express probabilistic notions such as risk and\nconfidence. These limitations hinder the applicability of co-design in domains\nwhere uncertainty plays a critical role. In this paper, we introduce a unified\nframework for composable uncertainty in co-design, capturing intervals,\ndistributions, and parametrized models. This extension enables reasoning about\nrisk-performance trade-offs and supports advanced queries such as experiment\ndesign, learning, and multi-stage decision making. We demonstrate the\nexpressiveness and utility of the framework via a numerical case study on the\nuncertainty-aware co-design of task-driven Unmanned Aerial Vehicle (UAV).","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-03T17:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.02775v1","title":"TailedCore: Few-Shot Sampling for Unsupervised Long-Tail Noisy Anomaly\n  Detection","summary":"We aim to solve unsupervised anomaly detection in a practical challenging\nenvironment where the normal dataset is both contaminated with defective\nregions and its product class distribution is tailed but unknown. We observe\nthat existing models suffer from tail-versus-noise trade-off where if a model\nis robust against pixel noise, then its performance deteriorates on tail class\nsamples, and vice versa. To mitigate the issue, we handle the tail class and\nnoise samples independently. To this end, we propose TailSampler, a novel class\nsize predictor that estimates the class cardinality of samples based on a\nsymmetric assumption on the class-wise distribution of embedding similarities.\nTailSampler can be utilized to sample the tail class samples exclusively,\nallowing to handle them separately. Based on these facets, we build a\nmemory-based anomaly detection model TailedCore, whose memory both well\ncaptures tail class information and is noise-robust. We extensively validate\nthe effectiveness of TailedCore on the unsupervised long-tail noisy anomaly\ndetection setting, and show that TailedCore outperforms the state-of-the-art in\nmost settings.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-03T17:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.02821v1","title":"Sparse Autoencoders Learn Monosemantic Features in Vision-Language\n  Models","summary":"Sparse Autoencoders (SAEs) have recently been shown to enhance\ninterpretability and steerability in Large Language Models (LLMs). In this\nwork, we extend the application of SAEs to Vision-Language Models (VLMs), such\nas CLIP, and introduce a comprehensive framework for evaluating monosemanticity\nin vision representations. Our experimental results reveal that SAEs trained on\nVLMs significantly enhance the monosemanticity of individual neurons while also\nexhibiting hierarchical representations that align well with expert-defined\nstructures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that\napplying SAEs to intervene on a CLIP vision encoder, directly steer output from\nmultimodal LLMs (e.g., LLaVA) without any modifications to the underlying\nmodel. These findings emphasize the practicality and efficacy of SAEs as an\nunsupervised approach for enhancing both the interpretability and control of\nVLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-03T17:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.04718v1","title":"T1: Tool-integrated Self-verification for Test-time Compute Scaling in\n  Small Language Models","summary":"Recent studies have demonstrated that test-time compute scaling effectively\nimproves the performance of small language models (sLMs). However, prior\nresearch has mainly examined test-time compute scaling with an additional\nlarger model as a verifier, leaving self-verification by sLMs underexplored. In\nthis work, we investigate whether sLMs can reliably self-verify their outputs\nunder test-time scaling. We find that even with knowledge distillation from\nlarger verifiers, sLMs struggle with verification tasks requiring memorization,\nsuch as numerical calculations and fact-checking. To address this limitation,\nwe propose Tool-integrated self-verification (T1), which delegates\nmemorization-heavy verification steps to external tools, such as a code\ninterpreter. Our theoretical analysis shows that tool integration reduces\nmemorization demands and improves test-time scaling performance. Experiments on\nthe MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under\ntest-time scaling outperforms the significantly larger Llama-3.1 8B model.\nMoreover, T1 generalizes effectively to both mathematical (MATH500) and\nmulti-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the\npotential of tool integration to substantially improve the self-verification\nabilities of sLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T04:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.04727v1","title":"Regression Model for Measurement of Wound Dimensions by Webcam Scanners\n  and Time-of-Flight Sensors","summary":"One use of image processing is for medical equipment such as wound\nidentification. This technology is carried out non-invasively by taking images\nso as to avoid direct touch with the wound thereby reducing the possibility of\ninfection. The images obtained using the RGB camera will be used for color\nsegmentation which will measure the wound dimensions. However, the image data\nis in the form of a raster, the distance will affect the pixel size. Therefore,\nit is necessary to consider the distance of the camera measurement to the\nobject. The time-of-flight (ToF) method with a lidar sensor is used to\ncalculate the distance of the camera to the object. It is necessary to\ncalculate the ratio of the distance to the number of pixels obtained so that\nthe value is always consistent. This study analyzed the use of appropriate\nratios and regression systems on a webcam and a lidar sensor for measuring\nwound dimensions. The results of the study show that there is a regression\nmodel with a second-order polynomial relationship for the distance and number\nof pixels obtained consistently with an error value of less than 5% which shows\nvery good results","main_category":"physics.comp-ph","categories":"physics.comp-ph,physics.ins-det","published":"2025-04-07T04:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.04734v1","title":"Teaching Data Science Students to Sketch Privacy Designs through\n  Heuristics (Extended Technical Report)","summary":"Recent studies reveal that experienced data practitioners often draw sketches\nto facilitate communication around privacy design concepts. However, there is\nlimited understanding of how we can help novice students develop such\ncommunication skills. This paper studies methods for lowering novice data\nscience students' barriers to creating high-quality privacy sketches. We first\nconducted a need-finding study (N=12) to identify barriers students face when\nsketching privacy designs. We then used a human-centered design approach to\nguide the method development, culminating in three simple, text-based\nheuristics. Our user studies with 24 data science students revealed that simply\npresenting three heuristics to the participants at the beginning of the study\ncan enhance the coverage of privacy-related design decisions in sketches,\nreduce the mental effort required for creating sketches, and improve the\nreadability of the final sketches.","main_category":"cs.HC","categories":"cs.HC,cs.CR,cs.CY","published":"2025-04-07T05:12:21Z"}
{"aid":"http://arxiv.org/abs/2504.04739v1","title":"MedGNN: Capturing the Links Between Urban Characteristics and Medical\n  Prescriptions","summary":"Understanding how urban socio-demographic and environmental factors relate\nwith health is essential for public health and urban planning. However,\ntraditional statistical methods struggle with nonlinear effects, while machine\nlearning models often fail to capture geographical (nearby areas being more\nsimilar) and topological (unequal connectivity between places) effects in an\ninterpretable way. To address this, we propose MedGNN, a spatio-topologically\nexplicit framework that constructs a 2-hop spatial graph, integrating\npositional and locational node embeddings with urban characteristics in a graph\nneural network. Applied to MEDSAT, a comprehensive dataset covering over 150\nenvironmental and socio-demographic factors and six prescription outcomes\n(depression, anxiety, diabetes, hypertension, asthma, and opioids) across 4,835\nGreater London neighborhoods, MedGNN improved predictions by over 25% on\naverage compared to baseline methods. Using depression prescriptions as a case\nstudy, we analyzed graph embeddings via geographical principal component\nanalysis, identifying findings that: align with prior research (e.g., higher\nantidepressant prescriptions among older and White populations), contribute to\nongoing debates (e.g., greenery linked to higher and NO2 to lower\nprescriptions), and warrant further study (e.g., canopy evaporation correlated\nwith fewer prescriptions). These results demonstrate MedGNN's potential, and\nmore broadly, of carefully applied machine learning, to advance\ntransdisciplinary public health research.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-07T05:35:16Z"}
{"aid":"http://arxiv.org/abs/2504.04751v1","title":"Unsupervised Estimation of Nonlinear Audio Effects: Comparing\n  Diffusion-Based and Adversarial approaches","summary":"Accurately estimating nonlinear audio effects without access to paired\ninput-output signals remains a challenging problem.This work studies\nunsupervised probabilistic approaches for solving this task. We introduce a\nmethod, novel for this application, based on diffusion generative models for\nblind system identification, enabling the estimation of unknown nonlinear\neffects using black- and gray-box models. This study compares this method with\na previously proposed adversarial approach, analyzing the performance of both\nmethods under different parameterizations of the effect operator and varying\nlengths of available effected recordings.Through experiments on guitar\ndistortion effects, we show that the diffusion-based approach provides more\nstable results and is less sensitive to data availability, while the\nadversarial approach is superior at estimating more pronounced distortion\neffects. Our findings contribute to the robust unsupervised blind estimation of\naudio effects, demonstrating the potential of diffusion models for system\nidentification in music technology.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-07T05:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.04757v1","title":"The Complexity of Maximal Common Subsequence Enumeration","summary":"Frequent pattern mining is widely used to find ``important'' or\n``interesting'' patterns in data. While it is not easy to mathematically define\nsuch patterns, maximal frequent patterns are promising candidates, as frequency\nis a natural indicator of relevance and maximality helps to summarize the\noutput. As such, their mining has been studied on various data types, including\nitemsets, graphs, and strings. The complexity of mining maximal frequent\nitemsets and subtrees has been thoroughly investigated (e.g., [Boros et al.,\n2003], [Uno et al., 2004]) in the literature. On the other hand, while the idea\nof mining frequent subsequences in sequential data was already introduced in\nthe seminal paper [Agrawal et al., 1995], the complexity of the problem is\nstill open.\n  In this paper, we investigate the complexity of the maximal common\nsubsequence enumeration problem, which is both an important special case of\nmaximal frequent subsequence mining and a generalization of the classic longest\ncommon subsequence (LCS) problem. We show the hardness of enumerating maximal\ncommon subsequences between multiple strings, ruling out the possibility of an\n\\emph{output-polynomial time} enumeration algorithm under $P \\neq NP$, that is,\nan algorithm that runs in time ${\\rm poly}(|\\mathcal I| + N)$, where $|\\mathcal\nI|$ and $N$ are the size of the input and number of output solutions,\nrespectively. To circumvent this intractability, we also investigate the\nparameterized complexity of the problem, and show several results when the\nalphabet size, the number of strings, and the length of a string are taken into\naccount as parameters.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-07T06:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.04760v1","title":"The spin measurement of the black hole SLX 1746-331 using Insight-HXMT\n  observations","summary":"We present an X-ray spectral analysis of a black hole X-ray binary SLX\n1746-331 during the 2023 outburst using five \\textit{Insight}-HXMT\nobservations. We jointly use the reflection model \\texttt{relxillcp} and the\ngeneral relativistic thermal thin disk model \\texttt{kerrbb} to fit the spectra\nfrom 2 - 100 keV. By jointly fitting the five spectra, we constrained the black\nhole mass to be $M=5.8\\pm 0.3 M_{\\odot}$ and dimensionless spin parameter to be\n$a_{*}=0.88^{+0.01}_{-0.02}$ (90 percent statistical confidence). The\nreflection model shows that SLX 1746-331 is a high-inclination system with the\ninclination angle $i=63.7^{+1.3}_{-1.0}$ degrees, the accretion disk has a\ndensity $\\rm{log}N\\sim 16 ~\\rm cm^{-3}$. In addition, with the different\nreflection model \\texttt{relxilllp}, which assumes a lamp-post geometry corona,\nwe still give similar results.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T06:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.04764v1","title":"Enhancing Leaf Disease Classification Using GAT-GCN Hybrid Model","summary":"Agriculture plays a critical role in the global economy, providing\nlivelihoods and ensuring food security for billions. As innovative agricultural\npractices become more widespread, the risk of crop diseases has increased,\nhighlighting the urgent need for efficient, low-intervention disease\nidentification methods. This research presents a hybrid model combining Graph\nAttention Networks (GATs) and Graph Convolution Networks (GCNs) for leaf\ndisease classification. GCNs have been widely used for learning from\ngraph-structured data, and GATs enhance this by incorporating attention\nmechanisms to focus on the most important neighbors. The methodology integrates\nsuperpixel segmentation for efficient feature extraction, partitioning images\ninto meaningful, homogeneous regions that better capture localized features.\nThe authors have employed an edge augmentation technique to enhance the\nrobustness of the model. The edge augmentation technique has introduced a\nsignificant degree of generalization in the detection capabilities of the\nmodel. To further optimize training, weight initialization techniques are\napplied. The hybrid model is evaluated against the individual performance of\nthe GCN and GAT models and the hybrid model achieved a precision of 0.9822,\nrecall of 0.9818, and F1-score of 0.9818 in apple leaf disease classification,\na precision of 0.9746, recall of 0.9744, and F1-score of 0.9743 in potato leaf\ndisease classification, and a precision of 0.8801, recall of 0.8801, and\nF1-score of 0.8799 in sugarcane leaf disease classification. These results\ndemonstrate the robustness and performance of the model, suggesting its\npotential to support sustainable agricultural practices through precise and\neffective disease detection. This work is a small step towards reducing the\nloss of crops and hence supporting sustainable goals of zero hunger and life on\nland.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T06:31:38Z"}
{"aid":"http://arxiv.org/abs/2504.04794v1","title":"Enhancing Trust in AI Marketplaces: Evaluating On-Chain Verification of\n  Personalized AI models using zk-SNARKs","summary":"The rapid advancement of artificial intelligence (AI) has brought about\nsophisticated models capable of various tasks ranging from image recognition to\nnatural language processing. As these models continue to grow in complexity,\nensuring their trustworthiness and transparency becomes critical, particularly\nin decentralized environments where traditional trust mechanisms are absent.\nThis paper addresses the challenge of verifying personalized AI models in such\nenvironments, focusing on their integrity and privacy. We propose a novel\nframework that integrates zero-knowledge succinct non-interactive arguments of\nknowledge (zk-SNARKs) with Chainlink decentralized oracles to verify AI model\nperformance claims on blockchain platforms. Our key contribution lies in\nintegrating zk-SNARKs with Chainlink oracles to securely fetch and verify\nexternal data to enable trustless verification of AI models on a blockchain.\nOur approach addresses the limitations of using unverified external data for AI\nverification on the blockchain while preserving sensitive information of AI\nmodels and enhancing transparency. We demonstrate our methodology with a linear\nregression model predicting Bitcoin prices using on-chain data verified on the\nSepolia testnet. Our results indicate the framework's efficacy, with key\nmetrics including proof generation taking an average of 233.63 seconds and\nverification time of 61.50 seconds. This research paves the way for transparent\nand trustless verification processes in blockchain-enabled AI ecosystems,\naddressing key challenges such as model integrity and model privacy protection.\nThe proposed framework, while exemplified with linear regression, is designed\nfor broader applicability across more complex AI models, setting the stage for\nfuture advancements in transparent AI verification.","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-07T07:38:29Z"}
{"aid":"http://arxiv.org/abs/2504.04818v1","title":"SUEDE:Shared Unified Experts for Physical-Digital Face Attack Detection\n  Enhancement","summary":"Face recognition systems are vulnerable to physical attacks (e.g., printed\nphotos) and digital threats (e.g., DeepFake), which are currently being studied\nas independent visual tasks, such as Face Anti-Spoofing and Forgery Detection.\nThe inherent differences among various attack types present significant\nchallenges in identifying a common feature space, making it difficult to\ndevelop a unified framework for detecting data from both attack modalities\nsimultaneously. Inspired by the efficacy of Mixture-of-Experts (MoE) in\nlearning across diverse domains, we explore utilizing multiple experts to learn\nthe distinct features of various attack types. However, the feature\ndistributions of physical and digital attacks overlap and differ. This suggests\nthat relying solely on distinct experts to learn the unique features of each\nattack type may overlook shared knowledge between them. To address these\nissues, we propose SUEDE, the Shared Unified Experts for Physical-Digital Face\nAttack Detection Enhancement. SUEDE combines a shared expert (always activated)\nto capture common features for both attack types and multiple routed experts\n(selectively activated) for specific attack types. Further, we integrate CLIP\nas the base network to ensure the shared expert benefits from prior visual\nknowledge and align visual-text representations in a unified space. Extensive\nresults demonstrate SUEDE achieves superior performance compared to\nstate-of-the-art unified detection methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:17:54Z"}
{"aid":"http://arxiv.org/abs/2504.04848v1","title":"Some remarks on almost locally uniformly rotund points","summary":"We study the relations between different notions of almost locally uniformly\nrotund points that appear in literature. We show that every non-reflexive\nBanach space admits an equivalent norm having a point in the corresponding unit\nsphere which is not almost locally uniformly rotund, and which is strongly\nexposed by all its supporting functionals. This result is in contrast with a\ncharacterization due to P. Bandyopadhyay, D. Huang, and B.-L. Lin from 2004. We\nalso show that such a characterization remains true in reflexive Banach spaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-07T09:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.04850v1","title":"An Efficient Approach for Cooperative Multi-Agent Learning Problems","summary":"In this article, we propose a centralized Multi-Agent Learning framework for\nlearning a policy that models the simultaneous behavior of multiple agents that\nneed to coordinate to solve a certain task. Centralized approaches often suffer\nfrom the explosion of an action space that is defined by all possible\ncombinations of individual actions, known as joint actions. Our approach\naddresses the coordination problem via a sequential abstraction, which\novercomes the scalability problems typical to centralized methods. It\nintroduces a meta-agent, called \\textit{supervisor}, which abstracts joint\nactions as sequential assignments of actions to each agent. This sequential\nabstraction not only simplifies the centralized joint action space but also\nenhances the framework's scalability and efficiency. Our experimental results\ndemonstrate that the proposed approach successfully coordinates agents across a\nvariety of Multi-Agent Learning environments of diverse sizes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T09:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.04851v1","title":"Nonlinear Phase Gates as Airy Transforms of the Wigner Function","summary":"Low-order nonlinear phase gates allow the construction of versatile\nhigher-order nonlinearities for bosonic systems and grant access to continuous\nvariable quantum simulations of many unexplored aspects of nonlinear quantum\ndynamics. The resulting nonlinear transformations produce, even with small\nstrength, multiple regions of negativity in the Wigner function and thus show\nan immediate departure from classical phase space. Towards the development of\nrealistic, bounded versions of these gates we show that the action of a\nquartic-bounded cubic gate on an arbitrary multimode quantum state in phase\nspace can be understood as an Airy transform of the Wigner function. This\ntoolbox generalises the symplectic transformations associated with Gaussian\noperations and allows for the practical calculation, analysis and\ninterpretation of explicit Wigner functions and the quantum non-Gaussian\nphenomena resulting from bounded nonlinear potentials.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T09:07:56Z"}
{"aid":"http://arxiv.org/abs/2504.04880v1","title":"Investigation of the baryon time-like electromagnetic form factors in\n  the electron-positron annihilation reactions","summary":"Based on the experimental measurements of the electron-positron annihilation\nreactions into a baryon ($B$) and anti-baryon ($\\bar{B}$) pair, the\nelectromagnetic form factors of hyperons in the time-like region can be\ninvestigated within the vector meson dominance model. The theoretical model\nparameters are determined by fitting them to the total cross sections of the\nprocess $e^+e^-\\to B \\bar{B}$, and it is found that the current experimental\ndata on the baryon electromagnetic form factors in the time-like region can be\nwell reproduced. In addition to the total cross sections, the electromagnetic\nform factors $G_E$ and $G_M$, and the charge radii of those baryons are also\nestimated, which are in agreement with the experimental data. On the other\nhand, we have also investigated the nonmonotonic behavior of the time-like\nbaryon electromagnetic form factors, and it is found that the previously\nproposed periodic behaviour of the nucleon time-like electromagnetic form\nfactor is not confirmed. However, we do observe the nonmonotonic structures in\nthe line shape of the baryon effective form factors or the ratio $|G_E/G_M|$\nfor the charmed baryon $\\Lambda^+_c$. These features can be naturally explained\nby incorporating contributions from excited vector states. More precise\nmeasurements of the $e^+e^-\\to B \\bar{B}$ reaction offer a valuable opportunity\nto probe the properties of excited vector states, which are at present poorly\nknown. Additionally, comprehensive theoretical and experimental studies of\nbaryon timelike electromagnetic form factors can provide critical insights into\nthe underlying mechanisms of electron-positron annihilation processes.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-07T09:42:07Z"}
{"aid":"http://arxiv.org/abs/2504.04918v1","title":"Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B","summary":"As language models continue to grow larger, the cost of acquiring\nhigh-quality training data has increased significantly. Collecting human\nfeedback is both expensive and time-consuming, and manual labels can be noisy,\nleading to an imbalance between helpfulness and harmfulness. Constitutional AI,\nintroduced by Anthropic in December 2022, uses AI to provide feedback to\nanother AI, greatly reducing the need for human labeling. However, the original\nimplementation was designed for a model with around 52 billion parameters, and\nthere is limited information on how well Constitutional AI performs with\nsmaller models, such as LLaMA 3-8B. In this paper, we replicated the\nConstitutional AI workflow using the smaller LLaMA 3-8B model. Our results show\nthat Constitutional AI can effectively increase the harmlessness of the model,\nreducing the Attack Success Rate in MT-Bench by 40.8%. However, similar to the\noriginal study, increasing harmlessness comes at the cost of helpfulness. The\nhelpfulness metrics, which are an average of the Turn 1 and Turn 2 scores,\ndropped by 9.8% compared to the baseline. Additionally, we observed clear signs\nof model collapse in the final DPO-CAI model, indicating that smaller models\nmay struggle with self-improvement due to insufficient output quality, making\neffective fine-tuning more challenging. Our study suggests that, like reasoning\nand math ability, self-improvement is an emergent property.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T11:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.04919v1","title":"Distorted Sounds: Unlocking the Physics of Modern Music","summary":"In the production of modern music, the musical characteristics of the guitar\nor keyboard amplifier play an integral role in the creative process. This\narticle explores the physics of music with an emphasis on the role of\ndistortion in the amplification. In particular, we derive and illustrate how a\ndistorted amplifier creates new musical notes that are not played by the\nmusician, greatly simplifying the playing technique. In providing a\ncomprehensive understanding, we commence with a discussion of the physics of\nmusic, highlighting the harmonic series and its relation to pleasing harmonies.\nThis is placed in the context of the standard music notation of intervals and\ntheir relation to note frequency ratios. We then discuss the problems of tuning\nan instrument and why the equal temperament of standard guitar tuners is\nincompatible with good sounding music when amplifier distortion is involved.\nDrawing on the basic trigonometric identities for angle sums and differences,\nwe show how the nonlinear amplification of a distorted amplifier, generates new\nnotes not played by the musician. Here the importance of setting your guitar\ntuner aside and using your ear to tune is emphasised. We close with a\ndiscussion of how humans decipher musical notes and why some highly distorted\nguitar chords give the impression of low notes that are not actually there.\nThis article will be of assistance to students interested in the physics of\nmusic and lecturers seeking fascinating and relevant applications of\nmathematical trigonometric relations and physics to capture the attention of\ntheir students.","main_category":"physics.pop-ph","categories":"physics.pop-ph","published":"2025-04-07T11:01:46Z"}
{"aid":"http://arxiv.org/abs/2504.04921v1","title":"Expectations vs Reality -- A Secondary Study on AI Adoption in Software\n  Testing","summary":"In the software industry, artificial intelligence (AI) has been utilized more\nand more in software development activities. In some activities, such as\ncoding, AI has already been an everyday tool, but in software testing\nactivities AI it has not yet made a significant breakthrough. In this paper,\nthe objective was to identify what kind of empirical research with industry\ncontext has been conducted on AI in software testing, as well as how AI has\nbeen adopted in software testing practice. To achieve this, we performed a\nsystematic mapping study of recent (2020 and later) studies on AI adoption in\nsoftware testing in the industry, and applied thematic analysis to identify\ncommon themes and categories, such as the real-world use cases and benefits, in\nthe found papers. The observations suggest that AI is not yet heavily utilized\nin software testing, and still relatively few studies on AI adoption in\nsoftware testing have been conducted in the industry context to solve\nreal-world problems. Earlier studies indicated there was a noticeable gap\nbetween the actual use cases and actual benefits versus the expectations, which\nwe analyzed further. While there were numerous potential use cases for AI in\nsoftware testing, such as test case generation, code analysis, and intelligent\ntest automation, the reported actual implementations and observed benefits were\nlimited. In addition, the systematic mapping study revealed a potential problem\nwith false positive search results in online databases when using the search\nstring \"artificial intelligence\".","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-07T11:03:54Z"}
{"aid":"http://arxiv.org/abs/2504.04922v1","title":"Real-time tuneable bright bonding plasmonic modes in Ga nanostructures","summary":"The precise control of nanogaps is crucial for plasmonic nanoassemblies,\nwhere plasmon hybridization is highly sensitive to gap size and geometry. This\nsensitivity enables fine-tuning of the resonance wavelength and near-field\nenhancement, offering the potential for advanced optical applications. However,\nconventional lithographic techniques for gap modulation are constrained to\ndiscrete values and face challenges in achieving nanometer order of\nseparations. Such limitations hinder the comprehensive study of plasmon\ncoupling across varying interaction regimes. Overcoming these challenges is\nessential for advancing nanoplasmonic research and its practical applications.\nHerein, we demonstrate a tuneable plasmonic device in which real-time\ntunability of this hybridization mode is achieved via manipulation of the\ninter-droplet gap of liquid metal nanoparticles by macroscopic physical\ndeformation. In particular, we show that the optical spectra obtained from the\nsample shift towards higher energy on the application of a linear strain,\nresulting in an increase of inter-droplet gaps leading to a direct probing of\nthe bright modes in situ. Our method thus offers a novel means of exploring the\nfundamental concept of real-time tuneable plasmon hybridization as well as\ntuning of nanoparticle assembly with any desired gap in a controlled manner.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T11:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.04926v1","title":"Coupling of AlfvÃ©n and magnetosonic waves in rotating Hall\n  magnetoplasmas","summary":"We study the linear theory of magnetohydrodynamic (MHD) waves, namely the\nAlfv{\\'e}n and the fast and slow magnetosonic modes in a rotating Hall-MHD\nplasma with the effects of the obliqueness of the external magnetic field and\nthe Coriolis force and show that these waves can be coupled either by the\ninfluence of the Coriolis force or the Hall effects. To this end, we derive a\ngeneral form of the linear dispersion relation for these coupled modes by the\ncombined influence of the Coriolis force and the Hall effects and analyze\nnumerically their characteristics in three different plasma-$\\beta$ regimes:\n$\\beta\\sim1$, $\\beta>1$, and $\\beta<1$, including some particular cases. We\nshow that while the coupling between the Alfv{\\'e}n and the fast magnetosonic\nmodes is strong in the low-$\\beta$ $(\\beta\\lesssim1)$ regime and the wave\ndispersion appears in the form of a thumb curve, in the high-$\\beta~(\\beta>1)$\nregime, the strong coupling can occur between the Alfv{\\'e}n and the slow\nmagnetosonic modes and the dispersion appears in the form of a teardrop curve.\nSwitching of the coupling in the regime of $\\beta\\sim1$ can occur, i.e.,\ninstead of a thumb curve, a teardrop curve appears when the obliqueness of\npropagation and rotational angle are close to $70^\\circ$ or more (but less than\n$90^\\circ$). Implications of our results to solar and fusion plasmas are\nbriefly discussed.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-07T11:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.04933v1","title":"Deformation of the Heisenberg-Weyl algebra and the Lie superalgebra\n  $\\mathfrak{osp}\\left( {1|2} \\right)$: exact solution for the quantum harmonic\n  oscillator with a position-dependent mass","summary":"We propose a new deformation of the quantum harmonic oscillator\nHeisenberg-Weyl algebra with a parameter $a>-1$. This parameter is introduced\nthrough the replacement of the homogeneous mass $m_0$ in the definition of the\nmomentum operator $\\hat p_x$ as well as in the creation-annihilation operators\n$\\hat a^\\pm$ with a mass varying with position $x$. The realization of such a\ndeformation is shown through the exact solution of the corresponding\nSchr\\\"odinger equation for the non-relativistic quantum harmonic oscillator\nwithin the canonical approach. The obtained analytical expression of the energy\nspectrum consists of an infinite number of equidistant levels, whereas the\nwavefunctions of the stationary states of the problem under construction are\nexpressed through the Hermite polynomials. Then, the Heisenberg-Weyl algebra\ndeformation is generalized to the case of the Lie superalgebra\n$\\mathfrak{osp}\\left( {1|2} \\right)$. It is shown that the realization of such\na generalized superalgebra can be performed for the parabose quantum harmonic\noscillator problem, the mass of which possesses a behavior completely\noverlapping with the position-dependent mass of the canonically deformed\nharmonic oscillator problem. This problem is solved exactly for both even and\nodd stationary states. It is shown that the energy spectrum of the deformed\nparabose oscillator is still equidistant, however, both even and odd state\nwavefunctions are now expressed through the Laguerre polynomials. Some basic\nlimit relations recovering the canonical harmonic oscillator with constant mass\nare also discussed briefly.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other,math-ph,math.MP","published":"2025-04-07T11:18:38Z"}
{"aid":"http://arxiv.org/abs/2504.04954v1","title":"GOTHAM: Graph Class Incremental Learning Framework under Weak\n  Supervision","summary":"Graphs are growing rapidly, along with the number of distinct label\ncategories associated with them. Applications like e-commerce, healthcare,\nrecommendation systems, and various social media platforms are rapidly moving\ntowards graph representation of data due to their ability to capture both\nstructural and attribute information. One crucial task in graph analysis is\nnode classification, where unlabeled nodes are categorized into predefined\nclasses. In practice, novel classes appear incrementally sometimes with just a\nfew labels (seen classes) or even without any labels (unseen classes), either\nbecause they are new or haven't been explored much. Traditional methods assume\nabundant labeled data for training, which isn't always feasible. We investigate\na broader objective: \\emph{Graph Class Incremental Learning under Weak\nSupervision (GCL)}, addressing this challenge by meta-training on base classes\nwith limited labeled instances. During the incremental streams, novel classes\ncan have few-shot or zero-shot representation. Our proposed framework GOTHAM\nefficiently accommodates these unlabeled nodes by finding the closest prototype\nrepresentation, serving as class representatives in the attribute space. For\nText-Attributed Graphs (TAGs), our framework additionally incorporates semantic\ninformation to enhance the representation. By employing teacher-student\nknowledge distillation to mitigate forgetting, GOTHAM achieves promising\nresults across various tasks. Experiments on datasets such as Cora-ML, Amazon,\nand OBGN-Arxiv showcase the effectiveness of our approach in handling evolving\ngraph data under limited supervision. The repository is available here:\n\\href{https://github.com/adityashahane10/GOTHAM--Graph-based-Class-Incremental-Learning-Framework-under-Weak-Supervision}{\\small\n\\textcolor{blue}{Code}}","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T11:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.04955v1","title":"The Short-spacing Interferometer Array for Global 21-cm Signal Detection\n  (SIGMA): Design of the Antennas and Layout","summary":"Numerous experiments have been designed to investigate the Cosmic Dawn (CD)\nand Epoch of Reionization (EoR) by examining redshifted 21-cm emissions from\nneutral hydrogen. Detecting the global spectrum of redshifted 21-cm signals is\ntypically achieved through single-antenna experiments. However, this global\n21-cm signal is deeply embedded in foreground emissions, which are about four\norders of magnitude stronger. Extracting this faint signal is a significant\nchallenge, requiring highly precise instrumental calibration. Additionally,\naccurately modelling receiver noise in single-antenna experiments is inherently\ncomplex. An alternative approach using a short-spacing interferometer is\nexpected to alleviate these difficulties because the noise in different\nreceivers is uncorrelated and averages to zero upon cross-correlation. The\nShort-spacing Interferometer array for Global 21-cm Signal detection (SIGMA) is\nan upcoming experiment aimed at detecting the global CD/EoR signal using this\napproach. We describe the SIGMA system with a focus on optimal antenna design\nand layout, and propose a framework to address cross-talk between antennas in\nfuture calibrations. The SIGMA system is intended to serve as a prototype to\ngain a better understanding of the system's instrumental effects and to\noptimize its performance further.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-07T11:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.04975v1","title":"Geometric quantization of generalized Hirzebruch fibrations","summary":"Hirzebruch surfaces, defined as the projectivization of line bundles over\n$\\C\\mathbb{P}^1$, support a toric action and thus represent an infinite class\nof symplectic toric manifolds of complex dimension 2. In this paper, an\ninfinite class of toric manifolds given as projective bundles over\n$\\mathbb{C}\\mathbb{P}^d$ will be constructed for every complex dimension $d$\nand it will be shown that each manifold supports a symplectic structure. With\nthe toric and symplectic structure of the manifolds at our disposal, we then\nstudy their geometric quantization and how it relates to different values of\nthe twisting parameter of the fibrations.","main_category":"math.SG","categories":"math.SG","published":"2025-04-07T12:04:15Z"}
{"aid":"http://arxiv.org/abs/2504.04996v1","title":"Laplacian eigenvalues for large negative Robin parameters on domains\n  with outward peaks","summary":"We study the asymptotic behavior of individual eigenvalues of the Laplacian\nin domains with outward peaks for large negative Robin parameters. A large\nclass of cross-sections is allowed, and the resulting asymptotic expansions\nreflect both the sharpness of the peak and the geometric shape of its\ncross-section. The results are an extension of previous works dealing with\npeaks whose cross-sections are balls.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-04-07T12:24:29Z"}
{"aid":"http://arxiv.org/abs/2504.05042v1","title":"Lattice packing of spheres in high dimensions using a stochastically\n  evolving ellipsoid","summary":"We prove that in any dimension $n$ there exists an origin-symmetric ellipsoid\n${\\mathcal{E}} \\subset {\\mathbb{R}}^n$ of volume $ c n^2 $ that contains no\npoints of ${\\mathbb{Z}}^n$ other than the origin, where $c > 0$ is a universal\nconstant. Equivalently, there exists a lattice sphere packing in\n${\\mathbb{R}}^n$ whose density is at least $cn^2 \\cdot 2^{-n}$. Previously\nknown constructions of sphere packings in ${\\mathbb{R}}^n$ had densities of the\norder of magnitude of $n \\cdot 2^{-n}$, up to logarithmic factors. Our proof\nutilizes a stochastically evolving ellipsoid that accumulates at least $c n^2$\nlattice points on its boundary, while containing no lattice points in its\ninterior except for the origin.","main_category":"math.MG","categories":"math.MG,math.NT,math.PR","published":"2025-04-07T13:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.05097v1","title":"State Tuning: State-based Test-Time Scaling on RWKV-7","summary":"Test-time scaling has emerged as a prominent research direction in machine\nlearning, enabling models to enhance their expressive capabilities during\ninference.Transformers, renowned for striking a delicate balance between\nefficiency and expressiveness, have benefited from test-time scaling techniques\nthat leverage an expanding key-value (KV) cache to significantly improve\nperformance.In this paper, we introduce a novel state-based approach to\ntest-time scaling, which we term state tuning, tailored to the RNN-based RWKV-7\nmodel.By exploiting the unique strengths of RWKV-7, our method achieves\nstate-of-the-art performance on the target task without altering the model's\npre-trained weights. Our approach centers on three key innovations. First, we\ndevelop an observer framework that allows a smaller model to replicate and\nlearn the state dynamics of the RWKV-7 model. Second, we employ a kernel method\nto dynamically upscale the state size, enhancing the model's capacity to\ncapture intricate patterns. Third, we integrate Decorrelated Backpropagation\n(DBP) to optimize the upscaled state matrix, thereby improving convergence and\nexpressivity. By tuning only the state matrix, we demonstrate that a smaller\nmodel can outperform larger models on the given task. This method preserves the\nefficiency of the original RWKV-7 architecture while harnessing the power of\ntest-time scaling to deliver superior results. Our findings underscore the\npotential of state tuning as an effective strategy for advancing model\nperformance in resource-constrained settings. Our code is\nhttps://github.com/TorchRWKV/flash-linear-attention.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-07T14:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.05119v1","title":"Balancing Robustness and Efficiency in Embedded DNNs Through Activation\n  Function Selection","summary":"Machine learning-based embedded systems for safety-critical applications,\nsuch as aerospace and autonomous driving, must be robust to perturbations\ncaused by soft errors. As transistor geometries shrink and voltages decrease,\nmodern electronic devices become more susceptible to background radiation,\nincreasing the concern about failures produced by soft errors. The resilience\nof deep neural networks (DNNs) to these errors depends not only on target\ndevice technology but also on model structure and the numerical representation\nand arithmetic precision of their parameters. Compression techniques like\npruning and quantization, used to reduce memory footprint and computational\ncomplexity, alter both model structure and representation, affecting soft error\nrobustness. In this regard, although often overlooked, the choice of activation\nfunctions (AFs) impacts not only accuracy and trainability but also\ncompressibility and error resilience. This paper explores the use of bounded\nAFs to enhance robustness against parameter perturbations, while evaluating\ntheir effects on model accuracy, compressibility, and computational load with a\ntechnology-agnostic approach. We focus on encoder-decoder convolutional models\ndeveloped for semantic segmentation of hyperspectral images with application to\nautonomous driving systems. Experiments are conducted on an AMD-Xilinx's KV260\nSoM.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.AR,cs.CV,eess.IV","published":"2025-04-07T14:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.05127v1","title":"Transitivity of the pure Hurwitz classes of quadratic post-critically\n  finite polynomials","summary":"We prove that for two post-critically finite quadratic polynomials $f,g$,\nthere is a mapping class $\\phi$ of the sphere with finitely many marked points\nsuch that $f\\phi$ and $g$ are pure Hurwitz equivalent.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-07T14:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.05141v1","title":"EffOWT: Transfer Visual Language Models to Open-World Tracking\n  Efficiently and Effectively","summary":"Open-World Tracking (OWT) aims to track every object of any category, which\nrequires the model to have strong generalization capabilities. Trackers can\nimprove their generalization ability by leveraging Visual Language Models\n(VLMs). However, challenges arise with the fine-tuning strategies when VLMs are\ntransferred to OWT: full fine-tuning results in excessive parameter and memory\ncosts, while the zero-shot strategy leads to sub-optimal performance. To solve\nthe problem, EffOWT is proposed for efficiently transferring VLMs to OWT.\nSpecifically, we build a small and independent learnable side network outside\nthe VLM backbone. By freezing the backbone and only executing backpropagation\non the side network, the model's efficiency requirements can be met. In\naddition, EffOWT enhances the side network by proposing a hybrid structure of\nTransformer and CNN to improve the model's performance in the OWT field.\nFinally, we implement sparse interactions on the MLP, thus reducing parameter\nupdates and memory costs significantly. Thanks to the proposed methods, EffOWT\nachieves an absolute gain of 5.5% on the tracking metric OWTA for unknown\ncategories, while only updating 1.3% of the parameters compared to full\nfine-tuning, with a 36.4% memory saving. Other metrics also demonstrate obvious\nimprovement.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T14:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.05155v1","title":"Phonon properties and unconventional heat transfer in quasi-2D\n  $Bi_2O_2Se$ crystal","summary":"Bi2O2Se belongs to a group of quasi-2D semiconductors that can replace\nsilicon in future high-speed/low-power electronics. However, the correlation\nbetween crystal/band structure and other physical properties still eludes\nunderstanding: carrier mobility increases non-intuitively with carrier\nconcentration; the observed $T^2$ temperature dependence of resistivity lacks\nexplanation. Moreover, a very high relative out-of-plane permittivity of about\n150 has been reported in the literature. A proper explanation for such a high\npermittivity is still lacking. We have performed infrared (IR) reflectivity and\nRaman scattering experiments on a large perfect single crystal with defined\nmosaicity, carrier concentration and mobility. Five of the eight phonons\nallowed by factor group theory have been observed and their symmetries\ndetermined. The IR spectra show that the permittivity measured in the\ntetragonal plane is as high as ${\\epsilon}_r{\\approx}500$, and this high value\nis due to a strong polar phonon with a low frequency of ~34 $cm^{-1}$ (~1 THz).\nSuch an unusually high permittivity allows the screening of charge defects,\nleading to the observation of high electron mobility at low temperatures. It\nalso allows effective modulation doping providing a platform for high\nperformance 2D electronics. DFT calculations suggest the existence of a very\nlow frequency acoustic phonon ~14 $cm^{-1}$ (~0.4 THz). Both the low frequency\nphonons cause anomalous phonon DOS, which is reflected in the unconventional\ntemperature dependence of the heat capacity, $c_M{\\approx}T^{3.5}$. The\ntemperature-dependent, two-component group velocity is proposed to explains the\nunusual temperature dependence of the thermal conductivity,\n${\\kappa}{\\approx}T^{1.5}$","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T14:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05160v1","title":"Some new functionals related to free boundary minimal submanifolds","summary":"The metrics induced on free boundary minimal surfaces in geodesic balls in\nthe upper unit hemisphere and hyperbolic space can be characterized as critical\nmetrics for the functionals $\\Theta_{r,i}$ and $\\Omega_{r,i}$, introduced\nrecently by Lima, Menezes and the second author. In this paper, we generalize\nthis characterization to free boundary minimal submanifolds of higher dimension\nin the same spaces. We also introduce some functionals of the form different\nfrom $\\Theta_{r,i}$ and show that the critical metrics for them are the metrics\ninduced by free boundary minimal immersions into a geodesic ball in the upper\nunit hemisphere. In the case of surfaces, these functionals are bounded from\nabove and not bounded from below. Moreover, the canonical metric on a geodesic\ndisk in a 3-ball in the upper unit hemisphere is maximal for this functional on\nthe set of all Riemannian metric of the topological disk.","main_category":"math.DG","categories":"math.DG","published":"2025-04-07T15:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.05172v1","title":"Attention-Based Multi-Scale Temporal Fusion Network for Uncertain-Mode\n  Fault Diagnosis in Multimode Processes","summary":"Fault diagnosis in multimode processes plays a critical role in ensuring the\nsafe operation of industrial systems across multiple modes. It faces a great\nchallenge yet to be addressed - that is, the significant distributional\ndifferences among monitoring data from multiple modes make it difficult for the\nmodels to extract shared feature representations related to system health\nconditions. In response to this problem, this paper introduces a novel method\ncalled attention-based multi-scale temporal fusion network. The multi-scale\ndepthwise convolution and gated recurrent unit are employed to extract\nmulti-scale contextual local features and long-short-term features. A temporal\nattention mechanism is designed to focus on critical time points with higher\ncross-mode shared information, thereby enhancing the accuracy of fault\ndiagnosis. The proposed model is applied to Tennessee Eastman process dataset\nand three-phase flow facility dataset. The experiments demonstrate that the\nproposed model achieves superior diagnostic performance and maintains a small\nmodel size.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T15:16:22Z"}
{"aid":"http://arxiv.org/abs/2504.05181v1","title":"Lightweight and Direct Document Relevance Optimization for Generative\n  Information Retrieval","summary":"Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.DL,cs.LG,H.3.3","published":"2025-04-07T15:27:37Z"}
{"aid":"http://arxiv.org/abs/2504.05185v1","title":"Concise Reasoning via Reinforcement Learning","summary":"Despite significant advancements in large language models (LLMs), a major\ndrawback of reasoning models is their enormous token usage, which increases\ncomputational cost, resource requirements, and response time. In this work, we\nrevisit the core principles of reinforcement learning (RL) and, through\nmathematical analysis, demonstrate that the tendency to generate lengthy\nresponses arises inherently from RL-based optimization during training. This\nfinding questions the prevailing assumption that longer responses inherently\nimprove reasoning accuracy. Instead, we uncover a natural correlation between\nconciseness and accuracy that has been largely overlooked. Moreover, we show\nthat introducing a secondary phase of RL post-training, using a small set of\nproblems and limited resources, can significantly reduce a model's chain of\nthought while maintaining or even enhancing accuracy. Finally, we validate our\nconclusions through extensive experimental results.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T15:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.05189v1","title":"Influence of pore-confined water on the thermal expansion of a\n  zinc-based metal-organic framework","summary":"Understanding the reversible intercalation of guest molecules into\nmetal-organic frameworks is crucial for advancing their design for practical\napplications. In this work, we explore the impact of H$_{\\mathrm{2}}\\!$O as a\nguest molecule on the thermal expansion of the zinc-based metal-organic\nframework GUT-2. Dehydration is achieved by thermal treatment of hydrated\nGUT-2. Rietveld refinement performed on temperature-dependent X-ray powder\ndiffraction data confirms the reversible structural transformation.\nAdditionally, it allows the determination of anisotropic thermal expansion\ncoefficients for both phases. The hydrated form exhibits near-zero thermal\nexpansion along the polymer chain direction, moderate expansion In the\ndirection of predominantly hydrogen bonds, and the highest expansion in the\ndirection with only Van der Waals bonding. Upon activation, the removal of\nH$_{\\mathrm{2}}\\!$O molecules triggers a doubling of the thermal expansion\ncoefficient in the direction, where the hydrogen bonds have been removed.\nRegarding the dynamics of the process, thermal activation in air occurs within\n6 hours at a temperature of 50{\\deg}C and takes only 30 minutes when heating to\n90{\\deg}C. In contrast, full rehydration under standard lab conditions (30 %\nrelative humidity) requires two days. During the activation/dehydration\nprocesses no change of the widths of the X-ray diffraction peaks is observed,\nwhich shows that the underlying crystal structures remains fully intact during\nthe transition processes. Fitting the transformations by the Avrami equation\nreveals a quasi one-dimensional evolution of the dehydrated areas for the\nactivation process and a more intricate, predominantly two-dimensional\nmechanism for the rehydration.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T15:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.05209v1","title":"Detailed $SU(3)$ Flavour Symmetry Analysis of Charmless Two-Body\n  $B$-Meson Decays Including Factorizable Corrections","summary":"We study the decays of $B_{(s)}$ mesons into light pseudoscalar mesons under\nthe $SU(3)$ flavour symmetry. Assuming exact $SU(3)$ symmetry at the level of\nthe amplitudes leads to a simple parameterization. Using the available\nexperimental data and, for the first time, mixing effects in the $B_s^0$\ndecays, we find that the data cannot be described with this assumption. We\nimprove this parametrization by including {\\it factorizable}\n$SU(3)_\\mathrm{F}$-breaking effects. This new approach allows for an excellent\ndescription of the data, with a fit $p$ value of $32.3\\%$. We provide posterior\npredictions for all observables and identify several decay channels that would\nsignificantly impact our analysis. Finally, we briefly compare our results with\nthe predictions of QCD factorization, paving the way to a more detailed\nanalysis which could provide insights into QCD effects at low energy scales.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-07T15:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.05215v1","title":"Quasinormal modes and absorption cross-section of a Bardeen black hole\n  surrounded by perfect fluid dark matter in four dimensions","summary":"In this paper we study quasinormal modes and absorption cross sections for\nthe $(1+3)$-dimensional Bardeen black hole surrounded by perfect fluid dark\nmatter. Studies of the massless scalar field is already done in\n\\cite{Sun:2023slzl}. Hence, in this paper we will focus on the massive scalar\nfield perturbations and massless Dirac field perturbations. To compute the\nquasinormal modes we use the semi-analytical 3rd-order WKB method, which has\nbeen shown to be one of the best approaches when the effective potential is\nadequate and when $n < \\ell$ and $n < \\lambda$. We have also utilized the\nP\\\"oschl-Teller method to compare the valus obtained using the WKB approach. We\nhave computed quasinormal frequencies by varying various parameters of the\ntheory such as the mass of the scalar field $\\mu$, dark matter parameter\n$\\alpha$ and the magnetic charge $g$. We have summarized our solutions in\ntables and figures for clarity. As for the absorption cross section, we used\nthird order WKB approach to compute reflection, transmission coefficients and\npartial absorption cross sections. Graphs are presented to demonstrate the\nbehavior of the above quantities when the dark matter parameter and mass of the\nmassive scalar field are varied.","main_category":"gr-qc","categories":"gr-qc,astro-ph.SR,hep-th","published":"2025-04-07T16:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.05219v1","title":"An ensemble deep learning approach to detect tumors on Mohs micrographic\n  surgery slides","summary":"Mohs micrographic surgery (MMS) is the gold standard technique for removing\nhigh risk nonmelanoma skin cancer however, intraoperative histopathological\nexamination demands significant time, effort, and professionality. The\nobjective of this study is to develop a deep learning model to detect basal\ncell carcinoma (BCC) and artifacts on Mohs slides. A total of 731 Mohs slides\nfrom 51 patients with BCCs were used in this study, with 91 containing tumor\nand 640 without tumor which was defined as non-tumor. The dataset was employed\nto train U-Net based models that segment tumor and non-tumor regions on the\nslides. The segmented patches were classified as tumor, or non-tumor to produce\npredictions for whole slide images (WSIs). For the segmentation phase, the deep\nlearning model success was measured using a Dice score with 0.70 and 0.67\nvalue, area under the curve (AUC) score with 0.98 and 0.96 for tumor and\nnon-tumor, respectively. For the tumor classification, an AUC of 0.98 for\npatch-based detection, and AUC of 0.91 for slide-based detection was obtained\non the test dataset. We present an AI system that can detect tumors and\nnon-tumors in Mohs slides with high success. Deep learning can aid Mohs\nsurgeons and dermatopathologists in making more accurate decisions.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-07T16:05:42Z"}
{"aid":"http://arxiv.org/abs/2504.05253v1","title":"Contour Integration Underlies Human-Like Vision","summary":"Despite the tremendous success of deep learning in computer vision, models\nstill fall behind humans in generalizing to new input distributions. Existing\nbenchmarks do not investigate the specific failure points of models by\nanalyzing performance under many controlled conditions. Our study\nsystematically dissects where and why models struggle with contour integration\n-- a hallmark of human vision -- by designing an experiment that tests object\nrecognition under various levels of object fragmentation. Humans (n=50) perform\nat high accuracy, even with few object contours present. This is in contrast to\nmodels which exhibit substantially lower sensitivity to increasing object\ncontours, with most of the over 1,000 models we tested barely performing above\nchance. Only at very large scales ($\\sim5B$ training dataset size) do models\nbegin to approach human performance. Importantly, humans exhibit an integration\nbias -- a preference towards recognizing objects made up of directional\nfragments over directionless fragments. We find that not only do models that\nshare this property perform better at our task, but that this bias also\nincreases with model training dataset size, and training models to exhibit\ncontour integration leads to high shape bias. Taken together, our results\nsuggest that contour integration is a hallmark of object vision that underlies\nobject recognition performance, and may be a mechanism learned from data at\nscale.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.05266v1","title":"Differential forms: Lagrange interpolation, sampling and approximation\n  on polynomial admissible integral k-meshes","summary":"In this work we address the problem of interpolating and approximating\ndifferential forms starting from data defined by integration. We show that many\naspects of nodal interpolation can naturally be carried to this more general\nframework; in contrast, some of them require the introduction of geometric and\nmeasure theoretic hypotheses. After characterizing the norms of the operators\ninvolved, we introduce the concept of admissible integral k-mesh, which allows\nfor the construction of robust approximation schemes, and is used to extract\ninterpolation sets with high stability properties. To this end, the concepts of\nFekete currents and Leja sequences of currents are formalized, and a numerical\nscheme for their approximation is proposed.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T17:04:51Z"}
{"aid":"http://arxiv.org/abs/2504.05268v1","title":"Performance and Complexity Analysis of Terahertz-Band MIMO Detection","summary":"Achieving terabit-per-second (Tbps) data rates in terahertz (THz)-band\ncommunications requires bridging the complexity gap in baseband transceiver\ndesign. This work addresses the signal processing challenges associated with\ndata detection in THz multiple-input multiple-output (MIMO) systems. We begin\nby analyzing the trade-offs between performance and complexity across various\ndetection schemes and THz channel models, demonstrating significant complexity\nreduction by leveraging spatial parallelizability over subspaces of correlated\nTHz MIMO channels. We derive accurate detection error probability bounds by\naccounting for THz-specific channel models and mismatches introduced by\nsubspace decomposition. Building on this, we propose a subspace detector that\nintegrates layer sorting, QR decomposition, and channel-matrix puncturing to\nbalance performance loss and parallelizability. Furthermore, we introduce a\nchannel-matrix reuse strategy for wideband THz MIMO detection. Simulations over\naccurate, ill-conditioned THz channels show that efficient parallelizability\nachieves multi-dB performance gains, while wideband reuse strategies offer\ncomputational savings with minimal performance degradation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T17:06:07Z"}
{"aid":"http://arxiv.org/abs/2504.05280v1","title":"Dimensionality Enhanced Out-of-Plane Spin Currents in NbIrTe$_4$ for\n  Efficient Field-Free Switching of Perpendicular Magnetization","summary":"Efficient generation of out-of-plane (OOP) spin currents is crucial for\nadvanced spintronic memory applications. However, the theoretical understanding\nand experimental implementation of robust OOP spin currents for high-density\nand low-power magnetization switching remain significant challenges of\nspintronics. Here, we demonstrate that transitioning NbIrTe$_4$ from a\ntwo-dimensional quantum spin Hall insulator to a three-dimensional type-II Weyl\nsemimetal markedly enhances OOP spin current generation. The bulk topological\nWeyl semimetal nature of NbIrTe$_4$, characterized by its Weyl cone,\nsignificantly enhances the OOP spin Berry curvature, enabling an unprecedented\nOOP spin Hall conductivity exceeding $10^5\\hbar/2e$ $\\Omega^{-1}m^{-1} $. This\nenhancement, surpassing the in-plane component by more than fourfold, enables\nefficient and field-free spin-orbit torque (SOT) switching of perpendicular\nmagnetization with a low current density of 1.4 MA/cm$^2$. The improved spin\nHall conductivity reduces the overall power consumption by more than two orders\nof magnitude compared to existing systems, such as heavy metals. Our findings\nhighlight the pivotal role of dimensionality in harnessing robust OOP spin\ncurrents in topological Weyl semimetals, paving the way for the development of\nhigh-density, low-power spintronic memory technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-07T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.05297v1","title":"Eigenvalue-Based Randomness Test for Residual Diagnostics in Panel Data\n  Models","summary":"This paper introduces the Eigenvalue-Based Randomness (EBR) test - a novel\napproach rooted in the Tracy-Widom law from random matrix theory - and applies\nit to the context of residual analysis in panel data models. Unlike traditional\nmethods, which target specific issues like cross-sectional dependence or\nautocorrelation, the EBR test simultaneously examines multiple assumptions by\nanalyzing the largest eigenvalue of a symmetrized residual matrix. Monte Carlo\nsimulations demonstrate that the EBR test is particularly robust in detecting\nnot only standard violations such as autocorrelation and linear cross-sectional\ndependence (CSD) but also more intricate non-linear and non-monotonic\ndependencies, making it a comprehensive and highly flexible tool for enhancing\nthe reliability of panel data analyses.","main_category":"stat.ME","categories":"stat.ME,econ.EM,stat.AP,stat.CO","published":"2025-04-07T17:52:36Z"}
{"aid":"http://arxiv.org/abs/2504.05632v1","title":"Reasoning Towards Fairness: Mitigating Bias in Language Models through\n  Reasoning-Guided Fine-Tuning","summary":"Recent advances in large-scale generative language models have shown that\nreasoning capabilities can significantly improve model performance across a\nvariety of tasks. However, the impact of reasoning on a model's ability to\nmitigate stereotypical responses remains largely underexplored. In this work,\nwe investigate the crucial relationship between a model's reasoning ability and\nfairness, and ask whether improved reasoning capabilities can mitigate harmful\nstereotypical responses, especially those arising due to shallow or flawed\nreasoning. We conduct a comprehensive evaluation of multiple open-source LLMs,\nand find that larger models with stronger reasoning abilities exhibit\nsubstantially lower stereotypical bias on existing fairness benchmarks.\nBuilding on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning,\na novel approach that extracts structured reasoning traces from advanced\nreasoning models and infuses them into models that lack such capabilities. We\nuse only general-purpose reasoning and do not require any fairness-specific\nsupervision for bias mitigation. Notably, we see that models fine-tuned using\nReGiFT not only improve fairness relative to their non-reasoning counterparts\nbut also outperform advanced reasoning models on fairness benchmarks. We also\nanalyze how variations in the correctness of the reasoning traces and their\nlength influence model fairness and their overall performance. Our findings\nhighlight that enhancing reasoning capabilities is an effective,\nfairness-agnostic strategy for mitigating stereotypical bias caused by\nreasoning flaws.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-08T03:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.05641v1","title":"Testing black holes in a perfect fluid dark matter environment using\n  quasinormal modes","summary":"This research explores the quasinormal modes (QNMs) characteristics of\ncharged black holes in a perfect fluid dark matter (PFDM) environment. Based on\nthe Event Horizon Telescope (EHT) observations of the M87* black hole shadow,\nwe implemented necessary constraints on the parameter\nspace($a/M$,$\\lambda/M$).We found that for lower values of the magnetic charge\nparameter, the effective range of the PFDM parameter is approximately between\n-0.2 and 0, while as the magnetic charge parameter increases, this effective\nrange gradually extends toward more negative values. Then through sixth-order\nWKB method and time-domain method, we systematically analyzed the quasinormal\noscillation spectra under scalar field and electromagnetic field perturbations.\nThe results reveal that: the magnetic charge $a$ and PFDM parameters $\\lambda$\nmodulate the effective potential barrier of black hole spacetime, profoundly\ninfluencing the response frequency and energy dissipation characteristics of\nexternal perturbations. The consistently negative imaginary part of QNMs across\nthe entire physical parameter domain substantiates the dynamical stability of\nthe investigated system. Moreover, we discovered differences in the parameter\nvariation sensitivity between scalar field and electromagnetic field\nperturbations, providing a theoretical basis for distinguishing different field\ndisturbances. These results not only unveil the modulation mechanisms of\nelectromagnetic interactions and dark matter distribution on black hole\nspacetime structures but also offer potential observational evidence for future\ngravitational wave detection and black hole environment identification.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T03:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.05642v1","title":"Leveraging Prompt-Tuning for Bengali Grammatical Error Explanation Using\n  Large Language Models","summary":"We propose a novel three-step prompt-tuning method for Bengali Grammatical\nError Explanation (BGEE) using state-of-the-art large language models (LLMs)\nsuch as GPT-4, GPT-3.5 Turbo, and Llama-2-70b. Our approach involves\nidentifying and categorizing grammatical errors in Bengali sentences,\ngenerating corrected versions of the sentences, and providing natural language\nexplanations for each identified error. We evaluate the performance of our BGEE\nsystem using both automated evaluation metrics and human evaluation conducted\nby experienced Bengali language experts. Our proposed prompt-tuning approach\nshows that GPT-4, the best performing LLM, surpasses the baseline model in\nautomated evaluation metrics, with a 5.26% improvement in F1 score and a 6.95%\nimprovement in exact match. Furthermore, compared to the previous baseline,\nGPT-4 demonstrates a decrease of 25.51% in wrong error type and a decrease of\n26.27% in wrong error explanation. However, the results still lag behind the\nhuman baseline.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T03:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.05649v1","title":"POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point\n  Cloud","summary":"LiDAR-based 3D object detection is a fundamental task in the field of\nautonomous driving. This paper explores the unique advantage of Frequency\nModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a single\nframe FMCW point cloud with radial velocity measurements, we expect that our\nobject detector can detect the short-term future locations of objects using\nonly the current frame sensor data and demonstrate a fast ability to respond to\nintermediate danger. To achieve this, we extend the standard object detection\ntask to a novel task named predictive object detection (POD), which aims to\npredict the short-term future location and dimensions of objects based solely\non current observations. Typically, a motion prediction task requires\nhistorical sensor information to process the temporal contexts of each object,\nwhile our detector's avoidance of multi-frame historical information enables a\nmuch faster response time to potential dangers. The core advantage of FMCW\nLiDAR lies in the radial velocity associated with every reflected point. We\npropose a novel POD framework, the core idea of which is to generate a virtual\nfuture point using a ray casting mechanism, create virtual two-frame point\nclouds with the current and virtual future frames, and encode these two-frame\nvoxel features with a sparse 4D encoder. Subsequently, the 4D voxel features\nare separated by temporal indices and remapped into two Bird's Eye View (BEV)\nfeatures: one decoded for standard current frame object detection and the other\nfor future predictive object detection. Extensive experiments on our in-house\ndataset demonstrate the state-of-the-art standard and predictive detection\nperformance of the proposed POD framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.05666v1","title":"Contraction and concentration of measures with applications to\n  theoretical neuroscience","summary":"We investigate the asymptotic behavior of probability measures associated\nwith stochastic dynamical systems featuring either globally contracting or\n$B_{r}$-contracting drift terms. While classical results often assume constant\ndiffusion and gradient-based drifts, we extend the analysis to spatially\ninhomogeneous diffusion and non-integrable vector fields. We establish\nsufficient conditions for the existence and uniqueness of stationary measures\nunder global contraction, showing that convergence is preserved when the\ncontraction rate dominates diffusion inhomogeneity. For systems contracting\nonly outside of a compact set and with constant diffusion, we demonstrate mass\nconcentration near the minima of an associated non-convex potential, like in\nmultistable regimes. The theoretical findings are illustrated through Hopfield\nnetworks, highlighting implications for memory retrieval dynamics in noisy\nenvironments.","main_category":"math.DS","categories":"math.DS,math-ph,math.AP,math.MP","published":"2025-04-08T04:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.05696v1","title":"Diabetic Retinopathy Detection Based on Convolutional Neural Networks\n  with SMOTE and CLAHE Techniques Applied to Fundus Images","summary":"Diabetic retinopathy (DR) is one of the major complications in diabetic\npatients' eyes, potentially leading to permanent blindness if not detected\ntimely. This study aims to evaluate the accuracy of artificial intelligence\n(AI) in diagnosing DR. The method employed is the Synthetic Minority\nOver-sampling Technique (SMOTE) algorithm, applied to identify DR and its\nseverity stages from fundus images using the public dataset \"APTOS 2019\nBlindness Detection.\" Literature was reviewed via ScienceDirect, ResearchGate,\nGoogle Scholar, and IEEE Xplore. Classification results using Convolutional\nNeural Network (CNN) showed the best performance for the binary classes normal\n(0) and DR (1) with an accuracy of 99.55%, precision of 99.54%, recall of\n99.54%, and F1-score of 99.54%. For the multiclass classification No_DR (0),\nMild (1), Moderate (2), Severe (3), Proliferate_DR (4), the accuracy was\n95.26%, precision 95.26%, recall 95.17%, and F1-score 95.23%. Evaluation using\nthe confusion matrix yielded results of 99.68% for binary classification and\n96.65% for multiclass. This study highlights the significant potential in\nenhancing the accuracy of DR diagnosis compared to traditional human analysis","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG,q-bio.NC","published":"2025-04-08T05:38:53Z"}
{"aid":"http://arxiv.org/abs/2504.05708v1","title":"Thermodynamic supercriticality and complex phase diagram for the AdS\n  black hole","summary":"In this study, we extend the application of the Lee-Yang phase transition\ntheorem to the realm of AdS black hole thermodynamics, thereby deriving a\ncomprehensive complex phase diagram for such systems. Our research augments\nextant studies on black hole thermodynamic phase diagrams, particularly in the\nregime above the critical point, by delineating the Widom line of AdS black\nholes. This boundary segregates the supercritical domain of the phase diagram\ninto two disparate zones. As the system traverses the thermodynamic crossover\nwithin the supercritical region, it undergoes a transition from one\nsupercritical phase to another, while maintaining the continuity of its\nthermodynamic state functions. This behavior is fundamentally different from\nthat below the critical point, where crossing the coexistence line results in\ndiscontinuities of thermodynamic state functions. The Widom line enables a\nthermodynamic crossover between single-phase states without traversing the\nspinodal that emerges in the critical region.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-08T06:03:39Z"}
{"aid":"http://arxiv.org/abs/2504.05712v1","title":"How I Learned to Stop Worrying and Love ChatGPT","summary":"In the dynamic landscape of software engineering, the emergence of\nChatGPT-generated code signifies a distinctive and evolving paradigm in\ndevelopment practices. We delve into the impact of interactions with ChatGPT on\nthe software development process, specifically analysing its influence on\nsource code changes. Our emphasis lies in aligning code with ChatGPT\nconversations, separately analysing the user-provided context of the code and\nthe extent to which the resulting code has been influenced by ChatGPT.\nAdditionally, employing survival analysis techniques, we examine the longevity\nof ChatGPT-generated code segments in comparison to lines written\ntraditionally. The goal is to provide valuable insights into the transformative\nrole of ChatGPT in software development, illuminating its implications for code\nevolution and sustainability within the ecosystem.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T06:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.05716v1","title":"Single-Agent vs. Multi-Agent LLM Strategies for Automated Student\n  Reflection Assessment","summary":"We explore the use of Large Language Models (LLMs) for automated assessment\nof open-text student reflections and prediction of academic performance.\nTraditional methods for evaluating reflections are time-consuming and may not\nscale effectively in educational settings. In this work, we employ LLMs to\ntransform student reflections into quantitative scores using two assessment\nstrategies (single-agent and multi-agent) and two prompting techniques\n(zero-shot and few-shot). Our experiments, conducted on a dataset of 5,278\nreflections from 377 students over three academic terms, demonstrate that the\nsingle-agent with few-shot strategy achieves the highest match rate with human\nevaluations. Furthermore, models utilizing LLM-assessed reflection scores\noutperform baselines in both at-risk student identification and grade\nprediction tasks. These findings suggest that LLMs can effectively automate\nreflection assessment, reduce educators' workload, and enable timely support\nfor students who may need additional assistance. Our work emphasizes the\npotential of integrating advanced generative AI technologies into educational\npractices to enhance student engagement and academic success.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-08T06:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.05776v1","title":"Quantifying uncertainty in inverse scattering problems set in layered\n  environments","summary":"The attempt to solve inverse scattering problems often leads to optimization\nand sampling problems that require handling moderate to large amounts of\npartial differential equations acting as constraints. We focus here on\ndetermining inclusions in a layered medium from the measurement of wave fields\non the surface, while quantifying uncertainty and addressing the effect of wave\nsolver quality. Inclusions are characterized by a few parameters describing\ntheir material properties and shapes. We devise algorithms to estimate the most\nlikely configurations by optimizing cost functionals with Bayesian\nregularizations and wave constraints. In particular, we design an automatic\nLevenberg-Marquardt-Fletcher type scheme based on the use of algorithmic\ndifferentiation and adaptive finite element meshes for time dependent wave\nequation constraints with changing inclusions. In synthetic tests with a single\nfrequency, this scheme converges in few iterations for increasing noise levels.\nTo attain a global view of other possible high probability configurations and\nasymmetry effects we resort to parallelizable affine invariant Markov Chain\nMonte Carlo methods, at the cost of solving a few million wave problems. This\nforces the use of prefixed meshes. While the optimal configurations remain\nsimilar, we encounter additional high probability inclusions influenced by the\nprior information, the noise level and the layered structure, effect that can\nbe reduced by considering more frequencies. We analyze the effect on the\ncalculations of working with adaptive and fixed meshes, under a simple choice\nof non-reflecting boundary conditions in truncated layered domains for which we\nestablish wellposedness and convergence results.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC,physics.comp-ph,physics.data-an,physics.geo-ph","published":"2025-04-08T07:57:36Z"}
{"aid":"http://arxiv.org/abs/2504.05779v1","title":"FASR-Net: Unsupervised Shadow Removal Leveraging Inherent Frequency\n  Priors","summary":"Shadow removal is challenging due to the complex interaction of geometry,\nlighting, and environmental factors. Existing unsupervised methods often\noverlook shadow-specific priors, leading to incomplete shadow recovery. To\naddress this issue, we propose a novel unsupervised Frequency Aware Shadow\nRemoval Network (FASR-Net), which leverages the inherent frequency\ncharacteristics of shadow regions. Specifically, the proposed Wavelet Attention\nDownsampling Module (WADM) integrates wavelet-based image decomposition and\ndeformable attention, effectively breaking down the image into frequency\ncomponents to enhance shadow details within specific frequency bands. We also\nintroduce several new loss functions for precise shadow-free image\nreproduction: a frequency loss to capture image component details, a\nbrightness-chromaticity loss that references the chromaticity of shadow-free\nregions, and an alignment loss to ensure smooth transitions between shadowed\nand shadow-free regions. Experimental results on the AISTD and SRD datasets\ndemonstrate that our method achieves superior shadow removal performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.05802v1","title":"Mass-Spring Models for Passive Keyword Spotting: A Springtronics\n  Approach","summary":"Mechanical systems played a foundational role in computing history, and have\nregained interest due to their unique properties, such as low damping and the\nability to process mechanical signals without transduction. However, recent\nefforts have primarily focused on elementary computations, implemented in\nsystems based on pre-defined reservoirs, or in periodic systems such as arrays\nof buckling beams. Here, we numerically demonstrate a passive mechanical system\n-- in the form of a nonlinear mass-spring model -- that tackles a real-world\nbenchmark for keyword spotting in speech signals. The model is organized in a\nhierarchical architecture combining feature extraction and continuous-time\nconvolution, with each individual stage tailored to the physics of the\nconsidered mass-spring systems. For each step in the computation, a subsystem\nis designed by combining a small set of low-order polynomial potentials. These\npotentials act as fundamental components that interconnect a network of masses.\nIn analogy to electronic circuit design, where complex functional circuits are\nconstructed by combining basic components into hierarchical designs, we refer\nto this framework as springtronics. We introduce springtronic systems with\nhundreds of degrees of freedom, achieving speech classification accuracy\ncomparable to existing sub-mW electronic systems.","main_category":"cs.SD","categories":"cs.SD,cond-mat.dis-nn,eess.AS","published":"2025-04-08T08:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.05805v1","title":"Why is Normalization Necessary for Linear Recommenders?","summary":"Despite their simplicity, linear autoencoder (LAE)-based models have shown\ncomparable or even better performance with faster inference speed than neural\nrecommender models. However, LAEs face two critical challenges: (i) popularity\nbias, which tends to recommend popular items, and (ii) neighborhood bias, which\noverly focuses on capturing local item correlations. To address these issues,\nthis paper first analyzes the effect of two existing normalization methods for\nLAEs, i.e., random-walk and symmetric normalization. Our theoretical analysis\nreveals that normalization highly affects the degree of popularity and\nneighborhood biases among items. Inspired by this analysis, we propose a\nversatile normalization solution, called Data-Adaptive Normalization (DAN),\nwhich flexibly controls the popularity and neighborhood biases by adjusting\nitem- and user-side normalization to align with unique dataset characteristics.\nOwing to its model-agnostic property, DAN can be easily applied to various\nLAE-based models. Experimental results show that DAN-equipped LAEs consistently\nimprove existing LAE-based models across six benchmark datasets, with\nsignificant gains of up to 128.57% and 12.36% for long-tail items and unbiased\nevaluations, respectively. Refer to our code in https://github.com/psm1206/DAN.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T08:37:32Z"}
{"aid":"http://arxiv.org/abs/2504.05845v1","title":"Eikonal boundary condition for level set method","summary":"In this paper, we propose to use the eikonal equation as a boundary condition\nwhen advective or normal flow equations in the level set formulation are solved\nnumerically on polyhedral meshes in the three-dimensional domain. Since the\nlevel set method can use a signed distance function as an initial condition,\nthe eikonal equation on the boundary is a suitable choice at the initial time.\nEnforcing the eikonal equation on the boundary for later times can eliminate\nthe need for inflow boundary conditions, which are typically required for\ntransport equations. In selected examples where exact solutions are available,\nwe compare the proposed method with the method using the exact Dirichlet\nboundary condition. The numerical results confirm that the use of the eikonal\nboundary condition provides comparable accuracy and robustness in surface\nevolution compared to the use of the exact Dirichlet boundary condition, which\nis generally not available. We also present numerical results of evolving a\ngeneral closed surface.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T09:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.05851v1","title":"Identifying and Replicating Code Patterns Driving Performance\n  Regressions in Software Systems","summary":"Context: Performance regressions negatively impact execution time and memory\nusage of software systems. Nevertheless, there is a lack of systematic methods\nto evaluate the effectiveness of performance test suites. Performance mutation\ntesting, which introduces intentional defects (mutants) to measure and enhance\nfault-detection capabilities, is promising but underexplored. A key challenge\nis understanding if generated mutants accurately reflect real-world performance\nissues. Goal: This study evaluates and extends mutation operators for\nperformance testing. Its objectives include (i) collecting existing performance\nmutation operators, (ii) introducing new operators from real-world code changes\nthat impact performance, and (iii) evaluating these operators on real-world\nsystems to see if they effectively degrade performance. Method: To this aim, we\nwill (i) review the literature to identify performance mutation operators, (ii)\nconduct a mining study to extract patterns of code changes linked to\nperformance regressions, (iii) propose new mutation operators based on these\npatterns, and (iv) apply and evaluate the operators to assess their\neffectiveness in exposing performance degradations. Expected Outcomes: We aim\nto provide an enriched set of mutation operators for performance testing,\nhelping developers and researchers identify harmful coding practices and design\nbetter strategies to detect and prevent performance regressions.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T09:28:46Z"}
{"aid":"http://arxiv.org/abs/2504.05861v1","title":"Sparse Bounded Hop-Spanners for Geometric Intersection Graphs","summary":"We present new results on $2$- and $3$-hop spanners for geometric\nintersection graphs. These include improved upper and lower bounds for $2$- and\n$3$-hop spanners for many geometric intersection graphs in $\\mathbb{R}^d$. For\nexample, we show that the intersection graph of $n$ balls in $\\mathbb{R}^d$\nadmits a $2$-hop spanner of size $O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2\\lfloor\nd/2\\rfloor +1)}}\\right)$ and the intersection graph of $n$ fat axis-parallel\nboxes in $\\mathbb{R}^d$ admits a $2$-hop spanner of size $O(n \\log^{d+1}n)$.\n  Furthermore, we show that the intersection graph of general semi-algebraic\nobjects in $\\mathbb{R}^d$ admits a $3$-hop spanner of size\n$O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2D-1)}}\\right)$, where $D$ is a parameter\nassociated with the description complexity of the objects. For such families\n(or more specifically, for tetrahedra in $\\mathbb{R}^3$), we provide a lower\nbound of $\\Omega(n^{\\frac{4}{3}})$. For $3$-hop and axis-parallel boxes in\n$\\mathbb{R}^d$, we provide the upper bound $O(n \\log ^{d-1}n)$ and lower bound\n$\\Omega\\left(n (\\frac{\\log n}{\\log \\log n})^{d-2}\\right)$.","main_category":"cs.CG","categories":"cs.CG,cs.DM","published":"2025-04-08T09:40:14Z"}
{"aid":"http://arxiv.org/abs/2504.05864v1","title":"Tunable spin-orbit splitting in bilayer graphene/WSe$_2$ quantum devices","summary":"Bilayer graphene (BLG)-based quantum devices represent a promising platform\nfor emerging technologies such as quantum computing and spintronics. However,\ntheir intrinsically weak spin-orbit coupling (SOC) presents a challenge for\nspin and valley manipulation, as these applications operate more efficiently in\nthe presence of strong SOC. Integrating BLG with transition metal\ndichalcogenides (TMDs) significantly enhances SOC via proximity effects. While\nthis enhancement has been experimentally demonstrated in 2D-layered structures,\n1D and 0D-nanostructures in BLG/TMD remain unrealized, with open questions\nregarding device quality, SOC strength, and tunability. In this work, we\ninvestigate quantum point contacts and quantum dots in two BLG/WSe$_2$\nheterostructures with different stacking orders. Across multiple devices, we\ndemonstrate a reproducible enhancement of spin-orbit splitting\n($\\Delta_\\mathrm{SO}$) reaching values of up to $1.5\\mathrm{meV}$ - more than\none order of magnitude higher than in pristine bilayer graphene\n($\\Delta_\\mathrm{SO}=40-80\\mu\\mathrm{eV}$). Furthermore, we show that the\ninduced SOC can be tuned in situ from its maximum value to near-complete\nsuppression by varying the perpendicular electric field, thereby controlling\nlayer polarization. This enhancement and in situ tunability establish SOC as an\nefficient control mechanism for dynamic spin and valley manipulation.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T09:44:16Z"}
{"aid":"http://arxiv.org/abs/2504.05871v1","title":"Agent Guide: A Simple Agent Behavioral Watermarking Framework","summary":"The increasing deployment of intelligent agents in digital ecosystems, such\nas social media platforms, has raised significant concerns about traceability\nand accountability, particularly in cybersecurity and digital content\nprotection. Traditional large language model (LLM) watermarking techniques,\nwhich rely on token-level manipulations, are ill-suited for agents due to the\nchallenges of behavior tokenization and information loss during\nbehavior-to-action translation. To address these issues, we propose Agent\nGuide, a novel behavioral watermarking framework that embeds watermarks by\nguiding the agent's high-level decisions (behavior) through probability biases,\nwhile preserving the naturalness of specific executions (action). Our approach\ndecouples agent behavior into two levels, behavior (e.g., choosing to bookmark)\nand action (e.g., bookmarking with specific tags), and applies watermark-guided\nbiases to the behavior probability distribution. We employ a z-statistic-based\nstatistical analysis to detect the watermark, ensuring reliable extraction over\nmultiple rounds. Experiments in a social media scenario with diverse agent\nprofiles demonstrate that Agent Guide achieves effective watermark detection\nwith a low false positive rate. Our framework provides a practical and robust\nsolution for agent watermarking, with applications in identifying malicious\nagents and protecting proprietary agent systems.","main_category":"cs.AI","categories":"cs.AI,K.6.5","published":"2025-04-08T09:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.05874v1","title":"Systematic Parameter Decision in Approximate Model Counting","summary":"This paper proposes a novel approach to determining the internal parameters\nof the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$.\nIn this problem, the chosen parameter values must ensure that\n$\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making\nit as efficient as possible. The existing approach to this problem relies on\nheuristics; in this paper, we solve this problem by formulating it as an\noptimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s\ncorrectness proof to arbitrary parameter values.\n  Our approach separates the concerns of algorithm soundness and optimality,\nallowing us to address the former without the need for repetitive case-by-case\nargumentation, while establishing a clear framework for the latter.\nFurthermore, after reduction, the resulting optimization problem takes on an\nexceptionally simple form, enabling the use of a basic search algorithm and\nproviding insight into how parameter values affect algorithm performance.\nExperimental results demonstrate that our optimized parameters improve the\nruntime performance of the latest $\\mathsf{ApproxMC}$ by a factor of 1.6 to\n2.4, depending on the error tolerance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T09:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05881v1","title":"Actuarial Learning for Pension Fund Mortality Forecasting","summary":"For the assessment of the financial soundness of a pension fund, it is\nnecessary to take into account mortality forecasting so that longevity risk is\nconsistently incorporated into future cash flows. In this article, we employ\nmachine learning models applied to actuarial science ({\\it actuarial learning})\nto make mortality predictions for a relevant sample of pension funds'\nparticipants. Actuarial learning represents an emerging field that involves the\napplication of machine learning (ML) and artificial intelligence (AI)\ntechniques in actuarial science. This encompasses the use of algorithms and\ncomputational models to analyze large sets of actuarial data, such as\nregression trees, random forest, boosting, XGBoost, CatBoost, and neural\nnetworks (eg. FNN, LSTM, and MHA). Our results indicate that some ML/AI\nalgorithms present competitive out-of-sample performance when compared to the\nclassical Lee-Carter model. This may indicate interesting alternatives for\nconsistent liability evaluation and effective pension fund risk management.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-08T10:09:41Z"}
{"aid":"http://arxiv.org/abs/2504.05888v1","title":"UVG-VPC: Voxelized Point Cloud Dataset for Visual Volumetric Video-based\n  Coding","summary":"Point cloud compression has become a crucial factor in immersive visual media\nprocessing and streaming. This paper presents a new open dataset called UVG-VPC\nfor the development, evaluation, and validation of MPEG Visual Volumetric\nVideo-based Coding (V3C) technology. The dataset is distributed under its own\nnon-commercial license. It consists of 12 point cloud test video sequences of\ndiverse characteristics with respect to the motion, RGB texture, 3D geometry,\nand surface occlusion of the points. Each sequence is 10 seconds long and\ncomprises 250 frames captured at 25 frames per second. The sequences are\nvoxelized with a geometry precision of 9 to 12 bits, and the voxel color\nattributes are represented as 8-bit RGB values. The dataset also includes\nassociated normals that make it more suitable for evaluating point cloud\ncompression solutions. The main objective of releasing the UVG-VPC dataset is\nto foster the development of V3C technologies and thereby shape the future in\nthis field.","main_category":"cs.MM","categories":"cs.MM,cs.CV","published":"2025-04-08T10:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.05920v1","title":"Local Thermal Non-Equilibrium Models in Porous Media: A Comparative\n  Study of Conduction Effects","summary":"Instantaneous heat transfer between different phases is a common assumption\nfor modeling heat transfer in porous media, known as Local Thermal Equilibrium\n(LTE). This assumption may not hold in certain technical and environmental\napplications, especially in systems with large temperature gradients, large\ndifferences in thermal properties, or high velocities. Local Thermal\nNon-Equilibrium (LTNE) models aim to describe heat transfer processes when the\nLTE assumption may fail. In this work, we compare three continuum-scale models\nfrom the pore to the representative elementary volume (REV) scale.\nSpecifically, dual-network and REV-scale models are evaluated against a\npore-resolved model, which we perceive as a reference in the absence of\nexperimental results. Different effective models are used to obtain upscaled\nproperties on the REV scale and to compare resulting temperature profiles. The\nsystems investigated are fully saturated, consisting of one fluid and one solid\nphase. This study focuses on purely conductive systems without significant\ndifferences in thermal properties. Results show that LTE holds then for low\ninterfacial resistances. However, for large interfacial resistances, solid and\nfluid temperatures differ. The REV-scale model with effective parameters\nobtained by homogenization leads to similar results as the pore-resolved model,\nwhereas the dual-network model shows greater deviation due to its fixed spatial\nresolution. Among the evaluated effective parameter formulations for the\nREV-scale model, only the homogenization-based approach captures the LTNE\nbehavior, as it incorporates the interfacial heat transfer coefficient.\nConvection is relevant for most practical applications, and its impact will be\naddressed in a follow-up article.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T11:19:02Z"}
{"aid":"http://arxiv.org/abs/2504.05929v1","title":"Cohomology and deformations of restricted Lie algebras and their\n  morphisms in positive characteristic","summary":"The main purpose of this paper is to study cohomology and develop a\ndeformation theory of restricted Lie algebras in positive characteristic $p>0$.\nIn the case $p\\geq3$, it is shown that the deformations of restricted Lie\nalgebras are controlled by the restricted cohomology introduced by Evans and\nFuchs. Moreover, we introduce a new cohomology that controls the deformations\nof restricted morphisms of restricted Lie algebras. In the case $p=2$, we\nprovide a full restricted cohomology complex with values in a restricted module\nand investigate its connections with formal deformations. Furthermore, we\nintroduce a full deformation cohomology that controls deformations of\nrestricted morphisms of restricted Lie algebras in characteristic $2$. As\nexample, we discuss restricted cohomology with adjoint coefficients of\nrestricted Heisenberg Lie algebras in characteristic $p\\geq 2$.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T11:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.05931v1","title":"A stability phenomenon in Kazhdan-Lusztig combinatorics","summary":"We prove that, when $n$ goes to infinity, the expression, with respect to the\ndual Kazhdan-Lusztig basis, of the product\n$\\hat{\\underline{H}}_x\\underline{H}_y$ of elements of the dual and the usual\nKazhdan-Lusztig bases in the Hecke algebra of the symmetric group $S_n$\nstabilizes. As an application, we define the action of projective functors on\nthe principal block of category $\\mathcal{O}$ for $\\mathfrak{sl}_\\infty$ and\nshow that the subcategory of finite length objects is stable under this action.\nAs a bonus, we also prove that this latter block is Koszul, answering, for this\nblock, a question from \\cite{CP}.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T11:42:32Z"}
{"aid":"http://arxiv.org/abs/2504.05944v1","title":"Laminar chaos in systems with random and chaotically time-varying delay","summary":"A type of chaos called laminar chaos was found in singularly perturbed\ndynamical systems with periodically [Phys. Rev. Lett. 120, 084102 (2018)] and\nquasiperiodically [Phys. Rev. E 107, 014205 (2023)] time-varying delay.\nCompared to high-dimensional turbulent chaos that is typically found in such\nsystems with large constant delay, laminar chaos is a very low-dimensional\nphenomenon. It is characterized by a time series with nearly constant laminar\nphases that are interrupted by irregular bursts, where the intensity level of\nthe laminar phases varies chaotically from phase to phase. In this paper, we\ndemonstrate that laminar chaos, and its generalizations, can also be observed\nin systems with random and chaotically time-varying delay. Moreover, while for\nperiodic and quasiperiodic delays the appearance of (generalized) laminar chaos\nand turbulent chaos depends in a fractal manner on the delay parameters, it\nturns out that short-time correlated random and chaotic delays lead to\n(generalized) laminar chaos in almost the whole delay parameter space, where\nthe properties of circle maps with quenched disorder play a crucial role. It\nfollows that introducing such a delay variation typically leads to a drastic\nreduction of the dimension of the chaotic attractor of the considered systems.\nWe investigate the dynamical properties and generalize the known methods for\ndetecting laminar chaos in experimental time series to random and chaotically\ntime-varying delay.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-08T11:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.05952v1","title":"Contrasting magnetism in VPS3 and CrI3 monolayers with the common\n  honeycomb S = 3/2 spin lattice","summary":"Two-dimensional (2D) magnetic materials are promising candidates for\nspintronics and quantum technologies. One extensively studied example is the\nferromagnetic (FM) CrI$_3$ monolayer with the honeycomb Cr$^{3+}$ ($t_{2g}^3$,\n$S$ = 3/2) spin lattice, while VPS$_3$ has a same honeycomb $S$ = 3/2 spin\nlattice (V$^{2+}$, $t_{2g}^3$) but displays N$\\acute{e}$el antiferromagnetism\n(AFM). In this work, we study the electronic structure and particularly the\ncontrasting magnetism of VPS$_3$ and CrI$_3$ monolayers. We find that VPS$_3$\nis a Mott-Hubbard insulator but CrI$_3$ is a charge-transfer insulator, and\ntherefore their magnetic exchange mechanisms are essentially different. The\nfirst nearest-neighbor (1NN) direct $d$-$d$ exchange dominates in VPS$_3$, thus\nleading to a strong antiferromagnetic (AF) coupling. However, the formation of\nvanadium vacancies, associated with instability of the low-valence V$^{2+}$\nions, suppresses the AF coupling and thus strongly reduces the N$\\acute{e}$el\ntemperature ($T_{\\text{N}}$) in line with the experimental observation. In\ncontrast, our results reveal that the major 1NN $d$-$p$-$d$ superexchanges in\nCrI$_3$ via different channels give rise to competing FM and AF couplings,\nultimately resulting in a weak FM coupling as observed experimentally. After\nrevisiting several important superexchange channels reported in the literature,\nbased on our MLWFs and tight-binding analyses, we note that some antiphase\ncontributions must be subtly and simultaneously considered, and thus we provide\na deeper insight into the FM coupling of CrI$_3$. Moreover, we identify and\ncompare the major contributions to the magnetic anisotropy, i.e., a weak shape\nanisotropy in VPS$_3$ and a relatively strong exchange anisotropy in CrI$_3$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T12:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.05976v1","title":"A Knowledge Base for Arts and Inclusion -- The Dataverse data archival\n  platform as a knowledge base management system enabling multimodal\n  accessibility","summary":"Creating an inclusive art environment requires engaging multiple senses for a\nfully immersive experience. Culture is inherently synesthetic, enriched by all\nsenses within a shared time and space. In an optimal synesthetic setting,\npeople of all abilities can connect meaningfully; when one sense is\ncompromised, other channels can be enhanced to compensate. This is the power of\nmultimodality. Digital technology is increasingly able to capture aspects of\nmultimodality. To document multimodality aspects of cultural practices and\nproducts for the long-term remains a challenge. Many artistic products from the\nperforming arts tend to be multimodal, and are often immersive, so only a\nmultimodal repository can offer a platform for this work. To our knowledge\nthere is no single, comprehensive repository with a knowledge base to serve\narts and disability. By knowledge base, we mean classifications, taxonomies, or\nontologies (in short, knowledge organisation systems). This paper presents\ninnovative ways to develop a knowledge base which capture multimodal features\nof archived representations of cultural assets, but also indicate various forms\nhow to interact with them including machine-readable description. We will\ndemonstrate how back-end and front-end applications, in a combined effort, can\nsupport accessible archiving and data management for complex digital objects\nborn out of artistic practices and make them available for wider audiences.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-08T12:33:12Z"}
{"aid":"http://arxiv.org/abs/2504.05980v1","title":"Langevin dynamics with generalized time-reversal symmetry","summary":"When analyzing the equilibrium properties of a stochastic process,\nidentifying the parity of the variables under time-reversal is imperative. This\ninitial step is required to assess the presence of detailed balance, and to\ncompute the entropy production rate, which is, otherwise, ambiguously defined.\nIn this work we deal with stochastic processes whose underlying time-reversal\nsymmetry cannot be reduced to the usual parity rules (namely, flip of the\nmomentum sign). We provide a systematic method to build equilibrium Langevin\ndynamics starting from their reversible deterministic counterparts: this\nstrategy can be applied, in particular, to all stable one-dimensional\nHamiltonian dynamics, exploiting the time-reversal symmetry unveiled in the\naction-angle framework. The case of the Lotka-Volterra model is discussed as an\nexample. We also show that other stochastic versions of this system violate\ntime-reversal symmetry and are, therefore, intrinsically out of equilibrium.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T12:36:30Z"}
{"aid":"http://arxiv.org/abs/2504.05981v1","title":"Arbitrary polarization retarders and polarization controllers,\n  constructed from sequences of half-wave and quarter-wave plates","summary":"We theoretically introduce several types of arbitrary polarization retarders\nconstructed from sequences of half-wave and quarter-wave plates, each rotated\nat specific angles. By integrating these arbitrary polarization retarders with\narbitrary polarization rotators, we develop a versatile device capable of\nperforming arbitrary-to-arbitrary polarization transformations. While some of\nthe proposed devices are documented in the literature, others are novel and, to\nthe best of our knowledge, have not been previously presented. The continuous\nadjustment of retardance and rotation in these devices is achieved by altering\nthe relative orientation of the wave plates in the sequence.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T12:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.05987v1","title":"Learning-enhanced electronic skin for tactile sensing on deformable\n  surface based on electrical impedance tomography","summary":"Electrical Impedance Tomography (EIT)-based tactile sensors offer\ncost-effective and scalable solutions for robotic sensing, especially promising\nfor soft robots. However a major issue of EIT-based tactile sensors when\napplied in highly deformable objects is their performance degradation due to\nsurface deformations. This limitation stems from their inherent sensitivity to\nstrain, which is particularly exacerbated in soft bodies, thus requiring\ndedicated data interpretation to disentangle the parameter being measured and\nthe signal deriving from shape changes. This has largely limited their\npractical implementations. This paper presents a machine learning-assisted\ntactile sensing approach to address this challenge by tracking surface\ndeformations and segregating this contribution in the signal readout during\ntactile sensing. We first capture the deformations of the target object,\nfollowed by tactile reconstruction using a deep learning model specifically\ndesigned to process and fuse EIT data and deformation information. Validations\nusing numerical simulations achieved high correlation coefficients (0.9660 -\n0.9999), peak signal-to-noise ratios (28.7221 - 55.5264 dB) and low relative\nimage errors (0.0107 - 0.0805). Experimental validations, using a\nhydrogel-based EIT e-skin under various deformation scenarios, further\ndemonstrated the effectiveness of the proposed approach in real-world settings.\nThe findings could underpin enhanced tactile interaction in soft and highly\ndeformable robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T12:49:54Z"}
{"aid":"http://arxiv.org/abs/2504.05993v1","title":"Strong Evidence That Abiogenesis Is a Rapid Process on Earth Analogs","summary":"The early start to life naively suggests that abiogenesis is a rapid process\non Earth-like planets. However, if evolution typically takes ~4Gyr to produce\nintelligent life-forms like us, then the limited lifespan of Earth's biosphere\n(~5-6Gyr) necessitates an early (and possibly highly atypical) start to our\nemergence - an example of the weak anthropic principle. Our previously proposed\nobjective Bayesian analysis of Earth's chronology culminated in a formula for\nthe minimum odds ratio between the fast and slow abiogenesis scenarios\n(relative to Earth's lifespan). Timing from microfossils (3.7Gya) yields 3:1\nodds in favor of rapid abiogenesis, whereas evidence from carbon isotopes\n(4.1Gya) gives 9:1, both below the canonical threshold of \"strong evidence\"\n(10:1). However, the recent result of a 4.2Gya LUCA pushes the odds over the\nthreshold for the first time (nominally 13:1). In fact, the odds ratio is >10:1\nfor all possible values of the biosphere's ultimate lifespan and speculative\nhypotheses of ancient civilizations. For the first time, we have formally\nstrong evidence that favors the hypothesis that life rapidly emerges in\nEarth-like conditions (although such environments may themselves be rare).","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-08T12:55:50Z"}
{"aid":"http://arxiv.org/abs/2504.05998v1","title":"Can gravity mediate the transmission of quantum information?","summary":"We propose an experiment to test the non-classicality of the gravitational\ninteraction. We consider two optomechanical systems that are perfectly\nisolated, except for a weak gravitational coupling. If a suitable resonance\ncondition is satisfied, an optical signal can be transmitted from one system to\nthe other over a narrow frequency band, a phenomenon that we call\ngravitationally induced transparency. In this framework, the challenging\nproblem of testing the quantum nature of gravity is mapped to the easier task\nof determining the non-classicality of the gravitationally-induced optical\nchannel: If the optical channel is not entanglement-breaking, then gravity must\nhave a quantum nature. This approach is applicable without making any\nassumption on the, currently unknown, correct model of gravity in the quantum\nregime. In the second part of this work, we model gravity as a quadratic\nHamiltonian interaction (e.g. a weak Newtonian force), resulting in a Gaussian\nthermal attenuator channel between the two systems. Depending on the strength\nof thermal noise, the system presents a sharp transition from an\nentanglement-breaking to a non-classical channel capable not only of\nentanglement preservation but also of asymptotically perfect quantum\ncommunication.","main_category":"quant-ph","categories":"quant-ph,gr-qc","published":"2025-04-08T13:03:58Z"}
{"aid":"http://arxiv.org/abs/2504.06003v1","title":"econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic\n  Gaussians","summary":"The primary focus of most recent works on open-vocabulary neural fields is\nextracting precise semantic features from the VLMs and then consolidating them\nefficiently into a multi-view consistent 3D neural fields representation.\nHowever, most existing works over-trusted SAM to regularize image-level CLIP\nwithout any further refinement. Moreover, several existing works improved\nefficiency by dimensionality reduction of semantic features from 2D VLMs before\nfusing with 3DGS semantic fields, which inevitably leads to multi-view\ninconsistency. In this work, we propose econSG for open-vocabulary semantic\nsegmentation with 3DGS. Our econSG consists of: 1) A Confidence-region Guided\nRegularization (CRR) that mutually refines SAM and CLIP to get the best of both\nworlds for precise semantic features with complete and precise boundaries. 2) A\nlow dimensional contextual space to enforce 3D multi-view consistency while\nimproving computational efficiency by fusing backprojected multi-view 2D\nfeatures and follow by dimensional reduction directly on the fused 3D features\ninstead of operating on each 2D view separately. Our econSG shows\nstate-of-the-art performance on four benchmark datasets compared to the\nexisting methods. Furthermore, we are also the most efficient training among\nall the methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.06008v1","title":"Impact of newly measured $Î²$\\nobreakdash-delayed neutron emitters\n  around \\myisoSimp{78}{Ni} on light element nucleosynthesis in the\n  neutrino-wind following a neutron star merger","summary":"Neutron emission probabilities and half-lives of 37 beta-delayed neutron\nemitters from 75Ni to 92Br were measured at the RIKEN Nishina Center in Japan,\nincluding 11 one-neutron and 13 two-neutron emission probabilities and 6\nhalf-lives measured for the first time, which supersede theoretical estimates.\nThese nuclei lie in the path of the weak r-process occurring in neutrino-driven\nwinds from the accretion disk formed after the merger of two neutron stars,\nsynthesizing elements in the A~80 abundance peak. The presence of such elements\ndominates the accompanying kilonova emission over the first few days and has\nbeen identified in the AT2017gfo event, associated with the gravitational wave\ndetection GW170817.\n  Abundance calculations based on over 17000 simulated trajectories describing\nthe evolution of matter properties in the merger outflows show that the new\ndata lead to an increase of 50-70 percent in the abundance of Y, Zr, Nb, and\nMo. This enhancement is large compared to the scatter of relative abundances\nobserved in old very metal-poor stars and is therefore significant in the\ncomparison with other possible astrophysical processes contributing to\nlight-element production.\n  These results underline the importance of including experimental decay data\nfor very neutron-rich beta-delayed neutron emitters into r-process models.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-08T13:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.06015v1","title":"Robust Statistics vs. Machine Learning vs. Bayesian Inference: Insights\n  into Handling Faulty GNSS Measurements in Field Robotics","summary":"This paper presents research findings on handling faulty measurements (i.e.,\noutliers) of global navigation satellite systems (GNSS) for robot localization\nunder adverse signal conditions in field applications, where raw GNSS data are\nfrequently corrupted due to environmental interference such as multipath,\nsignal blockage, or non-line-of-sight conditions. In this context, we\ninvestigate three strategies applied specifically to GNSS pseudorange\nobservations: robust statistics for error mitigation, machine learning for\nfaulty measurement prediction, and Bayesian inference for noise distribution\napproximation. Since previous studies have provided limited insight into the\ntheoretical foundations and practical evaluations of these three methodologies\nwithin a unified problem statement (i.e., state estimation using ranging\nsensors), we conduct extensive experiments using real-world sensor data\ncollected in diverse urban environments. Our goal is to examine both\nestablished techniques and newly proposed methods, thereby advancing the\nunderstanding of how to handle faulty range measurements, such as GNSS, for\nrobust, long-term robot localization. In addition to presenting successful\nresults, this work highlights critical observations and open questions to\nmotivate future research in robust state estimation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T13:21:04Z"}
{"aid":"http://arxiv.org/abs/2504.06021v1","title":"Memory-Modular Classification: Learning to Generalize with Memory\n  Replacement","summary":"We propose a novel memory-modular learner for image classification that\nseparates knowledge memorization from reasoning. Our model enables effective\ngeneralization to new classes by simply replacing the memory contents, without\nthe need for model retraining. Unlike traditional models that encode both world\nknowledge and task-specific skills into their weights during training, our\nmodel stores knowledge in the external memory of web-crawled image and text\ndata. At inference time, the model dynamically selects relevant content from\nthe memory based on the input image, allowing it to adapt to arbitrary classes\nby simply replacing the memory contents. The key differentiator that our\nlearner meta-learns to perform classification tasks with noisy web data from\nunseen classes, resulting in robust performance across various classification\nscenarios. Experimental results demonstrate the promising performance and\nversatility of our approach in handling diverse classification tasks, including\nzero-shot/few-shot classification of unseen classes, fine-grained\nclassification, and class-incremental classification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.06029v1","title":"Red giant component of the recurrent nova T Coronae Borealis","summary":"We performed simultaneous V band photometry and spectroscopic observations of\nthe recurrent nova T CrB and estimate the V band magnitude of the red giant. We\nfind for the red giant of T CrB apparent and absolute V-band magnitudes m_V =\n10.17 +/- 0.06 and M_V = +0.14 +/- 0.08, respectively. At the maximum of the\nellipsoidal variation when these values are obtained, its absolute V-band\nmagnitude is similar but fainter than the typical M4/5III giants. The data are\navailable on : zenodo.org/records/15174720","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T13:34:05Z"}
{"aid":"http://arxiv.org/abs/2504.06034v1","title":"Distance to M87 as the Mode of the Modulus Distribution","summary":"de Grijs and Bono (ApJS 2020, 246, 3) compiled a list of distances to M87\nfrom the literature published in the last 100 years. They reported the\narithmetic mean of the three most stable tracers (Cepheids, tip of the red\ngiant branch, and surface brightness fluctuations). The arithmetic mean is one\nof the measures of central tendency of a distribution; others are the median\nand mode. The three do not align for asymmetric distributions, which is the\ncase for the distance moduli $\\mu_0$ to M87. I construct a kernel density\ndistribution of the set of $\\mu_0$ and estimate the recommended distance to M87\nas its mode, obtaining $\\mu_0 =\n\\left(31.06~\\pm~0.001\\,\\textrm{(statistical)}\\,^{+0.04}_{-0.06}\\,\\textrm{(systematic)}\\right)$~mag,\ncorresponding to \\linebreak $D=16.29^{+0.30}_{-0.45}$~Mpc, which yields\nuncertainties smaller than those associated with the mean and median.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T13:35:55Z"}
{"aid":"http://arxiv.org/abs/2504.06043v1","title":"Hadronic molecules and multiquark states","summary":"In this text different theoretical approaches towards multi-quark states are\nintroduced, namely hadrocharmonia, compact tetraquarks and hadronic molecules.\nThe predictions derived from either of them are contrasted with current and\npossible future observations. The focus is on doubly heavy systems, but singly\nheavy and light systems are mentioned briefly as well.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-08T13:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.06060v1","title":"Fast summation of fermionic Feynman diagrams beyond Bravais Lattices and\n  on-site Hubbard interactions","summary":"We designed new algorithms for summing bold-line Feynman diagrams in\narbitrary channels, where it can be readily modified for bare interaction\nseries as well. When applied to magnetic channel bold-line series with on-site\nHubbard interactions, the algorithm achieves competitive performance compared\nwith the state-of-art RPADet. We then generalize it beyond square lattice and\non-site Hubbard interactions and achieve better scaling in the number of sites\nwithin a unit cell, while there is substantial increase when there are more\ntypes of interactions. This work paves the way of diagrammatic Monte Carlo\nsimulations for real materials, holding the premise for a robust replacement of\nstate-of-art simulation tools in the thermodynamical limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T14:04:46Z"}
{"aid":"http://arxiv.org/abs/2504.06066v1","title":"The Quantum Double of Hopf Algebras Realized via Partial Dualization and\n  the Tensor Category of Its Representations","summary":"In this paper, we aim to study the (generalized) quantum double\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ determined by a (skew) pairing between\nfinite-dimensional Hopf algebras $K^{\\ast\\mathrm{cop}}$ and $H$, especially the\ntensor category $\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ of its\nfinite-dimensional representations. Specifically, we show that\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ is a left partially dualized\n(quasi-)Hopf algebra of $K^\\mathrm{op}\\otimes H$, and use this formulation to\nestablish tensor equivalences from\n$\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ to the categories\n${}^K_K\\mathcal{M}^K_H$ and ${}^{K^\\ast}_{K^\\ast}\\mathcal{M}^{H^\\ast}_{K^\\ast}$\nof two-sided two-cosided relative Hopf modules, as well as the category\n${}_H\\mathfrak{YD}^K$ of relative Yetter-Drinfeld modules.","main_category":"math.QA","categories":"math.QA,math.CT,math.RA","published":"2025-04-08T14:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.06071v1","title":"On Onsager-type conjecture for the ElsÃ¤sser energies of the ideal\n  MHD equations","summary":"In this paper, we investigate the ideal magnetohydrodynamics (MHD) equations\non tours $\\TTT^d$. For $d=3$, we resolve the flexible part of Onsager-type\nconjecture for Els\\\"{a}sser energies of the ideal MHD equations. More\nprecisely, for \\(\\beta < 1/3\\), we construct weak solutions \\((u, b) \\in\nC^\\beta([0,T] \\times \\mathbb{T}^3)\\) with both the total energy dissipation and\nfailure of cross helicity conservation. The key idea of the proof relies on a\nsymmetry reduction that embeds the ideal MHD system into a 2$\\frac{1}{2}$D\nEuler flow and the Newton-Nash iteration technique recently developed in\n\\cite{GR}. For $d=2$, we show the non-uniqueness of H\\\"{o}lder-continuous weak\nsolutions with non-trivial magnetic fields. Specifically, for \\(\\beta < 1/5\\),\nthere exist infinitely many solutions \\((u, b) \\in C^\\beta([0,T] \\times\n\\mathbb{T}^2)\\) with the same initial data while satisfying the total energy\ndissipation with non-vanishing velocity and magnetic fields. The new ingredient\nis developing a spatial-separation-driven iterative scheme that incorporates\nthe magnetic field as a controlled perturbation within the convex integration\nframework for the velocity field, thereby providing sufficient oscillatory\nfreedom for Nash-type perturbations in the 2D setting. As a byproduct, we prove\nthat any H\\\"{o}lder-continuous Euler solution can be approximated by a sequence\nof $C^\\beta$-weak solutions for the ideal MHD equations in the $L^p$-topology\nfor $1\\le p<\\infty$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T14:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.06095v1","title":"Nonuniform-Tensor-Parallelism: Mitigating GPU failure impact for\n  Scaled-up LLM Training","summary":"LLM training is scaled up to 10Ks of GPUs by a mix of data-(DP) and\nmodel-parallel (MP) execution. Critical to achieving efficiency is\ntensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of\nGPUs, referred to as a scale-up domain, and the larger the scale-up domain the\nbetter the performance. New datacenter architectures are emerging with more\nGPUs able to be tightly-coupled in a scale-up domain, such as moving from 8\nGPUs to 72 GPUs connected via NVLink. Unfortunately, larger scale-up domains\nincrease the blast-radius of failures, with a failure of single GPU potentially\nimpacting TP execution on the full scale-up domain, which can degrade overall\nLLM training throughput dramatically. With as few as 0.1% of GPUs being in a\nfailed state, a high TP-degree job can experience nearly 10% reduction in LLM\ntraining throughput. We propose nonuniform-tensor-parallelism (NTP) to mitigate\nthis amplified impact of GPU failures. In NTP, a DP replica that experiences\nGPU failures operates at a reduced TP degree, contributing throughput equal to\nthe percentage of still-functional GPUs. We also propose a rack-design with\nimproved electrical and thermal capabilities in order to sustain power-boosting\nof scale-up domains that have experienced failures; combined with NTP, this can\nallow the DP replica with the reduced TP degree (i.e., with failed GPUs) to\nkeep up with the others, thereby achieving near-zero throughput loss for\nlarge-scale LLM training.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-08T14:35:40Z"}
{"aid":"http://arxiv.org/abs/2504.06105v1","title":"Uncertainty-Aware Hybrid Machine Learning in Virtual Sensors for Vehicle\n  Sideslip Angle Estimation","summary":"Precise vehicle state estimation is crucial for safe and reliable autonomous\ndriving. The number of measurable states and their precision offered by the\nonboard vehicle sensor system are often constrained by cost. For instance,\nmeasuring critical quantities such as the Vehicle Sideslip Angle (VSA) poses\nsignificant commercial challenges using current optical sensors. This paper\naddresses these limitations by focusing on the development of high-performance\nvirtual sensors to enhance vehicle state estimation for active safety. The\nproposed Uncertainty-Aware Hybrid Learning (UAHL) architecture integrates a\nmachine learning model with vehicle motion models to estimate VSA directly from\nonboard sensor data. A key aspect of the UAHL architecture is its focus on\nuncertainty quantification for individual model estimates and hybrid fusion.\nThese mechanisms enable the dynamic weighting of uncertainty-aware predictions\nfrom machine learning and vehicle motion models to produce accurate and\nreliable hybrid VSA estimates. This work also presents a novel dataset named\nReal-world Vehicle State Estimation Dataset (ReV-StED), comprising synchronized\nmeasurements from advanced vehicle dynamic sensors. The experimental results\ndemonstrate the superior performance of the proposed method for VSA estimation,\nhighlighting UAHL as a promising architecture for advancing virtual sensors and\nenhancing active safety in autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-08T14:49:58Z"}
{"aid":"http://arxiv.org/abs/2504.06147v1","title":"Noncommutative resolutions and CICY quotients from a non-abelian GLSM","summary":"We discuss a one-parameter non-abelian GLSM with gauge group $(U(1)\\times\nU(1)\\times U(1))\\rtimes\\mathbb{Z}_3$ and its associated Calabi-Yau phases. The\nlarge volume phase is a free $\\mathbb{Z}_3$-quotient of a codimension $3$\ncomplete intersection of degree-$(1,1,1)$ hypersurfaces in\n$\\mathbb{P}^2\\times\\mathbb{P}^2\\times\\mathbb{P}^2$. The associated Calabi-Yau\ndifferential operator has a second point of maximal unipotent monodromy,\nleading to the expectation that the other GLSM phase is geometric as well.\nHowever, the associated GLSM phase appears to be a hybrid model with continuous\nunbroken gauge symmetry and cubic superpotential, together with a Coulomb\nbranch. Using techniques from topological string theory and mirror symmetry we\ncollect evidence that the phase should correspond to a non-commutative\nresolution, in the sense of Katz-Klemm-Schimannek-Sharpe, of a codimension two\ncomplete intersection in weighted projective space with $63$ nodal points, for\nwhich a resolution has $\\mathbb{Z}_3$-torsion. We compute the associated\nGopakumar-Vafa invariants up to genus $11$, incorporating their torsion\nrefinement. We identify two integral symplectic bases constructed from\ntopological data of the mirror geometries in either phase.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T15:42:39Z"}
{"aid":"http://arxiv.org/abs/2504.06158v1","title":"Rethinking the Nested U-Net Approach: Enhancing Biomarker Segmentation\n  with Attention Mechanisms and Multiscale Feature Fusion","summary":"Identifying biomarkers in medical images is vital for a wide range of biotech\napplications. However, recent Transformer and CNN based methods often struggle\nwith variations in morphology and staining, which limits their feature\nextraction capabilities. In medical image segmentation, where data samples are\noften limited, state-of-the-art (SOTA) methods improve accuracy by using\npre-trained encoders, while end-to-end approaches typically fall short due to\ndifficulties in transferring multiscale features effectively between encoders\nand decoders. To handle these challenges, we introduce a nested UNet\narchitecture that captures both local and global context through Multiscale\nFeature Fusion and Attention Mechanisms. This design improves feature\nintegration from encoders, highlights key channels and regions, and restores\nspatial details to enhance segmentation performance. Our method surpasses SOTA\napproaches, as evidenced by experiments across four datasets and detailed\nablation studies. Code: https://github.com/saadwazir/ReN-UNet","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T15:53:46Z"}
{"aid":"http://arxiv.org/abs/2504.06164v1","title":"Functional ItÃ´-formula and Taylor expansions for non-anticipative maps\n  of cÃ dlÃ g rough paths","summary":"We derive a functional It\\^o-formula for non-anticipative maps of rough\npaths, based on the approximation properties of the signature of c\\`adl\\`ag\nrough paths. This result is a functional extension of the It\\^o-formula for\nc\\`adl\\`ag rough paths (by Friz and Zhang (2018)), which coincides with the\nchange of variable formula formulated by Dupire (2009) whenever the\nfunctionals' representations, the notions of regularity, and the integration\nconcepts can be matched. Unlike these previous works, we treat the vertical\n(jump) pertubation via the Marcus transformation, which allows for\nincorporating path functionals where the second order vertical derivatives do\nnot commute, as is the case for typical signature functionals. As a byproduct,\nwe show that sufficiently regular non-anticipative maps admit a functional\nTaylor expansion in terms of the path's signature, leading to an important\ngeneralization of the recent results by Dupire and Tissot-Daguette (2022).","main_category":"math.PR","categories":"math.PR,math.CA,q-fin.MF","published":"2025-04-08T16:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.06168v1","title":"Differential diffusion effects and super-adiabatic local temperature in\n  lean hydrogen-air turbulent flames","summary":"Analyzed in this paper are three-dimensional Direct Numerical Simulation\n(DNS) data obtained from seven statistically planar and one-dimensional, lean\ncomplex-chemistry hydrogen-air flames propagating in a box with forced\nturbulence. The simulation conditions cover a wide range of non-dimensional\nturbulent combustion characteristics. Specifically, root-mean-square turbulent\nvelocity is varied from 2.2 to 54 laminar flame speeds, integral length scale\nof turbulence is varied from 0.5 to 2.2 laminar flame thicknesses, Damk\\\"ohler\nand Karlovitz number are varied from 0.01 to 0.53 and from 10 to 1315,\nrespectively. Two equivalence ratios, 0.5 and 0.35, are explored. Turbulent\nburning velocities are evaluated for these seven low Lewis number flames and\nequidiffusion counterparts to six of them. Moreover, conditioned profiles of\ntemperature, fuel consumption and heat release rates and probabilities of\nfinding superadiabatic temperature are sampled from all seven low Lewis number\nflames. Analyses of obtained results show that both magnitude of superadiabatic\ntemperature and probability of finding it are decreased with increasing\nKarlovitz number Ka. However, significant influence of differential diffusion\neffects on local structure of flame reaction zones and bulk burning velocity is\nwell pronounced in all cases, even at Ka as high as 1315. Therefore, a decrease\nin magnitude of superadiabatic local temperature with increasing Karlovitz\nnumber or even negligible probability of finding such a high temperature at\nhigh Ka is not an evidence that differential diffusion effects play a minor\nrole under such conditions. The simulated mitigation of phenomenon of\nsuperadiabatic temperature at high Ka is attributed to intensification of\nturbulent mixing in local flame oxidation zones, rather than weakening\ndifferential diffusion effects in local flame reaction zones.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T16:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.06171v1","title":"Generalized Ridge Regression: Applications to Nonorthogonal Linear\n  Regression Models","summary":"This paper analyzes the possibilities of using the generalized ridge\nregression to mitigate multicollinearity in a multiple linear regression model.\nFor this purpose, we obtain the expressions for the estimated variance, the\ncoefficient of variation, the coefficient of correlation, the variance\ninflation factor and the condition number. The results obtained are illustrated\nwith two numerical examples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T16:16:31Z"}
{"aid":"http://arxiv.org/abs/2504.06173v1","title":"Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles\n  Using Deep Learning","summary":"Beamforming techniques are considered as essential parts to compensate severe\npath losses in millimeter-wave (mmWave) communications. In particular, these\ntechniques adopt large antenna arrays and formulate narrow beams to obtain\nsatisfactory received powers. However, performing accurate beam alignment over\nnarrow beams for efficient link configuration by traditional standard defined\nbeam selection approaches, which mainly rely on channel state information and\nbeam sweeping through exhaustive searching, imposes computational and\ncommunications overheads. And, such resulting overheads limit their potential\nuse in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications involving highly dynamic scenarios. In comparison, utilizing\nout-of-band contextual information, such as sensing data obtained from sensor\ndevices, provides a better alternative to reduce overheads. This paper presents\na deep learning-based solution for utilizing the multi-modality sensing data\nfor predicting the optimal beams having sufficient mmWave received powers so\nthat the best V2I and V2V line-of-sight links can be ensured proactively. The\nproposed solution has been tested on real-world measured mmWave sensing and\ncommunication data, and the results show that it can achieve up to 98.19%\naccuracies while predicting top-13 beams. Correspondingly, when compared to\nexisting been sweeping approach, the beam sweeping searching space and time\noverheads are greatly shortened roughly by 79.67% and 91.89%, respectively\nwhich confirm a promising solution for beamforming in mmWave enabled\ncommunications.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.ET,cs.LG,eess.SP","published":"2025-04-08T16:18:00Z"}
{"aid":"http://arxiv.org/abs/2504.06197v1","title":"Orthogonal polynomials with complex densities and quantum minimal\n  surfaces","summary":"We show that the discrete Painlev\\'e-type equations arising from quantum\nminimal surfaces are equations for recurrence coefficients of orthogonal\npolynomials for indefinite hermitian products. As a consequence we obtain an\nexplicit formula for the initial conditions leading to positive solutions.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-08T16:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.06207v1","title":"An experimental survey and Perspective View on Meta-Learning for\n  Automated Algorithms Selection and Parametrization","summary":"Considerable progress has been made in the recent literature studies to\ntackle the Algorithms Selection and Parametrization (ASP) problem, which is\ndiversified in multiple meta-learning setups. Yet there is a lack of surveys\nand comparative evaluations that critically analyze, summarize and assess the\nperformance of existing methods. In this paper, we provide an overview of the\nstate of the art in this continuously evolving field. The survey sheds light on\nthe motivational reasons for pursuing classifiers selection through\nmeta-learning. In this regard, Automated Machine Learning (AutoML) is usually\ntreated as an ASP problem under the umbrella of the democratization of machine\nlearning. Accordingly, AutoML makes machine learning techniques accessible to\ndomain scientists who are interested in applying advanced analytics but lack\nthe required expertise. It can ease the task of manually selecting ML\nalgorithms and tuning related hyperparameters. We comprehensively discuss the\ndifferent phases of classifiers selection based on a generic framework that is\nformed as an outcome of reviewing prior works. Subsequently, we propose a\nbenchmark knowledge base of 4 millions previously learned models and present\nextensive comparative evaluations of the prominent methods for classifiers\nselection based on 08 classification algorithms and 400 benchmark datasets. The\ncomparative study quantitatively assesses the performance of algorithms\nselection methods along while emphasizing the strengths and limitations of\nexisting studies.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T16:51:22Z"}
{"aid":"http://arxiv.org/abs/2504.06215v1","title":"Randomization Inference in Two-Sided Market Experiments","summary":"Randomized experiments are increasingly employed in two-sided markets, such\nas buyer-seller platforms, to evaluate treatment effects from marketplace\ninterventions. These experiments must reflect the underlying two-sided market\nstructure in their design (e.g., sellers and buyers), making them particularly\nchallenging to analyze. In this paper, we propose a randomization inference\nframework to analyze outcomes from such two-sided experiments. Our approach is\nfinite-sample valid under sharp null hypotheses for any test statistic and\nmaintains asymptotic validity under weak null hypotheses through\nstudentization. Moreover, we provide heuristic guidance for choosing among\nmultiple valid randomization tests to enhance statistical power, which we\ndemonstrate empirically. Finally, we demonstrate the performance of our\nmethodology through a series of simulation studies.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-08T17:00:42Z"}
{"aid":"http://arxiv.org/abs/2504.06233v1","title":"On the homology of special unitary groups over polynomial rings","summary":"In this work, we answer the homotopy invariance question for the ''smallest''\nnon-isotrivial group-scheme over $\\mathbb{P}^1$, obtaining a result, which is\nnot contained in previous works due to Knudson and Wendt. More explicitly, let\n$\\mathcal{G}=\\mathrm{SU}_{3,\\mathbb{P}^1}$ be the (non-isotrivial) non-split\ngroup-scheme over $\\mathbb{P}^1$ defined from the standard (isotropic)\nhermitian form in three variables. In this article, we prove that there exists\na natural homomorphism $\\mathrm{PGL}_2(F) \\to \\mathcal{G}(F[t])$ that induces\nisomorphisms $H_*(\\mathrm{PGL}_2(F), \\mathbb{Z}) \\to H_*(\\mathcal{G}(F[t]),\n\\mathbb{Z})$. Then we study the rational homology of\n$\\mathcal{G}(F[t,t^{-1}])$, by previously describing suitable fundamental\ndomains for certain arithmetic subgroups of $\\mathcal{G}$.","main_category":"math.KT","categories":"math.KT,math.GR,math.NT","published":"2025-04-08T17:30:56Z"}
{"aid":"http://arxiv.org/abs/2504.06240v1","title":"Dictionary-free Koopman Predictive Control for Autonomous Vehicles in\n  Mixed Traffic","summary":"Koopman Model Predictive Control (KMPC) and Data-EnablEd Predictive Control\n(DeePC) use linear models to approximate nonlinear systems and integrate them\nwith predictive control. Both approaches have recently demonstrated promising\nperformance in controlling Connected and Autonomous Vehicles (CAVs) in mixed\ntraffic. However, selecting appropriate lifting functions for the Koopman\noperator in KMPC is challenging, while the data-driven representation from\nWillems' fundamental lemma in DeePC must be updated to approximate the local\nlinearization when the equilibrium traffic state changes. In this paper, we\npropose a dictionary-free Koopman model predictive control (DF-KMPC) for CAV\ncontrol. In particular, we first introduce a behavioral perspective to identify\nthe optimal dictionary-free Koopman linear model. We then utilize an iterative\nalgorithm to compute a data-driven approximation of the dictionary-free Koopman\nrepresentation. Integrating this data-driven linear representation with\npredictive control leads to our DF-KMPC, which eliminates the need to select\nlifting functions and update the traffic equilibrium state. Nonlinear traffic\nsimulations show that DF-KMPC effectively mitigates traffic waves and improves\ntracking performance.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-08T17:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.06242v1","title":"Addressing Relative Degree Issues in Control Barrier Function Synthesis\n  with Physics-Informed Neural Networks","summary":"In robotics, control barrier function (CBF)-based safety filters are commonly\nused to enforce state constraints. A critical challenge arises when the\nrelative degree of the CBF varies across the state space. This variability can\ncreate regions within the safe set where the control input becomes\nunconstrained. When implemented as a safety filter, this may result in\nchattering near the safety boundary and ultimately compromise system safety. To\naddress this issue, we propose a novel approach for CBF synthesis by\nformulating it as solving a set of boundary value problems. The solutions to\nthe boundary value problems are determined using physics-informed neural\nnetworks (PINNs). Our approach ensures that the synthesized CBFs maintain a\nconstant relative degree across the set of admissible states, thereby\npreventing unconstrained control scenarios. We illustrate the approach in\nsimulation and further verify it through real-world quadrotor experiments,\ndemonstrating its effectiveness in preserving desired system safety properties.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-08T17:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.06244v1","title":"The distinction between Ice phases VII, VIII and X","summary":"Ice phases VII, VIII and X are all based on a body-centered cubic arrangement\nof molecules, the differences coming from molecular orientation. There is some\ndebate as to whether these should even be considered distinct phases. The\nstandard definition of a transition between distinct phases involves a\ndiscontinuity in any derivative of the free energy. This can be hard to prove\nexperimentally, and most previous theoretical works have been based on models\nwhich either have continuously differentiable free energies, or no\nstraightforward way to determine the free energy. Here we build a free energy\nmodel based on the common definitions of the phases ; ordered ice-VIII,\norientationally disordered ice VII and proton-disordered ice X. All transitions\nin this model might or might not be associated with a discontinuity in the\nspecific heat, depending on paramaterization. By comparing with data, we find\nthat a VII-X transition line exists, but it ends in a critical point hidden\nwithin the stability field of phase VIII. If the model is correct, there is a\ndiscontinuity between VII and X, so they are separate phases. We propose that\nthe hidden phase boundary might be demonstrated experimentally by compression\nof supercooled ice VII.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.mtrl-sci","published":"2025-04-08T17:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.06253v1","title":"Solving General QUBOs with Warm-Start QAOA via a Reduction to Max-Cut","summary":"The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm\nthat finds approximate solutions to problems in combinatorial optimization,\nespecially those that can be formulated as a Quadratic Unconstrained Binary\nOptimization (QUBO) problem. In prior work, researchers have considered various\nways of \"warm-starting\" QAOA by constructing an initial quantum state using\nclassically-obtained solutions or information; these warm-starts typically\ncause QAOA to yield better approximation ratios at much lower circuit depths.\nFor the Max-Cut problem, one warm-start approaches constructs the initial state\nusing the high-dimensional vectors that are output from an SDP relaxation of\nthe corresponding Max-Cut problem. This work leverages these semidefinite\nwarmstarts for a broader class of problem instances by using a standard\nreduction that transforms any QUBO instance into a Max-Cut instance. We\nempirically compare this approach to a \"QUBO-relaxation\" approach that relaxes\nthe QUBO directly. Our results consider a variety of QUBO instances ranging\nfrom randomly generated QUBOs to QUBOs corresponding to specific problems such\nas the traveling salesman problem, maximum independent set, and portfolio\noptimization. We find that the best choice of warmstart approach is strongly\ndependent on the problem type.","main_category":"quant-ph","categories":"quant-ph,cs.DM,math.OC","published":"2025-04-08T17:57:12Z"}
{"aid":"http://arxiv.org/abs/2504.06256v1","title":"Transfer between Modalities with MetaQueries","summary":"Unified multimodal models aim to integrate understanding (text output) and\ngeneration (pixel output), but aligning these different modalities within a\nsingle architecture often demands complex training recipes and careful data\nbalancing. We introduce MetaQueries, a set of learnable queries that act as an\nefficient interface between autoregressive multimodal LLMs (MLLMs) and\ndiffusion models. MetaQueries connects the MLLM's latents to the diffusion\ndecoder, enabling knowledge-augmented image generation by leveraging the MLLM's\ndeep understanding and reasoning capabilities. Our method simplifies training,\nrequiring only paired image-caption data and standard diffusion objectives.\nNotably, this transfer is effective even when the MLLM backbone remains frozen,\nthereby preserving its state-of-the-art multimodal understanding capabilities\nwhile achieving strong generative performance. Additionally, our method is\nflexible and can be easily instruction-tuned for advanced applications such as\nimage editing and subject-driven generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.06260v1","title":"FEABench: Evaluating Language Models on Multiphysics Reasoning Ability","summary":"Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.NA,math.NA","published":"2025-04-08T17:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.06546v1","title":"Several new infinite families of NMDS codes with arbitrary dimensions\n  supporting $t$-designs","summary":"Near maximum distance separable (NMDS) codes, where both the code and its\ndual are almost maximum distance separable, play pivotal roles in combinatorial\ndesign theory and cryptographic applications. Despite progress in fixed\ndimensions (e.g., dimension 4 codes by Ding and Tang \\cite{Ding2020}),\nconstructing NMDS codes with arbitrary dimensions supporting $t$-designs\n($t\\geq 2$) has remained open. In this paper, we construct two infinite\nfamilies of NMDS codes over $\\mathbb{F}_q$ for any prime power $q$ with\nflexible dimensions and determine their weight distributions. Further, two\nadditional families with arbitrary dimensions over $\\mathbb{F}_{2^m}$\nsupporting $2$-designs and $3$-designs, and their weight distributions are\nobtained. Our results fully generalize prior fixed-dimension\nworks~\\cite{DingY2024,Heng2023,Heng20231,Xu2022}, and affirmatively settle the\nHeng-Wang conjecture \\cite{Heng2023} on the existence of NMDS codes with\nflexible parameters supporting $2$-designs.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T03:02:10Z"}
{"aid":"http://arxiv.org/abs/2504.06576v1","title":"Theoretical analysis for non-linear effects of magnetic fields on\n  unsteady boundary layer flows","summary":"This study investigates unsteady boundary layer phenomena in electrically\nconducting fluids subjected to static magnetic fields. Using a semi-explicit\nsimilarity transformation method, the momentum equation associated with the\nStokes stream function is solved. The nonlinear closed analytical solutions for\nboth stagnation flow and converging flow are derived. The results demonstrate\nthat the boundary layer structure incorporates similar shock and solitary wave\ncomponents which are promoted by Lorentz force. Under extreme magnetic fields,\nthe flow exhibits sine and cosine wave patterns, which are motivated by the\nstrong Lorentz force. An in-depth asymptotic analysis establishes the square\nroot scaling laws that quantify the growth of friction and flux with increasing\nmagnetic field strength. The boundary layer thickness scales inversely with the\nHartmann number, a consequence of dominant Lorentz force, which differs from\nthe conclusion of duct flow (Hunt 1965). These findings elucidate the physical\nmechanisms governing the nonlinear coupling between magnetic fields and the\ndynamics of the boundary layer.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T04:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.06582v1","title":"Harmful information spreading and its impact on vaccination campaigns\n  modeled through fractal-fractional operators","summary":"Despite the huge efforts to develop and administer vaccines worldwide to cope\nwith the COVID-19 pandemic, misinformation spreading through fake news in media\nand social networks about vaccination safety, make that people refuse to be\nvaccinated, which harms not only these people but also the whole population.\n  In this work, we model the effects of harmful information spreading in\nimmunization acquisition through vaccination. Our model is posed for several\nfractional derivative operators. We have conducted a comprehensive foundation\nanalysis of this model for the different fractional derivatives. Additionally,\nwe have incorporated a strength parameter that shows the combined impact of\nnonlinear and linear components within an epidemiological model. We have used\nthe second derivative of the Lyapunov function to ascertain the detection of\nwave patterns within the vaccination dynamics.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T05:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.06583v1","title":"Aplicando diferencias finitas para resolver ecuaciones y sistemas de\n  ecuaciones diferenciales parciales sobre dominios planos irregulares\n  simplemente conexos y no conexos","summary":"Using exhaustion method and finite differences a new method to solve system\nof partial differential equations and is presented. This method allows design\nalgorithm to solve linear and nonlinear systems in irregular domains. Applying\nthis method to solve linear and nonlinear problems with prescribed conditions\nDirichlet over two-dimensional irregular domains are analyzed.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T05:05:04Z"}
{"aid":"http://arxiv.org/abs/2504.06603v1","title":"Asymptotic Variance in the Central Limit Theorem for Multilevel\n  Markovian Stochastic Approximation","summary":"In this note we consider the finite-dimensional parameter estimation problem\nassociated to inverse problems. In such scenarios, one seeks to maximize the\nmarginal likelihood associated to a Bayesian model. This latter model is\nconnected to the solution of partial or ordinary differential equation. As\nsuch, there are two primary difficulties in maximizing the marginal likelihood\n(i) that the solution of differential equation is not always analytically\ntractable and (ii) neither is the marginal likelihood. Typically (i) is dealt\nwith using a numerical solution of the differential equation, leading to a\nnumerical bias and (ii) has been well studied in the literature using, for\ninstance, Markovian stochastic approximation. It is well-known that to reduce\nthe computational effort to obtain the maximal value of the parameter, one can\nuse a hierarchy of solutions of the differential equation and combine with\nstochastic gradient methods. Several approaches do exactly this. In this paper\nwe consider the asymptotic variance in the central limit theorem, associated to\nknown estimates and find bounds on the asymptotic variance in terms of the\nprecision of the solution of the differential equation. The significance of\nthese bounds are the that they provide missing theoretical guidelines on how to\nset simulation parameters; that is, these appear to be the first mathematical\nresults which help to run the methods efficiently in practice.","main_category":"math.NA","categories":"math.NA,cs.NA,stat.CO","published":"2025-04-09T05:59:40Z"}
{"aid":"http://arxiv.org/abs/2504.06614v1","title":"AgentFM: Role-Aware Failure Management for Distributed Databases with\n  LLM-Driven Multi-Agents","summary":"Distributed databases are critical infrastructures for today's large-scale\nsoftware systems, making effective failure management essential to ensure\nsoftware availability. However, existing approaches often overlook the role\ndistinctions within distributed databases and rely on small-scale models with\nlimited generalization capabilities. In this paper, we conduct a preliminary\nempirical study to emphasize the unique significance of different roles.\nBuilding on this insight, we propose AgentFM, a role-aware failure management\nframework for distributed databases powered by LLM-driven multi-agents. AgentFM\naddresses failure management by considering system roles, data roles, and task\nroles, with a meta-agent orchestrating these components. Preliminary\nevaluations using Apache IoTDB demonstrate the effectiveness of AgentFM and\nopen new directions for further research.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T06:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.06619v1","title":"Sufficient conditions for a graph with minimum degree to have a\n  component factor","summary":"Let $\\mathcal{T}_{\\frac{k}{r}}$ denote the set of trees $T$ such that\n$i(T-S)\\leq\\frac{k}{r}|S|$ for any $S\\subset V(T)$ and for any $e\\in E(T)$\nthere exists a set $S^{*}\\subset V(T)$ with\n$i((T-e)-S^{*})>\\frac{k}{r}|S^{*}|$, where $r<k$ are two positive integers. A\n$\\{C_{2i+1},T:1\\leq i<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor of\na graph $G$ is a spanning subgraph of $G$, in which every component is\nisomorphic to an element in $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$. Let $A(G)$ and $Q(G)$ denote\nthe adjacency matrix and the signless Laplacian matrix of $G$, respectively.\nThe adjacency spectral radius and the signless Laplacian spectral radius of\n$G$, denoted by $\\rho(G)$ and $q(G)$, are the largest eigenvalues of $A(G)$ and\n$Q(G)$, respectively. In this paper, we study the connections between the\nspectral radius and the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. We first\nestablish a tight sufficient condition involving the adjacency spectral radius\nto guarantee the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. Then we\npropose a tight signless Laplacian spectral radius condition for the existence\nof a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:35:29Z"}
{"aid":"http://arxiv.org/abs/2504.06628v1","title":"Entropy Production in Non-Gaussian Active Matter: A Unified Fluctuation\n  Theorem and Deep Learning Framework","summary":"We present a general framework for deriving entropy production rates in\nactive matter systems driven by non-Gaussian active fluctuations. Employing the\nprobability flow equivalence technique, we rigorously derive an entropy\nproduction decomposition formula and demonstrate that the entropy production,\n$\\Delta s_\\mathrm{tot}$, satisfies the integral fluctuation theorem $\\langle\n\\exp[ -\\Delta s_\\mathrm{tot} + B_\\mathrm{act}] \\rangle = 1$ and the generalized\nsecond law of thermodynamics $\\langle \\Delta s_\\mathrm{tot}\\rangle \\geq\\langle\nB_\\mathrm{act}\\rangle$, where $B_\\mathrm{act}$ is a path-dependent random\nvariable associated with the active fluctuations. Our result holds generally\nfor arbitrary initial conditions, encompassing both steady-state and transient\nfinite-time regimes. In the limiting case where active fluctuations are absent\n(i.e., $B_\\mathrm{act} \\equiv 0$), the theorem reduces to the well-established\nresults in stochastic thermodynamics. Building on the theoretical foundation,\nwe propose a deep learning-based methodology to efficiently compute the entropy\nproduction, utilizing the L\\'{e}vy score function we proposed. To illustrate\nthe validity of this approach, we apply it to two representative systems: a\nBrownian particle in a periodic active bath and an active polymer system\nconsisting of an active Brownian particle cross-linker interacting with passive\nBrownian beads. Our results provide a unified framework for analyzing entropy\nproduction in active matter systems while offering practical computational\ntools for investigating complex nonequilibrium behaviors.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-09T07:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.06653v1","title":"Hunting axion dark matter signatures in low-frequency terrestrial\n  magnetic fields","summary":"We show that Earth's natural environment can serve as a powerful probe for\nultralight axion dark matter. In the presence of global geomagnetic fields, the\naxions with masses ranging from $10^{-15}\\,{\\rm eV}-10^{-13}\\,{\\rm eV}$ induce\nelectromagnetic waves in the (sub-) extremely low-frequency band ($0.3-30\\,{\\rm\nHz}$) through the axion-photon coupling. We predict the amplitude of induced\nmagnetic fields in the Earth-ionosphere cavity, taking the finite conductivity\nof the atmosphere into account. This allows us to constrain the axion-photon\ncoupling parameter, $g_{\\rm a\\gamma}$, from the long-term monitoring data of\nthe low-frequency magnetic fields, resulting in a significant improvement from\nthe previous constraints down to $g_{\\rm a\\gamma} \\lesssim\n4\\times10^{-13}\\,{\\rm GeV}^{-1}$ for axion mass $\\sim 3 \\times 10^{-14}\\,{\\rm\neV}$.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-09T07:42:28Z"}
{"aid":"http://arxiv.org/abs/2504.06680v1","title":"Deep Learning for Cardiovascular Risk Assessment: Proxy Features from\n  Carotid Sonography as Predictors of Arterial Damage","summary":"In this study, hypertension is utilized as an indicator of individual\nvascular damage. This damage can be identified through machine learning\ntechniques, providing an early risk marker for potential major cardiovascular\nevents and offering valuable insights into the overall arterial condition of\nindividual patients. To this end, the VideoMAE deep learning model, originally\ndeveloped for video classification, was adapted by finetuning for application\nin the domain of ultrasound imaging. The model was trained and tested using a\ndataset comprising over 31,000 carotid sonography videos sourced from the\nGutenberg Health Study (15,010 participants), one of the largest prospective\npopulation health studies. This adaptation facilitates the classification of\nindividuals as hypertensive or non-hypertensive (75.7% validation accuracy),\nfunctioning as a proxy for detecting visual arterial damage. We demonstrate\nthat our machine learning model effectively captures visual features that\nprovide valuable insights into an individual's overall cardiovascular health.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.06722v1","title":"Plastic tensor networks for interpretable generative modeling","summary":"A structural optimization scheme for a single-layer nonnegative adaptive\ntensor tree (NATT) that models a target probability distribution is proposed.\nThe NATT scheme, by construction, has the advantage that it is interpretable as\na probabilistic graphical model. We consider the NATT scheme and a recently\nproposed Born machine adaptive tensor tree (BMATT) optimization scheme and\ndemonstrate their effectiveness on a variety of generative modeling tasks where\nthe objective is to infer the hidden structure of a provided dataset. Our\nresults show that in terms of minimizing the negative log-likelihood, the\nsingle-layer scheme has model performance comparable to the Born machine\nscheme, though not better. The tasks include deducing the structure of binary\nbitwise operations, learning the internal structure of random Bayesian networks\ngiven only visible sites, and a real-world example related to hierarchical\nclustering where a cladogram is constructed from mitochondrial DNA sequences.\nIn doing so, we also show the importance of the choice of network topology and\nthe versatility of a least-mutual information criterion in selecting a\ncandidate structure for a tensor tree, as well as discuss aspects of these\ntensor tree generative models including their information content and\ninterpretability.","main_category":"cs.LG","categories":"cs.LG,cond-mat.stat-mech","published":"2025-04-09T09:23:11Z"}
{"aid":"http://arxiv.org/abs/2504.06725v1","title":"Using theory-driven Integrated Population Models to evaluate competitive\n  outcomes in stage-structured systems","summary":"Predicting competitive outcomes typically requires fitting dynamical models\nto data, from which interaction strengths and coexistence indicators such as\ninvasion criteria can be produced. Methods that allow to propagate parameter\nuncertainty are particularly indicated. These should ideally allow for\ncompetition between and within species at various life-stages, and make the\nbest out of multiple data sources, each of which can be relatively scarce by\nstatistical standards. Here, we embed a mathematical model of stage-structured\ncompetition between two species, producing analytical invasion criteria, into a\ntwo-species Integrated Population Model. The community-level IPM allows to\ncombine counts, capture-recapture, and fecundity data into a single statistical\nframework, and the Bayesian formulation of the IPM fully propagates parameter\nuncertainty into invasion criteria. Model fitting demonstrates that we can\ncorrectly predict coexistence through reciprocal invasion when present, but\nthat interaction strengths are not always estimable, depending on the prior\nchosen. Our competitive exclusion scenario is shown to be harder to identify,\nalthough our model allows to at least flag this scenario as uncertain rather\nthan mistakenly present it as coexistence. Our results confirm the importance\nof accounting for uncertainty in the prediction of competitive outcomes.","main_category":"q-bio.PE","categories":"q-bio.PE,stat.AP,stat.ME","published":"2025-04-09T09:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.06734v1","title":"Locally Repairable Convertible Codes: Improved Lower Bound and General\n  Construction","summary":"In this paper, we consider the convertible code with locally repairable\nproperty. We present an improved lower bound on access cost associated with\n$(r,\\delta)$. Then, we provide a general construction of convertible codes with\noptimal access cost which shows that those codes can be with super-linear\nlength or maximum repairable property. Additionally, employing the known\nlocally repairable codes with super-linear length or maximum repairable\nproperty, we provide explicit constructions of convertible codes with\nsuper-linear length or maximum repairable property.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T09:46:08Z"}
{"aid":"http://arxiv.org/abs/2504.06749v1","title":"Evidence of star cluster migration and merger in dwarf galaxies","summary":"Nuclear star clusters (NSCs) are the densest stellar systems in the Universe.\nThey can be found at the center of all galaxy types, but tend to favor galaxies\nof intermediate stellar mass around 10$^9\\,$M$_{\\odot}$[1, 2]. Currently, two\nmain processes are under debate to explain their formation: in-situ\nstar-formation from gas infall[3] and migration and merging of globular\nclusters (GCs) caused by dynamical friction[4]. Studies[5-9] of NSC stellar\npopulations suggest that the former predominates in massive galaxies, the\nlatter prevails in dwarf galaxies, and both contribute equally at intermediate\nmass. However, up to now, no ongoing merger of GCs has yet been observed to\nconfirm this scenario. Here we report the serendipitous discovery of five dwarf\ngalaxies with complex nuclear regions, characterized by multiple nuclei and\ntidal tails, using high resolution images from the Hubble Space Telescope.\nThese structures have been reproduced in complementary N-body simulations,\nsupporting the interpretation that they result from migrating and merging of\nstar clusters. The small detection rate and short simulated timescales (below\n100 Myr) of this process may explain why this has not been observed previously.\nThis study highlights the need of large surveys with high resolution to fully\nmap the migration scenario steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T10:12:37Z"}
{"aid":"http://arxiv.org/abs/2504.06753v1","title":"Detect All-Type Deepfake Audio: Wavelet Prompt Tuning for Enhanced\n  Auditory Perception","summary":"The rapid advancement of audio generation technologies has escalated the\nrisks of malicious deepfake audio across speech, sound, singing voice, and\nmusic, threatening multimedia security and trust. While existing\ncountermeasures (CMs) perform well in single-type audio deepfake detection\n(ADD), their performance declines in cross-type scenarios. This paper is\ndedicated to studying the alltype ADD task. We are the first to comprehensively\nestablish an all-type ADD benchmark to evaluate current CMs, incorporating\ncross-type deepfake detection across speech, sound, singing voice, and music.\nThen, we introduce the prompt tuning self-supervised learning (PT-SSL) training\nparadigm, which optimizes SSL frontend by learning specialized prompt tokens\nfor ADD, requiring 458x fewer trainable parameters than fine-tuning (FT).\nConsidering the auditory perception of different audio types,we propose the\nwavelet prompt tuning (WPT)-SSL method to capture type-invariant auditory\ndeepfake information from the frequency domain without requiring additional\ntraining parameters, thereby enhancing performance over FT in the all-type ADD\ntask. To achieve an universally CM, we utilize all types of deepfake audio for\nco-training. Experimental results demonstrate that WPT-XLSR-AASIST achieved the\nbest performance, with an average EER of 3.58% across all evaluation sets. The\ncode is available online.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-09T10:18:45Z"}
{"aid":"http://arxiv.org/abs/2504.06756v1","title":"Preservation of notion of C sets near zero over reals","summary":"There are several notions of largeness in a semigroup. N. Hindman and D.\nStrauss established that if $u,v \\in \\mathbb{N}$, $A$ is a $u \\times v$ matrix\nwith entries from $\\mathbb{Q}$ and $\\psi$ is a notion of a large set in\n$\\mathbb{N}$, then $\\{\\vec{x} \\in \\mathbb{N}^v: A\\vec{x} \\in \\psi^u \\}$ is\nlarge in $\\mathbb{N}^v$. Among the several notions of largeness, C sets\noccupies an important place of study because they exhibit strong combinatorial\nproperties. The analogous notion of C set appears for a dense subsemigroup $S$\nof $((0, \\infty),+)$ called a C-set near zero. These sets also have very rich\ncombinatorial structure. In this article, we investigate the above result for C\nsets near zero in $\\mathbb{R}^+$ when the matrix has real entries. We also\ndevelop a new characterisation of C-sets near zero in $\\mathbb{R}^+$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T10:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.06762v1","title":"Matching and Edge Cover in Temporal Graphs","summary":"Temporal graphs are a special class of graphs for which a temporal component\nis added to edges, that is, each edge possesses a set of times at which it is\navailable and can be traversed. Many classical problems on graphs can be\ntranslated to temporal graphs, and the results may differ. In this paper, we\ndefine the Temporal Edge Cover and Temporal Matching problems and show that\nthey are NP-complete even when fixing the lifetime or when the underlying graph\nis a tree. We then describe two FPT algorithms, with parameters lifetime and\ntreewidth, that solve the two problems. We also find lower bounds for the\napproximation of the two problems and give two approximation algorithms which\nmatch these bounds. Finally, we discuss the differences between the problems in\nthe temporal and the static framework.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-09T10:33:10Z"}
{"aid":"http://arxiv.org/abs/2504.06790v1","title":"Analog Computing with Microwave Networks","summary":"Analog computing has been recently revived due to its potential for\nenergy-efficient and highly parallel computations. In this paper, we\ninvestigate analog computers that linearly process microwave signals, named\nmicrowave linear analog computers (MiLACs), and their applications in signal\nprocessing for communications. We model a MiLAC as a multiport microwave\nnetwork with tunable impedance components, which enables the execution of\nmathematical operations by reconfiguring the microwave network and applying\ninput signals at its ports. We demonstrate that a MiLAC can efficiently compute\nthe linear minimum mean square error (LMMSE) estimator, widely used in\nmultiple-input multiple-output (MIMO) communications beamforming and detection,\nwith remarkably low computational complexity, unachievable through digital\ncomputing. Specifically, the LMMSE estimator can be computed with complexity\ngrowing with the square of its input size, rather than the cube, with\nrevolutionary applications to gigantic MIMO beamforming and detection.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-09T11:29:39Z"}
{"aid":"http://arxiv.org/abs/2504.06791v1","title":"Beware of \"Explanations\" of AI","summary":"Understanding the decisions made and actions taken by increasingly complex AI\nsystem remains a key challenge. This has led to an expanding field of research\nin explainable artificial intelligence (XAI), highlighting the potential of\nexplanations to enhance trust, support adoption, and meet regulatory standards.\nHowever, the question of what constitutes a \"good\" explanation is dependent on\nthe goals, stakeholders, and context. At a high level, psychological insights\nsuch as the concept of mental model alignment can offer guidance, but success\nin practice is challenging due to social and technical factors. As a result of\nthis ill-defined nature of the problem, explanations can be of poor quality\n(e.g. unfaithful, irrelevant, or incoherent), potentially leading to\nsubstantial risks. Instead of fostering trust and safety, poorly designed\nexplanations can actually cause harm, including wrong decisions, privacy\nviolations, manipulation, and even reduced AI adoption. Therefore, we caution\nstakeholders to beware of explanations of AI: while they can be vital, they are\nnot automatically a remedy for transparency or responsible AI adoption, and\ntheir misuse or limitations can exacerbate harm. Attention to these caveats can\nhelp guide future research to improve the quality and impact of AI\nexplanations.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T11:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.06803v1","title":"DyDiT++: Dynamic Diffusion Transformers for Efficient Visual Generation","summary":"Diffusion Transformer (DiT), an emerging diffusion model for visual\ngeneration, has demonstrated superior performance but suffers from substantial\ncomputational costs. Our investigations reveal that these costs primarily stem\nfrom the \\emph{static} inference paradigm, which inevitably introduces\nredundant computation in certain \\emph{diffusion timesteps} and \\emph{spatial\nregions}. To overcome this inefficiency, we propose \\textbf{Dy}namic\n\\textbf{Di}ffusion \\textbf{T}ransformer (DyDiT), an architecture that\n\\emph{dynamically} adjusts its computation along both \\emph{timestep} and\n\\emph{spatial} dimensions. Specifically, we introduce a \\emph{Timestep-wise\nDynamic Width} (TDW) approach that adapts model width conditioned on the\ngeneration timesteps. In addition, we design a \\emph{Spatial-wise Dynamic\nToken} (SDT) strategy to avoid redundant computation at unnecessary spatial\nlocations. TDW and SDT can be seamlessly integrated into DiT and significantly\naccelerates the generation process. Building on these designs, we further\nenhance DyDiT in three key aspects. First, DyDiT is integrated seamlessly with\nflow matching-based generation, enhancing its versatility. Furthermore, we\nenhance DyDiT to tackle more complex visual generation tasks, including video\ngeneration and text-to-image generation, thereby broadening its real-world\napplications. Finally, to address the high cost of full fine-tuning and\ndemocratize technology access, we investigate the feasibility of training DyDiT\nin a parameter-efficient manner and introduce timestep-based dynamic LoRA\n(TD-LoRA). Extensive experiments on diverse visual generation models, including\nDiT, SiT, Latte, and FLUX, demonstrate the effectiveness of DyDiT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T11:48:37Z"}
{"aid":"http://arxiv.org/abs/2504.06805v1","title":"Robust Classification with Noisy Labels Based on Posterior Maximization","summary":"Designing objective functions robust to label noise is crucial for real-world\nclassification algorithms. In this paper, we investigate the robustness to\nlabel noise of an $f$-divergence-based class of objective functions recently\nproposed for supervised classification, herein referred to as $f$-PML. We show\nthat, in the presence of label noise, any of the $f$-PML objective functions\ncan be corrected to obtain a neural network that is equal to the one learned\nwith the clean dataset. Additionally, we propose an alternative and novel\ncorrection approach that, during the test phase, refines the posterior\nestimated by the neural network trained in the presence of label noise. Then,\nwe demonstrate that, even if the considered $f$-PML objective functions are not\nsymmetric, they are robust to symmetric label noise for any choice of\n$f$-divergence, without the need for any correction approach. This allows us to\nprove that the cross-entropy, which belongs to the $f$-PML class, is robust to\nsymmetric label noise. Finally, we show that such a class of objective\nfunctions can be used together with refined training strategies, achieving\ncompetitive performance against state-of-the-art techniques of classification\nwith label noise.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T11:52:51Z"}
{"aid":"http://arxiv.org/abs/2504.06828v1","title":"New physics particles mixing with mesons: production in the\n  fragmentation chain","summary":"A class of extensions to the Standard Model adds hypothetical long-lived\nparticles (LLPs) that have mass- or kinetic-mixing with neutral mesons, such as\npions or rho mesons. The mixing can contribute significantly to the production\nof LLPs at proton accelerator experiments, and no consistent description of\nthese production modes exists in the literature. In this paper, we develop a\nframework for studying different LLPs - dark photons, vector mediators coupled\nto the baryon current, and axion-like particles with different coupling\npatterns. In particular, we implement the production mechanisms in\n\\texttt{PYTHIA8}, study how the overall flux and kinematic distributions depend\non the LLP's mass, and compare various sub-processes where the mixing\ncontributes - proton bremsstrahlung, meson decay, and production in the\nfragmentation chain. We find that our new description of LLP production\npredicts an integrated flux that differs from current approaches by one to two\norders of magnitude, and highlight the unavoidable theoretical uncertainties\ncoming from poor knowledge of the properties of heavy mesons.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T12:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.06829v1","title":"Adaptive Locally Linear Embedding","summary":"Manifold learning techniques, such as Locally linear embedding (LLE), are\ndesigned to preserve the local neighborhood structures of high-dimensional data\nduring dimensionality reduction. Traditional LLE employs Euclidean distance to\ndefine neighborhoods, which can struggle to capture the intrinsic geometric\nrelationships within complex data. A novel approach, Adaptive locally linear\nembedding(ALLE), is introduced to address this limitation by incorporating a\ndynamic, data-driven metric that enhances topological preservation. This method\nredefines the concept of proximity by focusing on topological neighborhood\ninclusion rather than fixed distances. By adapting the metric based on the\nlocal structure of the data, it achieves superior neighborhood preservation,\nparticularly for datasets with complex geometries and high-dimensional\nstructures. Experimental results demonstrate that ALLE significantly improves\nthe alignment between neighborhoods in the input and feature spaces, resulting\nin more accurate and topologically faithful embeddings. This approach advances\nmanifold learning by tailoring distance metrics to the underlying data,\nproviding a robust solution for capturing intricate relationships in\nhigh-dimensional datasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T12:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.06852v1","title":"Quantum controlling and the topological properties of the magnon\n  photo-transport in two-dimensional collinear ferromagnet","summary":"In our work, we study magnon transport induced by light through\nAharonov-Casher (AC) effect, including magnon spin photocurrent (MSPC) and\nmagnon energy photocurrent (MEPC). Firstly, we regard the effect of the\nelectric field on the magnon through the AC effect as a perturbation. Then we\nderived the expressions of MSPC and MEPC in two-dimensional collinear\nferromagnetic system. And we apply our theory to the two-dimension\nferromagnetic Hexagonal and Kagome lattice. We find that the optical frequency\nand the relaxation time of the material can be used to control the\nphoto-transport of magnons. In addition, under the condition of low light\nfrequncy and infinite relaxation time, the longitudinal magnon photo-transport\nis related to the topological property of the magnon system.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T13:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.06853v1","title":"Magnetic ground state discrimination of a Polyradical Nanog-raphene\n  using Nickelocene-Functionalized Tips","summary":"Molecular magnets are a promising class of materials with exciting properties\nand applications. However, a profound understanding and application of such\nmaterials depends on the accurate detection of their electronic and magnetic\nproperties. Despite the availability of experimental techniques that can sense\nthe magnetic signal, the exact determination of the spin ground states and\nspatial distribution of exchange interaction of strongly correlated\nsingle-molecule magnets remains challenging. Here, we demonstrate that scanning\nprobe microscopy with a nickelocene-functionalized probe can distinguish\nbetween nearly degenerate multireference ground states of single-molecule\n{\\pi}-magnets and map their spatial distribution of the exchange interaction.\nThis method expands the already outstanding imaging capabilities of scanning\nprobe microscopy for characterizing the chemical and electronic structures of\nindividual molecules, paving the way for the study of strongly correlated\nmolecular magnets with unprecedented spatial resolution.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-09T13:07:03Z"}
{"aid":"http://arxiv.org/abs/2504.06855v1","title":"Compactified moduli spaces and Hecke correspondences for elliptic curves\n  with a prescribed $N$-torsion scheme","summary":"Given an integer $N \\geq 3$, we prove that for any ring $R$ and any finite\nlocally free $R$-group scheme $G$ which is fppf-locally (over $R$) isomorphic\nthe $N$-torsion subscheme of some elliptic curve $E/R$, there is a smooth\naffine curve $Y_G(N)$ parametrizing elliptic curves over $R$-schemes whose\n$N$-torsion subscheme is isomorphic to $G$. We also describe compactifications\n$X_G(N)$ of these curves when $R$ is a regular excellent Noetherian ring in\nwhich $N$ is invertible, as well as construct the Hecke correspondences they\nare endowed with. As an application, we show that the equations for $X_G(N)$\nfound over base fields for $N=7,8,9,11,13$ (by Halberstadt--Kraus,\nPoonen--Schaefer--Stoll, Chen and Fisher) are in fact valid over regular\nexcellent Noetherian bases that are $\\mathbb{Q}$-algebras. Finally, we describe\nin detail the equivalence of this construction with the point of view of Galois\ntwists that these authors use.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-09T13:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.06860v1","title":"Machine Learning (ML) based Reduced Order Modeling (ROM) for linear and\n  non-linear solid and structural mechanics","summary":"Multiple model reduction techniques have been proposed to tackle linear and\nnon linear problems. Intrusive model order reduction techniques exhibit high\naccuracy levels, however, they are rarely used as a standalone industrial tool,\nbecause of the required high level knowledge involved in the construction and\nusage of these techniques. Moreover, the computation time benefit is\ncompromised for highly nonlinear problems. On the other hand, non-intrusive\nmethods often struggle with accuracy in nonlinear cases, typically requiring a\nlarge design of experiment and a large number of snapshots achieve a reliable\nperformance. However, generating the stiffness matrix in a non-intrusive\napproach presents an optimal way to align accuracy with efficiency, allying the\nadvantages of both intrusive and non-intrusive methods.This work introduces a\nlightly intrusive model order reduction technique that employs machine learning\nwithin a Proper Orthogonal Decomposition framework to achieve this alliance. By\nleveraging outputs from commercial full-order models, this method constructs a\nreduced-order model that operates effectively without requiring expert user\nintervention. The proposed technique has the possibility to approximate linear\nnon affine as well as non linear terms. It is showcased for linear and\nnonlinear structural mechanics problems.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-09T13:11:05Z"}
{"aid":"http://arxiv.org/abs/2504.06876v1","title":"Anomalous transport models for fluid classification: insights from an\n  experimentally driven approach","summary":"In recent years, research and development in nanoscale science and technology\nhave grown significantly, with electrical transport playing a key role. A\nnatural challenge for its description is to shed light on anomalous behaviours\nobserved in a variety of low-dimensional systems. We use a synergistic\ncombination of experimental and mathematical modelling to explore the transport\nproperties of the electrical discharge observed within a micro-gap based sensor\nimmersed in fluids with different insulating properties. Data from laboratory\nexperiments are collected and used to inform and calibrate four mathematical\nmodels that comprise partial differential equations describing different kinds\nof transport, including anomalous diffusion: the Gaussian Model with Time\nDependent Diffusion Coefficient, the Porous Medium Equation, the\nKardar-Parisi-Zhang Equation and the Telegrapher Equation. Performance analysis\nof the models through data fitting reveals that the Gaussian Model with a\nTime-Dependent Diffusion Coefficient most effectively describes the observed\nphenomena. This model proves particularly valuable in characterizing the\ntransport properties of electrical discharges when the micro-electrodes are\nimmersed in a wide range of insulating as well as conductive fluids. Indeed, it\ncan suitably reproduce a range of behaviours spanning from clogging to bursts,\nallowing accurate and quite general fluid classification. Finally, we apply the\ndata-driven mathematical modeling approach to ethanol-water mixtures. The\nresults show the model's potential for accurate prediction, making it a\npromising method for analyzing and classifying fluids with unknown insulating\nproperties.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.flu-dyn","published":"2025-04-09T13:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.06877v1","title":"Dissipation and noise in strongly driven Josephson junctions","summary":"In circuit quantum electrodynamics systems, the quasiparticle-related losses\nin Josephson junctions are suppressed due to the gap in the superconducting\ndensity of states which is much higher than the typical energy of a microwave\nphoton. In this work, we show that a strong drive even at frequency lower than\nthe double superconducting gap enables dissipation in the junctions due to\nphoton-assisted breaking of the Cooper pairs. Both the decay rate and noise\nstrength associated with the losses are sensitive to the dc phase bias of the\njunction and can be tuned in a broad range by the amplitude and the frequency\nof the external driving field, making the suggested mechanism potentially\nattractive for designing tunable dissipative elements. Furthermore, pronounced\nmemory effects in the driven Josephson junctions render them perspective for\nboth theoretical and experimental study of non-Markovian physics in\nsuperconducting quantum circuits. We illustrate our theoretical findings by\nstudying the spectral properties and the steady state population of a low\nimpedance resonator coupled to the driven Josephson junction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.06895v1","title":"ColorizeDiffusion v2: Enhancing Reference-based Sketch Colorization\n  Through Separating Utilities","summary":"Reference-based sketch colorization methods have garnered significant\nattention due to their potential applications in the animation production\nindustry. However, most existing methods are trained with image triplets of\nsketch, reference, and ground truth that are semantically and spatially\nwell-aligned, while real-world references and sketches often exhibit\nsubstantial misalignment. This mismatch in data distribution between training\nand inference leads to overfitting, consequently resulting in spatial artifacts\nand significant degradation in overall colorization quality, limiting potential\napplications of current methods for general purposes. To address this\nlimitation, we conduct an in-depth analysis of the \\textbf{carrier}, defined as\nthe latent representation facilitating information transfer from reference to\nsketch. Based on this analysis, we propose a novel workflow that dynamically\nadapts the carrier to optimize distinct aspects of colorization. Specifically,\nfor spatially misaligned artifacts, we introduce a split cross-attention\nmechanism with spatial masks, enabling region-specific reference injection\nwithin the diffusion process. To mitigate semantic neglect of sketches, we\nemploy dedicated background and style encoders to transfer detailed reference\ninformation in the latent feature space, achieving enhanced spatial control and\nricher detail synthesis. Furthermore, we propose character-mask merging and\nbackground bleaching as preprocessing steps to improve foreground-background\nintegration and background generation. Extensive qualitative and quantitative\nevaluations, including a user study, demonstrate the superior performance of\nour proposed method compared to existing approaches. An ablation study further\nvalidates the efficacy of each proposed component.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:55:32Z"}
{"aid":"http://arxiv.org/abs/2504.06915v1","title":"An Analysis of Temporal Dropout in Earth Observation Time Series for\n  Regression Tasks","summary":"Missing instances in time series data impose a significant challenge to deep\nlearning models, particularly in regression tasks. In the Earth Observation\nfield, satellite failure or cloud occlusion frequently results in missing\ntime-steps, introducing uncertainties in the predicted output and causing a\ndecline in predictive performance. While many studies address missing\ntime-steps through data augmentation to improve model robustness, the\nuncertainty arising at the input level is commonly overlooked. To address this\ngap, we introduce Monte Carlo Temporal Dropout (MC-TD), a method that\nexplicitly accounts for input-level uncertainty by randomly dropping time-steps\nduring inference using a predefined dropout ratio, thereby simulating the\neffect of missing data. To bypass the need for costly searches for the optimal\ndropout ratio, we extend this approach with Monte Carlo Concrete Temporal\nDropout (MC-ConcTD), a method that learns the optimal dropout distribution\ndirectly. Both MC-TD and MC-ConcTD are applied during inference, leveraging\nMonte Carlo sampling for uncertainty quantification. Experiments on three EO\ntime-series datasets demonstrate that MC-ConcTD improves predictive performance\nand uncertainty calibration compared to existing approaches. Additionally, we\nhighlight the advantages of adaptive dropout tuning over manual selection,\nmaking uncertainty quantification more robust and accessible for EO\napplications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-09T14:23:04Z"}
{"aid":"http://arxiv.org/abs/2504.06933v1","title":"Well-posedness of half-harmonic map heat flows for rough initial data","summary":"We adopt the Koch-Tataru theory for the Navier-Stokes equations, based on\nCarleson measure estimates, to develop a scaling-critical low-regularity\nframework for half-harmonic map heat flows. This nonlocal variant of the\nharmonic map heat flow has been studied recently in connection with free\nboundary minimal surfaces. We introduce a new class of initial data for the\nflow, broader than the conventional energy or Sobolev spaces considered in\nprevious work, for which we establish existence, uniqueness, and continuous\ndependence.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.06937v1","title":"Finite Field Multiple Access III: from 2-ary to p-ary","summary":"This paper extends finite-field multiple-access (FFMA) techniques from binary\nto general $p$-ary source transmission. We introduce element-assemblage (EA)\ncodes over GF($p^m$), generalizing element-pair (EP) codes, and define two\nspecific types for ternary transmission: orthogonal EA codes and double\ncodeword EA (D-CWEA) codes. A unique sum-pattern mapping (USPM) constraint is\nproposed for the design of uniquely-decodable CWEA (UD-CWEA) codes, including\nadditive inverse D-CWEA (AI-D-CWEA) and basis decomposition D-CWEA (BD-D-CWEA)\ncodes. Moreover, we extend EP-coding to EA-coding, focusing on non-orthogonal\nCWEA (NO-CWEA) codes and their USPM constraint in the complex field.\nAdditionally, $p$-ary CWEA codes are constructed using a basis decomposition\nmethod, leveraging ternary decomposition for faster convergence and simplified\nencoder/decoder design. We present a comprehensive performance analysis of the\nproposed FFMA system from two complementary perspectives: channel capacity and\nerror performance. We demonstrate that equal power allocation (EPA) achieves\nthe theoretical channel capacity bound, while independently developing a\nrate-driven capacity alignment (CA) theorem based on the capacity-to-rate ratio\n(CRR) metric for error performance analysis. We then explore the multiuser\nfinite blocklength (FBL) characteristics of FFMA systems. Finally, a\ncomparative analysis of $p$-ary transmission systems against classical binary\nsystems is conducted, revealing that low-order $p$-ary systems (e.g., $p=3$)\noutperform binary systems at small loading factors, while higher-order systems\n(e.g., $p=257$) excel at larger loading factors. These findings highlight the\npotential of $p$-ary systems, although practical implementations may benefit\nfrom decomposing $p$-ary systems into ternary systems to manage complexity.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T14:41:36Z"}
{"aid":"http://arxiv.org/abs/2504.06940v1","title":"More-efficient Quantum Multivariate Mean Value Estimator from\n  Generalized Grover Gate","summary":"In this work, we present an efficient algorithm for multivariate mean value\nestimation. Our algorithm outperforms previous work by polylog factors and\nnearly saturates the known lower bound. We find an algorithm that uses\n$O\\left(n \\log \\frac{d}{\\delta}\\right)$ to achieve precision\n$\\frac{\\sqrt{\\text{tr } \\Sigma}}{n}$ in $\\lVert \\rVert_\\infty$ norm and hence\n$\\frac{\\sqrt{d \\text{ tr } \\Sigma}}{n}$ in $\\lVert \\rVert_2$ norm, where $d$ is\nthe dimension and $\\Sigma$ is the covariance matrix. We also presented another\nalgorithm that uses smaller memory but costs an extra $d^\\frac{1}{4}$ in\ncomplexity. The idea originates from the previous observations that the Grover\ngate, when generalized to allow for arbitrary phases instead of $\\pm 1$,\nbecomes a good mean value estimator in some mathematical notion. The only\nremaining $\\log \\frac{d}{\\delta}$ as opposed to $\\log \\frac{1}{\\delta}$ is due\nto the phase estimation primitive we employed, which so far is the only major\nknown method to tackle the problem. Our results demonstrates that our\nmethodology with generalized Grover gate can be used locate the optimal\nalgorithm, without polylog overhead, for different taks relating to mean value\nestimation.","main_category":"quant-ph","categories":"quant-ph,cs.CC","published":"2025-04-09T14:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.06941v1","title":"Proofs of two conjectures on congruences of overcubic partition triples","summary":"Let $\\overline{bt}(n)$ denote the number of overcubic partition triples of\n$n$. Nayaka, Dharmendra and Kumar proved some congruences modulo 8, 16 and 32\nfor $\\overline{bt}(n)$. Recently, Saikia and Sarma established some congruences\nmodulo 64 for $\\overline{bt}(n)$ by using both elementary techniques and the\ntheory of modular forms. In their paper, they also posed two conjectures on\ninfinite families of congruences modulo 64 and 128 for $\\overline{bt}(n)$. In\nthis paper, we confirm the two conjectures.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T14:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.06945v1","title":"Generic deformation channels for critical Fermi surfaces including the\n  impact of collisions","summary":"This paper constitutes a sequel to our theoretical efforts to determine the\nnature of the generic low-energy deformations of the Fermi surface of a\nquantum-critical metal, which arises at the stable non-Fermi liquid (NFL) fixed\npoint of a quantum phase transition. The emergent critical Fermi surface,\narising right at the Ising-nematic quantum critical point (QCP), is a\nparadigmatic example where an NFL behaviour is induced by the strong\ninteractions of the fermionic degrees of freedom with those of the bosonic\norder parameter. It is an artifact of the bosonic modes becoming massless at\nthe QCP, thus undergoing Landau damping at the level of one-loop self-energy.\nWe resort to the well-tested formalism of the quantum Boltzmann equations\n(QBEs)for identifying the excitations. While in our earlier works, we have\nfocussed on the collisionless regime by neglecting the collision integral and\nassuming the bosons to be in equilibrium, here we embark on a full analysis. In\nparticular, we take into account the bosonic part of the QBEs. The final\nresults show that that the emergent modes are long-lived and robust against the\ndamping effects brought about the collision integral(s), exhibiting the same\nqualitative features as obtained from the no-collision approximations.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,hep-th","published":"2025-04-09T14:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.06960v1","title":"Higher-Order Color Voronoi Diagrams and the Colorful Clarkson-Shor\n  Framework","summary":"Given a set $S$ of $n$ colored sites, each $s\\in S$ associated with a\ndistance-to-site function $\\delta_s \\colon \\mathbb{R}^2 \\to \\mathbb{R}$, we\nconsider two distance-to-color functions for each color: one takes the minimum\nof $\\delta_s$ for sites $s\\in S$ in that color and the other takes the maximum.\nThese two sets of distance functions induce two families of higher-order\nVoronoi diagrams for colors in the plane, namely, the minimal and maximal\norder-$k$ color Voronoi diagrams, which include various well-studied Voronoi\ndiagrams as special cases. In this paper, we derive an exact upper bound\n$4k(n-k)-2n$ on the total number of vertices in both the minimal and maximal\norder-$k$ color diagrams for a wide class of distance functions $\\delta_s$ that\nsatisfy certain conditions, including the case of point sites $S$ under convex\ndistance functions and the $L_p$ metric for any $1\\leq p \\leq\\infty$. For the\n$L_1$ (or, $L_\\infty$) metric, and other convex polygonal metrics, we show that\nthe order-$k$ minimal diagram of point sites has $O(\\min\\{k(n-k), (n-k)^2\\})$\ncomplexity, while its maximal counterpart has $O(\\min\\{k(n-k), k^2\\})$\ncomplexity. To obtain these combinatorial results, we extend the Clarkson--Shor\nframework to colored objects, and demonstrate its application to several\nfundamental geometric structures, including higher-order color Voronoi\ndiagrams, colored $j$-facets, and levels in the arrangements of piecewise\nlinear/algebraic curves/surfaces. We also present an iterative approach to\ncompute higher-order color Voronoi diagrams.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-09T15:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.06964v1","title":"Thermodynamics of effective loop quantum black holes","summary":"We study the thermodynamics of a non-singular black hole model with effective\nquantum corrections motivated by Loop Quantum Gravity (LQG). The effective\ngeometry has a transition surface that connects trapped and anti-trapped\nregions with the same mass. There is a minimum mass for which the horizon\ntemperature and Komar energy are zero, and the black hole stops its Hawking\nevaporation. For horizons above this limit, we present the grey-body factors,\nemission spectra, and the mass loss rate, solving a one-dimensional\nSchrdinger-type equation with an effective short-range potential barrier for\nmassless fields of spins 0, 1/2, 1 and 2.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-09T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.06972v1","title":"Signatures of unconventional superconductivity near reentrant and\n  fractional quantum anomalous Hall insulators","summary":"Two-dimensional moir\\'e Chern bands provide an exceptional platform for\nexploring a variety of many-body electronic liquid and solid phases at zero\nmagnetic field within a lattice system. One particular intriguing possibility\nis that flat Chern bands can, in principle, support exotic superconducting\nphases together with fractional topological phases. Here, we report the\nobservation of integer and fractional quantum anomalous Hall effects, the\nreentrant quantum anomalous Hall effect, and superconductivity within the first\nmoir\\'e Chern band of twisted bilayer MoTe2. The superconducting phase emerges\nfrom a normal state exhibiting anomalous Hall effects and sustains an large\nperpendicular critical magnetic field. Our results present the first example of\nsuperconductivity emerging within a flat Chern band that simultaneously hosts\nfractional quantum anomalous effects, a phenomenon never observed in any other\nsystems. Our work expands the understanding of emergent quantum phenomena in\nmoir\\'e Chern bands, and offers a nearly ideal platform for engineering\nMajorana and parafermion zero modes in gate-controlled hybrid devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-09T15:27:56Z"}
{"aid":"http://arxiv.org/abs/2504.06977v1","title":"Probing dipolar interactions between Rydberg atoms and ultracold polar\n  molecules","summary":"We probe resonant dipolar interactions between ultracold $^{40}$K$^{87}$Rb\nmolecules and Rydberg $^{87}$Rb atoms in an optically trapped ensemble. Through\nstate-selective ionization detection of the KRb molecules, we observe resonant\nenergy transfer at 2.227 GHz from Rydberg atoms to molecules under a tunable\nexternal electric field. We measure a broadening up to 3.5 MHz, for the Rb\nRydberg excitation spectrum, which matches a Monte Carlo simulation that\ndescribes a Rydberg atom and neighboring molecules evolving under a\ndipole-dipole interacting Hamiltonian. The demonstrated interspecies dipolar\ninteraction is a key ingredient for hybrid Rydberg-polar molecule systems,\nwhere the advantages of each system can be leveraged and combined.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-09T15:31:02Z"}
{"aid":"http://arxiv.org/abs/2504.06985v1","title":"M-theory boundaries beyond supersymmetry","summary":"The chiral worldvolume theory of an M-theory boundary (the so-called M9\nbrane) is uniquely determined by supersymmetry and anomaly inflow. In this\nbrief note we investigate whether alternative chiral boundary field contents\nmay be allowed by anomaly cancellation once supersymmetry is dropped. Even\nthen, anomaly inflow places stringent constraints on the gauge group $G$ and\nmatter content of the boundary worldvolume theory, which we determine\nexplicitly. We find the most general solution to these constraints in the case\nwhere all matter fields are of the same chirality, for all simple Lie algebras\nexcept $\\mathfrak{sp}_2$, $\\mathfrak{su}_{n\\leq5}$, and $\\mathfrak{so}_{n}$\nwith $7\\leq n\\leq 12$, and find no solutions other than the supersymmetric\n$E_8$ boundary of Ho\\v{r}ava and Witten. However, when we extend our search to\nallow for any chirality in the matter fields, we find one minimal solution with\ngauge group $G_2$, charged matter in the $\\mathsf{14}$, $\\mathsf{27}$ and\n$\\mathsf{77}$ representations, which satisfies all constraints in a non-trivial\nway. Therefore, it could in principle describe the low-energy theory of a novel\nnonsupersymmetric M-theory boundary condition, different from the\nHo\\v{r}ava-Witten proposal. We briefly discuss some consequences if this was\nindeed the case, such as the existence of a non-supersymmetric, exotic\n\"$G_2$-string\" CFT in 6d, and a novel, non-perturbative, heterotic-like 10d\nstring with gauge group $G_2\\times G_2$.","main_category":"hep-th","categories":"hep-th","published":"2025-04-09T15:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.06987v1","title":"Enhancing Metabolic Syndrome Prediction with Hybrid Data Balancing and\n  Counterfactuals","summary":"Metabolic Syndrome (MetS) is a cluster of interrelated risk factors that\nsignificantly increases the risk of cardiovascular diseases and type 2\ndiabetes. Despite its global prevalence, accurate prediction of MetS remains\nchallenging due to issues such as class imbalance, data scarcity, and\nmethodological inconsistencies in existing studies. In this paper, we address\nthese challenges by systematically evaluating and optimizing machine learning\n(ML) models for MetS prediction, leveraging advanced data balancing techniques\nand counterfactual analysis. Multiple ML models, including XGBoost, Random\nForest, TabNet, etc., were trained and compared under various data balancing\ntechniques such as random oversampling (ROS), SMOTE, ADASYN, and CTGAN.\nAdditionally, we introduce MetaBoost, a novel hybrid framework that integrates\nSMOTE, ADASYN, and CTGAN, optimizing synthetic data generation through weighted\naveraging and iterative weight tuning to enhance the model's performance\n(achieving a 1.14% accuracy improvement over individual balancing techniques).\nA comprehensive counterfactual analysis is conducted to quantify feature-level\nchanges required to shift individuals from high-risk to low-risk categories.\nThe results indicate that blood glucose (50.3%) and triglycerides (46.7%) were\nthe most frequently modified features, highlighting their clinical significance\nin MetS risk reduction. Additionally, probabilistic analysis shows elevated\nblood glucose (85.5% likelihood) and triglycerides (74.9% posterior\nprobability) as the strongest predictors. This study not only advances the\nmethodological rigor of MetS prediction but also provides actionable insights\nfor clinicians and researchers, highlighting the potential of ML in mitigating\nthe public health burden of metabolic syndrome.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T15:51:10Z"}
{"aid":"http://arxiv.org/abs/2504.06997v1","title":"Cerebral blood flow monitoring using a deep learning implementation of\n  the two-layer DCS analytical model with a 512 512 SPAD array","summary":"Diffuse correlation spectroscopy (DCS) analyzes the autocorrelation function\nof photons scattered by red blood cells, enabling non-invasive, continuous\nmeasurement of deep tissue blood flow at the bedside. Multi-layer DCS models\n(two- and three-layer) enhance cerebral blood flow index (CBFi) sensitivity and\nmitigate interference from extracerebral tissues. However, these models require\nmultiple predefined parameters and are computationally intensive, making them\nimpractical for real-time bedside monitoring. To address this challenge, we\nintegrate a single-photon avalanche diode (SPAD) array with a deep learning\n(DL)-based approach trained on data generated by the two-layer analytical\nmodel. This method bypasses traditional model fitting, enabling real-time CBFi\nmonitoring while minimizing superficial tissue contamination. We first validate\nour approach using Monte Carlo-simulated test datasets, demonstrating superior\naccuracy in relative CBFi estimation (5.8% error vs. 19.1% for conventional\nfitting) and enhanced CBFi sensitivity (87.1% vs. 55.4%). Additionally, our\nmethod effectively isolates shallow blood flow changes and 750-fold faster than\nsingle-exponential fitting in a realistic scenario. We further evaluate the\nsystem in a healthy adult, achieving real-time CBFi monitoring and pulsatile\nwaveform recovery during a brain activity test using a 512 512 SPAD array\nsensor. These results highlight the potential of our approach for real-time\nbrain activity monitoring.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.bio-ph","published":"2025-04-09T16:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07019v1","title":"Non-Hermitian Numerical Renormalization Group: Solution of the\n  non-Hermitian Kondo model","summary":"Non-Hermitian (NH) Hamiltonians describe open quantum systems, nonequilibrium\ndynamics, and dissipative processes. Although a rich range of single-particle\nNH physics has been uncovered, many-body phenomena in strongly correlated NH\nsystems have been far less well studied. The Kondo effect, an important\nparadigm for strong correlation physics, has recently been considered in the NH\nsetting. Here we develop a NH generalization of the numerical renormalization\ngroup (NRG) and use it to solve the NH Kondo model. Our non-perturbative\nsolution applies beyond weak coupling, and we uncover a nontrivial phase\ndiagram. The method is showcased by application to the NH pseudogap Kondo\nmodel, which we show supports a completely novel phase with a genuine NH stable\nfixed point and complex eigenspectrum. Our NH-NRG code, which can be used in\nregimes and for models inaccessible to, e.g., perturbative scaling and Bethe\nansatz, is provided open source.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-09T16:34:49Z"}
{"aid":"http://arxiv.org/abs/2504.07030v1","title":"Decoherence effects in entangled fermion pairs at colliders","summary":"Recent measurements at the Large Hadron Collider have observed entanglement\nin the spins of $t\\bar t$ pairs. The effects of radiation, which are expected\nto lead to quantum decoherence and a reduction of entanglement, are generally\nneglected in such measurements. In this letter we calculate the effects of\ndecoherence from various different types of radiation for a maximally entangled\npair of fermions -- a bipartite system of qubits in a Bell state. We identify\nthe Kraus operators describing the evolution of the open quantum system with\nthe integrated Altarelli-Parisi splitting functions.","main_category":"quant-ph","categories":"quant-ph,hep-ex,hep-ph","published":"2025-04-09T16:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.07039v1","title":"Microlensing at Cosmological Distances: Event Rate Predictions in the\n  Warhol Arc of MACS 0416","summary":"Highly magnified stars ($\\mu$ $>$ 100) are now outinely identified as\ntransient events at cosmological distances thanks to microlensing by\nintra-cluster stars near the critical curves of galaxy clusters. Using the {\\it\nJames Webb} Space Telescope (JWST) in combination with the {\\it Hubble} Space\nTelescope (HST), we outline here an analytical framework that is applied to the\nWarhol arc (at $z=0.94$) in the MACS 0416 galaxy cluster (at $z=0.396)$ where\nover a dozen microlensed stars have been detected to date. This method is\ngeneral and can be applied to other lensed arcs. Within this lensed galaxy we\nfit the spatially resolved SED spanned by eight JWST-NIRCam filters combined\nwith three ACS filters, for accurate lensed star predictions in 2D. With this\ntool we can generate 2D maps of microlensed stars for well resolved arcs in\ngeneral, including dependence on wavelength and limiting apparent magnitude,\nfor comparison with with planned cadenced campaigns for JWST and Hubble, for\nconstraining directly the IMF and the level of dark matter substructure.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,astro-ph.SR","published":"2025-04-09T16:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.07073v1","title":"New empirical mass-loss recipe for UV radiation line-driven winds of hot\n  stars across various metallicities","summary":"The winds of massive stars remove a significant fraction of their mass,\nstrongly impacting their evolution. As a star evolves, the rate at which it\nloses mass changes. In stellar evolution codes, different mass-loss recipes are\nemployed for different evolutionary stages. The choice of the recipes is\nuser-dependent and the conditions for switching between them are poorly\ndefined. Focusing on hot stars, we aim to produce a physically motivated,\nempirically calibrated mass-loss recipe suitable for a wide range of\nmetallicities. We want to provide a ready-to-use universal recipe that\neliminates the need for switching between recipes for hot stars during stellar\nevolution calculations. We compile a sample of hot stars with reliable stellar\nand wind parameters in the Galaxy and the Magellanic Clouds. The sample is used\nto determine the dependence of the mass-loss rate on the basic stellar\nparameters. We find that independent of evolutionary stage and temperature, the\nwind mass-loss rate is a function of the electron-scattering Eddington\nparameter ($\\Gamma_e$) and metallicity (Z), being in line with expectations of\nradiation-driven wind theory. Our derived scaling relation provides an adequate\n($\\Delta$log($\\dot{M}$/(M$_\\odot$/yr)) = 0.43) and broadly applicable mass-loss\nrecipe for hot stars. The newly derived mass-loss recipe covers nearly the\nentire parameter space of hot stars with UV radiation-driven winds and\neliminates the need for interpolation between mass-loss formulae at different\nevolutionary stages when applied in stellar evolution models. Examples of\nstellar evolution calculations using our new recipe reveal that the predictions\non the ionizing fluxes and final fates of massive stars, especially at low\nmetallicity, differ significantly from models that use the standard mass-loss\nrates, impacting our understanding of stellar populations at low metallicity\nand in the young Universe.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-09T17:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.07419v1","title":"Exploring Vulnerabilities and Concerns in Solana Smart Contracts","summary":"The Solana blockchain was created by Anatoly Yakovenko of Solana Labs and was\nintroduced in 2017, employing a novel transaction verification method. However,\nat the same time, the innovation process introduced some new security issues.\nThe frequent security incidents in smart contracts have not only caused\nenormous economic losses, but also undermined the credit system based on the\nblockchain. The security and reliability of smart contracts have become a new\nfocus of research both domestically and abroad. This paper studies the current\nstatus of security analysis of Solana by researching Solana smart contract\nsecurity analysis tools. This paper systematically sorts out the\nvulnerabilities existing in Solana smart contracts and gives examples of some\nvulnerabilities, summarizes the principles of security analysis tools, and\ncomprehensively summarizes and details the security analysis tools in Solana\nsmart contracts. The data of Solana smart contract security analysis tools are\ncollected and compared with Ethereum, and the differences are analyzed and some\ntools are selected for practical testing.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-10T03:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.07428v1","title":"Task-oriented Age of Information for Remote Inference with Hybrid\n  Language Models","summary":"Large Language Models (LLMs) have revolutionized the field of artificial\nintelligence (AI) through their advanced reasoning capabilities, but their\nextensive parameter sets introduce significant inference latency, posing a\nchallenge to ensure the timeliness of inference results. While Small Language\nModels (SLMs) offer faster inference speeds with fewer parameters, they often\ncompromise accuracy on complex tasks. This study proposes a novel remote\ninference system comprising a user, a sensor, and an edge server that\nintegrates both model types alongside a decision maker. The system dynamically\ndetermines the resolution of images transmitted by the sensor and routes\ninference tasks to either an SLM or LLM to optimize performance. The key\nobjective is to minimize the Task-oriented Age of Information (TAoI) by jointly\nconsidering the accuracy and timeliness of the inference task. Due to the\nnon-uniform transmission time and inference time, we formulate this problem as\na Semi-Markov Decision Process (SMDP). By converting the SMDP to an equivalent\nMarkov decision process, we prove that the optimal control policy follows a\nthreshold-based structure. We further develop a relative policy iteration\nalgorithm leveraging this threshold property. Simulation results demonstrate\nthat our proposed optimal policy significantly outperforms baseline approaches\nin managing the accuracy-timeliness trade-off.","main_category":"cs.IT","categories":"cs.IT,cs.NI,math.IT","published":"2025-04-10T03:48:09Z"}
{"aid":"http://arxiv.org/abs/2504.07450v1","title":"Synthetic CT Generation from Time-of-Flight Non-Attenutaion-Corrected\n  PET for Whole-Body PET Attenuation Correction","summary":"Positron Emission Tomography (PET) imaging requires accurate attenuation\ncorrection (AC) to account for photon loss due to tissue density variations. In\nPET/MR systems, computed tomography (CT), which offers a straightforward\nestimation of AC is not available. This study presents a deep learning approach\nto generate synthetic CT (sCT) images directly from Time-of-Flight (TOF)\nnon-attenuation corrected (NAC) PET images, enhancing AC for PET/MR. We first\nevaluated models pre-trained on large-scale natural image datasets for a\nCT-to-CT reconstruction task, finding that the pre-trained model outperformed\nthose trained solely on medical datasets. The pre-trained model was then\nfine-tuned using an institutional dataset of 35 TOF NAC PET and CT volume\npairs, achieving the lowest mean absolute error (MAE) of 74.49 HU and highest\npeak signal-to-noise ratio (PSNR) of 28.66 dB within the body contour region.\nVisual assessments demonstrated improved reconstruction of both bone and soft\ntissue structures from TOF NAC PET images. This work highlights the\neffectiveness of using pre-trained deep learning models for medical image\ntranslation tasks. Future work will assess the impact of sCT on PET attenuation\ncorrection and explore additional neural network architectures and datasets to\nfurther enhance performance and practical applications in PET imaging.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-10T04:49:41Z"}
{"aid":"http://arxiv.org/abs/2504.07455v1","title":"Explicit Morphisms in the Galois-Tukey Category","summary":"If the Continuum Hypothesis is false, it implies the existence of\ncardinalities between the integers and the real numbers. In studying these\n\"cardinal characteristics of the continuum\", it was discovered that many of the\nassociated inequalities can be interpreted as morphisms within the\n\"Galois-Tukey\" category. This thesis aims to reformulate traditional direct\nproofs of cardinal characteristic inequalities by making the underlying\nmorphisms explicit. New, purely categorical results are also discussed.","main_category":"math.LO","categories":"math.LO","published":"2025-04-10T05:00:16Z"}
{"aid":"http://arxiv.org/abs/2504.07482v1","title":"Tame categorical local Langlands correspondence","summary":"In one of our previous articles, we outlined the formulation of a version of\nthe categorical arithmetic local Langlands conjecture. The aims of this article\nare threefold. First, we provide a detailed account of one component of this\nconjecture: the local Langlands category. Second, we aim to prove this\nconjecture in the tame case for quasi-split unramified reductive groups.\nFinally, we will explore the first applications of such categorical\nequivalence.","main_category":"math.RT","categories":"math.RT,math.AG","published":"2025-04-10T06:24:41Z"}
{"aid":"http://arxiv.org/abs/2504.07500v1","title":"Energy-Efficient UAV Replacement in Software-Defined UAV Networks","summary":"Unmanned Aerial Vehicles (UAVs) in networked environments face significant\nchallenges due to energy constraints and limited battery life, which\nnecessitate periodic replacements to maintain continuous operation. Efficiently\nmanaging the handover of data flows during these replacements is crucial to\navoid disruptions in communication and to optimize energy consumption. This\npaper addresses the complex issue of energy-efficient UAV replacement in\nsoftware-defined UAV network. We introduce a novel approach based on\nestablishing a strict total ordering relation for UAVs and data flows, allowing\nus to formulate the problem as an integer linear program. By utilizing the\nGurobi solver, we obtain optimal handover schedules for the tested problem\ninstances. Additionally, we propose a heuristic algorithm that significantly\nreduces computational complexity while maintaining near-optimal performance.\nThrough comprehensive simulations, we demonstrate that our heuristic offers\npractical and scalable solution, ensuring energy-efficient UAV replacement\nwhile minimizing network disruptions. Our results suggest that the proposed\napproach can enhance UAV battery life and improve overall network reliability\nin real-world applications.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T06:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.07501v1","title":"Distance signless Laplacian spectral radius and tough graphs involving\n  minimun degree","summary":"Let $G=(V(G),E(G))$ be a simple graph, where $V(G)$ and $E(G)$ are the vertex\nset and the edge set of $G$, respectively. The number of components of $G$ is\ndenoted by $c(G)$. Let $t$ be a positive real number, and a connected graph $G$\nis $t$-tough if $t c(G-S)\\leq|S|$ for every vertex cut $S$ of $V(G)$. The\ntoughness of graph $G$, denoted by $\\tau(G)$, is the largest value of $t$ for\nwhich $G$ is $t$-tough. Recently, Fan, Lin and Lu [European J. Combin.\n110(2023), 103701] presented sufficient conditions based on the spectral radius\nfor graphs to be 1-tough with minimum degree $\\delta(G)$ and graphs to be\n$t$-tough with $t\\geq 1$ being an integer, respectively. In this paper, we\nestablish sufficient conditions in terms of the distance signless Laplacian\nspectral radius for graphs to be 1-tough with minimum degree $\\delta(G)$ and\ngraphs to be $t$-tough, where $\\frac{1}{t}$ is a positive integer. Moreover, we\nconsider the relationship between the distance signless Laplacian spectral\nradius and $t$-tough graphs in terms of the order $n$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T07:01:52Z"}
{"aid":"http://arxiv.org/abs/2504.07516v1","title":"Enhancements for Developing a Comprehensive AI Fairness Assessment\n  Standard","summary":"As AI systems increasingly influence critical sectors like\ntelecommunications, finance, healthcare, and public services, ensuring fairness\nin decision-making is essential to prevent biased or unjust outcomes that\ndisproportionately affect vulnerable entities or result in adverse impacts.\nThis need is particularly pressing as the industry approaches the 6G era, where\nAI will drive complex functions like autonomous network management and\nhyper-personalized services. The TEC Standard for Fairness Assessment and\nRating of AI Systems provides guidelines for evaluating fairness in AI,\nfocusing primarily on tabular data and supervised learning models. However, as\nAI applications diversify, this standard requires enhancement to strengthen its\nimpact and broaden its applicability. This paper proposes an expansion of the\nTEC Standard to include fairness assessments for images, unstructured text, and\ngenerative AI, including large language models, ensuring a more comprehensive\napproach that keeps pace with evolving AI technologies. By incorporating these\ndimensions, the enhanced framework will promote responsible and trustworthy AI\ndeployment across various sectors.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-04-10T07:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.07523v1","title":"Lifetime-limited Gigahertz-frequency Mechanical Oscillators with\n  Millisecond Coherence Times","summary":"High-frequency mechanical oscillators with long coherence times are essential\nto realizing a variety of high-fidelity quantum sensors, transducers, and\nmemories. However, the unprecedented coherence times needed for quantum\napplications require exquisitely sensitive new techniques to probe the material\norigins of phonon decoherence and new strategies to mitigate decoherence in\nmechanical oscillators. Here, we combine non-invasive laser spectroscopy\ntechniques with materials analysis to identify key sources of phonon\ndecoherence in crystalline media. Using micro-fabricated high-overtone bulk\nacoustic-wave resonators ($\\mu$HBARs) as an experimental testbed, we identify\nphonon-surface interactions as the dominant source of phonon decoherence in\ncrystalline quartz; lattice distortion, subsurface damage, and high\nconcentration of elemental impurities near the crystal surface are identified\nas the likely causes. Removal of this compromised surface layer using an\noptimized polishing process is seen to greatly enhance coherence times,\nenabling $\\mu$HBARs with Q-factors of > 240 million at 12 GHz frequencies,\ncorresponding to > 6 ms phonon coherence times and record-level f-Q products.\nComplementary phonon linewidth and time-domain ringdown measurements, performed\nusing a new Brillouin-based pump-probe spectroscopy technique, reveal\nnegligible dephasing within these oscillators. Building on these results, we\nidentify a path to > 100 ms coherence times as the basis for high-frequency\nquantum memories. These findings clearly demonstrate that, with enhanced\ncontrol over surfaces, dissipation and noise can be significantly reduced in a\nwide range of quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci","published":"2025-04-10T07:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.07538v1","title":"A 950 MHz SIMT Soft Processor","summary":"Although modern FPGAs have a performance potential of a 1 GHz clock frequency\n- with both clock networks and embedded blocks such as memories and DSP Blocks\ncapable of these clock rates - user implementations approaching this speed are\nrarely realized in practice. This is especially true of complex designs such as\nsoft processors.\n  In this work we implement a soft GPGPU which exceeds 950 MHz in an Altera\nAgilex-7 FPGA. The architecture is a 32-bit fixed point Single Instruction,\nMultiple Thread (SIMT) design, with parameterized thread and register spaces.\nUp to 4096 threads and 64K registers can be specified by the user. In one\nexample, a processor with 16K registers and a 16KB shared memory required\napproximately 7K ALMs, 99 M20K memories, and 32 DSP Blocks.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T08:05:36Z"}
{"aid":"http://arxiv.org/abs/2504.07540v1","title":"PoGO: A Scalable Proof of Useful Work via Quantized Gradient Descent and\n  Merkle Proofs","summary":"We present a design called \\emph{Proof of Gradient Optimization} (PoGO) for\nblockchain consensus, where miners produce verifiable evidence of training\nlarge-scale machine-learning models. Building on previous work, we incorporate\n\\emph{quantized gradients} (4-bit precision) to reduce storage and computation\nrequirements, while still preserving the ability of verifiers to check that\nreal progress has been made on lowering the model's loss. Additionally, we\nemploy Merkle proofs over the full 32-bit model to handle large parameter sets\nand to enable random leaf checks with minimal on-chain data. We illustrate\nthese ideas using GPT-3 (175B parameters) as a reference example and also refer\nto smaller but high-performance models (e.g., \\emph{Gemma~3} with 27B\nparameters). We provide an empirical cost analysis showing that verification is\nsignificantly cheaper than training, thanks in part to quantization and\nsampling. We also discuss the necessity of longer block times (potentially\nhours) when incorporating meaningful training steps, the trade-offs when using\nspecialized GPU hardware, and how binary diffs may incrementally optimize\nupdates. Finally, we note that fine-tuning can be handled in a similar manner,\nmerely changing the dataset and the manner of sampling but preserving the\noverall verification flow. Our protocol allows verifiers to issue either\n\\emph{positive} or \\emph{negative} attestations; these are aggregated at\nfinalization to either confirm the update or slash the miner.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T08:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07541v1","title":"On the initial ideal of a generic artinian Gorenstein algebra","summary":"In this note we show that the initial ideal of the annihilator ideal of a\ngeneric form is generated by the largest possible monomials in each degree. We\nalso show that the initial ideal with respect to the degree reverse\nlexicographical ordering of the annihilator ideal of the complete symmetric\nform has this property, by determining a minimal Gr\\\"obner basis of it.\nMoreover, we determine the total Betti numbers for a class of strongly stable\nmonomial ideals and show that these numbers agree with those for the degree\nreverse lexicographical initial ideals of the ideal generated by a sufficiently\nlarge number of generic forms, and of the annihilator ideal of a generic form.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:10:14Z"}
{"aid":"http://arxiv.org/abs/2504.07551v1","title":"Topology optimization of decoupling feeding networks for antenna arrays","summary":"Near-field and radiation coupling between nearby radiating elements is\nunavoidable, and it is considered a limiting factor for applications in\nwireless communications and active sensing. This article proposes a\ndensity-based topology optimization approach to design decoupling networks for\nsuch systems. The decoupling networks are designed based on a multi-objective\noptimization problem with the radiating elements replaced by their time-domain\nimpulse response for efficient computations and to enable the solution of the\ndesign problem using gradient-based optimization methods. We use the\nadjoint-field method to compute the gradients of the optimization objectives.\nAdditionally, nonlinear filters are applied during the optimization procedure\nto impose minimum-size control on the optimized designs. We demonstrate the\nconcept by designing the decoupling network for a two-element planar antenna\narray; the antenna is designed in a separate optimization problem. The\noptimized decoupling networks provide a signal path that destructively\ninterferes with the coupling between the radiating elements while preserving\ntheir individual matching to the feeding ports. Compact decoupling networks\ncapable of suppressing the mutual coupling by more than 10 dB between two\nclosely separated planar antennas operating around 2.45 GHz are presented and\nvalidated experimentally.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T08:27:04Z"}
{"aid":"http://arxiv.org/abs/2504.07561v1","title":"Regular Black Hole Models in the Transition from Baryonic Matter to\n  Quark Matter","summary":"In this paper, we investigate gravitational collapse scenarios involving\nbaryonic matter transitioning into quark-gluon plasma under extreme\nastrophysical conditions, focusing on their implications for the formation of\nregular black holes. Standard gravitational collapse models inevitably predict\ncentral singularities, highlighting the limitations of classical general\nrelativity in extreme density regimes. By introducing a physically motivated,\ninhomogeneous transition rate between baryonic and quark matter, we demonstrate\nanalytically and numerically that it is possible to construct regular black\nhole solutions featuring a nonsingular de Sitter-like core. We further analyze\nthe observable consequences of these models, particularly emphasizing\nmodifications to the black hole shadow radius, which provide direct\nobservational constraints accessible through Event Horizon Telescope (EHT)\nmeasurements.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T08:46:40Z"}
{"aid":"http://arxiv.org/abs/2504.07570v1","title":"Exploring Human-Like Thinking in Search Simulations with Large Language\n  Models","summary":"Simulating user search behavior is a critical task in information retrieval,\nwhich can be employed for user behavior modeling, data augmentation, and system\nevaluation. Recent advancements in large language models (LLMs) have opened up\nnew possibilities for generating human-like actions including querying,\nbrowsing, and clicking. In this work, we explore the integration of human-like\nthinking into search simulations by leveraging LLMs to simulate users' hidden\ncognitive processes. Specifically, given a search task and context, we prompt\nLLMs to first think like a human before executing the corresponding action. As\nexisting search datasets do not include users' thought processes, we conducted\na user study to collect a new dataset enriched with users' explicit thinking.\nWe investigate the impact of incorporating such human-like thinking on\nsimulation performance and apply supervised fine-tuning (SFT) to teach LLMs to\nemulate both human thinking and actions. Our experiments span two dimensions in\nleveraging LLMs for user simulation: (1) with or without explicit thinking, and\n(2) with or without fine-tuning on the thinking-augmented dataset. The results\ndemonstrate the feasibility and potential of incorporating human-like thinking\nin user simulations, though performance improvements on some metrics remain\nmodest. We believe this exploration provides new avenues and inspirations for\nadvancing user behavior modeling in search simulations.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:04:58Z"}
{"aid":"http://arxiv.org/abs/2504.07579v1","title":"Controlling Complex Systems","summary":"This chapter provides a comprehensive overview of controlling collective\nbehavior in complex systems comprising large ensembles of interacting dynamical\nagents. Building upon traditional control theory's foundation in individual\nsystems, we introduce tools designed to address the unique challenges of\ncoordinating networks that exhibit emergent phenomena, including consensus,\nsynchronization, and pattern formation. We analyze how local agent interactions\ngenerate macroscopic behaviors and investigate the fundamental role of network\ntopology in determining system dynamics. Inspired by natural systems, we\nemphasize control strategies that achieve global coordination through localized\ninterventions while considering practical implementation challenges. The\nchapter concludes by presenting novel frameworks for managing very large agent\nensembles and leveraging interacting networks for control purposes.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-10T09:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.07610v1","title":"What Contributes to Affective Polarization in Networked Online\n  Environments? Evidence from an Agent-Based Model","summary":"Affective polarization, or, inter-party hostility, is increasingly recognized\nas a pervasive issue in democracies worldwide, posing a threat to social\ncohesion. The digital media ecosystem, now widely accessible and ever-present,\nhas often been implicated in accelerating this phenomenon. However, the precise\ncausal mechanisms responsible for driving affective polarization have been a\nsubject of extensive debate. While the concept of echo chambers, characterized\nby individuals ensconced within like-minded groups, bereft of\ncounter-attitudinal content, has long been the prevailing hypothesis,\naccumulating empirical evidence suggests a more nuanced picture. This study\naims to contribute to the ongoing debate by employing an agent-based model to\nillustrate how affective polarization is either fostered or hindered by\nindividual news consumption and dissemination patterns based on ideological\nalignment. To achieve this, we parameterize three key aspects: (1) The\naffective asymmetry of individuals' engagement with in-party versus out-party\ncontent, (2) The proportion of in-party members within one's social\nneighborhood, and (3) The degree of partisan bias among the elites within the\npopulation. Subsequently, we observe macro-level changes in affective\npolarization within the population under various conditions stipulated by these\nparameters. This approach allows us to explore the intricate dynamics of\naffective polarization within digital environments, shedding light on the\ninterplay between individual behaviors, social networks, and information\nexposure.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T10:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.07614v1","title":"Enhanced THz emission from spintronic emitters with Pt-Al alloys","summary":"Platinum (Pt) is the element with the largest spin Hall conductivity and is\nknown as the most efficient spin-to-charge conversion material in spintronic\nTHz emitters. By alloying with aluminum (Al), its resistivity can be\nsubstantially increased, exceeding $100\\,\\mu\\Omega$cm. While the spin Hall\nconductivity is reduced by alloying, the relative resistivity increase\nsurpasses the reduction of spin Hall conductivity and thereby enhances the spin\nHall angle. We make use of this mechanism to improve the commonly used Pt-based\nspintronic THz emitter and demonstrate that an increase of 67% in the THz\nemission amplitude can be achieved between 20\\% and 30\\% Al in Pt. We show that\nthe enhanced THz emission amplitude is driven by the enhanced multilayer\nimpedance due to the larger resistivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T10:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.07620v1","title":"Equivariant recollements and singular equivalences","summary":"In this paper we investigate equivariant recollements of abelian (resp.\ntriangulated) categories. We first characterize when a recollement of abelian\n(resp. triangulated) categories induces an equivariant recollement, i.e. a\nrecollement between the corresponding equivariant abelian (resp. triangulated)\ncategories. We further investigate singular equivalences in the context of\nequivariant abelian recollements. In particular, we characterize when a\nsingular equivalence induced by the quotient functor in an abelian recollement\nlift to a singular equivalence induced by the equivariant quotient functor. As\napplications of our results: (i) we construct equivariant recollements for the\nderived category of a quasi-compact, quasi-separated scheme where the action is\ncoming from a subgroup of the automorphism group of the scheme and (ii) we\nderive new singular equivalences between certain skew group algebras.","main_category":"math.RT","categories":"math.RT,math.AG,math.CT,math.RA","published":"2025-04-10T10:08:23Z"}
{"aid":"http://arxiv.org/abs/2504.07632v1","title":"A Stochastic Ekman-Stokes Model for Coupled Ocean-Atmosphere-Wave\n  Dynamics","summary":"Accurate representation of atmosphere-ocean boundary layers, including the\ninterplay of turbulence, surface waves, and air-sea fluxes, remains a challenge\nin geophysical fluid dynamics, particularly for climate simulations. This study\nintroduces a stochastic coupled Ekman-Stokes model (SCESM) developed within the\nphysically consistent Location Uncertainty framework, explicitly incorporating\nrandom turbulent fluctuations and surface wave effects. The SCESM integrates\nestablished parameterizations for air-sea fluxes, turbulent viscosity, and\nStokes drift, and its performance is rigorously assessed through ensemble\nsimulations against LOTUS observational data. A performance ranking analysis\nquantifies the impact of different model components, highlighting the critical\nrole of explicit uncertainty representation in both oceanic and atmospheric\ndynamics for accurately capturing system variability. Wave-induced mixing terms\nimprove model performance, while wave-dependent surface roughness enhances\nair-sea fluxes but reduces the relative influence of wave-driven mixing. This\nfully coupled stochastic framework provides a foundation for advancing boundary\nlayer parameterizations in large-scale climate models.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-10T10:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.07634v1","title":"Agent That Debugs: Dynamic State-Guided Vulnerability Repair","summary":"In recent years, more vulnerabilities have been discovered every day, while\nmanual vulnerability repair requires specialized knowledge and is\ntime-consuming. As a result, many detected or even published vulnerabilities\nremain unpatched, thereby increasing the exposure of software systems to\nattacks. Recent advancements in agents based on Large Language Models have\ndemonstrated their increasing capabilities in code understanding and\ngeneration, which can be promising to achieve automated vulnerability repair.\nHowever, the effectiveness of agents based on static information retrieval is\nstill not sufficient for patch generation. To address the challenge, we propose\na program repair agent called VulDebugger that fully utilizes both static and\ndynamic context, and it debugs programs in a manner akin to humans. The agent\ninspects the actual state of the program via the debugger and infers expected\nstates via constraints that need to be satisfied. By continuously comparing the\nactual state with the expected state, it deeply understands the root causes of\nthe vulnerabilities and ultimately accomplishes repairs. We experimentally\nevaluated VulDebugger on 50 real-life projects. With 60.00% successfully fixed,\nVulDebugger significantly outperforms state-of-the-art approaches for\nvulnerability repair.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T10:31:10Z"}
{"aid":"http://arxiv.org/abs/2504.07638v1","title":"Predicting the Lifespan of Industrial Printheads with Survival Analysis","summary":"Accurately predicting the lifespan of critical device components is essential\nfor maintenance planning and production optimization, making it a topic of\nsignificant interest in both academia and industry. In this work, we\ninvestigate the use of survival analysis for predicting the lifespan of\nproduction printheads developed by Canon Production Printing. Specifically, we\nfocus on the application of five techniques to estimate survival probabilities\nand failure rates: the Kaplan-Meier estimator, Cox proportional hazard model,\nWeibull accelerated failure time model, random survival forest, and gradient\nboosting. The resulting estimates are further refined using isotonic regression\nand subsequently aggregated to determine the expected number of failures. The\npredictions are then validated against real-world ground truth data across\nmultiple time windows to assess model reliability. Our quantitative evaluation\nusing three performance metrics demonstrates that survival analysis outperforms\nindustry-standard baseline methods for printhead lifespan prediction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T10:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.07643v1","title":"CollEX -- A Multimodal Agentic RAG System Enabling Interactive\n  Exploration of Scientific Collections","summary":"In this paper, we introduce CollEx, an innovative multimodal agentic\nRetrieval-Augmented Generation (RAG) system designed to enhance interactive\nexploration of extensive scientific collections. Given the overwhelming volume\nand inherent complexity of scientific collections, conventional search systems\noften lack necessary intuitiveness and interactivity, presenting substantial\nbarriers for learners, educators, and researchers. CollEx addresses these\nlimitations by employing state-of-the-art Large Vision-Language Models (LVLMs)\nas multimodal agents accessible through an intuitive chat interface. By\nabstracting complex interactions via specialized agents equipped with advanced\ntools, CollEx facilitates curiosity-driven exploration, significantly\nsimplifying access to diverse scientific collections and records therein. Our\nsystem integrates textual and visual modalities, supporting educational\nscenarios that are helpful for teachers, pupils, students, and researchers by\nfostering independent exploration as well as scientific excitement and\ncuriosity. Furthermore, CollEx serves the research community by discovering\ninterdisciplinary connections and complementing visual data. We illustrate the\neffectiveness of our system through a proof-of-concept application containing\nover 64,000 unique records across 32 collections from a local scientific\ncollection from a public university.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.CV","published":"2025-04-10T10:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07653v1","title":"Optimum design of permeable diffractive lenses based on photon sieves","summary":"Photon sieves are permeable diffractive optical elements generated by open\napertures on a substrate. These elements are well suited for the monitoring of\nrunning fluids. Our analysis considers the fabrication constrains of the photon\nsieve and translate them into values of the optical parameters of the element.\nWhen used as focusing elements, or diffractive lenses, the spatial distribution\nof apertures can be designed to maximize the intensity at the focal plane and\nthe permeability of the device. This is done by defining a weighted merit\nfunction. The computation time of this merit function is key when applying\ndifferent strategies for the design, which often require a very large number of\ncalculations of this merit function. Then, besides using a reliable propagation\nmethod, we have included an analytic solution applicable for circular\napertures. Also, a geometrical merit function is proposed to simplify and\nreduce the computation even more. The methods proposed in this contribution are\ncompared in terms of the focused irradiance and permeability parameters,\nallowing an educated choice adapted to the given case or application. In this\ncontribution we analyze several methods to generate photon sieves in an optimum\nmanner. The resulted spatial distributions resemble the classical Fresnel zone\narrangement.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T11:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.07664v1","title":"Data Requirement Goal Modeling for Machine Learning Systems","summary":"Machine Learning (ML) has been integrated into various software and systems.\nTwo main components are essential for training an ML model: the training data\nand the ML algorithm. Given the critical role of data in ML system development,\nit has become increasingly important to assess the quality of data attributes\nand ensure that the data meets specific requirements before its utilization.\nThis work proposes an approach to guide non-experts in identifying data\nrequirements for ML systems using goal modeling. In this approach, we first\ndevelop the Data Requirement Goal Model (DRGM) by surveying the white\nliterature to identify and categorize the issues and challenges faced by data\nscientists and requirement engineers working on ML-related projects. An initial\nDRGM was built to accommodate common tasks that would generalize across\nprojects. Then, based on insights from both white and gray literature, a\ncustomization mechanism is built to help adjust the tasks, KPIs, and goals'\nimportance of different elements within the DRGM. The generated model can aid\nits users in evaluating different datasets using GRL evaluation strategies. We\nthen validate the approach through two illustrative examples based on\nreal-world projects. The results from the illustrative examples demonstrate\nthat the data requirements identified by the proposed approach align with the\nrequirements of real-world projects, demonstrating the practicality and\neffectiveness of the proposed framework. The proposed dataset selection\ncustomization mechanism and the proposed DRGM are helpful in guiding\nnon-experts in identifying the data requirements for machine learning systems\ntailored to a specific ML problem. This approach also aids in evaluating\ndifferent dataset alternatives to choose the optimum dataset for the problem.\nFor future work, we recommend implementing tool support to generate the DRGM\nbased on a chatbot interface.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-10T11:30:25Z"}
{"aid":"http://arxiv.org/abs/2504.07666v1","title":"On a fuzzy Landau Equation: Part I. A variational approach","summary":"This article is the first in a series of works on the fuzzy Landau equation,\nwhere particles interact through delocalised Coulomb collisions. Here, we\nestablish a variational characterisation that recasts the fuzzy Landau equation\nwithin the framework of GENERIC systems (General Equations for Non-Equilibrium\nReversible-Irreversible Coupling).","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T11:39:35Z"}
{"aid":"http://arxiv.org/abs/2504.07693v1","title":"Molecular nature of hidden-charm pentaquark states $P_{c\\bar{c}s}$ with\n  strangeness $S=-1$","summary":"We investigate the hidden-charm pentaquark states with strangeness $S=-1$\n($P_{c\\bar{c}s}$) within an off-shell coupled-channel approach based on\neffective Lagrangians that respect heavy-quark spin symmetry, SU(3) flavor\nsymmetry, and hidden local symmetry. All relevant meson-baryon two-body\nchannels composed of low-lying anti-charmed mesons and singly-charmed baryons\nwith $S=-1$, as well as the $J/\\psi \\Lambda$ channel, are included. We find a\ntotal of eleven negative-parity states and three positive-parity states. AMong\nthe negative-parity states, the $P_{c\\bar{c}s}(4338)$ and $P_{c\\bar{c}s}(4459)$\ncan be naturally interpreted as $\\bar{D} \\Xi_c$ and $\\bar{D}^* \\Xi_c$ molecular\nstates, respectively. We identify a second state, $P_{c\\bar{c}s}(4472)$,\nlocated close to the $P_{c\\bar{c}s}(4459)$ but with different spin and width,\nwhich may correspond to the structure observed by the Belle Collaboration. Both\nstates are generated from the $\\bar{D}^* \\Xi_c$ channel and can be interpreted\nas spin partners. Their properties are consistent with recent experimental\nobservations, providing strong support for the molecular interpretation of the\n$P_{c\\bar{c}s}$ states. We also observe a two-pole structure near the\n$\\bar{D}_s^* \\Lambda_c$ and $\\bar{D}^* \\Xi_c'$ channel depending on\nspin-parity.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-10T12:26:39Z"}
{"aid":"http://arxiv.org/abs/2504.07711v1","title":"Merging Embedded Topics with Optimal Transport for Online Topic Modeling\n  on Data Streams","summary":"Topic modeling is a key component in unsupervised learning, employed to\nidentify topics within a corpus of textual data. The rapid growth of social\nmedia generates an ever-growing volume of textual data daily, making online\ntopic modeling methods essential for managing these data streams that\ncontinuously arrive over time. This paper introduces a novel approach to online\ntopic modeling named StreamETM. This approach builds on the Embedded Topic\nModel (ETM) to handle data streams by merging models learned on consecutive\npartial document batches using unbalanced optimal transport. Additionally, an\nonline change point detection algorithm is employed to identify shifts in\ntopics over time, enabling the identification of significant changes in the\ndynamics of text streams. Numerical experiments on simulated and real-world\ndata show StreamETM outperforming competitors.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T13:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.07717v1","title":"PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented\n  Generation in Large Language Models via Bilevel Optimization","summary":"Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of applications, e.g., medical question-answering, mathematical\nsciences, and code generation. However, they also exhibit inherent limitations,\nsuch as outdated knowledge and susceptibility to hallucinations.\nRetrieval-Augmented Generation (RAG) has emerged as a promising paradigm to\naddress these issues, but it also introduces new vulnerabilities. Recent\nefforts have focused on the security of RAG-based LLMs, yet existing attack\nmethods face three critical challenges: (1) their effectiveness declines\nsharply when only a limited number of poisoned texts can be injected into the\nknowledge database, (2) they lack sufficient stealth, as the attacks are often\ndetectable by anomaly detection systems, which compromises their effectiveness,\nand (3) they rely on heuristic approaches to generate poisoned texts, lacking\nformal optimization frameworks and theoretic guarantees, which limits their\neffectiveness and applicability. To address these issues, we propose\ncoordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack\nthat introduces a small number of poisoned texts into the knowledge database\nwhile embedding a backdoor trigger within the prompt. When activated, the\ntrigger causes the LLM to generate pre-designed responses to targeted queries,\nwhile maintaining normal behavior in other contexts. This ensures both high\neffectiveness and stealth. We formulate the attack generation process as a\nbilevel optimization problem leveraging a principled optimization framework to\ndevelop optimal poisoned texts and triggers. Extensive experiments across\ndiverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving\na high attack success rate even with a limited number of poisoned texts and\nsignificantly improved stealth compared to existing methods.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-10T13:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.07718v1","title":"Multi-modal Reference Learning for Fine-grained Text-to-Image Retrieval","summary":"Fine-grained text-to-image retrieval aims to retrieve a fine-grained target\nimage with a given text query. Existing methods typically assume that each\ntraining image is accurately depicted by its textual descriptions. However,\ntextual descriptions can be ambiguous and fail to depict discriminative visual\ndetails in images, leading to inaccurate representation learning. To alleviate\nthe effects of text ambiguity, we propose a Multi-Modal Reference learning\nframework to learn robust representations. We first propose a multi-modal\nreference construction module to aggregate all visual and textual details of\nthe same object into a comprehensive multi-modal reference. The multi-modal\nreference hence facilitates the subsequent representation learning and\nretrieval similarity computation. Specifically, a reference-guided\nrepresentation learning module is proposed to use multi-modal references to\nlearn more accurate visual and textual representations. Additionally, we\nintroduce a reference-based refinement method that employs the object\nreferences to compute a reference-based similarity that refines the initial\nretrieval results. Extensive experiments are conducted on five fine-grained\ntext-to-image retrieval datasets for different text-to-image retrieval tasks.\nThe proposed method has achieved superior performance over state-of-the-art\nmethods. For instance, on the text-to-person image retrieval dataset RSTPReid,\nour method achieves the Rank1 accuracy of 56.2\\%, surpassing the recent CFine\nby 5.6\\%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T13:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.07728v1","title":"The Scaling Behaviors in Achieving High Reliability via\n  Chance-Constrained Optimization","summary":"We study the problem of resource provisioning under stringent reliability or\nservice level requirements, which arise in applications such as power\ndistribution, emergency response, cloud server provisioning, and regulatory\nrisk management. With chance-constrained optimization serving as a natural\nstarting point for modeling this class of problems, our primary contribution is\nto characterize how the optimal costs and decisions scale for a generic joint\nchance-constrained model as the target probability of satisfying the\nservice/reliability constraints approaches its maximal level. Beyond providing\ninsights into the behavior of optimal solutions, our scaling framework has\nthree key algorithmic implications. First, in distributionally robust\noptimization (DRO) modeling of chance constraints, we show that widely used\napproaches based on KL-divergences, Wasserstein distances, and moments heavily\ndistort the scaling properties of optimal decisions, leading to exponentially\nhigher costs. In contrast, incorporating marginal distributions or using\nappropriately chosen f-divergence balls preserves the correct scaling, ensuring\ndecisions remain conservative by at most a constant or logarithmic factor.\nSecond, we leverage the scaling framework to quantify the conservativeness of\ncommon inner approximations and propose a simple line search to refine their\nsolutions, yielding near-optimal decisions. Finally, given N data samples, we\ndemonstrate how the scaling framework enables the estimation of approximately\nPareto-optimal decisions with constraint violation probabilities significantly\nsmaller than the Omega(1/N)-barrier that arises in the absence of parametric\nassumptions","main_category":"math.OC","categories":"math.OC,math.PR,q-fin.RM","published":"2025-04-10T13:21:49Z"}
{"aid":"http://arxiv.org/abs/2504.07768v1","title":"Weighted special cycles on Rapoport--Zink spaces with almost self-dual\n  level","summary":"We introduce a ``vector valued'' version of special cycles on GSpin\nRapoport--Zink spaces with almost self-dual level in the context of the Kudla\nprogram, with certain linear invariance and local modularity features. They are\nlocal analogs of special cycles on GSpin Shimura varieties with almost\nself-dual parahoric level (e.g. Siegel threefolds with paramodular level). We\nestablish local arithmetic Siegel--Weil formulas relating arithmetic\nintersection numbers of these special cycles and derivatives of certain local\nWhittaker functions in any dimension. The proof is based on a reduction formula\nfor cyclic quadratic lattices.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T14:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.07784v1","title":"The row left rank of quaternion unit gain graphs in terms of pendant\n  vertices","summary":"Let $\\widetilde{G}=(G,U(\\mathbb{Q}),\\varphi)$ be a quaternion unit gain graph\n(or $U(\\mathbb{Q})$-gain graph), where $G$ is the underlying graph of\n$\\widetilde{G}$, $U(\\mathbb{Q})=\\{q\\in \\mathbb{Q}: |q|=1\\}$ and\n$\\varphi:\\overrightarrow{E}\\rightarrow U(\\mathbb{Q})$ is the gain function such\nthat $\\varphi(e_{ij})=\\varphi(e_{ji})^{-1}=\\overline{\\varphi(e_{ji})}$ for any\nadjacent vertices $v_{i}$ and $v_{j}$. Let $A(\\widetilde{G})$ be the adjacency\nmatrix of $\\widetilde{G}$ and let $r(\\widetilde{G})$ be the row left rank of\n$\\widetilde{G}$. In this paper, we prove some lower bounds on the row left rank\nof $U(\\mathbb{Q})$-gain graphs in terms of pendant vertices. All corresponding\nextremal graphs are characterized.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T14:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.07800v1","title":"A Systematic Approach to Hyperbolic Quantum Error Correction Codes","summary":"Hyperbolic quantum error correction codes (HQECCs) leverage the unique\ngeometric properties of hyperbolic space to enhance the capabilities and\nperformance of quantum error correction. By embedding qubits in hyperbolic\nlattices, HQECCs achieve higher encoding rates and improved error thresholds\ncompared to conventional Euclidean codes. Building on recent advances in\nhyperbolic crystallography, we present a systematic framework for constructing\nHQECCs. As a key component of this framework, we develop a novel algorithm for\ncomputing all plaquette cycles and logical operators associated with a given\nHQECC. To demonstrate the effectiveness of this approach, we utilize this\nframework to simulate two HQECCs based respectively on two relevant examples of\nhyperbolic tilings. In the process, we evaluate key code parameters such as\nencoding rate, error threshold, and code distance for different sub-lattices.\nThis work establishes a solid foundation for a systematic and comprehensive\nanalysis of HQECCs, paving the way for the practical implementation of HQECCs\nin the pursuit of robust quantum error correction strategies.","main_category":"quant-ph","categories":"quant-ph,cs.DS,math.AG,math.DG,math.GR","published":"2025-04-10T14:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.07803v1","title":"A System for Comprehensive Assessment of RAG Frameworks","summary":"Retrieval Augmented Generation (RAG) has emerged as a standard paradigm for\nenhancing the factual accuracy and contextual relevance of Large Language\nModels (LLMs) by integrating retrieval mechanisms. However, existing evaluation\nframeworks fail to provide a holistic black-box approach to assessing RAG\nsystems, especially in real-world deployment scenarios. To address this gap, we\nintroduce SCARF (System for Comprehensive Assessment of RAG Frameworks), a\nmodular and flexible evaluation framework designed to benchmark deployed RAG\napplications systematically. SCARF provides an end-to-end, black-box evaluation\nmethodology, enabling a limited-effort comparison across diverse RAG\nframeworks. Our framework supports multiple deployment configurations and\nfacilitates automated testing across vector databases and LLM serving\nstrategies, producing a detailed performance report. Moreover, SCARF integrates\npractical considerations such as response coherence, providing a scalable and\nadaptable solution for researchers and industry professionals evaluating RAG\napplications. Using the REST APIs interface, we demonstrate how SCARF can be\napplied to real-world scenarios, showcasing its flexibility in assessing\ndifferent RAG frameworks and configurations. SCARF is available at GitHub\nrepository.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-10T14:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.07819v1","title":"Testing Leptogenesis from Observable Gravitational Waves","summary":"Leptogenesis provides an elegant mechanism to explain the observed baryon\nasymmetry of the Universe (BAU), yet its experimental verification remains\nchallenging due to requirements of either extremely heavy right-handed\nneutrinos or precisely fine-tuned mass splittings. We adapt a solution by\nintroducing an extra scalar field that significantly enhances $CP$ asymmetry\nthrough loop-level contributions. This scalar extension not only facilitates\nsuccessful leptogenesis but also enables a strong first-order electroweak phase\ntransition, generating potentially observable gravitational waves (GWs). We\ndemonstrate a strong correlation between the generated BAU and the GW signal\nstrength, establishing a unique way to test the leptogenesis. We show that when\nthe model achieves a successful BAU, the resulting GW signal from EWPT can have\nsignal-to-noise ratio of $\\mathcal{O}(10^3)$ and $\\mathcal{O}(10^6)$ at the\nupcoming LISA and DECIGO experiments, respectively. This work presents a\nconcrete connection between successful leptogenesis and detectable GWs,\noffering a promising method for experimental testing of the leptogenesis\nmechanism through future GW observations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-10T14:57:22Z"}
{"aid":"http://arxiv.org/abs/2504.07827v1","title":"HarmonySeg: Tubular Structure Segmentation with Deep-Shallow Feature\n  Fusion and Growth-Suppression Balanced Loss","summary":"Accurate segmentation of tubular structures in medical images, such as\nvessels and airway trees, is crucial for computer-aided diagnosis,\nradiotherapy, and surgical planning. However, significant challenges exist in\nalgorithm design when faced with diverse sizes, complex topologies, and (often)\nincomplete data annotation of these structures. We address these difficulties\nby proposing a new tubular structure segmentation framework named HarmonySeg.\nFirst, we design a deep-to-shallow decoder network featuring flexible\nconvolution blocks with varying receptive fields, which enables the model to\neffectively adapt to tubular structures of different scales. Second, to\nhighlight potential anatomical regions and improve the recall of small tubular\nstructures, we incorporate vesselness maps as auxiliary information. These maps\nare aligned with image features through a shallow-and-deep fusion module, which\nsimultaneously eliminates unreasonable candidates to maintain high precision.\nFinally, we introduce a topology-preserving loss function that leverages\ncontextual and shape priors to balance the growth and suppression of tubular\nstructures, which also allows the model to handle low-quality and incomplete\nannotations. Extensive quantitative experiments are conducted on four public\ndatasets. The results show that our model can accurately segment 2D and 3D\ntubular structures and outperform existing state-of-the-art methods. External\nvalidation on a private dataset also demonstrates good generalizability.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T15:04:42Z"}
{"aid":"http://arxiv.org/abs/2504.07847v1","title":"An update-resilient Kalman filtering approach","summary":"We propose a new robust filtering paradigm considering the situation in which\nmodel uncertainty, described through an ambiguity set, is present only in the\nobservations. We derive the corresponding robust estimator, referred to as\nupdate-resilient Kalman filter, which appears to be novel compared to existing\nminimax game-based filtering approaches. Moreover, we characterize the\ncorresponding least favorable state space model and analyze the filter\nstability. Finally, some numerical examples show the effectiveness of the\nproposed estimator.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.07848v1","title":"Opinion dynamics and the unpredictability of opinion trajectories in an\n  adaptive social network model","summary":"Understanding opinion dynamics in social networks is critical for predicting\nsocial behavior and detecting polarization. Traditional approaches often rely\non static snapshots of network states, which can obscure the underlying\ndynamics of opinion evolution. In this study, we introduce a dynamic framework\nthat quantifies the unpredictability of opinion trajectories using the\nnormalized Lempel-Ziv (nLZ) complexity. Our approach leverages an adaptive\nsocial network model where each node is characterized by three behavioral\nparameters - homophily, neophily, and social conformity - and where opinions\nevolve continuously according to a system of ordinary differential equations.\nThe results reveal distinct nLZ complexity signatures for each node type:\nhomophilic nodes exhibit consistently rising complexity, reflecting\nincreasingly unpredictable opinion shifts that are counterintuitive given their\ntendency for similarity; neophilic nodes maintain low and stable complexity,\nsuggesting that openness to novelty can, surprisingly, lead to stable opinion\ndynamics; and conformic nodes display a U-shaped complexity trend,\ntransitioning from early opinion stagnation to later unpredictability. In fully\nheterogeneous networks, modest interaction effects emerge, with slight shifts\nin the unpredictability of each faction's trajectories. These findings\nunderscore the importance of temporal analysis in uncovering hidden dynamical\npatterns, offering novel insights into the mechanisms underlying social\nadaptation and polarization.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T15:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.07880v1","title":"Sculpting the outer edge of accretion disks in pre-circumbinary binary\n  black hole systems","summary":"Binary black hole systems (BBHs) have become a vivid reality in astrophysics\nas stellar-mass black hole mergers are now detected through their related\ngravitational wave emission during the merger stage. If many studies were\nrecently dedicated to the last stages of BBH where black holes are surrounded\nby a circumbinary disk (CBD), the structure of these systems prior to the\nformation of the CBD remains mostly unexplored. The aim of the present article\nis to investigate the potential modifications induced by the presence of a\nsecondary black hole onto the structure of the accretion disk surrounding the\nprimary black hole. We performed 2D classical hydrodynamical simulations of an\naccretion disk surrounding the primary black hole while taking into account all\ngravitational effects induced by both the primary black hole and the secondary\nblack hole orbiting on circular orbits around the center of mass of the\nsystem.We report three main effects of the presence of a secondary black hole\norbiting a circular orbit beyond the outer edge of the accretion disk: 1/ the\nouter radius of the accretion disk is significantly reduced and its ratio to\nthe black hole separation is directly linked to only the mass ratio of the\nblack holes; 2/ two spiral arms are visible in the gas density structure of the\ndisk and 3/ the outer edge of the accretion disk exhibits an elliptical shape\nthat mainly depends on the mass ratio of the black holes. Our results show that\nan accretion disk orbiting a primary black hole in a pre-CBD BBH exhibits\nspecific features induced by the gravitational force generated by the presence\nof a secondary black hole beyond its outer edge. Such features, directly linked\nto the binary separation and mass ratio, has therefore the potential to help in\nthe search and identification of BBH in the pre-CBD stage.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-10T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.07887v1","title":"Benchmarking Adversarial Robustness to Bias Elicitation in Large\n  Language Models: Scalable Automated Assessment with LLM-as-a-Judge","summary":"Large Language Models (LLMs) have revolutionized artificial intelligence,\ndriving advancements in machine translation, summarization, and conversational\nagents. However, their increasing integration into critical societal domains\nhas raised concerns about embedded biases, which can perpetuate stereotypes and\ncompromise fairness. These biases stem from various sources, including\nhistorical inequalities in training data, linguistic imbalances, and\nadversarial manipulation. Despite mitigation efforts, recent studies indicate\nthat LLMs remain vulnerable to adversarial attacks designed to elicit biased\nresponses. This work proposes a scalable benchmarking framework to evaluate LLM\nrobustness against adversarial bias elicitation. Our methodology involves (i)\nsystematically probing models with a multi-task approach targeting biases\nacross various sociocultural dimensions, (ii) quantifying robustness through\nsafety scores using an LLM-as-a-Judge approach for automated assessment of\nmodel responses, and (iii) employing jailbreak techniques to investigate\nvulnerabilities in safety mechanisms. Our analysis examines prevalent biases in\nboth small and large state-of-the-art models and their impact on model safety.\nAdditionally, we assess the safety of domain-specific models fine-tuned for\ncritical fields, such as medicine. Finally, we release a curated dataset of\nbias-related prompts, CLEAR-Bias, to facilitate systematic vulnerability\nbenchmarking. Our findings reveal critical trade-offs between model size and\nsafety, aiding the development of fairer and more robust future language\nmodels.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-10T16:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.07890v1","title":"Stupendously Large Primordial Black Holes from the QCD axion","summary":"The inflationary diffusion of (pseudo-)scalar fields with discrete symmetries\ncan seed the formation of a gas of closed domain walls after inflation, when\nthe distance between degenerate minima in field space is not too far from the\ninflationary Hubble scale. Primordial black holes (PBHs) can then be formed\nonce sufficiently heavy domain walls re-enter the Hubble sphere. In this\nscenario, inflation determines a distinctive PBH mass distribution that is\nrather flat and can thus lead to a sizable total abundance of PBHs, while\navoiding some of the downsides of PBH formation from critical collapse. We show\nthat generic QCD axion models, with decay constant close to the inflationary\nHubble scale, can yield up to $1\\%$ of the dark matter (DM) today in the form\nof PBHs, while being compatible with isocurvature constraints from Cosmic\nMicrowave Background observations. This occurs for values of axion decay\nconstants around $f_a\\simeq 10^{8}~\\text{GeV}$, that is the region targeted by\naxion helioscopes and partially constrained by astrophysical observations. The\nresulting PBHs have \\textit{stupendously} large masses, above $10^{11}M_\\odot$,\nand their existence can be probed by Large Scale Structure observations. Larger\nPBH abundances can be generated by axion-like particles. Alternatively, in\nscenarios where isocurvature constraints can be relaxed, we find that the\ntotality of the DM can be produced by the QCD axion misalignment mechanism,\naccompanied by a ${\\cal O}(10^{-3})$ DM fraction in PBHs of masses\n$(10^5-10^6)~M_\\odot$. These can act as seeds for the formation of massive\nblack holes at large redshifts, as suggested by recent JWST observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-10T16:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.07920v1","title":"Directed Temporal Tree Realization for Periodic Public Transport: Easy\n  and Hard Cases","summary":"We study the complexity of the directed periodic temporal graph realization\nproblem. This work is motivated by the design of periodic schedules in public\ntransport with constraints on the quality of service. Namely, we require that\nthe fastest path between (important) pairs of vertices is upper bounded by a\nspecified maximum duration, encoded in an upper distance matrix $D$. While\nprevious work has considered the undirected version of the problem, the\napplication in public transport schedule design requires the flexibility to\nassign different departure times to the two directions of an edge. A problem\ninstance can only be feasible if all values of the distance matrix are at least\nshortest path distances. However, the task of realizing exact fastest path\ndistances in a periodic temporal graph is often too restrictive. Therefore, we\nintroduce a minimum slack parameter $k$ that describes a lower bound on the\nmaximum allowed waiting time on each path. We concentrate on tree topologies\nand provide a full characterization of the complexity landscape with respect to\nthe period $\\Delta$ and the minimum slack parameter~$k$, showing a sharp\nthreshold between NP-complete cases and cases which are always realizable. We\nalso provide hardness results for the special case of period $\\Delta = 2$ for\ngeneral directed and undirected graphs.","main_category":"cs.DS","categories":"cs.DS,cs.CC,cs.DM","published":"2025-04-10T17:36:23Z"}
{"aid":"http://arxiv.org/abs/2504.07930v1","title":"Localization and Topology in Noncentrosymmetric Superconductors with\n  Disorder","summary":"The celebrated Kitaev chain reveals a captivating phase diagram in the\npresence of various disorders, encompassing multifractal states and topological\nAnderson phases. In this work, we investigate the localization and topological\nproperties of a dimerized topological noncentrosymmetric superconductor (NCS)\nunder quasiperiodic and Anderson disorders. Using both global and local\ncharacterization methods, we identify energy-dependent transitions from ergodic\nto multifractal and localized states. Extended multifractal regimes emerge from\nthe competition between dimerization, NCS order, and quasiperiodic modulation.\nThis interplay causes localization to occur preferentially in different energy\nbands depending on the disorder strength, with the lowest bands exhibiting the\nhighest sensitivity to parameter variations. We employ the real-space\npolarization method to compute the $\\mathbb{Z}_2$ topological invariant,\nrevealing alternating topological and trivial phases as the quasiperiodic\npotential increases, a behavior distinct from the typical topological Anderson\nphase diagram. Additionally, the topological states show remarkable robustness\nagainst Anderson disorder, providing new insights into topological phase\nstability in non-centrosymmetric systems. Finally, we propose a feasible\nexperimental scheme based on superconducting Josephson junctions, where\nNCS-like behavior can be engineered via spatially modulated supercurrents. Our\nfindings highlight the distinct roles of different disorder types in shaping\nlocalization and topology, providing insight into the engineering of Majorana\nzero modes and offering profound implications for topological quantum\nencryption schemes.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-04-10T17:45:28Z"}
{"aid":"http://arxiv.org/abs/2504.07936v1","title":"We Are All Creators: Generative AI, Collective Knowledge, and the Path\n  Towards Human-AI Synergy","summary":"Generative AI presents a profound challenge to traditional notions of human\nuniqueness, particularly in creativity. Fueled by neural network based\nfoundation models, these systems demonstrate remarkable content generation\ncapabilities, sparking intense debates about authorship, copyright, and\nintelligence itself. This paper argues that generative AI represents an\nalternative form of intelligence and creativity, operating through mathematical\npattern synthesis rather than biological understanding or verbatim replication.\nThe fundamental differences between artificial and biological neural networks\nreveal AI learning as primarily statistical pattern extraction from vast\ndatasets crystallized forms of collective human knowledge scraped from the\ninternet. This perspective complicates copyright theft narratives and\nhighlights practical challenges in attributing AI outputs to individual\nsources. Rather than pursuing potentially futile legal restrictions, we\nadvocate for human AI synergy. By embracing generative AI as a complementary\ntool alongside human intuition, context, and ethical judgment, society can\nunlock unprecedented innovation, democratize creative expression, and address\ncomplex challenges. This collaborative approach, grounded in realistic\nunderstanding of AIs capabilities and limitations, offers the most promising\npath forward. Additionally, recognizing these models as products of collective\nhuman knowledge raises ethical questions about accessibility ensuring equitable\naccess to these tools could prevent widening societal divides and leverage\ntheir full potential for collective benefit.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T17:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.07953v1","title":"Free monad sequences and extension operations","summary":"In the first part of this article, we give an analysis of the free monad\nsequence in non-cocomplete categories, with the needed colimits explicitly\nparametrized. This enables us to state a more finely grained functoriality\nprinciple for free monad and monoid sequences.\n  In the second part, we deal with the problem of functorially extending via\npullback squares a category of maps along the category of coalgebras of an\nalgebraic weak factorization system. This generalizes the classical problem of\nextending a class of maps along the left class of a weak factorization system\nin the sense of pullback squares where the vertical maps are in the chosen\nclass and the bottom map is in the left class. Such situations arise in the\ncontext of model structures where one might wish to extend fibrations along\ntrivial cofibrations. We derive suitable conditions for the algebraic analogue\nof weak saturation of the extension problem, using the results of the first\npart to reduce the technical burden.","main_category":"math.CT","categories":"math.CT","published":"2025-04-10T17:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.07964v1","title":"C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization\n  for Test-Time Expert Re-Mixing","summary":"Mixture-of-Experts (MoE) Large Language Models (LLMs) suffer from severely\nsub-optimal expert pathways-our study reveals that naive expert selection\nlearned from pretraining leaves a surprising 10-20% accuracy gap for\nimprovement. Motivated by this observation, we develop a novel class of\ntest-time optimization methods to re-weight or \"re-mixing\" the experts in\ndifferent layers jointly for each test sample. Since the test sample's ground\ntruth is unknown, we propose to optimize a surrogate objective defined by the\nsample's \"successful neighbors\" from a reference set of samples. We introduce\nthree surrogates and algorithms based on mode-finding, kernel regression, and\nthe average loss of similar reference samples/tasks. To reduce the cost of\noptimizing whole pathways, we apply our algorithms merely to the core experts'\nmixing weights in critical layers, which enjoy similar performance but save\nsignificant computation. This leads to \"Critical-Layer, Core-Expert,\nCollaborative Pathway Optimization (C3PO)\". We apply C3PO to two recent MoE\nLLMs and examine it on six widely-used benchmarks. It consistently improves the\nbase model by 7-15% in accuracy and outperforms widely used test-time learning\nbaselines, e.g., in-context learning and prompt/prefix tuning, by a large\nmargin. Moreover, C3PO enables MoE LLMs with 1-3B active parameters to\noutperform LLMs of 7-9B parameters, hence improving MoE's advantages on\nefficiency. Our thorough ablation study further sheds novel insights on\nachieving test-time improvement on MoE.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.09880v1","title":"The Universal Gap-to-Critical Temperature Ratio in Superconductors: a\n  Statistical Mechanical Perspective","summary":"We propose a statistical mechanical framework to unify the observed\nrelationship between the superconducting energy gap $\\Delta$, the pseudogap\n$\\Delta^\\ast$, and the critical temperature $T_\\mathrm{c}$. In this model,\nfermions couple as a composite boson and condense to occupy a single bound\nstate as the temperature drops. We derive a concise formula for $T_\\mathrm{c}$\nin terms of $\\Delta$ and $\\Delta^\\ast$, namely: $$\\frac{\\Delta}{k_\\mathrm{B}\nT_\\mathrm{c}} = 1.4+4\\log(\\Delta^\\ast/\\Delta).$$ This expression reproduces the\nstandard BCS gap-to-$T_\\mathrm{c}$ ratio in the absence of a pseudogap, while\nnaturally explaining its enhancement in unconventional superconductors. The\nmodel is supported by comparisons with experimental data from several cuprates\nand iron-based superconductors, which highlight its generality. This\nformulation also offers a theoretical explanation for the observed persistence\nof the pseudogap phase into the overdoped regime.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-14T05:04:25Z"}
{"aid":"http://arxiv.org/abs/2504.09885v1","title":"Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated\n  Piano Hand Motion Synthesis","summary":"Automating the synthesis of coordinated bimanual piano performances poses\nsignificant challenges, particularly in capturing the intricate choreography\nbetween the hands while preserving their distinct kinematic signatures. In this\npaper, we propose a dual-stream neural framework designed to generate\nsynchronized hand gestures for piano playing from audio input, addressing the\ncritical challenge of modeling both hand independence and coordination. Our\nframework introduces two key innovations: (i) a decoupled diffusion-based\ngeneration framework that independently models each hand's motion via\ndual-noise initialization, sampling distinct latent noise for each while\nleveraging a shared positional condition, and (ii) a Hand-Coordinated\nAsymmetric Attention (HCAA) mechanism suppresses symmetric (common-mode) noise\nto highlight asymmetric hand-specific features, while adaptively enhancing\ninter-hand coordination during denoising. The system operates hierarchically:\nit first predicts 3D hand positions from audio features and then generates\njoint angles through position-aware diffusion models, where parallel denoising\nstreams interact via HCAA. Comprehensive evaluations demonstrate that our\nframework outperforms existing state-of-the-art methods across multiple\nmetrics.","main_category":"cs.SD","categories":"cs.SD,cs.CV,eess.AS","published":"2025-04-14T05:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.09890v1","title":"Probing the Quantum Capacitance of Rydberg Transitions of Surface\n  Electrons on Liquid Helium via Microwave Frequency Modulation","summary":"We present a method for probing the quantum capacitance associated with the\nRydberg transition of surface electrons on liquid helium using RF\nreflectometry. Excitation to Rydberg states induces a redistribution of image\ncharges on capacitively coupled electrodes, giving rise to a quantum\ncapacitance. By applying frequency-modulated resonant microwaves to drive the\nRydberg transition, we systematically measured a capacitance sensitivity of\n0.38~aF/$\\sqrt{\\mathrm{Hz}}$. This level of sensitivity is sufficient to\nresolve the Rydberg transition of a single electron, providing a scalable\npathway toward the implementation of qubit readout schemes based on surface\nelectrons on helium.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-14T05:33:35Z"}
{"aid":"http://arxiv.org/abs/2504.09899v1","title":"Digital Staining with Knowledge Distillation: A Unified Framework for\n  Unpaired and Paired-But-Misaligned Data","summary":"Staining is essential in cell imaging and medical diagnostics but poses\nsignificant challenges, including high cost, time consumption, labor intensity,\nand irreversible tissue alterations. Recent advances in deep learning have\nenabled digital staining through supervised model training. However, collecting\nlarge-scale, perfectly aligned pairs of stained and unstained images remains\ndifficult. In this work, we propose a novel unsupervised deep learning\nframework for digital cell staining that reduces the need for extensive paired\ndata using knowledge distillation. We explore two training schemes: (1)\nunpaired and (2) paired-but-misaligned settings. For the unpaired case, we\nintroduce a two-stage pipeline, comprising light enhancement followed by\ncolorization, as a teacher model. Subsequently, we obtain a student staining\ngenerator through knowledge distillation with hybrid non-reference losses. To\nleverage the pixel-wise information between adjacent sections, we further\nextend to the paired-but-misaligned setting, adding the Learning to Align\nmodule to utilize pixel-level information. Experiment results on our dataset\ndemonstrate that our proposed unsupervised deep staining method can generate\nstained images with more accurate positions and shapes of the cell targets in\nboth settings. Compared with competing methods, our method achieves improved\nresults both qualitatively and quantitatively (e.g., NIQE and PSNR).We applied\nour digital staining method to the White Blood Cell (WBC) dataset,\ninvestigating its potential for medical applications.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-14T05:48:05Z"}
{"aid":"http://arxiv.org/abs/2504.09914v1","title":"Improving Multimodal Hateful Meme Detection Exploiting LMM-Generated\n  Knowledge","summary":"Memes have become a dominant form of communication in social media in recent\nyears. Memes are typically humorous and harmless, however there are also memes\nthat promote hate speech, being in this way harmful to individuals and groups\nbased on their identity. Therefore, detecting hateful content in memes has\nemerged as a task of critical importance. The need for understanding the\ncomplex interactions of images and their embedded text renders the hateful meme\ndetection a challenging multimodal task. In this paper we propose to address\nthe aforementioned task leveraging knowledge encoded in powerful Large\nMultimodal Models (LMM). Specifically, we propose to exploit LMMs in a two-fold\nmanner. First, by extracting knowledge oriented to the hateful meme detection\ntask in order to build strong meme representations. Specifically, generic\nsemantic descriptions and emotions that the images along with their embedded\ntexts elicit are extracted, which are then used to train a simple\nclassification head for hateful meme detection. Second, by developing a novel\nhard mining approach introducing directly LMM-encoded knowledge to the training\nprocess, providing further improvements. We perform extensive experiments on\ntwo datasets that validate the effectiveness of the proposed method, achieving\nstate-of-the-art performance. Our code and trained models are publicly\navailable at: https://github.com/IDT-ITI/LMM-CLIP-meme.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T06:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.09926v1","title":"Quotients of Poisson boundaries, entropy, and spectral gap","summary":"Poisson boundary is a measurable $\\Gamma$-space canonically associated with a\ngroup $\\Gamma$ and a probability measure $\\mu$ on it. The collection of all\nmeasurable $\\Gamma$-equivariant quotients, known as $\\mu$-boundaries, of the\nPoisson boundary forms a partially ordered set, equipped with a strictly\nmonotonic non-negative function, known as Furstenberg or differential entropy.\n  In this paper we demonstrate the richness and the complexity of this lattice\nof quotients for the case of free groups and surface groups and rather general\nmeasures. In particular, we show that there are continuum many unrelated\n$\\mu$-boundaries at each, sufficiently low, entropy level, and there are\ncontinuum many distinct order-theoretic cubes of $\\mu$-boundaries.\n  These $\\mu$-boundaries are constructed from dense linear representations\n$\\rho:\\Gamma\\to G$ to semi-simple Lie groups, like $\\PSL_2(\\bbC)^d$ with\nabsolutely continuous stationary measures on $\\hat\\bbC^d$.","main_category":"math.GR","categories":"math.GR,math.DS","published":"2025-04-14T06:35:18Z"}
{"aid":"http://arxiv.org/abs/2504.09928v1","title":"On the difference of the two initial logarithmic coefficients for\n  Bazilevic class of univalent functions","summary":"In this paper we give sharp bounds of the difference of the moduli of the\nsecond and the first logarithmic coefficient for Bazilevi\\v{c} class of\nunivalent functions.","main_category":"math.CV","categories":"math.CV","published":"2025-04-14T06:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.09934v1","title":"Tight Semidefinite Relaxations for Verifying Robustness of Neural\n  Networks","summary":"For verifying the safety of neural networks (NNs), Fazlyab et al. (2019)\nintroduced a semidefinite programming (SDP) approach called DeepSDP. This\nformulation can be viewed as the dual of the SDP relaxation for a problem\nformulated as a quadratically constrained quadratic program (QCQP). While SDP\nrelaxations of QCQPs generally provide approximate solutions with some gaps,\nthis work focuses on tight SDP relaxations that provide exact solutions to the\nQCQP for single-layer NNs. Specifically, we analyze tightness conditions in\nthree cases: (i) NNs with a single neuron, (ii) single-layer NNs with an\nellipsoidal input set, and (iii) single-layer NNs with a rectangular input set.\nFor NNs with a single neuron, we propose a condition that ensures the SDP\nadmits a rank-1 solution to DeepSDP by transforming the QCQP into an equivalent\ntwo-stage problem leads to a solution collinear with a predetermined vector.\nFor single-layer NNs with an ellipsoidal input set, the collinearity of\nsolutions is proved via the Karush-Kuhn-Tucker condition in the two-stage\nproblem. In case of single-layer NNs with a rectangular input set, we\ndemonstrate that the tightness of DeepSDP can be reduced to the single-neuron\nNNs, case (i), if the weight matrix is a diagonal matrix.","main_category":"math.OC","categories":"math.OC","published":"2025-04-14T06:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.09945v1","title":"Topological $Ï€/2$ modes in photonic waveguide arrays","summary":"Periodic driving is a powerful tool to generate exotic topological phases\nwithout static counterparts, such as the anomalous chiral edge modes from bulk\nbands with zero Chern number and topological $\\pi$ modes exhibiting\nperiod-doubled dynamics. Recently, a new class of Floquet topological mode,\nnamely the $\\pi/2$ mode, which carries four-period periodicity and has\npotential applications in quantum computing, was proposed based on a\nsquare-root method and realized in an acoustic system. Here we propose a\nlaser-written waveguide array lattice to realize topological $\\pi/2$ modes in\nphotonics. Our photonic model simulates a square-root periodically driven\nSu-Schrieffer-Heeger model and has a rich phase diagram allowing for the\nco-existence of conventional zero, $\\pi$ modes, and the new $\\pi/2$ modes.\nThrough numerical simulations of the wave equation, we uncover the unique\nfour-period evolution feature of the $\\pi/2$ modes. Our model, which only\ncontains four waveguides per unit cell and two driving steps, is easy to\nimplement with current fabrication techniques and may find applications in\nquantum optics.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-14T07:13:39Z"}
{"aid":"http://arxiv.org/abs/2504.09975v1","title":"OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape\n  Generation","summary":"Autoregressive models have achieved remarkable success across various\ndomains, yet their performance in 3D shape generation lags significantly behind\nthat of diffusion models. In this paper, we introduce OctGPT, a novel\nmultiscale autoregressive model for 3D shape generation that dramatically\nimproves the efficiency and performance of prior 3D autoregressive approaches,\nwhile rivaling or surpassing state-of-the-art diffusion models. Our method\nemploys a serialized octree representation to efficiently capture the\nhierarchical and spatial structures of 3D shapes. Coarse geometry is encoded\nvia octree structures, while fine-grained details are represented by binary\ntokens generated using a vector quantized variational autoencoder (VQVAE),\ntransforming 3D shapes into compact \\emph{multiscale binary sequences} suitable\nfor autoregressive prediction. To address the computational challenges of\nhandling long sequences, we incorporate octree-based transformers enhanced with\n3D rotary positional encodings, scale-specific embeddings, and token-parallel\ngeneration schemes. These innovations reduce training time by 13 folds and\ngeneration time by 69 folds, enabling the efficient training of high-resolution\n3D shapes, e.g.,$1024^3$, on just four NVIDIA 4090 GPUs only within days.\nOctGPT showcases exceptional versatility across various tasks, including text-,\nsketch-, and image-conditioned generation, as well as scene-level synthesis\ninvolving multiple objects. Extensive experiments demonstrate that OctGPT\naccelerates convergence and improves generation quality over prior\nautoregressive methods, offering a new paradigm for high-quality, scalable 3D\ncontent creation.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-14T08:31:26Z"}
{"aid":"http://arxiv.org/abs/2504.09980v1","title":"Turn-taking annotation for quantitative and qualitative analyses of\n  conversation","summary":"This paper has two goals. First, we present the turn-taking annotation layers\ncreated for 95 minutes of conversational speech of the Graz Corpus of Read and\nSpontaneous Speech (GRASS), available to the scientific community. Second, we\ndescribe the annotation system and the annotation process in more detail, so\nother researchers may use it for their own conversational data. The annotation\nsystem was developed with an interdisciplinary application in mind. It should\nbe based on sequential criteria according to Conversation Analysis, suitable\nfor subsequent phonetic analysis, thus time-aligned annotations were made\nPraat, and it should be suitable for automatic classification, which required\nthe continuous annotation of speech and a label inventory that is not too large\nand results in a high inter-rater agreement. Turn-taking was annotated on two\nlayers, Inter-Pausal Units (IPU) and points of potential completion (PCOMP;\nsimilar to transition relevance places). We provide a detailed description of\nthe annotation process and of segmentation and labelling criteria. A detailed\nanalysis of inter-rater agreement and common confusions shows that agreement\nfor IPU annotation is near-perfect, that agreement for PCOMP annotations is\nsubstantial, and that disagreements often are either partial or can be\nexplained by a different analysis of a sequence which also has merit. The\nannotation system can be applied to a variety of conversational data for\nlinguistic studies and technological applications, and we hope that the\nannotations, as well as the annotation system will contribute to a stronger\ncross-fertilization between these disciplines.","main_category":"cs.CL","categories":"cs.CL,cs.DB,cs.HC,eess.AS","published":"2025-04-14T08:45:04Z"}
{"aid":"http://arxiv.org/abs/2504.09989v1","title":"FTHP-MPI: Towards Providing Replication-based Fault Tolerance in a\n  Fault-Intolerant Native MPI Library","summary":"Faults in high-performance systems are expected to be very large in the\ncurrent exascale computing era. To compensate for a higher failure rate, the\nstandard checkpoint/restart technique would need to create checkpoints at a\nmuch higher frequency resulting in an excessive amount of overhead which would\nnot be sustainable for many scientific applications. To improve application\nefficiency in such high failure environments, the mechanism of replication of\nMPI processes was proposed. Replication allows for fast recovery from failures\nby simply dropping the failed processes and using their replicas to continue\nthe regular operation of the application.\n  In this paper, we have implemented FTHP-MPI (Fault Tolerance and High\nPerformance MPI), a novel fault-tolerant MPI library that augments\ncheckpoint/restart with replication to provide resilience from failures. The\nnovelty of our work is that it is designed to provide fault tolerance in a\nnative MPI library that does not provide support for fault tolerance. This lets\napplication developers achieve fault tolerance at high failure rates while also\nusing efficient communication protocols in the native MPI libraries that are\ngenerally fine-tuned for specific HPC platforms. We have also implemented\nefficient parallel communication techniques that involve replicas. Our\nframework deals with the unique challenges of integrating support for\ncheckpointing and partial replication.\n  We conducted experiments emulating the failure rates of exascale computing\nsystems with three applications, HPCG, PIC and CloverLeaf. We show that for\nlarge scale systems where the failure intervals are expected to be within a\nhour, our replication-based library provides higher efficiency and performance\nthan checkpointing-based approaches. We show that under failure-free\nconditions, the additional overheads due to replication are negligible in our\nlibrary.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:52:35Z"}
{"aid":"http://arxiv.org/abs/2504.09997v1","title":"GenTe: Generative Real-world Terrains for General Legged Robot\n  Locomotion Control","summary":"Developing bipedal robots capable of traversing diverse real-world terrains\npresents a fundamental robotics challenge, as existing methods using predefined\nheight maps and static environments fail to address the complexity of\nunstructured landscapes. To bridge this gap, we propose GenTe, a framework for\ngenerating physically realistic and adaptable terrains to train generalizable\nlocomotion policies. GenTe constructs an atomic terrain library that includes\nboth geometric and physical terrains, enabling curriculum training for\nreinforcement learning-based locomotion policies. By leveraging\nfunction-calling techniques and reasoning capabilities of Vision-Language\nModels (VLMs), GenTe generates complex, contextually relevant terrains from\ntextual and graphical inputs. The framework introduces realistic force modeling\nfor terrain interactions, capturing effects such as soil sinkage and\nhydrodynamic resistance. To the best of our knowledge, GenTe is the first\nframework that systemically generates simulation environments for legged robot\nlocomotion control. Additionally, we introduce a benchmark of 100 generated\nterrains. Experiments demonstrate improved generalization and robustness in\nbipedal robot locomotion.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T09:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.09998v1","title":"Metric-Guided Synthesis of Class Activation Mapping","summary":"Class activation mapping (CAM) is a widely adopted class of saliency methods\nused to explain the behavior of convolutional neural networks (CNNs). These\nmethods generate heatmaps that highlight the parts of the input most relevant\nto the CNN output. Various CAM methods have been proposed, each distinguished\nby the expressions used to derive heatmaps. In general, users look for heatmaps\nwith specific properties that reflect different aspects of CNN functionality.\nThese may include similarity to ground truth, robustness, equivariance, and\nmore. Although existing CAM methods implicitly encode some of these properties\nin their expressions, they do not allow for variability in heatmap generation\nfollowing the user's intent or domain knowledge. In this paper, we address this\nlimitation by introducing SyCAM, a metric-based approach for synthesizing CAM\nexpressions. Given a predefined evaluation metric for saliency maps, SyCAM\nautomatically generates CAM expressions optimized for that metric. We\nspecifically explore a syntax-guided synthesis instantiation of SyCAM, where\nCAM expressions are derived based on predefined syntactic constraints and the\ngiven metric. Using several established evaluation metrics, we demonstrate the\nefficacy and flexibility of our approach in generating targeted heatmaps. We\ncompare SyCAM with other well-known CAM methods on three prominent models:\nResNet50, VGG16, and VGG19.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T09:01:49Z"}
{"aid":"http://arxiv.org/abs/2504.10005v1","title":"Session-based Recommender Systems: User Interest as a Stochastic Process\n  in the Latent Space","summary":"This paper jointly addresses the problem of data uncertainty, popularity\nbias, and exposure bias in session-based recommender systems. We study the\nsymptoms of this bias both in item embeddings and in recommendations. We\npropose treating user interest as a stochastic process in the latent space and\nproviding a model-agnostic implementation of this mathematical concept. The\nproposed stochastic component consists of elements: debiasing item embeddings\nwith regularization for embedding uniformity, modeling dense user interest from\nsession prefixes, and introducing fake targets in the data to simulate extended\nexposure. We conducted computational experiments on two popular benchmark\ndatasets, Diginetica and YooChoose 1/64, as well as several modifications of\nthe YooChoose dataset with different ratios of popular items. The results show\nthat the proposed approach allows us to mitigate the challenges mentioned.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-14T09:08:40Z"}
{"aid":"http://arxiv.org/abs/2504.10026v1","title":"An efffcient numerical scheme for two-dimensional nonlinear time\n  fractional SchrÃ¶dinger equation","summary":"In this paper, a linearized fully discrete scheme is proposed to solve the\ntwo-dimensional nonlinear time fractional Schr\\\"odinger equation with weakly\nsingular solutions, which is constructed by using L1 scheme for Caputo\nfractional derivative, backward formula for the approximation of nonlinear term\nand five-point difference scheme in space. We rigorously prove the\nunconditional stability and pointwise-in-time convergence of the fully discrete\nscheme, which does not require any restriction on the grid ratio. Numerical\nresults are presented to verify the accuracy of the theoretical analysis.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T09:30:49Z"}
{"aid":"http://arxiv.org/abs/2504.10034v1","title":"Uniform Planar Array Based Weighted Cooperative Spectrum Sensing for\n  Cognitive Radio Networks","summary":"Cooperative spectrum sensing (CSS) is essential for improving the spectrum\nefficiency and reliability of cognitive radio applications. Next-generation\nwireless communication networks increasingly employ uniform planar arrays (UPA)\ndue to their ability to steer beamformers towards desired directions,\nmitigating interference and eavesdropping. However, the application of\nUPA-based CSS in cognitive radio remains largely unexplored. This paper\nproposes a multi-beam UPA-based weighted CSS (WCSS) framework to enhance\ndetection reliability, applicable to various cognitive radio networks,\nincluding cellular, vehicular, and satellite communications. We first propose a\nweighting factor for commonly used energy detection (ED) and eigenvalue\ndetection (EVD) techniques, based on the spatial variation of signal strengths\nresulting from UPA antenna beamforming. We then analytically characterize the\nperformance of both weighted ED and weighted EVD by deriving closed-form\nexpressions for false alarm and detection probabilities. Our numerical results,\nconsidering both static and dynamic user behaviors, demonstrate the superiority\nof WCSS in enhancing sensing performance compared to uniformly weighted\ndetectors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T09:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10072v1","title":"Comparison of an OGS/Polystyrene scintillator (BSO-406) with pure OGS\n  (BSO-100), EJ-276, EJ-309, and M600 scintillators","summary":"In this paper, we present an investigation into the scintillation properties\nand pulse shape discrimination (PSD) performance of the new BSO-406, which is a\nblend of 40% organic glass scintillator and 60% polystyrene. We tested a\ncylindrical sample with dimensions of 2x2 inches. The study includes\nmeasurements of neutron-gamma discrimination capability, emission spectra,\nphotoelectron yield, and the analysis of light pulse shapes originating from\nevents related to gamma-rays and fast neutrons. The results were compared to\ndata previously recorded using a pure Organic Glass Scintillator (BSO-100), an\nEJ-309 liquid scintillator, and EJ-276 and M600 polyurethane-based plastic\nscintillators.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-14T10:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.10081v1","title":"RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning\n  Capability","summary":"Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been\nrapidly progressing and achieving breakthrough performance on complex reasoning\ntasks such as mathematics and coding. However, the open-source R1 models have\nraised safety concerns in wide applications, such as the tendency to comply\nwith malicious queries, which greatly impacts the utility of these powerful\nmodels in their applications. In this paper, we introduce RealSafe-R1 as\nsafety-aligned versions of DeepSeek-R1 distilled models. To train these models,\nwe construct a dataset of 15k safety-aware reasoning trajectories generated by\nDeepSeek-R1, under explicit instructions for expected refusal behavior. Both\nquantitative experiments and qualitative case studies demonstrate the models'\nimprovements, which are shown in their safety guardrails against both harmful\nqueries and jailbreak attacks. Importantly, unlike prior safety alignment\nefforts that often compromise reasoning performance, our method preserves the\nmodels' reasoning capabilities by maintaining the training data within the\noriginal distribution of generation. Model weights of RealSafe-R1 are\nopen-source at https://huggingface.co/RealSafe.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-14T10:26:37Z"}
{"aid":"http://arxiv.org/abs/2504.10084v1","title":"UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based\n  Person Retrieval","summary":"Text-based Person Retrieval (TPR) as a multi-modal task, which aims to\nretrieve the target person from a pool of candidate images given a text\ndescription, has recently garnered considerable attention due to the progress\nof contrastive visual-language pre-trained model. Prior works leverage\npre-trained CLIP to extract person visual and textual features and fully\nfine-tune the entire network, which have shown notable performance improvements\ncompared to uni-modal pre-training models. However, full-tuning a large model\nis prone to overfitting and hinders the generalization ability. In this paper,\nwe propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method\nfor Text-based Person Retrieval (UP-Person) to thoroughly transfer the\nmulti-modal knowledge from CLIP. Specifically, UP-Person simultaneously\nintegrates three lightweight PETL components including Prefix, LoRA and\nAdapter, where Prefix and LoRA are devised together to mine local information\nwith task-specific information prompts, and Adapter is designed to adjust\nglobal feature representations. Additionally, two vanilla submodules are\noptimized to adapt to the unified architecture of TPR. For one thing, S-Prefix\nis proposed to boost attention of prefix and enhance the gradient propagation\nof prefix tokens, which improves the flexibility and performance of the vanilla\nprefix. For another thing, L-Adapter is designed in parallel with layer\nnormalization to adjust the overall distribution, which can resolve conflicts\ncaused by overlap and interaction among multiple submodules. Extensive\nexperimental results demonstrate that our UP-Person achieves state-of-the-art\nresults across various person retrieval datasets, including CUHK-PEDES,\nICFG-PEDES and RSTPReid while merely fine-tuning 4.7\\% parameters. Code is\navailable at https://github.com/Liu-Yating/UP-Person.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T10:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.10107v1","title":"Enhancing LLM-based Recommendation through Semantic-Aligned\n  Collaborative Knowledge","summary":"Large Language Models (LLMs) demonstrate remarkable capabilities in\nleveraging comprehensive world knowledge and sophisticated reasoning mechanisms\nfor recommendation tasks. However, a notable limitation lies in their inability\nto effectively model sparse identifiers (e.g., user and item IDs), unlike\nconventional collaborative filtering models (Collabs.), thus hindering LLM to\nlearn distinctive user-item representations and creating a performance\nbottleneck. Prior studies indicate that integrating collaborative knowledge\nfrom Collabs. into LLMs can mitigate the above limitations and enhance their\nrecommendation performance. Nevertheless, the significant discrepancy in\nknowledge distribution and semantic space between LLMs and Collab. presents\nsubstantial challenges for effective knowledge transfer. To tackle these\nchallenges, we propose a novel framework, SeLLa-Rec, which focuses on achieving\nalignment between the semantic spaces of Collabs. and LLMs. This alignment\nfosters effective knowledge fusion, mitigating the influence of discriminative\nnoise and facilitating the deep integration of knowledge from diverse models.\nSpecifically, three special tokens with collaborative knowledge are embedded\ninto the LLM's semantic space through a hybrid projection layer and integrated\ninto task-specific prompts to guide the recommendation process. Experiments\nconducted on two public benchmark datasets (MovieLens-1M and Amazon Book)\ndemonstrate that SeLLa-Rec achieves state-of-the-art performance.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T11:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.10123v1","title":"M2S-RoAD: Multi-Modal Semantic Segmentation for Road Damage Using Camera\n  and LiDAR Data","summary":"Road damage can create safety and comfort challenges for both human drivers\nand autonomous vehicles (AVs). This damage is particularly prevalent in rural\nareas due to less frequent surveying and maintenance of roads. Automated\ndetection of pavement deterioration can be used as an input to AVs and driver\nassistance systems to improve road safety. Current research in this field has\npredominantly focused on urban environments driven largely by public datasets,\nwhile rural areas have received significantly less attention. This paper\nintroduces M2S-RoAD, a dataset for the semantic segmentation of different\nclasses of road damage. M2S-RoAD was collected in various towns across New\nSouth Wales, Australia, and labelled for semantic segmentation to identify nine\ndistinct types of road damage. This dataset will be released upon the\nacceptance of the paper.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:32:01Z"}
{"aid":"http://arxiv.org/abs/2504.10152v1","title":"Neo balcobalancing numbers","summary":"In this work, we defined neo balcobalancing numbers, neo Lucas-balcobalancing\nnumbers, neo balcobalancers and neo Lucas-balcobalancers and derived the\ngeneral terms of these numbers in terms of balancing numbers. Conversely we\ndeduced the general terms of balancing, cobalancing, Lucas-balancing and\nLucas-cobalancing numbers in terms of these numbers. We also deduced some\nrelations on Binet formulas, recurrence relations, relationship with Pell,\nPell-Lucas, triangular, square triangular numbers, Pythagorean triples and\nCassini identities. We also formulate the sum of first $n$-terms of these\nnumbers and obtained some formulas for the sums of Pell, Pell-Lucas, balancing\nand Lucas-cobalancing numbers in terms of these numbers.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T12:04:32Z"}
{"aid":"http://arxiv.org/abs/2504.10163v1","title":"Shoulder Range of Motion Rehabilitation Robot Incorporating\n  Scapulohumeral Rhythm for Frozen Shoulder","summary":"This paper presents a novel rehabilitation robot designed to address the\nchallenges of passive range of motion (PROM) exercises for frozen shoulder\npatients by integrating advanced scapulohumeral rhythm stabilization. Frozen\nshoulder is characterized by limited glenohumeral motion and disrupted\nscapulohumeral rhythm, with therapist-assisted interventions being highly\neffective for restoring normal shoulder function. While existing robotic\nsolutions replicate natural shoulder biomechanics, they lack the ability to\nstabilize compensatory movements, such as shoulder shrugging, which are\ncritical for effective rehabilitation. Our proposed device features a 6 degrees\nof freedom (DoF) mechanism, including 5 DoF for shoulder motion and an\ninnovative 1 DoF Joint press for scapular stabilization. The robot employs a\npersonalized two-phase operation: recording normal shoulder movement patterns\nfrom the unaffected side and applying them to guide the affected side.\nExperimental results demonstrated the robot's ability to replicate recorded\nmotion patterns with high precision, with root mean square error (RMSE) values\nconsistently below 1 degree. In simulated frozen shoulder conditions, the robot\neffectively suppressed scapular elevation, delaying the onset of compensatory\nmovements and guiding the affected shoulder to move more closely in alignment\nwith normal shoulder motion, particularly during arm elevation movements such\nas abduction and flexion. These findings confirm the robot's potential as a\nrehabilitation tool capable of automating PROM exercises while correcting\ncompensatory movements. The system provides a foundation for advanced,\npersonalized rehabilitation for patients with frozen shoulders.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T12:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.10187v1","title":"Deep Reasoning Translation via Reinforcement Learning","summary":"Recently, deep reasoning LLMs (e.g., OpenAI o1/o3 and DeepSeek-R1) have shown\npromising performance in various complex tasks. Free translation is an\nimportant and interesting task in the multilingual world, which requires going\nbeyond word-for-word translation and taking cultural differences into account.\nThis task is still under-explored in deep reasoning LLMs. In this paper, we\nintroduce DeepTrans, a deep reasoning translation model that learns free\ntranslation via reinforcement learning. Specifically, we carefully build a\nreward model with pre-defined scoring criteria on both the translation results\nand the thought process. Given the source sentences, the reward model teaches\nthe deep translation model how to think and free-translate them during\nreinforcement learning. In this way, training DeepTrans does not need any\nlabeled translations, avoiding the human-intensive annotation or\nresource-intensive data synthesis. Experimental results show the effectiveness\nof DeepTrans. Using Qwen2.5-7B as the backbone, DeepTrans improves performance\nby 16.3% in literature translation, and outperforms strong deep reasoning\nbaselines as well as baselines that are fine-tuned with synthesized data.\nMoreover, we summarize the failures and interesting findings during our RL\nexploration. We hope this work could inspire other researchers in free\ntranslation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.10196v1","title":"On compact embeddings in $\\mathbf{L^p}$ and fractional spaces","summary":"Let $X,Y$ be Hilbert spaces and $\\mathcal{A}\\colon X\\to X'$ a continuous and\nsymmetric elliptic operator. We suppose that $X$ is dense in $Y$ and that the\nembedding $X\\subset Y$ is compact. In this paper we show some consequences of\nthis setting on the study of the fractional operator attached to $\\mathcal{A}$\nin the extension setting $\\mathbb{R}^N\\times (0, \\infty)$. Being more specific,\nwe will give some examples where the embedding $H(\\mathbb{R}^{N+1}_+)\\subset\nL^2(\\mathbb{R}^N)$ is compact, with the space $H(\\mathbb{R}^{N+1}_+)$ depending\non the operator $\\mathcal{A}$.","main_category":"math.FA","categories":"math.FA,math.AP","published":"2025-04-14T13:02:48Z"}
{"aid":"http://arxiv.org/abs/2504.10210v1","title":"Can Competition Enhance the Proficiency of Agents Powered by Large\n  Language Models in the Realm of News-driven Time Series Forecasting?","summary":"Multi-agents-based news-driven time series forecasting is considered as a\npotential paradigm shift in the era of large language models (LLMs). The\nchallenge of this task lies in measuring the influences of different news\nevents towards the fluctuations of time series. This requires agents to possess\nstronger abilities of innovative thinking and the identifying misleading logic.\nHowever, the existing multi-agent discussion framework has limited enhancement\non time series prediction in terms of optimizing these two capabilities.\nInspired by the role of competition in fostering innovation, this study embeds\na competition mechanism within the multi-agent discussion to enhance agents'\ncapability of generating innovative thoughts. Furthermore, to bolster the\nmodel's proficiency in identifying misleading information, we incorporate a\nfine-tuned small-scale LLM model within the reflective stage, offering\nauxiliary decision-making support. Experimental results confirm that the\ncompetition can boost agents' capacity for innovative thinking, which can\nsignificantly improve the performances of time series prediction. Similar to\nthe findings of social science, the intensity of competition within this\nframework can influence the performances of agents, providing a new perspective\nfor studying LLMs-based multi-agent systems.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-14T13:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10214v1","title":"Balancing Stability and Plasticity in Pretrained Detector: A Dual-Path\n  Framework for Incremental Object Detection","summary":"The balance between stability and plasticity remains a fundamental challenge\nin pretrained model-based incremental object detection (PTMIOD). While existing\nPTMIOD methods demonstrate strong performance on in-domain tasks aligned with\npretraining data, their plasticity to cross-domain scenarios remains\nunderexplored. Through systematic component-wise analysis of pretrained\ndetectors, we reveal a fundamental discrepancy: the localization modules\ndemonstrate inherent cross-domain stability-preserving precise bounding box\nestimation across distribution shifts-while the classification components\nrequire enhanced plasticity to mitigate discriminability degradation in\ncross-domain scenarios. Motivated by these findings, we propose a dual-path\nframework built upon pretrained DETR-based detectors which decouples\nlocalization stability and classification plasticity: the localization path\nmaintains stability to preserve pretrained localization knowledge, while the\nclassification path facilitates plasticity via parameter-efficient fine-tuning\nand resists forgetting with pseudo-feature replay. Extensive evaluations on\nboth in-domain (MS COCO and PASCAL VOC) and cross-domain (TT100K) benchmarks\nshow state-of-the-art performance, demonstrating our method's ability to\neffectively balance stability and plasticity in PTMIOD, achieving robust\ncross-domain adaptation and strong retention of anti-forgetting capabilities.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T13:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.10226v1","title":"Geodesic interpretation of the global quasi-geostrophic equations","summary":"We give an interpretation of the global shallow water quasi-geostrophic\nequations on the sphere $\\Sph^2$ as a geodesic equation on the central\nextension of the quantomorphism group on $\\Sph^3$. The study includes deriving\nthe model as a geodesic equation for a weak Riemannian metric, demonstrating\nsmooth dependence on the initial data, and establishing global-in-time\nexistence and uniqueness of solutions. We also prove that the Lamb parameter in\nthe model has a stabilizing effect on the dynamics: if it is large enough, the\nsectional curvature along the trade-wind current is positive, implying\nconjugate points.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T13:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.10227v1","title":"Probing then Editing Response Personality of Large Language Models","summary":"Large Language Models (LLMs) have demonstrated promising capabilities to\ngenerate responses that exhibit consistent personality traits. Despite the\nmajor attempts to analyze personality expression through output-based\nevaluations, little is known about how such traits are internally encoded\nwithin LLM parameters. In this paper, we introduce a layer-wise probing\nframework to systematically investigate the layer-wise capability of LLMs in\nencoding personality for responding. We conduct probing experiments on 11\nopen-source LLMs over the PersonalityEdit benchmark and find that LLMs\npredominantly encode personality for responding in their middle and upper\nlayers, with instruction-tuned models demonstrating a slightly clearer\nseparation of personality traits. Furthermore, by interpreting the trained\nprobing hyperplane as a layer-wise boundary for each personality category, we\npropose a layer-wise perturbation method to edit the personality expressed by\nLLMs during inference. Our results show that even when the prompt explicitly\nspecifies a particular personality, our method can still successfully alter the\nresponse personality of LLMs. Interestingly, the difficulty of converting\nbetween certain personality traits varies substantially, which aligns with the\nrepresentational distances in our probing experiments. Finally, we conduct a\ncomprehensive MMLU benchmark evaluation and time overhead analysis,\ndemonstrating that our proposed personality editing method incurs only minimal\ndegradation in general capabilities while maintaining low training costs and\nacceptable inference latency. Our code is publicly available at\nhttps://github.com/universe-sky/probing-then-editing-personality.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T13:46:35Z"}
{"aid":"http://arxiv.org/abs/2504.10231v1","title":"A Model Zoo of Vision Transformers","summary":"The availability of large, structured populations of neural networks - called\n'model zoos' - has led to the development of a multitude of downstream tasks\nranging from model analysis, to representation learning on model weights or\ngenerative modeling of neural network parameters. However, existing model zoos\nare limited in size and architecture and neglect the transformer, which is\namong the currently most successful neural network architectures. We address\nthis gap by introducing the first model zoo of vision transformers (ViT). To\nbetter represent recent training approaches, we develop a new blueprint for\nmodel zoo generation that encompasses both pre-training and fine-tuning steps,\nand publish 250 unique models. They are carefully generated with a large span\nof generating factors, and their diversity is validated using a thorough choice\nof weight-space and behavioral metrics. To further motivate the utility of our\nproposed dataset, we suggest multiple possible applications grounded in both\nextensive exploratory experiments and a number of examples from the existing\nliterature. By extending previous lines of similar work, our model zoo allows\nresearchers to push their model population-based methods from the small model\nregime to state-of-the-art architectures. We make our model zoo available at\ngithub.com/ModelZoos/ViTModelZoo.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T13:52:26Z"}
{"aid":"http://arxiv.org/abs/2504.10244v1","title":"Towards contrast- and pathology-agnostic clinical fetal brain MRI\n  segmentation using SynthSeg","summary":"Magnetic resonance imaging (MRI) has played a crucial role in fetal\nneurodevelopmental research. Structural annotations of MR images are an\nimportant step for quantitative analysis of the developing human brain, with\nDeep learning providing an automated alternative for this otherwise tedious\nmanual process. However, segmentation performances of Convolutional Neural\nNetworks often suffer from domain shift, where the network fails when applied\nto subjects that deviate from the distribution with which it is trained on. In\nthis work, we aim to train networks capable of automatically segmenting fetal\nbrain MRIs with a wide range of domain shifts pertaining to differences in\nsubject physiology and acquisition environments, in particular shape-based\ndifferences commonly observed in pathological cases. We introduce a novel\ndata-driven train-time sampling strategy that seeks to fully exploit the\ndiversity of a given training dataset to enhance the domain generalizability of\nthe trained networks. We adapted our sampler, together with other existing data\naugmentation techniques, to the SynthSeg framework, a generator that utilizes\ndomain randomization to generate diverse training data, and ran thorough\nexperimentations and ablation studies on a wide range of training/testing data\nto test the validity of the approaches. Our networks achieved notable\nimprovements in the segmentation quality on testing subjects with intense\nanatomical abnormalities (p < 1e-4), though at the cost of a slighter decrease\nin performance in cases with fewer abnormalities. Our work also lays the\nfoundation for future works on creating and adapting data-driven sampling\nstrategies for other training pipelines.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-14T14:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.10245v1","title":"A short proof for the acyclicity of oriented exchange graphs of cluster\n  algebras","summary":"The statement in the title was proved in \\cite{Cao23} by introducing dominant\nsets of seeds, which are analogs of torsion classes in representation theory.\nIn this note, we observe a short proof by the existence of consistent cluster\nscattering diagrams.","main_category":"math.RT","categories":"math.RT,math.RA","published":"2025-04-14T14:09:06Z"}
{"aid":"http://arxiv.org/abs/2504.10249v1","title":"Struggle First, Prompt Later: How Task Complexity Shapes Learning with\n  GenAI-Assisted Pretesting","summary":"This study examines the role of AI-assisted pretesting in enhancing learning\noutcomes, particularly when integrated with generative AI tools like ChatGPT.\nPretesting, a learning strategy in which students attempt to answer questions\nor solve problems before receiving instruction, has been shown to improve\nretention by activating prior knowledge. The adaptability and interactivity of\nAI-assisted pretesting introduce new opportunities for optimizing learning in\ndigital environments. Across three experimental studies, we explored how\npretesting strategies, task characteristics, and student motivation influence\nlearning. Findings suggest that AI-assisted pretesting enhances learning\noutcomes, particularly for tasks requiring higher-order thinking. While\nadaptive AI-driven pretesting increased engagement, its benefits were most\npronounced in complex, exploratory tasks rather than straightforward\ncomputational problems. These results highlight the importance of aligning\npretesting strategies with task demands, demonstrating that AI can optimize\nlearning when applied to tasks requiring deeper cognitive engagement. This\nresearch provides insights into how AI-assisted pretesting can be effectively\nintegrated with generative AI tools to enhance both cognitive and motivational\noutcomes in learning environments.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T14:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.10258v1","title":"XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a\n  Novel Benchmark","summary":"Document Reading Order Recovery is a fundamental task in document image\nunderstanding, playing a pivotal role in enhancing Retrieval-Augmented\nGeneration (RAG) and serving as a critical preprocessing step for large\nlanguage models (LLMs). Existing methods often struggle with complex\nlayouts(e.g., multi-column newspapers), high-overhead interactions between\ncross-modal elements (visual regions and textual semantics), and a lack of\nrobust evaluation benchmarks. We introduce XY-Cut++, an advanced layout\nordering method that integrates pre-mask processing, multi-granularity\nsegmentation, and cross-modal matching to address these challenges. Our method\nsignificantly enhances layout ordering accuracy compared to traditional XY-Cut\ntechniques. Specifically, XY-Cut++ achieves state-of-the-art performance (98.8\nBLEU overall) while maintaining simplicity and efficiency. It outperforms\nexisting baselines by up to 24\\% and demonstrates consistent accuracy across\nsimple and complex layouts on the newly introduced DocBench-100 dataset. This\nadvancement establishes a reliable foundation for document structure recovery,\nsetting a new standard for layout ordering tasks and facilitating more\neffective RAG and LLM preprocessing.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-14T14:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10281v1","title":"Zero-shot Autonomous Microscopy for Scalable and Intelligent\n  Characterization of 2D Materials","summary":"Characterization of atomic-scale materials traditionally requires human\nexperts with months to years of specialized training. Even for trained human\noperators, accurate and reliable characterization remains challenging when\nexamining newly discovered materials such as two-dimensional (2D) structures.\nThis bottleneck drives demand for fully autonomous experimentation systems\ncapable of comprehending research objectives without requiring large training\ndatasets. In this work, we present ATOMIC (Autonomous Technology for Optical\nMicroscopy & Intelligent Characterization), an end-to-end framework that\nintegrates foundation models to enable fully autonomous, zero-shot\ncharacterization of 2D materials. Our system integrates the vision foundation\nmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),\nunsupervised clustering, and topological analysis to automate microscope\ncontrol, sample scanning, image segmentation, and intelligent analysis through\nprompt engineering, eliminating the need for additional training. When\nanalyzing typical MoS2 samples, our approach achieves 99.7% segmentation\naccuracy for single layer identification, which is equivalent to that of human\nexperts. In addition, the integrated model is able to detect grain boundary\nslits that are challenging to identify with human eyes. Furthermore, the system\nretains robust accuracy despite variable conditions including defocus, color\ntemperature fluctuations, and exposure variations. It is applicable to a broad\nspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless\nof whether they were fabricated via chemical vapor deposition or mechanical\nexfoliation. This work represents the implementation of foundation models to\nachieve autonomous analysis, establishing a scalable and data-efficient\ncharacterization paradigm that fundamentally transforms the approach to\nnanoscale materials research.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cs.AI,cs.CV,cs.LG","published":"2025-04-14T14:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.10291v1","title":"Towards a Flat Space Carrollian Hologram from AdS$_4$/CFT$_3$","summary":"Finding a concrete example holography in four dimensional asymptotically flat\nspace is an important open problem. A natural strategy is to take the flat\nspace limit of the celebrated AdS$_4$/CFT$_3$ correspondence, which relates\nM-theory in AdS$_4 \\times$S$^7$ to a certain superconformal Chern-Simons-matter\ntheory known as the ABJM theory. In this limit, the boundary of AdS$_4$ becomes\nnull infinity and the ABJM theory should exhibit an emergent superconformal\nCarrollian symmetry. We investigate this possiblity by matching the Carrollian\nlimit of ABJM correlators with four-dimensional supergravity amplitudes that\narise from taking the flat space limit of AdS$_4 \\times$S$^7$ and reducing\nalong the S$^7$. We also present a general analysis of three-dimensional\nsuperconformal Carrollian symmetry.","main_category":"hep-th","categories":"hep-th","published":"2025-04-14T15:02:58Z"}
{"aid":"http://arxiv.org/abs/2504.10293v1","title":"Gravity-induced emergence of the Fermi scale in quantum quadratic\n  gravity","summary":"In the framework of asymptotic safety, we study quantum quadratic gravity in\nthe presence of the Higgs field considered as non-separable from the vacuum.\nThe theory flows to a high energy fixed point where the Higgs field is strongly\ncoupled to gravity, its potential is symmetric, and the quadratic Weyl\ncurvature coupling is large. The latter renders the ghost graviton an unstable\nhigh mass resonance which renders unitarity in the spirit of Lee-Week type\ntheories. Furthermore, if the scalar graviton is tachyonic then there will be a\nlow energy fixed point where tachyonic condensation leads to a new stable\nvacuum. At this fixed point the symmetry breaks and the Fermi scale emerges,\nand the behavior of the Higgs field is classical (not influenced by\ngravitational interaction). Gravity at the UV scale is purely quadratic whereas\nat the Fermi scale it is linear, and in the intermediate region both\ncontributions are relevant. Thus, at the Fermi scale the quadratic curvature\nfields disappear through the ghost instability and tachyon condensation, giving\nrise to Einstein gravity and the electroweak phase transition.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-14T15:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.10297v1","title":"Bumblebee cosmology: The FLRW solution and the CMB temperature\n  anisotropy","summary":"We put into test the idea of replacing dark energy by a vector field against\nthe cosmic microwave background (CMB) observation using the simplest\nvector-tensor theory, where a massive vector field couples to the Ricci scalar\nand the Ricci tensor quadratically. First, a remarkable\nFriedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) metric solution that is\ncompletely independent of the matter-energy compositions of the universe is\nfound. Second, based on the FLRW solution as well as the perturbation\nequations, a numerical code calculating the CMB temperature power spectrum is\nbuilt. We find that though the FLRW solution can mimic the evolution of the\nuniverse in the standard $\\Lambda$CDM model, the calculated CMB temperature\npower spectrum shows unavoidable discrepancies from the CMB power spectrum\nmeasurements.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-14T15:06:38Z"}
{"aid":"http://arxiv.org/abs/2504.10311v1","title":"Performance of a Brownian information engine through potential\n  profiling: Optimum output requisites, Heating-to-Refrigeration transition and\n  their Re-entrance","summary":"Brownian Information engine (BIE) harnesses the energy from a fluctuating\nenvironment by utilizing the associated information change in the presence of a\nsingle heat bath. The engine operates in a space-dependent confining potential\nand requires an appropriate feedback control mechanism. In general, the\nfeedback controller has three different steps: measurement, feedback, and\nrelaxation. The feedback step is related to a sudden change in the potential\nenergy that is essential for a nonzero work output. BIE utilises the amount of\ninformation (surprise) acquired during the measurement step for the energy\noutput. However, due to the relaxation process, a certain amount of acquired\ninformation is lost or becomes unavailable. So, controlling information loss\nduring relaxation is crucial for the overall efficiency of the engine. The net\n(available) information, therefore, can be monitored by tuning the feedback\ncontroller and the shape of the confining potential. In this paper, we explore\nthe effect of the shape modulation of the confining potential, which may have\nmultiple stable valleys and unstable hills, on the net available information\nand, hence, the performance of a BIE that operates under an asymmetric feedback\nprotocol. We examine the optimal performance requirements of the BIE and the\namount of maximum work output under different potential profiling. For\nmonostable trapping, a concave shape in confining potential results in a higher\nwork output than a convex one. We also find that hills and valleys in the\nconfining potential may lead to multiple good operating conditions. An\nappropriate shape modulation can create a heater-refrigerator transition and\ntheir reentrance due to non-trivial changes in information loss during the\nrelaxation process.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T15:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.10328v1","title":"Continuous fields of interval algebras","summary":"This paper investigates and classifies a specific class of one-parameter\ncontinuous fields of C*-algebras, which can be seen as generalized AI-algebras.\nBuilding on the classification of *-homomorphisms between interval algebras by\nthe Cuntz semigroup, along with a selection theorem and a gluing procedure, we\nemploy a 'local-to-global' strategy to achieve our classification result.","main_category":"math.OA","categories":"math.OA","published":"2025-04-14T15:36:03Z"}
{"aid":"http://arxiv.org/abs/2504.10329v1","title":"InstructEngine: Instruction-driven Text-to-Image Alignment","summary":"Reinforcement Learning from Human/AI Feedback (RLHF/RLAIF) has been\nextensively utilized for preference alignment of text-to-image models. Existing\nmethods face certain limitations in terms of both data and algorithm. For\ntraining data, most approaches rely on manual annotated preference data, either\nby directly fine-tuning the generators or by training reward models to provide\ntraining signals. However, the high annotation cost makes them difficult to\nscale up, the reward model consumes extra computation and cannot guarantee\naccuracy. From an algorithmic perspective, most methods neglect the value of\ntext and only take the image feedback as a comparative signal, which is\ninefficient and sparse. To alleviate these drawbacks, we propose the\nInstructEngine framework. Regarding annotation cost, we first construct a\ntaxonomy for text-to-image generation, then develop an automated data\nconstruction pipeline based on it. Leveraging advanced large multimodal models\nand human-defined rules, we generate 25K text-image preference pairs. Finally,\nwe introduce cross-validation alignment method, which refines data efficiency\nby organizing semantically analogous samples into mutually comparable pairs.\nEvaluations on DrawBench demonstrate that InstructEngine improves SD v1.5 and\nSDXL's performance by 10.53% and 5.30%, outperforming state-of-the-art\nbaselines, with ablation study confirming the benefits of InstructEngine's all\ncomponents. A win rate of over 50% in human reviews also proves that\nInstructEngine better aligns with human preferences.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T15:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.10334v1","title":"Flying Hand: End-Effector-Centric Framework for Versatile Aerial\n  Manipulation Teleoperation and Policy Learning","summary":"Aerial manipulation has recently attracted increasing interest from both\nindustry and academia. Previous approaches have demonstrated success in various\nspecific tasks. However, their hardware design and control frameworks are often\ntightly coupled with task specifications, limiting the development of\ncross-task and cross-platform algorithms. Inspired by the success of robot\nlearning in tabletop manipulation, we propose a unified aerial manipulation\nframework with an end-effector-centric interface that decouples high-level\nplatform-agnostic decision-making from task-agnostic low-level control. Our\nframework consists of a fully-actuated hexarotor with a 4-DoF robotic arm, an\nend-effector-centric whole-body model predictive controller, and a high-level\npolicy. The high-precision end-effector controller enables efficient and\nintuitive aerial teleoperation for versatile tasks and facilitates the\ndevelopment of imitation learning policies. Real-world experiments show that\nthe proposed framework significantly improves end-effector tracking accuracy,\nand can handle multiple aerial teleoperation and imitation learning tasks,\nincluding writing, peg-in-hole, pick and place, changing light bulbs, etc. We\nbelieve the proposed framework provides one way to standardize and unify aerial\nmanipulation into the general manipulation community and to advance the field.\nProject website: https://lecar-lab.github.io/flying_hand/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T15:41:14Z"}
{"aid":"http://arxiv.org/abs/2504.10379v1","title":"Minimal surfaces in strongly correlated random environments","summary":"A minimal surface in a random environment (MSRE) is a $d$-dimensional surface\nin $(d+n)$-dimensional space which minimizes the sum of its elastic energy and\nits environment potential energy, subject to prescribed boundary values. Apart\nfrom their intrinsic interest, such surfaces are further motivated by\nconnections with disordered spin systems and first-passage percolation models.\nIn this work, we consider the case of strongly correlated environments,\nrealized by the model of harmonic MSRE in a fractional Brownian environment of\nHurst parameter $H\\in(0,1)$. This includes the case of Brownian environment\n($H=1/2$ and $n=1$), which is commonly used to approximate the domain walls of\nthe $(d+1)$-dimensional random-field Ising model.\n  We prove that surfaces of dimension $d\\in\\{1,2,3\\}$ delocalize with power-law\nfluctuations, and determine their precise transversal and minimal energy\nfluctuation exponents, as well as the stretched exponential exponents governing\nthe tail decay of their distributions. These exponents are found to be the same\nin all codimensions $n$, depending only on $d$ and $H$. The transversal and\nminimal energy fluctuation exponents are specified by two scaling relations.\n  We further show that surfaces of dimension $d=4$ delocalize with\nsub-power-law fluctuations, with their height and minimal energy fluctuations\ntied by a scaling relation. Lastly, we prove that surfaces of dimensions $d\\ge\n5$ localize.\n  These results put several predictions from the physics literature on\nmathematically rigorous ground.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-14T16:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.10382v1","title":"Why Cold BGK Modes Are So Cool: Dispersion Relations from\n  Orbit-Constrained Distribution Functions","summary":"We derive analytic dispersion relations for cold, orbitally constrained\nsystems governed by the Vlasov equation. For magnetized plasmas, we obtain the\nfirst explicit relation for two-dimensional anisotropic BGK modes with finite\nmagnetic field, showing that only a finite number of angular modes can become\nunstable and identifying a magnetic-field threshold for stabilization. In the\ngravitational case, we establish a bound on the growth rate of core\nperturbations, set by the potential's curvature. These results clarify how\norbital constraints shape the spectrum and growth of kinetic instabilities in\ncold, collisionless media.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,astro-ph.GA","published":"2025-04-14T16:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.10385v1","title":"Normalized solutions for SchrÃ¶dinger-Bopp-Podolsky systems in bounded\n  domains","summary":"We consider an elliptic system of Schr\\\"odinger-Bopp-Podolsky type in a\nbounded and smooth domain of R3 with a non constant coupling factor. This kind\nof system has been introduced in the mathematical literature in [14] and in the\nlast years many contributions appeared. In particular here we present the\nresults in [2] and [34] which show existence of solutions by means of the\nLjusternik-Schnirelmann theory under different boundary conditions on the\nelectrostatic potential.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:28:31Z"}
{"aid":"http://arxiv.org/abs/2504.10391v1","title":"LLM-driven Constrained Copy Generation through Iterative Refinement","summary":"Crafting a marketing message (copy), or copywriting is a challenging\ngeneration task, as the copy must adhere to various constraints. Copy creation\nis inherently iterative for humans, starting with an initial draft followed by\nsuccessive refinements. However, manual copy creation is time-consuming and\nexpensive, resulting in only a few copies for each use case. This limitation\nrestricts our ability to personalize content to customers. Contrary to the\nmanual approach, LLMs can generate copies quickly, but the generated content\ndoes not consistently meet all the constraints on the first attempt (similar to\nhumans). While recent studies have shown promise in improving constrained\ngeneration through iterative refinement, they have primarily addressed tasks\nwith only a few simple constraints. Consequently, the effectiveness of\niterative refinement for tasks such as copy generation, which involves many\nintricate constraints, remains unclear. To address this gap, we propose an\nLLM-based end-to-end framework for scalable copy generation using iterative\nrefinement. To the best of our knowledge, this is the first study to address\nmultiple challenging constraints simultaneously in copy generation. Examples of\nthese constraints include length, topics, keywords, preferred lexical ordering,\nand tone of voice. We demonstrate the performance of our framework by creating\ncopies for e-commerce banners for three different use cases of varying\ncomplexity. Our results show that iterative refinement increases the copy\nsuccess rate by $16.25-35.91$% across use cases. Furthermore, the copies\ngenerated using our approach outperformed manually created content in multiple\npilot studies using a multi-armed bandit framework. The winning copy improved\nthe click-through rate by $38.5-45.21$%.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T16:38:28Z"}
{"aid":"http://arxiv.org/abs/2504.10392v1","title":"Spin-Orbital Intertwined Topological Superconductivity in a Class of\n  Correlated Noncentrosymmetric Materials","summary":"In this study, we propose an alternative route to achieving topological\nsuperconductivity (TSC). Our approach applies to a new class of correlated\nnoncentrosymmetric materials that host two spin-split Fermi surfaces with\nidentical spin textures due to a spin-orbital intertwined effect. Incorporating\nmulti-orbital repulsive Hubbard interactions, we calculate the superconducting\npairings of a minimal two-orbital effective model within a\nspin-fluctuation-mediated superconductivity framework. We find that, depending\non the effective Rashba spin-orbit coupling (RSOC) strength and filling level,\nthe Hubbard interaction can drive the leading pairing symmetry into the\n$A_1(S_{\\pm})$, $B_1$, $B_2$ or $B_2(d_{\\pm})$ irreducible representations\n(IRs) of the $C_{4v}$ point group. Notably, the $A_1(S_{\\pm})$ pairing gives\nrise to a fully gapped TSC characterized by a $Z_2$ invariant, while the\n$B_2(d_{\\pm})$ pairing results in a nodal TSC. Our analysis reveals that the\nfully gapped TSC is predominated by spin-singlet regardless of the presence of\nthe spin-triplet components. This distinguishes our model from\nnoncentrosymmetric materials with conventional Rashba-split band structures,\nwhere TSC typically emerges near the van Hove singularity and is primarily\ndriven by $p$-wave or $f$-wave spin-triplet pairing. These features enhances\nits experimental accessibility, and we discuss potential experimental systems\nfor its realization.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-14T16:40:34Z"}
{"aid":"http://arxiv.org/abs/2504.10405v1","title":"Performance of Large Language Models in Supporting Medical Diagnosis and\n  Treatment","summary":"The integration of Large Language Models (LLMs) into healthcare holds\nsignificant potential to enhance diagnostic accuracy and support medical\ntreatment planning. These AI-driven systems can analyze vast datasets,\nassisting clinicians in identifying diseases, recommending treatments, and\npredicting patient outcomes. This study evaluates the performance of a range of\ncontemporary LLMs, including both open-source and closed-source models, on the\n2024 Portuguese National Exam for medical specialty access (PNA), a\nstandardized medical knowledge assessment. Our results highlight considerable\nvariation in accuracy and cost-effectiveness, with several models demonstrating\nperformance exceeding human benchmarks for medical students on this specific\ntask. We identify leading models based on a combined score of accuracy and\ncost, discuss the implications of reasoning methodologies like\nChain-of-Thought, and underscore the potential for LLMs to function as valuable\ncomplementary tools aiding medical professionals in complex clinical\ndecision-making.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.ET,cs.HC","published":"2025-04-14T16:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.10406v1","title":"A discrete model for surface configuration spaces","summary":"One of the primary methods of studying the topology of configurations of\npoints in a graph and configurations of disks in a planar region has been to\nexamine discrete combinatorial models arising from the underlying spaces.\nDespite the success of these models in the graph and disk settings, they have\nnot been constructed for the vast majority of surface configuration spaces. In\nthis paper, we construct such a model for the ordered configuration space of\n$m$ points in an oriented surface $\\Sigma$. More specifically, we prove that if\nwe give $\\Sigma$ a certain cube complex structure $K$, then the ordered\nconfiguration space of $m$ points in $\\Sigma$ is homotopy equivalent to a\nsubcomplex of $K^{m}$","main_category":"math.AT","categories":"math.AT,math.CO,math.GT","published":"2025-04-14T16:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.10408v1","title":"Software package for simulations using the coarse-grained CALVADOS model","summary":"We present the CALVADOS package for performing simulations of biomolecules\nusing OpenMM and the coarse-grained CALVADOS model. The package makes it easy\nto run simulations using the family of CALVADOS models of biomolecules\nincluding disordered proteins, multi-domain proteins, proteins in crowded\nenvironments, and disordered RNA. We briefly describe the CALVADOS force fields\nand how they were parametrised. We then discuss the design paradigms and\narchitecture of the CALVADOS package, and give examples of how to use it for\nrunning and analysing simulations. The simulation package is freely available\nunder a GNU GPL license; therefore, it can easily be extended and we provide\nsome examples of how this might be done.","main_category":"q-bio.BM","categories":"q-bio.BM","published":"2025-04-14T16:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.10409v1","title":"GPS: Distilling Compact Memories via Grid-based Patch Sampling for\n  Efficient Online Class-Incremental Learning","summary":"Online class-incremental learning aims to enable models to continuously adapt\nto new classes with limited access to past data, while mitigating catastrophic\nforgetting. Replay-based methods address this by maintaining a small memory\nbuffer of previous samples, achieving competitive performance. For effective\nreplay under constrained storage, recent approaches leverage distilled data to\nenhance the informativeness of memory. However, such approaches often involve\nsignificant computational overhead due to the use of bi-level optimization.\nMotivated by these limitations, we introduce Grid-based Patch Sampling (GPS), a\nlightweight and effective strategy for distilling informative memory samples\nwithout relying on a trainable model. GPS generates informative samples by\nsampling a subset of pixels from the original image, yielding compact\nlow-resolution representations that preserve both semantic content and\nstructural information. During replay, these representations are reassembled to\nsupport training and evaluation. Experiments on extensive benchmarks\ndemonstrate that GRS can be seamlessly integrated into existing replay\nframeworks, leading to 3%-4% improvements in average end accuracy under\nmemory-constrained settings, with limited computational overhead.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.10413v1","title":"On perimeter minimizing sets in manifolds with quadratic volume growth","summary":"This paper studies whether the presence of a perimeter minimizing set in a\nRiemannian manifold $(M,g)$ forces an isometric splitting. We show that this is\nthe case when $M$ has non-negative sectional curvature and quadratic volume\ngrowth at infinity. Moreover, we obtain that the boundary of the perimeter\nminimizing set is identified with a slice in the product structure of $M$.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T16:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.10450v1","title":"AC Current-Driven Magnetization Switching and Nonlinear Hall\n  Rectification in a Magnetic Topological Insulator","summary":"Spin-orbit torque arising from the spin-orbit-coupled surface states of\ntopological insulators enables current-induced control of magnetization with\nhigh efficiency. Here, alternating-current (AC) driven magnetization reversal\nis demonstrated in a semi-magnetic topological insulator\n(Cr,Bi,Sb)2Te3/(Bi,Sb)2Te3, facilitated by a low threshold current density of\n1.5x10^9 A/m^2. Time-domain Hall voltage measurements using an oscilloscope\nreveal a strongly nonlinear and nonreciprocal Hall response during the\nmagnetization reversal process. Fourier analysis of the time-varying Hall\nvoltage identifies higher-harmonic signals and a rectified direct-current (DC)\ncomponent, highlighting the complex interplay among the applied current,\nexternal magnetic field, and magnetization dynamics. Furthermore, a hysteretic\nbehavior in the current-voltage characteristics gives rise to frequency mixing\nunder dual-frequency excitation. This effect, distinct from conventional\npolynomial-based nonlinearities, allows for selective extraction of specific\nfrequency components. The results demonstrate that AC excitation can not only\nswitch magnetization efficiently but also induce tunable nonlinear responses,\noffering a new pathway for multifunctional spintronic devices with potential\napplications in energy-efficient memory, signal processing, and frequency\nconversion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-14T17:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.10455v1","title":"The stellar decomposition of Gaussian quantum states","summary":"We introduce the stellar decomposition, a novel method for characterizing\nnon-Gaussian states produced by photon-counting measurements on Gaussian\nstates. Given an (m+n)-mode Gaussian state G, we express it as an (m+n)-mode\n\"Gaussian core state\" G_core followed by a fixed m-mode Gaussian transformation\nT that only acts on the first m modes. The defining property of the Gaussian\ncore state G_core is that measuring the last n of its modes in the\nphoton-number basis leaves the first m modes on a finite Fock support, i.e. a\ncore state. Since T is measurement-independent and G_core has an exact and\nfinite Fock representation, this decomposition exactly describes all\nnon-Gaussian states obtainable by projecting n modes of G onto the Fock basis.\nFor pure states we prove that a physical pair (G_core, T) always exists with\nG_core pure and T unitary. For mixed states, we establish necessary and\nsufficient conditions for (G_core, T) to be a Gaussian mixed state and a\nGaussian channel. Finally, we develop a semidefinite program to extract the\n\"largest\" possible Gaussian channel when these conditions fail. The stellar\ndecomposition leads to practical bounds on achievable state quality in photonic\ncircuits and for GKP state generation in particular. Our results are based on a\nnew characterization of Gaussian completely positive maps in the Bargmann\npicture, which may be of independent interest. As a result, this work provides\nnovel tools for improved simulations of quantum optical systems, and for\nunderstanding the generation of non-Gaussian resource states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T17:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.10456v1","title":"Privacy-Preserving Distributed Link Predictions Among Peers in Online\n  Classrooms Using Federated Learning","summary":"Social interactions among classroom peers, represented as social learning\nnetworks (SLNs), play a crucial role in enhancing learning outcomes. While SLN\nanalysis has recently garnered attention, most existing approaches rely on\ncentralized training, where data is aggregated and processed on a local/cloud\nserver with direct access to raw data. However, in real-world educational\nsettings, such direct access across multiple classrooms is often restricted due\nto privacy concerns. Furthermore, training models on isolated classroom data\nprevents the identification of common interaction patterns that exist across\nmultiple classrooms, thereby limiting model performance. To address these\nchallenges, we propose one of the first frameworks that integrates Federated\nLearning (FL), a distributed and collaborative machine learning (ML) paradigm,\nwith SLNs derived from students' interactions in multiple classrooms' online\nforums to predict future link formations (i.e., interactions) among students.\nBy leveraging FL, our approach enables collaborative model training across\nmultiple classrooms while preserving data privacy, as it eliminates the need\nfor raw data centralization. Recognizing that each classroom may exhibit unique\nstudent interaction dynamics, we further employ model personalization\ntechniques to adapt the FL model to individual classroom characteristics. Our\nresults demonstrate the effectiveness of our approach in capturing both shared\nand classroom-specific representations of student interactions in SLNs.\nAdditionally, we utilize explainable AI (XAI) techniques to interpret model\npredictions, identifying key factors that influence link formation across\ndifferent classrooms. These insights unveil the drivers of social learning\ninteractions within a privacy-preserving, collaborative, and distributed ML\nframework -- an aspect that has not been explored before.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-14T17:43:11Z"}
{"aid":"http://arxiv.org/abs/2504.10475v1","title":"Probing the Sivers Asymmetry with Transverse Energy-Energy Correlators\n  in the Small-$x$ Regime","summary":"We investigate transverse energy-energy correlators (TEECs) for both\npolarized and unpolarized targets in the small-$x$ regime at the Electron-Ion\nCollider (EIC). Focusing on the approximately back-to-back electroproduction of\na hadron-electron pair, we apply transverse-momentum-dependent (TMD)\nfactorization formulas that incorporate TMD evolution for both event-shape\nobservables and expand them in terms of the small-$x$ dipole amplitude. This\nallows us to write the TEEC off the transversely polarized proton in terms of a\nC-odd interaction, corresponding to an odderon exchange. Due to the\ncharge-conjugation-odd nature of the small-$x$ quark Sivers function, we\nrestrict the sum over final hadronic states to positively and negatively\ncharged hadrons separately. We present numerical predictions for the TEEC\nSivers asymmetry at the EIC and find the magnitude of the asymmetry to be on\nthe $0.1 \\%$ level. This channel offers a promising avenue for benchmarking the\nstill largely unconstrained odderon amplitude.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-14T17:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.10476v1","title":"Donor-Acceptor Pairs near Silicon Carbide surfaces","summary":"Donor-acceptor pairs (DAPs) in wide-bandgap semiconductors are promising\nplatforms for the realization of quantum technologies, due to their optically\ncontrollable, long-range dipolar interactions. Specifically, Al-N DAPs in bulk\nsilicon carbide (SiC) have been predicted to enable coherent coupling over\ndistances exceeding 10 nm. However, their practical implementations require an\nunderstanding of the properties of these pairs near surfaces and interfaces.\nHere, using first principles calculations we investigate how the presence of\nsurfaces influence the stability and optical properties of Al-N DAPs in SiC,\nand we show that they retain favorable optical properties comparable to their\nbulk counterparts, despite a slight increase in electron-phonon coupling.\nFurthermore, we introduce the concept of surface-defect pairs (SDPs), where an\nelectron-hole pair is generated between a near-surface defect and an occupied\nsurface state located in the bandgap of the material. We show that\nvanadium-based SDPs near OH-terminated 4H-SiC surfaces exhibit dipoles\nnaturally aligned perpendicular to the surface, greatly enhancing dipole-dipole\ncoupling between SDPs. Our results also reveal significant\npolarization-dependent modulation in the stimulated emission and\nphotoionization cross sections of V-based SDPs, which are tunable by two orders\nof magnitude via the polarization angle of the incident laser light. The\nnear-surface defects investigated here provide novel possibilities for the\ndevelopment of hybrid quantum-classical interfaces, as they can be used to\nmediate information transfer between quantum nodes and integrated photonic\ncircuits.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,quant-ph","published":"2025-04-14T17:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.10828v1","title":"Following Is All You Need: Robot Crowd Navigation Using People As\n  Planners","summary":"Navigating in crowded environments requires the robot to be equipped with\nhigh-level reasoning and planning techniques. Existing works focus on\ndeveloping complex and heavyweight planners while ignoring the role of human\nintelligence. Since humans are highly capable agents who are also widely\navailable in a crowd navigation setting, we propose an alternative scheme where\nthe robot utilises people as planners to benefit from their effective planning\ndecisions and social behaviours. Through a set of rule-based evaluations, we\nidentify suitable human leaders who exhibit the potential to guide the robot\ntowards its goal. Using a simple base planner, the robot follows the selected\nleader through shorthorizon subgoals that are designed to be straightforward to\nachieve. We demonstrate through both simulated and real-world experiments that\nour novel framework generates safe and efficient robot plans compared to\nexisting planners, even without predictive or data-driven modules. Our method\nalso brings human-like robot behaviours without explicitly defining traffic\nrules and social norms. Code will be available at\nhttps://github.com/centiLinda/PeopleAsPlanner.git.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T03:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.10833v1","title":"Towards Spatially-Aware and Optimally Faithful Concept-Based\n  Explanations","summary":"Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a\npromising tool for generating semantic explanations of the decision-making\nprocesses in deep neural networks, having applications in both model\nimprovement and understanding. It is vital that the explanation is accurate, or\nfaithful, to the model, yet we identify several limitations of prior\nfaithfulness metrics that inhibit an accurate evaluation; most notably, prior\nmetrics involve only the set of concepts present, ignoring how they may be\nspatially distributed. We address these limitations with Surrogate Faithfulness\n(SF), an evaluation method that introduces a spatially-aware surrogate and two\nnovel faithfulness metrics. Using SF, we produce Optimally Faithful (OF)\nexplanations, where concepts are found that maximize faithfulness. Our\nexperiments show that (1) adding spatial-awareness to prior U-CBEMs increases\nfaithfulness in all cases; (2) OF produces significantly more faithful\nexplanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's\nlearned concepts generalize well to out-of-domain data and are more robust to\nadversarial examples, where prior U-CBEMs struggle.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-15T03:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.10844v1","title":"Nonlinear Diffusion Equations on Graphs: Global Well-Posedness, Blow-Up\n  Analysis and Applications","summary":"For a nonlinear diffusion equation on graphs whose nonlinearity violates the\nLipschitz condition, we prove short-time solution existence and characterize\nglobal well-posedness by establishing sufficient criteria for blow-up phenomena\nand quantifying blow-up rates. These theoretical results are then applied to\nmodel complex dynamical networks, with supporting numerical experiments. This\nwork mainly makes two contributions: (i) generalization of existing results for\ndiffusion equations on graphs to cases with nontrivial potentials, producing\nricher analytical results; (ii) a new PDE approach to model complex dynamical\nnetworks, with preliminary numerical experiments confirming its validity.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T04:06:12Z"}
{"aid":"http://arxiv.org/abs/2504.10849v1","title":"Real-Time Word-Level Temporal Segmentation in Streaming Speech\n  Recognition","summary":"Rich-text captions are essential to help communication for Deaf and\nhard-of-hearing (DHH) people, second-language learners, and those with autism\nspectrum disorder (ASD). They also preserve nuances when converting speech to\ntext, enhancing the realism of presentation scripts and conversation or speech\nlogs. However, current real-time captioning systems lack the capability to\nalter text attributes (ex. capitalization, sizes, and fonts) at the word level,\nhindering the accurate conveyance of speaker intent that is expressed in the\ntones or intonations of the speech. For example, ''YOU should do this'' tends\nto be considered as indicating ''You'' as the focus of the sentence, whereas\n''You should do THIS'' tends to be ''This'' as the focus. This paper proposes a\nsolution that changes the text decorations at the word level in real time. As a\nprototype, we developed an application that adjusts word size based on the\nloudness of each spoken word. Feedback from users implies that this system\nhelped to convey the speaker's intent, offering a more engaging and accessible\ncaptioning experience.","main_category":"cs.HC","categories":"cs.HC,cs.MM,cs.SD,eess.AS","published":"2025-04-15T04:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.10853v1","title":"PT-Mark: Invisible Watermarking for Text-to-image Diffusion Models via\n  Semantic-aware Pivotal Tuning","summary":"Watermarking for diffusion images has drawn considerable attention due to the\nwidespread use of text-to-image diffusion models and the increasing need for\ntheir copyright protection. Recently, advanced watermarking techniques, such as\nTree Ring, integrate watermarks by embedding traceable patterns (e.g., Rings)\ninto the latent distribution during the diffusion process. Such methods disrupt\nthe original semantics of the generated images due to the inevitable\ndistribution shift caused by the watermarks, thereby limiting their\npracticality, particularly in digital art creation. In this work, we present\nSemantic-aware Pivotal Tuning Watermarks (PT-Mark), a novel invisible\nwatermarking method that preserves both the semantics of diffusion images and\nthe traceability of the watermark. PT-Mark preserves the original semantics of\nthe watermarked image by gradually aligning the generation trajectory with the\noriginal (pivotal) trajectory while maintaining the traceable watermarks during\nwhole diffusion denoising process. To achieve this, we first compute the\nsalient regions of the watermark at each diffusion denoising step as a spatial\nprior to identify areas that can be aligned without disrupting the watermark\npattern. Guided by the region, we then introduce an additional pivotal tuning\nbranch that optimizes the text embedding to align the semantics while\npreserving the watermarks. Extensive evaluations demonstrate that PT-Mark can\npreserve the original semantics of the diffusion images while integrating\nrobust watermarks. It achieves a 10% improvement in the performance of semantic\npreservation (i.e., SSIM, PSNR, and LPIPS) compared to state-of-the-art\nwatermarking methods, while also showing comparable robustness against\nreal-world perturbations and four times greater efficiency.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T04:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.10857v1","title":"ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping","summary":"Robotic grasping is a cornerstone capability of embodied systems. Many\nmethods directly output grasps from partial information without modeling the\ngeometry of the scene, leading to suboptimal motion and even collisions. To\naddress these issues, we introduce ZeroGrasp, a novel framework that\nsimultaneously performs 3D reconstruction and grasp pose prediction in near\nreal-time. A key insight of our method is that occlusion reasoning and modeling\nthe spatial relationships between objects is beneficial for both accurate\nreconstruction and grasping. We couple our method with a novel large-scale\nsynthetic dataset, which comprises 1M photo-realistic images, high-resolution\n3D reconstructions and 11.3B physically-valid grasp pose annotations for 12K\nobjects from the Objaverse-LVIS dataset. We evaluate ZeroGrasp on the\nGraspNet-1B benchmark as well as through real-world robot experiments.\nZeroGrasp achieves state-of-the-art performance and generalizes to novel\nreal-world objects by leveraging synthetic data.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-15T04:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.10888v1","title":"CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal\n  Visible-Infrared Detectors","summary":"Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T05:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.10920v1","title":"Towards Efficient Partially Relevant Video Retrieval with Active Moment\n  Discovering","summary":"Partially relevant video retrieval (PRVR) is a practical yet challenging task\nin text-to-video retrieval, where videos are untrimmed and contain much\nbackground content. The pursuit here is of both effective and efficient\nsolutions to capture the partial correspondence between text queries and\nuntrimmed videos. Existing PRVR methods, which typically focus on modeling\nmulti-scale clip representations, however, suffer from content independence and\ninformation redundancy, impairing retrieval performance. To overcome these\nlimitations, we propose a simple yet effective approach with active moment\ndiscovering (AMDNet). We are committed to discovering video moments that are\nsemantically consistent with their queries. By using learnable span anchors to\ncapture distinct moments and applying masked multi-moment attention to\nemphasize salient moments while suppressing redundant backgrounds, we achieve\nmore compact and informative video representations. To further enhance moment\nmodeling, we introduce a moment diversity loss to encourage different moments\nof distinct regions and a moment relevance loss to promote semantically\nquery-relevant moments, which cooperate with a partially relevant retrieval\nloss for end-to-end optimization. Extensive experiments on two large-scale\nvideo datasets (\\ie, TVR and ActivityNet Captions) demonstrate the superiority\nand efficiency of our AMDNet. In particular, AMDNet is about 15.5 times smaller\n(\\#parameters) while 6.0 points higher (SumR) than the up-to-date method\nGMMFormer on TVR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T07:00:18Z"}
{"aid":"http://arxiv.org/abs/2504.10927v1","title":"Translating between NIP integral domains and topological fields","summary":"We prove that definable ring topologies on NIP fields are closely connected\nto NIP integral domains. More precisely, we show that up to elementary\nequivalence, any NIP topological field arises from an NIP integral domain. As\nan application, we prove several results about definable ring topologies on NIP\nfields, including the following. Let $K$ be an NIP field or expansion of a\nfield. Let $\\tau$ be a definable ring topology on $K$. Then $\\tau$ is a field\ntopology, and $\\tau$ is locally bounded. If $K$ has characteristic $p$ or\nfinite dp-rank, then $\\tau$ is \"generalized t-henselian\" in the sense of\nDittman, Walsberg, and Ye, meaning that the implicit function theorem holds for\npolynomials. If $K$ has finite dp-rank, then $\\tau$ must be a topology of\n\"finite breadth\" (a $W_n$-topology). Using these techniques, we give some\nreformulations of the conjecture that NIP local rings are henselian.","main_category":"math.LO","categories":"math.LO","published":"2025-04-15T07:13:03Z"}
{"aid":"http://arxiv.org/abs/2504.10938v1","title":"Iterative Linear Quadratic Regulator for Quantum Optimal Control","summary":"Quantum optimal control for gate optimization aims to provide accurate,\nrobust, and fast pulse sequences to achieve gate fidelities on quantum systems\nbelow the error correction threshold. Many methods have been developed and\nsuccessfully applied in simulation and on quantum hardware. In this paper, we\nestablish a connection between the iterative linear quadratic regulator and\nquantum optimal control by adapting it to gate optimization of quantum systems.\nWe include constraints on the controls and their derivatives to enable smoother\npulses. We achieve high-fidelity simulation results for X and cross-resonance\ngates on one- and two-qubit fixed-frequency transmons simulated with two and\nthree levels.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T07:36:32Z"}
{"aid":"http://arxiv.org/abs/2504.10975v1","title":"Simplicial volume of open books in dimension 4","summary":"In this short note we adapt a proof by Bucher and Neofytidis to prove that\nthe simplicial volume of 4-manifolds admitting an open book decomposition\nvanishes. In particular this shows that Quinns signature invariant, which\ndetects the existence of an open book decomposition in dimensions above 4, is\ninsufficient to characterize open books in dimension 4, even if one allows\narbitrary stabilizations via connected sums.","main_category":"math.GT","categories":"math.GT,math.AT","published":"2025-04-15T08:36:54Z"}
{"aid":"http://arxiv.org/abs/2504.10983v1","title":"ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed\n  Protein Language Model Embeddings","summary":"The design of protein sequences with desired functionalities is a fundamental\ntask in protein engineering. Deep generative methods, such as autoregressive\nmodels and diffusion models, have greatly accelerated the discovery of novel\nprotein sequences. However, these methods mainly focus on local or shallow\nresidual semantics and suffer from low inference efficiency, large modeling\nspace and high training cost. To address these challenges, we introduce\nProtFlow, a fast flow matching-based protein sequence design framework that\noperates on embeddings derived from semantically meaningful latent space of\nprotein language models. By compressing and smoothing the latent space,\nProtFlow enhances performance while training on limited computational\nresources. Leveraging reflow techniques, ProtFlow enables high-quality\nsingle-step sequence generation. Additionally, we develop a joint design\npipeline for the design scene of multichain proteins. We evaluate ProtFlow\nacross diverse protein design tasks, including general peptides and long-chain\nproteins, antimicrobial peptides, and antibodies. Experimental results\ndemonstrate that ProtFlow outperforms task-specific methods in these\napplications, underscoring its potential and broad applicability in\ncomputational protein sequence design and analysis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.BM","published":"2025-04-15T08:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.11014v1","title":"GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*","summary":"The emerging trend in computer vision emphasizes developing universal models\ncapable of simultaneously addressing multiple diverse tasks. Such universality\ntypically requires joint training across multi-domain datasets to ensure\neffective generalization. However, monocular 3D object detection presents\nunique challenges in multi-domain training due to the scarcity of datasets\nannotated with accurate 3D ground-truth labels, especially beyond typical\nroad-based autonomous driving contexts. To address this challenge, we introduce\na novel weakly supervised framework leveraging pseudo-labels. Current\npretrained models often struggle to accurately detect pedestrians in non-road\nenvironments due to inherent dataset biases. Unlike generalized image-based 2D\nobject detection models, achieving similar generalization in monocular 3D\ndetection remains largely unexplored. In this paper, we propose GATE3D, a novel\nframework designed specifically for generalized monocular 3D object detection\nvia weak supervision. GATE3D effectively bridges domain gaps by employing\nconsistency losses between 2D and 3D predictions. Remarkably, our model\nachieves competitive performance on the KITTI benchmark as well as on an\nindoor-office dataset collected by us to evaluate the generalization\ncapabilities of our framework. Our results demonstrate that GATE3D\nsignificantly accelerates learning from limited annotated data through\neffective pre-training strategies, highlighting substantial potential for\nbroader impacts in robotics, augmented reality, and virtual reality\napplications. Project page: https://ies0411.github.io/GATE3D/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T09:37:54Z"}
{"aid":"http://arxiv.org/abs/2504.11027v1","title":"From Heteropolymer Stiffness Distributions to Effective Homopolymers: A\n  Conformational Analysis of Intrinsically Disordered Proteins","summary":"Intrinsically disordered proteins (IDPs) are characterized by a lack of\ndefined secondary and tertiary structures, and are thus well-suited for\ndescriptions within polymer theory. However, the intrinsic heterogeneity of\nproteins, stemming from their diverse amino acid building blocks, introduces\nlocal variations in chain stiffness, which can impact conformational behavior\nat larger scales. To investigate this effect, we developed a heterogeneous\nworm-like chain model in which the local persistence length follows a Gaussian\ndistribution. We demonstrate that these heterogeneous chains can be effectively\nmapped to homogeneous chains with a single effective persistence length. To\nassess whether this mapping can be extended to naturally occurring IDPs, we\nperformed simulations using various coarse-grained IDP models, finding that the\nsimulated IDPs have similar shapes like the corresponding homogeneous and\nheterogeneous worm-like chains. However, the IDPs are systematically larger\nthan ideal worm-like chains, yet slightly more compact when excluded volume\ninteractions are considered. We attribute these differences to intramolecular\ninteractions between non-bonded monomers, which our theoretical models do not\naccount for.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-15T09:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.11043v1","title":"Riemannian optimization for model order reduction of linear systems with\n  quadratic outputs","summary":"This paper investigates the optimal $H_2$ model order reduction for linear\nsystems with quadratic outputs. In the framework of Galerkin projection, we\nfirst formulate the optimal $H_2$ MOR as an unconstrained Riemannian\noptimization problem on the Stiefel manifold. The Riemannian gradient of the\nspecific cost function is derived with the aid of Gramians of systems, and the\nDai-Yuan-type Riemannian conjugate gradient method is adopted to generate\nstructure-preserving reduced models. We also consider the optimal $H_2$ MOR\nbased on the product manifold, where some coefficient matrices of reduced\nmodels are determined directly via the iteration of optimization problem,\ninstead of the Galerkin projection method. In addition, we provide a scheme to\ncompute low-rank approximate solutions of Sylvester equations based on the\ntruncated polynomial expansions, which fully exploits the specific structure of\nSylvester equations in the optimization problems, and enables an efficient\nexecution of our approach. Finally, two numerical examples are simulated to\ndemonstrate the efficiency of our methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T10:09:28Z"}
{"aid":"http://arxiv.org/abs/2504.11059v1","title":"Quantifying Group Fairness in Community Detection","summary":"Understanding community structures is crucial for analyzing networks, as\nnodes join communities that collectively shape large-scale networks. In\nreal-world settings, the formation of communities is often impacted by several\nsocial factors, such as ethnicity, gender, wealth, or other attributes. These\nfactors may introduce structural inequalities; for instance, real-world\nnetworks can have a few majority groups and many minority groups. Community\ndetection algorithms, which identify communities based on network topology, may\ngenerate unfair outcomes if they fail to account for existing structural\ninequalities, particularly affecting underrepresented groups. In this work, we\npropose a set of novel group fairness metrics to assess the fairness of\ncommunity detection methods. Additionally, we conduct a comparative evaluation\nof the most common community detection methods, analyzing the trade-off between\nperformance and fairness. Experiments are performed on synthetic networks\ngenerated using LFR, ABCD, and HICH-BA benchmark models, as well as on\nreal-world networks. Our results demonstrate that the fairness-performance\ntrade-off varies widely across methods, with no single class of approaches\nconsistently excelling in both aspects. We observe that Infomap and\nSignificance methods are high-performing and fair with respect to different\ntypes of communities across most networks. The proposed metrics and findings\nprovide valuable insights for designing fair and effective community detection\nalgorithms.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-15T10:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.11071v1","title":"Avoshifts, Unishifts and Nondeterministic Cellular Automata","summary":"In this paper, we study avoshifts and unishifts on $\\mathbb{Z}^d$. Avoshifts\nare subshifts where for each convex set $C$, and each vector $v$ such that $C\n\\cup \\{\\vec v\\}$ is also convex, the set of valid extensions of globally valid\npatterns on $C$ to ones on $C \\cup \\{v\\}$ is determined by a bounded subpattern\nof $C$. Unishifts are the subshifts where for such $C, \\vec v$, every\n$C$-pattern has the same number of $\\vec v$-extensions. Cellwise quasigroup\nshifts (including group shifts) and TEP subshifts are examples of unishifts,\nwhile unishifts and subshifts with topological strong spatial mixing are\nexamples of avoshifts. We prove that every avoshift is the spacetime subshift\nof a nondeterministic cellular automaton on an avoshift of lower dimension up\nto a linear transformation and a convex blocking. From this, we deduce that all\navoshifts contain periodic points, and that unishifts have dense periodic\npoints and admit equal entropy full shift factors.","main_category":"math.DS","categories":"math.DS,math.CO","published":"2025-04-15T11:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.11094v1","title":"Evaluation Report on MCP Servers","summary":"With the rise of LLMs, a large number of Model Context Protocol (MCP)\nservices have emerged since the end of 2024. However, the effectiveness and\nefficiency of MCP servers have not been well studied. To study these questions,\nwe propose an evaluation framework, called MCPBench. We selected several widely\nused MCP server and conducted an experimental evaluation on their accuracy,\ntime, and token usage. Our experiments showed that the most effective MCP, Bing\nWeb Search, achieved an accuracy of 64%. Importantly, we found that the\naccuracy of MCP servers can be substantially enhanced by involving declarative\ninterface. This research paves the way for further investigations into\noptimized MCP implementations, ultimately leading to better AI-driven\napplications and data retrieval solutions.","main_category":"cs.IR","categories":"cs.IR,cs.DB","published":"2025-04-15T11:40:12Z"}
{"aid":"http://arxiv.org/abs/2504.11115v1","title":"Transient random walks on the space of lattices","summary":"Given $d\\geq2$, we construct a Zariski-dense random walk on the space of\nlattices SL$_d(\\mathbb{R})/$SL$_d(\\mathbb{Z})$ that exhibits escape of mass.\nThis negates the suggestion of recurrence made by Benoist [Ben14] (ICM 2014)\nand by B\\'enard-de Saxc\\'e [BS22] (also asked in [BQ12]). For any $p \\in\n(0,1)$, we also construct such a random walk with finite $L^p$-moment which\nshows that the moment assumption in [BS22] is sharp.","main_category":"math.PR","categories":"math.PR,math.DS","published":"2025-04-15T12:02:29Z"}
{"aid":"http://arxiv.org/abs/2504.11134v1","title":"Visual Re-Ranking with Non-Visual Side Information","summary":"The standard approach for visual place recognition is to use global image\ndescriptors to retrieve the most similar database images for a given query\nimage. The results can then be further improved with re-ranking methods that\nre-order the top scoring images. However, existing methods focus on re-ranking\nbased on the same image descriptors that were used for the initial retrieval,\nwhich we argue provides limited additional signal.\n  In this work we propose Generalized Contextual Similarity Aggregation (GCSA),\nwhich is a graph neural network-based re-ranking method that, in addition to\nthe visual descriptors, can leverage other types of available side information.\nThis can for example be other sensor data (such as signal strength of nearby\nWiFi or BlueTooth endpoints) or geometric properties such as camera poses for\ndatabase images. In many applications this information is already present or\ncan be acquired with low effort. Our architecture leverages the concept of\naffinity vectors to allow for a shared encoding of the heterogeneous\nmulti-modal input. Two large-scale datasets, covering both outdoor and indoor\nlocalization scenarios, are utilized for training and evaluation. In\nexperiments we show significant improvement not only on image retrieval\nmetrics, but also for the downstream visual localization task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T12:37:16Z"}
{"aid":"http://arxiv.org/abs/2504.11142v1","title":"On the dimension of the boundaries of attracting basins of entire maps","summary":"We study the dimension of the boundaries of periodic Fatou components of\ntranscendental entire maps. We prove that if $U$ is an immediate component of\nthe basin of an attracting periodic point $\\zeta$ of period $p\\ge 1$ of a\ntranscendental entire function $f\\colon \\mathbb C \\to \\mathbb C$ from the\nEremenko--Lyubich class $\\mathcal B$, such that $\\text{deg} f^p|_U = \\infty$\nand $\\overline{\\text{Sing}(f^p|_U)}$ is a compact subset of $U$, then the\nhyperbolic (and, consequently, Hausdorff) dimension of the boundary of $U$ is\nlarger than $1$. The same holds if $U$ is an immediate component of the basin\nof a parabolic $p$-periodic point $\\zeta$, under an additional assumption\n$\\zeta \\notin \\overline{\\text{Sing}(f^p)}$. We also show that if $U$ is a\nbounded immediate component of an attracting basin of a transcendental entire\nfunction $f$, then the hyperbolic dimension of the boundary of $U$ is larger\nthan $1$. In particular, this implies that the boundary of a component of an\nattracting basin of a transcendental entire function is never a smooth or\nrectifiable curve.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T12:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.11149v1","title":"An Application of Membrane Computing to Humanitarian Relief via\n  Generalized Nash Equilibrium","summary":"Natural and political disasters, including earthquakes, hurricanes, and\ntsunamis, but also migration and refugees crisis, need quick and coordinated\nresponses in order to support vulnerable populations. In such disasters,\nnongovernmental organizations compete with each other for financial donations,\nwhile people who need assistance suffer a lack of coordination, congestion in\nterms of logistics, and duplication of services. From a theoretical point of\nview, this problem can be formalized as a Generalized Nash Equilibrium (GNE)\nproblem. This is a generalization of the Nash equilibrium problem, where the\nagents' strategies are not fixed but depend on the other agents' strategies. In\nthis paper, we show that Membrane Computing can model humanitarian relief as a\nGNE problem. We propose a family of P systems that compute GNE in this context,\nand we illustrate their capabilities with Hurricane Katrina in 2005 as a case\nstudy.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-15T12:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.11164v1","title":"TSAL: Few-shot Text Segmentation Based on Attribute Learning","summary":"Recently supervised learning rapidly develops in scene text segmentation.\nHowever, the lack of high-quality datasets and the high cost of pixel\nannotation greatly limit the development of them. Considering the\nwell-performed few-shot learning methods for downstream tasks, we investigate\nthe application of the few-shot learning method to scene text segmentation. We\npropose TSAL, which leverages CLIP's prior knowledge to learn text attributes\nfor segmentation. To fully utilize the semantic and texture information in the\nimage, a visual-guided branch is proposed to separately extract text and\nbackground features. To reduce data dependency and improve text detection\naccuracy, the adaptive prompt-guided branch employs effective adaptive prompt\ntemplates to capture various text attributes. To enable adaptive prompts\ncapture distinctive text features and complex background distribution, we\npropose Adaptive Feature Alignment module(AFA). By aligning learnable tokens of\ndifferent attributes with visual features and prompt prototypes, AFA enables\nadaptive prompts to capture both general and distinctive attribute information.\nTSAL can capture the unique attributes of text and achieve precise segmentation\nusing only few images. Experiments demonstrate that our method achieves SOTA\nperformance on multiple text segmentation datasets under few-shot settings and\nshow great potential in text-related domains.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.11171v1","title":"TerraMind: Large-Scale Generative Multimodality for Earth Observation","summary":"We present TerraMind, the first any-to-any generative, multimodal foundation\nmodel for Earth observation (EO). Unlike other multimodal models, TerraMind is\npretrained on dual-scale representations combining both token-level and\npixel-level data across modalities. On a token level, TerraMind encodes\nhigh-level contextual information to learn cross-modal relationships, while on\na pixel level, TerraMind leverages fine-grained representations to capture\ncritical spatial nuances. We pretrained TerraMind on nine geospatial modalities\nof a global, large-scale dataset. In this paper, we demonstrate that (i)\nTerraMind's dual-scale early fusion approach unlocks a range of zero-shot and\nfew-shot applications for Earth observation, (ii) TerraMind introduces\n\"Thinking-in-Modalities\" (TiM) -- the capability of generating additional\nartificial data during finetuning and inference to improve the model output --\nand (iii) TerraMind achieves beyond state-of-the-art performance in\ncommunity-standard benchmarks for EO like PANGAEA. The pretraining dataset, the\nmodel weights, and our code is open-sourced under a permissive license.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T13:17:39Z"}
{"aid":"http://arxiv.org/abs/2504.11177v1","title":"Pressure-Tunable Generalized Wigner Crystal and Fractional Chern\n  Insulator in twisted MoTe$_2$","summary":"Due to the forming of low-energy flat bands, the moir\\'e superlattices of the\ntransition metal dichalcogenides are fascinating platforms for studying novel\ncorrelated states when such flat bands are fractionally filled, with the\nCoulomb interaction dominating. Here, we demonstrate that pressure can\nefficiently tune the flatness and quantum geometry of the single-particle bands\nin twisted bilayer MoTe$_2$ ($\\textit{t}$MoTe$_2$). By fractionally filling the\ntopmost valence band, we find that pressure can act as a flexible means to\nmodulate the fractional Chern insulator (FCI) and the generalized Wigner\ncrystal (GWC) and control their many-body topological phase transitions.\nMoreover, our results indicate a remarkable correspondence between the\nsingle-particle band geometry and the formation of FCI and GWC. As the recent\nexperiments report the presence of FCI phases in $\\textit{t}$MoTe$_2$, our\npredictions could be readily implemented experimentally.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T13:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.11192v1","title":"Field-effect detected magnetic resonance of NV centers in diamond based\n  on all-carbon Schottky contacts","summary":"The nitrogen vacancy (NV) center is a defect in diamond whose spin state can\nbe read optically by exploiting its photoluminescence or electrically by\nexploiting its charge generation rate under illumination, both of which being\nspin-dependent. The latter method offers numerous opportunities in terms of\nintegration and performance compared to conventional optical reading. Here, we\ninvestigate the physical properties of a graphitic-diamond-graphitic structure\nunder illumination. We show how, for a type IIa diamond material, electron-hole\npairs generated by an ensemble of NV centers lead to a p-type material upon\nillumination, making this all-carbon structure equivalent to two back-to-back\nSchottky diodes. We analyze how the reverse current flowing upon illumination\nchanges as a function of bias voltage and radiofrequency-induced excitation of\nthe NV ensemble spin resonances. Furthermore, we demonstrate how an additional\nfield effect arising from the illumination scheme affects the reverse current,\nresulting in a photoelectrical signal that can exceed the optical signal under\nthe same illumination conditions.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-15T13:48:49Z"}
{"aid":"http://arxiv.org/abs/2504.11204v1","title":"BenchQC -- Scalable and modular benchmarking of industrial quantum\n  computing applications","summary":"We present BenchQC, a research project funded by the state of Bavaria, which\npromotes an application-centric perspective for benchmarking real-world quantum\napplications. Diverse use cases from industry consortium members are the\nstarting point of a benchmarking workflow, that builds on the open-source\nplatform QUARK, encompassing the full quantum software stack from the hardware\nprovider interface to the application layer. By identifying and evaluating key\nmetrics across the entire pipeline, we aim to uncover meaningful trends,\nprovide systematic guidance on quantum utility, and distinguish promising\nresearch directions from less viable approaches. Ultimately, this initiative\ncontributes to the broader effort of establishing reliable benchmarking\nstandards that drive the transition from experimental demonstrations to\npractical quantum advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T14:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.11207v1","title":"On deformations of AdS$_3$ solutions, supersymmetry and $G$-structures","summary":"We construct new families of supersymmetric AdS$_3$ solutions in both massive\nand massless Type IIA supergravity via deformations to known backgrounds\npreserving $\\mathcal{N} = (4,0)$ and $\\mathcal{N} = (6,0)$ supersymmetry. These\ndeformations are performed along internal isometries and lead to backgrounds\nwith fully preserved or reduced supersymmetry. Using the formalism of\n$G$-structures, we systematically characterise the resulting geometries and\ntrack the evolution of their supersymmetric properties under the deformation.\nIn particular, we identify transitions among SU(3), SU(2), and identity\nstructures, and demonstrate the preservation of Killing spinors through\nexplicit spinor bilinear constructions. Additionally, we investigate D-brane\nembeddings in the deformed geometries, uncovering stable and supersymmetric\nconfigurations supported by the new backgrounds. Our results offer new insights\ninto the classification of AdS$_3$ flux vacua and provide a concrete framework\nfor understanding their potential holographic duals.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T14:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.11220v1","title":"Test of lepton flavor universality with measurements of $R(D^{+})$ and\n  $R(D^{*+})$ using semileptonic $B$ tagging at the Belle II experiment","summary":"We report measurements of the ratios of branching fractions\n$\\mathcal{R}(D^{(*)+}) = \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\,\\tau^- \\,\n\\overline{\\nu}_\\tau) / \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\, \\ell^- \\,\n\\overline{\\nu}_\\ell)$, where $\\ell$ denotes either an electron or a muon. These\nratios test the universality of the charged-current weak interaction. The\nresults are based on a $365\\, \\mathrm{fb}^{-1}$ data sample collected with the\nBelle II detector at the SuperKEKB $e^+e^-$ collider, which operates at a\ncenter-of-mass energy corresponding to the $\\Upsilon(4S)$ resonance, just above\nthe threshold for $B\\overline{B}{}$ production. Signal candidates are\nreconstructed by selecting events in which the companion $B$ meson from the\n$\\Upsilon(4S) \\to B\\overline{B}{}$ decay is identified in semileptonic modes.\nThe $\\tau$ lepton is reconstructed via its leptonic decays. We obtain\n$\\mathcal{R}(D^+) = 0.418 \\pm 0.074 ~({\\mathrm{stat}}) \\pm 0.051\n~({\\mathrm{syst}})$ and $\\mathcal{R}(D^{*+}) = 0.306 \\pm 0.034\n~({\\mathrm{stat}}) \\pm 0.018 ~({\\mathrm{syst}})$, which are consistent with\nworld average values. Accounting for the correlation between them, these values\ndiffer from the Standard Model expectation by a collective significance of\n$1.7$ standard deviations.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-15T14:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.11241v1","title":"Physics-Aware Initialization Refinement in Code-Aided EM for Blind\n  Channel Estimation","summary":"This paper addresses the well-known local maximum problem of the\nexpectation-maximization (EM) algorithm in blind intersymbol interference (ISI)\nchannel estimation. This problem primarily results from phase and shift\nambiguity during initialization, which blind estimation is inherently unable to\ndistinguish. We propose an effective initialization refinement algorithm that\nutilizes the decoder output as a model selection metric, incorporating a\ntechnique to detect phase and shift ambiguity. Our results show that the\nproposed algorithm significantly reduces the number of local maximum cases to\nnearly one-third for a 3-tap ISI channel under highly uncertain initial\nconditions. The improvement becomes more pronounced as initial errors increase\nand the channel memory grows. When used in a turbo equalizer, the proposed\nalgorithm is required only in the first turbo iteration, which limits any\ncomplexity increase with subsequent iterations.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T14:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.11247v1","title":"Next-Future: Sample-Efficient Policy Learning for Robotic-Arm Tasks","summary":"Hindsight Experience Replay (HER) is widely regarded as the state-of-the-art\nalgorithm for achieving sample-efficient multi-goal reinforcement learning (RL)\nin robotic manipulation tasks with binary rewards. HER facilitates learning\nfrom failed attempts by replaying trajectories with redefined goals. However,\nit relies on a heuristic-based replay method that lacks a principled framework.\nTo address this limitation, we introduce a novel replay strategy,\n\"Next-Future\", which focuses on rewarding single-step transitions. This\napproach significantly enhances sample efficiency and accuracy in learning\nmulti-goal Markov decision processes (MDPs), particularly under stringent\naccuracy requirements -- a critical aspect for performing complex and precise\nrobotic-arm tasks. We demonstrate the efficacy of our method by highlighting\nhow single-step learning enables improved value approximation within the\nmulti-goal RL framework. The performance of the proposed replay strategy is\nevaluated across eight challenging robotic manipulation tasks, using ten random\nseeds for training. Our results indicate substantial improvements in sample\nefficiency for seven out of eight tasks and higher success rates in six tasks.\nFurthermore, real-world experiments validate the practical feasibility of the\nlearned policies, demonstrating the potential of \"Next-Future\" in solving\ncomplex robotic-arm tasks.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.LG","published":"2025-04-15T14:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.11267v1","title":"Optimal control of geometric phase in pairs of interacting atoms\n  traveling along two-dimensional closed paths","summary":"Universal quantum gates whose operation depends on the manipulation of the\ngeometric phase of atomic systems are promising candidates for implementation\nof quantum computing. We propose a scheme inducing a non-trivial\nAharonov-Anandan geometric phase in pairs of atoms interacting via\ndipole-dipole potential. Our protocol relies on mobile optical trap technology\nand consists of steering a single atom along a closed loop. The trajectory of\nthe atom is controlled by a mobile optical trap, and the shape of the path is\ndesigned by applying an optimal control procedure. The geometric phase is\ngenerated as a residual of the two-atom entanglement induced by the\ndipole-dipole interaction. The stability of our scheme in the presence of noise\nor experimental imperfections is discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:06:40Z"}
{"aid":"http://arxiv.org/abs/2504.11268v1","title":"Single-Input Multi-Output Model Merging: Leveraging Foundation Models\n  for Dense Multi-Task Learning","summary":"Model merging is a flexible and computationally tractable approach to merge\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\non constrained multi-task settings where there is a one-to-one mapping between\na sample and a task, overlooking the paradigm where multiple tasks may operate\non the same sample, e.g., scene understanding. In this paper, we focus on the\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\nqualitatively differs from the single-input-single-output model merging\nsettings studied in the literature due to the existence of task-specific\ndecoders and diverse loss objectives. We identify that existing model merging\nmethods lead to significant performance degradation, primarily due to\nrepresentation misalignment between the merged encoder and task-specific\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\nre-align the feature representation after merging. Compared to joint\nfine-tuning, our approach is computationally effective and flexible, and sheds\nlight into identifying task relationships in an offline manner. Experiments on\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\narithmetic suffices to enable multi-task capabilities; however, the\nrepresentations generated by the merged encoder has to be re-aligned with the\ntask-specific heads; (2) the proposed architecture rivals traditional\nmulti-task learning in performance but requires fewer samples and training\nsteps by leveraging the existence of task-specific models.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T15:10:46Z"}
{"aid":"http://arxiv.org/abs/2504.11286v1","title":"Efficient Medical Image Restoration via Reliability Guided Learning in\n  Frequency Domain","summary":"Medical image restoration tasks aim to recover high-quality images from\ndegraded observations, exhibiting emergent desires in many clinical scenarios,\nsuch as low-dose CT image denoising, MRI super-resolution, and MRI artifact\nremoval. Despite the success achieved by existing deep learning-based\nrestoration methods with sophisticated modules, they struggle with rendering\ncomputationally-efficient reconstruction results. Moreover, they usually ignore\nthe reliability of the restoration results, which is much more urgent in\nmedical systems. To alleviate these issues, we present LRformer, a Lightweight\nTransformer-based method via Reliability-guided learning in the frequency\ndomain. Specifically, inspired by the uncertainty quantification in Bayesian\nneural networks (BNNs), we develop a Reliable Lesion-Semantic Prior Producer\n(RLPP). RLPP leverages Monte Carlo (MC) estimators with stochastic sampling\noperations to generate sufficiently-reliable priors by performing multiple\ninferences on the foundational medical image segmentation model, MedSAM.\nAdditionally, instead of directly incorporating the priors in the spatial\ndomain, we decompose the cross-attention (CA) mechanism into real symmetric and\nimaginary anti-symmetric parts via fast Fourier transform (FFT), resulting in\nthe design of the Guided Frequency Cross-Attention (GFCA) solver. By leveraging\nthe conjugated symmetric property of FFT, GFCA reduces the computational\ncomplexity of naive CA by nearly half. Extensive experimental results in\nvarious tasks demonstrate the superiority of the proposed LRformer in both\neffectiveness and efficiency.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-15T15:26:28Z"}
{"aid":"http://arxiv.org/abs/2504.11291v1","title":"Policy heterogeneity improves collective olfactory search in 3-D\n  turbulence","summary":"We investigate the role of policy heterogeneity in enhancing the olfactory\nsearch capabilities of cooperative agent swarms operating in complex,\nreal-world turbulent environments. Using odor fields from direct numerical\nsimulations of the Navier-Stokes equations, we demonstrate that heterogeneous\ngroups, with exploratory and exploitative agents, consistently outperform\nhomogeneous swarms where the exploration-exploitation tradeoff is managed at\nthe individual level. Our results reveal that policy diversity enables the\ngroup to reach the odor source more efficiently by mitigating the detrimental\neffects of spatial correlations in the signal. These findings provide new\ninsights into collective search behavior in biological systems and offer\npromising strategies for the design of robust, bioinspired search algorithms in\nengineered systems.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph,physics.data-an","published":"2025-04-15T15:31:11Z"}
{"aid":"http://arxiv.org/abs/2504.11304v1","title":"Differentially Private Geodesic and Linear Regression","summary":"In statistical applications it has become increasingly common to encounter\ndata structures that live on non-linear spaces such as manifolds. Classical\nlinear regression, one of the most fundamental methodologies of statistical\nlearning, captures the relationship between an independent variable and a\nresponse variable which both are assumed to live in Euclidean space. Thus,\ngeodesic regression emerged as an extension where the response variable lives\non a Riemannian manifold. The parameters of geodesic regression, as with linear\nregression, capture the relationship of sensitive data and hence one should\nconsider the privacy protection practices of said parameters. We consider\nreleasing Differentially Private (DP) parameters of geodesic regression via the\nK-Norm Gradient (KNG) mechanism for Riemannian manifolds. We derive theoretical\nbounds for the sensitivity of the parameters showing they are tied to their\nrespective Jacobi fields and hence the curvature of the space. This\ncorroborates recent findings of differential privacy for the Fr\\'echet mean. We\ndemonstrate the efficacy of our methodology on the sphere,\n$\\mbS^2\\subset\\mbR^3$ and, since it is general to Riemannian manifolds, the\nmanifold of Euclidean space which simplifies geodesic regression to a case of\nlinear regression. Our methodology is general to any Riemannian manifold and\nthus it is suitable for data in domains such as medical imaging and computer\nvision.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-15T15:45:48Z"}
{"aid":"http://arxiv.org/abs/2504.11336v1","title":"Looking beyond the next token","summary":"The structure of causal language model training assumes that each token can\nbe accurately predicted from the previous context. This contrasts with humans'\nnatural writing and reasoning process, where goals are typically known before\nthe exact argument or phrasings. While this mismatch has been well studied in\nthe literature, the working assumption has been that architectural changes are\nneeded to address this mismatch. We argue that rearranging and processing the\ntraining data sequences can allow models to more accurately imitate the true\ndata-generating process, and does not require any other changes to the\narchitecture or training infrastructure. We demonstrate that this technique,\nTrelawney, and the inference algorithms derived from it allow us to improve\nperformance on several key benchmarks that span planning, algorithmic\nreasoning, and story generation tasks. Finally, our method naturally enables\nthe generation of long-term goals at no additional cost. We investigate how\nusing the model's goal-generation capability can further improve planning and\nreasoning. Additionally, we believe Trelawney could potentially open doors to\nnew capabilities beyond the current language modeling paradigm.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-15T16:09:06Z"}
{"aid":"http://arxiv.org/abs/2504.11387v1","title":"On the distribution of the telegraph meander and its properties","summary":"In this paper we present the distribution of the telegraph meander, a random\nfunction obtained by conditioning the telegraph process to stay above the zero\nlevel. The reflection principle for finite-velocity random motions allows the\nlaw of the telegraph meander to be expressed in terms of the spatial derivative\nof the law of the telegraph process with initial negative velocity. As a\nresult, we are able to obtain the characteristic function, the moments and the\nhyperbolic equation that governs the law of the telegraph meander. Furthermore,\nwe prove that Brownian meander is the weak limit of the telegraph meander.","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T16:57:41Z"}
{"aid":"http://arxiv.org/abs/2504.11424v1","title":"MINDS. Anatomy of a water-rich, inclined, brown dwarf disk: lack of\n  abundant hydrocarbons","summary":"2MASS J04381486+2611399 (or J0438) is one of the few young brown dwarfs (BD)\nwith a highly inclined ($i\\!\\sim\\!70^\\circ$) disk. Here we report results from\nJWST-MIRI MRS, HST-ACS and ALMA Band 7 observations. Despite its late spectral\ntype (M7.25), the spectrum of J0438 resembles those of inner disks around\nearlier-type stars (K1-M5, T Tauri stars), with a volatile reservoir lacking\nhydrocarbons (except for acetylene, C$_2$H$_2$) and dominated by water. Other\nidentified species are H$_2$, CO$_2$, HCN, [Ar$^{+}$], and [Ne$^{+}$]. The\ndominance of water over hydrocarbons is driven by multiple factors such as disk\ndynamics, young disk age, low accretion rate and possible inner disk clearing.\nJ0438 appears highly dynamic, showing a seesaw-like variability and extended\nemission in H$_2 \\,\\,\\, S$(1), $S$(3), $S$(5), [Ne$^{+}$] and CO ($J=3-2$).\nInterestingly, the CO emission reaches up to 400 au from the brown dwarf,\nsuggesting ongoing infalling/outflowing activity impacting the disk chemistry.\nThese observations underscore the combined power of JWST, HST and ALMA in\ncharacterizing the chemical diversity and dynamics of brown dwarf disks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA,astro-ph.SR","published":"2025-04-15T17:37:59Z"}
{"aid":"http://arxiv.org/abs/2504.11754v1","title":"GrabS: Generative Embodied Agent for 3D Object Segmentation without\n  Scene Supervision","summary":"We study the hard problem of 3D object segmentation in complex point clouds\nwithout requiring human labels of 3D scenes for supervision. By relying on the\nsimilarity of pretrained 2D features or external signals such as motion to\ngroup 3D points as objects, existing unsupervised methods are usually limited\nto identifying simple objects like cars or their segmented objects are often\ninferior due to the lack of objectness in pretrained features. In this paper,\nwe propose a new two-stage pipeline called GrabS. The core concept of our\nmethod is to learn generative and discriminative object-centric priors as a\nfoundation from object datasets in the first stage, and then design an embodied\nagent to learn to discover multiple objects by querying against the pretrained\ngenerative priors in the second stage. We extensively evaluate our method on\ntwo real-world datasets and a newly created synthetic dataset, demonstrating\nremarkable segmentation performance, clearly surpassing all existing\nunsupervised methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.RO","published":"2025-04-16T04:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.11758v1","title":"Hardy spaces, Campanato spaces and higher order Riesz transforms\n  associated with Bessel operators","summary":"Let $\\nu = (\\nu_1, \\ldots, \\nu_n) \\in (-1/2, \\infty)^n$, with $n \\ge 1$, and\nlet $\\Delta_\\nu$ be the multivariate Bessel operator defined by\n  \\[\n  \\Delta_{\\nu} = -\\sum_{j=1}^n\\left( \\frac{\\partial^2}{\\partial x_j^2} -\n\\frac{\\nu_j^2 - 1/4}{x_j^2} \\right).\n  \\]\n  In this paper, we develop the theory of Hardy spaces and BMO-type spaces\nassociated with the Bessel operator $\\Delta_\\nu$. We then study the\nhigher-order Riesz transforms associated with $\\Delta_\\nu$. First, we show that\nthese transforms are Calder\\'on-Zygmund operators. We further prove that they\nare bounded on the Hardy spaces and BMO-type spaces associated with\n$\\Delta_\\nu$.","main_category":"math.CA","categories":"math.CA","published":"2025-04-16T04:34:41Z"}
{"aid":"http://arxiv.org/abs/2504.11761v1","title":"Delayed Acceptance Markov Chain Monte Carlo for Robust Bayesian Analysis","summary":"This study introduces a computationally efficient algorithm, delayed\nacceptance Markov chain Monte Carlo (DA-MCMC), designed to improve posterior\nsimulation in quasi-Bayesian inference. Quasi-Bayesian methods, which do not\nrequire fully specifying a probabilistic model, are often computationally\nexpensive owing to the need to evaluate the inverse and determinant of large\ncovariance matrices. DA-MCMC addresses this challenge by employing a two-stage\nprocess: In the first stage, proposals are screened using an approximate\nposterior, whereas a final acceptance or rejection decision is made in the\nsecond stage based on the exact target posterior. This reduces the need for\ncostly matrix computations, thereby improving efficiency without sacrificing\naccuracy. We demonstrate the effectiveness of DA-MCMC through applications to\nboth synthetic and real data. The results demonstrate that, although DA-MCMC\nslightly reduces the effective sample size per iteration compared with the\nstandard MCMC, it achieves substantial improvement in terms of effective sample\nsize per second, approximately doubling the efficiency. This makes DA-MCMC\nparticularly useful for cases where posterior simulation is computationally\nintensive. Thus, the DA-MCMC algorithm offers a significant advancement in\ncomputational efficiency for quasi-Bayesian inference, making it a valuable\ntool for robust Bayesian analysis.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-16T04:40:17Z"}
{"aid":"http://arxiv.org/abs/2504.11771v1","title":"Design and Continuation of Nonlinear Teardrop Hovering Formation along\n  the Near Rectilinear Halo Orbit","summary":"This short communication is devoted to the design and continuation of a\nteardrop hovering formation along the Near Rectilinear Halo orbit and provides\nfurther insights into future on-orbit services in the cislunar space. First, we\nextend the concept of the teardrop hovering formation to scenarios along the\nNear Rectilinear Halo orbit in the Earth-Moon circular restricted three-body\nproblem. Then, we develop two methods for designing these formations based on\nthe nonlinear model for relative motion. The first method addresses the design\nof the teardrop hovering formations with relatively short revisit distances,\nwhile the second method continues hovering trajectories from short to longer\nrevisit distances. In particular, new continuation method is developed to meet\nthe design requirements of this new scenario. Simulation results verify the\neffectiveness of the proposed methods, and a near-natural teardrop hovering\nformation is achieved by considering the dynamical properties near the NRHO.\nComparisons between design results obtained using linear and nonlinear models\nfurther strengthen the necessity of using the nonlinear model.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T05:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.11772v1","title":"Admissible subcategories and metric techniques","summary":"In this work, we provide a way of constructing new semiorthogonal\ndecompositions using metric techniques (\\`a la Neeman). Given a semiorthogonal\ndecomposition on a category with a special kind of metric, which we call a\ncompressible metric, we can construct new semiorthogonal decomposition on a\ncategory constructed from the given one using the aforementioned metric. In the\nalgebro-geometric setting, this gives us a way of producing new semiorthogonal\ndecompositions on various small triangulated categories associated to a scheme,\nif we are given one. In the general setting, the work is related to that of\nSun-Zhang, while its applications to algebraic geometry are related to the work\nof Bondarko and Kuznetsov-Shinder.","main_category":"math.AG","categories":"math.AG,math.CT","published":"2025-04-16T05:24:55Z"}
{"aid":"http://arxiv.org/abs/2504.11786v1","title":"DART: Disease-aware Image-Text Alignment and Self-correcting\n  Re-alignment for Trustworthy Radiology Report Generation","summary":"The automatic generation of radiology reports has emerged as a promising\nsolution to reduce a time-consuming task and accurately capture critical\ndisease-relevant findings in X-ray images. Previous approaches for radiology\nreport generation have shown impressive performance. However, there remains\nsignificant potential to improve accuracy by ensuring that retrieved reports\ncontain disease-relevant findings similar to those in the X-ray images and by\nrefining generated reports. In this study, we propose a Disease-aware\nimage-text Alignment and self-correcting Re-alignment for Trustworthy radiology\nreport generation (DART) framework. In the first stage, we generate initial\nreports based on image-to-text retrieval with disease-matching, embedding both\nimages and texts in a shared embedding space through contrastive learning. This\napproach ensures the retrieval of reports with similar disease-relevant\nfindings that closely align with the input X-ray images. In the second stage,\nwe further enhance the initial reports by introducing a self-correction module\nthat re-aligns them with the X-ray images. Our proposed framework achieves\nstate-of-the-art results on two widely used benchmarks, surpassing previous\napproaches in both report generation and clinical efficacy metrics, thereby\nenhancing the trustworthiness of radiology reports.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:39:08Z"}
{"aid":"http://arxiv.org/abs/2504.11795v1","title":"Schemex: Interactive Structural Abstraction from Examples with\n  Contrastive Refinement","summary":"Each type of creative or communicative work is underpinned by an implicit\nstructure. People learn these structures from examples - a process known in\ncognitive science as schema induction. However, inducing schemas is\nchallenging, as structural patterns are often obscured by surface-level\nvariation. We present Schemex, an interactive visual workflow that scaffolds\nschema induction through clustering, abstraction, and contrastive refinement.\nSchemex supports users through visual representations and interactive\nexploration that connect abstract structures to concrete examples, promoting\ntransparency, adaptability, and effective human-AI collaboration. In our user\nstudy, participants reported significantly greater insight and confidence in\nthe schemas developed with Schemex compared to those created using a baseline\nof an AI reasoning model. We conclude by discussing the broader implications of\nstructural abstraction and contrastive refinement across domains.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-16T06:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.11808v1","title":"Federated Spectral Graph Transformers Meet Neural Ordinary Differential\n  Equations for Non-IID Graphs","summary":"Graph Neural Network (GNN) research is rapidly advancing due to GNNs'\ncapacity to learn distributed representations from graph-structured data.\nHowever, centralizing large volumes of real-world graph data for GNN training\nis often impractical due to privacy concerns, regulatory restrictions, and\ncommercial competition. Federated learning (FL), a distributed learning\nparadigm, offers a solution by preserving data privacy with collaborative model\ntraining. Despite progress in training huge vision and language models,\nfederated learning for GNNs remains underexplored. To address this challenge,\nwe present a novel method for federated learning on GNNs based on spectral GNNs\nequipped with neural ordinary differential equations (ODE) for better\ninformation capture, showing promising results across both homophilic and\nheterophilic graphs. Our approach effectively handles non-Independent and\nIdentically Distributed (non-IID) data, while also achieving performance\ncomparable to existing methods that only operate on IID data. It is designed to\nbe privacy-preserving and bandwidth-optimized, making it suitable for\nreal-world applications such as social network analysis, recommendation\nsystems, and fraud detection, which often involve complex, non-IID, and\nheterophilic graph structures. Our results in the area of federated learning on\nnon-IID heterophilic graphs demonstrate significant improvements, while also\nachieving better performance on homophilic graphs. This work highlights the\npotential of federated learning in diverse and challenging graph settings.\nOpen-source code available on GitHub\n(https://github.com/SpringWiz11/Fed-GNODEFormer).","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T06:43:20Z"}
{"aid":"http://arxiv.org/abs/2504.11810v1","title":"Light WIMPs and MeV Gamma-ray Detection with COSI","summary":"Light weakly interacting massive particles (WIMPs), whose masses are in the\nsub-GeV scale, have been attracting more attention due to the negative results\nsearching for traditional WIMPs. The light WIMPs are expected to produce gamma\nrays from annihilation in the MeV energy region. Advancements in technology\nhave opened up possibilities to precisely detect MeV gamma rays, leading to the\nupcoming space-based mission of the Compton Spectrometer and Imager (COSI). We\ncomprehensively and quantitatively study the phenomenology of light WIMPs to\ndetermine if the COSI observations will probe their viable model parameter\nregions. We first construct models to describe light WIMPs based on the\nminimality and renormalizability of quantum field theory. Next, we impose\nvarious constraints on the models obtained from cosmological observations (CMB,\nBBN) and dark matter searches (accelerator, underground, astrophysical\nexperiments, etc.). Finally, we identify viable parameter regions in each model\nand discuss whether or not COSI will be sensitive to the parameter regions. We\nfind that a velocity-dependent annihilation cross-section is predicted in some\nregions, enabling COSI to detect the dark matter signal while avoiding severe\nconstraints from cosmological observations.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE","published":"2025-04-16T06:48:42Z"}
{"aid":"http://arxiv.org/abs/2504.11832v1","title":"Generation of Paths for Motion Planning for a Dubins Vehicle on Sphere","summary":"In this article, the candidate optimal paths for a Dubins vehicle on a sphere\nare analytically derived. In particular, the arc angles for segments in $CGC$,\n$CCC$, $CCCC$, and $CCCCC$ paths, which have previously been shown to be\noptimal depending on the turning radius $r$ of the vehicle by Kumar \\textit{et\nal.}, are analytically derived. The derived expressions are used for the\nimplementation provided in\nhttps://github.com/DeepakPrakashKumar/Motion-planning-on-sphere.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T07:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.11841v1","title":"Permutation dimensions of prime cyclic groups","summary":"Based on recent successes concerning permutation resolutions of\nrepresentations by Balmer and Gallauer we define a new invariant of finite\ngroups: the p-permutation dimension. We compute this invariant for cyclic\ngroups of prime order.","main_category":"math.RT","categories":"math.RT","published":"2025-04-16T08:00:36Z"}
{"aid":"http://arxiv.org/abs/2504.11843v1","title":"Scalable Multi-task Edge Sensing via Task-oriented Joint Information\n  Gathering and Broadcast","summary":"The recent advance of edge computing technology enables significant sensing\nperformance improvement of Internet of Things (IoT) networks. In particular, an\nedge server (ES) is responsible for gathering sensing data from distributed\nsensing devices, and immediately executing different sensing tasks to\naccommodate the heterogeneous service demands of mobile users. However, as the\nnumber of users surges and the sensing tasks become increasingly\ncompute-intensive, the huge amount of computation workloads and data\ntransmissions may overwhelm the edge system of limited resources. Accordingly,\nwe propose in this paper a scalable edge sensing framework for multi-task\nexecution, in the sense that the computation workload and communication\noverhead of the ES do not increase with the number of downstream users or\ntasks. By exploiting the task-relevant correlations, the proposed scheme\nimplements a unified encoder at the ES, which produces a common low-dimensional\nmessage from the sensing data and broadcasts it to all users to execute their\nindividual tasks. To achieve high sensing accuracy, we extend the well-known\ninformation bottleneck theory to a multi-task scenario to jointly optimize the\ninformation gathering and broadcast processes. We also develop an efficient\ntwo-step training procedure to optimize the parameters of the neural\nnetwork-based codecs deployed in the edge sensing system. Experiment results\nshow that the proposed scheme significantly outperforms the considered\nrepresentative benchmark methods in multi-task inference accuracy. Besides, the\nproposed scheme is scalable to the network size, which maintains almost\nconstant computation delay with less than 1% degradation of inference\nperformance when the user number increases by four times.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T08:06:46Z"}
{"aid":"http://arxiv.org/abs/2504.11905v1","title":"A Novel Splitter Design for RSMA Networks","summary":"Rate splitting multiple access (RSMA) has firmly established itself as a\npowerful methodology for multiple access, interference management, and\nmulti-user strategy for next-generation communication systems. In this paper,\nwe propose a novel channel-dependent splitter design for multi-carrier RSMA\nsystems, aimed at improving reliability performance. Specifically, the proposed\nsplitter leverages channel state information and the inherent structure of RSMA\nto intelligently replicate segments of the private stream data that are likely\nto encounter deep-faded subchannels into the common stream. Thus, the\nreliability is enhanced within the same transmission slot, minimizing the need\nfor frequent retransmissions and thereby reducing latency. To assess the\neffectiveness of our approach, we conduct comprehensive evaluations using key\nperformance metrics, including achievable sum rate, average packet delay, and\nbit error rate (BER), under both perfect and imperfect channel estimation\nscenarios.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-16T09:30:02Z"}
{"aid":"http://arxiv.org/abs/2504.11910v1","title":"The role of wild birds in the global highly pathogenic avian influenza\n  H5 panzootic","summary":"The highly pathogenic avian influenza (HPAI) H5 clade 2.3.4.4b has triggered\nan unprecedented global panzootic. As the frequency and scale of HPAI H5\noutbreaks continue to rise, understanding how wild birds contribute to shape\nthe global virus spread across regions, affecting poultry, domestic and wild\nmammals, is increasingly critical. In this review, we examine ecological and\nevolutionary studies to map the global transmission routes of HPAI H5 viruses,\nidentify key wild bird species involved in viral dissemination, and explore\ninfection patterns, including mortality and survival. We also highlight major\nremaining knowledge gaps that hinder a full understanding of wild birds role in\nviral dynamics, which must be addressed to enhance surveillance strategies and\nrefine risk assessment models aimed at preventing future outbreaks in wildlife,\ndomestic animals and safeguard public health.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-16T09:42:40Z"}
{"aid":"http://arxiv.org/abs/2504.11916v1","title":"Non-vanishing of Dirichlet $L$-functions at the Central Point","summary":"We prove that for at least $\\frac{7}{19}$ of the primitive Dirichlet\ncharacters $\\chi$ with large general modulus, the central value\n$L(\\frac12,\\chi)$ is non-vanishing.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T09:54:28Z"}
{"aid":"http://arxiv.org/abs/2504.11932v1","title":"Technological Complexity Based on Japanese Patent Data","summary":"As international competition intensifies in technologies, nations need to\nidentify key technologies to foster innovation. However, the identification is\ndifficult because a technology is independent, therefore has complex nature.\nHere, this study aims to assess patent technological fields by applying\nTechnological Complexity Index from a corporate perspective, addressing its\nunderutilization in Japan despite its potential. By utilizing carefully\nprocessed patent data from fiscal years 1981 to 2010, we analyze the bipartite\nnetwork which consists of 1,938 corporations and 35 or 124 technological\nfields. Our findings provide quantitative characteristics of ubiquity and\nsophistication for patent fields, the detailed technological trends that\nreflect the social context, and methodological stability for policymakers and\nresearchers, contributing to targeted innovation strategies in Japan.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-16T10:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.11937v1","title":"Complete Classification of the Symmetry Groups of Monge-AmpÃ¨re\n  Equation and Affine Maximal type Equation","summary":"The affine maximal type hypersurface has been a core topic in Affine\nGeometry. When the hypersurface is presented as a regular graph of a convex\nfunction $u$, the statement that the graph is of affine maximal type is\nequivalent to the statement that $u$ satisfies the fully nonlinear partial\ndifferential equation\n  $$\n  D_{ij}(U^{ij}w)=0, \\ \\ w\\equiv[\\det D^2u]^{-\\theta}, \\ \\ \\theta>0, \\ \\\n\\forall x\\in{\\mathbb{R}}^N\n  $$ of fourth order. This equation can be regarded as a generalization of the\n$N$-dimensional Monge-Amp\\`{e}re equation\n  $$\n  \\det D^2u=1, \\ \\ \\forall x\\in{\\mathbb{R}}^N\n  $$ of second order, since each solution of Monge-Amp\\`{e}re Equation\nsatisfies affine maximal type equation automatically. In this paper, we will\ndetermine the symmetry groups of these two important fully nonlinear equations\nwithout asymptotic growth assumption. Our method develops the Lie's theory to\nfully nonlinear PDEs.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T10:16:28Z"}
{"aid":"http://arxiv.org/abs/2504.11941v1","title":"Admissible matchings and the Castelnuovo-Mumford regularity of\n  square-free powers","summary":"Let $I$ be any square-free monomial ideal, and $\\mathcal{H}_I$ denote the\nhypergraph associated with $I$. Refining the concept of $k$-admissible matching\nof a graph defined by Erey and Hibi, we introduce the notion of generalized\n$k$-admissible matching for any hypergraph. Using this, we give a sharp lower\nbound on the (Castelnuovo-Mumford) regularity of $I^{[k]}$, where $I^{[k]}$\ndenotes the $k^{\\text{th}}$ square-free power of $I$. In the special case when\n$I$ is equigenerated in degree $d$, this lower bound can be described using a\ncombinatorial invariant $\\mathrm{aim}(\\mathcal{H}_I,k)$, called the\n$k$-admissible matching number of $\\mathcal{H}_I$. Specifically, we prove that\n$\\mathrm{reg}(I^{[k]})\\ge (d-1)\\mathrm{aim}(\\mathcal{H}_I,k)+k$, whenever\n$I^{[k]}$ is non-zero. Even for the edge ideal $I(G)$ of a graph $G$, it turns\nout that $\\mathrm{aim}(G,k)+k$ is the first general lower bound for the\nregularity of $I(G)^{[k]}$. In fact, when $G$ is a forest, $\\mathrm{aim}(G,k)$\ncoincides with the $k$-admissible matching number introduced by Erey and Hibi.\nNext, we show that if $G$ is a block graph, then $\\mathrm{reg}(I(G)^{[k]})=\n\\mathrm{aim}(G,k)+k$, and this result can be seen as a generalization of the\ncorresponding regularity formula for forests. Additionally, for a\nCohen-Macaulay chordal graph $G$, we prove that $\\mathrm{reg}(I(G)^{[2]})=\n\\mathrm{aim}(G,2)+2$. Finally, we propose a conjecture on the regularity of\nsquare-free powers of edge ideals of chordal graphs.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-16T10:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.11942v1","title":"ADAT: Time-Series-Aware Adaptive Transformer Architecture for Sign\n  Language Translation","summary":"Current sign language machine translation systems rely on recognizing hand\nmovements, facial expressions and body postures, and natural language\nprocessing, to convert signs into text. Recent approaches use Transformer\narchitectures to model long-range dependencies via positional encoding.\nHowever, they lack accuracy in recognizing fine-grained, short-range temporal\ndependencies between gestures captured at high frame rates. Moreover, their\nhigh computational complexity leads to inefficient training. To mitigate these\nissues, we propose an Adaptive Transformer (ADAT), which incorporates\ncomponents for enhanced feature extraction and adaptive feature weighting\nthrough a gating mechanism to emphasize contextually relevant features while\nreducing training overhead and maintaining translation accuracy. To evaluate\nADAT, we introduce MedASL, the first public medical American Sign Language\ndataset. In sign-to-gloss-to-text experiments, ADAT outperforms the\nencoder-decoder transformer, improving BLEU-4 accuracy by 0.1% while reducing\ntraining time by 14.33% on PHOENIX14T and 3.24% on MedASL. In sign-to-text\nexperiments, it improves accuracy by 8.7% and reduces training time by 2.8% on\nPHOENIX14T and achieves 4.7% higher accuracy and 7.17% faster training on\nMedASL. Compared to encoder-only and decoder-only baselines in sign-to-text,\nADAT is at least 6.8% more accurate despite being up to 12.1% slower due to its\ndual-stream structure.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV","published":"2025-04-16T10:20:11Z"}
{"aid":"http://arxiv.org/abs/2504.11957v1","title":"Unconditional robustness of multipartite entanglement of superposition","summary":"We study the robustness of genuine multipartite entanglement and\ninseparability of multipartite pure states under superposition with product\npure states. We introduce the concept of the maximal and the minimal Schmidt\nranks for multipartite states. From the minimal Schmidt rank of the first order\nwe present criterion of verifying unconditional robustness of genuine\nmultipartite entanglement of multipartite pure states under superposition with\nproduct pure states. By the maximal Schmidt rank of the first order we verify\nthe unconditional robustness of multipartite inseparability under superposition\nwith product pure states. The number of product states superposed to a given\nentangled state which result in a separable state is investigated in detail.\nFurthermore, the minimal Schmidt ranks of the second order are also introduced\nto identify the unconditional robustness of an entangled state for tripartite\ninseparability.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T10:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.11993v1","title":"New Three Different Generators for Constructing New Three Different\n  Bivariate Copulas","summary":"In this paper, the author introduces new methods to construct Archimedean\ncopulas. The generator of each copula fulfills the sufficient conditions as\nregards the boundary and being continuous, decreasing, and convex. Each inverse\ngenerator also fulfills the necessary conditions as regards the boundary\nconditions, marginal uniformity, and 2-increasing properties. Although these\ncopulas satisfy these conditions, they have some limitations. They do not cover\nthe entire dependency spectrum, ranging from perfect negative dependency to\nperfect positive dependency, passing through the independence state","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-16T11:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.12004v1","title":"Scaled Block Vecchia Approximation for High-Dimensional Gaussian Process\n  Emulation on GPUs","summary":"Emulating computationally intensive scientific simulations is essential to\nenable uncertainty quantification, optimization, and decision-making at scale.\nGaussian Processes (GPs) offer a flexible and data-efficient foundation for\nstatistical emulation, but their poor scalability limits applicability to large\ndatasets. We introduce the Scaled Block Vecchia (SBV) algorithm for distributed\nGPU-based systems. SBV integrates the Scaled Vecchia approach for anisotropic\ninput scaling with the Block Vecchia (BV) method to reduce computational and\nmemory complexity while leveraging GPU acceleration techniques for efficient\nlinear algebra operations. To the best of our knowledge, this is the first\ndistributed implementation of any Vecchia-based GP variant. Our implementation\nemploys MPI for inter-node parallelism and the MAGMA library for\nGPU-accelerated batched matrix computations. We demonstrate the scalability and\nefficiency of the proposed algorithm through experiments on synthetic and\nreal-world workloads, including a 50M point simulation from a respiratory\ndisease model. SBV achieves near-linear scalability on up to 64 A100 and GH200\nGPUs, handles 320M points, and reduces energy use relative to exact GP solvers,\nestablishing SBV as a scalable and energy-efficient framework for emulating\nlarge-scale scientific models on GPU-based distributed systems.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-16T11:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.12049v1","title":"Impact of spin correlations on resistivity and microwave absorption of\n  Ba(Fe$_{1-x}$Co$_x$)$_2$As$_2$","summary":"The results of studies of BaFe$_2$As$_2$ single crystals doped with cobalt by\nmeans of resistivity and microwave absorption measurement are reported. A\ntheoretical description of the behavior of the microwave absorption amplitude\nis made taking into account the temperature dependence of resistivity, magnetic\nsusceptibility and the lifetime of spin fluctuations. An assumption has been\nmade that the deviation from the linear dependence of resistivity on\ntemperature at $T<100$ K is not related to the electron-electron scattering\nmechanism, but it is due to the appearance of nematic fluctuations. Estimates\nof the rate of scattering by spin fluctuations indicate their nematic nature at\ntemperatures near the structural transition.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T13:04:29Z"}
{"aid":"http://arxiv.org/abs/2504.12052v1","title":"Bayesian dynamic borrowing considering semantic similarity between\n  outcomes for disproportionality analysis in FAERS","summary":"We present a Bayesian dynamic borrowing (BDB) approach to enhance the\nquantitative identification of adverse events (AEs) in spontaneous reporting\nsystems (SRSs). The method embeds a robust meta-analytic predictive (MAP) prior\nwithin a Bayesian hierarchical model and incorporates semantic similarity\nmeasures (SSMs) to enable weighted information sharing from MedDRA Preferred\nTerms (PTs) that are clinical similar to the target PT. This continuous\nsimilarity-based borrowing addresses limitation of rigid hierarchical grouping\nin current disproportionality analysis (DPA).\n  Using data from the FDA Adverse Event Reporting System (FAERS) between 2015\nand 2019, we evalute this approach - termed IC SSM - against standard\nInformation Component (IC) analysis and IC with borrowing at the MedDRA\nhigh-level group term (HLGT) level. A novel references set (PVLens), derived\nfrom FDA product label updates, enabled prospective evaluation of method\nperformance in identifying AEs prior to official labeling.\n  The IC SSM approach demonstrated improved sensitivity compared to both\ntraditional IC and HLGT-based borrowing, with minor trade-offs in F1 scores and\nYouden's index. IC SSM consistently identified more true positives and detected\nsignals over 5 months sooner than traditional IC. Despite a marginally lower\naggregate Youden's index, IC SSM showed higher performance in the early\npost-marketing period, providing more stable and relevant estimates than\nHLGT-based borrowing and traditional IC.\n  These findings support the use of SSM-informed Bayesian borrowing as a\nscalable and context-aware enhancement to traditional DPA methods. Future\nresearch should validate this approach across other datasets and explore\nadditional similarity metrics and Bayesian inference strategies using\ncase-level data.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T13:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.12064v1","title":"One-stage hollow-core fiber-based compression of Yb:KGW lasers to the\n  single-cycle regime","summary":"The generation of intense, waveform-controlled, single-cycle pulses based on\nYb:KGW amplifiers is central to integrating these lasers with attosecond\nmetrology and spectroscopy. Here, we demonstrate single-stage, multi-octave (~\n2.4 octaves) spectral broadening of Yb:KGW amplified pulses in a\nneon-pressurized hollow-core fiber (HCF) capillary and their compression to the\nsingle-cycle regime (1.1 cycles at 880 nm) using chirped mirrors. Utilizing\nHomochromatic Attosecond Streaking (HAS), we characterize the field waveforms\nof the generated pulses and demonstrate precise control of their\ncarrier-envelope phase. Our results provide a simplified route to single-cycle\npulse generation using Yb:KGW technology, previously possible only with\nTi:Sapphire-based front ends. This work paves the way for advanced applications\nin attosecond science, strong-field physics, and spectroscopy.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-16T13:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.12099v1","title":"Logical multi-qubit entanglement with dual-rail superconducting qubits","summary":"Recent advances in quantum error correction (QEC) across hardware platforms\nhave demonstrated operation near and beyond the fault-tolerance threshold, yet\nachieving exponential suppression of logical errors through code scaling\nremains a critical challenge. Erasure qubits, which enable hardware-level\ndetection of dominant error types, offer a promising path toward\nresource-efficient QEC by exploiting error bias. Single erasure qubits with\ndual-rail encoding in superconducting cavities and transmons have demonstrated\nhigh coherence and low single-qubit gate errors with mid-circuit erasure\ndetection, but the generation of multi-qubit entanglement--a fundamental\nrequirement for quantum computation and error correction--has remained an\noutstanding milestone. Here, we demonstrate a superconducting processor\nintegrating four dual-rail erasure qubits that achieves the logical multi-qubit\nentanglement with error-biased protection. Each dual-rail qubit, encoded in\npairs of tunable transmons, preserves millisecond-scale coherence times and\nsingle-qubit gate errors at the level of $10^{-5}$. By engineering tunable\ncouplings between logical qubits, we generate high-fidelity entangled states\nresilient to physical qubit noise, including logical Bell states (98.8%\nfidelity) and a three-logical-qubit Greenberger-Horne-Zeilinger (GHZ) state\n(93.5% fidelity). A universal gate set is realized through a calibrated logical\ncontrolled-NOT (CNOT) gate with 96.2% process fidelity, enabled by\ncoupler-activated $XX$ interactions in the protected logical subspace. This\nwork advances dual-rail architectures beyond single-qubit demonstrations,\nproviding a blueprint for concatenated quantum error correction with erasure\nqubits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T14:02:30Z"}
{"aid":"http://arxiv.org/abs/2504.12118v1","title":"Unraveling the origin of giant exoplanets -- Observational implications\n  of convective mixing","summary":"The connection between the atmospheric composition of giant planets and their\norigin remains elusive. In this study, we explore how convective mixing can\nlink the planetary primordial state to its atmospheric composition. We simulate\nthe long-term evolution of gas giants with masses between 0.3 and 3 Jupiter\nmasses, considering various composition profiles and primordial entropies\n(assuming no entropy-mass dependence). Our results show that when convective\nmixing is considered, the atmospheric metallicity increases with time and that\nthis time evolution encodes information about the planetary primordial\nstructure. Additionally, the degree of compositional mixing affects the\nplanetary radius, altering its evolution in a measurable way. By applying mock\nobservations, we demonstrate that combining radius and atmospheric composition\ncan help to constrain the planetary formation history. Young systems emerge as\nprime targets for such characterization, with lower-mass gas giants\n(approaching Saturn's mass) being particularly susceptible to mixing-induced\nchanges. Our findings highlight convective mixing as a key mechanism for\nprobing the primordial state of giant planets, offering new constraints on\nformation models and demonstrating that the conditions inside giant planets\nshortly after their formation are not necessarily erased over billions of years\nand can leave a lasting imprint on their evolution.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-16T14:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.12131v1","title":"Equidistribution of CM points on Shimura Curves and ternary theta series","summary":"We prove an equidistribution statement for the reduction of Galois orbits of\nCM points on the special fiber of a Shimura curve over a totally real field,\nconsidering both the split and the ramified case. The main novelty of the\nramified case consists in the use of the moduli interpretation of the\nCerednik--Drinfeld uniformisation. Our result is achieved by associating to the\nreduction of CM points certain Hilbert modular forms of weight $3/2$ and by\nanalyzing their Fourier coefficients. Moreover, we also deduce the Shimura\ncurves case of the integral version of the Andr\\'e--Oort conjecture.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T14:45:22Z"}
{"aid":"http://arxiv.org/abs/2504.12133v1","title":"Coherent EUV scatterometry of 2D periodic structure profiles with\n  mathematically optimal experimental design","summary":"Extreme ultraviolet (EUV) scatterometry is an increasingly important\nmetrology that can measure critical parameters of periodic nanostructured\nmaterials in a fast, accurate, and repeatable manner and with high sensitivity\nto nanoscale structure and material composition. Because of this, EUV\nscatterometry could support manufacturing of semiconductor devices or polymer\nmetamaterials, addressing the limitations of traditional imaging methods such\nas resolution and field of view, sample damage, throughput, or low sensitivity.\nHere we use EUV scatterometry to measure the profile of an industrially\nrelevant 2D periodic interconnect structure, using $\\lambda = 29$ nm light from\na table-top high harmonic generation source. We show that EUV scatterometry is\nsensitive to out-of-plane features with single-nanometer sensitivity.\nFurthermore, we also apply a methodology based on the Fisher information matrix\nto optimize experimental design parameters, such as incidence angles and\nwavelength, to show how measurement sensitivity can be maximized. This\nmethodology reveals the strong dependence of measurement sensitivity on both\nincidence angle and wavelength $-$ even in a simple two-parameter case. Through\na simultaneous optimization of incidence angles and wavelength, we determine\nthat the most sensitive measurement of the quantities of interest can be made\nat a wavelength of $\\sim$14 nm. In the future, by reducing sample contamination\ndue to sample preparation, deep sub-nanometer sensitivity to axial profiles and\n2D structures will be possible. Our results are an important step in guiding\nEUV scatterometry towards increased accuracy and throughput with a priori\ncomputations and by leveraging new experimental capabilities.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-16T14:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.12134v1","title":"Quantum sensing with arbitrary frequency resolution via correlation\n  measurements","summary":"Achieving high-frequency spectral resolution with quantum sensors, while\ncrucial in fields ranging from physical to biological sciences, is challenging\ndue to their finite coherence time. Here, we introduce a novel protocol that\nachieves this goal by measuring phase correlations of AC magnetic fields using\nensembles of NV centers. Our method extends the sensing dynamic range to\nfrequencies higher than the system's Rabi frequency while achieving arbitrary\nfrequency resolution, limited only by the target field coherence time.\nMoreover, our approach operates more robustly with respect to the magnetic\nfield's amplitude. Thanks to this robustness, our protocol allows the\napplication of more $\\pi$-pulses in pulse sequences such as CPMG, enabling the\ndecoupling of a broader range of frequency noise. The higher harmonics\ngenerated in this process continue to act as a part of the signal, ultimately\nimproving the frequency resolution. This method paves the way for achieving\narbitrary frequency resolution with improved performances, making it highly\nversatile for quantum sensing applications across diverse scientific fields.","main_category":"quant-ph","categories":"quant-ph,physics.app-ph","published":"2025-04-16T14:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.12145v1","title":"Factorizations of polynomials with integral non-negative coefficients","summary":"We study the structure of the commutative multiplicative monoid $\\mathbb\nN_0[x]^*$ of all the non-zero polynomials in $\\mathbb Z[x]$ with non-negative\ncoefficients. We show that $\\mathbb N_0[x]^*$ is not a half-factorial monoid\nand is not a Krull monoid, but has a structure very similar to that of Krull\nmonoids, replacing valuations into $\\mathbb N_0$ with derivations into $\\mathbb\nN_0$. We study ideals, chain of ideals, prime ideals and prime elements of\n$\\mathbb N_0[x]^*$. Our monoid $\\mathbb N_0[x]^*$ is a submonoid of the\nmultiplicative monoid of the ring $\\mathbb Z[x]$, which is a left module over\nthe Weyl algebra $A_1(\\mathbb Z)$.","main_category":"math.AC","categories":"math.AC","published":"2025-04-16T14:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.12175v1","title":"Approximation Bounds for Transformer Networks with Application to\n  Regression","summary":"We explore the approximation capabilities of Transformer networks for\nH\\\"older and Sobolev functions, and apply these results to address\nnonparametric regression estimation with dependent observations. First, we\nestablish novel upper bounds for standard Transformer networks approximating\nsequence-to-sequence mappings whose component functions are H\\\"older continuous\nwith smoothness index $\\gamma \\in (0,1]$. To achieve an approximation error\n$\\varepsilon$ under the $L^p$-norm for $p \\in [1, \\infty]$, it suffices to use\na fixed-depth Transformer network whose total number of parameters scales as\n$\\varepsilon^{-d_x n / \\gamma}$. This result not only extends existing findings\nto include the case $p = \\infty$, but also matches the best known upper bounds\non number of parameters previously obtained for fixed-depth FNNs and RNNs.\nSimilar bounds are also derived for Sobolev functions. Second, we derive\nexplicit convergence rates for the nonparametric regression problem under\nvarious $\\beta$-mixing data assumptions, which allow the dependence between\nobservations to weaken over time. Our bounds on the sample complexity impose no\nconstraints on weight magnitudes. Lastly, we propose a novel proof strategy to\nestablish approximation bounds, inspired by the Kolmogorov-Arnold\nrepresentation theorem. We show that if the self-attention layer in a\nTransformer can perform column averaging, the network can approximate\nsequence-to-sequence H\\\"older functions, offering new insights into the\ninterpretability of self-attention mechanisms.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-16T15:25:58Z"}
{"aid":"http://arxiv.org/abs/2504.12183v1","title":"Towards asteroseismology of neutron stars with physics-informed neural\n  networks","summary":"The study of the gravitational wave signatures of neutron star oscillations\nmay provide important information of their interior structure and Equation of\nState (EoS) at high densities. We present a novel technique based on physically\ninformed neural networks (PINNs) to solve the eigenvalue problem associated\nwith normal oscillation modes of neutron stars. The procedure is tested in a\nsimplified scenario, with an analytical solution, that can be used to test the\nperformance and the accuracy of the method. We show that it is possible to get\naccurate results of both the eigenfrequencies and the eigenfunctions with this\nscheme. The flexibility of the method and its capability of adapting to complex\nscenarios may serve in the future as a path to include more physics into these\nsystems.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-16T15:39:45Z"}
{"aid":"http://arxiv.org/abs/2504.12198v1","title":"Diagrammatic Simplification of Linearized Coupled Cluster Theory","summary":"Linearized Coupled Cluster Doubles (LinCCD) often provides near-singular\nenergies in small-gap systems that exhibit static correlation. This has been\nattributed to the lack of quadratic $T_2^2$ terms that typically balance out\nsmall energy denominators in the CCD amplitude equations. Herein, I show that\nexchange contributions to ring and crossed-ring contractions (not small\ndenominators per se) cause the divergent behavior of LinCC(S)D approaches.\nRather than omitting exchange terms, I recommend a regular and size-consistent\nmethod that retains only linear ladder diagrams. As LinCCD and configuration\ninteraction doubles (CID) equations are isomorphic, this also implies that\nsimplification (rather than quadratic extensions) of CID amplitude equations\ncan lead to a size-consistent theory. Linearized ladder CCD (LinLCCD) is robust\nin statically-correlated systems and can be made\n$O(n_{\\text{occ}}^4n_{\\text{vir}}^2)$ with a hole-hole approximation. The\nrelationship between LinLCCD and random-phase approximation sets the stage for\nthe development of next-generation double-hybrid density functionals that can\ndescribe static correlation.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-16T15:48:33Z"}
{"aid":"http://arxiv.org/abs/2504.12211v1","title":"Creating benchmarkable components to measure the quality ofAI-enhanced\n  developer tools","summary":"In the AI community, benchmarks to evaluate model quality are well\nestablished, but an equivalent approach to benchmarking products built upon\ngenerative AI models is still missing. This has had two consequences. First, it\nhas made teams focus on model quality over the developer experience, while\nsuccessful products combine both. Second, product team have struggled to answer\nquestions about their products in relation to their competitors.\n  In this case study, we share: (1) our process to create robust,\nenterprise-grade and modular components to support the benchmarking of the\ndeveloper experience (DX) dimensions of our team's AI for code offerings, and\n(2) the components we have created to do so, including demographics and\nattitudes towards AI surveys, a benchmarkable task, and task and feature\nsurveys. By doing so, we hope to lower the barrier to the DX benchmarking of\ngenAI-enhanced code products.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-04-16T15:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.12233v1","title":"Hardness of observing strong-to-weak symmetry breaking","summary":"Spontaneous symmetry breaking (SSB) is the cornerstone of our understanding\nof quantum phases of matter. Recent works have generalized this concept to the\ndomain of mixed states in open quantum systems, where symmetries can be\nrealized in two distinct ways dubbed strong and weak. Novel intrinsically mixed\nphases of quantum matter can then be defined by the spontaneous breaking of\nstrong symmetry down to weak symmetry. However, proposed order parameters for\nstrong-to-weak SSB (based on mixed-state fidelities or purities) seem to\nrequire exponentially many copies of the state, raising the question: is it\npossible to efficiently detect strong-to-weak SSB in general? Here we answer\nthis question negatively in the paradigmatic cases of $Z_2$ and $U(1)$\nsymmetries. We construct ensembles of pseudorandom mixed states that do not\nbreak the strong symmetry, yet are computationally indistinguishable from\nstates that do. This rules out the existence of efficient state-agnostic\nprotocols to detect strong-to-weak SSB.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-16T16:31:27Z"}
{"aid":"http://arxiv.org/abs/2504.12236v1","title":"Towards Human-Centered Early Prediction Models for Academic Performance\n  in Real-World Contexts","summary":"Supporting student success requires collaboration among multiple\nstakeholders. Researchers have explored machine learning models for academic\nperformance prediction; yet key challenges remain in ensuring these models are\ninterpretable, equitable, and actionable within real-world educational support\nsystems. First, many models prioritize predictive accuracy but overlook\nhuman-centered considerations, limiting trust among students and reducing their\nusefulness for educators and institutional decision-makers. Second, most models\nrequire at least a month of data before making reliable predictions, delaying\nopportunities for early intervention. Third, current models primarily rely on\nsporadically collected, classroom-derived data, missing broader behavioral\npatterns that could provide more continuous and actionable insights. To address\nthese gaps, we present three modeling approaches-LR, 1D-CNN, and MTL-1D-CNN-to\nclassify students as low or high academic performers. We evaluate them based on\nexplainability, fairness, and generalizability to assess their alignment with\nkey social values. Using behavioral and self-reported data collected within the\nfirst week of two Spring terms, we demonstrate that these models can identify\nat-risk students as early as week one. However, trade-offs across\nhuman-centered considerations highlight the complexity of designing predictive\nmodels that effectively support multi-stakeholder decision-making and\nintervention strategies. We discuss these trade-offs and their implications for\ndifferent stakeholders, outlining how predictive models can be integrated into\nstudent support systems. Finally, we examine broader socio-technical challenges\nin deploying these models and propose future directions for advancing\nhuman-centered, collaborative academic prediction systems.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-16T16:40:56Z"}
{"aid":"http://arxiv.org/abs/2504.12241v1","title":"The Late-time Afterglow of GW170817 and Implications for Jet Dynamics","summary":"GW170817 is the first binary neutron star merger detected with gravitational\nand electromagnetic waves, and its afterglow is still detectable 7 years\npost-merger. Some previous studies of the X-ray afterglow have claimed the\nonset of a new afterglow component or raised concerns about the data processing\ntechniques. Motivated thus, we present here a reanalysis of X-ray afterglow\ndata for GW170817 and find potential sources of discrepancies between the data\nreduction techniques employed by various research groups. We also analyze the\nupdated panchromatic afterglow data to find that there is no significant\nevidence for any new afterglow component (e.g. due to the ejecta that gave rise\nto the kilonova) and that the jet must be still in a mildly relativistic phase.\nThe decline in the afterglow light curve is significantly shallower compared to\nthat expected from the standard synchrotron afterglow jet models with sideways\nspreading, indicating either an additional energy injection at late times or\nthe velocity dependence on the microphysics parameters. In this context, we\ndiscuss the implications of the late time afterglow data on jet dynamics.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T16:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.12248v1","title":"RÃ©nyi security framework against coherent attacks applied to\n  decoy-state QKD","summary":"We develop a flexible and robust framework for finite-size security proofs of\nquantum key distribution (QKD) protocols under coherent attacks, applicable to\nboth fixed- and variable-length protocols. Our approach achieves high\nfinite-size key rates across a broad class of protocols while imposing minimal\nrequirements. In particular, it eliminates the need for restrictive conditions\nsuch as limited repetition rates or the implementation of virtual tomography\nprocedures. To achieve this goal, we introduce new numerical techniques for the\nevaluation of sandwiched conditional R\\'enyi entropies. In doing so, we also\nfind an alternative formulation of the \"QKD cone\" studied in previous work. We\nillustrate the versatility of our framework by applying it to several\npractically relevant protocols, including decoy-state protocols. Furthermore,\nwe extend the analysis to accommodate realistic device imperfections, such as\nindependent intensity and phase imperfections. Overall, our framework provides\nboth greater scope of applicability and better key rates than existing\ntechniques, especially for small block sizes, hence offering a scalable path\ntoward secure quantum communication under realistic conditions","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T16:54:23Z"}
{"aid":"http://arxiv.org/abs/2504.12250v1","title":"AnomalyGen: An Automated Semantic Log Sequence Generation Framework with\n  LLM for Anomaly Detection","summary":"The scarcity of high-quality public log datasets has become a critical\nbottleneck in advancing log-based anomaly detection techniques. Current\ndatasets exhibit three fundamental limitations: (1) incomplete event coverage,\n(2) artificial patterns introduced by static analysis-based generation\nframeworks, and (3) insufficient semantic awareness. To address these\nchallenges, we present AnomalyGen, the first automated log synthesis framework\nspecifically designed for anomaly detection. Our framework introduces a novel\nfour-phase architecture that integrates enhanced program analysis with\nChain-of-Thought reasoning (CoT reasoning), enabling iterative log generation\nand anomaly annotation without requiring physical system execution. Evaluations\non Hadoop and HDFS distributed systems demonstrate that AnomalyGen achieves\nsubstantially broader log event coverage (38-95 times improvement over existing\ndatasets) while producing more operationally realistic log sequences compared\nto static analysis-based approaches. When augmenting benchmark datasets with\nsynthesized logs, we observe maximum F1-score improvements of 3.7% (average\n1.8% improvement across three state-of-the-art anomaly detection models). This\nwork not only establishes a high-quality benchmarking resource for automated\nlog analysis but also pioneers a new paradigm for applying large language\nmodels (LLMs) in software engineering workflows.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T16:54:38Z"}
{"aid":"http://arxiv.org/abs/2504.12253v1","title":"Stability conditions on K3 surfaces via mass of spherical objects","summary":"We prove that a stability condition on a K3 surface is determined by the\nmasses of spherical objects up to a natural $\\mathbb{C}$-action. This is\nmotivated by the result of Huybrechts and the recent proposal of\nBapat-Deopurkar-Licata on the construction of a compactification of a stability\nmanifold. We also construct lax stability conditions in the sense of\nBroomhead-Pauksztello-Ploog-Woolf associated to spherical bundles.","main_category":"math.AG","categories":"math.AG,math.GT","published":"2025-04-16T17:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.12274v1","title":"Kernels for Storage Capacity and Dual Index Coding","summary":"The storage capacity of a graph measures the maximum amount of information\nthat can be stored across its vertices, such that the information at any vertex\ncan be recovered from the information stored at its neighborhood. The study of\nthis graph quantity is motivated by applications in distributed storage and by\nits intimate relations to the index coding problem from the area of network\ninformation theory. In the latter, one wishes to minimize the amount of\ninformation that has to be transmitted to a collection of receivers, in a way\nthat enables each of them to discover its required data using some prior side\ninformation.\n  In this paper, we initiate the study of the Storage Capacity and Index Coding\nproblems from the perspective of parameterized complexity. We prove that the\nStorage Capacity problem parameterized by the solution size admits a\nkernelization algorithm producing kernels of linear size. We also provide such\na result for the Index Coding problem, in the linear and non-linear settings,\nwhere it is parameterized by the dual value of the solution, i.e., the length\nof the transmission that can be saved using the side information. A key\ningredient in the proofs is the crown decomposition technique due to Chor,\nFellows, and Juedes (WG 2003, WG 2004). As an application, we significantly\nextend an algorithmic result of Dau, Skachek, and Chee (IEEE Trans. Inform.\nTheory, 2014).","main_category":"cs.DS","categories":"cs.DS,cs.IT,math.IT","published":"2025-04-16T17:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.12276v1","title":"The Tenth NTIRE 2025 Image Denoising Challenge Report","summary":"This paper presents an overview of the NTIRE 2025 Image Denoising Challenge\n({\\sigma} = 50), highlighting the proposed methodologies and corresponding\nresults. The primary objective is to develop a network architecture capable of\nachieving high-quality denoising performance, quantitatively evaluated using\nPSNR, without constraints on computational complexity or model size. The task\nassumes independent additive white Gaussian noise (AWGN) with a fixed noise\nlevel of 50. A total of 290 participants registered for the challenge, with 20\nteams successfully submitting valid results, providing insights into the\ncurrent state-of-the-art in image denoising.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T17:35:09Z"}
{"aid":"http://arxiv.org/abs/2504.12279v1","title":"Dysarthria Normalization via Local Lie Group Transformations for Robust\n  ASR","summary":"We present a geometry-driven method for normalizing dysarthric speech using\nlocal Lie group transformations of spectrograms. Time, frequency, and amplitude\ndistortions are modeled as smooth, invertible deformations, parameterized by\nscalar fields and applied via exponential maps. A neural network is trained to\ninfer these fields from synthetic distortions of typical speech-without using\nany pathological data. At test time, the model applies an approximate inverse\nto real dysarthric inputs. Despite zero-shot generalization, we observe\nsubstantial ASR gains, including up to 16 percentage points WER reduction on\nchallenging TORGO samples, with no degradation on clean speech. This work\nintroduces a principled, interpretable approach for robust speech recognition\nunder motor speech disorders","main_category":"cs.SD","categories":"cs.SD,cs.CL,cs.LG,eess.AS","published":"2025-04-16T17:41:19Z"}
{"aid":"http://arxiv.org/abs/2504.12291v1","title":"Liouvillean Spectral Transition in Noisy Quantum Many-Body Scars","summary":"Understanding the behavior of quantum many-body systems under decoherence is\nessential for developing robust quantum technologies. Here, we examine the fate\nof weak ergodicity breaking in systems hosting quantum many-body scars when\nsubject to local pure dephasing -- an experimentally relevant form of\nenvironmental noise. Focusing on a large class of models with an approximate\nsu(2)-structured scar subspace, we show that scarred eigenmodes of the\nLiouvillean exhibit a transition reminiscent of spontaneous\n$\\mathbb{PT}$-symmetry breaking as the dephasing strength increases. Unlike\npreviously studied non-Hermitian mechanisms, this transition arises from a\ndistinct quantum jump effect. Remarkably, in platforms such as the XY spin\nladder and PXP model of Rydberg atom arrays, the critical dephasing rate shows\nonly weak dependence on system size, revealing an unexpected robustness of\nscarred dynamics in noisy quantum simulators.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-16T17:55:02Z"}
{"aid":"http://arxiv.org/abs/2504.12297v1","title":"Optimal flock formation induced by agent heterogeneity","summary":"The study of flocking in biological systems has identified conditions for\nself-organized collective behavior, inspiring the development of decentralized\nstrategies to coordinate the dynamics of swarms of drones and other autonomous\nvehicles. Previous research has focused primarily on the role of the\ntime-varying interaction network among agents while assuming that the agents\nthemselves are identical or nearly identical. Here, we depart from this\nconventional assumption to investigate how inter-individual differences between\nagents affect the stability and convergence in flocking dynamics. We show that\nflocks of agents with optimally assigned heterogeneous parameters significantly\noutperform their homogeneous counterparts, achieving 20-40% faster convergence\nto desired formations across various control tasks. These tasks include target\ntracking, flock formation, and obstacle maneuvering. In systems with\ncommunication delays, heterogeneity can enable convergence even when flocking\nis unstable for identical agents. Our results challenge existing paradigms in\nmulti-agent control and establish system disorder as an adaptive, distributed\nmechanism to promote collective behavior in flocking dynamics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cs.SY,eess.SY,math.DS,math.OC,nlin.AO","published":"2025-04-16T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.12626v1","title":"Packing Input Frame Context in Next-Frame Prediction Models for Video\n  Generation","summary":"We present a neural network structure, FramePack, to train next-frame (or\nnext-frame-section) prediction models for video generation. The FramePack\ncompresses input frames to make the transformer context length a fixed number\nregardless of the video length. As a result, we are able to process a large\nnumber of frames using video diffusion with computation bottleneck similar to\nimage diffusion. This also makes the training video batch sizes significantly\nhigher (batch sizes become comparable to image diffusion training). We also\npropose an anti-drifting sampling method that generates frames in inverted\ntemporal order with early-established endpoints to avoid exposure bias (error\naccumulation over iterations). Finally, we show that existing video diffusion\nmodels can be finetuned with FramePack, and their visual quality may be\nimproved because the next-frame prediction supports more balanced diffusion\nschedulers with less extreme flow shift timesteps.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T04:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.12662v1","title":"Flat Circular Velocities on a megaparsec scale from the $Î›$CDM\n  model","summary":"A recent study using weak gravitational lensing reveals that there are some\nisolated galaxies having almost flat rotation curves at very large distance\nfrom the galactic centres. According to the authors of the study this provides\na strong challenge the standard cold dark matter model, since the dark haloes\nare too small to explain their observations, especially for small stellar\nmasses. In this article, we show that improving their model, the virial radius\nis larger than their estimates. The NFW rotational curve, and especially the\npseudo Isothermal one, are in agreement with their flat rotational curves,\nespecially for the larger baryonic mass bins used by the authors.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T05:47:06Z"}
{"aid":"http://arxiv.org/abs/2504.12672v1","title":"Post-processing improves accuracy of Artificial Intelligence weather\n  forecasts","summary":"Artificial Intelligence (AI) weather models are now reaching\noperational-grade performance for some variables, but like traditional\nNumerical Weather Prediction (NWP) models, they exhibit systematic biases and\nreliability issues. We test the application of the Bureau of Meteorology's\nexisting statistical post-processing system, IMPROVER, to ECMWF's deterministic\nArtificial Intelligence Forecasting System (AIFS), and compare results against\npost-processed outputs from the ECMWF HRES and ENS models. Without any\nmodification to configuration or processing workflows, post-processing yields\ncomparable accuracy improvements for AIFS as for traditional NWP forecasts, in\nboth expected value and probabilistic outputs. We show that blending AIFS with\nNWP models improves overall forecast skill, even when AIFS alone is not the\nmost accurate component. These findings show that statistical post-processing\nmethods developed for NWP are directly applicable to AI models, enabling\nnational meteorological centres to incorporate AI forecasts into existing\nworkflows in a low-risk, incremental fashion.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.AI,cs.LG","published":"2025-04-17T06:05:10Z"}
{"aid":"http://arxiv.org/abs/2504.12684v1","title":"SOPHY: Generating Simulation-Ready Objects with Physical Materials","summary":"We present SOPHY, a generative model for 3D physics-aware shape synthesis.\nUnlike existing 3D generative models that focus solely on static geometry or 4D\nmodels that produce physics-agnostic animations, our approach jointly\nsynthesizes shape, texture, and material properties related to physics-grounded\ndynamics, making the generated objects ready for simulations and interactive,\ndynamic environments. To train our model, we introduce a dataset of 3D objects\nannotated with detailed physical material attributes, along with an annotation\npipeline for efficient material annotation. Our method enables applications\nsuch as text-driven generation of interactive, physics-aware 3D objects and\nsingle-image reconstruction of physically plausible shapes. Furthermore, our\nexperiments demonstrate that jointly modeling shape and material properties\nenhances the realism and fidelity of generated shapes, improving performance on\ngenerative geometry evaluation metrics.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T06:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.12697v1","title":"The Theory Of Auxiliary Weierstrassian Zeta Functions And Zeta\n  Differences","summary":"In this paper, we expand the theory of Weierstrassian elliptic functions by\nintroducing auxiliary zeta functions $\\zeta_\\lambda$, zeta differences of first\nkind $\\Delta_\\lambda$ and second kind $\\Delta_{\\lambda,\\mu}$ where\n$\\lambda,\\mu=1,2,3$. Fundamental and novel results pertaining to these\nfunctions are proven. Furthermore, results already existing in the literature\nare translated in terms of auxiliary zeta functions. Their relationship to\nJacobian elliptic functions and Jacobian functions are given.","main_category":"math.CV","categories":"math.CV,math.NT","published":"2025-04-17T06:50:55Z"}
{"aid":"http://arxiv.org/abs/2504.12705v1","title":"7-Methylquinolinium Iodobismuthate Memristor: Exploring Plasticity and\n  Memristive Properties for Digit Classification in Physical Reservoir\n  Computing","summary":"This study investigates 7-methylquinolinium halobismuthates (I, Br, and Cl)\nin two aspects: (1) their structural and semiconducting properties influenced\nby anionic composition, and (2) their memristive and plasticity characteristics\nfor neuromorphic and reservoir computing applications. Structural changes\ninduced by halides form low-dimensional halobismuthate fragments, confirmed by\ncrystallographic analysis. Optical band gaps were studied using diffuse\nreflectance spectroscopy, aligning with density functional theory results. Due\nto solubility limitations, only bismuth iodide complexes were explored in\nelectronic devices. Current-voltage scans showed pinched hysteresis loops,\ncharacteristic of memristors. Conductivity versus temperature study indicates\ncombined ionic and electronic contributions to conductivity of the devices.\nGiven that a memristor can function as a single synapse without the need for\nprogramming, aligning with the requirements of neuromorphic computing, the\nstudy investigated long-term depression, potentiation, and spike-time-dependent\nplasticity. As the potentiation-depression plots showed non-linearity with\nfading memory, these materials can be a good candidate for application in\nphysical reservoir computing. To further assess this material, an electronic\ndevice with sixteen gold electrodes was applied, featuring one input and 15\noutput electrodes deposited on silicon substrate and covered with a layer of\nstudied compound. Basic test to assess the complexity and non-linearity of the\ndevices were conducted through a series of benchmark tasks, including waveform\ngeneration, NARMA-2, memory capacity assessment, and noise study under both DC\nand AC current. The ability of device in MNIST digit classification with 82.26%\naccuracy and voice classification for digit 2 for six different people with 82\n% accuracy has been demonstrated.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-17T07:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.12709v1","title":"Self-Supervised Pre-training with Combined Datasets for 3D Perception in\n  Autonomous Driving","summary":"The significant achievements of pre-trained models leveraging large volumes\nof data in the field of NLP and 2D vision inspire us to explore the potential\nof extensive data pre-training for 3D perception in autonomous driving. Toward\nthis goal, this paper proposes to utilize massive unlabeled data from\nheterogeneous datasets to pre-train 3D perception models. We introduce a\nself-supervised pre-training framework that learns effective 3D representations\nfrom scratch on unlabeled data, combined with a prompt adapter based domain\nadaptation strategy to reduce dataset bias. The approach significantly improves\nmodel performance on downstream tasks such as 3D object detection, BEV\nsegmentation, 3D object tracking, and occupancy prediction, and shows steady\nperformance increase as the training data volume scales up, demonstrating the\npotential of continually benefit 3D perception models for autonomous driving.\nWe will release the source code to inspire further investigations in the\ncommunity.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T07:26:11Z"}
{"aid":"http://arxiv.org/abs/2504.12734v1","title":"Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning\n  Across Diverse Structured Knowledge","summary":"Unified Structured Knowledge Reasoning (USKR) aims to answer natural language\nquestions (NLQs) by using structured sources such as tables, databases, and\nknowledge graphs in a unified way. Existing USKR methods either rely on\nemploying task-specific strategies or custom-defined representations, which\nstruggle to leverage the knowledge transfer between different SKR tasks or\nalign with the prior of LLMs, thereby limiting their performance. This paper\nproposes a novel USKR framework named \\textsc{Pandora}, which takes advantage\nof \\textsc{Python}'s \\textsc{Pandas} API to construct a unified knowledge\nrepresentation for alignment with LLM pre-training. It employs an LLM to\ngenerate textual reasoning steps and executable Python code for each question.\nDemonstrations are drawn from a memory of training examples that cover various\nSKR tasks, facilitating knowledge transfer. Extensive experiments on four\nbenchmarks involving three SKR tasks demonstrate that \\textsc{Pandora}\noutperforms existing unified frameworks and competes effectively with\ntask-specific methods.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T08:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.12768v1","title":"Self-consistent random phase approximation and optimized hybrid\n  functionals for solids","summary":"The random phase approximation (RPA) and the $GW$ approximation share the\nsame total energy functional but RPA is defined on a restricted domain of\nGreen's functions determined by a local Kohn-Sham (KS) potential. In this work,\nwe perform self-consistent RPA calculations by optimizing the local KS\npotential through the optimized effective potential equation. We study a number\nof solids (C, Si, BN, LiF, MgO, TiO$_2$), and find in all cases a lowering of\nthe total energy with respect to non-self-consistent RPA. We then propose a\nvariational approach to optimize PBE0-type hybrid functionals based on the\nminimization of the RPA total energy with respect to the fraction of exact\nexchange used to generate the input KS orbitals. We show that this scheme leads\nto hybrid functionals with a KS band structure in close agreement with RPA, and\nwith lattice constants of similar accuracy as within RPA. Finally, we evaluate\n$G_0W_0$ gaps using RPA and hybrid KS potentials as starting points. Special\nattention is given to TiO$_2$, which exhibits a strong starting-point\ndependence.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T09:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.12778v1","title":"Towards Lossless Token Pruning in Late-Interaction Retrieval Models","summary":"Late interaction neural IR models like ColBERT offer a competitive\neffectiveness-efficiency trade-off across many benchmarks. However, they\nrequire a huge memory space to store the contextual representation for all the\ndocument tokens. Some works have proposed using either heuristics or\nstatistical-based techniques to prune tokens from each document. This however\ndoesn't guarantee that the removed tokens have no impact on the retrieval\nscore. Our work uses a principled approach to define how to prune tokens\nwithout impacting the score between a document and a query. We introduce three\nregularization losses, that induce a solution with high pruning ratios, as well\nas two pruning strategies. We study them experimentally (in and out-domain),\nshowing that we can preserve ColBERT's performance while using only 30\\% of the\ntokens.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-17T09:18:58Z"}
{"aid":"http://arxiv.org/abs/2504.12779v1","title":"Crossover in Electronic Specific Heat near Narrow-Sense Type-III Dirac\n  Cones","summary":"Two-dimensional massless Dirac fermions exhibit Dirac cones, which are\nclassified into three types: type-I, type-II, and type-III. In both type-I and\ntype-II cones, the energy dispersion is linear in all momentum directions.\nType-I cones are characterized by a non-overtilted structure, where the Dirac\npoint serves as a local minimum (maximum) for the upper (lower) band. In\ncontrast, type-II cones exhibit overtilted dispersions, leading to the\ncoexistence of electron and hole pockets. At the critical tilt, the linear\nenergy dispersion vanishes in one momentum direction, corresponding to a\ntype-III Dirac cone. We further define a special case, termed the\n\"narrow-sense\" type-III cone, where not only the linear term but also quadratic\nand higher-order terms vanish, resulting in a completely flat dispersion along\none direction. In this work, we numerically investigate the temperature ($T$)\n-dependence of the electronic specific heat ($C$), as the Dirac cone is\ncontinuously tilted from type-I to narrow-sense type-III. A model with\nparticle-hole symmetry is employed to ensure that the chemical potential\n($\\mu$) remains temperature independent. Our results reveal a notable crossover\nin $C$ near narrow-sense type-III, where $C$ changes from $C \\propto T^{2}$\nbelow the crossover temperature ($T_{\\rm co}$) to $C \\propto T^{\\frac{1}{2}}$\nabove $T_{\\rm co}$. This crossover is attributed to the energy-dependent\nstructure of the density of states. The present findings suggest a feasible\napproach for experimentally probing the degree of Dirac cone tilting near the\nnarrow-sense type-III limit.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-17T09:23:00Z"}
{"aid":"http://arxiv.org/abs/2504.12789v1","title":"Enumeration of cube-free groups and counting certain types of split\n  extensions","summary":"A group is said to be cube-free if its order is not divisible by the cube of\nany prime. Let $f_{cf,sol}(n)$ denote the isomorphism classes of solvable\ncube-free groups of order $n$. We find asymptotic bounds for $f_{cf,sol}(n)$ in\nthis paper. Let $p$ be a prime and let $q = p^k$ for some positive integer $k$.\nWe also give a formula for the number of conjugacy classes of the subgroups\nthat are maximal amongst non-abelian solvable cube-free $p'$-subgroups of ${\\rm\nGL}(2,q)$. Further, we find the exact number of split extensions of $P$ by $Q$\nup to isomorphism of a given order where $P \\in \\{{\\mathbb Z}_p \\times {\\mathbb\nZ}_p, {\\mathbb Z}_{p^{\\alpha}}\\}$, $p$ is a prime, $\\alpha$ is a positive\ninteger and $Q$ is a cube-free abelian group of odd order such that $p \\nmid\n|Q|$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-17T09:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.12795v1","title":"EarthGPT-X: Enabling MLLMs to Flexibly and Comprehensively Understand\n  Multi-Source Remote Sensing Imagery","summary":"Recent advances in the visual-language area have developed natural\nmulti-modal large language models (MLLMs) for spatial reasoning through visual\nprompting. However, due to remote sensing (RS) imagery containing abundant\ngeospatial information that differs from natural images, it is challenging to\neffectively adapt natural spatial models to the RS domain. Moreover, current RS\nMLLMs are limited in overly narrow interpretation levels and interaction\nmanner, hindering their applicability in real-world scenarios. To address those\nchallenges, a spatial MLLM named EarthGPT-X is proposed, enabling a\ncomprehensive understanding of multi-source RS imagery, such as optical,\nsynthetic aperture radar (SAR), and infrared. EarthGPT-X offers zoom-in and\nzoom-out insight, and possesses flexible multi-grained interactive abilities.\nMoreover, EarthGPT-X unifies two types of critical spatial tasks (i.e.,\nreferring and grounding) into a visual prompting framework. To achieve these\nversatile capabilities, several key strategies are developed. The first is the\nmulti-modal content integration method, which enhances the interplay between\nimages, visual prompts, and text instructions. Subsequently, a cross-domain\none-stage fusion training strategy is proposed, utilizing the large language\nmodel (LLM) as a unified interface for multi-source multi-task learning.\nFurthermore, by incorporating a pixel perception module, the referring and\ngrounding tasks are seamlessly unified within a single framework. In addition,\nthe experiments conducted demonstrate the superiority of the proposed\nEarthGPT-X in multi-grained tasks and its impressive flexibility in multi-modal\ninteraction, revealing significant advancements of MLLM in the RS field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T09:56:35Z"}
{"aid":"http://arxiv.org/abs/2504.12796v1","title":"A Survey on Cross-Modal Interaction Between Music and Multimodal Data","summary":"Multimodal learning has driven innovation across various industries,\nparticularly in the field of music. By enabling more intuitive interaction\nexperiences and enhancing immersion, it not only lowers the entry barriers to\nthe music but also increases its overall appeal. This survey aims to provide a\ncomprehensive review of multimodal tasks related to music, outlining how music\ncontributes to multimodal learning and offering insights for researchers\nseeking to expand the boundaries of computational music. Unlike text and\nimages, which are often semantically or visually intuitive, music primarily\ninteracts with humans through auditory perception, making its data\nrepresentation inherently less intuitive. Therefore, this paper first\nintroduces the representations of music and provides an overview of music\ndatasets. Subsequently, we categorize cross-modal interactions between music\nand multimodal data into three types: music-driven cross-modal interactions,\nmusic-oriented cross-modal interactions, and bidirectional music cross-modal\ninteractions. For each category, we systematically trace the development of\nrelevant sub-tasks, analyze existing limitations, and discuss emerging trends.\nFurthermore, we provide a comprehensive summary of datasets and evaluation\nmetrics used in multimodal tasks related to music, offering benchmark\nreferences for future research. Finally, we discuss the current challenges in\ncross-modal interactions involving music and propose potential directions for\nfuture research.","main_category":"cs.MM","categories":"cs.MM,cs.SD,eess.AS","published":"2025-04-17T09:58:38Z"}
{"aid":"http://arxiv.org/abs/2504.12831v1","title":"Long-wavelength optical lattices from optical beatnotes: theory and\n  applications","summary":"We present a theoretical analysis of Beat-Note Superlattices (BNSLs), a\nrecently demonstrated technique for generating periodic trapping potentials for\nultracold atomic clouds, with arbitrarily large lattice spacings while\nmaintaining interferometric stability. By combining two optical lattices with\nslightly different wavelengths, a beatnote intensity pattern is formed,\ngenerating, for low depths, an effective lattice potential with a periodicity\nequal to the wavelength associated to the difference between the wavevectors of\nthe two lattices. We study the range of lattice depths and wavelengths under\nwhich this approximation is valid and investigate its robustness against\nperturbations. We present a few examples where the use of BNSLs could offer\nsignificant advantages in comparison to well established techniques for the\nmanipulation of ultracold atomic gases. Our results highlight the potential of\nBNSLs for quantum simulation, atom interferometry, and other applications in\nquantum technologies.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,quant-ph","published":"2025-04-17T10:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.12844v1","title":"High-Fidelity Image Inpainting with Multimodal Guided GAN Inversion","summary":"Generative Adversarial Network (GAN) inversion have demonstrated excellent\nperformance in image inpainting that aims to restore lost or damaged image\ntexture using its unmasked content. Previous GAN inversion-based methods\nusually utilize well-trained GAN models as effective priors to generate the\nrealistic regions for missing holes. Despite excellence, they ignore a hard\nconstraint that the unmasked regions in the input and the output should be the\nsame, resulting in a gap between GAN inversion and image inpainting and thus\ndegrading the performance. Besides, existing GAN inversion approaches often\nconsider a single modality of the input image, neglecting other auxiliary cues\nin images for improvements. Addressing these problems, we propose a novel GAN\ninversion approach, dubbed MMInvertFill, for image inpainting. MMInvertFill\ncontains primarily a multimodal guided encoder with a pre-modulation and a GAN\ngenerator with F&W+ latent space. Specifically, the multimodal encoder aims to\nenhance the multi-scale structures with additional semantic segmentation edge\ntexture modalities through a gated mask-aware attention module. Afterwards, a\npre-modulation is presented to encode these structures into style vectors. To\nmitigate issues of conspicuous color discrepancy and semantic inconsistency, we\nintroduce the F&W+ latent space to bridge the gap between GAN inversion and\nimage inpainting. Furthermore, in order to reconstruct faithful and\nphotorealistic images, we devise a simple yet effective Soft-update Mean Latent\nmodule to capture more diversified in-domain patterns for generating\nhigh-fidelity textures for massive corruptions. In our extensive experiments on\nsix challenging datasets, we show that our MMInvertFill qualitatively and\nquantitatively outperforms other state-of-the-arts and it supports the\ncompletion of out-of-domain images effectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T10:58:45Z"}
{"aid":"http://arxiv.org/abs/2504.12856v1","title":"3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise","summary":"Large pretrained vision foundation models have shown significant potential in\nvarious vision tasks. However, for industrial anomaly detection, the scarcity\nof real defect samples poses a critical challenge in leveraging these models.\nWhile 2D anomaly generation has significantly advanced with established\ngenerative models, the adoption of 3D sensors in industrial manufacturing has\nmade leveraging 3D data for surface quality inspection an emerging trend. In\ncontrast to 2D techniques, 3D anomaly generation remains largely unexplored,\nlimiting the potential of 3D data in industrial quality inspection. To address\nthis gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS,\nbased on Perlin noise and surface parameterization. Our method generates\nrealistic 3D surface anomalies by projecting the point cloud onto a 2D plane,\nsampling multi-scale noise values from a Perlin noise field, and perturbing the\npoint cloud along its normal direction. Through comprehensive visualization\nexperiments, we demonstrate how key parameters - including noise scale,\nperturbation strength, and octaves, provide fine-grained control over the\ngenerated anomalies, enabling the creation of diverse defect patterns from\npronounced deformations to subtle surface variations. Additionally, our\ncross-category experiments show that the method produces consistent yet\ngeometrically plausible anomalies across different object types, adapting to\ntheir specific surface characteristics. We also provide a comprehensive\ncodebase and visualization toolkit to facilitate future research.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG,cs.RO,I.5.4","published":"2025-04-17T11:23:17Z"}
{"aid":"http://arxiv.org/abs/2504.12860v1","title":"When do Random Forests work?","summary":"We study the effectiveness of randomizing split-directions in random forests.\nPrior literature has shown that, on the one hand, randomization can reduce\nvariance through decorrelation, and, on the other hand, randomization\nregularizes and works in low signal-to-noise ratio (SNR) environments. First,\nwe bring together and revisit decorrelation and regularization by presenting a\nsystematic analysis of out-of-sample mean-squared error (MSE) for different SNR\nscenarios based on commonly-used data-generating processes. We find that\nvariance reduction tends to increase with the SNR and forests outperform\nbagging when the SNR is low because, in low SNR cases, variance dominates bias\nfor both methods. Second, we show that the effectiveness of randomization is a\nquestion that goes beyond the SNR. We present a simulation study with fixed and\nmoderate SNR, in which we examine the effectiveness of randomization for other\ndata characteristics. In particular, we find that (i) randomization can\nincrease bias in the presence of fat tails in the distribution of covariates;\n(ii) in the presence of irrelevant covariates randomization is ineffective\nbecause bias dominates variance; and (iii) when covariates are mutually\ncorrelated randomization tends to be effective because variance dominates bias.\nBeyond randomization, we find that, for both bagging and random forests, bias\ncan be significantly reduced in the presence of correlated covariates. This\nlast finding goes beyond the prevailing view that averaging mostly works by\nvariance reduction. Given that in practice covariates are often correlated, our\nfindings on correlated covariates could open the way for a better understanding\nof why random forests work well in many applications.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-17T11:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.12869v1","title":"SC3EF: A Joint Self-Correlation and Cross-Correspondence Estimation\n  Framework for Visible and Thermal Image Registration","summary":"Multispectral imaging plays a critical role in a range of intelligent\ntransportation applications, including advanced driver assistance systems\n(ADAS), traffic monitoring, and night vision. However, accurate visible and\nthermal (RGB-T) image registration poses a significant challenge due to the\nconsiderable modality differences. In this paper, we present a novel joint\nSelf-Correlation and Cross-Correspondence Estimation Framework (SC3EF),\nleveraging both local representative features and global contextual cues to\neffectively generate RGB-T correspondences. For this purpose, we design a\nconvolution-transformer-based pipeline to extract local representative features\nand encode global correlations of intra-modality for inter-modality\ncorrespondence estimation between unaligned visible and thermal images. After\nmerging the local and global correspondence estimation results, we further\nemploy a hierarchical optical flow estimation decoder to progressively refine\nthe estimated dense correspondence maps. Extensive experiments demonstrate the\neffectiveness of our proposed method, outperforming the current\nstate-of-the-art (SOTA) methods on representative RGB-T datasets. Furthermore,\nit also shows competitive generalization capabilities across challenging\nscenarios, including large parallax, severe occlusions, adverse weather, and\nother cross-modal datasets (e.g., RGB-N and RGB-D).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T11:54:12Z"}
{"aid":"http://arxiv.org/abs/2504.12878v1","title":"Frustrated kagome-lattice bilayer quantum Heisenberg antiferromagnet","summary":"We consider the $S=1/2$ antiferromagnetic Heisenberg model on a frustrated\nkagome-lattice bilayer with strong nearest-neighbor interlayer coupling and\nexamine its low-temperature magnetothermodynamics using a mapping onto a rhombi\ngas on the kagome lattice. Besides, we use finite-size numerics to illustrate\nthe validity of the classical lattice-gas description. Among our findings there\nare i) the absence of an order-disorder phase transition and ii) the\nsensitivity of the specific heat at low temperatures to the shape of the system\njust below the saturation magnetic field even in the thermodynamic limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-17T12:08:42Z"}
{"aid":"http://arxiv.org/abs/2504.12911v1","title":"Benchmarking Multi-National Value Alignment for Large Language Models","summary":"Do Large Language Models (LLMs) hold positions that conflict with your\ncountry's values? Occasionally they do! However, existing works primarily focus\non ethical reviews, failing to capture the diversity of national values, which\nencompass broader policy, legal, and moral considerations. Furthermore, current\nbenchmarks that rely on spectrum tests using manually designed questionnaires\nare not easily scalable.\n  To address these limitations, we introduce NaVAB, a comprehensive benchmark\nto evaluate the alignment of LLMs with the values of five major nations: China,\nthe United States, the United Kingdom, France, and Germany. NaVAB implements a\nnational value extraction pipeline to efficiently construct value assessment\ndatasets. Specifically, we propose a modeling procedure with instruction\ntagging to process raw data sources, a screening process to filter\nvalue-related topics and a generation process with a Conflict Reduction\nmechanism to filter non-conflicting values.We conduct extensive experiments on\nvarious LLMs across countries, and the results provide insights into assisting\nin the identification of misaligned scenarios. Moreover, we demonstrate that\nNaVAB can be combined with alignment techniques to effectively reduce value\nconcerns by aligning LLMs' values with the target country.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T13:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.12920v1","title":"CSMF: Cascaded Selective Mask Fine-Tuning for Multi-Objective\n  Embedding-Based Retrieval","summary":"Multi-objective embedding-based retrieval (EBR) has become increasingly\ncritical due to the growing complexity of user behaviors and commercial\nobjectives. While traditional approaches often suffer from data sparsity and\nlimited information sharing between objectives, recent methods utilizing a\nshared network alongside dedicated sub-networks for each objective partially\naddress these limitations. However, such methods significantly increase the\nmodel parameters, leading to an increased retrieval latency and a limited\nability to model causal relationships between objectives. To address these\nchallenges, we propose the Cascaded Selective Mask Fine-Tuning (CSMF), a novel\nmethod that enhances both retrieval efficiency and serving performance for\nmulti-objective EBR. The CSMF framework selectively masks model parameters to\nfree up independent learning space for each objective, leveraging the cascading\nrelationships between objectives during the sequential fine-tuning. Without\nincreasing network parameters or online retrieval overhead, CSMF computes a\nlinearly weighted fusion score for multiple objective probabilities while\nsupporting flexible adjustment of each objective's weight across various\nrecommendation scenarios. Experimental results on real-world datasets\ndemonstrate the superior performance of CSMF, and online experiments validate\nits significant practical value.","main_category":"cs.IR","categories":"cs.IR,H.3.3","published":"2025-04-17T13:10:56Z"}
{"aid":"http://arxiv.org/abs/2504.12949v1","title":"RL-PINNs: Reinforcement Learning-Driven Adaptive Sampling for Efficient\n  Training of PINNs","summary":"Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs). However, their performance\nheavily relies on the strategy used to select training points. Conventional\nadaptive sampling methods, such as residual-based refinement, often require\nmulti-round sampling and repeated retraining of PINNs, leading to computational\ninefficiency due to redundant points and costly gradient\ncomputations-particularly in high-dimensional or high-order derivative\nscenarios. To address these limitations, we propose RL-PINNs, a reinforcement\nlearning(RL)-driven adaptive sampling framework that enables efficient training\nwith only a single round of sampling. Our approach formulates adaptive sampling\nas a Markov decision process, where an RL agent dynamically selects optimal\ntraining points by maximizing a long-term utility metric. Critically, we\nreplace gradient-dependent residual metrics with a computationally efficient\nfunction variation as the reward signal, eliminating the overhead of derivative\ncalculations. Furthermore, we employ a delayed reward mechanism to prioritize\nlong-term training stability over short-term gains. Extensive experiments\nacross diverse PDE benchmarks, including low-regular, nonlinear,\nhigh-dimensional, and high-order problems, demonstrate that RL-PINNs\nsignificantly outperforms existing residual-driven adaptive methods in\naccuracy. Notably, RL-PINNs achieve this with negligible sampling overhead,\nmaking them scalable to high-dimensional and high-order problems.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-17T13:50:55Z"}
{"aid":"http://arxiv.org/abs/2504.12956v1","title":"Optic Fingerprint(OFP): Enhancing Security in Li-Fi Networks","summary":"We present a hardware-integrated security framework for LiFi networks through\ndevice fingerprint extraction within the IEEE 802.15.7 protocol. Our Optic\nFingerprint (OFP) model utilizes inherent LED nonlinearities to generate\namplitude-based feature vectors in time and frequency domains, specifically\ndesigned for optical wireless systems. Experimental results with 39 commercial\nLEDs demonstrate 90.36% classification accuracy across SNR 10-30 dB while\nmaintaining standard compliance, offering a practical physical-layer\nauthentication solution for visible light communication.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T14:01:02Z"}
{"aid":"http://arxiv.org/abs/2504.12981v1","title":"Efficient Chebyshev Reconstruction for the Anisotropic Equilibrium Model\n  in Magnetic Particle Imaging","summary":"Magnetic Particle Imaging (MPI) is a tomographic imaging modality capable of\nreal-time, high-sensitivity mapping of superparamagnetic iron oxide\nnanoparticles. Model-based image reconstruction provides an alternative to\nconventional methods that rely on a measured system matrix, eliminating the\nneed for laborious calibration measurements. Nevertheless, model-based\napproaches must account for the complexities of the imaging chain to maintain\nhigh image quality. A recently proposed direct reconstruction method leverages\nweighted Chebyshev polynomials in the frequency domain, removing the need for a\nsimulated system matrix. However, the underlying model neglects key physical\neffects, such as nanoparticle anisotropy, leading to distortions in\nreconstructed images. To mitigate these artifacts, an adapted direct Chebyshev\nreconstruction (DCR) method incorporates a spatially variant deconvolution\nstep, significantly improving reconstruction accuracy at the cost of increased\ncomputational demands. In this work, we evaluate the adapted DCR on six\nexperimental phantoms, demonstrating enhanced reconstruction quality in real\nmeasurements and achieving image fidelity comparable to or exceeding that of\nsimulated system matrix reconstruction. Furthermore, we introduce an efficient\napproximation for the spatially variable deconvolution, reducing both runtime\nand memory consumption while maintaining accuracy. This method achieves\ncomputational complexity of O(N log N ), making it particularly beneficial for\nhigh-resolution and three-dimensional imaging. Our results highlight the\npotential of the adapted DCR approach for improving model-based MPI\nreconstruction in practical applications.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.NA,eess.IV,math.NA","published":"2025-04-17T14:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.12988v1","title":"Why Ask One When You Can Ask $k$? Two-Stage Learning-to-Defer to a Set\n  of Experts","summary":"Learning-to-Defer (L2D) enables decision-making systems to improve\nreliability by selectively deferring uncertain predictions to more competent\nagents. However, most existing approaches focus exclusively on single-agent\ndeferral, which is often inadequate in high-stakes scenarios that require\ncollective expertise. We propose Top-$k$ Learning-to-Defer, a generalization of\nthe classical two-stage L2D framework that allocates each query to the $k$ most\nconfident agents instead of a single one. To further enhance flexibility and\ncost-efficiency, we introduce Top-$k(x)$ Learning-to-Defer, an adaptive\nextension that learns the optimal number of agents to consult for each query,\nbased on input complexity, agent competency distributions, and consultation\ncosts. For both settings, we derive a novel surrogate loss and prove that it is\nBayes-consistent and $(\\mathcal{R}, \\mathcal{G})$-consistent, ensuring\nconvergence to the Bayes-optimal allocation. Notably, we show that the\nwell-established model cascades paradigm arises as a restricted instance of our\nTop-$k$ and Top-$k(x)$ formulations. Extensive experiments across diverse\nbenchmarks demonstrate the effectiveness of our framework on both\nclassification and regression tasks.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-17T14:50:40Z"}
{"aid":"http://arxiv.org/abs/2504.12989v1","title":"Query Complexity of Classical and Quantum Channel Discrimination","summary":"Quantum channel discrimination has been studied from an information-theoretic\nperspective, wherein one is interested in the optimal decay rate of error\nprobabilities as a function of the number of unknown channel accesses. In this\npaper, we study the query complexity of quantum channel discrimination, wherein\nthe goal is to determine the minimum number of channel uses needed to reach a\ndesired error probability. To this end, we show that the query complexity of\nbinary channel discrimination depends logarithmically on the inverse error\nprobability and inversely on the negative logarithm of the (geometric and\nHolevo) channel fidelity. As a special case of these findings, we precisely\ncharacterize the query complexity of discriminating between two classical\nchannels. We also provide lower and upper bounds on the query complexity of\nbinary asymmetric channel discrimination and multiple quantum channel\ndiscrimination. For the former, the query complexity depends on the geometric\nR\\'enyi and Petz R\\'enyi channel divergences, while for the latter, it depends\non the negative logarithm of (geometric and Uhlmann) channel fidelity. For\nmultiple channel discrimination, the upper bound scales as the logarithm of the\nnumber of channels.","main_category":"quant-ph","categories":"quant-ph,cs.IT,cs.LG,math.IT,math.ST,stat.TH","published":"2025-04-17T14:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.12996v1","title":"SHA256 at SemEval-2025 Task 4: Selective Amnesia -- Constrained\n  Unlearning for Large Language Models via Knowledge Isolation","summary":"Large language models (LLMs) frequently memorize sensitive information during\ntraining, posing risks when deploying publicly accessible models. Current\nmachine unlearning methods struggle to selectively remove specific data\nassociations without degrading overall model capabilities. This paper presents\nour solution to SemEval-2025 Task 4 on targeted unlearning, which introduces a\ntwo-stage methodology that combines causal mediation analysis with\nlayer-specific optimization. Through systematic causal tracing experiments on\nOLMo architectures (1B and 7B parameters), we identify the critical role of the\nfirst few transformer layers (layers 0-5) in storing subject-attribute\nassociations within MLP modules. Building on this insight, we develop a\nconstrained optimization approach that freezes upper layers while applying a\nnovel joint loss function to lower layers-simultaneously maximizing forget set\nloss via output token cross-entropy penalties and minimizing retain set\ndeviation through adaptive regularization. Our method achieves 2nd place in the\n1B model track, demonstrating strong task performance while maintaining 88% of\nbaseline MMLU accuracy. These results establish causal-informed layer\noptimization as a promising paradigm for efficient, precise unlearning in LLMs,\noffering a significant step forward in addressing data privacy concerns in AI\nsystems.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T15:05:40Z"}
{"aid":"http://arxiv.org/abs/2504.13011v1","title":"Two-loop Feynman integrals for leading colour $t\\bar{t}W$ production at\n  hadron colliders","summary":"We compute a complete set of the two-loop Feynman integrals that are required\nfor the next-to-next-to-leading order QCD corrections to on-shell top-pair\nproduction in association with a $W$ boson at hadron colliders in the leading\ncolour approximation. These Feynman integrals also contribute to Higgs or\n$Z$-boson production in association with a top pair. We employ the method of\ndifferential equations (DEs), facilitated by the use of finite field methods to\nhandle the algebraic complexity stemming from the seven-scale kinematics. The\npresence of the top quark in the virtual propagators, in addition to the mass\nof the external $W$ boson, gives rise to nested square roots and three elliptic\ncurves. We obtain DEs that depend at most quadratically on the dimensional\nregulator $\\epsilon$ for sectors where these analytic structures appear, and\nare $\\epsilon$-factorised otherwise. We express the DEs in terms of a minimal\nset of differential one-forms, separating the logarithmic ones. We solve the\nDEs numerically in the physical kinematic region, with the method of\ngeneralised power series expansions.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-17T15:17:35Z"}
{"aid":"http://arxiv.org/abs/2504.13026v1","title":"TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for\n  Remote Sensing Image Super-Resolution","summary":"Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution\n(HR) remote sensing images from low-resolution inputs to support fine-grained\nground object interpretation. Existing methods face three key challenges: (1)\nDifficulty in extracting multi-scale features from spatially heterogeneous RS\nscenes, (2) Limited prior information causing semantic inconsistency in\nreconstructions, and (3) Trade-off imbalance between geometric accuracy and\nvisual quality. To address these issues, we propose the Texture Transfer\nResidual Denoising Dual Diffusion Model (TTRD3) with three innovations: First,\na Multi-scale Feature Aggregation Block (MFAB) employing parallel heterogeneous\nconvolutional kernels for multi-scale feature extraction. Second, a Sparse\nTexture Transfer Guidance (STTG) module that transfers HR texture priors from\nreference images of similar scenes. Third, a Residual Denoising Dual Diffusion\nModel (RDDM) framework combining residual diffusion for deterministic\nreconstruction and noise diffusion for diverse generation. Experiments on\nmulti-source RS datasets demonstrate TTRD3's superiority over state-of-the-art\nmethods, achieving 1.43% LPIPS improvement and 3.67% FID enhancement compared\nto best-performing baselines. Code/model: https://github.com/LED-666/TTRD3.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:37:13Z"}
{"aid":"http://arxiv.org/abs/2504.13028v1","title":"Profinite Iterated Monodromy Groups of Unicritical Polynomials","summary":"Let $f(x) = ax^d + b \\in K[x]$ be a unicritical polynomial with degree $d\n\\geq 2$ which is coprime to $\\mathrm{char} K$. We provide an explicit\npresentation for the profinite iterated monodromy group of $f$, analyze the\nstructure of this group, and use this analysis to determine the constant field\nextension in $K(f^{-\\infty}(t))/K(t)$.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-17T15:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.13047v1","title":"Observation of quantum entanglement between free electrons and photons","summary":"Quantum entanglement is central to both the foundations of quantum mechanics\nand the development of new technologies in information processing,\ncommunication, and sensing. Entanglement has been realised in a variety of\nphysical systems, spanning atoms, ions, photons, collective excitations, and\nhybrid combinations of particles. Remarkably, however, photons and free\nelectrons -- the quanta of light and their most elementary sources -- have\nnever been observed in an entangled state. Here, we demonstrate quantum\nentanglement between free electrons and photons. We show that entanglement is\nproduced when an electron, prepared in a superposition of two beams, passes a\nnanostructure and generates transition radiation in a polarisation state tied\nto the electron path. By implementing quantum state tomography, we reconstruct\nthe full density matrix of the electron-photon pair, and show that the\nPeres-Horodecki separability criterion is violated by more than 7 standard\ndeviations. Based on this foundational element of emerging free-electron\nquantum optics, we anticipate manifold developments in enhanced electron\nimaging and spectroscopy beyond the standard quantum limit. More broadly, the\nability to generate and measure entanglement opens electron microscopy to\npreviously inaccessible quantum observables and correlations in solids and\nnanostructures.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T16:03:05Z"}
{"aid":"http://arxiv.org/abs/2504.13066v1","title":"Some spherical function values for two-row tableaux and Young subgroups\n  with three factors","summary":"A Young subgroup of the symmetric group $\\mathcal{S}_{N}$ with three factors,\nis realized as the stabilizer $G_{n}$ of a monomial $x^{\\lambda}$ (\n$=x_{1}^{\\lambda_{1}}x_{2}^{\\lambda_{2}}\\cdots x_{N}^{\\lambda_{N}}$) with\n$\\lambda=\\left( d_{1}^{n_{1}},d_{2}^{n_{2}},d_{3}^{n_{3}}\\right) $ (meaning\n$d_{j}$ is repeated $n_{j}$ times, $1\\leq j\\leq3$), thus is isomorphic to the\ndirect product $\\mathcal{S}_{n_{1}}\\times\\mathcal{S}_{n_{2}}\\times\n\\mathcal{S}_{n_{3}}$. The orbit of $x^{\\lambda}$ under the action of\n$\\mathcal{S}_{N}$ (by permutation of coordinates) spans a module $V_{\\lambda}%\n$, the representation induced from the identity representation of $G_{n}$. The\nspace $V_{\\lambda}$ decomposes into a direct sum of irreducible $\\mathcal{S}%\n_{N}$-modules. The spherical function is defined for each of these, it is the\ncharacter of the module averaged over the group $G_{n}$. This paper concerns\nthe value of certain spherical functions evaluated at a cycle which has no more\nthan one entry in each of the three intervals $I_{j}=\\left\\{\ni:\\lambda_{i}=d_{j}\\right\\} ,1\\leq j\\leq3$. These values appear in the study of\neigenvalues of the Heckman-Polychronakos operators in the paper by V. Gorin and\nthe author (arXiv:2412:01938v1). The present paper determines the spherical\nfunction values for $\\mathcal{S}_{N}$-modules $V$ of two-row tableau type,\ncorresponding to Young tableaux of shape $\\left[ N-k,k\\right] $. The method is\nbased on analyzing the effect of a cycle on $G_{n}$-invariant elements of $V$.\nThese are constructed in terms of Hahn polynomials in two variables.","main_category":"math.RT","categories":"math.RT,math.CA","published":"2025-04-17T16:20:29Z"}
{"aid":"http://arxiv.org/abs/2504.13078v1","title":"Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual\n  Try-Off","summary":"Computer vision is transforming fashion through Virtual Try-On (VTON) and\nVirtual Try-Off (VTOFF). VTON generates images of a person in a specified\ngarment using a target photo and a standardized garment image, while a more\nchallenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo\nof another person wearing the garment. VTOFF, on the other hand, extracts\nstandardized garment images from clothed individuals. We introduce TryOffDiff,\na diffusion-based VTOFF model. Built on a latent diffusion framework with\nSigLIP image conditioning, it effectively captures garment properties like\ntexture, shape, and patterns. TryOffDiff achieves state-of-the-art results on\nVITON-HD and strong performance on DressCode dataset, covering upper-body,\nlower-body, and dresses. Enhanced with class-specific embeddings, it pioneers\nmulti-garment VTOFF, the first of its kind. When paired with VTON models, it\nimproves p2p-VTON by minimizing unwanted attribute transfer, such as skin\ncolor. Code is available at: https://rizavelioglu.github.io/tryoffdiff/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T16:45:18Z"}
{"aid":"http://arxiv.org/abs/2504.13101v1","title":"An Empirically Grounded Identifiability Theory Will Accelerate\n  Self-Supervised Learning Research","summary":"Self-Supervised Learning (SSL) powers many current AI systems. As research\ninterest and investment grow, the SSL design space continues to expand. The\nPlatonic view of SSL, following the Platonic Representation Hypothesis (PRH),\nsuggests that despite different methods and engineering approaches, all\nrepresentations converge to the same Platonic ideal. However, this phenomenon\nlacks precise theoretical explanation. By synthesizing evidence from\nIdentifiability Theory (IT), we show that the PRH can emerge in SSL. However,\ncurrent IT cannot explain SSL's empirical success. To bridge the gap between\ntheory and practice, we propose expanding IT into what we term Singular\nIdentifiability Theory (SITh), a broader theoretical framework encompassing the\nentire SSL pipeline. SITh would allow deeper insights into the implicit data\nassumptions in SSL and advance the field towards learning more interpretable\nand generalizable representations. We highlight three critical directions for\nfuture research: 1) training dynamics and convergence properties of SSL; 2) the\nimpact of finite samples, batch size, and data diversity; and 3) the role of\ninductive biases in architecture, augmentations, initialization schemes, and\noptimizers.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-17T17:10:33Z"}
{"aid":"http://arxiv.org/abs/2504.13108v1","title":"Global patterns in signed permutations","summary":"Global permutation patterns have recently been shown to characterize\nimportant properties of a Coxeter group. Here we study global patterns in the\ncontext of signed permutations, with both characterizing and enumerative\nresults. Surprisingly, many properties of signed permutations may be\ncharacterized by avoidance of the same set of patterns as the corresponding\nproperties in the symmetric group. We also extend previous enumerative work of\nEgge, and our work has connections to the Garfinkle--Barbasch--Vogan\ncorrespondence, the Erd\\H{o}s--Szekeres theorem, and well-known integer\nsequences.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T17:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.13119v1","title":"Object-Driven Narrative in AR: A Scenario-Metaphor Framework with VLM\n  Integration","summary":"Most adaptive AR storytelling systems define environmental semantics using\nsimple object labels and spatial coordinates, limiting narratives to rigid,\npre-defined logic. This oversimplification overlooks the contextual\nsignificance of object relationships-for example, a wedding ring on a\nnightstand might suggest marital conflict, yet is treated as just \"two objects\"\nin space. To address this, we explored integrating Vision Language Models\n(VLMs) into AR pipelines. However, several challenges emerged: First, stories\ngenerated with simple prompt guidance lacked narrative depth and spatial usage.\nSecond, spatial semantics were underutilized, failing to support meaningful\nstorytelling. Third, pre-generated scripts struggled to align with AR\nFoundation's object naming and coordinate systems. We propose a scene-driven AR\nstorytelling framework that reimagines environments as active narrative agents,\nbuilt on three innovations: 1. State-aware object semantics: We decompose\nobject meaning into physical, functional, and metaphorical layers, allowing\nVLMs to distinguish subtle narrative cues between similar objects. 2.\nStructured narrative interface: A bidirectional JSON layer maps VLM-generated\nmetaphors to AR anchors, maintaining spatial and semantic coherence. 3. STAM\nevaluation framework: A three-part experimental design evaluates narrative\nquality, highlighting both strengths and limitations of VLM-AR integration. Our\nfindings show that the system can generate stories from the environment itself,\nnot just place them on top of it. In user studies, 70% of participants reported\nseeing real-world objects differently when narratives were grounded in\nenvironmental symbolism. By merging VLMs' generative creativity with AR's\nspatial precision, this framework introduces a novel object-driven storytelling\nparadigm, transforming passive spaces into active narrative landscapes.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-17T17:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.13130v1","title":"General Analytic Solutions for Circumplanetary Disks during the Late\n  Stages of Giant Planet Formation","summary":"Forming giant planets are accompanied by circumplanetary disks, as indicated\nby considerations of angular momentum conservation, observations of candidate\nprotoplanets, and the satellite systems of planets in our Solar System. This\npaper derives surface density distributions for circumplanetary disks during\nthe final stage of evolution when most of the mass is accreted. This approach\ngeneralizes previous treatments to include the angular momentum bias for the\ninfalling material, more accurate solutions for the incoming trajectories,\ncorrections to the outer boundary condition of the circumplanetary disk, and\nthe adjustment of newly added material as it becomes incorporated into the\nKeplerian flow of the pre-existing disk. These generalizations lead to smaller\ncentrifugal radii, higher column density for the surrounding envelopes, and\nhigher disk accretion efficiency. In addition, we explore the consequences of\ndifferent angular distributions for the incoming material at the outer\nboundary, with the concentration of the incoming flow varying from polar to\nisotropic to equatorial. These geometric variations modestly affect the disk\nsurface density, but also lead to substantial modification to the location in\nthe disk where the mass accretion rate changes sign. This paper finds analytic\nsolutions for the orbits, source functions, surface density distributions, and\nthe corresponding disk temperature profiles over the expanded parameter space\noutlined above.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-17T17:45:32Z"}
{"aid":"http://arxiv.org/abs/2504.13136v1","title":"Freezing of the renormalized one-loop primordial scalar power spectrum","summary":"By consistently using the effective field theory of inflationary fluctuations\nin the decoupling limit, we explicitly prove that the renormalized one-loop\npower spectrum of the primordial curvature perturbation freezes exactly on\nscales larger than its sound horizon.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-17T17:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.13138v1","title":"Extending the Mott-Gurney law to one-dimensional nonplanar diodes using\n  point transformations","summary":"Recent studies have applied variational calculus, conformal mapping, and\npoint transformations to generalize the one-dimensional (1D) space-charge\nlimited current density (SCLCD) and electron emission mechanisms to nonplanar\ngeometries; however, these assessments have focused on extending the\nChild-Langmuir law (CLL) for SCLCD in vacuum. Since the charge in the diode is\nindependent of coordinate system (i.e., covariant), we apply bijective point\ntransformations to extend the Mott-Gurney law (MGL) for the SCLCD in a\ncollisional or semiconductor gap to nonplanar 1D geometries. This yields a\nmodified MGL that replaces the Cartesian gap distance with a canonical gap\ndistance that may be written generally in terms of geometric scale factors that\nare known for multiple geometries. We tabulate results for common geometries.\nSuch an approach may be applied to any current density, including\nnon-space-charge limited gaps and SCLCD that may fall between the CLL and MGL.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.plasm-ph","published":"2025-04-17T17:49:06Z"}
{"aid":"http://arxiv.org/abs/2504.13143v1","title":"$\\texttt{Complex-Edit}$: CoT-Like Instruction Generation for\n  Complexity-Controllable Image Editing Benchmark","summary":"We introduce $\\texttt{Complex-Edit}$, a comprehensive benchmark designed to\nsystematically evaluate instruction-based image editing models across\ninstructions of varying complexity. To develop this benchmark, we harness\nGPT-4o to automatically collect a diverse set of editing instructions at scale.\nOur approach follows a well-structured ``Chain-of-Edit'' pipeline: we first\ngenerate individual atomic editing tasks independently and then integrate them\nto form cohesive, complex instructions. Additionally, we introduce a suite of\nmetrics to assess various aspects of editing performance, along with a\nVLM-based auto-evaluation pipeline that supports large-scale assessments. Our\nbenchmark yields several notable insights: 1) Open-source models significantly\nunderperform relative to proprietary, closed-source models, with the\nperformance gap widening as instruction complexity increases; 2) Increased\ninstructional complexity primarily impairs the models' ability to retain key\nelements from the input images and to preserve the overall aesthetic quality;\n3) Decomposing a complex instruction into a sequence of atomic steps, executed\nin a step-by-step manner, substantially degrades performance across multiple\nmetrics; 4) A straightforward Best-of-N selection strategy improves results for\nboth direct editing and the step-by-step sequential approach; and 5) We observe\na ``curse of synthetic data'': when synthetic data is involved in model\ntraining, the edited images from such models tend to appear increasingly\nsynthetic as the complexity of the editing instructions rises -- a phenomenon\nthat intriguingly also manifests in the latest GPT-4o outputs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T17:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.13157v1","title":"AerialMegaDepth: Learning Aerial-Ground Reconstruction and View\n  Synthesis","summary":"We explore the task of geometric reconstruction of images captured from a\nmixture of ground and aerial views. Current state-of-the-art learning-based\napproaches fail to handle the extreme viewpoint variation between aerial-ground\nimage pairs. Our hypothesis is that the lack of high-quality, co-registered\naerial-ground datasets for training is a key reason for this failure. Such data\nis difficult to assemble precisely because it is difficult to reconstruct in a\nscalable way. To overcome this challenge, we propose a scalable framework\ncombining pseudo-synthetic renderings from 3D city-wide meshes (e.g., Google\nEarth) with real, ground-level crowd-sourced images (e.g., MegaDepth). The\npseudo-synthetic data simulates a wide range of aerial viewpoints, while the\nreal, crowd-sourced images help improve visual fidelity for ground-level images\nwhere mesh-based renderings lack sufficient detail, effectively bridging the\ndomain gap between real images and pseudo-synthetic renderings. Using this\nhybrid dataset, we fine-tune several state-of-the-art algorithms and achieve\nsignificant improvements on real-world, zero-shot aerial-ground tasks. For\nexample, we observe that baseline DUSt3R localizes fewer than 5% of\naerial-ground pairs within 5 degrees of camera rotation error, while\nfine-tuning with our data raises accuracy to nearly 56%, addressing a major\nfailure point in handling large viewpoint changes. Beyond camera estimation and\nscene reconstruction, our dataset also improves performance on downstream tasks\nlike novel-view synthesis in challenging aerial-ground scenarios, demonstrating\nthe practical value of our approach in real-world applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:57:05Z"}
{"aid":"http://arxiv.org/abs/2504.13172v1","title":"SemCORE: A Semantic-Enhanced Generative Cross-Modal Retrieval Framework\n  with MLLMs","summary":"Cross-modal retrieval (CMR) is a fundamental task in multimedia research,\nfocused on retrieving semantically relevant targets across different\nmodalities. While traditional CMR methods match text and image via\nembedding-based similarity calculations, recent advancements in pre-trained\ngenerative models have established generative retrieval as a promising\nalternative. This paradigm assigns each target a unique identifier and\nleverages a generative model to directly predict identifiers corresponding to\ninput queries without explicit indexing. Despite its great potential, current\ngenerative CMR approaches still face semantic information insufficiency in both\nidentifier construction and generation processes. To address these limitations,\nwe propose a novel unified Semantic-enhanced generative Cross-mOdal REtrieval\nframework (SemCORE), designed to unleash the semantic understanding\ncapabilities in generative cross-modal retrieval task. Specifically, we first\nconstruct a Structured natural language IDentifier (SID) that effectively\naligns target identifiers with generative models optimized for natural language\ncomprehension and generation. Furthermore, we introduce a Generative Semantic\nVerification (GSV) strategy enabling fine-grained target discrimination.\nAdditionally, to the best of our knowledge, SemCORE is the first framework to\nsimultaneously consider both text-to-image and image-to-text retrieval tasks\nwithin generative cross-modal retrieval. Extensive experiments demonstrate that\nour framework outperforms state-of-the-art generative cross-modal retrieval\nmethods. Notably, SemCORE achieves substantial improvements across benchmark\ndatasets, with an average increase of 8.65 points in Recall@1 for text-to-image\nretrieval.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.MM","published":"2025-04-17T17:59:27Z"}
{"aid":"http://arxiv.org/abs/2504.14833v1","title":"IoT-AMLHP: Aligned Multimodal Learning of Header-Payload Representations\n  for Resource-Efficient Malicious IoT Traffic Classification","summary":"Traffic classification is crucial for securing Internet of Things (IoT)\nnetworks. Deep learning-based methods can autonomously extract latent patterns\nfrom massive network traffic, demonstrating significant potential for IoT\ntraffic classification tasks. However, the limited computational and spatial\nresources of IoT devices pose challenges for deploying more complex deep\nlearning models. Existing methods rely heavily on either flow-level features or\nraw packet byte features. Flow-level features often require inspecting entire\nor most of the traffic flow, leading to excessive resource consumption, while\nraw packet byte features fail to distinguish between headers and payloads,\noverlooking semantic differences and introducing noise from feature\nmisalignment. Therefore, this paper proposes IoT-AMLHP, an aligned multimodal\nlearning framework for resource-efficient malicious IoT traffic classification.\nFirstly, the framework constructs a packet-wise header-payload representation\nby parsing packet headers and payload bytes, resulting in an aligned and\nstandardized multimodal traffic representation that enhances the\ncharacterization of heterogeneous IoT traffic. Subsequently, the traffic\nrepresentation is fed into a resource-efficient neural network comprising a\nmultimodal feature extraction module and a multimodal fusion module. The\nextraction module employs efficient depthwise separable convolutions to capture\nmulti-scale features from different modalities while maintaining a lightweight\narchitecture. The fusion module adaptively captures complementary features from\ndifferent modalities and effectively fuses multimodal features.","main_category":"cs.NI","categories":"cs.NI,cs.CR","published":"2025-04-21T03:24:14Z"}
{"aid":"http://arxiv.org/abs/2504.14836v1","title":"Systematic search for blue hyper-velocity stars from LAMOST survey","summary":"Hypervelocity stars (HVSs) represent a unique class of objects capable of\nescaping the gravitational pull of the Milky Way due to extreme acceleration\nevents, such as close encounters with the supermassive black hole at the\nGalactic center (GC), supernova explosions in binary systems, or multi-body\ndynamical interactions. Finding and studying HVSs are crucial to exploring\nthese ejection mechanisms, characterizing central black holes, probing the GC\nenvironment, and revealing the distribution of dark matter in our galaxy. The\nLarge Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST)\nspectroscopic surveys have so far identified four B-type unbound HVSs. To\nexpand this sample with the second-phase LAMOST survey that started in 2018, we\nconducted a systematic search for early-type HVSs using the LAMOST Data Release\n10. We identified 125 early-type high-velocity candidates with total velocities\nexceeding 300 km\\,s$^{-1}$. Among them, we report ten new unbound B- and A-type\nhypervelocity star (HVS) candidates (designated LAMOST-HVS5 through\nLAMOST-HVS14), tripling the number of unbound HVSs previously identified by\nLAMOST. Kinematic analyses suggest that these newly discovered HVS candidates\nlikely originated either from the Galactic Center or via dynamical\ninteractions. Future high-resolution follow-up observations promise to refine\nthe stellar parameters, distances, and elemental abundances of these\ncandidates, thereby providing deeper insights into their origins and broadening\ntheir potential applications across astrophysics.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-21T03:34:00Z"}
{"aid":"http://arxiv.org/abs/2504.14840v1","title":"Spectral Properties of the Gramian of Finite Ultrametric Spaces","summary":"The concept of $p$-negative type is such that a metric space $(X,d_{X})$ has\n$p$-negative type if and only if $(X,d_{X}^{p/2})$ embeds isometrically into a\nHilbert space. If $X=\\{x_{0},x_{1},\\dots,x_{n}\\}$ then the $p$-negative type of\n$X$ is intimately related to the Gramian matrix $G_{p}=(g_{ij})_{i,j=1}^{n}$\nwhere\n$g_{ij}=\\frac{1}{2}(d_{X}(x_{i},x_{0})^{p}+d_{X}(x_{j},x_{0})^{p}-d_{X}(x_{i},x_{j})^{p})$.\nIn particular, $X$ has strict $p$-negative type if and only if $G_{p}$ is\nstrictly positive semidefinite. As such, a natural measure of the degree of\nstrictness of $p$-negative type that $X$ possesses is the minimum eigenvalue of\nthe Gramian $\\lambda_{min}(G_{p})$. In this article we compute the minimum\neigenvalue of the Gramian of a finite ultrametric space. Namely, if $X$ is a\nfinite ultrametric space with minimum nonzero distance $\\alpha_{1}$ then we\nshow that $\\lambda_{min}(G_{p})=\\alpha_{1}^{p}/2$. We also provide a\ndescription of the corresponding eigenspace.","main_category":"math.FA","categories":"math.FA","published":"2025-04-21T03:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.14854v1","title":"Uncertainty quantification of neural network models of evolving\n  processes via Langevin sampling","summary":"We propose a scalable, approximate inference hypernetwork framework for a\ngeneral model of history-dependent processes. The flexible data model is based\non a neural ordinary differential equation (NODE) representing the evolution of\ninternal states together with a trainable observation model subcomponent. The\nposterior distribution corresponding to the data model parameters (weights and\nbiases) follows a stochastic differential equation with a drift term related to\nthe score of the posterior that is learned jointly with the data model\nparameters. This Langevin sampling approach offers flexibility in balancing the\ncomputational budget between the evaluation cost of the data model and the\napproximation of the posterior density of its parameters. We demonstrate\nperformance of the hypernetwork on chemical reaction and material physics data\nand compare it to mean-field variational inference.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-21T04:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.14858v1","title":"AlignRAG: An Adaptable Framework for Resolving Misalignments in\n  Retrieval-Aware Reasoning of RAG","summary":"Retrieval-augmented generation (RAG) has emerged as a foundational paradigm\nfor knowledge-grounded text generation. However, existing RAG pipelines often\nfail to ensure that the reasoning trajectories align with the evidential\nconstraints imposed by retrieved content. In this paper, we reframe RAG as a\nproblem of retrieval-aware reasoning and identify a core challenge: reasoning\nmisalignment-the mismatch between a model's reasoning trajectory and the\nretrieved evidence. To address this challenge, we propose AlignRAG, a novel\ntest-time framework that mitigates reasoning misalignment through iterative\nCritique-Driven Alignment (CDA) steps. In contrast to prior approaches that\nrely on static training or post-hoc selection, AlignRAG actively refines\nreasoning trajectories during inference by enforcing fine-grained alignment\nwith evidence. Our framework introduces a new paradigm for retrieval-aware\nreasoning by: (1) constructing context-rich training corpora; (2) generating\ncontrastive critiques from preference-aware reasoning trajectories; (3)\ntraining a dedicated \\textit{Critic Language Model (CLM)} to identify reasoning\nmisalignments; and (4) applying CDA steps to optimize reasoning trajectories\niteratively. Empirical results demonstrate that AlignRAG consistently\noutperforms all baselines and could integrate as a plug-and-play module into\nexisting RAG pipelines without further changes. By reconceptualizing RAG as a\nstructured reasoning trajectory and establishing the test-time framework for\ncorrecting reasoning misalignments in RAG, AlignRAG provides practical\nadvancements for retrieval-aware generation.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-21T04:56:47Z"}
{"aid":"http://arxiv.org/abs/2504.14859v1","title":"The automorphism group of torsion points of an elliptic curve over a\n  field of characteristic $\\ge 5$","summary":"For a field $\\mathbb{K}$ of characteristic $p\\ge5$ containing\n$\\mathbb{F}_{p}^{\\operatorname{alg}}$ and the elliptic curve $E_{s,t}: y^{2} =\nx^{3} + sx + t$ defined over the function field $\\mathbb{K}\\left(s,t\\right)$ of\ntwo variables $s$ and $t$, we prove that for a non-negative positive integer\n$e$ and a positive integer $N$ which is not divisible by $p$, the automorphism\ngroup of the normal extension\n$\\mathbb{K}\\left(s,t\\right)\\left(E_{s,t}\\left[p^{e} N\\right]\\right)$ over\n$\\mathbb{K}\\left(s,t\\right)$ is isomorphic to\n$\\left(\\mathbb{Z}/p^{e}\\mathbb{Z}\\right)^{\\times} \\times \\operatorname{SL}_{2}\n\\left(\\mathbb{Z}/N\\mathbb{Z}\\right)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-21T04:57:43Z"}
{"aid":"http://arxiv.org/abs/2504.14863v1","title":"On minimal nonperfectly divisible fork-free graphs","summary":"A fork is a graph obtained from $K_{1,3}$ (usually called claw) by\nsubdividing an edge once. A graph is perfectly divisible if for each of its\ninduced subgraph $H$, $V(H)$ can be partitioned into $A$ and $B$ such that\n$H[A]$ is perfect and $\\omega(H[B]) < \\omega(H)$. In this paper, we prove that\nthe perfect divisibility of fork-free graphs is equivalent to that of claw-free\ngraphs. We also prove that, for $F\\in \\{P_7, P_6\\cup K_1\\}$, each (fork,\n$F$)-free graph $G$ is perfectly divisible and hence $\\chi(G)\\leq\n\\binom{\\omega(G)+1}{2}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-21T05:08:16Z"}
{"aid":"http://arxiv.org/abs/2504.14882v1","title":"Some Optimizers are More Equal: Understanding the Role of Optimizers in\n  Group Fairness","summary":"We study whether and how the choice of optimization algorithm can impact\ngroup fairness in deep neural networks. Through stochastic differential\nequation analysis of optimization dynamics in an analytically tractable setup,\nwe demonstrate that the choice of optimization algorithm indeed influences\nfairness outcomes, particularly under severe imbalance. Furthermore, we show\nthat when comparing two categories of optimizers, adaptive methods and\nstochastic methods, RMSProp (from the adaptive category) has a higher\nlikelihood of converging to fairer minima than SGD (from the stochastic\ncategory). Building on this insight, we derive two new theoretical guarantees\nshowing that, under appropriate conditions, RMSProp exhibits fairer parameter\nupdates and improved fairness in a single optimization step compared to SGD. We\nthen validate these findings through extensive experiments on three publicly\navailable datasets, namely CelebA, FairFace, and MS-COCO, across different\ntasks as facial expression recognition, gender classification, and multi-label\nclassification, using various backbones. Considering multiple fairness\ndefinitions including equalized odds, equal opportunity, and demographic\nparity, adaptive optimizers like RMSProp and Adam consistently outperform SGD\nin terms of group fairness, while maintaining comparable predictive accuracy.\nOur results highlight the role of adaptive updates as a crucial yet overlooked\nmechanism for promoting fair outcomes.","main_category":"cs.LG","categories":"cs.LG,cs.CV,stat.ML","published":"2025-04-21T06:20:50Z"}
{"aid":"http://arxiv.org/abs/2504.14900v1","title":"Distributed Time-Varying Gaussian Regression via Kalman Filtering","summary":"We consider the problem of learning time-varying functions in a distributed\nfashion, where agents collect local information to collaboratively achieve a\nshared estimate. This task is particularly relevant in control applications,\nwhenever real-time and robust estimation of dynamic cost/reward functions in\nsafety critical settings has to be performed. In this paper, we,adopt a\nfinite-dimensional approximation of a Gaussian Process, corresponding to a\nBayesian linear regression in an appropriate feature space, and propose a new\nalgorithm, DistKP, to track the time-varying coefficients via a distributed\nKalman filter. The proposed method works for arbitrary kernels and under weaker\nassumptions on the time-evolution of the function to learn compared to the\nliterature. We validate our results using a simulation example in which a fleet\nof Unmanned Aerial Vehicles (UAVs) learns a dynamically changing wind field.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-21T07:12:05Z"}
{"aid":"http://arxiv.org/abs/2504.14903v1","title":"ColBERT-serve: Efficient Multi-Stage Memory-Mapped Scoring","summary":"We study serving retrieval models, specifically late interaction models like\nColBERT, to many concurrent users at once and under a small budget, in which\nthe index may not fit in memory. We present ColBERT-serve, a novel serving\nsystem that applies a memory-mapping strategy to the ColBERT index, reducing\nRAM usage by 90% and permitting its deployment on cheap servers, and\nincorporates a multi-stage architecture with hybrid scoring, reducing ColBERT's\nquery latency and supporting many concurrent queries in parallel.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-21T07:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.14905v1","title":"CRAVE: A Conflicting Reasoning Approach for Explainable Claim\n  Verification Using LLMs","summary":"The rapid spread of misinformation, driven by digital media and AI-generated\ncontent, has made automatic claim verification essential. Traditional methods,\nwhich depend on expert-annotated evidence, are labor-intensive and not\nscalable. Although recent automated systems have improved, they still struggle\nwith complex claims that require nuanced reasoning. To address this, we propose\nCRAVE, a Conflicting Reasoning Approach for explainable claim VErification,\nthat verify the complex claims based on the conflicting rationales reasoned by\nlarge language models (LLMs). Specifically, CRAVE introduces a three-module\nframework. Ambiguity Elimination enchanced Evidence Retrieval module performs\nambiguity elimination and entity-based search to gather relevant evidence\nrelated to claim verification from external sources like Wikipedia. Conflicting\nPerspective Reasoning and Preliminary Judgment module with LLMs adopts LLMs to\nreason rationales with conflicting stances about claim verification from\nretrieved evidence across four dimensions, i.e., direct evidence, semantic\nrelationships, linguistic patterns, and logical reasoning and make a\npreliminary judgment. Finally, Small Language Model (SLM) based Judge module is\nfine-tuned to make use of preliminary judgment from LLMs to assess the\nconfidence of the conflicting rationales and make a final authenticity\njudgment. This methodology allows CRAVE to capture subtle inconsistencies in\ncomplex claims, improving both the accuracy and transparency of claim\nverification. Extensive experiments on two public claim verification datasets\ndemonstrate that our CRAVE model achieves much better performance than\nstate-of-the-art methods and exhibits a superior capacity for finding relevant\nevidence and explaining the model predictions. The code is provided at\nhttps://github.com/8zym/CRAVE.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T07:20:31Z"}
{"aid":"http://arxiv.org/abs/2504.14915v1","title":"StableQuant: Layer Adaptive Post-Training Quantization for Speech\n  Foundation Models","summary":"In this paper, we propose StableQuant, a novel adaptive post-training\nquantization (PTQ) algorithm for widely used speech foundation models (SFMs).\nWhile PTQ has been successfully employed for compressing large language models\n(LLMs) due to its ability to bypass additional fine-tuning, directly applying\nthese techniques to SFMs may not yield optimal results, as SFMs utilize\ndistinct network architecture for feature extraction. StableQuant demonstrates\noptimal quantization performance regardless of the network architecture type,\nas it adaptively determines the quantization range for each layer by analyzing\nboth the scale distributions and overall performance. We evaluate our algorithm\non two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)\ntask, and achieve superior performance compared to traditional PTQ methods.\nStableQuant successfully reduces the sizes of SFM models to a quarter and\ndoubles the inference speed while limiting the word error rate (WER)\nperformance drop to less than 0.3% with 8-bit quantization.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-21T07:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.14932v1","title":"Hilbert expansion of the Boltzmann equation on a 2-dimensional disk with\n  specular boundary condition","summary":"In the present paper, we concern the hydrodynamic limit of Boltzmann equation\nwith specular reflection boundary condition in a two-dimensional disk to the\ncompressible Euler equations. Due to the non-zero curvature and non-zero\ntangential velocity of compressible Euler solution on the boundary, new\ndifficulties arise in the construction of Knudsen boundary layer. By employing\nthe geometric correction, and an innovative and refined $L^2-L^\\infty$ method,\nwe establish the existence and space-decay for a truncated Knudsen boundary\nlayer. Then, by the Hilbert expansion of multi-scales, we successfully justify\nthe hydrodynamic limit of Boltzmann equation with specular reflection boundary\ncondition to the compressible Euler equations in the two-dimensional disk.","main_category":"math.AP","categories":"math.AP","published":"2025-04-21T07:51:48Z"}
{"aid":"http://arxiv.org/abs/2504.14933v1","title":"TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion\n  Models","summary":"In today's age of social media and marketing, copyright issues can be a major\nroadblock to the free sharing of images. Generative AI models have made it\npossible to create high-quality images, but concerns about copyright\ninfringement are a hindrance to their abundant use. As these models use data\nfrom training images to generate new ones, it is often a daunting task to\nensure they do not violate intellectual property rights. Some AI models have\neven been noted to directly copy copyrighted images, a problem often referred\nto as source copying. Traditional copyright protection measures such as\nwatermarks and metadata have also proven to be futile in this regard. To\naddress this issue, we propose a novel two-step image generation model inspired\nby the conditional diffusion model. The first step involves creating an image\nsegmentation mask for some prompt-based generated images. This mask embodies\nthe shape of the image. Thereafter, the diffusion model is asked to generate\nthe image anew while avoiding the shape in question. This approach shows a\ndecrease in structural similarity from the training image, i.e. we are able to\navoid the source copying problem using this approach without expensive\nretraining of the model or user-centered prompt generation techniques. This\nmakes our approach the most computationally inexpensive approach to avoiding\nboth copyright infringement and source copying for diffusion model-based image\ngeneration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.14938v1","title":"Integrating Response Time and Attention Duration in Bayesian Preference\n  Learning for Multiple Criteria Decision Aiding","summary":"We introduce a multiple criteria Bayesian preference learning framework\nincorporating behavioral cues for decision aiding. The framework integrates\npairwise comparisons, response time, and attention duration to deepen insights\ninto decision-making processes. The approach employs an additive value function\nmodel and utilizes a Bayesian framework to derive the posterior distribution of\npotential ranking models by defining the likelihood of observed preference data\nand specifying a prior on the preference structure. This distribution\nhighlights each model's ability to reconstruct Decision-Makers' holistic\npairwise comparisons. By leveraging both response time as a proxy for cognitive\neffort and alternative discriminability as well as attention duration as an\nindicator of criterion importance, the proposed model surpasses traditional\nmethods by uncovering richer behavioral patterns. We report the results of a\nlaboratory experiment on mobile phone contract selection involving 30 real\nsubjects using a dedicated application with time-, eye-, and mouse-tracking\ncomponents. We validate the novel method's ability to reconstruct complete\npreferences. The detailed ablation studies reveal time- and attention-related\nbehavioral patterns, confirming that integrating comprehensive data leads to\ndeveloping models that better align with the DM's actual preferences.","main_category":"stat.AP","categories":"stat.AP,cs.LG","published":"2025-04-21T08:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.14941v1","title":"Vector Embedding, Retrieval-Augmented Generation, CPU-NPU Collaboration,\n  Heterogeneous Computing","summary":"Retrieval-Augmented Generation is a technology that enhances large language\nmodels by integrating information retrieval. In the industry, inference\nservices based on LLMs are highly sensitive to cost-performance ratio,\nprompting the need for improving hardware resource utilization in the inference\nservice. Specifically, vector embedding and retrieval processes take up to 20%\nof the total latency. Therefore, optimizing the utilization of computational\nresources in vector embeddings is crucial for enhancing the cost-performance\nratio of inference processes, which in turn boosts their product\ncompetitiveness.In this paper, we analyze the deployment costs of vector\nembedding technology in inference services, propose a theoretical formula, and\ndetermine through the mathematical expression that increasing the capacity to\nprocess concurrent queries is the key to reducing the deployment costs of\nvector embeddings. Therefore, in this paper, we focus on improving the\nproduct's capability to process concurrent queries. To optimize concurrency\nwithout sacrificing performance, we have designed a queue manager that adeptly\noffloads CPU peak queries. This manager utilizes a linear regression model to\nascertain the optimal queue depths, a critical parameter that significantly\ninfluences the efficacy of the system. We further develop a system named WindVE\nthat uses a CPU-NPU heterogeneous architecture to offload peak concurrent\nqueries, which leverages the performance differences between the two processors\nto effectively manage traffic surges. Through experiments, we compare WindVE to\nthe state-of-the-art vector embedding framework FlagEmbedding, and achieve a\nconcurrency level up to 22.3% higher than the scheme without offloading.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-21T08:02:25Z"}
{"aid":"http://arxiv.org/abs/2504.14946v1","title":"Symmetry-Preserving Architecture for Multi-NUMA Environments (SPANE): A\n  Deep Reinforcement Learning Approach for Dynamic VM Scheduling","summary":"As cloud computing continues to evolve, the adoption of multi-NUMA\n(Non-Uniform Memory Access) architecture by cloud service providers has\nintroduced new challenges in virtual machine (VM) scheduling. To address these\nchallenges and more accurately reflect the complexities faced by modern cloud\nenvironments, we introduce the Dynamic VM Allocation problem in Multi-NUMA PM\n(DVAMP). We formally define both offline and online versions of DVAMP as\nmixed-integer linear programming problems, providing a rigorous mathematical\nfoundation for analysis. A tight performance bound for greedy online algorithms\nis derived, offering insights into the worst-case optimality gap as a function\nof the number of physical machines and VM lifetime variability. To address the\nchallenges posed by DVAMP, we propose SPANE (Symmetry-Preserving Architecture\nfor Multi-NUMA Environments), a novel deep reinforcement learning approach that\nexploits the problem's inherent symmetries. SPANE produces invariant results\nunder arbitrary permutations of physical machine states, enhancing learning\nefficiency and solution quality. Extensive experiments conducted on the\nHuawei-East-1 dataset demonstrate that SPANE outperforms existing baselines,\nreducing average VM wait time by 45%. Our work contributes to the field of\ncloud resource management by providing both theoretical insights and practical\nsolutions for VM scheduling in multi-NUMA environments, addressing a critical\ngap in the literature and offering improved performance for real-world cloud\nsystems.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T08:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.14960v1","title":"MoE Parallel Folding: Heterogeneous Parallelism Mappings for Efficient\n  Large-Scale MoE Model Training with Megatron Core","summary":"Mixture of Experts (MoE) models enhance neural network scalability by\ndynamically selecting relevant experts per input token, enabling larger model\nsizes while maintaining manageable computation costs. However, efficient\ntraining of large-scale MoE models across thousands of GPUs presents\nsignificant challenges due to limitations in existing parallelism strategies.\nWe introduce an end-to-end training framework for large-scale MoE models that\nutilizes five-dimensional hybrid parallelism: Tensor Parallelism, Expert\nParallelism, Context Parallelism, Data Parallelism, and Pipeline Parallelism.\nCentral to our approach is MoE Parallel Folding, a novel strategy that\ndecouples the parallelization of attention and MoE layers in Transformer\nmodels, allowing each layer type to adopt optimal parallel configurations.\nAdditionally, we develop a flexible token-level dispatcher that supports both\ntoken-dropping and token-dropless MoE training across all five dimensions of\nparallelism. This dispatcher accommodates dynamic tensor shapes and coordinates\ndifferent parallelism schemes for Attention and MoE layers, facilitating\ncomplex parallelism implementations. Our experiments demonstrate significant\nimprovements in training efficiency and scalability. We achieve up to 49.3%\nModel Flops Utilization (MFU) for the Mixtral 8x22B model and 39.0% MFU for the\nQwen2-57B-A14B model on H100 GPUs, outperforming existing methods. The\nframework scales efficiently up to 1,024 GPUs and maintains high performance\nwith sequence lengths up to 128K tokens, validating its effectiveness for\nlarge-scale MoE model training. The code is available in Megatron-Core.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-21T08:39:47Z"}
{"aid":"http://arxiv.org/abs/2504.14977v1","title":"RealisDance-DiT: Simple yet Strong Baseline towards Controllable\n  Character Animation in the Wild","summary":"Controllable character animation remains a challenging problem, particularly\nin handling rare poses, stylized characters, character-object interactions,\ncomplex illumination, and dynamic scenes. To tackle these issues, prior work\nhas largely focused on injecting pose and appearance guidance via elaborate\nbypass networks, but often struggles to generalize to open-world scenarios. In\nthis paper, we propose a new perspective that, as long as the foundation model\nis powerful enough, straightforward model modifications with flexible\nfine-tuning strategies can largely address the above challenges, taking a step\ntowards controllable character animation in the wild. Specifically, we\nintroduce RealisDance-DiT, built upon the Wan-2.1 video foundation model. Our\nsufficient analysis reveals that the widely adopted Reference Net design is\nsuboptimal for large-scale DiT models. Instead, we demonstrate that minimal\nmodifications to the foundation model architecture yield a surprisingly strong\nbaseline. We further propose the low-noise warmup and \"large batches and small\niterations\" strategies to accelerate model convergence during fine-tuning while\nmaximally preserving the priors of the foundation model. In addition, we\nintroduce a new test dataset that captures diverse real-world challenges,\ncomplementing existing benchmarks such as TikTok dataset and UBC fashion video\ndataset, to comprehensively evaluate the proposed method. Extensive experiments\nshow that RealisDance-DiT outperforms existing methods by a large margin.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T09:09:21Z"}
{"aid":"http://arxiv.org/abs/2504.14979v1","title":"Identify hadron anomalous couplings at colliders","summary":"We investigate the identification of the Wess-Zumino-Witten (WZW) Lagrangian\nat colliders such as BESIII and the Super-$\\tau$-Charm Facility. Our analysis\nconcentrates on the radiative decays of $\\eta$ and $\\eta'$ mesons, including\n$\\eta^{(\\prime)} \\to \\gamma\\gamma$, $\\eta^{(\\prime)} \\to \\gamma\\ell^+ \\ell^-$,\n$\\eta^{(\\prime)} \\to \\pi^+\\pi^-\\gamma$, and $\\eta^{(\\prime)} \\to\n\\pi^+\\pi^-\\ell^+\\ell^-$, as well as semileptonic kaon decays such as $K^+ \\to\n\\pi^+\\pi^- e^+ \\nu_e$. Employing the hidden local symmetry framework to\nincorporate vector meson contributions, we compute the decay amplitudes and\nform factors. For the decay $\\eta \\to \\pi^+\\pi^-\\gamma$, the box anomaly\ndominates, and we find that the anomalous coupling can be experimentally\ndetermined to percent-level precision at BESIII. In contrast, vector meson\ncontributions are significant in the decay $\\eta' \\to \\pi^+\\pi^-\\gamma$. Using\nexperimental data for $\\eta' \\to \\pi^+\\pi^-\\gamma$, we obtain ${\\cal\nB}_{\\mathrm{box}}^{\\text{exp}} = (1.70 \\pm 0.05)\\%$, which is approximately ten\ntimes larger than previously expected experimentally. We observe good agreement\nbetween our calculated anomalous couplings and experimental results. In kaon\ndecays, WZW terms uniquely contribute to the form factor $H$, which can be\nextracted from parity-conserving decay distributions. While predictions at the\nchiral point closely match experimental values (e.g., $H^+ = -2.31$ versus\n$-2.27 \\pm 0.10$), we find that intermediate vector meson states introduce\nsubstantial corrections, potentially as large as 25%. We strongly advocate for\nrevisiting these experiments to achieve improved precision in form factor\nextractions.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-21T09:14:32Z"}
{"aid":"http://arxiv.org/abs/2504.14992v1","title":"Efficient Pretraining Length Scaling","summary":"Recent advances in large language models have demonstrated the effectiveness\nof length scaling during post-training, yet its potential in pre-training\nremains underexplored. We present the Parallel Hidden Decoding Transformer\n(\\textit{PHD}-Transformer), a novel framework that enables efficient length\nscaling during pre-training while maintaining inference efficiency.\n\\textit{PHD}-Transformer achieves this through an innovative KV cache\nmanagement strategy that distinguishes between original tokens and hidden\ndecoding tokens. By retaining only the KV cache of original tokens for\nlong-range dependencies while immediately discarding hidden decoding tokens\nafter use, our approach maintains the same KV cache size as the vanilla\ntransformer while enabling effective length scaling. To further enhance\nperformance, we introduce two optimized variants: \\textit{PHD-SWA} employs\nsliding window attention to preserve local dependencies, while\n\\textit{PHD-CSWA} implements chunk-wise sliding window attention to eliminate\nlinear growth in pre-filling time. Extensive experiments demonstrate consistent\nimprovements across multiple benchmarks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T09:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.15003v1","title":"NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and\n  Enhancement: KwaiSR Dataset and Study","summary":"In this work, we build the first benchmark dataset for short-form UGC Image\nSuper-resolution in the wild, termed KwaiSR, intending to advance the research\non developing image super-resolution algorithms for short-form UGC platforms.\nThis dataset is collected from the Kwai Platform, which is composed of two\nparts, i.e., synthetic and wild parts. Among them, the synthetic dataset,\nincluding 1,900 image pairs, is produced by simulating the degradation\nfollowing the distribution of real-world low-quality short-form UGC images,\naiming to provide the ground truth for training and objective comparison in the\nvalidation/testing. The wild dataset contains low-quality images collected\ndirectly from the Kwai Platform, which are filtered using the quality\nassessment method KVQ from the Kwai Platform. As a result, the KwaiSR dataset\ncontains 1800 synthetic image pairs and 1900 wild images, which are divided\ninto training, validation, and testing parts with a ratio of 8:1:1. Based on\nthe KwaiSR dataset, we organize the NTIRE 2025 challenge on a second short-form\nUGC Video quality assessment and enhancement, which attracts lots of\nresearchers to develop the algorithm for it. The results of this competition\nhave revealed that our KwaiSR dataset is pretty challenging for existing Image\nSR methods, which is expected to lead to a new direction in the image\nsuper-resolution field. The dataset can be found from\nhttps://lixinustc.github.io/NTIRE2025-KVQE-KwaSR-KVQ.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T10:04:26Z"}
{"aid":"http://arxiv.org/abs/2504.15006v1","title":"Sum-Rate Maximization for NOMA-Assisted Pinching-Antenna Systems","summary":"In this letter, we investigate a non-orthogonal multiple access (NOMA)\nassisted downlink pinching-antenna system. Leveraging the ability of pinching\nantennas to flexibly adjust users' wireless channel conditions, we formulate an\noptimization problem to maximize the sum rate by optimizing both the users'\npower allocation coefficients and the positions of pinching antennas. The\noptimal power allocation coefficients are obtained in closed-form by using the\nKarush-Kuhn-Tucker (KKT) conditions. The optimization problem of pinching\nantenna placements is more challenging than the power allocation problem, and\nis solved by a bisection-based search algorithm. In particular, the algorithm\nfirst optimizes the antenna placements to create favorable channel disparities\nbetween users, followed by fine-tuning the antenna positions to ensure the\nphase alignment for users, thus maximizing the sum rate. Simulation results\ndemonstrate that, compared to conventional-antenna systems, pinching antennas\ncan significantly enhance the sum rate in NOMA scenarios, and the proposed\nbisection-based search algorithm can achieve a sum rate nearly equivalent to\nthat of an exhaustive search.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T10:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.15010v1","title":"The Schouten-Nijenhuis bracket in infinite dimensions","summary":"The Schouten-Nijenhuis bracket on smooth infinite-dimensional manifolds $M$\nis developed in two steps: For summable multivector fields whose pointwise dual\nare all differential form, and in an extended form for multivector fields which\nare sections of $L^{\\bullet}_{\\text{skew}}(T^*M,\\mathbb R)$. We need to either\nassume that $C^{\\infty}(M)$ separates points on $TM$, or consider sheaves of\nlocal sections.","main_category":"math.DG","categories":"math.DG,math.FA","published":"2025-04-21T10:23:40Z"}
{"aid":"http://arxiv.org/abs/2504.15014v1","title":"Computations of Spin-Sp(4), Spin-SU(8), and Spin-Spin(16) bordism groups\n  in dimensions up to 7","summary":"We investigate the structure of Spin-$G$ bordism groups, focusing on the\ninterplay between Spin and additional twisting symmetries such as $Sp(4)$,\n$SU(8)$ and $Spin(16)$. Using techniques from spectral sequences, obstruction\ntheory, and cohomology operations, we compute explicit generators for the\nSpin-$G$ bordism groups in dimensions up to 7.","main_category":"math.AT","categories":"math.AT","published":"2025-04-21T10:47:10Z"}
{"aid":"http://arxiv.org/abs/2504.15027v1","title":"DistilQwen2.5: Industrial Practices of Training Distilled Open\n  Lightweight Language Models","summary":"Enhancing computational efficiency and reducing deployment costs for large\nlanguage models (LLMs) have become critical challenges in various\nresource-constrained scenarios. In this work, we present DistilQwen2.5, a\nfamily of distilled, lightweight LLMs derived from the public Qwen2.5 models.\nThese distilled models exhibit enhanced instruction-following capabilities\ncompared to the original models based on a series of distillation techniques\nthat incorporate knowledge from much larger LLMs. In our industrial practice,\nwe first leverage powerful proprietary LLMs with varying capacities as\nmulti-agent teachers to select, rewrite, and refine instruction-response pairs\nthat are more suitable for student LLMs to learn. After standard fine-tuning,\nwe further leverage a computationally efficient model fusion approach that\nenables student models to progressively integrate fine-grained hidden knowledge\nfrom their teachers. Experimental evaluations demonstrate that the distilled\nmodels possess significantly stronger capabilities than their original\ncheckpoints. Additionally, we present use cases to illustrate the applications\nof our framework in real-world scenarios. To facilitate practical use, we have\nreleased all the DistilQwen2.5 models to the open-source community.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T11:26:02Z"}
{"aid":"http://arxiv.org/abs/2504.15045v1","title":"Period-luminosity and period-luminosity-metallicity relation for\n  $Î´$ Scuti Stars","summary":"$\\delta$ Scuti ($\\delta$ Sct) stars are potential distance tracers for\nstudying the Milky Way structure. We conduct a comprehensive analysis of the\nperiod-luminosity (PL) and period-luminosity-metallicity (PLZ) relation for\n$\\delta$ Sct stars, integrating data from the Zwicky Transient Facility (ZTF),\nthe Transiting Exoplanet Survey Satellite (TESS), Large Sky Area Multi-Object\nFiber Spectroscopic Telescope (LAMOST), Apache Point Observatory Galactic\nEvolution Experiment (APOGEE), and Gaia. To mitigate the impact of the Gaia\nparallax zero point offset, we applied a correction method, determining the\noptimal zero point value to be $zp_\\varpi = 35 \\pm 2 \\, \\mu\\text{as}$. Using\nthe three best bands, by varying the parallax error threshold, we found that\nthe total error of the PLR zero point was minimized to 0.9\\% at a parallax\nerror threshold of 6\\%. With this threshold, we derived the PL and PLZ relation\nfor nine bands (from optical to mid-infrared) and five Wesenheit bands. Through\nour analysis, we conclude that the influence of metallicity on the PLR of\n$\\delta$ Sct stars is not significant, and the differences across various bands\nare minimal.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-21T11:57:12Z"}
{"aid":"http://arxiv.org/abs/2504.15049v1","title":"ScanEdit: Hierarchically-Guided Functional 3D Scan Editing","summary":"With the fast pace of 3D capture technology and resulting abundance of 3D\ndata, effective 3D scene editing becomes essential for a variety of graphics\napplications. In this work we present ScanEdit, an instruction-driven method\nfor functional editing of complex, real-world 3D scans. To model large and\ninterdependent sets of ob- jectswe propose a hierarchically-guided approach.\nGiven a 3D scan decomposed into its object instances, we first construct a\nhierarchical scene graph representation to enable effective, tractable editing.\nWe then leverage reason- ing capabilities of Large Language Models (LLMs) and\ntranslate high-level language instructions into actionable commands applied\nhierarchically to the scene graph. Fi- nally, ScanEdit integrates LLM-based\nguidance with ex- plicit physical constraints and generates realistic scenes\nwhere object arrangements obey both physics and common sense. In our extensive\nexperimental evaluation ScanEdit outperforms state of the art and demonstrates\nexcellent re- sults for a variety of real-world scenes and input instruc-\ntions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T12:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.15065v1","title":"On the behavior of orbits of Vanhaecke system on integral surfaces","summary":"In the 1990s, P. Vanhecke described a Hamiltonian system with two degrees of\nfreedom and a polynomial Hamiltonian integrable in Abelian functions of two\nvariables. This system provides a convenient example of an integrable system in\nwhich integral curves are wound on a two-dimensional manifold, an algebraic\nsurface in a 4-dimensional phase space. In this report, we show that all\nnecessary calculations can be performed in the Sage system. The role of periods\nof Abelian integrals and their commensurability in describing the nature of the\nwinding of integral curves on an algebraic integral surface is discussed. The\nresults of numerical experiments performed in fdm for Sage are presented.","main_category":"nlin.SI","categories":"nlin.SI,math.CA","published":"2025-04-21T12:51:05Z"}
{"aid":"http://arxiv.org/abs/2504.15082v1","title":"An island-parallel ensemble metaheuristic algorithm for large graph\n  coloring problems","summary":"Graph Coloring Problem (GCP) is an NP-Hard vertex labeling problem in graphs\nsuch that no two adjacent vertices can have the same color. Large instances of\nGCP cannot be solved in reasonable execution times by exact algorithms.\nTherefore, soft computing approaches, such as metaheuristics, have proven to be\nvery efficient for solving large instances of GCP. In this study, we propose a\nnew island-parallel ensemble metaheuristic algorithm (PEM-Color) to solve large\nGCP instances. Ensemble learning is a new machine learning approach based on\ncombining the output of multiple models instead of using a single one. We use\nMessage Passing Interface (MPI) parallel computation libraries to combine\nrecent state-of-the-art metaheuristics: Harris Hawk Optimization (HHO),\nArtificial Bee Colony (ABC), and Teaching Learning Based (TLBO) to improve the\nquality of their solutions further. To the best of our knowledge, this is the\nfirst study that combines metaheuristics and applies to the GCP using an\nensemble approach. We conducted experiments on large graph instances from the\nwell-known DIMACS benchmark using 64 processors and achieved significant\nimprovements in execution times. The experiments also indicate an almost linear\nspeed-up with a strong scalability potential. The solution quality of the\ninstances is promising, as our algorithm outperforms 13 state-of-the-art\nalgorithms.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-21T13:15:23Z"}
{"aid":"http://arxiv.org/abs/2504.15083v1","title":"A survey on asymptotic equilibrium distribution of zeros of random\n  holomorphic sections","summary":"This is a survey of results concerning the asymptotic equilibrium\ndistribution of zeros of random holomorphic polynomials and holomorphic\nsections of high powers of a positive line bundle, as related to the authors'\nrecent work. Our primary focus is on the role of pluripotential theory in this\nresearch area.","main_category":"math.CV","categories":"math.CV,math.PR","published":"2025-04-21T13:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.15088v1","title":"Safety Co-Option and Compromised National Security: The Self-Fulfilling\n  Prophecy of Weakened AI Risk Thresholds","summary":"Risk thresholds provide a measure of the level of risk exposure that a\nsociety or individual is willing to withstand, ultimately shaping how we\ndetermine the safety of technological systems. Against the backdrop of the Cold\nWar, the first risk analyses, such as those devised for nuclear systems,\ncemented societally accepted risk thresholds against which safety-critical and\ndefense systems are now evaluated. But today, the appropriate risk tolerances\nfor AI systems have yet to be agreed on by global governing efforts, despite\nthe need for democratic deliberation regarding the acceptable levels of harm to\nhuman life. Absent such AI risk thresholds, AI technologists-primarily industry\nlabs, as well as \"AI safety\" focused organizations-have instead advocated for\nrisk tolerances skewed by a purported AI arms race and speculative\n\"existential\" risks, taking over the arbitration of risk determinations with\nlife-or-death consequences, subverting democratic processes.\n  In this paper, we demonstrate how such approaches have allowed AI\ntechnologists to engage in \"safety revisionism,\" substituting traditional\nsafety methods and terminology with ill-defined alternatives that vie for the\naccelerated adoption of military AI uses at the cost of lowered safety and\nsecurity thresholds. We explore how the current trajectory for AI risk\ndetermination and evaluation for foundation model use within national security\nis poised for a race to the bottom, to the detriment of the US's national\nsecurity interests. Safety-critical and defense systems must comply with\nassurance frameworks that are aligned with established risk thresholds, and\nfoundation models are no exception. As such, development of evaluation\nframeworks for AI-based military systems must preserve the safety and security\nof US critical and defense infrastructure, and remain in alignment with\ninternational humanitarian law.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-21T13:20:56Z"}
{"aid":"http://arxiv.org/abs/2504.15091v1","title":"Wireless energy transfer in non-Hermitian quantum battery","summary":"The extraction of energy is one of fundamental challenges in realizing\nquantum batteries (QBs). Here, we propose two wireless transfer schemes with\nparity-time symmetries to efficiently extract the energy stored in\nnon-Hermitian QBs to consumption centers. For linear cases, the transfer energy\noscillates periodically in the unbroken symmetry region and grows\nhyperbolically in the broken region. For nonlinear cases, the transfer energy\neventually reach and remain steady-state values arising from the feedback\nmechanism of the nonlinear saturable gain. Furthermore, we show the significant\nrobustness and the ultrafast response of the wireless transfer schemes to\nsudden movements around one metre. Our work overcomes energy bottlenecks for\nwireless transfer schemes in QBs and may provide inspirations for practical\napplications of QBs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T13:24:31Z"}
{"aid":"http://arxiv.org/abs/2504.15116v1","title":"Wigner multiplets in QFT: from Wigner degeneracy to Elko fields","summary":"We establish the theoretical foundation of the Wigner superposition field, a\nquantum field framework for spin-1/2 fermions that exhibit a Wigner doublet --\na discrete quantum number arising from nontrivial representations of the\nextended Poincar\\'{e} group. In contrast to the previously developed doublet\nformalism, which treats the Wigner degeneracy as a superficial label, the\nsuperposition formalism encodes it directly into the structure of a unified\nfield via a coherent superposition of degenerate spinor fields. By imposing the\nLorentz covariance, causality, and canonical quantization, we derive nontrivial\nconstraints on the field configuration, which uniquely identify the Elko field\nas the consistent realization of the Wigner superposition field. Our analysis\nfurther clarifies that although the Elko field is a spinor field, it possesses\nmass dimension one and obeys the Klein-Gordon rather than the Dirac kinematics.\nMoreover, we explore the general Elko representation through basis\nredefinitions, showing that certain traditional properties, such as being\neigenspinors of charge conjugation, are artifacts of specific basis choices\nrather than intrinsic features. Finally, we discuss the physical implications\nof Elko as a dark matter (DM) candidate. This work lays the foundation for a\nsystematic reformulation of Elko interactions and its phenomenology as a viable\ncomponent of DM.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-21T14:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.15148v1","title":"Uniformly resolvable decompositions of $K_v$ into $1$-factors and odd\n  $n$-star factors","summary":"We consider uniformly resolvable decompositions of $K_v$ into subgraphs such\nthat each resolution class contains only blocks isomorphic to the same graph.\nWe give a partial solution for the case in which all resolution classes are\neither $K_2$ or $K_{1,n}$ where $n$ is odd.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-21T14:52:40Z"}
{"aid":"http://arxiv.org/abs/2504.15169v1","title":"Improving efficiency and stability for perovskite solar cell with\n  diethylene glycol dimethacrylate modification","summary":"The humidity resistance is the key challenges that hinder the commercial\napplication of perovskite solar cells (PSCs). Herein, we propose an ultra-thin\nacrylate polymer (diethylene glycol dimethacrylate, DGDMA) into perovskite\nfilms to investigate the influence of polymerized networks on stability. The\nmonomer molecules containing acrylate and carbonyl groups were selected, and\nthe effects of the polymerized were quantified with different concentration.\nThe experimental results show that, when the concentration of DGDMA is 1 mg/ml,\nthe PCE increases from 18.06% to 21.82%, which is optimum. The monomer\nmolecules with carbonyl groups polymerize, they can chelate with uncoordinated\nPb2+ in perovskite films to improve the film quality, reduce the surface defect\ndensity to decrease non-radiative recombination, and also significantly enhance\nthe humidity stability of PSCs.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T15:23:51Z"}
{"aid":"http://arxiv.org/abs/2504.15173v1","title":"Poroelastic flow across a permeable interface: a Hamilton's principle\n  approach and its finite element implementation","summary":"We consider fluid flow across a permeable interface within a deformable\nporous medium. We use mixture theory. The mixture's constituents are assumed to\nbe incompressible in their pure form. We use Hamilton's principle to obtain the\ngoverning equations, and we propose a corresponding finite element\nimplementation. The filtration velocity and the pore pressure are allowed to be\ndiscontinuous across the interface while some control of these discontinuities\nis built into the interfacial constitutive behavior. To facilitate the\npractical implementation of the formulation in a finite element scheme, we\nintroduce a Lagrange multiplier field over the interface for the explicit\nenforcement of the jump condition of the balance of mass. Our formulation\nappears to recover some basic results from the literature. The novelty of the\nwork is the formulation of an approach that can accommodate specific\nconstitutive assumptions pertaining to the behavior of the interface that do\nnot necessarily imply the continuity of the filtration velocity and/or of the\npore pressure across it.","main_category":"math.NA","categories":"math.NA,cs.NA,physics.flu-dyn","published":"2025-04-21T15:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.15181v1","title":"Existing Industry Practice for the EU AI Act's General-Purpose AI Code\n  of Practice Safety and Security Measures","summary":"This report provides a detailed comparison between the measures proposed in\nthe EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and\ncurrent practices adopted by leading AI companies. As the EU moves toward\nenforcing binding obligations for GPAI model providers, the Code of Practice\nwill be key to bridging legal requirements with concrete technical commitments.\nOur analysis focuses on the draft's Safety and Security section which is only\nrelevant for the providers of the most advanced models (Commitments II.1-II.16)\nand excerpts from current public-facing documents quotes that are relevant to\neach individual measure.\n  We systematically reviewed different document types - including companies'\nfrontier safety frameworks and model cards - from over a dozen companies,\nincluding OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and\nothers. This report is not meant to be an indication of legal compliance nor\ndoes it take any prescriptive viewpoint about the Code of Practice or\ncompanies' policies. Instead, it aims to inform the ongoing dialogue between\nregulators and GPAI model providers by surfacing evidence of precedent.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-21T15:44:01Z"}
{"aid":"http://arxiv.org/abs/2504.15215v1","title":"An experimental study of the influence of anonymous information on\n  social media users","summary":"Increasingly, people use social media for their day-to-day interactions and\nas a source of information, even though much of this information is practically\nanonymous. This raises the question: does anonymous information influence its\nrecipients? We conducted an online, two-phase, preregistered experiment using a\nnationally representative sample of participants from the U.S. to find the\nanswer. To avoid biases of opinions among participants, in the first phase,\neach participant examines ten Rorschach inkblots and chooses one of four\nopinions assigned to each inkblot. In the second phase, the participants are\nrandomly assigned to one of four distinct information conditions and are asked\nto revisit their opinions for the same ten inkblots. Conditions ranged from\nrepeating phase one to receiving anonymous comments about certain opinions.\nResults were consistent with the preregistration. Importantly, anonymous\ncomments shown in phase two influence up to half of the participants' opinion\nselections. To better understand the role of anonymous comments in influencing\nthe selections of opinions, we implemented agent-based modeling (ABM). ABM\nresults suggest that a straightforward mechanism can explain the impact of such\ninformation. Overall, our results indicate that even anonymous information can\nhave a significant impact on its recipients, potentially altering their\npopularity rankings. However, the strength of such influence weakens when\nrecipients' confidence in their selections increases. Additionally, we found\nthat participants' confidence in the first phase is inversely related to the\nnumber of change opinions.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-21T16:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.15236v1","title":"Values in the Wild: Discovering and Analyzing Values in Real-World\n  Language Model Interactions","summary":"AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG","published":"2025-04-21T17:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.15238v1","title":"Swap Monte Carlo for diatomic molecules","summary":"In recent years the Swap Monte Carlo algorithm has led to remarkable progress\nin equilibrating supercooled model liquids at low temperatures. Applications\nhave so far been limited to systems composed of spherical particles, however,\nwhereas most real-world supercooled liquids are molecular. We here introduce a\nsimple size-polydisperse molecular model that allows for efficient thermal\nequilibration \\textit{in silico} with the Swap Monte Carlo method, resulting in\nan estimated speedup of $10^3-10^6$ at moderate polydispersity (5-10 %).\nDespite being polydisperse, the model exhibits little difference between the\nsize-resolved orientational time-autocorrelation functions. Our results\ndemonstrate the possibility of designing molecular models that can be simulated\nclose to the calorimetric glass transition.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-21T17:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.15240v1","title":"Conformalized-KANs: Uncertainty Quantification with Coverage Guarantees\n  for Kolmogorov-Arnold Networks (KANs) in Scientific Machine Learning","summary":"This paper explores uncertainty quantification (UQ) methods in the context of\nKolmogorov-Arnold Networks (KANs). We apply an ensemble approach to KANs to\nobtain a heuristic measure of UQ, enhancing interpretability and robustness in\nmodeling complex functions. Building on this, we introduce Conformalized-KANs,\nwhich integrate conformal prediction, a distribution-free UQ technique, with\nKAN ensembles to generate calibrated prediction intervals with guaranteed\ncoverage. Extensive numerical experiments are conducted to evaluate the\neffectiveness of these methods, focusing particularly on the robustness and\naccuracy of the prediction intervals under various hyperparameter settings. We\nshow that the conformal KAN predictions can be applied to recent extensions of\nKANs, including Finite Basis KANs (FBKANs) and multifideilty KANs (MFKANs). The\nresults demonstrate the potential of our approaches to improve the reliability\nand applicability of KANs in scientific machine learning.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T17:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.15266v1","title":"Roll the dice & look before you leap: Going beyond the creative limits\n  of next-token prediction","summary":"We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-21T17:47:46Z"}
{"aid":"http://arxiv.org/abs/2504.15280v1","title":"Seeing from Another Perspective: Evaluating Multi-View Understanding in\n  MLLMs","summary":"Multi-view understanding, the ability to reconcile visual information across\ndiverse viewpoints for effective navigation, manipulation, and 3D scene\ncomprehension, is a fundamental challenge in Multi-Modal Large Language Models\n(MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive\nadvances in high-level reasoning and planning, they frequently fall short when\nconfronted with multi-view geometric consistency and cross-view correspondence.\nTo comprehensively evaluate the challenges of MLLMs in multi-view scene\nreasoning, we propose All-Angles Bench, a benchmark of over 2,100 human\ncarefully annotated multi-view question-answer pairs across 90 diverse\nreal-world scenes. Our six tasks (counting, attribute identification, relative\ndistance, relative direction, object manipulation, and camera pose estimation)\nspecifically test model's geometric correspondence and the capacity to align\ninformation consistently across views. Our extensive experiments, benchmark on\n27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and\nGPT-4o against human evaluators reveals a substantial performance gap,\nindicating that current MLLMs remain far from human-level proficiency. Through\nin-depth analysis, we show that MLLMs are particularly underperforming under\ntwo aspects: (1) cross-view correspondence for partially occluded views and (2)\nestablishing the coarse camera poses. These findings highlight the necessity of\ndomain-specific refinements or modules that embed stronger multi-view\nawareness. We believe that our All-Angles Bench offers valuable insights and\ncontribute to bridging the gap between MLLMs and human-level multi-view\nunderstanding. The project and benchmark are publicly available at\nhttps://danielchyeh.github.io/All-Angles-Bench/.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-21T17:59:53Z"}
{"aid":"http://arxiv.org/abs/2504.15588v1","title":"Bayesian Parameter Estimation for Partially Observed McKean-Vlasov\n  Diffusions Using Multilevel Markov chain Monte Carlo","summary":"In this article we consider Bayesian estimation of static parameters for a\nclass of partially observed McKean-Vlasov diffusion processes with\ndiscrete-time observations over a fixed time interval. This problem features\nseveral obstacles to its solution, which include that the posterior density is\nnumerically intractable in continuous-time, even if the transition\nprobabilities are available and even when one uses a time-discretization, the\nposterior still cannot be used by adopting well-known computational methods\nsuch as Markov chain Monte Carlo (MCMC). In this paper we provide a solution to\nthis problem by using new MCMC algorithms which can solve the afore-mentioned\nissues. This MCMC algorithm is extended to use multilevel Monte Carlo (MLMC)\nmethods. We prove convergence bounds on our parameter estimators and show that\nthe MLMC-based MCMC algorithm reduces the computational cost to achieve a mean\nsquare error versus ordinary MCMC by an order of magnitude. We numerically\nillustrate our results on two models.","main_category":"stat.CO","categories":"stat.CO,cs.NA,math.NA","published":"2025-04-22T05:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.15605v1","title":"Lie derivatives of sections of natural vector bundles","summary":"Time derivatives of pullbacks and push forwards along smooth curves of\ndiffeomorphism of sections of natural vector bundles are computed in terms of\nLie derivatives along adapted non-autonomous vector fields by extending a key\nlemma in [Markus Mauhart, Peter W. Michor: Commutators of flows and fields.\nArch. Math. (Brno) 28 (1992), 228-236. arXiv:math/9204221]. There is also the\nanalogous result about the first non-vanishing derivative of higher order.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T05:54:01Z"}
{"aid":"http://arxiv.org/abs/2504.15608v1","title":"Experimental Aspects of Lorentz Invariance Violation","summary":"Lorentz invariance is a cornerstone of modern physics, yet its possible\nviolation remains both theoretically intriguing and experimentally significant.\nIn this work, using quantum electrodynamics as an example, we explore how\nLorentz invariance violation, introduced into a specific sector of the theory,\nspreads through loop corrections, modifying the propagation and dispersion\nrelations of other particles. Self-energy and vacuum polarization graphs reveal\nhow LIV effects transfer across sectors, influencing particle kinematics. Due\nto these loop effects, constraints from cosmic-ray observations and other\nEarth-based experiments impose limits on induced LIV parameters that would\notherwise be less constrained. We show that while interaction-based LIV effects\nrequire unrealistically large parameters for detection, modifications to\ndispersion relations can be probed down to $\\delta \\sim 10^{-8} \\text{ to }\n10^{-9}$ at the LHC. This suggests that accelerator-based resonance studies\nprovide a promising avenue for stringent LIV constraints, potentially rivaling\nastrophysical observations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T05:58:04Z"}
{"aid":"http://arxiv.org/abs/2504.15635v1","title":"Questioning Cosmic Acceleration with DESI: The Big Stall of the Universe","summary":"One of the most important discoveries in modern cosmology is cosmic\nacceleration. However, we find that today's universe could decelerate in the\nstatistically preferred Chevallier-Polarski-Linder (CPL) scenario over the\n$\\Lambda$CDM model by cosmic microwave background, type Ia supernova and DESI's\nnew measurements of baryon acoustic oscillations. Using various datasets, at a\nbeyond $5\\,\\sigma$ confidence level, we demonstrate that the universe\nexperiences a triple deceleration during its evolution and finally reaches the\nstate of the ``Big Stall\", which predicts that: (i) the universe suddenly comes\nto a halt in the distant future; (ii) its eventual destiny is dominated by dark\nmatter rather than dark energy ; (iii) it ultimately retains an extremely small\nfraction of dark energy but exerts an extremely large pressure. Our findings\nprofoundly challenge the established understanding of cosmic acceleration and\nenrich our comprehension of cosmic evolution.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.HE,gr-qc","published":"2025-04-22T06:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.15658v1","title":"Improved Upper Bound on Brun's Constant Under GRH","summary":"Brun's constant is the summation of the reciprocals of all twin primes, given\nby $B=\\sum_{p \\in P_2}{\\left( \\frac{1}{p} + \\frac{1}{p+2}\\right)}$. In this\npaper, we provide the first rigorous bound on Brun's constant under the GRH\nassumption, resulting in $B < 2.1609$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T07:30:00Z"}
{"aid":"http://arxiv.org/abs/2504.15688v1","title":"Subject islands do not reduce to construction-specific discourse\n  function","summary":"The term islands in linguistics refers to phrases from which extracting an\nelement results in ungrammaticality (Ross, 1967). Grammatical subjects are\nconsidered islands because extracting a sub-part of a subject results in an\nill-formed sentence, despite having a clear intended meaning (e.g., \"Which\ntopic did the article about inspire you?\"). The generative tradition, which\nviews syntax as autonomous of meaning and function, attributes this\nungrammaticality to the abstract movement dependency between the wh-phrase and\nthe subject-internal position with which it is associated for interpretation.\nHowever, research on language that emphasizes its communicative function\nsuggests instead that syntactic constraints, including islands, can be\nexplained based on the way different constructions package information.\nAccordingly, Abeill\\'e et al. (2020) suggest that the islandhood of subjects is\nspecific to the information structure of wh-questions, and propose that\nsubjects are not islands for movement, but for focusing, due to their\ndiscourse-backgroundedness. This predicts that other constructions that differ\nin their information structure from wh-questions, but still involve movement,\nshould not create a subject island effect. We test this prediction in three\nlarge-scale acceptability studies, using a super-additive design that singles\nout subject island violations, in three different constructions: wh-questions,\nrelative clauses, and topicalization. We report evidence for a subject island\neffect in each construction type, despite only wh-questions introducing what\nAbeill\\'e et al. (2020) call \"a clash in information structure.\" We argue that\nthis motivates an account of islands in terms of abstract, syntactic\nrepresentations, independent of the communicative function associated with the\nconstructions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T08:13:04Z"}
{"aid":"http://arxiv.org/abs/2504.15698v1","title":"Entanglement-enhanced randomized measurement in noisy quantum devices","summary":"Quantum hardware is advancing rapidly across various platforms, yet\nimplementing large-scale quantum error correction (QEC) remains challenging. As\nhardware continues to improve, there is a growing need to identify potential\napplications on noisy quantum devices that can leverage these enhancements.\nWith this motivation, we explore the advantages of shallow measurements over\n(non-entangling) single-qubit measurements for learning various properties of a\nquantum state. While previous studies have examined this subject, they have\nprimarily focused on specific problems. Here, by developing a new theoretical\nframework, we demonstrate how shallow measurements can benefit in diverse\nscenarios. Despite the additional errors from two-qubit gates in shallow\nmeasurements, we experimentally validated improvements compared to single-qubit\nmeasurements in applications like derandomization, common randomized\nmeasurements, and machine learning up to 40 qubits and 46 layers of two-qubit\ngates, respectively. As a result, we show that hardware improvements, even\nbefore QEC, could broaden the range of feasible applications.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T08:33:36Z"}
{"aid":"http://arxiv.org/abs/2504.15713v1","title":"Zernike system revisited: imaginary gauge and Higgs oscillator","summary":"We analyze that recently proposed clasical/quantum mechanical interpretation\nof Zernike system and establish its equivalence to the Higgs oscillator on\nsphere or pseudosphere (Lobachevsky plane). We show that the non-reality of the\nclassical Zernike Hamiltonian is an insignificant artifact of imaginary gauge\nand can be eliminated with a canonical transformation. The quantum counterpart\nof this canonical transformation is a similarity transformation mapping the\nsystem to the quantum Higgs oscillator with integration measure depending on\n$\\alpha,\\beta$ parameters. When $\\alpha=2 \\beta$ it results in the Hermitian\nHamiltonian describing a free particle on (pseudo)sphere, while deviation from\nthis point leads to a pseudo-Hermitian system.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,physics.optics","published":"2025-04-22T08:55:07Z"}
{"aid":"http://arxiv.org/abs/2504.15721v1","title":"BBAL: A Bidirectional Block Floating Point-Based Quantisation\n  Accelerator for Large Language Models","summary":"Large language models (LLMs), with their billions of parameters, pose\nsubstantial challenges for deployment on edge devices, straining both memory\ncapacity and computational resources. Block Floating Point (BFP) quantisation\nreduces memory and computational overhead by converting high-overhead floating\npoint operations into low-bit fixed point operations. However, BFP requires\naligning all data to the maximum exponent, which causes loss of small and\nmoderate values, resulting in quantisation error and degradation in the\naccuracy of LLMs. To address this issue, we propose a Bidirectional Block\nFloating Point (BBFP) data format, which reduces the probability of selecting\nthe maximum as shared exponent, thereby reducing quantisation error. By\nutilizing the features in BBFP, we present a full-stack Bidirectional Block\nFloating Point-Based Quantisation Accelerator for LLMs (BBAL), primarily\ncomprising a processing element array based on BBFP, paired with proposed\ncost-effective nonlinear computation unit. Experimental results show BBAL\nachieves a 22% improvement in accuracy compared to an outlier-aware accelerator\nat similar efficiency, and a 40% efficiency improvement over a BFP-based\naccelerator at similar accuracy.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-22T09:11:21Z"}
{"aid":"http://arxiv.org/abs/2504.15727v1","title":"On some classes of non-commutative dimonoids","summary":"The present paper is devoted to the study of dimonoids, algebraic structures\nwith two associative binary operations that satisfy a prescribed system of\naxioms. We investigate the properties of dual dimonoids. In the class of\nnon-commutative dimonoids, we construct a number of abelian, non-abelian, and\nrectangular dimonoids. The internal structure of these objects is analyzed, in\nparticular, their automorphism groups and halos are computed.","main_category":"math.GR","categories":"math.GR,math.RA","published":"2025-04-22T09:21:44Z"}
{"aid":"http://arxiv.org/abs/2504.15733v1","title":"Operator Inference for Elliptic Eigenvalue Problems","summary":"Eigenvalue problems for elliptic operators play an important role in science\nand engineering applications, where efficient and accurate numerical\ncomputation is essential. In this work, we propose a novel operator inference\napproach for elliptic eigenvalue problems based on neural network\napproximations that directly maps computational domains to their associated\neigenvalues and eigenfunctions. Motivated by existing neural network\narchitectures and the mathematical characteristics of eigenvalue problems, we\nrepresent computational domains as pixelated images and decompose the task into\ntwo subtasks: eigenvalue prediction and eigenfunction prediction. For the\neigenvalue prediction, we design a convolutional neural network (CNN), while\nfor the eigenfunction prediction, we employ a Fourier Neural Operator (FNO).\nAdditionally, we introduce a critical preprocessing module that integrates\ndomain scaling, detailed boundary pixelization, and main-axis alignment. This\npreprocessing step not only simplifies the learning task but also enhances the\nperformance of the neural networks. Finally, we present numerical results to\ndemonstrate the effectiveness of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T09:25:36Z"}
{"aid":"http://arxiv.org/abs/2504.15762v1","title":"Product separability in central extensions","summary":"We show that a central extension of locally quasiconvex subgroup separable\nhyperbolic group is product separable, so long as it is subgroup separable. We\nalso establish that a central extension of a double coset separable group by a\nfinitely generated group is double coset separable if and only if it is\nsubgroup separable, and that double coset separability is stable under taking\ndirect products with finitely generated nilpotent groups.","main_category":"math.GR","categories":"math.GR","published":"2025-04-22T10:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.15783v1","title":"Towards prediction of morphological heart age from computed tomography\n  angiography","summary":"Age prediction from medical images or other health-related non-imaging data\nis an important approach to data-driven aging research, providing knowledge of\nhow much information a specific tissue or organ carries about the chronological\nage of the individual. In this work, we studied the prediction of age from\ncomputed tomography angiography (CTA) images, which provide detailed\nrepresentations of the heart morphology, with the goals of (i) studying the\nrelationship between morphology and aging, and (ii) developing a novel\n\\emph{morphological heart age} biomarker. We applied an image\nregistration-based method that standardizes the images from the whole cohort\ninto a single space. We then extracted supervoxels (using unsupervised\nsegmentation), and corresponding robust features of density and local volume,\nwhich provide a detailed representation of the heart morphology while being\nrobust to registration errors. Machine learning models are then trained to fit\nregression models from these features to the chronological age. We applied the\nmethod to a subset of the images from the Swedish CArdioPulomonary bioImage\nStudy (SCAPIS) dataset, consisting of 721 females and 666 males. We observe a\nmean absolute error of $2.74$ years for females and $2.77$ years for males. The\npredictions from different sub-regions of interest were observed to be more\nhighly correlated with the predictions from the whole heart, compared to the\nchronological age, revealing a high consistency in the predictions from\nmorphology. Saliency analysis was also performed on the prediction models to\nstudy what regions are associated positively and negatively with the predicted\nage. This resulted in detailed association maps where the density and volume of\nknown, as well as some novel sub-regions of interest, are determined to be\nimportant. The saliency analysis aids in the interpretability of the models and\ntheir predictions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T10:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.15860v1","title":"The area of spheres in the Brownian plane","summary":"We consider the area of spheres centered at the distinguished point in the\nBrownian plane. As a function of the radius, the resulting process has\ncontinuously differentiable sample paths. Furthermore, the pair consisting of\nthe process and its derivative is time-homogeneous Markov and satisfies an\nexplicit stochastic differential equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T12:57:07Z"}
{"aid":"http://arxiv.org/abs/2504.15862v1","title":"SBH-ellipticity of the relaxed interfacial energy density in the context\n  of second-order structured deformations","summary":"Starting from an energy comprised of both a bulk term and a surface term, set\nin the space of special functions of bounded hessian, $SBH$, a relaxation\nproblem in the context of second-order structured deformations was studied in\nFonseca-Hagerty-Paroni. It was shown, via the global method for relaxation,\nthat the relaxed functional admits an integral representation and the relaxed\nenergy densities were identified. In this paper we show that, under certain\nhypotheses on the original densities, the corresponding relaxed energy\ndensities verify the same type of growth conditions and the surface energy\ndensity satisfies a specific ``convexity-type'' property, i.e. it is\n$SBH$-elliptic.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T12:57:43Z"}
{"aid":"http://arxiv.org/abs/2504.15870v1","title":"Machine-learned RG-improved gauge actions and classically perfect\n  gradient flows","summary":"Extracting continuum properties of quantum field theories from discretized\nspacetime is challenging due to lattice artifacts. Renormalization-group\n(RG)-improved lattice actions can preserve continuum properties, but are in\ngeneral difficult to parameterize. Machine learning (ML) with gauge-equivariant\nconvolutional neural networks provides a way to efficiently describe such\nactions. We test a machine-learned RG-improved lattice gauge action, the\nclassically perfect fixed-point (FP) action, for four-dimensional SU(3) gauge\ntheory through Monte Carlo simulations. We establish that the gradient flow of\nthe FP action is free of tree-level discretization effects to all orders in the\nlattice spacing, making it classically perfect. This allows us to test the\nquality of improvement of the FP action, without introducing additional\nartifacts. We find that discretization effects in gradient-flow observables are\nhighly suppressed and less than 1% up to lattice spacings of 0.14 fm, allowing\ncontinuum physics to be extracted from coarse lattices. The quality of\nimprovement achieved motivates the use of the FP action in future gauge theory\nstudies. The advantages of ML-based parameterizations also highlight the\npossibility of realizing quantum perfect actions in lattice gauge theory.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-22T13:14:49Z"}
{"aid":"http://arxiv.org/abs/2504.15876v1","title":"Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement\n  Learning for Strategic Confrontation","summary":"In swarm robotics, confrontation scenarios, including strategic\nconfrontations, require efficient decision-making that integrates discrete\ncommands and continuous actions. Traditional task and motion planning methods\nseparate decision-making into two layers, but their unidirectional structure\nfails to capture the interdependence between these layers, limiting\nadaptability in dynamic environments. Here, we propose a novel bidirectional\napproach based on hierarchical reinforcement learning, enabling dynamic\ninteraction between the layers. This method effectively maps commands to task\nallocation and actions to path planning, while leveraging cross-training\ntechniques to enhance learning across the hierarchical framework. Furthermore,\nwe introduce a trajectory prediction model that bridges abstract task\nrepresentations with actionable planning goals. In our experiments, it achieves\nover 80\\% in confrontation win rate and under 0.01 seconds in decision time,\noutperforming existing approaches. Demonstrations through large-scale tests and\nreal-world robot experiments further emphasize the generalization capabilities\nand practical applicability of our method.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-22T13:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.15891v1","title":"Optimal body force for heat transfer in turbulent vertical heated pipe\n  flow","summary":"As buoyancy can help drive a flow, the vertical heated-pipe arrangement is\nwidely used in thermal engineering applications. However, buoyancy suppresses\nand can even laminarise turbulence in the flow, thereby seriously damaging the\nheat transfer, measured by the Nusselt number Nu. As buoyancy, measured by the\nparameter C, is increased, three flow regimes are possible: shear-driven\nturbulence, laminarised flow, and convective turbulence. In Chu et al. (2024)\nwe employed a variational optimisation method to investigate how the buoyancy\nchanges the structure of the minimal flow perturbation that triggers\nturbulence. Here, we extend the method to find an optimal body force of limited\nmagnitude that maximises heat transfer, and examine how time-dependence of the\nflow affects the optimisation in each of the three flow regimes. Optimisations\nare performed at Re = 3000, and the force is found to laminarise convective\nturbulence, or make it only weakly chaotic for C up to 8. Consistent with\nprevious computations that assume steady flow, the optimal force induces\nstreamwise-independent rolls, but at larger amplitude the force triggers\ntime-dependent turbulent flow. Transition from the laminar\nstreamwise-independent state to turbulent flow can either enhance Nu or reduce\nNu. For highly chaotic flows, either shear turbulence at C = 1 or convective\nturbulence at C = 16, 32, optimisations place rolls closer to the wall than\ncalculations with the steady flow assumption. At any given force amplitude,\nhowever, the enhanced Nu is only weakly dependent on the number of induced\nrolls.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-22T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.15897v1","title":"SUPRA: Subspace Parameterized Attention for Neural Operator on General\n  Domains","summary":"Neural operators are efficient surrogate models for solving partial\ndifferential equations (PDEs), but their key components face challenges: (1) in\norder to improve accuracy, attention mechanisms suffer from computational\ninefficiency on large-scale meshes, and (2) spectral convolutions rely on the\nFast Fourier Transform (FFT) on regular grids and assume a flat geometry, which\ncauses accuracy degradation on irregular domains. To tackle these problems, we\nregard the matrix-vector operations in the standard attention mechanism on\nvectors in Euclidean space as bilinear forms and linear operators in vector\nspaces and generalize the attention mechanism to function spaces. This new\nattention mechanism is fully equivalent to the standard attention but\nimpossible to compute due to the infinite dimensionality of function spaces. To\naddress this, inspired by model reduction techniques, we propose a Subspace\nParameterized Attention (SUPRA) neural operator, which approximates the\nattention mechanism within a finite-dimensional subspace. To construct a\nsubspace on irregular domains for SUPRA, we propose using the Laplacian\neigenfunctions, which naturally adapt to domains' geometry and guarantee the\noptimal approximation for smooth functions. Experiments show that the SUPRA\nneural operator reduces error rates by up to 33% on various PDE datasets while\nmaintaining state-of-the-art computational efficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-22T13:40:04Z"}
{"aid":"http://arxiv.org/abs/2504.15898v1","title":"Stationary distributions of McKean-Vlasov SDEs with jumps: existence,\n  uniqueness, and multiplicity","summary":"In this paper, we are interested in the issues on existence, uniqueness, and\nmultiplicity of stationary distributions for McKean-Vlasov SDEs with jumps. In\ndetail, with regarding to McKean-Vlasov SDEs driven by pure jump L\\'{e}vy\nprocesses, we principally (i) explore the existence of stationary distributions\nvia Schauder's fixed point theorem under an appropriate Lyapunov condition;\n(ii) tackle the uniqueness of stationary distributions and the convergence to\nthe equilibria as long as the underlying drifts are continuous with respect to\nthe measure variables under the weighted total variation distance and the\n$L^1$-Wasserstein distance, respectively; (iii) demonstrate the multiplicity of\nstationary distributions under a locally dissipative condition. In addition,\nsome illustrative examples are provided to show that the associated\nMcKean-Vlasov SDEs possess a unique, two and three stationary distributions,\nrespectively.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T13:40:19Z"}
{"aid":"http://arxiv.org/abs/2504.15912v1","title":"Automated Bug Report Prioritization in Large Open-Source Projects","summary":"Large open-source projects receive a large number of issues (known as bugs),\nincluding software defect (i.e., bug) reports and new feature requests from\ntheir user and developer communities at a fast rate. The often limited project\nresources do not allow them to deal with all issues. Instead, they have to\nprioritize them according to the project's priorities and the issues'\nseverities. In this paper, we propose a novel approach to automated bug\nprioritization based on the natural language text of the bug reports that are\nstored in the open bug repositories of the issue-tracking systems. We conduct\ntopic modeling using a variant of LDA called TopicMiner-MTM and text\nclassification with the BERT large language model to achieve a higher\nperformance level compared to the state-of-the-art. Experimental results using\nan existing reference dataset containing 85,156 bug reports of the Eclipse\nPlatform project indicate that we outperform existing approaches in terms of\nAccuracy, Precision, Recall, and F1-measure of the bug report priority\nprediction.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-22T13:57:48Z"}
{"aid":"http://arxiv.org/abs/2504.15921v1","title":"ViSMaP: Unsupervised Hour-long Video Summarisation by Meta-Prompting","summary":"We introduce ViSMap: Unsupervised Video Summarisation by Meta Prompting, a\nsystem to summarise hour long videos with no-supervision. Most existing video\nunderstanding models work well on short videos of pre-segmented events, yet\nthey struggle to summarise longer videos where relevant events are sparsely\ndistributed and not pre-segmented. Moreover, long-form video understanding\noften relies on supervised hierarchical training that needs extensive\nannotations which are costly, slow and prone to inconsistency. With ViSMaP we\nbridge the gap between short videos (where annotated data is plentiful) and\nlong ones (where it's not). We rely on LLMs to create optimised\npseudo-summaries of long videos using segment descriptions from short ones.\nThese pseudo-summaries are used as training data for a model that generates\nlong-form video summaries, bypassing the need for expensive annotations of long\nvideos. Specifically, we adopt a meta-prompting strategy to iteratively\ngenerate and refine creating pseudo-summaries of long videos. The strategy\nleverages short clip descriptions obtained from a supervised short video model\nto guide the summary. Each iteration uses three LLMs working in sequence: one\nto generate the pseudo-summary from clip descriptions, another to evaluate it,\nand a third to optimise the prompt of the generator. This iteration is\nnecessary because the quality of the pseudo-summaries is highly dependent on\nthe generator prompt, and varies widely among videos. We evaluate our summaries\nextensively on multiple datasets; our results show that ViSMaP achieves\nperformance comparable to fully supervised state-of-the-art models while\ngeneralising across domains without sacrificing performance. Code will be\nreleased upon publication.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:06:01Z"}
{"aid":"http://arxiv.org/abs/2504.15962v1","title":"Blimp-based Crime Scene Analysis","summary":"To tackle the crucial problem of crime, evidence at indoor crime scenes must\nbe analyzed before it becomes contaminated or degraded. Here, as an application\nof artificial intelligence (AI), computer vision, and robotics, we explore how\na blimp could be designed as a kind of \"floating camera\" to drift over and\nrecord evidence with minimal disturbance. In particular, rapid prototyping is\nused to develop a proof-of-concept to gain insight into what such blimps could\ndo, manually piloted or semi-autonomously. As a result, we show the feasibility\nof attaching various components to an indoor blimp, and confirm our basic\npremise, that blimps can sense evidence without producing much wind. Some\nadditional suggestions--regarding mapping, sensing, and path-finding--aim to\nstimulate the flow of ideas for further exploration.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T15:01:10Z"}
{"aid":"http://arxiv.org/abs/2504.15971v1","title":"On the greatest prime factor of polynomial values and subexponential\n  Szpiro in families","summary":"Combining a modular approach to the $abc$ conjecture developed by the second\nauthor with the classical method of linear forms in logarithms, we obtain\nimproved unconditional bounds for two classical problems. First, for Szpiro's\nconjecture when the relevant elliptic curves are members of a one-parameter\nfamily (an elliptic surface). And secondly, for the problem of giving lower\nbounds for the greatest prime factor of polynomial values, in the case of\nquadratic and cubic polynomials. The latter extends earlier work by the second\nauthor for the polynomial $n^2+1$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T15:12:24Z"}
{"aid":"http://arxiv.org/abs/2504.15974v1","title":"Well-posedness of the transport of normal currents by time-dependent\n  vector fields","summary":"We prove existence and uniqueness for the transport equation for currents\n(Geometric Transport Equation) when the driving vector field is time-dependent,\nLipschitz in space and merely integrable in time. This extends previous work\nwhere well-posedness was shown in the case of a time-independent, Lipschitz\nvector field. The proof relies on the decomposability bundle and requires to\nextend some of its properties to the class of functions that in one direction\nare only absolutely continuous, rather than Lipschitz.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T15:21:17Z"}
{"aid":"http://arxiv.org/abs/2504.15993v1","title":"Benchmarking machine learning models for predicting aerofoil performance","summary":"This paper investigates the capability of Neural Networks (NNs) as\nalternatives to the traditional methods to analyse the performance of aerofoils\nused in the wind and tidal energy industry. The current methods used to assess\nthe characteristic lift and drag coefficients include Computational Fluid\nDynamics (CFD), thin aerofoil and panel methods, all face trade-offs between\ncomputational speed and the accuracy of the results and as such NNs have been\ninvestigated as an alternative with the aim that it would perform both quickly\nand accurately. As such, this paper provides a benchmark for the windAI_bench\ndataset published by the National Renewable Energy Laboratory (NREL) in the\nUSA. In order to validate the methodology of the benchmarking, the AirfRANS\n{\\tt arXiv:2212.07564v3} dataset is used as both a starting point and a point\nof comparison. This study evaluates four neural networks (MLP, PointNet,\nGraphSAGE, GUNet) trained on a range aerofoils at 25 angles of attack\n(4$^\\circ$ to 20$^\\circ$). to predict fluid flow and calculate lift\ncoefficients ($C_L$) via the panel method. GraphSAGE and GUNet performed well\nduring the testing phase, but underperformed during validation. Accordingly,\nthis paper has identified PointNet and MLP as the two strongest models tested,\nhowever whilst the results from MLP are more commonly correct for predicting\nthe behaviour of the fluid, the results from PointNet provide the more accurate\nresults for calculating $C_L$.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-22T15:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.15998v1","title":"Effects of the Matter Potential at One-Loop Level on Neutrino\n  Oscillations in Long-Baseline Experiments","summary":"In this work, we demonstrate that one-loop corrections to the matter\npotential for neutrino oscillations can significantly impact the sensitivity to\nneutrino mass ordering in long-baseline accelerator experiments. Using\nnumerical simulations for the future experiment DUNE, we find that the\nstatistical significance for excluding the incorrect mass ordering can be\nenhanced by $1.0\\sigma$--$1.2\\sigma$ if a one-loop correction of $5.8\\%$ --\npredicted by the Standard Model in the on-shell renormalization scheme -- is\nincluded. Even with a smaller correction of $2.0\\%$, based instead on the Fermi\ncoupling constant $G^{}_\\mu$ derived from measurements of muon lifetime, we\nshow that the enhancement remains notable at about $0.4\\sigma$. In contrast,\nthe sensitivity to leptonic CP violation in DUNE is essentially unchanged.\nFinally, we emphasize that one-loop corrections should be incorporated into\nanalyses of future neutrino oscillation data in a consistent and systematic\nmanner.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T16:03:43Z"}
{"aid":"http://arxiv.org/abs/2504.16004v1","title":"Clifford and Non-Clifford Splitting in Quantum Circuits: Applications\n  and ZX-Calculus Detection Procedure","summary":"Classical simulation of quantum circuits is a pivotal part of the quantum\ncomputing landscape, specially within the NISQ era, where the constraints\nimposed by available hardware are unavoidable. The Gottesman-Knill theorem\nfurther motivates this argument by accentuating the importance of Clifford\ncircuits and their role on this topic of simulation. In this work, we propose\nand analyze use cases that come from quantum circuits that can be written as\nproduct between a Clifford and a Non-Clifford unitary, these ranging from fully\nclassical emulation, hybrid quantum-classical execution or even quantum\nalgorithm simplification. To further complement this analysis, we make use of\nZX-Calculus and its assets to detect a limiting border of these circuits that\nwould allow for a separation between a Clifford section and a Non-Clifford\nsection. To achieve this, we present a novel procedure for parsing ZX diagrams,\nthat not only allows for the detection of this border but also simplifies the\ncircuit extraction process.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T16:10:34Z"}
{"aid":"http://arxiv.org/abs/2504.16012v1","title":"Interpolation error analysis using a new geometric parameter","summary":"This article presents novel proof methods for estimating interpolation\nerrors, predicated on the understanding that one has already studied\nfoundational error analysis using the finite element method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T16:20:54Z"}
{"aid":"http://arxiv.org/abs/2504.16020v1","title":"AlphaGrad: Non-Linear Gradient Normalization Optimizer","summary":"We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer\naddressing the memory overhead and hyperparameter complexity of adaptive\nmethods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2\ngradient normalization followed by a smooth hyperbolic tangent transformation,\n$g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness\nparameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm\nformulation; (2) a formal non-convex convergence analysis guaranteeing\nstationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN,\nTD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent\nperformance profile. While exhibiting instability in off-policy DQN, it\nprovides enhanced training stability with competitive results in TD3 (requiring\ncareful $\\alpha$ tuning) and achieves substantially superior performance in\non-policy PPO. These results underscore the critical importance of empirical\n$\\alpha$ selection, revealing strong interactions between the optimizer's\ndynamics and the underlying RL algorithm. AlphaGrad presents a compelling\nalternative optimizer for memory-constrained scenarios and shows significant\npromise for on-policy learning regimes where its stability and efficiency\nadvantages can be particularly impactful.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE,stat.ML","published":"2025-04-22T16:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.16032v1","title":"LLMs meet Federated Learning for Scalable and Secure IoT Management","summary":"The rapid expansion of IoT ecosystems introduces severe challenges in\nscalability, security, and real-time decision-making. Traditional centralized\narchitectures struggle with latency, privacy concerns, and excessive resource\nconsumption, making them unsuitable for modern large-scale IoT deployments.\nThis paper presents a novel Federated Learning-driven Large Language Model\n(FL-LLM) framework, designed to enhance IoT system intelligence while ensuring\ndata privacy and computational efficiency. The framework integrates Generative\nIoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS),\ndynamically optimizing model updates based on real-time network conditions. By\nleveraging a hybrid edge-cloud processing architecture, our approach balances\nintelligence, scalability, and security in distributed IoT environments.\nEvaluations on the IoT-23 dataset demonstrate that our framework improves model\naccuracy, reduces response latency, and enhances energy efficiency,\noutperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings\nhighlight the potential of integrating LLM-powered federated learning into\nlarge-scale IoT ecosystems, paving the way for more secure, scalable, and\nadaptive IoT management solutions.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.ET","published":"2025-04-22T16:56:59Z"}
{"aid":"http://arxiv.org/abs/2504.16053v1","title":"LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free\n  Receptive Field Enlargement","summary":"State space models (SSMs) have emerged as an efficient alternative to\nTransformer models for language modeling, offering linear computational\ncomplexity and constant memory usage as context length increases. However,\ndespite their efficiency in handling long contexts, recent studies have shown\nthat SSMs, such as Mamba models, generally underperform compared to\nTransformers in long-context understanding tasks. To address this significant\nshortfall and achieve both efficient and accurate long-context understanding,\nwe propose LongMamba, a training-free technique that significantly enhances the\nlong-context capabilities of Mamba models. LongMamba builds on our discovery\nthat the hidden channels in Mamba can be categorized into local and global\nchannels based on their receptive field lengths, with global channels primarily\nresponsible for long-context capability. These global channels can become the\nkey bottleneck as the input context lengthens. Specifically, when input lengths\nlargely exceed the training sequence length, global channels exhibit\nlimitations in adaptively extend their receptive fields, leading to Mamba's\npoor long-context performance. The key idea of LongMamba is to mitigate the\nhidden state memory decay in these global channels by preventing the\naccumulation of unimportant tokens in their memory. This is achieved by first\nidentifying critical tokens in the global channels and then applying token\nfiltering to accumulate only those critical tokens. Through extensive\nbenchmarking across synthetic and real-world long-context scenarios, LongMamba\nsets a new standard for Mamba's long-context performance, significantly\nextending its operational range without requiring additional training. Our code\nis available at https://github.com/GATECH-EIC/LongMamba.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T17:30:36Z"}
{"aid":"http://arxiv.org/abs/2504.16054v1","title":"$Ï€_{0.5}$: a Vision-Language-Action Model with Open-World\n  Generalization","summary":"In order for robots to be useful, they must perform practically relevant\ntasks in the real world, outside of the lab. While vision-language-action (VLA)\nmodels have demonstrated impressive results for end-to-end robot control, it\nremains an open question how far such models can generalize in the wild. We\ndescribe $\\pi_{0.5}$, a new model based on $\\pi_{0}$ that uses co-training on\nheterogeneous tasks to enable broad generalization. $\\pi_{0.5}$\\ uses data from\nmultiple robots, high-level semantic prediction, web data, and other sources to\nenable broadly generalizable real-world robotic manipulation. Our system uses a\ncombination of co-training and hybrid multi-modal examples that combine image\nobservations, language commands, object detections, semantic subtask\nprediction, and low-level actions. Our experiments show that this kind of\nknowledge transfer is essential for effective generalization, and we\ndemonstrate for the first time that an end-to-end learning-enabled robotic\nsystem can perform long-horizon and dexterous manipulation skills, such as\ncleaning a kitchen or bedroom, in entirely new homes.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-22T17:31:29Z"}
{"aid":"http://arxiv.org/abs/2504.16061v1","title":"Vision language models are unreliable at trivial spatial cognition","summary":"Vision language models (VLMs) are designed to extract relevant visuospatial\ninformation from images. Some research suggests that VLMs can exhibit humanlike\nscene understanding, while other investigations reveal difficulties in their\nability to process relational information. To achieve widespread applicability,\nVLMs must perform reliably, yielding comparable competence across a wide\nvariety of related tasks. We sought to test how reliable these architectures\nare at engaging in trivial spatial cognition, e.g., recognizing whether one\nobject is left of another in an uncluttered scene. We developed a benchmark\ndataset -- TableTest -- whose images depict 3D scenes of objects arranged on a\ntable, and used it to evaluate state-of-the-art VLMs. Results show that\nperformance could be degraded by minor variations of prompts that use logically\nequivalent descriptions. These analyses suggest limitations in how VLMs may\nreason about spatial relations in real-world applications. They also reveal\nnovel opportunities for bolstering image caption corpora for more efficient\ntraining and testing.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T17:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.16073v1","title":"Guiding VLM Agents with Process Rewards at Inference Time for GUI\n  Navigation","summary":"Recent advancements in visual language models (VLMs) have notably enhanced\ntheir capabilities in handling complex Graphical User Interface (GUI)\ninteraction tasks. Despite these improvements, current frameworks often\nstruggle to generate correct actions in challenging GUI environments.\nState-of-the-art commercial VLMs are black-boxes, and fine-tuning open-source\nVLMs for GUI tasks requires significant resources. Additionally, existing\ntrajectory-level evaluation and refinement techniques frequently fall short due\nto delayed feedback and local optimization issues. To address these challenges,\nwe propose an approach that guides VLM agents with process supervision by a\nreward model during GUI navigation and control at inference time. This guidance\nallows the VLM agent to optimize actions at each inference step, thereby\nimproving performance in both static and dynamic environments. In particular,\nour method demonstrates significant performance gains in three GUI navigation\ntasks, achieving a 3.4% improvement in single step action accuracy for static\nenvironments, along with a around 33% increase in task success rate in one\ndynamic environment. With further integration of trajectory reflection and\nretry mechanisms, we also demonstrate even greater enhancement in task success.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T17:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.16075v1","title":"Explainable Unsupervised Anomaly Detection with Random Forest","summary":"We describe the use of an unsupervised Random Forest for similarity learning\nand improved unsupervised anomaly detection. By training a Random Forest to\ndiscriminate between real data and synthetic data sampled from a uniform\ndistribution over the real data bounds, a distance measure is obtained that\nanisometrically transforms the data, expanding distances at the boundary of the\ndata manifold. We show that using distances recovered from this transformation\nimproves the accuracy of unsupervised anomaly detection, compared to other\ncommonly used detectors, demonstrated over a large number of benchmark\ndatasets. As well as improved performance, this method has advantages over\nother unsupervised anomaly detection methods, including minimal requirements\nfor data preprocessing, native handling of missing data, and potential for\nvisualizations. By relating outlier scores to partitions of the Random Forest,\nwe develop a method for locally explainable anomaly predictions in terms of\nfeature importance.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-22T17:54:44Z"}
{"aid":"http://arxiv.org/abs/2504.16389v1","title":"SaENeRF: Suppressing Artifacts in Event-based Neural Radiance Fields","summary":"Event cameras are neuromorphic vision sensors that asynchronously capture\nchanges in logarithmic brightness changes, offering significant advantages such\nas low latency, low power consumption, low bandwidth, and high dynamic range.\nWhile these characteristics make them ideal for high-speed scenarios,\nreconstructing geometrically consistent and photometrically accurate 3D\nrepresentations from event data remains fundamentally challenging. Current\nevent-based Neural Radiance Fields (NeRF) methods partially address these\nchallenges but suffer from persistent artifacts caused by aggressive network\nlearning in early stages and the inherent noise of event cameras. To overcome\nthese limitations, we present SaENeRF, a novel self-supervised framework that\neffectively suppresses artifacts and enables 3D-consistent, dense, and\nphotorealistic NeRF reconstruction of static scenes solely from event streams.\nOur approach normalizes predicted radiance variations based on accumulated\nevent polarities, facilitating progressive and rapid learning for scene\nrepresentation construction. Additionally, we introduce regularization losses\nspecifically designed to suppress artifacts in regions where photometric\nchanges fall below the event threshold and simultaneously enhance the light\nintensity difference of non-zero events, thereby improving the visual fidelity\nof the reconstructed scene. Extensive qualitative and quantitative experiments\ndemonstrate that our method significantly reduces artifacts and achieves\nsuperior reconstruction quality compared to existing methods. The code is\navailable at https://github.com/Mr-firework/SaENeRF.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T03:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.16402v1","title":"Detection of X-ray Polarization in the Hard State of IGR J17091-3624:\n  Spectro-Polarimetric Study with IXPE and NuSTAR Data","summary":"The class-transition Galactic X-ray binary IGR J17091--3624 was\nsimultaneously monitored by the IXPE and NuSTAR satellites. We present a\ndetailed spectro-polarimetric study of the source using data from both\nsatellites covering the period from March 7-10, 2025. A polarimetric analysis\nin the $2$-$8$~keV band using a model-independent method reveals a significant\ndetection of polarization degree (PD) of $(11.3\\pm2.35)\\%$ at a polarization\nangle (PA) of $82^\\circ.7\\pm5^\\circ.96$ (significant at $>4\\sigma$). The\nmodel-dependent polarization analysis using the polconst and polpow models\nyields consistent values of PD and PA. In both methods, an energy-dependent\nincreasing trend of PD is observed. In the $6$-$8$~keV band, a maximum PD of\n$(29.9\\pm8.46)\\%$ is detected at a PA of $88^\\circ.0\\pm8^\\circ.15$ (significant\nat $>3\\sigma$) . The joint spectral analysis using IXPE and NuSTAR data in the\n$2$-$70$~keV band was performed with four different sets of phenomenological\nand physical models. Our results indicate a strong dominance of non-thermal\nphotons originating from a `hot' Compton cloud, suggesting that the source was\nin a hard spectral state. Spectral fitting with the physical kerrbb and TCAF\nmodels provides an estimate of the black hole mass $M_{\\rm BH} =\n14.8^{+4.7}_{-3.4}~M_\\odot$ and dimensionless spin parameter $a^* \\sim 0.54$.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T04:11:16Z"}
{"aid":"http://arxiv.org/abs/2504.16424v1","title":"Complex tridiagonal quantum Hamiltonians and matrix continued fractions","summary":"Quantum resonances described by non-Hermitian tridiagonal-matrix Hamiltonians\n$H$ with complex energy eigenvalues $E_n \\in {\\mathbb C}$ are considered. The\nmethod of evaluation of quantities $\\sigma_n=\\sqrt{E_n^*E_n}$ known as the\nsingular values of $H$ is proposed. Its basic idea is that the quantities\n$\\sigma_n$ can be treated as square roots of eigenvalues of a certain auxiliary\nself-adjoint operator $\\mathbb{H}$. As long as such an operator can be given a\nblock-tridiagonal matrix form, we construct its resolvent as a matrix continued\nfraction. In an illustrative application of the formalism, a discrete version\nof conventional Hamiltonian $H=-d^2/dx^2+V(x)$ with complex local $V(x) \\neq\nV^*(x)$ is considered. The numerical convergence of the recipe is found quick,\nsupported also by a fixed-point-based formal proof.","main_category":"math-ph","categories":"math-ph,math.MP,quant-ph","published":"2025-04-23T05:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.16447v1","title":"Node Assigned physics-informed neural networks for thermal-hydraulic\n  system simulation: CVH/FL module","summary":"Severe accidents (SAs) in nuclear power plants have been analyzed using\nthermal-hydraulic (TH) system codes such as MELCOR and MAAP. These codes\nefficiently simulate the progression of SAs, while they still have inherent\nlimitations due to their inconsistent finite difference schemes. The use of\nempirical schemes incorporating both implicit and explicit formulations\ninherently induces unidirectional coupling in multi-physics analyses. The\nobjective of this study is to develop a novel numerical method for TH system\ncodes using physics-informed neural network (PINN). They have shown strength in\nsolving multi-physics due to the innate feature of neural networks-automatic\ndifferentiation. We propose a node-assigned PINN (NA-PINN) that is suitable for\nthe control volume approach-based system codes. NA-PINN addresses the issue of\nspatial governing equation variation by assigning an individual network to each\nnodalization of the system code, such that spatial information is excluded from\nboth the input and output domains, and each subnetwork learns to approximate a\npurely temporal solution. In this phase, we evaluated the accuracy of the PINN\nmethods for the hydrodynamic module. In the 6 water tank simulation, PINN and\nNA-PINN showed maximum absolute errors of 1.678 and 0.007, respectively. It\nshould be noted that only NA-PINN demonstrated acceptable accuracy. To the best\nof the authors' knowledge, this is the first study to successfully implement a\nsystem code using PINN. Our future work involves extending NA-PINN to a\nmulti-physics solver and developing it in a surrogate manner.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T06:17:04Z"}
{"aid":"http://arxiv.org/abs/2504.16452v1","title":"Photonic single-arm gravitational wave detectors based on the quantum\n  state transition of orbital angular momentum","summary":"We explore the quantum state transition of photon orbital angular momentum\n(OAM) in the present of gravitational waves (GWs) and demonstrate the potential\nof a new photonic single-arm GW detection technique. The interaction is\ncalculated based on the framework of the wave propagation in linearized gravity\ntheory and canonical quantization of the electromagnetic field in curved\nspacetime. It is demonstrated that when a photon possessing OAM of 1 interacts\nwith GWs, it may relinquish its OAM and produce a central signal that may be\ndetected. The detector provides a high and steady rate of detected photons in\nthe low-frequency range ($<1$ Hz), opens a potential window to identify GWs in\nthe mid-frequency range ($1\\sim10$ Hz), which is absent in other contemporary\nGW detectors, and establishes a selection rule for GW frequencies in the\nhigh-frequency range ($>10$ Hz), allowing for the adjustment of detector\nparameters to focus on specific GW frequencies. Furthermore, the detector is\ninsensitive to seismic noise, and the detectable photon count rate is\nproportional to the square of the GW amplitude, making it more advantageous for\ndetermining the distance of the source compared to current interferometer\ndetectors. This technique not only facilitates the extraction of GW information\nbut also creates a new approach for identifying and selecting GW signals.","main_category":"gr-qc","categories":"gr-qc,astro-ph.IM,quant-ph","published":"2025-04-23T06:32:06Z"}
{"aid":"http://arxiv.org/abs/2504.16454v1","title":"Killing Two Birds with One Stone: Unifying Retrieval and Ranking with a\n  Single Generative Recommendation Model","summary":"In recommendation systems, the traditional multi-stage paradigm, which\nincludes retrieval and ranking, often suffers from information loss between\nstages and diminishes performance. Recent advances in generative models,\ninspired by natural language processing, suggest the potential for unifying\nthese stages to mitigate such loss. This paper presents the Unified Generative\nRecommendation Framework (UniGRF), a novel approach that integrates retrieval\nand ranking into a single generative model. By treating both stages as sequence\ngeneration tasks, UniGRF enables sufficient information sharing without\nadditional computational costs, while remaining model-agnostic. To enhance\ninter-stage collaboration, UniGRF introduces a ranking-driven enhancer module\nthat leverages the precision of the ranking stage to refine retrieval\nprocesses, creating an enhancement loop. Besides, a gradient-guided adaptive\nweighter is incorporated to dynamically balance the optimization of retrieval\nand ranking, ensuring synchronized performance improvements. Extensive\nexperiments demonstrate that UniGRF significantly outperforms existing models\non benchmark datasets, confirming its effectiveness in facilitating information\ntransfer. Ablation studies and further experiments reveal that UniGRF not only\npromotes efficient collaboration between stages but also achieves synchronized\noptimization. UniGRF provides an effective, scalable, and compatible framework\nfor generative recommendation systems.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-23T06:43:54Z"}
{"aid":"http://arxiv.org/abs/2504.16461v1","title":"Sum rules for x-ray circular and linear dichroism based on complete\n  magnetic multipole basis","summary":"X-ray magnetic circular dichroism (XMCD) and X-ray magnetic linear dichroism\n(XMLD) are powerful spectroscopic techniques for probing magnetic properties in\nsolids. In this study, we revisit the XMCD and XMLD sum rules within a complete\nmagnetic multipole basis that incorporates both spinless and spinful\nmultipoles. We demonstrate that these multipoles can be clearly distinguished\nand individually detected through the sum-rule formalism. Within this\nframework, the anisotropic magnetic dipole term is naturally derived in XMCD,\noffering a microscopic origin for ferromagnetic-like behavior in\nantiferromagnets. Furthermore, we derive the sum rules for out-of-plane and\nin-plane XMLD regarding electric quadrupole contributions defined based on the\ncomplete multipole basis. Our theoretical approach provides a unified,\nsymmetry-consistent framework for analyzing dichroic signals in various\nmagnetic materials. These findings deepen the understanding of XMCD and XMLD\nand open pathways to exploring complex magnetic structures and spin-orbit\ncoupling effects in emergent magnetic materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T07:14:46Z"}
{"aid":"http://arxiv.org/abs/2504.16475v1","title":"The Dodecacopter: a Versatile Multirotor System of Dodecahedron-Shaped\n  Modules","summary":"With the promise of greater safety and adaptability, modular reconfigurable\nuncrewed air vehicles have been proposed as unique, versatile platforms holding\nthe potential to replace multiple types of monolithic vehicles at once.\nState-of-the-art rigidly assembled modular vehicles are generally\ntwo-dimensional configurations in which the rotors are coplanar and assume the\nshape of a \"flight array\". We introduce the Dodecacopter, a new type of modular\nrotorcraft where all modules take the shape of a regular dodecahedron, allowing\nthe creation of richer sets of configurations beyond flight arrays. In\nparticular, we show how the chosen module design can be used to create\nthree-dimensional and fully actuated configurations. We justify the relevance\nof these types of configurations in terms of their structural and actuation\nproperties with various performance indicators. Given the broad range of\nconfigurations and capabilities that can be achieved with our proposed design,\nwe formulate tractable optimization programs to find optimal configurations\ngiven structural and actuation constraints. Finally, a prototype of such a\nvehicle is presented along with results of performed flights in multiple\nconfigurations.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T07:38:00Z"}
{"aid":"http://arxiv.org/abs/2504.16480v1","title":"Balancing Costs and Utilities in Future Networks via Market Equilibrium\n  with Externalities","summary":"We study the problem of market equilibrium (ME) in future wireless networks,\nwith multiple actors competing and negotiating for a pool of heterogeneous\nresources (communication and computing) while meeting constraints in terms of\nglobal cost. The latter is defined in a general way but is associated with\nenergy and/or carbon emissions. In this direction, service providers competing\nfor network resources do not acquire the latter, but rather the right to\nconsume, given externally defined policies and regulations. We propose to apply\nthe Fisher market model, and prove its convergence towards an equilibrium\nbetween utilities, regulatory constraints, and individual budgets. The model is\nthen applied to an exemplary use case of access network, edge computing, and\ncloud resources, and numerical results assess the theoretical findings of\nconvergence, under different assumptions on the utility function and more or\nless stringent constraints.","main_category":"cs.GT","categories":"cs.GT,cs.NI","published":"2025-04-23T07:46:45Z"}
{"aid":"http://arxiv.org/abs/2504.16495v1","title":"Quasi-triangular and factorizable perm bialgebras","summary":"In this paper, we introduce the notions of quasi-triangular and factorizable\nperm bialgebras, based on notions of the perm Yang-Baxter equation and $(R,\n\\mathrm{ad})$-invariant condition. A factorizable perm bialgebra induces a\nfactorization of the underlying perm algebra and the double of a perm bialgebra\nnaturally admits a factorizable perm bialgebra structure. The notion of\nrelative Rota-Baxter operators of weights on perm algebras is introduced to\ncharacterize solutions of the perm Yang-Baxter equation, whose skew-symmetric\nparts are $(R, \\mathrm{ad})$-invariant. These operators are in one-to-one\ncorrespondence with linear transformations fulfilling a Rota-Baxter-type\nidentity in the case of quadratic perm algebras. Furthermore, we introduce the\nnotion of quadratic Rota-Baxter perm algebras of weights, demonstrate that a\nquadratic Rota-Baxter perm algebra of weight $0$ induces a triangular perm\nbialgebra, and establish a one-to-one correspondence between quadratic\nRota-Baxter perm algebras of nonzero weights and factorizable perm bialgebras.","main_category":"math.RT","categories":"math.RT","published":"2025-04-23T08:17:53Z"}
{"aid":"http://arxiv.org/abs/2504.16500v1","title":"Strongly inhomogeneous spin dynamics induced by ultrashort laser pulses\n  with a gradient intensity profile","summary":"The optical pump-probe technique is a common tool for investigation of\nultrafast spin dynamics, which usually utilizes single-diode detection\naveraging the dynamics over the pumped area. Using ultrafast imaging technique,\nwe show experimentally that a femtosecond laser pulse with a gradient\ndistribution of intensity efficiently excites strongly inhomogeneous spin\ndynamics on spatial scales much smaller than the pump spot size. The mechanism\nresponsible for the inhomogeneous distribution is based on temperature\ngradients and corresponds to a sign change of the torque derivative in\ndifferent areas of the pump. We argue that the observed phenomenon is general\nfor the systems with competitive magnetic anisotropies. Overlooking this effect\nin the majority of pump-probe experiments may result in a dramatic\nunderestimation of the live time and amplitude of the laser-induced spin\ndynamics.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-23T08:23:54Z"}
{"aid":"http://arxiv.org/abs/2504.16509v1","title":"Solvability of the ${\\rm SK}_1$-analog of the orthogonal groups","summary":"We prove the dilation principle for the relative Dickson-Siegel-Eichler-Roy\n(DSER) elementary orthogonal group and using the dilation principle we prove\nthe Quillen's analog of the local-global principle for the group. Applying the\nrelative local-global principle, we prove the solvability and nilpotency of the\n${\\rm SK_1}$-analog of the orthogonal groups and study the homotopy and\ncommutativity principle for odd elementary orthogonal groups.","main_category":"math.KT","categories":"math.KT","published":"2025-04-23T08:36:07Z"}
{"aid":"http://arxiv.org/abs/2504.16514v1","title":"A new proof of the Artin-Springer theorem in Schur index 2","summary":"We provide a new proof of the analogue of the Artin-Springer theorem for\ngroups of type $\\mathsf{D}$ that can be represented by similitudes over an\nalgebra of Schur index $2$: an anisotropic generalized quadratic form over a\nquaternion algebra $Q$ remains anisotropic after generic splitting of $Q$,\nhence also under odd degree field extensions of the base field. Our proof is\ncharacteristic free and does not use the excellence property.","main_category":"math.KT","categories":"math.KT","published":"2025-04-23T08:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.16520v1","title":"A Few-Shot Metric Learning Method with Dual-Channel Attention for\n  Cross-Modal Same-Neuron Identification","summary":"In neuroscience research, achieving single-neuron matching across different\nimaging modalities is critical for understanding the relationship between\nneuronal structure and function. However, modality gaps and limited annotations\npresent significant challenges. We propose a few-shot metric learning method\nwith a dual-channel attention mechanism and a pretrained vision transformer to\nenable robust cross-modal neuron identification. The local and global channels\nextract soma morphology and fiber context, respectively, and a gating mechanism\nfuses their outputs. To enhance the model's fine-grained discrimination\ncapability, we introduce a hard sample mining strategy based on the\nMultiSimilarityMiner algorithm, along with the Circle Loss function.\nExperiments on two-photon and fMOST datasets demonstrate superior Top-K\naccuracy and recall compared to existing methods. Ablation studies and t-SNE\nvisualizations validate the effectiveness of each module. The method also\nachieves a favorable trade-off between accuracy and training efficiency under\ndifferent fine-tuning strategies. These results suggest that the proposed\napproach offers a promising technical solution for accurate single-cell level\nmatching and multimodal neuroimaging integration.","main_category":"cs.CV","categories":"cs.CV,q-bio.NC","published":"2025-04-23T08:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.16522v1","title":"On Bell numbers of type $D$","summary":"In this paper, we will introduce Bell numbers $D(n)$ of type $D$ as an\nanalogue to the classical Bell numbers related to all the partitions of the set\n$[n]$. Then based on a signed set partition of type $D$, we will construct the\nrecurrence relations of Bell numbers $D(n)$. In addition, we deduce the\nexponential generating function for $D(n)$. Finally, we will provide an\nexplicit formula for $D(n)$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-23T08:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.16523v1","title":"Alternately-optimized SNN method for acoustic scattering problem in\n  unbounded domain","summary":"In this paper, we propose a novel machine learning-based method to solve the\nacoustic scattering problem in unbounded domain. We first employ the\nDirichlet-to-Neumann (DtN) operator to truncate the physically unbounded domain\ninto a computable bounded domain. This transformation reduces the original\nscattering problem in the unbounded domain to a boundary value problem within\nthe bounded domain. To solve this boundary value problem, we design a neural\nnetwork with a subspace layer, where each neuron in this layer represents a\nbasis function. Consequently, the approximate solution can be expressed by a\nlinear combination of these basis functions. Furthermore, we introduce an\ninnovative alternating optimization technique which alternately updates the\nbasis functions and their linear combination coefficients respectively by\ntraining and least squares methods. In our method, we set the coefficients of\nbasis functions to 1 and use a new loss function each time train the subspace.\nThese innovations ensure that the subspace formed by these basis functions is\ntruly optimized. We refer to this method as the alternately-optimized subspace\nmethod based on neural networks (AO-SNN). Extensive numerical experiments\ndemonstrate that our new method can significantly reduce the relative $l^2$\nerror to $10^{-7}$ or lower, outperforming existing machine learning-based\nmethods to the best of our knowledge.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-23T08:46:22Z"}
{"aid":"http://arxiv.org/abs/2504.16530v1","title":"Modern Computational Methods in Reinsurance Optimization: From Simulated\n  Annealing to Quantum Branch & Bound","summary":"We propose and implement modern computational methods to enhance catastrophe\nexcess-of-loss reinsurance contracts in practice. The underlying optimization\nproblem involves attachment points, limits, and reinstatement clauses, and the\nobjective is to maximize the expected profit while considering risk measures\nand regulatory constraints. We study the problem formulation, paving the way\nfor practitioners, for two very different approaches: A local search optimizer\nusing simulated annealing, which handles realistic constraints, and a branch &\nbound approach exploring the potential of a future speedup via quantum branch &\nbound. On the one hand, local search effectively generates contract structures\nwithin several constraints, proving useful for complex treaties that have\nmultiple local optima. On the other hand, although our branch & bound\nformulation only confirms that solving the full problem with a future quantum\ncomputer would require a stronger, less expensive bound and substantial\nhardware improvements, we believe that the designed application-specific bound\nis sufficiently strong to serve as a basis for further works. Concisely, we\nprovide insurance practitioners with a robust numerical framework for contract\noptimization that handles realistic constraints today, as well as an outlook\nand initial steps towards an approach which could leverage quantum computers in\nthe future.","main_category":"math.OC","categories":"math.OC,q-fin.CP,quant-ph","published":"2025-04-23T08:55:40Z"}
{"aid":"http://arxiv.org/abs/2504.16550v1","title":"A Collaborative Intrusion Detection System Using Snort IDS Nodes","summary":"Intrusion Detection Systems (IDSs) are integral to safeguarding networks by\ndetecting and responding to threats from malicious traffic or compromised\ndevices. However, standalone IDS deployments often fall short when addressing\nthe increasing complexity and scale of modern cyberattacks. This paper proposes\na Collaborative Intrusion Detection System (CIDS) that leverages Snort, an\nopen-source network intrusion detection system, to enhance detection accuracy\nand reduce false positives. The proposed architecture connects multiple Snort\nIDS nodes to a centralised node and integrates with a Security Information and\nEvent Management (SIEM) platform to facilitate real-time data sharing,\ncorrelation, and analysis. The CIDS design includes a scalable configuration of\nSnort sensors, a centralised database for log storage, and LogScale SIEM for\nadvanced analytics and visualisation. By aggregating and analysing intrusion\ndata from multiple nodes, the system enables improved detection of distributed\nand sophisticated attack patterns that standalone IDSs may miss. Performance\nevaluation against simulated attacks, including Nmap port scans and ICMP flood\nattacks, demonstrates our CIDS's ability to efficiently process large-scale\nnetwork traffic, detect threats with higher accuracy, and reduce alert fatigue.\nThis paper highlights the potential of CIDS in modern network environments and\nexplores future enhancements, such as integrating machine learning for advanced\nthreat detection and creating public datasets to support collaborative\nresearch. The proposed CIDS framework provides a promising foundation for\nbuilding more resilient and adaptive network security systems.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-23T09:25:52Z"}
{"aid":"http://arxiv.org/abs/2504.16570v1","title":"CountingDINO: A Training-free Pipeline for Class-Agnostic Counting using\n  Unsupervised Backbones","summary":"Class-agnostic counting (CAC) aims to estimate the number of objects in\nimages without being restricted to predefined categories. However, while\ncurrent exemplar-based CAC methods offer flexibility at inference time, they\nstill rely heavily on labeled data for training, which limits scalability and\ngeneralization to many downstream use cases. In this paper, we introduce\nCountingDINO, the first training-free exemplar-based CAC framework that\nexploits a fully unsupervised feature extractor. Specifically, our approach\nemploys self-supervised vision-only backbones to extract object-aware features,\nand it eliminates the need for annotated data throughout the entire proposed\npipeline. At inference time, we extract latent object prototypes via ROI-Align\nfrom DINO features and use them as convolutional kernels to generate similarity\nmaps. These are then transformed into density maps through a simple yet\neffective normalization scheme. We evaluate our approach on the FSC-147\nbenchmark, where we outperform a baseline under the same label-free setting.\nOur method also achieves competitive -- and in some cases superior -- results\ncompared to training-free approaches relying on supervised backbones, as well\nas several fully supervised state-of-the-art methods. This demonstrates that\ntraining-free CAC can be both scalable and competitive. Website:\nhttps://lorebianchi98.github.io/CountingDINO/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T09:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.16579v1","title":"Optimization Framework for Reducing Mid-circuit Measurements and Resets","summary":"The paper addresses the optimization of dynamic circuits in quantum\ncomputing, with a focus on reducing the cost of mid-circuit measurements and\nresets. We extend the probabilistic circuit model (PCM) and implement an\noptimization framework that targets both mid-circuit measurements and resets.\nTo overcome the limitation of the prior PCM-based pass, where optimizations are\nonly possible on pure single-qubit states, we incorporate circuit synthesis to\nenable optimizations on multi-qubit states. With a parameter $n_{pcm}$, our\nframework balances optimization level against resource usage.We evaluate our\nframework using a large dataset of randomly generated dynamic circuits.\nExperimental results demonstrate that our method is highly effective in\nreducing mid-circuit measurements and resets. In our demonstrative example,\nwhen applying our optimization framework to the Bernstein-Vazirani algorithm\nafter employing qubit reuse, we significantly reduce its runtime overhead by\nremoving all of the resets.","main_category":"quant-ph","categories":"quant-ph,cs.PL,cs.SE","published":"2025-04-23T10:01:00Z"}
{"aid":"http://arxiv.org/abs/2504.16589v1","title":"More on genuine multi-entropy and holography","summary":"By generalizing the construction of genuine multi-entropy ${\\rm\nGM}[\\mathtt{q}]$ for genuine multi-partite entanglement proposed in the\nprevious paper arXiv:2504.01625, we give a prescription on how to construct\n${\\rm GM}[\\mathtt{q}]$ systematically for any $\\mathtt{q}$. The crucial point\nis that our construction naturally fits to the partition number $p(\\mathtt{a})$\nof integer $\\mathtt{a}$. For general $\\mathtt{q}$, ${\\rm GM}[\\mathtt{q}]$\ncontains $N (\\mathtt{q}) = p(\\mathtt{q})-p(\\mathtt{q}-1)-1$ number of free\nparameters. Furthermore, these give $N (\\mathtt{q})+1$ number of new\ndiagnostics for genuine $\\mathtt{q}$-partite entanglement. Especially for\n$\\mathtt{q}=4$ case, this reproduces not only the known diagnostics pointed out\nby arXiv:1406.2663, but also a new diagnostics for quadripartite entanglement.\nWe also study these ${\\rm GM}[\\mathtt{q}]$ for $\\mathtt{q} = 4, 5$ in\nholography and show that these are of the order of ${\\cal{O}}\\left(1/G_N\n\\right)$ both analytically and numerically. Our results give evidence that\ngenuine multipartite entanglement is ubiquitous in holography. We discuss the\nconnection to quantum error correction and the role of genuine multipartite\nentanglement in bulk reconstruction.","main_category":"hep-th","categories":"hep-th,gr-qc,quant-ph","published":"2025-04-23T10:13:10Z"}
{"aid":"http://arxiv.org/abs/2504.16591v1","title":"JEPA for RL: Investigating Joint-Embedding Predictive Architectures for\n  Reinforcement Learning","summary":"Joint-Embedding Predictive Architectures (JEPA) have recently become popular\nas promising architectures for self-supervised learning. Vision transformers\nhave been trained using JEPA to produce embeddings from images and videos,\nwhich have been shown to be highly suitable for downstream tasks like\nclassification and segmentation. In this paper, we show how to adapt the JEPA\narchitecture to reinforcement learning from images. We discuss model collapse,\nshow how to prevent it, and provide exemplary data on the classical Cart Pole\ntask.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T10:16:12Z"}
{"aid":"http://arxiv.org/abs/2504.16616v1","title":"EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for\n  Hybrid Event Stream Perception","summary":"Event cameras, with microsecond temporal resolution and high dynamic range\n(HDR) characteristics, emit high-speed event stream for perception tasks.\nDespite the recent advancement in GNN-based perception methods, they are prone\nto use straightforward pairwise connectivity mechanisms in the pure Euclidean\nspace where they struggle to capture long-range dependencies and fail to\neffectively characterize the inherent hierarchical structures of non-uniformly\ndistributed event stream. To this end, in this paper we propose a novel\napproach named EHGCN, which is a pioneer to perceive event stream in both\nEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce an\nadaptive sampling strategy to dynamically regulate sampling rates, retaining\ndiscriminative events while attenuating chaotic noise. Then we present a Markov\nVector Field (MVF)-driven motion-aware hyperedge generation method based on\nmotion state transition probabilities, thereby eliminating cross-target\nspurious associations and providing critically topological priors while\ncapturing long-range dependencies between events. Finally, we propose a\nEuclidean-Hyperbolic GCN to fuse the information locally aggregated and\nglobally hierarchically modeled in Euclidean and hyperbolic spaces,\nrespectively, to achieve hybrid event perception. Experimental results on event\nperception tasks such as object detection and recognition validate the\neffectiveness of our approach.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T11:01:03Z"}
{"aid":"http://arxiv.org/abs/2504.16623v1","title":"Censored lifespans in a double-truncated sample: Maximum likelihood\n  inference for the exponential distribution","summary":"The analysis of a truncated sample can be hindered by censoring. Survival\ninformation may be lost to follow-up or the birthdate may be missing. The data\ncan still be modeled as a truncated point process and it is close to a Poisson\nprocess, in the Hellinger distance, as long as the sample is small relative to\nthe population. We assume an exponential distribution for the lifespan, derive\nthe likelihood and profile out the unobservable sample size. Identification of\nthe exponential parameter is shown, together with consistency and asymptotic\nnormality of its M-estimator. Even though the estimator sequence is indexed in\nthe sample size, both the point estimator and the standard error are\nobservable. Enterprise lifespans in Germany constitute our example.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-23T11:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.16636v1","title":"Dual-Camera All-in-Focus Neural Radiance Fields","summary":"We present the first framework capable of synthesizing the all-in-focus\nneural radiance field (NeRF) from inputs without manual refocusing. Without\nrefocusing, the camera will automatically focus on the fixed object for all\nviews, and current NeRF methods typically using one camera fail due to the\nconsistent defocus blur and a lack of sharp reference. To restore the\nall-in-focus NeRF, we introduce the dual-camera from smartphones, where the\nultra-wide camera has a wider depth-of-field (DoF) and the main camera\npossesses a higher resolution. The dual camera pair saves the high-fidelity\ndetails from the main camera and uses the ultra-wide camera's deep DoF as\nreference for all-in-focus restoration. To this end, we first implement spatial\nwarping and color matching to align the dual camera, followed by a\ndefocus-aware fusion module with learnable defocus parameters to predict a\ndefocus map and fuse the aligned camera pair. We also build a multi-view\ndataset that includes image pairs of the main and ultra-wide cameras in a\nsmartphone. Extensive experiments on this dataset verify that our solution,\ntermed DC-NeRF, can produce high-quality all-in-focus novel views and compares\nfavorably against strong baselines quantitatively and qualitatively. We further\nshow DoF applications of DC-NeRF with adjustable blur intensity and focal\nplane, including refocusing and split diopter.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T11:55:02Z"}
{"aid":"http://arxiv.org/abs/2504.16641v1","title":"$H^1$ local exact controllability of some one-dimensional bilinear\n  Schr{Ã¶}dinger equations","summary":"The local exact controllability of the one-dimensional bilinear\nSchr{\\\"o}dinger equation with Dirichlet boundary conditions has been\nextensively studied in subspaces of H 3 since the seminal work of K. Beauchard.\nOur first objective is to revisit this result and establish the controllability\nin H 1 0 for suitable discontinuous control potentials. In the second part, we\nconsider the equation in the presence of periodic boundary conditions and a\nconstant magnetic field. We prove the local exact controllability of periodic H\n1 -states, thanks to a Zeeman-type effect induced by the magnetic field which\ndecouples the resonant spectrum. Finally, we discuss open problems and partial\nresults for the Neumann case and the harmonic oscillator.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T12:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.16656v1","title":"Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning","summary":"We present Skywork R1V2, a next-generation multimodal reasoning model and a\nmajor leap forward from its predecessor, Skywork R1V. At its core, R1V2\nintroduces a hybrid reinforcement learning paradigm that harmonizes\nreward-model guidance with rule-based strategies, thereby addressing the\nlong-standing challenge of balancing sophisticated reasoning capabilities with\nbroad generalization. To further enhance training efficiency, we propose the\nSelective Sample Buffer (SSB) mechanism, which effectively counters the\n``Vanishing Advantages'' dilemma inherent in Group Relative Policy Optimization\n(GRPO) by prioritizing high-value samples throughout the optimization process.\nNotably, we observe that excessive reinforcement signals can induce visual\nhallucinations--a phenomenon we systematically monitor and mitigate through\ncalibrated reward thresholds throughout the training process. Empirical results\naffirm the exceptional capability of R1V2, with benchmark-leading performances\nsuch as 62.6 on OlympiadBench, 79.0 on AIME2024, 63.6 on LiveCodeBench, and\n74.0 on MMMU. These results underscore R1V2's superiority over existing\nopen-source models and demonstrate significant progress in closing the\nperformance gap with premier proprietary systems, including Gemini 2.5 and\nOpenAI o4-mini. The Skywork R1V2 model weights have been publicly released to\npromote openness and reproducibility\nhttps://huggingface.co/Skywork/Skywork-R1V2-38B.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:24:10Z"}
{"aid":"http://arxiv.org/abs/2504.16678v1","title":"An Intersection Product for the Polytope Algebra","summary":"We introduce a new multiplication for the polytope algebra, defined via the\nintersection of polytopes. After establishing the foundational properties of\nthis intersection product, we investigate finite-dimensional subalgebras that\narise naturally from this construction. These subalgebras can be regarded as\nvolumetric analogues of the graded M\\\"obius algebra, which appears in the\ncontext of the Dowling-Wilson conjecture. We conjecture that they also satisfy\nthe injective hard Lefschetz property and the Hodge-Riemann relations, and we\nprove these in degree one.","main_category":"math.CO","categories":"math.CO,math.MG","published":"2025-04-23T12:54:07Z"}
{"aid":"http://arxiv.org/abs/2504.16686v1","title":"Wafer-Scale Characterization of Al/AlxOy/Al Josephson Junctions at Room\n  Temperature","summary":"Josephson junctions (JJs) are the key element of many devices operating at\ncryogenic temperatures. Development of time-efficient wafer-scale JJ\ncharacterization for process optimization and control of JJ fabrication is\nessential. Such statistical characterization has to rely on room temperature\ntechniques since cryogenic measurements typically used for JJs are too time\nconsuming and unsuitable for wafer-scale characterization. In this work, we\nshow that from room temperature capacitance and current-voltage measurements,\nwith proper data analysis, we can independently obtain useful parameters of the\nJJs on wafer-scale, like oxide thickness, tunnel coefficient, and interfacial\ndefect densities. Moreover, based on detailed analysis of current vs voltage\ncharacteristics, different charge transport mechanisms across the junctions can\nbe distinguished. We exemplary demonstrate the worth of these methods by\nstudying junctions fabricated on 200 mm wafers with an industrially scale-able\nconcept based on subtractive processing using only CMOS compatible tools. From\nthese studies, we find that our subtractive fabrication approach yields\njunctions with quite homogeneous average oxide thickness across the full\nwafers, with a spread of less then 3$\\,$%. The analysis also revealed a\nvariation of the tunnel coefficient with oxide thickness, pointing to a\nstoichiometry gradient across the junctions' oxide width. Moreover, we\nestimated relatively low interfacial defect densities in the range of 70 -\n5000$\\,$defects/cm$^2$ for our junctions and established that the density\nincreased with decreasing oxide thickness, indicating that the wet etching\nprocess applied in the JJs fabrication for oxide thickness control leads to\nformation of interfacial trap state","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-23T13:15:01Z"}
{"aid":"http://arxiv.org/abs/2504.16694v1","title":"Emergent Kagome lattice and non-Abelian lattice gauge field of\n  biexcitons in t-MoTe$_2$","summary":"Non-Abelian gauge fields, characterized by their non-commutative symmetry\ngroups, shape physical laws from the Standard Model to emergent topological\nmatter for quantum computation. Here we find that moir\\'e exciton dimers\n(biexcitons) in twisted bilayer MoTe$_2$ are governed by a genuine non-Abelian\nlattice gauge field. These dipolar-bound exciton dimers, formed on bonds of the\nhoneycomb moir\\'e superlattice, exhibit three quadrupole configurations\norganized into a Kagome lattice geometry, on which the valley-flip biexciton\nhoppings through electron-hole Coulomb exchange act as link variables of the\nnon-Abelian lattice gauge theory. The emergence of gauge structure here is a\nnew possibility for composite particles, where the moir\\'e electronic structure\nand interactions between the electron and hole constituents jointly enforce the\nunderlying geometric constraint. The quadrupole nature of biexciton further\nmakes possible local gate controls to isolate designated pathways from the\nextended lattice for exploiting consequences of non-commutative gauge structure\nincluding the genuine non-Abelian Aharonov-Bohm effect. This also provides a\nnew approach for quantum manipulation of excitonic valley qubit. We show path\ninterference on a simplest loop can deterministically transform the\ncomputational basis states into Bell states.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T13:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.16740v1","title":"Gaussian Splatting is an Effective Data Generator for 3D Object\n  Detection","summary":"We investigate data augmentation for 3D object detection in autonomous\ndriving. We utilize recent advancements in 3D reconstruction based on Gaussian\nSplatting for 3D object placement in driving scenes. Unlike existing\ndiffusion-based methods that synthesize images conditioned on BEV layouts, our\napproach places 3D objects directly in the reconstructed 3D space with\nexplicitly imposed geometric transformations. This ensures both the physical\nplausibility of object placement and highly accurate 3D pose and position\nannotations.\n  Our experiments demonstrate that even by integrating a limited number of\nexternal 3D objects into real scenes, the augmented data significantly enhances\n3D object detection performance and outperforms existing diffusion-based 3D\naugmentation for object detection. Extensive testing on the nuScenes dataset\nreveals that imposing high geometric diversity in object placement has a\ngreater impact compared to the appearance diversity of objects. Additionally,\nwe show that generating hard examples, either by maximizing detection loss or\nimposing high visual occlusion in camera images, does not lead to more\nefficient 3D data augmentation for camera-based 3D object detection in\nautonomous driving.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T14:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.16786v1","title":"MOOSComp: Improving Lightweight Long-Context Compressor via Mitigating\n  Over-Smoothing and Incorporating Outlier Scores","summary":"Recent advances in large language models have significantly improved their\nability to process long-context input, but practical applications are\nchallenged by increased inference time and resource consumption, particularly\nin resource-constrained environments. To address these challenges, we propose\nMOOSComp, a token-classification-based long-context compression method that\nenhances the performance of a BERT-based compressor by mitigating the\nover-smoothing problem and incorporating outlier scores. In the training phase,\nwe add an inter-class cosine similarity loss term to penalize excessively\nsimilar token representations, thereby improving the token classification\naccuracy. During the compression phase, we introduce outlier scores to preserve\nrare but critical tokens that are prone to be discarded in task-agnostic\ncompression. These scores are integrated with the classifier's output, making\nthe compressor more generalizable to various tasks. Superior performance is\nachieved at various compression ratios on long-context understanding and\nreasoning benchmarks. Moreover, our method obtains a speedup of 3.3x at a 4x\ncompression ratio on a resource-constrained mobile device.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-23T15:02:53Z"}
{"aid":"http://arxiv.org/abs/2504.16800v1","title":"Array Partitioning Based Near-Field Attitude and Location Estimation","summary":"This paper studies a passive source localization system, where a single base\nstation (BS) is employed to estimate the positions and attitudes of multiple\nmobile stations (MSs). The BS and the MSs are equipped with uniform rectangular\narrays, and the MSs are located in the near-field region of the BS array. To\navoid the difficulty of tackling the problem directly based on the near-field\nsignal model, we establish a subarray-wise far-field received signal model. In\nthis model, the entire BS array is divided into multiple subarrays to ensure\nthat each MS is in the far-field region of each BS subarray. By exploiting the\nangles of arrival (AoAs) of an MS antenna at different BS subarrays, we\nformulate the attitude and location estimation problem under the Bayesian\ninference framework. Based on the factor graph representation of the\nprobabilistic problem model, a message passing algorithm named array\npartitioning based pose and location estimation (APPLE) is developed to solve\nthis problem. An estimation-error lower bound is obtained as a performance\nbenchmark of the proposed algorithm. Numerical results demonstrate that the\nproposed APPLE algorithm outperforms other baseline methods in the accuracy of\nposition and attitude estimation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T15:20:39Z"}
{"aid":"http://arxiv.org/abs/2504.16804v1","title":"Constructing Four-Body Ballistic Lunar Transfers via Analytical Energy\n  Conditions","summary":"This paper derives and summarizes the analytical conditions for lunar\nballistic capture and constructs ballistic lunar transfers based on these\nconditions. We adopt the Sun-Earth/Moon planar bicircular restricted four-body\nproblem as the dynamical model to construct lunar transfers. First, the\nanalytical conditions for ballistic capture are derived based on the\nrelationship between the Keplerian energy with respect to the Moon and the\nangular momentum with respect to the Moon, summarized in form of exact ranges\nof the Jacobi energy at the lunar insertion point. Both sufficient and\nnecessary condition and necessary condition are developed. Then, an\noptimization method combined with the analytical energy conditions is proposed\nto construct ballistic lunar transfers. Simulations shows that a high ballistic\ncapture ratio is achieved by our proposed method (100$\\%$ for direct insertion\nand $99.15\\%$ for retrograde insertion). Examining the obtained ballistic lunar\ntransfers, the effectiveness of the analytical energy conditions is verified.\nSamples of our obtained lunar transfers achieves a lower impulse and shorter\ntime of flight compared to two conventional methods, further strengthening the\nadvantage of our proposed method.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-23T15:22:02Z"}
{"aid":"http://arxiv.org/abs/2504.16817v1","title":"Rediscussion of eclipsing binaries. Paper XXIII. The F-type twin system\n  RZ Chamaeleontis","summary":"RZ Cha is a detached eclipsing binary containing two slightly evolved F5\nstars in a circular orbit of period 2.832 d. We use new light curves from the\nTransiting Exoplanet Survey Satellite (TESS) and spectroscopic orbits from Gaia\nDR3 to measure the physical properties of the component stars. We obtain masses\nof 1.488 +/- 0.011 Msun and 1.482 +/- 0.011 Msun, and radii of 2.150 +/- 0.006\nRsun and 2.271 +/- 0.006 Rsun. An orbital ephemeris from the TESS data does not\nmatch published times of mid-eclipse from the 1970s, suggesting the period is\nnot constant. We measure a distance to the system of 176.7 +/- 3.7 pc, which\nagrees with the Gaia DR3 value. A comparison with theoretical models finds\nagreement for metal abundances of Z = 0.014 and Z = 0.017 and an age of 2.3\nGyr. No evidence for pulsations was found in the light curves. Future data from\nTESS and Gaia will provide more precise masses and constraints on any changes\nin orbital period.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.16827v1","title":"Endpoint boundedness of singular integrals: CMO space associated to\n  SchrÃ¶dinger operators","summary":"Let $ \\mathcal{L} = -\\Delta + V $ be a Schr\\\"odinger operator acting on $\nL^2(\\mathbb{R}^n) $, where the nonnegative potential $ V $ belongs to the\nreverse H\\\"older class $ RH_q $ for some $ q \\geq n/2 $. This article is\nprimarily concerned with the study of endpoint boundedness for classical\nsingular integral operators in the context of the space $\n\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $, consisting of functions of\nvanishing mean oscillation associated with $ \\mathcal{L} $.\n  We establish the following main results: (i) the standard Hardy--Littlewood\nmaximal operator is bounded on $\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $;\n(ii) for each $ j = 1, \\ldots, n$, the adjoint of the Riesz transform $\n\\partial_j \\mathcal{L}^{-1/2} $ is bounded from $ C_0(\\mathbb{R}^n) $ into $\n\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $; and (iii) the approximation to the\nidentity generated by the Poisson and heat semigroups associated with $\n\\mathcal{L} $ characterizes $ \\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $\nappropriately.\n  These results recover the classical analogues corresponding to the Laplacian\nas a special case. However, the presence of the potential $ V $ introduces\nsubstantial analytical challenges, necessitating tools beyond the scope of\nclassical Calder\\'on--Zygmund theory. Our approach leverages precise heat\nkernel estimates and the structural properties of $\n\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $ established by Song and the third\nauthor in [J. Geom. Anal. 32 (2022), no. 4, Paper No. 130, 37 pp].","main_category":"math.CA","categories":"math.CA","published":"2025-04-23T15:43:52Z"}
{"aid":"http://arxiv.org/abs/2504.16829v1","title":"Bogomolov type inequalities and Frobenius semipositivity","summary":"We prove Bogomolov type inequalities for high Chern characters of semistable\nsheaves satisfying certain Frobenius semipositivity. The key ingredients in the\nproof are a high rank generalization of the asymptotic Riemann-Roch theorem and\nLanger's estimation theorem of the global sections of torsion free sheaves.\nThese results give some Bogomolov type inequalities for semistable sheaves with\nvanishing low Chern characters. Our results are also applied to obtain\ninequalities of Chern characters of threefolds and varieties of small\ncodimension in projective spaces and abelian varieties.","main_category":"math.AG","categories":"math.AG","published":"2025-04-23T15:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.16845v1","title":"An accreting dwarf star orbiting the S-type giant star pi1 Gru","summary":"Aims. We aim to characterize the properties of the inner companion of the\nS-type AGB star pi1 Gru, and to identify plausible future evolution scenarios\nfor this triple system. Methods. We observed pi1 Gru with ALMA and VLT/SPHERE.\nIn addition, we collected archival photometry data and used the Hipparcos-Gaia\nproper motion anomaly. We derive the best orbital parameters from Bayesian\ninference. Results. The inner companion, pi1 Gru C was located at 37.4 +/- 2.0\nmas from the primary in June-July 2019 (projected separation of 6.05 +/- 0.55\nau at 161.7 +/- 11.7 pc). The best orbital solution gives a companion mass of\n0.86 (+0.22/-0.20) Msun (using the derived mass of the primary), and a\nsemi-major axis of 7.05 (+0.54/-0.57) au. This leads to an orbital period of\n11.0 (+1.7/-1.5) yr. The best solution is an elliptical orbit with eccentricity\ne = 0.35 (+0.18/-0.17), but a circular orbit cannot be totally excluded. The\nclose companion can either be a K1V (F9.5V/K7V) star or a white dwarf. The\nultraviolet and millimeter continuum photometry are consistent with the\npresence of an accretion disk around the close companion. The ultraviolet\nemission could then either originate in hot spots in an overall cooler disk, or\nalso from a hot disk in case the companion is a white dwarf. Conclusions.\nThough the close companion and the AGB star are interacting, and an accretion\ndisk is observed around the companion, the mass-accretion rate is too low to\ncause a Ia supernova but could produce novae every ~900 yr. Short wavelength\nspatially resolved observations are needed to further constrain the nature of\nthe C companion. Searches for close-in companions similar to this system will\nhelp to better understand the physics of mass- and angular-momentum transfer,\nand orbital evolution in the late evolutionary stages.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T16:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.16847v1","title":"Pulsed Magnetophononics in Gapped Quantum Magnets","summary":"One route to the control of quantum magnetism at ultrafast timescales is\nmagnetophononics, the modulation of magnetic interactions by coherently driven\nlattice excitations. Theoretical studies of a gapped quantum magnet subject to\ncontinuous, single-frequency driving of one strongly coupled phonon mode find\nintriguing phenomena including mutually repelling phonon-bitriplon excitations\nand global renormalization of the spin excitation spectrum. Because experiments\nare performed with ultrashort pulses that contain a wide range of driving\nfrequencies, we investigate phonon-bitriplon physics under pulsed laser\ndriving. We use the equations of motion to compute the transient response of\nthe driven and dissipative spin-phonon system, which we characterize using the\nphonon displacement, phonon number, and triplon occupations. In the Fourier\ntransforms of each quantity we discover a low-frequency energetic oscillation\nbetween the lattice and spin sectors, which is an intrinsically nonequilibrium\ncollective mode, and demonstrate its origin as a beating between mutually\nrepelling composite excitations. We introduce a phonon-bitriplon approximation\nthat captures all the physics of hybridization, collective mode formation, and\ndifference-frequency excitation, and show that sum-frequency phenomena also\nleave clear signatures in the repsonse. We model the appearance of such\nmagnetophononic phenomena in the strongly-coupled spin-chain compound\nCuGeO$_3$, whose overlapping phonon and spin excitation spectra are well\ncharacterized, to deduce the criteria for their possible observation in quantum\nmagnetic materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-23T16:10:01Z"}
{"aid":"http://arxiv.org/abs/2504.16870v1","title":"High-Quality Cloud-Free Optical Image Synthesis Using Multi-Temporal SAR\n  and Contaminated Optical Data","summary":"Addressing gaps caused by cloud cover and the long revisit cycle of\nsatellites is vital for providing essential data to support remote sensing\napplications. This paper tackles the challenges of missing optical data\nsynthesis, particularly in complex scenarios with cloud cover. We propose\nCRSynthNet, a novel image synthesis network that incorporates innovative\ndesigned modules such as the DownUp Block and Fusion Attention to enhance\naccuracy. Experimental results validate the effectiveness of CRSynthNet,\ndemonstrating substantial improvements in restoring structural details,\npreserving spectral consist, and achieving superior visual effects that far\nexceed those produced by comparison methods. It achieves quantitative\nimprovements across multiple metrics: a peak signal-to-noise ratio (PSNR) of\n26.978, a structural similarity index measure (SSIM) of 0.648, and a root mean\nsquare error (RMSE) of 0.050. Furthermore, this study creates the TCSEN12\ndataset, a valuable resource specifically designed to address cloud cover\nchallenges in missing optical data synthesis study. The dataset uniquely\nincludes cloud-covered images and leverages earlier image to predict later\nimage, offering a realistic representation of real-world scenarios. This study\noffer practical method and valuable resources for optical satellite image\nsynthesis task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T16:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.16884v1","title":"Do Large Language Models know who did what to whom?","summary":"Large Language Models (LLMs) are commonly criticized for not understanding\nlanguage. However, many critiques focus on cognitive abilities that, in humans,\nare distinct from language processing. Here, we instead study a kind of\nunderstanding tightly linked to language: inferring who did what to whom\n(thematic roles) in a sentence. Does the central training objective of\nLLMs-word prediction-result in sentence representations that capture thematic\nroles? In two experiments, we characterized sentence representations in four\nLLMs. In contrast to human similarity judgments, in LLMs the overall\nrepresentational similarity of sentence pairs reflected syntactic similarity\nbut not whether their agent and patient assignments were identical vs.\nreversed. Furthermore, we found little evidence that thematic role information\nwas available in any subset of hidden units. However, some attention heads\nrobustly captured thematic roles, independently of syntax. Therefore, LLMs can\nextract thematic roles but, relative to humans, this information influences\ntheir representations more weakly.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T17:00:45Z"}
{"aid":"http://arxiv.org/abs/2504.16892v1","title":"Collective Defined Contribution Schemes Without Intergenerational\n  Cross-Subsidies","summary":"We present an architecture for managing Collective Defined Contribution (CDC)\nschemes. The current approach to UK CDC can be described as shared-indexation,\nwhere the nominal benefit of every member in a scheme receives the same level\nof indexation each year. The design of such schemes rely on the use of\napproximate discounting methodologies to value liabilities, and this leads to\nintergenerational cross-subsidies which can be large and unpredictable. We\npresent an alternative approach which we call Collective-Drawdown CDC. This\napproach does not result in intergenerational cross-subsidies since all pooling\nis performed by explicit insurance contracts. It is therefore completely fair.\nMoreover, this scheme results in better pension outcomes when compared to\nshared-indexation CDC under the same model parameters.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-23T17:15:35Z"}
{"aid":"http://arxiv.org/abs/2504.16911v1","title":"Dynamical tides in neutron stars with first-order phase transitions: the\n  role of the discontinuity mode","summary":"During the late stages of a binary neutron star inspiral, dynamical tides\ninduced in each star by its companion become significant and should be included\nin complete gravitational-wave (GW) modeling. We investigate the coupling\nbetween the tidal field and quasi-normal modes in hybrid stars and show that\nthe discontinuity mode ($g$-mode)--intrinsically associated with first-order\nphase transitions and buoyancy--can rival the contribution of the fundamental\n$f$-mode. We find that the $g$-mode overlap integral can reach up to $\\sim\n10\\%$ of the $f$-mode value for hybrid star masses in the range\n1.4-2.0$M_{\\odot}$, with the largest values generally associated with larger\ndensity jumps. This leads to a GW phase shift due to the $g$-mode of $\\Delta\n\\phi_g \\lesssim 0.1$-$1$ rad (i.e., up to $\\sim$5\\%-10\\% of $\\Delta \\phi_f$),\nwith the largest shifts occurring for masses near the phase transition. At\nhigher masses, the shifts remain smaller and nearly constant, with $\\Delta\n\\phi_g \\lesssim 0.1$ rad (roughly $\\sim 1\\%$ of $\\Delta \\phi_f$). These GW\nshifts may be relevant even at the design sensitivity of current\nsecond-generation GW detectors in the most optimistic cases. Moreover, if a\n$g$-mode is present and lies near the $f$-mode frequency, neglecting it in the\nGW modeling can lead to systematic biases in neutron star parameter estimation,\nresulting in radius errors of up to $1\\%-2\\%$. These results show the\nimportance of dynamical tides to probe neutron stars' equation of state, and to\ntest the existence of dense-matter phase transitions.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-23T17:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.16914v1","title":"MorphoNavi: Aerial-Ground Robot Navigation with Object Oriented Mapping\n  in Digital Twin","summary":"This paper presents a novel mapping approach for a universal aerial-ground\nrobotic system utilizing a single monocular camera. The proposed system is\ncapable of detecting a diverse range of objects and estimating their positions\nwithout requiring fine-tuning for specific environments. The system's\nperformance was evaluated through a simulated search-and-rescue scenario, where\nthe MorphoGear robot successfully located a robotic dog while an operator\nmonitored the process. This work contributes to the development of intelligent,\nmultimodal robotic systems capable of operating in unstructured environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T17:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.16926v1","title":"Meteor CNEOS 2014-01-08 has nothing to do with Planet 9","summary":"It has been suggested that a gravitational slingshot from the hypothetical\nPlanet 9 (P9) could explain the unusually large velocity of meteor CNEOS\n2014-01-08. I show that this explanation does not work because P9 can at most\nprovide an insignificant 0.25 km/s of the object's 42 km/s asymptotic\nheliocentric velocity and at most a 7.6 degree deflection due to P9's low\norbital speed and non-zero radius. Furthermore, the hypothesis requires an\nencounter with two planets that is trillions of times more unlikely than CNEOS\n2014-01-08 simply being fast from the beginning.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-23T17:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.17236v1","title":"Rate-Distortion-Perception Theory for the Quadratic Wasserstein Space","summary":"We establish a single-letter characterization of the fundamental\ndistortion-rate-perception tradeoff with limited common randomness under the\nsquared error distortion measure and the squared Wasserstein-2 perception\nmeasure. Moreover, it is shown that this single-letter characterization can be\nexplicitly evaluated for the Gaussian source. Various notions of universal\nrepresentation are also clarified.","main_category":"cs.IT","categories":"cs.IT,cs.LG,math.IT","published":"2025-04-24T04:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.17240v1","title":"Quantum stream cipher and Quantum block cipher -The Era of 100 Gbit/sec\n  real-time encryption-","summary":"This paper is the part-II of the previous paper and introduces the world of\nYuen's concept. In the theory of cryptology, the Shannon impossibility theorem\nstates that the upper bound of the security of a plaintext against a\nciphertext-only attack is the entropy of the secret key. At the same time, it\ngives the upper bound of the unicity distance against a known plaintext attack.\nHence the development of a new symmetric key cipher requires finding a way to\nundo or lift this theorem. Such challenges have been attempted with quantum\nstream cipher and quantum data locking as block cipher. Both ciphers are\ndesigned by means of differentiating the receiving performance of Bob with key\nand Eve without key according to the principle of quantum communication theory.\nThus, the origin of security of both ciphers come from the principle of keyed\ncommunication in quantum noise (KCQ) proposed by Yuen. In this paper, we\nexplain and compare the principles and features of both cipher and assist to\nimprove the quantum data locking scheme. Then we will introduce experimental\nresearch on quantum stream cipher towards commercialization, which has\nperformance superior to conventional cipher.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-24T04:28:17Z"}
{"aid":"http://arxiv.org/abs/2504.17243v1","title":"NeuralGrok: Accelerate Grokking by Neural Gradient Transformation","summary":"Grokking is proposed and widely studied as an intricate phenomenon in which\ngeneralization is achieved after a long-lasting period of overfitting. In this\nwork, we propose NeuralGrok, a novel gradient-based approach that learns an\noptimal gradient transformation to accelerate the generalization of\ntransformers in arithmetic tasks. Specifically, NeuralGrok trains an auxiliary\nmodule (e.g., an MLP block) in conjunction with the base model. This module\ndynamically modulates the influence of individual gradient components based on\ntheir contribution to generalization, guided by a bilevel optimization\nalgorithm. Our extensive experiments demonstrate that NeuralGrok significantly\naccelerates generalization, particularly in challenging arithmetic tasks. We\nalso show that NeuralGrok promotes a more stable training paradigm, constantly\nreducing the model's complexity, while traditional regularization methods, such\nas weight decay, can introduce substantial instability and impede\ngeneralization. We further investigate the intrinsic model complexity\nleveraging a novel Absolute Gradient Entropy (AGE) metric, which explains that\nNeuralGrok effectively facilitates generalization by reducing the model\ncomplexity. We offer valuable insights on the grokking phenomenon of\nTransformer models, which encourages a deeper understanding of the fundamental\nprinciples governing generalization ability.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T04:41:35Z"}
{"aid":"http://arxiv.org/abs/2504.17244v1","title":"Service Rate Regions of MDS Codes & Fractional Matchings in\n  Quasi-uniform Hypergraphs","summary":"The service rate region (SRR) has emerged as a critical performance metric\nfor distributed systems that store data redundantly. It measures the system's\nability to serve multiple users concurrently. Mathematically, the SRR is a\npolytope in R^k where each dimension corresponds to the service request rate of\none of the k data objects. This paper focuses on systems employing a class of\nMaximum Distance Separable (MDS) codes. For each code in the class, we\ncharacterize the k axes intercept points of its SRR, and the smallest standard\nsimplex that includes the SRR. We use these results to show that the SRR grows\nwith the increasing number of systematic columns in the generator matrices. We\nestablish a graph-theoretic framework associating this SRR problem with\nfractional matchings in quasi-uniform hypergraphs. Identifying the SRR polytope\nis equivalent to determining a particular image of the fractional-matching\npolytope. We introduce a notion of Greedy Matching and show that it is\nsufficient to focus on these matchings to characterize the SRR rather than the\nentire matching polytope. With these tools, we determine the SRR of a large\nsubset of the considered class of codes. Our results generalize previous\ncharacterizations of systematic and non-systematic MDS-coded systems, offering\na unified framework for analyzing service rate regions of codes.","main_category":"cs.IT","categories":"cs.IT,math.CO,math.IT","published":"2025-04-24T04:44:37Z"}
{"aid":"http://arxiv.org/abs/2504.17247v1","title":"Targeted AMP generation through controlled diffusion with efficient\n  embeddings","summary":"Deep learning-based antimicrobial peptide (AMP) discovery faces critical\nchallenges such as low experimental hit rates as well as the need for nuanced\ncontrollability and efficient modeling of peptide properties. To address these\nchallenges, we introduce OmegAMP, a framework that leverages a diffusion-based\ngenerative model with efficient low-dimensional embeddings, precise\ncontrollability mechanisms, and novel classifiers with drastically reduced\nfalse positive rates for candidate filtering. OmegAMP enables the targeted\ngeneration of AMPs with specific physicochemical properties, activity profiles,\nand species-specific effectiveness. Moreover, it maximizes sample diversity\nwhile ensuring faithfulness to the underlying data distribution during\ngeneration. We demonstrate that OmegAMP achieves state-of-the-art performance\nacross all stages of the AMP discovery pipeline, significantly advancing the\npotential of computational frameworks in combating antimicrobial resistance.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.BM","published":"2025-04-24T04:53:04Z"}
{"aid":"http://arxiv.org/abs/2504.17251v1","title":"Ultrafast ultrasound coded vector Doppler imaging of blood flow velocity\n  and resistivity","summary":"Dynamic and precise measurement of cerebral blood flow velocity is crucial in\nneuroscience and the diagnosis of cerebrovascular diseases. Traditional color\nDoppler ultrasound can only measure the velocity component along the ultrasound\nbeam, which restricts its ability to accurately capture the complete blood flow\nvector in complex environments. To overcome these limitations, we propose an\nultrafast pulse-coded vector Doppler (PC-UVD) imaging method, utilizing\nHadamard matrix-based pulse encoding to improve velocity estimation accuracy\nunder low signal-to-noise ratio (SNR) conditions. Our study encompasses spiral\nflow simulations and in vivo rat brain experiments, showing significantly\nenhanced measurement precision compared to conventional ultrafast vector\nDoppler (UVD). This innovative approach enables the measurement of dynamic\ncerebral blood flow velocity within a single cardiac cycle, offering insights\ninto the characteristics of cerebrovascular resistivity. The proposed PC-UVD\nmethod employs Hadamard matrix encoding of plane waves, boosting SNR without\ncompromising temporal or spatial resolution. Velocity vectors are subsequently\nestimated using a weighted least squares (WLS) approach, with iterative\nresidual-based weight optimization improving robustness to noise and minimizing\nthe impact of outliers. The effectiveness of this technique is confirmed\nthrough simulations with a spiral blood flow phantom, demonstrating a marked\nimprovement in velocity estimation accuracy, particularly in deep imaging\nregions with significant signal attenuation. In vivo experiments on rat brains\nfurther confirm that the proposed method offers greater accuracy than existing\nUVD approaches, particularly for small vessels. Notably, our method can\nprecisely differentiate arterial from venous flow by analyzing pulsatility and\nresistivity within the cerebral vascular network.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-24T05:01:06Z"}
{"aid":"http://arxiv.org/abs/2504.17259v1","title":"Multiobjective Optimization for Robust Holonomic Quantum Gates","summary":"Robust pulses have been widely used to reduce the sensitivity of quantum gate\noperations against various systematic errors due to the imperfections in\npractical quantum control. Yet, the typical optimization focuses on minimizing\none type of errors serving as the one-objective algorithm, which arises a more\nsusceptible sensitivity to other error sources. Optimizing multiple conflicting\nobjectives of errors simultaneously remains a big challenge in quantum\ncomputing. Here, we propose a multiobjective optimization algorithm to achieve\nnonadiabatic holonomic quantum gates with enhanced robustness. We show that by\nconsidering the amplitude error, the detuning error and the decoherence of the\nRydberg state as three individual objectives to be minimized, this algorithm\ncan effectively balance multiple competing objectives, giving rise to a set of\nPareto optimal solutions. We apply the Entropy Weight method to select the best\nsolution that implements the robust holonomic gates, outperforming existing\noptimal gates with one-objective by having both higher gate fidelity and\nstronger robustness. This numerical approach of optimizing gates with multiple\nobjectives can be readily applied to other gate protocols featuring a promising\nadvance in fault-tolerant quantum computing with Rydberg atoms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-24T05:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.17275v1","title":"Physics-Embedded Bayesian Neural Network (PE-BNN) to predict Energy\n  Dependence of Fission Product Yields with Fine Structures","summary":"We present a physics-embedded Bayesian neural network (PE-BNN) framework that\nintegrates fission product yields (FPYs) with prior nuclear physics knowledge\nto predict energy-dependent FPY data with fine structure. By incorporating an\nenergy-independent phenomenological shell factor as a single input feature, the\nPE-BNN captures both fine structures and global energy trends. The combination\nof this physics-informed input with hyperparameter optimization via the\nWatanabe-Akaike Information Criterion (WAIC) significantly enhances predictive\nperformance. Our results demonstrate that the PE-BNN framework is well-suited\nfor target observables with systematic features that can be embedded as model\ninputs, achieving close agreement with known shell effects and prompt neutron\nmultiplicities.","main_category":"nucl-th","categories":"nucl-th,nucl-ex,physics.data-an","published":"2025-04-24T06:04:04Z"}
{"aid":"http://arxiv.org/abs/2504.17281v1","title":"Building Sustainable and Trustworthy Indigenous Knowledge Preservation\n  Ecosystem","summary":"This paper focuses on the essential global issue of protecting and\ntransmitting indigenous knowledge. It reveals the challenges in this area and\nproposes a sustainable supply chain framework for indigenous knowledge. The\npaper reviews existing technological solutions and identifies technical\nchallenges and gaps. It then introduces cutting-edge technologies to protect\nand disseminate indigenous knowledge more effectively. The paper also discusses\nhow the proposed framework can address real-world challenges in protecting and\ntransmitting indigenous knowledge, and explores future research applications of\nthe proposed solutions. Finally, it addresses open issues and provides a\ndetailed analysis, offering promising research directions for the protection\nand transmission of indigenous knowledge worldwide.","main_category":"cs.CY","categories":"cs.CY,cs.ET","published":"2025-04-24T06:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.17300v1","title":"The Ultimate Cookbook for Invisible Poison: Crafting Subtle Clean-Label\n  Text Backdoors with Style Attributes","summary":"Backdoor attacks on text classifiers can cause them to predict a predefined\nlabel when a particular \"trigger\" is present. Prior attacks often rely on\ntriggers that are ungrammatical or otherwise unusual, leading to conspicuous\nattacks. As a result, human annotators, who play a critical role in curating\ntraining data in practice, can easily detect and filter out these unnatural\ntexts during manual inspection, reducing the risk of such attacks. We argue\nthat a key criterion for a successful attack is for text with and without\ntriggers to be indistinguishable to humans. However, prior work neither\ndirectly nor comprehensively evaluated attack subtlety and invisibility with\nhuman involvement. We bridge the gap by conducting thorough human evaluations\nto assess attack subtlety. We also propose \\emph{AttrBkd}, consisting of three\nrecipes for crafting subtle yet effective trigger attributes, such as\nextracting fine-grained attributes from existing baseline backdoor attacks. Our\nhuman evaluations find that AttrBkd with these baseline-derived attributes is\noften more effective (higher attack success rate) and more subtle (fewer\ninstances detected by humans) than the original baseline backdoor attacks,\ndemonstrating that backdoor attacks can bypass detection by being inconspicuous\nand appearing natural even upon close inspection, while still remaining\neffective. Our human annotation also provides information not captured by\nautomated metrics used in prior work, and demonstrates the misalignment of\nthese metrics with human judgment.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T06:50:59Z"}
{"aid":"http://arxiv.org/abs/2504.17312v1","title":"Quantum diamond microscopy of individual vaterite microspheres\n  containing magnetite nanoparticles","summary":"Biocompatible vaterite microspheres, renowned for their porous structure, are\npromising carriers for magnetic nanoparticles (MNPs) in biomedical applications\nsuch as targeted drug delivery and diagnostic imaging. Precise control over the\nmagnetic moment of individual microspheres is crucial for these applications.\nThis study employs widefield quantum diamond microscopy to map the stray\nmagnetic fields of individual vaterite microspheres (3-10 um) loaded with Fe3O4\nMNPs of varying sizes (5 nm, 10 nm, and 20 nm). By analyzing over 35\nmicrospheres under a 222 mT external magnetizing field, we measured\npeak-to-peak stray field amplitudes of 41 uT for 5 nm and 10 nm\nsuperparamagnetic MNPs, reflecting their comparable magnetic response, and 12\nuT for 20 nm ferrimagnetic MNPs, due to distinct magnetization behavior.\nFinite-element simulations confirm variations in MNP distribution and\nmagnetization uniformity within the vaterite matrix, with each microsphere\nencapsulating thousands of MNPs to generate its magnetization. This\nhigh-resolution magnetic imaging approach yields critical insights into\nMNP-loaded vaterite, enabling optimized synthesis and magnetically controlled\nsystems for precision therapies and diagnostics.","main_category":"physics.bio-ph","categories":"physics.bio-ph,physics.app-ph","published":"2025-04-24T07:13:32Z"}
{"aid":"http://arxiv.org/abs/2504.17372v1","title":"Formation of the glycine isomer glycolamide (NH$_2$C(O)CH$_2$OH) on the\n  surfaces of interstellar ice grains: Insights from atomistic simulations","summary":"Syn-glycolamide, a glycine isomer, has recently been detected in the\nG+0.693-0.027 molecular cloud. Investigations on its formation in the\ninterstellar medium could offer insights into synthetic routes leading to\nglycine in prebiotic environments. Quantum chemical simulations on glycolamide\n(NH$_2$C(O)CH$_2$OH) formation on interstellar ice mantles, mimicked by a water\nice cluster model, are presented. Glycolamide synthesis has been here modeled\nconsidering a stepwise process: the coupling between formaldehyde (H$_2$CO) and\nthe radical of formamide (NH$_2$CO$^{\\bullet}$) occurs first, forming the\nglycolamide precursor NH$_2$C(O)CH$_2$O$^{\\bullet}$, which is then hydrogenated\nto give anti-glycolamide. We hypothesize that anti-to-syn interconversion will\noccur in conjunction with glycolamide desorption from the ice surface. The\nreaction barrier for NH$_2$C(O)CH$_2$O$^{\\bullet}$ formation varies from 9 to\n26 kJ mol$^{-1}$, depending on surface binding sites. Kinetic studies indicate\nthat this reaction step is feasible in environments with a $T > 35~\\text{K}$,\nuntil desorption of the reactants. The hydrogenation step leading to\nanti-glycolamide presents almost no energy barrier due to the easy H atom\ndiffusion towards the NH$_2$C(O)CH$_2$O$^{\\bullet}$ intermediate. However, it\ncompetes with the extraction of an H atom from the formyl group of\nNH$_2$C(O)CH$_2$O$^{\\bullet}$, which leads to formyl formamide, NH$_2$C(O)CHO,\nand H$_2$. Nonetheless, according to our results, anti-glycolamide formation is\npredicted to be the most favored reactive channel.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T08:44:07Z"}
{"aid":"http://arxiv.org/abs/2504.17381v1","title":"Subtrajectory Clustering and Coverage Maximization in Cubic Time, or\n  Better","summary":"Many application areas collect unstructured trajectory data. In subtrajectory\nclustering, one is interested to find patterns in this data using a hybrid\ncombination of segmentation and clustering. We analyze two variants of this\nproblem based on the well-known \\textsc{SetCover} and\n\\textsc{CoverageMaximization} problems. In both variants the set system is\ninduced by metric balls under the Fr\\'echet distance centered at polygonal\ncurves. Our algorithms focus on improving the running time of the update step\nof the generic greedy algorithm by means of a careful combination of sweeps\nthrough a candidate space. In the first variant, we are given a polygonal curve\n$P$ of complexity $n$, distance threshold $\\Delta$ and complexity bound $\\ell$\nand the goal is to identify a minimum-size set of center curves $\\mathcal{C}$,\nwhere each center curve is of complexity at most $\\ell$ and every point $p$ on\n$P$ is covered. A point $p$ on $P$ is covered if it is part of a subtrajectory\n$\\pi_p$ of $P$ such that there is a center $c\\in\\mathcal{C}$ whose Fr\\'echet\ndistance to $\\pi_p$ is at most $\\Delta$. We present an approximation algorithm\nfor this problem with a running time of $O((n^2\\ell +\n\\sqrt{k_\\Delta}n^{5/2})\\log^2n)$, where $k_\\Delta$ is the size of an optimal\nsolution. The algorithm gives a bicriterial approximation guarantee that\nrelaxes the Fr\\'echet distance threshold by a constant factor and the size of\nthe solution by a factor of $O(\\log n)$. The second problem variant asks for\nthe maximum fraction of the input curve $P$ that can be covered using $k$\ncenter curves, where $k\\leq n$ is a parameter to the algorithm. Here, we show\nthat our techniques lead to an algorithm with a running time of\n$O((k+\\ell)n^2\\log^2 n)$ and similar approximation guarantees. Note that in\nboth algorithms $k,k_\\Delta\\in O(n)$ and hence the running time is cubic, or\nbetter if $k\\ll n$.","main_category":"cs.CG","categories":"cs.CG,F.2.2","published":"2025-04-24T08:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.17400v1","title":"Selectivity filter conductance, rectification and fluctuations of\n  subdomains - how can this all relate to the value of Hurst exponent in the\n  dwell-times of ion channels states?","summary":"The Hurst effect in the signals describing ion channels' activity has been\nknown for many years. This effect is present in the experimental recordings of\nsingle-channel currents, but not only. The sequences of dwell times of\nfunctionally different channel states also exhibit long-range correlations. We\nhave found that the memory effect within the dwell-time series is related to\nthe coupling between the channel's activation gate (AG) and selectivity filter\n(SF), which controls the ion conduction. In this work, we analyzed both the\nexperimental data describing the activity of potassium channels of different\ntypes (e.g., BK, mitoBK, mitoTASK-3, mitoKv1.3, TREK-2-like channels) and the\nseries generated according to our previously proposed Hurst effect model. The\nobtained results suggest that the strength of the allosteric cooperation\nbetween the AG and SF determines not only the conductance of the channel -\nwhich governs how often ions in SF move or remain blocked - but also modulates\nthe correlations present in the dwell times when sampled with a suitably high\nsampling rate. Moreover, we found that rectification can interfere with this\nprocess, contributing to additional changes in correlations within the\nchannel's sojourns in subsequent states. Similarly, the correlations may be\naffected by processes proceeding at longer time scales, like interactions with\nthe channel's auxiliary domains or lipid surroundings.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-24T09:41:03Z"}
{"aid":"http://arxiv.org/abs/2504.17404v1","title":"Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI\n  Co-Alignment to Sustainable Symbiotic Society","summary":"Artificial Intelligence (AI) systems are becoming increasingly powerful and\nautonomous, and may progress to surpass human intelligence levels, namely\nArtificial Superintelligence (ASI). During the progression from AI to ASI, it\nmay exceed human control, violate human values, and even lead to irreversible\ncatastrophic consequences in extreme cases. This gives rise to a pressing issue\nthat needs to be addressed: superalignment, ensuring that AI systems much\nsmarter than humans, remain aligned with human (compatible) intentions and\nvalues. Existing scalable oversight and weak-to-strong generalization methods\nmay prove substantially infeasible and inadequate when facing ASI. We must\nexplore safer and more pluralistic frameworks and approaches for\nsuperalignment. In this paper, we redefine superalignment as the human-AI\nco-alignment towards a sustainable symbiotic society, and highlight a framework\nthat integrates external oversight and intrinsic proactive alignment. External\noversight superalignment should be grounded in human-centered ultimate\ndecision, supplemented by interpretable automated evaluation and correction, to\nachieve continuous alignment with humanity's evolving values. Intrinsic\nproactive superalignment is rooted in a profound understanding of the self,\nothers, and society, integrating self-awareness, self-reflection, and empathy\nto spontaneously infer human intentions, distinguishing good from evil and\nproactively considering human well-being, ultimately attaining human-AI\nco-alignment through iterative interaction. The integration of\nexternally-driven oversight with intrinsically-driven proactive alignment\nempowers sustainable symbiotic societies through human-AI co-alignment, paving\nthe way for achieving safe and beneficial AGI and ASI for good, for human, and\nfor a symbiotic ecology.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T09:53:49Z"}
{"aid":"http://arxiv.org/abs/2504.17428v1","title":"Detection, Classification and Prevalence of Self-Admitted Aging Debt","summary":"Context: Previous research on software aging is limited with focus on dynamic\nruntime indicators like memory and performance, often neglecting evolutionary\nindicators like source code comments and narrowly examining legacy issues\nwithin the TD context. Objective: We introduce the concept of Aging Debt (AD),\nrepresenting the increased maintenance efforts and costs needed to keep\nsoftware updated. We study AD through Self-Admitted Aging Debt (SAAD) observed\nin source code comments left by software developers. Method: We employ a\nmixed-methods approach, combining qualitative and quantitative analyses to\ndetect and measure AD in software. This includes framing SAAD patterns from the\nsource code comments after analysing the source code context, then utilizing\nthe SAAD patterns to detect SAAD comments. In the process, we develop a\ntaxonomy for SAAD that reflects the temporal aging of software and its\nassociated debt. Then we utilize the taxonomy to quantify the different types\nof AD prevalent in OSS repositories. Results: Our proposed taxonomy categorizes\ntemporal software aging into Active and Dormant types. Our extensive analysis\nof over 9,000+ Open Source Software (OSS) repositories reveals that more than\n21% repositories exhibit signs of SAAD as observed from our gold standard SAAD\ndataset. Notably, Dormant AD emerges as the predominant category, highlighting\na critical but often overlooked aspect of software maintenance. Conclusion: As\nsoftware volume grows annually, so do evolutionary aging and maintenance\nchallenges; our proposed taxonomy can aid researchers in detailed software\naging studies and help practitioners develop improved and proactive maintenance\nstrategies.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CE,cs.GL","published":"2025-04-24T10:38:55Z"}
{"aid":"http://arxiv.org/abs/2504.17430v1","title":"Stratifying quiver Schur algebras via ersatz parity sheaves","summary":"We propose an extension of the theory of parity sheaves, which allows for\nnon-locally constant sheaves along strata. Our definition is tailored for\nproving the existence of (proper, quasihereditary, etc) stratifications of\n$\\mathrm{Ext}$-algebras. We use this to study quiver Schur algebras $A(\\alpha)$\nfor the cyclic quiver of length $2$. We find a polynomial quasihereditary\nstructure on $A(\\alpha)$ compatible with the categorified PBW basis of McNamara\nand Kleshchev-Muth, and sharpen their results to arbitrary characteristic. We\nalso prove that semicuspidal algebras of $A(n\\delta)$ are polynomial\nquasihereditary covers of semicuspidal algebras of the corresponding KLR\nalgebra $R(n\\delta)$, and compute them diagrammatically.","main_category":"math.RT","categories":"math.RT,math.AG,math.QA","published":"2025-04-24T10:44:51Z"}
{"aid":"http://arxiv.org/abs/2504.17474v1","title":"Enhanced Sample Selection with Confidence Tracking: Identifying\n  Correctly Labeled yet Hard-to-Learn Samples in Noisy Data","summary":"We propose a novel sample selection method for image classification in the\npresence of noisy labels. Existing methods typically consider small-loss\nsamples as correctly labeled. However, some correctly labeled samples are\ninherently difficult for the model to learn and can exhibit high loss similar\nto mislabeled samples in the early stages of training. Consequently, setting a\nthreshold on per-sample loss to select correct labels results in a trade-off\nbetween precision and recall in sample selection: a lower threshold may miss\nmany correctly labeled hard-to-learn samples (low recall), while a higher\nthreshold may include many mislabeled samples (low precision). To address this\nissue, our goal is to accurately distinguish correctly labeled yet\nhard-to-learn samples from mislabeled ones, thus alleviating the trade-off\ndilemma. We achieve this by considering the trends in model prediction\nconfidence rather than relying solely on loss values. Empirical observations\nshow that only for correctly labeled samples, the model's prediction confidence\nfor the annotated labels typically increases faster than for any other classes.\nBased on this insight, we propose tracking the confidence gaps between the\nannotated labels and other classes during training and evaluating their trends\nusing the Mann-Kendall Test. A sample is considered potentially correctly\nlabeled if all its confidence gaps tend to increase. Our method functions as a\nplug-and-play component that can be seamlessly integrated into existing sample\nselection techniques. Experiments on several standard benchmarks and real-world\ndatasets demonstrate that our method enhances the performance of existing\nmethods for learning with noisy labels.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-24T12:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.17489v1","title":"Towards Equitable Rail Service Allocation Through Fairness-Oriented\n  Timetabling in Liberalized Markets","summary":"Over the last few decades, European rail transport has undergone major\nchanges as part of the process of liberalization set out in European\nregulations. In this context of liberalization, railway undertakings compete\nwith each other for the limited infrastructure capacity available to offer\ntheir rail services. The infrastructure manager is responsible for the\nequitable allocation of infrastructure between all companies in the market,\nwhich is essential to ensure the efficiency and sustainability of this\ncompetitive ecosystem. In this paper, a methodology based on Jain, Gini and\nAtkinson equity metrics is used to solve the rail service allocation problem in\na liberalized railway market, analyzing the solutions obtained. The results\nshow that the proposed methodology and the equity metrics used allow for\nequitable planning in different competitiveness scenarios. These results\ncontrast with solutions where the objective of the infrastructure manager is to\nmaximize its own profit, without regard for the equitable allocation of\ninfrastructure. Therefore, the computational tests support the methodology and\nmetrics used as a planning and decision support tool in a liberalized railway\nmarket.","main_category":"cs.NE","categories":"cs.NE,cs.CE","published":"2025-04-24T12:30:27Z"}
{"aid":"http://arxiv.org/abs/2504.17493v1","title":"Goal-Oriented Time-Series Forecasting: Foundation Framework Design","summary":"Traditional time-series forecasting often focuses only on minimizing\nprediction errors, ignoring the specific requirements of real-world\napplications that employ them. This paper presents a new training methodology,\nwhich allows a forecasting model to dynamically adjust its focus based on the\nimportance of forecast ranges specified by the end application. Unlike previous\nmethods that fix these ranges beforehand, our training approach breaks down\npredictions over the entire signal range into smaller segments, which are then\ndynamically weighted and combined to produce accurate forecasts. We tested our\nmethod on standard datasets, including a new dataset from wireless\ncommunication, and found that not only it improves prediction accuracy but also\nimproves the performance of end application employing the forecasting model.\nThis research provides a basis for creating forecasting systems that better\nconnect prediction and decision-making in various practical applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T12:34:43Z"}
{"aid":"http://arxiv.org/abs/2504.17505v1","title":"Auerbach bases, projection constants, and the joint spectral radius of\n  principal submatrices","summary":"It is shown that compact sets of complex matrices can always be brought, via\nsimilarity transformation, into a form where all matrix entries are bounded in\nabsolute value by the joint spectral radius (JSR). The key tool for this is\nthat every extremal norm of a matrix set admits an Auerbach basis; any such\nbasis gives rise to a desired coordinate system. An immediate implication is\nthat all diagonal entries - equivalently, all one-dimensional principal\nsubmatrices - are uniformly bounded above by the JSR. It is shown that the\ncorresponding bounding property does not hold for higher dimensional principal\nsubmatrices. More precisely, we construct finite matrix sets for which, across\nthe entire similarity orbit, the JSRs of all higher-dimensional principal\nsubmatrices exceed that of the original set. This shows that the bounding\nresult does not extend to submatrices of dimension greater than one. The\nconstructions rely on tools from the geometry of finite-dimensional Banach\nspaces, with projection constants of norms playing a key role. Additional\nbounds of the JSR of principal submatrices are obtained using John's\nellipsoidal approximation and known estimates for projection constants.","main_category":"math.DS","categories":"math.DS,math.FA","published":"2025-04-24T12:48:53Z"}
{"aid":"http://arxiv.org/abs/2504.17506v1","title":"Population III Supernovae as a dust factory I --- molecule formation and\n  mixing/fallback in ejecta","summary":"Recent observations have revealed the spectral feature of carbonaceous grains\neven in a very distant galaxy. We develop a state-of-the-art dust synthesis\ncode by self-consistently solving molecule and dust formation in supernova (SN)\nejecta that contain various elements in different layers. With a progenitor\nmass 25 Msun and explosion energy 10^{52} erg, we run the following four test\ncalculations to investigate the impact of input physics. (i) With molecule\nformation solved, our SN model produces 8.45x10^{-2} Msun carbonaceous grains.\n(ii) If all available C and Si were initially depleted into CO and SiO\nmolecules, respectively, the C grain mass could be underestimated by ~40%. In\nthese two models producing 0.07 Msun 56Ni without mixing fallback, a large\namount of silicates (0.260 Msun) created in O-rich layers are also ejected and\nlikely to hide the spectral feature of carbonaceous grains. We then consider\nmixing-fallback that can reproduce the observed elemental abundance ratios of\nC-normal and C-enhanced extremely metal-poor stars in the Milky Way. (iii) In\nthe former, the mass ratio of carbonaceous to silicate grains is still small\n(~0.3). However, (iv) in the latter (known as a ``faint SN'), while the C grain\nmass is unchanged (6.78x10^{-2} Msun), the silicate mass is reduced\n(9.98x10^{-3} Msun). Therefore, we conclude that faint SNe can be a significant\ncarbonaceous dust factory in the early Universe.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T12:49:49Z"}
{"aid":"http://arxiv.org/abs/2504.17512v1","title":"Admittance Identification of Grid-Forming Inverters Using Time and\n  Frequency-Domain Techniques","summary":"The increasing integration of inverter-based resources (IBRs) into the power\ngrid introduces new challenges, requiring detailed electromagnetic transient\n(EMT) studies to analyze system interactions. Despite these needs, access to\nthe internal firmware of power electronic devices remains restricted due to\nstringent nondisclosure agreements enforced by manufacturers. To address this,\nwe explore three system identification techniques: sweep frequency response\nanalysis (SFRA), step excitation method (SEM), and eigensystem realization\nalgorithm (ERA). SFRA employs sinusoidal signals of varying frequencies to\nmeasure the system's frequency response, while SEM and ERA utilize step\nfunctions to derive time-domain responses and transform them into\nLaplace-domain transfer functions. All three approaches are shown to provide\nconsistent results in identifying the dq admittance of grid-forming inverters\n(GFM) over a frequency range of 1 Hz to 100 Hz.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-24T12:56:26Z"}
{"aid":"http://arxiv.org/abs/2504.17518v1","title":"On estimates for the discrete eigenvalues of two-dimensional quantum\n  waveguides","summary":"In this paper, we give upper estimates for the number and sum of eigenvalues\nbelow the bottom of the essential spectrum counting multiplicities of quantum\nwaveguides in two dimensions. We consider both straight and curved waveguides\nof constant width, and the estimates are presented in terms of norms of the\npotential. For curved quantum waveguide, we assume that the waveguide is not\nself-intersecting and its curvature is a continuous and bounded function on R.\nThe estimates are new, particularly for the case of curved quantum waveguides\nand this opens a window for their extension to different configurations such as\nwaveguides with local defamations.","main_category":"math.SP","categories":"math.SP","published":"2025-04-24T13:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.17531v1","title":"Towards Machine-Generated Code for the Resolution of User Intentions","summary":"The growing capabilities of Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), prompt a reassessment of the interaction mechanisms\nbetween users and their devices. Currently, users are required to use a set of\nhigh-level applications to achieve their desired results. However, the advent\nof AI may signal a shift in this regard, as its capabilities have generated\nnovel prospects for user-provided intent resolution through the deployment of\nmodel-generated code, which is tantamount to the generation of workflows\ncomprising a multitude of interdependent steps. This development represents a\nsignificant progression in the realm of hybrid workflows, where human and\nartificial intelligence collaborate to address user intentions, with the former\nresponsible for defining these intentions and the latter for implementing the\nsolutions to address them. In this paper, we investigate the feasibility of\ngenerating and executing workflows through code generation that results from\nprompting an LLM with a concrete user intention, such as \\emph{Please send my\ncar title to my insurance company}, and a simplified application programming\ninterface for a GUI-less operating system. We provide in-depth analysis and\ncomparison of various user intentions, the resulting code, and its execution.\nThe findings demonstrate a general feasibility of our approach and that the\nemployed LLM, GPT-4o-mini, exhibits remarkable proficiency in the generation of\ncode-oriented workflows in accordance with provided user intentions.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T13:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.17543v1","title":"Knapsack with compactness: a semidefinite approach","summary":"The min-knapsack problem with compactness constraints extends the classical\nknapsack problem, in the case of ordered items, by introducing a restriction\nensuring that they cannot be too far apart. This problem has applications in\nstatistics, particularly in the detection of change-points in time series. In\nthis paper, we propose a semidefinite programming approach for this problem,\nincorporating compactness in constraints or in objective. We study and compare\nthe different relaxations, and argue that our method provides high-quality\nheuristics and tight bounds. In particular, the single hyperparameter of our\npenalized semidefinite models naturally balances the trade-off between\ncompactness and accuracy of the computed solutions. Numerical experiments\nillustrate, on the hardest instances, the effectiveness and versatility of our\napproach compared to the existing mixed-integer programming formulation.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T13:32:26Z"}
{"aid":"http://arxiv.org/abs/2504.17565v1","title":"DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale\n  Difficulty-Graded Data Training","summary":"Although large language models (LLMs) have recently achieved remarkable\nperformance on various complex reasoning benchmarks, the academic community\nstill lacks an in-depth understanding of base model training processes and data\nquality. To address this, we construct a large-scale, difficulty-graded\nreasoning dataset containing approximately 3.34 million unique queries of\nvarying difficulty levels and about 40 million distilled responses generated by\nmultiple models over several passes. Leveraging pass rate and Coefficient of\nVariation (CV), we precisely select the most valuable training data to enhance\nreasoning capability. Notably, we observe a training pattern shift, indicating\nthat reasoning-focused training based on base models requires higher learning\nrates for effective training. Using this carefully selected data, we\nsignificantly improve the reasoning capabilities of the base model, achieving a\npass rate of 79.2\\% on the AIME2024 mathematical reasoning benchmark. This\nresult surpasses most current distilled models and closely approaches\nstate-of-the-art performance. We provide detailed descriptions of our data\nprocessing, difficulty assessment, and training methodology, and have publicly\nreleased all datasets and methods to promote rapid progress in open-source\nlong-reasoning LLMs. The dataset is available at:\nhttps://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T13:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.17586v1","title":"A Machine Learning Approach for Denoising and Upsampling HRTFs","summary":"The demand for realistic virtual immersive audio continues to grow, with\nHead-Related Transfer Functions (HRTFs) playing a key role. HRTFs capture how\nsound reaches our ears, reflecting unique anatomical features and enhancing\nspatial perception. It has been shown that personalized HRTFs improve\nlocalization accuracy, but their measurement remains time-consuming and\nrequires a noise-free environment. Although machine learning has been shown to\nreduce the required measurement points and, thus, the measurement time, a\ncontrolled environment is still necessary. This paper proposes a method to\naddress this constraint by presenting a novel technique that can upsample\nsparse, noisy HRTF measurements. The proposed approach combines an HRTF Denoisy\nU-Net for denoising and an Autoencoding Generative Adversarial Network (AE-GAN)\nfor upsampling from three measurement points. The proposed method achieves a\nlog-spectral distortion (LSD) error of 5.41 dB and a cosine similarity loss of\n0.0070, demonstrating the method's effectiveness in HRTF upsampling.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-24T14:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.17609v1","title":"STCL:Curriculum learning Strategies for deep learning image\n  steganography models","summary":"Aiming at the problems of poor quality of steganographic images and slow\nnetwork convergence of image steganography models based on deep learning, this\npaper proposes a Steganography Curriculum Learning training strategy (STCL) for\ndeep learning image steganography models. So that only easy images are selected\nfor training when the model has poor fitting ability at the initial stage, and\ngradually expand to more difficult images, the strategy includes a difficulty\nevaluation strategy based on the teacher model and an knee point-based training\nscheduling strategy. Firstly, multiple teacher models are trained, and the\nconsistency of the quality of steganographic images under multiple teacher\nmodels is used as the difficulty score to construct the training subsets from\neasy to difficult. Secondly, a training control strategy based on knee points\nis proposed to reduce the possibility of overfitting on small training sets and\naccelerate the training process. Experimental results on three large public\ndatasets, ALASKA2, VOC2012 and ImageNet, show that the proposed image\nsteganography scheme is able to improve the model performance under multiple\nalgorithmic frameworks, which not only has a high PSNR, SSIM score, and\ndecoding accuracy, but also the steganographic images generated by the model\nunder the training of the STCL strategy have a low steganography analysis\nscores. You can find our code at\n\\href{https://github.com/chaos-boops/STCL}{https://github.com/chaos-boops/STCL}.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-24T14:34:41Z"}
{"aid":"http://arxiv.org/abs/2504.17638v1","title":"Testing Quintessence Axion Dark Energy with Recent Cosmological Results","summary":"We investigate a quintessence axion model for dynamical dark energy,\nmotivated in part by recent results from the Baryon Acoustic Oscillation (BAO)\nmeasurements of the Dark Energy Spectroscopic Instrument (DESI) and the Cosmic\nMicrowave Background (CMB) observations from the Atacama Cosmology Telescope\n(ACT). By carefully treating the initial conditions and parameter sampling, we\nidentify a preferred parameter space featuring a sub-Planckian axion decay\nconstant and a relatively large axion mass, which naturally avoids the quality\nproblem and remains consistent with the perturbative string conjecture. Our\nparameter scan also uncovers a trans-Planckian regime of theoretical interest,\nwhich is only mildly disfavored by observations. The results remain robust when\nDESI BAO data are combined with CMB and supernova observations. Finally, we\ndiscuss the possible connection between this model and the recently reported\nnon-zero rotation of the CMB linear polarization angle, emphasizing the broader\ncosmological implications and the promising prospects for testing this\nscenario. We show that an $\\mathcal{O}(1)$ electromagnetic anomaly coefficient\nis preferred by the strongest constraint, which is in full agreement with the\nminimal quintessence axion model.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-24T15:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.17643v1","title":"CLIPSE -- a minimalistic CLIP-based image search engine for research","summary":"A brief overview of CLIPSE, a self-hosted image search engine with the main\napplication of research, is provided. In general, CLIPSE uses CLIP embeddings\nto process the images and also the text queries. The overall framework is\ndesigned with simplicity to enable easy extension and usage. Two benchmark\nscenarios are described and evaluated, covering indexing and querying time. It\nis shown that CLIPSE is capable of handling smaller datasets; for larger\ndatasets, a distributed approach with several instances should be considered.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T15:13:37Z"}
{"aid":"http://arxiv.org/abs/2504.17665v1","title":"Evaluating Grounded Reasoning by Code-Assisted Large Language Models for\n  Mathematics","summary":"Assisting LLMs with code generation improved their performance on\nmathematical reasoning tasks. However, the evaluation of code-assisted LLMs is\ngenerally restricted to execution correctness, lacking a rigorous evaluation of\ntheir generated programs. In this work, we bridge this gap by conducting an\nin-depth analysis of code-assisted LLMs' generated programs in response to math\nreasoning tasks. Our evaluation focuses on the extent to which LLMs ground\ntheir programs to math rules, and how that affects their end performance. For\nthis purpose, we assess the generations of five different LLMs, on two\ndifferent math datasets, both manually and automatically. Our results reveal\nthat the distribution of grounding depends on LLMs' capabilities and the\ndifficulty of math problems. Furthermore, mathematical grounding is more\neffective for closed-source models, while open-source models fail to employ\nmath rules in their solutions correctly. On MATH500, the percentage of grounded\nprograms decreased to half, while the ungrounded generations doubled in\ncomparison to ASDiv grade-school problems. Our work highlights the need for\nin-depth evaluation beyond execution accuracy metrics, toward a better\nunderstanding of code-assisted LLMs' capabilities and limits in the math\ndomain.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T15:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.17674v1","title":"Energy Considerations of Large Language Model Inference and Efficiency\n  Optimizations","summary":"As large language models (LLMs) scale in size and adoption, their\ncomputational and environmental costs continue to rise. Prior benchmarking\nefforts have primarily focused on latency reduction in idealized settings,\noften overlooking the diverse real-world inference workloads that shape energy\nuse. In this work, we systematically analyze the energy implications of common\ninference efficiency optimizations across diverse Natural Language Processing\n(NLP) and generative Artificial Intelligence (AI) workloads, including\nconversational AI and code generation. We introduce a modeling approach that\napproximates real-world LLM workflows through a binning strategy for\ninput-output token distributions and batch size variations. Our empirical\nanalysis spans software frameworks, decoding strategies, GPU architectures,\nonline and offline serving settings, and model parallelism configurations. We\nshow that the effectiveness of inference optimizations is highly sensitive to\nworkload geometry, software stack, and hardware accelerators, demonstrating\nthat naive energy estimates based on FLOPs or theoretical GPU utilization\nsignificantly underestimate real-world energy consumption. Our findings reveal\nthat the proper application of relevant inference efficiency optimizations can\nreduce total energy use by up to 73% from unoptimized baselines. These insights\nprovide a foundation for sustainable LLM deployment and inform energy-efficient\ndesign strategies for future AI infrastructure.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-24T15:45:05Z"}
{"aid":"http://arxiv.org/abs/2504.17679v1","title":"Extremal negative dependence and the strongly Rayleigh property","summary":"We provide a geometrical characterization of extremal negative dependence as\na convex polytope in the simplex of multidimensional Bernoulli distributions,\nand we prove that it is an antichain that satisfies some minimality conditions\nwith respect to the strongest negative dependence orders. We study the strongly\nRayleigh property within this class and explicitly find a distribution that\nsatisfies this property by maximizing the entropy. Furthermore, we construct a\nchain for the supermodular order starting from extremal negative dependence to\nindependence by mixing the maximum entropy strongly Rayleigh distribution with\nindependence.","main_category":"math.PR","categories":"math.PR","published":"2025-04-24T15:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.17680v1","title":"Time-reversed Stochastic Inflation","summary":"Cosmic inflation may exhibit stochastic periods during which quantum\nfluctuations dominate over the semi-classical evolution. Extracting observables\nin these regimes is a notoriously difficult program as quantum randomness makes\nthem fully probabilistic. However, among all the possible quantum histories,\nthe ones which are relevant for Cosmology are conditioned by the requirement\nthat stochastic inflation ended. From an observational point of view, it would\nbe more convenient to model stochastic periods as starting from the time at\nwhich they ended and evolving backwards in times. We present a time-reversed\napproach to stochastic inflation, based on a reverse Fokker-Planck equation,\nwhich allows us to derive non-perturbatively the probability distribution of\nthe field values at a given time before the end of the quantum regime. As a\nmotivated example, we solve the flat semi-infinite potential and derive a new\nand exact formula for the probability distribution of the quantum-generated\ncurvature fluctuations. It is normalisable while exhibiting tails slowly\ndecaying as a Levy distribution. Our reverse-time stochastic formalism could be\napplied to any inflationary potentials and quantum diffusion eras, including\nthe ones that can lead to the formation of primordial black holes.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-24T15:53:17Z"}
{"aid":"http://arxiv.org/abs/2504.17681v1","title":"Long-range four-body interactions in the Hamiltonian mean field model","summary":"In this paper, a Hamiltonian mean field model with long-range four-body\ninteractions is proposed. The model describes a long-range mean-field system in\nwhich N unit-mass particles move on a unit circle. Each particle theta_i\ninteracts with any three other particles through an infinite-range cosine\npotential with an attractive interaction (epsilon > 0). By applying a method\nthat remaps the average phase of global particle pairs onto a new unit circle,\nand using the saddle-point technique, the partition function is solved\nanalytically after introducing four-body interactions, yielding expressions for\nthe free energy f and the energy per particle U. These results were further\nvalidated through numerical simulations. The results show that the system\nundergoes a second-order phase transition at the critical energy U_c.\nSpecifically, the critical energy corresponds to U_c = 0.32 when the coupling\nconstant epsilon = 5, and U_c = 0.63 when epsilon = 10. Finally, we calculated\nthe system's largest Lyapunov exponent lambda and kinetic energy fluctuations\nSigma through numerical simulations. It is found that the peak of the largest\nLyapunov exponent lambda occurs slightly below the critical energy U_c, which\nis consistent with the point of maximum kinetic energy fluctuations Sigma. And\nthere is a scaling law of Sigma / N^(1/2) proportional to lambda between them.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-24T15:53:33Z"}
{"aid":"http://arxiv.org/abs/2504.17685v1","title":"Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve\n  LLM-level Accuracy in Profile Matching Tasks","summary":"This study explores the potential of small language model(SLM) ensembles to\nachieve accuracy comparable to proprietary large language models (LLMs). We\npropose Ensemble Bayesian Inference (EBI), a novel approach that applies\nBayesian estimation to combine judgments from multiple SLMs, allowing them to\nexceed the performance limitations of individual models. Our experiments on\ndiverse tasks(aptitude assessments and consumer profile analysis in both\nJapanese and English) demonstrate EBI's effectiveness. Notably, we analyze\ncases where incorporating models with negative Lift values into ensembles\nimproves overall performance, and we examine the method's efficacy across\ndifferent languages. These findings suggest new possibilities for constructing\nhigh-performance AI systems with limited computational resources and for\neffectively utilizing models with individually lower performance. Building on\nexisting research on LLM performance evaluation, ensemble methods, and\nopen-source LLM utilization, we discuss the novelty and significance of our\napproach.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T15:55:10Z"}
{"aid":"http://arxiv.org/abs/2504.17689v1","title":"On Hopf hypersurfaces of the complex quadric with constant principal\n  curvatures","summary":"In this paper, we classify the Hopf hypersurfaces of the complex quadric\n$Q^m=SO_{m+2}/(SO_2SO_m)$ ($m\\geq3$) with at most five distinct constant\nprincipal curvatures. We also classify the Hopf hypersurfaces of $Q^m$\n($m=3,4,5$) with constant principal curvatures. All these real hypersurfaces\nare open parts of homogeneous examples.","main_category":"math.DG","categories":"math.DG","published":"2025-04-24T15:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.17700v1","title":"Applied Sheaf Theory For Multi-agent Artificial Intelligence\n  (Reinforcement Learning) Systems: A Prospectus","summary":"This paper provides a pedagogical introduction to classical sheaf theory and\nsheaf cohomology, followed by a research prospectus exploring potential\napplications to multi-agent artificial intelligence systems. The first section\noffers a comprehensive overview of fundamental sheaf-theoretic\nconcepts-presheaves, sheaves, stalks, and cohomology-aimed at researchers in\ncomputer science and AI who may not have extensive background in algebraic\ntopology. The second section presents a detailed research prospectus that\noutlines a roadmap for developing sheaf-theoretic approaches to model and\nanalyze complex systems of interacting agents. We propose that sheaf theory's\ninherent local-to-global perspective may provide valuable mathematical tools\nfor reasoning about how local agent behaviors collectively determine emergent\nsystem properties. The third section contains a literature review connecting\nsheaf theory with existing research in multi-agent systems, reinforcement\nlearning, and economic modeling. This paper does not present a completed model\nbut rather lays theoretical groundwork and identifies promising research\ndirections that could bridge abstract mathematics with practical AI\napplications, potentially revealing new approaches to coordination and\nemergence in multi-agent systems.","main_category":"math.OC","categories":"math.OC,math.AT","published":"2025-04-24T16:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.17728v1","title":"CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from\n  Casually Captured Videos","summary":"Recently, photo-realistic novel view synthesis from multi-view images, such\nas neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered\nwidespread attention due to their superior performance. However, most works\nrely on low dynamic range (LDR) images, which limits the capturing of richer\nscene details. Some prior works have focused on high dynamic range (HDR) scene\nreconstruction, typically require capturing of multi-view sharp images with\ndifferent exposure times at fixed camera positions during exposure times, which\nis time-consuming and challenging in practice. For a more flexible data\nacquisition, we propose a one-stage method: \\textbf{CasualHDRSplat} to easily\nand robustly reconstruct the 3D HDR scene from casually captured videos with\nauto-exposure enabled, even in the presence of severe motion blur and varying\nunknown exposure time. \\textbf{CasualHDRSplat} contains a unified\ndifferentiable physical imaging model which first applies continuous-time\ntrajectory constraint to imaging process so that we can jointly optimize\nexposure time, camera response function (CRF), camera poses, and sharp 3D HDR\nscene. Extensive experiments demonstrate that our approach outperforms existing\nmethods in terms of robustness and rendering quality. Our source code will be\navailable at https://github.com/WU-CVGL/CasualHDRSplat","main_category":"cs.GR","categories":"cs.GR,cs.CV,cs.MM","published":"2025-04-24T16:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.17730v1","title":"Bandstructure of a coupled BEC-cavity system: effects of dissipation and\n  geometry","summary":"We present a theoretical model for a transversally driven Bose-Einstein\ncondensate coupled to an optical cavity. We focus on the interplay between\ndifferent coherent couplings, which can trigger a structural phase transition,\nknown as the superradiant phase transition. Our approach, based on band\nstructure theory and a mean-field description, enables a comprehensive analysis\nof the nature of the system's excited modes, precursing the phase transitions.\nBy incorporating dissipative couplings, intrinsic to these systems, we find\nnon-Hermitian phenomena such as the coalescence of crossing precursor modes and\nthe emergence of exceptional points (EPs). The general formulation of our model\nallows us to explain the role of an angle between transverse pump and the\ncavity deviating from $90^\\circ$. This offers us a unified perspective on the\nplethora of different implementations of such systems.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,quant-ph","published":"2025-04-24T16:43:45Z"}
{"aid":"http://arxiv.org/abs/2504.17733v1","title":"Fuzzy clustering and community detection: an integrated approach","summary":"This paper addresses the ambitious goal of merging two different approaches\nto group detection in complex domains: one based on fuzzy clustering and the\nother on community detection theory. To achieve this, two clustering algorithms\nare proposed: Fuzzy C-Medoids Clustering with Modularity Spatial Correction and\nFuzzy C-Modes Clustering with Modularity Spatial Correction. The former is\ndesigned for quantitative data, while the latter is intended for qualitative\ndata. The concept of fuzzy modularity is introduced into the standard objective\nfunction of fuzzy clustering algorithms as a spatial regularization term, whose\ncontribution to the clustering criterion based on attributes is controlled by\nan exogenous parameter. An extensive simulation study is conducted to support\nthe theoretical framework, complemented by two applications to real-world data\nrelated to the theme of sustainability. The first application involves data\nfrom the 2030 Agenda for Sustainable Development, while the second focuses on\nurban green spaces in Italian provincial capitals and metropolitan cities. Both\nthe simulation results and the applications demonstrate the advantages of this\nnew methodological proposal.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-24T16:47:17Z"}
{"aid":"http://arxiv.org/abs/2504.17751v1","title":"Revisiting Reset Mechanisms in Spiking Neural Networks for Sequential\n  Modeling: Specialized Discretization for Binary Activated RNN","summary":"In the field of image recognition, spiking neural networks (SNNs) have\nachieved performance comparable to conventional artificial neural networks\n(ANNs). In such applications, SNNs essentially function as traditional neural\nnetworks with quantized activation values. This article focuses on an another\nalternative perspective,viewing SNNs as binary-activated recurrent neural\nnetworks (RNNs) for sequential modeling tasks.From this viewpoint, current SNN\narchitectures face several fundamental challenges in sequence modeling: (1)\nTraditional models lack effective memory mechanisms for long-range sequence\nmodeling; (2) The biological-inspired components in SNNs (such as reset\nmechanisms and refractory period applications) remain theoretically\nunder-explored for sequence tasks; (3) The RNN-like computational paradigm in\nSNNs prevents parallel training across different timesteps.To address these\nchallenges, this study conducts a systematic analysis of the fundamental\nmechanisms underlying reset operations and refractory periods in\nbinary-activated RNN-based SNN sequence models. We re-examine whether such\nbiological mechanisms are strictly necessary for generating sparse spiking\npatterns, provide new theoretical explanations and insights, and ultimately\npropose the fixed-refractory-period SNN architecture for sequence modeling.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-24T17:09:59Z"}
{"aid":"http://arxiv.org/abs/2504.17762v1","title":"Introducing STARDIS: An Open and Modular Stellar Spectral Synthesis Code","summary":"We introduce a new 1D stellar spectral synthesis Python code called \\stardis.\n\\stardis\\ is a modular, open-source radiative transfer code that is capable of\nspectral synthesis from near-UV to IR for FGK stars. We describe the structure,\ninputs, features, underlying physics, and assumptions of \\stardis\\ as well as\nthe radiative transfer scheme implemented. To validate our code, we show\nspectral comparisons between \\stardis\\ and \\textsc{korg} with the same input\natmospheric structure models, and also compare qualitatively to\n\\textsc{phoenix} for solar models. We find that \\stardis\\ generally agrees well\nwith \\textsc{korg} for solar models on the few percent level or better, that\nthe codes can diverge in the ultraviolet, with more extreme differences in\ncooler stars. \\stardis\\ can be found at\n\\href{https://github.com/tardis-sn/stardis}{https://github.com/tardis-sn/stardis},\nand documentation can be found at\n\\href{https://tardis-sn.github.io/stardis/}{https://tardis-sn.github.io/stardis/}.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM","published":"2025-04-24T17:26:23Z"}
{"aid":"http://arxiv.org/abs/2504.17765v1","title":"Extended Scalar Particle Solutions in Black String Spacetimes with\n  Anisotropic Quintessence","summary":"We present new solutions to the Klein-Gordon equation for a scalar particle\nin a black string spacetime immersed in an anisotropic quintessence fluid\nsurrounded by a cloud of strings, extending the analysis presented in our\nprevious work. These novel solutions are dependent on the quintessence state\nparameter, $\\alpha_{Q}$, and are now valid for a much larger domain of the\nradial coordinate. We investigate the cases when $\\alpha_{Q} = 0,\\,1/2,\\,1$,\nencompassing both black hole and horizonless scenarios. We express the\nresulting radial wave functions using the confluent and biconfluent Heun\nfunctions, with special cases represented by Bessel functions. We derive\nrestrictions on the allowed quantum energy levels by imposing constraints on\nthe Heun parameters to ensure polynomial solutions. Furthermore, we investigate\nthe emergence of \"dark phases\" associated with the radial wave function,\nfocusing on the interesting case of $\\alpha_{Q} = 1$. Our findings provide\ninsights into the dynamics of scalar particles in this complex spacetime and\nthe potential impact of dark energy on quantum systems.","main_category":"gr-qc","categories":"gr-qc,hep-th,math-ph,math.MP","published":"2025-04-24T17:34:07Z"}
{"aid":"http://arxiv.org/abs/2504.17770v1","title":"Zeptosecond free-electron compression through temporal lensing","summary":"The pursuit of ever-shorter time scales is a frontier in modern physics,\nexemplified by the synthesis of attosecond light pulses -- an achievement made\npossible by coherently superimposing a broad range of photon energies, as\nrequired by the uncertainty principle. However, extending this progress into\nthe zeptosecond regime poses significant challenges, as it demands\nphase-correlated optical spectra spanning hundreds of electronvolts. In this\ncontext, electrons offer a compelling alternative to light because they can be\ncoherently manipulated to form broad energy superpositions, as demonstrated by\nthe generation of attosecond pulses in ultrafast electron microscopes. Here, we\npropose a practical scheme for compressing free electrons into the zeptosecond\ndomain by modulating their wave functions using suitably tailored broadband\nlight fields. Building on recent advances in {free-electron--light--matter}\ninteractions, our method introduces the concept of temporal lensing -- an\nextension of conventional optical lensing to the time domain -- to produce\nelectron pulses with arbitrarily short durations.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-24T17:41:22Z"}
{"aid":"http://arxiv.org/abs/2504.17773v1","title":"Three-local Charge Conservation Implies Quantum Integrability","summary":"It is shown that the existence of a local conserved charge supported by three\nneighboring sites, or its local version, Reshetikhin's condition, suffices to\nguarantee the existence of all higher conserved charges and hence the\nintegrability of a quantum spin chain. This explains the ``coincidence'' that\nno counterexample is known to Grabowski and Mathieu's long-standing conjecture\ndespite the folklore that the conservation of local charges of order higher\nthan 4 imposes additional constraints not implied by the conservation of the\nthree-local charge.","main_category":"math-ph","categories":"math-ph,cond-mat.stat-mech,hep-th,math.MP,nlin.SI,quant-ph","published":"2025-04-24T17:48:03Z"}
{"aid":"http://arxiv.org/abs/2504.17788v1","title":"Dynamic Camera Poses and Where to Find Them","summary":"Annotating camera poses on dynamic Internet videos at scale is critical for\nadvancing fields like realistic video generation and simulation. However,\ncollecting such a dataset is difficult, as most Internet videos are unsuitable\nfor pose estimation. Furthermore, annotating dynamic Internet videos present\nsignificant challenges even for state-of-theart methods. In this paper, we\nintroduce DynPose-100K, a large-scale dataset of dynamic Internet videos\nannotated with camera poses. Our collection pipeline addresses filtering using\na carefully combined set of task-specific and generalist models. For pose\nestimation, we combine the latest techniques of point tracking, dynamic\nmasking, and structure-from-motion to achieve improvements over the\nstate-of-the-art approaches. Our analysis and experiments demonstrate that\nDynPose-100K is both large-scale and diverse across several key attributes,\nopening up avenues for advancements in various downstream applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.17789v1","title":"Token-Shuffle: Towards High-Resolution Image Generation with\n  Autoregressive Models","summary":"Autoregressive (AR) models, long dominant in language generation, are\nincreasingly applied to image synthesis but are often considered less\ncompetitive than Diffusion-based models. A primary limitation is the\nsubstantial number of image tokens required for AR models, which constrains\nboth training and inference efficiency, as well as image resolution. To address\nthis, we present Token-Shuffle, a novel yet simple method that reduces the\nnumber of image tokens in Transformer. Our key insight is the dimensional\nredundancy of visual vocabularies in Multimodal Large Language Models (MLLMs),\nwhere low-dimensional visual codes from visual encoder are directly mapped to\nhigh-dimensional language vocabularies. Leveraging this, we consider two key\noperations: token-shuffle, which merges spatially local tokens along channel\ndimension to decrease the input token number, and token-unshuffle, which\nuntangles the inferred tokens after Transformer blocks to restore the spatial\narrangement for output. Jointly training with textual prompts, our strategy\nrequires no additional pretrained text-encoder and enables MLLMs to support\nextremely high-resolution image synthesis in a unified next-token prediction\nway while maintaining efficient training and inference. For the first time, we\npush the boundary of AR text-to-image generation to a resolution of 2048x2048\nwith gratifying generation performance. In GenAI-benchmark, our 2.7B model\nachieves 0.77 overall score on hard prompts, outperforming AR models LlamaGen\nby 0.18 and diffusion models LDM by 0.15. Exhaustive large-scale human\nevaluations also demonstrate our prominent image generation ability in terms of\ntext-alignment, visual flaw, and visual appearance. We hope that Token-Shuffle\ncan serve as a foundational design for efficient high-resolution image\ngeneration within MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T17:59:56Z"}
