{"aid":"http://arxiv.org/abs/2503.21695v1","title":"AMA-SAM: Adversarial Multi-Domain Alignment of Segment Anything Model\n  for High-Fidelity Histology Nuclei Segmentation","summary":"Accurate segmentation of cell nuclei in histopathology images is essential\nfor numerous biomedical research and clinical applications. However, existing\ncell nucleus segmentation methods only consider a single dataset (i.e., primary\ndomain), while neglecting to leverage supplementary data from diverse sources\n(i.e., auxiliary domains) to reduce overfitting and enhance the performance.\nAlthough incorporating multiple datasets could alleviate overfitting, it often\nexacerbates performance drops caused by domain shifts. In this work, we\nintroduce Adversarial Multi-domain Alignment of Segment Anything Model\n(AMA-SAM) that extends the Segment Anything Model (SAM) to overcome these\nobstacles through two key innovations. First, we propose a Conditional Gradient\nReversal Layer (CGRL), a multi-domain alignment module that harmonizes features\nfrom diverse domains to promote domain-invariant representation learning while\npreserving crucial discriminative features for the primary dataset. Second, we\naddress SAM's inherent low-resolution output by designing a High-Resolution\nDecoder (HR-Decoder), which directly produces fine-grained segmentation maps in\norder to capture intricate nuclei boundaries in high-resolution histology\nimages. To the best of our knowledge, this is the first attempt to adapt SAM\nfor multi-dataset learning with application to histology nuclei segmentation.\nWe validate our method on several publicly available datasets, demonstrating\nconsistent and significant improvements over state-of-the-art approaches.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-27T16:59:39Z"}
{"aid":"http://arxiv.org/abs/2503.21697v1","title":"The commutativity problem for effective varieties of formal series, and\n  applications","summary":"A formal series in noncommuting variables $\\Sigma$ over the rationals is a\nmapping $\\Sigma^* \\to \\mathbb Q$. We say that a series is commutative if the\nvalue in the output does not depend on the order of the symbols in the input.\nThe commutativity problem for a class of series takes as input a (finite\npresentation of) a series from the class and amounts to establishing whether it\nis commutative. This is a very natural, albeit nontrivial problem, which has\nnot been considered before from an algorithmic perspective.\n  We show that commutativity is decidable for all classes of series that\nconstitute a so-called effective prevariety, a notion generalising Reutenauer's\nvarieties of formal series. For example, the class of rational series,\nintroduced by Sch\\\"utzenberger in the 1960's, is well-known to be an effective\n(pre)variety, and thus commutativity is decidable for it.\n  In order to showcase the applicability of our result, we consider classes of\nformal series generalising the rational ones. We consider polynomial automata,\nshuffle automata, and infiltration automata, and we show that each of these\nmodels recognises an effective prevariety of formal series. Consequently, their\ncommutativity problem is decidable, which is a novel result. We find it\nremarkable that commutativity can be decided in a uniform way for such\ndisparate computation models.\n  Finally, we present applications of commutativity outside the theory of\nformal series. We show that we can decide solvability in sequences and in power\nseries for restricted classes of algebraic difference and differential\nequations, for which such problems are undecidable in full generality. Thanks\nto this, we can prove that the syntaxes of multivariate polynomial recursive\nsequences and of constructible differentially algebraic power series are\neffective, which are new results which were left open in previous work.","main_category":"cs.FL","categories":"cs.FL,cs.DM,cs.LO","published":"2025-03-27T17:01:19Z"}
{"aid":"http://arxiv.org/abs/2503.21724v1","title":"Ram-pressure stripping caught in action in a forming galaxy cluster 3\n  billion years after the Big Bang","summary":"Galaxy clusters in the local Universe are dominated by massive quiescent\ngalaxies with old ages, formed at high redshifts. It is debated whether their\nquenching is driven by internal processes or environmental effects, which has\nbeen challenging due to the lack of observations during their peak formation\nepoch. Here we report clear evidence from ALMA of extended and elongated gas\ntails in nine galaxies in a forming cluster at z = 2.51. The distinct gas\ndistribution compared to the stellar emission probed by JWST, which is rather\nisolated without signatures of mergers or interactions, provides evidence of\nram-pressure stripping (RPS). This represents the most distant confirmed case\nof RPS, highlighting the critical role of environmental effects in gas removal\nat high redshifts, an often overlooked quenching pathway.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-27T17:36:57Z"}
{"aid":"http://arxiv.org/abs/2503.21725v1","title":"Low-noise environment for probing fundamental symmetries","summary":"We present the design and characterization of a low-noise environment for\nmeasuring the electron's electric dipole moment (EDM) with a beam of molecules.\nTo minimize magnetic Johnson noise from metals, the design features ceramic\nelectric field plates housed in a glass vacuum chamber. To suppress external\nmagnetic noise the apparatus is enclosed within a cylindrical four-layer\nmu-metal shield with a shielding factor exceeding $10^6$ in one radial\ndirection and $10^5$ in the other. Finite element modelling shows that the\ndifference between these shielding factors is due to imperfect joints between\nsections of mu-metal. Using atomic magnetometers to monitor the magnetic field\ninside the shield, we measure noise below 40 fT/$\\sqrt{{\\rm Hz}}$ at 1 Hz and\nabove, rising to 500 fT/$\\sqrt{{\\rm Hz}}$ at 0.1 Hz. Analytical and numerical\nstudies show that residual magnetic Johnson noise contributes approximately 13\nfT/$\\sqrt{{\\rm Hz}}$. The background magnetic field averaged along the beamline\nis maintained below 3 pT, with typical gradients of a few nT/m. An electric\nfield of 20 kV/cm is applied without discharges and with leakage currents below\n1 nA. Each magnetometer measures the magnetic field correlated with the\ndirection of the applied electric field with a precision of 0.11 fT in 104\nhours of data. These results demonstrate that the apparatus is suitable for\nmeasuring the electron EDM with precision at the $10^{-31}$ e cm level. The\ndesign principles and characterization techniques presented here are broadly\napplicable to precision measurements probing fundamental symmetries in\nmolecules, atoms, and neutrons.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-03-27T17:37:12Z"}
{"aid":"http://arxiv.org/abs/2503.21728v1","title":"Near field imaging of local interference in radio interferometric data:\n  Impact on the redshifted 21-cm power spectrum","summary":"Radio-frequency interference (RFI) is a major systematic limitation in radio\nastronomy, particularly for science cases requiring high sensitivity, such as\n21-cm cosmology. Traditionally, RFI is dealt with by identifying its signature\nin the dynamic spectra of visibility data and flagging strongly affected\nregions. However, for RFI sources that do not occupy narrow regions in the\ntime-frequency space, such as persistent local RFI, modeling these sources\ncould be essential to mitigating their impact. This paper introduces two\nmethods for detecting and characterizing local RFI sources from radio\ninterferometric visibilities: matched filtering and maximum a posteriori (MAP)\nimaging. These algorithms use the spherical wave equation to construct\nthree-dimensional near-field image cubes of RFI intensity from the\nvisibilities. The matched filter algorithm can generate normalized maps by\ncross-correlating the expected contributions from RFI sources with the observed\nvisibilities, while the MAP method performs a regularized inversion of the\nvisibility equation in the near field. We also develop a full polarization\nsimulation framework for RFI and demonstrate the methods on simulated\nobservations of local RFI sources. The stability, speed, and errors introduced\nby these algorithms are investigated, and, as a demonstration, the algorithms\nare applied to a subset of NenuFAR observations to perform spatial, spectral,\nand temporal characterization of two local RFI sources. We assess the impact of\nlocal RFI on images, the uv plane, and cylindrical power spectra through\nsimulations and describe these effects qualitatively. We also quantify the\nlevel of errors and biases that these algorithms induce and assess their\nimplications for the estimated 21-cm power spectrum with radio interferometers.\nThe near-field imaging and simulation codes are made available publicly in the\nPython library nfis.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO","published":"2025-03-27T17:40:38Z"}
{"aid":"http://arxiv.org/abs/2503.21735v1","title":"GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release\n  Analytics","summary":"Ensuring the reliability and effectiveness of software release decisions is\ncritical, particularly in safety-critical domains like automotive systems.\nPrecise analysis of release validation data, often presented in tabular form,\nplays a pivotal role in this process. However, traditional methods that rely on\nmanual analysis of extensive test datasets and validation metrics are prone to\ndelays and high costs. Large Language Models (LLMs) offer a promising\nalternative but face challenges in analytical reasoning, contextual\nunderstanding, handling out-of-scope queries, and processing structured test\ndata consistently; limitations that hinder their direct application in\nsafety-critical scenarios. This paper introduces GateLens, an LLM-based tool\nfor analyzing tabular data in the automotive domain. GateLens translates\nnatural language queries into Relational Algebra (RA) expressions and then\ngenerates optimized Python code. It outperforms the baseline system on\nbenchmarking datasets, achieving higher F1 scores and handling complex and\nambiguous queries with greater robustness. Ablation studies confirm the\ncritical role of the RA module, with performance dropping sharply when omitted.\nIndustrial evaluations reveal that GateLens reduces analysis time by over 80%\nwhile maintaining high accuracy and reliability. As demonstrated by presented\nresults, GateLens achieved high performance without relying on few-shot\nexamples, showcasing strong generalization across various query types from\ndiverse company roles. Insights from deploying GateLens with a partner\nautomotive company offer practical guidance for integrating AI into critical\nworkflows such as release validation. Results show that by automating test\nresult analysis, GateLens enables faster, more informed, and dependable release\ndecisions, and can thus advance software scalability and reliability in\nautomotive systems.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL,cs.MA","published":"2025-03-27T17:48:32Z"}
{"aid":"http://arxiv.org/abs/2503.21747v1","title":"CTRL-O: Language-Controllable Object-Centric Visual Representation\n  Learning","summary":"Object-centric representation learning aims to decompose visual scenes into\nfixed-size vectors called \"slots\" or \"object files\", where each slot captures a\ndistinct object. Current state-of-the-art object-centric models have shown\nremarkable success in object discovery in diverse domains, including complex\nreal-world scenes. However, these models suffer from a key limitation: they\nlack controllability. Specifically, current object-centric models learn\nrepresentations based on their preconceived understanding of objects, without\nallowing user input to guide which objects are represented. Introducing\ncontrollability into object-centric models could unlock a range of useful\ncapabilities, such as the ability to extract instance-specific representations\nfrom a scene. In this work, we propose a novel approach for user-directed\ncontrol over slot representations by conditioning slots on language\ndescriptions. The proposed ConTRoLlable Object-centric representation learning\napproach, which we term CTRL-O, achieves targeted object-language binding in\ncomplex real-world scenes without requiring mask supervision. Next, we apply\nthese controllable slot representations on two downstream vision language\ntasks: text-to-image generation and visual question answering. The proposed\napproach enables instance-specific text-to-image generation and also achieves\nstrong performance on visual question answering.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-03-27T17:53:50Z"}
{"aid":"http://arxiv.org/abs/2503.21751v1","title":"Reconstructing Humans with a Biomechanically Accurate Skeleton","summary":"In this paper, we introduce a method for reconstructing 3D humans from a\nsingle image using a biomechanically accurate skeleton model. To achieve this,\nwe train a transformer that takes an image as input and estimates the\nparameters of the model. Due to the lack of training data for this task, we\nbuild a pipeline to produce pseudo ground truth model parameters for single\nimages and implement a training procedure that iteratively refines these pseudo\nlabels. Compared to state-of-the-art methods for 3D human mesh recovery, our\nmodel achieves competitive performance on standard benchmarks, while it\nsignificantly outperforms them in settings with extreme 3D poses and\nviewpoints. Additionally, we show that previous reconstruction methods\nfrequently violate joint angle limits, leading to unnatural rotations. In\ncontrast, our approach leverages the biomechanically plausible degrees of\nfreedom making more realistic joint rotation estimates. We validate our\napproach across multiple human pose estimation benchmarks. We make the code,\nmodels and data available at: https://isshikihugh.github.io/HSMR/","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:56:24Z"}
{"aid":"http://arxiv.org/abs/2503.21768v1","title":"Results on branching random walks and rumor processes via germ order","summary":"Germ order is a non-standard stochastic order defined through the comparison\nof the generating functions of the processes. This order was first introduced\nfor branching random walks with a constant breeding law and independent\ndispersal of offspring, which are characterized by a one-dimensional generating\nfunction. In this work, we investigate the properties of the extension of this\nconcept to processes characterized by a multidimensional generating function,\nsuch as general branching random walks and rumor processes. In particular, we\nuse germ ordering to characterize the behavior of certain branching random\nwalks and rumor processes with inhomogeneous breeding/transmitting laws.","main_category":"math.PR","categories":"math.PR","published":"2025-03-27T17:59:06Z"}
{"aid":"http://arxiv.org/abs/2503.23696v1","title":"Pinalites: Optical properties and Quantum Magnetism of Heteroanionic\n  A$_3$MO$_5$X$_2$ Compounds","summary":"Heteroanionic compounds, which contain two or more types of anions, have\nemerged as a promising class of materials with diverse properties and\nfunctionalities. In this paper, I review the experimental findings on\nCa3ReO5Cl2 and related com-pounds that exhibit remarkable pleochroism and novel\nquantum magnetism. I discuss how the heteroanionic coordination affects the\noptical and magnetic properties by modulating the d-orbital states of the\ntransition metal ions and then compare these materials with other heteroanionic\nand monoanionic compounds and highlight the potential of A3MO5X2 materials for\nfuture exploration of materials and phenomena.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T03:51:35Z"}
{"aid":"http://arxiv.org/abs/2503.23702v1","title":"3D Dental Model Segmentation with Geometrical Boundary Preserving","summary":"3D intraoral scan mesh is widely used in digital dentistry diagnosis,\nsegmenting 3D intraoral scan mesh is a critical preliminary task. Numerous\napproaches have been devised for precise tooth segmentation. Currently, the\ndeep learning-based methods are capable of the high accuracy segmentation of\ncrown. However, the segmentation accuracy at the junction between the crown and\nthe gum is still below average. Existing down-sampling methods are unable to\neffectively preserve the geometric details at the junction. To address these\nproblems, we propose CrossTooth, a boundary-preserving segmentation method that\ncombines 3D mesh selective downsampling to retain more vertices at the\ntooth-gingiva area, along with cross-modal discriminative boundary features\nextracted from multi-view rendered images, enhancing the geometric\nrepresentation of the segmentation network. Using a point network as a backbone\nand incorporating image complementary features, CrossTooth significantly\nimproves segmentation accuracy, as demonstrated by experiments on a public\nintraoral scan dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:00:11Z"}
{"aid":"http://arxiv.org/abs/2503.23714v1","title":"Building Instruction-Tuning Datasets from Human-Written Instructions\n  with Open-Weight Large Language Models","summary":"Instruction tuning is crucial for enabling Large Language Models (LLMs) to\nsolve real-world tasks. Prior work has shown the effectiveness of\ninstruction-tuning data synthesized solely from LLMs, raising a fundamental\nquestion: Do we still need human-originated signals for instruction tuning?\nThis work answers the question affirmatively: we build state-of-the-art\ninstruction-tuning datasets sourced from human-written instructions, by simply\npairing them with LLM-generated responses. LLMs fine-tuned on our datasets\nconsistently outperform those fine-tuned on existing ones. Our data\nconstruction approach can be easily adapted to other languages; we build\ndatasets for Japanese and confirm that LLMs tuned with our data reach\nstate-of-the-art performance. Analyses suggest that instruction-tuning in a new\nlanguage allows LLMs to follow instructions, while the tuned models exhibit a\nnotable lack of culture-specific knowledge in that language. The datasets and\nfine-tuned models will be publicly available. Our datasets, synthesized with\nopen-weight LLMs, are openly distributed under permissive licenses, allowing\nfor diverse use cases.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T04:28:38Z"}
{"aid":"http://arxiv.org/abs/2503.23727v1","title":"Angle-dependent in-situ fast flavor transformations in post-neutron star\n  merger disks","summary":"The remnant black hole-accretion disk system resulting from binary neutron\nstar mergers has proven to be a promising site for synthesizing the heaviest\nelements via rapid neutron capture (r-process). A critical factor in\ndetermining the full r-process pattern in these environments is the neutron\nrichness of the ejecta, which is strongly influenced by neutrino interactions.\nOne key ingredient shaping these interactions is fast neutrino flavor\nconversions (FFCs), which arise due to angular crossings in neutrino\ndistributions and occur on nanosecond timescales. We present the first\nthree-dimensional, in-situ, angle-dependent modeling of FFCs in post-merger\ndisks, implemented within general relativistic magnetohydrodynamics with Monte\nCarlo neutrino transport. Our results reveal that, by suppressing electron\nneutrinos, FFCs more efficiently cool the disk and weaken the early thermally\ndriven wind. Less re-leptonization due to electron neutrino absorption makes\nthis cooler wind more neutron-rich, producing a more robust r-process at higher\nlatitudes of the outflow. This study underscores the necessity of incorporating\nFFCs in realistic simulations.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T05:01:52Z"}
{"aid":"http://arxiv.org/abs/2503.23732v1","title":"Generalized Reflected BSDEs with RCLL Random Obstacles in a General\n  Filtration","summary":"This paper addresses the existence and uniqueness of solutions to Reflected\nGeneralized Backward Stochastic Differential Equations (GRBSDEs) within a\ngeneral filtration that supports a Brownian motion and an independent\ninteger-valued random measure. Our study focuses on cases where the given data\nsatisfy appropriate $\\mathbb{L}^2$-integrability conditions and the\ncoefficients satisfy a monotonicity assumption. Additionally, we establish a\nconnection between the solution and an optimal control problem over the set of\nstopping times.","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T05:08:57Z"}
{"aid":"http://arxiv.org/abs/2503.23738v1","title":"Coherent manipulation of interacting electron qubits on solid neon","summary":"Solid neon has emerged as a pristine material host for electron qubits.\nSingle electron-on-solid-neon (eNe) charge qubits have shown extraordinarily\nlong coherence times and high operation fidelities. Realizing two-qubit gates\nin this platform is the next major step for realistic quantum information\nprocessing. In this work, we demonstrate frequency- and time-domain coherent\nmanipulation of multiple eNe charge qubits that are coupled by short-range\ncharge interactions. Cross-resonance and bSWAP two-qubit gates are implemented,\nlaying the foundation for universal quantum computing. An inter-qubit coupling\nstrength exceeding 60~MHz has been observed, promising fast gate speed and\nsuppressed infidelity. These results highlight the potential to scale up the\neNe qubit platform toward universal quantum computing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T05:27:23Z"}
{"aid":"http://arxiv.org/abs/2503.23779v1","title":"WinoWhat: A Parallel Corpus of Paraphrased WinoGrande Sentences with\n  Common Sense Categorization","summary":"In this study, we take a closer look at how Winograd schema challenges can be\nused to evaluate common sense reasoning in LLMs. Specifically, we evaluate\ngenerative models of different sizes on the popular WinoGrande benchmark. We\nrelease WinoWhat, a new corpus, in which each instance of the WinoGrande\nvalidation set is paraphrased. Additionally, we evaluate the performance on the\nchallenge across five common sense knowledge categories, giving more\nfine-grained insights on what types of knowledge are more challenging for LLMs.\nSurprisingly, all models perform significantly worse on WinoWhat, implying that\nLLM reasoning capabilities are overestimated on WinoGrande. To verify whether\nthis is an effect of benchmark memorization, we match benchmark instances to\nLLM trainingdata and create two test-suites. We observe that memorization has a\nminimal effect on model performance on WinoGrande.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T06:53:53Z"}
{"aid":"http://arxiv.org/abs/2503.23786v1","title":"MGD-SAM2: Multi-view Guided Detail-enhanced Segment Anything Model 2 for\n  High-Resolution Class-agnostic Segmentation","summary":"Segment Anything Models (SAMs), as vision foundation models, have\ndemonstrated remarkable performance across various image analysis tasks.\nDespite their strong generalization capabilities, SAMs encounter challenges in\nfine-grained detail segmentation for high-resolution class-independent\nsegmentation (HRCS), due to the limitations in the direct processing of\nhigh-resolution inputs and low-resolution mask predictions, and the reliance on\naccurate manual prompts. To address these limitations, we propose MGD-SAM2\nwhich integrates SAM2 with multi-view feature interaction between a global\nimage and local patches to achieve precise segmentation. MGD-SAM2 incorporates\nthe pre-trained SAM2 with four novel modules: the Multi-view Perception Adapter\n(MPAdapter), the Multi-view Complementary Enhancement Module (MCEM), the\nHierarchical Multi-view Interaction Module (HMIM), and the Detail Refinement\nModule (DRM). Specifically, we first introduce MPAdapter to adapt the SAM2\nencoder for enhanced extraction of local details and global semantics in HRCS\nimages. Then, MCEM and HMIM are proposed to further exploit local texture and\nglobal context by aggregating multi-view features within and across\nmulti-scales. Finally, DRM is designed to generate gradually restored\nhigh-resolution mask predictions, compensating for the loss of fine-grained\ndetails resulting from directly upsampling the low-resolution prediction maps.\nExperimental results demonstrate the superior performance and strong\ngeneralization of our model on multiple high-resolution and normal-resolution\ndatasets. Code will be available at https://github.com/sevenshr/MGD-SAM2.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T07:02:32Z"}
{"aid":"http://arxiv.org/abs/2503.23833v1","title":"Products of Kirillov-Reshetikhin modules and maximal green sequences","summary":"We show that a $q$-character of a Kirillov-Reshetikhin module (KR modules)\nfor untwisted quantum affine algebras of simply laced types $A_n^{(1)}$,\n$D_n^{(1)}$, $E_6^{(1)}$, $E_7^{(1)}$, $E_8^{(1)}$ might be obtained from a\nspecific cluster variable of a seed obtained by applying a maximal green\nsequence to the initial (infinite) quiver of the Hernandez-Leclerc cluster\nalgebra. For a collection of KR-modules with nested supports, we show an\nexplicit construction of a cluster seed, which has cluster variables\ncorresponding to the $q$-characters of KR-modules of such a collection. We\nprove that the product of KR-modules of such a collection is a simple module.\nWe also construct cluster seeds with cluster variables corresponding to\n$q$-characters of KR-modules of some non-nested collections. We make a\nconjecture that tensor products of KR-modules for such non-nested collections\nare simple. We show that the cluster Donaldson-Thomas transformations for\ndouble Bruhat cells for $ADE$ types can be computed using $q$-characters of\nKR-modules.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-03-31T08:28:36Z"}
{"aid":"http://arxiv.org/abs/2503.23834v1","title":"$q$-deformed rationals and irrationals","summary":"The concept of $q$-deformation, or ``$q$-analogue'' arises in many areas of\nmathematics. In algebra and representation theory, it is the origin of quantum\ngroups; $q$-deformations are important for knot invariants, combinatorial\nenumeration, discrete geometry, analysis, and many other parts of mathematics.\nIn mathematical physics, $q$-deformations are often understood as\n``quantizations''.\n  The recently introduced notion of a $q$-deformed real number is based on the\ngeometric idea of invariance by a modular group action. The goal of this\nlecture is to explain what is a $q$-rational and a $q$-irrational, demonstrate\nbeautiful properties of these objects, and describe their relations to many\ndifferent areas. We also tried to describe some applications of $q$-numbers.","main_category":"math.CO","categories":"math.CO,math.QA","published":"2025-03-31T08:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.23843v1","title":"The Problem of the Global Astrometric Sphere Reconstruction in\n  Astrometry -- Issues and Approaches","summary":"In this contribution we give a brief account of the problem of the Global\nAstrometric Sphere Reconstruction in Astrometry, with particular reference to\nthe Gaia and Gaia-like astrometric missions, namely those adopting a scanning\nstrategy with observations in TDI mode. We sketch the design of the Gaia\nmission, the mathematical modelling that comes naturally from its observing\nstrategy, and how the problem of the global sphere reconstruction translates\ninto that of the solution of large, sparse, and overdetermined system of\nlinearized equations. After a short description of the two approaches to this\nproblem implemented in the Gaia data reduction pipelines, we list the main\nknown problems of the current approaches, with specific reference to the\ncalibration and the correlation issues. Finally, we suggest how an arc-based\nsolution could help to alleviate some of these problems, how it would be\npossible to devise a mathematical model for such an observable despite the TDI\nobserving mode, and the main difficulty that a parallel implementation of this\nmodel would have to solve.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T08:45:29Z"}
{"aid":"http://arxiv.org/abs/2503.23849v1","title":"Narrow-Line Seyfert 1 Galaxies Beyond the Local X-ray Universe: An X-ray\n  spectral sample","summary":"Narrow-line Seyfert 1 AGNs (NLS1s) represent a unique stage in the black hole\ngrowth history, characterised by low black hole masses of approximately\n$10^{6}$-$10^{8}$ solar masses and around-Eddington accretion rates. X-ray\nstudies of NLS1s have largely been confined to the local Universe ($z < 0.2$),\nwhile their broad-line counterparts and radio-loud quasars have been more\nextensively investigated at higher redshifts. In this work, we conducted an\nX-ray spectral analysis for 14 SDSS-observed NLS1s at $z\\approx1$ in the eRASS1\ncatalogue. We found that all of their eROSITA observations agree with the\nexpected rest-frame 2 keV monochromatic luminosity given their rest-frame 2500\nangstrom monochromatic luminosity, further supporting evidence of AGN emission.\nSecond, when fitted with a power-law model, most continuum spectra between\n0.7-7 keV in their rest frames necessitate photon indices $\\Gamma\\gtrsim2.5$.\nNotably, the highest photon index of around 4.7 in one of our NLS1 AGNs hints\nat a significant contribution from soft excess emission. Finally, our analysis\ndemonstrates that we can align the Eddington ratios with optical measurements\nby applying a correction factor between 10-120 to their X-ray luminosity.\nAlthough measurement uncertainty remains considerable, our findings suggest\nthat assumptions for the standard geometrically thin accretion disc model made\nin previous estimations of this correction factor may not apply to near or\nsuper-Eddington NLS1 AGNs. Finally, we also compare this sample with extremely\nvariable nearby NLS1s and other X-ray-weak AGNs, such as JWST-observed,\nbroad-line AGNs at $z=5-6$, and underscores the importance of deeper X-ray\nsurveys for more X-ray-weak NLS1s.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T08:55:07Z"}
{"aid":"http://arxiv.org/abs/2503.23850v1","title":"Event-activity dependence of heavy-flavor production at the ALICE\n  experiment","summary":"Heavy-flavor production at the LHC offers valuable tests of\nquantum-chromodynamics calculations, owing to the large masses of heavy quarks.\nMeasurements of charm production as a function of event activity reveal new\nfeatures of charm production and fragmentation, providing insights to the\ninterplay between soft and hard processes. In addition, charm production in\nheavy-ion collisions addresses flavor-dependent quark transport properties in\nboth hot and cold nuclear matter, helping to clarify the roles of coalescence\nand fragmentation in heavy-flavor hadron formation. This contribution\nsummarizes recent measurements from the ALICE experiment on charm production as\na function of charged-particle multiplicity in pp collisions at various\nenergies, including the measurements of charm baryon-to-meson production yield\nratios in pp, p--Pb and Pb--Pb collisions. New results on ${\\rm D}^0$\nproduction in pp collisions as a function of the transverse spherocity of the\nevent, as well as of the transverse event-activity classifier $R_{\\rm T}$, are\nalso presented.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T08:55:52Z"}
{"aid":"http://arxiv.org/abs/2503.23861v1","title":"$s_{\\pm}$ pairing via interlayer interaction in\n  La$_{2.85}$Pr$_{0.15}$Ni$_2$O$_7$ Thin Films under Ambient Pressure","summary":"We demonstrate that interlayer \\(s_{\\pm}\\)-wave pairing dominates\nsuperconductivity in La\\(_{2.85}\\)Pr\\(_{0.15}\\)Ni\\(_2\\)O\\(_7\\) thin films\nthrough self-consistent mean-field calculations. We further show that applying\na perpendicular electric field breaks layer equivalence, generating nodal\nstructures, Fermi arcs, and finite low-energy states in the \\(d_{x^2-y^2}\\)\norbital. Our results quantitatively align with recent experimental observations\nfor the superconducting gaps, and we propose experimental symmetry-breaking\nperturbations as a direct test for the interlayer pairing mechanism.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-03-31T09:08:26Z"}
{"aid":"http://arxiv.org/abs/2503.23875v1","title":"GenSwarm: Scalable Multi-Robot Code-Policy Generation and Deployment via\n  Language Models","summary":"The development of control policies for multi-robot systems traditionally\nfollows a complex and labor-intensive process, often lacking the flexibility to\nadapt to dynamic tasks. This has motivated research on methods to automatically\ncreate control policies. However, these methods require iterative processes of\nmanually crafting and refining objective functions, thereby prolonging the\ndevelopment cycle. This work introduces \\textit{GenSwarm}, an end-to-end system\nthat leverages large language models to automatically generate and deploy\ncontrol policies for multi-robot tasks based on simple user instructions in\nnatural language. As a multi-language-agent system, GenSwarm achieves zero-shot\nlearning, enabling rapid adaptation to altered or unseen tasks. The white-box\nnature of the code policies ensures strong reproducibility and\ninterpretability. With its scalable software and hardware architectures,\nGenSwarm supports efficient policy deployment on both simulated and real-world\nmulti-robot systems, realizing an instruction-to-execution end-to-end\nfunctionality that could prove valuable for robotics specialists and\nnon-specialists alike.The code of the proposed GenSwarm system is available\nonline: https://github.com/WindyLab/GenSwarm.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.MA","published":"2025-03-31T09:26:34Z"}
{"aid":"http://arxiv.org/abs/2503.23921v1","title":"$K$-theoretic computation of the Atiyah(-Patodi)-Singer index of lattice\n  Dirac operators","summary":"We show that the Wilson Dirac operator in lattice gauge theory can be\nidentified as a mathematical object in $K$-theory and that its associated\nspectral flow is equal to the index. In comparison to the standard lattice\nDirac operator index, our formulation does not require the Ginsparg-Wilson\nrelation and has broader applicability to systems with boundaries and to the\nmod-two version of the indices in general dimensions. We numerically verify\nthat the $K$ and $KO$ group formulas reproduce the known index theorems in\ncontinuum theory. We examine the Atiyah-Singer index on a flat two-dimensional\ntorus and, for the first time, demonstrate that the Atiyah-Patodi-Singer index\nwith nontrivial curved boundaries, as well as the mod-two versions, can be\ncomputed on a lattice.","main_category":"hep-th","categories":"hep-th,hep-lat,math.KT","published":"2025-03-31T10:11:44Z"}
{"aid":"http://arxiv.org/abs/2503.23924v1","title":"Model Hemorrhage and the Robustness Limits of Large Language Models","summary":"Large language models (LLMs) demonstrate strong performance across natural\nlanguage processing tasks, yet undergo significant performance degradation when\nmodified for deployment through quantization, pruning, or decoding strategy\nadjustments. We define this phenomenon as model hemorrhage - performance\ndecline caused by parameter alterations and architectural changes. Through\nsystematic analysis of various LLM frameworks, we identify key vulnerability\npatterns: layer expansion frequently disrupts attention mechanisms, compression\ntechniques induce information loss cascades, and decoding adjustments amplify\nprediction divergences. Our investigation reveals transformer architectures\nexhibit inherent robustness thresholds that determine hemorrhage severity\nacross modification types. We propose three mitigation strategies:\ngradient-aware pruning preserves critical weight pathways, dynamic quantization\nscaling maintains activation integrity, and decoding calibration aligns\ngeneration trajectories with original model distributions. This work\nestablishes foundational metrics for evaluating model stability during\nadaptation, providing practical guidelines for maintaining performance while\nenabling efficient LLM deployment. Our findings advance understanding of neural\nnetwork resilience under architectural transformations, particularly for\nlarge-scale language models.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-03-31T10:16:03Z"}
{"aid":"http://arxiv.org/abs/2503.23930v1","title":"Exploring Reliable PPG Authentication on Smartwatches in Daily Scenarios","summary":"Photoplethysmography (PPG) Sensors, widely deployed in smartwatches, offer a\nsimple and non-invasive authentication approach for daily use. However, PPG\nauthentication faces reliability issues due to motion artifacts from physical\nactivity and physiological variability over time. To address these challenges,\nwe propose MTL-RAPID, an efficient and reliable PPG authentication model, that\nemploys a multitask joint training strategy, simultaneously assessing signal\nquality and verifying user identity. The joint optimization of these two tasks\nin MTL-RAPID results in a structure that outperforms models trained on\nindividual tasks separately, achieving stronger performance with fewer\nparameters. In our comprehensive user studies regarding motion artifacts (N =\n30), time variations (N = 32), and user preferences (N = 16), MTL-RAPID\nachieves a best AUC of 99.2\\% and an EER of 3.5\\%, outperforming existing\nbaselines. We opensource our PPG authentication dataset along with the\nMTL-RAPID model to facilitate future research on GitHub.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:25:48Z"}
{"aid":"http://arxiv.org/abs/2503.23939v1","title":"Simulation of Shor algorithm for discrete logarithm problems with\n  comprehensive pairs of modulo p and order q","summary":"The discrete logarithm problem (DLP) over finite fields, commonly used in\nclassical cryptography, has no known polynomial-time algorithm on classical\ncomputers. However, Shor has provided its polynomial-time algorithm on quantum\ncomputers. Nevertheless, there are only few examples simulating quantum\ncircuits that operate on general pairs of modulo $p$ and order $q$. In this\npaper, we constructed such quantum circuits and solved DLPs for all 1,860\npossible pairs of $p$ and $q$ up to 32 qubits using a quantum simulator with\nPRIMEHPC FX700. From this, we obtained and verified values of the success\nprobabilities, which had previously been heuristically analyzed by Eker\\r{a}.\nAs a result, we found that the success probability of Shor's algorithm for\nsolving the DLP exhibits periodicity with an asymmetric waveform determined by\nthe order $q$. Additionally, we generated 1,015 quantum circuits for larger\npairs of $p$ and $q$, extrapolated the circuit sizes obtained, and compared\nthem for $p=2048$ bits between safe-prime groups and Schnorr groups. While in\nclassical cryptography, the cipher strength of safe-prime groups and Schnorr\ngroups is the same if $p$ is equal, we quantitatively demonstrated how much the\nstrength of the latter decreases to the bit length of $p$ in the former when\nusing Shor's quantum algorithm. In particular, it was experimentally and\ntheoretically shown that when a ripple carry adder is used in the addition\ncircuit, the cryptographic strength of a Schnorr group with $p=2048$ bits under\nShor's algorithm is almost equivalent to that of a safe-prime group with\n$p=1024$ bits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T10:39:10Z"}
{"aid":"http://arxiv.org/abs/2503.23953v1","title":"Skilful global seasonal predictions from a machine learning weather\n  model trained on reanalysis data","summary":"Machine learning weather models trained on observed atmospheric conditions\ncan outperform conventional physics-based models at short- to medium-range\n(1-14 day) forecast timescales. Here we take the machine learning weather model\nACE2, trained to predict 6-hourly steps in atmospheric evolution and which can\nremain stable over long forecast periods, and assess it from a seasonal\nforecasting perspective. Applying persisted sea surface temperature (SST) and\nsea-ice anomalies centred on 1st November each year, we initialise a lagged\nensemble of winter predictions covering 1993/1994 to 2015/2016. Over this\n23-year period there is remarkable similarity in the patterns of predictability\nwith a leading physics-based model. The ACE2 model exhibits skilful predictions\nof the North Atlantic Oscillation (NAO) with a correlation score of 0.47\n(p=0.02), as well as a realistic global distribution of skill and ensemble\nspread. Surprisingly, ACE2 is found to exhibit a signal-to-noise error as seen\nin physics-based models, in which it is better at predicting the real world\nthan itself. Examining predictions of winter 2009/2010 indicates potential\nlimitations of ACE2 in capturing extreme seasonal conditions that extend\noutside the training data. Nevertheless, this study reveals that machine\nlearning weather models can produce skilful global seasonal predictions and\nheralds a new era of increased understanding, development and generation of\nnear-term climate predictions.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-03-31T11:11:16Z"}
{"aid":"http://arxiv.org/abs/2503.23960v1","title":"Testing for integer integration in functional time series","summary":"We develop a statistical testing procedure to examine whether the\ncurve-valued time series of interest is integrated of order d for an integer d.\nThe proposed procedure can distinguish between integer-integrated time series\nand fractionally-integrated ones, and it has broad applicability in practice.\nMonte Carlo simulation experiments show that the proposed testing procedure\nperforms reasonably well. We apply our methodology to Canadian yield curve data\nand French sub-national age-specific mortality data. We find evidence that\nthese time series are mostly integrated of order one, while some have\nfractional orders exceeding or falling below one.","main_category":"stat.ME","categories":"stat.ME","published":"2025-03-31T11:20:38Z"}
{"aid":"http://arxiv.org/abs/2503.24010v1","title":"Roommates with Convex Preferences","summary":"Roommate problems with convex preferences always have stable matchings.\nEfficiency and individual rationality are, moreover, compatible with\nstrategyproofness in such convex roommate problems. Both of these results fail\nwithout the assumption of convexity. In the environment under study,\npreferences are convex if and only if they are single peaked. Any individually\nrational and convex roommate problem is homomorphic to a marriage market where\nan agent's gender corresponds to the direction of the agent's top-ranked\npartner. The existence of stable matchings then follows from the existence of\nstable matchings in marriage markets. To prove the second existence result, I\ndefine an efficient, individually rational, and strategyproof mechanism for\nconvex roommate problems. To calculate outcomes, this mechanism starts with all\nagents being single and then gradually reassigns agents to better partners by\nperforming minimal Pareto improvements. Whenever it becomes clear that some\nagent cannot be part of any further Pareto improvement, such an agent is\nmatched.","main_category":"econ.TH","categories":"econ.TH","published":"2025-03-31T12:36:48Z"}
{"aid":"http://arxiv.org/abs/2503.24047v1","title":"Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents","summary":"As scientific research becomes increasingly complex, innovative tools are\nneeded to manage vast data, facilitate interdisciplinary collaboration, and\naccelerate discovery. Large language models (LLMs) are now evolving into\nLLM-based scientific agents that automate critical tasks, ranging from\nhypothesis generation and experiment design to data analysis and simulation.\nUnlike general-purpose LLMs, these specialized agents integrate domain-specific\nknowledge, advanced tool sets, and robust validation mechanisms, enabling them\nto handle complex data types, ensure reproducibility, and drive scientific\nbreakthroughs. This survey provides a focused review of the architectures,\ndesign, benchmarks, applications, and ethical considerations surrounding\nLLM-based scientific agents. We highlight why they differ from general agents\nand the ways in which they advance research across various scientific fields.\nBy examining their development and challenges, this survey offers a\ncomprehensive roadmap for researchers and practitioners to harness these agents\nfor more efficient, reliable, and ethically sound scientific discovery.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-03-31T13:11:28Z"}
{"aid":"http://arxiv.org/abs/2503.24076v1","title":"On a question about real rooted polynomials and f-polynomials of\n  simplicial complexes","summary":"For a polynomial $f(t) = 1+f_0t+\\cdots +f_{d-1}t^d$ with positive integer\ncoefficients Bell and Skandera ask if real rootedness of f(t) implies that\nthere is a simplicial complex with f-vector $(1,f_0 \\ldots,f_{d-1})$. In this\npaper we discover properties implied by the real rootedness of f(t) in terms of\nthe binomial representation $f_i = \\binom{x_{i+1}}{i+1}, i \\geq 0$. We use\nthese to provide a sufficient criterion for a positive answer to the question\nby Bell and Skandera. We also describe two further approaches to the conjecture\nand use one to verify that some well studied real rooted classical polynomials\nare f-polynomials. Finally, we provide a series of results showing that the set\nof f-vectors of simplicial complexes is closed under constructions also\npreserving real rootedness of their generating polynomials.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T13:31:37Z"}
{"aid":"http://arxiv.org/abs/2503.24119v1","title":"Measuring User Experience Through Speech Analysis: Insights from HCI\n  Interviews","summary":"User satisfaction plays a crucial role in user experience (UX) evaluation.\nTraditionally, UX measurements are based on subjective scales, such as\nquestionnaires. However, these evaluations may suffer from subjective bias. In\nthis paper, we explore the acoustic and prosodic features of speech to\ndifferentiate between positive and neutral UX during interactive sessions. By\nanalyzing speech features such as root-mean-square (RMS), zero-crossing\nrate(ZCR), jitter, and shimmer, we identified significant differences between\nthe positive and neutral user groups. In addition, social speech features such\nas activity and engagement also show notable variations between these groups.\nOur findings underscore the potential of speech analysis as an objective and\nreliable tool for UX measurement, contributing to more robust and\nbias-resistant evaluation methodologies. This work offers a novel approach to\nintegrating speech features into UX evaluation and opens avenues for further\nresearch in HCI.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T14:07:38Z"}
{"aid":"http://arxiv.org/abs/2503.24120v1","title":"Renormalized mechanics and stochastic thermodynamics of growing model\n  protocells","summary":"Uncovering the rules governing the nonequilibrium dynamics of the membranes\nthat define biological cells is of central importance to understanding the\nphysics of living systems. We theoretically and computationally investigate the\nbehavior of model protocells -- flexible quasispherical vesicles -- that\nexchange membrane constituents, internal volume, and heat with an external\nreservoir. The excess chemical potential and osmotic pressure difference\nimposed by the reservoir act as generalized thermodynamic driving forces that\nmodulate vesicle morphology. We identify an associated nonequilibrium\nmorphological transition between a weakly driven regime, in which growing\nvesicles remain quasispherical, and a strongly driven regime, in which vesicles\naccommodate rapid membrane uptake by developing surface wrinkles. This\ntransition emerges due to the renormalization of membrane mechanical properties\nby nonequilibrium driving. Further, using insights from stochastic\nthermodynamics we propose a minimal vesicle growth-shape law that remains\nrobust even in strongly driven, far-from-equilibrium regimes.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-03-31T14:08:15Z"}
{"aid":"http://arxiv.org/abs/2503.24123v1","title":"CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic\n  Learning","summary":"Many computational tasks benefit from being formulated as the composition of\nneural networks followed by a discrete symbolic program. The goal of\nneurosymbolic learning is to train the neural networks using only end-to-end\ninput-output labels of the composite. We introduce CTSketch, a novel, scalable\nneurosymbolic learning algorithm. CTSketch uses two techniques to improve the\nscalability of neurosymbolic inference: decompose the symbolic program into\nsub-programs and summarize each sub-program with a sketched tensor. This\nstrategy allows us to approximate the output distribution of the program with\nsimple tensor operations over the input distributions and summaries. We provide\ntheoretical insight into the maximum error of the approximation. Furthermore,\nwe evaluate CTSketch on many benchmarks from the neurosymbolic literature,\nincluding some designed for evaluating scalability. Our results show that\nCTSketch pushes neurosymbolic learning to new scales that have previously been\nunattainable by obtaining high accuracy on tasks involving over one thousand\ninputs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T14:08:58Z"}
{"aid":"http://arxiv.org/abs/2503.24124v1","title":"Effect of Interlayer Stacking on the Electronic Properties of\n  1$T$-TaS$_2$","summary":"Controlled stacking of van der Waals materials is a powerful tool for\nexploring the physics of quantum condensed matter. Given the small binding\nbetween layers, exploitation for engineering will require a breakthrough in\nstacking methodology, or an ability to take advantage of thicker defective\nstacks. Here we describe computational groundwork for the latter, using -- on\naccount of its promise for cold memory applications -- 1$T$-TaS$_2$ as a model\nsystem. Comparing recursive Hendricks-Teller calculations and Monte Carlo\nsimulations to published X-ray diffraction data, we obtain the key parameters\ndescribing the random stacking in mesoscopic flakes. These then regulate the\nelectronic structures via specification of the random stacks in dynamical\nmean-field theory simulations. Hubbard repulsion induces strongly correlated\nmetallic, band and Mott insulating layers, providing compelling evidence that\nelectronic properties follow from the coexistence of more than the metallic and\ninsulating planes associated by ordinary band theory.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-03-31T14:09:14Z"}
{"aid":"http://arxiv.org/abs/2503.24142v1","title":"Dust Concentration Via Coupled Vertical Settling and Radial Migration in\n  Substructured Non-Ideal MHD Discs and Early Planet Formation","summary":"We investigate the dynamics of dust concentration in actively accreting,\nsubstructured, non-ideal MHD wind-launching disks using 2D and 3D simulations\nincorporating pressureless dust fluids of various grain sizes and their\naerodynamic feedback on gas dynamics. Our results reveal that mm/cm-sized\ngrains are preferentially concentrated within the inner 5-10 au of the disk,\nwhere the dust-to-gas surface density ratio (local metalicity Z) significantly\nexceeds the canonical 0.01, reaching values up to 0.25. This enhancement arises\nfrom the interplay of dust settling and complex gas flows in the meridional\nplane, including midplane accretion streams at early times, midplane expansion\ndriven by magnetically braked surface accretion at later times, and vigorous\nmeridional circulation in spontaneously formed gas rings. The resulting\nsize-dependent dust distribution has a strong spatial variation, with large\ngrains preferentially accumulating in dense rings, particularly in the inner\ndisk, while being depleted in low-density gas gaps. In 3D, these rings and gaps\nare unstable to Rossby wave instability (RWI), generating arc-shaped vortices\nthat stand out more prominently than their gas counterparts in the inner disk\nbecause of preferential dust concentration at small radii. The substantial\nlocal enhancement of the dust relative to the gas could promote planetesimal\nformation via streaming instability, potentially aided by the \"azimuthal drift\"\nstreaming instability (AdSI) that operates efficiently in accreting disks and a\nlower Toomre Q expected in younger disks. Our findings suggest that actively\naccreting young disks may provide favorable conditions for early planetesimal\nformation, which warrants further investigation.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-03-31T14:26:32Z"}
{"aid":"http://arxiv.org/abs/2503.24146v1","title":"Joint Modeling of Multiple Longitudinal Biomarkers and Survival Outcomes\n  via Threshold Regression: Variability as a Predictor","summary":"Longitudinal biomarker data and health outcomes are routinely collected in\nmany studies to assess how biomarker trajectories predict health outcomes.\nExisting methods primarily focus on mean biomarker profiles, treating\nvariability as a nuisance. However, excess variability may indicate system\ndysregulations that may be associated with poor outcomes. In this paper, we\naddress the long-standing problem of using variability information of multiple\nlongitudinal biomarkers in time-to-event analyses by formulating and studying a\nBayesian joint model. We first model multiple longitudinal biomarkers, some of\nwhich are subject to limit-of-detection censoring. We then model the survival\ntimes by incorporating random effects and variances from the longitudinal\ncomponent as predictors through threshold regression that admits\nnon-proportional hazards. We demonstrate the operating characteristics of the\nproposed joint model through simulations and apply it to data from the Study of\nWomen's Health Across the Nation (SWAN) to investigate the impact of the mean\nand variability of follicle-stimulating hormone (FSH) and anti-Mullerian\nhormone (AMH) on age at the final menstrual period (FMP).","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-31T14:33:04Z"}
{"aid":"http://arxiv.org/abs/2503.24156v1","title":"Reinforcing Localization Credibility Through Convex Optimization","summary":"This work proposes a novel approach to reinforce localization security in\nwireless networks in the presence of malicious nodes that are able to\nmanipulate (spoof) radio measurements. It substitutes the original measurement\nmodel by another one containing an auxiliary variance dilation parameter that\ndisguises corrupted radio links into ones with large noise variances. This\nallows for relaxing the non-convex maximum likelihood estimator (MLE) into a\nsemidefinite programming (SDP) problem by applying convex-concave programming\n(CCP) procedure. The proposed SDP solution simultaneously outputs target\nlocation and attacker detection estimates, eliminating the need for further\napplication of sophisticated detectors. Numerical results corroborate excellent\nperformance of the proposed method in terms of localization accuracy and show\nthat its detection rates are highly competitive with the state of the art.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T14:40:08Z"}
{"aid":"http://arxiv.org/abs/2503.24170v1","title":"Localization of operator-valued frames","summary":"We introduce a localization concept for operator-valued frames, where the\nquality of localization is measured by the associated operator-valued Gram\nmatrix belonging to some suitable Banach algebra. We prove that intrinsic\nlocalization of an operator-valued frame is preserved by its canonical dual.\nMoreover, we show that the series associated to the perfect reconstruction of\nan operator-valued frame converges not only in the underlying Hilbert space,\nbut also in a whole class of associated (quasi-)Banach spaces. Finally, we\napply our results to irregular Gabor g-frames.","main_category":"math.FA","categories":"math.FA","published":"2025-03-31T14:49:54Z"}
{"aid":"http://arxiv.org/abs/2503.24181v1","title":"Computational challenges of 21st century Global Astrometry","summary":"Major advancements in space science and detector technology brought about a\nrevolution in global astrometry, the science of measuring distances and motions\nof stars in the Milky Way and in the local universe. From the first ESA\nastrometric mission HIPPARCOS of the early 80s to the current Gaia mission, the\ndata volume and computational complexity of the full reduction process has\nincreased by several orders of magnitude, requiring high-performance computing\nand data throughput. We review the principles and computational complexity of\ngeneral global astrometric models that lead to the statistical treatment of an\nextra-large, highly non-linear estimation problem. Some numerical aspects of\ninspecting Gaia's proper motions to find cosmological signals at all scales are\nalso addressed.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T14:58:40Z"}
{"aid":"http://arxiv.org/abs/2503.24188v1","title":"A Swift analysis of the Eras tour set list and implications for\n  astrophysics research (Taylor's version)","summary":"Popular culture plays a significant role in shaping public interest in\nscience, and Taylor Swift's discography frequently incorporates astrophysics\nterminology. This study examines the occurrence of astrophysics-related words\nin her lyrics and their representation in the Eras tour set list. By analyzing\nthe frequency of words in Swift's total discography, we identify that\nastrophysics is promoted the most within her most recent album, The Tortured\nPoets Department, whereas songs from Midnights promoted astrophysics the most\nthroughout the Eras tour. We catagorize words into various disciplines of\nastrophysics and find that multimessenger astronomy is promoted the most, both\nin Swift's total discography and throughout the Eras tour. We perform Taylor\nexpansion and predict $12 \\pm 5$ astrophysical terms in Swift's next album.\nThis analysis offers a unique perspective on the intersection of music and\nscience, revealing how Swift's artistry may unintentionally promote interest in\ndifferent fields of astrophysics.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO,astro-ph.IM,astro-ph.SR,physics.ed-ph,physics.soc-ph","published":"2025-03-31T15:05:48Z"}
{"aid":"http://arxiv.org/abs/2503.24189v1","title":"Quantum superalgebras and the free-fermionic Yang-Baxter equation","summary":"The free-fermion point refers to a\n$\\operatorname{GL}(2)\\times\\operatorname{GL}(1)$ parametrized Yang-Baxter\nequation within the six-vertex model. It has been known for a long time that\nthis is connected with the quantum group $U_q(\\mathfrak{gl}(1|1))$. We\ndemonstrate that $R$-matrices from the finite quantum superalgebra\n$U_q(\\mathfrak{gl}(1|1))$ recovers a dense subset of the free-fermion point of\nthe six-vertex model and recover the prime, simple modules in the affine\nquantum superalgebra $U_q(\\widehat{\\mathfrak{gl}}(1|1))$. Either of these\nquantum groups can be used to generate the full free-fermion point, and we\ndiscuss them both. Our discussion includes 6 families of six-vertex models used\nby Brubaker, Bump, and Friedberg in connection with Tokuyama's theorem, a\ndeformation of the Weyl character formula. Thus our work gives quantum group\ninterpretations for those models, known informally as Tokuyama ice.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-03-31T15:06:50Z"}
{"aid":"http://arxiv.org/abs/2503.24195v1","title":"Computational Orthodontic Force Simulation: A Review","summary":"In orthodontic treatment, the biological response of the tooth, periodontal\nligament, and bone complex to orthodontic force is crucial in influencing\ntreatment outcomes. The challenge lies in accurately measuring, estimating, and\npredicting these forces during clinical procedures. This review aims to fill\nthe gap in the literature by systematically summarizing existing research on\northodontic force simulation, examining common loading techniques and\ntechnologies, and discussing the potential for refining the orthodontic force\nsimulation process. The literature was comprehensively reviewed, with an\nemphasis on the exploration of the biological mechanism of tooth movement.\nStudies were categorized based on force-loading techniques for both fixed and\ninvisible orthodontic appliances. Finite element (FE) analysis stands out as\nthe predominant technique for orthodontic force simulation, with a significant\nfocus on fixed orthodontics but limited emphasis on invisible orthodontics.\nCurrent orthodontic force simulations tend to be fragmented, often considering\nonly the instantaneous response to applied forces. There exists an urgent\ndemand for a sophisticated analytical simulation model. Such a model, possibly\nleveraging advanced technologies like deep learning, holds the promise of\nforecasting orthodontic treatment outcomes with heightened precision and\nefficiency.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.NA,math.NA","published":"2025-03-31T15:13:36Z"}
{"aid":"http://arxiv.org/abs/2503.24220v1","title":"BAR-Analytics: A Web-based Platform for Analyzing Information Spreading\n  Barriers in News: Comparative Analysis Across Multiple Barriers and Events","summary":"This paper presents BAR-Analytics, a web-based, open-source platform designed\nto analyze news dissemination across geographical, economic, political, and\ncultural boundaries. Using the Russian-Ukrainian and Israeli-Palestinian\nconflicts as case studies, the platform integrates four analytical methods:\npropagation analysis, trend analysis, sentiment analysis, and temporal topic\nmodeling. Over 350,000 articles were collected and analyzed, with a focus on\neconomic disparities and geographical influences using metadata enrichment. We\nevaluate the case studies using coherence, sentiment polarity, topic frequency,\nand trend shifts as key metrics. Our results show distinct patterns in news\ncoverage: the Israeli-Palestinian conflict tends to have more negative\nsentiment with a focus on human rights, while the Russia-Ukraine conflict is\nmore positive, emphasizing election interference. These findings highlight the\ninfluence of political, economic, and regional factors in shaping media\nnarratives across different conflicts.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T15:36:55Z"}
{"aid":"http://arxiv.org/abs/2503.24221v1","title":"The Categories of Lubin-Tate and Drinfeld Bundles","summary":"For a finite extension $F$ of $\\mathbb{Q}_p$ and $n \\geq 1$, we show that the\ncategory of Lubin-Tate bundles on the $(n-1)$-dimensional Drinfeld symmetric\nspace is equivalent to the category of finite-dimensional smooth\nrepresentations of the group of units of the division algebra of invariant\n$1/n$ over $F$.","main_category":"math.NT","categories":"math.NT,math.AG,math.RT","published":"2025-03-31T15:37:25Z"}
{"aid":"http://arxiv.org/abs/2503.24226v1","title":"Asymptotic Freedom and Finite-size Scaling of Two-dimensional Classical\n  Heisenberg Model","summary":"The classical Heisenberg model is one of the most fundamental models in\nstatistical and condensed matter physics. Extensive theoretical and numerical\nstudies suggest that, in two dimensions, this model does not exhibit a\nfinite-temperature phase transition but instead manifests asymptotic freedom.\nHowever, some research has also proposed the possibility of a\nBerezinskii-Kosterlitz-Thouless (BKT) phase transition over the years. In this\nstudy, we revisit the classical two-dimensional (2D) Heisenberg model through\nlarge-scale simulations with linear system sizes up to $L=16384$. Our\nMonte-Carlo data, without any extrapolation, clearly reveal an exponential\ndivergence of the correlation length $\\xi$ as a function of inverse temperature\n$\\beta$, a hallmark of asymptotic freedom. Moreover, extrapolating $\\xi$ to the\nthermodynamic limit in the low-temperature regime achieves close agreement with\nthe three-loop perturbative calculations. We further propose a finite-size\nscaling (FSS) ansatz for $\\xi$, demonstrating that the pseudo-critical point\n$\\beta_L$ diverges logarithmically with $L$. The thermodynamic and finite-size\nscaling behaviors of the magnetic susceptibility $\\chi$ are also investigated\nand corroborate the prediction of asymptotic freedom. Our work provides solid\nevidence for asymptotic freedom in the 2D Heisenberg model and advances\nunderstanding of finite-size scaling in such systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T15:39:13Z"}
{"aid":"http://arxiv.org/abs/2503.24236v1","title":"Estimating a graph's spectrum via random Kirchhoff forests","summary":"Exact eigendecomposition of large matrices is very expensive, and it is\npractically impossible to compute exact eigenvalues. Instead, one may set a\nmore modest goal of approaching the empirical distribution of the eigenvalues,\nrecovering the overall shape of the eigenspectrum. Current approaches to\nspectral estimation typically work with \\emph{moments} of the spectral\ndistribution. These moments are first estimated using Monte Carlo trace\nestimators, then the estimates are combined to approximate the spectral\ndensity. In this article we show how \\emph{Kirchhoff forests}, which are random\nforests on graphs, can be used to estimate certain non-linear moments of very\nlarge graph Laplacians. We show how to combine these moments into an estimate\nof the spectral density. If the estimate's desired precision isn't too high,\nour approach paves the way to the estimation of a graph's spectrum in time\nsublinear in the number of links.","main_category":"stat.CO","categories":"stat.CO,math.ST,stat.TH","published":"2025-03-31T15:47:55Z"}
{"aid":"http://arxiv.org/abs/2503.24244v1","title":"The 2-Token Theorem: Recognising History-Deterministic Parity Automata\n  Efficiently","summary":"History-determinism is a restricted notion of nondeterminism in automata,\nwhere the nondeterminism can be successfully resolved based solely on the\nprefix read so far. History-deterministic automata still allow for exponential\nsuccinctness in automata over infinite words compared to deterministic automata\n(Kuperberg and Skrzypczak, 2015), allow for canonical forms unlike\ndeterministic automata (Abu Radi and Kupferman, 2019 and 2020; Ehlers and\nSchewe, 2022), and retain some of the algorithmic properties of deterministic\nautomata, for example for reactive synthesis (Henzinger and Piterman, 2006;\nEhlers and Khalimov, 2024).\n  Despite the topic of history-determinism having received a lot of attention\nover the last decade, the complexity of deciding whether a parity automaton is\nhistory-deterministic has, up till now, remained open. We show that\nhistory-determinism for a parity automaton with a fixed parity index can be\nchecked in PTIME, thus improving upon the naive EXPTIME upper bound of\nHenzinger and Piterman that has stood since 2006. More precisely, we show that\nthe so-called 2-token game, which can be solved in PTIME for parity automata\nwith a fixed parity index, characterises history-determinism for parity\nautomata. This game was introduced by Bagnol and Kuperberg in 2018, who showed\nthat to decide if a B\\\"uchi automaton is history-determinism, it suffices to\nfind the winner of the 2-token game on it. They conjectured that this 2-token\ngame based characterisation extends to parity automata. Boker, Kuperberg,\nLehtinen, and Skrzypcak showed in 2020 that this conjecture holds for coB\\\"uchi\nautomata as well. We prove Bagnol and Kuperberg's conjecture that the winner of\nthe 2-token game characterises history-determinism on parity automata.","main_category":"cs.FL","categories":"cs.FL","published":"2025-03-31T15:57:44Z"}
{"aid":"http://arxiv.org/abs/2503.24270v1","title":"Visual Acoustic Fields","summary":"Objects produce different sounds when hit, and humans can intuitively infer\nhow an object might sound based on its appearance and material properties.\nInspired by this intuition, we propose Visual Acoustic Fields, a framework that\nbridges hitting sounds and visual signals within a 3D space using 3D Gaussian\nSplatting (3DGS). Our approach features two key modules: sound generation and\nsound localization. The sound generation module leverages a conditional\ndiffusion model, which takes multiscale features rendered from a\nfeature-augmented 3DGS to generate realistic hitting sounds. Meanwhile, the\nsound localization module enables querying the 3D scene, represented by the\nfeature-augmented 3DGS, to localize hitting positions based on the sound\nsources. To support this framework, we introduce a novel pipeline for\ncollecting scene-level visual-sound sample pairs, achieving alignment between\ncaptured images, impact locations, and corresponding sounds. To the best of our\nknowledge, this is the first dataset to connect visual and acoustic signals in\na 3D context. Extensive experiments on our dataset demonstrate the\neffectiveness of Visual Acoustic Fields in generating plausible impact sounds\nand accurately localizing impact sources. Our project page is at\nhttps://yuelei0428.github.io/projects/Visual-Acoustic-Fields/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T16:16:10Z"}
{"aid":"http://arxiv.org/abs/2503.24290v1","title":"Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement\n  Learning on the Base Model","summary":"We introduce Open-Reasoner-Zero, the first open source implementation of\nlarge-scale reasoning-oriented RL training focusing on scalability, simplicity\nand accessibility. Through extensive experiments, we demonstrate that a\nminimalist approach, vanilla PPO with GAE ($\\lambda=1$, $\\gamma=1$) and\nstraightforward rule-based rewards, without any KL regularization, is\nsufficient to scale up both response length and benchmark performance, similar\nto the phenomenon observed in DeepSeek-R1-Zero. Using the same base model as\nDeepSeek-R1-Zero-Qwen-32B, our implementation achieves superior performance on\nAIME2024, MATH500, and the GPQA Diamond benchmark while demonstrating\nremarkable efficiency -- requiring only a tenth of the training steps, compared\nto DeepSeek-R1-Zero pipeline. In the spirit of open source, we release our\nsource code, parameter settings, training data, and model weights across\nvarious sizes.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-03-31T16:36:05Z"}
{"aid":"http://arxiv.org/abs/2503.24302v1","title":"Synergy of Doob Transformation and Montroll Defect Theory for Random\n  Walks in External Potentials","summary":"We present a systematic method for constructing stochastic processes by\nmodifying simpler, analytically solvable random walks on discrete lattices. Our\nframework integrates the Doob $h$-transformation with the Montroll defect\ntheory, overcoming the strict constraints associated with each method alone. By\ncombining these two approaches, we map random walks in simple potentials onto\nprocesses involving more general external potentials and metastable states.\nExplicit analytical expressions relate the transformed process to the original\none, facilitating direct investigation of exponential decay rates and\nadditional dynamical modes. As an illustrative example, we demonstrate our\nmethod by analyzing a random walker in a linear potential modified to include a\nmetastable state, revealing distinct exponential decay regimes relevant to\nescape dynamics.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T16:47:14Z"}
{"aid":"http://arxiv.org/abs/2503.24318v1","title":"Quantum Conference Key Agreement with Classical Advantage Distillation","summary":"In this work, we prove security of a quantum conference key agreement (QCKA)\nprotocol augmented with a classical advantage distillation (CAD) protocol. We\nderive a proof of security, in the finite key setting, that is able to bound\nthe secure key rate for any general, coherent, attack. We evaluate the\nperformance of the system, showing our result can improve the noise tolerance\nof the protocol in some, but not all, scenarios.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:07:36Z"}
{"aid":"http://arxiv.org/abs/2503.24323v1","title":"Synthesis of europium-based crystals containing As or P by a flux\n  method: attempts to grow EuAgP single crystals","summary":"Europium-based materials are highly attractive due to their diverse range of\nphysical properties. In these studies, we aimed to synthesize single crystals\nof the potentially topological semimetallic compound EuAgP, which up to this\nday has only been obtained in polycrystalline form. The flux method was\nemployed for the syntheses, using fluxes such as: Bi, Sn, Pb, and In, in their\nvarious ratios. The purpose of using Bi flux was to try synthesizing an analog\nof EuAgAs single crystals, by fully substituting arsenic with phosphorus. The\nobtained crystals were characterized by x-ray diffraction and scanning electron\nmicroscopy. Despite many unsuccessful attempts to synthesize EuAgP single\ncrystals, the study provides valuable insights into how different fluxes and\ntheir ratios influence the final synthesis product. It also underscores the\ncomplexity of designing analogs between arsenides and phosphides.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T17:10:04Z"}
{"aid":"http://arxiv.org/abs/2503.24338v1","title":"Spontaneous Emission from Electronic Metastable Resonance States","summary":"We demonstrate that calculating the spontaneous emission decay rate from\nmetastable resonance states (states with finite lifetimes embedded in the\ncontinuum) requires considering transitions to all continuum states, not just\nto lower states. This holds even when the lifetimes of the metastable states\nare very long and might be effectively considered as bound states in the\ncontinuum. However, employing complex-scaling transformations, this\ncomputationally prohibitive task becomes feasible by utilizing methods\noriginally designed for excited bound states for calculation of complex poles\nof the scattering matrix. As an illustrative example, these methods are applied\nto calculate the spontaneous emission decay rates of metastable resonance\nstates in a double-barrier potential. The rapid numerical convergence of this\napproach highlights a new avenue for studying spontaneous emission from\nmetastable states in real-life systems, particularly in many-electron systems,\nwhere calculation of the spontaneous emission decay rate from metastable\nresonances (e.g., autoionization states) is computationally difficult, if not\nimpossible, using the standard (Hermitian) formalism of quantum mechanics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:24:32Z"}
{"aid":"http://arxiv.org/abs/2503.24365v1","title":"Which LIME should I trust? Concepts, Challenges, and Solutions","summary":"As neural networks become dominant in essential systems, Explainable\nArtificial Intelligence (XAI) plays a crucial role in fostering trust and\ndetecting potential misbehavior of opaque models. LIME (Local Interpretable\nModel-agnostic Explanations) is among the most prominent model-agnostic\napproaches, generating explanations by approximating the behavior of black-box\nmodels around specific instances. Despite its popularity, LIME faces challenges\nrelated to fidelity, stability, and applicability to domain-specific problems.\nNumerous adaptations and enhancements have been proposed to address these\nissues, but the growing number of developments can be overwhelming,\ncomplicating efforts to navigate LIME-related research. To the best of our\nknowledge, this is the first survey to comprehensively explore and collect\nLIME's foundational concepts and known limitations. We categorize and compare\nits various enhancements, offering a structured taxonomy based on intermediate\nsteps and key issues. Our analysis provides a holistic overview of advancements\nin LIME, guiding future research and helping practitioners identify suitable\napproaches. Additionally, we provide a continuously updated interactive website\n(https://patrick-knab.github.io/which-lime-to-trust/), offering a concise and\naccessible overview of the survey.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T17:44:39Z"}
{"aid":"http://arxiv.org/abs/2503.24367v1","title":"The structure and topology of an amorphous metal-organic framework","summary":"Amorphous metal-organic frameworks are an important emerging materials class\nthat combine the attractive physical properties of the amorphous state with the\nversatility of metal-organic framework (MOF) chemistry. The structures of\namorphous MOFs have largely been inferred by drawing analogies to crystalline\npolymorphs and inorganic glasses, but ultimately the validity of such\nstructural models has been challenging to establish either experimentally or\ncomputationally. Here we use a unified data-driven approach, combining\nexperimental scattering data and active machine learning for interatomic\npotentials, to determine the structure of an amorphous zeolitic imidazolate\nframework (a-ZIF) -- the canonical amorphous MOF. Our results reveal clear\ndifferences between the structure of a-ZIF and that of other amorphous\ntetrahedral networks, allowing us to invalidate the long-standing assumption\nthat these inorganic and hybrid glasses are topologically equivalent. To this\nend, we introduce a systematic notation for the network topology of amorphous\nsolids, building a bridge to the successful use of topology analysis in\ncrystalline MOFs and to materials informatics. Our work provides insights into\nthe structure and topology of the archetypal amorphous MOF and opens up new\navenues for modelling and understanding amorphous framework materials more\ngenerally.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph","published":"2025-03-31T17:46:37Z"}
{"aid":"http://arxiv.org/abs/2504.01325v1","title":"Coarse chain recurrence, Morse graphs with finite errors, and\n  persistence of circulations","summary":"In flow control, finite energy may be injected to push out material trapped\nin the attractor and to eliminate stagnation and circulate the flow. To\ndescribe such phenomena and to give a lower bound on the energy required, we\ngeneralize the existing concepts of chain recurrence. In fact, this paper\nintroduces concepts of ``coarse chain recurrences'' and Morse graphs with\nfinite errors. Using these concepts, we describe toy models of escape from\nattracting basins and elimination of stagnation by controls using finite\nenergy, persistence of recurrent points, and singular limit behaviors where\nenergy injections go to zero. Furthermore, we construct filtrations associated\nwith dynamical systems, which indicate the persistence of circulations.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T03:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.01351v1","title":"Demonstration of Plate Analysis, an algorithm for precise relative\n  astrometry","summary":"Astrometry plays a crucial role in understanding the structure, dynamics, and\nevolution of celestial objects by providing precise measurements of their\npositions and motions. We propose a new approach to wide-field, relative\nastrometry, Plate Analysis. Plate Analysis is an innovative algorithm that\nestimates stellar coordinates and corrects geometric distortion based on\nprecise reference sources, without relying on dedicated calibration fields. It\nis implemented as a probabilistic framework using Stochastic Variational\nInference to efficiently optimize the numerous parameters involved in the\nmodel.\n  The methodology was tested through a simplified simulation designed after the\nGalactic center survey of the JASMINE mission. This simulation, called the\nJASMINE mini-mock survey, covered three years of observation with 100 satellite\norbits, providing a comprehensive dataset for evaluating the performance of\nPlate Analysis. Although the observation model incorporated more than 30,000\nparameters, the parameters were efficiently optimized through Plate Analysis.\nThe results showed that the estimated coordinates closely match the expected\nstellar motions, with an average positional error of about $70\\,\\mathrm{\\mu\nas}$. These findings validate the potential of Plate Analysis for precise\nwide-field astrometric applications, offering significant insights into\nimproving the accuracy of stellar dynamics measurements.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T04:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.01356v1","title":"xML-workFlow: an end-to-end explainable scikit-learn workflow for rapid\n  biomedical experimentation","summary":"Motivation: Building and iterating machine learning models is often a\nresource-intensive process. In biomedical research, scientific codebases can\nlack scalability and are not easily transferable to work beyond what they were\nintended. xML-workFlow addresses this issue by providing a rapid, robust, and\ntraceable end-to-end workflow that can be adapted to any ML project with\nminimal code rewriting.\n  Results: We show a practical, end-to-end workflow that integrates\nscikit-learn, MLflow, and SHAP. This template significantly reduces the time\nand effort required to build and iterate on ML models, addressing the common\nchallenges of scalability and reproducibility in biomedical research. Adapting\nour template may save bioinformaticians time in development and enables\nbiomedical researchers to deploy ML projects.\n  Availability and implementation: xML-workFlow is available at\nhttps://github.com/MedicalGenomicsLab/xML-workFlow.","main_category":"cs.LG","categories":"cs.LG,cs.SE","published":"2025-04-02T05:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.01401v1","title":"Systematic study of α-decay half-lives of superheavy nuclei based\n  on Coulomb and proximity potential models with temperature effects","summary":"By employing the Coulomb proximity potential model (CPPM) in conjunction with\n22 distinct proximity potential models, we investigated the temperature\ndependence and the effects of proton number and neutron number on the diffusion\nparameters that determine the {\\alpha}-decay half-lives of superheavy nuclei.\nThe results indicate that the Prox.77-3 T-DEP proximity potential model yields\nthe best performance, with the lowest root mean square deviation\n({\\sigma}=0.515), reflecting a high consistency with experimental data. In\ncontrast, Bass77, AW95, Ngo80, and Guo2013 display larger deviations. The\ninclusion of temperature dependence significantly improves the accuracy of\nmodels such as Prox.77-3, Prox.77-6, and Prox.77-7. The -decay half-lives of 36\npotential superheavy nuclei were further predicted using the five most accurate\nproximity potential models and Ni's empirical formula, with the results\naligning well with experimental data. These predictions underscore the high\nreliability of the CPPM combined with proximity potential models in the\ntheoretical calculation of {\\alpha}-decay half-lives of superheavy nuclei,\noffering valuable theoretical insights for future experimental investigations\nof superheavy nuclei.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-02T06:39:48Z"}
{"aid":"http://arxiv.org/abs/2504.01404v1","title":"LLM4SZZ: Enhancing SZZ Algorithm with Context-Enhanced Assessment on\n  Large Language Models","summary":"The SZZ algorithm is the dominant technique for identifying bug-inducing\ncommits and serves as a foundation for many software engineering studies, such\nas bug prediction and static code analysis. Researchers have proposed many\nvariants to enhance the SZZ algorithm's performance since its introduction. The\nmajority of them rely on static techniques or heuristic assumptions, making\nthem easy to implement, but their performance improvements are often limited.\nRecently, a deep learning-based SZZ algorithm has been introduced to enhance\nthe original SZZ algorithm. However, it requires complex preprocessing and is\nrestricted to a single programming language. Additionally, while it enhances\nprecision, it sacrifices recall. Furthermore, most of variants overlook crucial\ninformation, such as commit messages and patch context, and are limited to\nbug-fixing commits involving deleted lines. The emergence of large language\nmodels (LLMs) offers an opportunity to address these drawbacks. In this study,\nwe investigate the strengths and limitations of LLMs and propose LLM4SZZ, which\nemploys two approaches (i.e., rank-based identification and context-enhanced\nidentification) to handle different types of bug-fixing commits. We determine\nwhich approach to adopt based on the LLM's ability to comprehend the bug and\nidentify whether the bug is present in a commit. The context-enhanced\nidentification provides the LLM with more context and requires it to find the\nbug-inducing commit among a set of candidate commits. In rank-based\nidentification, we ask the LLM to select buggy statements from the bug-fixing\ncommit and rank them based on their relevance to the root cause. Experimental\nresults show that LLM4SZZ outperforms all baselines across three datasets,\nimproving F1-score by 6.9% to 16.0% without significantly sacrificing recall.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T06:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.01414v1","title":"Balancing Subjectivity and Objectivity in Network Selection: A\n  Decision-Making Framework Towards Digital Twins","summary":"Selecting the optimal radio access technology (RAT) during vertical handovers\n(VHO) in heterogeneous wireless networks (HWNs) is critical. Multi-attribute\ndecision-making (MADM) is the most common approach used for network selection\n(NS) in HWNs. However, existing MADM-NS methods face two major challenges: the\nrank reversal problem (RRP), where the relative ranking of alternatives changes\nunexpectedly, and inefficient handling of user and/or service requirements.\nThese limitations result in suboptimal RAT selection and diminished quality of\nservice, which becomes particularly critical for time-sensitive applications.\nTo address these issues, we introduce in this work a novel weighting assignment\ntechnique called BWM-GWO, which integrates the Best-Worst Method (BWM) with the\nGrey Wolf Optimization (GWO) algorithm through a convex linear combination. The\nproposed framework achieves a balanced decision-making process by using BWM to\ncompute subjective weights that capture user/service preferences, while\nemploying GWO to derive objective weights aimed at minimizing RRP. The\ndevelopment and validation of this framework establish a digital model for NS\nin HWNs, marking the initial step toward realizing a digital twin (DT).\nExperimental results show that integrating the proposed BWM-GWO technique with\nMADM-NS reduces RRP occurrence by up to 71.3% while significantly improving\nuser and service satisfaction compared to benchmark approaches.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T07:06:58Z"}
{"aid":"http://arxiv.org/abs/2504.01424v1","title":"On the Role of Priors in Bayesian Causal Learning","summary":"In this work, we investigate causal learning of independent causal mechanisms\nfrom a Bayesian perspective. Confirming previous claims from the literature, we\nshow in a didactically accessible manner that unlabeled data (i.e., cause\nrealizations) do not improve the estimation of the parameters defining the\nmechanism. Furthermore, we observe the importance of choosing an appropriate\nprior for the cause and mechanism parameters, respectively. Specifically, we\nshow that a factorized prior results in a factorized posterior, which resonates\nwith Janzing and Sch\\\"olkopf's definition of independent causal mechanisms via\nthe Kolmogorov complexity of the involved distributions and with the concept of\nparameter independence of Heckerman et al.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T07:19:49Z"}
{"aid":"http://arxiv.org/abs/2504.01426v1","title":"Temperature and misorientation-dependent austenite nucleation at ferrite\n  grain boundaries in a medium manganese steel: role of\n  misorientation-dependent grain boundary segregation","summary":"In the current work, we study the role of grain boundary (GB)\nmisorientation-dependent segregation on austenite nucleation in a 50% cold\nrolled intercritically annealed 10Mn-0.05C-1.5Al (wt. %) medium Mn steel.\nDuring intercritical annealing at 500{\\deg}C, austenite nucleates predominantly\nat high-angle GBs. At 600{\\deg}C, austenite nucleates additionally at low-angle\nGBs, exhibiting a temperature dependance. Correlative transmission Kikuchi\ndiffraction /atom probe tomography reveals a misorientation-dependent\nsegregation. While GB segregation has been reported to assist austenite\nnucleation in medium manganese steels (3-12 wt.% Mn), an understanding of the\ntemperature and misorientation dependance is lacking, which is the aim of\ncurrent work. Since artifacts of atom probe can cause a broadening of the\nsegregation width, we combined experiments with results from density functional\ntheory (DFT) calculations that reveal that the Mn segregation is not limited to\nthe GB plane but confined to a region in the range of approximately 1 nm.\nConsequently, GB segregation alters both the GB interface energy and the free\nenergy per unit volume corresponding to the transformation. We estimate the\nlocal driving force for austenite nucleation accounting for the segregation\nwidth of ~ 1 nm. Based on classical nucleation theory, we clarify the effect of\nGB segregation on the critical radius and activation energy barrier for\nconfined austenite nucleation at the GB.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T07:22:43Z"}
{"aid":"http://arxiv.org/abs/2504.01456v1","title":"Multiscale exploration of SMACS J0723.3--7327's intracluster light and\n  past dynamical history","summary":"In this work an analysis of the intracluster light (ICL) in the galaxy\ncluster SMACS J0723.3-7327 (hereafter, SMACS J0723) using JWST/NIRCam deep\nimaging in six filters (F090W to F444W) is presented. The images were processed\nfor low surface brightness (LSB) science, with additional correction for\ninstrumental scattering in the short-wavelength channels, and analysed using\nwavelet-based decomposition. The ICL, brightest cluster galaxy (BCG), and\nsatellite galaxies were extracted and modelled, with 2D maps for each\ncomponent. ICL and ICL+BCG fractions, computed across all filters within a 400\nkpc radius, exhibit a flat trend with wavelength, averaging 28% and 34%,\nrespectively. Flux ratios between the BCG and the next brightest members\n(M$_{12}$, M$_{13}$ and M$_{14}$) also display minimal wavelength dependence.\nThese results indicate that SMACS J0723 is a dynamically evolved cluster with a\ndominant BCG and well-developed ICL. Five prominent ICL substructures are\nanalysed, contributing to 10-12% of the total ICL+BCG flux budget, slightly\nexceeding simulation predictions. Their short dynamical timescales suggest an\ninstantaneous ICL injection rate of several $10^3 L_{\\odot}\\,{\\rm yr}^{-1}$,\nconsistent with active dynamical assembly. These findings support a scenario\nwhere SMACS J0723's ICL growth is currently driven by galaxy mergers involving\nthe BCG and other bright satellites, rather than by the accretion of\npre-processed ICL from a recent cluster merger. However, extrapolating the\ncurrent injection rate to the cluster's lifetime indicates that additional\nmechanisms are required to match the growth observed in other clusters over\ncosmic times.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T08:10:05Z"}
{"aid":"http://arxiv.org/abs/2504.01483v1","title":"GarmageNet: A Dataset and Scalable Representation for Generic Garment\n  Modeling","summary":"High-fidelity garment modeling remains challenging due to the lack of\nlarge-scale, high-quality datasets and efficient representations capable of\nhandling non-watertight, multi-layer geometries. In this work, we introduce\nGarmage, a neural-network-and-CG-friendly garment representation that\nseamlessly encodes the accurate geometry and sewing pattern of complex\nmulti-layered garments as a structured set of per-panel geometry images. As a\ndual-2D-3D representation, Garmage achieves an unprecedented integration of 2D\nimage-based algorithms with 3D modeling workflows, enabling high fidelity,\nnon-watertight, multi-layered garment geometries with direct compatibility for\nindustrial-grade simulations.Built upon this representation, we present\nGarmageNet, a novel generation framework capable of producing detailed\nmulti-layered garments with body-conforming initial geometries and intricate\nsewing patterns, based on user prompts or existing in-the-wild sewing patterns.\nFurthermore, we introduce a robust stitching algorithm that recovers per-vertex\nstitches, ensuring seamless integration into flexible simulation pipelines for\ndownstream editing of sewing patterns, material properties, and dynamic\nsimulations. Finally, we release an industrial-standard, large-scale,\nhigh-fidelity garment dataset featuring detailed annotations, vertex-wise\ncorrespondences, and a robust pipeline for converting unstructured production\nsewing patterns into GarmageNet standard structural assets, paving the way for\nlarge-scale, industrial-grade garment generation systems.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-02T08:37:32Z"}
{"aid":"http://arxiv.org/abs/2504.01489v1","title":"Test-Time Alignment for Tracking User Interest Shifts in Sequential\n  Recommendation","summary":"Sequential recommendation is essential in modern recommender systems, aiming\nto predict the next item a user may interact with based on their historical\nbehaviors. However, real-world scenarios are often dynamic and subject to\nshifts in user interests. Conventional sequential recommendation models are\ntypically trained on static historical data, limiting their ability to adapt to\nsuch shifts and resulting in significant performance degradation during\ntesting. Recently, Test-Time Training (TTT) has emerged as a promising\nparadigm, enabling pre-trained models to dynamically adapt to test data by\nleveraging unlabeled examples during testing. However, applying TTT to\neffectively track and address user interest shifts in recommender systems\nremains an open and challenging problem. Key challenges include how to capture\ntemporal information effectively and explicitly identifying shifts in user\ninterests during the testing phase. To address these issues, we propose\nT$^2$ARec, a novel model leveraging state space model for TTT by introducing\ntwo Test-Time Alignment modules tailored for sequential recommendation,\neffectively capturing the distribution shifts in user interest patterns over\ntime. Specifically, T$^2$ARec aligns absolute time intervals with\nmodel-adaptive learning intervals to capture temporal dynamics and introduce an\ninterest state alignment mechanism to effectively and explicitly identify the\nuser interest shifts with theoretical guarantees. These two alignment modules\nenable efficient and incremental updates to model parameters in a\nself-supervised manner during testing, enhancing predictions for online\nrecommendation. Extensive evaluations on three benchmark datasets demonstrate\nthat T$^2$ARec achieves state-of-the-art performance and robustly mitigates the\nchallenges posed by user interest shifts.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-02T08:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.01510v1","title":"Surface forces and frictional properties of adsorbed bio-based cationic\n  polysaccharide thin films in salted aqueous medium","summary":"Inter-surface forces mediated by polymer films are important in a range of\ntechnological and industrial situations. In cosmetics, applications such as\nhair conditioning typically rely on the adsorption of polyelectrolyte films\nonto the charged surface of hair fibers, whose contact mechanics and\ntribological properties are central in determining the final sensorial\nperceptions associated with the cosmetic treatment. A major current challenge\nto be tackled by the cosmetic industry is to design high-performance products\nemploying bio-sourced polyelectrolytes, with the aim of achieving\neco-sustainable processes and products. In this context, the present study\nfocuses on the mechanical properties of thin films obtained by adsorption from\nsolution of fungal chitosan onto negatively charged mica surfaces. We use a\nSurface Forces Apparatus allowing for the simultaneous measurement of film\nthickness and friction force as a function of the applied normal load and shear\nvelocity. We show that, in aqueous medium at an ionic strength of 40 mM,\nadsorbed films of chitosan give rise to repulsive inter-surface forces whose\nrange, comparable to the Flory radius of the macromolecules, increases with the\npolymer molecular weight. In addition, the adsorbed layers are found to behave,\nunder compressive forces, as pseudo-brushes of neutral polymers. Finally, we\nshow that under shear forces, chitosan layers exhibit a transition from a low\nto a high friction regime under increasing confinement.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T08:57:56Z"}
{"aid":"http://arxiv.org/abs/2504.01527v1","title":"Beyond Nearest Neighbor Interpolation in Data Augmentation","summary":"Avoiding the risk of undefined categorical labels using nearest neighbor\ninterpolation overlooks the risk of exacerbating pixel level annotation errors\nin data augmentation. To simultaneously avoid these risks, the author modified\nconvolutional neural networks data transformation functions by incorporating a\nmodified geometric transformation function to improve the quality of augmented\ndata by removing the reliance on nearest neighbor interpolation and integrating\na mean based class filtering mechanism to handle undefined categorical labels\nwith alternative interpolation algorithms. Experiments on semantic segmentation\ntasks using three medical image datasets demonstrated both qualitative and\nquantitative improvements with alternative interpolation algorithms.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.01539v1","title":"Black hole solutions in quantum phenomenological gravitational dynamics","summary":"We investigate black hole solutions within a phenomenological approach to\nquantum gravity based on spacetime thermodynamics developed by Alonso-Serrano\nand Li\\v{s}ka. The field equations are traceless, similarly to unimodular\ngravity, and include quadratic curvature corrections. We find that static,\nspherically symmetric, vacuum spacetimes in this theory split into two\nbranches. The first branch is indistinguishable from corresponding solutions in\nunimodular gravity and describes Schwarzschild-(Anti) de Sitter black holes.\nThe second branch instead describes horizonless solutions and is characterized\nby large values of the spatial curvature. We analyze the dynamics of\nfirst-order metric perturbations on both branches, showing that there are no\ndeviations from unimodular gravity at this level.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-02T09:26:01Z"}
{"aid":"http://arxiv.org/abs/2504.01585v1","title":"Nonlinear Bandwidth and Bode Diagrams based on Scaled Relative Graphs","summary":"Scaled Relative Graphs (SRGs) provide a novel graphical frequency domain\nmethod for the analysis of nonlinear systems. In this paper, we use the\nrestriction of the SRG to particular input spaces to compute\nfrequency-dependent gain bounds for incrementally stable nonlinear systems.\nThis leads to a nonlinear (NL) generalization of the Bode diagram, where the\nsinusoidal, harmonic, and subharmonic inputs are considered separately. When\napplied to the analysis of the NL loop transfer and sensitivity, we define a\nnotion of bandwidth for both the open-loop and closed-loop, compatible with the\nLTI definitions. We illustrate the power of our method on the analysis of a DC\nmotor with a parasitic nonlinearity, verifying our results in simulations.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-02T10:41:49Z"}
{"aid":"http://arxiv.org/abs/2504.01609v1","title":"The Mini-SiTian Array: the mini-SiTian Realtime Image Processing\n  pipeline (STRIP)","summary":"This paper provides a comprehensive introduction to the Mini-SiTian Real-Time\nImage Processing pipeline (STRIP) and evaluates its operational performance.\nThe STRIP pipeline is specifically designed for real-time alert triggering and\nlight curve generation for transient sources. By applying the STRIP pipeline to\nboth simulated and real observational data of the Mini-SiTian survey, it\nsuccessfully identified various types of variable sources, including stellar\nflares, supernovae, variable stars, and asteroids, while meeting requirements\nof reduction speed within 5 minutes. For the real observational dataset, the\npipeline detected 1 flare event, 127 variable stars, and 14 asteroids from\nthree monitored sky regions. Additionally, two datasets were generated: one, a\nreal-bogus training dataset comprising 218,818 training samples, and the other,\na variable star light curve dataset with 421 instances. These datasets will be\nused to train machine learning algorithms, which are planned for future\nintegration into STRIP.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-02T11:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.01629v1","title":"A 0.3\\% calibration of the W UMa-type contact binary luminosity based on\n  Gaia DR3","summary":"W Ursa Majoris (W UMa)-type contact binary systems (CBs) with\nperiod--luminosity (PL) relations are valuable distance indicators. The PL\nrelations of CBs are affected by metallicity. Here, we establish PL relations\nand period--luminosity--metallicity (PLZ) relations in nine bands from optical\nto mid-infrared ($BP$, $G$, $RP$, $J$, $H$, $K_S$, $W1$, $W2$, $W3$) and in\nfive Wesenheit bands based on Gaia DR3 parallaxes. The dispersion of PLZ\nrelations gradually decreases from the optical to mid-infrared bands, with the\nminimum dispersion of 0.138 mag. We fit the best PL relations for three bands\n($W1$, $W_{G,BP,RP}$, $W_{W1,BP,RP}$) under different parallax uncertainty\ncriteria and determine a parallax (after correction) zero point of\n$zp_\\varpi=24\\pm4$ $\\mu$as. After fixing the parallax zero point, we find that\nthe total zero errors of the PL and PLZ relation are smallest when the parallax\nuncertainty is less than 2\\%, resulting in a calibrated CB luminosity with an\naccuracy of 0.33\\%, which is more accurate than the classical Cepheids.\nFurthermore, by examining the absolute magnitude residuals in different\nmetallicity intervals, we find that the use of a linear metallicity effect is\nappropriate for CBs with different metallicities. These results indicate that\nCBs are excellent standard candles.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-02T11:36:46Z"}
{"aid":"http://arxiv.org/abs/2504.01631v1","title":"Constructive Decompositions of the Identity for Functional John\n  Ellipsoids","summary":"We consider functional ellipsoids in the sense defined by Ivanov and\nNasz\\'odi and we study the problem of constructing a decomposition of the\nidentity similar to the one given by Fritz John in his fundamental theorem.","main_category":"math.FA","categories":"math.FA,math.DG","published":"2025-04-02T11:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.01634v1","title":"Shape Anisotropy Enabled Field Free Switching of Perpendicular\n  Nanomagnets","summary":"Spin Orbit Torque-Magnetic Random Access Memory (SOT-MRAM) is being developed\nas a successor to the Spin transfer torque MRAM (STT-MRAM) owing to its\nsuperior performance on the metrics of reliability and read-write speed. SOT\nswitching of perpendicularly magnetized ferromagnet in the heavy\nmetal/ferromagnet bilayer of SOT-MRAM unit cell requires an additional external\nmagnetic field to support the spin-orbit torque generated by heavy metal to\ncause deterministic switching. This complexity can be overcome if an internal\nfield can be generated to break the switching symmetry. We experimentally\ndemonstrate that by engineering the shape of ferromagnet, an internal magnetic\nfield capable of breaking the switching symmetry can be generated, which allows\nfor deterministic switching by spin-orbit torques. We fabricated nanomagnets of\nCobalt with triangular shape on top of Platinum and showed external magnetic\nfield free switching between the two stable states of magnetization by\napplication of nano-second voltage pulses. The experimental findings are\nconsistent with the micro-magnetic simulation results of the proposed geometry.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-02T11:40:10Z"}
{"aid":"http://arxiv.org/abs/2504.01648v1","title":"ProtoGuard-guided PROPEL: Class-Aware Prototype Enhancement and\n  Progressive Labeling for Incremental 3D Point Cloud Segmentation","summary":"3D point cloud semantic segmentation technology has been widely used.\nHowever, in real-world scenarios, the environment is evolving. Thus,\noffline-trained segmentation models may lead to catastrophic forgetting of\npreviously seen classes. Class-incremental learning (CIL) is designed to\naddress the problem of catastrophic forgetting. While point clouds are common,\nwe observe high similarity and unclear boundaries between different classes.\nMeanwhile, they are known to be imbalanced in class distribution. These lead to\nissues including misclassification between similar classes and the long-tail\nproblem, which have not been adequately addressed in previous CIL methods. We\nthus propose ProtoGuard and PROPEL (Progressive Refinement Of PsEudo-Labels).\nIn the base-class training phase, ProtoGuard maintains geometric and semantic\nprototypes for each class, which are combined into prototype features using an\nattention mechanism. In the novel-class training phase, PROPEL inherits the\nbase feature extractor and classifier, guiding pseudo-label propagation and\nupdates based on density distribution and semantic similarity. Extensive\nexperiments show that our approach achieves remarkable results on both the\nS3DIS and ScanNet datasets, improving the mIoU of 3D point cloud segmentation\nby a maximum of 20.39% under the 5-step CIL scenario on S3DIS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T11:58:04Z"}
{"aid":"http://arxiv.org/abs/2504.01650v1","title":"Sparse Gaussian Neural Processes","summary":"Despite significant recent advances in probabilistic meta-learning, it is\ncommon for practitioners to avoid using deep learning models due to a\ncomparative lack of interpretability. Instead, many practitioners simply use\nnon-meta-models such as Gaussian processes with interpretable priors, and\nconduct the tedious procedure of training their model from scratch for each\ntask they encounter. While this is justifiable for tasks with a limited number\nof data points, the cubic computational cost of exact Gaussian process\ninference renders this prohibitive when each task has many observations. To\nremedy this, we introduce a family of models that meta-learn sparse Gaussian\nprocess inference. Not only does this enable rapid prediction on new tasks with\nsparse Gaussian processes, but since our models have clear interpretations as\nmembers of the neural process family, it also allows manual elicitation of\npriors in a neural process for the first time. In meta-learning regimes for\nwhich the number of observed tasks is small or for which expert domain\nknowledge is available, this offers a crucial advantage.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-02T12:00:09Z"}
{"aid":"http://arxiv.org/abs/2504.01657v1","title":"Impact of Small-Scale Gravity Waves on Tracer Transport","summary":"Small-scale gravity waves play a crucial role in atmospheric tracer\ntransport, yet their effects remain unresolved in climate models and must be\nparameterized. This study investigates how gravity waves influence large-scale\ntracer distributions, utilizing a multiple-scale analysis to systematically\nidentify the governing terms of gravity wave-induced tracer fluxes. The\nanalysis reveals both leading-order and next-order impacts: the former being\nthe inertia-gravity wave-induced tracer Stokes drift, which acts perpendicular\nto both the large-scale tracer gradient and the wave number, while the latter\nbecomes significant at lower latitudes where Coriolis effects diminish. A\nnumerical framework is developed to incorporate these fluxes into a gravity\nwave parameterization model, potentially enhancing climate model accuracy\nwithout requiring explicit resolution of small-scale wave dynamics. Model\nvalidation against high-resolution wave-resolving simulations confirms the\neffectiveness of this approach. By improving the representation of gravity\nwave-induced tracer transport, this research advances the accuracy of climate\nsimulations, particularly in their depiction of microphysics and radiative\nprocesses.","main_category":"physics.ao-ph","categories":"physics.ao-ph,physics.flu-dyn","published":"2025-04-02T12:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.01682v1","title":"A result on certain sums of element orders in finite groups","summary":"Given a finite group $G$ of order $p^nm$, where $p$ is a prime and $p\\nmid\nm$, we denote by $\\psi_p(G)$ the sum of orders of $p$-parts of elements in $G$.\nIn the current note, we prove that $\\psi_p(G)\\leq\\psi_p(C_{p^nm})$, where\n$C_{p^nm}$ is the cyclic group of order $p^nm$, and the equality holds if and\nonly if $G$ is $p$-nilpotent of a particular type. A generalization of this\nresult is also presented.","main_category":"math.GR","categories":"math.GR","published":"2025-04-02T12:29:27Z"}
{"aid":"http://arxiv.org/abs/2504.01693v1","title":"$SL_k$-Tilings and Paths in $\\mathbb{Z}^k$","summary":"An $SL_k$-tiling is a bi-infinite array of integers having all adjacent\n$k\\times k$ minors equal to one and all adjacent $(k+1)\\times (k+1)$ minors\nequal to zero. Introduced and studied by Bergeron and Reutenauer,\n$SL_k$-tilings generalize the notion of Conway-Coxeter frieze patterns in the\ncase $k=2$. In a recent paper, Short showed a bijection between bi-infinite\npaths of reduced rationals in the Farey graph and $SL_2$-tilings. We extend\nthis result to higher $k$ by constructing a bijection between $SL_k$-tilings\nand certain pairs of bi-infinite strips of vectors in $\\mathbb{Z}^k$ called\npaths. The key ingredient in the proof is the connection to Pl\\\"ucker friezes\nand Grassmannian cluster algebras. As an application, we obtain results about\nperiodicity, duality, and positivity for tilings.","main_category":"math.CO","categories":"math.CO,math.RA,math.RT","published":"2025-04-02T12:49:39Z"}
{"aid":"http://arxiv.org/abs/2504.01696v1","title":"On anticyclotomic Selmer groups of elliptic curves","summary":"Let $p\\geq5$ be a prime number and let $K$ be an imaginary quadratic field\nwhere $p$ is unramified. Under mild technical assumptions, in this paper we\nprove the non-existence of non-trivial finite $\\Lambda$-submodules of\nPontryagin duals of signed Selmer groups of a $p$-supersingular rational\nelliptic curve over the anticyclotomic $\\mathbb Z_p$-extension of $K$, where\n$\\Lambda$ is the corresponding Iwasawa algebra. In particular, we work under\nthe assumption that our plus/minus Selmer groups have $\\Lambda$-corank $1$, so\nthey are not $\\Lambda$-cotorsion. Our main theorem extends to the supersinular\ncase analogous non-existence results by Bertolini in the ordinary setting;\nfurthermore, since we cover the case where $p$ is inert in $K$, we refine\nprevious results of Hatley-Lei-Vigni, which deal with $p$-supersingular\nelliptic curves under the assumption that $p$ splits in $K$.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-02T12:55:15Z"}
{"aid":"http://arxiv.org/abs/2504.01718v1","title":"A Novel Dynamic Epidemic Model for Successive Opinion Diffusion in\n  Social Networks","summary":"This paper proposes a dynamic epidemic model for successive opinion diffusion\nin social networks, extending the SHIMR model. It incorporates dynamic\ndecision-making influenced by social distances and captures accumulative\nopinion diffusion caused by interrelated rumors. The model reflects the impact\nof rumor spread on social network structures. Simulations validate its\neffectiveness in explaining phenomena like the echo chamber effect and provide\ninsights into opinion diffusion dynamics, with implications for understanding\nsocial polarization and network evolution.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-02T13:26:30Z"}
{"aid":"http://arxiv.org/abs/2504.01729v1","title":"On the effect of the Coriolis force on the enstrophy cascade","summary":"We study the direct enstrophy cascade at small spatial scales in\nstatistically stationary forced-dissipated 2D Navier-Stokes equations subject\nto the Coriolis force in the $\\beta$-plane approximation. We provide sufficient\nconditions inspired by [6,63] to prove that at small scales, in the presence of\nthe Coriolis force, the so-called third-order structure function's asymptotics\nfollows the third-order universal law of 2D turbulence without the Coriolis\nforce. Our result indicates that at small scales, the enstrophy flux from\nlarger to smaller scales is not affected by the Coriolis force, confirming\nexperimental and numerical observations. To the best of our knowledge, this is\nthe first mathematically rigorous study of the above equations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T13:38:32Z"}
{"aid":"http://arxiv.org/abs/2504.01794v1","title":"On the regularity of entropy solutions to stochastic degenerate\n  parabolic equations","summary":"We study the regularity of entropy solutions for quasilinear parabolic\nequations with anisotropic degeneracy and stochastic forcing. Building on\nprevious works, we establish space-time regularity under a non-degeneracy\ncondition that does not require an assumption on the derivative of the symbol\nof the corresponding kinetic equation, a restriction imposed in earlier\nstudies. This allows us to obtain regularity results for certain equations not\naccounted for by prior theory, albeit with reduced regularity exponents. Our\napproach uses a kinetic formulation with two transport equations, one of second\norder and one of first order, leveraging a form of \"parabolic regularity\"\ninherent in these equations that was not utilized in previous studies.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T15:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.01796v1","title":"A New Approach to the Nonparametric Behrens-Fisher Problem with\n  Compatible Confidence Intervals","summary":"We propose a new test to address the nonparametric Behrens-Fisher problem\ninvolving different distribution functions in the two samples. Our procedure\ntests the null hypothesis $\\mathcal{H}_0: \\theta = \\frac{1}{2}$, where $\\theta\n= P(X<Y) + \\frac{1}{2}P(X=Y)$ denotes the Mann-Whitney effect. No restrictions\non the underlying distributions of the data are imposed with the trivial\nexception of one-point distributions. The method is based on evaluating the\nratio of the variance $\\sigma_N^2$ of the Mann-Whitney effect estimator\n$\\widehat{\\theta}$ to its theoretical maximum, as derived from the\nBirnbaum-Klose inequality. Through simulations, we demonstrate that the\nproposed test effectively controls the type-I error rate under various\nconditions, including small sample sizes, unbalanced designs, and different\ndata-generating mechanisms. Notably, it provides better control of the type-1\nerror rate compared to the widely used Brunner-Munzel test, particularly at\nsmall significance levels such as $\\alpha \\in \\{0.01, 0.005\\}$. Additionally,\nwe derive range-preserving compatible confidence intervals, showing that they\noffer improved coverage over those compatible to the Brunner-Munzel test.\nFinally, we illustrate the application of our method in a clinical trial\nexample.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-02T15:03:01Z"}
{"aid":"http://arxiv.org/abs/2504.01804v1","title":"US National Input to the European Strategy Update for Particle Physics","summary":"In this document we summarize the output of the US community planning\nexercises for particle physics that were performed between 2020 and 2023 and\ncomment upon progress made since then towards our common scientific goals. This\ndocument leans heavily on the formal report of the Particle Physics Project\nPrioritization Panel and other recent US planning documents, often quoting them\nverbatim to retain the community consensus.","main_category":"hep-ex","categories":"hep-ex,nucl-ex","published":"2025-04-02T15:12:04Z"}
{"aid":"http://arxiv.org/abs/2504.01818v1","title":"Efficient Constant-Space Multi-Vector Retrieval","summary":"Multi-vector retrieval methods, exemplified by the ColBERT architecture, have\nshown substantial promise for retrieval by providing strong trade-offs in terms\nof retrieval latency and effectiveness. However, they come at a high cost in\nterms of storage since a (potentially compressed) vector needs to be stored for\nevery token in the input collection. To overcome this issue, we propose\nencoding documents to a fixed number of vectors, which are no longer\nnecessarily tied to the input tokens. Beyond reducing the storage costs, our\napproach has the advantage that document representations become of a fixed size\non disk, allowing for better OS paging management. Through experiments using\nthe MSMARCO passage corpus and BEIR with the ColBERT-v2 architecture, a\nrepresentative multi-vector ranking model architecture, we find that passages\ncan be effectively encoded into a fixed number of vectors while retaining most\nof the original effectiveness.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-02T15:22:23Z"}
{"aid":"http://arxiv.org/abs/2504.01832v1","title":"Quantum Meets SAR: A Novel Range-Doppler Algorithm for Next-Gen Earth\n  Observation","summary":"Synthetic aperture radar (SAR) data processing is crucial for high-resolution\nEarth observation and remote sensing applications, one of the most commonly\nused algorithms for this task is the Range Doppler Algorithm (RDA). Using the\nFast Fourier Transform (FFT), the collected signal is transformed to the\nfrequency domain and then goes through the processing steps of this algorithm.\nHowever, when it comes to large datasets, this process can be computationally\nexpensive. This paper explores the implementation of a Quantum Range Doppler\nAlgorithm (QRDA), relying on the Quantum Fourier Transform (QFT) as a speedup\ntool over the classical FFT. Additionally, it proposes a quantum version of the\nRange Cell Migration Correction (RCMC) in the Fourier domain, one of the key\ncorrectional steps of the RDA algorithm, and compares it with its classical\ncounterpart.","main_category":"quant-ph","categories":"quant-ph,eess.SP","published":"2025-04-02T15:40:12Z"}
{"aid":"http://arxiv.org/abs/2504.01833v1","title":"YourBench: Easy Custom Evaluation Sets for Everyone","summary":"Evaluating large language models (LLMs) effectively remains a critical\nbottleneck, as traditional static benchmarks suffer from saturation and\ncontamination, while human evaluations are costly and slow. This hinders timely\nor domain-specific assessment, crucial for real-world applications. We\nintroduce YourBench, a novel, open-source framework that addresses these\nlimitations by enabling dynamic, automated generation of reliable, up-to-date,\nand domain-tailored benchmarks cheaply and without manual annotation, directly\nfrom user-provided documents. We demonstrate its efficacy by replicating 7\ndiverse MMLU subsets using minimal source text, achieving this for under 15 USD\nin total inference costs while perfectly preserving the relative model\nperformance rankings (Spearman Rho = 1) observed on the original benchmark. To\nensure that YourBench generates data grounded in provided input instead of\nrelying on posterior parametric knowledge in models, we also introduce\nTempora-0325, a novel dataset of over 7K diverse documents, published\nexclusively after March 2025. Our comprehensive analysis spans 26 SoTA models\nfrom 7 major families across varying scales (3-671B parameters) to validate the\nquality of generated evaluations through rigorous algorithmic checks (e.g.,\ncitation grounding) and human assessments. We release the YourBench library,\nthe Tempora-0325 dataset, 150k+ question answer pairs based on Tempora and all\nevaluation and inference traces to facilitate reproducible research and empower\nthe community to generate bespoke benchmarks on demand, fostering more relevant\nand trustworthy LLM evaluation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2.1","published":"2025-04-02T15:40:24Z"}
{"aid":"http://arxiv.org/abs/2504.01845v1","title":"Dust environment of long-period comet C/2023 A3 (Tsuchinshan-ATLAS)","summary":"We present a characterization of the dust environment of long-period comet\nC/2023 A3 (Tsuchinshan-ATLAS) by analyzing an extensive dataset, including dust\ntail images and photometric measurements, from 10 au pre-perihelion to 1.6 au\npost-perihelion, using our forward Monte Carlo code. For this analysis, we\ncombine pre-perihelion images from the Zwicky Transient Facility with\npost-perihelion images from the Sierra Nevada Observatory (IAA-CSIC, Granada,\nSpain), along with both amateur and professional photometric measurements,\nincluding Af$\\rho$ and magnitude data. We find that the dust loss rate\nincreases monotonically from the assumed start of activity at a heliocentric\ndistance of approximately 15 au down to 4 au inbound, where the comet exhibits\na notable decrease in dust production by about one order of magnitude.\nFollowing this period of reduced activity, the dust production rate rises again\ntoward perihelion, reaching a peak production rate of 10$^5$ kg s$^{-1}$. The\nsize distribution of the particles follows a power law, with its index\ndecreasing toward perihelion, along with a reduction in the minimum particle\nradius, leading to both brightness and dust mass being dominated by small\nparticles at perihelion. The particle speeds exhibit a dependence on\nheliocentric distance ($r_h$) that closely follows the classical $r_h^{-0.5}$\nlaw near perihelion but deviates at larger heliocentric distances. We\ndemonstrate that the dependence of particle speeds on the cosine of the solar\nzenith angle at the emission point plays a significant role in shaping the\nsynthetic dust tails and in the formation of a dark stripe along the tail axis\nobserved in high spatial resolution images near the comet's perihelion.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-02T15:50:16Z"}
{"aid":"http://arxiv.org/abs/2504.01847v1","title":"Confluence of Conditional Rewriting Modulo","summary":"Sets of equations E play an important computational role in rewriting-based\nsystems R by defining an equivalence relation =E inducing a partition of terms\ninto E-equivalence classes on which rewriting computations, denoted ->R/E and\ncalled *rewriting modulo E*, are issued. This paper investigates *confluence of\n->R/E*, usually called *E-confluence*, for *conditional* rewriting-based\nsystems, where rewriting steps are determined by conditional rules. We rely on\nJouannaud and Kirchner's framework to investigate confluence of an abstract\nrelation R modulo an abstract equivalence relation E on a set A. We show how to\nparticularize the framework to be used with conditional systems. Then, we show\nhow to define appropriate finite sets of *conditional pairs* to prove and\ndisprove E-confluence. In particular, we introduce *Logic-based Conditional\nCritical Pairs* which do not require the use of (often infinitely many)\nE-unifiers to provide a finite representation of the *local peaks* considered\nin the abstract framework. We also introduce *parametric Conditional Variable\nPairs* which are essential to deal with conditional rules in the analysis of\nE-confluence. Our results apply to well-known classes of rewriting-based\nsystems. In particular, to *Equational (Conditional) Term Rewriting Systems*.","main_category":"cs.LO","categories":"cs.LO,cs.PL,cs.SC","published":"2025-04-02T15:55:06Z"}
{"aid":"http://arxiv.org/abs/2504.01848v1","title":"PaperBench: Evaluating AI's Ability to Replicate AI Research","summary":"We introduce PaperBench, a benchmark evaluating the ability of AI agents to\nreplicate state-of-the-art AI research. Agents must replicate 20 ICML 2024\nSpotlight and Oral papers from scratch, including understanding paper\ncontributions, developing a codebase, and successfully executing experiments.\nFor objective evaluation, we develop rubrics that hierarchically decompose each\nreplication task into smaller sub-tasks with clear grading criteria. In total,\nPaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed\nwith the author(s) of each ICML paper for accuracy and realism. To enable\nscalable evaluation, we also develop an LLM-based judge to automatically grade\nreplication attempts against rubrics, and assess our judge's performance by\ncreating a separate benchmark for judges. We evaluate several frontier models\non PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet\n(New) with open-source scaffolding, achieves an average replication score of\n21.0\\%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench,\nfinding that models do not yet outperform the human baseline. We\n\\href{https://github.com/openai/preparedness}{open-source our code} to\nfacilitate future research in understanding the AI engineering capabilities of\nAI agents.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-02T15:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.01849v1","title":"An Approach to Technical AGI Safety and Security","summary":"Artificial General Intelligence (AGI) promises transformative benefits but\nalso presents significant risks. We develop an approach to address the risk of\nharms consequential enough to significantly harm humanity. We identify four\nareas of risk: misuse, misalignment, mistakes, and structural risks. Of these,\nwe focus on technical approaches to misuse and misalignment. For misuse, our\nstrategy aims to prevent threat actors from accessing dangerous capabilities,\nby proactively identifying dangerous capabilities, and implementing robust\nsecurity, access restrictions, monitoring, and model safety mitigations. To\naddress misalignment, we outline two lines of defense. First, model-level\nmitigations such as amplified oversight and robust training can help to build\nan aligned model. Second, system-level security measures such as monitoring and\naccess control can mitigate harm even if the model is misaligned. Techniques\nfrom interpretability, uncertainty estimation, and safer design patterns can\nenhance the effectiveness of these mitigations. Finally, we briefly outline how\nthese ingredients could be combined to produce safety cases for AGI systems.","main_category":"cs.AI","categories":"cs.AI,cs.CY,cs.LG","published":"2025-04-02T15:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.01859v1","title":"A method to derive material-specific spin-bath model descriptions of\n  materials displaying prevalent spin physics (for simulation on NISQ devices)","summary":"Magnetism and spin physics are true quantum mechanical effects and their\ndescription usually requires multi reference methods and is often hidden in the\nstandard description of molecules in quantum chemistry. In this work we present\na twofold approach to the description of spin physics in molecules and solids.\nFirst, we present a method that identifies the single-particle basis in which a\ngiven subset of the orbitals is equivalent to spin degrees of freedom for\nmodels and materials which feature significant spin physics at low energies. We\nintroduce a metric for the spin-like character of a basis orbital, of which the\noptimization yields the basis containing the optimum spin-like basis orbitals.\nSecond, we demonstrate an extended Schrieffer-Wolff transformation method to\nderive the effective Hamiltonian acting on the subspace of the Hilbert space in\nwhich the charge degree of freedom of electron densities in the spin-like\norbitals is integrated out. The method then yields an effective spin-bath\nHamiltonian description for the system. This extended Schrieffer-Wolff\ntransformation is applicable to a wide range of Hamiltonians and has been\nutilized in this work for model Hamiltonians as well as the active space\nHamiltonian of molecular chromium bromide.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-02T16:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.01860v1","title":"Hyperbolic decomposition of Dirichlet distance for ARMA models","summary":"We investigate the hyperbolic decomposition of the Dirichlet norm and\ndistance between autoregressive moving average (ARMA) models. Beginning with\nthe K\\\"ahler information geometry of linear systems in the Hardy space and\nweighted Hardy spaces, we demonstrate that the Dirichlet norm and distance of\nARMA models, corresponding to the mutual information between the past and\nfuture, are decomposed into functions of the hyperbolic distance between the\npoles and zeros of the ARMA models.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-02T16:12:24Z"}
{"aid":"http://arxiv.org/abs/2504.01882v1","title":"CO-DEFEND: Continuous Decentralized Federated Learning for Secure\n  DoH-Based Threat Detection","summary":"The use of DNS over HTTPS (DoH) tunneling by an attacker to hide malicious\nactivity within encrypted DNS traffic poses a serious threat to network\nsecurity, as it allows malicious actors to bypass traditional monitoring and\nintrusion detection systems while evading detection by conventional traffic\nanalysis techniques. Machine Learning (ML) techniques can be used to detect DoH\ntunnels; however, their effectiveness relies on large datasets containing both\nbenign and malicious traffic. Sharing such datasets across entities is\nchallenging due to privacy concerns. In this work, we propose CO-DEFEND\n(Continuous Decentralized Federated Learning for Secure DoH-Based Threat\nDetection), a Decentralized Federated Learning (DFL) framework that enables\nmultiple entities to collaboratively train a classification machine learning\nmodel while preserving data privacy and enhancing resilience against single\npoints of failure. The proposed DFL framework, which is scalable and\nprivacy-preserving, is based on a federation process that allows multiple\nentities to train online their local models using incoming DoH flows in real\ntime as they are processed by the entity. In addition, we adapt four classical\nmachine learning algorithms, Support Vector Machines (SVM), Logistic Regression\n(LR), Decision Trees (DT), and Random Forest (RF), for federated scenarios,\ncomparing their results with more computationally complex alternatives such as\nneural networks. We compare our proposed method by using the dataset\nCIRA-CIC-DoHBrw-2020 with existing machine learning approaches to demonstrate\nits effectiveness in detecting malicious DoH tunnels and the benefits it\nbrings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T16:40:01Z"}
{"aid":"http://arxiv.org/abs/2504.01896v1","title":"Composition Design of Shape Memory Ceramics based on Gaussian Processes","summary":"We present a Gaussian process machine learning model to predict the\ntransformation temperature and lattice parameters of ZrO$_2$-based ceramics.\nOur overall goal is to search for a shape memory ceramic with a reversible\ntransformation and low hysteresis. The identification of a new low hysteresis\ncomposition is based on design criteria that have been successful in metal\nalloys: (1) $\\lambda_2 = 1$, where $\\lambda_2$ is the middle eigenvalue of the\ntransformation stretch tensor, (2) minimizing the max$|q(f)|$, which measures\nthe deviation from satisfying the cofactor conditions, (3) high transformation\ntemperature, (4) low transformational volume change, and (5) solid solubility.\nWe generate many synthetic compositions, and identify a promising composition,\n31.75Zr-37.75Hf-14.5Y-14.5Ta-1.5Er, which closely satisfies all the design\ncriteria based on predictions from machine learning. However, differential\nthermal analysis reveals a relatively high thermal hysteresis of 137{\\deg}C for\nthis composition, indicating that the proposed design criteria are not\nuniversally applicable to all ZrO$_2$-based ceramics. We also explore reducing\ntetragonality of the austenite phase by addition of Er$_2$O$_3$. The idea is to\ntune the lattice parameters of austenite phase towards a cubic structure will\nincrease the number of martensite variants, thus, allowing more flexibility for\nthem to accommodate high strain during transformation. We find the effect of\nEr$_2$O$_3$ on tetragonality is weak due to limited solubility. We conclude\nthat a more effective dopant is needed to achieve significant tetragonality\nreduction. Overall, Gaussian process machine learning models are shown to be\nhighly useful for prediction of compositions and lattice parameters, but the\ndiscovery of low hysteresis ceramic materials apparently involves other factors\nnot relevant to phase transformations in metals.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.data-an","published":"2025-04-02T16:56:59Z"}
{"aid":"http://arxiv.org/abs/2504.01906v1","title":"Gaze-Hand Steering for Travel and Multitasking in Virtual Environments","summary":"As head-mounted displays (HMDs) with eye-tracking become increasingly\naccessible, the need for effective gaze-based interfaces in virtual reality\n(VR) grows. Traditional gaze- or hand-based navigation often limits user\nprecision or impairs free viewing, making multitasking difficult. We present a\ngaze-hand steering technique that combines eye-tracking with hand-pointing:\nusers steer only when gaze aligns with a hand-defined target, reducing\nunintended actions and enabling free look. Speed is controlled via either a\njoystick or a waist-level speed circle. We evaluated our method in a user study\n(N=20) across multitasking and single-task scenarios, comparing it to a similar\ntechnique. Results show that gaze-hand steering maintains performance and\nenhances user comfort and spatial awareness during multitasking. Our findings\nsupport the use of gaze-hand steering in gaze-dominant VR applications\nrequiring precision and simultaneous interaction. Our method significantly\nimproves VR navigation in gaze-dominant, multitasking-intensive applications,\nsupporting immersion and efficient control.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-02T17:07:01Z"}
{"aid":"http://arxiv.org/abs/2504.01922v1","title":"Is Less Really More? Fake News Detection with Limited Information","summary":"The threat that online fake news and misinformation pose to democracy,\njustice, public confidence, and especially to vulnerable populations, has led\nto a sharp increase in the need for fake news detection and intervention.\nWhether multi-modal or pure text-based, most fake news detection methods depend\non textual analysis of entire articles. However, these fake news detection\nmethods come with certain limitations. For instance, fake news detection\nmethods that rely on full text can be computationally inefficient, demand large\namounts of training data to achieve competitive accuracy, and may lack\nrobustness across different datasets. This is because fake news datasets have\nstrong variations in terms of the level and types of information they provide;\nwhere some can include large paragraphs of text with images and metadata,\nothers can be a few short sentences. Perhaps if one could only use minimal\ninformation to detect fake news, fake news detection methods could become more\nrobust and resilient to the lack of information. We aim to overcome these\nlimitations by detecting fake news using systematically selected, limited\ninformation that is both effective and capable of delivering robust, promising\nperformance. We propose a framework called SLIM Systematically-selected Limited\nInformation) for fake news detection. In SLIM, we quantify the amount of\ninformation by introducing information-theoretic measures. SLIM leverages\nlimited information to achieve performance in fake news detection comparable to\nthat of state-of-the-art obtained using the full text. Furthermore, by\ncombining various types of limited information, SLIM can perform even better\nwhile significantly reducing the quantity of information required for training\ncompared to state-of-the-art language model-based fake news detection\ntechniques.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-02T17:32:37Z"}
{"aid":"http://arxiv.org/abs/2504.01938v1","title":"A Unified Approach to Analysis and Design of Denoising Markov Models","summary":"Probabilistic generative models based on measure transport, such as diffusion\nand flow-based models, are often formulated in the language of Markovian\nstochastic dynamics, where the choice of the underlying process impacts both\nalgorithmic design choices and theoretical analysis. In this paper, we aim to\nestablish a rigorous mathematical foundation for denoising Markov models, a\nbroad class of generative models that postulate a forward process transitioning\nfrom the target distribution to a simple, easy-to-sample distribution,\nalongside a backward process particularly constructed to enable efficient\nsampling in the reverse direction. Leveraging deep connections with\nnonequilibrium statistical mechanics and generalized Doob's $h$-transform, we\npropose a minimal set of assumptions that ensure: (1) explicit construction of\nthe backward generator, (2) a unified variational objective directly minimizing\nthe measure transport discrepancy, and (3) adaptations of the classical\nscore-matching approach across diverse dynamics. Our framework unifies existing\nformulations of continuous and discrete diffusion models, identifies the most\ngeneral form of denoising Markov models under certain regularity assumptions on\nforward generators, and provides a systematic recipe for designing denoising\nMarkov models driven by arbitrary L\\'evy-type processes. We illustrate the\nversatility and practical effectiveness of our approach through novel denoising\nMarkov models employing geometric Brownian motion and jump processes as forward\ndynamics, highlighting the framework's potential flexibility and capability in\nmodeling complex distributions.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA,stat.ML","published":"2025-04-02T17:46:43Z"}
{"aid":"http://arxiv.org/abs/2504.01942v1","title":"De Sitter entropy: on-shell versus off-shell","summary":"Attributing thermodynamic properties to the Bunch-Davies state in static\npatch of de Sitter space and setting the corresponding equations of state, we\ndemonstrate that, for pure gravity, the bulk entropy computed on-shell as a\nvolume integral in de Sitter space coincides with the Wald entropy (area law)\nin any spacetime dimension and for any theory of f(R) gravity. We extend this\nresult to the renormalized entanglement entropy of a non-minimally coupled\nscalar field. From the on-shell perspective, entropy emerges as a bulk\ncontribution, whereas from the off-shell viewpoint, it manifests as a boundary\n(horizon) contribution. As a result, in de Sitter space, generalized entropy\ncan be understood in two distinct ways: either as a bulk or as a boundary\ncontribution.","main_category":"hep-th","categories":"hep-th","published":"2025-04-02T17:48:35Z"}
{"aid":"http://arxiv.org/abs/2504.01953v1","title":"Deep Representation Learning for Unsupervised Clustering of Myocardial\n  Fiber Trajectories in Cardiac Diffusion Tensor Imaging","summary":"Understanding the complex myocardial architecture is critical for diagnosing\nand treating heart disease. However, existing methods often struggle to\naccurately capture this intricate structure from Diffusion Tensor Imaging (DTI)\ndata, particularly due to the lack of ground truth labels and the ambiguous,\nintertwined nature of fiber trajectories. We present a novel deep learning\nframework for unsupervised clustering of myocardial fibers, providing a\ndata-driven approach to identifying distinct fiber bundles. We uniquely combine\na Bidirectional Long Short-Term Memory network to capture local sequential\ninformation along fibers, with a Transformer autoencoder to learn global shape\nfeatures, with pointwise incorporation of essential anatomical context.\nClustering these representations using a density-based algorithm identifies 33\nto 62 robust clusters, successfully capturing the subtle distinctions in fiber\ntrajectories with varying levels of granularity. Our framework offers a new,\nflexible, and quantitative way to analyze myocardial structure, achieving a\nlevel of delineation that, to our knowledge, has not been previously achieved,\nwith potential applications in improving surgical planning, characterizing\ndisease-related remodeling, and ultimately, advancing personalized cardiac\ncare.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-02T17:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.02210v1","title":"Mid-Infrared Imaging Spectroscopy of N2O Solid Simulating the haze of\n  trans-Neptunian objects","summary":"\\ Nitrous oxide (N$_2$O) ice is likely to exist in trans-Neptunian objects\nsuch as Pluto and Triton, potentially formed through ultraviolet (UV) radiation\nfrom the Sun or cosmic ray irradiation of N$_2$ and CO ices. However, the\nmid-infrared spectral characteristics of N$_2$O ice in higher temperature\nregions (90-110 K), changes in mid-infrared spectra during UV irradiation, and\nthe chemical network of nitrogen oxide (N$_x$O$_y$) ices remain insufficiently\nunderstood. This study aims to elucidate these aspects through in-situ\nmid-infrared spectral measurements of cryogenic particles using two-dimensional\nimaging Fourier transform infrared spectroscopy.\n  Spectroscopic imaging confirmed strong absorption at 7.75 $\\mu$m (N$_2$O\n$\\nu_1$ vibrational mode), with weaker vibrational modes observed at 8.60\n$\\mu$m (N$_2$O 2$\\nu_2$), 7.27 $\\mu$m (N$_2$O torsion), and 5.29 $\\mu$m (N$_2$O\n$\\nu_1$+$\\nu_2$). Annealing experiments simulating high-temperature conditions\ndemonstrated that all vibrational modes irreversibly intensified with\nincreasing temperature, indicating progressive crystallization. New spectral\nfeatures appeared at approximately 12 $\\mu$m and 14 $\\mu$m at the condensed\nsample.\n  N$_2$O ice was exposed to ultraviolet radiation (190-340 nm) using a D$_2$\nlamp for 8.5 hours to investigate spectral changes during UV irradiation. After\n60-90 minutes of irradiation, all N$_2$O vibrational modes disappeared, while\nabsorption intensities of various nitrogen oxides, including NO, NO$_2$,\nN$_2$O$_3$, and O$_3$ increased. Beyond 180 minutes, vibrational modes of\nmultiple nitrogen oxide ices exhibited intensity variations across different\nwavelengths, corresponding to other species such as cis-(NO)$_2$, N$_2$O$_4$,\nand N$_2$O$_5$.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,physics.chem-ph","published":"2025-04-03T02:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.02219v1","title":"Experimental evidence of non-equilibrium phase separation in\n  supercritical fluids","summary":"Supercritical fluids (SCFs) have long been considered homogeneous and\nstructureless, yet recent studies suggest the existence of transient,\nliquid-like clusters under dynamic processes. In this study, we provide\nexperimental evidence of semi-stable non-equilibrium phase separation in SCFs\nthrough opacity measurements and small-angle neutron scattering (SANS). By\ninvestigating the thermophysical properties of helium, argon, and krypton\nduring adiabatic expansion, we show that cooling dynamics vary significantly\namong species, influencing cluster formation. Neutron scattering measurements\nreveal distinct variations in signal intensity, supporting that the clusters\nslowly dissolve into the background with a surprisingly long time scale of tens\nof minutes. Given that SCFs in industrial applications frequently experience\ndynamic, non-equilibrium conditions rather than in strict thermodynamic\nequilibrium, our results provide crucial insights with potential implications\nfor advanced material processing, energy systems, and chemical engineering.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-03T02:20:59Z"}
{"aid":"http://arxiv.org/abs/2504.02229v1","title":"Identify Main-sequence Binaries from the Chinese Space Station Telescope\n  Survey with Machine Learning. II. Based on Gaia and GALEX","summary":"The statistical characteristics of double main-sequence (MS) binaries are\nessential for investigating star formation, binary evolution, and population\nsynthesis. Our previous study proposed a machine learning-based method to\nidentify MS binaries from MS single stars using mock data from the Chinese\nSpace Station Telescope (CSST). We further utilized detection efficiencies and\nan empirical mass ratio distribution to estimate the binary fraction within the\nsample. To further validate the effectiveness of this method, we conducted a\nmore realistic sample simulation, incorporating additional factors such as\nmetallicity, extinction, and photometric errors from CSST simulations. The\ndetection efficiency for binaries with mass ratios between 0.2 and 0.7 reached\nover 80%. We performed a detailed observational validation using the data\nselected from the Gaia Sky Survey and Galaxy Evolution Explorer. The detection\nefficiency for MS binaries in the observed sample was 65%. The binary fraction\ncan be inferred with high precision for a set of observed samples, based on\naccurate empirical mass ratio distribution.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-03T02:50:00Z"}
{"aid":"http://arxiv.org/abs/2504.02233v1","title":"Testing independence and conditional independence in high dimensions via\n  coordinatewise Gaussianization","summary":"We propose new statistical tests, in high-dimensional settings, for testing\nthe independence of two random vectors and their conditional independence given\na third random vector. The key idea is simple, i.e., we first transform each\ncomponent variable to standard normal via its marginal empirical distribution,\nand we then test for independence and conditional independence of the\ntransformed random vectors using appropriate $L_\\infty$-type test statistics.\nWhile we are testing some necessary conditions of the independence or the\nconditional independence, the new tests outperform the 13 frequently used\ntesting methods in a large scale simulation comparison. The advantage of the\nnew tests can be summarized as follows: (i) they do not require any moment\nconditions, (ii) they allow arbitrary dependence structures of the components\namong the random vectors, and (iii) they allow the dimensions of random vectors\ndiverge at the exponential rates of the sample size. The critical values of the\nproposed tests are determined by a computationally efficient multiplier\nbootstrap procedure. Theoretical analysis shows that the sizes of the proposed\ntests can be well controlled by the nominal significance level, and the\nproposed tests are also consistent under certain local alternatives. The finite\nsample performance of the new tests is illustrated via extensive simulation\nstudies and a real data application.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-03T02:59:52Z"}
{"aid":"http://arxiv.org/abs/2504.02235v1","title":"On the Clustering of Conditional Mutual Information via Dissipative\n  Dynamics","summary":"Conditional mutual information (CMI) has recently attracted significant\nattention as a key quantity for characterizing quantum correlations in\nmany-body systems. While it is conjectured that CMI decays rapidly in\nfinite-temperature Gibbs states, a complete and general proof remains elusive.\nPrevious work addressed this problem in the high-temperature regime using\ncluster expansion techniques [T. Kuwahara, K. Kato, F.G.S.L. Brand\\~ao, Phys.\nRev. Lett. 124, 220601 (2020)]; however, flaws in the proof have been pointed\nout, and the method does not provide a uniformly convergent expansion at\narbitrarily high temperatures. In this work, we demonstrate that the cluster\nexpansion approach indeed fails to converge absolutely, even at any\nhigh-temperatures. To overcome this limitation, we propose a new approach to\nproving the spatial decay of CMI. Our method leverages the connection between\nCMI and quantum recovery maps, specifically utilizing the Fawzi-Renner theorem.\nWe show that such recovery maps can be realized through dissipative dynamics,\nand by analyzing the locality properties of these dynamics, we establish the\nexponential decay of CMI in high-temperature regimes. As a technical\ncontribution, we also present a new result on the perturbative stability of\nquasi-local Liouvillian dynamics. Our results indicate that, contrary to common\nintuition, high-temperature Gibbs states can exhibit nontrivial mathematical\nstructure, particularly when multipartite correlations such as CMI are\nconsidered.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-03T03:06:55Z"}
{"aid":"http://arxiv.org/abs/2504.02257v1","title":"In-situ three-dimensional strain engineering of solid-state quantum\n  emitters in photonic structures towards scalable quantum networks","summary":"Solid-state quantum emitters are pivotal for modern photonic quantum\ntechnology, yet their inherent spectral inhomogeneity imposes a critical\nchallenge in pursuing scalable quantum network. Here, we develop a\ncryogenic-compatible strain-engineering platform based on a\npolydimethylsiloxane (PDMS) stamp that is not obviously working properly at\ncryogenic temperature. In-situ three-dimensional (3D) strain control is\nachieved for quantum dots (QDs) embedded in photonic nanostructures. The\ncompliant PDMS enables independent tuning of emission energy and elimination of\nfine structure splitting (FSS) of single QDs, as demonstrated by a 7 meV\nspectral shift with a near-vanishing FSS in circular Bragg resonators and an\nunprecedented 15 meV tuning range in the micropillar. The PDMS-based 3D\nstrain-engineering platform, compatible with diverse photonic structures at\ncryogenic temperature, provides a powerful and versatile tool for exploring\nfundamental strain-related physics and advancing integrated photonic quantum\ntechnology.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-03T04:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.02274v1","title":"Extended Hybridization Expansion Solver for Impurity Models with\n  Retarded Interactions","summary":"We extend the continuous-time hybridization expansion solver to a general\nform, where the hybridization function and retarded interaction are treated on\nequal footing. Correlation functions can now be directly obtained via\nfunctional derivatives with respect to the bosonic propagators, similar to the\nmeasurement of Green's functions. We devise a combinatorial scheme of measuring\nthe correlation function, whose efficiency partially emulates that of the\nGreen's function measurement. The algorithm and numerical methods are validated\nthrough application to an impurity model involving both electron-phonon\ncoupling and exchange interactions, a case where the previous hybridization\nexpansion algorithm is not applicable. Our improvement of the hybridization\nexpansion solver promotes its applicability in studies of electron-phonon\ncoupling, the extended dynamical mean field theory, and the dual boson method.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-03T04:49:35Z"}
{"aid":"http://arxiv.org/abs/2504.02282v1","title":"Complete Minimal Surfaces in $\\mathbb{R}^4$ with Three Embedded Planar\n  Ends","summary":"In this paper, we study complete minimal surfaces in $\\mathbb{R}^4$ with\nthree embedded planar ends parallel to those of the union of the Lagrangian\ncatenoid and the plane passing through its waist circle. We show that any\ncomplete, oriented, immersed minimal surface in $\\mathbb{R}^4$ of finite total\ncurvature with genus $1$ and three such ends must be $J$-holomorphic for some\nalmost complex structure $J$. Under the additional assumptions of embeddedness\nand at least $8$ symmetries, we prove that the number of symmetries must be\neither $8$ or $12$, and in each case, the surface is uniquely determined up to\nrigid motions and scalings. Furthermore, we establish a nonexistence result for\ngenus $g\\geq2$ when the surface is embedded and has at least $4(g+1)$\nsymmetries. Our approach is based on a modification of the method of Costa and\nHoffman-Meeks in the setting of $\\mathbb{R}^4$, utilizing the generalized\nWeierstrass representation.","main_category":"math.DG","categories":"math.DG","published":"2025-04-03T05:08:10Z"}
{"aid":"http://arxiv.org/abs/2504.02319v1","title":"Fields with small class group in the family $\\mathbb{Q}(\\sqrt{9m^2+2m})$","summary":"Very recently, Issa and Darrag [Arch. Math. (Basel) 123 (2024), no. 4,\n379-383] determined partial Dedekind zeta values for certain ideal classes in\nthe real quadratic fields of the form $\\mathbb{Q}(\\sqrt{9m^2+2m})$, where\n$9m^2+2m$ is square-free and $m\\equiv 2\\pmod 3$ is an odd positive integer. We\nuse these partial Dedekind zeta values to investigate the small class numbers\nof such fields. More precisely, we prove that the class numbers of the fields\nin the above mentioned family are at least $4$. Further, we provide a\nsufficient condition permitting to specify the structure of the class groups of\norder $4$ in this family of fields.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T06:46:18Z"}
{"aid":"http://arxiv.org/abs/2504.02367v1","title":"CrystalFormer-RL: Reinforcement Fine-Tuning for Materials Design","summary":"Reinforcement fine-tuning has instrumental enhanced the instruction-following\nand reasoning abilities of large language models. In this work, we explore the\napplications of reinforcement fine-tuning to the autoregressive\ntransformer-based materials generative model CrystalFormer (arXiv:2403.15734)\nusing discriminative machine learning models such as interatomic potentials and\nproperty prediction models. By optimizing reward signals-such as energy above\nthe convex hull and material property figures of merit-reinforcement\nfine-tuning infuses knowledge from discriminative models into generative\nmodels. The resulting model, CrystalFormer-RL, shows enhanced stability in\ngenerated crystals and successfully discovers crystals with desirable yet\nconflicting material properties, such as substantial dielectric constant and\nband gap simultaneously. Notably, we observe that reinforcement fine-tuning\nenables not only the property-guided novel material design ability of\ngenerative pre-trained model but also unlocks property-driven material\nretrieval from the unsupervised pre-training dataset. Leveraging rewards from\ndiscriminative models to fine-tune materials generative models opens an\nexciting gateway to the synergies of the machine learning ecosystem for\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.comp-ph","published":"2025-04-03T07:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.02385v1","title":"Quantum singular value transformation without block encodings:\n  Near-optimal complexity with minimal ancilla","summary":"We develop new algorithms for Quantum Singular Value Transformation (QSVT), a\nunifying framework underlying a wide range of quantum algorithms. Existing\nimplementations of QSVT rely on block encoding, incurring $O(\\log L)$ ancilla\noverhead and circuit depth $\\widetilde{O}(d\\lambda L)$ for polynomial\ntransformations of a Hamiltonian $H=\\sum_{k=1}^L \\lambda_k H_k$, where $d$ is\npolynomial degree, and $\\lambda=\\sum_k |\\lambda_k|$. We introduce a new\napproach that eliminates block encoding, needs only a single ancilla qubit, and\nmaintains near-optimal complexity, using only basic Hamiltonian simulation\nmethods such as Trotterization. Our method achieves a circuit depth of\n$\\widetilde{O}(L(d\\lambda_{\\mathrm{comm}})^{1+o(1)})$, without any multi-qubit\ncontrolled gates. Here, $\\lambda_{\\mathrm{comm}}$ depends on the nested\ncommutators of the $H_k$'s and can be much smaller than $\\lambda$. Central to\nour technique is a novel use of Richardson extrapolation, enabling systematic\nerror cancellation in interleaved sequences of arbitrary unitaries and\nHamiltonian evolution operators, establishing a broadly applicable framework\nbeyond QSVT. Additionally, we propose two randomized QSVT algorithms for cases\nwith only sampling access to Hamiltonian terms. The first uses qDRIFT, while\nthe second replaces block encodings in QSVT with randomly sampled unitaries.\nBoth achieve quadratic complexity in $d$, which we establish as a lower bound\nfor any randomized method implementing polynomial transformations in this\nmodel. Finally, as applications, we develop end-to-end quantum algorithms for\nquantum linear systems and ground state property estimation, achieving\nnear-optimal complexity without oracular access. Our results provide a new\nframework for quantum algorithms, reducing hardware overhead while maintaining\nnear-optimal performance, with implications for both near-term and\nfault-tolerant quantum computing.","main_category":"quant-ph","categories":"quant-ph,cs.DS","published":"2025-04-03T08:24:15Z"}
{"aid":"http://arxiv.org/abs/2504.02400v1","title":"The model example of wave equation with oscillating scale-invariant\n  damping","summary":"We analyze a simple example of wave equation with a time-dependent damping\nterm, whose coefficient decays at infinity at the scale-invariant rate and\nincludes an oscillatory component that is integrable but not absolutely\nintegrable.\n  We show that the oscillations in the damping coefficient induce a resonance\neffect with a fundamental solution of the elastic term, altering the energy\ndecay rate of solutions. In particular, some solutions exhibit slower decay\ncompared to the case without the oscillatory component.\n  Our proof relies on Fourier analysis and a representation of solutions in\npolar coordinates, reducing the problem to a detailed study of the asymptotic\nbehavior of solutions to a family of ordinary differential equations and\nsuitable oscillatory integrals.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T08:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.02417v1","title":"Leveraging Static Relationships for Intra-Type and Inter-Type Message\n  Passing in Video Question Answering","summary":"Video Question Answering (VideoQA) is an important research direction in the\nfield of artificial intelligence, enabling machines to understand video content\nand perform reasoning and answering based on natural language questions.\nAlthough methods based on static relationship reasoning have made certain\nprogress, there are still deficiencies in the accuracy of static relationship\nrecognition and representation, and they have not fully utilized the static\nrelationship information in videos for in-depth reasoning and analysis.\nTherefore, this paper proposes a reasoning method for intra-type and inter-type\nmessage passing based on static relationships. This method constructs a dual\ngraph for intra-type message passing reasoning and builds a heterogeneous graph\nbased on static relationships for inter-type message passing reasoning. The\nintra-type message passing reasoning model captures the neighborhood\ninformation of targets and relationships related to the question in the dual\ngraph, updating the dual graph to obtain intra-type clues for answering the\nquestion. The inter-type message passing reasoning model captures the\nneighborhood information of targets and relationships from different categories\nrelated to the question in the heterogeneous graph, updating the heterogeneous\ngraph to obtain inter-type clues for answering the question. Finally, the\nanswers are inferred by combining the intra-type and inter-type clues based on\nstatic relationships. Experimental results on the ANetQA and Next-QA datasets\ndemonstrate the effectiveness of this method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T09:14:41Z"}
{"aid":"http://arxiv.org/abs/2504.02440v1","title":"HGFormer: Topology-Aware Vision Transformer with HyperGraph Learning","summary":"The computer vision community has witnessed an extensive exploration of\nvision transformers in the past two years. Drawing inspiration from traditional\nschemes, numerous works focus on introducing vision-specific inductive biases.\nHowever, the implicit modeling of permutation invariance and fully-connected\ninteraction with individual tokens disrupts the regional context and spatial\ntopology, further hindering higher-order modeling. This deviates from the\nprinciple of perceptual organization that emphasizes the local groups and\noverall topology of visual elements. Thus, we introduce the concept of\nhypergraph for perceptual exploration. Specifically, we propose a\ntopology-aware vision transformer called HyperGraph Transformer (HGFormer).\nFirstly, we present a Center Sampling K-Nearest Neighbors (CS-KNN) algorithm\nfor semantic guidance during hypergraph construction. Secondly, we present a\ntopology-aware HyperGraph Attention (HGA) mechanism that integrates hypergraph\ntopology as perceptual indications to guide the aggregation of global and\nunbiased information during hypergraph messaging. Using HGFormer as visual\nbackbone, we develop an effective and unitive representation, achieving\ndistinct and detailed scene depictions. Empirical experiments show that the\nproposed HGFormer achieves competitive performance compared to the recent SoTA\ncounterparts on various visual benchmarks. Extensive ablation and visualization\nstudies provide comprehensive explanations of our ideas and contributions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:58:01Z"}
{"aid":"http://arxiv.org/abs/2504.02447v1","title":"Measuring the Low-Energy Weak Mixing Angle with Supernova Neutrinos","summary":"The weak mixing angle $\\theta_W$ is a fundamental parameter in the\nelectroweak theory with a value running according to the energy scale, and its\nprecision measurement in the low-energy regime is still ongoing. We propose a\nmethod to measure the low-energy $\\sin{^2\\theta_W}$ by taking advantage of\nArgo, a future ton-scale liquid argon dark matter detector, and the neutrino\nflux from a nearby core-collapse supernova (CCSN). We evaluate the expected\nprecision of this measurement through the coherent elastic neutrino-nucleus\nscattering (CE$\\nu$NS) channel. We show that Argo is potentially capable of\nachieving a few percent determination of $\\sin{^2\\theta_W}$, at the momentum\ntransfer of $q \\sim 20$ MeV, in the observation of a CCSN within $\\sim 3$ kpc\nfrom the Earth. Such a measurement is valuable for both the precision test of\nthe electroweak theory and searching for new physics beyond the standard model\nin the neutrino sector.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-03T10:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.02452v1","title":"Thermo-optic bistability in 2D all-dielectric resonators","summary":"We consider thermo-optic bistability in resonant excitation of high-quality\nmodes in two-dimensional dielectric resonators. We develop a coupled-mode\ntheory approach which account for the frequency shift due to a temperature\ndependent dielectric permittivity. The model is applied to rectangular and\nhexagonal resonators supporting an isolated high-quality resonant mode. The\nresults are verified in comparison with straightforward finite-element\nsimulations. It is shown that the model accurately describes the effect\nbistabily which occurs under variation of the angle of incidence or the\nintensity of the incident wave. In particular, it is demonstrated that\nvariation of the incident angle can optimize the coupling between the resonator\nand the incident waves leading to bistabily with low intensity incident waves\n$W_0 = 0.35 {\\rm \\mu W/\\mu m}^2$. The bistability threshold is shown to be\nextremely sensitive to the imaginary part of the dielectric permittivity\n$\\epsilon''$.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-03T10:16:28Z"}
{"aid":"http://arxiv.org/abs/2504.02469v1","title":"An MHD Simulation of the Possible Modulations of Stellar CMEs Radio\n  Observations by an Exoplanetary Magnetosphere","summary":"Type II radio bursts are the indicator of adverse space weather in a stellar\nsystem. These radio bursts are the consequence of shock wave acceleration due\nto the coronal mass ejection (CME). Here, we perform a series of\nmagnetohydrodynamic (MHD) simulations of a CME-driven star-planet system in\norder to investigate the modulation in radio burst mechanism by a close-in\nexoplanetary system. We use a model for the stellar wind with a close-in\nexoplanet, and a CME model based on the eruption of a flux rope. We are able to\ngenerate synthetic radio burst images from our MHD simulations. We find that\nradio burst like phenomena is most likely to be observed for moderately active\nsolar like stars and close-in exoplanetary systems have significant influence\non the nature of radio burst spectrum. We find that when the planetary field is\nnot too strong, the planetary magnetosphere is pushing against the CME,\nincreasing its density so the radio burst is visible at higher frequencies.\nWhen the planetary field is very strong, the large magnetosphere does not leave\nroom for the CME shock to evolve so the radio burst is more visible in the\nlower frequencies associated with the weak compression at the flanks of the CME\nshock. In case of highly active solar-like stars, strong overlying stellar\nfields weakens the solar-like CME shock, thus generates very weak (almost\nnon-visible) radio burst signals. For HD 189733 (moderate stellar field), only\nintensity difference is visible when the CME arrives the planet. We also do not\nfind significant modulation in the radio emission by a close-in exoplanet\nsystem when the stellar magnetic field is complex. In summary, our result\nsuggests that the nature of the radio burst spectrum is highly dependent on the\ntopology of the stellar magnetic field and the close-in exoplanetary magnetic\nfield strength.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-03T10:42:30Z"}
{"aid":"http://arxiv.org/abs/2504.02486v1","title":"We Need Improved Data Curation and Attribution in AI for Scientific\n  Discovery","summary":"As the interplay between human-generated and synthetic data evolves, new\nchallenges arise in scientific discovery concerning the integrity of the data\nand the stability of the models. In this work, we examine the role of synthetic\ndata as opposed to that of real experimental data for scientific research. Our\nanalyses indicate that nearly three-quarters of experimental datasets available\non open-access platforms have relatively low adoption rates, opening new\nopportunities to enhance their discoverability and usability by automated\nmethods. Additionally, we observe an increasing difficulty in distinguishing\nsynthetic from real experimental data. We propose supplementing ongoing efforts\nin automating synthetic data detection by increasing the focus on watermarking\nreal experimental data, thereby strengthening data traceability and integrity.\nOur estimates suggest that watermarking even less than half of the real world\ndata generated annually could help sustain model robustness, while promoting a\nbalanced integration of synthetic and human-generated content.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T11:07:52Z"}
{"aid":"http://arxiv.org/abs/2504.02509v1","title":"A Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D\n  Printing Work Orders","summary":"With the rapid development of 3D printing, the demand for personalized and\ncustomized production on the manufacturing line is steadily increasing.\nEfficient merging of printing workpieces can significantly enhance the\nprocessing efficiency of the production line. Addressing the challenge, a Large\nLanguage Model (LLM)-driven method is established in this paper for the\nautonomous merging of 3D printing work orders, integrated with a\nmemory-augmented learning strategy. In industrial scenarios, both device and\norder features are modeled into LLM-readable natural language prompt templates,\nand develop an order-device matching tool along with a merging interference\nchecking module. By incorporating a self-memory learning strategy, an\nintelligent agent for autonomous order merging is constructed, resulting in\nimproved accuracy and precision in order allocation. The proposed method\neffectively leverages the strengths of LLMs in industrial applications while\nreducing hallucination.","main_category":"cs.AI","categories":"cs.AI,cs.RO","published":"2025-04-03T11:50:29Z"}
{"aid":"http://arxiv.org/abs/2504.02523v1","title":"Denoising medium resolution stellar spectra with U-Net convolutional\n  neural networks","summary":"We investigated the use of a U-Net convolutional neural network for denoising\nsimulated medium-resolution spectroscopic observations of stars. Simulated\nspectra were generated under realistic observational conditions resembling the\nSubaru Prime Focus Spectrograph (PFS). We found that our U-Net model\neffectively captured spectral features, achieving an average relative error of\naround $1\\%$ across a broad range of stellar parameters, despite a limited\ntraining set of only $1000$ observations and a relatively short training\nperiod. Although U-Net did not reach the performance previously demonstrated by\nfully-connected denoising autoencoders (DAEs) consisting of dense layers and\ntrained extensively on larger datasets, it outperformed dense networks trained\nunder similarly constrained conditions. These results indicate that the U-Net\narchitecture offers rapid, robust feature learning and may be particularly\nadvantageous in scenarios involving initial denoising, subsequently refined by\nmore accurate, but otherwise slower deep-learning models.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.SR","published":"2025-04-03T12:27:14Z"}
{"aid":"http://arxiv.org/abs/2504.02551v1","title":"Human-Centered Development of an Explainable AI Framework for Real-Time\n  Surgical Risk Surveillance","summary":"Background: Artificial Intelligence (AI) clinical decision support (CDS)\nsystems have the potential to augment surgical risk assessments, but successful\nadoption depends on an understanding of end-user needs and current workflows.\nThis study reports the initial co-design of MySurgeryRisk, an AI CDS tool to\npredict the risk of nine post-operative complications in surgical patients.\nMethods: Semi-structured focus groups and interviews were held as co-design\nsessions with perioperative physicians at a tertiary academic hospital in the\nSoutheastern United States. Participants were read a surgical vignette and\nasked questions to elicit an understanding of their current decision-making\npractices before being introduced to the MySurgeryRisk prototype web interface.\nThey were asked to provide feedback on the user interface and system features.\nSession transcripts were qualitatively coded, after which thematic analysis\ntook place. Results: Data saturation was reached after 20 surgeons and\nanesthesiologists from varying career stages participated across 11 co-design\nsessions. Thematic analysis resulted in five themes: (1) decision-making\ncognitive processes, (2) current approach to decision-making, (3) future\napproach to decision-making with MySurgeryRisk, (4) feedback on current\nMySurgeryRisk prototype, and (5) trustworthy considerations. Conclusion:\nClinical providers perceived MySurgeryRisk as a promising CDS tool that factors\nin a large volume of data and is computed in real-time without any need for\nmanual input. Participants provided feedback on the design of the interface and\nimaged applications of the tool in the clinical workflow. However, its\nsuccessful implementation will depend on its actionability and explainability\nof model outputs, integration into current electronic systems, and calibration\nof trust among end-users.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T13:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.02574v1","title":"Quasi-periodic moiré patterns and dimensional localization in\n  three-dimensional quasi-moiré crystals","summary":"Recent advances in spin-dependent optical lattices [Meng et al., Nature\n\\textbf{615}, 231 (2023)] have enabled the experimental implementation of two\nsuperimposed three-dimensional lattices, presenting new opportunities to\ninvestigate \\textit{three-dimensional moir\\'{e} physics} in ultracold atomic\ngases. This work studies the moir\\'{e} physics of atoms within a spin-dependent\ncubic lattice with relative twists along different directions. It is discovered\nthat dimensionality significantly influences the low-energy moir\\'{e} physics.\nFrom a geometric perspective, this manifests in the observation that moir\\'{e}\npatterns, generated by rotating lattices along different axes, can exhibit\neither periodic or quasi-periodic behavior--a feature not present in\ntwo-dimensional systems. We develop a low-energy effective theory applicable to\nsystems with arbitrary rotation axes and small rotation angles. This theory\nelucidates the emergence of quasi-periodicity in three dimensions and\ndemonstrates its correlation with the arithmetic properties of the rotation\naxes. Numerical analyses reveal that these quasi-periodic moir\\'{e} potentials\ncan lead to distinctive dimensional localization behaviors of atoms,\nmanifesting as localized wave functions in planar or linear configurations.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-03T13:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.02605v1","title":"Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving","summary":"The task of issue resolving is to modify a codebase to generate a patch that\naddresses a given issue. However, existing benchmarks, such as SWE-bench, focus\nalmost exclusively on Python, making them insufficient for evaluating Large\nLanguage Models (LLMs) across diverse software ecosystems. To address this, we\nintroduce a multilingual issue-resolving benchmark, called Multi-SWE-bench,\ncovering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a\ntotal of 1,632 high-quality instances, which were carefully annotated from\n2,456 candidates by 68 expert annotators, ensuring that the benchmark can\nprovide an accurate and reliable evaluation. Based on Multi-SWE-bench, we\nevaluate a series of state-of-the-art models using three representative methods\n(Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with\nkey empirical insights. In addition, we launch a Multi-SWE-RL open-source\ncommunity, aimed at building large-scale reinforcement learning (RL) training\ndatasets for issue-resolving tasks. As an initial contribution, we release a\nset of 4,723 well-structured instances spanning seven programming languages,\nlaying a solid foundation for RL research in this domain. More importantly, we\nopen-source our entire data production pipeline, along with detailed tutorials,\nencouraging the open-source community to continuously contribute and expand the\ndataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL\ncommunity as catalysts for advancing RL toward its full potential, bringing us\none step closer to the dawn of AGI.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL","published":"2025-04-03T14:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.02640v1","title":"RoSMM: A Robust and Secure Multi-Modal Watermarking Framework for\n  Diffusion Models","summary":"Current image watermarking technologies are predominantly categorized into\ntext watermarking techniques and image steganography; however, few methods can\nsimultaneously handle text and image-based watermark data, which limits their\napplicability in complex digital environments. This paper introduces an\ninnovative multi-modal watermarking approach, drawing on the concept of vector\ndiscretization in encoder-based vector quantization. By constructing adjacency\nmatrices, the proposed method enables the transformation of text watermarks\ninto robust image-based representations, providing a novel multi-modal\nwatermarking paradigm for image generation applications. Additionally, this\nstudy presents a newly designed image restoration module to mitigate image\ndegradation caused by transmission losses and various noise interferences,\nthereby ensuring the reliability and integrity of the watermark. Experimental\nresults validate the robustness of the method under multiple noise attacks,\nproviding a secure, scalable, and efficient solution for digital image\ncopyright protection.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-03T14:36:08Z"}
{"aid":"http://arxiv.org/abs/2504.02652v1","title":"Optimizing Resource Allocation to Mitigate the Risk of Disruptive Events\n  in Homeland Security and Emergency Management","summary":"Homeland security in the United States faces a daunting task due to the\nmultiple threats and hazards that can occur. Natural disasters, human-caused\nincidents such as terrorist attacks, and technological failures can result in\nsignificant damage, fatalities, injuries, and economic losses. The increasing\nfrequency and severity of disruptive events in the United States highlight the\nurgent need for effectively allocating resources in homeland security and\nemergency preparedness. This article presents an optimization-based decision\nsupport model to help homeland security policymakers identify and select\nprojects that best mitigate the risk of threats and hazards while satisfying a\nbudget constraint. The model incorporates multiple hazards, probabilistic risk\nassessments, and multidimensional consequences and integrates historical data\nand publicly available sources to evaluate and select the most effective risk\nmitigation projects and optimize resource allocation across various disaster\nscenarios. We apply this model to the state of Iowa, considering 16 hazards,\nsix types of consequences, and 52 mitigation projects. Our results demonstrate\nhow different budget levels influence project selection, emphasizing\ncost-effective solutions that maximize risk reduction. Sensitivity analysis\nexamines the robustness of project selection under varying effectiveness\nassumptions and consequence estimations. The findings offer critical insights\nfor policymakers in homeland security and emergency management and provide a\nbasis for more efficient resource allocation and improved disaster resilience.","main_category":"cs.CY","categories":"cs.CY,math.OC","published":"2025-04-03T14:49:15Z"}
{"aid":"http://arxiv.org/abs/2504.02676v1","title":"Snow: Self-organizing Broadcast Protocol for Cloud","summary":"In large-scale distributed applications, efficient and reliable broadcast\nprotocols are essential for node communication. Tree-based broadcast lacks\nflexibility and may suffer performance degradation or even broadcast failure\nwhen cluster membership changes. Gossip-based broadcast incurs high bandwidth\noverhead and only provides probabilistic delivery guarantees. In tree-based\nbroadcasting, when an internal node leaves, its child nodes need to reconnect\nto a new parent. This process may introduce instability, leading to potential\nmessage duplication and increased transmission latency. However, in cloud\nenvironments, node departures and arrivals are common, causing frequent\nperformance degradation in tree-based broadcasting. This paper introduces Snow,\na self-organizing broadcast protocol designed for cloud environments. Instead,\nit dynamically sends or forwards messages based on each node's membership view,\nultimately forming a broadcast structure resembling a multi-way balanced\ntree(the height difference of leaf nodes is at most 1). Our experimental\nresults showed that Snow maintains message delivery reliability and latency\nguarantees under node churn while maintaining low overhead without sending\nunnecessary redundant messages.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-03T15:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.02680v1","title":"The role of hydrodynamics in the synchronisation of {\\it Chlamydomonas}\n  flagella","summary":"While hydrodynamic coupling has long been considered essential for\nsynchronisation of eukaryotic flagella, recent experiments on the unicellular\nbiflagellate model organism {\\it Chlamydomonas} demonstrate that -- at the\nsingle cell level -- intracellular mechanical coupling is necessary for\ncoordination. It is therefore unclear what role, if any, hydrodynamic forces\nactually play in the synchronisation of multiple flagella within individual\ncells, arguably the building block of large scale coordination. Here we address\nthis question experimentally by transiently blocking hydrodynamic coupling\nbetween the two flagella of single {\\it Chlamydomonas}. Our results reveal that\nin wild type cells intracellularly-mediated forces are necessary and sufficient\nfor flagellar synchronisation, with hydrodynamic coupling causing minimal\nchanges in flagellar dynamics. However, fluid-mediated ciliary coupling is\nresponsible for the extended periods of anti-phase synchronisation observed in\na mutant with weaker intracellular coupling. At the single-cell level,\ntherefore, flagellar coordination depends on a subtle balance between\nintracellular and extracellular forces.","main_category":"physics.bio-ph","categories":"physics.bio-ph,q-bio.CB","published":"2025-04-03T15:15:48Z"}
{"aid":"http://arxiv.org/abs/2504.02693v1","title":"Joint Modeling of Spatial Dependencies Across Multiple Subjects in\n  Multiplexed Tissue Imaging","summary":"The tumor microenvironment (TME) is a spatially heterogeneous ecosystem where\ncellular interactions shape tumor progression and response to therapy.\nMultiplexed imaging technologies enable high-resolution spatial\ncharacterization of the TME, yet statistical methods for analyzing\nmulti-subject spatial tissue data remain limited. We propose a Bayesian\nhierarchical model for inferring spatial dependencies in multiplexed imaging\ndatasets across multiple subjects. Our model represents the TME as a\nmultivariate log-Gaussian Cox process, where spatial intensity functions of\ndifferent cell types are governed by a latent multivariate Gaussian process. By\npooling information across subjects, we estimate spatial correlation functions\nthat capture within-type and cross-type dependencies, enabling interpretable\ninference about disease-specific cellular organization. We validate our method\nusing simulations, demonstrating robustness to latent factor specification and\nspatial resolution. We apply our approach to two multiplexed imaging datasets:\npancreatic cancer and colorectal cancer, revealing distinct spatial\norganization patterns across disease subtypes and highlighting tumor-immune\ninteractions that differentiate immune-permissive and immune-exclusive\nmicroenvironments. These findings provide insight into mechanisms of immune\nevasion and may inform novel therapeutic strategies. Our approach offers a\nprincipled framework for modeling spatial dependencies in multi-subject data,\nwith broader applicability to spatially resolved omics and imaging studies. An\nR package, available online, implements our methods.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-03T15:32:25Z"}
{"aid":"http://arxiv.org/abs/2504.02697v1","title":"Learning Phase Distortion with Selective State Space Models for Video\n  Turbulence Mitigation","summary":"Atmospheric turbulence is a major source of image degradation in long-range\nimaging systems. Although numerous deep learning-based turbulence mitigation\n(TM) methods have been proposed, many are slow, memory-hungry, and do not\ngeneralize well. In the spatial domain, methods based on convolutional\noperators have a limited receptive field, so they cannot handle a large spatial\ndependency required by turbulence. In the temporal domain, methods relying on\nself-attention can, in theory, leverage the lucky effects of turbulence, but\ntheir quadratic complexity makes it difficult to scale to many frames.\nTraditional recurrent aggregation methods face parallelization challenges.\n  In this paper, we present a new TM method based on two concepts: (1) A\nturbulence mitigation network based on the Selective State Space Model\n(MambaTM). MambaTM provides a global receptive field in each layer across\nspatial and temporal dimensions while maintaining linear computational\ncomplexity. (2) Learned Latent Phase Distortion (LPD). LPD guides the state\nspace model. Unlike classical Zernike-based representations of phase\ndistortion, the new LPD map uniquely captures the actual effects of turbulence,\nsignificantly improving the model's capability to estimate degradation by\nreducing the ill-posedness. Our proposed method exceeds current\nstate-of-the-art networks on various synthetic and real-world TM benchmarks\nwith significantly faster inference speed. The code is available at\nhttp://github.com/xg416/MambaTM.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T15:33:18Z"}
{"aid":"http://arxiv.org/abs/2504.02715v1","title":"Equality of tropical rank and dimension for tropical linear series","summary":"The tropical rank of a semimodule of rational functions on a metric graph\nmirrors the concept of rank in linear algebra. Defined in terms of the maximal\nnumber of tropically independent elements within the semimodule, this quantity\nhas remained elusive due to the challenges of computing it in practice. In this\nnote, we establish that the tropical rank is, in fact, precisely equal to the\ntopological dimension of the semimodule, one more than the dimension of the\nassociated linear system of divisors. Moreover, we show that the equality of\ndivisorial and tropical ranks in the definition of tropical linear series is\nequivalent to the pure dimensionality of the corresponding linear system. We\nconclude with complementary results and questions on combinatorial and\ntopological properties of the tropical rank.","main_category":"math.AG","categories":"math.AG,math.CO","published":"2025-04-03T15:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.02725v1","title":"ERPO: Advancing Safety Alignment via Ex-Ante Reasoning Preference\n  Optimization","summary":"Recent advancements in large language models (LLMs) have accelerated progress\ntoward artificial general intelligence, yet their potential to generate harmful\ncontent poses critical safety challenges. Existing alignment methods often\nstruggle to cover diverse safety scenarios and remain vulnerable to adversarial\nattacks. In this work, we propose Ex-Ante Reasoning Preference Optimization\n(ERPO), a novel safety alignment framework that equips LLMs with explicit\npreemptive reasoning through Chain-of-Thought and provides clear evidence for\nsafety judgments by embedding predefined safety rules. Specifically, our\napproach consists of three stages: first, equipping the model with Ex-Ante\nreasoning through supervised fine-tuning (SFT) using a constructed reasoning\nmodule; second, enhancing safety, usefulness, and efficiency via Direct\nPreference Optimization (DPO); and third, mitigating inference latency with a\nlength-controlled iterative preference optimization strategy. Experiments on\nmultiple open-source LLMs demonstrate that ERPO significantly enhances safety\nperformance while maintaining response efficiency.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:07:38Z"}
{"aid":"http://arxiv.org/abs/2504.02763v1","title":"CanonNet: Canonical Ordering and Curvature Learning for Point Cloud\n  Analysis","summary":"Point cloud processing poses two fundamental challenges: establishing\nconsistent point ordering and effectively learning fine-grained geometric\nfeatures. Current architectures rely on complex operations that limit\nexpressivity while struggling to capture detailed surface geometry. We present\nCanonNet, a lightweight neural network composed of two complementary\ncomponents: (1) a preprocessing pipeline that creates a canonical point\nordering and orientation, and (2) a geometric learning framework where networks\nlearn from synthetic surfaces with precise curvature values. This modular\napproach eliminates the need for complex transformation-invariant architectures\nwhile effectively capturing local geometric properties. Our experiments\ndemonstrate state-of-the-art performance in curvature estimation and\ncompetitive results in geometric descriptor tasks with significantly fewer\nparameters (\\textbf{100X}) than comparable methods. CanonNet's efficiency makes\nit particularly suitable for real-world applications where computational\nresources are limited, demonstrating that mathematical preprocessing can\neffectively complement neural architectures for point cloud analysis. The code\nfor the project is publicly available\n\\hyperlink{https://benjyfri.github.io/CanonNet/}{https://benjyfri.github.io/CanonNet/}.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T16:58:57Z"}
{"aid":"http://arxiv.org/abs/2504.02819v1","title":"GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution\n  Kernel Using Gaussian Mixture Rings","summary":"Symmetry, where certain features remain invariant under geometric\ntransformations, can often serve as a powerful prior in designing convolutional\nneural networks (CNNs). While conventional CNNs inherently support\ntranslational equivariance, extending this property to rotation and reflection\nhas proven challenging, often forcing a compromise between equivariance,\nefficiency, and information loss. In this work, we introduce Gaussian Mixture\nRing Convolution (GMR-Conv), an efficient convolution kernel that smooths\nradial symmetry using a mixture of Gaussian-weighted rings. This design\nmitigates discretization errors of circular kernels, thereby preserving robust\nrotation and reflection equivariance without incurring computational overhead.\nWe further optimize both the space and speed efficiency of GMR-Conv via a novel\nparameterization and computation strategy, allowing larger kernels at an\nacceptable cost. Extensive experiments on eight classification and one\nsegmentation datasets demonstrate that GMR-Conv not only matches conventional\nCNNs' performance but can also surpass it in applications with orientation-less\ndata. GMR-Conv is also proven to be more robust and efficient than the\nstate-of-the-art equivariant learning methods. Our work provides inspiring\nempirical evidence that carefully applied radial symmetry can alleviate the\nchallenges of information loss, marking a promising advance in equivariant\nnetwork architectures. The code is available at\nhttps://github.com/XYPB/GMR-Conv.","main_category":"cs.CV","categories":"cs.CV,cs.AI,eess.IV,eess.SP","published":"2025-04-03T17:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.04717v1","title":"Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large\n  Language Models","summary":"Recent advancements in large language models (LLMs) have revolutionized their\nability to handle single-turn tasks, yet real-world applications demand\nsophisticated multi-turn interactions. This survey provides a comprehensive\nreview of recent advancements in evaluating and enhancing multi-turn\ninteractions in LLMs. Focusing on task-specific scenarios, from instruction\nfollowing in diverse domains such as math and coding to complex conversational\nengagements in roleplay, healthcare, education, and even adversarial jailbreak\nsettings, we systematically examine the challenges of maintaining context,\ncoherence, fairness, and responsiveness over prolonged dialogues. The paper\norganizes current benchmarks and datasets into coherent categories that reflect\nthe evolving landscape of multi-turn dialogue evaluation. In addition, we\nreview a range of enhancement methodologies under multi-turn settings,\nincluding model-centric strategies (contextual learning, supervised\nfine-tuning, reinforcement learning, and new architectures), external\nintegration approaches (memory-augmented, retrieval-based methods, and\nknowledge graph), and agent-based techniques for collaborative interactions.\nFinally, we discuss open challenges and propose future directions for research\nto further advance the robustness and effectiveness of multi-turn interactions\nin LLMs. Related resources and papers are available at\nhttps://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T04:00:08Z"}
{"aid":"http://arxiv.org/abs/2504.04768v1","title":"Strong approximation and central limit theorems for multiscale\n  stochastic gene networks","summary":"We study a mutliscale jump process introduced in a work by Crudu, Debussche,\nMuller and Radulescu. Using an adequate coupling, we are able to prove the\nstrong convergence, for the uniform topology, to a piecewise deterministic\nMarkov process. Under some additional regularity, we also obtain a central\nlimit theorem and prove that the fluctuations of the continuous scale converge,\nin a weaker sense, to the solution of a stochastic differential equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T06:46:30Z"}
{"aid":"http://arxiv.org/abs/2504.04789v1","title":"Multimodal Agricultural Agent Architecture (MA3): A New Paradigm for\n  Intelligent Agricultural Decision-Making","summary":"As a strategic pillar industry for human survival and development, modern\nagriculture faces dual challenges: optimizing production efficiency and\nachieving sustainable development. Against the backdrop of intensified climate\nchange leading to frequent extreme weather events, the uncertainty risks in\nagricultural production systems are increasing exponentially. To address these\nchallenges, this study proposes an innovative \\textbf{M}ultimodal\n\\textbf{A}gricultural \\textbf{A}gent \\textbf{A}rchitecture (\\textbf{MA3}),\nwhich leverages cross-modal information fusion and task collaboration\nmechanisms to achieve intelligent agricultural decision-making. This study\nconstructs a multimodal agricultural agent dataset encompassing five major\ntasks: classification, detection, Visual Question Answering (VQA), tool\nselection, and agent evaluation. We propose a unified backbone for sugarcane\ndisease classification and detection tools, as well as a sugarcane disease\nexpert model. By integrating an innovative tool selection module, we develop a\nmultimodal agricultural agent capable of effectively performing tasks in\nclassification, detection, and VQA. Furthermore, we introduce a\nmulti-dimensional quantitative evaluation framework and conduct a comprehensive\nassessment of the entire architecture over our evaluation dataset, thereby\nverifying the practicality and robustness of MA3 in agricultural scenarios.\nThis study provides new insights and methodologies for the development of\nagricultural agents, holding significant theoretical and practical\nimplications. Our source code and dataset will be made publicly available upon\nacceptance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T07:32:41Z"}
{"aid":"http://arxiv.org/abs/2504.04790v1","title":"Unified speed limits in classical and quantum dynamics via temporal\n  Fisher information","summary":"The importance of Fisher information is increasing in nonequilibrium\nthermodynamics, as it has played a fundamental role in trade-off relations such\nas thermodynamic uncertainty relations and speed limits. In this work, we\ninvestigate temporal Fisher information, which measures the temporal\ninformation content encoded in probability distributions, for both classical\nand quantum systems. We establish that temporal Fisher information is bounded\nfrom above by physical costs, such as entropy production in classical Langevin\nand Markov processes, and the variance of interaction Hamiltonians in open\nquantum systems. Conversely, temporal Fisher information is bounded from below\nby statistical distances (e.g., the Bhattacharyya arccos distance), leading to\nclassical and quantum speed limits that constrain the minimal time required for\nstate transformations. Our work provides a unified perspective of speed limits\nfrom the point of view of temporal Fisher information in both classical and\nquantum dynamics.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-07T07:34:18Z"}
{"aid":"http://arxiv.org/abs/2504.04799v1","title":"Topological Schrödinger Bridge Matching","summary":"Given two boundary distributions, the Schr\\\"odinger Bridge (SB) problem seeks\nthe ``most likely`` random evolution between them with respect to a reference\nprocess. It has revealed rich connections to recent machine learning methods\nfor generative modeling and distribution matching. While these methods perform\nwell in Euclidean domains, they are not directly applicable to topological\ndomains such as graphs and simplicial complexes, which are crucial for data\ndefined over network entities, such as node signals and edge flows. In this\nwork, we propose the Topological Schr\\\"odinger Bridge problem (TSBP) for\nmatching signal distributions on a topological domain. We set the reference\nprocess to follow some linear tractable topology-aware stochastic dynamics such\nas topological heat diffusion. For the case of Gaussian boundary distributions,\nwe derive a closed-form topological SB (TSB) in terms of its time-marginal and\nstochastic differential. In the general case, leveraging the well-known result,\nwe show that the optimal process follows the forward-backward topological\ndynamics governed by some unknowns. Building on these results, we develop\nTSB-based models for matching topological signals by parameterizing the\nunknowns in the optimal process as (topological) neural networks and learning\nthem through likelihood training. We validate the theoretical results and\ndemonstrate the practical applications of TSB-based models on both synthetic\nand real-world networks, emphasizing the role of topology. Additionally, we\ndiscuss the connections of TSB-based models to other emerging models, and\noutline future directions for topological signal matching.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-07T07:45:21Z"}
{"aid":"http://arxiv.org/abs/2504.04835v1","title":"Inland Waterway Object Detection in Multi-environment: Dataset and\n  Approach","summary":"The success of deep learning in intelligent ship visual perception relies\nheavily on rich image data. However, dedicated datasets for inland waterway\nvessels remain scarce, limiting the adaptability of visual perception systems\nin complex environments. Inland waterways, characterized by narrow channels,\nvariable weather, and urban interference, pose significant challenges to object\ndetection systems based on existing datasets. To address these issues, this\npaper introduces the Multi-environment Inland Waterway Vessel Dataset (MEIWVD),\ncomprising 32,478 high-quality images from diverse scenarios, including sunny,\nrainy, foggy, and artificial lighting conditions. MEIWVD covers common vessel\ntypes in the Yangtze River Basin, emphasizing diversity, sample independence,\nenvironmental complexity, and multi-scale characteristics, making it a robust\nbenchmark for vessel detection. Leveraging MEIWVD, this paper proposes a\nscene-guided image enhancement module to improve water surface images based on\nenvironmental conditions adaptively. Additionally, a parameter-limited dilated\nconvolution enhances the representation of vessel features, while a multi-scale\ndilated residual fusion method integrates multi-scale features for better\ndetection. Experiments show that MEIWVD provides a more rigorous benchmark for\nobject detection algorithms, and the proposed methods significantly improve\ndetector performance, especially in complex multi-environment scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.04839v1","title":"Crossed Ponderomotive Lenses for Spherical Aberration Correction in\n  Electron Optics","summary":"This article evaluates the lens characteristics of a non-rotationally\nsymmetric electron lens based on a ponderomotive potential (i.e., a\nponderomotive lens) formed by intersecting one or more optical beams\nperpendicular to an electron beam. Based on geometric optics, design formulas\nare derived for the focal length and general spherical aberration coefficients\nof specifically crossed ponderomotive lenses. Numerical calculations\ndemonstrate that a pair of these crossed ponderomotive lenses can effectively\ncorrect spherical aberration in the objective lens of an electron microscope.\nUnlike rotationally symmetric ponderomotive lenses, which require the optical\nbeam to be coaxially aligned with the electron beam, the crossed ponderomotive\nlens avoids the need to place optical mirrors and lenses directly on the beam\naxis. Thus, it offers practical advantages in designing and building electron\noptical instruments and contributes to system miniaturization. With lens\nproperties similar to multipole lenses, the proposed crossed ponderomotive lens\nis expected to facilitate diverse developments in electron optical systems\nincorporating ponderomotive potentials.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T08:49:37Z"}
{"aid":"http://arxiv.org/abs/2504.04865v1","title":"Imagining the Far East: Exploring Perceived Biases in AI-Generated\n  Images of East Asian Women","summary":"Image-generating AI, which allows users to create images from text, is\nincreasingly used to produce visual content. Despite its advancements, cultural\nbiases in AI-generated images have raised significant concerns. While much\nresearch has focused on issues within Western contexts, our study examines the\nperceived biases regarding the portrayal of East Asian women. In this\nexploratory study, we invited East Asian users to audit three popular models\n(DALL-E, Midjourney, Stable Diffusion) and identified 18 specific perceived\nbiases, categorized into four patterns: Westernization, overuse or misuse of\ncultural symbols, sexualization & feminization, and racial stereotypes. This\nwork highlights the potential challenges posed by AI models in portraying\nEastern individuals.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-07T09:20:14Z"}
{"aid":"http://arxiv.org/abs/2504.04866v1","title":"Optimal Network-Guided Covariate Selection for High-Dimensional Data\n  Integration","summary":"When integrating datasets from different studies, it is common that they have\ncomponents of different formats. How to combine them organically for improved\nestimation is important and challenging. This paper investigates this problem\nin a two-study scenario, where covariates are observed for all subjects, but\nnetwork data is available in only one study, and response variables are\navailable only in the other.\n  To leverage the partially observed network information, we propose the\nNetwork-Guided Covariate Selection (NGCS) algorithm. It integrates the spectral\ninformation from network adjacency matrices with the Higher Criticism\nThresholding approach for informative covariates identification. Theoretically,\nwe prove that NGCS achieves the optimal rate in covariate selection, which is\nthe same rate in the supervised learning setting. Furthermore, this optimality\nis robust to network models and tuning parameters.\n  This framework extends naturally to clustering and regression tasks, with two\nproposed algorithms: NG-clu and NG-reg. For clustering, NG-clu accurately\nclusters data points despite incomplete network information. For regression,\nNG-reg enhances predictive performance by incorporating latent covariate\nstructures inferred from network data. Empirical studies on synthetic and\nreal-world datasets demonstrate the robustness and superior performance of our\nalgorithms, underscoring their effectiveness in handling heterogeneous data\nformats.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-07T09:21:34Z"}
{"aid":"http://arxiv.org/abs/2504.04874v1","title":"Futureproof Static Memory Planning","summary":"The NP-complete combinatorial optimization task of assigning offsets to a set\nof buffers with known sizes and lifetimes so as to minimize total memory usage\nis called dynamic storage allocation (DSA). Existing DSA implementations bypass\nthe theoretical state-of-the-art algorithms in favor of either fast but\nwasteful heuristics, or memory-efficient approaches that do not scale beyond\none thousand buffers. The \"AI memory wall\", combined with deep neural networks'\nstatic architecture, has reignited interest in DSA. We present idealloc, a\nlow-fragmentation, high-performance DSA implementation designed for\nmillion-buffer instances. Evaluated on a novel suite of particularly hard\nbenchmarks from several domains, idealloc ranks first against four production\nimplementations in terms of a joint effectiveness/robustness criterion.","main_category":"cs.OS","categories":"cs.OS,cs.AI,cs.PL","published":"2025-04-07T09:28:54Z"}
{"aid":"http://arxiv.org/abs/2504.04877v1","title":"SoK: LLM-based Log Parsing","summary":"Log data, generated by software systems, provides crucial insights for tasks\nlike monitoring, root cause analysis, and anomaly detection. Due to the vast\nvolume of logs, automated log parsing is essential to transform semi-structured\nlog messages into structured representations. Traditional log parsing\ntechniques often require manual configurations, such as defining log formats or\nlabeling data, which limits scalability and usability. Recent advances in large\nlanguage models (LLMs) have introduced the new research field of LLM-based log\nparsing, offering potential improvements in automation and adaptability.\nDespite promising results, there is no structured overview of these approaches\nsince this is a relatively new research field with the earliest advances\npublished in late 2023. This paper systematically reviews 29 LLM-based log\nparsing methods, comparing their capabilities, limitations, and reliance on\nmanual effort. We analyze the learning and prompt-engineering paradigms\nemployed, efficiency- and effectiveness-enhancing techniques, and the role of\nLLMs in the parsing process. We aggregate the results of the survey in a large\ntable comprising the characterizing features of LLM-based log parsing\napproaches and derive the general process of LLM-based log parsing,\nincorporating all reviewed approaches in a single flow chart. Additionally, we\nbenchmark seven open-source LLM-based log parsers on public datasets and\ncritically assess their reproducibility. Our findings summarize the advances of\nthis new research field and provide insights for researchers and practitioners\nseeking efficient and user-friendly log parsing solutions, with all code and\nresults made publicly available for transparency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T09:41:04Z"}
{"aid":"http://arxiv.org/abs/2504.04898v1","title":"SLIDE: Automated Identification and Quantification of Grain Boundary\n  Sliding and Opening in 3D","summary":"Grain Boundary (GB) deformation mechanisms such as Sliding (GBS) and Opening\n(GBO) are prevalent in alloys at high homologous temperatures but are hard to\ncapture quantitatively. We propose an automated procedure to quantify 3D GB\ndeformations at the nanoscale, using a combination of precisely aligned Digital\nImage Correlation (DIC), electron backscatter diffraction, optical\nprofilometry, and in-beam secondary electron maps. The framework, named Sliding\nidentification by Local Integration of Displacements across Edges (SLIDE), (i)\ndistinguishes GBS from GBO, (ii) computes the datapoint-wise measured in-plane\ndisplacement gradient tensor (from DIC), (iii) projects this data onto the\ntheoretical GBS tensor to reject near-GB plasticity/elasticity/noise, and (iv)\nadds the out-of-plane step from optical profilometry to yield the local 3D\nGBS/GBO vector; automatically repeated for each $\\sim$50nm-long GB segment.\nSLIDE is validated on a virtual experiment of discrete 3D sliding, and\nsuccessfully applied to Zn-coated steel experiments, yielding quantitative\nGBS/GBO activity maps.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T10:14:25Z"}
{"aid":"http://arxiv.org/abs/2504.04899v1","title":"Achieving precision in measuring birefringence characteristics of a\n  periodically-poled Lithium Niobate waveguide","summary":"The refraction of light in an optical medium is not only a subject of\nfundamental interest, but the refractive index also plays a crucial role in\napplications involving integrated and non-linear optics. One such application\nis photon-pair generation in waveguides with second-order non-linearity. The\nspectral properties of the generated photon pairs are governed by the effective\ngroup refractive indices of the interacting modes, which normally are\ncalculated via Sellmeier's equations for bulk crystals. However, in integrated\noptics, the effective group refractive indices experienced by the propagating\nmodes can differ from those in bulk materials. Therefore, we present an\naccurate, in-situ measurement technique for determining the birefringence\ncharacteristics of a structure with high reflective end facets by performing a\nFourier transformation of the light transmission spectrum and apply this method\nto a periodically-poled Lithium Niobate waveguide resonator in the telecom\nwavelength range. We directly predict important spectral figures of merit of\nthe photon-pair generation process, which depend on the optical path length\ndifference that can be resolved with a high precision of more than 16 standard\ndeviations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T10:15:03Z"}
{"aid":"http://arxiv.org/abs/2504.04911v1","title":"IterMask3D: Unsupervised Anomaly Detection and Segmentation with\n  Test-Time Iterative Mask Refinement in 3D Brain MR","summary":"Unsupervised anomaly detection and segmentation methods train a model to\nlearn the training distribution as 'normal'. In the testing phase, they\nidentify patterns that deviate from this normal distribution as 'anomalies'. To\nlearn the `normal' distribution, prevailing methods corrupt the images and\ntrain a model to reconstruct them. During testing, the model attempts to\nreconstruct corrupted inputs based on the learned 'normal' distribution.\nDeviations from this distribution lead to high reconstruction errors, which\nindicate potential anomalies. However, corrupting an input image inevitably\ncauses information loss even in normal regions, leading to suboptimal\nreconstruction and an increased risk of false positives. To alleviate this, we\npropose IterMask3D, an iterative spatial mask-refining strategy designed for 3D\nbrain MRI. We iteratively spatially mask areas of the image as corruption and\nreconstruct them, then shrink the mask based on reconstruction error. This\nprocess iteratively unmasks 'normal' areas to the model, whose information\nfurther guides reconstruction of 'normal' patterns under the mask to be\nreconstructed accurately, reducing false positives. In addition, to achieve\nbetter reconstruction performance, we also propose using high-frequency image\ncontent as additional structural information to guide the reconstruction of the\nmasked area. Extensive experiments on the detection of both synthetic and\nreal-world imaging artifacts, as well as segmentation of various pathological\nlesions across multiple MRI sequences, consistently demonstrate the\neffectiveness of our proposed method.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T10:41:23Z"}
{"aid":"http://arxiv.org/abs/2504.04958v1","title":"Probabilistic imaginary-time evolution in state-vector-based and\n  shot-based simulations and on quantum devices","summary":"Imaginary-time evolution, an important technique in tensor network and\nquantum Monte Carlo algorithms on classical computers, has recently been\nadapted to quantum computing. In this study, we focus on probabilistic\nimaginary-time evolution (PITE) algorithm and derive its formulation in the\ncontext of state-vector-based simulations, where quantum state vectors are\ndirectly used to compute observables without statistical errors. We compare the\nresults with those of shot-based simulations, which estimate observables\nthrough repeated projective measurements. Applying the PITE algorithm to the\nHeisenberg chain, we investigate optimal initial conditions for convergence. We\nfurther demonstrate the method on the transverse-field Ising model using a\nstate-of-the-art trapped-ion quantum device. Finally, we explore the potential\nof error mitigation in this framework, highlighting practical considerations\nfor near-term digital quantum simulations.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-07T11:45:31Z"}
{"aid":"http://arxiv.org/abs/2504.04971v1","title":"Below threshold nonsequential double ionization with linearly polarized\n  two-color fields II: Quantum interference","summary":"We perform a systematic analysis of intra-channel quantum interference in\nlaser-induced nonsequential double ionization with linearly polarized\nbichromatic fields, focusing on the recollision-excitation with subsequent\nionization (RESI) mechanism, and employing the strong-field approximation. We\ngeneralize and elaborate several analytic interference conditions for RESI in\narbitrary driving fields, with a focus on the interference arising from the\nspecific symmetries of bichromatic fields. For example, for waves of comparable\nstrengths, multiple events per half cycle for the direct electron must be\nconsidered. Furthermore, interference breaks some of the symmetries arising\nfrom the field. We detangle the superimposed interference fringes originating\nfrom phase differences related to symmetrization due to electron exchange,\ntemporal shifts and a combination of exchange and event interference. We show\nthat the hierarchy between exchange-only and exchange-temporal interference is\nfluid and can be manipulated by an appropriate choice of driving-field\nparameters. This is enabled by different types of interference occupying\nspecific regions of the plane spanned by the electron momentum components\nparallel to the driving-field polarization.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-07T11:57:18Z"}
{"aid":"http://arxiv.org/abs/2504.04976v1","title":"A Domain-Based Taxonomy of Jailbreak Vulnerabilities in Large Language\n  Models","summary":"The study of large language models (LLMs) is a key area in open-world machine\nlearning. Although LLMs demonstrate remarkable natural language processing\ncapabilities, they also face several challenges, including consistency issues,\nhallucinations, and jailbreak vulnerabilities. Jailbreaking refers to the\ncrafting of prompts that bypass alignment safeguards, leading to unsafe outputs\nthat compromise the integrity of LLMs. This work specifically focuses on the\nchallenge of jailbreak vulnerabilities and introduces a novel taxonomy of\njailbreak attacks grounded in the training domains of LLMs. It characterizes\nalignment failures through generalization, objectives, and robustness gaps. Our\nprimary contribution is a perspective on jailbreak, framed through the\ndifferent linguistic domains that emerge during LLM training and alignment.\nThis viewpoint highlights the limitations of existing approaches and enables us\nto classify jailbreak attacks on the basis of the underlying model deficiencies\nthey exploit. Unlike conventional classifications that categorize attacks based\non prompt construction methods (e.g., prompt templating), our approach provides\na deeper understanding of LLM behavior. We introduce a taxonomy with four\ncategories -- mismatched generalization, competing objectives, adversarial\nrobustness, and mixed attacks -- offering insights into the fundamental nature\nof jailbreak vulnerabilities. Finally, we present key lessons derived from this\ntaxonomic study.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-04-07T12:05:16Z"}
{"aid":"http://arxiv.org/abs/2504.04980v1","title":"Combining kinetic and thermodynamic uncertainty relations in quantum\n  transport","summary":"We study the fluctuations of generic currents in multi-terminal,\nmulti-channel quantum transport settings. In the quantum regime, these\nfluctuations and the resulting precision differ strongly depending on whether\nthe device is of fermionic or bosonic nature. Using scattering theory, we show\nthat the precision is bounded by constraints set by the entropy production and\nby the activity in the spirit of thermodynamic or kinetic uncertainty\nrelations, valid for fermionic and bosonic quantum systems and even in the\nabsence of time-reversal symmetry. Furthermore, we derive a combined\nthermodynamic kinetic uncertainty relation, which is tight over a wide range of\nparameters and can hence predict the reachable precision of a device.\n  Since these constraints can be expressed in terms of observables accessible\nin transport measurements, such as currents and bandwidth, we foresee that the\ntight thermodynamic kinetic uncertainty-like bounds are also useful as an\ninference tool: they can be exploited to estimate entropy production from\ntransport observables, such as the charge current and its noise, which are more\neasily accessible in experiment.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-04-07T12:09:09Z"}
{"aid":"http://arxiv.org/abs/2504.05001v1","title":"SILVIA: Ultra-precision formation flying demonstration for space-based\n  interferometry","summary":"We propose SILVIA (Space Interferometer Laboratory Voyaging towards\nInnovative Applications), a mission concept designed to demonstrate\nultra-precision formation flying between three spacecraft separated by 100 m.\nSILVIA aims to achieve sub-micrometer precision in relative distance control by\nintegrating spacecraft sensors, laser interferometry, low-thrust and low-noise\nmicro-propulsion for real-time measurement and control of distances and\nrelative orientations between spacecraft. A 100-meter-scale mission in a\nnear-circular low Earth orbit has been identified as an ideal, cost-effective\nsetting for demonstrating SILVIA, as this configuration maintains a good\nbalance between small relative perturbations and low risk for collision. This\nmission will fill the current technology gap towards future missions, including\ngravitational wave observatories such as DECIGO (DECihertz Interferometer\nGravitational wave Observatory), designed to detect the primordial\ngravitational wave background, and high-contrast nulling infrared\ninterferometers like LIFE (Large Interferometer for Exoplanets), designed for\ndirect imaging of thermal emissions from nearby terrestrial planet candidates.\nThe mission concept and its key technologies are outlined, paving the way for\nthe next generation of high-precision space-based observatories.","main_category":"astro-ph.IM","categories":"astro-ph.IM,cs.SY,eess.SY,gr-qc,physics.ins-det","published":"2025-04-07T12:27:46Z"}
{"aid":"http://arxiv.org/abs/2504.05004v1","title":"Stacking Variational Bayesian Monte Carlo","summary":"Variational Bayesian Monte Carlo (VBMC) is a sample-efficient method for\napproximate Bayesian inference with computationally expensive likelihoods.\nWhile VBMC's local surrogate approach provides stable approximations, its\nconservative exploration strategy and limited evaluation budget can cause it to\nmiss regions of complex posteriors. In this work, we introduce Stacking\nVariational Bayesian Monte Carlo (S-VBMC), a method that constructs global\nposterior approximations by merging independent VBMC runs through a principled\nand inexpensive post-processing step. Our approach leverages VBMC's mixture\nposterior representation and per-component evidence estimates, requiring no\nadditional likelihood evaluations while being naturally parallelizable. We\ndemonstrate S-VBMC's effectiveness on two synthetic problems designed to\nchallenge VBMC's exploration capabilities and two real-world applications from\ncomputational neuroscience, showing substantial improvements in posterior\napproximation quality across all cases.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-07T12:30:59Z"}
{"aid":"http://arxiv.org/abs/2504.05028v1","title":"The Lorentzian splitting theorem with weakened curvature condition","summary":"In this note we present a version of the Lorentzian splitting theorem under\nan averaged Ricci curvature condition, utilizing, in its proof, the properties\nof achronal limits developed in [18], [19].","main_category":"math.DG","categories":"math.DG,gr-qc","published":"2025-04-07T12:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.05030v1","title":"AsyReC: A Multimodal Graph-based Framework for Spatio-Temporal\n  Asymmetric Dyadic Relationship Classification","summary":"Dyadic social relationships, which refer to relationships between two\nindividuals who know each other through repeated interactions (or not), are\nshaped by shared spatial and temporal experiences. Current computational\nmethods for modeling these relationships face three major challenges: (1) the\nfailure to model asymmetric relationships, e.g., one individual may perceive\nthe other as a friend while the other perceives them as an acquaintance, (2)\nthe disruption of continuous interactions by discrete frame sampling, which\nsegments the temporal continuity of interaction in real-world scenarios, and\n(3) the limitation to consider periodic behavioral cues, such as rhythmic\nvocalizations or recurrent gestures, which are crucial for inferring the\nevolution of dyadic relationships. To address these challenges, we propose\nAsyReC, a multimodal graph-based framework for asymmetric dyadic relationship\nclassification, with three core innovations: (i) a triplet graph neural network\nwith node-edge dual attention that dynamically weights multimodal cues to\ncapture interaction asymmetries (addressing challenge 1); (ii) a clip-level\nrelationship learning architecture that preserves temporal continuity, enabling\nfine-grained modeling of real-world interaction dynamics (addressing challenge\n2); and (iii) a periodic temporal encoder that projects time indices onto\nsine/cosine waveforms to model recurrent behavioral patterns (addressing\nchallenge 3). Extensive experiments on two public datasets demonstrate\nstate-of-the-art performance, while ablation studies validate the critical role\nof asymmetric interaction modeling and periodic temporal encoding in improving\nthe robustness of dyadic relationship classification in real-world scenarios.\nOur code is publicly available at: https://github.com/tw-repository/AsyReC.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-07T12:52:23Z"}
{"aid":"http://arxiv.org/abs/2504.05052v1","title":"Assess Space-Based Solar Power in European-Scale Power System\n  Decarbonization","summary":"Meeting net-zero targets remains formidable as terrestrial renewables grapple\nwith intermittency and regional variability. Here, we integrate space-based\nsolar power (SBSP) -- a potential near-constant, orbital solar technology --\ninto a high-resolution, Europe-wide capacity-expansion and dispatch model to\nquantify its contribution under net-zero constraints. We examine two advanced\nSBSP designs: (1) a near-baseload, low Technology Readiness Level (TRL) concept\n(heliostat-based Representative Design RD1) and (2) a partially intermittent,\nhigher-TRL concept (planar-based RD2), both drawing on NASA's 2050 cost and\nperformance projections. Our results show that RD1 can reduce total system\ncosts by 7--15%, displace up to 80% of intermittent wind and solar, and cut\nbattery usage by over 70%, if it meets its forecast cost reductions -- though\nlong-duration storage (e.g., hydrogen) remains essential for seasonal\nbalancing. By contrast, RD2 is economically unattractive at its projected 2050\ncosts. Through extensive sensitivity analyses, we identify cost thresholds at\nwhich SBSP shifts from cost-prohibitive to complementary and ultimately to a\ndominant baseload technology. Specifically, RD1 becomes complementary at\nroughly 14x and dominant at 9x the 2050 solar PV capital cost, benefiting from\nits continuous power generation. Meanwhile, RD2 must achieve even lower cost\nlevels (9x to be complementary and 6x to dominate) and would rely on\nshort-duration storage to mitigate its partial intermittency. These findings\nprovide quantified techno-economic benchmarks and reveal alternative net-zero\npathways, offering critical guidance for policymakers and industry stakeholders\nseeking large-scale, centrally coordinated renewable solutions with non- or\nlow-intermittency.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-07T13:21:01Z"}
{"aid":"http://arxiv.org/abs/2504.05078v1","title":"Serverless Approach to Running Resource-Intensive STAR Aligner","summary":"The application of serverless computing for alignment of RNA-sequences can\nimprove many existing bioinformatics workflows by reducing operational costs\nand execution times. This work analyzes the applicability of serverless\nservices for running the STAR aligner, which is known for its accuracy and\nlarge memory requirement. This presents a challenge, as serverless services\nwere designed for light and short tasks. Nevertheless, we successfully deploy a\nSTAR-based pipeline on AWS ECS service, propose multiple optimizations, and\nperform experiment with 17 TBs of data. Results are compared against standard\nvirtual machine (VM) based solution showing that serverless is a valid\nalternative for small-scale batch processing. However, in large-scale where\nefficiency matters the most, VMs are still recommended.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-07T13:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.05093v1","title":"Flexible Estimation of the Heterogeneous Non-Parametric Component in a\n  Relative Survival Cure Model","summary":"Estimating the cure fraction in a diseased population, especially in the\npresence of competing mortality causes, is crucial for both patients and\nclinicians. It offers a valuable measure for monitoring and interpreting trends\nin disease outcomes. When information on the cause of death is unavailable or\nunreliable, the Relative Survival (RS) framework is the preferred approach for\nestimating Net Survival, which represents survival in a hypothetical scenario\nwhere the disease of interest is the only possible cause of death. In the\ncontext of cancer, RS often reaches a plateau, indicating that a portion of\ndiagnosed patients is cured, as they have the same risk of dying as a\ncomparable group of healthy individuals with similar demographic\ncharacteristics. Classical RS cure models use logistic regression to estimate\nthe fraction of cured patients. However, this functional form is somewhat\narbitrary, and misspecifying it can severely distort the resulting cure\nindicators. Consequently, evaluations of the efficacy of cancer treatments at\nthe population level could be inaccurate, leading to biased decision-making\nregarding patient care. In this paper, we address this issue by relaxing the\nparametric assumption and considering flexible functions of the covariates\nwithin the framework of \\textit{Generalized Models} and \\textit{Neural\nNetworks}. We design an EM algorithm for these RS cure models and conduct a\nsimulation study to compare our proposals with the classical approach. We apply\nour methodology to a real-world dataset from a historical Italian cancer\nregistry. The results demonstrate that our proposed models outperform the\nclassical approach and provide valuable insights into the survival outcomes of\nItalian colon cancer patients.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-07T14:00:37Z"}
{"aid":"http://arxiv.org/abs/2504.05113v1","title":"Minimal Reduction Type and Affine Springer Fibers","summary":"We extend a result of Yun on minimal reduction types to the parahoric case.\nThis implies a uniqueness property for 2-special representations appearing in\nthe cohomology of certain affine Springer fibers. Using this, we settle a\nconjecture of Lusztig on strata in a reductive group.","main_category":"math.RT","categories":"math.RT","published":"2025-04-07T14:15:55Z"}
{"aid":"http://arxiv.org/abs/2504.05176v1","title":"Cellular Network Design for UAV Corridors via Data-driven\n  High-dimensional Bayesian Optimization","summary":"We address the challenge of designing cellular networks for uncrewed aerial\nvehicles (UAVs) corridors through a novel data-driven approach. We assess\nmultiple state-of-the-art high-dimensional Bayesian optimization (HD-BO)\ntechniques to jointly optimize the cell antenna tilts and half-power beamwidth\n(HPBW). We find that some of these approaches achieve over 20dB gains in median\nSINR along UAV corridors, with negligible degradation to ground user\nperformance. Furthermore, we explore the HD-BO's capabilities in terms of model\ngeneralization via transfer learning, where data from a previously observed\nscenario source is leveraged to predict the optimal solution for a new scenario\ntarget. We provide examples of scenarios where such transfer learning is\nsuccessful and others where it fails. Moreover, we demonstrate that HD-BO\nenables multi-objective optimization, identifying optimal design trade-offs\nbetween data rates on the ground versus UAV coverage reliability. We observe\nthat aiming to provide UAV coverage across the entire sky can lower the rates\nfor ground users compared to setups specifically optimized for UAV corridors.\nFinally, we validate our approach through a case study in a real-world cellular\nnetwork, where HD-BO identifies optimal and non-obvious antenna configurations\nthat result in more than double the rates along 3D UAV corridors with\nnegligible ground performance loss.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-07T15:20:14Z"}
{"aid":"http://arxiv.org/abs/2504.05183v1","title":"Utility-aware Social Network Anonymization using Genetic Algorithms","summary":"Social networks may contain privacy-sensitive information about individuals.\nThe objective of the network anonymization problem is to alter a given social\nnetwork dataset such that the number of anonymous nodes in the social graph is\nmaximized. Here, a node is anonymous if it does not have a unique surrounding\nnetwork structure. At the same time, the aim is to ensure data utility, i.e.,\npreserve topological network properties and retain good performance on\ndownstream network analysis tasks. We propose two versions of a genetic\nalgorithm tailored to this problem: one generic GA and a uniqueness-aware GA\n(UGA). The latter aims to target edges more effectively during mutation by\navoiding edges connected to already anonymous nodes. After hyperparameter\ntuning, we compare the two GAs against two existing baseline algorithms on\nseveral real-world network datasets. Results show that the proposed genetic\nalgorithms manage to anonymize on average 14 times more nodes than the best\nbaseline algorithm. Additionally, data utility experiments demonstrate how the\nUGA requires fewer edge deletions, and how our GAs and the baselines retain\nperformance on downstream tasks equally well. Overall, our results suggest that\ngenetic algorithms are a promising approach for finding solutions to the\nnetwork anonymization problem.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-07T15:29:28Z"}
{"aid":"http://arxiv.org/abs/2504.05198v1","title":"Bayesian estimation of causal effects from observational categorical\n  data","summary":"We present a Bayesian procedure for estimation of pairwise intervention\neffects in a high-dimensional system of categorical variables. We assume that\nwe have observational data generated from an unknown causal Bayesian network\nfor which there are no latent confounders. Most of the existing methods\ndeveloped for this setting assume that the underlying model is linear Gaussian,\nincluding the Bayesian IDA (BIDA) method that we build upon in this work. By\ncombining a Bayesian backdoor estimator with model averaging, we obtain a\nposterior over the intervention distributions of a cause-effect pair that can\nbe expressed as a mixture over stochastic linear combinations of Dirichlet\ndistributions. Although there is no closed-form expression for the posterior\ndensity, it is straightforward to produce Monte Carlo approximations of target\nquantities through direct sampling, and we also derive closed-form expressions\nfor a few selected moments. To scale up the proposed procedure, we employ\nMarkov Chain Monte Carlo (MCMC), which also enables us to use more efficient\nadjustment sets compared to the current exact BIDA. Finally, we use\nJensen-Shannon divergence to define a novel causal effect based on a set of\nintervention distributions in the general categorical setting. We compare our\nmethod to the original IDA method and existing Bayesian approaches in numerical\nsimulations and show that categorical BIDA performs favorably against the\nexisting alternative methods in terms of producing point estimates and\ndiscovering strong effects.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-07T15:49:36Z"}
{"aid":"http://arxiv.org/abs/2504.05202v1","title":"Infinitely Divisible Noise for Differential Privacy: Nearly Optimal\n  Error in the High $\\varepsilon$ Regime","summary":"Differential privacy (DP) can be achieved in a distributed manner, where\nmultiple parties add independent noise such that their sum protects the overall\ndataset with DP. A common technique here is for each party to sample their\nnoise from the decomposition of an infinitely divisible distribution. We\nanalyze two mechanisms in this setting: 1) the generalized discrete Laplace\n(GDL) mechanism, whose distribution (which is closed under summation) follows\nfrom differences of i.i.d. negative binomial shares, and 2) the multi-scale\ndiscrete Laplace (MSDLap) mechanism, a novel mechanism following the sum of\nmultiple i.i.d. discrete Laplace shares at different scales.\n  For $\\varepsilon \\geq 1$, our mechanisms can be parameterized to have\n$O\\left(\\Delta^3 e^{-\\varepsilon}\\right)$ and $O\\left(\\min\\left(\\Delta^3\ne^{-\\varepsilon}, \\Delta^2 e^{-2\\varepsilon/3}\\right)\\right)$ MSE,\nrespectively, where $\\Delta$ denote the sensitivity; the latter bound matches\nknown optimality results. We also show a transformation from the discrete\nsetting to the continuous setting, which allows us to transform both mechanisms\nto the continuous setting and thereby achieve the optimal $O\\left(\\Delta^2\ne^{-2\\varepsilon / 3}\\right)$ MSE. To our knowledge, these are the first\ninfinitely divisible additive noise mechanisms that achieve order-optimal MSE\nunder pure DP, so our work shows formally there is no separation in utility\nwhen query-independent noise adding mechanisms are restricted to infinitely\ndivisible noise. For the continuous setting, our result improves upon the Arete\nmechanism from [Pagh and Stausholm, ALT 2022] which gives an MSE of\n$O\\left(\\Delta^2 e^{-\\varepsilon/4}\\right)$. Furthermore, we give an exact\nsampler tuned to efficiently implement the MSDLap mechanism, and we apply our\nresults to improve a state of the art multi-message shuffle DP protocol in the\nhigh $\\varepsilon$ regime.","main_category":"cs.CR","categories":"cs.CR,cs.DS","published":"2025-04-07T15:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.05204v1","title":"Quantum Program Linting with LLMs: Emerging Results from a Comparative\n  Study","summary":"Ensuring the quality of quantum programs is increasingly important; however,\ntraditional static analysis techniques are insufficient due to the unique\ncharacteristics of quantum computing. Quantum-specific linting tools, such as\nLintQ, have been developed to detect quantum-specific programming problems;\nhowever, they typically rely on manually crafted analysis queries. The manual\neffort required to update these tools limits their adaptability to evolving\nquantum programming practices.\n  To address this challenge, this study investigates the feasibility of\nemploying Large Language Models (LLMs) to develop a novel linting technique for\nquantum software development and explores potential avenues to advance linting\napproaches. We introduce LintQ-LLM, an LLM-based linting tool designed to\ndetect quantum-specific problems comparable to those identified by LintQ.\nThrough an empirical comparative study using real-world Qiskit programs, our\nresults show that LintQ-LLM is a viable solution that complements LintQ, with\nparticular strengths in problem localization, explanation clarity, and\nadaptability potential for emerging quantum programming frameworks, thus\nproviding a basis for further research. Furthermore, this study discusses\nseveral research opportunities for developing more advanced, adaptable, and\nfeedback-aware quantum software quality assurance methods by leveraging LLMs.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-07T15:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.05210v1","title":"A moving target in AI-assisted decision-making: Dataset shift, model\n  updating, and the problem of update opacity","summary":"Machine learning (ML) systems are vulnerable to performance decline over time\ndue to dataset shift. To address this problem, experts often suggest that ML\nsystems should be regularly updated to ensure ongoing performance stability.\nSome scholarly literature has begun to address the epistemic and ethical\nchallenges associated with different updating methodologies. Thus far, however,\nlittle attention has been paid to the impact of model updating on the\nML-assisted decision-making process itself, particularly in the AI ethics and\nAI epistemology literatures. This article aims to address this gap in the\nliterature. It argues that model updating introduces a new sub-type of opacity\ninto ML-assisted decision-making -- update opacity -- that occurs when users\ncannot understand how or why an update has changed the reasoning or behaviour\nof an ML system. This type of opacity presents a variety of distinctive\nepistemic and safety concerns that available solutions to the black box problem\nin ML are largely ill-equipped to address. A variety of alternative strategies\nmay be developed or pursued to address the problem of update opacity more\ndirectly, including bi-factual explanations, dynamic model reporting, and\nupdate compatibility. However, each of these strategies presents its own risks\nor carries significant limitations. Further research will be needed to address\nthe epistemic and safety concerns associated with model updating and update\nopacity going forward.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC,cs.LG","published":"2025-04-07T15:58:23Z"}
{"aid":"http://arxiv.org/abs/2504.05218v1","title":"Hybrid machine learning data assimilation for marine biogeochemistry","summary":"Marine biogeochemistry models are critical for forecasting, as well as\nestimating ecosystem responses to climate change and human activities. Data\nassimilation (DA) improves these models by aligning them with real-world\nobservations, but marine biogeochemistry DA faces challenges due to model\ncomplexity, strong nonlinearity, and sparse, uncertain observations. Existing\nDA methods applied to marine biogeochemistry struggle to update unobserved\nvariables effectively, while ensemble-based methods are computationally too\nexpensive for high-complexity marine biogeochemistry models. This study\ndemonstrates how machine learning (ML) can improve marine biogeochemistry DA by\nlearning statistical relationships between observed and unobserved variables.\nWe integrate ML-driven balancing schemes into a 1D prototype of a system used\nto forecast marine biogeochemistry in the North-West European Shelf seas. ML is\napplied to predict (i) state-dependent correlations from free-run ensembles and\n(ii), in an ``end-to-end'' fashion, analysis increments from an Ensemble Kalman\nFilter. Our results show that ML significantly enhances updates for previously\nnot-updated variables when compared to univariate schemes akin to those used\noperationally. Furthermore, ML models exhibit moderate transferability to new\nlocations, a crucial step toward scaling these methods to 3D operational\nsystems. We conclude that ML offers a clear pathway to overcome current\ncomputational bottlenecks in marine biogeochemistry DA and that refining\ntransferability, optimizing training data sampling, and evaluating scalability\nfor large-scale marine forecasting, should be future research priorities.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.LG","published":"2025-04-07T16:04:10Z"}
{"aid":"http://arxiv.org/abs/2504.05233v1","title":"Formation of Near-surface Atmospheric Inversion and Surface Inversion in\n  Hothouse Climates","summary":"A hothouse climate may develop throughout Earth's history and its warming\nfuture and on potentially habitable exoplanets near the inner edge of the\nhabitable zone. Previous studies suggested that near-surface atmospheric\ninversion (NAIV) with planetary boundary air temperature being higher than the\nair temperature adjacent to the surface, is a pronounced phenomenon in hothouse\nclimates. However, the underlying mechanisms are unclear. Here we show that\nlower-tropospheric radiative heating is necessary but not independently\nsufficient in forming the NAIV. Instead, the dynamic heating induced by\nlarge-scale subsidence is essential. With the prescribed reasonable large-scale\nsubsidence, NAIV appears in small-domain cloud-resolving simulations, which was\nnot observed in previous studies. Surface evaporative cooling also contributes\nto the formation of the NAIV. Besides NAIV, we find that surface inversion\n(SIV) with the air adjacent to the surface being warmer than the underlying sea\nsurface is also a distinct phenomenon in hothouse climates. SIV is caused by\nstrong surface evaporative cooling and large atmospheric shortwave absorption.\nThese two types of inversion strongly stabilize the atmosphere, weaken\natmospheric circulation, dry the free troposphere, and suppress the\nhydrological cycle.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.ao-ph","published":"2025-04-07T16:18:06Z"}
{"aid":"http://arxiv.org/abs/2504.05262v1","title":"Do PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning\n  vs. Memorization in Large Language Models","summary":"Despite high benchmark scores, Large Language Models (LLMs) often fail simple\nproblem, raising a critical question: Do LLMs learn mathematical principles or\nmerely memorize patterns? Rather than designing increasingly complex benchmarks\nlike recent works, we investigate this using elementary two-integer addition\n($0$ to $2^{64}$), probing two core properties: commutativity ($A+B=B+A$) and\ncompositional generalization (via isomorphic symbolic mappings, e.g., $7\n\\rightarrow y$). While state-of-the-art LLMs achieve 73.8-99.8\\% accuracy on\nnumerical addition, performance collapses to $\\leq$7.5\\% under symbolic\nmapping, indicating failure to generalize learned rules. Non-monotonic\nperformance scaling with digit count and frequent commutativity violations\n(over 1,700 cases of $A+B \\neq B+A$) further support this. Explicitly providing\naddition rules degrades performance by 81.2\\% on average, while\nself-explanation maintains baseline accuracy, suggesting LLM arithmetic\nprocessing is misaligned with human-defined principles. Our findings indicate\ncurrent LLMs rely on memory pattern over genuine rule learning, highlighting\narchitectural limitations and the need for new approaches to achieve true\nmathematical reasoning.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.05272v1","title":"The Standard Model tested with neutrinos","summary":"The Standard Model (SM) of particle physics effectively explains most\nobserved phenomena, though some anomalies, especially in the neutrino sector,\nsuggest the need for extensions. In this work, we perform the first global fit\nof elastic neutrino-nucleus and neutrino-electron scattering data to further\ntest the SM within a consistent framework. Our results on the neutrino charge\nradius, the only non-zero electromagnetic property of neutrinos in the SM, show\nno significant deviation, indicating no large beyond the SM flavor-dependent\neffects for electron and muon neutrinos. By incorporating solar neutrino data\nfrom dark matter direct detection experiments, we also place the most stringent\nconstraints on the tau neutrino charge radius obtained from neutrino scattering\nexperiments. Additionally, we determine updated constraints on the vector and\naxial-vector neutrino-electron neutral current couplings, adjusting for\nflavor-dependent effects and for the different experimental momentum transfers.\nThe global analysis reveals two allowed solutions: one close to the SM\nprediction, and a degenerate solution that is favored. We show that future dark\nmatter detectors could achieve sufficient precision to resolve the degeneracy.\nAs we move toward the precision era, this work demonstrates the crucial need to\nproperly account for flavor- and momentum-dependent effects to avoid\nmisinterpretations of the data.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-07T17:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.05296v1","title":"Let it Snow! Animating Static Gaussian Scenes With Dynamic Weather\n  Effects","summary":"3D Gaussian Splatting has recently enabled fast and photorealistic\nreconstruction of static 3D scenes. However, introducing dynamic elements that\ninteract naturally with such static scenes remains challenging. Accordingly, we\npresent a novel hybrid framework that combines Gaussian-particle\nrepresentations for incorporating physically-based global weather effects into\nstatic 3D Gaussian Splatting scenes, correctly handling the interactions of\ndynamic elements with the static scene. We follow a three-stage process: we\nfirst map static 3D Gaussians to a particle-based representation. We then\nintroduce dynamic particles and simulate their motion using the Material Point\nMethod (MPM). Finally, we map the simulated particles back to the Gaussian\ndomain while introducing appearance parameters tailored for specific effects.\nTo correctly handle the interactions of dynamic elements with the static scene,\nwe introduce specialized collision handling techniques. Our approach supports a\nvariety of weather effects, including snowfall, rainfall, fog, and sandstorms,\nand can also support falling objects, all with physically plausible motion and\nappearance. Experiments demonstrate that our method significantly outperforms\nexisting approaches in both visual quality and physical realism.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-07T17:51:21Z"}
{"aid":"http://arxiv.org/abs/2504.05637v1","title":"Spontaneous vortex crystal formation in classical rotating flows","summary":"Vortex crystals, ordered structures observed in superconductors and rotating\nsuperfluids, have also been hypothesized to form in classical fluids, based on\nnumerical simulations and observations of the Jovian polar atmospheres. We\nperform direct numerical simulations of the Navier-Stokes equations in rotating\nframes, to investigate the spontaneous emergence of metastable vortex crystals.\nWe analyze the energy spectrum, vortex morphology, and spatio-temporal dynamics\nto understand their roles in crystal formation and evolution. In addition, we\nexplore domains with varying aspect ratios to examine their impact on the\nvortex lattice. Our results indicate a relationship between the crystal\nlifespan and dissipation, and we propose a scaling law linking the rotation\nrate, domain geometry, and vortex lattice periodicity. Finally, we identify a\ncritical threshold in the control parameter, the Rossby number, suggesting a\nbehavior similar to that found in phase transitions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T03:30:30Z"}
{"aid":"http://arxiv.org/abs/2504.05639v1","title":"DBOT: Artificial Intelligence for Systematic Long-Term Investing","summary":"Long-term investing was previously seen as requiring human judgment. With the\nadvent of generative artificial intelligence (AI) systems, automated systematic\nlong-term investing is now feasible. In this paper, we present DBOT, a system\nwhose goal is to reason about valuation like Aswath Damodaran, who is a unique\nexpert in the investment arena in terms of having published thousands of\nvaluations on companies in addition to his numerous writings on the topic,\nwhich provide ready training data for an AI system. DBOT can value any publicly\ntraded company. DBOT can also be back-tested, making its behavior and\nperformance amenable to scientific inquiry. We compare DBOT to its analytic\nparent, Damodaran, and highlight the research challenges involved in raising\nits current capability to that of Damodaran's. Finally, we examine the\nimplications of DBOT-like AI agents for the financial industry, especially how\nthey will impact the role of human analysts in valuation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,q-fin.PR","published":"2025-04-08T03:34:22Z"}
{"aid":"http://arxiv.org/abs/2504.05651v1","title":"Measuring Déjà vu Memorization Efficiently","summary":"Recent research has shown that representation learning models may\naccidentally memorize their training data. For example, the d\\'ej\\`a vu method\nshows that for certain representation learning models and training images, it\nis sometimes possible to correctly predict the foreground label given only the\nrepresentation of the background - better than through dataset-level\ncorrelations. However, their measurement method requires training two models -\none to estimate dataset-level correlations and the other to estimate\nmemorization. This multiple model setup becomes infeasible for large\nopen-source models. In this work, we propose alternative simple methods to\nestimate dataset-level correlations, and show that these can be used to\napproximate an off-the-shelf model's memorization ability without any\nretraining. This enables, for the first time, the measurement of memorization\nin pre-trained open-source image representation and vision-language\nrepresentation models. Our results show that different ways of measuring\nmemorization yield very similar aggregate results. We also find that\nopen-source models typically have lower aggregate memorization than similar\nmodels trained on a subset of the data. The code is available both for vision\nand vision language models.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-08T03:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.05655v1","title":"Multi-bubble solutions for the Dirichlet problem of the $H$-system with\n  higher degree","summary":"We consider a Dirichlet problem of the $H$-system \\begin{equation*}\n\\begin{cases} \\Delta v = 2v_x\\wedge v_y ~& \\text{ in }\\mathcal{D},\\\\\nv=\\varepsilon \\tilde g ~& \\text{ on }\\partial{\\mathcal{D}}, \\end{cases}\n\\end{equation*} where $\\mathcal D\\subset \\mathbb{R}^2$ is the unit disk,\n$v:\\mathcal D\\to \\mathbb{R}^3$, and $\\tilde g:\\partial \\mathcal D\\to\n\\mathbb{R}^3$ is a given smooth map. As $\\varepsilon\\to 0^+$, we construct\nmulti-bubble solutions concentrating at distinct points, taking around each\npoint the profile of degree 2 $H$-bubble. This gives a partial answer to a\nconjecture due to Brezis-Coron \\cite{BrezisCoron} and Chanillo-Malchiodi\n\\cite{chanillomalchiodi2005cagasymptotic} concerning the limiting configuration\nin the case of higher degrees. This seems to be the first construction in\nemploying higher-degree harmonic maps as the primary configurations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T04:05:53Z"}
{"aid":"http://arxiv.org/abs/2504.05660v1","title":"Entangling quantum memories over 420 km in fiber","summary":"Long-distance entanglement is pivotal for quantum communication, distributed\nquantum computing and sensing. Significant progresses have been made in\nextending the distribution distance of entangled photons, either in free space\nor fiber. For future quantum network applications, matter-based entanglement is\nmore favorable since the capability of storage is essential for advanced\napplications. Extending entanglement distance for memory qubits was partially\nhindered by the mismatch of its photonic emission wavelength with the low-loss\ntransmission window of optical fiber. By incorporating quantum frequency\nconversion, memory-memory entanglement has been successfully extended to\nseveral tens of kilometers. Here, we make a significant step further by\nreporting the entanglement between two atomic ensemble quantum memories over\n420 km. We convert photons emitted from the memories to telecom S-band, which\nenable us to exploit the significantly low transmission loss in fiber (0.17\ndB/km). We employ the DLCZ scheme for remote entanglement generation, and\ndelicately stabilize the relative phase between the two memories by using\nfulltime far-off-resonant locking to reduce high-frequency noise and\nintermittent dual-band locking to compensate low-frequency drift jointly. We\ndemonstrate that the memory-memory entangling probability beats the\nrepeaterless channel capacity for direct entanglement distribution. Our\nexperiment provides a testbed of studying quantum network applications from\nmetropolitan scale to intercity scale.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T04:19:24Z"}
{"aid":"http://arxiv.org/abs/2504.05678v1","title":"On The Merit Principle in Strategic Exchanges","summary":"New fairness notions in align with the merit principle are proposed for\ndesigning exchange rules. We show that, for an obviously strategy-proof,\nefficient and individually rational rule, an upper bound of fairness attainable\nis that, if two agents possess objects considered the best by all others, then\nat least one receives her favorite object. Notably, it is not possible to\nguarantee them both receiving favorites. Our results thus indicate an\nunambiguous trade-off between incentives and fairness in the design of exchange\nrules.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-08T04:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.05679v1","title":"Event-based Civil Infrastructure Visual Defect Detection: ev-CIVIL\n  Dataset and Benchmark","summary":"Small Unmanned Aerial Vehicle (UAV) based visual inspections are a more\nefficient alternative to manual methods for examining civil structural defects,\noffering safe access to hazardous areas and significant cost savings by\nreducing labor requirements. However, traditional frame-based cameras, widely\nused in UAV-based inspections, often struggle to capture defects under low or\ndynamic lighting conditions. In contrast, Dynamic Vision Sensors (DVS), or\nevent-based cameras, excel in such scenarios by minimizing motion blur,\nenhancing power efficiency, and maintaining high-quality imaging across diverse\nlighting conditions without saturation or information loss. Despite these\nadvantages, existing research lacks studies exploring the feasibility of using\nDVS for detecting civil structural defects.Moreover, there is no dedicated\nevent-based dataset tailored for this purpose. Addressing this gap, this study\nintroduces the first event-based civil infrastructure defect detection dataset,\ncapturing defective surfaces as a spatio-temporal event stream using DVS.In\naddition to event-based data, the dataset includes grayscale intensity image\nframes captured simultaneously using an Active Pixel Sensor (APS). Both data\ntypes were collected using the DAVIS346 camera, which integrates DVS and APS\nsensors.The dataset focuses on two types of defects: cracks and spalling, and\nincludes data from both field and laboratory environments. The field dataset\ncomprises 318 recording sequences,documenting 458 distinct cracks and 121\ndistinct spalling instances.The laboratory dataset includes 362 recording\nsequences, covering 220 distinct cracks and 308 spalling instances.Four\nrealtime object detection models were evaluated on it to validate the dataset\neffectiveness.The results demonstrate the dataset robustness in enabling\naccurate defect detection and classification,even under challenging lighting\nconditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T04:44:33Z"}
{"aid":"http://arxiv.org/abs/2504.05686v1","title":"kNN-SVC: Robust Zero-Shot Singing Voice Conversion with Additive\n  Synthesis and Concatenation Smoothness Optimization","summary":"Robustness is critical in zero-shot singing voice conversion (SVC). This\npaper introduces two novel methods to strengthen the robustness of the kNN-VC\nframework for SVC. First, kNN-VC's core representation, WavLM, lacks harmonic\nemphasis, resulting in dull sounds and ringing artifacts. To address this, we\nleverage the bijection between WavLM, pitch contours, and spectrograms to\nperform additive synthesis, integrating the resulting waveform into the model\nto mitigate these issues. Second, kNN-VC overlooks concatenative smoothness, a\nkey perceptual factor in SVC. To enhance smoothness, we propose a new distance\nmetric that filters out unsuitable kNN candidates and optimize the summing\nweights of the candidates during inference. Although our techniques are built\non the kNN-VC framework for implementation convenience, they are broadly\napplicable to general concatenative neural synthesis models. Experimental\nresults validate the effectiveness of these modifications in achieving robust\nSVC. Demo: http://knnsvc.com Code: https://github.com/SmoothKen/knn-svc","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.LG,cs.MM,eess.AS","published":"2025-04-08T04:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.05693v1","title":"STRIVE: A Think & Improve Approach with Iterative Refinement for\n  Enhancing Question Quality Estimation","summary":"Automatically assessing question quality is crucial for educators as it saves\ntime, ensures consistency, and provides immediate feedback for refining\nteaching materials. We propose a novel methodology called STRIVE (Structured\nThinking and Refinement with multiLLMs for Improving Verified Question\nEstimation) using a series of Large Language Models (LLMs) for automatic\nquestion evaluation. This approach aims to improve the accuracy and depth of\nquestion quality assessment, ultimately supporting diverse learners and\nenhancing educational practices. The method estimates question quality in an\nautomated manner by generating multiple evaluations based on the strengths and\nweaknesses of the provided question and then choosing the best solution\ngenerated by the LLM. Then the process is improved by iterative review and\nresponse with another LLM until the evaluation metric values converge. This\nsophisticated method of evaluating question quality improves the estimation of\nquestion quality by automating the task of question quality evaluation.\nCorrelation scores show that using this proposed method helps to improve\ncorrelation with human judgments compared to the baseline method. Error\nanalysis shows that metrics like relevance and appropriateness improve\nsignificantly relative to human judgments by using STRIVE.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T05:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.05695v1","title":"Architecture independent generalization bounds for overparametrized deep\n  ReLU networks","summary":"We prove that overparametrized neural networks are able to generalize with a\ntest error that is independent of the level of overparametrization, and\nindependent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds\nthat only depend on the metric geometry of the test and training sets, on the\nregularity properties of the activation function, and on the operator norms of\nthe weights and norms of biases. For overparametrized deep ReLU networks with a\ntraining sample size bounded by the input space dimension, we explicitly\nconstruct zero loss minimizers without use of gradient descent, and prove that\nthe generalization error is independent of the network architecture.","main_category":"cs.LG","categories":"cs.LG,cs.AI,math.AP,math.OC,stat.ML","published":"2025-04-08T05:37:38Z"}
{"aid":"http://arxiv.org/abs/2504.05714v1","title":"Mass spectrum of S-wave mesons in the relativistic independent quark\n  model","summary":"The confining strength or model parameters and constituent quark masses are\nreparametrized for predicting the ground state meson masses. We analyzed these\nfrom the hyperfine splitting of $S$-wave heavy-flavored, heavy-light and light\n(except non-strange) mesons in the framework of a relativistic independent\nquark (RIQ) model with one gluon exchange and centre-of-mass correction. These\nmesons with spin parity $J^P=0^-$ and $1^-$, the masses obtained are in\naccordance with the experimental physical masses. The results will serve as\ngood complementary tools in further study of hadron dynamics and will behave as\na foundation for the higher excited and exotic states of hadrons.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T06:25:04Z"}
{"aid":"http://arxiv.org/abs/2504.05724v1","title":"Duality for operator systems with generating cones","summary":"Let $S$ be a complete operator system with a generating cone; i.e. $S_\\sa =\nS_+ - S_+$. We show that there is a matrix norm on the dual space $S^*$, under\nwhich, and the usual dual matrix cone, $S^*$ becomes a dual operator system\nwith a generating cone, denoted by $S^\\rd$. The canonical complete order\nisomorphism $\\iota_{S^*}: S^* \\to S^\\rd$ is a dual Banach space isomorphism.\nFurthermore, we construct a canonical completely contractive\nweak$^*$-homeomorphism $\\beta_S: (S^\\rd)^\\rd\\to S^{**}$, and verify that it is\na complete order isomorphism.\n  For a complete operator system $T$ with a generating cone and a completely\npositive complete contraction $\\varphi:S\\to T$, there is a weak$^*$-continuous\ncompletely positive complete contraction $\\varphi^\\rd:T^\\rd \\to S^\\rd$ with\n$\\iota_{S^*}\\circ \\varphi^* = \\varphi^\\rd \\circ \\iota_{T^*}$. This produces a\nfaithful functor from the category of complete operator systems with generating\ncones (where morphisms are completely positive complete contractions) to the\ncategory of dual operator systems with generating cones (where morphisms are\nweak$^*$-continuous completely positive complete contractions).\n  We define the notion of approximately unital operator systems, and verify\nthat operator systems considered in \\cite{CvS} and \\cite{CvS2} are\napproximately unital. If $S$ is approximately unital, then $\\iota_{S^*}:S^* \\to\nS^\\rd$ is an operator space isomorphism and $\\beta_S: (S^\\rd)^\\rd\\to S^{**}$ is\na complete isometry. We will also establish that the restriction of the\nfaithful functor $(S,T,\\varphi)\\mapsto (T^\\rd, S^\\rd, \\varphi^\\rd)$ to the\ncategory of approximately unital complete operator systems is both full and\ninjective on objects.","main_category":"math.OA","categories":"math.OA,math.FA","published":"2025-04-08T06:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.05731v1","title":"Retrieval Augmented Generation with Collaborative Filtering for\n  Personalized Text Generation","summary":"Recently, the personalization of Large Language Models (LLMs) to generate\ncontent that aligns with individual user preferences has garnered widespread\nattention. Personalized Retrieval-Augmented Generation (RAG), which retrieves\nrelevant documents from the user's history to reflect their preferences and\nenhance LLM generation, is one commonly used approach for personalization.\nHowever, existing personalized RAG methods do not consider that the histories\nof similar users can also assist in personalized generation for the current\nuser, meaning that collaborative information between users can also benefit\npersonalized generation. Inspired by the application of collaborative filtering\nin recommender systems, we propose a method called CFRAG, which adapts\nCollaborative Filtering to RAG for personalized text generation. However, this\npresents two challenges: (1)~how to incorporate collaborative information\nwithout explicit user similarity labels? (2)~how to retrieve documents that\nsupport personalized LLM generation? For Challenge 1, we use contrastive\nlearning to train user embeddings to retrieve similar users and introduce\ncollaborative information. For Challenge 2, we design a personalized retriever\nand reranker to retrieve the top-$k$ documents from these users' histories. We\ntake into account the user's preference during retrieval and reranking. Then we\nleverage feedback from the LLM to fine-tune the personalized retriever and\nreranker, enabling them to retrieve documents that meet the personalized\ngeneration needs of the LLM. Experimental results on the Language Model\nPersonalization (LaMP) benchmark validate the effectiveness of CFRAG. Further\nanalysis confirms the importance of incorporating collaborative information.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-08T07:03:36Z"}
{"aid":"http://arxiv.org/abs/2504.05742v1","title":"Linear-space LCS enumeration with quadratic-time delay for two strings","summary":"Suppose we want to seek the longest common subsequences (LCSs) of two strings\nas informative patterns that explain the relationship between the strings. The\ndynamic programming algorithm gives us a table from which all LCSs can be\nextracted by traceback. However, the need for quadratic space to hold this\ntable can be an obstacle when dealing with long strings. A question that\nnaturally arises in this situation would be whether it is possible to\nexhaustively search for all LCSs one by one in a time-efficient manner using\nonly a space linear in the LCS length, where we treat read-only memory for\nstoring the strings as excluded from the space consumed. As a part of the\nanswer to this question, we propose an $O(L)$-space algorithm that outputs all\ndistinct LCSs of the strings one by one each in $O(n^2)$ time, where the\nstrings are both of length $n$ and $L$ is the LCS length of the strings.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-08T07:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.05758v1","title":"Addressing Class Imbalance with Probabilistic Graphical Models and\n  Variational Inference","summary":"This study proposes a method for imbalanced data classification based on deep\nprobabilistic graphical models (DPGMs) to solve the problem that traditional\nmethods have insufficient learning ability for minority class samples. To\naddress the classification bias caused by class imbalance, we introduce\nvariational inference optimization probability modeling, which enables the\nmodel to adaptively adjust the representation ability of minority classes and\ncombines the class-aware weight adjustment strategy to enhance the classifier's\nsensitivity to minority classes. In addition, we combine the adversarial\nlearning mechanism to generate minority class samples in the latent space so\nthat the model can better characterize the category boundary in the\nhigh-dimensional feature space. The experiment is evaluated on the Kaggle\n\"Credit Card Fraud Detection\" dataset and compared with a variety of advanced\nimbalanced classification methods (such as GAN-based sampling, BRF,\nXGBoost-Cost Sensitive, SAAD, HAN). The results show that the method in this\nstudy has achieved the best performance in AUC, Precision, Recall and F1-score\nindicators, effectively improving the recognition rate of minority classes and\nreducing the false alarm rate. This method can be widely used in imbalanced\nclassification tasks such as financial fraud detection, medical diagnosis, and\nanomaly detection, providing a new solution for related research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T07:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.05786v1","title":"How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM","summary":"3D spatial understanding is essential in real-world applications such as\nrobotics, autonomous vehicles, virtual reality, and medical imaging. Recently,\nLarge Language Models (LLMs), having demonstrated remarkable success across\nvarious domains, have been leveraged to enhance 3D understanding tasks, showing\npotential to surpass traditional computer vision methods. In this survey, we\npresent a comprehensive review of methods integrating LLMs with 3D spatial\nunderstanding. We propose a taxonomy that categorizes existing methods into\nthree branches: image-based methods deriving 3D understanding from 2D visual\ndata, point cloud-based methods working directly with 3D representations, and\nhybrid modality-based methods combining multiple data streams. We\nsystematically review representative methods along these categories, covering\ndata representations, architectural modifications, and training strategies that\nbridge textual and 3D modalities. Finally, we discuss current limitations,\nincluding dataset scarcity and computational challenges, while highlighting\npromising research directions in spatial perception, multi-modal fusion, and\nreal-world applications.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T08:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.05788v1","title":"Space-averaged non-equilibrium Green's function approach for quantum\n  transport in 3D","summary":"The non-equilibrium Green's function (NEGF) approach offers a practical\nframework for simulating various phenomena in mesoscopic systems. As the\ndimension of electronic devices shrinks to just a few nanometers, the need for\nnew effective-mass based 3D implementations of NEGF has become increasingly\napparent. This work extends our previous Finite-Volume implementation --\noriginally developed for the self-consistent solution of the Schr\\\"odinger and\nPoisson equations in 2D -- into a full 3D NEGF framework. Our implementation\nbegins with exploring a few problems with the common textbook Finite Difference\nimplementations of NEGF. We then concisely demonstrate how Finite-Volume\ndiscretization addresses few key implementation challenges. Importantly, we\nexplain how this type of discretization enables evaluating the self-energies,\nwhich account for the effects of reservoirs. The potential applications of this\nnew method are illustrated through two examples. We anticipate that this\nimplementation will be broadly applicable to open quantum systems, especially\nin cases where a fully three-dimensional domain is essential.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T08:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.05828v1","title":"Capacity Region for Covert Secret Key Generation over Multiple Access\n  Channels","summary":"We study covert secret key generation over a binary-input two-user multiple\naccess channel with one-way public discussion and derive bounds on the capacity\nregion. Specifically, in this problem, there are three legitimate parties:\nAlice, Bob and Charlie. The goal is to allow Charlie to generate a secret key\nwith Alice and another secret key with Bob, reliably, secretly and covertly.\nReliability ensures that the key generated by Alice and Charlie is the same and\nthe key generated by Bob and Charlie is the same. Secrecy ensures that the\nsecret keys generated are only known to specific legitimate parties. Covertness\nensures that the key generation process is undetectable by a warden Willie. As\na corollary of our result, we establish bounds on the capacity region of\nwiretap secret key generation without the covertness constraint and discuss the\nimpact of covertness. Our results generalize the point-to-point result of\nTahmasbi and Bloch (TIFS 2020) to the setting of multiterminal communication.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-08T09:08:45Z"}
{"aid":"http://arxiv.org/abs/2504.05844v1","title":"Adaptive Substructure-Aware Expert Model for Molecular Property\n  Prediction","summary":"Molecular property prediction is essential for applications such as drug\ndiscovery and toxicity assessment. While Graph Neural Networks (GNNs) have\nshown promising results by modeling molecules as molecular graphs, their\nreliance on data-driven learning limits their ability to generalize,\nparticularly in the presence of data imbalance and diverse molecular\nsubstructures. Existing methods often overlook the varying contributions of\ndifferent substructures to molecular properties, treating them uniformly. To\naddress these challenges, we propose ASE-Mol, a novel GNN-based framework that\nleverages a Mixture-of-Experts (MoE) approach for molecular property\nprediction. ASE-Mol incorporates BRICS decomposition and significant\nsubstructure awareness to dynamically identify positive and negative\nsubstructures. By integrating a MoE architecture, it reduces the adverse impact\nof negative motifs while improving adaptability to positive motifs.\nExperimental results on eight benchmark datasets demonstrate that ASE-Mol\nachieves state-of-the-art performance, with significant improvements in both\naccuracy and interpretability.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T09:25:03Z"}
{"aid":"http://arxiv.org/abs/2504.05854v1","title":"50 Dra: Am-type twins with additional variability in a non-eclipsing\n  system","summary":"The interplay between radiative diffusion, rotation, convection, and\nmagnetism in metallic-line chemically peculiar stars is still not fully\nunderstood. Recently, evidence has emerged that these effects can work\ntogether. Our goal is to study the bright binary system 50 Dra, describe its\norbit and components, and study additional variability. We conducted our\nanalysis using TESS short-cadence data and new high-resolution spectroscopic\nobservations. We disentangled the spectra using Korel and performed spectral\nsynthesis with Atlas9 and Synthe codes. The system was modelled using Korel and\nPhoebe2.4. We also employed SED fitting in Ariadne and isochrone fitting using\nParam1.5 codes. Our findings indicate that the non-eclipsing system (with an\ninclination of 49.9(8) deg) 50 Dra, displaying ellipsoidal brightness\nvariations, consists of two nearly equal A-type stars with masses of\n$M_{1}=2.08(8)$ and $M_{2}=1.97(8)$ M$_{\\odot}$ and temperatures of 9800(100)\nand 9200(200) K, respectively. Our analysis also suggests that the system, with\nan orbital period of $P_{\\rm orb}=4.117719(2)$ days, is tidally relaxed with a\ncircular orbit and synchronous rotation of the components. Furthermore, we\ndiscovered that both stars are metallic-line Am chemically peculiar stars with\nan underabundance of Sc and an overabundance of iron-peak and rare-earth\nelements. We identified additional variations with slightly higher frequency\nthan the rotational frequency of the components that we interpret as prograde\ng-mode pulsations. The system 50 Dra exhibits numerous exciting phenomena that\nco-exist together and may have an impact on our understanding of chemical\npeculiarity and pulsations.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-08T09:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.05877v1","title":"Threshold-less and Flexibly Tunable Frequency Comb via Floquet\n  Engineering","summary":"Frequency combs have revolutionized communication, metrology and\nspectroscopy. Numerous efforts have been dedicated to developing integrated\ncombs, predominantly relying on Pockels or Kerr mechanisms. In this work, we\npropose and demonstrate a new type of frequency comb-Floquet cavity frequency\ncomb-that does not rely on intrinsic non-linearity. By periodically modulating\nthe resonance frequency of a cavity, a giant-mode cavity with multiple equally\nspaced frequency components is created. The pump tone interacts with the\npre-modulated cavity, generating the output frequency comb. This approach\noffers a flexible tuning range and operates in a threshold-less manner,\nobviating the need to overcome nonlinear initiation thresholds. We implement\nthis on a microwave cavity optomechanical system on-chip. Compared to Kerr\noptomechanical combs, this approach efficiently generates comb with pump signal\nfar from the cavity's intrinsic frequency, and the power required for detection\nis reduced by approximately a factor of ($10^6$), providing a promising\nplatform for frequency comb generation.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,physics.optics","published":"2025-04-08T10:05:20Z"}
{"aid":"http://arxiv.org/abs/2504.05902v1","title":"Defending Deep Neural Networks against Backdoor Attacks via Module\n  Switching","summary":"The exponential increase in the parameters of Deep Neural Networks (DNNs) has\nsignificantly raised the cost of independent training, particularly for\nresource-constrained entities. As a result, there is a growing reliance on\nopen-source models. However, the opacity of training processes exacerbates\nsecurity risks, making these models more vulnerable to malicious threats, such\nas backdoor attacks, while simultaneously complicating defense mechanisms.\nMerging homogeneous models has gained attention as a cost-effective\npost-training defense. However, we notice that existing strategies, such as\nweight averaging, only partially mitigate the influence of poisoned parameters\nand remain ineffective in disrupting the pervasive spurious correlations\nembedded across model parameters. We propose a novel module-switching strategy\nto break such spurious correlations within the model's propagation path. By\nleveraging evolutionary algorithms to optimize fusion strategies, we validate\nour approach against backdoor attacks targeting text and vision domains. Our\nmethod achieves effective backdoor mitigation even when incorporating a couple\nof compromised models, e.g., reducing the average attack success rate (ASR) to\n22% compared to 31.9% with the best-performing baseline on SST-2.","main_category":"cs.CR","categories":"cs.CR,cs.CL","published":"2025-04-08T11:01:07Z"}
{"aid":"http://arxiv.org/abs/2504.05907v1","title":"A Method for Generating Connected Erdos-Renyi Random Graphs","summary":"We propose a novel and exact algorithm for generating connected Erdos-Renyi\nrandom graphs $G(n, p)$. Our approach exploits a link between the distribution\nof exploration process trajectories and an inhomogeneous random walk. In\ncontrast to existing methods, our approach guarantees the correct distribution\nunder the connectivity condition and achieves $O(n^2)$ runtime in the sparse\ncase $p = c/n$. Furthermore, we show that our method can be extended to\nuniformly generate connected graphs $G(n, m)$ via an acceptance-rejection\nprocedure.","main_category":"cs.DS","categories":"cs.DS,cs.DM,cs.IT,math.CO,math.IT,math.PR","published":"2025-04-08T11:06:01Z"}
{"aid":"http://arxiv.org/abs/2504.05915v1","title":"Quantum inverse scattering for time-dependent repulsive Hamiltonians","summary":"We study a multidimensional inverse scattering problem under the\ntime-dependent repulsive Hamiltonian. The time-dependent coefficient on the\nrepulsive term decays as the inverse square of time, which is the threshold\nbetween the standard free Schroedinger operator and the time-independent\nrepulsive Hamiltonian. Applying the Enss-Weder time-dependent method, we can\ndetermine uniquely the short-range potential functions with Coulomb-like\nsingularities from the velocity limit of the scattering operator.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T11:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.05919v1","title":"Measurement of high-mass $t\\bar{t}\\ell^{+}\\ell^{-}$ production and\n  lepton flavour universality-inspired effective field theory interpretations\n  at $\\sqrt{s}=13$ TeV with the ATLAS detector","summary":"Measurements of $t\\bar{t}\\ell^{+}\\ell^{-}$ production in the region of high\ndilepton invariant mass with effective field theory (EFT) interpretations are\npresented. They are performed using final states with three isolated leptons\n(electrons or muons) and are based on $\\sqrt{s} = 13$ TeV proton-proton\ncollision data with an integrated luminosity of $140\\,\\mathrm{fb}^{-1}$,\nrecorded from 2015 to 2018 with the ATLAS detector at the Large Hadron\nCollider. Measurements of the $t\\bar{t}\\ell^{+}\\ell^{-}$ signal strength and\ncross-section upper-limits are performed inclusively in lepton flavour and\nseparately for electrons and muons. The study also aims to probe anomalous\nfour-fermion interactions including to test for possible lepton flavor\nuniversality violation. No significant deviations from the Standard Model\npredictions are observed and the measurements are interpreted through the EFT\nformalism to provide new constraints on relevant operators.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-08T11:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.05927v1","title":"A nongraphical obstacle problem for elastic curves","summary":"We study an obstacle problem for the length-penalized elastic bending energy\nfor open planar curves pinned at the boundary. We first consider the case\nwithout length penalization and investigate the role of global minimizers among\ngraph curves in our minimization problem for planar curves. In addition, for\nlarge values of the length-penalization parameter $\\lambda>0$, we expose an\nexplicit threshold parameter above which minimizers touch the obstacle,\nregardless of its shape. On contrary, for small values of $\\lambda>0$ we show\nthat the minimizers do not touch the obstacle, and they are given by an\nexplicit elastica.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-08T11:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.05979v1","title":"An Empirical Study of GPT-4o Image Generation Capabilities","summary":"The landscape of image generation has rapidly evolved, from early GAN-based\napproaches to diffusion models and, most recently, to unified generative\narchitectures that seek to bridge understanding and generation tasks. Recent\nadvances, especially the GPT-4o, have demonstrated the feasibility of\nhigh-fidelity multimodal generation, their architectural design remains\nmysterious and unpublished. This prompts the question of whether image and text\ngeneration have already been successfully integrated into a unified framework\nfor those methods. In this work, we conduct an empirical study of GPT-4o's\nimage generation capabilities, benchmarking it against leading open-source and\ncommercial models. Our evaluation covers four main categories, including\ntext-to-image, image-to-image, image-to-3D, and image-to-X generation, with\nmore than 20 tasks. Our analysis highlights the strengths and limitations of\nGPT-4o under various settings, and situates it within the broader evolution of\ngenerative modeling. Through this investigation, we identify promising\ndirections for future unified generative models, emphasizing the role of\narchitectural design and data scaling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T12:34:36Z"}
{"aid":"http://arxiv.org/abs/2504.06025v1","title":"Geometries with trialities arising from linear spaces","summary":"A triality is a sort of super-symmetry that exchanges the types of the\nelements of an incidence geometry in cycles of length three. Although\ngeometries with trialities exhibit fascinating behaviors, their construction is\nchallenging, making them rare in the literature. To understand trialities more\ndeeply, it is crucial to have a wide variety of examples at hand. In this\narticle, we introduce a general method for constructing various rank-three\nincidence systems with trialities. Specifically, for any rank two incidence\nsystem $\\Gamma$, we define its triangle complex $\\Delta(\\Gamma)$, a rank three\nincidence system whose elements consist of three copies of the flags (pairs of\nincident elements) of $\\Gamma$. This triangle complex always admits a triality\nthat cyclically permutes the three copies. We then explore in detail the\nproperties of the triangle complex when $\\Gamma$ is a linear space, including\nflag-transitivity, the existence of dualities, and connectivity properties. As\na consequence of our work, this construction yields the first infinite family\nof thick, flag-transitive and residually connected geometries with trialities\nbut no dualities.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-08T13:28:55Z"}
{"aid":"http://arxiv.org/abs/2504.06046v1","title":"Rhythmic neuromorphic control of a pendulum: A hybrid systems analysis","summary":"Neuromorphic engineering is an emerging research domain that aims to realize\nimportant implementation advantages that brain-inspired technologies can offer\nover classical digital technologies, including energy efficiency, adaptability,\nand robustness. For the field of systems and control, neuromorphic controllers\ncould potentially bring many benefits, but their advancement is hampered by\nlack of systematic analysis and design tools. In this paper, the objective is\nto show that hybrid systems methods can aid in filling this gap. We do this by\nformally analyzing rhythmic neuromorphic control of a pendulum system, which\nwas recently proposed as a prototypical setup. The neuromorphic controller\ngenerates spikes, which we model as a Dirac delta pulse, whenever the pendulum\nangular position crosses its resting position, with the goal of inducing a\nstable limit cycle. This leads to modeling the closed-loop system as a hybrid\ndynamical system, which in between spikes evolves in open loop and where the\njumps correspond to the spiking control actions. Exploiting the hybrid system\nmodel, we formally prove the existence, uniqueness, and a stability property of\nthe hybrid limit cycle for the closed-loop system. Numerical simulations\nillustrate our approach. We finally elaborate on a possible spiking adaptation\nmechanism on the pulse amplitude to generate a hybrid limit cycle of a desired\nmaximal angular amplitude.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T13:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.06058v1","title":"Symbol Frequencies in Surjective Cellular Automata","summary":"We study the behavior of probability measures under iteration of a surjective\ncellular automaton. We solve the following question in the negative: if the\ninitial measure is ergodic and has full support, do all weak-* limit points of\nthe sequence of measures have full support as well? The initial measure of our\nsolution is not a product measure, and in this case the question remains open.\nTo this end, we present a tool for studying the frequencies of symbols in\npreimages of surjective cellular automata, and prove some basic results about\nit. % do we know they are nontrivial? :P However, we show that by itself it is\nnot enough to solve the stricter question in the positive.","main_category":"math.DS","categories":"math.DS","published":"2025-04-08T14:01:13Z"}
{"aid":"http://arxiv.org/abs/2504.06080v1","title":"Two-Loop Renormalization of a Chiral $SU(2)$ Gauge Theory in Dimensional\n  Regularization with Non-Anticommuting $γ_5$","summary":"Higher order calculations in chiral gauge theories such as the Electroweak\nStandard Model require a sound treatment of the notoriously problematic\n$\\gamma_5$-matrix in Dimensional Regularization (DReg). In the all-order\nconsistent BMHV scheme anticommutativity has to be sacrificed, resulting in\nspurious breakings of BRST invariance, the restoration of which necessitates\nfinite, symmetry-restoring counterterms. Following recent advances in\nsuccessfully applying this scheme to multi-loop calculations for Abelian\nmodels, we shall here present the first complete non-Abelian two-loop result\nfor the case of $SU(2)$, which is of particular interest to the Standard Model.\nWe provide the complete list of finite, two-loop symmetry restoring\ncounterterms and discuss intricacies of the non-Abelian implementation. Except\nfor one novel term, the finite counterterm action exhibits the same structure\nas at one-loop order.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-08T14:20:22Z"}
{"aid":"http://arxiv.org/abs/2504.06091v1","title":"Real-Time LaCAM","summary":"The vast majority of Multi-Agent Path Finding (MAPF) methods with\ncompleteness guarantees require planning full horizon paths. However, planning\nfull horizon paths can take too long and be impractical in real-world\napplications. Instead, real-time planning and execution, which only allows the\nplanner a finite amount of time before executing and replanning, is more\npractical for real world multi-agent systems. Several methods utilize real-time\nplanning schemes but none are provably complete, which leads to livelock or\ndeadlock. Our main contribution is to show the first Real-Time MAPF method with\nprovable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023)\nin an incremental fashion. Our results show how we can iteratively plan for\ncongested environments with a cutoff time of milliseconds while still\nmaintaining the same success rate as full horizon LaCAM. We also show how it\ncan be used with a single-step learned MAPF policy. The proposed Real-Time\nLaCAM also provides us with a general mechanism for using iterative constraints\nfor completeness in future real-time MAPF algorithms.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.RO","published":"2025-04-08T14:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.06100v1","title":"Timescales for thermalization, quantum chaos, and self-averaging","summary":"This chapter discusses the conditions and timescales under which isolated\nmany-body quantum systems, initially far from equilibrium, ultimately reach\nthermal equilibrium. We also examine quantities that, during the relaxation\nprocess, exhibit dynamical manifestations of spectral correlations as in random\nmatrix theory and investigate how these manifestations affect their\nequilibration times. We refer to systems presenting these spectral correlations\nas chaotic quantum systems, although the correct term to be employed, whether\nchaotic or ergodic quantum systems, is debatable and both have limitations.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T14:44:37Z"}
{"aid":"http://arxiv.org/abs/2504.06107v1","title":"Doubly-charmed hexaquarks in the diquark picture","summary":"We investigate doubly-charmed hexaquark states within the diquark picture, by\nemploying the constituent quark model and the quark-interchange model as our\ntheoretical frameworks. Using the Gaussian expansion method, we systematically\nstudy these states, with calculating various properties such as mass spectra,\ninternal contributions of each Hamiltonian component, root-mean-square radii,\nand two-body strong decay widths. Our analysis of the mass spectra reveals no\nstable state in this system. Furthermore, the root-mean-square radii suggest\nthat the doubly-charmed hexaquark states exhibit a compact configuration. By\nexamining the decay widths, we identify potentially detectable states and their\nprimary decay channels within each subsystem. Despite the large decay phase\nspace, we still find narrow states with total widths of less than 10 MeV. This\nstudy provides a theoretical foundation for understanding the structures and\ninteractions of doubly-charmed hexaquark states and offers valuable insights\nfor future experimental searches.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-08T14:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.06142v1","title":"Unification of Conformal and Fuzzy Gravities with Internal Interactions\n  resulting in SO(10) and a Possible Probe through Stochastic Gravitational\n  Wave Background","summary":"The unification of conformal and fuzzy gravities with internal interactions\nis based on the facts that i) the tangent group of a curved manifold and the\nmanifold itself do not necessarily have the same dimensions and ii) both\ngravitational theories considered here have been formulated in a gauge\ntheoretic way. We review the gauge-theoretic approach of gravities, commenting\nin particular on their diffeomorphism invariance, and the construction of\nconformal and noncommutative (fuzzy) gravity using the gauge-theoretic\nframework. Based on an extension of the four-dimensional tangent group,\nunification of both gravities with the internal interactions is achieved. Both\nunified schemes are examined at 1-loop level considering suitable spontaneous\nsymmetry breakings to a SO(10) grand unified theory and consequently down to\nthe Standard Model of particle physics through four specific spontaneous\nbreaking channels. Each channel is examined against proton lifetime\nexperimental bounds and its observation potential through gravitational signal\nfrom cosmic strings production is discussed.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T15:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.06153v1","title":"A Large-Scale Analysis on Contextual Self-Supervised Video\n  Representation Learning","summary":"Self-supervised learning has emerged as a powerful paradigm for label-free\nmodel pretraining, particularly in the video domain, where manual annotation is\ncostly and time-intensive. However, existing self-supervised approaches employ\ndiverse experimental setups, making direct comparisons challenging due to the\nabsence of a standardized benchmark. In this work, we establish a unified\nbenchmark that enables fair comparisons across different methods. Additionally,\nwe systematically investigate five critical aspects of self-supervised learning\nin videos: (1) dataset size, (2) model complexity, (3) data distribution, (4)\ndata noise, and (5) feature representations. To facilitate this study, we\nevaluate six self-supervised learning methods across six network architectures,\nconducting extensive experiments on five benchmark datasets and assessing\nperformance on two distinct downstream tasks. Our analysis reveals key insights\ninto the interplay between pretraining strategies, dataset characteristics,\npretext tasks, and model architectures. Furthermore, we extend these findings\nto Video Foundation Models (ViFMs), demonstrating their relevance in\nlarge-scale video representation learning. Finally, leveraging these insights,\nwe propose a novel approach that significantly reduces training data\nrequirements while surpassing state-of-the-art methods that rely on 10% more\npretraining data. We believe this work will guide future research toward a\ndeeper understanding of self-supervised video representation learning and its\nbroader implications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.06163v1","title":"Action Valuation in Sports: A Survey","summary":"Action Valuation (AV) has emerged as a key topic in Sports Analytics,\noffering valuable insights by assigning scores to individual actions based on\ntheir contribution to desired outcomes. Despite a few surveys addressing\nrelated concepts such as Player Valuation, there is no comprehensive review\ndedicated to an in-depth analysis of AV across different sports. In this\nsurvey, we introduce a taxonomy with nine dimensions related to the AV task,\nencompassing data, methodological approaches, evaluation techniques, and\npractical applications. Through this analysis, we aim to identify the essential\ncharacteristics of effective AV methods, highlight existing gaps in research,\nand propose future directions for advancing the field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:59:19Z"}
{"aid":"http://arxiv.org/abs/2504.06176v1","title":"A Self-Supervised Framework for Space Object Behaviour Characterisation","summary":"Foundation Models, pre-trained on large unlabelled datasets before\ntask-specific fine-tuning, are increasingly being applied to specialised\ndomains. Recent examples include ClimaX for climate and Clay for satellite\nEarth observation, but a Foundation Model for Space Object Behavioural Analysis\nhas not yet been developed. As orbital populations grow, automated methods for\ncharacterising space object behaviour are crucial for space safety. We present\na Space Safety and Sustainability Foundation Model focusing on space object\nbehavioural analysis using light curves (LCs). We implemented a\nPerceiver-Variational Autoencoder (VAE) architecture, pre-trained with\nself-supervised reconstruction and masked reconstruction on 227,000 LCs from\nthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,\nand LC generation. We fine-tuned the model for anomaly detection & motion\nprediction using two independent LC simulators (CASSANDRA and GRIAL\nrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlink\nplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,\nidentifying potentially anomalous light curves through reconstruction\ndifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90\nand 0.95 ROC AUC scores respectively in both anomaly detection and motion mode\nprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomaly\npredictions on real data revealed distinct patterns including characteristic\nobject profiles and satellite glinting. Here, we demonstrate how\nself-supervised learning can simultaneously enable anomaly detection, motion\nprediction, and synthetic data generation from rich representations learned in\npre-training. Our work therefore supports space safety and sustainability\nthrough automated monitoring and simulation capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.AI,physics.space-ph","published":"2025-04-08T16:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.06185v1","title":"WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and\n  Real-World Wound Care","summary":"Chronic wounds affect a large population, particularly the elderly and\ndiabetic patients, who often exhibit limited mobility and co-existing health\nconditions. Automated wound monitoring via mobile image capture can reduce\nin-person physician visits by enabling remote tracking of wound size. Semantic\nsegmentation is key to this process, yet wound segmentation remains\nunderrepresented in medical imaging research. To address this, we benchmark\nstate-of-the-art deep learning models from general-purpose vision, medical\nimaging, and top methods from public wound challenges. For fair comparison, we\nstandardize training, data augmentation, and evaluation, conducting\ncross-validationto minimize partitioning bias. We also assess real-world\ndeployment aspects, including generalization to an out-of-distribution wound\ndataset, computational efficiency, and interpretability. Additionally, we\npropose a reference object-based approach to convert AI-generated masks into\nclinically relevant wound size estimates, and evaluate this, along with mask\nquality, for the best models based on physician assessments. Overall, the\ntransformer-based TransNeXt showed the highest levels of generalizability.\nDespite variations in inference times, all models processed at least one image\nper second on the CPU, which is deemed adequate for the intended application.\nInterpretability analysis typically revealed prominent activations in wound\nregions, emphasizing focus on clinically relevant features. Expert evaluation\nshowed high mask approval for all analyzed models, with VWFormer and ConvNeXtS\nbackbone performing the best. Size retrieval accuracy was similar across\nmodels, and predictions closely matched expert annotations. Finally, we\ndemonstrate how our AI-driven wound size estimation framework, WoundAmbit, can\nbe integrated into a custom telehealth system. Our code will be made available\non GitHub upon publication.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T16:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.06196v1","title":"TxGemma: Efficient and Agentic LLMs for Therapeutics","summary":"Therapeutic development is a costly and high-risk endeavor that is often\nplagued by high failure rates. To address this, we introduce TxGemma, a suite\nof efficient, generalist large language models (LLMs) capable of therapeutic\nproperty prediction as well as interactive reasoning and explainability. Unlike\ntask-specific models, TxGemma synthesizes information from diverse sources,\nenabling broad application across the therapeutic development pipeline. The\nsuite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a\ncomprehensive dataset of small molecules, proteins, nucleic acids, diseases,\nand cell lines. Across 66 therapeutic development tasks, TxGemma achieved\nsuperior or comparable performance to the state-of-the-art generalist model on\n64 (superior on 45), and against state-of-the-art specialist models on 50\n(superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks,\nsuch as clinical trial adverse event prediction, requires less training data\nthan fine-tuning base LLMs, making TxGemma suitable for data-limited\napplications. Beyond these predictive capabilities, TxGemma features\nconversational models that bridge the gap between general LLMs and specialized\nproperty predictors. These allow scientists to interact in natural language,\nprovide mechanistic reasoning for predictions based on molecular structure, and\nengage in scientific discussions. Building on this, we further introduce\nAgentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that\nreasons, acts, manages diverse workflows, and acquires external domain\nknowledge. Agentic-Tx surpasses prior leading models on the Humanity's Last\nExam benchmark (Chemistry & Biology) with 52.3% relative improvement over\no3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels\nwith improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over\no3-mini (high).","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.LG","published":"2025-04-08T16:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.06218v1","title":"Role of mechanical effects on the excitation spectra of\n  microwave-dressed Rydberg states in a cold atomic cloud","summary":"We explore the excitation spectra of cold 87Rb atoms to the 55D_3/2 Rydberg\nstate in the presence of microwave (MW) radiation as a function of MW\nfrequency. The spectra reveal several features around the\ntransition-frequencies between adjacent Rydberg states. We argue that some of\nthese features are indicative of variations in the Rydberg excitation\nprobability while others result from the removal of atoms from the cold cloud\nas a consequence of a MW induced strong dipole-dipole inter-atomic force. Our\nclaim is supported by experimental observations and theoretical modeling.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-08T17:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.06252v1","title":"A systematic method to identify runaways from star clusters produced\n  from single-binary interactions: A case study of M67","summary":"One hypothesis for runaway stars (RSs) is that they are ejected from star\nclusters with high velocities relative to the cluster center-of-mass motion.\nThere are two competing mechanisms for their production: supernova-based\nejections in binaries, where one companion explodes, leaves no remnant, and\nlaunches the other companion at the instantaneous orbital velocity, and the\ndisintegration of triples (or higher-order multiples), which produces a\nrecoiled runaway binary (RB) and an RS. We search for RS candidates using data\nfrom the Gaia DR3 survey with a focus on triple disintegration since in this\ncase the product is always a binary and a single star that should be moving in\nopposite directions. We created a systematic methodology to look for candidate\nRS-RB runaway pairs produced from the disintegration of bound three-body\nsystems formed from single-binary interactions based on momentum conservation\nand causality. The method we use is general and can be applied to any cluster\nwith a 5D kinematic data set. We used our criteria to search for these pairs in\na 150 pc circular field of view surrounding the open cluster M67, which we used\nas a benchmark cluster to test the robustness of our method. Our results reveal\nonly one RS-RB pair that is consistent with all of our selection criteria out\nof an initial sample of $10^8$ pairs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-08T17:57:10Z"}
{"aid":"http://arxiv.org/abs/2504.06264v1","title":"D^2USt3R: Enhancing 3D Reconstruction with 4D Pointmaps for Dynamic\n  Scenes","summary":"We address the task of 3D reconstruction in dynamic scenes, where object\nmotions degrade the quality of previous 3D pointmap regression methods, such as\nDUSt3R, originally designed for static 3D scene reconstruction. Although these\nmethods provide an elegant and powerful solution in static settings, they\nstruggle in the presence of dynamic motions that disrupt alignment based solely\non camera poses. To overcome this, we propose D^2USt3R that regresses 4D\npointmaps that simultaneiously capture both static and dynamic 3D scene\ngeometry in a feed-forward manner. By explicitly incorporating both spatial and\ntemporal aspects, our approach successfully encapsulates spatio-temporal dense\ncorrespondence to the proposed 4D pointmaps, enhancing downstream tasks.\nExtensive experimental evaluations demonstrate that our proposed approach\nconsistently achieves superior reconstruction performance across various\ndatasets featuring complex motions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.06547v1","title":"Extremal metrics involving scalar curvature","summary":"We investigate extremal metrics at which various types of rigidity theorems\ninvolving scalar curvatures hold. The rigidity we discuss here is related to\nthe rigidity theorems presented by Mario Listing in his previous preprint. More\nspecifically, we give some sufficient conditions for metrics not to be rigid in\nthis sense. We also give several examples of Riemannian manifolds that satisfy\nsuch sufficient conditions.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T03:04:52Z"}
{"aid":"http://arxiv.org/abs/2504.06568v1","title":"Relaxed Weak Accelerated Proximal Gradient Method: a Unified Framework\n  for Nesterov's Accelerations","summary":"This paper is devoted to the study of accelerated proximal gradient methods\nwhere the sequence that controls the momentum term doesn't follow Nesterov's\nrule. We propose a relaxed weak accelerated proximal gradient (R-WAPG) method,\na generic algorithm that unifies the convergence results for strongly convex\nand convex problems where the extrapolation constant is characterized by a\nsequence that is much weaker than Nesterov's rule. Our R-WAPG provides a\nunified framework for several notable Euclidean variants of FISTA and verifies\ntheir convergences. In addition, we provide the convergence rate of strongly\nconvex objective with a constant momentum term. Without using the idea of\nrestarting, we also reformulate R-WAPG as ``Free R-WAPG\" so that it doesn't\nrequire any parameter. Explorative numerical experiments were conducted to show\nits competitive advantages.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T04:05:54Z"}
{"aid":"http://arxiv.org/abs/2504.06571v1","title":"Double shape quantum phase transitions in the SU3-IBM (I) new\n  $γ$-soft phase and the shape phase transition from the new $γ$-soft\n  phase to the prolate shape","summary":"Shape quantum phase transition is an important topic in nuclear structure. In\nthis paper, we begin to study the shape quantum phase transition in the\nSU3-IBM. In this new proposed model, spherical-like spectra was found to\nresolve the spherical nucleus puzzle, which is a new $\\gamma$-soft rotational\nmode. In this paper, the shape phase transition along the new $\\gamma$-soft\nline is first discussed, and then the neighbouring case at the prolate side is\nalso studied. We find that double shape phase transitions occur along a single\nparameter path. The new $\\gamma$-softness is really a shape phase and the shape\nphase transition from the new $\\gamma$-soft phase to the prolate shape is\nfound. The experimental support is also found and $^{108}$Pd is the critical\nnucleus.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-09T04:15:40Z"}
{"aid":"http://arxiv.org/abs/2504.06574v1","title":"Uncovering influence of football players' behaviour on team performance\n  in ball possession through dynamical modelling","summary":"A quest for uncovering influence of behaviour on team performance involves\nunderstanding individual behaviour, interactions with others and environment,\nvariations across groups, and effects of interventions. Although insights into\neach of these areas have accumulated in sports science literature on football,\nit remains unclear how one can enhance team performance. We analyse influence\nof football players' behaviour on team performance in three-versus-one ball\npossession game by constructing and analysing a dynamical model. We developed a\nmodel for the motion of the players and the ball, which mathematically\nrepresented our hypotheses on players' behaviour and interactions. The model's\nplausibility was examined by comparing simulated outcomes with our experimental\nresult. Possible influences of interventions were analysed through sensitivity\nanalysis, where causal effects of several aspects of behaviour such as pass\nspeed and accuracy were found. Our research highlights the potential of\ndynamical modelling for uncovering influence of behaviour on team\neffectiveness.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-09T04:29:33Z"}
{"aid":"http://arxiv.org/abs/2504.06592v1","title":"On Coalgebraic Product Constructions for Markov Chains and Automata","summary":"Verifying traces of systems is a central topic in formal verification. We\nstudy model checking of Markov chains (MCs) against temporal properties\nrepresented as (finite) automata. For instance, given an MC and a deterministic\nfinite automaton (DFA), a simple but practically useful model checking problem\nasks for the probability of traces on the MC that are accepted by the DFA. A\nstandard approach to solving this problem constructs a product MC of the given\nMC and DFA, reducing the task to a simple reachability probability problem on\nthe resulting product MC.\n  In this paper, on top of our recent development of coalgebraic framework, we\nfirst present a no-go theorem for product constructions, showing a case when we\ncannot do product constructions for model checking. Specifically, we show that\nthere are no coalgebraic product MCs of MCs and nondeterministic finite\nautomata for computing the probability of the accepting traces. This no-go\ntheorem is established via a characterisation of natural transformations\nbetween certain functors that determine the type of branching, including\nnondeterministic or probabilistic branching.\n  Second, we present a coalgebraic product construction of MCs and multiset\nfinite automata (MFAs) as a new instance within our framework. This\nconstruction addresses a model checking problem that asks for the expected\nnumber of accepting runs on MFAs over traces of MCs. The problem is reduced to\nsolving linear equations, which is solvable in polynomial-time under a\nreasonable assumption that ensures the finiteness of the solution.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-09T05:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.06595v1","title":"Time-local stochastic equation of motion for solid ionic electrolytes","summary":"Numerical studies of ionic motion through solid electrolytes commonly involve\nstatic nudged-elastic band (NEB) methods or costly \\emph{ab initio} molecular\ndynamics (AIMD). Building on a time-local model of current carrier-electrolyte\ninteraction and incorporating thermal motion, we introduce an approach that is\nintermediate between the two well-established methodologies by treating the\nelectrolyte as an effective medium that interacts with the mobile particle.\nThrough this coupling, the thermally vibrating electrolyte imparts energy to\nthe charge carriers while also absorbing energy from them due to its own finite\nelasticity. Using a simple model system, we validate our approach through a\nseries of numerical simulations. Our methodology reproduces both dissipative\nand diffusive behavior, and helps link microscopic system parameters to\nmeasurable macroscopic properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-09T05:45:10Z"}
{"aid":"http://arxiv.org/abs/2504.06597v1","title":"Dynamics of two Interacting Drops in a Microfluidic Confinement under\n  imposed Temperature Gradient","summary":"Thermocapillary motion is widespread in both natural and engineering\napplications. A tiny drop of one liquid, suspended within another, may be set\ninto motion aligned with an imposed thermal gradient, as influenced by\nthermocapillary action stemming from the gradients in interfacial tension due\nto the local variations in temperature. In real-world situations, however, such\ndrops do not remain in isolation, as they interact with their neighboring\nentities, including other drops in proximity as well as a nearby solid\nboundary, setting up a complex interplay between the confinement-mediated\ninteractions and the three-dimensional nature of the droplet dynamics. In this\nstudy, we present numerical solutions for the migration dynamics of a tightly\nconfined drop couple, incorporating deformable interfaces, film flow, and\nMarangoni effects in the presence of dynamically evolving thermocapillary\nstresses induced by an imposed uniform temperature gradient. Unlike prior\ninvestigations, our work highlights the influence of the confinement towards\norchestrating non-trivial features of drop migration, as dictated by an\nintricate coupling of the thermal and flow fields amidst the interferences of\nthe domain boundaries. The study reveals that hydrodynamic interactions\nresulting from a juxtaposition of these influences deform the drops in a unique\nmanner as compared to the characteristics evidenced by previously reported\nstudies, causing a distortion of the local thermal fields around them. This, in\nturn, leads to changes in the local thermocapillary stress, affecting the local\nshear gradient in a manner that alters the local flow field in accordance with\nensuring the interfacial stress balance.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T05:48:53Z"}
{"aid":"http://arxiv.org/abs/2504.06642v1","title":"Current-Enabled Optical Conductivity of Collective Modes in\n  Unconventional Superconductors","summary":"We theoretically investigate the current-enabled linear optical conductivity\nof collective modes in superconductors with unconventional pairing symmetries.\nAfter deriving general formulas for the optical conductivity of a\nsuperconductor featuring multiple pairing channels and bands using the path\nintegral formalism, we apply these formulas to several models. Using a model of\ncompeting s- and d-wave pairing interactions, we find that several known\ncollective modes generate peaks in the optical conductivity upon injection of a\nsupercurrent. This includes single- and multiband versions of\nBardasis-Schrieffer modes, mixed-symmetry Bardasis-Schrieffer modes, and\nLeggett modes. Using a model for interband p-wave superconductivity with Rashba\nspin-orbit coupling, we find that in such a system Bardasis-Schrieffer modes\nare optically active even without introducing a supercurrent. In a p+ip chiral\nground state, these modes turn out to produce peaks in the longitudinal and\ntransverse optical conductivity. Other collective modes belonging to the chiral\np+ip order parameter turn out to be unaffected by the spin-orbit coupling but\ncontribute to the optical response when a supercurrent is introduced. These\nresults promise new avenues for the observation of collective modes in a\nvariety of superconducting systems, including multiband superconductors and\nsuperconductors that feature multiple pairing channels or multi-component order\nparameters, such as chiral p- or d-wave superconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-09T07:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.06649v1","title":"GRAIN: Multi-Granular and Implicit Information Aggregation Graph Neural\n  Network for Heterophilous Graphs","summary":"Graph neural networks (GNNs) have shown significant success in learning graph\nrepresentations. However, recent studies reveal that GNNs often fail to\noutperform simple MLPs on heterophilous graph tasks, where connected nodes may\ndiffer in features or labels, challenging the homophily assumption. Existing\nmethods addressing this issue often overlook the importance of information\ngranularity and rarely consider implicit relationships between distant nodes.\nTo overcome these limitations, we propose the Granular and Implicit Graph\nNetwork (GRAIN), a novel GNN model specifically designed for heterophilous\ngraphs. GRAIN enhances node embeddings by aggregating multi-view information at\nvarious granularity levels and incorporating implicit data from distant,\nnon-neighboring nodes. This approach effectively integrates local and global\ninformation, resulting in smoother, more accurate node representations. We also\nintroduce an adaptive graph information aggregator that efficiently combines\nmulti-granularity and implicit data, significantly improving node\nrepresentation quality, as shown by experiments on 13 datasets covering varying\nhomophily and heterophily. GRAIN consistently outperforms 12 state-of-the-art\nmodels, excelling on both homophilous and heterophilous graphs.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T07:36:44Z"}
{"aid":"http://arxiv.org/abs/2504.06676v1","title":"Ranking alternatives from opinions on criteria","summary":"A primary challenge in collective decision-making is that achieving unanimous\nagreement is difficult, even at the level of criteria. The history of social\nchoice theory illustrates this: numerous normative criteria on voting rules\nhave been proposed; however, disagreements persist regarding which criteria\nshould take precedence. This study addresses the problem of ranking\nalternatives based on the aggregation of opinions over criteria that the\nalternatives might fulfill. Using the opinion aggregation model, we propose a\nnew rule, termed the Intersection Initial Segment (IIS) rule, and characterize\nit using five axioms: neutrality, independence of the worst set, independence\nof the best set, weak intersection very important player, and independence of\nnon-unanimous improvement. We illustrate our approach on a running example\nwhere the objective is to rank voting rules, showing that our opinion\naggregation model is particularly well-suited to this context, and that the IIS\nrule is a counterpart to the method discussed in Nurmi's paper (2015).","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-09T08:31:33Z"}
{"aid":"http://arxiv.org/abs/2504.06706v1","title":"Learning-Inspired Fuzzy Logic Algorithms for Enhanced Control of\n  Oscillatory Systems","summary":"The transportation of sensitive equipment often suffers from vibrations\ncaused by terrain, weather, and motion speed, leading to inefficiencies and\npotential damage. To address this challenge, this paper explores an intelligent\ncontrol framework leveraging fuzzy logic, a foundational AI technique, to\nsuppress oscillations in suspension systems. Inspired by learning based\nmethodologies, the proposed approach utilizes fuzzy inference and Gaussian\nmembership functions to emulate adaptive, human like decision making. By\nminimizing the need for explicit mathematical models, the method demonstrates\nrobustness in both linear and nonlinear systems. Experimental validation\nhighlights the controllers ability to adapt to varying suspension lengths,\nreducing oscillation amplitudes and improving stability under dynamic\nconditions. This research bridges the gap between traditional control systems\nand learning inspired techniques, offering a scalable, data efficient solution\nfor modern transportation challenges","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T09:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.06714v1","title":"Unifying Search and Recommendation: A Generative Paradigm Inspired by\n  Information Theory","summary":"Recommender systems and search engines serve as foundational elements of\nonline platforms, with the former delivering information proactively and the\nlatter enabling users to seek information actively. Unifying both tasks in a\nshared model is promising since it can enhance user modeling and item\nunderstanding. Previous approaches mainly follow a discriminative paradigm,\nutilizing shared encoders to process input features and task-specific heads to\nperform each task. However, this paradigm encounters two key challenges:\ngradient conflict and manual design complexity. From the information theory\nperspective, these challenges potentially both stem from the same issue -- low\nmutual information between the input features and task-specific outputs during\nthe optimization process.\n  To tackle these issues, we propose GenSR, a novel generative paradigm for\nunifying search and recommendation (S&R), which leverages task-specific prompts\nto partition the model's parameter space into subspaces, thereby enhancing\nmutual information. To construct effective subspaces for each task, GenSR first\nprepares informative representations for each subspace and then optimizes both\nsubspaces in one unified model. Specifically, GenSR consists of two main\nmodules: (1) Dual Representation Learning, which independently models\ncollaborative and semantic historical information to derive expressive item\nrepresentations; and (2) S&R Task Unifying, which utilizes contrastive learning\ntogether with instruction tuning to generate task-specific outputs effectively.\nExtensive experiments on two public datasets show GenSR outperforms\nstate-of-the-art methods across S&R tasks. Our work introduces a new generative\nparadigm compared with previous discriminative methods and establishes its\nsuperiority from the mutual information perspective.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T09:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.06721v1","title":"Learning global control of underactuated systems with Model-Based\n  Reinforcement Learning","summary":"This short paper describes our proposed solution for the third edition of the\n\"AI Olympics with RealAIGym\" competition, held at ICRA 2025. We employed\nMonte-Carlo Probabilistic Inference for Learning Control (MC-PILCO), an MBRL\nalgorithm recognized for its exceptional data efficiency across various\nlow-dimensional robotic tasks, including cart-pole, ball \\& plate, and Furuta\npendulum systems. MC-PILCO optimizes a system dynamics model using interaction\ndata, enabling policy refinement through simulation rather than direct system\ndata optimization. This approach has proven highly effective in physical\nsystems, offering greater data efficiency than Model-Free (MF) alternatives.\nNotably, MC-PILCO has previously won the first two editions of this\ncompetition, demonstrating its robustness in both simulated and real-world\nenvironments. Besides briefly reviewing the algorithm, we discuss the most\ncritical aspects of the MC-PILCO implementation in the tasks at hand: learning\na global policy for the pendubot and acrobot systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-09T09:20:37Z"}
{"aid":"http://arxiv.org/abs/2504.06724v1","title":"End-to-end design framework for compressed on-chip pixel-wise\n  spectro-polarimeters","summary":"Modern detector manufacturing allows spectral and polarimetric filters to be\ndirectly integrated on top of separate detector pixels. This enables the\ncreation of CubeSat-sized spectro-polarimetric instruments that are not much\nlarger than the detector and a lens. Redundancy inherent to the observed scene,\noffers the opportunity for sparse sampling in the form of not scanning all\nfilters at every location. However, when there are fewer pushbroom steps than\nfilters, data are missing in the resulting data cube. The missing, largely\nredundant data can be filled in with interpolation methods, often called\ndemosaicers. The choice of filters and their precise layout influences the\nperformance of the instrument after the demosaicing process. In these\nproceedings we describe a part of a design toolbox for both the filter layout\nand the optimum parameters for the reconstruction to a full\nspectro-polarimetric data cube. The design tool is based on training a (neural)\nnetwork and jointly updating the values of the filters and demosaicer. We\noptimized a filter layout by training on spectro-polarimetric remote\nobservations of the Earth acquired by SPEX airborne. This optimised filter\nlayout could reconstruct a validation scene from five overlapping snapshots\n(pushbroom steps), which would take 109 pushbroom steps when measuring with a\nclassical layout and no reconstruction.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.optics","published":"2025-04-09T09:29:30Z"}
{"aid":"http://arxiv.org/abs/2504.06737v1","title":"Urysohn width of hypersurfaces and positive macroscopic scalar curvature","summary":"We prove that if a complete Riemannian $n$-manifold with non-trivial\ncodimension 1 homology with $\\mathbb{Z}_2$-coefficients or\n$\\mathbb{Z}$-coefficients has positive macroscopic scalar curvature large\nenough, then it contains a non-nullhomologous hypersurface of small Urysohn\n$(n-2)$-width. This constitutes a macroscopic analogue of a theorem by\nBray--Brendle--Neves on the area of non-contractible 2-spheres in a closed\nRiemannian 3-manifold with positive scalar curvature. Our proof is based on an\nadaptation of Guth's macroscopic version of the Schoen-Yau descent argument.","main_category":"math.DG","categories":"math.DG","published":"2025-04-09T09:51:03Z"}
{"aid":"http://arxiv.org/abs/2504.06739v1","title":"Selective Kondo screening and strange metallicity by sliding Dirac\n  semimetals","summary":"Kondo screening of local moments in normal metals typically leads to\nhybridized conduction and valence bands separated by a Kondo gap, resulting in\nan insulating state at half-band filling. We show a dramatic change of this\nscenario in a Dirac-semimetal-based correlated system -- a bilayer honeycomb\nlattice heterostructure where the local moment lattice is stacked on a Dirac\nsemimetal breaking the inversion symmetry. This system is modeled by an\nextended Anderson honeycomb lattice involving the real-space dependence of\nmajor interlayer hybridization parameters on the relative sliding distance\nalong the armchair direction. First, we unveil the multiple Kondo scales and\nthe successive Kondo breakdown transitions in this correlated heterostructure\nunder sliding. Second, we demonstrate the existence of a genuine selective\nKondo screening phase which is stabilized near the A-B stack pattern and is\naccessible by applying the interlayer voltage. Third, we find a nearly flat\nhybridized band located concomitantly within the Kondo gap, resulting in an\nunprecedented metallic state at the half-band filling. This unconventional\nheavy fermion state is characterized by the violation of Luttinger theorem and\nthe appearance of a Van Hove singularity at the Fermi energy. The general\nsliding-driven band structure landscape and the implications of our results for\nthe broad context of multiorbital Kondo physics are briefly discussed.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-09T09:51:47Z"}
{"aid":"http://arxiv.org/abs/2504.06745v1","title":"A pluripotential theoretic framework for polynomial interpolation of\n  vector-valued functions and differential forms","summary":"We consider the problem of uniform interpolation of functions with values in\na complex inner product space of finite dimension. This problem can be casted\nwithin a modified weighted pluripotential theoretic framework. Indeed, in the\nproposed modification a vector valued weight is considered, allowing to\npartially extend the main asymptotic results holding for interpolation of\nscalar valued functions to the case of vector valued ones. As motivating\nexample and main application we specialize our results to interpolation of\ndifferential forms by differential forms with polynomial coefficients.","main_category":"math.CV","categories":"math.CV","published":"2025-04-09T10:04:23Z"}
{"aid":"http://arxiv.org/abs/2504.06748v1","title":"Efficient Deployment of Spiking Neural Networks on SpiNNaker2 for DVS\n  Gesture Recognition Using Neuromorphic Intermediate Representation","summary":"Spiking Neural Networks (SNNs) are highly energy-efficient during inference,\nmaking them particularly suitable for deployment on neuromorphic hardware.\nTheir ability to process event-driven inputs, such as data from dynamic vision\nsensors (DVS), further enhances their applicability to edge computing tasks.\nHowever, the resource constraints of edge hardware necessitate techniques like\nweight quantization, which reduce the memory footprint of SNNs while preserving\naccuracy. Despite its importance, existing quantization methods typically focus\non synaptic weights quantization without taking account of other critical\nparameters, such as scaling neuron firing thresholds.\n  To address this limitation, we present the first benchmark for the DVS\ngesture recognition task using SNNs optimized for the many-core neuromorphic\nchip SpiNNaker2. Our study evaluates two quantization pipelines for fixed-point\ncomputations. The first approach employs post training quantization (PTQ) with\npercentile-based threshold scaling, while the second uses quantization aware\ntraining (QAT) with adaptive threshold scaling. Both methods achieve accurate\n8-bit on-chip inference, closely approximating 32-bit floating-point\nperformance. Additionally, our baseline SNNs perform competitively against\npreviously reported results without specialized techniques. These models are\ndeployed on SpiNNaker2 using the neuromorphic intermediate representation\n(NIR). Ultimately, we achieve 94.13% classification accuracy on-chip,\ndemonstrating the SpiNNaker2's potential for efficient, low-energy neuromorphic\ncomputing.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T10:09:29Z"}
{"aid":"http://arxiv.org/abs/2504.06771v1","title":"AI, Help Me Think$\\unicode{x2014}$but for Myself: Assisting People in\n  Complex Decision-Making by Providing Different Kinds of Cognitive Support","summary":"How can we design AI tools that effectively support human decision-making by\ncomplementing and enhancing users' reasoning processes? Common\nrecommendation-centric approaches face challenges such as inappropriate\nreliance or a lack of integration with users' decision-making processes. Here,\nwe explore an alternative interaction model in which the AI outputs build upon\nusers' own decision-making rationales. We compare this approach, which we call\nExtendAI, with a recommendation-based AI. Participants in our mixed-methods\nuser study interacted with both AIs as part of an investment decision-making\ntask. We found that the AIs had different impacts, with ExtendAI integrating\nbetter into the decision-making process and people's own thinking and leading\nto slightly better outcomes. RecommendAI was able to provide more novel\ninsights while requiring less cognitive effort. We discuss the implications of\nthese and other findings along with three tensions of AI-assisted\ndecision-making which our study revealed.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-09T10:48:17Z"}
{"aid":"http://arxiv.org/abs/2504.06779v1","title":"What if we find nothing? Bayesian analysis of the statistical\n  information of null results in future exoplanet habitability and biosignature\n  surveys","summary":"Future telescopes will survey temperate, terrestrial exoplanets to estimate\nthe frequency of habitable ($\\eta_{\\text{Hab}}$) or inhabited\n($\\eta_{\\text{Life}}$) planets. This study aims to determine the minimum number\nof planets ($N$) required to draw statistically significant conclusions,\nparticularly in the case of a null result (i.e., no detections). Using a\nBayesian framework, we analyzed surveys of up to $N=100$ planets to infer the\nfrequency of a binary observable feature ($\\eta_{\\text{obs}}$) after null\nresults. Posterior best fits and upper limits were derived for various survey\nsizes and compared with predicted yields from missions like the Large\nInterferometer for Exoplanets (LIFE) and the Habitable Worlds Observatory\n(HWO). Our findings indicate that $N=20-50$ ``perfect'' observations (100\\%\nconfidence in detecting or excluding the feature) yield conclusions relatively\nindependent of priors. To achieve 99.9\\% upper limits of $\\eta_{\\text{obs}}\n\\leq 0.2/0.1$, approximately $N \\simeq 40/80$ observations are needed. For\n``imperfect'' observations, uncertainties in interpretation and sample biases\nbecome limiting factors. We show that LIFE and HWO aim for sufficiently large\nsurvey sizes to provide statistically meaningful estimates of habitable\nenvironments and life prevalence under these assumptions. However, robust\nconclusions require careful sample selection and high-confidence detection or\nexclusion of features in each observation.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-09T11:02:19Z"}
{"aid":"http://arxiv.org/abs/2504.06809v1","title":"Modeling and analysis methods for early detection of leakage points in\n  gas transmission systems","summary":"Early detection of leaks in gas transmission systems is crucial for ensuring\nuninterrupted gas supply, enhancing operational efficiency, and minimizing\nenvironmental and economic risks. This study aims to develop an analytical\nmethod for accurately identifying leak locations in gas pipelines based on\nunsteady gas flow dynamics. A novel approach is proposed that utilizes pressure\nvariations at the inlet and outlet points to determine the minimum fixation\ntime (t = t1) required for real-time leak detection. Through mathematical\nmodeling and numerical analysis, the study demonstrates that the ratio of\npressure drops at different points along the pipeline can be effectively used\nto pinpoint leakage locations. The results indicate that the proposed method\nsignificantly improves detection accuracy and response time, making it a viable\nsolution for integration into gas pipeline monitoring and control systems.","main_category":"math.OC","categories":"math.OC","published":"2025-04-09T11:59:24Z"}
{"aid":"http://arxiv.org/abs/2504.06839v1","title":"Convergence to the equilibrium for the kinetic transport equation in the\n  two-dimensional periodic Lorentz Gas","summary":"We consider the Boltzmann-Grad limit of the two-dimensional periodic Lorentz\nGas. It has been proved in [6,14,4] that the time evolution of a probability\ndensity on $\\mathbb{R}^2\\times\\mathbb{T}^1\\ni(x,v)$ is obtained by extending\nthe phase space $\\mathbb{R}^2\\times\\mathbb{T}^1$ to\n$\\mathbb{R}^2\\times\\mathbb{T}^1\\times[0,+\\infty)\\times[-1,1]$, where\n$s\\in[0,+\\infty)$ represents the time to the next collision and $h\\in[-1,1]$\nthe corresponding impact parameter. Here we prove that under suitable\nconditions the time evolution of an initial datum in\n$L^p(\\mathbb{T}^2\\times\\mathbb{T}^1\\times[0,+\\infty)\\times[-1,1])$ converges to\nthe equilibrium state with respect to the $L^p$ norm ($^*$-weakly if\n$p=\\infty$). If $p=2$, or if the initial datum does not depend on $x$, we also\nget more precise estimates about the rate of the approach to the equilibrium.\nOur proof is based on the analysis of the long time behavior of the Fourier\ncoefficients of the solution.","main_category":"math-ph","categories":"math-ph,math.AP,math.MP","published":"2025-04-09T12:57:42Z"}
{"aid":"http://arxiv.org/abs/2504.06841v1","title":"Classifying the Unknown: In-Context Learning for Open-Vocabulary Text\n  and Symbol Recognition","summary":"We introduce Rosetta, a multimodal model that leverages Multimodal In-Context\nLearning (MICL) to classify sequences of novel script patterns in documents by\nleveraging minimal examples, thus eliminating the need for explicit retraining.\nTo enhance contextual learning, we designed a dataset generation process that\nensures varying degrees of contextual informativeness, improving the model's\nadaptability in leveraging context across different scenarios. A key strength\nof our method is the use of a Context-Aware Tokenizer (CAT), which enables\nopen-vocabulary classification. This allows the model to classify text and\nsymbol patterns across an unlimited range of classes, extending its\nclassification capabilities beyond the scope of its training alphabet of\npatterns. As a result, it unlocks applications such as the recognition of new\nalphabets and languages. Experiments on synthetic datasets demonstrate the\npotential of Rosetta to successfully classify Out-Of-Distribution visual\npatterns and diverse sets of alphabets and scripts, including but not limited\nto Chinese, Greek, Russian, French, Spanish, and Japanese.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T12:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.06842v1","title":"Optimality of Gradient-MUSIC for Spectral Estimation","summary":"The goal of spectral estimation is to estimate the frequencies and amplitudes\nof a nonharmonic Fourier sum given noisy time samples. This paper introduces\nthe Gradient-MUSIC algorithm, which is a novel nonconvex optimization\nreformulation of the classical MUSIC algorithm. Under the assumption that\n$m\\Delta\\geq 8\\pi$, where $\\pi/m$ is the Nyquist rate and $\\Delta$ is the\nminimum separation of the frequencies normalized to be in $[0,2\\pi)$, we\nprovide a thorough geometric analysis of the objective functions generated by\nthe algorithm. Gradient-MUSIC thresholds the objective function on a set that\nis as coarse as possible and locates a set of suitable initialization for\ngradient descent. Although the objective function is nonconvex, gradient\ndescent converges exponentially fast to the desired local minima, which are the\nestimated frequencies of the signal. For deterministic $\\ell^p$ perturbations\nand any $p\\in [1,\\infty]$, Gradient-MUSIC estimates the frequencies and\namplitudes at the minimax optimal rate in terms of the noise level and $m$. For\nexample, if the noise has $\\ell^\\infty$ norm at most $\\epsilon$, then the\nfrequencies and amplitudes are recovered up to error at most $C\\epsilon/m$ and\n$C\\epsilon$, respectively, which are optimal in $\\epsilon$ and $m$. Aside from\nlogarithmic factors, Gradient-MUSIC is optimal for white noise and matches the\nrate achieved by nonlinear least squares for various families of nonstationary\nindependent Gaussian noise. Our results show that classical MUSIC is equally\noptimal, but it requires an expensive search on a thin grid, whereas\nGradient-MUSIC is always computationally more efficient, especially for small\nnoise. As a consequence of this paper, for sufficiently well separated\nfrequencies, both Gradient-MUSIC and classical MUSIC are the first provably\noptimal and computationally tractable algorithms for deterministic $\\ell^p$\nperturbations.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T13:00:49Z"}
{"aid":"http://arxiv.org/abs/2504.06856v1","title":"CasTex: Cascaded Text-to-Texture Synthesis via Explicit Texture Maps and\n  Physically-Based Shading","summary":"This work investigates text-to-texture synthesis using diffusion models to\ngenerate physically-based texture maps. We aim to achieve realistic model\nappearances under varying lighting conditions. A prominent solution for the\ntask is score distillation sampling. It allows recovering a complex texture\nusing gradient guidance given a differentiable rasterization and shading\npipeline. However, in practice, the aforementioned solution in conjunction with\nthe widespread latent diffusion models produces severe visual artifacts and\nrequires additional regularization such as implicit texture parameterization.\nAs a more direct alternative, we propose an approach using cascaded diffusion\nmodels for texture synthesis (CasTex). In our setup, score distillation\nsampling yields high-quality textures out-of-the box. In particular, we were\nable to omit implicit texture parameterization in favor of an explicit\nparameterization to improve the procedure. In the experiments, we show that our\napproach significantly outperforms state-of-the-art optimization-based\nsolutions on public texture synthesis benchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:08:30Z"}
{"aid":"http://arxiv.org/abs/2504.06882v1","title":"Brillouin Platycosms and Topological Phases","summary":"There exist ten distinct closed flat $3$D manifolds, known as platycosms,\nwhich hold significance in mathematics and have been postulated as potential\ngeometric models for our universe. In this work, we demonstrate their\nmanifestation as universes of Bloch particles, namely as momentum-space units\nreferred to as Brillouin platycosms, which are natural extensions of the\nBrillouin torus within a broader framework of projective crystallographic\nsymmetries. Moreover, we provide exact K-theoretical classifications of\ntopological insulators over these platycosms by the Atiyah-Hirzebruch spectral\nsequence, and formulate a complete set of topological invariants for their\nidentification. Topological phase transitions are generically characterized by\nWeyl semimetals, adhering to the generalized Nielsen-Ninomiya theorem: the\ntotal chirality number over a Brillouin platycosm is even (zero) if the\nplatycosm is non-orientable (orientable). Our work generalizes the notion of\nBrillouin torus to ten Brillouin platycosms and therefore fundamentally\ndiversifies the stages on which Block wavefunctions can perform their\ntopological dance.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T13:36:41Z"}
{"aid":"http://arxiv.org/abs/2504.06905v1","title":"A Game Theoretic Treatment of Contagion in Trade Networks","summary":"Global trade of material goods involves the potential to create pathways for\nthe spread of infectious pathogens. One trade sector in which this synergy is\nclearly critical is that of wildlife trade networks. This highly complex system\ninvolves important and understudied bidirectional coupling between the economic\ndecision making of the stakeholders and the contagion dynamics on the emergent\ntrade network. While each of these components are independently well studied,\nthere is a meaningful gap in understanding the feedback dynamics that can arise\nbetween them. In the present study, we describe a general game theoretic model\nfor trade networks of goods susceptible to contagion. The primary result relies\non the acyclic nature of the trade network and shows that, through the course\nof trading with stochastic infections, the probability of infection converges\nto a directly computable fixed point. This allows us to compute best responses\nand thus identify equilibria in the game. We present ways to use this model to\ndescribe and evaluate trade networks in terms of global and individual risk of\ninfection under a wide variety of structural or individual modifications to the\ntrade network. In capturing the bidirectional coupling of the system, we\nprovide critical insight into the global and individual drivers and\nconsequences for risks of infection inherent in and arising from the global\nwildlife trade, and any economic trade network with associated contagion risks.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-09T14:07:24Z"}
{"aid":"http://arxiv.org/abs/2504.06917v1","title":"Data Augmentation for Fake Reviews Detection in Multiple Languages and\n  Multiple Domains","summary":"With the growth of the Internet, buying habits have changed, and customers\nhave become more dependent on the online opinions of other customers to guide\ntheir purchases. Identifying fake reviews thus became an important area for\nNatural Language Processing (NLP) research. However, developing\nhigh-performance NLP models depends on the availability of large amounts of\ntraining data, which are often not available for low-resource languages or\ndomains. In this research, we used large language models to generate datasets\nto train fake review detectors. Our approach was used to generate fake reviews\nin different domains (book reviews, restaurant reviews, and hotel reviews) and\ndifferent languages (English and Chinese). Our results demonstrate that our\ndata augmentation techniques result in improved performance at fake review\ndetection for all domains and languages. The accuracy of our fake review\ndetection model can be improved by 0.3 percentage points on DeRev TEST, 10.9\npercentage points on Amazon TEST, 8.3 percentage points on Yelp TEST and 7.2\npercentage points on DianPing TEST using the augmented datasets.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T14:23:54Z"}
{"aid":"http://arxiv.org/abs/2504.06936v1","title":"On Macdonald expansions of $q$-chromatic symmetric functions and the\n  Stanley-Stembridge Conjecture","summary":"The Stanley-Stembridge conjecture asserts that the chromatic symmetric\nfunction of a $(3+1)$-free graph is $e$-positive. Recently, Hikita proved this\nconjecture by giving an explicit $e$-expansion of the Shareshian-Wachs\n$q$-chromatic refinement for unit interval graphs. Using the $\\mathbb{A}_{q,t}$\nalgebra, we give an expansion of these $q$-chromatic symmetric functions into\nMacdonald polynomials. Upon setting $t=1$, we obtain another proof of the\nStanley-Stembridge conjecture and rederive Hikita's formula. Upon setting\n$t=0$, we obtain an expansion into Hall-Littlewood symmetric functions.","main_category":"math.CO","categories":"math.CO,math.RT","published":"2025-04-09T14:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.06938v1","title":"On the Compressibility of Integral Operators in Anisotropic Wavelet\n  Coordinates","summary":"The present article is concerned with the s*-compressibility of classical\nboundary integral operators in anisotropic wavelet coordinates. Having the\ns*-compressibility at hand, one can design adaptive wavelet algorithms which\nare asymptotically optimal, meaning that any target accuracy can be achieved at\na computational expense that stays proportional to the number of degrees of\nfreedom (within the setting determined by an underlying wavelet basis) that\nwould ideally be necessary for realising that target accuracy if full knowledge\nabout the unknown solution were given. As we consider here anisotropic wavelet\ncoordinates, we can achieve higher convergence rates compared to the standard,\nisotropic setting. Especially, edge singularities of anisotropic nature can be\nresolved.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T14:42:01Z"}
{"aid":"http://arxiv.org/abs/2504.06967v1","title":"Optimal promotions of new products on networks","summary":"We present a novel methodology for analyzing the optimal promotion in the\nBass model for the spreading of new products on networks. For general networks\nwith $M$ nodes, the optimal promotion is the solution of $2^M-1$\nnonlinearly-coupled boundary-value problems. On structured networks, however,\nthe number of equations can be reduced to a manageable size which is amendable\nto simulations and analysis. This enables us to gain insight into the effect of\nthe network structure on optimal promotions. We find that the optimal\nadvertising strategy decreases with time, whereas the optimal boosting of peer\neffects increases from zero and then decreases. In low-degree networks, it is\noptimal to prioritize advertising over boosting peer effects, but this relation\nis flipped in high-degree networks. When the planning horizon is finite, the\noptimal promotion continues until the last minute, as opposed to an infinite\nplanning horizon where the optimal promotion decays to zero. Finally,\npromotions with short planning horizons can yield an order of magnitude higher\nincrease of profits, compared to those with long planning horizons.","main_category":"math.OC","categories":"math.OC,cs.SI","published":"2025-04-09T15:23:10Z"}
{"aid":"http://arxiv.org/abs/2504.06981v1","title":"LCL Resonance Analysis and Damping in Single-Loop Grid-Forming Wind\n  Turbines","summary":"A dynamic phenomenon known as LCL resonance is often neglected when stability\nanalysis is carried out for grid-forming (GFM) control schemes by wind turbine\nsystems, due to its high frequency. This paper shows that this simplification\nis not always valid for single-loop (SL) control schemes. A detailed\nsmall-signal analysis reveals that reactive power (RAP) control significantly\ninfluences the resonant modes, which may be dominant in determining overall\nsystem stability, even if the resonant frequency is high. The underlying\nmechanism via which the LCL resonance may dominate the overall system stability\nis systematically analyzed. Furthermore, various RAP control strategies are\ncompared to assess their different effects on resonant modes. An active damping\n(AD) strategy favorable for SL-GFM control is then designed. We also provide a\ncomparison between SL-GFM and well-studied grid-following control schemes,\nhighlighting quite different resonance features between them. Finally, case\nstudies associated with a 14-bus, 5-machine IEEE test system are presented.\nThese show that instability originates from the LCL resonance rather than\nlow-frequency interactions among multiple machines, validating the theoretical\nanalysis and the proposed AD strategy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T15:37:02Z"}
{"aid":"http://arxiv.org/abs/2504.06991v1","title":"Dissimilar Batch Decompositions of Random Datasets","summary":"For better learning, large datasets are often split into small batches and\nfed sequentially to the predictive model. In this paper, we study such batch\ndecompositions from a probabilistic perspective. We assume that data points\n(possibly corrupted) are drawn independently from a given space and define a\nconcept of similarity between two data points. We then consider decompositions\nthat restrict the amount of similarity within each batch and obtain high\nprobability bounds for the minimum size. We demonstrate an inherent tradeoff\nbetween relaxing the similarity constraint and the overall size and also use\nmartingale methods to obtain bounds for the maximum size of data subsets with a\ngiven similarity.","main_category":"cs.LG","categories":"cs.LG,math.PR,stat.ML","published":"2025-04-09T15:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.07005v1","title":"A stacky approach to prismatic crystals via $q$-prism charts","summary":"Let $Y$ be a locally complete intersection over $\\mathcal{O}_K$ containing a\n$p$-power root of unity $\\zeta_p$. We classify the derived category of\nprismatic crystals on the absolute prismatic site of $Y$ by studying\nquasi-coherent complexes on the prismatization of $Y$ via $q$-prism charts. We\nalso develop a Galois descent mechanism to remove the assumption on\n$\\mathcal{O}_K$. As an application, we classify quasi-coherent complexes on the\nCartier-Witt stack and give a purely algebraic calculation of the cohomology of\nthe structure sheaf on the absolute prismatic site of $\\mathbb{Z}_p$. Along the\nway, for $Y$ a locally complete intersection over $\\overline{A}$ with $A$ lying\nover a $q$-prism, we classify quasi-coherent complexes on the relative\nprismatization of $Y$.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-09T16:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.07017v1","title":"Adapting GT2-FLS for Uncertainty Quantification: A Blueprint Calibration\n  Strategy","summary":"Uncertainty Quantification (UQ) is crucial for deploying reliable Deep\nLearning (DL) models in high-stakes applications. Recently, General Type-2\nFuzzy Logic Systems (GT2-FLSs) have been proven to be effective for UQ,\noffering Prediction Intervals (PIs) to capture uncertainty. However, existing\nmethods often struggle with computational efficiency and adaptability, as\ngenerating PIs for new coverage levels $(\\phi_d)$ typically requires retraining\nthe model. Moreover, methods that directly estimate the entire conditional\ndistribution for UQ are computationally expensive, limiting their scalability\nin real-world scenarios. This study addresses these challenges by proposing a\nblueprint calibration strategy for GT2-FLSs, enabling efficient adaptation to\nany desired $\\phi_d$ without retraining. By exploring the relationship between\n$\\alpha$-plane type reduced sets and uncertainty coverage, we develop two\ncalibration methods: a lookup table-based approach and a derivative-free\noptimization algorithm. These methods allow GT2-FLSs to produce accurate and\nreliable PIs while significantly reducing computational overhead. Experimental\nresults on high-dimensional datasets demonstrate that the calibrated GT2-FLS\nachieves superior performance in UQ, highlighting its potential for scalable\nand practical applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T16:32:43Z"}
{"aid":"http://arxiv.org/abs/2504.07018v1","title":"ShadowBinding: Realizing Effective Microarchitectures for In-Core Secure\n  Speculation Schemes","summary":"Secure speculation schemes have shown great promise in the war against\nspeculative side-channel attacks, and will be a key building block for\ndeveloping secure, high-performance architectures moving forward. As the field\nmatures, the need for rigorous microarchitectures, and corresponding\nperformance and cost analysis, become critical for evaluating secure schemes\nand for enabling their future adoption.\n  In ShadowBinding, we present effective microarchitectures for two\nstate-of-the-art secure schemes, uncovering and mitigating fundamental\nmicroarchitectural limitations within the analyzed schemes, and provide\nimportant design characteristics. We uncover that Speculative Taint Tracking's\n(STT's) rename-based taint computation must be completed in a single cycle,\ncreating an expensive dependency chain which greatly limits performance for\nwider processor cores. We also introduce a novel michroarchitectural approach\nfor STT, named STT-Issue, which, by delaying the taint computation to the issue\nstage, eliminates the dependency chain, achieving better instructions per cycle\n(IPC), timing, area, and performance results.\n  Through a comprehensive evaluation of our STT and Non-Speculative Data Access\n(NDA) microarchitectural designs on the RISC-V Berkeley Out-of-Order Machine,\nwe find that the IPC impact of in-core secure schemes is higher than previously\nestimated, close to 20% for the highest performance core. With insights into\ntiming from our RTL evaluation, the performance loss, created by the combined\nimpact of IPC and timing, becomes even greater, at 35%, 27%, and 22% for\nSTT-Rename, STT-Issue, and NDA, respectively. If these trends were to hold for\nleading processor core designs, the performance impact would be well over 30%,\neven for the best-performing scheme.","main_category":"cs.CR","categories":"cs.CR,cs.AR","published":"2025-04-09T16:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.07023v1","title":"Swinging small quantum systems out of available values of control\n  parameters","summary":"When a quantum system is prepared in its many-body ground state, it can be\nadiabatically driven to another ground state by changing its control parameter.\nHowever, relying on adiabaticity is experimentally unjustified. Moreover, the\ntarget value of the control parameter may occur outside the experimentally\naccessible range. The indicated target state, however, can still be reached\nwithin a clever protocol of temporal changes of the control parameter provided\nits decomposition into some basis is known. It turns out that such a protocol\ncan be obtained in the framework of the optimal control theory. In this paper,\nwe show how to apply such an optimization scheme to small quantum systems\ntreating interaction strength as the control parameter. We believe that the\nproposed approach can be creatively extended to various complex quantum\nsystems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas","published":"2025-04-09T16:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.07050v1","title":"Minimal mechanism for fluidic flocks in interacting active colloids","summary":"Collective motion as a flock is a widely observed phenomenon in active matter\nsystems. Finding possible mechanisms of attaining a global polar order via\ndynamical mechanisms - without any explicit alignment interaction - is an area\nof active current research. Here, we report a flocking transition sustained\npurely by chemo-repulsive torques at low to medium densities in a system of\nchemically interacting colloidal particles. The basic requirements to sustain\nthe flock are excluded volume repulsions and deterministic long-ranged net\nrepulsive torques, with the time scale individual colloids move a unit length\nbeing dominant with respect to the time they deterministically sense chemicals.\nSwitching on the translational repulsive forces renders the flock a crystalline\nstructure. The generality of this phenomenon is displayed for a range of\nattractive translational forces to which the flock is robust. We rationalize\nthese results with a phenomenological hydrodynamical model.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-09T17:09:48Z"}
{"aid":"http://arxiv.org/abs/2504.07060v1","title":"Generalized Semantic Contrastive Learning via Embedding Side Information\n  for Few-Shot Object Detection","summary":"The objective of few-shot object detection (FSOD) is to detect novel objects\nwith few training samples. The core challenge of this task is how to construct\na generalized feature space for novel categories with limited data on the basis\nof the base category space, which could adapt the learned detection model to\nunknown scenarios. However, limited by insufficient samples for novel\ncategories, two issues still exist: (1) the features of the novel category are\neasily implicitly represented by the features of the base category, leading to\ninseparable classifier boundaries, (2) novel categories with fewer data are not\nenough to fully represent the distribution, where the model fine-tuning is\nprone to overfitting. To address these issues, we introduce the side\ninformation to alleviate the negative influences derived from the feature space\nand sample viewpoints and formulate a novel generalized feature representation\nlearning method for FSOD. Specifically, we first utilize embedding side\ninformation to construct a knowledge matrix to quantify the semantic\nrelationship between the base and novel categories. Then, to strengthen the\ndiscrimination between semantically similar categories, we further develop\ncontextual semantic supervised contrastive learning which embeds side\ninformation. Furthermore, to prevent overfitting problems caused by sparse\nsamples, a side-information guided region-aware masked module is introduced to\naugment the diversity of samples, which finds and abandons biased information\nthat discriminates between similar categories via counterfactual explanation,\nand refines the discriminative representation space further. Extensive\nexperiments using ResNet and ViT backbones on PASCAL VOC, MS COCO, LVIS V1,\nFSOD-1K, and FSVOD-500 benchmarks demonstrate that our model outperforms the\nprevious state-of-the-art methods, significantly improving the ability of FSOD\nin most shots/splits.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T17:24:05Z"}
{"aid":"http://arxiv.org/abs/2504.07066v1","title":"Intertwining Josephson and Vortex Topologies in Conventional\n  Superconductors","summary":"Recent experimental advances have unveiled promising evidence of vortex-bound\nMajorana quasiparticles in multiple superconducting compounds. However,\ntheoretical progress in understanding these phenomena, especially from ab\ninitio approaches, has been limited by the computational complexity of\nsimulating vortex structures. To bridge this gap, we introduce the\nJosephson-vortex correspondence (JVC), a theoretical framework that\nsystematically maps the bound-state topological properties of vortices to those\nof $\\pi$-phase Josephson junctions in the same superconductor. This\ncorrespondence allows vortex phase diagrams to be constructed directly from\njunction calculations, thereby eliminating the need for large-scale vortex\ncalculations. We demonstrate the validity and predictive power of JVC across a\nvariety of effective models, and further extend the framework to the\nfirst-principles level. Applying our approach to 2M-WS$_2$ and Sr$_3$SnO, we\nidentify them as realistic, doping-tunable platforms for realizing vortex\nMajorana zero modes. Our theory will pave the way for ab initio Majorana\nmaterial discovery and design.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-09T17:31:34Z"}
{"aid":"http://arxiv.org/abs/2504.07087v1","title":"KG-LLM-Bench: A Scalable Benchmark for Evaluating LLM Reasoning on\n  Textualized Knowledge Graphs","summary":"Knowledge graphs have emerged as a popular method for injecting up-to-date,\nfactual knowledge into large language models (LLMs). This is typically achieved\nby converting the knowledge graph into text that the LLM can process in\ncontext. While multiple methods of encoding knowledge graphs have been\nproposed, the impact of this textualization process on LLM performance remains\nunder-explored. We introduce KG-LLM-Bench, a comprehensive and extensible\nbenchmark spanning five knowledge graph understanding tasks, and evaluate how\ndifferent encoding strategies affect performance across various base models.\nOur extensive experiments with seven language models and five textualization\nstrategies provide insights for optimizing LLM performance on KG reasoning\ntasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-04-09T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.07090v1","title":"A Differentiable, End-to-End Forward Model for 21 cm Cosmology:\n  Estimating the Foreground, Instrument, and Signal Joint Posterior","summary":"We present a differentiable, end-to-end Bayesian forward modeling framework\nfor line intensity mapping cosmology experiments, with a specific focus on\nlow-frequency radio telescopes targeting the redshifted 21 cm line from neutral\nhydrogen as a cosmological probe. Our framework is capable of posterior density\nestimation of the cosmological signal jointly with foreground and telescope\nparameters at the field level. Our key aim is to be able to optimize the\nmodel's high-dimensional, non-linear, and ill-conditioned parameter space,\nwhile also sampling from it to perform robust uncertainty quantification within\na Bayesian framework. We show how a differentiable programming paradigm,\naccelerated by recent advances in machine learning software and hardware, can\nmake this computationally-demanding, end-to-end Bayesian approach feasible. We\ndemonstrate a proof-of-concept on a simplified signal recovery problem for the\nHydrogen Epoch of Reionization Array experiment, highlighting the framework's\nability to build confidence in early 21 cm signal detections even in the\npresence of poorly understood foregrounds and instrumental systematics. We use\na Hessian-preconditioned Hamiltonian Monte Carlo algorithm to efficiently\nsample our parameter space with a dimensionality approaching $N\\sim10^5$, which\nenables joint, end-to-end nuisance parameter marginalization over foreground\nand instrumental terms. Lastly, we introduce a new spherical harmonic formalism\nthat is a complete and orthogonal basis on the cut sky relevant to drift-scan\nradio surveys, which we call the spherical stripe harmonic formalism, and it's\nassociated three-dimensional basis, the spherical stripe Fourier-Bessel\nformalism.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-04-09T17:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.07096v1","title":"OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training\n  Tokens","summary":"We present OLMoTrace, the first system that traces the outputs of language\nmodels back to their full, multi-trillion-token training data in real time.\nOLMoTrace finds and shows verbatim matches between segments of language model\noutput and documents in the training text corpora. Powered by an extended\nversion of infini-gram (Liu et al., 2024), our system returns tracing results\nwithin a few seconds. OLMoTrace can help users understand the behavior of\nlanguage models through the lens of their training data. We showcase how it can\nbe used to explore fact checking, hallucination, and the creativity of language\nmodels. OLMoTrace is publicly available and fully open-source.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T17:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.07098v1","title":"Nonhermitian topological zero modes at smooth domain walls: Exact\n  solutions","summary":"The bulk-boundary correspondence predicts the existence of boundary modes\nlocalized at the edges of topologically nontrivial systems. The wavefunctions\nof hermitian boundary modes can be obtained as the eigenmode of a modified\nJackiw-Rebbi equation. Recently, the bulk-boundary correspondence has been\nextended to nonhermitian systems, which describe physical phenomena such as\ngain and loss in open and non-equilibrium systems. Nonhermitian energy spectra\ncan be complex-valued and exhibit point gaps or line gaps in the complex plane,\nwhether the gaps can be continuously deformed into points or lines,\nrespectively. Specifically, line-gapped nonhermitian systems can be\ncontinuously deformed into hermitian gapped spectra. Here, we find the\nanalytical form of the wavefunctions of nonhermitian boundary modes with zero\nenergy localized at smooth domain boundaries between topologically distinct\nphases, by solving the generalized Jackiw-Rebbi equation in the nonhermitian\nregime. Moreover, we unveil a universal relation between the scalar fields and\nthe decay rate and oscillation wavelength of the boundary modes. This relation\nquantifies the bulk-boundary correspondence in nonhermitian line-gapped systems\nin terms of experimentally measurable physical quantities and is not affected\nby the details of the spatial dependence of the scalar fields. These findings\nshed some new light on the localization properties of boundary modes in\nnonhermitian and topologically nontrivial states of matter.","main_category":"hep-th","categories":"hep-th,cond-mat.mes-hall,cond-mat.quant-gas,cond-mat.supr-con","published":"2025-04-09T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.07441v1","title":"WS-DETR: Robust Water Surface Object Detection through Vision-Radar\n  Fusion with Detection Transformer","summary":"Robust object detection for Unmanned Surface Vehicles (USVs) in complex water\nenvironments is essential for reliable navigation and operation. Specifically,\nwater surface object detection faces challenges from blurred edges and diverse\nobject scales. Although vision-radar fusion offers a feasible solution,\nexisting approaches suffer from cross-modal feature conflicts, which negatively\naffect model robustness. To address this problem, we propose a robust\nvision-radar fusion model WS-DETR. In particular, we first introduce a\nMulti-Scale Edge Information Integration (MSEII) module to enhance edge\nperception and a Hierarchical Feature Aggregator (HiFA) to boost multi-scale\nobject detection in the encoder. Then, we adopt self-moving point\nrepresentations for continuous convolution and residual connection to\nefficiently extract irregular features under the scenarios of irregular point\ncloud data. To further mitigate cross-modal conflicts, an Adaptive Feature\nInteractive Fusion (AFIF) module is introduced to integrate visual and radar\nfeatures through geometric alignment and semantic fusion. Extensive experiments\non the WaterScenes dataset demonstrate that WS-DETR achieves state-of-the-art\n(SOTA) performance, maintaining its superiority even under adverse weather and\nlighting conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T04:16:46Z"}
{"aid":"http://arxiv.org/abs/2504.07478v1","title":"Intelligent DoS and DDoS Detection: A Hybrid GRU-NTM Approach to Network\n  Security","summary":"Detecting Denial of Service (DoS) and Distributed Denial of Service (DDoS)\nattacks remains a critical challenge in cybersecurity. This research introduces\na hybrid deep learning model combining Gated Recurrent Units (GRUs) and a\nNeural Turing Machine (NTM) for enhanced intrusion detection. Trained on the\nUNSW-NB15 and BoT-IoT datasets, the model employs GRU layers for sequential\ndata processing and an NTM for long-term pattern recognition. The proposed\napproach achieves 99% accuracy in distinguishing between normal, DoS, and DDoS\ntraffic. These findings offer promising advancements in real-time threat\ndetection and contribute to improved network security across various domains.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-10T06:08:04Z"}
{"aid":"http://arxiv.org/abs/2504.07480v1","title":"Echoes of Disagreement: Measuring Disparity in Social Consensus","summary":"Public discourse and opinions stem from multiple social groups. Each group\nhas beliefs about a topic (such as vaccination, abortion, gay marriage, etc.),\nand opinions are exchanged and blended to produce consensus. A particular\nmeasure of interest corresponds to measuring the influence of each group on the\nconsensus and the disparity between groups on the extent to which they\ninfluence the consensus. In this paper, we study and give provable algorithms\nfor optimizing the disparity under the DeGroot or the Friedkin-Johnsen models\nof opinion dynamics. Our findings provide simple poly-time algorithms to\noptimize disparity for most cases, fully characterize the instances that\noptimize disparity, and show how simple interventions such as contracting\nvertices or adding links affect disparity. Finally, we test our developed\nalgorithms in a variety of real-world datasets.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T06:18:27Z"}
{"aid":"http://arxiv.org/abs/2504.07493v1","title":"Quickest change detection for UAV-based sensing","summary":"This paper addresses the problem of quickest change detection (QCD) at two\nspatially separated locations monitored by a single unmanned aerial vehicle\n(UAV) equipped with a sensor. At any location, the UAV observes i.i.d. data\nsequentially in discrete time instants. The distribution of the observation\ndata changes at some unknown, arbitrary time and the UAV has to detect this\nchange in the shortest possible time. Change can occur at most at one location\nover the entire infinite time horizon. The UAV switches between these two\nlocations in order to quickly detect the change. To this end, we propose\nLocation Switching and Change Detection (LS-CD) algorithm which uses a repeated\none-sided sequential probability ratio test (SPRT) based mechanism for\nobservation-driven location switching and change detection. The primary goal is\nto minimize the worst-case average detection delay (WADD) while meeting\nconstraints on the average run length to false alarm (ARL2FA) and the UAV's\ntime-averaged energy consumption. We provide a rigorous theoretical analysis of\nthe algorithm's performance by using theory of random walk. Specifically, we\nderive tight upper and lower bounds to its ARL2FA and a tight upper bound to\nits WADD. In the special case of a symmetrical setting, our analysis leads to a\nnew asymptotic upper bound to the ARL2FA of the standard CUSUM algorithm, a\nnovel contribution not available in the literature, to our knowledge. Numerical\nsimulations demonstrate the efficacy of LS-CD.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-10T06:49:55Z"}
{"aid":"http://arxiv.org/abs/2504.07505v1","title":"$c$-Birkhoff polytopes","summary":"In a 2018 paper, Davis and Sagan studied several pattern-avoiding polytopes.\nThey found that a particular pattern-avoiding Birkhoff polytope had the same\nnormalized volume as the order polytope of a certain poset, leading them to ask\nif the two polytopes were unimodularly equivalent. Motivated by Davis and\nSagan's question, in this paper we define a pattern-avoiding Birkhoff polytope\ncalled a $c$-Birkhoff polytope for each Coxeter element $c$ of the symmetric\ngroup. We then show that the $c$-Birkhoff polytope is unimodularly equivalent\nto the order polytope of the heap poset of the $c$-sorting word of the longest\npermutation. When $c=s_1s_2\\dots s_{n}$, this result recovers an affirmative\nanswer to Davis and Sagan's question. Another consequence of this result is\nthat the normalized volume of the $c$-Birkhoff polytope is the number of the\nlongest chains in the (type A) $c$-Cambrian lattice.","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T07:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.07511v1","title":"The finite basis problem for additively idempotent semirings of order\n  four, III","summary":"We study the finite basis problem for $4$-element additively idempotent\nsemirings whose additive reducts have two minimal elements and one coatom. Up\nto isomorphism, there are $112$ such algebras. We show that $106$ of them are\nfinitely based and the remaining ones are nonfinitely based.","main_category":"math.GR","categories":"math.GR","published":"2025-04-10T07:14:04Z"}
{"aid":"http://arxiv.org/abs/2504.07550v1","title":"A search for periodic activity in multi-peaked long gamma-ray bursts","summary":"A sizeable fraction of gamma-ray burst (GRB) light curves (LCs) features a\nsequence of peaks, which holds information on the unknown way energy is\ndissipated into gamma-rays over time. Traditional searches for periodic signals\nin GRB LCs turned out to be inconclusive, partly because they are challenging\nas a consequence of the short-lived, coloured-noise, and non-stationary nature\nof the LCs themselves. Yet, recent claims have revived the issue. We searched\nfor periodic components in GRB LCs through a new approach to GRBs, which\nescapes most of the issues faced by traditional techniques. We identified peaks\nthrough a well tested algorithm and selected GRBs with at least 10 peaks out of\n5 GRB catalogues (Swift/BAT, CGRO/BATSE, Fermi/GBM, Insight-HXMT,\nBeppoSAX/GRBM). Each GRB was simply treated as a discrete point process, whose\nrealisation coincides with the sequence of peak times. We searched for possible\nperiodic recurrences based on the multinomial distribution, after accounting\nfor the clustering of peaks due to the non-stationarity of the GRB signals. The\nbest candidate has a p-value of 3e-4 that there is no periodic recurrence.\nHowever, accounting for the multiple trials of 555 searched GRBs, its\nstatistical significance is demoted to 17%. The overall distribution of the\np-values obtained for all GRBs is compatible with a uniform distribution in\n[0,1]. We found no robust evidence for multi-peaked GRBs with periodic\nrecurrences. We can exclude that a sizeable fraction (>~ 0.75) of peaks of each\nGRB with at least 10 peaks are periodic. While our result does not necessarily\nclash with claimed periodicities based on Fourier techniques, it constrains the\nputative recurrent behaviour, which would not manifest itself through the\nsequence of peaks, but, evidently, in a more elusive way.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-10T08:25:10Z"}
{"aid":"http://arxiv.org/abs/2504.07568v1","title":"Ground State Energy of Helium Using a Four-Qubit Photonic Processor with\n  the Variational Quantum Eigensolver (VQE)","summary":"To understand the properties and interactions of materials, and determining\nthe ground state energies is one of the important challenges in quantum\nchemistry, materials science, and quantum mechanics, where quantum computing\ncan play an important role for studying the properties of materials. In this\nstudy, we have explored the quantum processor application to compute the Helium\n(He) molecule ground state energy which utilizes the Variational Quantum\nEigensolver (VQE) algorithm. In here, we have implemented VQE on a\nstate-of-the-art quantum processor, optimizing a parameterized quantum circuit\nto minimize the energy expectation value of the He molecule's Hamiltonian on\nthe four qubits processor. The obtained results of this work show a significant\nimprovement in accuracy compared to classical computational methods, such as\nHartree-Fock and density functional theory, which demonstrate the compute\npotential of quantum algorithms in quantum many-body problems. Thus, these\nresults demonstrate the advantages of quantum computing in achieving high\naccuracy in simulations of molecular and material properties, and pave the way\nfor future applications in more complex systems. This work highlights the\npotential of quantum processors in the fields of quantum chemistry,\ncomputational physics, and data science.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-04-10T09:00:08Z"}
{"aid":"http://arxiv.org/abs/2504.07589v1","title":"Copy-and-Paste? Identifying EVM-Inequivalent Code Smells in Multi-chain\n  Reuse Contracts","summary":"As the development of Solidity contracts on Ethereum, more developers are\nreusing them on other compatible blockchains. However, developers may overlook\nthe differences between the designs of the blockchain system, such as the Gas\nMechanism and Consensus Protocol, leading to the same contracts on different\nblockchains not being able to achieve consistent execution as on Ethereum. This\ninconsistency reveals design flaws in reused contracts, exposing code smells\nthat hinder code reusability, and we define this inconsistency as\nEVM-Inequivalent Code Smells. In this paper, we conducted the first empirical\nstudy to reveal the causes and characteristics of EVM-Inequivalent Code Smells.\nTo ensure the identified smells reflect real developer concerns, we collected\nand analyzed 1,379 security audit reports and 326 Stack Overflow posts related\nto reused contracts on EVM-compatible blockchains, such as Binance Smart Chain\n(BSC) and Polygon. Using the open card sorting method, we defined six types of\nEVM-Inequivalent Code Smells. For automated detection, we developed a tool\nnamed EquivGuard. It employs static taint analysis to identify key paths from\ndifferent patterns and uses symbolic execution to verify path reachability. Our\nanalysis of 905,948 contracts across six major blockchains shows that\nEVM-Inequivalent Code Smells are widespread, with an average prevalence of\n17.70%. While contracts with code smells do not necessarily lead to financial\nloss and attacks, their high prevalence and significant asset management\nunderscore the potential threats of reusing these smelly Ethereum contracts.\nThus, developers are advised to abandon Copy-and-Paste programming practices\nand detect EVM-Inequivalent Code Smells before reusing Ethereum contracts.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T09:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.07608v1","title":"DUCA: Dynamic Universe Cosmological Analysis. I. The halo mass function\n  in dynamical dark energy cosmologies","summary":"The halo mass function (HMF) is fundamental for interpreting the number\ncounts of galaxy clusters, serving as a pivotal theoretical tool in cosmology.\nWith the advent of high-precision surveys such as LSST, eROSITA, DESI, and\nEuclid, accurate HMF modeling becomes indispensable to avoid systematic biases\nin cosmological parameter estimation from cluster cosmology. Moreover, these\nsurveys aim to shed light on the dark sector and uncover dark energy's puzzling\nnature, necessitating models that faithfully capture its features to ensure\nrobust parameter inference. We aim to construct a model for the HMF in\ndynamical dark energy cosmologies that preserves the accuracy achieved for the\nstandard $\\Lambda (\\nu)$CDM model of cosmology, while meeting the precision\nrequirements necessary for future cosmological surveys. Our approach models the\nHMF parameters as functions of the deceleration parameter at the turnaround, a\nquantity shown to encapsulate essential information regarding the impact of\ndynamical dark energy on structure formation. We calibrate the model using\nresults from a comprehensive suite of $N$-body simulations spanning various\ncosmological scenarios, ensuring sub-percent systematic accuracy. We present an\nHMF model tailored for dynamical dark energy cosmologies. The model is\ncalibrated following a Bayesian approach, and its uncertainty is characterized\nby a single parameter controlling its systematic error, which remains at the\nsub-percent level. This ensures that theoretical uncertainties from our model\nare subdominant relative to other error sources in future cluster number counts\nanalyses.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T09:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.07611v1","title":"Conditional Conformal Risk Adaptation","summary":"Uncertainty quantification is becoming increasingly important in image\nsegmentation, especially for high-stakes applications like medical imaging.\nWhile conformal risk control generalizes conformal prediction beyond standard\nmiscoverage to handle various loss functions such as false negative rate, its\napplication to segmentation often yields inadequate conditional risk control:\nsome images experience very high false negative rates while others have\nnegligibly small ones. We develop Conformal Risk Adaptation (CRA), which\nintroduces a new score function for creating adaptive prediction sets that\nsignificantly improve conditional risk control for segmentation tasks. We\nestablish a novel theoretical framework that demonstrates a fundamental\nconnection between conformal risk control and conformal prediction through a\nweighted quantile approach, applicable to any score function. To address the\nchallenge of poorly calibrated probabilities in segmentation models, we\nintroduce a specialized probability calibration framework that enhances the\nreliability of pixel-wise inclusion estimates. Using these calibrated\nprobabilities, we propose Calibrated Conformal Risk Adaptation (CCRA) and a\nstratified variant (CCRA-S) that partitions images based on their\ncharacteristics and applies group-specific thresholds to further enhance\nconditional risk control. Our experiments on polyp segmentation demonstrate\nthat all three methods (CRA, CCRA, and CCRA-S) provide valid marginal risk\ncontrol and deliver more consistent conditional risk control across diverse\nimages compared to standard approaches, offering a principled approach to\nuncertainty quantification that is particularly valuable for high-stakes and\npersonalized segmentation applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T10:01:06Z"}
{"aid":"http://arxiv.org/abs/2504.07630v1","title":"An intrinsic cosmological observer","summary":"There has been much recent interest in the necessity of an observer degree of\nfreedom in the description of local algebras in semiclassical gravity. In this\nwork, we describe an example where the observer can be constructed\nintrinsically from the quantum fields. This construction involves the slow-roll\ninflation example recently analyzed by Chen and Penington, in which the\ngauge-invariant gravitational algebra arises from marginalizing over modular\nflow in a de Sitter static patch. We relate this procedure to the\nConnes-Takesaki theory of the flow of weights for type III von Neumann\nalgebras, and further show that the resulting gravitational algebra can\nnaturally be presented as a crossed product. This leads to a decomposition of\nthe gravitational algebra into quantum field and observer degrees of freedom,\nwith different choices of observer being related to changes in a quantum\nreference frame for the algebra. We also connect this example to other\nconstructions of type II algebras in semiclassical gravity, and argue they all\nshare the feature of being the result of gauging modular flow. The arguments in\nthis work involve various properties of automorphism groups of hyperfinite\nfactors, and so in an appendix we review the structure of these groups, which\nmay be of independent interest for further investigations into von Neumann\nalgebras in quantum gravity.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-10T10:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.07631v1","title":"The super Alternative Daugavet property for Banach spaces","summary":"We introduce the super alternative Daugavet property (super ADP) which lies\nstrictly between the Daugavet property and the Alternative Daugavet property as\nfollows. A Banach space $X$ has the super ADP if for every element $x$ in the\nunit sphere and for every relatively weakly open subset $W$ of the unit ball\nintersecting the unit sphere, one can find an element $y\\in W$ and a modulus\none scalar $\\theta$ such that $\\|x+\\theta y\\|$ is almost two. It is known that\nspaces with the Daugavet property satisfy this condition, and that this\ncondition implies the Alternative Daugavet property. We first provide examples\nof super ADP spaces which fail the Daugavet property. We show that the norm of\na super ADP space is rough, hence the space cannot be Asplund, and we also\nprove that the space fails the point of continuity property (particularly, the\nRadon--Nikod\\'ym property). In particular, we get examples of spaces with the\nAlternative Daugavet property that fail the super ADP. For a better\nunderstanding of the differences between the super ADP, the Daugavet property,\nand the Alternative Daugavet property, we will also consider the localizations\nof these three properties and prove that they behave rather differently. As a\nconsequence, we provide characterizations of the super ADP for spaces of\nvector-valued continuous functions and of vector-valued integrable functions.","main_category":"math.FA","categories":"math.FA","published":"2025-04-10T10:25:23Z"}
{"aid":"http://arxiv.org/abs/2504.07651v1","title":"Nonperturbative quantum theory of multiplasmonic electron emission from\n  surfaces: Gauge-specific cumulant expansions vs. Volkov ansatz over plasmonic\n  coherent states","summary":"Energetic electromagnetic fields produce a variety of elementary excitations\nin solids that can strongly modify their primary photoemission spectra. Such is\nthe plasmon excitation or pumping mechanism which, although indirect, is very\nefficient and hence may give rise to formation of plasmonic coherent states. In\nturn, these states may act as a source or sink of energy and momentum for\nescaping electrons. Starting from the model Hamiltonian approach we show that\nprepumped plasmonic bath of coherent states gives rise to ponderomotive\npotentials and Floquet electronic band structure that support multiple\nplasmon-induced electron emission or plasmoemission from metals. Theoretical\ndescription of multiple plasmoemission requires a nonperturbative approch which\nis here formulated by applying cumulant expansion and Volkov ansatz to the\ncalculations of electron wavefunctions and emission rates. The calculations are\nperformed in the standard length gauge as well as in the Pauli-transformed\nvelocity gauge for electron-plasmon interaction. The applicability of two\nnonperturbative approaches to calculation of excitation amplitudes are examined\nin each gauge. They smoothly interpolate between the fully quantal first order\nBorn approximation and semiclassical multiplasmon-induced electron excitation\nlimit. This is illustrated on the example of plasmoemission from Floquet\nsurface bands on Ag(111) from which this channel of electron yield has been\ndetected. Our calculations indicate that even subsingle mode occupations of\nplasmonic coherent states can support multiplasmon electron emission from\nsurface bands. A way of calibration of plasmonic coherent states is proposed.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-10T10:58:28Z"}
{"aid":"http://arxiv.org/abs/2504.07662v1","title":"On the monomorphism category of large modules","summary":"Let $R$ be an associative ring with identity. This paper investigates the\nstructure of the monomorphism category of large $R$-modules and establishes\nconnections with the category of contravariant functors defined on finitely\npresented $R$-modules. Several equivalences and dualities will be presented.\nOur results highlight the role of pure-injective modules in studying the\nhomological properties of functor categories.","main_category":"math.RT","categories":"math.RT","published":"2025-04-10T11:20:44Z"}
{"aid":"http://arxiv.org/abs/2504.07708v1","title":"TOCALib: Optimal control library with interpolation for bimanual\n  manipulation and obstacles avoidance","summary":"The paper presents a new approach for constructing a library of optimal\ntrajectories for two robotic manipulators, Two-Arm Optimal Control and\nAvoidance Library (TOCALib). The optimisation takes into account kinodynamic\nand other constraints within the FROST framework. The novelty of the method\nlies in the consideration of collisions using the DCOL method, which allows\nobtaining symbolic expressions for assessing the presence of collisions and\nusing them in gradient-based optimization control methods. The proposed\napproach allowed the implementation of complex bimanual manipulations. In this\npaper we used Mobile Aloha as an example of TOCALib application. The approach\ncan be extended to other bimanual robots, as well as to gait control of bipedal\nrobots. It can also be used to construct training data for machine learning\ntasks for manipulation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T12:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.07761v1","title":"Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection","summary":"In an increasingly digitalized world, verifying the authenticity of ID\ndocuments has become a critical challenge for real-life applications such as\ndigital banking, crypto-exchanges, renting, etc. This study focuses on the\ntopic of fake ID detection, covering several limitations in the field. In\nparticular, no publicly available data from real ID documents exists, and most\nstudies rely on proprietary in-house databases that are not available due to\nprivacy reasons. In order to shed some light on this critical challenge that\nmakes difficult to advance in the field, we explore a trade-off between privacy\n(i.e., amount of sensitive data available) and performance, proposing a novel\npatch-wise approach for privacy-preserving fake ID detection. Our proposed\napproach explores how privacy can be enhanced through: i) two levels of\nanonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii)\ndifferent patch size configurations, varying the amount of sensitive data\nvisible in the patch image. Also, state-of-the-art methods such as Vision\nTransformers and Foundation Models are considered in the analysis. The\nexperimental framework shows that, on an unseen database (DLC-2021), our\nproposal achieves 13.91% and 0% EERs at patch and ID document level, showing a\ngood generalization to other databases. In addition to this exploration,\nanother key contribution of our study is the release of the first publicly\navailable database that contains 48,400 patches from both real and fake ID\ndocuments, along with the experimental framework and models, which will be\navailable in our GitHub.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-10T14:01:22Z"}
{"aid":"http://arxiv.org/abs/2504.07804v1","title":"Function-Correcting Codes for $ρ$-locally $λ$-functions","summary":"In this paper, we explore $\\rho$-locally $\\lambda$-functions and develop\nfunction-correcting codes for these functions. We propose an upper bound on the\nredundancy of these codes, based on the minimum possible length of an\nerror-correcting code with a given number of codewords and minimum distance.\nAdditionally, we provide a sufficient optimality condition for the\nfunction-correcting codes when $\\lambda = 4$. We also demonstrate that any\nfunction can be represented as a $\\rho$-locally $\\lambda$-function,\nillustrating this with a representation of Hamming weight distribution\nfunctions. Furthermore, we present another construction of function-correcting\ncodes for Hamming weight distribution functions.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T14:41:51Z"}
{"aid":"http://arxiv.org/abs/2504.07813v1","title":"P2Object: Single Point Supervised Object Detection and Instance\n  Segmentation","summary":"Object recognition using single-point supervision has attracted increasing\nattention recently. However, the performance gap compared with fully-supervised\nalgorithms remains large. Previous works generated class-agnostic\n\\textbf{\\textit{proposals in an image}} offline and then treated mixed\ncandidates as a single bag, putting a huge burden on multiple instance learning\n(MIL). In this paper, we introduce Point-to-Box Network (P2BNet), which\nconstructs balanced \\textbf{\\textit{instance-level proposal bags}} by\ngenerating proposals in an anchor-like way and refining the proposals in a\ncoarse-to-fine paradigm. Through further research, we find that the bag of\nproposals, either at the image level or the instance level, is established on\ndiscrete box sampling. This leads the pseudo box estimation into a sub-optimal\nsolution, resulting in the truncation of object boundaries or the excessive\ninclusion of background. Hence, we conduct a series exploration of\ndiscrete-to-continuous optimization, yielding P2BNet++ and Point-to-Mask\nNetwork (P2MNet). P2BNet++ conducts an approximately continuous proposal\nsampling strategy by better utilizing spatial clues. P2MNet further introduces\nlow-level image information to assist in pixel prediction, and a boundary\nself-prediction is designed to relieve the limitation of the estimated boxes.\nBenefiting from the continuous object-aware \\textbf{\\textit{pixel-level\nperception}}, P2MNet can generate more precise bounding boxes and generalize to\nsegmentation tasks. Our method largely surpasses the previous methods in terms\nof the mean average precision on COCO, VOC, SBD, and Cityscapes, demonstrating\ngreat potential to bridge the performance gap compared with fully supervised\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T14:51:08Z"}
{"aid":"http://arxiv.org/abs/2504.07814v1","title":"Estimating entanglement monotones of non-pure spin-squeezed states","summary":"We investigate how to estimate entanglement monotones of general mixed\nmany-body quantum states via lower and upper bounds from entanglement witnesses\nand separable ansatz states respectively. This allows us to study spin systems\non fully-connected graphs at nonzero temperature. We derive lower bounds to\ndistance-like measure from the set of fully separable states based on\nspin-squeezing inequalities. These are nonlinear expressions based on variances\nof collective spin operators and are potentially close to optimal in the large\nparticle-number limit, at least for models with two-particle interactions.\nConcretely, we apply our methods to equilibrium states of the\npermutation-invariant XXZ model with an external field and investigate\nentanglement at nonzero temperature close to quantum phase transition (QPT)\npoints in both the ferromagnetic and anti-ferromagnetic cases. We observe that\nthe lower bound becomes tight for zero temperature as well as for the\ntemperature at which entanglement disappears, both of which are thus precisely\ncaptured by the spin-squeezing inequalities. We further observe, among other\nthings, that entanglement arises at nonzero temperature close to a QPT even in\nthe ordered phase, where the ground state is separable. This can be considered\nan entanglement signature of a QPT that may also be visible in experiments.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T14:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.07852v1","title":"The signless Laplacian spectral Turán problems for color-critical\n  graphs","summary":"The well-known Tur\\'{a}n theorem states that if $G$ is an $n$-vertex\n$K_{r+1}$-free graph, then $e(G)\\le e(T_{n,r})$, with equality if and only if\n$G$ is the $r$-partite Tur\\'{a}n graph $T_{n,r}$. A graph $F$ is called\ncolor-critical if it contains an edge whose deletion reduces its chromatic\nnumber. Extending the Tur\\'{a}n theorem, Simonovits (1968) proved that for any\ncolor-critical graph $F$ with $\\chi (F)=r+1$ and sufficiently large $n$, the\nTur\\'{a}n graph $T_{n,r}$ is the unique graph with maximum number of edges\namong all $n$-vertex $F$-free graphs. Subsequently, Nikiforov [Electron. J.\nCombin., 16 (1) (2009)] proved a spectral version of the Simonovits theorem in\nterms of the adjacency spectral radius. In this paper, we show an extension of\nthe Simonovits theorem for the signless Laplacian spectral radius. We prove\nthat for any color-critical graph $F$ with $\\chi (F)=r+1\\ge 4$ and sufficiently\nlarge $n$, if $G$ is an $F$-free graph on $n$ vertices, then $q(G)\\le\nq(T_{n,r})$, with equality if and only if $G=T_{n,r}$. Our approach is to\nestablish a signless Laplacian spectral version of the criterion of Keevash,\nLenz and Mubayi [SIAM J. Discrete Math., 28 (4) (2014)]. Consequently, we can\ndetermine the signless Laplacian spectral extremal graphs for generalized books\nand even wheels. As an application, our result gives an upper bound on the\ndegree power of an $F$-free graph. We show that if $n$ is sufficiently large\nand $G$ is an $F$-free graph on $n$ vertices with $m$ edges, then $\\sum_{v\\in\nV(G)} d^2(v) \\le 2(1- \\frac{1}{r})mn$, with equality if and only if $G$ is a\nregular Tur\\'{a}n graph $T_{n,r}$. This extends a result of Nikiforov and\nRousseau [J. Combin. Theory Ser B 92 (2004)].","main_category":"math.CO","categories":"math.CO","published":"2025-04-10T15:28:40Z"}
{"aid":"http://arxiv.org/abs/2504.07856v1","title":"2D-Curri-DPO: Two-Dimensional Curriculum Learning for Direct Preference\n  Optimization","summary":"Aligning large language models with human preferences is crucial for their\nsafe deployment. While Direct Preference Optimization (DPO) offers an efficient\nalternative to reinforcement learning from human feedback, traditional DPO\nmethods are limited by their reliance on single preference pairs. Recent work\nlike Curriculum-DPO integrates multiple pairs using a one-dimensional\ndifficulty curriculum based on pairwise distinguishability (PD), but overlooks\nthe complexity of the input prompt itself. To address this, we propose\n2D-Curri-DPO, a novel framework employing a two-dimensional curriculum that\njointly models Prompt Complexity (PC) and Pairwise Distinguishability. This\nframework introduces dual difficulty metrics to quantify prompt semantic\ncomplexity and response preference clarity, defines a curriculum strategy space\nencompassing multiple selectable strategies for task adaptation, and\nincorporates a KL-divergence-based adaptive mechanism for dynamic reference\nmodel updates to enhance training stability. Comprehensive experiments\ndemonstrate that 2D-Curri-DPO significantly outperforms standard DPO and prior\ncurriculum methods across multiple benchmarks, including MT-Bench, Vicuna\nBench, and WizardLM. Our approach achieves state-of-the-art performance on\nchallenging test sets like UltraFeedback. Ablation studies confirm the benefits\nof the 2D structure and adaptive mechanisms, while analysis provides guidance\nfor strategy selection. These findings demonstrate that effective alignment\nrequires modeling both prompt complexity and pairwise distinguishability,\nestablishing adaptive, multi-dimensional curriculum learning as a powerful and\ninterpretable new paradigm for preference-based language model optimization.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T15:32:00Z"}
{"aid":"http://arxiv.org/abs/2504.07861v1","title":"Horizons, throats and bounces in hybrid metric-Palatini gravity with a\n  non-zero potential","summary":"This work conducts an in-depth exploration of exact electrically charged\nsolutions, including traversable wormholes, black holes, and black bounces,\nwithin the framework of the scalar-tensor representation of hybrid\nmetric-Palatini gravity (HMPG) with a non-zero scalar potential. By integrating\nprinciples from both the metric and Palatini formulations, HMPG provides a\nflexible approach to addressing persistent challenges in General Relativity\n(GR), such as the late-time cosmic acceleration and the nature of dark matter.\nUnder the assumption of spherical symmetry, we employ an inverse problem\ntechnique to derive exact solutions in both the Jordan and Einstein conformal\nframes. This method naturally leads to configurations involving either\ncanonical or phantom scalar fields. A thorough examination of horizon\nstructures, throat conditions, asymptotic behaviour, and curvature regularity\n(via the Kretschmann scalar) reveals the intricate causal structures permitted\nby this theoretical model. The analysis uncovers a diverse range of geometric\nconfigurations, with the phantom sector exhibiting a notably richer spectrum of\nsolutions than the canonical case. These solutions encompass traversable\nwormholes, black universe models, where the interior of a black hole evolves\ninto an expanding cosmological phase rather than a singularity, as well as\nblack bounce structures and multi-horizon black holes. The results demonstrate\nthat introducing a non-zero scalar potential within HMPG significantly expands\nthe array of possible gravitational solutions, yielding complex causal and\ncurvature properties that go beyond standard GR. Consequently, HMPG stands out\nas a powerful theoretical framework for modelling extreme astrophysical\nenvironments, where deviations from classical gravity are expected to play a\ncrucial role.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th","published":"2025-04-10T15:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.07895v1","title":"Magnetic Fields of Satellite Galaxies Stronger Than Comparable Centrals\n  in TNG100","summary":"Magnetic fields exist in and around galaxies, but the properties of these\nfields have not been fully explored due to the challenges inherent in observing\nand modeling them. In this Note, we explore the differences in magnetic field\nstrength of central and satellite galaxies from the magnetohydrodynamic TNG100\nsimulation. We find that on average, magnetic fields in satellite galaxies are\nroughly an order of magnitude stronger than those of central galaxies with\ncomparable masses. The difference is greater for satellites that have already\napproached within $1 R_{200}$ of their host galaxies. These results indicate\nthat magnetic fields in satellite galaxies are amplified by environmental\nprocesses as they fall into a host halo.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-10T16:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.07897v1","title":"The Constituent Quark Model","summary":"In this chapter we give a pedagogical introduction to the constituent quark\nmodel. The explanation of magnetic moments of the nucleons was crucial to\nintroduce an effective quark mass for light quarks that nowadays are understood\nas an effect of Spontaneous Chiral Symmetry Breaking in QCD. We give an\noverview of the first applications of the model and an introduction to the most\nmodern developments studying states beyond the naive quark model as tetraquarks\nand pentaquarks.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-10T16:14:37Z"}
{"aid":"http://arxiv.org/abs/2504.07900v1","title":"Temporal Tensors and Quantum Shortcut Dynamics in a Supermaze of\n  Multidimensional Time","summary":"We develop a theoretical framework that unifies concepts of multiple time\ndimensions, quantum shortcut dynamics, and complex topological structures\n('supermazes') to explore novel phenomena in quantum and classical systems. In\nparticular, we introduce a Temporal Tensor Formalism to describe\nmultidimensional time, define Quantum Shortcut Operators that enact\nnear-instantaneous state transitions, and incorporate these into a supermaze\ntopological model inspired by labyrinthine geometry and network complexity. We\nshow how this framework can give rise to surprising effects such as anomalous\nthermodynamic relaxation (analogous to the Mpemba effect) in quantum systems.\nTheoretical implications for quantum computing (including quantum cloud\nnetworks) are discussed, and connections are drawn to established mathematical\nparadoxes and physical principles.","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-10T16:19:56Z"}
{"aid":"http://arxiv.org/abs/2504.07945v1","title":"GenEAva: Generating Cartoon Avatars with Fine-Grained Facial Expressions\n  from Realistic Diffusion-based Faces","summary":"Cartoon avatars have been widely used in various applications, including\nsocial media, online tutoring, and gaming. However, existing cartoon avatar\ndatasets and generation methods struggle to present highly expressive avatars\nwith fine-grained facial expressions and are often inspired from real-world\nidentities, raising privacy concerns. To address these challenges, we propose a\nnovel framework, GenEAva, for generating high-quality cartoon avatars with\nfine-grained facial expressions. Our approach fine-tunes a state-of-the-art\ntext-to-image diffusion model to synthesize highly detailed and expressive\nfacial expressions. We then incorporate a stylization model that transforms\nthese realistic faces into cartoon avatars while preserving both identity and\nexpression. Leveraging this framework, we introduce the first expressive\ncartoon avatar dataset, GenEAva 1.0, specifically designed to capture 135\nfine-grained facial expressions, featuring 13,230 expressive cartoon avatars\nwith a balanced distribution across genders, racial groups, and age ranges. We\ndemonstrate that our fine-tuned model generates more expressive faces than the\nstate-of-the-art text-to-image diffusion model SDXL. We also verify that the\ncartoon avatars generated by our framework do not include memorized identities\nfrom fine-tuning data. The proposed framework and dataset provide a diverse and\nexpressive benchmark for future research in cartoon avatar generation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-10T17:54:02Z"}
{"aid":"http://arxiv.org/abs/2504.07947v1","title":"Activating high-power parametric oscillation in photonic-crystal\n  resonators","summary":"By engineering the mode spectrum of a Kerr microresonator, we selectively\nactivate nonlinear phase matching amongst broadband parametric gain. At\nthreshold, optical parametric oscillators (OPOs) emerge from vacuum\nfluctuations in the presence of a pump laser, and above threshold, OPOs seed\nthe formation of intraresonator patterns and states, such as chaos and\nsolitons. These competing nonlinear processes hinder an important application\nof OPOs as wavelength-variable, low-noise sources. Recently, nanopatterned\nmicroresonator OPOs have leveraged photonic crystal bandgaps to enable\nuniversal phase matching and control of nonlinear interactions. Here, we\nexplore a design paradigm optimized for high-output power that uses geometric\ndispersion to suppress nonlinear interactions and a photonic crystal bandgap to\nactivate only a single OPO interaction. Our devices convert an input pump laser\nto output signal and idler waves with powers exceeding 40 mW while maintaining\nspectral purity and side-mode suppression ratios greater than 40 dB. We show\nthat this approach suits custom wavelengths by measuring four independent\noscillators that vary only photonic crystal parameters to select output waves.\nOur experiments demonstrate that microresonators functionalized by photonic\ncrystals offer a versatile and lossless palette of controls for nonlinear laser\nconversion.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T17:54:33Z"}
{"aid":"http://arxiv.org/abs/2504.07954v1","title":"Perception-R1: Pioneering Perception Policy with Reinforcement Learning","summary":"Inspired by the success of DeepSeek-R1, we explore the potential of\nrule-based reinforcement learning (RL) in MLLM post-training for perception\npolicy learning. While promising, our initial experiments reveal that\nincorporating a thinking process through RL does not consistently lead to\nperformance gains across all visual perception tasks. This leads us to delve\ninto the essential role of RL in the context of visual perception. In this\nwork, we return to the fundamentals and explore the effects of RL on different\nperception tasks. We observe that the perceptual complexity is a major factor\nin determining the effectiveness of RL. We also observe that reward design\nplays a crucial role in further approching the upper limit of model perception.\nTo leverage these findings, we propose Perception-R1, a scalable RL framework\nusing GRPO during MLLM post-training. With a standard Qwen2.5-VL-3B-Instruct,\nPerception-R1 achieves +4.2% on RefCOCO+, +17.9% on PixMo-Count, +4.2% on\nPageOCR, and notably, 31.9% AP on COCO2017 val for the first time, establishing\na strong baseline for perception policy learning.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-10T17:58:27Z"}
{"aid":"http://arxiv.org/abs/2504.07957v1","title":"MM-IFEngine: Towards Multimodal Instruction Following","summary":"The Instruction Following (IF) ability measures how well Multi-modal Large\nLanguage Models (MLLMs) understand exactly what users are telling them and\nwhether they are doing it right. Existing multimodal instruction following\ntraining data is scarce, the benchmarks are simple with atomic instructions,\nand the evaluation strategies are imprecise for tasks demanding exact output\nconstraints. To address this, we present MM-IFEngine, an effective pipeline to\ngenerate high-quality image-instruction pairs. Our MM-IFEngine pipeline yields\nlarge-scale, diverse, and high-quality training data MM-IFInstruct-23k, which\nis suitable for Supervised Fine-Tuning (SFT) and extended as MM-IFDPO-23k for\nDirect Preference Optimization (DPO). We further introduce MM-IFEval, a\nchallenging and diverse multi-modal instruction-following benchmark that\nincludes (1) both compose-level constraints for output responses and\nperception-level constraints tied to the input images, and (2) a comprehensive\nevaluation pipeline incorporating both rule-based assessment and judge model.\nWe conduct SFT and DPO experiments and demonstrate that fine-tuning MLLMs on\nMM-IFInstruct-23k and MM-IFDPO-23k achieves notable gains on various IF\nbenchmarks, such as MM-IFEval (+10.2$\\%$), MIA (+7.6$\\%$), and IFEval\n(+12.3$\\%$). The full data and evaluation code will be released on\nhttps://github.com/SYuan03/MM-IFEngine.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:12Z"}
{"aid":"http://arxiv.org/abs/2504.09940v1","title":"TianQuan-Climate: A Subseasonal-to-Seasonal Global Weather Model via\n  Incorporate Climatology State","summary":"Subseasonal forecasting serves as an important support for Sustainable\nDevelopment Goals (SDGs), such as climate challenges, agricultural yield and\nsustainable energy production. However, subseasonal forecasting is a complex\ntask in meteorology due to dissipating initial conditions and delayed external\nforces. Although AI models are increasingly pushing the boundaries of this\nforecasting limit, they face two major challenges: error accumulation and\nSmoothness. To address these two challenges, we propose Climate Furnace\nSubseasonal-to-Seasonal (TianQuan-Climate), a novel machine learning model\ndesigned to provide global daily mean forecasts up to 45 days, covering five\nupper-air atmospheric variables at 13 pressure levels and two surface\nvariables. Our proposed TianQuan-Climate has two advantages: 1) it utilizes a\nmulti-model prediction strategy to reduce system error impacts in long-term\nsubseasonal forecasts; 2) it incorporates a Content Fusion Module for\nclimatological integration and extends ViT with uncertainty blocks (UD-ViT) to\nimprove generalization by learning from uncertainty. We demonstrate the\neffectiveness of TianQuan-Climate on benchmarks for weather forecasting and\nclimate projections within the 15 to 45-day range, where TianQuan-Climate\noutperforms existing numerical and AI methods.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T07:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.09961v1","title":"Privacy Meets Explainability: Managing Confidential Data and\n  Transparency Policies in LLM-Empowered Science","summary":"As Large Language Models (LLMs) become integral to scientific workflows,\nconcerns over the confidentiality and ethical handling of confidential data\nhave emerged. This paper explores data exposure risks through LLM-powered\nscientific tools, which can inadvertently leak confidential information,\nincluding intellectual property and proprietary data, from scientists'\nperspectives. We propose \"DataShield\", a framework designed to detect\nconfidential data leaks, summarize privacy policies, and visualize data flow,\nensuring alignment with organizational policies and procedures. Our approach\naims to inform scientists about data handling practices, enabling them to make\ninformed decisions and protect sensitive information. Ongoing user studies with\nscientists are underway to evaluate the framework's usability, trustworthiness,\nand effectiveness in tackling real-world privacy challenges.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-14T07:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.09969v1","title":"Semi-implicit-explicit Runge-Kutta method for nonlinear differential\n  equations","summary":"A semi-implicit-explicit (semi-IMEX) Runge-Kutta (RK) method is proposed for\nthe numerical integration of ordinary differential equations (ODEs) of the form\n$\\mathbf{u}' = \\mathbf{f}(t,\\mathbf{u}) + G(t,\\mathbf{u}) \\mathbf{u}$, where\n$\\mathbf{f}$ is a non-stiff term and $G\\mathbf{u}$ represents the stiff terms.\nSuch systems frequently arise from spatial discretizations of time-dependent\nnonlinear partial differential equations (PDEs). For instance, $G$ could\ninvolve higher-order derivative terms with nonlinear coefficients. Traditional\nIMEX-RK methods, which treat $\\mathbf{f}$ explicitly and $G\\mathbf{u}$\nimplicitly, require solving nonlinear systems at each time step when $G$\ndepends on $\\mathbf{u}$, leading to increased computational cost and\ncomplexity. In contrast, the proposed semi-IMEX scheme treats $G$ explicitly\nwhile keeping $\\mathbf{u}$ implicit, reducing the problem to solving only\nlinear systems. This approach eliminates the need to compute Jacobians while\npreserving the stability advantages of implicit methods. A family of semi-IMEX\nRK schemes with varying orders of accuracy is introduced. Numerical simulations\nfor various nonlinear equations, including nonlinear diffusion models, the\nNavier-Stokes equations, and the Cahn-Hilliard equation, confirm the expected\nconvergence rates and demonstrate that the proposed method allows for larger\ntime step sizes without triggering stability issues.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T08:18:57Z"}
{"aid":"http://arxiv.org/abs/2504.09973v1","title":"Beyond Degradation Redundancy: Contrastive Prompt Learning for\n  All-in-One Image Restoration","summary":"All-in-one image restoration, addressing diverse degradation types with a\nunified model, presents significant challenges in designing task-specific\nprompts that effectively guide restoration across multiple degradation\nscenarios. While adaptive prompt learning enables end-to-end optimization, it\noften yields overlapping or redundant task representations. Conversely,\nexplicit prompts derived from pretrained classifiers enhance discriminability\nbut may discard critical visual information for reconstruction. To address\nthese limitations, we introduce Contrastive Prompt Learning (CPL), a novel\nframework that fundamentally enhances prompt-task alignment through two\ncomplementary innovations: a \\emph{Sparse Prompt Module (SPM)} that efficiently\ncaptures degradation-specific features while minimizing redundancy, and a\n\\emph{Contrastive Prompt Regularization (CPR)} that explicitly strengthens task\nboundaries by incorporating negative prompt samples across different\ndegradation types. Unlike previous approaches that focus primarily on\ndegradation classification, CPL optimizes the critical interaction between\nprompts and the restoration model itself. Extensive experiments across five\ncomprehensive benchmarks demonstrate that CPL consistently enhances\nstate-of-the-art all-in-one restoration models, achieving significant\nimprovements in both standard multi-task scenarios and challenging composite\ndegradation settings. Our framework establishes new state-of-the-art\nperformance while maintaining parameter efficiency, offering a principled\nsolution for unified image restoration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.09991v1","title":"Bipartite Matching is in Catalytic Logspace","summary":"Matching is a central problem in theoretical computer science, with a large\nbody of work spanning the last five decades. However, understanding matching in\nthe time-space bounded setting remains a longstanding open question, even in\nthe presence of additional resources such as randomness or non-determinism.\n  In this work we study space-bounded machines with access to catalytic space,\nwhich is additional working memory that is full with arbitrary data that must\nbe preserved at the end of its computation. Despite this heavy restriction,\nmany recent works have shown the power of catalytic space, its utility in\ndesigning classical space-bounded algorithms, and surprising connections\nbetween catalytic computation and derandomization.\n  Our main result is that bipartite maximum matching ($MATCH$) can be computed\nin catalytic logspace ($CL$) with a polynomial time bound ($CLP$). Moreover, we\nshow that $MATCH$ can be reduced to the lossy coding problem for $NC$ circuits\n($LOSSY[NC]$). This has consequences for matching, catalytic space, and\nderandomization:\n  - Matching: this is the first well studied subclass of $P$ which is known to\ncompute $MATCH$, as well as the first algorithm simultaneously using sublinear\nfree space and polynomial time with any additional resources.\n  - Catalytic space: this is the first new problem shown to be in $CL$ since\nthe model was defined, and one which is extremely central and well-studied.\n  - Derandomization: we give the first class $\\mathcal{C}$ beyond $L$ for which\nwe exhibit a natural problem in $LOSSY[\\mathcal{C}]$ which is not known to be\nin $\\mathcal{C}$, as well as a full derandomization of the isolation lemma in\n$CL$ in the context of $MATCH$.\n  Our proof combines a number of strengthened ideas from isolation-based\nalgorithms for matching alongside the compress-or-random framework in catalytic\ncomputation.","main_category":"cs.CC","categories":"cs.CC,cs.DS","published":"2025-04-14T08:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.09995v1","title":"COUNTER: Cluster GCN based Energy Efficient Resource Management for\n  Sustainable Cloud Computing Environments","summary":"Cloud computing, thanks to the pervasiveness of information technologies,\nprovides a foundational environment for developing IT applications, offering\norganizations virtually unlimited and flexible computing resources on a\npay-per-use basis. However, the large data centres where cloud computing\nservices are hosted consume significant amounts of electricity annually due to\nInformation and Communication Technology (ICT) components. This issue is\nexacerbated by the increasing deployment of large artificial intelligence (AI)\nmodels, which often rely on distributed data centres, thereby significantly\nimpacting the global environment. This study proposes the COUNTER model,\ndesigned for sustainable cloud resource management. COUNTER is integrated with\ncluster graph neural networks and evaluated in a simulated cloud environment,\naiming to reduce energy consumption while maintaining quality of service\nparameters. Experimental results demonstrate improvements in resource\nutilisation, energy consumption, and cost effectiveness compared to the\nbaseline model, HUNTER, which employs a gated graph neural network aimed at\nachieving carbon neutrality in cloud computing for modern ICT systems.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:58:34Z"}
{"aid":"http://arxiv.org/abs/2504.09999v1","title":"Multipartite entanglement based on realignment moments","summary":"Based on the realignment moments of density matrix, we study parameterized\nentanglement criteria for bipartite and multipartite states. By adjusting the\ndifferent parameter values, our criterion can detect not only bound entangled\nstates, but also non-positive partial transpose entangled states for bipartite\nquantum systems. Moreover, we propose the definition of multipartite\nrealignment moments and generalize the result of bipartite systems to obtain a\nsufficient criterion to detect entanglement for multipartite quantum states in\narbitrary dimensions. And we further improve the conclusion to obtain another\nnew entanglement criterion. The new method can detect more entangled states\nthan previous methods as backed by detailed examples.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T09:02:58Z"}
{"aid":"http://arxiv.org/abs/2504.10040v1","title":"The Security of Quantum Computing in 6G: from Technical Perspectives to\n  Ethical Implications","summary":"Quantum technologies hold promise as essential components for the upcoming\ndeployment of the future 6G network. In this future network, the security and\ntrustworthiness requirements are not considered fulfilled with the current\nstate of the quantum computers, as the malicious behaviour on the part of the\nservice provider towards the user may still be present. Therefore, this article\nprovides an initial interdisciplinary work of regulations and solutions in the\nscope of trustworthy quantum computing for future 6G that can be viewed as\ncomplimentary regulations to the existing strategies shared by different actors\nof states and organizations. More precisely, we describe the importance of a\nreliable quantum service provider and its implication on the ethical aspects\nconcerning digital sovereignty. By exploring the critical relationship between\ntrustworthiness and digital sovereignty in the context of future 6G networks,\nwe analyse a trade-off between accessibility to this new technology and\npreservation of digital sovereignty engaging in parallel the United Nation's\n(UN's) sustainable development goals. Furthermore, we propose a partnership\nmodel based on cooperation, coordination, and collaboration giving rise to a\ntrusted, ethical, and inclusive quantum ecosystem, whose implications can spill\nover to the entire global scenario.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T09:42:16Z"}
{"aid":"http://arxiv.org/abs/2504.10041v1","title":"Prior Does Matter: Visual Navigation via Denoising Diffusion Bridge\n  Models","summary":"Recent advancements in diffusion-based imitation learning, which show\nimpressive performance in modeling multimodal distributions and training\nstability, have led to substantial progress in various robot learning tasks. In\nvisual navigation, previous diffusion-based policies typically generate action\nsequences by initiating from denoising Gaussian noise. However, the target\naction distribution often diverges significantly from Gaussian noise, leading\nto redundant denoising steps and increased learning complexity. Additionally,\nthe sparsity of effective action distributions makes it challenging for the\npolicy to generate accurate actions without guidance. To address these issues,\nwe propose a novel, unified visual navigation framework leveraging the\ndenoising diffusion bridge models named NaviBridger. This approach enables\naction generation by initiating from any informative prior actions, enhancing\nguidance and efficiency in the denoising process. We explore how diffusion\nbridges can enhance imitation learning in visual navigation tasks and further\nexamine three source policies for generating prior actions. Extensive\nexperiments in both simulated and real-world indoor and outdoor scenarios\ndemonstrate that NaviBridger accelerates policy inference and outperforms the\nbaselines in generating target action sequences. Code is available at\nhttps://github.com/hren20/NaiviBridger.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-14T09:42:35Z"}
{"aid":"http://arxiv.org/abs/2504.10053v1","title":"Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired\n  Olfactory Perception System","summary":"In this study, we explore how the combination of synthetic biology,\nneuroscience modeling, and neuromorphic electronic systems offers a new\napproach to creating an artificial system that mimics the natural sense of\nsmell. We argue that a co-design approach offers significant advantages in\nreplicating the complex dynamics of odor sensing and processing. We investigate\na hybrid system of synthetic sensory neurons that provides three key features:\na) receptor-gated ion channels, b) interface between synthetic biology and\nsemiconductors and c) event-based encoding and computing based on spiking\nnetworks. This research seeks to develop a platform for ultra-sensitive,\nspecific, and energy-efficient odor detection, with potential implications for\nenvironmental monitoring, medical diagnostics, and security.","main_category":"cs.NE","categories":"cs.NE,cs.ET,q-bio.NC","published":"2025-04-14T09:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.10059v1","title":"Central limit theorem for $ε$-independent products and\n  higher-order tensors","summary":"We establish a central limit theorem (CLT) for families of products of\n$\\epsilon$-independent random variables. We utilize graphon limits to encode\nthe evolution of independence and characterize the limiting distribution. Our\nframework subsumes a wide class of dependency structures and includes, as a\nspecial case, a CLT for higher-order tensor products of free random variables.\nOur results extend earlier findings and recover as a special case a recent\ntensor-free CLT, which was obtained through the development of a tensor\nanalogue of free probability. In contrast, our approach is more direct and\nprovides a unified and concise derivation of a more general CLT via graphon\nconvergence.","main_category":"math.PR","categories":"math.PR","published":"2025-04-14T10:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.10065v1","title":"A Computational Cognitive Model for Processing Repetitions of\n  Hierarchical Relations","summary":"Patterns are fundamental to human cognition, enabling the recognition of\nstructure and regularity across diverse domains. In this work, we focus on\nstructural repeats, patterns that arise from the repetition of hierarchical\nrelations within sequential data, and develop a candidate computational model\nof how humans detect and understand such structural repeats. Based on a\nweighted deduction system, our model infers the minimal generative process of a\ngiven sequence in the form of a Template program, a formalism that enriches the\ncontext-free grammar with repetition combinators. Such representation\nefficiently encodes the repetition of sub-computations in a recursive manner.\nAs a proof of concept, we demonstrate the expressiveness of our model on short\nsequences from music and action planning. The proposed model offers broader\ninsights into the mental representations and cognitive mechanisms underlying\nhuman pattern recognition.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T10:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.10074v1","title":"MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation\n  Framework","summary":"Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2\\% on the Single-Hop subset and\n+0.4\\% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8\\% on the Unseen-Q subset, +8.2\\% on the Unseen-E subset, and +8.1\\% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-14T10:19:47Z"}
{"aid":"http://arxiv.org/abs/2504.10090v1","title":"CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography","summary":"Large language models (LLMs) and multimodal large language models (MLLMs)\nhave significantly advanced artificial intelligence. However, visual reasoning,\nreasoning involving both visual and textual inputs, remains underexplored.\nRecent advancements, including the reasoning models like OpenAI o1 and Gemini\n2.0 Flash Thinking, which incorporate image inputs, have opened this\ncapability. In this ongoing work, we focus specifically on photography-related\ntasks because a photo is a visual snapshot of the physical world where the\nunderlying physics (i.e., illumination, blur extent, etc.) interplay with the\ncamera parameters. Successfully reasoning from the visual information of a\nphoto to identify these numerical camera settings requires the MLLMs to have a\ndeeper understanding of the underlying physics for precise visual\ncomprehension, representing a challenging and intelligent capability essential\nfor practical applications like photography assistant agents. We aim to\nevaluate MLLMs on their ability to distinguish visual differences related to\nnumerical camera settings, extending a methodology previously proposed for\nvision-language models (VLMs). Our preliminary results demonstrate the\nimportance of visual reasoning in photography-related tasks. Moreover, these\nresults show that no single MLLM consistently dominates across all evaluation\ntasks, demonstrating ongoing challenges and opportunities in developing MLLMs\nwith better visual reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-14T10:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.10131v1","title":"A three-functor formalism for commutative von Neumann algebras","summary":"A three-functor formalism is the half of a six-functor formalism that\nsupports the projection and base change formulas. In this paper, we provide a\nthree-functor formalism for commutative von Neumann algebras and their modules.\nUsing the Gelfand-Naimark theorem, this gives rise to a three-functor formalism\nfor measure spaces and measurable bundles of Hilbert spaces. We use this to\nprove Fell absorption for unitary representations of measure groupoids.\n  The three-functor formalism for commutative von Neumann algebras takes values\nin W*-categories, and we discuss in what sense it is a unitary three-functor\nformalism.","main_category":"math.OA","categories":"math.OA,math.CT,math.QA","published":"2025-04-14T11:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.10133v1","title":"Discovery of an intriguing chemically rich outflow in the OMC-2/3\n  filament","summary":"Studying chemically rich protostellar outflows and their jet provides an\nimportant insight into the low-mass star formation process and its related\nchemistry. Whilst well-known shock tracers such as SiO can be used to study the\njet properties and give information about the dynamics of the system,\ninterstellar complex organic molecules (iCOMs) have been useful in constraining\nthe age of shocked gas, for example. Yet, the number of outflows mapped in\niCOMs is still limited. In this work, we study the outflow driven by the\nprotostar FIR6c-a (HOPS 409) located in the OMC-2/3 filament. We report the\ndetection of the red-shifted jet, left undetected in previous studies, as well\nas the detection of the iCOMs methanol (CH$_3$OH) and methyl cyanide (CH$_3$CN)\nfor the first time towards this outflow. Using SiO, we derived some jet\nproperties (i.e., collimation and dynamical time). We found a clear dichotomy\nbetween the blue- and red-shifted jets, likely due to the density of the medium\nin which the jets propagate. In addition, we identified two bow shocks within\nthe blue-shifted part of the outflow, which we attribute to two different\nejection events. Finally, using the CH$_3$OH} and \\ce{CH$_3$CN} abundance ratio\nand chemical modelling, we constrained the outflow age to be $\\geq 1000$ yr old\nand, surprisingly, found that a cosmic-ray ionization rate of $10^{-14}$\ns$^{-1}$ is needed to reproduce the observed ratio towards the source.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-14T11:42:54Z"}
{"aid":"http://arxiv.org/abs/2504.10139v1","title":"Conditional Distribution Compression via the Kernel Conditional Mean\n  Embedding","summary":"Existing distribution compression methods, like Kernel Herding (KH), were\noriginally developed for unlabelled data. However, no existing approach\ndirectly compresses the conditional distribution of labelled data. To address\nthis gap, we first introduce the Average Maximum Conditional Mean Discrepancy\n(AMCMD), a natural metric for comparing conditional distributions. We then\nderive a consistent estimator for the AMCMD and establish its rate of\nconvergence. Next, we make a key observation: in the context of distribution\ncompression, the cost of constructing a compressed set targeting the AMCMD can\nbe reduced from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(n)$. Building on this, we\nextend the idea of KH to develop Average Conditional Kernel Herding (ACKH), a\nlinear-time greedy algorithm that constructs a compressed set targeting the\nAMCMD. To better understand the advantages of directly compressing the\nconditional distribution rather than doing so via the joint distribution, we\nintroduce Joint Kernel Herding (JKH), a straightforward adaptation of KH\ndesigned to compress the joint distribution of labelled data. While herding\nmethods provide a simple and interpretable selection process, they rely on a\ngreedy heuristic. To explore alternative optimisation strategies, we propose\nJoint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing\nPoints (ACKIP), which jointly optimise the compressed set while maintaining\nlinear complexity. Experiments show that directly preserving conditional\ndistributions with ACKIP outperforms both joint distribution compression (via\nJKH and JKIP) and the greedy selection used in ACKH. Moreover, we see that JKIP\nconsistently outperforms JKH.","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.CO,stat.ME","published":"2025-04-14T11:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.10165v1","title":"WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs","summary":"Live tracking of wildlife via high-resolution video processing directly\nonboard drones is widely unexplored and most existing solutions rely on\nstreaming video to ground stations to support navigation. Yet, both autonomous\nanimal-reactive flight control beyond visual line of sight and/or\nmission-specific individual and behaviour recognition tasks rely to some degree\non this capability. In response, we introduce WildLive -- a near real-time\nanimal detection and tracking framework for high-resolution imagery running\ndirectly onboard uncrewed aerial vehicles (UAVs). The system performs\nmulti-animal detection and tracking at 17fps+ for HD and 7fps+ on 4K video\nstreams suitable for operation during higher altitude flights to minimise\nanimal disturbance. Our system is optimised for Jetson Orin AGX onboard\nhardware. It integrates the efficiency of sparse optical flow tracking and\nmission-specific sampling with device-optimised and proven YOLO-driven object\ndetection and segmentation techniques. Essentially, computational resource is\nfocused onto spatio-temporal regions of high uncertainty to significantly\nimprove UAV processing speeds without domain-specific loss of accuracy.\nAlongside, we introduce our WildLive dataset, which comprises 200k+ annotated\nanimal instances across 19k+ frames from 4K UAV videos collected at the Ol\nPejeta Conservancy in Kenya. All frames contain ground truth bounding boxes,\nsegmentation masks, as well as individual tracklets and tracking point\ntrajectories. We compare our system against current object tracking approaches\nincluding OC-SORT, ByteTrack, and SORT. Our multi-animal tracking experiments\nwith onboard hardware confirm that near real-time high-resolution wildlife\ntracking is possible on UAVs whilst maintaining high accuracy levels as needed\nfor future navigational and mission-specific animal-centric operational\nautonomy.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T12:21:16Z"}
{"aid":"http://arxiv.org/abs/2504.10168v1","title":"HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for\n  Hallucination Detection","summary":"In this paper, we present HalluSearch, a multilingual pipeline designed to\ndetect fabricated text spans in Large Language Model (LLM) outputs. Developed\nas part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and\nRelated Observable Overgeneration Mistakes, HalluSearch couples\nretrieval-augmented verification with fine-grained factual splitting to\nidentify and localize hallucinations in fourteen different languages. Empirical\nevaluations show that HalluSearch performs competitively, placing fourth in\nboth English (within the top ten percent) and Czech. While the system's\nretrieval-based strategy generally proves robust, it faces challenges in\nlanguages with limited online coverage, underscoring the need for further\nresearch to ensure consistent hallucination detection across diverse linguistic\ncontexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.10169v1","title":"Challenges in interpretability of additive models","summary":"We review generalized additive models as a type of ``transparent'' model that\nhas recently seen renewed interest in the deep learning community as neural\nadditive models. We highlight multiple types of nonidentifiability in this\nmodel class and discuss challenges in interpretability, arguing for restraint\nwhen claiming ``interpretability'' or ``suitability for safety-critical\napplications'' of such models.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-14T12:24:17Z"}
{"aid":"http://arxiv.org/abs/2504.10188v1","title":"Efficient Generative Model Training via Embedded Representation Warmup","summary":"Diffusion models excel at generating high-dimensional data but fall short in\ntraining efficiency and representation quality compared to self-supervised\nmethods. We identify a key bottleneck: the underutilization of high-quality,\nsemantically rich representations during training notably slows down\nconvergence. Our systematic analysis reveals a critical representation\nprocessing region -- primarily in the early layers -- where semantic and\nstructural pattern learning takes place before generation can occur. To address\nthis, we propose Embedded Representation Warmup (ERW), a plug-and-play\nframework where in the first stage we get the ERW module serves as a warmup\nthat initializes the early layers of the diffusion model with high-quality,\npretrained representations. This warmup minimizes the burden of learning\nrepresentations from scratch, thereby accelerating convergence and boosting\nperformance. Our theoretical analysis demonstrates that ERW's efficacy depends\non its precise integration into specific neural network layers -- termed the\nrepresentation processing region -- where the model primarily processes and\ntransforms feature representations for later generation. We further establish\nthat ERW not only accelerates training convergence but also enhances\nrepresentation quality: empirically, our method achieves a 40$\\times$\nacceleration in training speed compared to REPA, the current state-of-the-art\nmethods. Code is available at https://github.com/LINs-lab/ERW.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-14T12:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.10199v1","title":"Multipole Moments of Double Heavy $J^P = \\frac{3}{2}^+$ Baryons","summary":"In the present study, we calculate the multipole moments of spin-3/2 doubly\nheavy baryons within the light cone QCD sum rules. We compare our results on\nmagnetic dipole moments with results existing in the literature. The results\nobtained in the present work may be useful for a deeper understanding of the\nproperties of doubly heavy baryons as well as in the analysis of their strong\nand electromagnetic decays.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-14T13:03:16Z"}
{"aid":"http://arxiv.org/abs/2504.10220v1","title":"Modeling the Thermal Structure of a Protoplanetary Disk Using Multiband\n  Flux-Limited Diffusion Approximation","summary":"This work continues the analysis of the model for calculating the thermal\nstructure of an axisymmetric protoplanetary disk, initiated in the paper by\nPavlyuchenkov (2024). The model is based on the well-known Flux-Limited\nDiffusion (FLD) approximation with separate calculation of heating by direct\nstellar radiation (hereinafter referred to as the FLD$^{\\rm s}$ method). In\naddition to the previously described FLD$^{\\rm s}$ model with\nwavelength-averaged opacities, we present a multiband model mFLD$^{\\rm s}$,\nwhere the spectrum of thermal radiation is divided into several frequency\nbands. The model is based on an implicit finite-difference scheme for the\nequations of thermal radiation diffusion, which reduces to a system of linear\nalgebraic equations written in hypermatrix form. A modified Gauss method for\ninverting the sparse hypermatrix of the original system of linear equations is\nproposed. The simulation results described in the article show that the\nmidplane radial temperature profile obtained with the mFLD$^{\\rm s}$ method has\na variable slope in accordance with the reference Monte Carlo radiative\ntransfer simulations. The mFLD$^{\\rm s}$ model also qualitatively reproduces\nthe non-isothermality of the temperature distribution along the angular\ncoordinate near the midplane, which is not provided by the FLD$^{\\rm s}$\nmethod. However, quantitative differences remain between the reference\ntemperature values and the results of mFLD$^{\\rm s}$. These differences are\nlikely due to the diffusive nature of the FLD approximation. It is also shown\nthat the characteristic times for the disk to reach thermal equilibrium within\nthe mFLD$^{\\rm s}$ model can be significantly shorter than in FLD$^{\\rm s}$.\nThis property should be taken into account when modeling non-stationary\nprocesses in protoplanetary disks within FLD-based models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-14T13:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.10223v1","title":"A proof of the Krzyz conjecture","summary":"A proof of the Krzyz conjecture is presented, based on the application of the\nvariational method, as well as on the use of two classical results and some of\ntheir consequences. The mentioned results are the Caratheodory-Toeplitz\ncriterion of continuing a polynomial to a Caratheodory class function, and the\nRiesz-Fejer theorem about trigonometric polynomials. This is an English\ntranslation of a preprint originally published in Russian:\nhttps://preprints.ru/article/1799","main_category":"math.CV","categories":"math.CV","published":"2025-04-14T13:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.10229v1","title":"ROSFD: Robust Online Streaming Fraud Detection with Resilience to\n  Concept Drift in Data Streams","summary":"Continuous generation of streaming data from diverse sources, such as online\ntransactions and digital interactions, necessitates timely fraud detection.\nTraditional batch processing methods often struggle to capture the rapidly\nevolving patterns of fraudulent activities. This paper highlights the critical\nimportance of processing streaming data for effective fraud detection. To\naddress the inherent challenges of latency, scalability, and concept drift in\nstreaming environments, we propose a robust online streaming fraud detection\n(ROSFD) framework. Our proposed framework comprises two key stages: (i) Stage\nOne: Offline Model Initialization. In this initial stage, a model is built in\noffline settings using incremental learning principles to overcome the\n\"cold-start\" problem. (ii) Stage Two: Real-time Model Adaptation. In this\ndynamic stage, drift detection algorithms (viz.,, DDM, EDDM, and ADWIN) are\nemployed to identify concept drift in the incoming data stream and\nincrementally train the model accordingly. This \"train-only-when-required\"\nstrategy drastically reduces the number of retrains needed without\nsignificantly impacting the area under the receiver operating characteristic\ncurve (AUC). Overall, ROSFD utilizing ADWIN as the drift detection method\ndemonstrated the best performance among the employed methods. In terms of model\nefficacy, Adaptive Random Forest consistently outperformed other models,\nachieving the highest AUC in four out of five datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T13:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.10248v1","title":"Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for\n  Dynamic Data Acquisition in Digital Twins","summary":"This paper introduces a sensor steering methodology based on deep\nreinforcement learning to enhance the predictive accuracy and decision support\ncapabilities of digital twins by optimising the data acquisition process.\nTraditional sensor placement techniques are often constrained by one-off\noptimisation strategies, which limit their applicability for online\napplications requiring continuous informative data assimilation. The proposed\napproach addresses this limitation by offering an adaptive framework for sensor\nplacement within the digital twin paradigm. The sensor placement problem is\nformulated as a Markov decision process, enabling the training and deployment\nof an agent capable of dynamically repositioning sensors in response to the\nevolving conditions of the physical structure as represented by the digital\ntwin. This ensures that the digital twin maintains a highly representative and\nreliable connection to its physical counterpart. The proposed framework is\nvalidated through a series of comprehensive case studies involving a cantilever\nplate structure subjected to diverse conditions, including healthy and damaged\nconditions. The results demonstrate the capability of the deep reinforcement\nlearning agent to adaptively reposition sensors improving the quality of data\nacquisition and hence enhancing the overall accuracy of digital twins.","main_category":"stat.ML","categories":"stat.ML,cs.LG,eess.SP","published":"2025-04-14T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.10285v1","title":"Grothendieck-Springer resolutions and TQFTs","summary":"Let $G$ be a connected complex semisimple group with Lie algebra\n$\\mathfrak{g}$ and fixed Kostant slice $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$.\nIn a previous work, we show that\n$((T^*G)_{\\text{reg}}\\rightrightarrows\\mathfrak{g}^*_{\\text{reg}},\\mathrm{Kos})$\nyields the open Moore-Tachikawa TQFT. Morphisms in the image of this TQFT are\ncalled open Moore-Tachikawa varieties. By replacing\n$T^*G\\rightrightarrows\\mathfrak{g}^*$ and $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$\nwith the double $\\mathrm{D}(G)\\rightrightarrows G$ and a Steinberg slice\n$\\mathrm{Ste}\\subseteq G$, respectively, one obtains quasi-Hamiltonian\nanalogues of the open Moore-Tachikawa TQFT and varieties.\n  We consider a conjugacy class $\\mathcal{C}$ of parabolic subalgebras of\n$\\mathfrak{g}$. This class determines partial Grothendieck-Springer resolutions\n$\\mu_{\\mathcal{C}}:\\mathfrak{g}_{\\mathcal{C}}\\longrightarrow\\mathfrak{g}^*=\\mathfrak{g}$\nand $\\nu_{\\mathcal{C}}:G_{\\mathcal{C}}\\longrightarrow G$. We construct a\ncanonical symplectic groupoid\n$(T^*G)_{\\mathcal{C}}\\rightrightarrows\\mathfrak{g}_{\\mathcal{C}}$ and\nquasi-symplectic groupoid $\\mathrm{D}(G)_{\\mathcal{C}}\\rightrightarrows\nG_{\\mathcal{C}}$. In addition, we prove that the pairs\n$(((T^*G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(\\mathfrak{g}_{\\mathcal{C}})_{\\text{reg}},\\mu_{\\mathcal{C}}^{-1}(\\mathrm{Kos}))$\nand\n$((\\mathrm{D}(G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(G_{\\mathcal{C}})_{\\text{reg}},\\nu_{\\mathcal{C}}^{-1}(\\mathrm{Ste}))$\ndetermine TQFTs in a $1$-shifted Weinstein symplectic category. Our main result\nis about the Hamiltonian symplectic varieties arising from the former TQFT; we\nshow that these have canonical Lagrangian relations to the open Moore-Tachikawa\nvarieties. Pertinent specializations of our results to the full\nGrothendieck-Springer resolution are discussed throughout this manuscript.","main_category":"math.SG","categories":"math.SG,math.AG,math.RT","published":"2025-04-14T14:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.10287v1","title":"From translations to non-collapsing logic combinations","summary":"Prawitz suggested expanding a natural deduction system for intuitionistic\nlogic to include rules for classical logic constructors, allowing both\nintuitionistic and classical elements to coexist without losing their inherent\ncharacteristics. Looking at the added rules from the point of view of the\nGodel-Gentzen translation, led us to propose a general method for the\ncoexistent combination of two logics when a conservative translation exists\nfrom one logic (the source) to another (the host). Then we prove that the\ncombined logic is a conservative extension of the original logics, thereby\npreserving the unique characteristics of each component logic. In this way\nthere is no collapse of one logic into the other in the combination. We also\ndemonstrate that a Gentzen calculus for the combined logic can be induced from\na Gentzen calculus for the host logic by considering the translation. This\napproach applies to semantics as well. We then establish a general sufficient\ncondition for ensuring that the combined logic is both sound and complete. We\napply these principles by combining classical and intuitionistic logics\ncapitalizing on the Godel-Gentzen conservative translation, intuitionistic and\nS4 modal logics relying on the Godel-McKinsey-Tarski conservative translation,\nand classical and Jaskowski's paraconsistent logics taking into account the\nexistence of a conservative translation.","main_category":"math.LO","categories":"math.LO","published":"2025-04-14T14:55:11Z"}
{"aid":"http://arxiv.org/abs/2504.10298v1","title":"Cross-talk in superconducting qubit lattices with tunable couplers -\n  comparing transmon and fluxonium architectures","summary":"Cross-talk between qubits is one of the main challenges for scaling\nsuperconducting quantum processors. Here, we use the density-matrix\nrenormalization-group to numerically analyze lattices of superconducting qubits\nfrom a perspective of many-body localization. Specifically, we compare\ndifferent architectures that include tunable couplers designed to decouple\nqubits in the idle state, and calculate the residual ZZ interactions as well as\nthe inverse participation ratio in the computational basis states. For transmon\nqubits outside of the straddling regime, the results confirm that tunable\nC-shunt flux couplers are significantly more efficient in mitigating the ZZ\ninteractions than tunable transmons. A recently proposed fluxonium architecture\nwith tunable transmon couplers is demonstrated to also maintain its strong\nsuppression of the ZZ interactions in larger systems, while having a higher\ninverse participation ratio in the computational basis states than lattices of\ntransmon qubits. Our results thus suggest that fluxonium architectures may\nfeature lower cross talk than transmon lattices when designed to achieve\nsimilar gate speeds and fidelities.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T15:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.10301v1","title":"Three-body problem for nuclear physics","summary":"A brief excursion into the three-body problem is presented for graduate\nstudents in nuclear physics or anyone at a similar stage. Starting from\nsingle-particle coordinates, a step-by-step derivation of the Shcr\\\"{o}dinger\nequation in Jacobi coordinates is outlined. Laplace operators are explicitly\ntransformed through the chain rule for multivariable calculus. The\ntransformation of Faddeev equations from Jacobi coordinates to hyperspherical\ncoordinates is elaborated upon. In all transformations (from single-particle\ncoordinates to Jacobi coordinates, rotation between Jacobi coordinates and from\nJacobi coordinates to hyperspherical coordinates) the determinant of the\nJacobian matrix is computed to show how volume elements transform. The\nprojection of Faddeev equations on a hyperspherical harmonics basis is\nexplicitly carried out to obtain the coupled hyperradial equations that define\nthe hyperspherical harmonics method.","main_category":"nucl-th","categories":"nucl-th,physics.ed-ph","published":"2025-04-14T15:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.10302v1","title":"Nonnegativity of signomials with Newton simplex over convex sets","summary":"We study a class of signomials whose positive support is the set of vertices\nof a simplex and which may have multiple negative support points in the\nsimplex. Various groups of authors have provided an exact characterization for\nthe global nonnegativity of a signomial in this class in terms of circuit\nsignomials and that characterization provides a tractable nonnegativity test.\nWe generalize this characterization to the constrained nonnegativity over a\nconvex set $X$. This provides a tractable $X$-nonnegativity test for the class\nin terms of relative entropy programming and in terms of the support function\nof $X$. Our proof methods rely on the convex cone of constrained SAGE\nsignomials (sums of arithmetic-geometric exponentials) and the duality theory\nof this cone.","main_category":"math.CO","categories":"math.CO,math.AG,math.OC","published":"2025-04-14T15:11:12Z"}
{"aid":"http://arxiv.org/abs/2504.10315v1","title":"An energy optimization method based on mixed-integer model and\n  variational quantum computing algorithm for faster IMPT","summary":"Intensity-modulated proton therapy (IMPT) offers superior dose conformity\nwith reduced exposure to surrounding healthy tissues compared to conventional\nphoton therapy. Improving IMPT delivery efficiency reduces motion-related\nuncertainties, enhances plan robustness, and benefits breath-hold techniques by\nshortening treatment time. Among various factors, energy switching time plays a\ncritical role, making energy layer optimization (ELO) essential. This work\ndevelops an energy layer optimization method based on mixed integer model and\nvariational quantum computing algorithm to enhance the efficiency of IMPT. The\nenergy layer optimization problem is modeled as a mixed-integer program, where\ncontinuous variables optimize the dose distribution and binary variables\nindicate energy layer selection. To solve it, iterative convex relaxation\ndecouples the dose-volume constraints, followed by the alternating direction\nmethod of multipliers (ADMM) to separate mixed-variable optimization and the\nminimum monitor unit (MMU) constraint. The resulting beam intensity subproblem,\nsubject to MMU, either admits a closed-form solution or is efficiently solvable\nvia conjugate gradient. The binary subproblem is cast as a quadratic\nunconstrained binary optimization (QUBO) problem, solvable using variational\nquantum computing algorithms. With nearly the same plan quality, the proposed\nmethod noticeable reduces the number of the used energies. For example,\ncompared to conventional IMPT, QC can reduce the number of energy layers from\n61 to 35 in HN case, from 56 to 35 in lung case, and from 59 to 32 to abdomen\ncase. The reduced number of energies also results in fewer delivery time, e.g.,\nthe delivery time is reduced from 100.6, 232.0, 185.3 seconds to 90.7, 215.4,\n154.0 seconds, respectively.","main_category":"physics.med-ph","categories":"physics.med-ph,math.OC","published":"2025-04-14T15:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.10317v1","title":"Analysis of Attention in Video Diffusion Transformers","summary":"We conduct an in-depth analysis of attention in video diffusion transformers\n(VDiTs) and report a number of novel findings. We identify three key properties\nof attention in VDiTs: Structure, Sparsity, and Sinks. Structure: We observe\nthat attention patterns across different VDiTs exhibit similar structure across\ndifferent prompts, and that we can make use of the similarity of attention\npatterns to unlock video editing via self-attention map transfer. Sparse: We\nstudy attention sparsity in VDiTs, finding that proposed sparsity methods do\nnot work for all VDiTs, because some layers that are seemingly sparse cannot be\nsparsified. Sinks: We make the first study of attention sinks in VDiTs,\ncomparing and contrasting them to attention sinks in language models. We\npropose a number of future directions that can make use of our insights to\nimprove the efficiency-quality Pareto frontier for VDiTs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T15:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.10327v1","title":"Probing Einstein-Maxwell-Scalar Black hole via Thin Accretion Disks and\n  Shadows with EHT Observations of M87* and Sgr A*","summary":"We investigated the shadows and thin accretion disks of\nEinstein-Maxwell-Scalar (EMS) black hole. Firstly, we investigated the\ninfluence of EMS parameters on the black hole shadow using the null geodesic\nmethod and constrained these parameters based on EHT observations of M87* and\nSgr A*. Furthermore, we analyzed the direct emission, lensing ring, and photon\nring structures in EMS black hole. Comparing our results with the Schwarzschild\nand Reissner-Nordstr$\\ddot{\\mathrm{o}}$m (RN) black holes, we found that the\nSchwarzschild black hole exhibits the largest shadow radius and the highest\nobserved intensity. Increasing the EMS model parameters leads to a reduction in\nintensity. Ultimately, our findings suggest that imaging black hole accretion\ndisks does not clearly distinguish among these three types of black holes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T15:35:47Z"}
{"aid":"http://arxiv.org/abs/2504.10336v1","title":"Analysis of the complex gas pipeline exploitation process in various\n  operating modes","summary":"The study aims to decrease gas loss and enhance system reliability during gas\npipeline accidents. A computational scheme has been developed that can enable\nthe elimination of gas leakage through the modeling and management of parallel\ngas pipeline systems. The dynamic state of processes for the supply of modern\nautomatic equipment to gas pipelines and the use of an efficient automated\ncontrol system have been extensively studied. The analytical determination of\nthe optimal transition time has been widely applied to ensure the most\nfavorable operating conditions for the system. Methods for calculating complex\ntransient processes in main gas pipelines, from a non-stationary regime to a\nstationary regime, have been developed, particularly at the moment of gas flow\ningress. A comparison of mathematical expressions for calculating transient\nprocesses in complex main gas pipelines has been conducted through theoretical\nsources.","main_category":"math.OC","categories":"math.OC","published":"2025-04-14T15:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.10373v1","title":"DUE: A Deep Learning Framework and Library for Modeling Unknown\n  Equations","summary":"Equations, particularly differential equations, are fundamental for\nunderstanding natural phenomena and predicting complex dynamics across various\nscientific and engineering disciplines. However, the governing equations for\nmany complex systems remain unknown due to intricate underlying mechanisms.\nRecent advancements in machine learning and data science offer a new paradigm\nfor modeling unknown equations from measurement or simulation data. This\nparadigm shift, known as data-driven discovery or modeling, stands at the\nforefront of AI for science, with significant progress made in recent years. In\nthis paper, we introduce a systematic framework for data-driven modeling of\nunknown equations using deep learning. This versatile framework is capable of\nlearning unknown ODEs, PDEs, DAEs, IDEs, SDEs, reduced or partially observed\nsystems, and non-autonomous differential equations. Based on this framework, we\nhave developed Deep Unknown Equations (DUE), an open-source software package\ndesigned to facilitate the data-driven modeling of unknown equations using\nmodern deep learning techniques. DUE serves as an educational tool for\nclassroom instruction, enabling students and newcomers to gain hands-on\nexperience with differential equations, data-driven modeling, and contemporary\ndeep learning approaches such as FNN, ResNet, generalized ResNet, operator\nsemigroup networks (OSG-Net), and Transformers. Additionally, DUE is a\nversatile and accessible toolkit for researchers across various scientific and\nengineering fields. It is applicable not only for learning unknown equations\nfrom data but also for surrogate modeling of known, yet complex, equations that\nare costly to solve using traditional numerical methods. We provide detailed\ndescriptions of DUE and demonstrate its capabilities through diverse examples,\nwhich serve as templates that can be easily adapted for other applications.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.DS,math.NA,stat.ML","published":"2025-04-14T16:20:55Z"}
{"aid":"http://arxiv.org/abs/2504.10441v1","title":"Position Uncertainty in a Prisoner's Dilemma Game : An Experiment","summary":"Gallice and Monzon (2019) present a natural environment that sustains full\ncooperation in one-shot social dilemmas among a finite number of\nself-interested agents. They demonstrate that in a sequential public goods\ngame, where agents lack knowledge of their position in the sequence but can\nobserve some predecessors' actions, full contribution emerges in equilibrium\ndue to agents' incentive to induce potential successors to follow suit.\nFurthermore, they show that this principle extends to a number of social\ndilemmas, with the prominent example that of the prisoner's dilemma. In this\nstudy, we experimentally test the theoretical predictions of this model in a\nmulti- player prisoner's dilemma environment, where subjects are not aware of\ntheir position in the sequence and receive only partial information on past\ncooperating actions. We test the predictions of the model, and through rigorous\nstructural econometric analysis, we test the descriptive capacity of the model\nagainst alternative behavioural strategies, such as conditional cooperation,\naltruistic play and free-riding behaviour. We find that the majority resorts to\nfree-riding behaviour, around 30% is classified as Gallice and Monzon (2019)\ntypes, followed by those with social preference considerations and the\nunconditional altruists.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-14T17:32:07Z"}
{"aid":"http://arxiv.org/abs/2504.10462v1","title":"The Scalability of Simplicity: Empirical Analysis of Vision-Language\n  Learning with a Single Transformer","summary":"This paper introduces SAIL, a single transformer unified multimodal large\nlanguage model (MLLM) that integrates raw pixel encoding and language decoding\nwithin a singular architecture. Unlike existing modular MLLMs, which rely on a\npre-trained vision transformer (ViT), SAIL eliminates the need for a separate\nvision encoder, presenting a more minimalist architecture design. Instead of\nintroducing novel architectural components, SAIL adapts mix-attention\nmechanisms and multimodal positional encodings to better align with the\ndistinct characteristics of visual and textual modalities. We systematically\ncompare SAIL's properties-including scalability, cross-modal information flow\npatterns, and visual representation capabilities-with those of modular MLLMs.\nBy scaling both training data and model size, SAIL achieves performance\ncomparable to modular MLLMs. Notably, the removal of pretrained ViT components\nenhances SAIL's scalability and results in significantly different cross-modal\ninformation flow patterns. Moreover, SAIL demonstrates strong visual\nrepresentation capabilities, achieving results on par with ViT-22B in vision\ntasks such as semantic segmentation. Code and models are available at\nhttps://github.com/bytedance/SAIL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:50:20Z"}
{"aid":"http://arxiv.org/abs/2504.10474v1","title":"Co-optimizing Physical Reconfiguration Parameters and Controllers for an\n  Origami-inspired Reconfigurable Manipulator","summary":"Reconfigurable robots that can change their physical configuration\npost-fabrication have demonstrate their potential in adapting to different\nenvironments or tasks. However, it is challenging to determine how to optimally\nadjust reconfigurable parameters for a given task, especially when the\ncontroller depends on the robot's configuration. In this paper, we address this\nproblem using a tendon-driven reconfigurable manipulator composed of multiple\nserially connected origami-inspired modules as an example. Under tendon\nactuation, these modules can achieve different shapes and motions, governed by\njoint stiffnesses (reconfiguration parameters) and the tendon displacements\n(control inputs). We leverage recent advances in co-optimization of design and\ncontrol for robotic system to treat reconfiguration parameters as design\nvariables and optimize them using reinforcement learning techniques. We first\nestablish a forward model based on the minimum potential energy method to\npredict the shape of the manipulator under tendon actuations. Using the forward\nmodel as the environment dynamics, we then co-optimize the control policy (on\nthe tendon displacements) and joint stiffnesses of the modules for goal\nreaching tasks while ensuring collision avoidance. Through co-optimization, we\nobtain optimized joint stiffness and the corresponding optimal control policy\nto enable the manipulator to accomplish the task that would be infeasible with\nfixed reconfiguration parameters (i.e., fixed joint stiffness). We envision the\nco-optimization framework can be extended to other reconfigurable robotic\nsystems, enabling them to optimally adapt their configuration and behavior for\ndiverse tasks and environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T17:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.10477v1","title":"Vector induced Gravitational Waves sourced by Primordial Magnetic Fields","summary":"In this work, we develop a generic formalism for the study of tensor\nperturbations induced at second order by first-order vector metric\nperturbations, dubbing these induced tensor modes $\\textit{vector-induced\ngravitational waves}$ (VIGWs). Notably, considering an inflation-inspired\npower-law type magnetic field power spectrum of the form $P_B(k)\\propto\nk^{n_\\mathrm{B}}$ (where $n_{\\rm B}$ is the magnetic spectral index), we show\nthat the VIGW signal is enhanced for stiff post-inflationary EoS, with the\nmaximum enhancement happening for $w=1$. We explicitly demonstrate this\ncontribution is dominant over the first-order magnetically-sourced GWs. The\nVIGW spectrum exhibits a maximum at around the scale crossing the cosmological\nhorizon at the end of reheating, $k_\\mathrm{reh}$, with its present day peak\namplitude scaling as $\\Omega_{\\rm GW}(k_{\\rm reh},\\eta_0)\\propto \\Delta N_{\\rm\nreh}\\times(H_{\\rm inf}/M_{\\rm Pl})^{8}$, where $H_{\\rm inf}$ is the Hubble\nparameter at the end of inflation and $\\Delta N_{\\rm reh}$ the duration of the\npost-inflationary era in $e$-folds. For $w=1$ (kination) and $n_{\\rm B}>-3/2$,\none further obtains a nearly $n_{\\rm B}$-independent frequency scaling of the\nGW spectrum of the form $\\Omega_{\\rm GW}(f,\\eta_0)\\propto \\left(\\frac{f}{f_{\\rm\nreh}}\\right)^{-2.8}$ for $f>f_\\mathrm{reh}\\equiv k_\\mathrm{reh}/(2\\pi)$.\nFinally, we need to highlight that the VIGW signal can be well within the\ndetection bands of several next-generation interferometric GW missions at small\nscales. Indicatively, for $H_{\\rm inf} \\sim O(10^{7})\\:\\mathrm{GeV}$ and\n$O(10^{14})\\:\\mathrm{GeV}$, and $\\Delta N_{\\rm reh} \\sim 15$ and $10$, the VIGW\nsignal is found to be detectable by LISA and ET respectively.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-14T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.10480v1","title":"Probing Long-Range Forces in Neutrino Oscillations at the ESSnuSB\n  Experiment","summary":"Neutrino oscillations constitute an excellent tool to probe physics beyond\nthe Standard Model. In this paper, we investigate the potential of the \\ess\nexperiment to constrain the effects of flavour-dependent long-range forces\n(LRFs) in neutrino oscillations, which may arise due to the extension of the\nStandard Model gauge group by introducing new $U(1)$ symmetries. Focusing on\nthree specific $U(1)$ symmetries -- $L_e - L_\\mu$, $L_e - L_\\tau$, and $L_\\mu -\nL_\\tau$, we demonstrate that \\ess offers a favourable environment to search for\nLRF effects. Our analyses reveal that \\ess can set 90\\% confidence level bounds\nof $V_{e\\mu} < 2.99 \\times 10^{-14} \\, \\text{eV}$, $V_{e\\tau} < 2.05 \\times\n10^{-14} \\, \\text{eV}$, and $V_{\\mu\\tau} < 1.81 \\times 10^{-14} \\, \\text{eV}$,\nwhich are competitive to the upcoming Deep Underground Neutrino Experiment\n(DUNE). It is also observed that reducing the systematic uncertainties from\n$5\\%$ to $2\\%$ improves the \\ess limits on $V_{\\alpha\\beta}$. Interestingly, we\nfind limited correlations between LRF parameters and the less constrained\nlepton mixing parameters $\\theta_{23}$ and $\\delta_{\\text{CP}}$, preserving the\nrobustness of ESSnuSB's sensitivity to CP violation. Even under extreme LRF\npotentials ($V_{\\alpha\\beta} \\gg 10^{-13} \\, \\text{eV}$), the CP-violation\nsensitivity and $\\delta_{\\text{CP}}$ precision remain largely unaffected. These\nresults establish ESSnuSB as a competitive experimental setup for probing LRF\neffects, complementing constraints from other neutrino sources and offering\ncritical insights into the physics of long-range forces.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-14T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.10838v1","title":"Directional Expansiveness for Rd-Actions and for Penrose Tilings","summary":"We define and study two kinds of directional expansiveness, weak and strong,\nfor an action T of \\mathbb{R}^d on a compact metric space X. We show that for\n\\mathbb{R}^2 finite local complexity (FLC) tiling dynamical systems, weak and\nstrong expansiveness are the same, and are both equivalent to a simple coding\nproperty. Then we show for the Penrose tiling dynamical system, which is FLC,\nthere are exactly five non expansive directions, the directions perpendicular\nto the 5th roots of unity. We also study Raphael Robinson's set of 24 Penrose\nWang tiles and show the corresponding Penrose Wang tile dynamical system is\nstrictly ergodic. Finally, we study two deformations of the Penrose Wang tile\nsystem, one where the square Wang tiles are all deformed into a 2\\pi/5 rhombus,\nand another where they are deformed into a set of eleven tetragon tiles. We\nshow both of these are topologically conjugate to the Penrose tiling dynamical\nsystem.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T03:43:06Z"}
{"aid":"http://arxiv.org/abs/2504.10845v1","title":"Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive\n  Language Generators","summary":"Large Language Models (LLMs), powered by Transformers, have demonstrated\nhuman-like intelligence capabilities, yet their underlying mechanisms remain\npoorly understood. This paper presents a novel framework for interpreting LLMs\nas probabilistic left context-sensitive languages (CSLs) generators. We\nhypothesize that Transformers can be effectively decomposed into three\nfundamental components: context windows, attention mechanisms, and\nautoregressive generation frameworks. This decomposition allows for the\ndevelopment of more flexible and interpretable computational models, moving\nbeyond the traditional view of attention and autoregression as inseparable\nprocesses. We argue that next-token predictions can be understood as\nprobabilistic, dynamic approximations of left CSL production rules, providing\nan intuitive explanation for how simple token predictions can yield human-like\nintelligence outputs. Given that all CSLs are left context-sensitive\n(Penttonen, 1974), we conclude that Transformers stochastically approximate\nCSLs, which are widely recognized as models of human-like intelligence. This\ninterpretation bridges the gap between Formal Language Theory and the observed\ngenerative power of Transformers, laying a foundation for future advancements\nin generative AI theory and applications. Our novel perspective on Transformer\narchitectures will foster a deeper understanding of LLMs and their future\npotentials.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T04:06:27Z"}
{"aid":"http://arxiv.org/abs/2504.10865v1","title":"Understanding the theoretical properties of projected Bellman equation,\n  linear Q-learning, and approximate value iteration","summary":"In this paper, we study the theoretical properties of the projected Bellman\nequation (PBE) and two algorithms to solve this equation: linear Q-learning and\napproximate value iteration (AVI). We consider two sufficient conditions for\nthe existence of a solution to PBE : strictly negatively row dominating\ndiagonal (SNRDD) assumption and a condition motivated by the convergence of\nAVI. The SNRDD assumption also ensures the convergence of linear Q-learning,\nand its relationship with the convergence of AVI is examined. Lastly, several\ninteresting observations on the solution of PBE are provided when using\n$\\epsilon$-greedy policy.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-15T04:56:33Z"}
{"aid":"http://arxiv.org/abs/2504.10897v1","title":"SCOOP: A Scalable Quantum-Computing Framework to Constrained\n  Combinatorial Optimization","summary":"While the ultimate goal of solving computationally intractable problems is to\nfind a provably optimal solutions, practical constraints of real-world\nscenarios often necessitate focusing on efficiently obtaining high-quality,\nnear-optimal solutions. The Quantum Approximate Optimization Algorithm (QAOA)\nis a state-of-the-art hybrid quantum-classical approach for tackling these\nchallenging problems that are encoded using quadratic and higher-order\nunconstrained binary optimization problems (QUBO and HUBO). We present SCOOP, a\nnovel QAOA-based framework for solving constrained optimization problems. SCOOP\ntransforms a constrained problem into an unconstrained counterpart, forming\nSCOOP problem twins. The QAOA quantum algorithm operates on the unconstrained\ntwin to identify potential optimal and near-optimal solutions. Effective\nclassical post-processing reduces the solution set to the constrained problem\nspace. Our SCOOP approach is solution-enhanced, objective-function-compatible,\nand scalable. We demonstrate the framework on three NP-hard problems, Minimum\nDominating Set, Minimum Maximal Matching, and Minimum Set Cover appearing in\npractical application domains such as resource allocation, communication\nnetworks, and machine learning. We validate SCOOP's feasibility and\neffectiveness on Xanadu PennyLane simulators.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T06:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.10908v1","title":"Generalizability of local neural operator: example for elastodynamic\n  problems","summary":"Local neural operator (LNO) conception has provided a feasible way for\nscientific computations. The LNO learns transient partial differential\nequations from random field samples, and then the pre-trained LNO solves\npractical problems on specific computational domains. For applications, we may\nask: Are the training samples rich enough? To what extent can we trust the\nsolutions obtained from pre-trained LNO models for unknown cases? The\ngeneralizability of LNO could answer these questions. Here, we propose to use\ntwo plain scalar features, the amplitude and wavenumber of the input functions,\nto indicate the richness of training samples and to evaluate the generalization\nerror of pre-trained LNO. In elastodynamic practices, we find that isolated\nevolving wavenumber modes for Lam\\'e-Navier equation caused the training\ndataset to lack mode diversity. By data supplementation and model fine-tuning\ntargeting to the discovered lack modes, the pre-trained and fine-tuned LNO\nmodel solves Lamb problem correctly and efficiently. These results and the\nproposed generalization criteria provide a paradigm for LNO applications.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-15T06:41:05Z"}
{"aid":"http://arxiv.org/abs/2504.10915v1","title":"LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI\n  Agent Ecosystems","summary":"The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that enables agents to make context-aware decisions grounded in\nshared ethical baselines. Anchored in emerging standards such as Decentralized\nIdentifiers (DIDs), Verifiable Credentials (VCs), and post-quantum\ncryptography, LOKA offers a scalable, future-resilient blueprint for\nmulti-agent AI governance. By embedding identity, trust, and ethics into the\nprotocol layer itself, LOKA establishes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.CY","published":"2025-04-15T06:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.10921v1","title":"MSCRS: Multi-modal Semantic Graph Prompt Learning Framework for\n  Conversational Recommender Systems","summary":"Conversational Recommender Systems (CRSs) aim to provide personalized\nrecommendations by interacting with users through conversations. Most existing\nstudies of CRS focus on extracting user preferences from conversational\ncontexts. However, due to the short and sparse nature of conversational\ncontexts, it is difficult to fully capture user preferences by conversational\ncontexts only. We argue that multi-modal semantic information can enrich user\npreference expressions from diverse dimensions (e.g., a user preference for a\ncertain movie may stem from its magnificent visual effects and compelling\nstoryline). In this paper, we propose a multi-modal semantic graph prompt\nlearning framework for CRS, named MSCRS. First, we extract textual and image\nfeatures of items mentioned in the conversational contexts. Second, we capture\nhigher-order semantic associations within different semantic modalities\n(collaborative, textual, and image) by constructing modality-specific graph\nstructures. Finally, we propose an innovative integration of multi-modal\nsemantic graphs with prompt learning, harnessing the power of large language\nmodels to comprehensively explore high-dimensional semantic relationships.\nExperimental results demonstrate that our proposed method significantly\nimproves accuracy in item recommendation, as well as generates more natural and\ncontextually relevant content in response generation. We have released the code\nand the expanded multi-modal CRS datasets to facilitate further exploration in\nrelated research\\footnote{https://github.com/BIAOBIAO12138/MSCRS-main}.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-15T07:05:22Z"}
{"aid":"http://arxiv.org/abs/2504.10926v1","title":"RedDots: Planetary masses in the GJ1061 system from planet-planet\n  interaction","summary":"GJ1061 is a very nearby M star hosting three low-mass temperate planets\ndetected from radial velocity variations. The close to 4:2:1 period\ncommensurability of the planets, the available long-term monitoring of the\nsystem and new very high-precision radial velocity measurements from ESPRESSO\nenable the determination of masses from the planet-planet interaction. Using\nnested sampling, we derived parameter distributions for a co-planar\nconfiguration. The three planets (Mb =1.07 +- 0.11M_Earth, Pb =3.2073 +- 0.0003\nd, Mc=1.76 +- 0.13M_Earth, Pc=6.6821 +- 0.0008 d, Md =1.55 +- 0.17M_Earth, Pd\n=13.066 +- 0.002 d) are potentially all rocky with equilibrium temperatures\nbetween 360 K and 240 K. This makes the GJ1061 system one of the prime targets\nfor future ground or space based instruments suitable for a direct detection of\nthe planetary atmospheres.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T07:12:03Z"}
{"aid":"http://arxiv.org/abs/2504.10935v1","title":"Sasaki-Einstein orbits in compact Hermitian symmetric spaces","summary":"The aim of the present papar is to study the orbits of the isotropy gourp\naction on an irreducible Hermitian symmetric space of compact type.\nSpecifically, we examine the properties of these orbits as {\\it CR}\nsubmanifolds of a K\\\"{a}hler manifold. Our focus is on the leaves of the\ntotally real distribution, and we investigate the properties of leaves as a\nRiemannian submanifold. In particular, we prove that any leaf is a totally\ngeodesic submanifold of the orbit. Additionally, we explore the conditions\nunder which each leaf becomes a totally geodesic submanifold of the ambient\nspace. The integrability of the complex distribution is also studied. Moreover,\nwe analyze a contact structure of orbits where the rank of the totally real\ndistribution is 1. We obtain a classification of the orbits that possess either\na contact structure or a Sasakian structure compatible with the complex\nstructure on the ambient space. Furthermore, we classify those Sasaki orbits\nthat are Einstein with respect to the induced metric. Specifically, we\ncompletely detemine Sasaki-Einstein orbits.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T07:32:14Z"}
{"aid":"http://arxiv.org/abs/2504.10941v1","title":"Tidal interactions in stellar and planetary systems","summary":"Gravitational tidal interactions drive long-term rotational and orbital\nevolution in planetary systems, in multiple (particularly close binary) star\nsystems and in planetary moon systems. Dissipation of tidal flows in Earth's\noceans is primarily responsible for producing gradual expansion of the Moon's\norbit at a few centimetres per year as the Earth's day lengthens by a few\nmilliseconds per century. Similar processes occur in many astrophysical\nsystems. For example, tidal dissipation inside (slowly rotating) stars hosting\nshort-period planets can cause the orbits of these planets to decay,\npotentially leading to planetary destruction; tidal dissipation inside stars in\nclose stellar binary systems -- and inside short-period planets such as hot\nJupiters in planetary systems -- can cause initially eccentric orbits to become\ncircular. To model these processes, explain many current observational results,\nand make predictions for future observations, we require a detailed theoretical\nunderstanding of tidal flows and the mechanisms by which -- and how efficiently\n-- they are dissipated inside stars and planets. This article will introduce\nour current understanding of tidal flows and dissipation inside stars (and to a\nlesser extent giant planets), as well as highlight some unsolved problems.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T07:41:32Z"}
{"aid":"http://arxiv.org/abs/2504.10947v1","title":"Improved MST3 Encryption scheme based on small Ree groups","summary":"This article presents an encryption scheme based on the small Ree groups. We\npropose utilizing the small Ree group structure to enhance the overall security\nparameters of the encryption scheme. By extending the logarithmic signature to\nencompass the entire group and modifying the encryption algorithm, we have\ndeveloped robust protection against sequential key recovery attacks.","main_category":"cs.CR","categories":"cs.CR,math.GR","published":"2025-04-15T07:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10959v1","title":"Learning-Based User Association for MmWave Vehicular Networks With\n  Kernelized Contextual Bandits","summary":"Vehicles require timely channel conditions to determine the base station (BS)\nto communicate with, but it is costly to estimate the fast-fading mmWave\nchannels frequently. Without additional channel estimations, the proposed\nDistributed Kernelized Upper Confidence Bound (DK-UCB) algorithm estimates the\ncurrent instantaneous transmission rates utilizing past contexts, such as the\nvehicle's location and velocity, along with past instantaneous transmission\nrates. To capture the nonlinear mapping from a context to the instantaneous\ntransmission rate, DK-UCB maps a context into the reproducing kernel Hilbert\nspace (RKHS) where a linear mapping becomes observable. To improve estimation\naccuracy, we propose a novel kernel function in RKHS which incorporates the\npropagation characteristics of the mmWave signals. Moreover, DK-UCB encourages\na vehicle to share necessary information when it has conducted significant\nexplorations, which speeds up the learning process while maintaining affordable\ncommunication costs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T08:05:27Z"}
{"aid":"http://arxiv.org/abs/2504.10978v1","title":"AgentPolyp: Accurate Polyp Segmentation via Image Enhancement Agent","summary":"Since human and environmental factors interfere, captured polyp images\nusually suffer from issues such as dim lighting, blur, and overexposure, which\npose challenges for downstream polyp segmentation tasks. To address the\nchallenges of noise-induced degradation in polyp images, we present AgentPolyp,\na novel framework integrating CLIP-based semantic guidance and dynamic image\nenhancement with a lightweight neural network for segmentation. The agent first\nevaluates image quality using CLIP-driven semantic analysis (e.g., identifying\n``low-contrast polyps with vascular textures\") and adapts reinforcement\nlearning strategies to dynamically apply multi-modal enhancement operations\n(e.g., denoising, contrast adjustment). A quality assessment feedback loop\noptimizes pixel-level enhancement and segmentation focus in a collaborative\nmanner, ensuring robust preprocessing before neural network segmentation. This\nmodular architecture supports plug-and-play extensions for various enhancement\nalgorithms and segmentation networks, meeting deployment requirements for\nendoscopic devices.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-15T08:39:35Z"}
{"aid":"http://arxiv.org/abs/2504.10981v1","title":"X-ray polarization of accreting black holes: Cyg X-1 and Swift\n  J1727.8-1613","summary":"The Imaging X-ray Polarimetry Explorer is an X-ray observatory measuring the\nX-ray polarization in the 2-8 keV energy range. Highly sensitive to the\nsystem's geometry, X-ray polarization is a unique method to probe the structure\nof X-ray binaries. The Imaging X-ray Polarimetry Explorer observed the\nHigh-Mass X-ray Binary Cygnus X-1 and the Low-Mass X-ray Binary Swift\nJ1727.8-1613 in different accretion states: in the hard state and in the soft\nstate. The X-ray polarimetry analysis of both sources shows a linear\npolarization degree increasing with energy, with higher values in the hard\nstate than in the soft state. However, the linear polarization angle stays\nsimilar in both states and is aligned with the radio jet within $5^\\circ$.\nFurthermore, the Low-Mass X-ray Binary Swift J1727.8-1613 has a lower optical\nintrinsic polarization and a lower X-ray polarization degree for a softer\nspectrum. The similarities observed in this analysis between the X-ray\npolarization results of different types of X-ray Binaries show that the\ninnermost accretion processes are independent of the companion star's type.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T08:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.10993v1","title":"A broken Hardy inequality on finite element space and application to\n  strain gradient elasticity","summary":"We illustrate a broken Hardy inequality on discontinuous finite element\nspaces, blowing up with a logarithmic factor with respect to the meshes size.\nThis is motivated by numerical analysis for the strain gradient elasticity with\nnatural boundary conditions. A mixed finite element pair is employed to solve\nthis model with nearly incompressible materials. This pair is quasi-stable with\na logarithmic factor, which is not significant in the approximation error, and\nconverges robustly in the incompressible limit and uniformly in the microscopic\nmaterial parameter. Numerical results back up that the theoretical predictions\nare nearly optimal. Moreover, the regularity estimates for the model over a\nsmooth domain have been proved with the aid of the Agmon-Douglis-Nirenberg\ntheory.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T09:08:57Z"}
{"aid":"http://arxiv.org/abs/2504.11007v1","title":"Kubernetes in the Cloud vs. Bare Metal: A Comparative Study of Network\n  Costs","summary":"Modern cloud-native applications increasingly utilise managed cloud services\nand containerisation technologies, such as Kubernetes, to achieve rapid\ntime-to-market and scalable deployments. Organisations must consider various\nfactors, including cost implications when deciding on a hosting platform for\ncontainerised applications as the usage grows. An emerging discipline called\nFinOps combines financial management and cloud operations to optimise costs in\ncloud-based applications. While prior research has explored system-level\noptimisation strategies for cost and resource efficiency in containerized\nsystems, analysing network costs in Kubernetes clusters remains underexplored.\nThis paper investigates the network usage and cost implications of\ncontainerised applications running on Kubernetes clusters. Using a methodology\nthat combines measurement analysis, experimentation, and cost modelling, we aim\nto provide organisations with actionable insights into network cost\noptimisation. Our findings highlight key considerations for analysing network\nexpenditures and evaluating the potential cost benefits of deploying\napplications on cloud providers. Overall, this paper contributes to the\nemerging FinOps discipline by addressing the financial and operational aspects\nof managing network costs in cloud-native environments.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-15T09:26:08Z"}
{"aid":"http://arxiv.org/abs/2504.11017v1","title":"Floquet realization of prethermal Meissner phase in a two-leg flux\n  ladder","summary":"We show that a periodically driven two-leg flux ladder hosting interacting\nhardcore bosons exhibits a prethermal Meissner phase for large drive amplitudes\nand at special drive frequencies. Such a prethermal Meissner phase is\ncharacterized by a finite time-averaged chiral current. We find an analytic\nexpression of these frequencies using Floquet perturbation theory. Our analysis\nreveals that the presence of the prethermal Meissner phase is tied to the\nemergence of strong Hilbert space fragmentation in these driven ladders. We\nsupport our analytical results by numerical study of finite-size flux ladders\nusing exact diagonalization and discuss experiments using ultracold dipolar\natom platforms that may test our theory.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.other","published":"2025-04-15T09:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.11023v1","title":"An Inexact Variable Metric Proximal Gradient-subgradient Algorithm for a\n  Class of Fractional Optimization Problems","summary":"In this paper, we study a class of fractional optimization problems, in which\nthe numerator of the objective is the sum of a convex function and a\ndifferentiable function with a Lipschitz continuous gradient, while the\ndenominator is a nonsmooth convex function. This model has broad applicability\nand encompasses several important optimization problems in the literature. To\naddress these problems, we propose an inexact variable metric proximal\ngradient-subgradient algorithm (iVPGSA), which, to our knowledge, is the first\ninexact proximal algorithm specifically designed for solving such type of\nfractional problems. By incorporating a variable metric proximal term and\nallowing for inexact solutions to the subproblem under a flexible error\ncriterion, the proposed algorithm is highly adaptable to a broader range of\nproblems while achieving favorable computational efficiency. Under mild\nassumptions, we establish that any accumulation point of the sequence generated\nby the iVPGSA is a critical point of the target problem. Moreover, we develop\nan improved Kurdyka-{\\L}ojasiewicz (KL)-based analysis framework to prove the\nglobal convergence of the entire sequence and characterize its convergence\nrate, \\textit{without} requiring a strict sufficient descent property. Our\nresults offer detailed insights into how the KL exponent and inexactness\ninfluence the convergence rate. The proposed analysis framework also has the\npotential to serve as a theoretical tool for studying the convergence rates of\na wide range of inexact algorithms beyond the iVPGSA. Finally, some numerical\nexperiments on the $\\ell_1/\\ell_2$ Lasso problem and the constrained\n$\\ell_1/\\ell_2$ sparse optimization problem are conducted to show the superior\nperformance of the iVPGSA in comparison to existing algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.11032v1","title":"On Rigid Varieties Isogenous to a Product of Curves","summary":"In this note, we study rigid complex manifolds that are realized as quotients\nof a product of curves by a free action of a finite group. They serve as\nhigher-dimensional analogues of Beauville surfaces. Using uniformization, we\noutline the theory to characterize these manifolds through specific\ncombinatorial data associated with the group under the assumption that the\naction is diagonal and the manifold is of general type. This leads to the\nnotion of a $n$-fold Beauville structure. We define an action on the set of all\n$n$-fold Beauville structures of a given finite group that allows us to\ndistinguish the biholomorphism classes of the underlying rigid manifolds. As an\napplication, we give a classification of these manifolds with group $\\mathbb\nZ_5^2$ in the three dimensional case and prove that this is the smallest\npossible group that allows a rigid, free and diagonal action on a product of\nthree curves. In addition, we provide the classification of rigid 3-folds $X$\ngiven by a group acting faithfully on each factor for any value of the\nholomorphic Euler number $\\chi(\\mathcal O_X) \\geq -5$.","main_category":"math.AG","categories":"math.AG,math.CV,math.GR","published":"2025-04-15T09:54:58Z"}
{"aid":"http://arxiv.org/abs/2504.11063v1","title":"UKDM: Underwater keypoint detection and matching using underwater image\n  enhancement techniques","summary":"The purpose of this paper is to explore the use of underwater image\nenhancement techniques to improve keypoint detection and matching. By applying\nadvanced deep learning models, including generative adversarial networks and\nconvolutional neural networks, we aim to find the best method which improves\nthe accuracy of keypoint detection and the robustness of matching algorithms.\nWe evaluate the performance of these techniques on various underwater datasets,\ndemonstrating significant improvements over traditional methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T10:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.11107v1","title":"An Invariance Principle for some Reaction-Diffusion Equations with a\n  Multiplicative Random Source","summary":"We establish a notion of universality for the parabolic Anderson model via an\ninvariance principle for a wide family of parabolic stochastic partial\ndifferential equations. We then use this invariance principle in order to\nprovide an asymptotic theory for a wide class of non-linear SPDEs. A novel\ningredient of this invariance principle is the dissipativity of the underlying\nstochastic PDE.","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T11:55:05Z"}
{"aid":"http://arxiv.org/abs/2504.11120v1","title":"Improved approximation ratios for the Quantum Max-Cut problem on\n  general, triangle-free and bipartite graphs","summary":"We study polynomial-time approximation algorithms for the Quantum Max-Cut\n(QMC) problem. Given an edge-weighted graph $G$ on n vertices, the QMC problem\nis to determine the largest eigenvalue of a particular $2^n \\times 2^n$ matrix\nthat corresponds to $G$. We provide a sharpened analysis of the currently\nbest-known QMC approximation algorithm for general graphs. This algorithm\nachieves an approximation ratio of $0.599$, which our analysis improves to\n$0.603$. Additionally, we propose two new approximation algorithms for the QMC\nproblem on triangle-free and bipartite graphs, that achieve approximation\nratios of $0.61383$ and $0.8162$, respectively. These are the best-known\napproximation ratios for their respective graph classes.","main_category":"quant-ph","categories":"quant-ph,math.OC","published":"2025-04-15T12:08:07Z"}
{"aid":"http://arxiv.org/abs/2504.11126v1","title":"KubeFence: Security Hardening of the Kubernetes Attack Surface","summary":"Kubernetes (K8s) is widely used to orchestrate containerized applications,\nincluding critical services in domains such as finance, healthcare, and\ngovernment. However, its extensive and feature-rich API interface exposes a\nbroad attack surface, making K8s vulnerable to exploits of software\nvulnerabilities and misconfigurations. Even if K8s adopts role-based access\ncontrol (RBAC) to manage access to K8s APIs, this approach lacks the\ngranularity needed to protect specification attributes within API requests.\nThis paper proposes a novel solution, KubeFence, which implements finer-grain\nAPI filtering tailored to specific client workloads. KubeFence analyzes\nKubernetes Operators from trusted repositories and leverages their\nconfiguration files to restrict unnecessary features of the K8s API, to\nmitigate misconfigurations and vulnerabilities exploitable through the K8s API.\nThe experimental results show that KubeFence can significantly reduce the\nattack surface and prevent attacks compared to RBAC.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T12:15:34Z"}
{"aid":"http://arxiv.org/abs/2504.11153v1","title":"The interplay between Jahn-Teller distortions and structural degrees of\n  freedom on pseudocubic states in manganite perovskites","summary":"The average structure of the solid solution LaMn$_{1-x}$Ga$_x$O$_3$ (LMGO)\nhas been investigated from a symmetry-motivated approach utilizing synchrotron\nx-ray and neutron powder diffraction techniques. We show experimentally that a\ntrilinear coupling term ($\\Gamma_5^+$M$_2^+$M$_3^+$) between shear strain,\noctahedral rotation, and the $C$-type orbital ordering mode is responsible for\ndriving the orthorhombic to pseudocubic phase transition occurring in the\ncomposition range 0.5 $<$ $x$ $<$ 0.6. Our Monte Carlo simulations elucidate\nthe macroscopic origin of this coupling to shear strain, and point to its\nimportance with respect to controlling the orbital order-disorder transitions.\nWe find that the emergence of the pseudocubic state can be rationalized by\nconsidering the competition between this trilinear term and a linear-quadratic\nterm of the out-of-phase octahedral tilting with strain\n($\\Gamma_5^+$(R$_5^-$)$^2$). Illustrating the general nature of these results,\nwe construct a simple function that captures the change in Landau free energy\nat the order-disorder transition, in parameters that are trivial to relate to\nthe concentration of Jahn--Teller active species, temperature, tolerance factor\nand unit cell strain, for a broad range of manganite perovskites. Our results\npoint to the fact that far from the pseudocubic state being a symptom of\norbital disorder, it is in many cases more correctly to view it as a cause. The\nresults have a broad impact on the study of orbital ordering physics in the\nperovskite materials and on chemical and physical control parameters through\nwhich to tune the richness of the intertwined physical properties.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T12:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.11178v1","title":"MeerKAT 1.3 GHz Observations Towards the Milky Way Bulge","summary":"We present a MeerKAT survey of portions of the Milky Way bulge. The survey\ncovers 172.8 square degrees in two contiguous mosaics above and below the\nGalactic Center as well as 32 single pointing fields at higher longitudes. The\nresolution of the images is $\\sim$8\\asec\\ at a frequency of 1333 MHz with a\ntypical Stokes I RMS of 20 $\\mu$Jy Beam$^{-1}$. Most of the emission seen is\nfrom background extragalactic sources but many compact Galactic objects are\nidentifiable by their polarization properties. Apparent polarized emission\nresulting from fine scale Faraday rotation in the ISM is widespread in this\nregion of the Galaxy. The survey is used to search for background Giant Radio\nGalaxies, $>$700 kpc in size, identifying 17 such objects. Data products\ninclude FITS images of Stokes I, Q, U and V as well as a Faraday analysis and\nlists of compact total intensity and polarized sources.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T13:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.11199v1","title":"Video Summarization with Large Language Models","summary":"The exponential increase in video content poses significant challenges in\nterms of efficient navigation, search, and retrieval, thus requiring advanced\nvideo summarization techniques. Existing video summarization methods, which\nheavily rely on visual features and temporal dynamics, often fail to capture\nthe semantics of video content, resulting in incomplete or incoherent\nsummaries. To tackle the challenge, we propose a new video summarization\nframework that leverages the capabilities of recent Large Language Models\n(LLMs), expecting that the knowledge learned from massive data enables LLMs to\nevaluate video frames in a manner that better aligns with diverse semantics and\nhuman judgments, effectively addressing the inherent subjectivity in defining\nkeyframes. Our method, dubbed LLM-based Video Summarization (LLMVS), translates\nvideo frames into a sequence of captions using a Muti-modal Large Language\nModel (M-LLM) and then assesses the importance of each frame using an LLM,\nbased on the captions in its local context. These local importance scores are\nrefined through a global attention mechanism in the entire context of video\ncaptions, ensuring that our summaries effectively reflect both the details and\nthe overarching narrative. Our experimental results demonstrate the superiority\nof the proposed method over existing ones in standard benchmarks, highlighting\nthe potential of LLMs in the processing of multimedia content.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:56:14Z"}
{"aid":"http://arxiv.org/abs/2504.11229v1","title":"The Forward-Forward Algorithm: Characterizing Training Behavior","summary":"The Forward-Forward algorithm is an alternative learning method which\nconsists of two forward passes rather than a forward and backward pass employed\nby backpropagation. Forward-Forward networks employ layer local loss functions\nwhich are optimized based on the layer activation for each forward pass rather\nthan a single global objective function. This work explores the dynamics of\nmodel and layer accuracy changes in Forward-Forward networks as training\nprogresses in pursuit of a mechanistic understanding of their internal\nbehavior. Treatments to various system characteristics are applied to\ninvestigate changes in layer and overall model accuracy as training progresses,\nhow accuracy is impacted by layer depth, and how strongly individual layer\naccuracy is correlated with overall model accuracy. The empirical results\npresented suggest that layers deeper within Forward-Forward networks experience\na delay in accuracy improvement relative to shallower layers and that shallower\nlayer accuracy is strongly correlated with overall model accuracy.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T14:30:18Z"}
{"aid":"http://arxiv.org/abs/2504.11231v1","title":"Emergent Magnetic Structures at the 2D Limit of the Altermagnet MnTe","summary":"MnTe has recently emerged as a canonical altermagnet, a newly identified\nclass of magnetism characterized by compensated antiferromagnetic order\ncoexisting with spin-split electronic bands, traditionally considered exclusive\nto ferromagnets. However, the extent to which altermagnetism persists as\naltermagnets are thinned to the two-dimensional (2D) limit remains unexplored.\nHere, we investigate the magnetic behaviour of 2D MnTe, specifically\natomically-thin monolayers (MLs) and bilayers (BLs) grown on graphene/Ir(111)\nsubstrate, by combining experimental scanning tunneling microscopy, x-ray\nphotoelectron spectroscopy, x-ray absorption spectroscopy and x-ray magnetic\ncircular dichroism with density functional theory calculations. We find that\nwhile ML and BL MnTe adopt atomic structures with symmetries incompatible with\naltermagnetism, they exhibit intriguing magnetic phases: the BL forms a\nhighly-robust layered antiferromagnet with in-plane spin anisotropy, whereas\nthe ML exhibits a spin-glass-like behavior below its freezing temperature, a\nphenomenon not previously observed in an atomically thin material. These\nfindings highlight how reduced dimensionality can promote the emergence of\nunusual magnetic structures distinct from those of their three-dimensional\ncounterparts, providing new insights into low-dimensional magnetism.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-15T14:30:28Z"}
{"aid":"http://arxiv.org/abs/2504.11239v1","title":"Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling\n  Reasoning Benchmark for LLMs","summary":"Reasoning is the fundamental capability of large language models (LLMs). Due\nto the rapid progress of LLMs, there are two main issues of current benchmarks:\ni) these benchmarks can be crushed in a short time (less than 1 year), and ii)\nthese benchmarks may be easily hacked. To handle these issues, we propose the\never-scalingness for building the benchmarks which are uncrushable, unhackable,\nauto-verifiable and general. This paper presents Nondeterministic\nPolynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark\nfor LLMs. Specifically, the NPPC has three main modules: i) npgym, which\nprovides a unified interface of 25 well-known NP-complete problems and can\ngenerate any number of instances with any levels of complexities, ii) npsolver:\nwhich provides a unified interface to evaluate the problem instances with both\nonline and offline models via APIs and local deployments, respectively, and\niii) npeval: which provides the comprehensive and ready-to-use tools to analyze\nthe performances of LLMs over different problems, the number of tokens, the aha\nmoments, the reasoning errors and the solution errors. Extensive experiments\nover widely-used LLMs demonstrate: i) NPPC can successfully decrease the\nperformances of advanced LLMs' performances to below 10%, demonstrating that\nNPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the\nmost powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and\no1/o3-mini in most NP-complete problems considered, and iii) the numbers of\ntokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and\nDeepSeek-R1, are observed first to increase and then decrease when the problem\ninstances become more and more difficult. We believe that NPPC is the first\never-scaling reasoning benchmark, serving as the uncrushable and unhackable\ntestbed for LLMs toward artificial general intelligence (AGI).","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-15T14:40:29Z"}
{"aid":"http://arxiv.org/abs/2504.11242v1","title":"Measurement of the g factor of ground-state 87Sr at the\n  parts-per-million level using co-trapped ultracold atoms","summary":"We demonstrate nuclear magnetic resonance of optically trapped ground-state\nultracold 87Sr atoms. Using a scheme in which a cloud of ultracold 87Rb is\nco-trapped nearby, we improve the determination of the nuclear g factor, gI ,\nof atomic 87Sr by more than two orders of magnitude, reaching accuracy at the\nparts-per-million level. We achieve similar accuracy in the ratio of relevant g\nfactors between Rb and Sr. This establishes ultracold 87Sr as an excellent\nlinear in-vacuum magnetometer. These results are relevant for ongoing efforts\ntowards quantum simulation, quantum computation and optical atomic clocks\nemploying 87Sr, and these methods can also be applied to other alkaline-earth\nand alkaline-earth-like atoms.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-15T14:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.11281v1","title":"The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to\n  Fine-Print Injections","summary":"A Large Language Model (LLM) powered GUI agent is a specialized autonomous\nsystem that performs tasks on the user's behalf according to high-level\ninstructions. It does so by perceiving and interpreting the graphical user\ninterfaces (GUIs) of relevant apps, often visually, inferring necessary\nsequences of actions, and then interacting with GUIs by executing the actions\nsuch as clicking, typing, and tapping. To complete real-world tasks, such as\nfilling forms or booking services, GUI agents often need to process and act on\nsensitive user data. However, this autonomy introduces new privacy and security\nrisks. Adversaries can inject malicious content into the GUIs that alters agent\nbehaviors or induces unintended disclosures of private information. These\nattacks often exploit the discrepancy between visual saliency for agents and\nhuman users, or the agent's limited ability to detect violations of contextual\nintegrity in task automation. In this paper, we characterized six types of such\nattacks, and conducted an experimental study to test these attacks with six\nstate-of-the-art GUI agents, 234 adversarial webpages, and 39 human\nparticipants. Our findings suggest that GUI agents are highly vulnerable,\nparticularly to contextually embedded threats. Moreover, human users are also\nsusceptible to many of these attacks, indicating that simple human oversight\nmay not reliably prevent failures. This misalignment highlights the need for\nprivacy-aware agent design. We propose practical defense strategies to inform\nthe development of safer and more reliable GUI agents.","main_category":"cs.HC","categories":"cs.HC,cs.CL,cs.CR","published":"2025-04-15T15:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.11307v1","title":"Uncertainty Estimation for Trust Attribution to Speed-of-Sound\n  Reconstruction with Variational Networks","summary":"Speed-of-sound (SoS) is a biomechanical characteristic of tissue, and its\nimaging can provide a promising biomarker for diagnosis. Reconstructing SoS\nimages from ultrasound acquisitions can be cast as a limited-angle\ncomputed-tomography problem, with Variational Networks being a promising\nmodel-based deep learning solution. Some acquired data frames may, however, get\ncorrupted by noise due to, e.g., motion, lack of contact, and acoustic shadows,\nwhich in turn negatively affects the resulting SoS reconstructions. We propose\nto use the uncertainty in SoS reconstructions to attribute trust to each\nindividual acquired frame. Given multiple acquisitions, we then use an\nuncertainty based automatic selection among these retrospectively, to improve\ndiagnostic decisions. We investigate uncertainty estimation based on Monte\nCarlo Dropout and Bayesian Variational Inference. We assess our automatic frame\nselection method for differential diagnosis of breast cancer, distinguishing\nbetween benign fibroadenoma and malignant carcinoma. We evaluate 21 lesions\nclassified as BI-RADS~4, which represents suspicious cases for probable\nmalignancy. The most trustworthy frame among four acquisitions of each lesion\nwas identified using uncertainty based criteria. Selecting a frame informed by\nuncertainty achieved an area under curve of 76% and 80% for Monte Carlo Dropout\nand Bayesian Variational Inference, respectively, superior to any\nuncertainty-uninformed baselines with the best one achieving 64%. A novel use\nof uncertainty estimation is proposed for selecting one of multiple data\nacquisitions for further processing and decision making.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:48:51Z"}
{"aid":"http://arxiv.org/abs/2504.11319v1","title":"Sensitivity Analysis of State Space Models for Scrap Composition\n  Estimation in EAF and BOF","summary":"This study develops and analyzes linear and nonlinear state space models for\nestimating the elemental composition of scrap steel used in steelmaking, with\napplications to Electric Arc Furnace (EAF) and Basic Oxygen Furnace (BOF)\nprocesses. The models incorporate mass balance equations and are fitted using a\nmodified Kalman filter for linear cases and the Unscented Kalman Filter (UKF)\nfor nonlinear cases. Using Cu and Cr as representative elements, we assess the\nsensitivity of model predictions to measurement noise in key process variables,\nincluding steel mass, steel composition, scrap input mass, slag mass, and iron\noxide fraction in slag. Results show that the models are robust to moderate\nnoise levels in most variables, particularly when errors are below $10\\%$.\nHowever, accuracy significantly deteriorates with noise in slag mass\nestimation. These findings highlight the practical feasibility and limitations\nof applying state space models for real-time scrap composition estimation in\nindustrial settings.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T15:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.11329v1","title":"Hunting for Maxwell's Demon in the Wild","summary":"The apparent paradox of Maxwell's demon motivated the development of\ninformation thermodynamics and, more recently, engineering advances enabling\nthe creation of nanoscale information engines. From these advances, it is now\nunderstood that nanoscale machines like the molecular motors within cells can\nin principle operate as Maxwell demons. This motivates the question: does\ninformation help power molecular motors? Answering this would seemingly require\nsimultaneous measurement of all system degrees of freedom, which is generally\nintractable in single-molecule experiments. To overcome this limitation, we\nderive a statistical estimator to infer both the direction and magnitude of\nsubsystem heat flows, and thus to determine whether -- and how strongly -- a\nmotor operates as a Maxwell demon. The estimator uses only trajectory\nmeasurements for a single degree of freedom. We demonstrate the estimator by\napplying it to simulations of an experimental realization of an information\nengine and a kinesin molecular motor. Our results show that kinesin transitions\nto a Maxwell-demon mechanism in the presence of nonequilibrium noise, with a\ncorresponding increase in velocity consistent with experiments. These findings\nsuggest that molecular motors may have evolved to leverage active fluctuations\nwithin cells.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,physics.bio-ph","published":"2025-04-15T16:03:10Z"}
{"aid":"http://arxiv.org/abs/2504.11331v1","title":"Dependency Structure Augmented Contextual Scoping Framework for\n  Multimodal Aspect-Based Sentiment Analysis","summary":"Multimodal Aspect-Based Sentiment Analysis (MABSA) seeks to extract\nfine-grained information from image-text pairs to identify aspect terms and\ndetermine their sentiment polarity. However, existing approaches often fall\nshort in simultaneously addressing three core challenges: Sentiment Cue\nPerception (SCP), Multimodal Information Misalignment (MIM), and Semantic Noise\nElimination (SNE). To overcome these limitations, we propose DASCO\n(\\textbf{D}ependency Structure \\textbf{A}ugmented \\textbf{Sco}ping Framework),\na fine-grained scope-oriented framework that enhances aspect-level sentiment\nreasoning by leveraging dependency parsing trees. First, we designed a\nmulti-task pretraining strategy for MABSA on our base model, combining\naspect-oriented enhancement, image-text matching, and aspect-level\nsentiment-sensitive cognition. This improved the model's perception of aspect\nterms and sentiment cues while achieving effective image-text alignment,\naddressing key challenges like SCP and MIM. Furthermore, we incorporate\ndependency trees as syntactic branch combining with semantic branch, guiding\nthe model to selectively attend to critical contextual elements within a\ntarget-specific scope while effectively filtering out irrelevant noise for\naddressing SNE problem. Extensive experiments on two benchmark datasets across\nthree subtasks demonstrate that DASCO achieves state-of-the-art performance in\nMABSA, with notable gains in JMASA (+3.1\\% F1 and +5.4\\% precision on\nTwitter2015).","main_category":"cs.CL","categories":"cs.CL,cs.MM","published":"2025-04-15T16:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.11380v1","title":"Speak with Confidence: Designing an Augmented Reality Training Tool for\n  Public Speaking","summary":"Public speaking anxiety affects many individuals, yet opportunities for\nreal-world practice remain limited. This study explores how augmented reality\n(AR) can provide an accessible training environment for public speaking.\nDrawing from literature on public speaking, VR-based training, self-efficacy,\nand behavioral feedback mechanisms, we designed SpeakAR, an AR-based tool that\nsimulates audience interaction through virtual models. SpeakAR was evaluated\nwith five participants of varying anxiety levels, each completing six speaking\ntasks. Results indicate that AR exposure can enhance confidence, with\nparticipants finding the system useful for practice. Feedback highlighted the\nimportance of dynamic facial expressions and idle animations in virtual models\nto improve realism and engagement. Our findings contribute to the design of\nAR-based training tools for public speaking, offering insights into how\nimmersive environments can support skill development and anxiety reduction.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-15T16:53:30Z"}
{"aid":"http://arxiv.org/abs/2504.11409v1","title":"Efficient Hybrid Language Model Compression through Group-Aware SSM\n  Pruning","summary":"Hybrid LLM architectures that combine Attention and State Space Models (SSMs)\nachieve state-of-the-art accuracy and runtime performance. Recent work has\ndemonstrated that applying compression and distillation to Attention-only\nmodels yields smaller, more accurate models at a fraction of the training cost.\nIn this work, we explore the effectiveness of compressing Hybrid architectures.\nWe introduce a novel group-aware pruning strategy that preserves the structural\nintegrity of SSM blocks and their sequence modeling capabilities. Furthermore,\nwe demonstrate the necessity of such SSM pruning to achieve improved accuracy\nand inference speed compared to traditional approaches. Our compression recipe\ncombines SSM, FFN, embedding dimension, and layer pruning, followed by\nknowledge distillation-based retraining, similar to the MINITRON technique.\nUsing this approach, we compress the Nemotron-H 8B Hybrid model down to 4B\nparameters with up to 40x fewer training tokens. The resulting model surpasses\nthe accuracy of similarly-sized models while achieving 2x faster inference,\nsignificantly advancing the Pareto frontier.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T17:26:29Z"}
{"aid":"http://arxiv.org/abs/2504.11443v1","title":"Early Impacts of M365 Copilot","summary":"Advances in generative AI have rapidly expanded the potential of computers to\nperform or assist in a wide array of tasks traditionally performed by humans.\nWe analyze a large, real-world randomized experiment of over 6,000 workers at\n56 firms to present some of the earliest evidence on how these technologies are\nchanging the way knowledge workers do their jobs. We find substantial time\nsavings on common core tasks across a wide range of industries and occupations:\nworkers who make use of this technology spent half an hour less reading email\neach week and completed documents 12% faster. Despite the newness of the\ntechnology, nearly 40% of workers who were given access to the tool used it\nregularly in their work throughout the 6-month study.","main_category":"econ.GN","categories":"econ.GN,cs.LG,q-fin.EC","published":"2025-04-15T17:55:32Z"}
{"aid":"http://arxiv.org/abs/2504.11448v1","title":"Full-Diversity Construction-D Lattices: Design and Decoding Perspective\n  on Block-Fading Channels","summary":"This paper introduces a novel framework for constructing algebraic lattices\nbased on Construction-D, leveraging nested linear codes and prime ideals from\nalgebraic number fields. We focus on the application of these lattices in\nblock-fading (BF) channels, which are characterized by piecewise-constant\nfading across blocks of transmitted symbols. This approach results in a\nsemi-systematic generator matrix, providing a structured foundation for\nhigh-dimensional lattice design for BF channels. The proposed Construction-D\nlattices exhibit the full diversity property, making them highly effective for\nerror performance improvement. To address this, we develop an efficient\ndecoding algorithm designed specifically for full-diversity Construction-D\nlattices.\n  Simulations indicate that the proposed lattices notably enhance error\nperformance compared to full-diversity Construction-A lattices in diversity-2\ncases. Interestingly, unlike AWGN channels, the expected performance\nenhancement of Construction-D over Construction-A, resulting from an increased\nnumber of nested code levels, was observed only in the two-level and\ndiversity-2 cases. This phenomenon is likely attributed to the intensified\neffects of error propagation that occur during successive cancellation at\nhigher levels, as well as the higher diversity orders.\n  These findings highlight the promise of Construction-D lattices as an\neffective coding strategy for enhancing communication reliability in BF\nchannels.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-15T17:57:56Z"}
{"aid":"http://arxiv.org/abs/2504.11456v1","title":"DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and\n  Verifiable Mathematical Dataset for Advancing Reasoning","summary":"The capacity for complex mathematical reasoning is a key benchmark for\nartificial intelligence. While reinforcement learning (RL) applied to LLMs\nshows promise, progress is significantly hindered by the lack of large-scale\ntraining data that is sufficiently challenging, possesses verifiable answer\nformats suitable for RL, and is free from contamination with evaluation\nbenchmarks. To address these limitations, we introduce DeepMath-103K, a new,\nlarge-scale dataset comprising approximately 103K mathematical problems,\nspecifically designed to train advanced reasoning models via RL. DeepMath-103K\nis curated through a rigorous pipeline involving source analysis, stringent\ndecontamination against numerous benchmarks, and filtering for high difficulty\n(primarily Levels 5-9), significantly exceeding existing open resources in\nchallenge. Each problem includes a verifiable final answer, enabling rule-based\nRL, and three distinct R1-generated solutions suitable for diverse training\nparadigms like supervised fine-tuning or distillation. Spanning a wide range of\nmathematical topics, DeepMath-103K promotes the development of generalizable\nreasoning. We demonstrate that models trained on DeepMath-103K achieve\nsignificant improvements on challenging mathematical benchmarks, validating its\neffectiveness. We release DeepMath-103K publicly to facilitate community\nprogress in building more capable AI reasoning systems:\nhttps://github.com/zwhe99/DeepMath.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.11752v1","title":"Real-Time Reconstruction of Ground Motion During Small Magnitude\n  Earthquakes: A Pilot Study","summary":"This study presents a pilot investigation into a novel method for\nreconstructing real-time ground motion during small magnitude earthquakes (M <\n4.5), removing the need for computationally expensive source characterization\nand simulation processes to assess ground shaking. Small magnitude earthquakes,\nwhich occur frequently and can be modeled as point sources, provide ideal\nconditions for evaluating real-time reconstruction methods. Utilizing sparse\nobservation data, the method applies the Gappy Auto-Encoder (Gappy AE)\nalgorithm for efficient field data reconstruction. This is the first study to\napply the Gappy AE algorithm to earthquake ground motion reconstruction.\nNumerical experiments conducted with SW4 simulations demonstrate the method's\naccuracy and speed across varying seismic scenarios. The reconstruction\nperformance is further validated using real seismic data from the Berkeley area\nin California, USA, demonstrating the potential for practical application of\nreal-time earthquake data reconstruction using Gappy AE. As a pilot\ninvestigation, it lays the groundwork for future applications to larger and\nmore complex seismic events.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-16T04:06:50Z"}
{"aid":"http://arxiv.org/abs/2504.11757v1","title":"Dynamics and Computational Principles of Echo State Networks: A\n  Mathematical Perspective","summary":"Reservoir computing (RC) represents a class of state-space models (SSMs)\ncharacterized by a fixed state transition mechanism (the reservoir) and a\nflexible readout layer that maps from the state space. It is a paradigm of\ncomputational dynamical systems that harnesses the transient dynamics of\nhigh-dimensional state spaces for efficient processing of temporal data. Rooted\nin concepts from recurrent neural networks, RC achieves exceptional\ncomputational power by decoupling the training of the dynamic reservoir from\nthe linear readout layer, thereby circumventing the complexities of\ngradient-based optimization. This work presents a systematic exploration of RC,\naddressing its foundational properties such as the echo state property, fading\nmemory, and reservoir capacity through the lens of dynamical systems theory. We\nformalize the interplay between input signals and reservoir states,\ndemonstrating the conditions under which reservoirs exhibit stability and\nexpressive power. Further, we delve into the computational trade-offs and\nrobustness characteristics of RC architectures, extending the discussion to\ntheir applications in signal processing, time-series prediction, and control\nsystems. The analysis is complemented by theoretical insights into\noptimization, training methodologies, and scalability, highlighting open\nchallenges and potential directions for advancing the theoretical underpinnings\nof RC.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-16T04:28:05Z"}
{"aid":"http://arxiv.org/abs/2504.11773v1","title":"TacoDepth: Towards Efficient Radar-Camera Depth Estimation with\n  One-stage Fusion","summary":"Radar-Camera depth estimation aims to predict dense and accurate metric depth\nby fusing input images and Radar data. Model efficiency is crucial for this\ntask in pursuit of real-time processing on autonomous vehicles and robotic\nplatforms. However, due to the sparsity of Radar returns, the prevailing\nmethods adopt multi-stage frameworks with intermediate quasi-dense depth, which\nare time-consuming and not robust. To address these challenges, we propose\nTacoDepth, an efficient and accurate Radar-Camera depth estimation model with\none-stage fusion. Specifically, the graph-based Radar structure extractor and\nthe pyramid-based Radar fusion module are designed to capture and integrate the\ngraph structures of Radar point clouds, delivering superior model efficiency\nand robustness without relying on the intermediate depth results. Moreover,\nTacoDepth can be flexible for different inference modes, providing a better\nbalance of speed and accuracy. Extensive experiments are conducted to\ndemonstrate the efficacy of our method. Compared with the previous\nstate-of-the-art approach, TacoDepth improves depth accuracy and processing\nspeed by 12.8% and 91.8%. Our work provides a new perspective on efficient\nRadar-Camera depth estimation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:25:04Z"}
{"aid":"http://arxiv.org/abs/2504.11782v1","title":"HyperKING: Quantum-Classical Generative Adversarial Networks for\n  Hyperspectral Image Restoration","summary":"Quantum machine intelligence starts showing its impact on satellite remote\nsensing (SRS). Also, recent literature exhibits that quantum generative\nintelligences encompass superior potential than their classical counterpart,\nmotivating us to develop quantum generative adversarial networks (GANs) for\nSRS. However, existing quantum GANs are restricted by the limited quantum bit\n(qubit) resources of current quantum computers and process merely a small 2x2\ngrayscale image, far from being applicable to SRS. Recently, the novel concept\nof hybrid quantum-classical GAN, a quantum generator with a classical\ndiscriminator, has upgraded the order to 28x28 (still grayscale), whereas it is\nstill insufficient for SRS. This motivates us to design a radically new hybrid\nframework, where both generator and discriminator are hybrid architectures. We\ndemonstrate this feasibility, leading to a breakthrough of processing 128x128\nhyperspectral images for SRS. Specifically, we design the quantum part with\nmathematically provable quantum full expressibility (FE) to address core signal\nprocessing tasks, wherein the FE property allows the quantum network to realize\nany valid quantum operator with appropriate training. The classical part,\ncomposed of convolutional layers, treats the read-in (compressing the optical\ninformation into limited qubits) and read-out (addressing the quantum collapse\neffect) procedures. The proposed innovative hybrid quantum GAN, named\nHyperspectral Knot-like IntelligeNt dIscrimiNator and Generator (HyperKING),\nwhere knot partly symbolizes the quantum entanglement and partly the compressed\nquantum domain in the central part of the network architecture. HyperKING\nsignificantly surpasses the classical approaches in hyperspectral tensor\ncompletion, mixed noise removal (about 3dB improvement), and blind source\nseparation results.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-16T05:35:06Z"}
{"aid":"http://arxiv.org/abs/2504.11796v1","title":"Efficient spin-orbit torque driven magnetization switching of GdFe using\n  phosphorus-implanted platinum layers","summary":"The capability of the spin-orbit torque (SOT) generated via phenomena such as\nthe spin Hall effect in heavy metals, in switching the magnetization of an\nadjacent magnetic material, has been studied extensively over the last decade.\nThe efficiency of SOT generation is commonly quantified in terms of the spin\nHall angle {\\theta}_SH. In this work, we demonstrate experimentally that\nimplanting platinum (Pt) with phosphorus (P), resulting in Pt (P) d, where d\ndenotes the implantation dose, increases {\\theta}_SH by a factor of 7, from\n0.06 (d = 0) to 0.43 (d = 10*10^16 ions/cm^2). The enhanced {\\theta}_SH, along\nwith factors such as perpendicular magnetic anisotropy and resistivity, lead to\nreduction of the critical current density for switching the perpendicular\nmagnetization of ferrimagnetic rare earth-transition metal alloy Gd26Fe74, by a\nfactor of nearly 27, from 4.0*1011 A/m^2 (d = 0) to 1.5*10^10 A/m^2 (d =\n10*10^16 ions/cm^2). Further, the switching current density at zero thermal\nfluctuations and thermal stability factor were evaluated and found to be\n2.0*10^10 A/m^2 and 61.4 (d = 10*10^16 ions/cm^2), with the latter being\nsufficiently above the required threshold for commercial memory applications.\nOur results suggest that Pt (P) could be a strong candidate in realizing\nefficient SOT driven magnetization switching leading to the development of\nimproved memory and logic devices in the future.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-16T06:03:53Z"}
{"aid":"http://arxiv.org/abs/2504.11800v1","title":"The \"Little Dark Dot\": Evidence for Self-Interacting Dark Matter in the\n  Strong Lens SDSSJ0946+1006?","summary":"Previous studies, based on precise modeling of a gravitationally lensing\nimage, have identified what may be a extremely compact, dark perturber in the\nwell-known lensing system SDSSJ0946+1006 (the \"Jackpot\"). Its remarkable\ncompactness challenges the standard cold dark matter (CDM) paradigm. In this\npaper, we explore whether such a compact perturber could be explained as a\ncore-collapsed halo described by the self-interacting dark matter (SIDM) model.\nUsing the isothermal Jeans method, we compute the density profiles of\ncore-collapsed halos across a range of masses. Our comparison with observations\nindicates that only a core-collapsed halo with a total mass of approximately\n$10^{11}~{\\rm M_{\\odot}}$ could produce an inner density profile and mass\nenclosed within 1 kpc that is consistent with observational data. However, such\na massive dark matter halo should host a galaxy detectable by prior Hubble\nimaging, which is not observed. Thus, the core-collapsed SIDM halo model\nstruggles to fully account for the exotic nature of the \"little dark dot\" in\nthe \"Jackpot\" lens.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-16T06:16:51Z"}
{"aid":"http://arxiv.org/abs/2504.11852v1","title":"A presentation of the pure cactus group of degree four","summary":"We give a simple presentation of the pure cactus group $PJ_4$ of degree four.\nThis presentation is obtained by considering an action of $PJ_4$ on the\nhyperbolic plane and constructing a Dirichlet polygon for the action. As a\ncorollary, we provide a direct alternative proof that $PJ_4$ is isomorphic to\nthe fundamental group of the connected sum of five real projective planes.","main_category":"math.GR","categories":"math.GR,math.GT","published":"2025-04-16T08:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.11879v1","title":"Learning Compatible Multi-Prize Subnetworks for Asymmetric Retrieval","summary":"Asymmetric retrieval is a typical scenario in real-world retrieval systems,\nwhere compatible models of varying capacities are deployed on platforms with\ndifferent resource configurations. Existing methods generally train pre-defined\nnetworks or subnetworks with capacities specifically designed for\npre-determined platforms, using compatible learning. Nevertheless, these\nmethods suffer from limited flexibility for multi-platform deployment. For\nexample, when introducing a new platform into the retrieval systems, developers\nhave to train an additional model at an appropriate capacity that is compatible\nwith existing models via backward-compatible learning. In this paper, we\npropose a Prunable Network with self-compatibility, which allows developers to\ngenerate compatible subnetworks at any desired capacity through post-training\npruning. Thus it allows the creation of a sparse subnetwork matching the\nresources of the new platform without additional training. Specifically, we\noptimize both the architecture and weight of subnetworks at different\ncapacities within a dense network in compatible learning. We also design a\nconflict-aware gradient integration scheme to handle the gradient conflicts\nbetween the dense network and subnetworks during compatible learning. Extensive\nexperiments on diverse benchmarks and visual backbones demonstrate the\neffectiveness of our method. Our code and model are available at\nhttps://github.com/Bunny-Black/PrunNet.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T08:59:47Z"}
{"aid":"http://arxiv.org/abs/2504.11895v1","title":"Search is All You Need for Few-shot Anomaly Detection","summary":"Few-shot anomaly detection (FSAD) has emerged as a crucial yet challenging\ntask in industrial inspection, where normal distribution modeling must be\naccomplished with only a few normal images. While existing approaches typically\nemploy multi-modal foundation models combining language and vision modalities\nfor prompt-guided anomaly detection, these methods often demand sophisticated\nprompt engineering and extensive manual tuning. In this paper, we demonstrate\nthat a straightforward nearest-neighbor search framework can surpass\nstate-of-the-art performance in both single-class and multi-class FSAD\nscenarios. Our proposed method, VisionAD, consists of four simple yet essential\ncomponents: (1) scalable vision foundation models that extract universal and\ndiscriminative features; (2) dual augmentation strategies - support\naugmentation to enhance feature matching adaptability and query augmentation to\naddress the oversights of single-view prediction; (3) multi-layer feature\nintegration that captures both low-frequency global context and high-frequency\nlocal details with minimal computational overhead; and (4) a class-aware visual\nmemory bank enabling efficient one-for-all multi-class detection. Extensive\nevaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrate\nVisionAD's exceptional performance. Using only 1 normal images as support, our\nmethod achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8%\nrespectively, outperforming current state-of-the-art approaches by significant\nmargins (+1.6%, +3.2%, and +1.4%). The training-free nature and superior\nfew-shot capabilities of VisionAD make it particularly appealing for real-world\napplications where samples are scarce or expensive to obtain. Code is available\nat https://github.com/Qiqigeww/VisionAD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T09:21:34Z"}
{"aid":"http://arxiv.org/abs/2504.11919v1","title":"Rethinking the Generation of High-Quality CoT Data from the Perspective\n  of LLM-Adaptive Question Difficulty Grading","summary":"Recently, DeepSeek-R1 (671B) (DeepSeek-AIet al., 2025) has demonstrated its\nexcellent reasoning ability in complex tasks and has publiclyshared its\nmethodology. This provides potentially high-quality chain-of-thought (CoT) data\nfor stimulating the reasoning abilities of small-sized large language models\n(LLMs). To generate high-quality CoT data for different LLMs, we seek an\nefficient method for generating high-quality CoT data with LLM-Adaptive\nquestiondifficulty levels. First, we grade the difficulty of the questions\naccording to the reasoning ability of the LLMs themselves and construct a\nLLM-Adaptive question database. Second, we sample the problem database based on\na distribution of difficulty levels of the questions and then use DeepSeek-R1\n(671B) (DeepSeek-AI et al., 2025) to generate the corresponding high-quality\nCoT data with correct answers. Thanks to the construction of CoT data with\nLLM-Adaptive difficulty levels, we have significantly reduced the cost of data\ngeneration and enhanced the efficiency of model supervised fine-tuning (SFT).\nFinally, we have validated the effectiveness and generalizability of the\nproposed method in the fields of complex mathematical competitions and code\ngeneration tasks. Notably, with only 2k high-quality mathematical CoT data, our\nZMath-32B surpasses DeepSeek-Distill-32B in math reasoning task. Similarly,\nwith only 2k high-quality code CoT data, our ZCode-32B surpasses\nDeepSeek-Distill-32B in code reasoning tasks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T09:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.11933v1","title":"Lifelong and Universal Machine Learning Potentials for Chemical Reaction\n  Network Explorations","summary":"Recent developments in computational chemistry facilitate the automated\nquantum chemical exploration of chemical reaction networks for the in-silico\nprediction of synthesis pathways, yield, and selectivity. However, the\nunderlying quantum chemical energy calculations require vast computational\nresources, limiting these explorations severely in practice. Machine learning\npotentials (MLPs) offer a solution to increase computational efficiency, while\nretaining the accuracy of reliable first-principles data used for their\ntraining. Unfortunately, MLPs will be limited in their generalization ability\nwithin chemical (reaction) space, if the underlying training data is not\nrepresentative for a given application. Within the framework of automated\nreaction network exploration, where new reactants or reagents composed of any\nelements from the periodic table can be introduced, this lack of\ngeneralizability will be the rule rather than the exception. Here, we therefore\nstudy the benefits and drawbacks of two MLP concepts in this context. Whereas\nuniversal MLPs are designed to cover most of the relevant chemical space in\ntheir training, lifelong MLPs push their adaptability by efficient continual\nlearning of additional data. While the accuracy of the universal MLPs turns out\nto be not yet sufficient for reaction search trials without any fine-tuning,\nlifelong MLPs can reach chemical accuracy. We propose an improved learning\nalgorithm for lifelong adaptive data selection yielding efficient integration\nof new data while previous expertise is preserved.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.comp-ph","published":"2025-04-16T10:12:08Z"}
{"aid":"http://arxiv.org/abs/2504.11984v1","title":"The Evolution of Zero Trust Architecture (ZTA) from Concept to\n  Implementation","summary":"Zero Trust Architecture (ZTA) is one of the paradigm changes in\ncybersecurity, from the traditional perimeter-based model to perimeterless.\nThis article studies the core concepts of ZTA, its beginning, a few use cases\nand future trends. Emphasising the always verify and least privilege access,\nsome key tenets of ZTA have grown to be integration technologies like Identity\nManagement, Multi-Factor Authentication (MFA) and real-time analytics. ZTA is\nexpected to strengthen cloud environments, education, work environments\n(including from home) while controlling other risks like lateral movement and\ninsider threats. Despite ZTA's benefits, it comes with challenges in the form\nof complexity, performance overhead and vulnerabilities in the control plane.\nThese require phased implementation and continuous refinement to keep up with\nevolving organisational needs and threat landscapes. Emerging technologies,\nsuch as Artificial Intelligence (AI) and Machine Learning (ML) will further\nautomate policy enforcement and threat detection in keeping up with dynamic\ncyber threats.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-04-16T11:26:54Z"}
{"aid":"http://arxiv.org/abs/2504.11991v1","title":"Non-Markovian Quantum Master and Fokker-Planck Equation for\n  Gravitational Systems and Gravitational Decoherence","summary":"A quantum master equation describing the stochastic dynamics of a quantum\nmassive system interacting with a quantum gravitational field is useful for the\ninvestigation of quantum gravitational and quantum informational issues such as\nthe quantum nature of gravity, gravity-induced entanglement and gravitational\ndecoherence. Studies of the decoherence of quantum systems by an\nelectromagnetic field shows that a lower temperature environment is more\nconducive to successful quantum information processing experiments. Likewise,\nthe quantum nature of (perturbative) gravity is far better revealed at lower\ntemperatures than high, minimizing the corruptive effects of thermal noise. In\nthis work, generalizing earlier results of the Markovian ABH master equation\n[1,2] which is valid only for high temperatures, we derive a non-Markovian\nquantum master equation for the reduced density matrix, and the associated\nFokker-Planck equation for the Wigner distribution function, for the stochastic\ndynamics of two masses following quantum trajectories, interacting with a\ngraviton field, including the effects of graviton noise, valid for all\ntemperatures. We follow the influence functional approach exemplified in the\nderivation of the non-Markovian Hu-Paz-Zhang master equation [62,64] for\nquantum Brownian motion. We find that in the low temperature limit, the\noff-diagonal elements of the reduced density matrix decrease in time\nlogarithmically for the zero temperature part and quadratically in time for the\ntemperature-dependent part, which is distinctly different from the Markovian\ncase. We end with a summary of our findings and a discussion on how this\nproblem studied here is related to the quantum stochastic equation derived in\n[77] for gravitational self force studies, and to quantum optomechanics where\nexperimental observation of gravitational decoherence and entanglement may be\nimplemented.","main_category":"gr-qc","categories":"gr-qc,cond-mat.stat-mech,hep-th,quant-ph","published":"2025-04-16T11:33:23Z"}
{"aid":"http://arxiv.org/abs/2504.12008v1","title":"Global Patterns of Extreme Temperature Teleconnections Using Climate\n  Network Analysis","summary":"Extreme weather events, rare yet profoundly impactful, are often accompanied\nby severe conditions. Increasing global temperatures are poised to exacerbate\nthese events, resulting in greater human casualties, economic losses, and\necological destruction. Complex global climate interactions, known as\nteleconnections, can lead to widespread repercussions triggered by localized\nextreme weather. Understanding these teleconnection patterns is crucial for\nweather forecasting, enhancing safety, and advancing climate science. Here, we\nemploy climate network analysis to uncover teleconnection patterns associated\nwith extreme temperature fluctuations, including both extreme warming and\ncooling events occurring on a daily basis. Our study results demonstrate that\nthe distances of significant teleconnections initially conform to a power-law\ndecay, signifying a decline in connectivity with distance. However, this\npower-law decay tendency breaks beyond a certain threshold distance, suggesting\nthe existence of long-distance connections. Additionally, we uncover a greater\nprevalence of long-distance connectivity among extreme cooling events compared\nto extreme warming events. The global pattern of teleconnections is, in part,\ndriven by the mechanism of Rossby waves, which serve as a rapid conduit for\ninducing correlated fluctuations in both pressure and temperature. These\nresults enhance our understanding of the multiscale nature of climate\nteleconnections and hold significant implications for improving weather\nforecasting and assessing climate risks in a warming world.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-16T12:05:15Z"}
{"aid":"http://arxiv.org/abs/2504.12018v1","title":"Instruction-augmented Multimodal Alignment for Image-Text and Element\n  Matching","summary":"With the rapid advancement of text-to-image (T2I) generation models,\nassessing the semantic alignment between generated images and text descriptions\nhas become a significant research challenge. Current methods, including those\nbased on Visual Question Answering (VQA), still struggle with fine-grained\nassessments and precise quantification of image-text alignment. This paper\npresents an improved evaluation method named Instruction-augmented Multimodal\nAlignment for Image-Text and Element Matching (iMatch), which evaluates\nimage-text semantic alignment by fine-tuning multimodal large language models.\nWe introduce four innovative augmentation strategies: First, the QAlign\nstrategy creates a precise probabilistic mapping to convert discrete scores\nfrom multimodal large language models into continuous matching scores. Second,\na validation set augmentation strategy uses pseudo-labels from model\npredictions to expand training data, boosting the model's generalization\nperformance. Third, an element augmentation strategy integrates element\ncategory labels to refine the model's understanding of image-text matching.\nFourth, an image augmentation strategy employs techniques like random lighting\nto increase the model's robustness. Additionally, we propose prompt type\naugmentation and score perturbation strategies to further enhance the accuracy\nof element assessments. Our experimental results show that the iMatch method\nsignificantly surpasses existing methods, confirming its effectiveness and\npractical value. Furthermore, our iMatch won first place in the CVPR NTIRE 2025\nText to Image Generation Model Quality Assessment - Track 1 Image-Text\nAlignment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T12:21:49Z"}
{"aid":"http://arxiv.org/abs/2504.12021v1","title":"Action Anticipation from SoccerNet Football Video Broadcasts","summary":"Artificial intelligence has revolutionized the way we analyze sports videos,\nwhether to understand the actions of games in long untrimmed videos or to\nanticipate the player's motion in future frames. Despite these efforts, little\nattention has been given to anticipating game actions before they occur. In\nthis work, we introduce the task of action anticipation for football broadcast\nvideos, which consists in predicting future actions in unobserved future\nframes, within a five- or ten-second anticipation window. To benchmark this\ntask, we release a new dataset, namely the SoccerNet Ball Action Anticipation\ndataset, based on SoccerNet Ball Action Spotting. Additionally, we propose a\nFootball Action ANticipation TRAnsformer (FAANTRA), a baseline method that\nadapts FUTR, a state-of-the-art action anticipation model, to predict\nball-related actions. To evaluate action anticipation, we introduce new\nmetrics, including mAP@$\\delta$, which evaluates the temporal precision of\npredicted future actions, as well as mAP@$\\infty$, which evaluates their\noccurrence within the anticipation window. We also conduct extensive ablation\nstudies to examine the impact of various task settings, input configurations,\nand model architectures. Experimental results highlight both the feasibility\nand challenges of action anticipation in football videos, providing valuable\ninsights into the design of predictive models for sports analytics. By\nforecasting actions before they unfold, our work will enable applications in\nautomated broadcasting, tactical analysis, and player decision-making. Our\ndataset and code are publicly available at\nhttps://github.com/MohamadDalal/FAANTRA.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T12:24:33Z"}
{"aid":"http://arxiv.org/abs/2504.12024v1","title":"Giant Exciton Transport in hBN/2D-Perovskite Heterostructures","summary":"Two-dimensional perovskites, such as Ruddlesden-Popper perovskites, exhibit\noutstanding optical properties and high exciton binding energies but are highly\nsusceptible to degradation under photo- and electron-beam exposure. To overcome\nthis limitation, we encapsulate the perovskites with mechanically exfoliated\nhexagonal boron nitride flakes, forming hexagonal boron nitride/perovskite\nheterostructures. Cathodoluminescence spectroscopy reveals that these\nheterostructures exhibit significantly reduced electron-beam-induced\ndegradation, enhanced luminescence intensity, a narrower emission bandwidth,\nand an extended exciton decay time. Moreover, leveraging the scanning\ncapability of our fiber-based cathodoluminescence spectroscopy technique, we\ndemonstrate ultra-long-range exciton transport over distances of approximately\n150 micrometers, attributed to exciton-defect coupling. This exciton-defect\ninteraction not only enhances luminescence but also highlights the potential of\nhexagonal boron nitride/perovskite heterostructures as hybrid van-der-Waals\nsystems with long-range exciton transport and slow radiative decay rates,\npaving the way for robust and efficient optoelectronic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-16T12:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.12032v1","title":"Combining Declarative and Linear Programming for Application Management\n  in the Cloud-Edge Continuum","summary":"This work investigates the data-aware multi-service application placement\nproblem in Cloud-Edge settings. We previously introduced EdgeWise, a hybrid\napproach that combines declarative programming with Mixed-Integer Linear\nProgramming (MILP) to determine optimal placements that minimise operational\ncosts and unnecessary data transfers. The declarative stage pre-processes\ninfrastructure constraints to improve the efficiency of the MILP solver,\nachieving optimal placements in terms of operational costs, with significantly\nreduced execution times. In this extended version, we improve the declarative\nstage with continuous reasoning, presenting EdgeWiseCR, which enables the\nsystem to reuse existing placements and reduce unnecessary recomputation and\nservice migrations. In addition, we conducted an expanded experimental\nevaluation considering multiple applications, diverse network topologies, and\nlarge-scale infrastructures with dynamic failures. The results show that\nEdgeWiseCR achieves up to 65% faster execution compared to EdgeWise, while\npreserving placement stability under dynamic conditions.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-16T12:45:35Z"}
{"aid":"http://arxiv.org/abs/2504.12037v1","title":"Integrating Neural Networks and Tensor Networks for Computing Free\n  Energy","summary":"Computing free energy is a fundamental problem in statistical physics.\nRecently, two distinct methods have been developed and have demonstrated\nremarkable success: the tensor-network-based contraction method and the\nneural-network-based variational method. Tensor networks are accu?rate, but\ntheir application is often limited to low-dimensional systems due to the high\ncomputational complexity in high-dimensional systems. The neural network method\napplies to systems with general topology. However, as a variational method, it\nis not as accurate as tensor networks. In this work, we propose an integrated\napproach, tensor-network-based variational autoregressive networks (TNVAN),\nthat leverages the strengths of both tensor networks and neural networks:\ncombining the variational autoregressive neural network's ability to compute an\nupper bound on free energy and perform unbiased sampling from the variational\ndistribution with the tensor network's power to accurately compute the\npartition function for small sub-systems, resulting in a robust method for\nprecisely estimating free energy. To evaluate the proposed approach, we\nconducted numerical experiments on spin glass systems with various topologies,\nincluding two-dimensional lattices, fully connected graphs, and random graphs.\nOur numerical results demonstrate the superior accuracy of our method compared\nto existing approaches. In particular, it effectively handles systems with\nlong-range interactions and leverages GPU efficiency without requiring singular\nvalue decomposition, indicating great potential in tackling statistical\nmechanics problems and simulating high-dimensional complex systems through both\ntensor networks and neural networks.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-16T12:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.12044v1","title":"Anatomy of the simplest renormalon","summary":"Perhaps the simplest IR renormalon occurs in the ground state energy of a\nsuperrenormalizable model, the scalar $O(N)$ theory in two dimensions with a\nquartic potential and negative squared mass. We show that this renormalon,\nfound previously in perturbation theory at next-to-leading order (NLO) in the\n$1/N$ expansion, gives indeed the correct asymptotic expansion of the exact\nlarge $N$ solution of the model, and we determine explicitly the complete\ntrans-series of non-perturbative corrections to the perturbative result. We\nalso use this framework to study the $O(N)$-invariant two-point function of the\nscalar field. As expected, it is IR finite in perturbation theory, but it is\nafflicted as well with an IR renormalon singularity and is not Borel summable.\nThe pole mass is purely non-perturbative and its trans-series can be also fully\ndetermined at NLO in $1/N$","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T13:00:45Z"}
{"aid":"http://arxiv.org/abs/2504.12046v1","title":"The Dynamic Inner Disk of a Planet Forming Star","summary":"Planets are a natural byproduct of the stellar formation process, resulting\nfrom local aggregations of material within the disks surrounding young stars.\nWhereas signatures of gas-giant planets at large orbital separations have been\nobserved and successfully modeled within protoplanetary disks, the formation\npathways of planets within their host star's future habitable zones remain\npoorly understood. Analyzing multiple nights of observations conducted over a\nshort, two-month span with the MIRC-X and PIONIER instruments at the CHARA\nArray and VLTI, respectively, we uncover a highly active environment at the\ninner-edge of the planet formation region in the disk of HD 163296. In\nparticular, we localize and track the motion of a disk feature near the\ndust-sublimation radius with a pattern speed of less than half the local\nKeplerian velocity, providing a potential glimpse at the planet formation\nprocess in action within the inner astronomical unit. We emphasize that this\nresult is at the edge of what is currently possible with available optical\ninterferometric techniques and behooves confirmation with a temporally dense\nfollowup observing campaign.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-16T13:03:30Z"}
{"aid":"http://arxiv.org/abs/2504.12053v1","title":"Causality, localisation, and universality of monitored quantum walks\n  with long-range hopping","summary":"Quantum resetting protocols can speed up the time in which a quantum walker\nreaches a target site on a lattice. In these setups, a detector monitors the\ntarget site and the walker motion is restarted if the detector has not clicked\nafter a fixed time interval. The optimal resetting rate can be extracted from\nthe time evolution of the probability $S(t)$ that the detector has not clicked\nup to time $t$. We analyse $S(t)$ for a quantum walk in a one-dimensional\nlattice when the coupling between sites decays algebraically as $d^{-\\alpha}$\nwith the distance $d$, for $\\alpha\\in(0,\\infty)$. At long-times, $S(t)$ decays\nwith a universal power-law exponent that is independent of $\\alpha$. At short\ntimes, $S(t)$ exhibits a plethora of phase transitions as a function of\n$\\alpha$. These lead to the identification of two main regimes for the optimal\nresetting rate. For $\\alpha>1$, the resetting rate $r$ is bounded from below by\nthe velocity with which information propagates causally across the lattice. For\n$\\alpha<1$, instead, the long-range hopping tends to localise the walker: The\noptimal resetting rate depends on the size of the lattice and diverges as\n$\\alpha\\to 0$. We derive simple models reproducing the numerical results,\nshedding light on the interplay of long-range coherent dynamics, symmetries,\nand local quantum measurement processes in determining equilibrium. Our\npredictions can be verified in existing experimental setups.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T13:08:42Z"}
{"aid":"http://arxiv.org/abs/2504.12061v1","title":"A survey on orderability and contact non-squeezing","summary":"The present article provides an overview of Yakov Eliashberg's seminal\ncontributions to the concepts of orderability and contact non-squeezing. It\nalso examines subsequent research by various authors, highlighting the\nsignificance of these notions and offering a detailed account of the current\nstate of the field.","main_category":"math.SG","categories":"math.SG","published":"2025-04-16T13:16:35Z"}
{"aid":"http://arxiv.org/abs/2504.12073v1","title":"Unconventional and anomalous magnetic field distribution in a bilayer\n  superconductor with geometric constraints","summary":"We investigate the magnetic field distribution in multi-component\nsuperconductors. We examine a layered superconductor and a two-component\none-layer superconductor. We evaluate the field distribution in the presence of\na half-flux quantum vortex with a kink structure in the phase space of gap\nfunctions. We also examine the magnetic field distribution of a knot soliton\nwhich is formulated in a two-component superconductor. We investigate the\neffect of geometric constraints for multi-component superconductors, where the\ngeometric constraint means that the system is compactified in one direction so\nthat the current in this direction becomes vanishingly small. This corresponds\nto the gauge fixing in this direction. An unconventional magnetic field\ndistribution takes place; here the unconventional means that the magnetic field\nis screened incompletely which would be called the anomalous Meissner effect.\nWe argue that this anomalous behavior creates a massless gauge field.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T13:29:40Z"}
{"aid":"http://arxiv.org/abs/2504.12083v1","title":"Self-alignment of Large Video Language Models with Refined Regularized\n  Preference Optimization","summary":"Despite recent advances in Large Video Language Models (LVLMs), they still\nstruggle with fine-grained temporal understanding, hallucinate, and often make\nsimple mistakes on even simple video question-answering tasks, all of which\npose significant challenges to their safe and reliable deployment in real-world\napplications. To address these limitations, we propose a self-alignment\nframework that enables LVLMs to learn from their own errors. Our proposed\nframework first obtains a training set of preferred and non-preferred response\npairs, where non-preferred responses are generated by incorporating common\nerror patterns that often occur due to inadequate spatio-temporal\nunderstanding, spurious correlations between co-occurring concepts, and\nover-reliance on linguistic cues while neglecting the vision modality, among\nothers. To facilitate self-alignment of LVLMs with the constructed preferred\nand non-preferred response pairs, we introduce Refined Regularized Preference\nOptimization (RRPO), a novel preference optimization method that utilizes\nsub-sequence-level refined rewards and token-wise KL regularization to address\nthe limitations of Direct Preference Optimization (DPO). We demonstrate that\nRRPO achieves more precise alignment and more stable training compared to DPO.\nOur experiments and analysis validate the effectiveness of our approach across\ndiverse video tasks, including video hallucination, short- and long-video\nunderstanding, and fine-grained temporal reasoning.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T13:43:56Z"}
{"aid":"http://arxiv.org/abs/2504.12091v1","title":"Locality-aware Pauli-based computation for local magic state preparation","summary":"Magic state distillation, a process for preparing magic states needed to\nimplement non-Clifford gates fault-tolerantly, plays a crucial role in\nfault-tolerant quantum computation. Historically, it has been a major\nbottleneck, leading to the pursuit of computation schemes optimized for slow\nmagic state preparation. Recent advances in magic state distillation have\nsignificantly reduced the overhead, enabling the simultaneous preparation of\nmany magic states. However, the magic state transfer cost prevents the\nconventional layout from efficiently utilizing them, highlighting the need for\nan alternative scheme optimized for highly parallel quantum algorithms. In this\nstudy, we propose locality-aware Pauli-based computation, a novel compilation\nscheme that distills magic states in the computation area, aiming to reduce\nexecution time by minimizing magic state transfer costs and improving locality.\nNumerical experiments on random circuit sampling and 2D Ising Hamiltonian\nsimulation demonstrate that our scheme significantly reduces execution time,\nwhile incurring little or no additional spatial overhead, compared to\nsequential Pauli-based computation, a conventional computation scheme, and\nscales favorably with increasing qubit count.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T13:54:03Z"}
{"aid":"http://arxiv.org/abs/2504.12101v1","title":"Disjoint Ces$\\grave{A}$ro-hypercyclic operators","summary":"In this paper, we investigate the properties of disjoint\nCes$\\grave{a}$ro-hypercyclic operators. First, the definition of disjoint\nCes$\\grave{a}$ro-hypercyclic operators is provided, and disjoint\nCes$\\grave{a}$ro-Hypercyclicity Criterion is proposed. Later, two methods are\nused to prove that operators satisfying this criterion possess disjoint\nCes$\\grave{a}$ro-hypercyclicity. Finally, this paper further investigates\nweighted shift operators and provides detailed characterizations of the weight\nsequences for disjoint Ces$\\grave{a}$ro-hypercyclic unilateral and bilateral\nweighted shift operators on sequence spaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-16T14:05:44Z"}
{"aid":"http://arxiv.org/abs/2504.12104v1","title":"Logits DeConfusion with CLIP for Few-Shot Learning","summary":"With its powerful visual-language alignment capability, CLIP performs well in\nzero-shot and few-shot learning tasks. However, we found in experiments that\nCLIP's logits suffer from serious inter-class confusion problems in downstream\ntasks, and the ambiguity between categories seriously affects the accuracy. To\naddress this challenge, we propose a novel method called Logits DeConfusion,\nwhich effectively learns and eliminates inter-class confusion in logits by\ncombining our Multi-level Adapter Fusion (MAF) module with our Inter-Class\nDeconfusion (ICD) module. Our MAF extracts features from different levels and\nfuses them uniformly to enhance feature representation. Our ICD learnably\neliminates inter-class confusion in logits with a residual structure.\nExperimental results show that our method can significantly improve the\nclassification performance and alleviate the inter-class confusion problem. The\ncode is available at https://github.com/LiShuo1001/LDC.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T14:12:56Z"}
{"aid":"http://arxiv.org/abs/2504.12120v1","title":"Logarithmic Spectral Distribution of a non-Hermitian $β$-Ensemble","summary":"We introduce a non-Hermitian $\\beta$-ensemble and determine its spectral\ndensity in the limit of large $\\beta$ and large matrix size $n$. The ensemble\nis given by a general tridiagonal complex random matrix of normal and\nchi-distributed random variables, extending previous work of two of the\nauthors. The joint distribution of eigenvalues contains a Vandermonde\ndeterminant to the power $\\beta$ and a residual coupling to the eigenvectors. A\ntool in the computation of the limiting spectral density is a single\ncharacteristic polynomial for centred tridiagonal Jacobi matrices, for which we\nexplicitly determine the coefficients in terms of its matrix elements. In the\nlow temperature limit $\\beta\\gg1$ our ensemble reduces to such a centred matrix\nwith vanishing diagonal. A general theorem from free probability based on the\nvariance of the coefficients of the characteristic polynomial allows us to\nobtain the spectral density when additionally taking the large-$n$ limit. It is\nrotationally invariant on a compact disc, given by the logarithm of the radius\nplus a constant. The same density is obtained when starting form a tridiagonal\ncomplex symmetric ensemble, which thus plays a special role. Extensive\nnumerical simulations confirm our analytical results and put this and the\npreviously studied ensemble in the context of the pseudospectrum.","main_category":"math-ph","categories":"math-ph,cond-mat.stat-mech,math.MP,math.PR","published":"2025-04-16T14:33:46Z"}
{"aid":"http://arxiv.org/abs/2504.12149v1","title":"Study on charmonium(-like) mesons within a diabatic approach","summary":"In this work, we study the charmonium(-like) spectrum below 4.1 GeV using the\ndiabatic approach, which offers a unified description of conventional and\nunconventional heavy meson states. Compared to previous studies, we consider a\nmore realistic $c\\bar c$ potential with including the spin-dependent\ninteractions, which allows us to obtain more states and get more insights on\nthe charmonium spectrum. Based on our calculation, we obtain the masses of the\ncharmonium spectrum which align with the experimental data well. We also\npresent the probabilities of finding various components, i.e. $c\\bar c$ or\nmeson-meson pair, in those states. Our results support the arguments that the\n$\\chi_{c1}(3872)$, $\\psi(4040)$ and $\\chi_{c2}(3930)$ have significant\nmolecular components. In addition, our calculations show that the\n$\\chi_{c0}(3860)$ and $\\psi(3770)$ can be looked as the candidates for the\ncharmonium states $\\chi_{c0}(2P)$ and $\\psi(1D)$, respectively.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T14:57:29Z"}
{"aid":"http://arxiv.org/abs/2504.12171v1","title":"Traveling wave profiles for a semi-discrete Burgers equation","summary":"We look for traveling waves of the semi-discrete conservation law $4\\dot u_j\n+u_{j+1}^2-u_{j-1}^2 = 0$, using variational principles related to concepts of\n``hidden convexity'' appearing in recent studies of various PDE (partial\ndifferential equations). We analyze and numerically compute with two\nvariational formulations related to dual convex optimization problems\nconstrained by either the differential-difference equation (DDE) or nonlinear\nintegral equation (NIE) that wave profiles should satisfy. We prove existence\ntheorems conditional on the existence of extrema that satisfy a strict\nconvexity criterion, and numerically exhibit a variety of localized, periodic\nand non-periodic wave phenomena.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA,nlin.PS","published":"2025-04-16T15:23:43Z"}
{"aid":"http://arxiv.org/abs/2504.12208v1","title":"Servo-Controllers with Operational Constraints","summary":"In this paper, a proportional-integral servo-control design method is\ndeveloped for multi-input-multioutput linear time invariant systems with\noperational constraints imposed on the system control input and on an output of\nthe same dimension as the control input. The design is based on min-norm\ncontrollers and Control Barrier Functions. It allows to enforce min/max box\nconstraints by analytically solving Quadratic Programs for min-norm\naugmentation controllers. The method provides an anti-windup protection for the\ncontroller integrator state and enforces the desired operational control and\noutput constraints, component-wise. A simulation example is given to illustrate\npotential benefits of the proposed design methodology for aerial flight\ncritical systems.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-16T15:55:55Z"}
{"aid":"http://arxiv.org/abs/2504.12209v1","title":"Evidence for a polar circumbinary exoplanet orbiting a pair of eclipsing\n  brown dwarfs","summary":"One notable example of exoplanet diversity is the population of circumbinary\nplanets, which orbit around both stars of a binary star system. There are so\nfar only 16 known circumbinary exoplanets, all of which lie in the same orbital\nplane as the host binary. Suggestions exist that circumbinary planets could\nalso exist on orbits highly inclined to the binary, close to 90$^{\\circ}$,\npolar orbits. No such planets have been found yet but polar circumbinary gas\nand debris discs have been observed and if these were to form planets then\nthose would be left on a polar orbit. We report strong evidence for a polar\ncircumbinary exoplanet, which orbits a close pair of brown dwarfs which are on\nan eccentric orbit. We use radial-velocities to measure a retrograde apsidal\nprecession for the binary, and show that this can only be attributed to the\npresence of a polar planet.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-16T15:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.12216v1","title":"d1: Scaling Reasoning in Diffusion Large Language Models via\n  Reinforcement Learning","summary":"Recent large language models (LLMs) have demonstrated strong reasoning\ncapabilities that benefits from online reinforcement learning (RL). These\ncapabilities have primarily been demonstrated within the left-to-right\nautoregressive (AR) generation paradigm. In contrast, non-autoregressive\nparadigms based on diffusion generate text in a coarse-to-fine manner. Although\nrecent diffusion-based large language models (dLLMs) have achieved competitive\nlanguage modeling performance compared to their AR counterparts, it remains\nunclear if dLLMs can also leverage recent advances in LLM reasoning. To this\nend, we propose d1, a framework to adapt pre-trained masked dLLMs into\nreasoning models via a combination of supervised finetuning (SFT) and RL.\nSpecifically, we develop and extend techniques to improve reasoning in\npretrained dLLMs: (a) we utilize a masked SFT technique to distill knowledge\nand instill self-improvement behavior directly from existing datasets, and (b)\nwe introduce a novel critic-free, policy-gradient based RL algorithm called\ndiffu-GRPO. Through empirical studies, we investigate the performance of\ndifferent post-training recipes on multiple mathematical and logical reasoning\nbenchmarks. We find that d1 yields the best performance and significantly\nimproves performance of a state-of-the-art dLLM.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-16T16:08:45Z"}
{"aid":"http://arxiv.org/abs/2504.12227v1","title":"A remark on Euler-like vector fields","summary":"In this note, we show that (the germ of) each Euler-like vector field comes\nfrom a tubular neighborhood embedding given by the normal exponential map of\nsome Riemannian metric.","main_category":"math.DG","categories":"math.DG","published":"2025-04-16T16:22:43Z"}
{"aid":"http://arxiv.org/abs/2504.12245v1","title":"SIDME: Self-supervised Image Demoiréing via Masked Encoder-Decoder\n  Reconstruction","summary":"Moir\\'e patterns, resulting from aliasing between object light signals and\ncamera sampling frequencies, often degrade image quality during capture.\nTraditional demoir\\'eing methods have generally treated images as a whole for\nprocessing and training, neglecting the unique signal characteristics of\ndifferent color channels. Moreover, the randomness and variability of moir\\'e\npattern generation pose challenges to the robustness of existing methods when\napplied to real-world data. To address these issues, this paper presents SIDME\n(Self-supervised Image Demoir\\'eing via Masked Encoder-Decoder Reconstruction),\na novel model designed to generate high-quality visual images by effectively\nprocessing moir\\'e patterns. SIDME combines a masked encoder-decoder\narchitecture with self-supervised learning, allowing the model to reconstruct\nimages using the inherent properties of camera sampling frequencies. A key\ninnovation is the random masked image reconstructor, which utilizes an\nencoder-decoder structure to handle the reconstruction task. Furthermore, since\nthe green channel in camera sampling has a higher sampling frequency compared\nto red and blue channels, a specialized self-supervised loss function is\ndesigned to improve the training efficiency and effectiveness. To ensure the\ngeneralization ability of the model, a self-supervised moir\\'e image generation\nmethod has been developed to produce a dataset that closely mimics real-world\nconditions. Extensive experiments demonstrate that SIDME outperforms existing\nmethods in processing real moir\\'e pattern data, showing its superior\ngeneralization performance and robustness.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-16T16:50:41Z"}
{"aid":"http://arxiv.org/abs/2504.12260v1","title":"On resolution of L1-norm minimization via a two-metric adaptive\n  projection method","summary":"The two-metric projection method is a simple yet elegant algorithm proposed\nby Bertsekas\n  to address bound/box-constrained optimization problems. The algorithm's low\nper-iteration\n  cost and potential for using Hessian information make it a favorable\ncomputation method\n  for this problem class. Inspired by this algorithm, we propose a two-metric\nadaptive projection\n  method for solving the $\\ell_1$-norm regularization problem that inherits\nthese advantages. We demonstrate that the method is theoretically sound -\n  it has global convergence. Furthermore, it is capable of manifold\nidentification and has\n  superlinear convergence rate under the error bound condition and strict\ncomplementarity.\n  Therefore, given sparsity in the solution, the method enjoys superfast\nconvergence in iteration\n  while maintaining scalability, making it desirable for large-scale problems.\nWe also equip\n  the algorithm with competitive complexity to solve nonconvex problems.\nNumerical experiments\n  are conducted to illustrate the advantages of this algorithm implied by the\ntheory compared\n  to other competitive methods, especially in large-scale scenarios. In\ncontrast to the original two-metric projection method, our algorithm directly\nsolves the $\\ell_1$-norm minimization problem without resorting to the\nintermediate reformulation as a bound-constrained problem, so it circumvents\nthe issue of numerical instability.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T17:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.12606v1","title":"Robo-SGG: Exploiting Layout-Oriented Normalization and Restitution for\n  Robust Scene Graph Generation","summary":"In this paper, we introduce a novel method named Robo-SGG, i.e.,\nLayout-Oriented Normalization and Restitution for Robust Scene Graph\nGeneration. Compared to the existing SGG setting, the robust scene graph\ngeneration aims to perform inference on a diverse range of corrupted images,\nwith the core challenge being the domain shift between the clean and corrupted\nimages. Existing SGG methods suffer from degraded performance due to\ncompromised visual features e.g., corruption interference or occlusions. To\nobtain robust visual features, we exploit the layout information, which is\ndomain-invariant, to enhance the efficacy of existing SGG methods on corrupted\nimages. Specifically, we employ Instance Normalization(IN) to filter out the\ndomain-specific feature and recover the unchangeable structural features, i.e.,\nthe positional and semantic relationships among objects by the proposed\nLayout-Oriented Restitution. Additionally, we propose a Layout-Embedded Encoder\n(LEE) that augments the existing object and predicate encoders within the SGG\nframework, enriching the robust positional and semantic features of objects and\npredicates. Note that our proposed Robo-SGG module is designed as a\nplug-and-play component, which can be easily integrated into any baseline SGG\nmodel. Extensive experiments demonstrate that by integrating the\nstate-of-the-art method into our proposed Robo-SGG, we achieve relative\nimprovements of 5.6%, 8.0%, and 6.5% in mR@50 for PredCls, SGCls, and SGDet\ntasks on the VG-C dataset, respectively, and achieve new state-of-the-art\nperformance in corruption scene graph generation benchmark (VG-C and GQA-C). We\nwill release our source code and model.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T03:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.12609v1","title":"Crossing the Human-Robot Embodiment Gap with Sim-to-Real RL using One\n  Human Demonstration","summary":"Teaching robots dexterous manipulation skills often requires collecting\nhundreds of demonstrations using wearables or teleoperation, a process that is\nchallenging to scale. Videos of human-object interactions are easier to collect\nand scale, but leveraging them directly for robot learning is difficult due to\nthe lack of explicit action labels from videos and morphological differences\nbetween robot and human hands. We propose Human2Sim2Robot, a novel\nreal-to-sim-to-real framework for training dexterous manipulation policies\nusing only one RGB-D video of a human demonstrating a task. Our method utilizes\nreinforcement learning (RL) in simulation to cross the human-robot embodiment\ngap without relying on wearables, teleoperation, or large-scale data collection\ntypically necessary for imitation learning methods. From the demonstration, we\nextract two task-specific components: (1) the object pose trajectory to define\nan object-centric, embodiment-agnostic reward function, and (2) the\npre-manipulation hand pose to initialize and guide exploration during RL\ntraining. We found that these two components are highly effective for learning\nthe desired task, eliminating the need for task-specific reward shaping and\ntuning. We demonstrate that Human2Sim2Robot outperforms object-aware open-loop\ntrajectory replay by 55% and imitation learning with data augmentation by 68%\nacross grasping, non-prehensile manipulation, and multi-step tasks. Project\nSite: https://human2sim2robot.github.io","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-17T03:15:20Z"}
{"aid":"http://arxiv.org/abs/2504.12617v1","title":"Bayesian Density-Density Regression with Application to Cell-Cell\n  Communications","summary":"We introduce a scalable framework for regressing multivariate distributions\nonto multivariate distributions, motivated by the application of inferring\ncell-cell communication from population-scale single-cell data. The observed\ndata consist of pairs of multivariate distributions for ligands from one cell\ntype and corresponding receptors from another. For each ordered pair $e=(l,r)$\nof cell types $(l \\neq r)$ and each sample $i = 1, \\ldots, n$, we observe a\npair of distributions $(F_{ei}, G_{ei})$ of gene expressions for ligands and\nreceptors of cell types $l$ and $r$, respectively. The aim is to set up a\nregression of receptor distributions $G_{ei}$ given ligand distributions\n$F_{ei}$. A key challenge is that these distributions reside in distinct spaces\nof differing dimensions. We formulate the regression of multivariate densities\non multivariate densities using a generalized Bayes framework with the sliced\nWasserstein distance between fitted and observed distributions. Finally, we use\ninference under such regressions to define a directed graph for cell-cell\ncommunications.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO,stat.ML","published":"2025-04-17T03:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.12618v1","title":"Simultaneous Superoscillations in Space and Time in Nonseparable Light\n  Pulses","summary":"A remarkable phenomenon of superoscillations implies that electromagnetic\nwaves can locally oscillate in space or time faster than the fastest spatial\nand temporal Fourier component of the entire function. This phenomenon allows\nto focus light into an arbitrary small hotspot enabling superresolution imaging\nand optical metrology with accuracy far beyond the Abbey-Reileigh diffraction\nlimit. Here we show that, in band-limited supertoroidal light pulses, the\ntemporal and spatial superoscillations can be observed simultaneously at a\nspecific region in space and at a specific interval in time.","main_category":"physics.optics","categories":"physics.optics,physics.class-ph","published":"2025-04-17T03:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.12622v1","title":"Can metric radio bursts be used as a diagnostics tool for interplanetary\n  coronal mass ejections?","summary":"Metric radio bursts are often said to be valuable diagnostic tools for\nstudying the near-sun kinematics and energetics of the Interplanetary Coronal\nMass Ejections (ICMEs). Radio observations also serve as an indirect tool to\nestimate the coronal magnetic fields. However, how these estimated coronal\nmagnetic fields are related to the magnetic field strength in the ICME at 1 AU\nhas rarely been explored. We aim to establish a relation between the coronal\nmagnetic fields obtained from the radio observations very close to the Sun and\nthe magnetic field measured at 1 AU when the ICME arrives at the Earth. We\nperformed statistical analysis of all metric type II radio bursts in solar\ncycles 23 and 24, which were found to be associated with ICMEs. We estimated\nthe coronal magnetic field associated with the corresponding CME near the Sun\n(middle corona) using a split-band radio technique and compared those with the\nmagnetic fields recorded at 1 AU with in-situ observations. We found that the\nestimated magnetic fields near the Sun using radio techniques are not well\ncorrelated with the magnetic fields measured at 1 AU using in-situ\nobservations. This could be due to the complex evolution of the magnetic field\nas it propagates through the heliosphere. Our results suggest that while metric\nradio observations can serve as effective proxies for estimating magnetic\nfields near the Sun, they may not be as effective close to the Earth. At least,\nno linear relation could be established using metric radio emissions to\nestimate the magnetic fields at 1 AU with acceptable error margins.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-17T03:55:30Z"}
{"aid":"http://arxiv.org/abs/2504.12630v1","title":"Crystal growth, structure and physical properties of\n  quasi-one-dimensional tellurides Fe$_{4-x}$VTe$_{4-y}$ ($x=1.01$, $y=0.74$)\n  and V$_{4.64}$Te$_4$","summary":"A new ternary compound Fe$_{4-x}$VTe$_{4-y}$ ($x=1.01$, $y=0.74$) with\nTi5Te4-type structure is identified. Fe and V atoms tend to occupy different\ncrystallographic positions and form quasi-one-dimensional (quasi-1D) Fe-V\nchains along the c-axis. Millimeter-sized single crystal of\nFe$_{2.99}$VTe$_{3.26}$ (FVT) with slender-stick shape could be grown by\nchemical vapor transport method which reflects its quasi-1D crystal structure.\nMagnetization measurements reveal that FVT orders antiferromagnetically below\nT$_N$=93 K with strong easy ab-plane magnetic anisotropy. Although a weak\nglassy-like behavior appears below 10 K, FVT is dominant by long-range\nantiferromagnetic order in contrast to the spin-glass state in previously\nreported isostructural Fe$_{5}$Te$_{4}$. We also synthesize V$_{4.64}$Te$_4$\nwith similar quasi-1D V-chains and find it has weak anomalies at 144 K on both\nresistivity and susceptibility curves. However, no clear evidence is found for\nthe development of magnetic or charge order. X-ray photoelectron spectroscopy\nand Curie-Weiss fit reveal that the effective moments for Fe$^{2+}$ and\nV$^{4+}$ in both compounds have large deviations from the conventional local\nmoment model, which may possibly result from the formation of Fe/V metal-metal\nbondings. Furthermore the resistivity of both FVT and V$_{4.64}$Te$_4$ exhibits\nsemiconducting-like temperature-dependent behavior but with average values\nclose to typical bad metals, which resembles the transport behavior in the\nnormal state of Fe-based superconductors. These quasi-1D compounds have shown\ninteresting physical properties for future condensed matter physics research.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci,cond-mat.supr-con","published":"2025-04-17T04:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.12639v1","title":"Mass measurements of proton-rich nuclei in the vicinity of ${}^{84}$Mo\n  and their impact on rp-process in type I X-ray burst","summary":"We report on the mass measurement of the rapid proton-capture process key\nnuclide ${}^{84}$Mo and its vicinity, such as ${}^{78}$Y${}^{\\rm m}$,\n${}^{79}$Y, ${}^{83}$Nb, and ${}^{88}$Ru, using the multi-reflection\ntime-of-flight spectrograph at RIKEN RIBF. For ${}^{78}$Y${}^{\\rm m}$,\n${}^{84}$Mo, and ${}^{88}$Ru, their masses are experimentally determined for\nthe first time with uncertainties of $\\delta m \\approx 20~{\\rm keV}$. The mass\nprecision of ${}^{79}$Y and ${}^{83}$Nb is improved to 13 keV and 9.6 keV,\nrespectively. The new $\\alpha$-separation energy of ${}^{84}$Mo, 1.434(83) MeV,\nunambiguously rules out the possibility of forming the ZrNb cycle. The X-ray\nburst simulation with the new masses shows that our measurements effectively\nremove the large final abundance uncertainties in the $A=80-90$ mass region.\nThe new mass values improve the prediction power for the composition of the\nnuclear ashes in X-ray bursts, including the production of light $p$-nuclei.","main_category":"nucl-ex","categories":"nucl-ex,astro-ph.HE,nucl-th","published":"2025-04-17T04:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.12648v1","title":"Enantiospecific Two-Photon Electric-Dipole Selection Rules of Chiral\n  Molecules","summary":"Distinguishing between enantiomers is crucial in the study of chiral\nmolecules in chemistry and pharmacology. Many optical approaches rely on\nenantiospecific cyclic electric-dipole transitions induced by three microwave\nor laser beams. However, these approaches impose stringent requirements,\nincluding phase locking, three-photon resonance, and precise control over beam\nintensities and operation times, which enhance the complexity and restrict the\napplicability. In this letter, we present a novel optical method that {\\it\neliminates these constraints entirely.} Specifically, we demonstrate that in\nthe presence of a static electric field, the selection rules for two-photon\nelectric-dipole transitions differ between enantiomers. This distinction arises\nbecause the static electric field breaks the symmetry associated with the\ncombined action of a specific rotation and time-reversal transformation.\nLeveraging the enantiospecific two-photon selection rule, one can selectively\nexcite a desired enantiomer using only two beams, without the need for phase\nlocking, resonance condition, and the precise control of their intensities and\noperation times. Our method significantly enhances the feasibility and\napplicability of optical approaches for enantiomer differentiation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T05:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.12655v1","title":"Optimizing low-dissipation Carnot-like thermal devices with heat leak","summary":"Delimiting the bounds of optimal performance for heat engines (HEs),\nrefrigerators (REs), and heat pumps (HPs) is a central goal in thermodynamics.\nWhile low-dissipation (LD) models have proven valuable for this purpose, the\nrole of heat leak in such models has received limited attention. Here, we\npresent a unified framework for LD Carnot-like (CL) HEs, REs, and HPs that\nincorporates heat leaks, and derive new results for the efficiency at maximum\npower and the power at maximum efficiency. We further investigate the\nrelationship between the bounds of power at fixed efficiency and efficiency at\nfixed power, demonstrating that these bounds coincide and are described by\nidentical curves across all thermal devices. Finally, we show that the optimal\nperformance of all three devices can be achieved by optimizing the average\nentropy production rate over the cycle, a result that holds for any CL device\nand extends beyond the LD assumption.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-17T05:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.12658v1","title":"Rare-Event-Induced Ergodicity Breaking in Logarithmic Aging Systems","summary":"Ergodicity breaking and aging effects are fundamental challenges in\nout-of-equilibrium systems. Various mechanisms have been proposed to understand\nthe non-ergodic and aging phenomena, possibly related to observations in\nsystems ranging from structural glass and Anderson glasses to biological\nsystems and mechanical systems. While anomalous diffusion described by Levy\nstatistics efficiently captures ergodicity breaking, the origin of aging and\nergodicity breaking in systems with ultraslow dynamics remain unclear. Here, we\nreport a novel mechanism of ergodicity breaking in systems exhibiting log-aging\ndiffusion. This mechanism, characterized by increasingly infrequent rare events\nwith aging, yields statistics deviating significantly from Levy distribution,\nbreaking ergodicity as shown by unequal time- and ensemble-averaged mean\nsquared displacements and two distinct asymptotic probability distribution\nfunctions. Notably, although these rare events contribute negligibly to\nstatistical averages, they dramatically change the system's characteristic\ntime. This work lays the groundwork for microscopic understanding of\nout-of-equilibrium systems and provides new perspectives on glasses and\nGriffiths-McCoy singularities.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.soft,cond-mat.stat-mech","published":"2025-04-17T05:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.12663v1","title":"Persona-judge: Personalized Alignment of Large Language Models via\n  Token-level Self-judgment","summary":"Aligning language models with human preferences presents significant\nchallenges, particularly in achieving personalization without incurring\nexcessive computational costs. Existing methods rely on reward signals and\nadditional annotated data, limiting their scalability and adaptability to\ndiverse human values. To address these challenges, we introduce Persona-judge,\na novel discriminative paradigm that enables training-free personalized\nalignment with unseen preferences. Instead of optimizing policy parameters\nthrough external reward feedback, Persona-judge leverages the intrinsic\npreference judgment capabilities of the model. Specifically, a draft model\ngenerates candidate tokens conditioned on a given preference, while a judge\nmodel, embodying another preference, cross-validates the predicted tokens\nwhether to be accepted. Experimental results demonstrate that Persona-judge,\nusing the inherent preference evaluation mechanisms of the model, offers a\nscalable and computationally efficient solution to personalized alignment,\npaving the way for more adaptive customized alignment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T05:50:13Z"}
{"aid":"http://arxiv.org/abs/2504.12674v1","title":"Can spacetime fluctuations generate entanglement between co-moving\n  accelerated detectors?","summary":"Recent studies [Class. Quant. Grav. 42, 03LT01 (2025); Phys. Rev. D 111,\n045023 (2025)] indicate that in a nested sequence of Rindler wedges, vacuum of\nformer Rindler frame appears to be thermally populated for an observer in\nshifted Rindler frame. Interestingly, this thermality is independent of shift\nparameter as long as it is non-zero and therefore arises even if the shift\nparameter is as small as Planck length. Building on this insight, we propose a\nset-up involving two atoms accelerating with identical acceleration. We find\nthat if their Rindler frames (consequently their trajectories) get\ninfinitesimally separated, the atoms become entangled. Remarkably again, this\nentanglement, like the perceived thermality, is independent of the shift\nparameter, provided it is non-vanishing. We investigate the dependence of\nentanglement on acceleration of the detectors. The present study indicates that\nthe entanglement between two detectors, moving on the same Rindler wedge, is\npossible. Moreover, small spacetime fluctuations can lead to entanglement\nbetween detectors, moving along same classical trajectory. Hence we feel that\nsuch theoretical prediction has potential to probe the Planck length nature of\nspacetime.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-17T06:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.12681v1","title":"GRAIL: Gradient-Based Adaptive Unlearning for Privacy and Copyright in\n  LLMs","summary":"Large Language Models (LLMs) trained on extensive datasets often learn\nsensitive information, which raises significant social and legal concerns under\nprinciples such as the \"Right to be forgotten.\" Retraining entire models from\nscratch to remove undesired information is both costly and impractical.\nFurthermore, existing single-domain unlearning methods fail to address\nmulti-domain scenarios, where knowledge is interwoven across domains such as\nprivacy and copyright, creating overlapping representations that lead to\nexcessive knowledge removal or degraded performance. To tackle these issues, we\npropose GRAIL (GRadient-based AdaptIve unLearning), a novel multi-domain\nunlearning framework. GRAIL leverages gradient information from multiple\ndomains to precisely distinguish the unlearning scope from the retention scope,\nand applies an adaptive parameter-wise localization strategy to selectively\nremove targeted knowledge while preserving critical parameters for each domain.\nExperimental results on unlearning benchmarks show that GRAIL achieves\nunlearning success on par with the existing approaches, while also\ndemonstrating up to 17% stronger knowledge retention success compared to the\nprevious state-of-art method. Our findings establish a new paradigm for\neffectively managing and regulating sensitive information in large-scale\npre-trained language models.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T06:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.12690v1","title":"Accessibility Recommendations for Designing Better Mobile Application\n  User Interfaces for Seniors","summary":"Seniors represent a growing user base for mobile applications; however, many\napps fail to adequately address their accessibility challenges and usability\npreferences. To investigate this issue, we conducted an exploratory focus group\nstudy with 16 senior participants, from which we derived an initial set of user\npersonas highlighting key accessibility and personalisation barriers. These\npersonas informed the development of a model-driven engineering toolset, which\nwas used to generate adaptive mobile app prototypes tailored to seniors' needs.\nWe then conducted a second focus group study with 22 seniors to evaluate these\nprototypes and validate our findings. Based on insights from both studies, we\ndeveloped a refined set of personas and a series of accessibility and\npersonalisation recommendations grounded in empirical data, prior research,\naccessibility standards, and developer resources, aimed at supporting software\npractitioners in designing more inclusive mobile applications.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-04-17T06:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.12743v1","title":"Quasinormal Modes and Greybody Factors of Scalar Field Perturbations in\n  the NED Corrected Charged Black Hole Spacetime","summary":"Inspired by the quark-antiquark confinement potential, Mazharimousavi et al.\n\\cite{Mazharimousavi:2023okd} proposed a nonlinear electrodynamics (NED) model,\nand based on this model, they constructed a charged black hole solution that\nincludes a logarithmic correction term ($\\propto \\frac{\\zeta \\ln r}{r}$). On\nthe basis of the Reissner-Nordstr\\\"om metric, this solution realizes a\nlong-range confinement correction by introducing the NED parameter $\\zeta$,\nproviding a new theoretical perspective for explaining the anomalies in galaxy\nrotation curves. To deeply explore the dynamic properties of this black hole\nsolution, this paper combines two complementary methods, namely, time-domain\nevolution and the WKB approximation, to calculate the quasinormal mode (QNM)\nspectrum of its scalar field perturbations. The research results show that the\noscillation frequencies and decay rates of the low-order QNM modes decrease\nmonotonically with the increase of the NED parameter $\\zeta$, and exhibit an\napproximately linear dependence. The analysis of the greybody factor (GF)\nindicates that as $\\zeta$ increases, the transmittance of the low-frequency\nscalar field also increases. The enhanced long-range confinement effect caused\nby the increase of $\\zeta$ makes low-frequency perturbations more likely to\nsurvive and propagate in space-time on the one hand, and at the same time\nenhances the transmission ability of the low-frequency scalar field. These\ncharacteristics provide key theoretical predictions and potential observational\nfeatures for testing and constraining such NED models in a strong gravitational\nfield environment in the future using the observational data of gravitational\nwave astronomy or Hawking radiation.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-17T08:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.12747v1","title":"Privacy Protection Against Personalized Text-to-Image Synthesis via\n  Cross-image Consistency Constraints","summary":"The rapid advancement of diffusion models and personalization techniques has\nmade it possible to recreate individual portraits from just a few publicly\navailable images. While such capabilities empower various creative\napplications, they also introduce serious privacy concerns, as adversaries can\nexploit them to generate highly realistic impersonations. To counter these\nthreats, anti-personalization methods have been proposed, which add adversarial\nperturbations to published images to disrupt the training of personalization\nmodels. However, existing approaches largely overlook the intrinsic multi-image\nnature of personalization and instead adopt a naive strategy of applying\nperturbations independently, as commonly done in single-image settings. This\nneglects the opportunity to leverage inter-image relationships for stronger\nprivacy protection. Therefore, we advocate for a group-level perspective on\nprivacy protection against personalization. Specifically, we introduce\nCross-image Anti-Personalization (CAP), a novel framework that enhances\nresistance to personalization by enforcing style consistency across perturbed\nimages. Furthermore, we develop a dynamic ratio adjustment strategy that\nadaptively balances the impact of the consistency loss throughout the attack\niterations. Extensive experiments on the classical CelebHQ and VGGFace2\nbenchmarks show that CAP substantially improves existing methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.12777v1","title":"Multi-Agent Reinforcement Learning Simulation for Environmental Policy\n  Synthesis","summary":"Climate policy development faces significant challenges due to deep\nuncertainty, complex system dynamics, and competing stakeholder interests.\nClimate simulation methods, such as Earth System Models, have become valuable\ntools for policy exploration. However, their typical use is for evaluating\npotential polices, rather than directly synthesizing them. The problem can be\ninverted to optimize for policy pathways, but the traditional optimization\napproaches often struggle with non-linear dynamics, heterogeneous agents, and\ncomprehensive uncertainty quantification. We propose a framework for augmenting\nclimate simulations with Multi-Agent Reinforcement Learning (MARL) to address\nthese limitations. We identify key challenges at the interface between climate\nsimulations and the application of MARL in the context of policy synthesis,\nincluding reward definition, scalability with increasing agents and state\nspaces, uncertainty propagation across linked systems, and solution validation.\nAdditionally, we discuss challenges in making MARL-derived solutions\ninterpretable and useful for policy-makers. Our framework provides a foundation\nfor more sophisticated climate policy exploration while acknowledging important\nlimitations and areas for future research.","main_category":"cs.MA","categories":"cs.MA,cs.AI","published":"2025-04-17T09:18:04Z"}
{"aid":"http://arxiv.org/abs/2504.12783v1","title":"A Battle-Lemarié Frame Characterization of Besov and Triebel-Lizorkin\n  Spaces","summary":"In this paper, we investigate a spline frame generated by oversampling\nagainst the well-known Battle-Lemari\\'e wavelet system of nonnegative integer\norder, $n$. We establish a characterization of the Besov and Triebel-Lizorkin\n(quasi-) norms for the smoothness parameter up to $s < n+1$, which includes\nvalues of $s$ where the Battle-Lemari\\'e system no longer provides an\nunconditional basis; we, additionally, prove a result for the endpoint case\n$s=n+1$. This builds off of earlier work by G. Garrig\\'os, A. Seeger, and T.\nUllrich, where they proved the case $n=0$, i.e. that of the Haar wavelet, and\nwork of R. Srivastava, where she gave a necessary range for the\nBattle-Lemari\\'e system to give an unconditional basis of the Triebel-Lizorkin\nspaces.","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-04-17T09:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.12794v1","title":"Supporting Urban Low-Altitude Economy: Channel Gain Map Inference Based\n  on 3D Conditional GAN","summary":"The advancement of advanced air mobility (AAM) in recent years has given rise\nto the concept of low-altitude economy (LAE). However, the diverse flight\nactivities associated with the emerging LAE applications in urban scenarios\nconfront complex physical environments, which urgently necessitates ubiquitous\nand reliable communication to guarantee the operation safety of the\nlow-altitude aircraft. As one of promising technologies for the sixth\ngeneration (6G) mobile networks, channel knowledge map (CKM) enables the\nenvironment-aware communication by constructing a site-specific dataset,\nthereby providing a priori on-site information for the aircraft to obtain the\nchannel state information (CSI) at arbitrary locations with much reduced online\noverhead. Diverse base station (BS) deployments in the three-dimensional (3D)\nurban low-altitude environment require efficient 3D CKM construction to capture\nspatial channel characteristics with less overhead. Towards this end, this\npaper proposes a 3D channel gain map (CGM) inference method based on a 3D\nconditional generative adversarial network (3D-CGAN). Specifically, we first\nanalyze the potential deployment types of BSs in urban low-altitude scenario,\nand investigate the CGM representation with the corresponding 3D channel gain\nmodel. The framework of the proposed 3D-CGAN is then discussed, which is\ntrained by a dataset consisting of existing CGMs. Consequently, the trained\n3D-CGAN is capable of inferring the corresponding CGM only based on the BS\ncoordinate without additional measurement. The simulation results demonstrate\nthat the CGMs inferred by the proposed 3D-CGAN outperform those of the\nbenchmark schemes, which can accurately reflect the radio propagation condition\nin 3D environment.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T09:55:03Z"}
{"aid":"http://arxiv.org/abs/2504.12800v1","title":"CAGE-GS: High-fidelity Cage Based 3D Gaussian Splatting Deformation","summary":"As 3D Gaussian Splatting (3DGS) gains popularity as a 3D representation of\nreal scenes, enabling user-friendly deformation to create novel scenes while\npreserving fine details from the original 3DGS has attracted significant\nresearch attention. We introduce CAGE-GS, a cage-based 3DGS deformation method\nthat seamlessly aligns a source 3DGS scene with a user-defined target shape.\nOur approach learns a deformation cage from the target, which guides the\ngeometric transformation of the source scene. While the cages effectively\ncontrol structural alignment, preserving the textural appearance of 3DGS\nremains challenging due to the complexity of covariance parameters. To address\nthis, we employ a Jacobian matrix-based strategy to update the covariance\nparameters of each Gaussian, ensuring texture fidelity post-deformation. Our\nmethod is highly flexible, accommodating various target shape representations,\nincluding texts, images, point clouds, meshes and 3DGS models. Extensive\nexperiments and ablation studies on both public datasets and newly proposed\nscenes demonstrate that our method significantly outperforms existing\ntechniques in both efficiency and deformation quality.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T10:00:15Z"}
{"aid":"http://arxiv.org/abs/2504.12805v1","title":"Assesing LLMs in Art Contexts: Critique Generation and Theory of Mind\n  Evaluation","summary":"This study explored how large language models (LLMs) perform in two areas\nrelated to art: writing critiques of artworks and reasoning about mental states\n(Theory of Mind, or ToM) in art-related situations. For the critique generation\npart, we built a system that combines Noel Carroll's evaluative framework with\na broad selection of art criticism theories. The model was prompted to first\nwrite a full-length critique and then shorter, more coherent versions using a\nstep-by-step prompting process. These AI-generated critiques were then compared\nwith those written by human experts in a Turing test-style evaluation. In many\ncases, human subjects had difficulty telling which was which, and the results\nsuggest that LLMs can produce critiques that are not only plausible in style\nbut also rich in interpretation, as long as they are carefully guided. In the\nsecond part, we introduced new simple ToM tasks based on situations involving\ninterpretation, emotion, and moral tension, which can appear in the context of\nart. These go beyond standard false-belief tests and allow for more complex,\nsocially embedded forms of reasoning. We tested 41 recent LLMs and found that\ntheir performance varied across tasks and models. In particular, tasks that\ninvolved affective or ambiguous situations tended to reveal clearer\ndifferences. Taken together, these results help clarify how LLMs respond to\ncomplex interpretative challenges, revealing both their cognitive limitations\nand potential. While our findings do not directly contradict the so-called\nGenerative AI Paradox--the idea that LLMs can produce expert-like output\nwithout genuine understanding--they suggest that, depending on how LLMs are\ninstructed, such as through carefully designed prompts, these models may begin\nto show behaviors that resemble understanding more closely than we might\nassume.","main_category":"cs.CL","categories":"cs.CL,cs.CY,cs.HC","published":"2025-04-17T10:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.12828v1","title":"Predicting Stock Prices using Permutation Decision Trees and Strategic\n  Trailing","summary":"In this paper, we explore the application of Permutation Decision Trees (PDT)\nand strategic trailing for predicting stock market movements and executing\nprofitable trades in the Indian stock market. We focus on high-frequency data\nusing 5-minute candlesticks for the top 50 stocks listed in the NIFTY 50 index.\nWe implement a trading strategy that aims to buy stocks at lower prices and\nsell them at higher prices, capitalizing on short-term market fluctuations. Due\nto regulatory constraints in India, short selling is not considered in our\nstrategy. The model incorporates various technical indicators and employs\nhyperparameters such as the trailing stop-loss value and support thresholds to\nmanage risk effectively. Our results indicate that the proposed trading bot has\nthe potential to outperform the market average and yield returns higher than\nthe risk-free rate offered by 10-year Indian government bonds. We trained and\ntested data on a 60 day dataset provided by Yahoo Finance. Specifically, 12\ndays for testing and 48 days for training. Our bot based on permutation\ndecision tree achieved a profit of 1.3468 % over a 12-day testing period, where\nas a bot based on LSTM gave a return of 0.1238 % over a 12-day testing period\nand a bot based on RNN gave a return of 0.3096 % over a 12-day testing period.\nAll of the bots outperform the buy-and-hold strategy, which resulted in a loss\nof 2.2508 %.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T10:42:38Z"}
{"aid":"http://arxiv.org/abs/2504.12837v1","title":"Dipole-pion cross section in the saturation regime","summary":"We analyse HERA data on leading neutron production in one-pion exchange\napproximation. The dipole-pion cross section as function of transverse\nseparation $\\bf r$ at small Bjorken variable $\\beta$ is parameterized within\nthe bSat model.\n  The evolution of the dipole-pion cross section is performed applying the\nLaplace transformation technique. We demonstrate that geometric scaling\n  for the dipole-pion cross section hold approximately within a wide kinematic\nregion of $rQ_s$. The geometrical scaling is improved applying the evolution\nmethod. That is compared with the constituent quark picture and the color\ndipole BFKL expansion. The cross section saturates at large dipole sizes.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T10:53:08Z"}
{"aid":"http://arxiv.org/abs/2504.12875v1","title":"A Client-level Assessment of Collaborative Backdoor Poisoning in Non-IID\n  Federated Learning","summary":"Federated learning (FL) enables collaborative model training using\ndecentralized private data from multiple clients. While FL has shown robustness\nagainst poisoning attacks with basic defenses, our research reveals new\nvulnerabilities stemming from non-independent and identically distributed\n(non-IID) data among clients. These vulnerabilities pose a substantial risk of\nmodel poisoning in real-world FL scenarios.\n  To demonstrate such vulnerabilities, we develop a novel collaborative\nbackdoor poisoning attack called CollaPois. In this attack, we distribute a\nsingle pre-trained model infected with a Trojan to a group of compromised\nclients. These clients then work together to produce malicious gradients,\ncausing the FL model to consistently converge towards a low-loss region\ncentered around the Trojan-infected model. Consequently, the impact of the\nTrojan is amplified, especially when the benign clients have diverse local data\ndistributions and scattered local gradients. CollaPois stands out by achieving\nits goals while involving only a limited number of compromised clients, setting\nit apart from existing attacks. Also, CollaPois effectively avoids noticeable\nshifts or degradation in the FL model's performance on legitimate data samples,\nallowing it to operate stealthily and evade detection by advanced robust FL\nalgorithms.\n  Thorough theoretical analysis and experiments conducted on various benchmark\ndatasets demonstrate the superiority of CollaPois compared to state-of-the-art\nbackdoor attacks. Notably, CollaPois bypasses existing backdoor defenses,\nespecially in scenarios where clients possess diverse data distributions.\nMoreover, the results show that CollaPois remains effective even when involving\na small number of compromised clients. Notably, clients whose local data is\nclosely aligned with compromised clients experience higher risks of backdoor\ninfections.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T12:03:02Z"}
{"aid":"http://arxiv.org/abs/2504.12877v1","title":"Market-Driven Flexibility Provision: A Tri-Level Optimization Approach\n  for Carbon Reduction","summary":"The integration of renewable energy resources (RES) in the power grid can\nreduce carbon intensity, but also presents certain challenges. The uncertainty\nand intermittent nature of RES emphasize the need for flexibility in power\nsystems. Moreover, there are noticeable mismatches between real-time\nelectricity prices and carbon intensity patterns throughout the day. These\ndiscrepancies may lead customers to schedule energy-intensive tasks during the\nearly hours of the day, a period characterized by lower electricity prices but\nhigher carbon intensity. This paper introduces a novel and comprehensive\nframework aimed at encouraging customer participation in electricity markets\nand aligning their flexibility with carbon intensity trends. The proposed\napproach integrates an incentive-based tariff with a tri-level optimization\nmodel, where customers are motivated to submit flexibility bids and, in return,\nreceive financial rewards based on their contributions. The tri-level model\nensures a dynamic interaction between the market operation platform (MOP) and\nend-users. Simulations are performed on a modified IEEE-33 bus system,\nsupported by two scenarios with different RES generations and customer\nbehaviors. Results demonstrate the effectiveness of the proposed framework in\nguiding the customers' consumption behaviors towards low carbon intensity.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-17T12:04:49Z"}
{"aid":"http://arxiv.org/abs/2504.12887v1","title":"A Novel View on the Inner Crusts of Neo-Neutron Stars: exotic light\n  nuclei, diffusional and thermodynamical stability","summary":"Based on an extended nuclear statistical equilibrium model, we investigate\nthe properties of non-accreted crusts of young and warm neo-neutron stars,\ni.e., of finite-temperature inhomogeneous dense matter in beta equilibrium. We\npresent two novel results and one known, but frequently ignored property of\nsuch matter. The first new feature is the appearance, in the deep inner crust,\nof an extensive and almost pure $^{14}$He layer that extends up to the density\nof the transition to homogeneous matter. This layer may challenge the idea of\nnuclear pasta phases, significantly impact the transport properties and the\ncrust crystallization process. Second, we raise the question of the\n(in)stability of the inner crust with respect to diffusion of ions (buoyancy)\nand demonstrate that our crust is stable, in contrast with the predictions of\nsome other models. Finally, we show that subsaturated stellar matter is\nthermodynamically stable with respect to density fluctuations, which rules out\na first-order phase transition between inhomogeneous and homogeneous phases.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-04-17T12:21:46Z"}
{"aid":"http://arxiv.org/abs/2504.12903v1","title":"Reduced Čech complexes and computing higher direct images under\n  toric maps","summary":"This paper has three main goals : (1) To give an axiomatic formulation of the\nconstruction of \"reduced \\v{C}ech complexes\", complexes using fewer than the\nusual number of intersections but still computing cohomology of sheaves; (2) To\ngive a construction of such a reduced \\v{C}ech complex for every semi-proper\ntoric variety $X$, such that every open used in the complex is torus stable,\nand such that the cell complex governing the reduced \\v{C}ech complex has\ndimension the cohomological dimension of $X$; and (3) to give an algorithm to\ncompute the higher direct images of line bundles relative to a toric fibration\nbetween smooth proper toric varieties.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T12:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.12914v1","title":"In Which Areas of Technical AI Safety Could Geopolitical Rivals\n  Cooperate?","summary":"International cooperation is common in AI research, including between\ngeopolitical rivals. While many experts advocate for greater international\ncooperation on AI safety to address shared global risks, some view cooperation\non AI with suspicion, arguing that it can pose unacceptable risks to national\nsecurity. However, the extent to which cooperation on AI safety poses such\nrisks, as well as provides benefits, depends on the specific area of\ncooperation. In this paper, we consider technical factors that impact the risks\nof international cooperation on AI safety research, focusing on the degree to\nwhich such cooperation can advance dangerous capabilities, result in the\nsharing of sensitive information, or provide opportunities for harm. We begin\nby why nations historically cooperate on strategic technologies and analyse\ncurrent US-China cooperation in AI as a case study. We further argue that\nexisting frameworks for managing associated risks can be supplemented with\nconsideration of key risks specific to cooperation on technical AI safety\nresearch. Through our analysis, we find that research into AI verification\nmechanisms and shared protocols may be suitable areas for such cooperation.\nThrough this analysis we aim to help researchers and governments identify and\nmitigate the risks of international cooperation on AI safety research, so that\nthe benefits of cooperation can be fully realised.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-17T13:03:56Z"}
{"aid":"http://arxiv.org/abs/2504.12938v1","title":"Optimal analysis of penalized lowest-order mixed FEMs for the\n  Stokes-Darcy model","summary":"This paper is concerned with non-uniform fully-mixed FEMs for dynamic coupled\nStokes-Darcy model with the well-known Beavers-Joseph-Saffman (BJS) interface\ncondition. In particular, a decoupled algorithm with the lowest-order mixed\nnon-uniform FE approximations (MINI for the Stokes equation and RT0-DG0 for the\nDarcy equation) and the classical Nitsche-type penalty is studied. The method\nwith the combined approximation of different orders is commonly used in\npractical simulations. However, the optimal error analysis of methods with\nnon-uniform approximations for the coupled Stokes-Darcy flow model has remained\nchallenging, although the analysis for uniform approximations has been well\ndone. The key question is how the lower-order approximation to the Darcy flow\ninfluences the accuracy of the Stokes solution through the interface condition.\nIn this paper, we prove that the decoupled algorithm provides a truly optimal\nconvergence rate in L^2-norm in spatial direction: O(h^2) for Stokes velocity\nand O(h) for Darcy flow in the coupled Stokes-Darcy model. This implies that\nthe lower-order approximation to the Darcy flow does not pollute the accuracy\nof numerical velocity for Stokes flow. The analysis presented in this paper is\nbased on a well-designed Stokes-Darcy Ritz projection and given for a dynamic\ncoupled model. The optimal error estimate holds for more general combined\napproximations and more general coupled models, including the corresponding\nmodel of steady-state Stokes-Darcy flows and the model of coupled dynamic\nStokes and steady-state Darcy flows. Numerical results confirm our theoretical\nanalysis and show that the decoupled algorithm is efficient.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-17T13:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.12991v1","title":"Chain-of-Thought Prompting for Out-of-Distribution Samples: A\n  Latent-Variable Study","summary":"Chain-of-Thought (CoT) prompting has emerged as a powerful technique to\nimprove in-context learning (ICL) in large language models (LLMs) by breaking\ncomplex reasoning into intermediate steps. However, the ability of CoT to\ngeneralize under distribution shift remains poorly understood. In this work, we\nextend a latent-variable framework for CoT prompting and study its behavior on\ntwo prototypical out-of-distribution (OOD) scenarios: (i) the latent variables\nfor CoT steps are permuted into novel combinations, and (ii) the latent\nvariables uniformly scaled by a factor. Our experiments demonstrate that CoT\ninference generalizes effectively to OOD samples whose latent variables closely\nresemble those seen during training, but its performance degrades as this\nsimilarity decreases. These findings provide foundational insights into the\nstrengths and limitations of CoT prompting under OOD conditions and suggest\ndirections for developing more resilient reasoning strategies in future LLMs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T14:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.13030v1","title":"High-Density Ultracold Neutron Source for Low-Energy Particle Physics\n  Experiments","summary":"SuperSUN, a new superthermal source of ultracold neutrons (UCN) at the\nInstitut Laue-Langevin, exploits inelastic scattering of neutrons in\nisotopically pure superfluid $^4$He at temperatures below $0.6\\,$K. For the\nfirst time, continuous operation with an intense broad-spectrum cold neutron\nbeam is demonstrated over 60 days. We observe continuous UCN extraction rates\nof $21000\\,$s$^{-1}$, and storage in the source with saturated\n$\\textit{in-situ}$ density $273\\,$cm$^{-3}$. The high stored density,\nlow-energy UCN spectrum, and long storage times open new possibilities in\nfundamental and applied physics.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex,nucl-ex","published":"2025-04-17T15:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.13038v1","title":"How Large Language Models Are Changing MOOC Essay Answers: A Comparison\n  of Pre- and Post-LLM Responses","summary":"The release of ChatGPT in late 2022 caused a flurry of activity and concern\nin the academic and educational communities. Some see the tool's ability to\ngenerate human-like text that passes at least cursory inspections for factual\naccuracy ``often enough'' a golden age of information retrieval and\ncomputer-assisted learning. Some, on the other hand, worry the tool may lead to\nunprecedented levels of academic dishonesty and cheating. In this work, we\nquantify some of the effects of the emergence of Large Language Models (LLMs)\non online education by analyzing a multi-year dataset of student essay\nresponses from a free university-level MOOC on AI ethics. Our dataset includes\nessays submitted both before and after ChatGPT's release. We find that the\nlaunch of ChatGPT coincided with significant changes in both the length and\nstyle of student essays, mirroring observations in other contexts such as\nacademic publishing. We also observe -- as expected based on related public\ndiscourse -- changes in prevalence of key content words related to AI and LLMs,\nbut not necessarily the general themes or topics discussed in the student\nessays as identified through (dynamic) topic modeling.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-17T15:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.13039v1","title":"Evidence for sulfur chemistry in the atmosphere of the warm sub-Neptune\n  TOI-270 d","summary":"Context: Recent JWST measurements allow access to the near-infrared spectrum\nof the sub-Neptune TOI-270 d, for which two different interpretations, a\nhigh-metallicity miscible envelope and a lower metallicity hycean world, are\ncurrently in conflict. Aims: Here, we reanalyze the published data and\nreproduce previously retrieved molecular abundances based on an independent\ndata reduction and a different retrieval framework. The aim of this study is to\nrefine the understanding of TOI-270 d and highlight considerations for JWST\ndata analysis. Additionally, we test the impact of data resolution on\natmospheric retrieval calculations. Methods: We reduce one JWST NIRSpec G395H\nand one NIRISS SOSS GR700XD transit dataset using the Eureka! pipeline and a\ncustom MCMC-based light curve fitting algorithm at the instruments' native\nresolutions. The atmospheric composition is estimated with the updated BeAR\nretrieval code across a grid of retrieval setups and spectral resolutions.\nResults: Our transit spectrum is consistent with previous studies, except at\nthe red end of the NIRISS data. Our retrievals support a higher mean molecular\nweight atmosphere for TOI-270 d. We provide refined abundance constraints and\nfind statistically favored model extensions indicating either sulfur-rich\nchemistry with species such as CS2, CS, and H2CS, or the possible presence of\nCH3Cl or CH3F. However, Bayesian inference cannot distinguish between these\nscenarios due to similar opacities below 4 microns. Conclusions: Our analysis\nreinforces TOI-270 d as a highly interesting warm sub-Neptune for atmospheric\nstudies, with a complex chemistry in a cloud-free upper atmosphere. However,\nits exact nature remains uncertain and warrants further detailed photochemical\nmodeling and observations.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-17T15:52:23Z"}
{"aid":"http://arxiv.org/abs/2504.13054v1","title":"Aspect-Based Summarization with Self-Aspect Retrieval Enhanced\n  Generation","summary":"Aspect-based summarization aims to generate summaries tailored to specific\naspects, addressing the resource constraints and limited generalizability of\ntraditional summarization approaches. Recently, large language models have\nshown promise in this task without the need for training. However, they rely\nexcessively on prompt engineering and face token limits and hallucination\nchallenges, especially with in-context learning. To address these challenges,\nin this paper, we propose a novel framework for aspect-based summarization:\nSelf-Aspect Retrieval Enhanced Summary Generation. Rather than relying solely\non in-context learning, given an aspect, we employ an embedding-driven\nretrieval mechanism to identify its relevant text segments. This approach\nextracts the pertinent content while avoiding unnecessary details, thereby\nmitigating the challenge of token limits. Moreover, our framework optimizes\ntoken usage by deleting unrelated parts of the text and ensuring that the model\ngenerates output strictly based on the given aspect. With extensive experiments\non benchmark datasets, we demonstrate that our framework not only achieves\nsuperior performance but also effectively mitigates the token limitation\nproblem.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T16:09:57Z"}
{"aid":"http://arxiv.org/abs/2504.13055v1","title":"NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation","summary":"Recent advances in reinforcement learning (RL) have strengthened the\nreasoning capabilities of vision-language models (VLMs). However, enhancing\npolicy exploration to more effectively scale test-time compute remains\nunderexplored in VLMs. In addition, VLMs continue to struggle with imperfect\nvisual perception, which in turn affects the subsequent reasoning process. To\nthis end, we propose NoisyRollout, a simple yet effective RL approach that\nmixes trajectories from both clean and moderately distorted images to introduce\ntargeted diversity in visual perception and the resulting reasoning patterns.\nWithout additional training cost, NoisyRollout enhances the exploration\ncapabilities of VLMs by incorporating a vision-oriented inductive bias.\nFurthermore, NoisyRollout employs a noise annealing schedule that gradually\nreduces distortion strength over training, ensuring benefit from noisy signals\nearly while maintaining training stability and scalability in later stages.\nWith just 2.1K training samples, NoisyRollout achieves state-of-the-art\nperformance among open-source RL-tuned models on 5 out-of-domain benchmarks\nspanning both reasoning and perception tasks, while preserving comparable or\neven better in-domain performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:10:13Z"}
{"aid":"http://arxiv.org/abs/2504.13062v1","title":"Seeing Beyond Dark-Field RGB Capabilities: Deep Spectral Extrapolation\n  of Ultrasmall Plasmonic Nanogaps","summary":"Localized surface plasmons can confine light within a deep-subwavelength\nvolume comparable to the scale of atoms and molecules, enabling ultrasensitive\nresponses to near-field variations. On the other hand, this extreme\nlocalization also inevitably amplifies the unwanted noise from the response of\nlocal morphological imperfections, leading to complex spectral variations and\nreduced consistency across the plasmonic nanostructures. Seeking uniform\noptical responses has therefore long been a sought-after goal in\nnanoplasmonics. However, conventional probing techniques by dark-field (DF)\nconfocal microscopy, such as image analysis or spectral measurements, can be\ninaccurate and time-consuming, respectively. Here, we introduce SPARX, a\ndeep-learning-powered paradigm that surpasses conventional imaging and\nspectroscopic capabilities. In particular, SPARX can batch-predict broadband DF\nspectra (e.g., 500-1000 nm) of numerous nanoparticles simultaneously from an\ninformation-limited RGB image (i.e., below 700 nm). It achieves this\nextrapolative inference beyond the camera's capture capabilities by learning\nthe underlying physical relationships among multiple orders of optical\nresonances. The spectral predictions only take milliseconds, achieving a\nspeedup of three to four orders of magnitude compared to traditional spectral\nacquisition, which may take from hours to days. As a proof-of-principle\ndemonstration for screening identical resonances, the selection accuracy\nachieved by SPARX is comparable to that of conventional spectroscopy\ntechniques. This breakthrough paves the way for consistent plasmonic\napplications and next-generation microscopies.","main_category":"physics.optics","categories":"physics.optics,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-17T16:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.13094v1","title":"Symmetry classification and invariant solutions of the classical\n  geometric mean reversion process","summary":"Based on the Lie symmetry method, we investigate a Feynman-Kac formula for\nthe classical geometric mean reversion process, which effectively describing\nthe dynamics of short-term interest rates. The Lie algebra of infinitesimal\nsymmetries and the corresponding one-parameter symmetry groups of the equation\nare obtained. An optimal system of invariant solutions are constructed by a\nderived optimal system of one-dimensional subalgebras. Because of taking into\naccount a supply response to price rises, this equation provides for a more\nrealistic assumption than the geometric Brownian motion in many investment\nscenarios.","main_category":"math.DS","categories":"math.DS,math.AP,math.PR,q-fin.MF","published":"2025-04-17T16:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.13102v1","title":"A Multi-task Learning Balanced Attention Convolutional Neural Network\n  Model for Few-shot Underwater Acoustic Target Recognition","summary":"Underwater acoustic target recognition (UATR) is of great significance for\nthe protection of marine diversity and national defense security. The\ndevelopment of deep learning provides new opportunities for UATR, but faces\nchallenges brought by the scarcity of reference samples and complex\nenvironmental interference. To address these issues, we proposes a multi-task\nbalanced channel attention convolutional neural network (MT-BCA-CNN). The\nmethod integrates a channel attention mechanism with a multi-task learning\nstrategy, constructing a shared feature extractor and multi-task classifiers to\njointly optimize target classification and feature reconstruction tasks. The\nchannel attention mechanism dynamically enhances discriminative acoustic\nfeatures such as harmonic structures while suppressing noise. Experiments on\nthe Watkins Marine Life Dataset demonstrate that MT-BCA-CNN achieves 97\\%\nclassification accuracy and 95\\% $F1$-score in 27-class few-shot scenarios,\nsignificantly outperforming traditional CNN and ACNN models, as well as popular\nstate-of-the-art UATR methods. Ablation studies confirm the synergistic\nbenefits of multi-task learning and attention mechanisms, while a dynamic\nweighting adjustment strategy effectively balances task contributions. This\nwork provides an efficient solution for few-shot underwater acoustic\nrecognition, advancing research in marine bioacoustics and sonar signal\nprocessing.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-17T17:11:32Z"}
{"aid":"http://arxiv.org/abs/2504.13123v1","title":"Low-hallucination Synthetic Captions for Large-Scale Vision-Language\n  Model Pre-training","summary":"In recent years, the field of vision-language model pre-training has\nexperienced rapid advancements, driven primarily by the continuous enhancement\nof textual capabilities in large language models. However, existing training\nparadigms for multimodal large language models heavily rely on high-quality\nimage-text pairs. As models and data scales grow exponentially, the\navailability of such meticulously curated data has become increasingly scarce\nand saturated, thereby severely limiting further advancements in this domain.\nThis study investigates scalable caption generation techniques for\nvision-language model pre-training and demonstrates that large-scale\nlow-hallucination synthetic captions can serve dual purposes: 1) acting as a\nviable alternative to real-world data for pre-training paradigms and 2)\nachieving superior performance enhancement when integrated into vision-language\nmodels through empirical validation. This paper presents three key\ncontributions: 1) a novel pipeline for generating high-quality,\nlow-hallucination, and knowledge-rich synthetic captions. Our continuous DPO\nmethodology yields remarkable results in reducing hallucinations. Specifically,\nthe non-hallucination caption rate on a held-out test set increases from 48.2%\nto 77.9% for a 7B-size model. 2) Comprehensive empirical validation reveals\nthat our synthetic captions confer superior pre-training advantages over their\ncounterparts. Across 35 vision language tasks, the model trained with our data\nachieves a significant performance gain of at least 6.2% compared to alt-text\npairs and other previous work. Meanwhile, it also offers considerable support\nin the text-to-image domain. With our dataset, the FID score is reduced by 17.1\non a real-world validation benchmark and 13.3 on the MSCOCO validation\nbenchmark. 3) We will release Hunyuan-Recap100M, a low-hallucination and\nknowledge-intensive synthetic caption dataset.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T17:40:06Z"}
{"aid":"http://arxiv.org/abs/2504.13128v1","title":"FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on\n  Technical Documents","summary":"We introduce FreshStack, a reusable framework for automatically building\ninformation retrieval (IR) evaluation benchmarks from community-asked questions\nand answers. FreshStack conducts the following steps: (1) automatic corpus\ncollection from code and technical documentation, (2) nugget generation from\ncommunity-asked questions and answers, and (3) nugget-level support, retrieving\ndocuments using a fusion of retrieval techniques and hybrid architectures. We\nuse FreshStack to build five datasets on fast-growing, recent, and niche topics\nto ensure the tasks are sufficiently challenging. On FreshStack, existing\nretrieval models, when applied out-of-the-box, significantly underperform\noracle approaches on all five topics, denoting plenty of headroom to improve IR\nquality. In addition, we identify cases where rerankers do not clearly improve\nfirst-stage retrieval accuracy (two out of five topics). We hope that\nFreshStack will facilitate future work toward constructing realistic, scalable,\nand uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are\navailable at: https://fresh-stack.github.io.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-17T17:44:06Z"}
{"aid":"http://arxiv.org/abs/2504.13133v1","title":"Giant nematic response of the incommensurate charge density wave in the\n  nickel-pnictide Ba$_{1-x}$Sr$_x$Ni$_2$As$_2$","summary":"Electron nematicity-the breaking of rotational symmetry while preserving\ntranslational symmetry-is the quantum analogue of classical nematic liquid\ncrystals. First predicted in 1998, electronic nematicity has been established\nin a variety of materials, including two-dimensional electron gases (2DEGs) in\nmagnetic fields, copper-oxide superconductors, and Fe-based superconductors. A\nlong-standing open question is what physical mechanisms drive electronic\nnematic order. In BaFe$_2$As$_2$ and highly underdoped YBa$_2$Cu$_3$O$_{6+y}$,\nstrong evidence suggests that nematicity arises from vestigial\nspin-density-wave (SDW) order. However, evidence for nematicity associated with\ncharge-density-wave (CDW) order has been less conclusive, particularly in\nsystems near a superconducting state. Here, we present direct evidence for\nCDW-driven nematic fluctuations in the pnictide superconductor\nBa$_{1-x}$Sr$_x$Ni$_2$As$_2$ (BSNA), a Ni-based homologue of Fe-based\nsuperconductors that exhibits CDW rather than SDW order. Previous\nelastoresistance studies have shown that BSNA displays a large nematic\nsusceptibility-linked to a six-fold enhancement of superconductivity-within a\nregion of the phase diagram occupied by an incommensurate CDW. Using x-ray\nscattering under uniaxial strain, we demonstrate that even minimal strain\nlevels ($\\epsilon \\sim 10^{-4}$) significantly break the fourfold symmetry of\nthe CDW. Within a Ginzburg-Landau framework, we define a nematic susceptibility\nbased on the asymmetric response of symmetry-related CDW superlattice\nreflections, showing strong agreement with elastoresistivity measurements. Our\nstudy provides the first clear demonstration of a direct link between charge\norder and a nematic state, offering key insights into the intertwined\nsuperconducting phases of these materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-17T17:47:04Z"}
{"aid":"http://arxiv.org/abs/2504.13134v1","title":"Energy-Based Reward Models for Robust Language Model Alignment","summary":"Reward models (RMs) are essential for aligning Large Language Models (LLMs)\nwith human preferences. However, they often struggle with capturing complex\nhuman preferences and generalizing to unseen data. To address these challenges,\nwe introduce Energy-Based Reward Model (EBRM), a lightweight post-hoc\nrefinement framework that enhances RM robustness and generalization. EBRM\nmodels the reward distribution explicitly, capturing uncertainty in human\npreferences and mitigating the impact of noisy or misaligned annotations. It\nachieves this through conflict-aware data filtering, label-noise-aware\ncontrastive training, and hybrid initialization. Notably, EBRM enhances RMs\nwithout retraining, making it computationally efficient and adaptable across\ndifferent models and tasks. Empirical evaluations on RM benchmarks demonstrate\nsignificant improvements in both robustness and generalization, achieving up to\na 5.97% improvement in safety-critical alignment tasks compared to standard\nRMs. Furthermore, reinforcement learning experiments confirm that our refined\nrewards enhance alignment quality, effectively delaying reward hacking. These\nresults demonstrate our approach as a scalable and effective enhancement for\nexisting RMs and alignment pipelines. The code is available at EBRM.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-17T17:47:15Z"}
{"aid":"http://arxiv.org/abs/2504.13142v1","title":"Transfer Learning via Auxiliary Labels with Application to\n  Cold-Hardiness Prediction","summary":"Cold temperatures can cause significant frost damage to fruit crops depending\non their resilience, or cold hardiness, which changes throughout the dormancy\nseason. This has led to the development of predictive cold-hardiness models,\nwhich help farmers decide when to deploy expensive frost-mitigation measures.\nUnfortunately, cold-hardiness data for model training is only available for\nsome fruit cultivars due to the need for specialized equipment and expertise.\nRather, farmers often do have years of phenological data (e.g. date of\nbudbreak) that they regularly collect for their crops. In this work, we\nintroduce a new transfer-learning framework, Transfer via Auxiliary Labels\n(TAL), that allows farmers to leverage the phenological data to produce more\naccurate cold-hardiness predictions, even when no cold-hardiness data is\navailable for their specific crop. The framework assumes a set of source tasks\n(cultivars) where each has associated primary labels (cold hardiness) and\nauxiliary labels (phenology). However, the target task (new cultivar) is\nassumed to only have the auxiliary labels. The goal of TAL is to predict\nprimary labels for the target task via transfer from the source tasks.\nSurprisingly, despite the vast literature on transfer learning, to our\nknowledge, the TAL formulation has not been previously addressed. Thus, we\npropose several new TAL approaches based on model selection and averaging that\ncan leverage recent deep multi-task models for cold-hardiness prediction. Our\nresults on real-world cold-hardiness and phenological data for multiple grape\ncultivars demonstrate that TAL can leverage the phenological data to improve\ncold-hardiness predictions in the absence of cold-hardiness data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T17:51:38Z"}
{"aid":"http://arxiv.org/abs/2504.13150v1","title":"Readable Twins of Unreadable Models","summary":"Creating responsible artificial intelligence (AI) systems is an important\nissue in contemporary research and development of works on AI. One of the\ncharacteristics of responsible AI systems is their explainability. In the\npaper, we are interested in explainable deep learning (XDL) systems. On the\nbasis of the creation of digital twins of physical objects, we introduce the\nidea of creating readable twins (in the form of imprecise information flow\nmodels) for unreadable deep learning models. The complete procedure for\nswitching from the deep learning model (DLM) to the imprecise information flow\nmodel (IIFM) is presented. The proposed approach is illustrated with an example\nof a deep learning classification model for image recognition of handwritten\ndigits from the MNIST data set.","main_category":"cs.AI","categories":"cs.AI,cs.CV","published":"2025-04-17T17:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.13162v1","title":"Personalized Text-to-Image Generation with Auto-Regressive Models","summary":"Personalized image synthesis has emerged as a pivotal application in\ntext-to-image generation, enabling the creation of images featuring specific\nsubjects in diverse contexts. While diffusion models have dominated this\ndomain, auto-regressive models, with their unified architecture for text and\nimage modeling, remain underexplored for personalized image generation. This\npaper investigates the potential of optimizing auto-regressive models for\npersonalized image synthesis, leveraging their inherent multimodal capabilities\nto perform this task. We propose a two-stage training strategy that combines\noptimization of text embeddings and fine-tuning of transformer layers. Our\nexperiments on the auto-regressive model demonstrate that this method achieves\ncomparable subject fidelity and prompt following to the leading diffusion-based\npersonalization methods. The results highlight the effectiveness of\nauto-regressive models in personalized image generation, offering a new\ndirection for future research in this area.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.13165v1","title":"RUKA: Rethinking the Design of Humanoid Hands with Learning","summary":"Dexterous manipulation is a fundamental capability for robotic systems, yet\nprogress has been limited by hardware trade-offs between precision,\ncompactness, strength, and affordability. Existing control methods impose\ncompromises on hand designs and applications. However, learning-based\napproaches present opportunities to rethink these trade-offs, particularly to\naddress challenges with tendon-driven actuation and low-cost materials. This\nwork presents RUKA, a tendon-driven humanoid hand that is compact, affordable,\nand capable. Made from 3D-printed parts and off-the-shelf components, RUKA has\n5 fingers with 15 underactuated degrees of freedom enabling diverse human-like\ngrasps. Its tendon-driven actuation allows powerful grasping in a compact,\nhuman-sized form factor. To address control challenges, we learn\njoint-to-actuator and fingertip-to-actuator models from motion-capture data\ncollected by the MANUS glove, leveraging the hand's morphological accuracy.\nExtensive evaluations demonstrate RUKA's superior reachability, durability, and\nstrength compared to other robotic hands. Teleoperation tasks further showcase\nRUKA's dexterous movements. The open-source design and assembly instructions of\nRUKA, code, and data are available at https://ruka-hand.github.io/.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-17T17:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.13167v1","title":"ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from\n  Monocular Videos","summary":"Creating a photorealistic scene and human reconstruction from a single\nmonocular in-the-wild video figures prominently in the perception of a\nhuman-centric 3D world. Recent neural rendering advances have enabled holistic\nhuman-scene reconstruction but require pre-calibrated camera and human poses,\nand days of training time. In this work, we introduce a novel unified framework\nthat simultaneously performs camera tracking, human pose estimation and\nhuman-scene reconstruction in an online fashion. 3D Gaussian Splatting is\nutilized to learn Gaussian primitives for humans and scenes efficiently, and\nreconstruction-based camera tracking and human pose estimation modules are\ndesigned to enable holistic understanding and effective disentanglement of pose\nand appearance. Specifically, we design a human deformation module to\nreconstruct the details and enhance generalizability to out-of-distribution\nposes faithfully. Aiming to learn the spatial correlation between human and\nscene accurately, we introduce occlusion-aware human silhouette rendering and\nmonocular geometric priors, which further improve reconstruction quality.\nExperiments on the EMDB and NeuMan datasets demonstrate superior or on-par\nperformance with existing methods in camera tracking, human pose estimation,\nnovel view synthesis and runtime. Our project page is at\nhttps://eth-ait.github.io/ODHSR.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-17T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.13169v1","title":"Generate, but Verify: Reducing Hallucination in Vision-Language Models\n  with Retrospective Resampling","summary":"Vision-Language Models (VLMs) excel at visual understanding but often suffer\nfrom visual hallucinations, where they generate descriptions of nonexistent\nobjects, actions, or concepts, posing significant risks in safety-critical\napplications. Existing hallucination mitigation methods typically follow one of\ntwo paradigms: generation adjustment, which modifies decoding behavior to align\ntext with visual inputs, and post-hoc verification, where external models\nassess and correct outputs. While effective, generation adjustment methods\noften rely on heuristics and lack correction mechanisms, while post-hoc\nverification is complicated, typically requiring multiple models and tending to\nreject outputs rather than refine them. In this work, we introduce REVERSE, a\nunified framework that integrates hallucination-aware training with on-the-fly\nself-verification. By leveraging a new hallucination-verification dataset\ncontaining over 1.3M semi-synthetic samples, along with a novel inference-time\nretrospective resampling technique, our approach enables VLMs to both detect\nhallucinations during generation and dynamically revise those hallucinations.\nOur evaluations show that REVERSE achieves state-of-the-art hallucination\nreduction, outperforming the best existing methods by up to 12% on CHAIR-MSCOCO\nand 28% on HaloQuest. Our dataset, model, and code are available at:\nhttps://reverse-vlm.github.io.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.14871v1","title":"Natural Fingerprints of Large Language Models","summary":"Large language models (LLMs) often exhibit biases -- systematic deviations\nfrom expected norms -- in their outputs. These range from overt issues, such as\nunfair responses, to subtler patterns that can reveal which model produced\nthem. We investigate the factors that give rise to identifiable characteristics\nin LLMs. Since LLMs model training data distribution, it is reasonable that\ndifferences in training data naturally lead to the characteristics. However,\nour findings reveal that even when LLMs are trained on the exact same data, it\nis still possible to distinguish the source model based on its generated text.\nWe refer to these unintended, distinctive characteristics as natural\nfingerprints. By systematically controlling training conditions, we show that\nthe natural fingerprints can emerge from subtle differences in the training\nprocess, such as parameter sizes, optimization settings, and even random seeds.\nWe believe that understanding natural fingerprints offers new insights into the\norigins of unintended bias and ways for improving control over LLM behavior.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T05:48:52Z"}
{"aid":"http://arxiv.org/abs/2504.14881v1","title":"Towards Fuzzing Zero-Knowledge Proof Circuits (Short Paper)","summary":"Zero-knowledge proofs (ZKPs) have evolved from a theoretical cryptographic\nconcept into a powerful tool for implementing privacy-preserving and verifiable\napplications without requiring trust assumptions. Despite significant progress\nin the field, implementing and using ZKPs via \\emph{ZKP circuits} remains\nchallenging, leading to numerous bugs that affect ZKP circuits in practice, and\n\\emph{fuzzing} remains largely unexplored as a method to detect bugs in ZKP\ncircuits. We discuss the unique challenges of applying fuzzing to ZKP circuits,\nexamine the oracle problem and its potential solutions, and propose techniques\nfor input generation and test harness construction. We demonstrate that fuzzing\ncan be effective in this domain by implementing a fuzzer for \\texttt{zk-regex},\na cornerstone library in modern ZKP applications. In our case study, we\ndiscovered \\textit{$10$} new bugs.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-21T06:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.14907v1","title":"Dynamic Graph-Like Learning with Contrastive Clustering on\n  Temporally-Factored Ship Motion Data for Imbalanced Sea State Estimation in\n  Autonomous Vessel","summary":"Accurate sea state estimation is crucial for the real-time control and future\nstate prediction of autonomous vessels. However, traditional methods struggle\nwith challenges such as data imbalance and feature redundancy in ship motion\ndata, limiting their effectiveness. To address these challenges, we propose the\nTemporal-Graph Contrastive Clustering Sea State Estimator (TGC-SSE), a novel\ndeep learning model that combines three key components: a time dimension\nfactorization module to reduce data redundancy, a dynamic graph-like learning\nmodule to capture complex variable interactions, and a contrastive clustering\nloss function to effectively manage class imbalance. Our experiments\ndemonstrate that TGC-SSE significantly outperforms existing methods across 14\npublic datasets, achieving the highest accuracy in 9 datasets, with a 20.79%\nimprovement over EDI. Furthermore, in the field of sea state estimation,\nTGC-SSE surpasses five benchmark methods and seven deep learning models.\nAblation studies confirm the effectiveness of each module, demonstrating their\nrespective roles in enhancing overall model performance. Overall, TGC-SSE not\nonly improves the accuracy of sea state estimation but also exhibits strong\ngeneralization capabilities, providing reliable support for autonomous vessel\noperations.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T07:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.14912v1","title":"Dynamics of pulsating swarmalators on a ring","summary":"We study a simple one-dimensional model of swarmalators, a generalization of\nphase oscillators that swarm around in space as well as synchronize internal\noscillations in time. Previous studies of the model focused on Kuramoto-type\ncouplings, where the phase interactions are governed by phase differences. Here\nwe consider Winfree-type coupling, where the interactions are multiplicative,\ndetermined by the product of a phase response function $R(\\theta)$ and phase\npulse function $P(\\theta)$. This more general interaction (from which the\nKuramoto phase differences emerge after averaging) produces rich physics: six\nlong-term modes of organization are found, which we characterize numerically\nand analytically.","main_category":"nlin.AO","categories":"nlin.AO,math-ph,math.MP","published":"2025-04-21T07:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.14914v1","title":"K-DRIFT Preparation: Experimental Verification of an Observation\n  Strategy for Accurate Dark-Sky Flats","summary":"Despite its scientific importance, the low-surface-brightness universe has\nyet to be fully explored due to various systematic uncertainties that affect\nthe achievable surface-brightness limit. Reducing these uncertainties requires\nvery accurate data processing. The dark-sky flat is a widely used calibration\nframe for accurate flat-field correction, generated by combining the sky\nbackground from science images. However, the night sky will likely contain\ncomplex local fluctuations, thus may still lead to photometric errors in data\ncalibrated with dark-sky flats. To address this concern, we conduct mock\nobservations with semi-realistic sky simulation data and evaluate observation\nstrategies to mitigate the impact of the fluctuating sky background. Our\nexperiments consider two representative sky conditions (clear and dirty) and\nperform intensive comparative analysis on two observation methods (offset and\nrolling). Our findings suggest that the rolling dithering method, which\nincorporates the operation of camera rotation into conventional dithering, can\nprovide more accurate dark-sky flats. Finally, we discuss the broader\nimplications of this method through additional experiments examining several\nfactors that may affect the imaging quality of observational data.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.GA","published":"2025-04-21T07:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.14919v1","title":"GenCLIP: Generalizing CLIP Prompts for Zero-shot Anomaly Detection","summary":"Zero-shot anomaly detection (ZSAD) aims to identify anomalies in unseen\ncategories by leveraging CLIP's zero-shot capabilities to match text prompts\nwith visual features. A key challenge in ZSAD is learning general prompts\nstably and utilizing them effectively, while maintaining both generalizability\nand category specificity. Although general prompts have been explored in prior\nworks, achieving their stable optimization and effective deployment remains a\nsignificant challenge. In this work, we propose GenCLIP, a novel framework that\nlearns and leverages general prompts more effectively through multi-layer\nprompting and dual-branch inference. Multi-layer prompting integrates\ncategory-specific visual cues from different CLIP layers, enriching general\nprompts with more comprehensive and robust feature representations. By\ncombining general prompts with multi-layer visual features, our method further\nenhances its generalization capability. To balance specificity and\ngeneralization, we introduce a dual-branch inference strategy, where a\nvision-enhanced branch captures fine-grained category-specific features, while\na query-only branch prioritizes generalization. The complementary outputs from\nboth branches improve the stability and reliability of anomaly detection across\nunseen categories. Additionally, we propose an adaptive text prompt filtering\nmechanism, which removes irrelevant or atypical class names not encountered\nduring CLIP's training, ensuring that only meaningful textual inputs contribute\nto the final vision-language alignment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.14940v1","title":"Gigaparsec structures are nowhere to be seen in $Λ$CDM: an\n  enhanced analysis of LSS in FLAMINGO-10K simulations","summary":"Recently, Sawala et al. 2025 claimed to refute the cosmological significance\nof the Giant Arc based on their analysis of the FLAMINGO-10K simulation data.\nIn our paper here, we highlight several shortcomings of the authors' analysis.\nWe then perform an enhanced analysis on the FLAMINGO-10K simulation data with\napplications of: the Single-Linkage Hierarchical Clustering (SLHC), the Convex\nHull of Member Spheres (CHMS), and the Minimal Spanning Tree (MST) algorithms.\nUsing the full $2.8^3$ Gpc$^3$ FLAMINGO-10K box, with subhaloes at $z=0.7$, and\n$100$ random realisations (from random subset selections) we find no gigaparsec\nstructures in FLAMINGO-10K, and only a few ultra-large large-scale structures\n(uLSSs, structures exceeding a maximum pairwise separation of $370$ Mpc).\nSomewhat surprisingly, we found that the large-scale aspects of the\nFLAMINGO-10K data could be adequately represented by a Poisson point\ndistribution. The enhanced analysis presented here further supports the\nremarkable nature of the Giant Arc as a cosmologically-significant structure.\nOf course, the Giant Arc is also accompanied by a second uLSS, the Big Ring.\nThe analysis presented here builds on the work presented by Sawala et al., but\namends the application of their statistical assessments. We do not yet know why\nthere appears to be such a large discrepancy between the FLAMINGO-10K data and\nthe observed LSS in MgII absorbers. Perhaps the results presented here might\nsuggest that the GA, and especially the GA + BR, presents a more direct\nchallenge to $\\Lambda$CDM. In contrast to the conclusion of Sawala et al. that\n`gigaparsec patterns abound in a $\\Lambda$CDM universe' we find that they are\nnowhere to be seen.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T08:02:11Z"}
{"aid":"http://arxiv.org/abs/2504.14949v1","title":"Photoinduced DC Hall current in few-layer black phosphorus with a\n  gate-tunable Floquet gap","summary":"We theoretically explore Floquet engineering in few-layer black phosphorus\n(fBP) under time-periodic driving. Motivated by the ability of circularly\npolarized light to induce nontrivial topological states at Dirac nodes, we\ninvestigate the emergence of a photoinduced DC Hall effect in the Dirac\nsemimetal phase of fBP. Starting from a low-energy continuum model, we derive\nthe effective Floquet Hamiltonian and analytically calculate the Berry\ncurvature, demonstrating the opening of a topological gap. We also perform\nlattice-model calculations incorporating a self-consistent Hartree method to\ncompute Floquet band structures and DC Hall conductivity under a perpendicular\nelectric field. Our results reveal that the DC Hall current in fBP can be\neffectively tuned via a periodic driving field and electrostatic gating.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-21T08:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.14974v1","title":"Nonreciprocal photon blockade induced by parametric amplification in an\n  asymmetrical cavity","summary":"We propose a scheme to generate and manipulate nonreciprocal photon blockade\neffect in an asymmetrical Fabry-P\\'{e}rot cavity, which consists of a single\ntwo-level atom and a second-order nonlinear medium. By utilizing the intrinsic\nspatial asymmetry of cavity and applying a parametric amplification pumping\nlaser to the nonlinear medium, we can realize direction-dependent single-photon\nand two-photon blockade effects. For nonreciprocal single-photon blockade, our\nproposal is robust across a wide range of parameters, such as the cavity or\natomic detuning, coupling strength, and atomic decay. Within similar parameter\nranges, nonreciprocal two-photon blockade can be achieved and modulated by\nfinely adjusting the parametric amplification pumping. Our project offers a\nfeasible access to generating high-quality and tunable nonreciprocal\nsingle/two-photon source and paves a new avenue for investigating the\nnonreciprocity of photon quantum statistical properties.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T09:00:37Z"}
{"aid":"http://arxiv.org/abs/2504.14985v1","title":"aiXamine: LLM Safety and Security Simplified","summary":"Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-21T09:26:05Z"}
{"aid":"http://arxiv.org/abs/2504.14989v1","title":"Dynamic Legged Ball Manipulation on Rugged Terrains with Hierarchical\n  Reinforcement Learning","summary":"Advancing the dynamic loco-manipulation capabilities of quadruped robots in\ncomplex terrains is crucial for performing diverse tasks. Specifically, dynamic\nball manipulation in rugged environments presents two key challenges. The first\nis coordinating distinct motion modalities to integrate terrain traversal and\nball control seamlessly. The second is overcoming sparse rewards in end-to-end\ndeep reinforcement learning, which impedes efficient policy convergence. To\naddress these challenges, we propose a hierarchical reinforcement learning\nframework. A high-level policy, informed by proprioceptive data and ball\nposition, adaptively switches between pre-trained low-level skills such as ball\ndribbling and rough terrain navigation. We further propose Dynamic\nSkill-Focused Policy Optimization to suppress gradients from inactive skills\nand enhance critical skill learning. Both simulation and real-world experiments\nvalidate that our methods outperform baseline approaches in dynamic ball\nmanipulation across rugged terrains, highlighting its effectiveness in\nchallenging environments. Videos are on our website: dribble-hrl.github.io.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T09:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.14998v1","title":"Decay of mass for a semilinear heat equation on Heisenberg group","summary":"In this paper, we are concerned with the Cauchy problem for the\nreaction-diffusion equation with time-dependent absorption\n$u_{t}-\\Delta_{\\mathbb{H}}u=- k(t)u^p$ posed on $\\mathbb{H}^n$, driven by the\nHeisenberg Laplacian and supplemented with a nonnegative integrable initial\ndata, where $p>1$, $n\\geq 1$, and $k:(0,\\infty)\\to(0,\\infty)$ is a locally\nintegrable function. We study the large time behavior of non-negative solutions\nand show that the nonlinear term determines the large time asymptotic for\n$p\\leq 1+2/Q,$ while the classical/anomalous diffusion effects win if\n$p>1+{2}/{Q}$, where $Q=2n+2$ is the homogeneous dimension of $\\mathbb{H}^n$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-21T09:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.15033v1","title":"Blinding the Wiretapper: RIS-Enabled User Occultation in the ISAC Era","summary":"An undesirable consequence of the foreseeable proliferation of sophisticated\nintegrated sensing and communications (ISAC) technologies is the enabling of\nspoofing, by malicious agents, of situational information (such as proximity,\ndirection or location) of legitimate users of wireless systems. In order to\nmitigate this threat, we present a novel ISAC scheme that, aided by a\nreconfigurable intelligent surface (RIS), enables the occultation of the\npositions of user equipment (UE) from wiretappers, while maintaining both\nsensing and desired communication performance between the UEs and a legitimate\nbase station (BS). To that end, we first formulate an RIS phase-shift\noptimization problem that jointly maximizes the sum-rate performance of the UEs\n(communication objective), while minimizing the projection of the wiretapper's\neffective channel onto the legitimate channel (hiding objective), thereby\ndisrupting the attempts by a wiretapper of localizing the UEs. Then, in order\nto efficiently solve the resulting non-convex joint optimization problem, a\nnovel manifold optimization algorithm is derived, whose effectiveness is\nvalidated by numerical results, which demonstrate that the proposed approach\npreserves legitimate ISAC performance while significantly degrading the\nwiretapper's sensing capability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T11:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.15034v1","title":"Predicting Methane Adsorption in Metal-Substituted MOFs: A Comparative\n  Study between Density Functional Theory and Machine Learning","summary":"Metal-organic frameworks (MOFs) are promising materials for methane capture\ndue to their high surface area and tunable properties. Metal substitution\nrepresents a powerful strategy to enhance MOF performance, yet systematic\nexploration of the vast chemical space remains challenging. In this work, we\ncompare density functional theory (DFT) and machine learning (ML) in predicting\nmethane adsorption properties in metal-substituted variants of three\nhigh-performing MOFs: M-HKUST-1, M-ATC, and M-ZIF-8 (M = Cu, Zn). DFT\ncalculations reveal significant differences in methane binding energetics\nbetween Cu and Zn variants of all three MOFs. On the other hand, we fine-tuned\na pretrained multimodal ML model, PMTransformer, on a curated subset of\nhypothetical MOF (hMOF) structures to predict macroscopic adsorption\nproperties. While the model qualitatively predicts adsorption properties for\nthe original unaltered MOFs, it fails to distinguish between metal variants\ndespite their different binding energetics identified by DFT. We trace this\nlimitation to the hMOF training data generated using Grand Canonical Monte\nCarlo (GCMC) simulations based on classical force fields (UFF/TraPPE). Our\nstudy highlights a key challenge in ML-based MOF screening: ML models inherit\nthe limitations of their training data, particularly when electronic effects\nsignificantly impact adsorption behavior. Our findings emphasize the need for\nimproved force fields or hybrid GCMC/DFT datasets to incorporate both geometric\nand electronic factors for accurate prediction of adsorption properties in\nmetal-substituted MOFs.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-21T11:41:32Z"}
{"aid":"http://arxiv.org/abs/2504.15035v1","title":"SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank\n  Adaptation","summary":"The accelerated advancement of speech generative models has given rise to\nsecurity issues, including model infringement and unauthorized abuse of\ncontent. Although existing generative watermarking techniques have proposed\ncorresponding solutions, most methods require substantial computational\noverhead and training costs. In addition, some methods have limitations in\nrobustness when handling variable-length inputs. To tackle these challenges, we\npropose \\textsc{SOLIDO}, a novel generative watermarking method that integrates\nparameter-efficient fine-tuning with speech watermarking through low-rank\nadaptation (LoRA) for speech diffusion models. Concretely, the watermark\nencoder converts the watermark to align with the input of diffusion models. To\nachieve precise watermark extraction from variable-length inputs, the watermark\ndecoder based on depthwise separable convolution is designed for watermark\nrecovery. To further enhance speech generation performance and watermark\nextraction capability, we propose a speech-driven lightweight fine-tuning\nstrategy, which reduces computational overhead through LoRA. Comprehensive\nexperiments demonstrate that the proposed method ensures high-fidelity\nwatermarked speech even at a large capacity of 2000 bps. Furthermore, against\ncommon individual and compound speech attacks, our SOLIDO achieves a maximum\naverage extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses\nother state-of-the-art methods by nearly 23\\% in resisting time-stretching\nattacks.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.SD","published":"2025-04-21T11:43:36Z"}
{"aid":"http://arxiv.org/abs/2504.15043v1","title":"Energy-Efficient UAV-Mounted RIS for IoT: A Hybrid Energy Harvesting and\n  DRL Approach","summary":"Many future Internet of Things (IoT) applications are expected to rely\nheavily on reconfigurable intelligent surface (RIS)-aided unmanned aerial\nvehicles (UAVs). However, the endurance of such systems is constrained by the\nlimited onboard energy, where frequent recharging or battery replacements are\nrequired. This consequently disrupts continuous operation and may be\nimpractical in disaster scenarios. To address this challenge, we explore a dual\nenergy harvesting (EH) framework that integrates time-switching (TS),\npower-splitting (PS), and element-splitting (ES) EH protocols for radio\nfrequency energy, along with solar energy as a renewable source. First, we\npresent the proposed system architecture and EH operating protocols,\nintroducing the proposed hybrid ES-TS-PS EH strategy to extend UAV-mounted RIS\nendurance. Next, we outline key application scenarios and the associated design\nchallenges. After that, a deep reinforcement learning-based framework is\nintroduced to maximize the EH efficiency by jointly optimizing UAV trajectory,\nRIS phase shifts, and EH strategies. The framework considers dual EH, hardware\nimpairments, and channel state information imperfections to reflect real-world\ndeployment conditions. The optimization problem is formulated as a Markov\ndecision process and solved using an enhanced deep deterministic policy\ngradient algorithm, incorporating clipped double Q-learning and softmax-based\nQ-value estimation for improved stability and efficiency. The results\ndemonstrate significant performance gains compared to the considered baseline\napproaches. Finally, possible challenges and open research directions are\npresented, highlighting the transformative potential of energy-efficient\nUAV-mounted RIS networks for IoT systems.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T11:54:40Z"}
{"aid":"http://arxiv.org/abs/2504.15060v1","title":"Flexible polyhedral nets in isotropic geometry","summary":"We study flexible polyhedral nets in isotropic geometry. This geometry has a\ndegenerate metric, but there is a natural notion of flexibility. We study\ninfinitesimal and finite flexibility, and classify all finitely flexible\npolyhedral nets of arbitrary size. We show that there are just two classes, in\ncontrast to Izmestiev's rather involved classification in Euclidean geometry,\nfor size 3x3 only. Using these nets to initialize the optimization algorithms,\nwe turn them into approximate Euclidean mechanisms. We also explore the smooth\nversions of these classes.","main_category":"math.MG","categories":"math.MG","published":"2025-04-21T12:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.15063v1","title":"Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle\n  Stages","summary":"Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-21T12:42:59Z"}
{"aid":"http://arxiv.org/abs/2504.15086v1","title":"Configuration Requirements for 21-cm Forest Background Quasar Searches\n  with the Moon-based Interferometer","summary":"The 21-cm forest offers a powerful cosmological probe of the thermal history\nand small-scale structure of the intergalactic medium during the Epoch of\nReionization (EoR). Its success, however, critically depends on the\navailability of high-redshift radio-loud quasars (HzRLQs) as background\nsources. In this work, we investigate the configuration requirements for a\nMoon-based low-frequency radio interferometer aimed at maximizing the detection\nof HzRLQs for future 21-cm forest studies. Building upon a previously developed\nquasar luminosity function (QLF), we forecast HzRLQ abundances under various\narray configurations. Assuming a total survey area of $10^4\\,\\mathrm{deg}^2$\nand 1 year of observation, we compare continuum surveys with 10 MHz bandwidth\nand 21-cm forest surveys with 5 kHz resolution. Our results show that a minimum\ncollecting area of $\\sim$6 500 m$^2$ enables detection at $z \\sim 6$, while\nSKA-like arrays ($N_{\\mathrm{st}} = 512$) extend the detection limit to $z \\sim\n10$ for 21-cm forest survey and $z \\sim 16$ for continuum survey. Larger arrays\nwith $N_{\\mathrm{st}} = 2048$ can reach $z \\sim 11$ in 21-cm forest mode. We\nalso explore configurations that maintain fixed collecting areas while\nincreasing the number to enhance survey efficiency. This boosts source\ndetection but significantly increases the data volume and computational\ndemands. These results underscore the importance of optimizing array design for\ndifferent survey goals and balancing sensitivity, spectral resolution, and data\nmanagement. A well-designed Moon-based array could open a new observational\nwindow on reionization and early cosmic structure formation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-21T13:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.15090v1","title":"Federated Latent Factor Model for Bias-Aware Recommendation with\n  Privacy-Preserving","summary":"A recommender system (RS) aims to provide users with personalized item\nrecommendations, enhancing their overall experience. Traditional RSs collect\nand process all user data on a central server. However, this centralized\napproach raises significant privacy concerns, as it increases the risk of data\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\nprivacy-sensitive users. To address these privacy challenges, federated\nlearning has been integrated into RSs, ensuring that user data remains secure.\nIn centralized RSs, the issue of rating bias is effectively addressed by\njointly analyzing all users' raw interaction data. However, this becomes a\nsignificant challenge in federated RSs, as raw data is no longer accessible due\nto privacy-preserving constraints. To overcome this problem, we propose a\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\nexplicitly incorporated into every local model's loss function, allowing for\nthe effective elimination of rating bias without compromising data privacy.\nExtensive experiments conducted on three real-world datasets demonstrate that\nFBALF achieves significantly higher recommendation accuracy compared to other\nstate-of-the-art federated RSs.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T13:24:30Z"}
{"aid":"http://arxiv.org/abs/2504.15113v1","title":"Adaptive sieving with semismooth Newton proximal augmented Lagrangian\n  algorithm for multi-task Lasso problems","summary":"Multi-task learning enhances model generalization by jointly learning from\nrelated tasks. This paper focuses on the $\\ell_{1,\\infty}$-norm constrained\nmulti-task learning problem, which promotes a shared feature representation\nwhile inducing sparsity in task-specific parameters. We propose an adaptive\nsieving (AS) strategy to efficiently generate a solution path for multi-task\nLasso problems. Each subproblem along the path is solved via an inexact\nsemismooth Newton proximal augmented Lagrangian ({\\sc Ssnpal}) algorithm,\nachieving an asymptotically superlinear convergence rate. By exploiting the\nKarush-Kuhn-Tucker (KKT) conditions and the inherent sparsity of multi-task\nLasso solutions, the {\\sc Ssnpal} algorithm solves a sequence of reduced\nsubproblems with small dimensions. This approach enables our method to scale\neffectively to large problems. Numerical experiments on synthetic and\nreal-world datasets demonstrate the superior efficiency and robustness of our\nalgorithm compared to state-of-the-art solvers.","main_category":"math.OC","categories":"math.OC","published":"2025-04-21T14:06:25Z"}
{"aid":"http://arxiv.org/abs/2504.15114v1","title":"Sensing with Quantum Light: A perspective","summary":"I present my perspective on sensing with quantum light. I summarise the\nmotivations and methodology for identifying quantum enhancements in sensing\nover a classical sensor. In the real world, this enhancement will be a constant\nfactor, and not increase with the size of the quantum probe as is often\nadvertised. I use a limited survey of interferometry, microscopy, and\nspectroscopy to extract the vital challenges that must be faced to realise\ntangible enhancements in sensing with quantum light.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T14:07:57Z"}
{"aid":"http://arxiv.org/abs/2504.15125v1","title":"Contemplative Wisdom for Superalignment","summary":"As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T14:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.15161v1","title":"A few identities and integrals involving Pochhammer symbol, Jacobi\n  polynomials and hypergeometric function","summary":"In this paper, we find some identities involving Pochhammer symbol (rising\nfactorial) and apply them to find a closed form for some integrals of the\nJacobi polynomials as well as a hypergeometric function multiplied by the\nproduct of Jacobi polynomial and the Beta density that makes this polynomial\nmember of the family of orthogonal polynomials. In other words, we expand a\nhypergeometric function in an orthogonal series of Jacobi polynomials.","main_category":"math.CA","categories":"math.CA","published":"2025-04-21T15:07:38Z"}
{"aid":"http://arxiv.org/abs/2504.15175v1","title":"Geometric speed limit of state preparation and curved control spaces","summary":"The preparation of quantum many-body systems faces the difficulty that in a\nrealistic scenario only few control parameters of the system may be accessible.\nIn this context, an interesting connection between the energy fluctuations\nduring state preparation and its geometric length as measured by the\nFubini-Study metric was discussed in Bukov et al., \"Geometric Speed Limit of\nAccessible Many-Body State Preparation\", Phys. Rev. X 9, 011034 (2019). An\ninspiring conjecture was put forward lower bounding the energy fluctuations by\nthe minimal geometric length of all accessible state preparation protocols. We\nhere show that the conjecture holds if the accessible parameter space has no\nextrinsic curvature, when embedded into the space of all dynamically accessible\nstates. If the parameter space has extrinsic curvature a weakened version of\nthe conjecture applies. We discuss instructive examples for a qubit system and\nharmonic oscillators.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T15:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.15188v1","title":"Synergistic Weak-Strong Collaboration by Aligning Preferences","summary":"Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T15:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.15229v1","title":"Immersive Teleoperation Framework for Locomanipulation Tasks","summary":"Recent advancements in robotic loco-manipulation have leveraged Virtual\nReality (VR) to enhance the precision and immersiveness of teleoperation\nsystems, significantly outperforming traditional methods reliant on 2D camera\nfeeds and joystick controls. Despite these advancements, challenges remain,\nparticularly concerning user experience across different setups. This paper\nintroduces a novel VR-based teleoperation framework designed for a robotic\nmanipulator integrated onto a mobile platform. Central to our approach is the\napplication of Gaussian splatting, a technique that abstracts the manipulable\nscene into a VR environment, thereby enabling more intuitive and immersive\ninteractions. Users can navigate and manipulate within the virtual scene as if\ninteracting with a real robot, enhancing both the engagement and efficacy of\nteleoperation tasks. An extensive user study validates our approach,\ndemonstrating significant usability and efficiency improvements. Two-thirds\n(66%) of participants completed tasks faster, achieving an average time\nreduction of 43%. Additionally, 93% preferred the Gaussian Splat interface\noverall, with unanimous (100%) recommendations for future use, highlighting\nimprovements in precision, responsiveness, and situational awareness. Finally,\nwe demonstrate the effectiveness of our framework through real-world\nexperiments in two distinct application scenarios, showcasing the practical\ncapabilities and versatility of the Splat-based VR interface.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:00:31Z"}
{"aid":"http://arxiv.org/abs/2504.15230v1","title":"Rydberg Atoms in a Ladder Geometry: Quench Dynamics and Floquet\n  Engineering","summary":"In recent days, Rydberg atom quantum simulator platforms have emerged as\nnovel quantum simulators for physical systems ranging from condensed matter to\nparticle physics. On a fundamental level, these platforms allow for a direct\ntest of our understanding of the emergence of quantum statistical mechanics\nstarting from the laws of quantum dynamics. In this paper, we investigate the\nfate of quantum dynamics in a model of Rydberg atoms arranged in a square\nladder geometry, with a Rabi frequency $2\\Omega$ and a detuning profile which\nis staggered along the longer direction with amplitude $\\Delta$. As the\nstaggering strength $\\Delta$ is tuned from $\\Delta/\\Omega=0\\rightarrow\\infty$,\nthe model exhibits a wide class of dynamical phenomena, ranging from (i)\nquantum many-body scars (QMBS) ($\\Delta/\\Omega \\sim 0,1$), (ii) integrability\ninduced slow dynamics and approximate Krylov fractures ($\\Delta/\\Omega \\gg 1$)\n. Additionally, by leveraging the underlying chiral nature of the spectrum of\nthis model Hamiltonian, it is possible to design Floquet protocols leading to\ndynamical signatures reminiscent of discrete time-crystalline order and exact\nFloquet flat bands. Finally, we study the robustness of these dynamical\nfeatures against imperfections in the implementation of the Floquet protocols,\nlong-range van der Waals interactions and inevitable influences from the\nenvironment in the form of pure dephasing and the finite lifetime of the\nRydberg excited state.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-21T17:00:44Z"}
{"aid":"http://arxiv.org/abs/2504.15231v1","title":"Linear Complementary Pairs of Quasi-Cyclic and Quasi-Twisted Codes","summary":"In this paper, we provide a polynomial characterization of linear\ncomplementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also\ngive several examples of linear complementary pairs of quasi-cyclic and\nquasi-twisted codes with (almost) optimal security parameters.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T17:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.15254v1","title":"CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation","summary":"C-to-Rust transpilation is essential for modernizing legacy C code while\nenhancing safety and interoperability with modern Rust ecosystems. However, no\ndataset currently exists for evaluating whether a system can transpile C into\nsafe Rust that passes a set of test cases. We introduce CRUST-Bench, a dataset\nof 100 C repositories, each paired with manually-written interfaces in safe\nRust as well as test cases that can be used to validate correctness of the\ntranspilation. By considering entire repositories rather than isolated\nfunctions, CRUST-Bench captures the challenges of translating complex projects\nwith dependencies across multiple files. The provided Rust interfaces provide\nexplicit specifications that ensure adherence to idiomatic, memory-safe Rust\npatterns, while the accompanying test cases enforce functional correctness. We\nevaluate state-of-the-art large language models (LLMs) on this task and find\nthat safe and idiomatic Rust generation is still a challenging problem for\nvarious state-of-the-art methods and techniques. We also provide insights into\nthe errors LLMs usually make in transpiling code from C to safe Rust. The best\nperforming model, OpenAI o1, is able to solve only 15 tasks in a single-shot\nsetting. Improvements on CRUST-Bench would lead to improved transpilation\nsystems that can reason about complex scenarios and help in migrating legacy\ncodebases from C into languages like Rust that ensure memory safety. You can\nfind the dataset and code at https://github.com/anirudhkhatry/CRUST-bench.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-04-21T17:33:33Z"}
{"aid":"http://arxiv.org/abs/2504.15554v1","title":"Partition laser assembling technique","summary":"The advancement of micro/nanofabrication techniques with high throughput,\nefficiency, and flexibility is critical for fields like integrated photonics,\nbiosensing, and medical diagnostics. This study presents Partition Laser\nAssembling (PLA), a novel laser technique for fabricating complex\nmicro/nanostructures akin to puzzle pieces. By dividing the target patterns\ndescribed by scalable vector graphics into partitions, any structures in each\npartition can be fabricated via structured lights as \"light stamp\" through\nspatial light modulation. Unlike traditional direct laser writing, PLA\neliminates reliance on mechanical components, avoiding step-like artifacts and\nensuring smoother fabrication of complex micro/nanostructures. By seamlessly\nassembling basic shapes, PLA achieves intricate structures like micro artworks\nand metalenses with unmatched precision and resolution. Leveraging two-photon\nfabrication, PLA guarantees high resolution and structural integrity,\npositioning it as a transformative tool for nanoscale 3D printing. With\napplications spanning research and industry, PLA paves the way for advanced\noptical devices, micro/nanofabrications, and next-gen manufacturing\ntechnologies.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-22T03:18:54Z"}
{"aid":"http://arxiv.org/abs/2504.15577v1","title":"State-Aware IoT Scheduling Using Deep Q-Networks and Edge-Based\n  Coordination","summary":"This paper addresses the challenge of energy efficiency management faced by\nintelligent IoT devices in complex application environments. A novel\noptimization method is proposed, combining Deep Q-Network (DQN) with an edge\ncollaboration mechanism. The method builds a state-action-reward interaction\nmodel and introduces edge nodes as intermediaries for state aggregation and\npolicy scheduling. This enables dynamic resource coordination and task\nallocation among multiple devices. During the modeling process, device status,\ntask load, and network resources are jointly incorporated into the state space.\nThe DQN is used to approximate and learn the optimal scheduling strategy. To\nenhance the model's ability to perceive inter-device relationships, a\ncollaborative graph structure is introduced to model the multi-device\nenvironment and assist in decision optimization. Experiments are conducted\nusing real-world IoT data collected from the FastBee platform. Several\ncomparative and validation tests are performed, including energy efficiency\ncomparisons across different scheduling strategies, robustness analysis under\nvarying task loads, and evaluation of state dimension impacts on policy\nconvergence speed. The results show that the proposed method outperforms\nexisting baseline approaches in terms of average energy consumption, processing\nlatency, and resource utilization. This confirms its effectiveness and\npracticality in intelligent IoT scenarios.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-04-22T04:24:16Z"}
{"aid":"http://arxiv.org/abs/2504.15585v1","title":"A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training\n  and Deployment","summary":"The remarkable success of Large Language Models (LLMs) has illuminated a\npromising pathway toward achieving Artificial General Intelligence for both\nacademic and industrial communities, owing to their unprecedented performance\nacross various applications. As LLMs continue to gain prominence in both\nresearch and commercial domains, their security and safety implications have\nbecome a growing concern, not only for researchers and corporations but also\nfor every nation. Currently, existing surveys on LLM safety primarily focus on\nspecific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning\nphase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.\nTo address this gap, this paper introduces, for the first time, the concept of\n\"full-stack\" safety to systematically consider safety issues throughout the\nentire process of LLM training, deployment, and eventual commercialization.\nCompared to the off-the-shelf LLM safety surveys, our work demonstrates several\ndistinctive advantages: (I) Comprehensive Perspective. We define the complete\nLLM lifecycle as encompassing data preparation, pre-training, post-training,\ndeployment and final commercialization. To our knowledge, this represents the\nfirst safety survey to encompass the entire lifecycle of LLMs. (II) Extensive\nLiterature Support. Our research is grounded in an exhaustive review of over\n800+ papers, ensuring comprehensive coverage and systematic organization of\nsecurity issues within a more holistic understanding. (III) Unique Insights.\nThrough systematic literature analysis, we have developed reliable roadmaps and\nperspectives for each chapter. Our work identifies promising research\ndirections, including safety in data generation, alignment techniques, model\nediting, and LLM-based agent systems. These insights provide valuable guidance\nfor researchers pursuing future work in this field.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.CL,cs.LG","published":"2025-04-22T05:02:49Z"}
{"aid":"http://arxiv.org/abs/2504.15586v1","title":"Joint leave-group-out cross-validation in Bayesian spatial models","summary":"Cross-validation (CV) is a widely-used method of predictive assessment based\non repeated model fits to different subsets of the available data. CV is\napplicable in a wide range of statistical settings. However, in cases where\ndata are not exchangeable, the design of CV schemes should account for\nsuspected correlation structures within the data. CV scheme designs include the\nselection of left-out blocks and the choice of scoring function for evaluating\npredictive performance.\n  This paper focuses on the impact of two scoring strategies for block-wise CV\napplied to spatial models with Gaussian covariance structures. We investigate,\nthrough several experiments, whether evaluating the predictive performance of\nblocks of left-out observations jointly, rather than aggregating individual\n(pointwise) predictions, improves model selection performance. Extending recent\nfindings for data with serial correlation (such as time-series data), our\nexperiments suggest that joint scoring reduces the variability of CV estimates,\nleading to more reliable model selection, particularly when spatial dependence\nis strong and model differences are subtle.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-22T05:02:58Z"}
{"aid":"http://arxiv.org/abs/2504.15602v1","title":"Mean Curvature Flow for Isoparametric Submanifolds in Hyperbolic Spaces","summary":"Mean curvature flows of isoparametric submanifolds in Euclidean spaces and\nspheres have been studied by Liu and Terng in \\cite{X.CT} and \\cite{X.C}. In\nparticular, it was proved that such flows always have ancient solutions. This\nis also true for mean curvature flows of isoparametric hypersurfaces in\nhyperbolic spaces by a result of Reis and Tenenblat in \\cite{S.H.T}. In this\npaper, we study mean curvature flows of isoparametric submanifolds in\nhyperbolic spaces with arbitrary codimension. In particular, we will show that\nthey always have ancient solutions and study their limiting behaviors.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T05:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.15616v1","title":"SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory\n  Prediction","summary":"The analysis and prediction of agent trajectories are crucial for\ndecision-making processes in intelligent systems, with precise short-term\ntrajectory forecasting being highly significant across a range of applications.\nAgents and their social interactions have been quantified and modeled by\nresearchers from various perspectives; however, substantial limitations exist\nin the current work due to the inherent high uncertainty of agent intentions\nand the complex higher-order influences among neighboring groups. SocialMOIF is\nproposed to tackle these challenges, concentrating on the higher-order\nintention interactions among neighboring groups while reinforcing the primary\nrole of first-order intention interactions between neighbors and the target\nagent. This method develops a multi-order intention fusion model to achieve a\nmore comprehensive understanding of both direct and indirect intention\ninformation. Within SocialMOIF, a trajectory distribution approximator is\ndesigned to guide the trajectories toward values that align more closely with\nthe actual data, thereby enhancing model interpretability. Furthermore, a\nglobal trajectory optimizer is introduced to enable more accurate and efficient\nparallel predictions. By incorporating a novel loss function that accounts for\ndistance and direction during training, experimental results demonstrate that\nthe model outperforms previous state-of-the-art baselines across multiple\nmetrics in both dynamic and static datasets.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-22T06:14:49Z"}
{"aid":"http://arxiv.org/abs/2504.15621v1","title":"Regularization of elliptic multiple zeta values","summary":"In this paper, we show that regularized elliptic multiple zeta values are\ngiven by polynomials in elliptic multiple zeta values with admissible indices\nand special ones whose indices consist of 0 and 1.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T06:24:48Z"}
{"aid":"http://arxiv.org/abs/2504.15640v1","title":"Cost-Effective Text Clustering with Large Language Models","summary":"Text clustering aims to automatically partition a collection of text\ndocuments into distinct clusters based on linguistic features. In the\nliterature, this task is usually framed as metric clustering based on text\nembeddings from pre-trained encoders or a graph clustering problem upon\npairwise similarities from an oracle, e.g., a large ML model. Recently, large\nlanguage models (LLMs) bring significant advancement in this field by offering\ncontextualized text embeddings and highly accurate similarity scores, but\nmeanwhile, present grand challenges to cope with substantial computational\nand/or financial overhead caused by numerous API-based queries or inference\ncalls to the models.\n  In response, this paper proposes TECL, a cost-effective framework that taps\ninto the feedback from LLMs for accurate text clustering within a limited\nbudget of queries to LLMs. Under the hood, TECL adopts our EdgeLLM or\nTriangleLLM to construct must-link/cannot-link constraints for text pairs, and\nfurther leverages such constraints as supervision signals input to our weighted\nconstrained clustering approach to generate clusters. Particularly, EdgeLLM\n(resp. TriangleLLM) enables the identification of informative text pairs (resp.\ntriplets) for querying LLMs via well-thought-out greedy algorithms and accurate\nextraction of pairwise constraints through carefully-crafted prompting\ntechniques. Our experiments on multiple benchmark datasets exhibit that TECL\nconsistently and considerably outperforms existing solutions in unsupervised\ntext clustering under the same query cost for LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T06:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.15646v1","title":"Quantum Corrections and Extremality: A Generalized Universal Relation","summary":"Logarithmic corrections to the entropy of extremal black holes have proven\neffective in precisely matching the microscopic degeneracies obtained from\nstring-theoretic as well as a non-perturbative quantum correction manifests as\nan exponential term in the black hole entropy. In this work, we extend the\nuniversal relation proposed by Goon and Penco by deriving a generalized form\nwhere entropy is not just the Bekenstein-Hawking entropy. Our analysis treats\nentropy as a general function of the horizon radius, and with the help of that,\nwe formulate the generalized universal relation. We show that, in the case of\nBekenstein-Hawking entropy, the generalized relation coincides with the\noriginal universal relation by Goon and Penco. Furthermore, we explore the\nimplications of logarithmic and exponential corrections to entropy and test the\nvalidity of the generalized universal relation under these modifications.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-22T07:12:53Z"}
{"aid":"http://arxiv.org/abs/2504.15663v1","title":"FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep\n  Learning","summary":"Recently, fake audio detection has gained significant attention, as\nadvancements in speech synthesis and voice conversion have increased the\nvulnerability of automatic speaker verification (ASV) systems to spoofing\nattacks. A key challenge in this task is generalizing models to detect unseen,\nout-of-distribution (OOD) attacks. Although existing approaches have shown\npromising results, they inherently suffer from overconfidence issues due to the\nusage of softmax for classification, which can produce unreliable predictions\nwhen encountering unpredictable spoofing attempts. To deal with this\nlimitation, we propose a novel framework called fake audio detection with\nevidential learning (FADEL). By modeling class probabilities with a Dirichlet\ndistribution, FADEL incorporates model uncertainty into its predictions,\nthereby leading to more robust performance in OOD scenarios. Experimental\nresults on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets\nindicate that the proposed method significantly improves the performance of\nbaseline models. Furthermore, we demonstrate the validity of uncertainty\nestimation by analyzing a strong correlation between average uncertainty and\nequal error rate (EER) across different spoofing algorithms.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-22T07:40:35Z"}
{"aid":"http://arxiv.org/abs/2504.15702v1","title":"Form factors from string amplitudes","summary":"In this letter, we propose a stringy model for $n$-point tree-level form\nfactor with the off-shell operator in the scalar and gluon theories, from the\nbosonic string disk amplitude: $n$ open string states and $1$ closed string\nstate scatter on the disk. In the field-theory limit ($\\alpha'\\to0$), the\nstringy form factor reduces to the form factor, helps us to investigate the\nhidden properties of the field-theory form factors, manifest the factorization\nand soft behaviors, and uncover more non-trivial relations between form factors\nand scattering amplitudes.","main_category":"hep-th","categories":"hep-th","published":"2025-04-22T08:45:17Z"}
{"aid":"http://arxiv.org/abs/2504.15704v1","title":"On relaxing the N-Reachability Implicit Requirement in NMPC Design","summary":"This paper proposes a proof of stability for Model Predictive Control\nformulations involving a prediction horizon that might be too short to meet the\nreachability condition generally invoked as a sufficient condition for\nclosed-loop stability. This condition is replaced by a contraction condition on\nthe stage cost. But unlike the contraction based existing formulations where\nthe prediction horizon becomes a decision variable, the formulation proposed in\nthis paper remains standard in that it uses constant and short prediction\nhorizon. An illustrative example is provided to assess the relevance of the\nproposed formulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T08:46:23Z"}
{"aid":"http://arxiv.org/abs/2504.15731v1","title":"Entropy Stabilized ZrHfCoNiSnSb Half-Heusler Alloy for Thermoelectric\n  Applications: A Theoretical Prediction","summary":"Half-Heusler (HH) alloys are potential thermoelectric materials for use at\nelevated temperatures due to their high Seebeck coefficient and superior\nmechanical and thermal stability. However, their enhanced lattice thermal\nconductivity is detrimental to thermoelectric applications. One way to\ncircumvent this problem is to introduce mass disorder at lattice sites by\nmixing the components of two or more alloys. Such systems are typically\nstabilized by the entropy of mixing. In this work, using computational tools,\nwe propose a mixed HH, namely, ZrHfCoNiSnSb, which can be formed by the\nelemental compositions of the parent half-Heuslers ZrNiSn/HfNiSn and\nHfCoSb/ZrCoSb. We propose that this new compound can be synthesized at elevated\ntemperatures, as its Gibbs free energy is reduced due to higher configurational\nentropy, making it more thermodynamically stable than the parent compounds\nunder such conditions. Our calculations indicate that it is a dynamically\nstable semiconductor with a band gap of 0.61 eV. Its lattice thermal\nconductivity at room temperature is $5.39~\\text{Wm}^{-1}\\text{K}^{-1}$, which\nis significantly lower than those of the parent compounds. The peak value of\nthis alloy's figure of merit (ZT) is 1.00 for the n-type carriers at 1100 K,\nwhich is 27% more than the best figure of merit obtained for the parent\ncompounds.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T09:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.15738v1","title":"RRC Signaling Storm Detection in O-RAN","summary":"The Open Radio Access Network (O-RAN) marks a significant shift in the mobile\nnetwork industry. By transforming a traditionally vertically integrated\narchitecture into an open, data-driven one, O-RAN promises to enhance\noperational flexibility and drive innovation. In this paper, we harness O-RAN's\nopenness to address one critical threat to 5G availability: signaling storms\ncaused by abuse of the Radio Resource Control (RRC) protocol. Such attacks\noccur when a flood of RRC messages from one or multiple User Equipments (UEs)\ndeplete resources at a 5G base station (gNB), leading to service degradation.\nWe provide a reference implementation of an RRC signaling storm attack, using\nthe OpenAirInterface (OAI) platform to evaluate its impact on a gNB. We\nsupplement the experimental results with a theoretical model to extend the\nfindings for different load conditions. To mitigate RRC signaling storms, we\ndevelop a threshold-based detection technique that relies on RRC layer features\nto distinguish between malicious activity and legitimate high network load\nconditions. Leveraging O-RAN capabilities, our detection method is deployed as\nan external Application (xApp). Performance evaluation shows attacks can be\ndetected within 90ms, providing a mitigation window of 60ms before gNB\nunavailability, with an overhead of 1.2% and 0% CPU and memory consumption,\nrespectively.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-04-22T09:32:11Z"}
{"aid":"http://arxiv.org/abs/2504.15764v1","title":"From Spin Waves to Monte Carlo Simulations: Compiling an Experimental\n  Exchange Interaction Dataset for Magnetic Materials","summary":"Inelastic neutron scattering data on magnetic crystals are highly valuable in\nmaterials science, as they provide direct insight into microscopic magnetic\ninteractions. Using spin wave theory, these interactions can be extracted from\nmagnetic excitations observed in such experiments. However, these datasets are\noften scattered across the literature and lack standardization, limiting their\naccessibility and usability. In this paper, we compile and standardize\nHeisenberg exchange interaction data for magnetic materials obtained from\ninelastic neutron scattering experiments. Through an extensive literature\nreview, we identify experimental data for approximately 100 magnetic materials.\nThe standardized dataset includes mapping the results of various Heisenberg\nHamiltonians into a unified standard form, visualizations of crystal structures\nwith annotated exchange interactions, and input and output files from Monte\nCarlo simulations performed for each compound using the ESpinS code. Using\nexperimentally determined exchange interactions, we calculate transition\ntemperatures $T_c$ via classical Monte Carlo simulations. Additionally, we\nassess the effectiveness of the $S+1)/S$ correction within classical Monte\nCarlo simulations, finding that it produces transition temperatures in\nexcellent agreement with experimental values in most cases. The complete\ndataset, along with supporting resources, is publicly available on GitHub.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T10:17:32Z"}
{"aid":"http://arxiv.org/abs/2504.15773v1","title":"Clifford Group Equivariant Diffusion Models for 3D Molecular Generation","summary":"This paper explores leveraging the Clifford algebra's expressive power for\n$\\E(n)$-equivariant diffusion models. We utilize the geometric products between\nClifford multivectors and the rich geometric information encoded in Clifford\nsubspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion\nprocess beyond just Clifford one-vectors to incorporate all higher-grade\nmultivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us\nto apply latent diffusion across complete multivectors. This enables CDMs to\ncapture the joint distribution across different subspaces of the algebra,\nincorporating richer geometric information through higher-order features. We\nprovide empirical results for unconditional molecular generation on the QM9\ndataset, showing that CDMs provide a promising avenue for generative modeling.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T10:30:06Z"}
{"aid":"http://arxiv.org/abs/2504.15814v1","title":"Fast Higher-Order Interpolation and Restriction in ExaHyPE Avoiding\n  Non-physical Reflections","summary":"Wave equations help us to understand phenomena ranging from earthquakes to\ntsunamis. These phenomena materialise over very large scales. It would be\ncomputationally infeasible to track them over a regular mesh. Yet, since the\nphenomena are localised, adaptive mesh refinement (AMR) can be used to\nconstruct meshes with a higher resolution close to the regions of interest.\nExaHyPE is a software engine created to solve wave problems using AMR, and we\nuse it as baseline to construct our numerical relativity application called\nExaGRyPE. To advance the mesh in time, we have to interpolate and restrict\nalong resolution transitions in each and every time step. ExaHyPE's vanilla\ncode version uses a d-linear tensor-product approach. In benchmarks of a\nstationary black hole this performs slowly and leads to errors in conserved\nquantities near AMR boundaries. We therefore introduce a set of higher-order\ninterpolation schemes where the derivatives are calculated at each coarse grid\ncell to approximate the enclosed fine cells. The resulting methods run faster\nthan the tensor-product approach. Most importantly, when running the stationary\nblack hole simulation using the higher order methods the errors near the AMR\nboundaries are removed.","main_category":"cs.CE","categories":"cs.CE,cs.MS,gr-qc","published":"2025-04-22T11:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.15822v1","title":"Quantifying Source Speaker Leakage in One-to-One Voice Conversion","summary":"Using a multi-accented corpus of parallel utterances for use with commercial\nspeech devices, we present a case study to show that it is possible to quantify\na degree of confidence about a source speaker's identity in the case of\none-to-one voice conversion. Following voice conversion using a HiFi-GAN\nvocoder, we compare information leakage for a range speaker characteristics;\nassuming a \"worst-case\" white-box scenario, we quantify our confidence to\nperform inference and narrow the pool of likely source speakers, reinforcing\nthe regulatory obligation and moral duty that providers of synthetic voices\nhave to ensure the privacy of their speakers' data.","main_category":"cs.SD","categories":"cs.SD,cs.CR,eess.AS","published":"2025-04-22T12:09:03Z"}
{"aid":"http://arxiv.org/abs/2504.15852v1","title":"Recovering Nesterov accelerated dynamics from Heavy Ball dynamics via\n  time rescaling","summary":"In a real Hilbert space, we consider two classical problems: the global\nminimization of a smooth and convex function $f$ (i.e., a convex optimization\nproblem) and finding the zeros of a monotone and continuous operator $V$ (i.e.,\na monotone equation). Attached to the optimization problem, first we study the\nasymptotic properties of the trajectories generated by a second-order dynamical\nsystem which features a constant viscous friction coefficient and a positive,\nmonotonically increasing function $b(\\cdot)$ multiplying $\\nabla f$. For a\ngenerated solution trajectory $y(t)$, we show small $o$ convergence rates\ndependent on $b(t)$ for $f(y(t)) - \\min f$, and the weak convergence of $y(t)$\ntowards a global minimizer of $f$. In 2015, Su, Boyd and Cand\\'es introduced a\nsecond-order system which could be seen as the continuous-time counterpart of\nNesterov's accelerated gradient. As the first key point of this paper, we show\nthat for a special choice for $b(t)$, these two seemingly unrelated dynamical\nsystems are connected: namely, they are time reparametrizations of each other.\nEvery statement regarding the continuous-time accelerated gradient system may\nbe recovered from its Heavy Ball counterpart.\n  As the second key point of this paper, we observe that this connection\nextends beyond the optimization setting. Attached to the monotone equation\ninvolving the operator $V$, we again consider a Heavy Ball-like system which\nfeatures an additional correction term which is the time derivative of the\noperator along the trajectory. We establish a time reparametrization\nequivalence with the Fast OGDA dynamics introduced by Bot, Csetnek and Nguyen\nin 2022, which can be seen as an analog of the continuous accelerated gradient\ndynamics, but for monotone operators. Again, every statement regarding the Fast\nOGDA system may be recovered from a Heavy Ball-like system.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T12:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.15880v1","title":"Cryptoanalysis of a public key exchange based on circulant matrix over\n  digital semiring","summary":"We present a cryptanalysis of a key exchange protocol based on the digital\nsemiring. For this purpose, we find the maximal solution of a linear system\nover such semiring, and use the properties of circulant matrix to demonstrate\nthat the protocol is vulnerable. Specifically, we provide an efficient attack\nthat recovers the shared secret key from publicly exchanged information for any\ninstance of the digital semiring in polynomial time.","main_category":"cs.CR","categories":"cs.CR,cs.IT,math.AC,math.IT","published":"2025-04-22T13:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.15928v1","title":"A Clinician-Friendly Platform for Ophthalmic Image Analysis Without\n  Technical Barriers","summary":"Artificial intelligence (AI) shows remarkable potential in medical imaging\ndiagnostics, but current models typically require retraining when deployed\nacross different clinical centers, limiting their widespread adoption. We\nintroduce GlobeReady, a clinician-friendly AI platform that enables ocular\ndisease diagnosis without retraining/fine-tuning or technical expertise.\nGlobeReady achieves high accuracy across imaging modalities: 93.9-98.5% for an\n11-category fundus photo dataset and 87.2-92.7% for a 15-category OCT dataset.\nThrough training-free local feature augmentation, it addresses domain shifts\nacross centers and populations, reaching an average accuracy of 88.9% across\nfive centers in China, 86.3% in Vietnam, and 90.2% in the UK. The built-in\nconfidence-quantifiable diagnostic approach further boosted accuracy to\n94.9-99.4% (fundus) and 88.2-96.2% (OCT), while identifying out-of-distribution\ncases at 86.3% (49 CFP categories) and 90.6% (13 OCT categories). Clinicians\nfrom multiple countries rated GlobeReady highly (average 4.6 out of 5) for its\nusability and clinical relevance. These results demonstrate GlobeReady's\nrobust, scalable diagnostic capability and potential to support ophthalmic care\nwithout technical barriers.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T14:17:22Z"}
{"aid":"http://arxiv.org/abs/2504.15932v1","title":"Reasoning Physical Video Generation with Diffusion Timestep Tokens via\n  Reinforcement Learning","summary":"Despite recent progress in video generation, producing videos that adhere to\nphysical laws remains a significant challenge. Traditional diffusion-based\nmethods struggle to extrapolate to unseen physical conditions (eg, velocity)\ndue to their reliance on data-driven approximations. To address this, we\npropose to integrate symbolic reasoning and reinforcement learning to enforce\nphysical consistency in video generation. We first introduce the Diffusion\nTimestep Tokenizer (DDT), which learns discrete, recursive visual tokens by\nrecovering visual attributes lost during the diffusion process. The recursive\nvisual tokens enable symbolic reasoning by a large language model. Based on it,\nwe propose the Phys-AR framework, which consists of two stages: The first stage\nuses supervised fine-tuning to transfer symbolic knowledge, while the second\nstage applies reinforcement learning to optimize the model's reasoning\nabilities through reward functions based on physical conditions. Our approach\nallows the model to dynamically adjust and improve the physical properties of\ngenerated videos, ensuring adherence to physical laws. Experimental results\ndemonstrate that PhysAR can generate videos that are physically consistent.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:20:59Z"}
{"aid":"http://arxiv.org/abs/2504.15936v1","title":"An effectful object calculus","summary":"We show how to smoothly incorporate in the object-oriented paradigm\nconstructs to raise, compose, and handle effects in an arbitrary monad. The\nunderlying pure calculus is meant to be a representative of the last generation\nof OO languages, and the effectful extension is manageable enough for ordinary\nprogrammers; notably, constructs to raise effects are just special methods. We\nequip the calculus with an expressive type-and-effect system, which, again by\nrelying on standard features such as inheritance and generic types, allows a\nsimple form of effect polymorphism. The soundness of the type-and-effect system\nis expressed and proved by a recently introduced technique, where the semantics\nis formalized by a one-step reduction relation from language expressions into\nmonadic ones, so that it is enough to prove progress and subject reduction\nproperties on this relation.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-22T14:24:59Z"}
{"aid":"http://arxiv.org/abs/2504.15944v1","title":"Deep learning of point processes for modeling high-frequency data","summary":"We investigate applications of deep neural networks to a point process having\nan intensity with mixing covariates processes as input. Our generic model\nincludes Cox-type models and marked point processes as well as multivariate\npoint processes. An oracle inequality and a rate of convergence are derived for\nthe prediction error. A simulation study shows that the marked point process\ncan be superior to the simple multivariate model in prediction. We apply the\nmarked ratio model to real limit order book data","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-22T14:42:16Z"}
{"aid":"http://arxiv.org/abs/2504.15946v1","title":"The e-Partitioning Principle of False Discovery Rate Control","summary":"We present a novel necessary and sufficient principle for False Discovery\nRate (FDR) control. This e-Partitioning Principle says that a procedure\ncontrols FDR if and only if it is a special case of a general e-Partitioning\nprocedure. By writing existing methods as special cases of this procedure, we\ncan achieve uniform improvements of these methods, and we show this in\nparticular for the eBH, BY and Su methods. We also show that methods developed\nusing the $e$-Partitioning Principle have several valuable properties. They\ngenerally control FDR not just for one rejected set, but simultaneously over\nmany, allowing post hoc flexibility for the researcher in the final choice of\nthe rejected hypotheses. Under some conditions, they also allow for post hoc\nadjustment of the error rate, choosing the FDR level $\\alpha$ post hoc, or\nswitching to familywise error control after seeing the data. In addition,\ne-Partitioning allows FDR control methods to exploit logical relationships\nbetween hypotheses to gain power.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-22T14:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.15954v1","title":"Monocular inspection of spacecraft under illumination constraints and\n  avoidance regions","summary":"This paper presents an adaptive control approach to information-based\nguidance and control of a spacecraft carrying out on-orbit inspection by\nactively computing optimal policies for the spacecraft to achieve the best\npossible representation of objects within its orbital environment. Due to the\ncomplexity of navigating the space environment, it may be impossible to carry\nout on-orbit servicing to maintain space systems like satellites using a\nspacecraft equipped with controllers that cannot adapt to changing conditions.\nIn particular, the presence of constraints such as illumination, field-of-view\n(FOV), minimal fuel, the use of visual-inertial navigation for improved\nlocalization, and the need for real-time computation of control policies render\nthe spacecraft motion planning problem challenging. The control framework\ndeveloped in this paper addresses these challenges by formulating the\ninspection task as a constrained optimization problem where the goal is to\nmaximize information gained from the cameras, while navigating to the next best\nview, subject to illumination and FOV constraints. The developed architecture\nis analyzed using a Lyapunov-based stability analysis and the effectiveness of\nthe planning algorithm is verified in simulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T14:50:09Z"}
{"aid":"http://arxiv.org/abs/2504.15968v1","title":"Global Compactness Result for a Brézis-Nirenberg-Type Problem\n  Involving Mixed Local Nonlocal Operator","summary":"This paper investigates the profile decomposition of Palais-Smale sequences\nassociated with a Br\\'ezis-Nirenberg-type problem involving a combination of\nlocal nonlocal operator, given by\n  \\begin{equation*}\n  \\begin{aligned}\n  &-\\Delta u + (-\\Delta)^s u - \\lambda u = |u|^{2^*-2}u \\;\\;\\mbox{ in } \\Omega,\n  &\\quad u=0\\,\\mbox{ in }\\mathbb{R}^N\\setminus \\Omega.\n  \\end{aligned}\n  \\end{equation*} where $ N \\geq 3$ and $2^* = \\frac{2N}{N - 2} $ denotes the\ncritical Sobolev exponent. As an application of the derived global compactness\nresult, we further study the corresponding Coron-type problem.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-22T15:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.15986v1","title":"Charting the Uncharted: The Landscape of Monero Peer-to-Peer Network","summary":"The Monero blockchain enables anonymous transactions through advanced\ncryptography in its peer-to-peer network, which underpins decentralization,\nsecurity, and trustless interactions. However, privacy measures obscure peer\nconnections, complicating network analysis. This study proposes a method to\ninfer peer connections in Monero's latest protocol version, where timestamp\ndata is unavailable. We collect peerlist data from TCP flows, validate our\ninference algorithm, and map the network structure. Our results show high\naccuracy, improving with longer observation periods. This work is the first to\nreveal connectivity patterns in Monero's updated protocol, providing\nvisualizations and insights into its topology. Our findings enhance the\nunderstanding of Monero's P2P network, including the role of supernodes, and\nhighlight potential protocol and security improvements.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-22T15:42:31Z"}
{"aid":"http://arxiv.org/abs/2504.16009v1","title":"Upscaling the Navier-Stokes-Cahn-Hilliard model for incompressible\n  multiphase flow in inhomogeneous porous media","summary":"In this work, we present a macroscopic model for the flow of two immiscible\nand incompressible fluids in inhomogeneous porous medium. At the pore scale,\nthe flow is governed by the fully Navier-Stokes equations while the evolution\nof the phase interface is captured by the Cahn-Hilliard equation. Using the\nvolume averaging method, the upscaled equations describing the averaged\nbehavior of two fluids at the Darcy scale are obtained, with unclosed terms\nrelated to spatial deviations. Then, spatial derivations are carefully modeled\nup to some undetermined coefficients, which could be evaluated by solving\nsimplified closure problems in each representative volume element. In\nparticular, the wetting behavior is incorporated into the averaged chemical\npotential. The differences between the proposed equations and the empirical\ntwo-phase Darcy-type models are discussed. Finally, a phase-field-based lattice\nBoltzmann model for the averaged equations is presented, and numerical results\ndemonstrate the abilities of the proposed model.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,math-ph,math.MP,physics.comp-ph,physics.geo-ph","published":"2025-04-22T16:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.16038v1","title":"The Global Phase Space of the Three-Vortex Interaction System","summary":"We derive a symplectic reduction of the evolution equations for a system of\nthree point vortices and use the reduced system to succinctly explain a kind of\nbifurcation diagram that has appeared in the literature in a form that was\ndifficult to understand and interpret. Using this diagram, we enumerate and\nplot all the global phase-space diagrams that occur as the circulations of the\nthree vortices are varied. The reduction proceeds in two steps: a reduction to\nJacobi coordinates and a Lie-Poisson reduction. In a recent paper, we used a\ndifferent method in the second step. This took two forms depending on a sign\nthat arose in the calculation. The Lie-Poisson equations unify these into a\nsingle form. The Jacobi coordinate reduction fails when the total circulation\nvanishes. We adapt the reduction method to this case and show how it relates to\nthe non-vanishing case.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T17:03:03Z"}
{"aid":"http://arxiv.org/abs/2504.16042v1","title":"Approximate matrices of systems of max-min fuzzy relational equations","summary":"In this article, we address the inconsistency of a system of max-min fuzzy\nrelational equations by minimally modifying the matrix governing the system in\norder to achieve consistency. Our method yields consistent systems that\napproximate the original inconsistent system in the following sense: the\nright-hand side vector of each consistent system is that of the inconsistent\nsystem, and the coefficients of the matrix governing each consistent system are\nobtained by modifying, exactly and minimally, the entries of the original\nmatrix that must be corrected to achieve consistency, while leaving all other\nentries unchanged.\n  To obtain a consistent system that closely approximates the considered\ninconsistent system, we study the distance (in terms of a norm among $L_1$,\n$L_2$ or $L_\\infty$) between the matrix of the inconsistent system and the set\nformed by the matrices of consistent systems that use the same right-hand side\nvector as the inconsistent system. We show that our method allows us to\ndirectly compute matrices of consistent systems that use the same right-hand\nside vector as the inconsistent system whose distance in terms of $L_\\infty$\nnorm to the matrix of the inconsistent system is minimal (the computational\ncosts are higher when using $L_1$ norm or $L_2$ norm). We also give an explicit\nanalytical formula for computing this minimal $L_\\infty$ distance. Finally, we\ntranslate our results for systems of min-max fuzzy relational equations and\npresent some potential applications.","main_category":"cs.AI","categories":"cs.AI,cs.LO","published":"2025-04-22T17:09:02Z"}
{"aid":"http://arxiv.org/abs/2504.16048v1","title":"PRIME: Fast Primal-Dual Feedback Optimization for Markets with\n  Application to Optimal Power Flow","summary":"Online Feedback Optimization (OFO) controllers iteratively drive a plant to\nan optimal operating point that satisfies input and output constraints, relying\nsolely on the input-output sensitivity as model information. This paper\nintroduces PRIME (PRoximal Iterative MarkEts), a novel OFO approach based on\nproximal-point iterations. Unlike existing OFO solutions, PRIME admits a\nmarket-based implementation, where self-interested actors are incentivized to\nmake choices that result in a safe and efficient operation, without\ncommunicating private costs or constraints. Furthermore, PRIME can cope with\nnon-smooth objective functions, achieve fast convergence rates and rapid\nconstraint satisfaction, and reject measurement noise. We demonstrate PRIME on\nan AC optimal power flow problem, obtaining an efficient real-time nonlinear\nlocal marginal pricing scheme.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T17:25:40Z"}
{"aid":"http://arxiv.org/abs/2504.16057v1","title":"Automated Static Vulnerability Detection via a Holistic Neuro-symbolic\n  Approach","summary":"Static vulnerability detection is still a challenging problem and demands\nexcessive human efforts, e.g., manual curation of good vulnerability patterns.\nNone of prior works, including classic program analysis or Large Language Model\n(LLM)-based approaches, have fully automated such vulnerability pattern\ngenerations with reasonable detection accuracy. In this paper, we design and\nimplement, MoCQ, a novel holistic neuro-symbolic framework that combines the\ncomplementary strengths of LLMs and classical static analysis to enable\nscalable vulnerability detection. The key insight is that MoCQ leverages an LLM\nto automatically extract vulnerability patterns and translate them into\ndetection queries, and then on static analysis to refine such queries in a\nfeedback loop and eventually execute them for analyzing large codebases and\nmining vulnerabilities. We evaluate MoCQ on seven types of vulnerabilities\nspanning two programming languages. We found MoCQ-generated queries uncovered\nat least 12 patterns that were missed by experts. On a ground truth dataset,\nMoCQ achieved comparable precision and recall compared to expert-crafted\nqueries. Moreover, MoCQ has identified seven previously unknown vulnerabilities\nin real-world applications, demonstrating its practical effectiveness. We have\nresponsibly disclosed them to the corresponding developers.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-22T17:33:53Z"}
{"aid":"http://arxiv.org/abs/2504.16062v1","title":"ForesightNav: Learning Scene Imagination for Efficient Exploration","summary":"Understanding how humans leverage prior knowledge to navigate unseen\nenvironments while making exploratory decisions is essential for developing\nautonomous robots with similar abilities. In this work, we propose\nForesightNav, a novel exploration strategy inspired by human imagination and\nreasoning. Our approach equips robotic agents with the capability to predict\ncontextual information, such as occupancy and semantic details, for unexplored\nregions. These predictions enable the robot to efficiently select meaningful\nlong-term navigation goals, significantly enhancing exploration in unseen\nenvironments. We validate our imagination-based approach using the Structured3D\ndataset, demonstrating accurate occupancy prediction and superior performance\nin anticipating unseen scene geometry. Our experiments show that the\nimagination module improves exploration efficiency in unseen environments,\nachieving a 100% completion rate for PointNav and an SPL of 67% for ObjectNav\non the Structured3D Validation split. These contributions demonstrate the power\nof imagination-driven reasoning for autonomous systems to enhance generalizable\nand efficient exploration.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-22T17:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.16412v1","title":"Superconductivity and Electron Correlations in Kagome Metal LuOs3B2","summary":"We report a comprehensive investigation of the physical properties of\nLuOs3B2, characterized by an ideal Os-based kagome lattice. Resistivity and\nmagnetization measurements confirm the emergence of type-II bulk\nsuperconductivity with a critical temperature Tc=4.63 K. The specific heat jump\nand the calculated electron-phonon coupling parameter support a moderately\ncoupled superconducting state. Electron correlation effects are supported by\nthe enhanced Wilson ratios. First-principles calculations reveal hallmark\nfeatures of kagome band structure, including Dirac points, van Hove\nsingularities, and quasi-flat bands, primarily derived from the Os d orbitals.\nThe inclusion of spin-orbit coupling opens a gap at the Dirac points,\nsignificantly altering the electronic properties. Furthermore, the\nsuperconductivity and electronic properties of isomorphic compounds are\ndiscussed. This work provides a thorough exploration of the superconducting and\nnormal states of LuOs3B2, deepening the understanding of kagome\nsuperconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-23T04:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.16416v1","title":"FeedQUAC: Quick Unobtrusive AI-Generated Commentary","summary":"Design thrives on feedback. However, gathering constant feedback throughout\nthe design process can be labor-intensive and disruptive. We explore how AI can\nbridge this gap by providing effortless, ambient feedback. We introduce\nFeedQUAC, a design companion that delivers real-time AI-generated commentary\nfrom a variety of perspectives through different personas. A design probe study\nwith eight participants highlights how designers can leverage quick yet ambient\nAI feedback to enhance their creative workflows. Participants highlight\nbenefits such as convenience, playfulness, confidence boost, and inspiration\nfrom this lightweight feedback agent, while suggesting additional features,\nlike chat interaction and context curation. We discuss the role of AI feedback,\nits strengths and limitations, and how to integrate it into existing design\nworkflows while balancing user involvement. Our findings also suggest that\nambient interaction is a valuable consideration for both the design and\nevaluation of future creativity support systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CY,cs.MM","published":"2025-04-23T04:48:00Z"}
{"aid":"http://arxiv.org/abs/2504.16443v1","title":"Marginalized Generalized IoU (MGIoU): A Unified Objective Function for\n  Optimizing Any Convex Parametric Shapes","summary":"Optimizing the similarity between parametric shapes is crucial for numerous\ncomputer vision tasks, where Intersection over Union (IoU) stands as the\ncanonical measure. However, existing optimization methods exhibit significant\nshortcomings: regression-based losses like L1/L2 lack correlation with IoU,\nIoU-based losses are unstable and limited to simple shapes, and task-specific\nmethods are computationally intensive and not generalizable accross domains. As\na result, the current landscape of parametric shape objective functions has\nbecome scattered, with each domain proposing distinct IoU approximations. To\naddress this, we unify the parametric shape optimization objective functions by\nintroducing Marginalized Generalized IoU (MGIoU), a novel loss function that\novercomes these challenges by projecting structured convex shapes onto their\nunique shape Normals to compute one-dimensional normalized GIoU. MGIoU offers a\nsimple, efficient, fully differentiable approximation strongly correlated with\nIoU. We then extend MGIoU to MGIoU+ that supports optimizing unstructured\nconvex shapes. Together, MGIoU and MGIoU+ unify parametric shape optimization\nacross diverse applications. Experiments on standard benchmarks demonstrate\nthat MGIoU and MGIoU+ consistently outperform existing losses while reducing\nloss computation latency by 10-40x. Additionally, MGIoU and MGIoU+ satisfy\nmetric properties and scale-invariance, ensuring robustness as an objective\nfunction. We further propose MGIoU- for minimizing overlaps in tasks like\ncollision-free trajectory prediction. Code is available at\nhttps://ldtho.github.io/MGIoU","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T06:05:39Z"}
{"aid":"http://arxiv.org/abs/2504.16449v1","title":"From Past to Present: A Survey of Malicious URL Detection Techniques,\n  Datasets and Code Repositories","summary":"Malicious URLs persistently threaten the cybersecurity ecosystem, by either\ndeceiving users into divulging private data or distributing harmful payloads to\ninfiltrate host systems. Gaining timely insights into the current state of this\nongoing battle holds significant importance. However, existing reviews exhibit\n4 critical gaps: 1) Their reliance on algorithm-centric taxonomies obscures\nunderstanding of how detection approaches exploit specific modal information\nchannels; 2) They fail to incorporate pivotal LLM/Transformer-based defenses;\n3) No open-source implementations are collected to facilitate benchmarking; 4)\nInsufficient dataset coverage.This paper presents a comprehensive review of\nmalicious URL detection technologies, systematically analyzing methods from\ntraditional blacklisting to advanced deep learning approaches (e.g.\nTransformer, GNNs, and LLMs). Unlike prior surveys, we propose a novel\nmodality-based taxonomy that categorizes existing works according to their\nprimary data modalities (URL, HTML, Visual, etc.). This hierarchical\nclassification enables both rigorous technical analysis and clear understanding\nof multimodal information utilization. Furthermore, to establish a profile of\naccessible datasets and address the lack of standardized benchmarking (where\ncurrent studies often lack proper baseline comparisons), we curate and analyze:\n1) publicly available datasets (2016-2024), and 2) open-source implementations\nfrom published works(2013-2025). Then, we outline essential design principles\nand architectural frameworks for product-level implementations. The review\nconcludes by examining emerging challenges and proposing actionable directions\nfor future research. We maintain a GitHub repository for ongoing curating\ndatasets and open-source implementations:\nhttps://github.com/sevenolu7/Malicious-URL-Detection-Open-Source/tree/master.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-23T06:23:18Z"}
{"aid":"http://arxiv.org/abs/2504.16455v1","title":"Cross Paradigm Representation and Alignment Transformer for Image\n  Deraining","summary":"Transformer-based networks have achieved strong performance in low-level\nvision tasks like image deraining by utilizing spatial or channel-wise\nself-attention. However, irregular rain patterns and complex geometric overlaps\nchallenge single-paradigm architectures, necessitating a unified framework to\nintegrate complementary global-local and spatial-channel representations. To\naddress this, we propose a novel Cross Paradigm Representation and Alignment\nTransformer (CPRAformer). Its core idea is the hierarchical representation and\nalignment, leveraging the strengths of both paradigms (spatial-channel and\nglobal-local) to aid image reconstruction. It bridges the gap within and\nbetween paradigms, aligning and coordinating them to enable deep interaction\nand fusion of features. Specifically, we use two types of self-attention in the\nTransformer blocks: sparse prompt channel self-attention (SPC-SA) and spatial\npixel refinement self-attention (SPR-SA). SPC-SA enhances global channel\ndependencies through dynamic sparsity, while SPR-SA focuses on spatial rain\ndistribution and fine-grained texture recovery. To address the feature\nmisalignment and knowledge differences between them, we introduce the Adaptive\nAlignment Frequency Module (AAFM), which aligns and interacts with features in\na two-stage progressive manner, enabling adaptive guidance and complementarity.\nThis reduces the information gap within and between paradigms. Through this\nunified cross-paradigm dynamic interaction framework, we achieve the extraction\nof the most valuable interactive fusion information from the two paradigms.\nExtensive experiments demonstrate that our model achieves state-of-the-art\nperformance on eight benchmark datasets and further validates CPRAformer's\nrobustness in other image restoration tasks and downstream applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T06:44:46Z"}
{"aid":"http://arxiv.org/abs/2504.16456v1","title":"A measure-theoretic expansion exponent","summary":"The expansion exponent (or expansion constant) for maps was introduced by\nSchreiber in \\cite{s}. In this paper, we introduce the analogous exponent for\nmeasures. We shall prove the following results: The expansion exponent of a\nmeasurable maps is equal to the minimum of the expansion exponent taken over\nthe Borel probability measures. In particular, a map expands small distances\n(in the sense of Reddy \\cite{r}) if and only if every Borel probability has\npositive expansion exponent. Any nonatomic invariant measure with positive\nexpansion exponent is positively expansive in the sense of \\cite{m}. For\nergodic invariant measures, the Kolmogorov-Sinai entropy is bounded below by\nthe product of the expansion exponent and the measure upper capacity. As a\nconsequence, any ergodic invariant measure with both positive upper capacity\nand positive expansion exponent must have positive entropy.","main_category":"math.DS","categories":"math.DS","published":"2025-04-23T06:50:53Z"}
{"aid":"http://arxiv.org/abs/2504.16463v1","title":"Multiplicative Spanners in Minor-Free Graphs","summary":"In FOCS 2017, Borradaille, Le, and Wulff-Nilsen addressed a long-standing\nopen problem by proving that minor-free graphs have light spanners.\nSpecifically, they proved that every $K_h$-minor-free graph has a\n$(1+\\epsilon)$-spanner of lightness $O_{\\epsilon}(h \\sqrt{\\log h})$, hence\nconstant when $h$ and $\\epsilon$ are regarded as constants.\n  We extend this result by showing that a more expressive size/stretch tradeoff\nis available. Specifically: for any positive integer $k$, every $n$-node,\n$K_h$-minor-free graph has a $(2k-1)$-spanner with sparsity\n\\[O\\left(h^{\\frac{2}{k+1}} \\cdot \\text{polylog } h\\right),\\] and a\n$(1+\\epsilon)(2k-1)$-spanner with lightness\n\\[O_{\\epsilon}\\left(h^{\\frac{2}{k+1}} \\cdot \\text{polylog } h \\right).\\] We\nfurther prove that this exponent $\\frac{2}{k+1}$ is best possible, assuming the\ngirth conjecture. At a technical level, our proofs leverage the recent\nimprovements by Postle (2020) to the remarkable density increment theorem for\nminor-free graphs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T07:22:24Z"}
{"aid":"http://arxiv.org/abs/2504.16464v1","title":"ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree\n  and Visual Guidance","summary":"While recent advancements in robotic manipulation video synthesis have shown\npromise, significant challenges persist in ensuring effective\ninstruction-following and achieving high visual quality. Recent methods, like\nRoboDreamer, utilize linguistic decomposition to divide instructions into\nseparate lower-level primitives, conditioning the world model on these\nprimitives to achieve compositional instruction-following. However, these\nseparate primitives do not consider the relationships that exist between them.\nFurthermore, recent methods neglect valuable visual guidance, including depth\nand semantic guidance, both crucial for enhancing visual quality. This paper\nintroduces ManipDreamer, an advanced world model based on the action tree and\nvisual guidance. To better learn the relationships between instruction\nprimitives, we represent the instruction as the action tree and assign\nembeddings to tree nodes, each instruction can acquire its embeddings by\nnavigating through the action tree. The instruction embeddings can be used to\nguide the world model. To enhance visual quality, we combine depth and semantic\nguidance by introducing a visual guidance adapter compatible with the world\nmodel. This visual adapter enhances both the temporal and physical consistency\nof video generation. Based on the action tree and visual guidance, ManipDreamer\nsignificantly boosts the instruction-following ability and visual quality.\nComprehensive evaluations on robotic manipulation benchmarks reveal that\nManipDreamer achieves large improvements in video quality metrics in both seen\nand unseen tasks, with PSNR improved from 19.55 to 21.05, SSIM improved from\n0.7474 to 0.7982 and reduced Flow Error from 3.506 to 3.201 in unseen tasks,\ncompared to the recent RoboDreamer model. Additionally, our method increases\nthe success rate of robotic manipulation tasks by 2.5% in 6 RLbench tasks on\naverage.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-23T07:23:41Z"}
{"aid":"http://arxiv.org/abs/2504.16470v1","title":"Improved Streaming Edge Coloring","summary":"Given a graph, an edge coloring assigns colors to edges so that no pairs of\nadjacent edges share the same color. We are interested in edge coloring\nalgorithms under the W-streaming model. In this model, the algorithm does not\nhave enough memory to hold the entire graph, so the edges of the input graph\nare read from a data stream one by one in an unknown order, and the algorithm\nneeds to print a valid edge coloring in an output stream. The performance of\nthe algorithm is measured by the amount of space and the number of different\ncolors it uses.\n  This streaming edge coloring problem has been studied by several works in\nrecent years. When the input graph contains $n$ vertices and has maximum vertex\ndegree $\\Delta$, it is known that in the W-streaming model, an\n$O(\\Delta^2)$-edge coloring can be computed deterministically with\n$\\tilde{O}(n)$ space [Ansari, Saneian, and Zarrabi-Zadeh, 2022], or an\n$O(\\Delta^{1.5})$-edge coloring can be computed by a $\\tilde{O}(n)$-space\nrandomized algorithm [Behnezhad, Saneian, 2024] [Chechik, Mukhtar, Zhang,\n2024].\n  In this paper, we achieve polynomial improvement over previous results.\nSpecifically, we show how to improve the number of colors to\n$\\tilde{O}(\\Delta^{4/3+\\epsilon})$ using space $\\tilde{O}(n)$\ndeterministically, for any constant $\\epsilon > 0$. This is the first\ndeterministic result that bypasses the quadratic bound on the number of colors\nwhile using near-linear space.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T07:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.16501v1","title":"Dynamic Time-aware Continual User Representation Learning","summary":"Traditional user modeling (UM) approaches have primarily focused on designing\nmodels for a single specific task, but they face limitations in generalization\nand adaptability across various tasks. Recognizing these challenges, recent\nstudies have shifted towards continual learning (CL)-based universal user\nrepresentation learning aiming to develop a single model capable of handling\nmultiple tasks. Despite advancements, existing methods are in fact evaluated\nunder an unrealistic scenario that does not consider the passage of time as\ntasks progress, which overlooks newly emerged items that may change the item\ndistribution of previous tasks. In this paper, we introduce a practical\nevaluation scenario on which CL-based universal user representation learning\napproaches should be evaluated, which takes into account the passage of time as\ntasks progress. Then, we propose a novel framework Dynamic Time-aware continual\nuser representation learner, named DITTO, designed to alleviate catastrophic\nforgetting despite continuous shifts in item distribution, while also allowing\nthe knowledge acquired from previous tasks to adapt to the current shifted item\ndistribution. Through our extensive experiments, we demonstrate the superiority\nof DITTO over state-of-the-art methods under a practical evaluation scenario.\nOur source code is available at\nhttps://github.com/seungyoon-Choi/DITTO_official.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T08:23:59Z"}
{"aid":"http://arxiv.org/abs/2504.16517v1","title":"Gravitational Equilibrium with Steady Flow and Relativistic Local\n  Thermodynamics","summary":"A relativistic self-gravitating equilibrium system with steady flow as well\nas spherical symmetry is discovered. The energy-momentum tensor contains the\ncontribution of a current related to the flow and the metric tensor does an\noff-diagonal component to balance with the flow momentum. The presence of the\noff-diagonal component of the metric implies the radial motion of the reference\nframe, which gives rise to a problem how the relativistic effect is included in\nthermodynamic observables for such a general relativistic system. This problem\nis solved by taking an instantaneously rest frame in which geometric\nthermodynamic observables read as previously and giving them the special\nrelativistic effect emerged from the inverse transformation to the original\nframe pointwise. The solution of the thermodynamic observables in accord with\nthe laws of thermodynamics and the theory of relativity is presented. Finally\nthe relativistic structure equations for the equilibrium are derived, from\nwhich the general relativistic Poisson equation as well as the heat conduction\none are developed exactly.","main_category":"gr-qc","categories":"gr-qc,astro-ph.SR,hep-ph,hep-th","published":"2025-04-23T08:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.16534v1","title":"Partitioning of multiple brain metastases improves dose gradients in\n  single-isocenter radiosurgery","summary":"Background: A growing number of cancer patients with brain metastases can\nbenefit from stereotactic radiosurgery (SRS) thanks to recent advances in\nsystemic therapies. With an increasing patient load, single-isocenter\ntreatments on widely available C-arm linear accelerators are an attractive\noption. However, the planning of such treatments is challenging for\nmulti-target cases due to the island blocking problem, which occurs when the\nmulti-leaf collimator cannot conform to all targets simultaneously.\n  Purpose: We propose a multi-target partitioning algorithm that mitigates\nexcessive exposure of normal tissue caused by the island blocking problem.\n  Methods: The algorithm divides (partitions) the set of targets into subsets\nto treat with separate arc passes, optimizing both subsets and collimator\nangles to minimize island blocking. The algorithm was incorporated into a fully\nautomated treatment planning script and evaluated on 20 simulated patient\ncases, each with 10 brain metastases and 21 Gy prescriptions. It was also\nretrospectively evaluated on six clinical cases.\n  Results: Partitioning significantly improved the gradient index, global\nefficiency index, and brain V12Gy compared to simultaneous treatment of all\nmetastases. For example, the average gradient index improved from 5.9 to 3.3,\nglobal efficiency index from 0.32 to 0.46, and normal brain V12Gy from 49 cm3\nto 26 cm3 between 3 and 9 arcs. The proposed algorithm outperformed baselines\nin utilizing a limited number of arcs. All target partitioning strategies\nincreased the total number of monitor units (MUs).\n  Conclusions: The dose gradient in single-isocenter VMAT plans can be\nsubstantially improved by treating a smaller subset of metastases at a time.\nThis requires more MUs and arcs, implying a trade-off between delivery time and\nplan quality which can be explored using the algorithm proposed in this paper.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-23T09:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.16560v1","title":"On existence of spatially regular strong solutions for a class of\n  transport equations","summary":"The paper considers existence of spatially regular solutions for a class of\nlinear Boltzmann transport equations. The related transport problem is an\n(initial) inflow boundary value problem. This problem is characteristic with\nvariable multiplicity, that is, the rank of the boundary matrix (here a scalar)\nis not constant on the boundary. It is known that for these types of (initial)\nboundary value problems the full higher order Sobolev regularity cannot\ngenerally be established. In this paper we present Sobolev regularity results\nfor solutions of linear Boltzmann transport problems when the data belongs to\nappropriate anisotropic Sobolev spaces whose elements are zero on the inflow\nand characteristic parts of the boundary.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T09:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.16572v1","title":"Bridging Data Gaps and Building Knowledge Networks in Indian Football\n  Analytics","summary":"The global rise of football analytics has rapidly transformed how clubs make\nstrategic decisions. However, in India, the adoption of analytics remains\nconstrained by institutional resistance, infrastructural limitations, and\ncultural barriers -- challenges that grassroots innovation and low-cost data\nsolutions have the potential to overcome. Despite the growing popularity of the\nIndian Super League, resource scarcity and fragmented governance continue to\nhinder the widespread adoption and impact of analytics. This mixed-methods\nstudy explores how informal, decentralised analytics communities -- comprising\namateur analysts and Twitter-based \"data sleuths\" -- navigate these constraints\nthrough peer mentorship and grassroots innovation. Drawing on extensive digital\nethnography, participant observation, and interviews, the study illustrates how\nthese informal networks mitigate data scarcity, limited digital infrastructure,\nand institutional indifference while fostering skill development and\nprofessional growth. Building on these insights, the paper proposes HCI\ninterventions such as decentralised knowledge platforms to facilitate\nstructured, cross-border peer mentorship and low-cost data solutions --\nincluding AI-assisted player tracking and mobile analytics dashboards -- rooted\nin principles of frugal innovation. These interventions aim to bridge the data\ndivide, support inclusive technical engagement in sport, and enhance\nanalytics-driven decision-making in resource-constrained environments. This\npaper contributes to HCIxB's focus on cross-border collaboration by\nhighlighting how community-driven technological adaptation in the Global South\ncan foster meaningful participation, skill-building, and long-term\nsustainability through informal learning networks and scalable,\ncontext-sensitive tools.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T09:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.16586v1","title":"Learning Switchable Priors for Neural Image Compression","summary":"Neural image compression (NIC) usually adopts a predefined family of\nprobabilistic distributions as the prior of the latent variables, and meanwhile\nrelies on entropy models to estimate the parameters for the probabilistic\nfamily. More complex probabilistic distributions may fit the latent variables\nmore accurately, but also incur higher complexity of the entropy models,\nlimiting their practical value. To address this dilemma, we propose a solution\nto decouple the entropy model complexity from the prior distributions. We use a\nfinite set of trainable priors that correspond to samples of the parametric\nprobabilistic distributions. We train the entropy model to predict the index of\nthe appropriate prior within the set, rather than the specific parameters.\nSwitching between the trained priors further enables us to embrace a skip mode\ninto the prior set, which simply omits a latent variable during the entropy\ncoding. To demonstrate the practical value of our solution, we present a\nlightweight NIC model, namely FastNIC, together with the learning of switchable\npriors. FastNIC obtains a better trade-off between compression efficiency and\ncomputational complexity for neural image compression. We also implanted the\nswitchable priors into state-of-the-art NIC models and observed improved\ncompression efficiency with a significant reduction of entropy coding\ncomplexity.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-23T10:06:58Z"}
{"aid":"http://arxiv.org/abs/2504.16587v1","title":"Spin polarization as a probe of the QCD critical point","summary":"Spin polarization is a novel method for probing the rotational properties of\nthe quark-gluon plasma (QGP) produced in relativistic heavy-ion collisions. In\nthis work, we investigate the effective transport and thermodynamic\ncoefficients in non-central O+O light-ion collisions, considering a parton\ndistribution function that incorporates the spin polarization induced by\nthermal vorticity during the collision. Using a kinetic theory approach, we\nfind that while the speed of sound squared ($c_s^2$) remains largely unaffected\nby spin polarization, the specific shear viscosity ($\\eta/s$), specific bulk\nviscosity ($\\zeta/s$), and mean free path ($\\lambda$) are significantly\nmodified.\n  Notably, when spin polarization is taken into account, both $c_s^2 $ and\n$\\zeta/s$ exhibit a non-monotonic dependence on collision energy, with an\ninflection point around $\\sqrt{s_{NN}} = 27 $~GeV, corresponding to an average\nparton chemical potential of $\\langle\\mu_p\\rangle = 0.021 $~GeV. This\nnon-monotonic behavior suggests that incorporating spin polarization into\ntheoretical calculations could provide an effective probe for locating the\ncritical point of the QCD phase transition.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-23T10:08:31Z"}
{"aid":"http://arxiv.org/abs/2504.16647v1","title":"Medium-induced coherent gluon radiation for $2\\to 2$ processes with\n  general kinematics","summary":"High-energy proton-nucleus (pA) collisions have provided various clues for\nthe role of cold nuclear matter effects in hadron production. In particular,\nmultiple rescatterings of an incoming parton by the nuclear target are known to\ninduce the radiation of many soft gluons, with those having a long formation\ntime leading to the modification of hadron production rates due to fully\ncoherent energy loss (FCEL). Here we present a recently derived formula for the\ninduced single soft gluon radiation spectrum beyond leading logarithmic\naccuracy, whose main features are demonstrated with the example of $q\\, g \\to\nq\\, g$ scattering.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-23T12:07:39Z"}
{"aid":"http://arxiv.org/abs/2504.16666v1","title":"Anomalies in Muon-Induced Neutron Emissions from Pb","summary":"This paper analyses neutron multiplicity spectra from massive targets at\ndepths of 3, 40, 210, 583, 1166, and 4000 m.w.e. The measurements, conducted\nbetween 2001 and 2024, utilised three experimental setups with either 14 or 60\nHe-3 neutron detectors and lead (Pb) targets weighing 306, 565, or 1134 kg. The\ntotal acquisition time exceeded six years. When available, the acquired spectra\nwere compared with Monte Carlo simulations. Our data challenges the practice of\napproximating the muon-induced neutron multiplicity spectra with one power-law\nfunction $k \\times m^{-p}$, where m is the multiplicity, k is the depth-related\nparameter decreasing with overburden, and p is the slope parameter that remains\nunchanged with depth. Instead, we see the emergence of a second component. It\nis evident already in the muon-suppressed spectrum collected on the surface and\ndominates the spectra at 1166 and 4000 m.w.e. In addition, we see indications\nof a possible structure in the second component that resembles emissions of\napproximately 74, 106, 143, and 214 neutrons from the target. Since the anomaly\nvaries only slightly with depth, it is not directly correlated with the muon\nflux. We propose new underground measurements employing low-cost, large-area,\nposition-sensitive neutron counters to verify and investigate the observed\nanomalies and ascertain their origin.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-23T12:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.16682v1","title":"Provable wavelet-based neural approximation","summary":"In this paper, we develop a wavelet-based theoretical framework for analyzing\nthe universal approximation capabilities of neural networks over a wide range\nof activation functions. Leveraging wavelet frame theory on the spaces of\nhomogeneous type, we derive sufficient conditions on activation functions to\nensure that the associated neural network approximates any functions in the\ngiven space, along with an error estimate. These sufficient conditions\naccommodate a variety of smooth activation functions, including those that\nexhibit oscillatory behavior. Furthermore, by considering the $L^2$-distance\nbetween smooth and non-smooth activation functions, we establish a generalized\napproximation result that is applicable to non-smooth activations, with the\nerror explicitly controlled by this distance. This provides increased\nflexibility in the design of network architectures.","main_category":"cs.LG","categories":"cs.LG,math.CA,stat.ML","published":"2025-04-23T13:02:37Z"}
{"aid":"http://arxiv.org/abs/2504.16715v1","title":"Modeling of Experimentally Observed Two-Dimensional Precursor Solitons\n  in a Dusty Plasma by the forced Kadomtsev-Petviashvili Equation","summary":"We compare model solutions of a forced Kadomtsev-Petviashvili (fKP) equation\nwith experimental observations of dust acoustic precursor solitons excited by a\nsupersonically moving charged cylindrical object in a dusty plasma medium. The\nfKP equation is derived from a three-fluid-Poisson model of the dusty plasma\nusing the reductive perturbation technique and numerically solved for\nparameters close to the experimental investigations of cylindrical precursor\nsolitons. The fKP model solutions show excellent agreement with the\nexperimental results in reproducing the prominent geometric features of the\ntwo-dimensional solitons and closely matching the quantitative values of their\nvelocities, amplitudes, and temporal evolutions. Our findings suggest that the\nfKP equation can serve as a very realistic model to investigate the dynamics of\nprecursor solitons and can be usefully employed in practical applications such\nas space debris detection and tracking techniques that are based on\nobserving/predicting nonlinear plasma excitations induced by the debris in the\nionosphere.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-23T13:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.16725v1","title":"Quantum sensing with spin defects in boron nitride nanotubes","summary":"Spin defects in semiconductors are widely investigated for various\napplications in quantum sensing. Conventional host materials such as diamond\nand hexagonal boron nitride (hBN) provide bulk or low-dimensional platforms for\noptically addressable spin systems, but often lack the structural properties\nneeded for chemical sensing. Here, we introduce a new class of quantum sensors\nbased on naturally occurring spin defects in boron nitride nanotubes (BNNTs),\nwhich combine high surface area with omnidirectional spin control, key features\nfor enhanced sensing performance. First, we present strong evidence that these\ndefects are carbon-related, akin to recently identified centers in hBN, and\ndemonstrate coherent spin control over ensembles embedded within dense,\nmicroscale BNNTs networks. Using dynamical decoupling, we enhance spin\ncoherence times by a factor exceeding 300x and implement high-resolution\ndetection of radiofrequency signals. By integrating the BNNT mesh sensor into a\nmicrofluidic platform we demonstrate chemical sensing of paramagnetic ions in\nsolution, with detectable concentrations reaching levels nearly 1000 times\nlower than previously demonstrated using comparable hBN-based systems. This\nhighly porous and flexible architecture positions BNNTs as a powerful new host\nmaterial for quantum sensing.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph,physics.chem-ph","published":"2025-04-23T13:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.16728v1","title":"IRIS: Interactive Research Ideation System for Accelerating Scientific\n  Discovery","summary":"The rapid advancement in capabilities of large language models (LLMs) raises\na pivotal question: How can LLMs accelerate scientific discovery? This work\ntackles the crucial first stage of research, generating novel hypotheses. While\nrecent work on automated hypothesis generation focuses on multi-agent\nframeworks and extending test-time compute, none of the approaches effectively\nincorporate transparency and steerability through a synergistic\nHuman-in-the-loop (HITL) approach. To address this gap, we introduce IRIS:\nInteractive Research Ideation System, an open-source platform designed for\nresearchers to leverage LLM-assisted scientific ideation. IRIS incorporates\ninnovative features to enhance ideation, including adaptive test-time compute\nexpansion via Monte Carlo Tree Search (MCTS), fine-grained feedback mechanism,\nand query-based literature synthesis. Designed to empower researchers with\ngreater control and insight throughout the ideation process. We additionally\nconduct a user study with researchers across diverse disciplines, validating\nthe effectiveness of our system in enhancing ideation. We open-source our code\nat https://github.com/Anikethh/IRIS-Interactive-Research-Ideation-System","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-23T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.16733v1","title":"Identification of quasars variable over long time scales from infrared\n  surveys. Ensemble variability and structure function properties","summary":"Quasars are variable and their variability can both constrain their physical\nproperties and help to identify them. We look for ways to efficiently identify\nquasars exhibiting consistent variability over multi-year time-scales, based on\na small number of epochs. Using infrared (IR) is desirable to avoid bias\nagainst reddened objects. We compare the apparent brightness of known quasars\nthat have been observed with two IR surveys, covering up to a twenty-year\nbaseline: the Two Micron All Sky Survey (2MASS; 1997-2001) and the VISTA\nHemisphere Survey (VHS; 2009-2017). We look at the previous studies of the\nselected variable quasars to see if their variable behaviour is known and when\navailable we use multi-epoch monitoring with the Zwicky Transient Facility\n(ZTF) to obtain a measure of optical variability of individual objects. We\nbuild a sample of ~2500 quasars that show statistically significant variability\nbetween the 2MASS and VHS. About 1500 of these come from the new Quaia sample\nbased on Gaia spectra and about 1/3 of these have hardly been studied. The\nQuaia sample constitutes the main product of this work. Based on ensemble\nvariability and structure function analysis we demonstrate that the selected\nobjects in our sample are representative of the typical quasar population and\nshow behaviour, consistent with other quasar samples. Our analysis strengthens\nprevious results, for example that variability decreases with the rest-frame\nwavelength and that it exhibits peaks for certain absolute magnitudes of the\nquasars. Similarly, the structure function shows an increase in variability for\nrest-frame time lags below ~1500 d and a decrease for longer lags, just like in\nprevious studies. Our selection, even though it is based on two epochs only,\nseems to be surprisingly robust, showing up to ~11% contamination by quasars\nthat show stable non-variable behaviour in ZTF.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-23T14:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.16748v1","title":"Simple Graph Contrastive Learning via Fractional-order Neural Diffusion\n  Networks","summary":"Graph Contrastive Learning (GCL) has recently made progress as an\nunsupervised graph representation learning paradigm. GCL approaches can be\ncategorized into augmentation-based and augmentation-free methods. The former\nrelies on complex data augmentations, while the latter depends on encoders that\ncan generate distinct views of the same input. Both approaches may require\nnegative samples for training. In this paper, we introduce a novel\naugmentation-free GCL framework based on graph neural diffusion models.\nSpecifically, we utilize learnable encoders governed by Fractional Differential\nEquations (FDE). Each FDE is characterized by an order parameter of the\ndifferential operator. We demonstrate that varying these parameters allows us\nto produce learnable encoders that generate diverse views, capturing either\nlocal or global information, for contrastive learning. Our model does not\nrequire negative samples for training and is applicable to both homophilic and\nheterophilic datasets. We demonstrate its effectiveness across various\ndatasets, achieving state-of-the-art performance.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T14:17:28Z"}
{"aid":"http://arxiv.org/abs/2504.16764v1","title":"A Note on the Stability of the Dark Energy Model from Time Crystals","summary":"In this note, we investigate the stability of the dark energy model from time\ncrystals proposed in [1]. We emphasize two ingredients, the coupling of the\nscalar field to gravity, and the fact that these time crystals are on an\nexpanding FRW background, which play a crucial role in the field's dynamics.\nThe Hubble parameter, which contributes a drag term to the equations of motion,\ngrows with time until the scale factor diverges. When taken into account, these\nfactors also alleviate the stability concern of [2].","main_category":"gr-qc","categories":"gr-qc,hep-ph,hep-th","published":"2025-04-23T14:34:30Z"}
{"aid":"http://arxiv.org/abs/2504.16777v1","title":"Systemic Flakiness: An Empirical Analysis of Co-Occurring Flaky Test\n  Failures","summary":"Flaky tests produce inconsistent outcomes without code changes, creating\nmajor challenges for software developers. An industrial case study reported\nthat developers spend 1.28% of their time repairing flaky tests at a monthly\ncost of $2,250. We discovered that flaky tests often exist in clusters, with\nco-occurring failures that share the same root causes, which we call systemic\nflakiness. This suggests that developers can reduce repair costs by addressing\nshared root causes, enabling them to fix multiple flaky tests at once rather\nthan tackling them individually. This study represents an inflection point by\nchallenging the deep-seated assumption that flaky test failures are isolated\noccurrences. We used an established dataset of 10,000 test suite runs from 24\nJava projects on GitHub, spanning domains from data orchestration to job\nscheduling. It contains 810 flaky tests, which we levered to perform a\nmixed-method empirical analysis of co-occurring flaky test failures. Systemic\nflakiness is significant and widespread. We performed agglomerative clustering\nof flaky tests based on their failure co-occurrence, finding that 75% of flaky\ntests across all projects belong to a cluster, with a mean cluster size of 13.5\nflaky tests. Instead of requiring 10,000 test suite runs to identify systemic\nflakiness, we demonstrated a lightweight alternative by training machine\nlearning models based on static test case distance measures. Through manual\ninspection of stack traces, conducted independently by four authors and\nresolved through negotiated agreement, we identified intermittent networking\nissues and instabilities in external dependencies as the predominant causes of\nsystemic flakiness.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.16789v1","title":"MLOps Monitoring at Scale for Digital Platforms","summary":"Machine learning models are widely recognized for their strong performance in\nforecasting. To keep that performance in streaming data settings, they have to\nbe monitored and frequently re-trained. This can be done with machine learning\noperations (MLOps) techniques under supervision of an MLOps engineer. However,\nin digital platform settings where the number of data streams is typically\nlarge and unstable, standard monitoring becomes either suboptimal or too labor\nintensive for the MLOps engineer. As a consequence, companies often fall back\non very simple worse performing ML models without monitoring. We solve this\nproblem by adopting a design science approach and introducing a new monitoring\nframework, the Machine Learning Monitoring Agent (MLMA), that is designed to\nwork at scale for any ML model with reasonable labor cost. A key feature of our\nframework concerns test-based automated re-training based on a data-adaptive\nreference loss batch. The MLOps engineer is kept in the loop via key metrics\nand also acts, pro-actively or retrospectively, to maintain performance of the\nML model in the production stage. We conduct a large-scale test at a last-mile\ndelivery platform to empirically validate our monitoring framework.","main_category":"econ.EM","categories":"econ.EM,stat.AP","published":"2025-04-23T15:04:38Z"}
{"aid":"http://arxiv.org/abs/2504.16806v1","title":"V4141 Sgr: Outflows and repeated outbursts","summary":"In this work, we analyze the ongoing brightening of the poorly studied\nsymbiotic star V4141 Sgr and examine its long-term variability. We present new\nlow-resolution spectroscopic observations of the system in its bright state and\ncombine them with multi-color photometric data from our observations, ASAS-SN,\nATLAS, and Gaia DR3. To investigate its long-term evolution, we also\nincorporate historical data, including photographic plates, constructing a\nlight curve spanning more than a century. Our analysis reveals that V4141 Sgr\nhas undergone multiple outbursts, with at least one exhibiting characteristics\ntypical of \"slow\" symbiotic novae. The current outburst is characterized by the\nejection of optically thick material and possibly bipolar jets, a phenomenon\nobserved in only a small fraction of symbiotic stars. These findings establish\nV4141 Sgr as an intriguing target for continued monitoring.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.16825v1","title":"Symbiotic stars in the era of modern ground- and space-based surveys","summary":"Symbiotic stars, interacting binaries composed of a cool giant and a hot\ncompact companion, exhibit complex variability across the electromagnetic\nspectrum. Over the past decades, large-scale photometric and spectroscopic\nsurveys from ground- and space-based observatories have significantly advanced\ntheir discovery and characterization. These datasets have transformed the\nsearch for new symbiotic candidates, providing extensive time-domain\ninformation crucial for their classification and analysis. This review\nhighlights recent observational results that have expanded the known population\nof symbiotic stars, refined classification criteria, and enhanced our\nunderstanding of their variability. Despite these advances, fundamental\nquestions remain regarding their long-term evolution, mass transfer and\naccretion processes, or their potential role as progenitors of Type Ia\nsupernovae. With ongoing and upcoming surveys, the coming years promise new\ndiscoveries and a more comprehensive picture of these intriguing interacting\nsystems.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.16865v1","title":"General method for solving nonlinear optical scattering problems using\n  fix point iterations","summary":"In this paper we introduce a new fix point iteration scheme for solving\nnonlinear electromagnetic scattering problems. The method is based on a\nspectral formulation of Maxwell's equations called the Bidirectional Pulse\nPropagation Equations. The scheme can be applied to a wide array of slab-like\ngeometries, and for arbitrary material responses. We derive the scheme and\ninvestigated how it performs with respect to convergence and accuracy by\napplying it to the case of light scattering from a simple slab whose nonlinear\nmaterial response is a sum a very fast electronic vibrational response, and a\nmuch slower molecular vibrational response.","main_category":"physics.class-ph","categories":"physics.class-ph,physics.comp-ph","published":"2025-04-23T16:38:49Z"}
{"aid":"http://arxiv.org/abs/2504.16872v1","title":"The FAST Discovery of a Millisecond Pulsar Hidden in the Harmonics of\n  PSR J2129+1210A (M15A)","summary":"We report the discovery of an isolated millisecond pulsar M15O (J2129+1210O)\nfrom the globular cluster M15 (NGC 7078) with a period of $\\sim$11.06686 ms and\na dispersion measure of $\\sim$67.44 cm$^{-3}$ pc. Its spin period is so close\nto the $10^{\\text{th}}$ harmonic of the bright pulsar M15A ($\\sim$11.06647 ms)\nand thus missed in previous pulsar search. We suggest adding the spectrum in\nthe pulsar candidate diagnostic plot to identify new signals near the\nharmonics. M15O has the first spin frequency derivative and the second spin\nfrequency derivative,being 1.79191(5) $\\times$ $10^{-14}$ Hz $s^{-2}$ and\n3.3133(6)$\\times$ $10^{-23}$ Hz $s^{-3}$, respectively. Its projected distance\nfrom the optical centre of M15 is the closest among all the pulsars in M15. The\norigin can be something from the center of the massive and core-collapsed\nglobular cluster M15.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T16:46:20Z"}
{"aid":"http://arxiv.org/abs/2504.16882v1","title":"Fractional $Q$-curvature on the sphere and optimal partitions","summary":"We study an optimal partition problem on the sphere, where the cost\nfunctional is associated with the fractional $Q$-curvature in terms of the\nconformal fractional Laplacian on the sphere. By leveraging symmetries, we\nprove the existence of a symmetric minimal partition through a variational\napproach. A key ingredient in our analysis is a new H\\\"older regularity result\nfor symmetric functions in a fractional Sobolev space on the sphere. As a\nbyproduct, we establish the existence of infinitely many solutions to a\nnonlocal weakly-coupled competitive system on the sphere that remain invariant\nunder a group of conformal diffeomorphisms and we investigate the asymptotic\nbehavior of least-energy solutions as the coupling parameters approach negative\ninfinity.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-23T16:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.16883v1","title":"Enhancing Critical Thinking with AI: A Tailored Warning System for RAG\n  Models","summary":"Retrieval-Augmented Generation (RAG) systems offer a powerful approach to\nenhancing large language model (LLM) outputs by incorporating fact-checked,\ncontextually relevant information. However, fairness and reliability concerns\npersist, as hallucinations can emerge at both the retrieval and generation\nstages, affecting users' reasoning and decision-making. Our research explores\nhow tailored warning messages -- whose content depends on the specific context\nof hallucination -- shape user reasoning and actions in an educational quiz\nsetting. Preliminary findings suggest that while warnings improve accuracy and\nawareness of high-level hallucinations, they may also introduce cognitive\nfriction, leading to confusion and diminished trust in the system. By examining\nthese interactions, this work contributes to the broader goal of AI-augmented\nreasoning: developing systems that actively support human reflection, critical\nthinking, and informed decision-making rather than passive information\nconsumption.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T17:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.16895v1","title":"Exact analytic solutions in 2+1 Hořava gravity with cosmological\n  constant","summary":"We investigate the static solutions with rotational symmetry in the\nnonprojectable Ho\\v{r}ava theory in 2+1 dimensions. We consider all\ninequivalent terms of the effective theory, including the cosmological\nconstant. We find two distinct types of solutions: the first one corresponds to\na Lifshitz solution, while the second one is obtained through a coordinate\ntransformation of the equations of motion. This exact solution does not exhibit\nLifshitz behavior and features a naked singularity.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T17:24:53Z"}
{"aid":"http://arxiv.org/abs/2504.16906v1","title":"An Accelerated Camera 3DMA Framework for Efficient Urban GNSS Multipath\n  Estimation","summary":"Robust GNSS positioning in urban environments is still plagued by multipath\neffects, particularly due to the complex signal propagation induced by\nubiquitous surfaces with varied radio frequency reflectivities. Current 3D\nMapping Aided (3DMA) GNSS techniques show great potentials in mitigating\nmultipath but face a critical trade-off between computational efficiency and\nmodeling accuracy. Most approaches often rely on offline outdated or\noversimplified 3D maps, while real-time LiDAR-based reconstruction boasts high\naccuracy, it is problematic in low laser reflectivity conditions; camera 3DMA\nis a good candidate to balance accuracy and efficiency but current methods\nsuffer from extremely low reconstruction speed, a far cry from real-time\nmultipath-mitigated navigation. This paper proposes an accelerated framework\nincorporating camera multi-view stereo (MVS) reconstruction and ray tracing. By\nhypothesizing on surface textures, an orthogonal visual feature fusion\nframework is proposed, which robustly addresses both texture-rich and\ntexture-poor surfaces, lifting off the reflectivity challenges in visual\nreconstruction. A polygonal surface modeling scheme is further integrated to\naccurately delineate complex building boundaries, enhancing the reconstruction\ngranularity. To avoid excessively accurate reconstruction, reprojected point\ncloud multi-plane fitting and two complexity control strategies are proposed,\nthus improving upon multipath estimation speed. Experiments were conducted in\nLujiazui, Shanghai, a typical multipath-prone district. The results show that\nthe method achieves an average reconstruction accuracy of 2.4 meters in dense\nurban environments featuring glass curtain wall structures, a traditionally\ntough case for reconstruction, and achieves a ray-tracing-based multipath\ncorrection rate of 30 image frames per second, 10 times faster than the\ncontemporary benchmarks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T17:34:37Z"}
{"aid":"http://arxiv.org/abs/2504.16918v1","title":"OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents","summary":"Optimization plays a vital role in scientific research and practical\napplications, but formulating a concrete optimization problem described in\nnatural language into a mathematical form and selecting a suitable solver to\nsolve the problem requires substantial domain expertise. We introduce\n\\textbf{OptimAI}, a framework for solving \\underline{Optim}ization problems\ndescribed in natural language by leveraging LLM-powered \\underline{AI} agents,\nachieving superior performance over current state-of-the-art methods. Our\nframework is built upon four key roles: (1) a \\emph{formulator} that translates\nnatural language problem descriptions into precise mathematical formulations;\n(2) a \\emph{planner} that constructs a high-level solution strategy prior to\nexecution; and (3) a \\emph{coder} and a \\emph{code critic} capable of\ninteracting with the environment and reflecting on outcomes to refine future\nactions. Ablation studies confirm that all roles are essential; removing the\nplanner or code critic results in $5.8\\times$ and $3.1\\times$ drops in\nproductivity, respectively. Furthermore, we introduce UCB-based debug\nscheduling to dynamically switch between alternative plans, yielding an\nadditional $3.3\\times$ productivity gain. Our design emphasizes multi-agent\ncollaboration, allowing us to conveniently explore the synergistic effect of\ncombining diverse models within a unified system. Our approach attains 88.1\\%\naccuracy on the NLP4LP dataset and 71.2\\% on the Optibench (non-linear w/o\ntable) subset, reducing error rates by 58\\% and 50\\% respectively over prior\nbest results.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T17:45:05Z"}
{"aid":"http://arxiv.org/abs/2504.17254v1","title":"Efficient simulation of discrete galaxy populations and associated\n  radiation fields during the first billion years","summary":"Understanding the epochs of cosmic dawn and reionisation requires us to\nleverage multi-wavelength and multi-tracer observations, with each dataset\nproviding a complimentary piece of the puzzle. To interpret such data, we\nupdate the public simulation code, 21cmFASTv4, to include a discrete source\nmodel based on stochastic sampling of conditional mass functions and\nsemi-empirical galaxy relations. We demonstrate that our new galaxy model,\nwhich parametrizes the means and scatters of well-established scaling\nrelations, is flexible enough to characterize very different predictions from\nhydrodynamic cosmological simulations of high-redshift galaxies. Combining a\ndiscrete galaxy population with approximate, efficient radiative transfer\nallows us to self-consistently forward-model galaxy surveys, line intensity\nmaps (LIMs), and observations of the intergalactic medium (IGM). Not only does\neach observable probe different scales and physical processes, but\ncross-correlation will maximise the information gained from each measurement by\nprobing the galaxy-IGM connection at high-redshift. We find that a stochastic\nsource field produces significant shot-noise in 21cm and LIM power spectra.\nScatter in galaxy properties can be constrained using UV luminosity functions\nand/or 21cm power spectra, especially if astrophysical scatter is higher than\nexpected (as might be needed to explain recent JWST observations). Our\nmodelling pipeline is both flexible and computationally efficient, facilitating\nhigh-dimensional, multi-tracer, field-level Bayesian inference of cosmology and\nastrophysics during the first billion years.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-24T05:18:08Z"}
{"aid":"http://arxiv.org/abs/2504.17263v1","title":"Precision Neural Network Quantization via Learnable Adaptive Modules","summary":"Quantization Aware Training (QAT) is a neural network quantization technique\nthat compresses model size and improves operational efficiency while\neffectively maintaining model performance. The paradigm of QAT is to introduce\nfake quantization operators during the training process, allowing the model to\nautonomously compensate for information loss caused by quantization. Making\nquantization parameters trainable can significantly improve the performance of\nQAT, but at the cost of compromising the flexibility during inference,\nespecially when dealing with activation values with substantially different\ndistributions. In this paper, we propose an effective learnable adaptive neural\nnetwork quantization method, called Adaptive Step Size Quantization (ASQ), to\nresolve this conflict. Specifically, the proposed ASQ method first dynamically\nadjusts quantization scaling factors through a trained module capable of\naccommodating different activations. Then, to address the rigid resolution\nissue inherent in Power of Two (POT) quantization, we propose an efficient\nnon-uniform quantization scheme. We utilize the Power Of Square root of Two\n(POST) as the basis for exponential quantization, effectively handling the\nbell-shaped distribution of neural network weights across various bit-widths\nwhile maintaining computational efficiency through a Look-Up Table method\n(LUT). Extensive experimental results demonstrate that the proposed ASQ method\nis superior to the state-of-the-art QAT approaches. Notably that the ASQ is\neven competitive compared to full precision baselines, with its 4-bit quantized\nResNet34 model improving accuracy by 1.2\\% on ImageNet.","main_category":"cs.CV","categories":"cs.CV,cs.CC","published":"2025-04-24T05:46:25Z"}
{"aid":"http://arxiv.org/abs/2504.17326v1","title":"Quantum Corner VOA and the Super Macdonald Polynomials","summary":"In this paper, we establish a relation between the quantum corner VOA\n$q\\widetilde{Y}_{L,0,N}[\\Psi]$, which can be regarded as a generalization of\nquantum $W_N$ algebra, and Sergeev-Veselov super Macdonald polynomials. We\ndemonstrate precisely that, under a specific map, the correlation functions of\nthe currents of $q\\widetilde{Y}_{L,0,N}[\\Psi]$, coincide with the\nSergeev-Veselov super Macdonald polynomials.","main_category":"hep-th","categories":"hep-th,math-ph,math.CO,math.MP,math.QA,math.RT","published":"2025-04-24T07:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.17348v1","title":"On the length of generating sets with conditions on minimal polynomial","summary":"Linear upper bounds may be derived by imposing specific structural conditions\non a generating set, such as additional constraints on ranks, eigenvalues, or\nthe degree of the minimal polynomial of the generating matrices. This paper\nestablishes a linear upper bound of \\(3n-5\\) for generating sets that contain a\nmatrix whose minimal polynomial has a degree exceeding \\(\\frac{n}{2}\\), where\n\\(n\\) denotes the order of the matrix. Compared to the bound provided in\n\\cite[Theorem 3.1]{r2}, this result reduces the constraints on the Jordan\ncanonical forms. Additionally, it is demonstrated that the bound\n\\(\\frac{7n}{2}-4\\) holds when the generating set contains a matrix with a\nminimal polynomial of degree \\(t\\) satisfying \\(2t\\le n\\le 3t-1\\). The primary\nenhancements consist of quantitative bounds and reduced reliance on Jordan form\nstructural constraints.","main_category":"math.RA","categories":"math.RA","published":"2025-04-24T08:09:32Z"}
{"aid":"http://arxiv.org/abs/2504.17355v1","title":"Collaborative Multi-Agent Reinforcement Learning for Automated Feature\n  Transformation with Graph-Driven Path Optimization","summary":"Feature transformation methods aim to find an optimal mathematical\nfeature-feature crossing process that generates high-value features and\nimproves the performance of downstream machine learning tasks. Existing\nframeworks, though designed to mitigate manual costs, often treat feature\ntransformations as isolated operations, ignoring dynamic dependencies between\ntransformation steps. To address the limitations, we propose TCTO, a\ncollaborative multi-agent reinforcement learning framework that automates\nfeature engineering through graph-driven path optimization. The framework's\ncore innovation lies in an evolving interaction graph that models features as\nnodes and transformations as edges. Through graph pruning and backtracking, it\ndynamically eliminates low-impact edges, reduces redundant operations, and\nenhances exploration stability. This graph also provides full traceability to\nempower TCTO to reuse high-utility subgraphs from historical transformations.\nTo demonstrate the efficacy and adaptability of our approach, we conduct\ncomprehensive experiments and case studies, which show superior performance\nacross a range of datasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T08:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.17364v1","title":"I-INR: Iterative Implicit Neural Representations","summary":"Implicit Neural Representations (INRs) have revolutionized signal processing\nand computer vision by modeling signals as continuous, differentiable functions\nparameterized by neural networks. However, their inherent formulation as a\nregression problem makes them prone to regression to the mean, limiting their\nability to capture fine details, retain high-frequency information, and handle\nnoise effectively. To address these challenges, we propose Iterative Implicit\nNeural Representations (I-INRs) a novel plug-and-play framework that enhances\nsignal reconstruction through an iterative refinement process. I-INRs\neffectively recover high-frequency details, improve robustness to noise, and\nachieve superior reconstruction quality. Our framework seamlessly integrates\nwith existing INR architectures, delivering substantial performance gains\nacross various tasks. Extensive experiments show that I-INRs outperform\nbaseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision\napplications such as image restoration, image denoising, and object occupancy\nprediction.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T08:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.17369v1","title":"Complexity one varieties are cluster type","summary":"The complexity of a pair $(X,B)$ is an invariant that relates the dimension\nof $X$, the rank of the group of divisors, and the coefficients of $B$. If the\ncomplexity is less than one, then $X$ is a toric variety. We prove that if the\ncomplexity is less than two, then $X$ is a Fano type variety. Furthermore, if\nthe complexity is less than 3/2, then $X$ admits a Calabi--Yau structure\n$(X,B)$ of complexity one and index at most two, and it admits a finite cover\n$Y \\to X$ of degree at most 2, where $Y$ is a cluster type variety. In\nparticular, if the complexity is one and the index is one, $(X,B)$ is cluster\ntype. Finally, we establish a connection with the theory of\n$\\mathbb{T}$-varieties. We prove that a variety of $\\mathbb{T}$-complexity one\nadmits a similar finite cover from a cluster type variety.","main_category":"math.AG","categories":"math.AG","published":"2025-04-24T08:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.17377v1","title":"Minimal Surfaces via Complex Quaternions","summary":"Minimal surfaces play a fundamental role in differential geometry, with\napplications spanning physics, material science, and geometric design. In this\npaper, we explore a novel quaternionic representation of minimal surfaces,\ndrawing an analogy with the well-established theory of Pythagorean Hodograph\n(PH) curves. By exploiting the algebraic structure of complex quaternions, we\nintroduce a new approach to generating minimal surfaces via quaternionic\ntransformations. This method extends classical Weierstra\\ss-Enneper\nrepresentations and provides insights into the interplay between quaternionic\nanalysis, PH curves, and minimal surface geometry. Additionally, we discuss the\nrole of the Sylvester equation in this framework and demonstrate practical\nexamples, including the construction of Enneper surface patches. The findings\nopen new avenues in computational geometry and geometric modeling, bridging\nabstract algebraic structures with practical applications in CAD and computer\ngraphics.","main_category":"math.CV","categories":"math.CV,math.RA","published":"2025-04-24T08:51:05Z"}
{"aid":"http://arxiv.org/abs/2504.17387v1","title":"Graph covers and semi-covers: Who is stronger?","summary":"The notion of graph cover, also known as locally bijective homomorphism, is a\ndiscretization of covering spaces known from general topology. It is a pair of\nincidence-preserving vertex- and edge-mappings between two graphs, the\nedge-component being bijective on the edge-neighborhoods of every vertex and\nits image. In line with the current trends in topological graph theory and its\napplications in mathematical physics, graphs are considered in the most relaxed\nform and as such they may contain multiple edges, loops and semi-edges.\n  Nevertheless, simple graphs (binary structures without multiple edges, loops,\nor semi-edges) play an important role. It has been conjectured in [Bok et al.:\nList covering of regular multigraphs, Proceedings IWOCA 2022, LNCS 13270, pp.\n228--242] that for every fixed graph $H$, deciding if a graph covers $H$ is\neither polynomial time solvable for arbitrary input graphs, or NP-complete for\nsimple ones. A graph $A$ is called stronger than a graph $B$ if every simple\ngraph that covers $A$ also covers $B$. This notion was defined and found useful\nfor NP-hardness reductions for disconnected graphs in [Bok et al.:\nComputational complexity of covering disconnected multigraphs, Proceedings FCT\n2022, LNCS 12867, pp. 85--99]. It was conjectured in [Kratochv\\'{\\i}l: Towards\nstrong dichotomy of graphs covers, GROW 2022 - Book of open problems, p. 10,\n{\\tt https://grow.famnit.upr.si/GROW-BOP.pdf}] that if $A$ has no semi-edges,\nthen $A$ is stronger than $B$ if and only if $A$ covers $B$. We prove this\nconjecture for cubic one-vertex graphs, and we also justify it for all cubic\ngraphs $A$ with at most 4 vertices.","main_category":"math.CO","categories":"math.CO,G.2.2","published":"2025-04-24T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.17411v1","title":"The KP equation of plane elastodynamics","summary":"The propagation of nonlinear and dispersive waves in various materials can be\ndescribed by the well-known Kadomtsev-Petviashvili (KP) equation, which is a\n(2+1)-dimensional partial differential equation. In this paper, we show that\nthe KP equation can be used to describe the in-plane motion of compressible\nelastic solids with dispersion. Furthermore, a modified KP equation with cubic\nnonlinearity is obtained in the case of incompressible solids with dispersion.\nThen, several solutions of these partial differential equations are discussed\nand computed using a Fourier spectral method. In particular, both equations\nadmit solitary wave solutions.","main_category":"math-ph","categories":"math-ph,math.MP,nlin.PS","published":"2025-04-24T10:03:50Z"}
{"aid":"http://arxiv.org/abs/2504.17420v1","title":"HydroStartML: A combined machine learning and physics-based approach to\n  reduce hydrological model spin-up time","summary":"Finding the initial depth-to-water table (DTWT) configuration of a catchment\nis a critical challenge when simulating the hydrological cycle with integrated\nmodels, significantly impacting simulation outcomes. Traditionally, this\ninvolves iterative spin-up computations, where the model runs under constant\natmospheric settings until steady-state is achieved. These so-called model\nspin-ups are computationally expensive, often requiring many years of simulated\ntime, particularly when the initial DTWT configuration is far from steady\nstate.\n  To accelerate the model spin-up process we developed HydroStartML, a machine\nlearning emulator trained on steady-state DTWT configurations across the\ncontiguous United States. HydroStartML predicts, based on available data like\nconductivity and surface slopes, a DTWT configuration of the respective\nwatershed, which can be used as an initial DTWT.\n  Our results show that initializing spin-up computations with HydroStartML\npredictions leads to faster convergence than with other initial configurations\nlike spatially constant DTWTs. The emulator accurately predicts configurations\nclose to steady state, even for terrain configurations not seen in training,\nand allows especially significant reductions in computational spin-up effort in\nregions with deep DTWTs. This work opens the door for hybrid approaches that\nblend machine learning and traditional simulation, enhancing predictive\naccuracy and efficiency in hydrology for improving water resource management\nand understanding complex environmental interactions.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.LG","published":"2025-04-24T10:24:34Z"}
{"aid":"http://arxiv.org/abs/2504.17440v1","title":"Generating Localized Audible Zones Using a Single-Channel Parametric\n  Loudspeaker","summary":"Advanced sound zone control (SZC) techniques typically rely on massive\nmulti-channel loudspeaker arrays to create high-contrast personal sound zones,\nmaking single-loudspeaker SZC seem impossible. In this Letter, we challenge\nthis paradigm by introducing the multi-carrier parametric loudspeaker (MCPL),\nwhich enables SZC using only a single loudspeaker. In our approach, distinct\naudio signals are modulated onto separate ultrasonic carrier waves at different\nfrequencies and combined into a single composite signal. This signal is emitted\nby a single-channel ultrasonic transducer, and through nonlinear demodulation\nin air, the audio signals interact to virtually form multi-channel outputs.\nThis novel capability allows the application of existing SZC algorithms\noriginally designed for multi-channel loudspeaker arrays. Simulations validate\nthe effectiveness of our proposed single-channel MCPL, demonstrating its\npotential as a promising alternative to traditional multi-loudspeaker systems\nfor achieving high-contrast SZC. Our work opens new avenues for simplifying SZC\nsystems without compromising performance.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-24T11:02:07Z"}
{"aid":"http://arxiv.org/abs/2504.17452v1","title":"The need for statistical physics in Africa: perspective and an\n  illustration in drug delivery problems","summary":"The development of statistical physics in Africa is in its nascent stages,\nyet its application holds immense promise for advancing emerging research\ntrends on the continent. This perspective paper, a product of a two-week\nworkshop on biophysics in Morogoro (Tanzania), aims to illuminate the potential\nof statistical physics in regional scientific research. We employ in-silico\natomistic molecular dynamics simulations to investigate the loading and\ndelivery capabilities of lecithin nanolipids for niclosamide, a poorly\nwater-soluble drug. Our simulations reveal that the loading capacity and\ninteraction strength between lecithin nanolipids and niclosamide improve with\nincreased lecithin concentrations. We perform a free-energy landscape analysis\nwhich uncovers two distinct metastable conformations of niclosamide within both\nthe aqueous phase and the lecithin nanolipids. Over a simulation period of half\na microsecond, lecithin nanolipids self-assemble into a spherical monolayer\nstructure, providing detailed atomic-level insights into their interactions\nwith niclosamide. These findings underscore the potential of lecithin\nnanolipids as efficient drug delivery systems.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,physics.bio-ph,physics.chem-ph,physics.soc-ph","published":"2025-04-24T11:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.17454v1","title":"Adaptive Orchestration of Modular Generative Information Access Systems","summary":"Advancements in large language models (LLMs) have driven the emergence of\ncomplex new systems to provide access to information, that we will collectively\nrefer to as modular generative information access (GenIA) systems. They\nintegrate a broad and evolving range of specialized components, including LLMs,\nretrieval models, and a heterogeneous set of sources and tools. While\nmodularity offers flexibility, it also raises critical challenges: How can we\nsystematically characterize the space of possible modules and their\ninteractions? How can we automate and optimize interactions among these\nheterogeneous components? And, how do we enable this modular system to\ndynamically adapt to varying user query requirements and evolving module\ncapabilities? In this perspective paper, we argue that the architecture of\nfuture modular generative information access systems will not just assemble\npowerful components, but enable a self-organizing system through real-time\nadaptive orchestration -- where components' interactions are dynamically\nconfigured for each user input, maximizing information relevance while\nminimizing computational overhead. We give provisional answers to the questions\nraised above with a roadmap that depicts the key principles and methods for\ndesigning such an adaptive modular system. We identify pressing challenges, and\npropose avenues for addressing them in the years ahead. This perspective urges\nthe IR community to rethink modular system designs for developing adaptive,\nself-optimizing, and future-ready architectures that evolve alongside their\nrapidly advancing underlying technologies.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T11:35:43Z"}
{"aid":"http://arxiv.org/abs/2504.17530v1","title":"Hollow polytopes with many vertices","summary":"Given a set $S \\subseteq \\mathbb{R}^d$, a hollow polytope has vertices in $S$\nbut contains no other point of $S$ in its interior. We prove upper and lower\nbounds on the maximum number of vertices of hollow polytopes whose facets are\nsimplices or whose vertices are in general position. We also obtain relatively\ntight asymptotic bounds for polytopes which do not contain lattice segments of\nlarge length.","main_category":"math.MG","categories":"math.MG","published":"2025-04-24T13:18:49Z"}
{"aid":"http://arxiv.org/abs/2504.17534v1","title":"Learning Isometric Embeddings of Road Networks using Multidimensional\n  Scaling","summary":"The lack of generalization in learning-based autonomous driving applications\nis shown by the narrow range of road scenarios that vehicles can currently\ncover. A generalizable approach should capture many distinct road structures\nand topologies, as well as consider traffic participants, and dynamic changes\nin the environment, so that vehicles can navigate and perform motion planning\ntasks even in the most difficult situations. Designing suitable feature spaces\nfor neural network-based motion planers that encapsulate all kinds of road\nscenarios is still an open research challenge. This paper tackles this\nlearning-based generalization challenge and shows how graph representations of\nroad networks can be leveraged by using multidimensional scaling (MDS)\ntechniques in order to obtain such feature spaces. State-of-the-art graph\nrepresentations and MDS approaches are analyzed for the autonomous driving use\ncase. Finally, the option of embedding graph nodes is discussed in order to\nperform easier learning procedures and obtain dimensionality reduction.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.ET,cs.SC","published":"2025-04-24T13:20:32Z"}
{"aid":"http://arxiv.org/abs/2504.17536v1","title":"Dynamic Membership for Regular Tree Languages","summary":"We study the dynamic membership problem for regular tree languages under\nrelabeling updates: we fix an alphabet ${\\Sigma}$ and a regular tree language\n$L$ over ${\\Sigma}$ (expressed, e.g., as a tree automaton), we are given a tree\n$T$ with labels in ${\\Sigma}$, and we must maintain the information of whether\nthe tree $T$ belongs to $L$ while handling relabeling updates that change the\nlabels of individual nodes in $T$. (The shape and size of the tree remain the\nsame throughout.)\n  Our first contribution is to show that this problem admits an $O(\\log n /\n\\log \\log n)$ algorithm for any fixed regular tree language, improving over\nknown algorithms that achieve $O(\\log n)$. This generalizes the known $O(\\log n\n/ \\log \\log n)$ upper bound over words, and it matches the lower bound of\n${\\Omega}(\\log n / \\log \\log n)$ from dynamic membership to some word languages\nand from the existential marked ancestor problem.\n  Our second contribution is to introduce a class of regular languages, dubbed\nalmost-commutative tree languages, and show that dynamic membership to such\nlanguages under relabeling updates can be done in constant time per update.\nAlmost-commutative languages generalize both commutative languages and finite\nlanguages, and they are the analogue for trees of the ZG languages enjoying\nconstant-time dynamic membership over words. Our main technical contribution is\nto show that this class is conditionally optimal when we assume that the\nalphabet features a neutral letter, i.e., a letter that has no effect on\nmembership to the language. More precisely, we show that any regular tree\nlanguage with a neutral letter which is not almost-commutative cannot be\nmaintained in constant time under the assumption that prefix-U1 problem from\n(Amarilli, Jachiet, Paperman, ICALP'21) also does not admit a constant-time\nalgorithm.","main_category":"cs.FL","categories":"cs.FL,cs.DS","published":"2025-04-24T13:26:08Z"}
{"aid":"http://arxiv.org/abs/2504.17539v1","title":"Proof of Useful Intelligence (PoUI): Blockchain Consensus Beyond Energy\n  Waste","summary":"Blockchain technology enables secure, transparent data management in\ndecentralized systems, supporting applications from cryptocurrencies like\nBitcoin to tokenizing real-world assets like property. Its scalability and\nsustainability hinge on consensus mechanisms balancing security and efficiency.\nProof of Work (PoW), used by Bitcoin, ensures security through energy-intensive\ncomputations but demands significant resources. Proof of Stake (PoS), as in\nEthereum post-Merge, selects validators based on staked cryptocurrency,\noffering energy efficiency but risking centralization from wealth\nconcentration. With AI models straining computational resources, we propose\nProof of Useful Intelligence (PoUI), a hybrid consensus mechanism. In PoUI,\nworkers perform AI tasks like language processing or image analysis to earn\ncoins, which are staked to secure the network, blending security with practical\nutility. Decentralized nodes--job posters, market coordinators, workers, and\nvalidators --collaborate via smart contracts to manage tasks and rewards.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-24T13:32:03Z"}
{"aid":"http://arxiv.org/abs/2504.17553v1","title":"Principal Minors of Hermitian Laplacian Matrix of Directed Graphs and\n  Their Connection to Directed Graph Substructures","summary":"This paper explores the algebraic characterization of directed graph\nsubstructures through principal minors of the Hermitian Laplacian matrix. By\ngeneralizing Bapat et al.'s nonsingular substructure theory and by defining\nsubstructures as vertex-edge pairs $(V',E')$ which allows edges to connect\nvertices outside $V'$, we establish a link between the principle minors and the\ntopological properties of key substructures such as rootless trees and\nunicyclic graphs. Using the Cauchy-Binet formula, we decompose principal minors\ninto sums of determinants of regular substructures. Specifically, we\ninvestigate how these algebraic invariants encode information about unicyclic\nsubstructures and their properties, contributing to the broader understanding\nof graph structures through the lens of Hermitian Laplacian matrix of algebraic\ngraph theory.","main_category":"math.CO","categories":"math.CO","published":"2025-04-24T13:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.17562v1","title":"When Does Metadata Conditioning (NOT) Work for Language Model\n  Pre-Training? A Study with Context-Free Grammars","summary":"The ability to acquire latent semantics is one of the key properties that\ndetermines the performance of language models. One convenient approach to\ninvoke this ability is to prepend metadata (e.g. URLs, domains, and styles) at\nthe beginning of texts in the pre-training data, making it easier for the model\nto access latent semantics before observing the entire text. Previous studies\nhave reported that this technique actually improves the performance of trained\nmodels in downstream tasks; however, this improvement has been observed only in\nspecific downstream tasks, without consistent enhancement in average next-token\nprediction loss. To understand this phenomenon, we closely investigate how\nprepending metadata during pre-training affects model performance by examining\nits behavior using artificial data. Interestingly, we found that this approach\nproduces both positive and negative effects on the downstream tasks. We\ndemonstrate that the effectiveness of the approach depends on whether latent\nsemantics can be inferred from the downstream task's prompt. Specifically,\nthrough investigations using data generated by probabilistic context-free\ngrammars, we show that training with metadata helps improve model's performance\nwhen the given context is long enough to infer the latent semantics. In\ncontrast, the technique negatively impacts performance when the context lacks\nthe necessary information to make an accurate posterior inference.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-24T13:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.17634v1","title":"Sparsity-Exploiting Channel Estimation For Unsourced Random Access With\n  Fluid Antenna","summary":"This work explores the channel estimation (CE) problem in uplink transmission\nfor unsourced random access (URA) with a fluid antenna receiver. The additional\nspatial diversity in a fluid antenna system (FAS) addresses the needs of URA\ndesign in multiple-input and multiple-output (MIMO) systems. We present two CE\nstrategies based on the activation of different FAS ports, namely alternate\nports and partial ports CE. Both strategies facilitate the estimation of\nchannel coefficients and angles of arrival (AoAs). Additionally, we discuss how\nto refine channel estimation by leveraging the sparsity of finite scatterers.\nSpecifically, the proposed partial ports CE strategy is implemented using a\nregularized estimator, and we optimize the estimator's parameter to achieve the\ndesired AoA precision and refinement. Extensive numerical results demonstrate\nthe feasibility of the proposed strategies, and a comparison with a\nconventional receiver using half-wavelength antennas highlights the promising\nfuture of integrating URA and FAS.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T15:07:12Z"}
{"aid":"http://arxiv.org/abs/2504.17648v1","title":"A Robust Fault Detection Filter for Linear Time-Varying System with\n  Non-Gaussian Noise","summary":"This paper addresses the problem of robust fault detection filtering for\nlinear time-varying (LTV) systems with non-Gaussian noise and additive faults.\nThe conventional generalized likelihood ratio (GLR) method utilizes the Kalman\nfilter, which may exhibit inadequate performance under non-Gaussian noise\nconditions. To mitigate this issue, a fault detection method employing the\n$H_{\\infty}$ filter is proposed. The $H_{\\infty}$ filter is first derived as\nthe solution to a regularized least-squares (RLS) optimization problem, and the\neffect of faults on the output prediction error is then analyzed. The proposed\napproach using the $H_{\\infty}$ filter demonstrates robustness in non-Gaussian\nnoise environments and significantly improves fault detection performance\ncompared to the original GLR method that employs the Kalman filter. The\neffectiveness of the proposed approach is illustrated using numerical examples.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T15:18:31Z"}
{"aid":"http://arxiv.org/abs/2504.17656v1","title":"polyGen: A Learning Framework for Atomic-level Polymer Structure\n  Generation","summary":"Synthetic polymeric materials underpin fundamental technologies in the\nenergy, electronics, consumer goods, and medical sectors, yet their development\nstill suffers from prolonged design timelines. Although polymer informatics\ntools have supported speedup, polymer simulation protocols continue to face\nsignificant challenges: on-demand generation of realistic 3D atomic structures\nthat respect the conformational diversity of polymer structures. Generative\nalgorithms for 3D structures of inorganic crystals, bio-polymers, and small\nmolecules exist, but have not addressed synthetic polymers. In this work, we\nintroduce polyGen, the first latent diffusion model designed specifically to\ngenerate realistic polymer structures from minimal inputs such as the repeat\nunit chemistry alone, leveraging a molecular encoding that captures polymer\nconnectivity throughout the architecture. Due to a scarce dataset of only 3855\nDFT-optimized polymer structures, we augment our training with DFT-optimized\nmolecular structures, showing improvement in joint learning between similar\nchemical structures. We also establish structure matching criteria to benchmark\nour approach on this novel problem. polyGen effectively generates diverse\nconformations of both linear chains and complex branched structures, though its\nperformance decreases when handling repeat units with a high atom count. Given\nthese initial results, polyGen represents a paradigm shift in atomic-level\nstructure generation for polymer science-the first proof-of-concept for\npredicting realistic atomic-level polymer conformations while accounting for\ntheir intrinsic structural flexibility.","main_category":"cs.CE","categories":"cs.CE,cond-mat.mtrl-sci,cs.LG","published":"2025-04-24T15:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.17694v1","title":"Using mathematical models of heart cells to assess the safety of new\n  pharmaceutical drugs","summary":"Many drugs have been withdrawn from the market worldwide, at a cost of\nbillions of dollars, because of patient fatalities due to them unexpectedly\ndisturbing heart rhythm. Even drugs for ailments as mild as hay fever have been\nwithdrawn due to an unacceptable increase in risk of these heart rhythm\ndisturbances. Consequently, the whole pharmaceutical industry expends a huge\neffort in checking all new drugs for any unwanted side effects on the heart.\nThe predominant root cause has been identified as drug molecules blocking ionic\ncurrent flows in the heart. Block of individual types of ionic currents can now\nbe measured experimentally at an early stage of drug development, and this is\nthe standard screening approach for a number of ion currents in many large\npharmaceutical companies. However, clinical risk is a complex function of the\ndegree of block of many different types of cardiac ion currents, and this is\ndifficult to understand by looking at results of these screens independently.\nBy using ordinary differential equation models for the electrical activity of\nheart cells (electrophysiology models) we can integrate information from\ndifferent types of currents, to predict the effect on whole heart cells and\nsubsequent risk of side effects. The resulting simulations can provide a more\naccurate summary of the risk of a drug earlier in development and hence more\ncheaply than the pre-existing approaches.","main_category":"q-bio.CB","categories":"q-bio.CB,q-bio.SC","published":"2025-04-24T16:03:06Z"}
{"aid":"http://arxiv.org/abs/2504.17699v1","title":"Quadratic Interest Network for Multimodal Click-Through Rate Prediction","summary":"Multimodal click-through rate (CTR) prediction is a key technique in\nindustrial recommender systems. It leverages heterogeneous modalities such as\ntext, images, and behavioral logs to capture high-order feature interactions\nbetween users and items, thereby enhancing the system's understanding of user\ninterests and its ability to predict click behavior. The primary challenge in\nthis field lies in effectively utilizing the rich semantic information from\nmultiple modalities while satisfying the low-latency requirements of online\ninference in real-world applications. To foster progress in this area, the\nMultimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshop\nformulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding:\nthis task aims to explore multimodal information extraction and item\nrepresentation learning methods that enhance recommendation tasks; and (2) Task\n2 of Multimodal CTR Prediction: this task aims to explore what multimodal\nrecommendation model can effectively leverage multimodal embedding features and\nachieve better performance. In this paper, we propose a novel model for Task 2,\nnamed Quadratic Interest Network (QIN) for Multimodal CTR Prediction.\nSpecifically, QIN employs adaptive sparse target attention to extract\nmultimodal user behavior features, and leverages Quadratic Neural Networks to\ncapture high-order feature interactions. As a result, QIN achieved an AUC of\n0.9798 on the leaderboard and ranked second in the competition. The model code,\ntraining logs, hyperparameter configurations, and checkpoints are available at\nhttps://github.com/salmon1802/QIN.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T16:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.17705v1","title":"LUIDA: Large-scale Unified Infrastructure for Digital Assessments based\n  on Commercial Metaverse Platform","summary":"Online experiments using metaverse platforms have gained significant traction\nin Human-Computer Interaction and Virtual Reality (VR) research. However,\ncurrent research workflows are highly fragmented, as researchers must use\nseparate tools for system implementation, participant recruitment, experiment\nexecution, and data collection, reducing consistency and increasing workload.\nWe present LUIDA (Large-scale Unified Infrastructure for Digital Assessments),\na metaverse-based framework that integrates these fragmented processes. LUIDA\nautomatically allocates interconnected virtual environments for parallel\nexperiment execution and provides implementation templates adaptable to various\nVR research domains, requiring minimal metaverse development expertise. Our\nevaluation included two studies using a prototype built on Cluster, the\ncommercial metaverse platform. First, VR researchers using LUIDA to develop and\nrun experiments reported high usability scores (SUS: 73.75) and moderate\nworkload (NASA-TLX: 24.11) for overall usage, with interviews confirming\nstreamlined workflows compared to traditional laboratory experiments. Second,\nwe conducted three replicated experiments with public Cluster users, each\nrecruiting approximately 200 participants within one week. These experiments\nproduced results that closely matched the original studies, validating the\nexperimental integrity of LUIDA across research domains. After technical\nrefinements, we plan to release LUIDA as an open platform, providing a\nstandardized protocol to improve research efficiency and experimental\nreproducibility in VR studies.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-24T16:11:12Z"}
{"aid":"http://arxiv.org/abs/2504.17706v1","title":"Inverse problem in the LaMET framework","summary":"One proposal to compute parton distributions from first principles is the\nlarge momentum effective theory (LaMET), which requires the Fourier transform\nof matrix elements computed non-perturbatively. Lattice quantum chromodynamics\n(QCD) provides calculations of these matrix elements over a finite range of\nFourier harmonics that are often noisy or unreliable in the largest computed\nharmonics. It has been suggested that enforcing an exponential decay of the\nmissing harmonics helps alleviate this issue. Using non-perturbative data, we\nshow that the uncertainty introduced by this inverse problem in a realistic\nsetup remains significant without very restrictive assumptions, and that the\nimportance of the exact asymptotic behavior is minimal for values of $x$ where\nthe framework is currently applicable. We show that the crux of the inverse\nproblem lies in harmonics of the order of $\\lambda=zP_z \\sim 5-15$, where the\nsignal in the lattice data is often barely existent in current studies, and the\nasymptotic behavior is not firmly established. We stress the need for more\nsophisticated techniques to account for this inverse problem, whether in the\nLaMET or related frameworks like the short-distance factorization. We also\naddress a misconception that, with available lattice methods, the LaMET\nframework allows a \"direct\" computation of the $x$-dependence, whereas the\nalternative short-distance factorization only gives access to moments or fits\nof the $x$-dependence.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-24T16:11:48Z"}
{"aid":"http://arxiv.org/abs/2504.17713v1","title":"Target-Date Funds: A State-of-the-Art Review with Policy Applications to\n  Chile's Pension Reform","summary":"This review paper explores the evolution and implementation of target-date\nfunds (TDFs), specifically focusing on their application within the context of\nChile's 2025 pension reform. The introduction of TDFs marks a significant shift\nin Chile's pension system, which has traditionally relied on a multifund\nstructure (essentially a target-risk funds system). We offer a comprehensive\nreview of the theoretical foundations and practical considerations of TDFs,\nhighlighting key challenges and opportunities for Chilean regulators and fund\nmanagers. Notably, we recommend that the glide path design should be dynamic,\nincorporating adjustments based on total accumulated wealth, with particular\nflexibility depending on each investor's risk tolerance. Furthermore, we\npropose that the new benchmark for generational funds should feature a wide\ndeviation band relative to the new benchmark portfolio, which could foster a\nmarket with more investment strategies and better competition among fund\nmanagers, encourage the inclusion of alternative assets, and foster greater\ndiversification. Lastly, we highlight the need for future work to define a\nglide path model that incorporates the theoretical frameworks described,\ntailored to the unique parameters of the Chilean pension system. These\nrecommendations aim to optimize the long-term retirement outcomes for Chilean\nworkers under the new pension structure.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-24T16:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.17732v1","title":"DPMambaIR:All-in-One Image Restoration via Degradation-Aware Prompt\n  State Space Model","summary":"All-in-One image restoration aims to address multiple image degradation\nproblems using a single model, significantly reducing training costs and\ndeployment complexity compared to traditional methods that design dedicated\nmodels for each degradation type. Existing approaches typically rely on\nDegradation-specific models or coarse-grained degradation prompts to guide\nimage restoration. However, they lack fine-grained modeling of degradation\ninformation and face limitations in balancing multi-task conflicts. To overcome\nthese limitations, we propose DPMambaIR, a novel All-in-One image restoration\nframework. By integrating a Degradation-Aware Prompt State Space Model (DP-SSM)\nand a High-Frequency Enhancement Block (HEB), DPMambaIR enables fine-grained\nmodeling of complex degradation information and efficient global integration,\nwhile mitigating the loss of high-frequency details caused by task competition.\nSpecifically, the DP-SSM utilizes a pre-trained degradation extractor to\ncapture fine-grained degradation features and dynamically incorporates them\ninto the state space modeling process, enhancing the model's adaptability to\ndiverse degradation types. Concurrently, the HEB supplements high-frequency\ninformation, effectively addressing the loss of critical details, such as edges\nand textures, in multi-task image restoration scenarios. Extensive experiments\non a mixed dataset containing seven degradation types show that DPMambaIR\nachieves the best performance, with 27.69dB and 0.893 in PSNR and SSIM,\nrespectively. These results highlight the potential and superiority of\nDPMambaIR as a unified solution for All-in-One image restoration.","main_category":"cs.CV","categories":"cs.CV,I.4.4","published":"2025-04-24T16:46:32Z"}
{"aid":"http://arxiv.org/abs/2504.17741v1","title":"Multi-messenger standard-siren cosmology for third-generation\n  gravitational-wave detectors: Considering observations of gamma-ray bursts\n  and kilonovae","summary":"In the third-generation (3G) gravitational-wave (GW) detector era, GW\nmulti-messenger observations for binary neutron star merger events can exert\ngreat impacts on exploring the cosmic expansion history. Extending the previous\nwork, we explore the potential of 3G GW standard siren observations in\ncosmological parameter estimation by considering their associated\nelectromagnetic (EM) counterparts, including $\\gamma$-ray burst (GRB)\ncoincidence observations by the Gravitational wave high-energy Electromagnetic\nCounterpart All-sky Monitor and GW-triggered target-of-opportunity observations\nof kilonovae by different optical survey projects. During an assumed 10-year\nobservation, we predict that the number of detectable GW-kilonova events is\n$\\sim 4900$ with redshifts below $\\sim 0.4$ under GW network and Large Synoptic\nSurvey Telescope in the $i$ band, which is three times more than that of GW-GRB\ndetections. For the cosmological analysis, we find that with the inclusion of\nGW-kilonova detections, the constraints on cosmological parameters from GW-EM\ndetections are significantly improved compared to those from GW-GRB detections.\nIn particular, GW-EM detections can tightly constrain the Hubble constant with\na precision ranging from $0.076\\%$ to $0.034\\%$. Moreover, GW multi-messenger\nobservations could effectively break the cosmological parameter degeneracies\ngenerated by the mainstream EM observations, CMB+BAO+SN (CBS). The combination\nof CBS and GW-EM can tightly constrain the equation of state parameters of dark\nenergy $w$ in the $w$CDM model and $w_0$ in the $w_0w_a$CDM model with\nprecisions of $0.72\\%$ and $0.99\\%$, respectively, meeting the standard of\nprecision cosmology. In conclusion, GW multi-messenger observations could play\na crucial role in helping solve the Hubble tension and probing the fundamental\nnature of dark energy.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-24T16:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.17743v1","title":"Realization of Temporally Connected Graphs Based on Degree Sequences","summary":"Given an undirected graph $G$, the problem of deciding whether $G$ admits a\nsimple and proper time-labeling that makes it temporally connected is known to\nbe NP-hard (G\\\"obel et al., 1991). In this article, we relax this problem and\nask whether a given degree sequence can be realized as a temporally connected\ngraph. Our main results are a complete characterization of the feasible cases,\nand a recognition algorithm that runs in $O(n)$ time for graphical degree\nsequences (realized as simple temporal graphs) and in $O(n+m)$ time for\nmultigraphical degree sequences (realized as non-simple temporal graphs, where\nthe number of time labels on an edge corresponds to the multiplicity of the\nedge in the multigraph). In fact, these algorithms can be made constructive at\nessentially no cost. Namely, we give a constructive $O(n+m)$ time algorithm\nthat outputs, for a given (multi)graphical degree sequence $\\mathbf{d}$, a\ntemporally connected graph whose underlying (multi)graph is a realization of\n$\\mathbf{d}$, if one exists.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T17:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.17744v1","title":"Nearby open clusters with tidal features: golden sample selection and 3D\n  structure","summary":"Open clusters offer unique opportunities to study stellar dynamics and\nevolution under the influence of their internal gravity, the Milky Way's\ngravitational field, and the interactions with encounters. Using the Gaia DR3\ndata for a catalog of open clusters within 500 parsecs that exhibit tidal\nfeatures reported by the literature, we apply a novel method based on 3D\nprincipal component analysis to select a ``golden sample'' of nearby open\nclusters with minimal line-of-sight distortions. This approach ensures a\nsystematic comparison of 3D and 2D structural parameters for tidally perturbed\nclusters. The selected golden sample includes Blanco 1, Melotte 20, Melotte 22,\nNGC 2632, NGC 7092, NGC 1662, Roslund 6 and Melotte 111. We analyze these\nclusters by fitting both 2D and 3D King Profiles to their stellar density\ndistributions. Our results reveal systematic discrepancies: most of the golden\nsample clusters exhibit larger 3D tidal radii compared to their 2D\ncounterparts, demonstrating that the 2D projection effects bias the measured\ncluster size. Furthermore, the 3D density profiles show stronger deviations\nfrom King profiles at the tidal radii ($\\Delta \\rho_{\\rm 3D} > \\Delta \\rho_{\\rm\n2D}$), highlighting enhanced sensitivity to tidal disturbances. Additionally,\nwe investigate the spatial distribution of cluster members relative to their\nbulk motion in the Galactic plane. We find that some clusters exhibit tidal\nfeatures oriented perpendicular to their direction of motion, which can be\nattributed to the fact that the current surveys only detect the curved inner\nregions of the tidal features. In conclusion, this work offers a golden sample\nof nearby open clusters that are most reliable for 3D structure analysis and\nunderscores the necessity of 3D analysis in characterizing OC morphological\nasymmetries, determining cluster size, and identifying tidal features.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-24T17:02:37Z"}
{"aid":"http://arxiv.org/abs/2504.19470v1","title":"A Cautionary Note on Quantum Oracles","summary":"In recent years, the quantum oracle model introduced by Aaronson and\nKuperberg (2007) has found a lot of use in showing oracle separations between\ncomplexity classes and cryptographic primitives. It is generally assumed that\nproof techniques that do not relativize with respect to quantum oracles will\nalso not relativize with respect to classical oracles. In this note, we show\nthat this is not the case: specifically, we show that there is a quantum oracle\nproblem that is contained in the class QMA, but not in a class we call\npolyQCPH. The class polyQCPH is equal to PSPACE with respect to classical\noracles, and it is a well-known result that QMA is contained in PSPACE (also\nwith respect to classical oracles).\n  We also show that the same separation holds relative to a distributional\noracle, which is a model introduced by Natarajan and Nirkhe (2024). We believe\nour findings show the need for some caution when using these non-standard\noracle models, particularly when showing separations between quantum and\nclassical resources.","main_category":"quant-ph","categories":"quant-ph,cs.CC","published":"2025-04-28T04:20:39Z"}
{"aid":"http://arxiv.org/abs/2504.19475v1","title":"Prisma: An Open Source Toolkit for Mechanistic Interpretability in\n  Vision and Video","summary":"Robust tooling and publicly available pre-trained models have helped drive\nrecent advances in mechanistic interpretability for language models. However,\nsimilar progress in vision mechanistic interpretability has been hindered by\nthe lack of accessible frameworks and pre-trained weights. We present Prisma\n(Access the codebase here: https://github.com/Prisma-Multimodal/ViT-Prisma), an\nopen-source framework designed to accelerate vision mechanistic\ninterpretability research, providing a unified toolkit for accessing 75+ vision\nand video transformers; support for sparse autoencoder (SAE), transcoder, and\ncrosscoder training; a suite of 80+ pre-trained SAE weights; activation\ncaching, circuit analysis tools, and visualization tools; and educational\nresources. Our analysis reveals surprising findings, including that effective\nvision SAEs can exhibit substantially lower sparsity patterns than language\nSAEs, and that in some instances, SAE reconstructions can decrease model loss.\nPrisma enables new research directions for understanding vision model internals\nwhile lowering barriers to entry in this emerging field.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-28T04:31:24Z"}
{"aid":"http://arxiv.org/abs/2504.19487v1","title":"Evolution of Cooperation in LLM-Agent Societies: A Preliminary Study\n  Using Different Punishment Strategies","summary":"The evolution of cooperation has been extensively studied using abstract\nmathematical models and simulations. Recent advances in Large Language Models\n(LLM) and the rise of LLM agents have demonstrated their ability to perform\nsocial reasoning, thus providing an opportunity to test the emergence of norms\nin more realistic agent-based simulations with human-like reasoning using\nnatural language. In this research, we investigate whether the cooperation\ndynamics presented in Boyd and Richerson's model persist in a more realistic\nsimulation of the diner's dilemma using LLM agents compared to the abstract\nmathematical nature in the work of Boyd and Richerson. Our findings indicate\nthat agents follow the strategies defined in the Boyd and Richerson model, and\nexplicit punishment mechanisms drive norm emergence, reinforcing cooperative\nbehaviour even when the agent strategy configuration varies. Our results\nsuggest that LLM-based Multi-Agent System simulations, in fact, can replicate\nthe evolution of cooperation predicted by the traditional mathematical models.\nMoreover, our simulations extend beyond the mathematical models by integrating\nnatural language-driven reasoning and a pairwise imitation method for strategy\nadoption, making them a more realistic testbed for cooperative behaviour in\nMASs.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-28T05:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.19507v1","title":"\\textit{From Freshness to Effectiveness}: Goal-Oriented Sampling for\n  Remote Decision Making","summary":"Data freshness, measured by Age of Information (AoI), is highly relevant in\nnetworked applications such as Vehicle to Everything (V2X), smart health\nsystems, and Industrial Internet of Things (IIoT). Yet, freshness alone does\nnot equate to informativeness. In decision-critical settings, some stale data\nmay prove more valuable than fresh updates. To explore this nuance, we move\nbeyond AoI-centric policies and investigate how data staleness impacts\ndecision-making under data-staleness-induced uncertainty. We pose a central\nquestion: What is the value of information, when freshness fades, and only its\npower to shape remote decisions remains? To capture this endured value, we\npropose AR-MDP, an Age-aware Remote Markov Decision Process framework, which\nco-designs optimal sampling and remote decision-making under a sampling\nfrequency constraint and random delay. To efficiently solve this problem, we\ndesign a new two-stage hierarchical algorithm namely Quick\nBellman-Linear-Program (QuickBLP), where the first stage involves solving the\nDinkelbach root of a Bellman variant and the second stage involves solving a\nstreamlined linear program (LP). For the tricky first stage, we propose a new\nOne-layer Primal-Dinkelbach Synchronous Iteration (OnePDSI) method, which\novercomes the re-convergence and non-expansive divergence present in existing\nper-sample multi-layer algorithms. Through rigorous convergence analysis of our\nproposed algorithms, we establish that the worst-case optimality gap in OnePDSI\nexhibits exponential decay with respect to iteration $K$ at a rate of\n$\\mathcal{O}(\\frac{1}{R^K})$. Through sensitivity analysis, we derive a\nthreshold for the sampling frequency, beyond which additional sampling does not\nyield further gains in decision-making. Simulation results validate our\nanalyses.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T06:17:09Z"}
{"aid":"http://arxiv.org/abs/2504.19512v1","title":"Gapped Boundaries of Kitaev's Quantum Double Models: A Lattice\n  Realization of Anyon Condensation from Lagrangian Algebras","summary":"The macroscopic theory of anyon condensation, rooted in the categorical\nstructure of topological excitations, provides a complete classification of\ngapped boundaries in topologically ordered systems, where distinct boundaries\ncorrespond to the condensation of different Lagrangian algebras. However, an\nintrinsic and direct understanding of anyon condensation in lattice models,\ngrounded in the framework of Lagrangian algebras, remains undeveloped. In this\npaper, we propose a systematic framework for constructing all gapped boundaries\nof Kitaev's quantum double models directly from the data of Lagrangian\nalgebras. Central to our approach is the observation that bulk interactions in\nthe quantum double models admit two complementary interpretations: the\nanyon-creating picture and anyon-probing picture. Generalizing this insight to\nthe boundary, we derive the consistency condition for boundary ribbon operators\nthat respect the mathematical axiomatic structure of Lagrangian algebras.\nSolving these conditions yields explicit expressions for the local boundary\ninteractions required to realize gapped boundaries. Our construction provides a\nmicroscopic characterization of the bulk-to-boundary anyon condensation\ndynamics via the action of ribbon operators. Moreover, all these boundary terms\nare supported within a common effective Hilbert space, making further studies\non pure boundary phase transitions natural and convenient. Given the broad\napplicability of anyon condensation theory, we believe that our approach can be\ngeneralized to extended string-net models or higher-dimensional topologically\nordered systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,math-ph,math.MP,quant-ph","published":"2025-04-28T06:22:06Z"}
{"aid":"http://arxiv.org/abs/2504.19514v1","title":"FSBench: A Figure Skating Benchmark for Advancing Artistic Sports\n  Understanding","summary":"Figure skating, known as the \"Art on Ice,\" is among the most artistic sports,\nchallenging to understand due to its blend of technical elements (like jumps\nand spins) and overall artistic expression. Existing figure skating datasets\nmainly focus on single tasks, such as action recognition or scoring, lacking\ncomprehensive annotations for both technical and artistic evaluation. Current\nsports research is largely centered on ball games, with limited relevance to\nartistic sports like figure skating. To address this, we introduce FSAnno, a\nlarge-scale dataset advancing artistic sports understanding through figure\nskating. FSAnno includes an open-access training and test dataset, alongside a\nbenchmark dataset, FSBench, for fair model evaluation. FSBench consists of\nFSBench-Text, with multiple-choice questions and explanations, and\nFSBench-Motion, containing multimodal data and Question and Answer (QA) pairs,\nsupporting tasks from technical analysis to performance commentary. Initial\ntests on FSBench reveal significant limitations in existing models'\nunderstanding of artistic sports. We hope FSBench will become a key tool for\nevaluating and enhancing model comprehension of figure skating.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T06:25:04Z"}
{"aid":"http://arxiv.org/abs/2504.19522v1","title":"A Model-based DNN for Learning HMIMO Beamforming","summary":"Holographic MIMO (HMIMO) is a promising technique for large-scale MIMO\nsystems to enhance spectral efficiency while maintaining low hardware cost and\npower consumption. Existing alternating optimization algorithms can effectively\noptimize the hybrid beamforming of HMIMO to improve the system performance,\nwhile their high computational complexity hinders real-time application. In\nthis paper, we propose a model-based deep neural network (MB-DNN), which\nleverages permutation equivalent properties and the optimal beamforming\nstructure to jointly optimize the holographic and digital beamforming.\nSimulation results demonstrate that the proposed MB-DNN outperforms benchmark\nschemes and requires much less inference time than existing alternating\noptimization algorithms.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T06:40:41Z"}
{"aid":"http://arxiv.org/abs/2504.19527v1","title":"Identification and Estimation of Long-Term Treatment Effects with\n  Monotone Missing","summary":"Estimating long-term treatment effects has a wide range of applications in\nvarious domains. A key feature in this context is that collecting long-term\noutcomes typically involves a multi-stage process and is subject to monotone\nmissing, where individuals missing at an earlier stage remain missing at\nsubsequent stages. Despite its prevalence, monotone missing has been rarely\nexplored in previous studies on estimating long-term treatment effects. In this\npaper, we address this gap by introducing the sequential missingness assumption\nfor identification. We propose three novel estimation methods, including\ninverse probability weighting, sequential regression imputation, and sequential\nmarginal structural model (SeqMSM). Considering that the SeqMSM method may\nsuffer from high variance due to severe data sparsity caused by monotone\nmissing, we further propose a novel balancing-enhanced approach, BalanceNet, to\nimprove the stability and accuracy of the estimation methods. Extensive\nexperiments on two widely used benchmark datasets demonstrate the effectiveness\nof our proposed methods.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-28T07:07:50Z"}
{"aid":"http://arxiv.org/abs/2504.19537v1","title":"Universally Wheeler Languages","summary":"The notion of Wheeler languages is rooted in the Burrows-Wheeler transform\n(BWT), one of the most central concepts in data compression and indexing. The\nBWT has been generalized to finite automata, the so-called Wheeler automata, by\nGagie et al. [Theor. Comput. Sci. 2017]. Wheeler languages have subsequently\nbeen defined as the class of regular languages for which there exists a Wheeler\nautomaton accepting them. Besides their advantages in data indexing, these\nWheelerlanguages also satisfy many interesting properties from a language\ntheoretic point of view [Alanko et al., Inf. Comput. 2021]. A characteristic\nyet unsatisfying feature of Wheeler languages however is that their definition\ndepends on a fixed order of the alphabet. In this paper we introduce the\nUniversally Wheeler languages UW, i.e., the regular languages that are Wheeler\nwith respect to all orders of a given alphabet. Our first main contribution is\nto relate UW to some very well known regular language classes. We first show\nthat the Striclty Locally Testable languages are strictly included in UW. After\nnoticing that UW is not closed under taking the complement, we prove that the\nclass of languages for which both the language and its complement are in UW\nexactly coincides with those languages that are Definite or Reverse Definite.\nSecondly, we prove that deciding if a regular language given by a DFA is in UW\ncan be done in quadratic time. We also show that this is optimal unless the\nStrong Exponential Time Hypothesis (SETH) fails.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-28T07:40:16Z"}
{"aid":"http://arxiv.org/abs/2504.19550v1","title":"Deployment Optimization for XL-IRS Assisted Multi-User Communications","summary":"In this paper, we study the deployment optimization for an extremely\nlarge-scale intelligent reflecting surface (XL-IRS) assisted multi-user\ncommunication system, within which the channels between the XL-IRS and the BS\n(or user) are modeled by the near-field spherical wavefronts. To draw some\nvaluable insights, we first consider the single-user case, where an alternating\noptimization (AO) based algorithm is devised to maximize the received\nsignal-to-noise ratio (SNR) at the user. To address the high computational\ncomplexity issue incurred by the AO based algorithm, three approximate received\nSNR expressions are obtained to yield useful insights, corresponding to the\nupper bound, approximate expression, and closed-form. It is demonstrated that\nthe XL-IRS ought to be positioned near the user (rather than the BS) to obtain\na higher beamforming gain. Then, for the multi-user scenario, an efficient\nalgorithm is proposed to obtain a high-quality XL-IRS placement solution by\nusing the AO and successive convex approximation (SCA) techniques. Furthermore,\nthe effective degree of freedom (DoF) of the BS-IRS channel is provided, which\nindicates that the additional effective DoF can be leveraged to improve\nmulti-user spatial multiplexing. Last, numerical results confirm the existence\nof a trade-off between near-field beam-focusing gain and multiplexing gain.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T07:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.19559v1","title":"Using the Translation Theorem for the Automated Stationkeeping of\n  Extremely-Low Lunar Missions","summary":"Extremely-Low Lunar Orbits (eLLOs) (altitudes $\\leq 50$ km) exhibit severe\nperturbations due to the highly non-spherical lunar gravitational field,\npresenting unique challenges to orbit maintenance. These altitudes are too low\nfor the existence of stable `frozen' orbits, and naive stationkeeping methods,\nsuch as circularization, perform poorly. However, mission designers have\nnoticed a particular characteristic of low lunar orbits, which they have found\nuseful for stationkeeping and dubbed the \"translation theorem\", wherein the\neccentricity vector follows a predictable monthly pattern that is independent\nof its starting value. We demonstrate this feature results from the low orbital\neccentricity combined with the dominant effect of a particular subset of\nsectoral and tesseral harmonics. Subsequently, automated stationkeeping\nstrategies for eLLOs are presented, utilizing this theorem for eccentricity\nvector control. Several constraints within the eccentricity vector plane are\nexplored, including circular, annular, and elevation-model derived regions,\neach forming distinct stationkeeping strategies for varying orbital\nconfigurations. Subsequently, the optimal control profiles for these maneuvers\nwithin the eccentricity plane are obtained using Sequential Convex Programming\n(SCP). The proposed strategies offer computational simplicity and clear\nadvantages when compared to traditional methods and are comparable to full\ntrajectory optimization.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.EP","published":"2025-04-28T08:08:06Z"}
{"aid":"http://arxiv.org/abs/2504.19584v1","title":"ShowMak3r: Compositional TV Show Reconstruction","summary":"Reconstructing dynamic radiance fields from video clips is challenging,\nespecially when entertainment videos like TV shows are given. Many challenges\nmake the reconstruction difficult due to (1) actors occluding with each other\nand having diverse facial expressions, (2) cluttered stages, and (3) small\nbaseline views or sudden shot changes. To address these issues, we present\nShowMak3r, a comprehensive reconstruction pipeline that allows the editing of\nscenes like how video clips are made in a production control room. In\nShowMak3r, a 3DLocator module locates recovered actors on the stage using depth\nprior and estimates unseen human poses via interpolation. The proposed\nShotMatcher module then tracks the actors under shot changes. Furthermore,\nShowMak3r introduces a face-fitting network that dynamically recovers the\nactors' expressions. Experiments on Sitcoms3D dataset show that our pipeline\ncan reassemble TV show scenes with new cameras at different timestamps. We also\ndemonstrate that ShowMak3r enables interesting applications such as synthetic\nshot-making, actor relocation, insertion, deletion, and pose manipulation.\nProject page : https://nstar1125.github.io/showmak3r","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T08:44:42Z"}
{"aid":"http://arxiv.org/abs/2504.19607v1","title":"Adaptive Locomotion on Mud through Proprioceptive Sensing of Substrate\n  Properties","summary":"Muddy terrains present significant challenges for terrestrial robots, as\nsubtle changes in composition and water content can lead to large variations in\nsubstrate strength and force responses, causing the robot to slip or get stuck.\nThis paper presents a method to estimate mud properties using proprioceptive\nsensing, enabling a flipper-driven robot to adapt its locomotion through muddy\nsubstrates of varying strength. First, we characterize mud reaction forces\nthrough actuator current and position signals from a statically mounted robotic\nflipper. We use the measured force to determine key coefficients that\ncharacterize intrinsic mud properties. The proprioceptively estimated\ncoefficients match closely with measurements from a lab-grade load cell,\nvalidating the effectiveness of the proposed method. Next, we extend the method\nto a locomoting robot to estimate mud properties online as it crawls across\ndifferent mud mixtures. Experimental data reveal that mud reaction forces\ndepend sensitively on robot motion, requiring joint analysis of robot movement\nwith proprioceptive force to determine mud properties correctly. Lastly, we\ndeploy this method in a flipper-driven robot moving across muddy substrates of\nvarying strengths, and demonstrate that the proposed method allows the robot to\nuse the estimated mud properties to adapt its locomotion strategy, and\nsuccessfully avoid locomotion failures. Our findings highlight the potential of\nproprioception-based terrain sensing to enhance robot mobility in complex,\ndeformable natural environments, paving the way for more robust field\nexploration capabilities.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-28T09:12:21Z"}
{"aid":"http://arxiv.org/abs/2504.19612v1","title":"Relative Advantage: Quantifying Performance in Noisy Competitive\n  Settings","summary":"Performance measurement in competitive domains is frequently confounded by\nshared environmental factors that obscure true performance differences. For\ninstance, absolute metrics can be heavily influenced by factors as varied as\nweather conditions in sports, prevailing economic climates in business\nevaluations, or the socioeconomic background of student populations in\neducation. This paper develops a unified mathematical framework for relative\nperformance metrics that systematically eliminates shared environmental effects\nthrough a principled transformation that will help improve interpretation of\nperformance metrics. We formalise the mechanism of environmental noise\ncancellation using signal-to-noise ratio analysis and establish theoretical\nbounds on metric performance. Through comprehensive simulations across diverse\nparameter configurations, we demonstrate that relative metrics consistently\noutperform absolute ones under specified conditions, with improvements up to\n28\\% in classification accuracy when environmental noise dominates individual\nvariations. As an example, we validate the mathematical framework using\nreal-world rugby performance data, confirming that relativised metrics provide\nsubstantially better predictive power than their absolute counterparts. Our\napproach offers both theoretical insights into the conditions governing metric\neffectiveness and practical guidance for measurement system design across\ncompetitive domains from sports analytics to financial performance evaluation\nand healthcare outcomes research.","main_category":"physics.data-an","categories":"physics.data-an","published":"2025-04-28T09:19:01Z"}
{"aid":"http://arxiv.org/abs/2504.19642v1","title":"Primal and dual characterizations of sign-symmetric norms","summary":"The paper studies primal and dual characterizations of a class of\nsign-symmetric norms on product vector spaces. Correspondences between these\nnorms and a class of convex functions are established. Explicit formulas for\nthe dual norm and the convex subdifferential of a given primal norm are\nderived. It is demonstrated that this class of norms is well-suited for\nstudying properties and problems on product spaces. As an application, we study\nthe von Neumann-Jordan constant of norms on product spaces and extend a\nclassical result of Clarkson from Lebesgue spaces to general normed vector\nspaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-28T10:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.19659v1","title":"Hardware/Software Co-Design of RISC-V Extensions for Accelerating Sparse\n  DNNs on FPGAs","summary":"The customizability of RISC-V makes it an attractive choice for accelerating\ndeep neural networks (DNNs). It can be achieved through instruction set\nextensions and corresponding custom functional units. Yet, efficiently\nexploiting these opportunities requires a hardware/software co-design approach\nin which the DNN model, software, and hardware are designed together. In this\npaper, we propose novel RISC-V extensions for accelerating DNN models\ncontaining semi-structured and unstructured sparsity. While the idea of\naccelerating structured and unstructured pruning is not new, our novel design\noffers various advantages over other designs. To exploit semi-structured\nsparsity, we take advantage of the fine-grained (bit-level) configurability of\nFPGAs and suggest reserving a few bits in a block of DNN weights to encode the\ninformation about sparsity in the succeeding blocks. The proposed custom\nfunctional unit utilizes this information to skip computations. To exploit\nunstructured sparsity, we propose a variable cycle sequential\nmultiply-and-accumulate unit that performs only as many multiplications as the\nnon-zero weights. Our implementation of unstructured and semi-structured\npruning accelerators can provide speedups of up to a factor of 3 and 4,\nrespectively. We then propose a combined design that can accelerate both types\nof sparsities, providing speedups of up to a factor of 5. Our designs consume a\nsmall amount of additional FPGA resources such that the resulting co-designs\nenable the acceleration of DNNs even on small FPGAs. We benchmark our designs\non standard TinyML applications such as keyword spotting, image classification,\nand person detection.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.AR","published":"2025-04-28T10:19:39Z"}
{"aid":"http://arxiv.org/abs/2504.19663v1","title":"The Boussinesq equation on the half-line","summary":"We study the initial-boundary value problem for the Boussinesq equation on\nthe half-line. Assuming that the solution exists, we prove that it can be\nrecovered from its initial-boundary values via the solution of a $3\\times 3$\nRiemann-Hilbert problem. The contour consists of $18$ arcs on the unit circle,\n$18$ segments and $18$ half-lines, and the associated jump matrices involve $9$\nreflection coefficients.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T10:21:54Z"}
{"aid":"http://arxiv.org/abs/2504.19672v1","title":"On Neutron Star Natal Kicks in High-Mass X-Ray Binaries: Insights from\n  Population Synthesis","summary":"The motion of neutron stars (NSs) in the Galaxy is largely dependent on natal\nkicks received by the NSs during supernova explosions. Thus, the measured\npeculiar velocities of NS high-mass X-ray binaries (HMXBs) provide valuable\nclues to natal kicks, which also play an important role in the evolution of\nHMXBs. In this work, we collect proper motions, radial velocities and\nparallaxes for 36 NS HMXBs to derive their peculiar velocities at the birth of\nthe NSs. We then use binary population synthesis to simulate the velocities of\nNS HMXBs with various choices of the kick velocity distribution for both\ncore-collapse and electron-capture supernovae. Comparing the simulated and\nmeasured velocities, orbital periods, and eccentricities, we show that the\nnatal kick distribution that can best match the observations is characterized\nby a bimodal Maxwellian distribution with $\\sigma_1$ = 320 km s$^{-1}$ (for\ncore-collapse supernovae) and $\\sigma_2$ = 80 km s$^{-1}$ (for electron-capture\nsupernovae) and the He core mass for the latter in the range of $(1.83-2.25)$\n$M_{\\odot}$. Our findings provide useful insights for further population\nsynthesis and binary evolution studies of NS binaries.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-28T10:57:36Z"}
{"aid":"http://arxiv.org/abs/2504.19673v1","title":"Generative AI in Education: Student Skills and Lecturer Roles","summary":"Generative Artificial Intelligence (GenAI) tools such as ChatGPT are emerging\nas a revolutionary tool in education that brings both positive aspects and\nchallenges for educators and students, reshaping how learning and teaching are\napproached. This study aims to identify and evaluate the key competencies\nstudents need to effectively engage with GenAI in education and to provide\nstrategies for lecturers to integrate GenAI into teaching practices. The study\napplied a mixed method approach with a combination of a literature review and a\nquantitative survey involving 130 students from South Asia and Europe to obtain\nits findings. The literature review identified 14 essential student skills for\nGenAI engagement, with AI literacy, critical thinking, and ethical AI practices\nemerging as the most critical. The student survey revealed gaps in prompt\nengineering, bias awareness, and AI output management. In our study of lecturer\nstrategies, we identified six key areas, with GenAI Integration and Curriculum\nDesign being the most emphasised. Our findings highlight the importance of\nincorporating GenAI into education. While literature prioritized ethics and\npolicy development, students favour hands-on, project-based learning and\npractical AI applications. To foster inclusive and responsible GenAI adoption,\ninstitutions should ensure equitable access to GenAI tools, establish clear\nacademic integrity policies, and advocate for global GenAI research\ninitiatives.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-28T10:58:30Z"}
{"aid":"http://arxiv.org/abs/2504.19676v1","title":"Exploring binary intermetallics for advanced interconnect applications\n  using ab initio simulations","summary":"The challenge of increasing copper (Cu) resistivity with diminishing Cu\ninterconnect dimensions in complementary metal-oxide-semiconductor (CMOS)\ntransistors, along with the imperative for efficient electron transport paths\nto fulfill scaling requirements in interconnects is significant.\nFirst-principles electronic structures calculations based on density functional\ntheory have been performed to evaluate the potential scalability of some Cu,\nAl, Ru and Mo based binary alloys to replace Cu. We evaluate the expected\nsensitivity of the resistivity of these binary alloys to reduced line\ndimensions with a figure of merit that is based on generalized\nfinite-temperature transport tensors. These transport tensors allow for a\nstraightforward comparison between highly anisotropic intermetallics with given\ntransport directions and Cu, and are evaluated together with their resistance\nto electromigration. Based on the figure-of-merit analysis, we identify several\naluminides that show potential to outperform Cu at reduced interconnect\ndimensions in terms of their electronic transport and reliability properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-28T11:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.19677v1","title":"A Polynomial-Time Inner Approximation Algorithm for Multi-Objective\n  Optimization","summary":"In multi-objective optimization, the problem of finding all non-dominated\nimages is often intractable. However, for any multiplicative factor greater\nthan one, an approximation set can be constructed in polynomial time for many\nproblems. In this paper, we use the concept of convex approximation sets: Each\nnon-dominated image is approximated by a convex combination of images of\nsolutions in such a set. Recently, Helfrich et al. (2024) presented a convex\napproximation algorithm that works in an adaptive fashion and outperforms all\npreviously existing algorithms. We use a different approach for constructing an\neven more efficient adaptive algorithm for computing convex approximation sets.\nOur algorithm is based on the skeleton algorithm for polyhedral inner\napproximation by Csirmaz (2021). If the weighted sum scalarization can be\nsolved exactly or approximately in polynomial time, our algorithm can find a\nconvex approximation set for an approximation factor arbitrarily close to this\nsolution quality. We demonstrate that our new algorithm significantly\noutperforms the current state-of-the-art algorithm from Helfrich et al. (2024)\non instances of the multi-objective variants of the assignment problem, the\nknapsack problem, and the symmetric metric travelling salesman problem.","main_category":"math.OC","categories":"math.OC","published":"2025-04-28T11:08:21Z"}
{"aid":"http://arxiv.org/abs/2504.19681v1","title":"The asymmetry $A_{LL}^{\\cos2φ}$ in the polarized proton-proton\n  Drell-Yan process within TMD factorization","summary":"We study the $\\cos2\\phi$ azimuthal asymmetry in doubly longitudinally\npolarized proton-proton Drell-Yan collisions within the transverse momentum\ndependent factorization framework. The asymmetry arises from the convolution of\nthe longitudinal transversity distribution $h_{1L}^{\\perp}$ for both protons.\nUsing the Bacchetta-Delcarro-Pisano-Radici-Signori parametrization for the\nnonperturbative Sudakov form factor and the Wandzura-Wilczek approximation for\nthe collinear $h_{1L}^{\\perp}$, we predict the double spin asymmetry\n$A_{LL}^{\\cos2\\phi}$ at RHIC and NICA kinematics. Our results demonstrate\nsensitivity to sea quark distributions, with the asymmetry reaching up to\n$25\\%$ for maximal sea quark contributions. These predictions highlight the\npotential of polarized Drell-Yan measurements to probe sea quark dynamics and\nadvance our understanding of nucleon structure.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-28T11:12:37Z"}
{"aid":"http://arxiv.org/abs/2504.19689v1","title":"On Unitary Groups in Ternary and Generalized Clifford Algebras","summary":"We discuss a generalization of Clifford algebras known as generalized\nClifford algebras (in particular, ternary Clifford algebras). In these objects,\nwe have a fixed higher-degree form (in particular, a ternary form) instead of a\nquadratic form in ordinary Clifford algebras. We present a natural realization\nof unitary Lie groups, which are important in physics and other applications,\nusing only operations in generalized Clifford algebras and without using the\ncorresponding matrix representations. Basis-free definitions of the\ndeterminant, trace, and characteristic polynomial in generalized Clifford\nalgebras are introduced. Explicit formulas for all coefficients of the\ncharacteristic polynomial and inverse in generalized Clifford algebras are\npresented. The operation of Hermitian conjugation (or Hermitian transpose) in\ngeneralized Clifford algebras is introduced without using the corresponding\nmatrix representations.","main_category":"math-ph","categories":"math-ph,math.MP,math.RA","published":"2025-04-28T11:33:43Z"}
{"aid":"http://arxiv.org/abs/2504.19721v1","title":"Morse homology for a class of elliptic partial differential equations","summary":"In this paper we show that a notion of non-degeneracy which allows to develop\nMorse theory is generically satisfied for a large class of $C^2$-functionals\ndefined on Banach spaces. The main element of novelty with respect to the\nprevious work of the first and third author is that we do not assume the\nsplitting induced by the second differential at a critical point to persist in\na neighborhood, provided one can give precise estimates on how much persistence\nfails. This allows us to enlarge significantly the class of elliptic pde's for\nwhich non-degeneracy holds and Morse homology can be defined. A concrete\nexample is given by equations involving the $p$-Laplacian, $p\\leq n$. As a\nbyproduct, we provide a criterion of independent interest to check whether\ncritical points are non-degenerate in the sense above, and give an abstract\nconstruction of Morse homology in a Banach setting for functionals satisfying\nthe Cerami condition.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-28T12:14:45Z"}
{"aid":"http://arxiv.org/abs/2504.19730v1","title":"Evaluate-and-Purify: Fortifying Code Language Models Against Adversarial\n  Attacks Using LLM-as-a-Judge","summary":"The widespread adoption of code language models in software engineering tasks\nhas exposed vulnerabilities to adversarial attacks, especially the identifier\nsubstitution attacks. Although existing identifier substitution attackers\ndemonstrate high success rates, they often produce adversarial examples with\nunnatural code patterns. In this paper, we systematically assess the quality of\nadversarial examples using LLM-as-a-Judge. Our analysis reveals that over 80%\nof adversarial examples generated by state-of-the-art identifier substitution\nattackers (e.g., ALERT) are actually detectable. Based on this insight, we\npropose EP-Shield, a unified framework for evaluating and purifying identifier\nsubstitution attacks via naturalness-aware reasoning. Specifically, we first\nevaluate the naturalness of code and identify the perturbed adversarial code,\nthen purify it so that the victim model can restore correct prediction.\nExtensive experiments demonstrate the superiority of EP-Shield over adversarial\nfine-tuning (up to 83.36% improvement) and its lightweight design 7B\nparameters) with GPT-4-level performance.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-04-28T12:28:55Z"}
{"aid":"http://arxiv.org/abs/2504.19738v1","title":"Learning Efficiency Meets Symmetry Breaking","summary":"Learning-based planners leveraging Graph Neural Networks can learn search\nguidance applicable to large search spaces, yet their potential to address\nsymmetries remains largely unexplored. In this paper, we introduce a graph\nrepresentation of planning problems allying learning efficiency with the\nability to detect symmetries, along with two pruning methods, action pruning\nand state pruning, designed to manage symmetries during search. The integration\nof these techniques into Fast Downward achieves a first-time success over LAMA\non the latest IPC learning track dataset. Code is released at:\nhttps://github.com/bybeye/Distincter.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-28T12:33:39Z"}
{"aid":"http://arxiv.org/abs/2504.19777v1","title":"On the Complexity of Identifying Groups without Abelian Normal\n  Subgroups: Parallel, First Order, and GI-Hardness","summary":"In this paper, we exhibit an $\\textsf{AC}^{3}$ isomorphism test for groups\nwithout Abelian normal subgroups (a.k.a. Fitting-free groups), a class for\nwhich isomorphism testing was previously known to be in $\\mathsf{P}$ (Babai,\nCodenotti, and Qiao; ICALP '12). Here, we leverage the fact that\n$G/\\text{PKer}(G)$ can be viewed as permutation group of degree $O(\\log |G|)$.\nAs $G$ is given by its multiplication table, we are able to implement the\nsolution for the corresponding instance of Twisted Code Equivalence in\n$\\textsf{AC}^{3}$.\n  In sharp contrast, we show that when our groups are specified by a generating\nset of permutations, isomorphism testing of Fitting-free groups is at least as\nhard as Graph Isomorphism and Linear Code Equivalence (the latter being\n$\\textsf{GI}$-hard and having no known subexponential-time algorithm).\n  Lastly, we show that any Fitting-free group of order $n$ is identified by\n$\\textsf{FO}$ formulas (without counting) using only $O(\\log \\log n)$\nvariables. This is in contrast to the fact that there are infinite families of\nAbelian groups that are not identified by $\\textsf{FO}$ formulas with $o(\\log\nn)$ variables (Grochow & Levet, FCT '23).","main_category":"cs.CC","categories":"cs.CC,cs.DS,cs.LO,math.GR","published":"2025-04-28T13:23:46Z"}
{"aid":"http://arxiv.org/abs/2504.19779v1","title":"Learning Brenier Potentials with Convex Generative Adversarial Neural\n  Networks","summary":"Brenier proved that under certain conditions on a source and a target\nprobability measure there exists a strictly convex function such that its\ngradient is a transport map from the source to the target distribution. This\nfunction is called the Brenier potential. Furthermore, detailed information on\nthe H\\\"older regularity of the Brenier potential is available. In this work we\ndevelop the statistical learning theory of generative adversarial neural\nnetworks that learn the Brenier potential. As by the transformation of\ndensities formula, the density of the generated measure depends on the second\nderivative of the Brenier potential, we develop the universal approximation\ntheory of ReCU networks with cubic activation $\\mathtt{ReCU}(x)=\\max\\{0,x\\}^3$\nthat combines the favorable approximation properties of H\\\"older functions with\na Lipschitz continuous density. In order to assure the convexity of such\ngeneral networks, we introduce an adversarial training procedure for a\npotential function represented by the ReCU networks that combines the classical\ndiscriminator cross entropy loss with a penalty term that enforces (strict)\nconvexity. We give a detailed decomposition of learning errors and show that\nfor a suitable high penalty parameter all networks chosen in the adversarial\nmin-max optimization problem are strictly convex. This is further exploited to\nprove the consistency of the learning procedure for (slowly) expanding network\ncapacity. We also implement the described learning algorithm and apply it to a\nnumber of standard test cases from Gaussian mixture to image data as target\ndistributions. As predicted in theory, we observe that the convexity loss\nbecomes inactive during the training process and the potentials represented by\nthe neural networks have learned convexity.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-28T13:24:52Z"}
{"aid":"http://arxiv.org/abs/2504.19801v1","title":"Stochastic quantum adiabatic algorithm with fractional Brownian motion","summary":"Adiabatic Quantum Computing relies on the quantum adiabatic theorem, which\nstates that a quantum system evolves along its ground state with time if the\ngoverning Hamiltonian varies infinitely slowly. However, practical limitations\nforce computations to be performed within limited times, exposing the system to\ntransitions into excited states, and thereby reducing the success probability.\nHere we investigate the counterintuitive hypothesis that incorporating\nstochastic noise, specifically noise driven by fractional Brownian motion, in a\nnon-Markovian setup can enhance the performance of adiabatic quantum computing\nby improving its success probability at limited evolution times. The study\nbegins by developing the mathematical framework to introduce stochastic noise\nmultiplicatively into the Schr\\\"{o}dinger equation, resulting in a stochastic\nSchr\\\"{o}dinger equation. To preserve It\\^{o} integrability within the\nnon-Markovian framework, a semimartingale approximation for fractional Brownian\nmotion is employed. We perform numerical simulations to compare the performance\nof the quantum adiabatic algorithm with and without noise driven by fractional\nBrownian motion using the NP-complete Exact Cover-3 problem, transformed into\nthe Ising model. Our results exhibit an improvement in success probability in\nthe presence of noise driven by fractional Brownian motion with Hurst parameter\n$0<H<\\frac{1}{2}$ and an increase in speedup as $H$ approaches 0. Although\nsimulations are limited to problems involving a modest number of qubits,\nevidence suggests that the proposed approach scales favorably with the system\nsize.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T13:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.19803v1","title":"Unconventional Relaxation Dynamics in Co_8Zn_7Mn_5 and Co_8Zn_8Mn_4:\n  Evidence of Inertial Effects","summary":"Magnetization relaxation dynamics serve as an essential tool for uncovering\nthe intrinsic mechanisms governing the magnetic response and energy dissipation\nin magnetic systems. In this work, we examine the relaxation dynamics for Beta\nMn type Co_8Zn_7Mn_5 and Co_8Zn_8Mn_4 across a frequency range of 1 kHz to 10\nkHz, spanning different magnetic phases. While most magnetic systems tend to\nfollow the Debye-like relaxation with non-zero distribution or the Cole-Cole\nformalism, our analysis reveal that these conventional models fail to capture\nfrequency dependence of ac susceptibility across different magnetic phases in\nCo_8Zn_7Mn_5 and Co_8Zn_8Mn_4. Instead, an inertial component is needed to\nsuccessfully describe the dynamics, suggesting the presence of unconventional\nrelaxation behavior. The characteristic relaxation time is found to be of the\norder of 10^-5 s for both the compositions. The field dependent variation of\nrelaxation time exhibits a non-monotonic nature, with the double peak like\nstructure at the skyrmion phase transitions, implying slower relaxation\ndynamics at the phase boundaries. Furthermore, the presence of non-zero\ndifference between isothermal and adiabatic susceptibility in the pure phases\nimplies slower relaxation dynamics, which is consistent with the presence of\nfinite dissipation in pure phases. The inertial term has been previously\ninvoked to describe the dynamics in spin ice systems due to the propagation of\nmagnetic monopoles. However, its necessity in this system, points to a wider\nsignificance in magnetization dynamics that goes beyond the conventional spin\nices and skyrmions.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.other,cond-mat.str-el,quant-ph","published":"2025-04-28T13:55:27Z"}
{"aid":"http://arxiv.org/abs/2504.19839v1","title":"SRMF: A Data Augmentation and Multimodal Fusion Approach for Long-Tail\n  UHR Satellite Image Segmentation","summary":"The long-tail problem presents a significant challenge to the advancement of\nsemantic segmentation in ultra-high-resolution (UHR) satellite imagery. While\nprevious efforts in UHR semantic segmentation have largely focused on\nmulti-branch network architectures that emphasize multi-scale feature\nextraction and fusion, they have often overlooked the importance of addressing\nthe long-tail issue. In contrast to prior UHR methods that focused on\nindependent feature extraction, we emphasize data augmentation and multimodal\nfeature fusion to alleviate the long-tail problem. In this paper, we introduce\nSRMF, a novel framework for semantic segmentation in UHR satellite imagery. Our\napproach addresses the long-tail class distribution by incorporating a\nmulti-scale cropping technique alongside a data augmentation strategy based on\nsemantic reordering and resampling. To further enhance model performance, we\npropose a multimodal fusion-based general representation knowledge injection\nmethod, which, for the first time, fuses text and visual features without the\nneed for individual region text descriptions, extracting more robust features.\nExtensive experiments on the URUR, GID, and FBP datasets demonstrate that our\nmethod improves mIoU by 3.33\\%, 0.66\\%, and 0.98\\%, respectively, achieving\nstate-of-the-art performance. Code is available at:\nhttps://github.com/BinSpa/SRMF.git.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T14:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.19847v1","title":"Foundation Model-Driven Framework for Human-Object Interaction\n  Prediction with Segmentation Mask Integration","summary":"In this work, we introduce Segmentation to Human-Object Interaction\n(\\textit{\\textbf{Seg2HOI}}) approach, a novel framework that integrates\nsegmentation-based vision foundation models with the human-object interaction\ntask, distinguished from traditional detection-based Human-Object Interaction\n(HOI) methods. Our approach enhances HOI detection by not only predicting the\nstandard triplets but also introducing quadruplets, which extend HOI triplets\nby including segmentation masks for human-object pairs. More specifically,\nSeg2HOI inherits the properties of the vision foundation model (e.g.,\npromptable and interactive mechanisms) and incorporates a decoder that applies\nthese attributes to HOI task. Despite training only for HOI, without additional\ntraining mechanisms for these properties, the framework demonstrates that such\nfeatures still operate efficiently. Extensive experiments on two public\nbenchmark datasets demonstrate that Seg2HOI achieves performance comparable to\nstate-of-the-art methods, even in zero-shot scenarios. Lastly, we propose that\nSeg2HOI can generate HOI quadruplets and interactive HOI segmentation from\nnovel text and visual prompts that were not used during training, making it\nversatile for a wide range of applications by leveraging this flexibility.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-28T14:45:26Z"}
{"aid":"http://arxiv.org/abs/2504.19868v1","title":"exoALMA XI: ALMA Observations and Hydrodynamic Models of LkCa 15:\n  Implications for Planetary Mass Companions in the Dust Continuum Cavity","summary":"In the past decade, the Atacama Large Millimeter/submillimeter Array (ALMA)\nhas revealed a plethora of substructures in the disks surrounding young stars.\nThese substructures have several proposed formation mechanisms, with one\nleading theory being the interaction between the disk and newly formed planets.\nIn this Letter, we present high angular resolution ALMA observations of\nLkCa~15's disk that reveal a striking difference in dust and CO emission\nmorphology. The dust continuum emission shows a ring-like structure\ncharacterized by a dust-depleted inner region of $\\sim$40 au in radius.\nConversely, the CO emission is radially smoother and shows no sign of gas\ndepletion within the dust cavity. We compare the observations with models for\nthe disk-planet interaction, including radiative transfer calculation in the\ndust and CO emission. This source is particularly interesting as the presence\nof massive planets within the dust cavity has been suggested based on previous\nNIR observations. We find that the level of CO emission observed within the\ndust cavity is inconsistent with the presence of planets more massive than\nJupiter orbiting between 10-40 au. Instead, we argue that the LkCa~15 innermost\ndust cavity might be created either by a chain of low-mass planets, or by other\nprocesses that do not require the presence of planets.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-28T15:01:13Z"}
{"aid":"http://arxiv.org/abs/2504.19875v1","title":"Fiber laser based stimulated Raman photothermal microscopy with long\n  working distance optics","summary":"Stimulated Raman scattering (SRS) microscopy is a highly sensitive chemical\nimaging technique. However, the broader application of SRS has been limited by\ntwo key challenges: the reliance on low-noise but bulky solid-state laser\nsources and stringent sample requirements necessitated by high numerical\naperture (NA) optics. Here, we present a fiber laser based stimulated Raman\nphotothermal (SRP) microscope that addresses these limitations. While\nappreciating the portability and compactness of a noisy source, fiber laser SRP\nenables a two-order-of-magnitude improvement in signal to noise ratio over\nfiber laser SRS without balance detection. Furthermore, with the use of low NA,\nlong working distance optics for signal collection, SRP expands the allowed\nsample space from millimeters to centimeters, which diversifies the sample\nformats to multi-well plates and thick tissues. The sensitivity and imaging\ndepth are further amplified by using urea for both thermal enhancement and\ntissue clearance. Together, fiber laser SRP microscopy provides a robust,\nuser-friendly platform for diverse applications.","main_category":"physics.optics","categories":"physics.optics,physics.ins-det","published":"2025-04-28T15:05:58Z"}
{"aid":"http://arxiv.org/abs/2504.19887v1","title":"Planar Coulomb gas on a Jordan arc at any temperature","summary":"We study a planar Coulomb gas confined to a sufficiently smooth Jordan arc\n$\\gamma$ in the complex plane, at inverse temperature $\\beta > 0$. Let\n\\[\\bar{Z}_{n}^\\beta(\\gamma) = Z_{n}^\\beta(\\gamma)/\\left(2\n\\textrm{cap}(\\gamma)\\right)^{\\beta n^2/2+(1-\\beta/2)n}\\] be the normalized\npartition function. We compute the free energy as the number of particles tends\nto infinity, including the constant term: \\[ \\lim_{n\\to \\infty}\\log\n\\frac{\\bar{Z}_{n}^\\beta(\\gamma)}{\\bar{Z}_{n}^\\beta([-1,1])} =\n\\frac{1}{24}J^A(\\gamma) + \\frac{1}{8} \\left( \\sqrt{ \\frac{\\beta}{2} } - \\sqrt{\n\\frac{2}{\\beta}} \\right)^2 J^{F}(\\gamma). \\] Here $\\bar{Z}_{n}^\\beta([-1,1])$\nis an explicit Selberg integral, $J^A(\\gamma)$ is half the Loewner energy of a\ncertain Jordan curve associated to $\\gamma$ plus a covariance term, and\n$J^F(\\gamma)$ is the Fekete energy, related to the zero temperature limit of\nthe model.\n  We also prove an asymptotic formula for the Laplace transform of linear\nstatistics for sufficiently regular test functions. As a consequence, the\ncentered empirical measure converges to a Gaussian field with explicit\nasymptotic mean, and asymptotic variance given by the Dirichlet energy of the\nbounded harmonic extension of the test function outside of the arc.\n  A key tool in our analysis is the arc-Grunsky operator $B$ associated to\n$\\gamma$, reminiscent to but different from the classical Grunsky operator. We\nderive several basic properties the arc-Grunsky operator, including an estimate\nanalogous to the strengthened Grunsky inequality and the relation to the\nDirichlet integral. In our proofs $J^A(\\gamma)$ arises from the Fredholm\ndeterminant $\\det(I+B)$ and a substantial part of the paper is devoted to\nrelating this to the Loewner energy.","main_category":"math.CV","categories":"math.CV,math.PR","published":"2025-04-28T15:19:09Z"}
{"aid":"http://arxiv.org/abs/2504.19888v1","title":"Enhancing breast cancer detection on screening mammogram using\n  self-supervised learning and a hybrid deep model of Swin Transformer and\n  Convolutional Neural Network","summary":"Purpose: The scarcity of high-quality curated labeled medical training data\nremains one of the major limitations in applying artificial intelligence (AI)\nsystems to breast cancer diagnosis. Deep models for mammogram analysis and mass\n(or micro-calcification) detection require training with a large volume of\nlabeled images, which are often expensive and time-consuming to collect. To\nreduce this challenge, we proposed a novel method that leverages\nself-supervised learning (SSL) and a deep hybrid model, named \\textbf{HybMNet},\nwhich combines local self-attention and fine-grained feature extraction to\nenhance breast cancer detection on screening mammograms.\n  Approach: Our method employs a two-stage learning process: (1) SSL\nPretraining: We utilize EsViT, a SSL technique, to pretrain a Swin Transformer\n(Swin-T) using a limited set of mammograms. The pretrained Swin-T then serves\nas the backbone for the downstream task. (2) Downstream Training: The proposed\nHybMNet combines the Swin-T backbone with a CNN-based network and a novel\nfusion strategy. The Swin-T employs local self-attention to identify\ninformative patch regions from the high-resolution mammogram, while the\nCNN-based network extracts fine-grained local features from the selected\npatches. A fusion module then integrates global and local information from both\nnetworks to generate robust predictions. The HybMNet is trained end-to-end,\nwith the loss function combining the outputs of the Swin-T and CNN modules to\noptimize feature extraction and classification performance.\n  Results: The proposed method was evaluated for its ability to detect breast\ncancer by distinguishing between benign (normal) and malignant mammograms.\nLeveraging SSL pretraining and the HybMNet model, it achieved AUC of 0.864 (95%\nCI: 0.852, 0.875) on the CMMD dataset and 0.889 (95% CI: 0.875, 0.903) on the\nINbreast dataset, highlighting its effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T15:23:28Z"}
{"aid":"http://arxiv.org/abs/2504.19897v1","title":"The Dust Echo Emission of Fast Blue Optical Transients and Application\n  to the Near-Infrared Excess of AT 2018cow","summary":"A near-infrared (NIR) excess has been discovered in the emission of the\nrepresentative fast blue optical transient (FBOT): AT 2018cow. It was suggested\nthat this NIR excess could be emitted by the dust surrounding the source and,\nthus, could provide a probe into the nature of its progenitor. We develop a\nmodel to describe the influence of the FBOT emission on the environmental dust\nand, as a result, a dust-free evaporation cavity can be formed on a timescale\nof one day. Outside this cavity, the surviving dust grains can have different\nsize distributions at different distances to the source. With such a special\ndust environment, we fit the multi-wavelength light curves of AT 2018cow by\ntaking into account the evolutionary dust echo of the FBOT emission. It is\nfound that the dust temperature can vary with time along with the evolution of\nthe irradiating FBOT emission. Even at a fixed time, the dust temperature can\nbe distributed in a wide range rather than having only a unique value.\nFurthermore, both the mass of the dust shell and its distance to the FBOT are\nfound to be much larger than those derived with a direct empirical fitting of\nthe NIR spectra but without considering the evolutionary relationship between\nthe spectra.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-28T15:28:44Z"}
{"aid":"http://arxiv.org/abs/2504.19902v1","title":"exoALMA V: Gaseous Emission Surfaces and Temperature Structures","summary":"Analysis of the gaseous component in protoplanetary disks can inform us about\ntheir thermal and physical structure, chemical composition, and kinematic\nproperties, all of which are crucial for understanding various processes within\nthe disks. By exploiting the asymmetry of the line emission, or via line\nprofile analysis, we can locate the emitting surfaces. Here, we present the\nemission surfaces of the exoALMA sources in $^{12}$CO $J=3-2$, $^{13}$CO\n$J=3-2$, and CS $J=7-6$. We find that $^{12}$CO traces the upper disk\natmosphere, with mean <$z/r$> values of $\\approx$ 0.28, while $^{13}$CO and CS\ntrace lower regions of the disk with mean <z/r> values of $\\approx$ 0.16 and\n$\\approx$ 0.18, respectively. We find that $^{12}$CO <$z/r$> and the disk mass\nare positively correlated with each other; this relationship offers a\nstraightforward way to infer the disk mass. We derive 2-D $r-z$ temperature\ndistributions of the disks. Additionally, we search for substructure in the\nsurfaces and radial intensity profiles; we find evidence of localized\nsubstructure in the emission surfaces and peak intensity profiles of nearly\nevery disk, with this substructure often being co-incident between molecular\ntracers, intensity profiles, and kinematic perturbations. Four disks display\nevidence of potential photo-desorption, implying that this effect may be common\neven in low FUV star-forming regions. For most disks, we find that the physical\nand thermal structure is more complex than analytical models can account for,\nhighlighting a need for more theoretical work and a better understanding of the\nrole of projection effects on our observations.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-28T15:33:15Z"}
{"aid":"http://arxiv.org/abs/2504.19922v1","title":"Dynamical analysis of stacked samples of asymmetric, non-static,\n  self-gravitating systems","summary":"We use numerical simulations to explore biases that arise in dynamical\nestimates of the mean mass profile for a collection of galaxy clusters that\nhave been stacked to make a composite. There are three types of bias. One\narises from anisotropy of the kinematic pressure tensor and has been already\nwell studied; a second arises from departures from equilibrium; and a third\narises because of heterogeneity of the clusters used, from their individual\nnon-sphericity, and because velocities used are measured with respect to\ncentres that are, in general, accelerating. Here we focus on the latter two. We\nstack clusters to measure the pressure tensor and density profiles and then\nestimate the dynamical mass profile using the Jeans equation, and compare to\nthe actual mean mass profile. The main result of this paper is an estimate of\nthe bias, that can be used to correct the dynamical mass estimate, and we show\nhow it depends on the cluster sample selection. We find that Jeans equation\ntypically overestimates the true mass by about 20\\% at the virial radius.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA","published":"2025-04-28T15:56:14Z"}
{"aid":"http://arxiv.org/abs/2504.19925v1","title":"Accelerating Mixture-of-Experts Training with Adaptive Expert\n  Replication","summary":"Mixture-of-Experts (MoE) models have become a widely adopted solution to\ncontinue scaling model sizes without a corresponding linear increase in\ncompute. During MoE model training, each input token is dynamically routed to a\nsubset of experts -- sparsely-activated feed-forward networks -- within each\ntransformer layer. The distribution of tokens assigned to each expert varies\nwidely and rapidly over the course of training. To handle the wide load\nimbalance across experts, current systems are forced to either drop tokens\nassigned to popular experts, degrading convergence, or frequently rebalance\nresources allocated to each expert based on popularity, incurring high state\nmigration overheads.\n  To break this performance-accuracy tradeoff, we introduce SwiftMoE, an\nadaptive MoE training system. The key insight of SwiftMoE is to decouple the\nplacement of expert parameters from their large optimizer state. SwiftMoE\nstatically partitions the optimizer of each expert across all training nodes.\nMeanwhile, SwiftMoE dynamically adjusts the placement of expert parameters by\nrepurposing existing weight updates, avoiding migration overheads. In doing so,\nSwiftMoE right-sizes the GPU resources allocated to each expert, on a\nper-iteration basis, with minimal overheads. Compared to state-of-the-art MoE\ntraining systems, DeepSpeed and FlexMoE, SwiftMoE is able to achieve a 30.5%\nand 25.9% faster time-to-convergence, respectively.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-28T15:58:55Z"}
{"aid":"http://arxiv.org/abs/2504.19938v1","title":"Mesh-Learner: Texturing Mesh with Spherical Harmonics","summary":"In this paper, we present a 3D reconstruction and rendering framework termed\nMesh-Learner that is natively compatible with traditional rasterization\npipelines. It integrates mesh and spherical harmonic (SH) texture (i.e.,\ntexture filled with SH coefficients) into the learning process to learn each\nmesh s view-dependent radiance end-to-end. Images are rendered by interpolating\nsurrounding SH Texels at each pixel s sampling point using a novel\ninterpolation method. Conversely, gradients from each pixel are back-propagated\nto the related SH Texels in SH textures. Mesh-Learner exploits graphic features\nof rasterization pipeline (texture sampling, deferred rendering) to render,\nwhich makes Mesh-Learner naturally compatible with tools (e.g., Blender) and\ntasks (e.g., 3D reconstruction, scene rendering, reinforcement learning for\nrobotics) that are based on rasterization pipelines. Our system can train vast,\nunlimited scenes because we transfer only the SH textures within the frustum to\nthe GPU for training. At other times, the SH textures are stored in CPU RAM,\nwhich results in moderate GPU memory usage. The rendering results on\ninterpolation and extrapolation sequences in the Replica and FAST-LIVO2\ndatasets achieve state-of-the-art performance compared to existing\nstate-of-the-art methods (e.g., 3D Gaussian Splatting and M2-Mapping). To\nbenefit the society, the code will be available at\nhttps://github.com/hku-mars/Mesh-Learner.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-28T16:09:25Z"}
{"aid":"http://arxiv.org/abs/2504.19944v1","title":"Probabilistic and Causal Satisfiability: Constraining the Model","summary":"We study the complexity of satisfiability problems in probabilistic and\ncausal reasoning. Given random variables $X_1, X_2,\\ldots$ over finite domains,\nthe basic terms are probabilities of propositional formulas over atomic events\n$X_i = x_i$, such as $P(X_1 = x_1)$ or $P(X_1 = x_1 \\vee X_2 = x_2)$. The basic\nterms can be combined using addition (yielding linear terms) or multiplication\n(polynomial terms). The probabilistic satisfiability problem asks whether a\njoint probability distribution satisfies a Boolean combination of\n(in)equalities over such terms. Fagin et al. (1990) showed that for basic and\nlinear terms, this problem is NP-complete, making it no harder than Boolean\nsatisfiability, while Moss\\'e et al. (2022) proved that for polynomial terms,\nit is complete for the existential theory of the reals.\n  Pearl's Causal Hierarchy (PCH) extends the probabilistic setting with\ninterventional and counterfactual reasoning, enriching the expressiveness of\nlanguages. However, Moss\\'e et al. (2022) found that satisfiability complexity\nremains unchanged. Van der Zander et al. (2023) showed that introducing a\nmarginalization operator to languages induces a significant increase in\ncomplexity.\n  We extend this line of work by adding two new dimensions to the problem by\nconstraining the models. First, we fix the graph structure of the underlying\nstructural causal model, motivated by settings like Pearl's do-calculus, and\ngive a nearly complete landscape across different arithmetics and PCH levels.\nSecond, we study small models. While earlier work showed that satisfiable\ninstances admit polynomial-size models, this is no longer guaranteed with\ncompact marginalization. We characterize the complexities of satisfiability\nunder small-model constraints across different settings.","main_category":"cs.CC","categories":"cs.CC,cs.AI,cs.LO","published":"2025-04-28T16:14:06Z"}
{"aid":"http://arxiv.org/abs/2504.19955v1","title":"Robust Federated Personalised Mean Estimation for the Gaussian Mixture\n  Model","summary":"Federated learning with heterogeneous data and personalization has received\nsignificant recent attention. Separately, robustness to corrupted data in the\ncontext of federated learning has also been studied. In this paper we explore\ncombining personalization for heterogeneous data with robustness, where a\nconstant fraction of the clients are corrupted. Motivated by this broad\nproblem, we formulate a simple instantiation which captures some of its\ndifficulty. We focus on the specific problem of personalized mean estimation\nwhere the data is drawn from a Gaussian mixture model. We give an algorithm\nwhose error depends almost linearly on the ratio of corrupted to uncorrupted\nsamples, and show a lower bound with the same behavior, albeit with a gap of a\nconstant factor.","main_category":"cs.LG","categories":"cs.LG,cs.IT,math.IT","published":"2025-04-28T16:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.19963v1","title":"Stochastic Subspace via Probabilistic Principal Component Analysis for\n  Characterizing Model Error","summary":"This paper proposes a probabilistic model of subspaces based on the\nprobabilistic principal component analysis (PCA). Given a sample of vectors in\nthe embedding space -- commonly known as a snapshot matrix -- this method uses\nquantities derived from the probabilistic PCA to construct distributions of the\nsample matrix, as well as the principal subspaces. It is applicable to\nprojection-based reduced-order modeling methods, such as proper orthogonal\ndecomposition and related model reduction methods. The stochastic subspace thus\nconstructed can be used, for example, to characterize model-form uncertainty in\ncomputational mechanics. The proposed method has multiple desirable properties:\n(1) it is naturally justified by the probabilistic PCA and has analytic forms\nfor the induced random matrix models; (2) it satisfies linear constraints, such\nas boundary conditions of all kinds, by default; (3) it has only one\nhyperparameter, which significantly simplifies training; and (4) its algorithm\nis very easy to implement. We compare the proposed method with existing\napproaches in a low-dimensional visualization example and a parametric static\nproblem, and demonstrate its performance in a dynamics model of a space\nstructure.","main_category":"cs.CE","categories":"cs.CE,math.ST,physics.comp-ph,physics.data-an,stat.ME,stat.TH","published":"2025-04-28T16:35:01Z"}
{"aid":"http://arxiv.org/abs/2504.19980v1","title":"Deep Declarative Risk Budgeting Portfolios","summary":"Recent advances in deep learning have spurred the development of end-to-end\nframeworks for portfolio optimization that utilize implicit layers. However,\nmany such implementations are highly sensitive to neural network\ninitialization, undermining performance consistency. This research introduces a\nrobust end-to-end framework tailored for risk budgeting portfolios that\neffectively reduces sensitivity to initialization. Importantly, this enhanced\nstability does not compromise portfolio performance, as our framework\nconsistently outperforms the risk parity benchmark.","main_category":"q-fin.PM","categories":"q-fin.PM,q-fin.CP","published":"2025-04-28T16:53:13Z"}
{"aid":"http://arxiv.org/abs/2504.20030v1","title":"Allele trees for the mother-dependent neutral mutations model and their\n  scaling limits in the rare mutations regime","summary":"The mother-dependent neutral mutations model describes the evolution of a\npopulation across discrete generations, where neutral mutations occur among a\nfinite set of possible alleles. In this model, each mutant child acquires a\ntype different from that of its mother, chosen uniformly at random. In this\nwork, we define a multitype allele tree associated with this model and analyze\nits scaling limit through a Markov chain that tracks the sizes of allelic\nsubfamilies and their mutant descendants. We show that this Markov chain\nconverges to a continuous-state Markov process, whose transition probabilities\ndepend on the sizes of the initial allelic populations and those of their\nmutant offspring in the first allelic generation. As a result, the allele tree\nconverges to a multidimensional limiting object, which can be described in\nterms of the universal allele tree introduced by Bertoin (2010).","main_category":"math.PR","categories":"math.PR","published":"2025-04-28T17:54:02Z"}
{"aid":"http://arxiv.org/abs/2504.20046v1","title":"On the Properties of Cosmological Ionization Fronts","summary":"We investigate the properties of cosmological ionization fronts during the\nEpoch of Reionization using the CROC simulations. By analyzing reionization\ntiming maps, we characterize ionization front velocities and curvatures and\ntheir dependence on the density structure of the intergalactic medium (IGM).\nThe velocity distribution of ionization fronts in the simulations indicates\nthat while the barrier-crossing analytical model captures the overall shape in\nhigh-velocity regions, it fails to reproduce the low-velocity tail,\nhighlighting the non-Gaussian nature of the IGM's density field. Ionization\nfront velocities are inversely correlated with local density, propagating\nfaster in underdense regions and more slowly in overdense environments. Faster\nionization fronts also lead to higher post-ionization temperatures, reaching a\nplateau at $\\sim 2 \\times 10^4$ K for velocities exceeding 3000 km/s. Examining\ncurvature statistics further establishes a connection between ionization front\nstructure and the normalized density contrast $\\nu$, with trends in overdense\nregions aligning well with barrier-crossing model predictions, while deviations\nappear in underdense environments due to model limitations. These results\nprovide a detailed characterization of ionization front dynamics and their\ninteraction with the underlying density field, bridging small-scale\nreionization physics with large-scale observables such as the 21 cm signal and\nthe IGM's thermal history.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-28T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.20388v1","title":"The two-clock problem in population dynamics","summary":"Biological time can be measured in two ways: in generations and in physical\ntime. When generation intervals differ between individuals, these two clocks\ndiverge, which impedes our ability to relate mathematical models to real\npopulations. In this paper we show that nevertheless, these disparate clocks\nbecome equivalent in the long run via a simple identity relating generational\nand physical time. This equivalence allows us to directly translate statements\nfrom mathematical models to the physical world and vice versa. As an\napplication, we obtain a generalized Euler-Lotka equation linking the basic\nreproduction number $R_0$ to the growth rate, and derive several\ninformation-theoretic bounds on these quantities. We also show how the fitness\nof a lineage can be defined consistently in population models, with\napplications to microbial growth, epidemiology and population biology.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.bio-ph","published":"2025-04-29T03:15:23Z"}
{"aid":"http://arxiv.org/abs/2504.20424v1","title":"ESPARTACO 2, a new stellar spectrograph at Uniandes","summary":"We present the construction and early results of ESPARTACO 2, the new stellar\nspectrograph built for research and education at the Astronomical Observatory\nof the Universidad de los Andes in Bogot\\'a, Colombia. This instrument offers\nseveral resolutions from 20,000 in first order using a 50 $\\mu$m fiber, to\n100,000 in second order in the near infrared. Precise radial-velocity\nmeasurements are made possible by simultaneous wavelength calibration. Combined\nwith the 40-cm Meade telescope located at our facilities, a limiting magnitude\nof 6 is reached. This instrument is a considerable improvement over its\npredecessor in throughput, reliability and ease.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.SR","published":"2025-04-29T04:39:20Z"}
{"aid":"http://arxiv.org/abs/2504.20425v1","title":"Metaheuristic Optimization of Trajectory and Dynamic Time Splitting for\n  UAV Communication Systems","summary":"The integration of unmanned aerial vehicles (UAVs) into wireless\ncommunication systems has emerged as a transformative approach, promising\ncost-efficient connectivity. This paper addresses the optimization of the\ndynamic time-splitting ratio and flight trajectory for a communication system\nlinking a ground base station to the UAV equipped with backscatter devices\n(referred to as UB), and from UB to an end user. Given the inherent\nnon-convexity of the problem, we develop two meta-heuristic-based approaches\ninspired by genetic algorithm and particle swarm optimization to enhance the\ntotal achievable rate while reducing computational complexity. Numerical\nresults demonstrate the effectiveness of these meta-heuristic solutions,\nshowcasing significant improvements in the achievable rate and computation time\ncompared to existing benchmarks.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-29T04:39:29Z"}
{"aid":"http://arxiv.org/abs/2504.20427v1","title":"Trees in the Largest Order With a Given Burning Number","summary":"Graph burning is modelled upon the spread of contagion, and the burning\nnumber measures the speed of the spread. By the fact that the burning number of\na connected graph is the minimum burning number of its spanning trees, our work\nfocuses on identifying the largest order of a general tree with a given burning\nnumber up to homeomorphism. In this work, we propose the concept of admissible\nsequences over a homeomorphically irreducible tree in addition to developing a\ngeneral framework. We then determine whether an admissible sequence induces a\ntree with a given burning number of the largest order. Additionally, we obtain\nsome results on the smallest attainable diameter of an $n$-spider having the\nlargest order with a given burning number.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T04:45:57Z"}
{"aid":"http://arxiv.org/abs/2504.20435v1","title":"AI Assisted Cervical Cancer Screening for Cytology Samples in Developing\n  Countries","summary":"Cervical cancer remains a significant health challenge, with high incidence\nand mortality rates, particularly in transitioning countries. Conventional\nLiquid-Based Cytology(LBC) is a labor-intensive process, requires expert\npathologists and is highly prone to errors, highlighting the need for more\nefficient screening methods. This paper introduces an innovative approach that\nintegrates low-cost biological microscopes with our simple and efficient AI\nalgorithms for automated whole-slide analysis. Our system uses a motorized\nmicroscope to capture cytology images, which are then processed through an AI\npipeline involving image stitching, cell segmentation, and classification. We\nutilize the lightweight UNet-based model involving human-in-the-loop approach\nto train our segmentation model with minimal ROIs. CvT-based classification\nmodel, trained on the SIPaKMeD dataset, accurately categorizes five cell types.\nOur framework offers enhanced accuracy and efficiency in cervical cancer\nscreening compared to various state-of-art methods, as demonstrated by\ndifferent evaluation metrics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T05:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.20438v1","title":"PixelHacker: Image Inpainting with Structural and Semantic Consistency","summary":"Image inpainting is a fundamental research area between image editing and\nimage generation. Recent state-of-the-art (SOTA) methods have explored novel\nattention mechanisms, lightweight architectures, and context-aware modeling,\ndemonstrating impressive performance. However, they often struggle with complex\nstructure (e.g., texture, shape, spatial relations) and semantics (e.g., color\nconsistency, object restoration, and logical correctness), leading to artifacts\nand inappropriate generation. To address this challenge, we design a simple yet\neffective inpainting paradigm called latent categories guidance, and further\npropose a diffusion-based model named PixelHacker. Specifically, we first\nconstruct a large dataset containing 14 million image-mask pairs by annotating\nforeground and background (potential 116 and 21 categories, respectively).\nThen, we encode potential foreground and background representations separately\nthrough two fixed-size embeddings, and intermittently inject these features\ninto the denoising process via linear attention. Finally, by pre-training on\nour dataset and fine-tuning on open-source benchmarks, we obtain PixelHacker.\nExtensive experiments show that PixelHacker comprehensively outperforms the\nSOTA on a wide range of datasets (Places2, CelebA-HQ, and FFHQ) and exhibits\nremarkable consistency in both structure and semantics. Project page at\nhttps://hustvl.github.io/projects/PixelHacker.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T05:28:36Z"}
{"aid":"http://arxiv.org/abs/2504.20442v1","title":"Multidimensional precipitation index prediction based on CNN-LSTM hybrid\n  framework","summary":"With the intensification of global climate change, accurate prediction of\nweather indicators is of great significance in disaster prevention and\nmitigation, agricultural production, and transportation. Precipitation, as one\nof the key meteorological indicators, plays a crucial role in water resource\nmanagement, agricultural production, and urban flood control. This study\nproposes a multidimensional precipitation index prediction model based on a\nCNN- LSTM hybrid framework, aiming to improve the accuracy of precipitation\nforecasts. The dataset is sourced from Pune, Maharashtra, India, covering\nmonthly mean precipitation data from 1972 to 2002. This dataset includes nearly\n31 years (1972-2002) of monthly average precipitation, reflecting the long-term\nfluctuations and seasonal variations of precipitation in the region. By\nanalyzing these time series data, the CNN-LSTM model effectively captures local\nfeatures and long-term dependencies. Experimental results show that the model\nachieves a root mean square error (RMSE) of 6.752, which demonstrates a\nsignificant advantage over traditional time series prediction methods in terms\nof prediction accuracy and generalization ability. Furthermore, this study\nprovides new research ideas for precipitation prediction. However, the model\nrequires high computational resources when dealing with large-scale datasets,\nand its predictive ability for multidimensional precipitation data still needs\nimprovement. Future research could extend the model to support and predict\nmultidimensional precipitation data, thereby promoting the development of more\naccurate and efficient meteorological prediction technologies.","main_category":"cs.LG","categories":"cs.LG,cs.HC","published":"2025-04-29T05:32:43Z"}
{"aid":"http://arxiv.org/abs/2504.20482v1","title":"Group Relative Knowledge Distillation: Learning from Teacher's\n  Relational Inductive Bias","summary":"Knowledge distillation typically transfers knowledge from a teacher model to\na student model by minimizing differences between their output distributions.\nHowever, existing distillation approaches largely focus on mimicking absolute\nprobabilities and neglect the valuable relational inductive biases embedded in\nthe teacher's relative predictions, leading to exposure bias. In this paper, we\npropose Group Relative Knowledge Distillation (GRKD), a novel framework that\ndistills teacher knowledge by learning the relative ranking among classes,\nrather than directly fitting the absolute distribution. Specifically, we\nintroduce a group relative loss that encourages the student model to preserve\nthe pairwise preference orderings provided by the teacher's outputs. Extensive\nexperiments on classification benchmarks demonstrate that GRKD achieves\nsuperior generalization compared to existing methods, especially in tasks\nrequiring fine-grained class differentiation. Our method provides a new\nperspective on exploiting teacher knowledge, focusing on relational structure\nrather than absolute likelihood.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-29T07:23:22Z"}
{"aid":"http://arxiv.org/abs/2504.20506v1","title":"SPARK Hand: Scooping-Pinching Adaptive Robotic Hand with Kempe Mechanism\n  for Vertical Passive Grasp in Environmental Constraints","summary":"This paper presents the SPARK finger, an innovative passive adaptive robotic\nfinger capable of executing both parallel pinching and scooping grasps. The\nSPARK finger incorporates a multi-link mechanism with Kempe linkages to achieve\na vertical linear fingertip trajectory. Furthermore, a parallelogram linkage\nensures the fingertip maintains a fixed orientation relative to the base,\nfacilitating precise and stable manipulation. By integrating these mechanisms\nwith elastic elements, the design enables effective interaction with surfaces,\nsuch as tabletops, to handle challenging objects. The finger employs a passive\nswitching mechanism that facilitates seamless transitions between pinching and\nscooping modes, adapting automatically to various object shapes and\nenvironmental constraints without additional actuators. To demonstrate its\nversatility, the SPARK Hand, equipped with two SPARK fingers, has been\ndeveloped. This system exhibits enhanced grasping performance and stability for\nobjects of diverse sizes and shapes, particularly thin and flat objects that\nare traditionally challenging for conventional grippers. Experimental results\nvalidate the effectiveness of the SPARK design, highlighting its potential for\nrobotic manipulation in constrained and dynamic environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-29T07:47:06Z"}
{"aid":"http://arxiv.org/abs/2504.20519v1","title":"Conversations with AI Chatbots Increase Short-Term Vaccine Intentions\n  But Do Not Outperform Standard Public Health Messaging","summary":"Large language model (LLM) based chatbots show promise in persuasive\ncommunication, but existing studies often rely on weak controls or focus on\nbelief change rather than behavioral intentions or outcomes. This\npre-registered multi-country (US, Canada, UK) randomized controlled trial\ninvolving 930 vaccine-hesitant parents evaluated brief (three-minute)\nmulti-turn conversations with LLM-based chatbots against standard public health\nmessaging approaches for increasing human papillomavirus (HPV) vaccine\nintentions for their children. Participants were randomly assigned to: (1) a\nweak control (no message), (2) a strong control reflecting the standard of care\n(reading official public health materials), or (3 and 4) one of two chatbot\nconditions. One chatbot was prompted to deliver short, conversational\nresponses, while the other used the model's default output style (longer with\nbullet points). While chatbot interactions significantly increased\nself-reported vaccination intent (by 7.1-10.3 points on a 100-point scale)\ncompared to no message, they did not outperform standard public health\nmaterials, with the conversational chatbot performing significantly worse.\nAdditionally, while the short-term effects of chatbot interactions faded during\na 15-day follow-up, the effects of public health material persisted relative to\nno message. These findings suggest that while LLMs can effectively shift\nvaccination intentions in the short-term, their incremental value over existing\npublic health communications is questionable, offering a more tempered view of\ntheir persuasive capabilities and highlighting the importance of integrating\nAI-driven tools alongside, rather than replacing, current public health\nstrategies.","main_category":"cs.CY","categories":"cs.CY,cs.HC","published":"2025-04-29T07:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.20520v1","title":"PRISM: Projection-based Reward Integration for Scene-Aware\n  Real-to-Sim-to-Real Transfer with Few Demonstrations","summary":"Learning from few demonstrations to develop policies robust to variations in\nrobot initial positions and object poses is a problem of significant practical\ninterest in robotics. Compared to imitation learning, which often struggles to\ngeneralize from limited samples, reinforcement learning (RL) can autonomously\nexplore to obtain robust behaviors. Training RL agents through direct\ninteraction with the real world is often impractical and unsafe, while building\nsimulation environments requires extensive manual effort, such as designing\nscenes and crafting task-specific reward functions. To address these\nchallenges, we propose an integrated real-to-sim-to-real pipeline that\nconstructs simulation environments based on expert demonstrations by\nidentifying scene objects from images and retrieving their corresponding 3D\nmodels from existing libraries. We introduce a projection-based reward model\nfor RL policy training that is supervised by a vision-language model (VLM)\nusing human-guided object projection relationships as prompts, with the policy\nfurther fine-tuned using expert demonstrations. In general, our work focuses on\nthe construction of simulation environments and RL-based policy training,\nultimately enabling the deployment of reliable robotic control policies in\nreal-world scenarios.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-29T08:01:27Z"}
{"aid":"http://arxiv.org/abs/2504.20558v1","title":"Galois measures and the Katz map","summary":"The purpose of this paper is to explain the proofs of the results announced\nby Nick Katz in 1977, namely a description of ``Galois measures for Tate\nmodules of height two formal groups over the ring of integers of a finite\nunramified extension of $\\mathbf{Q}_p$''.","main_category":"math.NT","categories":"math.NT","published":"2025-04-29T09:00:18Z"}
{"aid":"http://arxiv.org/abs/2504.20576v1","title":"From Klein-Gordon-Wave to Schrödinger-Wave: a Normal Form Approach","summary":"In this study, we consider a Klein-Gordon-Wave system, which couples the\nevolution of a massive field and a massless one through a Yukawa interaction\nand we derive its Hamiltonian normal form to second order. To the first-order\napproximation, the normal form results in a Schr\\\"odinger-Wave system, while a\nSchr\\\"odinger-Poisson system is derived in the limit of vanishing perturbative\nparameter. A second-order approximation provides the successive corrections to\nthe Schr\\\"odinger-Wave system, while higher-order approximations can be\nobtained by iterating our constructive procedure.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-29T09:30:42Z"}
{"aid":"http://arxiv.org/abs/2504.20585v1","title":"Rigidity of Complete Free Boundary Minimal Hypersurfaces in Convex NNSC\n  Manifolds","summary":"We prove that in the unit ball of $\\mathbb{R}^4$, there is no complete\ntwo-sided stable free boundary immersion. The result follows from a rigidity\ntheorem of complete free boundary minimal hypersurfaces in complete 4-manifolds\nwith non-negative intermediate Ricci curvature, convex boundary and weakly\nbounded geometry. The method uses warped $\\theta$-bubble, a generalization of\ncapillary surfaces.","main_category":"math.DG","categories":"math.DG","published":"2025-04-29T09:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.20595v1","title":"ReasonIR: Training Retrievers for Reasoning Tasks","summary":"We present ReasonIR-8B, the first retriever specifically trained for general\nreasoning tasks. Existing retrievers have shown limited gains on reasoning\ntasks, in part because existing training datasets focus on short factual\nqueries tied to documents that straightforwardly answer them. We develop a\nsynthetic data generation pipeline that, for each document, our pipeline\ncreates a challenging and relevant query, along with a plausibly related but\nultimately unhelpful hard negative. By training on a mixture of our synthetic\ndata and existing public data, ReasonIR-8B achieves a new state-of-the-art of\n29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a\nwidely-used reasoning-intensive information retrieval (IR) benchmark. When\napplied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4%\nand 22.6% respectively, relative to the closed-book baseline, outperforming\nother retrievers and search engines. In addition, ReasonIR-8B uses test-time\ncompute more effectively: on BRIGHT, its performance consistently increases\nwith longer and more information-rich rewritten queries; it continues to\noutperform other retrievers when combined with an LLM reranker. Our training\nrecipe is general and can be easily extended to future LLMs; to this end, we\nopen-source our code, data, and model.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-29T09:49:28Z"}
{"aid":"http://arxiv.org/abs/2504.20602v1","title":"Purifying, Labeling, and Utilizing: A High-Quality Pipeline for Small\n  Object Detection","summary":"Small object detection is a broadly investigated research task and is\ncommonly conceptualized as a \"pipeline-style\" engineering process. In the\nupstream, images serve as raw materials for processing in the detection\npipeline, where pre-trained models are employed to generate initial feature\nmaps. In the midstream, an assigner selects training positive and negative\nsamples. Subsequently, these samples and features are fed into the downstream\nfor classification and regression. Previous small object detection methods\noften focused on improving isolated stages of the pipeline, thereby neglecting\nholistic optimization and consequently constraining overall performance gains.\nTo address this issue, we have optimized three key aspects, namely Purifying,\nLabeling, and Utilizing, in this pipeline, proposing a high-quality Small\nobject detection framework termed PLUSNet. Specifically, PLUSNet comprises\nthree sequential components: the Hierarchical Feature Purifier (HFP) for\npurifying upstream features, the Multiple Criteria Label Assignment (MCLA) for\nimproving the quality of midstream training samples, and the Frequency\nDecoupled Head (FDHead) for more effectively exploiting information to\naccomplish downstream tasks. The proposed PLUS modules are readily integrable\ninto various object detectors, thus enhancing their detection capabilities in\nmulti-scale scenarios. Extensive experiments demonstrate the proposed PLUSNet\nconsistently achieves significant and consistent improvements across multiple\ndatasets for small object detection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T10:11:03Z"}
{"aid":"http://arxiv.org/abs/2504.20626v1","title":"A Novel Cipher for Enhancing MAVLink Security: Design, Security\n  Analysis, and Performance Evaluation Using a Drone Testbed","summary":"We present MAVShield, a novel lightweight cipher designed to secure\ncommunications in Unmanned Aerial Vehicles (UAVs) using the MAVLink protocol,\nwhich by default transmits unencrypted messages between UAVs and Ground Control\nStations (GCS). While existing studies propose encryption for MAVLink, most\nremain theoretical or simulation-based. We implement MAVShield alongside\nAES-CTR, ChaCha20, Speck-CTR, and Rabbit, and evaluate them on a real drone\ntestbed. A comprehensive security analysis using statistical test suites (NIST\nand Diehard) demonstrates strong resistance of the novel cipher to\ncryptanalysis. Performance evaluation across key metrics including memory\nusage, CPU load, and battery power consumption, demonstrates that MAVShield\noutperforms existing algorithms and offers an efficient, real-world solution\nfor securing MAVLink communications in UAVs.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T10:53:17Z"}
{"aid":"http://arxiv.org/abs/2504.20645v1","title":"LDPoly: Latent Diffusion for Polygonal Road Outline Extraction in\n  Large-Scale Topographic Mapping","summary":"Polygonal road outline extraction from high-resolution aerial images is an\nimportant task in large-scale topographic mapping, where roads are represented\nas vectorized polygons, capturing essential geometric features with minimal\nvertex redundancy. Despite its importance, no existing method has been\nexplicitly designed for this task. While polygonal building outline extraction\nhas been extensively studied, the unique characteristics of roads, such as\nbranching structures and topological connectivity, pose challenges to these\nmethods. To address this gap, we introduce LDPoly, the first dedicated\nframework for extracting polygonal road outlines from high-resolution aerial\nimages. Our method leverages a novel Dual-Latent Diffusion Model with a\nChannel-Embedded Fusion Module, enabling the model to simultaneously generate\nroad masks and vertex heatmaps. A tailored polygonization method is then\napplied to obtain accurate vectorized road polygons with minimal vertex\nredundancy. We evaluate LDPoly on a new benchmark dataset, Map2ImLas, which\ncontains detailed polygonal annotations for various topographic objects in\nseveral Dutch regions. Our experiments include both in-region and cross-region\nevaluations, with the latter designed to assess the model's generalization\nperformance on unseen regions. Quantitative and qualitative results demonstrate\nthat LDPoly outperforms state-of-the-art polygon extraction methods across\nvarious metrics, including pixel-level coverage, vertex efficiency, polygon\nregularity, and road connectivity. We also design two new metrics to assess\npolygon simplicity and boundary smoothness. Moreover, this work represents the\nfirst application of diffusion models for extracting precise vectorized object\noutlines without redundant vertices from remote-sensing imagery, paving the way\nfor future advancements in this field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T11:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.20651v1","title":"Learning and Generalization with Mixture Data","summary":"In many, if not most, machine learning applications the training data is\nnaturally heterogeneous (e.g. federated learning, adversarial attacks and\ndomain adaptation in neural net training). Data heterogeneity is identified as\none of the major challenges in modern day large-scale learning. A classical way\nto represent heterogeneous data is via a mixture model. In this paper, we study\ngeneralization performance and statistical rates when data is sampled from a\nmixture distribution. We first characterize the heterogeneity of the mixture in\nterms of the pairwise total variation distance of the sub-population\ndistributions. Thereafter, as a central theme of this paper, we characterize\nthe range where the mixture may be treated as a single (homogeneous)\ndistribution for learning. In particular, we study the generalization\nperformance under the classical PAC framework and the statistical error rates\nfor parametric (linear regression, mixture of hyperplanes) as well as\nnon-parametric (Lipschitz, convex and H\\\"older-smooth) regression problems. In\norder to do this, we obtain Rademacher complexity and (local) Gaussian\ncomplexity bounds with mixture data, and apply them to get the generalization\nand convergence rates respectively. We observe that as the (regression)\nfunction classes get more complex, the requirement on the pairwise total\nvariation distance gets stringent, which matches our intuition. We also do a\nfiner analysis for the case of mixed linear regression and provide a tight\nbound on the generalization error in terms of heterogeneity.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-29T11:21:15Z"}
{"aid":"http://arxiv.org/abs/2504.20656v1","title":"Federated learning, ethics, and the double black box problem in medical\n  AI","summary":"Federated learning (FL) is a machine learning approach that allows multiple\ndevices or institutions to collaboratively train a model without sharing their\nlocal data with a third-party. FL is considered a promising way to address\npatient privacy concerns in medical artificial intelligence. The ethical risks\nof medical FL systems themselves, however, have thus far been underexamined.\nThis paper aims to address this gap. We argue that medical FL presents a new\nvariety of opacity -- federation opacity -- that, in turn, generates a\ndistinctive double black box problem in healthcare AI. We highlight several\ninstances in which the anticipated benefits of medical FL may be exaggerated,\nand conclude by highlighting key challenges that must be overcome to make FL\nethically feasible in medicine.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CY,cs.HC","published":"2025-04-29T11:31:48Z"}
{"aid":"http://arxiv.org/abs/2504.20678v1","title":"Non-native Children's Automatic Speech Assessment Challenge (NOCASA)","summary":"This paper presents the \"Non-native Children's Automatic Speech Assessment\"\n(NOCASA) - a data competition part of the IEEE MLSP 2025 conference. NOCASA\nchallenges participants to develop new systems that can assess single-word\npronunciations of young second language (L2) learners as part of a gamified\npronunciation training app. To achieve this, several issues must be addressed,\nmost notably the limited nature of available training data and the highly\nunbalanced distribution among the pronunciation level categories. To expedite\nthe development, we provide a pseudo-anonymized training data (TeflonNorL2),\ncontaining 10,334 recordings from 44 speakers attempting to pronounce 205\ndistinct Norwegian words, human-rated on a 1 to 5 scale (number of stars that\nshould be given in the game). In addition to the data, two already trained\nsystems are released as official baselines: an SVM classifier trained on the\nComParE_16 acoustic feature set and a multi-task wav2vec 2.0 model. The latter\nachieves the best performance on the challenge test set, with an unweighted\naverage recall (UAR) of 36.37%.","main_category":"cs.CL","categories":"cs.CL,eess.AS","published":"2025-04-29T11:59:08Z"}
{"aid":"http://arxiv.org/abs/2504.20721v1","title":"Unitary ensembles with a critical edge point, their multiplicative\n  statistics and the Korteweg-de-Vries hierarchy","summary":"We study the multiplicative statistics associated to the limiting\ndeterminantal point process describing unitary random matrices with a critical\nedge point, where limiting density vanishes like a power 5/2. We prove that\nthese statistics are governed by the first three equations of the KdV\nhierarchy, and study the asymptotic behavior of the relevant solutions.","main_category":"math-ph","categories":"math-ph,math.MP,math.PR","published":"2025-04-29T13:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.20726v1","title":"Enhancing Vulnerability Reports with Automated and Augmented Description\n  Summarization","summary":"Public vulnerability databases, such as the National Vulnerability Database\n(NVD), document vulnerabilities and facilitate threat information sharing.\nHowever, they often suffer from short descriptions and outdated or insufficient\ninformation. In this paper, we introduce Zad, a system designed to enrich NVD\nvulnerability descriptions by leveraging external resources. Zad consists of\ntwo pipelines: one collects and filters supplementary data using two encoders\nto build a detailed dataset, while the other fine-tunes a pre-trained model on\nthis dataset to generate enriched descriptions. By addressing brevity and\nimproving content quality, Zad produces more comprehensive and cohesive\nvulnerability descriptions. We evaluate Zad using standard summarization\nmetrics and human assessments, demonstrating its effectiveness in enhancing\nvulnerability information.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.LG","published":"2025-04-29T13:08:27Z"}
{"aid":"http://arxiv.org/abs/2504.20727v1","title":"All-dielectric metasurface polarization scrambler for imaging\n  applications","summary":"Polarization scramblers are essential for many imaging applications involving\npolarization sensitive instruments and partially polarized fluxes. In such\ncases, the light must be depolarized to allow properly calibrated measurements.\nSeveral types of depolarizers are already in use, but none is optimal due to\nthe inevitable image degradation associated with the scrambling process. Here,\nwe present a device based on an all-dielectric metasurface using anisotropic\nscatterers capable of generating multiple polarization states by varying their\norientation angle. Our new scrambling solution allows a massive reduction in\nthe integrated degree of polarization and thus the spatial depolarization of\nany incident linear polarization, while allowing easier integration into the\ninstrument design and reducing the impact on its image quality.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T13:11:40Z"}
{"aid":"http://arxiv.org/abs/2504.20732v1","title":"Bayesian Inference in Quantum Programs","summary":"Conditioning is a key feature in probabilistic programming to enable modeling\nthe influence of data (also known as observations) to the probability\ndistribution described by such programs. Determining the posterior distribution\nis also known as Bayesian inference. This paper equips a quantum while-language\nwith conditioning, defines its denotational and operational semantics over\ninfinite-dimensional Hilbert spaces, and shows their equivalence. We provide\nsufficient conditions for the existence of weakest (liberal)\nprecondition-transformers and derive inductive characterizations of these\ntransformers. It is shown how w(l)p-transformers can be used to assess the\neffect of Bayesian inference on (possibly diverging) quantum programs.","main_category":"cs.LO","categories":"cs.LO,quant-ph","published":"2025-04-29T13:15:54Z"}
{"aid":"http://arxiv.org/abs/2504.20737v1","title":"Path-connectedness of incompressible Euler solutions","summary":"We study the incompressible Euler equation and prove that the set of weak\nsolutions is path-connected. More precisely, we construct paths of H\\\"older\nregularity $C^{1/2}$, valued in $C^0_{t, loc} L^2_x$ endowed with the strong\ntopology. The main result relies on a convex integration construction adapted\nfrom the seminal work of De Lellis and Sz\\'ekelyhidi [14, The Euler equations\nas a differential inclusion], extending it to a more broader geometric\nframework, replacing balls with arbitrary convex compact sets.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T13:21:25Z"}
{"aid":"http://arxiv.org/abs/2504.20738v1","title":"EDD-NSTE: Edge Data Distribution as a Network Steiner Tree Estimation in\n  Edge Computing","summary":"Edge computing is a distributed computing paradigm that brings computation\nand data storage closer to the user's geographical location to improve response\ntimes and save bandwidth. It also helps to power a variety of applications\nrequiring low latency. These application data hosted on the cloud needs to be\ntransferred to the respective edge servers in a specific area to help provide\nlow-latency app functionalities to the users of that area. Meanwhile, these\narbitrary heavy data transactions from the cloud to the edge servers result in\nhigh cost and time penalties. Thus, we need an application data distribution\nstrategy that minimizes these penalties within the app vendors' specific\nlatency constraint. In this work, we provide a refined formulation of an\noptimal approach to solve this Edge Data Distribution (EDD) problem using\nInteger Programming (IP) technique. Due to the time complexity limitation of\nthe IP approach, we suggest an O(k) approximation algorithm based on network\nSteiner tree estimation (EDD-NSTE) for estimating solutions to dense,\nlarge-scale EDD problems. Integer Programming and EDD-NSTE are evaluated on a\nstandard real-world EUA data set and the result demonstrates that EDD-NSTE\nsignificantly outperforms with a performance margin of 86.67% over the other\nthree representative approaches and the state-of-the-art approach.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-29T13:21:27Z"}
{"aid":"http://arxiv.org/abs/2504.20753v1","title":"Vladimirov-Pearson Operators on $ζ$-regular Ultrametric Cantor Sets","summary":"A new operator for certain types of ultrametric Cantor sets is constructed\nusing the measure coming from the spectral triple associated with the Cantor\nset, as well as its zeta function. Under certain mild conditions on that\nmeasure, it is shown that it is an integral operator similar to the\nVladimirov-Taibleson operator on the p-adic integers. Its spectral properties\nare studied, and the Markov property and kernel representation of the heat\nkernel generated by this so-called \\emph{Vladimirov-Pearson} operator is shown,\nviewed as acting on a certain Sobolev space. A large class of these operators\nhave a heat kernel and a Green function explicitly given by the ultrametric\nwavelets on the Cantor set, which are eigenfunctions of the operator.","main_category":"math.AP","categories":"math.AP,math.PR","published":"2025-04-29T13:33:59Z"}
{"aid":"http://arxiv.org/abs/2504.20795v1","title":"Effective Index Construction Algorithm for Optimal $(k,η)$-cores\n  Computation","summary":"Computing $(k,\\eta)$-cores from uncertain graphs is a fundamental problem in\nuncertain graph analysis. UCF-Index is the state-of-the-art resolution to\nsupport $(k,\\eta)$-core queries, allowing the $(k,\\eta)$-core for any\ncombination of $k$ and $\\eta$ to be computed in an optimal time. However, this\nindex constructed by current algorithm is usually incorrect. During\ndecomposition, the key is to obtain the $k$-probabilities of its neighbors when\nthe vertex with minimum $k$-probability is deleted. Current method uses\nrecursive floating-point division to update it, which can lead to serious\nerrors. We propose a correct and efficient index construction algorithm to\naddress this issue. Firstly, we propose tight bounds on the $k$-probabilities\nof the vertices that need to be updated, and the accurate $k$-probabilities are\nrecalculated in an on-demand manner. Secondly, vertices partitioning and\nprogressive refinement strategy is devised to search the vertex with the\nminimum $k$-probability, thereby reducing initialization overhead for each $k$\nand avoiding unnecessary recalculations. Finally, extensive experiments\ndemonstrate the efficiency and scalability of our approach.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-29T14:10:39Z"}
{"aid":"http://arxiv.org/abs/2504.20810v1","title":"Effective Metric Description of Charged Black Holes","summary":"Charged black holes arise as solutions of General Relativity (GR) coupled to\nMaxwell theory. As functions of the mass and charge, they can exhibit extremal\nbehavior, in which case they are stable against thermal decay. (Quantum)\ncorrections to GR are expected to alter the classical features of these\nobjects, especially near extremality. To capture such effects in a\nmodel-independent way, we extend the Effective Metric Description (EMD)\npreviously introduced in [Phys.Rev.D 109 (2024) 2, 024045, Eur.Phys.J.C 84\n(2024) 12, 1273] for spherically symmetric and static black holes. The EMD\nparametrizes deformations of the metric in terms of physical quantities, such\nas the radial spatial distance to the event horizon. While the latter is still\nviable for non-extremal charged black holes, we argue that the proper time of a\nfree-falling observer is better suited in the extremal case: we derive the\nnecessary conditions for the parameters of such an EMD for constructing a\nconsistent space-time in the vicinity of the (extremal) horizon. Finally, we\nillustrate our framework through a concrete example, and mention implications\nof the Weak Gravity Conjecture on the effective metric parameters.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-29T14:23:33Z"}
{"aid":"http://arxiv.org/abs/2504.20832v1","title":"Approximate Quantum Fourier Transform in Logarithmic Depth on a Line","summary":"The approximate quantum Fourier transform (AQFT) on $n$ qubits can be\nimplemented in logarithmic depth using $8n$ qubits with all-to-all\nconnectivity, as shown in [Hales, PhD Thesis Berkeley, 2002]. However,\nrealizing the required all-to-all connectivity can be challenging in practice.\nIn this work, we use dynamic circuits, i.e., mid-circuit measurements and\nfeed-forward operations, to implement the AQFT in logarithmic depth using only\n$4n$ qubits arranged on a line with nearest-neighbor connectivity. Furthermore,\nfor states with a specific structure, the number of qubits can be further\nreduced to $2n$ while keeping the logarithmic depth and line connectivity. As\npart of our construction, we introduce a new implementation of an adder with\nlogarithmic depth on a line, which allows us to improve the AQFT construction\nof Hales.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T14:56:41Z"}
{"aid":"http://arxiv.org/abs/2504.20852v1","title":"Machine Learning (ML)-Physics Fusion Model Outperforms Both Physics-Only\n  and ML-Only Models in Typhoon Predictions","summary":"Data-driven machine learning (ML) models, such as FuXi, exhibit notable\nlimitations in forecasting typhoon intensity and structure. This study presents\na comprehensive evaluation of FuXi-SHTM, a hybrid ML-physics model, using all\n2024 western North Pacific typhoon cases. The FuXi-SHTM hybrid demonstrates\nclear improvements in both track and intensity forecasts compared to the\nstandalone SHTM, FuXi, and ECMWF HRES models. Compared to FuXi alone, FuXi-SHTM\nreduces typhoon track forecast errors by 16.5% and 5.2% at lead times of 72 h\nand 120 h, respectively, and reduces intensity forecast errors by 59.7% and\n47.6%. Furthermore, FuXi-SHTM simulates cloud structures more realistically\ncompared to SHTM, and achieves superior representation of the 10-m wind fields\nin both intensity and spatial structure compared to FuXi and SHTM. Increasing\nthe resolution of FuXi-SHTM from 9 km to 3 km further enhances intensity\nforecasts, highlighting the critical role of the resolution of the physical\nmodel in advancing hybrid forecasting capabilities.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-29T15:21:07Z"}
{"aid":"http://arxiv.org/abs/2504.20860v1","title":"FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language\n  Models","summary":"Textual prompt tuning adapts Vision-Language Models (e.g., CLIP) in federated\nlearning by tuning lightweight input tokens (or prompts) on local client data,\nwhile keeping network weights frozen. Post training, only the prompts are\nshared by the clients with the central server for aggregation. However, textual\nprompt tuning often struggles with overfitting to known concepts and may be\noverly reliant on memorized text features, limiting its adaptability to unseen\nconcepts. To address this limitation, we propose Federated Multimodal Visual\nPrompt Tuning (FedMVP) that conditions the prompts on comprehensive contextual\ninformation -- image-conditioned features and textual attribute features of a\nclass -- that is multimodal in nature. At the core of FedMVP is a PromptFormer\nmodule that synergistically aligns textual and visual features through\ncross-attention, enabling richer contexual integration. The dynamically\ngenerated multimodal visual prompts are then input to the frozen vision encoder\nof CLIP, and trained with a combination of CLIP similarity loss and a\nconsistency loss. Extensive evaluation on 20 datasets spanning three\ngeneralization settings demonstrates that FedMVP not only preserves performance\non in-distribution classes and domains, but also displays higher\ngeneralizability to unseen classes and domains when compared to\nstate-of-the-art methods. Codes will be released upon acceptance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T15:36:51Z"}
{"aid":"http://arxiv.org/abs/2504.20861v1","title":"Simulating Heterogeneity within Elastic and Inelastic Discrete\n  Mechanical Models","summary":"The study investigates the elastic and fracture behaviors of discrete,\nelastically homogeneous models of heterogeneous media. The homogeneity is\naccomplished either by volumetric-deviatoric decomposition of constitutive\nfunction or by an auxiliary stress homogenization method. The elastic\nparameters of the homogenized material models are randomly varied in space to\nintroduce heterogeneity independently of the geometric properties of the\ndiscrete model. Several forms of randomization are investigated using\nstatistical properties of nodal stress oscillations in periodic representative\nvolume elements (RVEs). It is found that the stress oscillations present in\ndiscrete models built on heterogeneous geometric structures with standard\nconstitutive models cannot be replicated by randomization of the elastically\nhomogeneous discrete system. The marginal distributions as well as dependencies\nbetween stress tensor components cannot be adequately matched.\n  With respect to quasi-brittle fracture behavior, the macroscopic response of\nthe different models is studied for the load case of uniaxial tension. The\nelastically homogenized material provides higher peak stress occurring at lower\nstrain levels and a steeper softening phase, compared to the standard material.\nRandomization of the elastic material parameters, as well as adjustment of\ninelastic material parameters, brings the macroscopic response of the\nhomogenized material close to that of the standard material, although the\ndamage distribution prior to the strain localization differs. These findings\nprovide insight into the potential for controlled, random assignment of\nheterogeneity in homogeneous models, using physically-based discretizations of\nmaterial structure with standard constitutive models for comparison.","main_category":"cs.CE","categories":"cs.CE,cond-mat.dis-nn,cond-mat.mtrl-sci","published":"2025-04-29T15:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.20876v1","title":"Chaos Around the Kerr Black Hole: its Effects on Entropy and the Shadow","summary":"Massless or massive particles in unstable orbits around a Kerr black hole\nexhibit chaotic motion when perturbed. They either plunge into the black hole\nor escape to infinity after making some oscillations around the equatorial\nplane. In both of these cases, chaotic motion causes information production. In\nthe case of the photons that escape to infinity, it was recently suggested that\nthis information can be used to resolve the subring structure of the shadow\nimage and obtain more precise data about the black hole mass and spin. Here, we\nextend this method to obtain more precise results by including the\nnon-equatorial contributions to the Lyapunov exponents. In the other case of\nmassive particles that plunge into the Kerr black hole, we show that the\nassociated Kolmogorov-Sinai entropy derived from the Lyapunov exponents can be\ninterpreted in the context of black hole thermodynamics and that it obeys\nBekenstein's bound on the entropy of a physical material system. Thus, the\nperturbed unstable orbits, either ending inside the black hole or at the\nobserver's screen, have physical consequences.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th,math-ph,math.MP","published":"2025-04-29T15:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.20923v1","title":"End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based\n  Approach with Cross-Dataset Evaluation","summary":"Audio deepfakes represent a growing threat to digital security and trust,\nleveraging advanced generative models to produce synthetic speech that closely\nmimics real human voices. Detecting such manipulations is especially\nchallenging under open-world conditions, where spoofing methods encountered\nduring testing may differ from those seen during training. In this work, we\npropose an end-to-end deep learning framework for audio deepfake detection that\noperates directly on raw waveforms. Our model, RawNetLite, is a lightweight\nconvolutional-recurrent architecture designed to capture both spectral and\ntemporal features without handcrafted preprocessing. To enhance robustness, we\nintroduce a training strategy that combines data from multiple domains and\nadopts Focal Loss to emphasize difficult or ambiguous samples. We further\ndemonstrate that incorporating codec-based manipulations and applying\nwaveform-level audio augmentations (e.g., pitch shifting, noise, and time\nstretching) leads to significant generalization improvements under realistic\nacoustic conditions. The proposed model achieves over 99.7% F1 and 0.25% EER on\nin-domain data (FakeOrReal), and up to 83.4% F1 with 16.4% EER on a challenging\nout-of-distribution test set (AVSpoof2021 + CodecFake). These findings\nhighlight the importance of diverse training data, tailored objective functions\nand audio augmentations in building resilient and generalizable audio forgery\ndetectors. Code and pretrained models are available at\nhttps://iplab.dmi.unict.it/mfs/Deepfakes/PaperRawNet2025/.","main_category":"cs.SD","categories":"cs.SD,cs.CV,eess.AS","published":"2025-04-29T16:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.20935v1","title":"Note about the complexity of the acyclic orientation with parity\n  constraint problem","summary":"Let $G = (V, E)$ be a connected graph, and let $T$ in $V$ be a subset of\nvertices. An orientation of $G$ is called $T$-odd if any vertex $v \\in V$ has\nodd in-degree if and only if it is in $T$. Finding a T -odd orientation of G\ncan be solved in polynomial time as shown by Chevalier, Jaeger, Payan and Xuong\n(1983). Since then, $T$-odd orientations have continued to attract interest,\nparticularly in the context of global constraints on the orientation. For\ninstance, Frank and Kir\\'aly (2002) investigated $k$-connected $T$-odd\norientations and raised questions about acyclic $T$-odd orientations. This\nproblem is now recognized as an Egres problem and is known as the \"Acyclic\norientation with parity constraints\" problem. Szegedy ( 005) proposed a\nrandomized polynomial algorithm to address this problem. An easy consequence of\nhis work provides a polynomial time algorithm for planar graphs whenever $|T |\n= |V | - 1$. Nevertheless, it remains unknown whether it exists in general. In\nthis paper we contribute to the understanding of the complexity of this problem\nby studying a more general one. We prove that finding a $T$-odd acyclic\norientation on graphs having some directed edges is NP-complete.","main_category":"cs.DM","categories":"cs.DM,math.CO","published":"2025-04-29T16:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.20955v1","title":"Egret-1: Pretrained Neural Network Potentials For Efficient and Accurate\n  Bioorganic Simulation","summary":"Accurate simulation of atomic systems has the potential to revolutionize the\ndesign of molecules and materials. Unfortunately, exact solutions of the\nSchr\\\"odinger equation scale as O(N!) and remain inaccessible for systems with\nmore than a handful of atoms, forcing scientists to accept steep tradeoffs\nbetween speed and accuracy and limiting the reliability and utility of the\nresultant simulations. Recent work in machine learning has demonstrated that\nneural network potentials (NNPs) can learn efficient approximations to quantum\nmechanics and resolve this tradeoff, but existing NNPs still suffer from\nlimited accuracy relative to state-of-the-art quantum-chemical methods. Here,\nwe present Egret-1, a family of large pre-trained NNPs based on the MACE\narchitecture with general applicability to main-group, organic, and\nbiomolecular chemistry. We find that the Egret-1 models equal or exceed the\naccuracy of routinely employed quantum-chemical methods on a variety of\nstandard tasks, including torsional scans, conformer ranking, and geometry\noptimization, while offering multiple-order-of-magnitude speedups relative to\nlegacy methods. We also highlight important lacunae for future NNP research to\ninvestigate, and suggest strategies for building future high-quality models\nwith increased scale and generality.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-29T17:26:21Z"}
{"aid":"http://arxiv.org/abs/2504.20975v1","title":"Linear function of a poset","summary":"Stanley and Grinberg introduced a symmetric function associated with digraphs\nand named it the Redei-Berge symmetric function. This function arises from a\nsuitable combinatorial Hopf algebra on digraphs, which made it possible to\nassign the Redei-Berge function to posets. In this paper, we define a new\ncombinatorial Hopf algebra of posets whose character is a close cousin of the\nRedei-Berge character for posets. Further, we investigate the properties of the\nsymmetric function that arises from this algebra and explore its expansions in\nvarious natural bases of $QSym$ and $Sym$. Finally, we obtain an interesting\nmethod for decomposing a poset.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T17:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.20981v1","title":"Optical Activity of Group III-V Quantum Dots Directly Embedded in\n  Silicon","summary":"Optically active III-V group semiconductor quantum dots (QDs) are the leading\nelement of the upcoming safe quantum communication. However, the entire\nelectronic and IT infrastructure relies on silicon-based devices, with silicon\nalso providing a natural platform for photonic integration. Combining\nsemiconductor optics with silicon electronics is thus a major technological\nchallenge. This obstacle cannot be directly solved because silicon is optically\ninactive. Interfacing III-V quantum dots with silicon is thus a sought-after\nsolution. A radical approach is to embed III-V material grains directly into\nsilicon. The first realization of such technology was developed, and it gave\nInAs and core-shell InAs/GaAs QDs embedded in Si with bright and narrow\nsingle-QD emission lines. No theory has been given, though, and, as we show\nhere, it is not even obvious if and how such QDs can be optically active. We\nfirst use general arguments, also supported by atomistic calculations, that\nInAs/Si QDs cannot confine both carrier types unless the structural strain is\nmostly relaxed, meaning many defects at the interface. This explains the lack\nof light emission from those dots. Then we show that the InAs/GaAs/Si QDs can\nconfine both carrier types. Their electron states are, however, highly\ninfluenced by $k$-space valley mixing, which impacts emission spectra and\ndeteriorates optical properties. We propose to overcome this by adding an\nadditional wider-bandgap material layer.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-29T17:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.20996v1","title":"X-Fusion: Introducing New Modality to Frozen Large Language Models","summary":"We propose X-Fusion, a framework that extends pretrained Large Language\nModels (LLMs) for multimodal tasks while preserving their language\ncapabilities. X-Fusion employs a dual-tower design with modality-specific\nweights, keeping the LLM's parameters frozen while integrating vision-specific\ninformation for both understanding and generation. Our experiments demonstrate\nthat X-Fusion consistently outperforms alternative architectures on both\nimage-to-text and text-to-image tasks. We find that incorporating\nunderstanding-focused data improves generation quality, reducing image data\nnoise enhances overall performance, and feature alignment accelerates\nconvergence for smaller models but has minimal impact on larger ones. Our\nfindings provide valuable insights into building efficient unified multimodal\nmodels.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T17:59:45Z"}
{"aid":"http://arxiv.org/abs/2504.21258v1","title":"On a phase field model for binary mixtures of micropolar fluids with\n  non-matched densities and moving contact lines","summary":"We introduce a new phase field model for binary mixtures of incompressible\nmicropolar fluids, which are among the simplest categories of fluids exhibiting\ninternal rotations. The model fulfils local and global dissipation inequalities\nso that thermodynamic consistency is guaranteed. Our model consists of a\nNavier--Stokes--Cahn--Hilliard system for the fluid velocity, pressure, phase\nfield variable and chemical potential, coupled to an additional system of\nNavier--Stokes type for the micro-rotation. Our model accounts for non-matched\ndensities as well as moving contact line dynamics, and serve as a\ngeneralisation to earlier models for binary fluid flows based on a volume\naveraged velocity formulation. We also establish the existence of global weak\nsolutions in three spatial dimensions for the model equipped with singular\nlogarithmic and double obstacle potentials.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T02:17:19Z"}
{"aid":"http://arxiv.org/abs/2504.21259v1","title":"LSTM+Geo with xgBoost Filtering: A Novel Approach for Race and Ethnicity\n  Imputation with Reduced Bias","summary":"Accurate imputation of race and ethnicity (R&E) is crucial for analyzing\ndisparities and informing policy. Methods like Bayesian Improved Surname\nGeocoding (BISG) are widely used but exhibit limitations, including systematic\nmisclassification biases linked to socioeconomic status. This paper introduces\nLSTM+Geo, a novel approach enhancing Long Short-Term Memory (LSTM) networks\nwith census tract geolocation information. Using a large voter dataset, we\ndemonstrate that LSTM+Geo (88.7% accuracy) significantly outperforms standalone\nLSTM (86.4%) and Bayesian methods like BISG (82.9%) and BIFSG (86.8%) in\naccuracy and F1-score on a held-out validation set. LSTM+Geo reduces the rate\nat which non-White individuals are misclassified as White (White FPR 19.3%)\ncompared to name-only LSTMs (White FPR 24.6%). While sophisticated ensemble\nmethods incorporating XGBoost achieve the highest overall accuracy (up to\n89.4%) and lowest White FPR (17.8%), LSTM+Geo offers strong standalone\nperformance with improved bias characteristics compared to baseline models.\nIntegrating LSTM+Geo into an XGBoost ensemble further boosts accuracy,\nhighlighting its utility as both a standalone model and a component for\nadvanced systems. We give a caution at the end regarding the appropriate use of\nthese methods.","main_category":"cs.CY","categories":"cs.CY,cs.LG","published":"2025-04-30T02:20:08Z"}
{"aid":"http://arxiv.org/abs/2504.21260v1","title":"Power Flow Approximations for Multiphase Distribution Networks using\n  Gaussian Processes","summary":"Learning-based approaches are increasingly leveraged to manage and coordinate\nthe operation of grid-edge resources in active power distribution networks.\nAmong these, model-based techniques stand out for their superior data\nefficiency and robustness compared to model-free methods. However, effective\nmodel learning requires a learning-based approximator for the underlying power\nflow model. This study extends existing work by introducing a data-driven power\nflow method based on Gaussian Processes (GPs) to approximate the multiphase\npower flow model, by mapping net load injections to nodal voltages. Simulation\nresults using the IEEE 123-bus and 8500-node distribution test feeders\ndemonstrate that the trained GP model can reliably predict the nonlinear power\nflow solutions with minimal training data. We also conduct a comparative\nanalysis of the training efficiency and testing performance of the proposed\nGP-based power flow approximator against a deep neural network-based\napproximator, highlighting the advantages of our data-efficient approach.\nResults over realistic operating conditions show that despite an 85% reduction\nin the training sample size (corresponding to a 92.8% improvement in training\ntime), GP models produce a 99.9% relative reduction in mean absolute error\ncompared to the baselines of deep neural networks.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-30T02:26:31Z"}
{"aid":"http://arxiv.org/abs/2504.21265v1","title":"Quantifying Flat-Band Voltage in Si Metal-Oxide-Semiconductor\n  Structures: An Evaluation via Terahertz Emission Spectroscopy (TES)","summary":"Laser-induced Terahertz (THz) Emission Spectroscopy (TES) has demonstrated\nits potential utility in the realm of Metal-Oxide-Semiconductor (MOS) devices\nas an expedient and noncontact estimation methodology. Owing to its discerning\nresponse to the interface electric field, the amplitude of the THz emission\npeak in time-domain spectroscopy encapsulates rich information regarding MOS\nproperties, notably the flat-band voltage. This paper concentrates on the\nprecise quantitative estimation of the flat-band voltage within the Si MOS\nstructure, elucidating the intricacies of the estimation process through the\nTHz emission model.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-30T02:49:09Z"}
{"aid":"http://arxiv.org/abs/2504.21267v1","title":"Searching beyond the fiducial stochastic gravitational wave background\n  in pulsar timing array data using likelihood reweighting","summary":"Since the recent announcements of evidence for a stochastic gravitational\nwave background from several pulsar timing array collaborations, much effort\nhas been devoted to explore features beyond the fiducial Hellings-Downs\nbackground including those arising in modified gravity theories and\ndeterministic gravitational wave signals. Inspired by previous studies, we\npropose a method to efficiently screen these models using likelihood\nreweighting based on the fiducial model. In order to alleviate the well-known\nunstable weight estimates in vanilla importance sampling, we implement\nreweighting for the second time making use of the kernel density estimation of\nthe previously reweighted samples. We tested this method by analyzing three\nsimulated datasets with an injected sinusoid signal applied to all pulsars. It\nis found that likelihood reweighting not only gives results compatible with\nthose from full Bayesian analyses when the signal is subdominant, but is also\nable to recover the signal posterior to a reasonable accuracy in the presence\nof a rather strong signal. Given samples from the fiducial model, this method\ncould bring an at least $\\mathcal{O}(10)$-time speedup in analyzing new models.","main_category":"gr-qc","categories":"gr-qc,astro-ph.IM","published":"2025-04-30T02:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.21303v1","title":"Confidence in Large Language Model Evaluation: A Bayesian Approach to\n  Limited-Sample Challenges","summary":"Large language models (LLMs) exhibit probabilistic output characteristics,\nyet conventional evaluation frameworks rely on deterministic scalar metrics.\nThis study introduces a Bayesian approach for LLM capability assessment that\nintegrates prior knowledge through probabilistic inference, addressing\nlimitations under limited-sample regimes. By treating model capabilities as\nlatent variables and leveraging a curated query set to induce discriminative\nresponses, we formalize model ranking as a Bayesian hypothesis testing problem\nover mutually exclusive capability intervals. Experimental evaluations with\nGPT-series models demonstrate that the proposed method achieves superior\ndiscrimination compared to conventional evaluation methods. Results indicate\nthat even with reduced sample sizes, the approach maintains statistical\nrobustness while providing actionable insights, such as probabilistic\nstatements about a model's likelihood of surpassing specific baselines. This\nwork advances LLM evaluation methodologies by bridging Bayesian inference with\npractical constraints in real-world deployment scenarios.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T04:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.21323v1","title":"How to Backdoor the Knowledge Distillation","summary":"Knowledge distillation has become a cornerstone in modern machine learning\nsystems, celebrated for its ability to transfer knowledge from a large, complex\nteacher model to a more efficient student model. Traditionally, this process is\nregarded as secure, assuming the teacher model is clean. This belief stems from\nconventional backdoor attacks relying on poisoned training data with backdoor\ntriggers and attacker-chosen labels, which are not involved in the distillation\nprocess. Instead, knowledge distillation uses the outputs of a clean teacher\nmodel to guide the student model, inherently preventing recognition or response\nto backdoor triggers as intended by an attacker. In this paper, we challenge\nthis assumption by introducing a novel attack methodology that strategically\npoisons the distillation dataset with adversarial examples embedded with\nbackdoor triggers. This technique allows for the stealthy compromise of the\nstudent model while maintaining the integrity of the teacher model. Our\ninnovative approach represents the first successful exploitation of\nvulnerabilities within the knowledge distillation process using clean teacher\nmodels. Through extensive experiments conducted across various datasets and\nattack settings, we demonstrate the robustness, stealthiness, and effectiveness\nof our method. Our findings reveal previously unrecognized vulnerabilities and\npave the way for future research aimed at securing knowledge distillation\nprocesses against backdoor attacks.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.LG","published":"2025-04-30T05:19:23Z"}
{"aid":"http://arxiv.org/abs/2504.21385v1","title":"IDDM: Bridging Synthetic-to-Real Domain Gap from Physics-Guided\n  Diffusion for Real-world Image Dehazing","summary":"Due to the domain gap between real-world and synthetic hazy images, current\ndata-driven dehazing algorithms trained on synthetic datasets perform well on\nsynthetic data but struggle to generalize to real-world scenarios. To address\nthis challenge, we propose \\textbf{I}mage \\textbf{D}ehazing \\textbf{D}iffusion\n\\textbf{M}odels (IDDM), a novel diffusion process that incorporates the\natmospheric scattering model into noise diffusion. IDDM aims to use the gradual\nhaze formation process to help the denoising Unet robustly learn the\ndistribution of clear images from the conditional input hazy images. We design\na specialized training strategy centered around IDDM. Diffusion models are\nleveraged to bridge the domain gap from synthetic to real-world, while the\natmospheric scattering model provides physical guidance for haze formation.\nDuring the forward process, IDDM simultaneously introduces haze and noise into\nclear images, and then robustly separates them during the sampling process. By\ntraining with physics-guided information, IDDM shows the ability of domain\ngeneralization, and effectively restores the real-world hazy images despite\nbeing trained on synthetic datasets. Extensive experiments demonstrate the\neffectiveness of our method through both quantitative and qualitative\ncomparisons with state-of-the-art approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T07:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.21386v1","title":"Power Suppression and Lensing Anomaly -- A phenomenological\n  investigation","summary":"Primordial power spectra with low power at long wavelengths can alleviate\nlensing anomaly. However the extent to which data favours such a primordial\nspectra is not clear. In this work, we investigate power suppression and\nrelated mitigation of lensing anomaly with the help of phenomenological models\nwhich are valid over scales of interest. We consider simple extensions to\nnearly scale invariant power spectra such as those which includes running and\nrunning of running of spectral index. We perform Bayesian analysis of these\nmodels, which are agnostic about power suppression, with various data sets and\nshow that data tend to choose parameters which leads to power suppression at\nlow multipoles. We then analyse the significance of these findings using\ninformation criteria. Further, we investigate the ability of near-ultimate\nfuture CMB missions such as ECHO to put tighter constraints on these models. We\nconclude that we can make stronger conclusions about the presence of power\nsuppression in the future by studying such simple phenomenological models.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-30T07:37:11Z"}
{"aid":"http://arxiv.org/abs/2504.21413v1","title":"An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and\n  Applications to Streaming Differential Privacy","summary":"Buffered Linear Toeplitz (BLT) matrices are a family of parameterized\nlower-triangular matrices that play an important role in streaming differential\nprivacy with correlated noise. Our main result is a BLT inversion theorem: the\ninverse of a BLT matrix is itself a BLT matrix with different parameters. We\nalso present an efficient and differentiable $O(d^3)$ algorithm to compute the\nparameters of the inverse BLT matrix, where $d$ is the degree of the original\nBLT (typically $d < 10$). Our characterization enables direct optimization of\nBLT parameters for privacy mechanisms through automatic differentiation.","main_category":"cs.CR","categories":"cs.CR,eess.SP","published":"2025-04-30T08:14:09Z"}
{"aid":"http://arxiv.org/abs/2504.21439v1","title":"Further results on arithmetic properties of biregular overpartitions","summary":"Recently there has been quite a bit of study carried out related to\narithmetic properties of overpartitions into non-multiples of two co-prime\nintegers. The paper [19] by Nadji et al. looked into congruences modulo $3$ and\npowers of $2$ for certain specific pairs of co-prime integers, while the paper\n[1] by Alanazi et al. investigated some congruences related to some similar and\nsome different pairs of co-prime integers. In this paper we propose some\nelegant and elementary proofs of a subset of the congruences given in [1] by\nusing only theta function and dissection identities. We also propose a generic\nmethod for proving congruences modulo $8$ which doesn't necessarily use any\nspecific $2$-dissection.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T08:55:25Z"}
{"aid":"http://arxiv.org/abs/2504.21444v1","title":"A Unified QoS-Aware Multiplexing Framework for Next Generation Immersive\n  Communication with Legacy Wireless Applications","summary":"Immersive communication, including emerging augmented reality, virtual\nreality, and holographic telepresence, has been identified as a key service for\nenabling next-generation wireless applications. To align with legacy wireless\napplications, such as enhanced mobile broadband or ultra-reliable low-latency\ncommunication, network slicing has been widely adopted. However, attempting to\nstatistically isolate the above types of wireless applications through\ndifferent network slices may lead to throughput degradation and increased queue\nbacklog. To address these challenges, we establish a unified QoS-aware\nframework that supports immersive communication and legacy wireless\napplications simultaneously. Based on the Lyapunov drift theorem, we transform\nthe original long-term throughput maximization problem into an equivalent\nshort-term throughput maximization weighted by virtual queue length. Moreover,\nto cope with the challenges introduced by the interaction between\nlarge-timescale network slicing and short-timescale resource allocation, we\npropose an adaptive adversarial slicing (Ad2S) scheme for networks with\ninvarying channel statistics. To track the network channel variations, we also\npropose a measurement extrapolation-Kalman filter (ME-KF)-based method and\nrefine our scheme into Ad2S-non-stationary refinement (Ad2S-NR). Through\nextended numerical examples, we demonstrate that our proposed schemes achieve\n3.86 Mbps throughput improvement and 63.96\\% latency reduction with 24.36\\%\nconvergence time reduction. Within our framework, the trade-off between total\nthroughput and user service experience can be achieved by tuning systematic\nparameters.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-30T08:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.21485v1","title":"Monolayer C$_{60}$ networks: A first-principles perspective","summary":"Monolayer fullerene (C$_{60}$) networks combine molecular-level rigidity with\ncrystalline connectivity, offering a promising platform for numerous\napplications. In this Feature article, we review the physical and chemical\nproperties of fullerene monolayers, focusing on first-principles studies. We\nfirst explore the structural stability of monolayer phases and investigate\ntheir thermal expansion behaviours. We then outline criteria for photocatalytic\nwater splitting and introduce theoretical predictions which are supported by\nrecent experimental verification. Finally, we show how interlayer stacking,\nmolecular size, and dimensional tuning (from 2D monolayers into 3D crystals, 1D\nchains, or nanoribbons) offer versatile approaches to modulate their chemical\nfunctionality. Together, these insights establish fullerene networks as a novel\nclass of carbon-based materials with tailored properties for catalysis,\nphotovoltaics, and flexible electronics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.app-ph,physics.atm-clus,physics.chem-ph","published":"2025-04-30T10:09:45Z"}
{"aid":"http://arxiv.org/abs/2504.21510v1","title":"A simple approach for power density calculation of spontaneous radiation\n  emission from a finite emittance electron beam in planar undulators","summary":"We extend the angular power density formulae for spontaneous radiation\nemission from planar undulators to include finite emittance and angular\nmisalignment of the electron beam. Then we calculate and compare power\ndensities estimated from integral approach with Gaussian beam distribution and\nsummation approach with the macro-particle allocation covering the particle\nbeam phase space. After showing that both approaches converge to each other, we\napply the macro-particle approach to study power absorbed and transmitted by\nvarious apertures at the front end of the 9-ID beamline at the National\nSynchrotron Light Source-II. Our analysis indicate that the electron beam\nmisalignment could lead to unwarranted power deposition at tighter apertures\nthat would have been otherwise difficult to account in the aperture\ndesign/choice process using the geometric ray-tracing approach.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-30T10:58:36Z"}
{"aid":"http://arxiv.org/abs/2504.21519v1","title":"K-moduli of quasimaps and quasi-projectivity of moduli of K-stable\n  Calabi-Yau fibrations over curves","summary":"We construct a projective K-moduli space of quasimaps with a certain log Fano\ncondition.\n  Moreover, we investigate relationships between the K-moduli of quasimaps and\nthe K-moduli of Calabi-Yau fibrations over curves of negative Kodaira dimension\nconstructed by the authors [HaHa23] when general fibers are Abelian varieties\nor irreducible holomorphic symplectic manifolds.\n  We show that there is a quasi-finite morphism from the K-moduli of Calabi-Yau\nfibrations to the K-moduli of quasimaps and the CM line bundle of the K-moduli\nof Calabi-Yau fibrations converges to the CM line bundle of the K-moduli of\nquasimaps.\n  As a corollary, we obtain the entire quasi-projectivity of K-moduli of\nCalabi-Yau fibrations in this case.","main_category":"math.AG","categories":"math.AG,math.DG","published":"2025-04-30T11:14:58Z"}
{"aid":"http://arxiv.org/abs/2504.21520v1","title":"Padding Matters -- Exploring Function Detection in PE Files","summary":"Function detection is a well-known problem in binary analysis. While previous\nresearch has primarily focused on Linux/ELF, Windows/PE binaries have been\noverlooked or only partially considered. This paper introduces FuncPEval, a new\ndataset for Windows x86 and x64 PE files, featuring Chromium and the Conti\nransomware, along with ground truth data for 1,092,820 function starts.\nUtilizing FuncPEval, we evaluate five heuristics-based (Ghidra, IDA, Nucleus,\nrev.ng, SMDA) and three machine-learning-based (DeepDi, RNN, XDA) function\nstart detection tools. Among the tested tools, IDA achieves the highest\nF1-score (98.44%) for Chromium x64, while DeepDi closely follows (97%) but\nstands out as the fastest by a significant margin. Working towards\nexplainability, we examine the impact of padding between functions on the\ndetection results. Our analysis shows that all tested tools, except rev.ng, are\nsusceptible to randomized padding. The randomized padding significantly\ndiminishes the effectiveness for the RNN, XDA, and Nucleus. Among the\nlearning-based tools, DeepDi exhibits the least sensitivity and demonstrates\noverall the fastest performance, while Nucleus is the most adversely affected\namong non-learning-based tools. In addition, we improve the recurrent neural\nnetwork (RNN) proposed by Shin et al. and enhance the XDA tool, increasing the\nF1-score by approximately 10%.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-30T11:15:09Z"}
{"aid":"http://arxiv.org/abs/2504.21526v1","title":"Physics-Informed Priors Improve Gravitational-Wave Constraints on\n  Neutron-Star Matter","summary":"Gravitational-wave astronomy shows great promise in determining nuclear\nphysics in a regime not accessible to terrestrial experiments. We introduce\nphysics-informed priors constrained by nuclear theory and perturbative Quantum\nChromodynamics calculations, as well as astrophysical measurements of\nneutron-star masses and radii. When these priors are used in gravitational-wave\nastrophysical inference, we show a significant improvement on nuclear equation\nof state constraints. Applying these to the first observed gravitational-wave\nbinary neutron-star merger GW170817, the constraints on the radius of a\n$1.4\\,M_\\odot$ neutron star improve from $R_{1.4} ={12.54^{+1.05}_{-1.54}} \\,\n{\\rm km}$ to $R_{1.4} = 12.11^{+0.91}_{-1.11} \\,{\\rm km}$ and those on the\ntidal deformability from $\\tilde{\\Lambda}_{1.186} < 720$ to\n$\\tilde{\\Lambda}_{1.186} = 384^{+306}_{-158}$ ($90\\%$ confidence intervals) at\nthe events measured chirp mass $\\mathcal{M}=1.186\\,M_\\odot$. We also show these\npriors can be used to perform model selection between binary neutron star and\nneutron star-black hole mergers; in the case of GW190425, the results provide\nonly marginal evidence with a Bayes factor $\\mathcal{BF}=1.33$ in favour of the\nbinary neutron star merger hypothesis. Given their ability to improve the\nastrophysical inference of binary mergers involving neutron stars, we advocate\nfor these physics-informed priors to be used as standard in the literature and\nprovide open-source code for reproducibility and adaptation of the method.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,nucl-th","published":"2025-04-30T11:19:52Z"}
{"aid":"http://arxiv.org/abs/2504.21530v1","title":"RoboGround: Robotic Manipulation with Grounded Vision-Language Priors","summary":"Recent advancements in robotic manipulation have highlighted the potential of\nintermediate representations for improving policy generalization. In this work,\nwe explore grounding masks as an effective intermediate representation,\nbalancing two key advantages: (1) effective spatial guidance that specifies\ntarget objects and placement areas while also conveying information about\nobject shape and size, and (2) broad generalization potential driven by\nlarge-scale vision-language models pretrained on diverse grounding datasets. We\nintroduce RoboGround, a grounding-aware robotic manipulation system that\nleverages grounding masks as an intermediate representation to guide policy\nnetworks in object manipulation tasks. To further explore and enhance\ngeneralization, we propose an automated pipeline for generating large-scale,\nsimulated data with a diverse set of objects and instructions. Extensive\nexperiments show the value of our dataset and the effectiveness of grounding\nmasks as intermediate guidance, significantly enhancing the generalization\nabilities of robot policies.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-30T11:26:40Z"}
{"aid":"http://arxiv.org/abs/2504.21531v1","title":"A Numerical scheme to approximate the solution of the planar Skorokhod\n  embedding problem","summary":"We present a numerical framework to approximate the $\\mu$-domain in the\nplanar Skorokhod embedding problem (PSEP), recently appeared in\n\\cite{gross2019}. Our approach investigates the continuity and convergence\nproperties of the solutions with respect to the underlying distribution $\\mu$.\nWe establish that, under weak convergence of a sequence of probability measures\n$(\\mu_n)$ with bounded support, the corresponding sequence of $\\mu_n$-domains\nconverges to the domain associated with $\\mu$, limit of $(\\mu_n)$. We derive\nexplicit convergence results in the $L^1$ norm, supported by a generalization\nusing the concept of $\\alpha_p$-convergence. Furthermore, we provide practical\nimplementation techniques, convergence rate estimates, and numerical\nsimulations using various distributions. The method proves robust and\nadaptable, offering a concrete computational pathway for approximating\n$\\mu$-domains in the PSEP.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T11:27:23Z"}
{"aid":"http://arxiv.org/abs/2504.21556v1","title":"On persistent energy currents at equilibrium in non-reciprocal systems","summary":"We investigate the properties of the mean Poynting vector in global thermal\nequilibrium, which can be non-zero in non-reciprocal electromagnetic systems.\nUsing dyadic Green's functions and the fluctuation-dissipation theorem, we\nprovide a general proof that the mean Poynting vector is divergence-free under\nequilibrium conditions. Relying on this proof, we explicitly demonstrate that\nfor systems where a normal mode expansion of the Green's function is\napplicable, the divergence of the equilibrium mean Poynting vector vanishes. As\nconcrete examples, we also examine the equilibrium mean Poynting vector near a\nplanar non-reciprocal substrate and in configurations involving an arbitrary\nnumber of dipolar non-reciprocal objects in free space. Finally, we argue that\nthe so-called persistent heat current, while present in equilibrium, cannot be\ndetected through out-of-equilibrium heat transfer measurements.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-30T11:54:41Z"}
{"aid":"http://arxiv.org/abs/2504.21570v1","title":"Extended self-similarity in two-dimensional complex plasmas","summary":"Self-similarity is a property of an object or process wherein a part is\nsimilar to the whole. Mathematically, it can often be expressed as a power-law\nscaling of the quantity of interest. Extended self-similarity is a concept\nwidely used in the field of turbulence and refers to the power-law scaling of\nthe longitudinal structure functions of the velocity field expressed through\nthe structure functions of different orders, rather than distance. Originally\ndiscovered by [R. Benzi et al., Phys. Rev. E 48, R29 (1993)] in fully developed\nturbulence, it was later found to hold in other situations and systems as well.\nIn this paper, we show that in an active-matter system, extended\nself-similarity is possible even without the presence of respective power-law\nscaling in the underlying structure functions of distance. The active-matter\nsystem used in this study was a single-layer suspension of active Janus\nparticles in a plasma. Janus particles are polymer microspheres with\nhemispherical metal coating. When dispersed in a plasma, they acquire\nself-propulsion and act as microswimmers. Extended self-similarity was also\nobserved in the velocity field of a single-layer suspension of laser-heated\nregular (passive) particles, where the underlying structure functions displayed\na hint of the power-law scaling near the mean interparticle distance.\nTherefore, it appears to be an inherent characteristic of complex plasmas.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-30T12:16:30Z"}
{"aid":"http://arxiv.org/abs/2504.21611v1","title":"Prospects for new glueballs and exotics searches","summary":"Glueballs and Hybrids are solid predictions of QCD, but none have this far\nbeen identified in an undisputable way. We list several strategies, including\nthe very promising search for \"cascade\" decays of glueballs and hybrids into\neach others, and mention the yet under-exploited sources in heavy ion\ncollisions","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-30T13:09:19Z"}
{"aid":"http://arxiv.org/abs/2504.21613v1","title":"ODE and PDE models for COVID-19, with reinfection and vaccination\n  process for Cameroon and Germany","summary":"The goal of this work is to develop and analyze a reaction-diffusion model\nfor the transmission dynamics of the Coronavirus (COVID-19) that accounts for\nreinfection and vaccination, as well as to compare it to the ODE model. After\ndeveloping a time-dependent ODE model, we calculate the control reproduction\nnumber $\\mathcal{R}_c$ and demonstrate the global stability of the COVID-19\nfree equilibrium for $\\mathcal{R}_c<1$. We also show that when\n$\\mathcal{R}_c>1$, the free equilibrium of COVID-19 becomes unstable and\nco-exists with at least one endemic equilibrium point. We then used data from\nGermany and Cameroon to calibrate our model and estimate some of its\ncharacteristics. We find $\\mathcal{R}_c\\approx 1.13$ for Germany and $\\mathcal\nR_c \\approx 1.2554$ for Cameroon, indicating that the disease persists in both\npopulations. Following that, we modify the prior model into a\nreaction-diffusion PDE model to account for spatial mobility. We show that the\nsolutions to the final initial value boundary problem (IVBP) exist and are\nnonnegative and unique. We also show that the disease-free equilibrium is\nstable locally, and globally when $\\mathcal{R}_c<1$. In contrast, when\n$\\mathcal{R}_c>1$, the DFE is unstable and coexists with at least one endemic\nequilibrium point. We ran multiple numerical simulations to validate our\ntheoretical predictions. We then compare the ODE and the PDE models.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T13:09:44Z"}
{"aid":"http://arxiv.org/abs/2504.21627v1","title":"LSNIF: Locally-Subdivided Neural Intersection Function","summary":"Neural representations have shown the potential to accelerate ray casting in\na conventional ray-tracing-based rendering pipeline. We introduce a novel\napproach called Locally-Subdivided Neural Intersection Function (LSNIF) that\nreplaces bottom-level BVHs used as traditional geometric representations with a\nneural network. Our method introduces a sparse hash grid encoding scheme\nincorporating geometry voxelization, a scene-agnostic training data collection,\nand a tailored loss function. It enables the network to output not only\nvisibility but also hit-point information and material indices. LSNIF can be\ntrained offline for a single object, allowing us to use LSNIF as a replacement\nfor its corresponding BVH. With these designs, the network can handle hit-point\nqueries from any arbitrary viewpoint, supporting all types of rays in the\nrendering pipeline. We demonstrate that LSNIF can render a variety of scenes,\nincluding real-world scenes designed for other path tracers, while achieving a\nmemory footprint reduction of up to 106.2x compared to a compressed BVH.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-30T13:29:42Z"}
{"aid":"http://arxiv.org/abs/2504.21650v1","title":"HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene\n  Generation","summary":"The rapid advancement of diffusion models holds the promise of\nrevolutionizing the application of VR and AR technologies, which typically\nrequire scene-level 4D assets for user experience. Nonetheless, existing\ndiffusion models predominantly concentrate on modeling static 3D scenes or\nobject-level dynamics, constraining their capacity to provide truly immersive\nexperiences. To address this issue, we propose HoloTime, a framework that\nintegrates video diffusion models to generate panoramic videos from a single\nprompt or reference image, along with a 360-degree 4D scene reconstruction\nmethod that seamlessly transforms the generated panoramic video into 4D assets,\nenabling a fully immersive 4D experience for users. Specifically, to tame video\ndiffusion models for generating high-fidelity panoramic videos, we introduce\nthe 360World dataset, the first comprehensive collection of panoramic videos\nsuitable for downstream 4D scene reconstruction tasks. With this curated\ndataset, we propose Panoramic Animator, a two-stage image-to-video diffusion\nmodel that can convert panoramic images into high-quality panoramic videos.\nFollowing this, we present Panoramic Space-Time Reconstruction, which leverages\na space-time depth estimation method to transform the generated panoramic\nvideos into 4D point clouds, enabling the optimization of a holistic 4D\nGaussian Splatting representation to reconstruct spatially and temporally\nconsistent 4D scenes. To validate the efficacy of our method, we conducted a\ncomparative analysis with existing approaches, revealing its superiority in\nboth panoramic video generation and 4D scene reconstruction. This demonstrates\nour method's capability to create more engaging and realistic immersive\nenvironments, thereby enhancing user experiences in VR and AR applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T13:55:28Z"}
{"aid":"http://arxiv.org/abs/2504.21651v1","title":"Pressure and strain effects on the $\\textit{ab initio}$ $GW$ electronic\n  structure of La$_3$Ni$_2$O$_7$","summary":"The recent discovery of superconductivity in La$_3$Ni$_2$O$_7$ at a critical\ntemperature above 80~K points to a non-conventional pairing mechanism in\nnickelates as in cuprates, possibly due to electronic correlations. We have\ncalculated from first principles the electronic structure of La$_3$Ni$_2$O$_7$\nunder the effect of pressure and epitaxial strain including correlations by the\n$GW$ approximation to the many-body self-energy. We find that the Fermi surface\nis composed of a characteristic cuprate-shape sheet $\\beta$ plus a\nnickelate-specific cylinder $\\alpha$, both from Ni $e_g$ orbitals, with a\nnon-negligible drop in the quasiparticle weight and an effective 1D character.\nThis topology results from a delicate balance between the Ni-3$d_{z^2}$ hole\npocket $\\gamma$, which is suppressed by correlations, and an emerging\nLa-5$d_{x^2-y^2}$ electron pocket induced by both correlation and\npressure/strain effects and whose role at low energy has been neglected so far.\nUnlike cuprates, the electronic structure of La$_3$Ni$_2$O$_7$ is already\ncorrectly described from ab initio and in agreement with the experiment without\nthe need to introduce Hubbard $U$ adjustable parameters or to invoke a strongly\ncorrelated physics.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-30T13:55:45Z"}
{"aid":"http://arxiv.org/abs/2504.21667v1","title":"From Precision to Perception: User-Centred Evaluation of Keyword\n  Extraction Algorithms for Internet-Scale Contextual Advertising","summary":"Keyword extraction is a foundational task in natural language processing,\nunderpinning countless real-world applications. A salient example is contextual\nadvertising, where keywords help predict the topical congruence between ads and\ntheir surrounding media contexts to enhance advertising effectiveness. Recent\nadvances in artificial intelligence, particularly large language models, have\nimproved keyword extraction capabilities but also introduced concerns about\ncomputational cost. Moreover, although the end-user experience is of vital\nimportance, human evaluation of keyword extraction performances remains\nunder-explored. This study provides a comparative evaluation of three prevalent\nkeyword extraction algorithms that vary in complexity: TF-IDF, KeyBERT, and\nLlama 2. To evaluate their effectiveness, a mixed-methods approach is employed,\ncombining quantitative benchmarking with qualitative assessments from 552\nparticipants through three survey-based experiments. Findings indicate a slight\nuser preference for KeyBERT, which offers a favourable balance between\nperformance and computational efficiency compared to the other two algorithms.\nDespite a strong overall preference for gold-standard keywords, differences\nbetween the algorithmic outputs are not statistically significant, highlighting\na long-overlooked gap between traditional precision-focused metrics and\nuser-perceived algorithm efficiency. The study highlights the importance of\nuser-centred evaluation methodologies and proposes analytical tools to support\ntheir implementation.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-30T14:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.21670v1","title":"Assimilation of SWOT Altimetry Data for Riverine Flood Reanalysis: From\n  Synthetic to Real Data","summary":"Floods are one of the most common and devastating natural disasters\nworldwide. The contribution of remote sensing is important for reducing the\nimpact of flooding both during the event itself and for improving hydrodynamic\nmodels by reducing their associated uncertainties. This article presents the\ninnovative capabilities of the Surface Water and Ocean Topography (SWOT)\nmission, especially its river node products, to enhance the accuracy of\nriverine flood reanalysis, performed on a 50-km stretch of the Garonne River.\nThe experiments incorporate various data assimilation strategies, based on the\nensemble Kalman filter (EnKF), which allows for sequential updates of model\nparameters based on available observations. The experimental results show that\nwhile SWOT data alone offers some improvements, combining it with in-situ water\nlevel measurements provides the most accurate representation of flood dynamics,\nboth at gauge stations and along the river. The study also investigates the\nimpact of different SWOT revisit frequencies on the models performance,\nrevealing that assimilating more frequent SWOT observations leads to more\nreliable flood reanalyses. In the real event, it was demonstrated that the\nassimilation of SWOT and in-situ data accurately reproduces the water level\ndynamics, offering promising prospects for future flood monitoring systems.\nOverall, this study emphasizes the complementary strengths of Earth Observation\ndata in improving the representation of the flood dynamics in the riverbed and\nthe floodplains.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-30T14:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.21689v1","title":"On the small mass limit of stochastic wave equation driven by\n  cylindrical stable process","summary":"We explore the small mass limit of a stochastic wave equation (SWE) driven by\ncylindrical $\\alpha$-stable noise, where $\\alpha\\in (1,2)$, and prove that it\nconverges to a stochastic heat equation. We establish its well-posedness, and\nin particular, the c\\`adl\\`ag property, which is not trivial in the infinite\ndimensional case. Using a splitting technique, we decompose the velocity\ncomponent into three parts, which gives convenience to the moment estimate. We\nshow the tightness of solution of SWE by verifying the infinite dimensional\nversion of Aldous condition. After these preparation, we pass the limit and\nderive the approximation equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T14:24:45Z"}
{"aid":"http://arxiv.org/abs/2504.21692v1","title":"Enhancing Self-Supervised Fine-Grained Video Object Tracking with\n  Dynamic Memory Prediction","summary":"Successful video analysis relies on accurate recognition of pixels across\nframes, and frame reconstruction methods based on video correspondence learning\nare popular due to their efficiency. Existing frame reconstruction methods,\nwhile efficient, neglect the value of direct involvement of multiple reference\nframes for reconstruction and decision-making aspects, especially in complex\nsituations such as occlusion or fast movement. In this paper, we introduce a\nDynamic Memory Prediction (DMP) framework that innovatively utilizes multiple\nreference frames to concisely and directly enhance frame reconstruction. Its\ncore component is a Reference Frame Memory Engine that dynamically selects\nframes based on object pixel features to improve tracking accuracy. In\naddition, a Bidirectional Target Prediction Network is built to utilize\nmultiple reference frames to improve the robustness of the model. Through\nexperiments, our algorithm outperforms the state-of-the-art self-supervised\ntechniques on two fine-grained video object tracking tasks: object segmentation\nand keypoint tracking.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-30T14:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.21740v1","title":"The monodromy of compact Lagrangian fibrations","summary":"We study the monodromy representations underlying compact Lagrangian\nfibrations. In the case where the associated period map is generically\nimmersive, we prove that the mondromy representation is irreducible over\n\\(\\mathbb{C}\\). In the alternative case where the fibration is isotrivial, we\nrecover a result of \\cite{kim-laza-martin23}, proving that its fibers are\nisogeneous to a power of an elliptic curve. We show that over \\(\\mathbb{C}\\),\nthe monodromy representation underlying an isotrivial Lagrangian fibration is a\ndirect sum of two irreducible \\(\\mathbb{C}\\)-local systems.","main_category":"math.AG","categories":"math.AG","published":"2025-04-30T15:38:12Z"}
{"aid":"http://arxiv.org/abs/2504.21770v1","title":"LASHED: LLMs And Static Hardware Analysis for Early Detection of RTL\n  Bugs","summary":"While static analysis is useful in detecting early-stage hardware security\nbugs, its efficacy is limited because it requires information to form checks\nand is often unable to explain the security impact of a detected vulnerability.\nLarge Language Models can be useful in filling these gaps by identifying\nrelevant assets, removing false violations flagged by static analysis tools,\nand explaining the reported violations. LASHED combines the two approaches\n(LLMs and Static Analysis) to overcome each other's limitations for hardware\nsecurity bug detection. We investigate our approach on four open-source SoCs\nfor five Common Weakness Enumerations (CWEs) and present strategies for\nimprovement with better prompt engineering. We find that 87.5% of instances\nflagged by our recommended scheme are plausible CWEs. In-context learning and\nasking the model to 'think again' improves LASHED's precision.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-30T16:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.21775v1","title":"Learning Heterogeneous Performance-Fairness Trade-offs in Federated\n  Learning","summary":"Recent methods leverage a hypernet to handle the performance-fairness\ntrade-offs in federated learning. This hypernet maps the clients' preferences\nbetween model performance and fairness to preference-specifc models on the\ntrade-off curve, known as local Pareto front. However, existing methods\ntypically adopt a uniform preference sampling distribution to train the\nhypernet across clients, neglecting the inherent heterogeneity of their local\nPareto fronts. Meanwhile, from the perspective of generalization, they do not\nconsider the gap between local and global Pareto fronts on the global dataset.\nTo address these limitations, we propose HetPFL to effectively learn both local\nand global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA)\nand Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the\noptimal preference sampling distribution for each client to accommodate\nheterogeneous local Pareto fronts. While PHF performs preference-aware fusion\nof clients' hypernets to ensure the performance of the global Pareto front. We\nprove that HetPFL converges linearly with respect to the number of rounds,\nunder weaker assumptions than existing methods. Extensive experiments on four\ndatasets show that HetPFL significantly outperforms seven baselines in terms of\nthe quality of learned local and global Pareto fronts.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T16:25:02Z"}
{"aid":"http://arxiv.org/abs/2504.21783v1","title":"Three-dimensional horseshoes near an unfolding of a Hopf-Hopf\n  singularity","summary":"Motivated by a certain type of unfolding of a Hopf-Hopf singularity, we\nconsider a one-parameter family $(f_\\gamma)_{\\gamma\\geq0}$ of $C^3$--vector\nfields in $\\mathbb{R}^4$ whose flows exhibit a heteroclinic cycle associated to\ntwo periodic solutions and a bifocus, all of them hyperbolic. It is formally\nproved that combining rotation with a generic condition concerning the\ntransverse intersection between the three-dimensional invariant manifolds of\nthe periodic solutions, all sets are highly distorted by the first return map\nand hyperbolic three-dimensional horseshoes emerge, accumulating on the\nnetwork. Infinitely many linked horseshoes prompt the coexistence of infinitely\nmany saddle-type invariant sets for all values of $\\gamma\\gtrsim 0$ belonging\nto the heteroclinic class of the two hyperbolic periodic solutions. We apply\nthe results to a particular unfolding of the Hopf-Hopf singularity, the so\ncalled \\emph{Gaspard-type unfolding}.","main_category":"math.DS","categories":"math.DS","published":"2025-04-30T16:39:06Z"}
{"aid":"http://arxiv.org/abs/2504.21799v1","title":"A $p$-Converse theorem for Real Quadratic Fields","summary":"Let $E$ be an elliptic curve defined over a real quadratic field $F$. Let $p\n> 5$ be a rational prime that is inert in $F$ and assume that $E$ has split\nmultiplicative reduction at the prime $\\mathfrak{p}$ of $F$ dividing $p$. Let\n$\\underline{III}(E/F)$ denote the Tate-Shafarevich group of $E$ over $F$ and $\nL(E/F,s) $ be the Hasse-Weil complex $L$-function of $E$ over $F$. Under some\ntechnical assumptions, we show that when $rank_{\\mathbb{Z}} \\hspace{0.01mm}\n\\hspace{1mm} E(F) = 1$ and $\\#\\Big(\\underline{III}(E/F)_ {p^\\infty}\\Big) <\n\\infty$, then $ord_{s=1} \\ L(E/F,s) = 1$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T16:56:10Z"}
{"aid":"http://arxiv.org/abs/2504.21806v1","title":"The embedding space of a Hopf link","summary":"We study the unparametrised smooth embedding space of a Hopf link in\n$\\mathbb{R}^3$, and prove that it is homotopy equivalent to the closed\n3-manifold $S^3/\\mathbb{Q}_8$. As an intermediate step in the proof, we show\nthat the inclusion of the subspace of round embeddings is a homotopy\nequivalence. We provide analogous results for the unparametrised smooth\nembedding space of a Hopf link in $S^3$.","main_category":"math.GT","categories":"math.GT","published":"2025-04-30T17:08:27Z"}
{"aid":"http://arxiv.org/abs/2504.21810v1","title":"A simple and effective approach for body part recognition on CT scans\n  based on projection estimation","summary":"It is well known that machine learning models require a high amount of\nannotated data to obtain optimal performance. Labelling Computed Tomography\n(CT) data can be a particularly challenging task due to its volumetric nature\nand often missing and$/$or incomplete associated meta-data. Even inspecting one\nCT scan requires additional computer software, or in the case of programming\nlanguages $-$ additional programming libraries. This study proposes a simple,\nyet effective approach based on 2D X-ray-like estimation of 3D CT scans for\nbody region identification. Although body region is commonly associated with\nthe CT scan, it often describes only the focused major body region neglecting\nother anatomical regions present in the observed CT. In the proposed approach,\nestimated 2D images were utilized to identify 14 distinct body regions,\nproviding valuable information for constructing a high-quality medical dataset.\nTo evaluate the effectiveness of the proposed method, it was compared against\n2.5D, 3D and foundation model (MI2) based approaches. Our approach outperformed\nthe others, where it came on top with statistical significance and F1-Score for\nthe best-performing model EffNet-B0 of 0.980 $\\pm$ 0.016 in comparison to the\n0.840 $\\pm$ 0.114 (2.5D DenseNet-161), 0.854 $\\pm$ 0.096 (3D VoxCNN), and 0.852\n$\\pm$ 0.104 (MI2 foundation model). The utilized dataset comprised three\ndifferent clinical centers and counted 15,622 CT scans (44,135 labels).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T17:13:44Z"}
{"aid":"http://arxiv.org/abs/2504.21813v1","title":"Turning a negative neutrino mass into a positive optical depth","summary":"Under $\\Lambda$CDM, recent baryon acoustic oscillation (BAO) distance\nmeasures from DESI, which favor a low matter density $\\Omega_m$, are in\nmoderate $2-3\\sigma$ tension with cosmic microwave background (CMB)\nobservations. This tension appears alternately as a preference for the sum of\nneutrino masses dropping below the $\\sum m_\\nu = 0.06$eV value required by\nneutrino oscillation measurements to formally negative values; a discrepant\nvalue of $\\Omega_m$ at 0.06eV; or preference for dynamical dark energy beyond\n$\\Lambda$CDM. We show that this tension largely arises from the CMB lensing\nconstraints on the calibration of the sound horizon for geometric measurements\nand relies on the measurement of the reionization optical depth $\\tau$ from\nlarge-angle CMB polarization to set the lensing amplitude. Dropping these\nconstraints removes the neutrino tension at $\\sum m_\\nu=0.06$eV entirely,\nfavoring $\\tau = 0.091\\pm 0.011$ in $\\Lambda$CDM. Beyond $\\Lambda$CDM, it\nbrings the preference for $w_0-w_a$ dynamical dark energy to below $95\\%$ CL.\nWe explore the freedom in interpreting the low-$\\ell$ EE polarization\nconstraint due to analysis choices and reionization modeling beyond the\nstandard step-function assumption and find that this drops the neutrino tension\nin $\\Lambda$CDM to below $95\\%$ CL. Alternately, this raising of $\\tau$ can\nalso be achieved by the same reduction in large-scale curvature fluctuations\nthat also ameliorates the low-$\\ell$ temperature anomaly.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-30T17:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.21818v1","title":"Topology, Kinetics and Inheritance in Clonal Colonies of Bone Marrow\n  Stromal Cells","summary":"Bone marrow stromal cells (BMSCs), whose populations contain multipotent\nskeletal stem cells with relevant therapeutic applications, are known to\nproduce very heterogeneous colonies upon in vitro culture, a trait that may\nseverely hinder the clinical usefulness of BMSC-based therapies. Therefore,\nreaching a better insight on the nature of such heterogeneity, as well as on\nthe factors determining it, is important. Here, by using time-lapse microscopy,\nwe study the structure of N=28 human BMSC colonies from six donors, each colony\nderived from a single cell, and trace their lineage trees up to the seventh\ngeneration. We confirm the presence of very significant inter-colony and\nintra-colony heterogeneities, both in the topology of the lineages and in the\nreplicative kinetics of the colonies. We also find that topology and kinetics\nare strongly correlated, consistent with the existence of regulating factors\nlinking the sub-population of inactive cells, which uniquely determine a\nlineage's topology, and that of active cells, which are the sole responsible\nfor the proliferation rate of the colony. Finally, we submit each colony to an\nentropy-based inheritance test, which measures the degree of non-random\nclustering of inactive cells within the same branches of the lineage, and find\na clear signature of hereditary transmission of the probability of emergence of\ninactive cells in the largest majority of the experimental lineages.","main_category":"q-bio.CB","categories":"q-bio.CB,cond-mat.stat-mech,physics.bio-ph","published":"2025-04-30T17:24:21Z"}
{"aid":"http://arxiv.org/abs/2504.21823v1","title":"A Sequoia stellar candidate with very high 7Li and 9Be","summary":"Aims. The metal-poor star BPM 3066 belongs to the retrograde halo and\npresents unexpectedly strong spectral features of lithium. To gain insight into\nthe origin of this peculiar abundance, we investigate the chemistry and\nkinematic properties of this star. Methods. We performed a local thermodynamic\nequilibrium chemical abundance analysis of UVES/VLT high-resolution spectra of\nBPM 3066 using ATLAS9 and ATLAS12 model atmospheres and the MyGIsFOS code. We\nfurther characterised the orbital properties of the star by integrating its\norbit and analysing its integrals of motion using the galpy code. Results. The\nstar BPM 3066 shows an exceptional overabundance of both lithium and beryllium.\nThe abundances are A(Li) = 3.0 and A(Be) = 2.1, which are respectively about\n0.8 and 2.2 dex higher than the Li and Be abundances expected at [Fe/H] = -1.5,\nthe metallicity of the star. The observed ratio 7Li/9Be is 7.9, which is close\nto that expected from a synthesis by spallation processes. Overabundances of\nSi, Al, and of the neutron capture elements Sr,Y, Zr, and Ba are also measured.\nKinematically, BPM 3066 has an eccentric, strongly retrograde orbit, confined\nto a height lower than 1 kpc from the galactic plane, and it is a candidate\nmember of the Sequoia/Thamnos accreted galaxy. Conclusions. The processes\nleading to the 7Li and 9Be synthesis could have occurred in the environment of\na hypernova. This is supported by some abundance anomalies like the high value\nof Si, [Si/Fe]=1.2 and [Si/O]=1.1. However, the simultaneous high values of N,\nNa, Al, Sc, Ti, and Cu are at odds with the expectations from a hypernova.\nAlternatively, the abundances of BPM 3066 could result from the engulfing of\nrocky planets that were rich in spallated Li and Be. In both cases, it is\nremarkable that such an extreme abundance pattern has been found in a star\nbelonging to the Sequoia/Thamnos accreted galaxy.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-30T17:26:59Z"}
{"aid":"http://arxiv.org/abs/2504.21834v1","title":"Advances on a conjecture about free divisors","summary":"In 2002, it was conjectured that a free divisor satisfying the so-called\nLogarithmic Comparison Theorem (LCT) must be strongly Euler-homogeneous. Today,\nit is known to be true only in ambient dimension less or equal than three or\nassuming Koszul-freeness. Thanks to our advances in the comprehension of strong\nEuler-homogeneity, we are able to prove the conjecture in the following new\ncases: assuming strong Euler-homogeneity on a punctured neighbourhood of a\npoint; assuming the divisor is weakly Koszul-free; for ambient dimension $n=4$;\nfor linear free divisors in ambient dimension $n=5$. We also refute a\nconjecture that states that all linear free divisors satisfy LCT and are\nstrongly Euler-homogeneous.","main_category":"math.AG","categories":"math.AG,math.CV","published":"2025-04-30T17:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.21855v1","title":"ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D\n  Physics Modeling for Complex Motion and Interaction","summary":"In recent years, video generation has seen significant advancements. However,\nchallenges still persist in generating complex motions and interactions. To\naddress these challenges, we introduce ReVision, a plug-and-play framework that\nexplicitly integrates parameterized 3D physical knowledge into a pretrained\nconditional video generation model, significantly enhancing its ability to\ngenerate high-quality videos with complex motion and interactions.\nSpecifically, ReVision consists of three stages. First, a video diffusion model\nis used to generate a coarse video. Next, we extract a set of 2D and 3D\nfeatures from the coarse video to construct a 3D object-centric representation,\nwhich is then refined by our proposed parameterized physical prior model to\nproduce an accurate 3D motion sequence. Finally, this refined motion sequence\nis fed back into the same video diffusion model as additional conditioning,\nenabling the generation of motion-consistent videos, even in scenarios\ninvolving complex actions and interactions. We validate the effectiveness of\nour approach on Stable Video Diffusion, where ReVision significantly improves\nmotion fidelity and coherence. Remarkably, with only 1.5B parameters, it even\noutperforms a state-of-the-art video generation model with over 13B parameters\non complex video generation by a substantial margin. Our results suggest that,\nby incorporating 3D physical knowledge, even a relatively small video diffusion\nmodel can generate complex motions and interactions with greater realism and\ncontrollability, offering a promising solution for physically plausible video\ngeneration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2505.00262v1","title":"Certain residual properties of HNN-extensions with normal associated\n  subgroups","summary":"Let $\\mathbb{E}$ be the HNN-extension of a group $B$ with subgroups $H$ and\n$K$ associated according to an isomorphism $\\varphi\\colon H \\to K$. Suppose\nthat $H$ and $K$ are normal in $B$ and $(H \\cap K)\\varphi = H \\cap K$. Under\nthese assumptions, we prove necessary and sufficient conditions for\n$\\mathbb{E}$ to be residually a $\\mathcal{C}$-group, where $\\mathcal{C}$ is a\nclass of groups closed under taking subgroups, quotient groups, and\nunrestricted wreath products. Among other things, these conditions give new\nfacts on the residual finiteness and the residual $p$-finiteness of the group\n$\\mathbb{E}$.","main_category":"math.GR","categories":"math.GR","published":"2025-05-01T03:05:25Z"}
{"aid":"http://arxiv.org/abs/2505.00305v1","title":"Iterations of Meromorphic Functions involving Sine","summary":"In this article, the dynamics of a one-parameter family of functions\n$f_{\\lambda}(z) = \\frac{\\sin{z}}{z^2 + \\lambda},$ $\\lambda>0$, are studied. It\nshows the existence of parameters $0< \\lambda_{1}< \\lambda_{2}$ such that\nbifurcations occur at $\\lambda_1$ and $\\lambda_2$ for $f_{\\lambda}$. It is\nproved that the Fatou set $\\mathcal{F}(f_{\\lambda})$ is the union of basins of\nattraction in the complex plane for $\\lambda \\in (\\lambda_1, \\lambda_2) \\cup\n(\\lambda_2, \\infty)$. Further, every Fatou component of $f_{\\lambda}$ is simply\nconnected for $\\lambda \\geq \\lambda_1$. The boundary of the Fatou set\n$\\mathcal{F}(f_{\\lambda})$ is the Julia set $\\mathcal{J}(f_{\\lambda})$ in the\nextended complex plane for $\\lambda> 1$. Interestingly, it is found that\n$f_{\\lambda}$ has only one completely invariant Fatou component, say\n$U_\\lambda$ such that $\\mathcal{F}(f_{\\lambda}) = U_{\\lambda}$ for $\\lambda\n>\\lambda_2$. Moreover, the characterization of the Julia set of $f_{\\lambda}$\nis seen for $\\lambda \\in (\\lambda_1, \\infty)\\setminus \\{\\lambda_2\\}$.","main_category":"math.DS","categories":"math.DS","published":"2025-05-01T04:57:20Z"}
{"aid":"http://arxiv.org/abs/2505.00332v1","title":"Active Contact Engagement for Aerial Navigation in Unknown Environments\n  with Glass","summary":"Autonomous aerial robots are increasingly being deployed in real-world\nscenarios, where transparent glass obstacles present significant challenges to\nreliable navigation. Researchers have investigated the use of non-contact\nsensors and passive contact-resilient aerial vehicle designs to detect glass\nsurfaces, which are often limited in terms of robustness and efficiency. In\nthis work, we propose a novel approach for robust autonomous aerial navigation\nin unknown environments with transparent glass obstacles, combining the\nstrengths of both sensor-based and contact-based glass detection. The proposed\nsystem begins with the incremental detection and information maintenance about\npotential glass surfaces using visual sensor measurements. The vehicle then\nactively engages in touch actions with the visually detected potential glass\nsurfaces using a pair of lightweight contact-sensing modules to confirm or\ninvalidate their presence. Following this, the volumetric map is efficiently\nupdated with the glass surface information and safe trajectories are replanned\non the fly to circumvent the glass obstacles. We validate the proposed system\nthrough real-world experiments in various scenarios, demonstrating its\neffectiveness in enabling efficient and robust autonomous aerial navigation in\ncomplex real-world environments with glass obstacles.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T06:14:53Z"}
{"aid":"http://arxiv.org/abs/2505.00374v1","title":"Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise\n  Separable Dilated Convolutional Network","summary":"Deep neural networks have demonstrated highly competitive performance in\nsuper-resolution (SR) for natural images by learning mappings from\nlow-resolution (LR) to high-resolution (HR) images. However, hyperspectral\nsuper-resolution remains an ill-posed problem due to the high spectral\ndimensionality of the data and the scarcity of available training samples.\nMoreover, existing methods often rely on large models with a high number of\nparameters or require the fusion with panchromatic or RGB images, both of which\nare often impractical in real-world scenarios. Inspired by the MobileNet\narchitecture, we introduce a lightweight depthwise separable dilated\nconvolutional network (DSDCN) to address the aforementioned challenges.\nSpecifically, our model leverages multiple depthwise separable convolutions,\nsimilar to the MobileNet architecture, and further incorporates a dilated\nconvolution fusion block to make the model more flexible for the extraction of\nboth spatial and spectral features. In addition, we propose a custom loss\nfunction that combines mean squared error (MSE), an L2 norm\nregularization-based constraint, and a spectral angle-based loss, ensuring the\npreservation of both spectral and spatial details. The proposed model achieves\nvery competitive performance on two publicly available hyperspectral datasets,\nmaking it well-suited for hyperspectral image super-resolution tasks. The\nsource codes are publicly available at:\n\\href{https://github.com/Usman1021/lightweight}{https://github.com/Usman1021/lightweight}.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-01T07:57:23Z"}
{"aid":"http://arxiv.org/abs/2505.00401v1","title":"Size-Dependent Tensile Behavior and Dislocation Dynamics in Cu and Ag\n  Nanowires: A Molecular Dynamics Study","summary":"By using molecular dynamics simulations, the research examine how copper and\nsilver nanowires respond to tensile loading in order to clarify their nanoscale\ndeformation mechanisms. The results demonstrate that these two metal nanowires\nfollow notably different stress - strain trends, with silver wires exhibiting\ngreater elastic stiffness and higher yield points at equivalent diameters - an\neffect likely rooted in silver's stronger atomic bonding and more stable\nmicrostructure. A pronounced size effect is observed: as the wire diameter\ndiminishes, both the yield strength and ultimate tensile strength increase\nsubstantially, a behavior driven by the higher proportion of surface atoms that\nenhance dislocation nucleation and mobility. Atomistic analyses further\nunderscore the dominant role of dislocations during plastic deformation, and in\nparticular reveal that surface - initiated dislocations in thinner wires\ncritically affect their fracture behavior.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-05-01T08:47:27Z"}
{"aid":"http://arxiv.org/abs/2505.00406v1","title":"Quantum Littlewood correspondences","summary":"In the 1940s Littlewood formulated three fundamental correspondences for the\nimmanants and Schur symmetric functions on the general linear group, which\nestablish deep connections between representation theory of the symmetric group\nand the general linear group parallel to the Schur-Weyl duality. In this paper,\nwe introduce the notion of quantum immanants in the quantum coordinate algebra\nusing primitive idempotents of the Hecke algebra. By employing $R$-matrix\ntechniques, we establish the quantum analog of Littlewood correspondences\nbetween quantum immanants and Schur functions for the quantum coordinate\nalgebra. In the setting of the Schur-Weyl-Jimbo duality, we construct an exact\ncorrespondence between the Gelfand-Tsetlin bases of the irreducible\nrepresentations of the quantum enveloping algebra $U_q(\\mathfrak{gl}(n))$ and\nYoung's orthonormal basis of an irreducible representation of the Hecke algebra\n$\\mathcal H_m$. This isomorphism leads to our trace formula for the quantum\nimmanants, which settled the generalization problem\n  of $q$-analog of Kostant's formular for $\\lambda$-immanants. As applications,\nwe also derive general $q$-Littlewood-Merris-Watkins identities and\n$q$-Goulden-Jackson identities as special cases of the quantum Littlewood\ncorrespondence III.","main_category":"math.RT","categories":"math.RT,math.CO,math.QA","published":"2025-05-01T08:56:33Z"}
{"aid":"http://arxiv.org/abs/2505.00411v1","title":"Affine matrix scrambling achieves smoothness-dependent convergence rates","summary":"We study the convergence rate of the median estimator for affine matrix\nscrambled digital nets applied to integrands over the unit hypercube $[0,\n1]^s$. By taking the median of $(2r-1)$ independent randomized quasi-Monte\nCarlo (RQMC) samples, we demonstrate that the desired convergence rates can be\nachieved without increasing the number of randomizations $r$ as the quadrature\nsize $N$ grows for both bounded and unbounded integrands. For unbounded\nintegrands, our analysis assumes a boundary growth condition on the weak\nderivatives and also considers singularities such as kinks and jump\ndiscontinuities. Notably, when $r = 1$, the median estimator reduces to the\nstandard RQMC estimator. By applying analytical techniques developed for median\nestimators, we prove that the affine matrix scrambled estimator achieves a\nconvergence rate depending on the integrand's smoothness, and is therefore not\nlimited by the canonical rate $\\mathcal{O}(N^{-3/2})$. However, this\nsmoothness-dependent theoretical rate is not observed empirically in numerical\nexperiments when the affine matrix scrambling yields a heavy-tailed sampling\ndistribution. In contrast, the median estimator consistently reveals the\ntheoretical rates and yields smaller integration errors than mean estimators,\nfurther highlighting its advantages.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T09:09:58Z"}
{"aid":"http://arxiv.org/abs/2505.00425v1","title":"A census of face-transitive surfaces","summary":"A face-transitive surface is a triangulated 2-dimensional manifold whose\nautomorphism group acts transitively on its set of triangles. In this paper, we\ninvestigate this class of highly symmetric surface triangulations. We identify\nseven types of such face-transitive surfaces, splitting up further into a total\nof thirteen sub-types, distinguished by how their automorphism groups act on\nthem. We use these theoretical results to compute a census of face-transitive\nsurfaces with up to 1280 faces by constructing suitable cycle double covers of\ncubic node-transitive graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T09:52:10Z"}
{"aid":"http://arxiv.org/abs/2505.00429v1","title":"On the structure of big bang singularities in spatially homogenous\n  solutions to the Einstein non-linear scalar field equations","summary":"The subject of this article is the structure of big bang singularities in\nspatially homogeneous solutions to the Einstein non-linear scalar field\nequations. In particular, we focus on Bianchi class A; i.e., developments\narising from left invariant initial data on unimodular $3$-dimensional Lie\ngroups. We prove that solutions are either vacuum or matter dominated,\ndepending on whether the limit of an expansion normalised normal derivative of\nthe scalar field is zero or not, respectively. The main result concerning the\nasymptotics in the direction of the singularity is, essentially, that solutions\ninduce data on the singularity, with two exceptions: vacuum dominated Bianchi\ntype VIII and IX without additional symmetries (they are neither isotropic nor\nlocally rotationally symmetric) exhibit BKL-type oscillations. Disregarding the\nexceptions, there is in fact a bijection between initial data on the\nsingularity and developments. Initial data on the singularity thus play a\ncentral role in the analysis; they both parameterise developments and give\noptimal asymptotic information. However, the main point of the article is to\nprove that the set of isometry classes of initial data on the singularity (of a\nfixed Bianchi type and symmetry (such as isotropy, local rotational symmetry\netc.)) has a smooth structure; that the set of isometry classes of developments\n(similarly restricted) has a smooth structure which fits together with the\nnatural smooth structure of isometry classes of regular initial data with fixed\nmean curvature; and that the Einstein flow generates a diffeomorphism between\nthe two sets. However, the article contains substantial additional information,\nsuch as, e.g., the construction of a large class of spatially locally\nhomogeneous solutions that can be demonstrated to be globally non-linearly\nstable (in the absence of symmetries) both to the future and to the past.","main_category":"gr-qc","categories":"gr-qc,math-ph,math.MP","published":"2025-05-01T09:58:07Z"}
{"aid":"http://arxiv.org/abs/2505.00434v1","title":"Stability of the first-order unified gas-kinetic scheme based on a\n  linear kinetic model","summary":"The unified gas-kinetic scheme (UGKS) is becoming increasingly popular for\nmultiscale simulations in all flow regimes. This paper provides the first\nanalytical study on the stability of the UGKS applied to a linear kinetic\nmodel, which is able to reproduce the one-dimensional linear scalar\nadvection-diffusion equation via the Chapman-Enskog expansion method. Adopting\nperiodic boundary conditions and neglecting the error from numerical\nintegration, this paper rigorously proves the weighted $L^2$-stability of the\nfirst-order UGKS under the Courant-Friedrichs-Lewy (CFL) conditions. It is\nshown that the time step of the method is not constrained by being less than\nthe particle collision time, nor is it limited by parabolic type CFL conditions\ntypically applied in solving diffusion equations. The novelty of the proof lies\nin that based on the ratio of the time step to the particle collision time, the\nupdate of distribution functions is viewed as a convex combinations of\nsub-methods related to various physics processes, such as the particle free\ntransport and collisions. The weighted $L^2$-stability of the sub-methods is\nobtained by considering them as discretizations to corresponding linear\nhyperbolic systems and utilizing the associated Riemann invariants. Finally,\nthe strong stability preserving property of the UGKS leads to the desired\nweighted $L^2$-stability.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T10:12:07Z"}
{"aid":"http://arxiv.org/abs/2505.00447v1","title":"Deterministic Scheduling over Wi-Fi 6 using Target Wake Time: An\n  Experimental Approach","summary":"Wi-Fi networks traditionally use Distributed Coordination Function (DCF) that\nemploys CSMA/CA along with the binary backoff mechanism for channel access.\nThis causes unavoidable contention overheads and does not provide performance\nguarantees. In this work, we outline some issues that occur with the\nprobabilistic channel access in highly congested scenarios and how those can be\nmitigated using deterministic scheduling. Towards this, we propose to use\nTarget Wake Time (TWT) - a feature introduced in Wi-Fi 6 as a power-saving\nmechanism, to improve the performance of Wi-Fi. To gain insights into the\nworkings of the TWT over commercially available off-the-shelf components and to\nanalyze the factors that affect its performance, we carry out various\nexperiments with it over our Wi-Fi 6 testbed. Using these insights and\nanalysis, we formulate and solve an optimization problem to synthesize\ndeterministic schedules and obtain the optimal values of various system\nparameters. Lastly, we configure our testbed with these optimal parameter\nvalues and show that the TWT based deterministic scheduling consistently\nresults in better performance of the TWT-capable clients and overall system\nperformance compared to traditional CSMA/CA based scheduling.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-01T10:43:01Z"}
{"aid":"http://arxiv.org/abs/2505.00502v1","title":"Towards Scalable Human-aligned Benchmark for Text-guided Image Editing","summary":"A variety of text-guided image editing models have been proposed recently.\nHowever, there is no widely-accepted standard evaluation method mainly due to\nthe subjective nature of the task, letting researchers rely on manual user\nstudy. To address this, we introduce a novel Human-Aligned benchmark for\nText-guided Image Editing (HATIE). Providing a large-scale benchmark set\ncovering a wide range of editing tasks, it allows reliable evaluation, not\nlimited to specific easy-to-evaluate cases. Also, HATIE provides a\nfully-automated and omnidirectional evaluation pipeline. Particularly, we\ncombine multiple scores measuring various aspects of editing so as to align\nwith human perception. We empirically verify that the evaluation of HATIE is\nindeed human-aligned in various aspects, and provide benchmark results on\nseveral state-of-the-art models to provide deeper insights on their\nperformance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T13:06:05Z"}
{"aid":"http://arxiv.org/abs/2505.00503v1","title":"Variational OOD State Correction for Offline Reinforcement Learning","summary":"The performance of Offline reinforcement learning is significantly impacted\nby the issue of state distributional shift, and out-of-distribution (OOD) state\ncorrection is a popular approach to address this problem. In this paper, we\npropose a novel method named Density-Aware Safety Perception (DASP) for OOD\nstate correction. Specifically, our method encourages the agent to prioritize\nactions that lead to outcomes with higher data density, thereby promoting its\noperation within or the return to in-distribution (safe) regions. To achieve\nthis, we optimize the objective within a variational framework that\nconcurrently considers both the potential outcomes of decision-making and their\ndensity, thus providing crucial contextual information for safe\ndecision-making. Finally, we validate the effectiveness and feasibility of our\nproposed method through extensive experimental evaluations on the offline\nMuJoCo and AntMaze suites.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.RO","published":"2025-05-01T13:14:07Z"}
{"aid":"http://arxiv.org/abs/2505.00536v1","title":"Ground Orthogonal Arrays and Their Applications","summary":"In computer experiments, it has become a standard practice to select the\ninputs that spread out as uniformly as possible over the design space. The\nresulting designs are called space-filling designs and they are undoubtedly\ndesirable choices when there is no prior knowledge on how the input variables\naffect the response and the objective of experiments is global fitting. When\nthere is some prior knowledge on the underlying true function of the system or\nwhat statistical models are more appropriate, a natural question is, are there\nmore suitable designs than vanilla space-filling designs? In this article, we\nprovide an answer for the cases where there are no interactions between the\nfactors from disjoint groups of variables. In other words, we consider the\ndesign issue when the underlying functional form of the system or the\nstatistical model to be used is additive where each component depends on one\ngroup of variables from a set of disjoint groups. For such cases, we recommend\nusing {\\em grouped orthogonal arrays.} Several construction methods are\nprovided and many designs are tabulated for practical use. Compared with\nexisting techniques in the literature, our construction methods can generate\nmany more designs with flexible run sizes and better within-group projection\nproperties for any prime power number of levels.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-01T14:02:35Z"}
{"aid":"http://arxiv.org/abs/2505.00539v1","title":"Unified QMF equation of state for neutron star matter: Static and\n  dynamic properties","summary":"We construct a set of unified equations of state based on the quark mean\nfield (QMF) model, calibrated to different values of nuclear symmetry energy\nslope at the saturation density ($L_0$), with the aim of exploring both the\nstatic properties and dynamical behavior of neutron stars (NSs), and building a\ncoherent picture of their internal structure. We assess the performance of\nthese QMF models in describing the mass-radius relation, the cooling evolution\nof isolated NSs and X-ray transients, and the instabilities (e.g., the r-mode).\nIn comparison to relativistic mean field (RMF) models formulated at the\nhadronic level, the QMF model predicts heavier nuclear clusters and larger\nWigner-Seitz cell sizes in the NS crust, while the density of the free neutron\ngas remains largely similar between the two approaches. For the cooling of\nisolated NSs, the thermal evolution is found to be insensitive to both the\nmany-body model and the symmetry energy slope in the absence of the direct Urca\n(dUrca) process. However, when rapid cooling via the dUrca process is allowed,\nin the case of large $L_0$ values (e.g., $L_0 \\gtrsim 80$ MeV) in our study,\nthe QMF model predicts a longer thermal relaxation time. Both the QMF and RMF\nmodels can reproduce cooling curves consistent with observations of X-ray\ntransients (e.g., KS 1731--260) during their crustal cooling phase, although\nstellar parameters show slight variations depending on the model and symmetry\nenergy slope. Within our unified framework, a larger $L_0$ value generally\nresults in a wider instability window, while increasing the stellar mass tends\nto suppress the instability window. We also provide simple power-law\nparameterizations that quantify the dependence of bulk and shear viscosities on\nthe symmetry energy slope for nuclear matter at saturation density.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-05-01T14:05:15Z"}
{"aid":"http://arxiv.org/abs/2505.00546v1","title":"Directly Forecasting Belief for Reinforcement Learning with Delays","summary":"Reinforcement learning (RL) with delays is challenging as sensory perceptions\nlag behind the actual events: the RL agent needs to estimate the real state of\nits environment based on past observations. State-of-the-art (SOTA) methods\ntypically employ recursive, step-by-step forecasting of states. This can cause\nthe accumulation of compounding errors. To tackle this problem, our novel\nbelief estimation method, named Directly Forecasting Belief Transformer (DFBT),\ndirectly forecasts states from observations without incrementally estimating\nintermediate states step-by-step. We theoretically demonstrate that DFBT\ngreatly reduces compounding errors of existing recursively forecasting methods,\nyielding stronger performance guarantees. In experiments with D4RL offline\ndatasets, DFBT reduces compounding errors with remarkable prediction accuracy.\nDFBT's capability to forecast state sequences also facilitates multi-step\nbootstrapping, thus greatly improving learning efficiency. On the MuJoCo\nbenchmark, our DFBT-based method substantially outperforms SOTA baselines.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T14:20:48Z"}
{"aid":"http://arxiv.org/abs/2505.00555v1","title":"On the Mechanistic Interpretability of Neural Networks for Causality in\n  Bio-statistics","summary":"Interpretable insights from predictive models remain critical in\nbio-statistics, particularly when assessing causality, where classical\nstatistical and machine learning methods often provide inherent clarity. While\nNeural Networks (NNs) offer powerful capabilities for modeling complex\nbiological data, their traditional \"black-box\" nature presents challenges for\nvalidation and trust in high-stakes health applications. Recent advances in\nMechanistic Interpretability (MI) aim to decipher the internal computations\nlearned by these networks. This work investigates the application of MI\ntechniques to NNs within the context of causal inference for bio-statistics.\n  We demonstrate that MI tools can be leveraged to: (1) probe and validate the\ninternal representations learned by NNs, such as those estimating nuisance\nfunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)\ndiscover and visualize the distinct computational pathways employed by the\nnetwork to process different types of inputs, potentially revealing how\nconfounders and treatments are handled; and (3) provide methodologies for\ncomparing the learned mechanisms and extracted insights across statistical,\nmachine learning, and NN models, fostering a deeper understanding of their\nrespective strengths and weaknesses for causal bio-statistical analysis.","main_category":"stat.AP","categories":"stat.AP,cs.AI","published":"2025-05-01T14:30:34Z"}
{"aid":"http://arxiv.org/abs/2505.00561v1","title":"Learning to Learn with Quantum Optimization via Quantum Neural Networks","summary":"Quantum Approximate Optimization Algorithms (QAOA) promise efficient\nsolutions to classically intractable combinatorial optimization problems by\nharnessing shallow-depth quantum circuits. Yet, their performance and\nscalability often hinge on effective parameter optimization, which remains\nnontrivial due to rugged energy landscapes and hardware noise. In this work, we\nintroduce a quantum meta-learning framework that combines quantum neural\nnetworks, specifically Quantum Long Short-Term Memory (QLSTM) architectures,\nwith QAOA. By training the QLSTM optimizer on smaller graph instances, our\napproach rapidly generalizes to larger, more complex problems, substantially\nreducing the number of iterations required for convergence. Through\ncomprehensive benchmarks on Max-Cut and Sherrington-Kirkpatrick model\ninstances, we demonstrate that QLSTM-based optimizers converge faster and\nachieve higher approximation ratios compared to classical baselines, thereby\noffering a robust pathway toward scalable quantum optimization in the NISQ era.","main_category":"quant-ph","categories":"quant-ph,cs.AI","published":"2025-05-01T14:39:26Z"}
{"aid":"http://arxiv.org/abs/2505.00576v1","title":"Narrow Inhomogeneous Distribution and Charge State Stabilization of\n  Lead-Vacancy Centers in Diamond","summary":"Lead-vacancy (PbV) centers in diamond with a large ground state splitting are\nexpected to be a building block of quantum network nodes. Due to the heaviness\nof the Pb atom, it is challenging to fabricate high-quality PbV centers with a\nnarrow inhomogeneous distribution and stable charge state. In this study, for\nthe formation of the PbV centers, high temperature anneal up to 2300{\\deg}C is\nperformed after Pb ion implantation. At a lower temperature of 1800{\\deg}C, the\nPbV centers show a large inhomogeneous distribution and spectral diffusion,\nwhile higher temperatures of 2200-2300{\\deg}C leads to narrow inhomogeneous\ndistributions with standard deviations of ~5 GHz. The charge state transition\nof the PbV centers formed at 2200{\\deg}C occurs by capturing photo-carriers\ngenerated from surrounding defects under 532 nm laser irradiation. Finally,\nmultiple stable PbV centers with nearly identical photon frequencies are\nobtained, which is essential for applications in quantum information\nprocessing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T15:02:10Z"}
{"aid":"http://arxiv.org/abs/2505.00578v1","title":"AI-Driven High-Resolution Cell Segmentation and Quantitative Analysis","summary":"Studying the growth and metabolism of microbes provides critical insights\ninto their evolutionary adaptations to harsh environments, which are essential\nfor microbial research and biotechnology applications. In this study, we\ndeveloped an AI-driven image analysis system to efficiently segment individual\ncells and quantitatively analyze key cellular features. This system is\ncomprised of four main modules. First, a denoising algorithm enhances contrast\nand suppresses noise while preserving fine cellular details. Second, the\nSegment Anything Model (SAM) enables accurate, zero-shot segmentation of cells\nwithout additional training. Third, post-processing is applied to refine\nsegmentation results by removing over-segmented masks. Finally, quantitative\nanalysis algorithms extract essential cellular features, including average\nintensity, length, width, and volume. The results show that denoising and\npost-processing significantly improved the segmentation accuracy of SAM in this\nnew domain. Without human annotations, the AI-driven pipeline automatically and\nefficiently outlines cellular boundaries, indexes them, and calculates key\ncellular parameters with high accuracy. This framework will enable efficient\nand automated quantitative analysis of high-resolution fluorescence microscopy\nimages to advance research into microbial adaptations to grow and metabolism\nthat allow extremophiles to thrive in their harsh habitats.","main_category":"eess.IV","categories":"eess.IV,q-bio.QM","published":"2025-05-01T15:09:03Z"}
{"aid":"http://arxiv.org/abs/2505.00591v1","title":"Explainable AI in Spatial Analysis","summary":"This chapter discusses the opportunities of eXplainable Artificial\nIntelligence (XAI) within the realm of spatial analysis. A key objective in\nspatial analysis is to model spatial relationships and infer spatial processes\nto generate knowledge from spatial data, which has been largely based on\nspatial statistical methods. More recently, machine learning offers scalable\nand flexible approaches that complement traditional methods and has been\nincreasingly applied in spatial data science. Despite its advantages, machine\nlearning is often criticized for being a black box, which limits our\nunderstanding of model behavior and output. Recognizing this limitation, XAI\nhas emerged as a pivotal field in AI that provides methods to explain the\noutput of machine learning models to enhance transparency and understanding.\nThese methods are crucial for model diagnosis, bias detection, and ensuring the\nreliability of results obtained from machine learning models. This chapter\nintroduces key concepts and methods in XAI with a focus on Shapley value-based\napproaches, which is arguably the most popular XAI method, and their\nintegration with spatial analysis. An empirical example of county-level voting\nbehaviors in the 2020 Presidential election is presented to demonstrate the use\nof Shapley values and spatial analysis with a comparison to multi-scale\ngeographically weighted regression. The chapter concludes with a discussion on\nthe challenges and limitations of current XAI techniques and proposes new\ndirections.","main_category":"cs.LG","categories":"cs.LG,econ.EM","published":"2025-05-01T15:25:23Z"}
{"aid":"http://arxiv.org/abs/2505.00626v1","title":"The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning\n  (and How to Fix Them)","summary":"Large language models (LLMs) that integrate multiple input roles (e.g.,\nsystem instructions, user queries, external tool outputs) are increasingly\nprevalent in practice. Ensuring that the model accurately distinguishes\nmessages from each role -- a concept we call \\emph{role separation} -- is\ncrucial for consistent multi-role behavior. Although recent work often targets\nstate-of-the-art prompt injection defenses, it remains unclear whether such\nmethods truly teach LLMs to differentiate roles or merely memorize known\ntriggers. In this paper, we examine \\emph{role-separation learning}: the\nprocess of teaching LLMs to robustly distinguish system and user tokens.\nThrough a \\emph{simple, controlled experimental framework}, we find that\nfine-tuned models often rely on two proxies for role identification: (1) task\ntype exploitation, and (2) proximity to begin-of-text. Although data\naugmentation can partially mitigate these shortcuts, it generally leads to\niterative patching rather than a deeper fix. To address this, we propose\nreinforcing \\emph{invariant signals} that mark role boundaries by adjusting\ntoken-wise cues in the model's input encoding. In particular, manipulating\nposition IDs helps the model learn clearer distinctions and reduces reliance on\nsuperficial proxies. By focusing on this mechanism-centered perspective, our\nwork illuminates how LLMs can more reliably maintain consistent multi-role\nbehavior without merely memorizing known prompts or triggers.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2","published":"2025-05-01T16:06:16Z"}
{"aid":"http://arxiv.org/abs/2505.00633v1","title":"Strong Rigidity and Elementary Embeddings","summary":"We present a method for producing elementary embeddings from homomorphisms.\nThis method is utilized in the study of the \"strongly rigid relation principle\"\nas defined by Hamkins and Palumbo in their paper \"The Rigid Relation Principle,\na New Weak Choice Principle.\" We establish that the strongly rigid relation\nprinciple is also a weak choice principle that is independent of ZF. Finally,\nwe characterize proto Berkeley cardinals in terms of a strong failure of the\nstrongly rigid relation principle.","main_category":"math.LO","categories":"math.LO","published":"2025-05-01T16:17:49Z"}
{"aid":"http://arxiv.org/abs/2505.00681v1","title":"MINERVA: Evaluating Complex Video Reasoning","summary":"Multimodal LLMs are turning their focus to video benchmarks, however most\nvideo benchmarks only provide outcome supervision, with no intermediate or\ninterpretable reasoning steps. This makes it challenging to assess if models\nare truly able to combine perceptual and temporal information to reason about\nvideos, or simply get the correct answer by chance or by exploiting linguistic\nbiases. To remedy this, we provide a new video reasoning dataset called MINERVA\nfor modern multimodal models. Each question in the dataset comes with 5 answer\nchoices, as well as detailed, hand-crafted reasoning traces. Our dataset is\nmultimodal, diverse in terms of video domain and length, and consists of\ncomplex multi-step questions. Extensive benchmarking shows that our dataset\nprovides a challenge for frontier open-source and proprietary models. We\nperform fine-grained error analysis to identify common failure modes across\nvarious models, and create a taxonomy of reasoning errors. We use this to\nexplore both human and LLM-as-a-judge methods for scoring video reasoning\ntraces, and find that failure modes are primarily related to temporal\nlocalization, followed by visual perception errors, as opposed to logical or\ncompleteness errors. The dataset, along with questions, answer candidates and\nreasoning traces will be publicly available under\nhttps://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-05-01T17:41:49Z"}
{"aid":"http://arxiv.org/abs/2505.00702v1","title":"RayZer: A Self-supervised Large View Synthesis Model","summary":"We present RayZer, a self-supervised multi-view 3D Vision model trained\nwithout any 3D supervision, i.e., camera poses and scene geometry, while\nexhibiting emerging 3D awareness. Concretely, RayZer takes unposed and\nuncalibrated images as input, recovers camera parameters, reconstructs a scene\nrepresentation, and synthesizes novel views. During training, RayZer relies\nsolely on its self-predicted camera poses to render target views, eliminating\nthe need for any ground-truth camera annotations and allowing RayZer to be\ntrained with 2D image supervision. The emerging 3D awareness of RayZer is\nattributed to two key factors. First, we design a self-supervised framework,\nwhich achieves 3D-aware auto-encoding of input images by disentangling camera\nand scene representations. Second, we design a transformer-based model in which\nthe only 3D prior is the ray structure, connecting camera, pixel, and scene\nsimultaneously. RayZer demonstrates comparable or even superior novel view\nsynthesis performance than ``oracle'' methods that rely on pose annotations in\nboth training and testing. Project: https://hwjiang1510.github.io/RayZer/","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T17:59:34Z"}
